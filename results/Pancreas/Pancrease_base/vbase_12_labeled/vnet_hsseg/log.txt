[00:35:10.589] {'base_lr': 0.001,
 'batch_size': 4,
 'cfg': 'config_3d_pan_aut.yml',
 'consistency': 2.0,
 'consistency_rampup': 40,
 'deterministic': 1,
 'ema_decay': 0.99,
 'exp': 'Pancrease_base/vbase',
 'gpu_id': 5,
 'labeled_bs': 2,
 'labeled_num': 12,
 'max_iterations': 15000,
 'max_samples': 62,
 'model': 'vnet_hsseg',
 'num_classes': 2,
 'patch_size': [96, 96, 96],
 'poly': True,
 'res_path': './results/Pancreas',
 'root_path': '/home/chenyu/SSMIS/data/Pancreas',
 'save_interval_epoch': 1000000,
 'seed': 2025,
 'test_interval_ep': 4,
 'test_interval_iter': 200,
 'weight_his': 0.6,
 'workers': 4}
[00:35:11.239] 25 iterations per epoch
[00:35:13.280] iteration:1  t-loss:2.5679, loss-lb:2.5679, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:13.477] iteration:2  t-loss:1.7975, loss-lb:1.7975, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:13.661] iteration:3  t-loss:1.5268, loss-lb:1.5268, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:13.853] iteration:4  t-loss:1.4728, loss-lb:1.4728, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:14.040] iteration:5  t-loss:1.3823, loss-lb:1.3823, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:14.229] iteration:6  t-loss:1.4050, loss-lb:1.4050, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:14.416] iteration:7  t-loss:1.3842, loss-lb:1.3842, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:14.606] iteration:8  t-loss:1.2958, loss-lb:1.2958, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:14.794] iteration:9  t-loss:1.3403, loss-lb:1.3403, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:14.987] iteration:10  t-loss:1.8292, loss-lb:1.8292, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:15.169] iteration:11  t-loss:1.4090, loss-lb:1.4090, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:15.354] iteration:12  t-loss:1.4601, loss-lb:1.4601, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:15.547] iteration:13  t-loss:1.2146, loss-lb:1.2146, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:15.727] iteration:14  t-loss:1.7107, loss-lb:1.7107, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:15.926] iteration:15  t-loss:1.8613, loss-lb:1.8613, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:16.110] iteration:16  t-loss:1.5313, loss-lb:1.5313, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:16.297] iteration:17  t-loss:1.3799, loss-lb:1.3799, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:16.482] iteration:18  t-loss:1.5177, loss-lb:1.5177, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:16.662] iteration:19  t-loss:1.6559, loss-lb:1.6559, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:16.836] iteration:20  t-loss:1.2242, loss-lb:1.2242, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:17.014] iteration:21  t-loss:1.2098, loss-lb:1.2098, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:17.192] iteration:22  t-loss:1.1606, loss-lb:1.1606, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:17.367] iteration:23  t-loss:1.2815, loss-lb:1.2815, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:17.541] iteration:24  t-loss:1.2465, loss-lb:1.2465, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:35:17.715] iteration:25  t-loss:1.1127, loss-lb:1.1127, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:34.108] iteration 25 : dice_score: 0.101850 best_dice: 0.101900
[00:37:34.108]  <<Test>> - Ep:0  - Dice-S/T:10.19/10.19, Best-S:10.19, Best-T:10.19
[00:37:34.108]           - AvgLoss(lb/ulb/all):1.48/0.00/1.41
[00:37:35.299] iteration:26  t-loss:1.1809, loss-lb:1.1809, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:35.509] iteration:27  t-loss:1.2491, loss-lb:1.2491, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:35.709] iteration:28  t-loss:1.2936, loss-lb:1.2936, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:35.903] iteration:29  t-loss:1.2526, loss-lb:1.2526, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:36.117] iteration:30  t-loss:1.2956, loss-lb:1.2956, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:36.323] iteration:31  t-loss:1.2536, loss-lb:1.2536, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:36.523] iteration:32  t-loss:1.3045, loss-lb:1.3045, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:36.729] iteration:33  t-loss:1.1562, loss-lb:1.1562, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:36.926] iteration:34  t-loss:1.0697, loss-lb:1.0697, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:37.117] iteration:35  t-loss:1.0625, loss-lb:1.0625, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:37.312] iteration:36  t-loss:1.3032, loss-lb:1.3032, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:37.511] iteration:37  t-loss:1.0125, loss-lb:1.0125, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:37.712] iteration:38  t-loss:1.1663, loss-lb:1.1663, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:37.899] iteration:39  t-loss:1.3303, loss-lb:1.3303, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:38.086] iteration:40  t-loss:1.2443, loss-lb:1.2443, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:38.274] iteration:41  t-loss:1.2869, loss-lb:1.2869, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:38.467] iteration:42  t-loss:1.1511, loss-lb:1.1511, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:38.656] iteration:43  t-loss:1.1979, loss-lb:1.1979, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:38.838] iteration:44  t-loss:1.3516, loss-lb:1.3516, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:39.019] iteration:45  t-loss:1.1362, loss-lb:1.1362, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:39.201] iteration:46  t-loss:1.4107, loss-lb:1.4107, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:39.379] iteration:47  t-loss:1.2448, loss-lb:1.2448, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:39.557] iteration:48  t-loss:1.3273, loss-lb:1.3273, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:39.733] iteration:49  t-loss:1.0272, loss-lb:1.0272, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:39.910] iteration:50  t-loss:1.1328, loss-lb:1.1328, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:41.121] iteration:51  t-loss:1.1444, loss-lb:1.1444, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:41.330] iteration:52  t-loss:1.1917, loss-lb:1.1917, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:41.534] iteration:53  t-loss:1.0880, loss-lb:1.0880, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:41.753] iteration:54  t-loss:1.1860, loss-lb:1.1860, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:41.954] iteration:55  t-loss:1.0649, loss-lb:1.0649, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:42.158] iteration:56  t-loss:1.0478, loss-lb:1.0478, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:42.356] iteration:57  t-loss:1.1437, loss-lb:1.1437, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:42.547] iteration:58  t-loss:1.0261, loss-lb:1.0261, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:42.744] iteration:59  t-loss:1.1403, loss-lb:1.1403, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:42.949] iteration:60  t-loss:1.3309, loss-lb:1.3309, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:43.137] iteration:61  t-loss:0.9855, loss-lb:0.9855, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:43.327] iteration:62  t-loss:1.0110, loss-lb:1.0110, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:43.521] iteration:63  t-loss:1.0830, loss-lb:1.0830, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:43.710] iteration:64  t-loss:1.1631, loss-lb:1.1631, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:43.893] iteration:65  t-loss:1.2444, loss-lb:1.2444, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:44.079] iteration:66  t-loss:1.1878, loss-lb:1.1878, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:44.265] iteration:67  t-loss:1.0202, loss-lb:1.0202, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:44.448] iteration:68  t-loss:1.1573, loss-lb:1.1573, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:44.629] iteration:69  t-loss:1.1223, loss-lb:1.1223, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:44.809] iteration:70  t-loss:1.2270, loss-lb:1.2270, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:44.986] iteration:71  t-loss:0.9923, loss-lb:0.9923, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:45.163] iteration:72  t-loss:1.2088, loss-lb:1.2088, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:45.340] iteration:73  t-loss:0.8629, loss-lb:0.8629, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:45.516] iteration:74  t-loss:1.0204, loss-lb:1.0204, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:45.698] iteration:75  t-loss:1.0953, loss-lb:1.0953, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:46.722] iteration:76  t-loss:0.8902, loss-lb:0.8902, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:46.930] iteration:77  t-loss:1.0018, loss-lb:1.0018, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:47.127] iteration:78  t-loss:1.0208, loss-lb:1.0208, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:47.324] iteration:79  t-loss:0.9590, loss-lb:0.9590, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:47.518] iteration:80  t-loss:1.0481, loss-lb:1.0481, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:47.717] iteration:81  t-loss:1.0178, loss-lb:1.0178, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:47.911] iteration:82  t-loss:0.8858, loss-lb:0.8858, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:48.108] iteration:83  t-loss:1.1547, loss-lb:1.1547, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:48.300] iteration:84  t-loss:0.8489, loss-lb:0.8489, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:48.491] iteration:85  t-loss:1.3378, loss-lb:1.3378, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:48.682] iteration:86  t-loss:0.9063, loss-lb:0.9063, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:48.869] iteration:87  t-loss:1.0211, loss-lb:1.0211, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:49.055] iteration:88  t-loss:0.9770, loss-lb:0.9770, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:49.248] iteration:89  t-loss:1.0698, loss-lb:1.0698, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:49.439] iteration:90  t-loss:1.1377, loss-lb:1.1377, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:49.625] iteration:91  t-loss:0.9935, loss-lb:0.9935, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:49.813] iteration:92  t-loss:1.1608, loss-lb:1.1608, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:50.000] iteration:93  t-loss:0.9946, loss-lb:0.9946, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:50.187] iteration:94  t-loss:0.9508, loss-lb:0.9508, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:50.372] iteration:95  t-loss:1.1032, loss-lb:1.1032, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:50.551] iteration:96  t-loss:1.0221, loss-lb:1.0221, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:50.729] iteration:97  t-loss:1.3006, loss-lb:1.3006, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:50.910] iteration:98  t-loss:0.9795, loss-lb:0.9795, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:51.092] iteration:99  t-loss:1.0054, loss-lb:1.0054, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:51.276] iteration:100  t-loss:0.8608, loss-lb:0.8608, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:52.575] iteration:101  t-loss:0.9609, loss-lb:0.9609, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:52.787] iteration:102  t-loss:0.8428, loss-lb:0.8428, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:52.986] iteration:103  t-loss:1.0066, loss-lb:1.0066, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:53.189] iteration:104  t-loss:0.7986, loss-lb:0.7986, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:53.395] iteration:105  t-loss:1.1997, loss-lb:1.1997, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:53.588] iteration:106  t-loss:0.7214, loss-lb:0.7214, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:53.791] iteration:107  t-loss:0.8907, loss-lb:0.8907, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:53.990] iteration:108  t-loss:1.0109, loss-lb:1.0109, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:54.185] iteration:109  t-loss:0.6803, loss-lb:0.6803, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:54.377] iteration:110  t-loss:1.0167, loss-lb:1.0167, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:54.575] iteration:111  t-loss:0.8766, loss-lb:0.8766, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:54.764] iteration:112  t-loss:0.9828, loss-lb:0.9828, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:54.951] iteration:113  t-loss:0.9190, loss-lb:0.9190, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:55.138] iteration:114  t-loss:0.8135, loss-lb:0.8135, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:55.317] iteration:115  t-loss:0.9318, loss-lb:0.9318, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:55.510] iteration:116  t-loss:0.8957, loss-lb:0.8957, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:55.701] iteration:117  t-loss:0.8623, loss-lb:0.8623, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:55.886] iteration:118  t-loss:1.1812, loss-lb:1.1812, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:56.073] iteration:119  t-loss:1.3126, loss-lb:1.3126, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:56.255] iteration:120  t-loss:1.3675, loss-lb:1.3675, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:56.439] iteration:121  t-loss:0.9554, loss-lb:0.9554, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:56.625] iteration:122  t-loss:1.0723, loss-lb:1.0723, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:56.807] iteration:123  t-loss:0.8754, loss-lb:0.8754, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:56.987] iteration:124  t-loss:0.9007, loss-lb:0.9007, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:37:57.166] iteration:125  t-loss:0.9008, loss-lb:0.9008, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:06.688] iteration 125 : dice_score: 0.051394 best_dice: 0.101900
[00:40:06.689]  <<Test>> - Ep:4  - Dice-S/T:9.58/5.14, Best-S:10.19, Best-T:10.19
[00:40:06.689]           - AvgLoss(lb/ulb/all):0.96/0.00/0.96
[00:40:07.782] iteration:126  t-loss:1.1573, loss-lb:1.1573, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:07.974] iteration:127  t-loss:0.7501, loss-lb:0.7501, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:08.168] iteration:128  t-loss:0.9608, loss-lb:0.9608, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:08.354] iteration:129  t-loss:0.8927, loss-lb:0.8927, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:08.545] iteration:130  t-loss:0.8460, loss-lb:0.8460, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:08.730] iteration:131  t-loss:0.8323, loss-lb:0.8323, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:08.925] iteration:132  t-loss:1.0478, loss-lb:1.0478, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:09.102] iteration:133  t-loss:1.5258, loss-lb:1.5258, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:09.289] iteration:134  t-loss:0.9660, loss-lb:0.9660, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:09.475] iteration:135  t-loss:0.8302, loss-lb:0.8302, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:09.660] iteration:136  t-loss:0.6342, loss-lb:0.6342, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:09.846] iteration:137  t-loss:0.9707, loss-lb:0.9707, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:10.037] iteration:138  t-loss:1.1587, loss-lb:1.1587, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:10.223] iteration:139  t-loss:0.9573, loss-lb:0.9573, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:10.404] iteration:140  t-loss:0.8211, loss-lb:0.8211, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:10.589] iteration:141  t-loss:1.2642, loss-lb:1.2642, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:10.765] iteration:142  t-loss:0.9614, loss-lb:0.9614, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:10.946] iteration:143  t-loss:0.8544, loss-lb:0.8544, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:11.132] iteration:144  t-loss:0.8884, loss-lb:0.8884, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:11.310] iteration:145  t-loss:0.7710, loss-lb:0.7710, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:11.490] iteration:146  t-loss:0.8594, loss-lb:0.8594, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:11.669] iteration:147  t-loss:0.8259, loss-lb:0.8259, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:11.850] iteration:148  t-loss:1.1132, loss-lb:1.1132, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:12.032] iteration:149  t-loss:1.5408, loss-lb:1.5408, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:12.213] iteration:150  t-loss:0.9591, loss-lb:0.9591, loss-ulb:0.0000, weight:0.01, lr:0.0010
[00:40:13.273] iteration:151  t-loss:1.0891, loss-lb:1.0891, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:13.472] iteration:152  t-loss:0.8503, loss-lb:0.8503, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:13.670] iteration:153  t-loss:0.7839, loss-lb:0.7839, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:13.868] iteration:154  t-loss:0.8245, loss-lb:0.8245, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:14.061] iteration:155  t-loss:0.6197, loss-lb:0.6197, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:14.253] iteration:156  t-loss:0.8950, loss-lb:0.8950, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:14.445] iteration:157  t-loss:0.7831, loss-lb:0.7831, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:14.646] iteration:158  t-loss:1.0167, loss-lb:1.0167, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:14.831] iteration:159  t-loss:0.6934, loss-lb:0.6934, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:15.019] iteration:160  t-loss:0.9490, loss-lb:0.9490, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:15.212] iteration:161  t-loss:0.6000, loss-lb:0.6000, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:15.402] iteration:162  t-loss:0.9339, loss-lb:0.9339, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:15.594] iteration:163  t-loss:0.8837, loss-lb:0.8837, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:15.784] iteration:164  t-loss:0.7385, loss-lb:0.7385, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:15.970] iteration:165  t-loss:0.6973, loss-lb:0.6973, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:16.156] iteration:166  t-loss:0.7995, loss-lb:0.7995, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:16.347] iteration:167  t-loss:1.3616, loss-lb:1.3616, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:16.531] iteration:168  t-loss:0.8457, loss-lb:0.8457, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:16.712] iteration:169  t-loss:0.7015, loss-lb:0.7015, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:16.892] iteration:170  t-loss:0.7108, loss-lb:0.7108, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:17.073] iteration:171  t-loss:0.8999, loss-lb:0.8999, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:17.252] iteration:172  t-loss:0.8316, loss-lb:0.8316, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:17.431] iteration:173  t-loss:0.7647, loss-lb:0.7647, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:17.610] iteration:174  t-loss:1.1097, loss-lb:1.1097, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:17.793] iteration:175  t-loss:0.8005, loss-lb:0.8005, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:18.946] iteration:176  t-loss:1.1784, loss-lb:1.1784, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:19.145] iteration:177  t-loss:0.9211, loss-lb:0.9211, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:19.343] iteration:178  t-loss:0.7224, loss-lb:0.7224, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:19.539] iteration:179  t-loss:0.9200, loss-lb:0.9200, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:19.736] iteration:180  t-loss:0.8204, loss-lb:0.8204, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:19.932] iteration:181  t-loss:0.9471, loss-lb:0.9471, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:20.123] iteration:182  t-loss:0.7481, loss-lb:0.7481, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:20.325] iteration:183  t-loss:1.0572, loss-lb:1.0572, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:20.512] iteration:184  t-loss:0.8586, loss-lb:0.8586, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:20.701] iteration:185  t-loss:1.0391, loss-lb:1.0391, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:20.900] iteration:186  t-loss:0.9698, loss-lb:0.9698, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:21.092] iteration:187  t-loss:0.9260, loss-lb:0.9260, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:21.279] iteration:188  t-loss:0.8517, loss-lb:0.8517, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:21.474] iteration:189  t-loss:0.8557, loss-lb:0.8557, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:21.671] iteration:190  t-loss:0.7895, loss-lb:0.7895, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:21.852] iteration:191  t-loss:0.6850, loss-lb:0.6850, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:22.035] iteration:192  t-loss:0.8623, loss-lb:0.8623, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:22.218] iteration:193  t-loss:0.9998, loss-lb:0.9998, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:22.399] iteration:194  t-loss:0.9873, loss-lb:0.9873, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:22.577] iteration:195  t-loss:0.7467, loss-lb:0.7467, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:22.758] iteration:196  t-loss:0.6563, loss-lb:0.6563, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:22.937] iteration:197  t-loss:1.0221, loss-lb:1.0221, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:23.126] iteration:198  t-loss:1.0699, loss-lb:1.0699, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:23.313] iteration:199  t-loss:0.8452, loss-lb:0.8452, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:23.491] iteration:200  t-loss:0.7156, loss-lb:0.7156, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:24.508] iteration:201  t-loss:0.6882, loss-lb:0.6882, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:24.713] iteration:202  t-loss:0.8567, loss-lb:0.8567, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:24.908] iteration:203  t-loss:0.9230, loss-lb:0.9230, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:25.104] iteration:204  t-loss:0.8377, loss-lb:0.8377, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:25.300] iteration:205  t-loss:1.0145, loss-lb:1.0145, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:25.486] iteration:206  t-loss:0.8122, loss-lb:0.8122, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:25.678] iteration:207  t-loss:0.7707, loss-lb:0.7707, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:25.869] iteration:208  t-loss:0.9942, loss-lb:0.9942, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:26.055] iteration:209  t-loss:0.7522, loss-lb:0.7522, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:26.236] iteration:210  t-loss:0.7260, loss-lb:0.7260, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:26.426] iteration:211  t-loss:0.7407, loss-lb:0.7407, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:26.613] iteration:212  t-loss:1.0151, loss-lb:1.0151, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:26.801] iteration:213  t-loss:0.6890, loss-lb:0.6890, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:26.990] iteration:214  t-loss:0.9776, loss-lb:0.9776, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:27.180] iteration:215  t-loss:0.7775, loss-lb:0.7775, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:27.365] iteration:216  t-loss:0.6341, loss-lb:0.6341, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:27.553] iteration:217  t-loss:1.0347, loss-lb:1.0347, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:27.744] iteration:218  t-loss:0.7266, loss-lb:0.7266, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:27.929] iteration:219  t-loss:0.8890, loss-lb:0.8890, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:28.111] iteration:220  t-loss:0.6830, loss-lb:0.6830, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:28.293] iteration:221  t-loss:0.9424, loss-lb:0.9424, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:28.474] iteration:222  t-loss:0.7652, loss-lb:0.7652, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:28.669] iteration:223  t-loss:0.8368, loss-lb:0.8368, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:28.851] iteration:224  t-loss:0.8011, loss-lb:0.8011, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:40:29.028] iteration:225  t-loss:0.7007, loss-lb:0.7007, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:51.310] iteration 225 : dice_score: 0.582405 best_dice: 0.582400
[00:42:51.311]  <<Test>> - Ep:8  - Dice-S/T:39.39/58.24, Best-S:39.39, Best-T:58.24
[00:42:51.311]           - AvgLoss(lb/ulb/all):0.82/0.00/0.81
[00:42:52.408] iteration:226  t-loss:0.5743, loss-lb:0.5743, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:52.624] iteration:227  t-loss:1.0449, loss-lb:1.0449, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:52.833] iteration:228  t-loss:1.0015, loss-lb:1.0015, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:53.047] iteration:229  t-loss:0.6235, loss-lb:0.6235, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:53.258] iteration:230  t-loss:0.4583, loss-lb:0.4583, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:53.464] iteration:231  t-loss:1.1741, loss-lb:1.1741, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:53.672] iteration:232  t-loss:0.9432, loss-lb:0.9432, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:53.874] iteration:233  t-loss:1.0297, loss-lb:1.0297, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:54.082] iteration:234  t-loss:0.7357, loss-lb:0.7357, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:54.298] iteration:235  t-loss:0.5891, loss-lb:0.5891, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:54.506] iteration:236  t-loss:0.7248, loss-lb:0.7248, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:54.711] iteration:237  t-loss:0.6385, loss-lb:0.6385, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:54.919] iteration:238  t-loss:0.7826, loss-lb:0.7826, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:55.116] iteration:239  t-loss:0.8667, loss-lb:0.8667, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:55.311] iteration:240  t-loss:0.6268, loss-lb:0.6268, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:55.506] iteration:241  t-loss:0.5562, loss-lb:0.5562, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:55.700] iteration:242  t-loss:0.6364, loss-lb:0.6364, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:55.891] iteration:243  t-loss:0.8693, loss-lb:0.8693, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:56.077] iteration:244  t-loss:0.7329, loss-lb:0.7329, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:56.257] iteration:245  t-loss:0.8232, loss-lb:0.8232, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:56.442] iteration:246  t-loss:1.0251, loss-lb:1.0251, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:56.624] iteration:247  t-loss:0.8165, loss-lb:0.8165, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:56.808] iteration:248  t-loss:0.7270, loss-lb:0.7270, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:56.988] iteration:249  t-loss:0.5199, loss-lb:0.5199, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:57.170] iteration:250  t-loss:0.7359, loss-lb:0.7359, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:58.414] iteration:251  t-loss:0.8387, loss-lb:0.8387, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:58.615] iteration:252  t-loss:0.8597, loss-lb:0.8597, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:58.815] iteration:253  t-loss:1.0303, loss-lb:1.0303, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:59.008] iteration:254  t-loss:0.7757, loss-lb:0.7757, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:59.204] iteration:255  t-loss:0.5969, loss-lb:0.5969, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:59.398] iteration:256  t-loss:1.0044, loss-lb:1.0044, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:59.595] iteration:257  t-loss:0.6058, loss-lb:0.6058, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:59.787] iteration:258  t-loss:1.1346, loss-lb:1.1346, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:42:59.983] iteration:259  t-loss:1.0638, loss-lb:1.0638, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:00.174] iteration:260  t-loss:0.5711, loss-lb:0.5711, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:00.365] iteration:261  t-loss:1.1705, loss-lb:1.1705, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:00.558] iteration:262  t-loss:0.7733, loss-lb:0.7733, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:00.747] iteration:263  t-loss:0.7460, loss-lb:0.7460, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:00.949] iteration:264  t-loss:1.2384, loss-lb:1.2384, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:01.142] iteration:265  t-loss:1.0002, loss-lb:1.0002, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:01.334] iteration:266  t-loss:0.7348, loss-lb:0.7348, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:01.539] iteration:267  t-loss:0.7764, loss-lb:0.7764, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:01.724] iteration:268  t-loss:0.7516, loss-lb:0.7516, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:01.904] iteration:269  t-loss:0.5527, loss-lb:0.5527, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:02.086] iteration:270  t-loss:1.0241, loss-lb:1.0241, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:02.269] iteration:271  t-loss:0.5650, loss-lb:0.5650, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:02.450] iteration:272  t-loss:1.5894, loss-lb:1.5894, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:02.633] iteration:273  t-loss:0.6793, loss-lb:0.6793, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:02.817] iteration:274  t-loss:0.8983, loss-lb:0.8983, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:02.997] iteration:275  t-loss:1.0204, loss-lb:1.0204, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:04.293] iteration:276  t-loss:0.5095, loss-lb:0.5095, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:04.491] iteration:277  t-loss:0.6806, loss-lb:0.6806, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:04.692] iteration:278  t-loss:0.5640, loss-lb:0.5640, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:04.887] iteration:279  t-loss:0.7482, loss-lb:0.7482, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:05.092] iteration:280  t-loss:0.6189, loss-lb:0.6189, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:05.292] iteration:281  t-loss:1.0260, loss-lb:1.0260, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:05.489] iteration:282  t-loss:0.5829, loss-lb:0.5829, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:05.690] iteration:283  t-loss:0.7315, loss-lb:0.7315, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:05.881] iteration:284  t-loss:0.6623, loss-lb:0.6623, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:06.079] iteration:285  t-loss:0.6302, loss-lb:0.6302, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:06.275] iteration:286  t-loss:0.6809, loss-lb:0.6809, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:06.466] iteration:287  t-loss:0.6345, loss-lb:0.6345, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:06.668] iteration:288  t-loss:1.1705, loss-lb:1.1705, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:06.876] iteration:289  t-loss:0.5590, loss-lb:0.5590, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:07.069] iteration:290  t-loss:0.8300, loss-lb:0.8300, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:07.262] iteration:291  t-loss:0.4411, loss-lb:0.4411, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:07.461] iteration:292  t-loss:0.5575, loss-lb:0.5575, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:07.650] iteration:293  t-loss:0.9900, loss-lb:0.9900, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:07.839] iteration:294  t-loss:0.7068, loss-lb:0.7068, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:08.024] iteration:295  t-loss:0.5164, loss-lb:0.5164, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:08.207] iteration:296  t-loss:0.7970, loss-lb:0.7970, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:08.389] iteration:297  t-loss:0.5061, loss-lb:0.5061, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:08.570] iteration:298  t-loss:0.5130, loss-lb:0.5130, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:08.758] iteration:299  t-loss:0.7308, loss-lb:0.7308, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:08.943] iteration:300  t-loss:0.5245, loss-lb:0.5245, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:10.154] iteration:301  t-loss:0.5801, loss-lb:0.5801, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:10.360] iteration:302  t-loss:1.2754, loss-lb:1.2754, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:10.562] iteration:303  t-loss:0.7469, loss-lb:0.7469, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:10.759] iteration:304  t-loss:0.9680, loss-lb:0.9680, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:10.954] iteration:305  t-loss:0.7461, loss-lb:0.7461, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:11.156] iteration:306  t-loss:1.0038, loss-lb:1.0038, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:11.351] iteration:307  t-loss:0.5081, loss-lb:0.5081, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:11.550] iteration:308  t-loss:0.7420, loss-lb:0.7420, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:11.743] iteration:309  t-loss:0.8526, loss-lb:0.8526, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:11.935] iteration:310  t-loss:0.5517, loss-lb:0.5517, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:12.129] iteration:311  t-loss:0.5194, loss-lb:0.5194, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:12.322] iteration:312  t-loss:0.5089, loss-lb:0.5089, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:12.506] iteration:313  t-loss:0.6951, loss-lb:0.6951, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:12.701] iteration:314  t-loss:0.6351, loss-lb:0.6351, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:12.894] iteration:315  t-loss:0.6019, loss-lb:0.6019, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:13.086] iteration:316  t-loss:0.9246, loss-lb:0.9246, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:13.271] iteration:317  t-loss:0.6478, loss-lb:0.6478, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:13.457] iteration:318  t-loss:0.5296, loss-lb:0.5296, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:13.637] iteration:319  t-loss:0.4382, loss-lb:0.4382, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:13.820] iteration:320  t-loss:0.5735, loss-lb:0.5735, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:14.001] iteration:321  t-loss:0.7260, loss-lb:0.7260, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:14.183] iteration:322  t-loss:0.6136, loss-lb:0.6136, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:14.362] iteration:323  t-loss:0.5949, loss-lb:0.5949, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:14.543] iteration:324  t-loss:0.5798, loss-lb:0.5798, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:43:14.723] iteration:325  t-loss:0.5140, loss-lb:0.5140, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:45.327] iteration 325 : dice_score: 0.606068 best_dice: 0.606100
[00:45:45.327]  <<Test>> - Ep:12  - Dice-S/T:55.50/60.61, Best-S:55.50, Best-T:60.61
[00:45:45.327]           - AvgLoss(lb/ulb/all):0.68/0.00/0.64
[00:45:46.545] iteration:326  t-loss:0.6920, loss-lb:0.6920, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:46.761] iteration:327  t-loss:0.6071, loss-lb:0.6071, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:46.968] iteration:328  t-loss:0.7350, loss-lb:0.7350, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:47.169] iteration:329  t-loss:0.8240, loss-lb:0.8240, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:47.375] iteration:330  t-loss:0.5041, loss-lb:0.5041, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:47.571] iteration:331  t-loss:0.8842, loss-lb:0.8842, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:47.773] iteration:332  t-loss:0.8947, loss-lb:0.8947, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:47.969] iteration:333  t-loss:0.7614, loss-lb:0.7614, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:48.184] iteration:334  t-loss:1.3025, loss-lb:1.3025, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:48.380] iteration:335  t-loss:0.7679, loss-lb:0.7679, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:48.578] iteration:336  t-loss:0.7490, loss-lb:0.7490, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:48.778] iteration:337  t-loss:0.4825, loss-lb:0.4825, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:48.978] iteration:338  t-loss:0.8798, loss-lb:0.8798, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:49.182] iteration:339  t-loss:0.6082, loss-lb:0.6082, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:49.369] iteration:340  t-loss:0.5103, loss-lb:0.5103, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:49.558] iteration:341  t-loss:0.8061, loss-lb:0.8061, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:49.744] iteration:342  t-loss:0.6863, loss-lb:0.6863, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:49.933] iteration:343  t-loss:1.0264, loss-lb:1.0264, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:50.118] iteration:344  t-loss:0.6835, loss-lb:0.6835, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:50.305] iteration:345  t-loss:0.6289, loss-lb:0.6289, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:50.491] iteration:346  t-loss:0.6324, loss-lb:0.6324, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:50.676] iteration:347  t-loss:0.6591, loss-lb:0.6591, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:50.864] iteration:348  t-loss:0.7047, loss-lb:0.7047, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:51.048] iteration:349  t-loss:0.6930, loss-lb:0.6930, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:51.232] iteration:350  t-loss:1.1396, loss-lb:1.1396, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:52.488] iteration:351  t-loss:1.0399, loss-lb:1.0399, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:52.689] iteration:352  t-loss:0.4631, loss-lb:0.4631, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:52.902] iteration:353  t-loss:1.0447, loss-lb:1.0447, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:53.094] iteration:354  t-loss:0.5277, loss-lb:0.5277, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:53.296] iteration:355  t-loss:0.5683, loss-lb:0.5683, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:53.488] iteration:356  t-loss:0.5452, loss-lb:0.5452, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:53.681] iteration:357  t-loss:0.8956, loss-lb:0.8956, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:53.874] iteration:358  t-loss:1.1090, loss-lb:1.1090, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:54.063] iteration:359  t-loss:1.0237, loss-lb:1.0237, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:54.293] iteration:360  t-loss:0.7147, loss-lb:0.7147, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:54.488] iteration:361  t-loss:0.8023, loss-lb:0.8023, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:54.682] iteration:362  t-loss:0.8889, loss-lb:0.8889, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:54.878] iteration:363  t-loss:0.8262, loss-lb:0.8262, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:55.069] iteration:364  t-loss:0.4754, loss-lb:0.4754, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:55.265] iteration:365  t-loss:0.6356, loss-lb:0.6356, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:55.457] iteration:366  t-loss:0.6864, loss-lb:0.6864, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:55.649] iteration:367  t-loss:0.6256, loss-lb:0.6256, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:55.842] iteration:368  t-loss:0.6377, loss-lb:0.6377, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:56.035] iteration:369  t-loss:0.4151, loss-lb:0.4151, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:56.221] iteration:370  t-loss:0.9887, loss-lb:0.9887, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:56.409] iteration:371  t-loss:0.6057, loss-lb:0.6057, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:56.592] iteration:372  t-loss:1.0909, loss-lb:1.0909, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:56.775] iteration:373  t-loss:0.4805, loss-lb:0.4805, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:56.959] iteration:374  t-loss:0.6463, loss-lb:0.6463, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:57.148] iteration:375  t-loss:1.3184, loss-lb:1.3184, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:58.635] iteration:376  t-loss:0.4669, loss-lb:0.4669, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:58.862] iteration:377  t-loss:0.8583, loss-lb:0.8583, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:59.079] iteration:378  t-loss:0.6519, loss-lb:0.6519, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:59.298] iteration:379  t-loss:1.0540, loss-lb:1.0540, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:59.509] iteration:380  t-loss:0.9767, loss-lb:0.9767, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:59.721] iteration:381  t-loss:0.6686, loss-lb:0.6686, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:45:59.927] iteration:382  t-loss:0.6457, loss-lb:0.6457, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:00.131] iteration:383  t-loss:0.6030, loss-lb:0.6030, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:00.346] iteration:384  t-loss:0.6152, loss-lb:0.6152, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:00.553] iteration:385  t-loss:0.9394, loss-lb:0.9394, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:00.759] iteration:386  t-loss:1.0615, loss-lb:1.0615, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:00.967] iteration:387  t-loss:0.7088, loss-lb:0.7088, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:01.176] iteration:388  t-loss:0.5472, loss-lb:0.5472, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:01.369] iteration:389  t-loss:0.5174, loss-lb:0.5174, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:01.565] iteration:390  t-loss:0.4947, loss-lb:0.4947, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:01.758] iteration:391  t-loss:0.5616, loss-lb:0.5616, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:01.959] iteration:392  t-loss:0.6413, loss-lb:0.6413, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:02.159] iteration:393  t-loss:0.6489, loss-lb:0.6489, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:02.342] iteration:394  t-loss:0.6834, loss-lb:0.6834, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:02.527] iteration:395  t-loss:0.6122, loss-lb:0.6122, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:02.708] iteration:396  t-loss:0.7233, loss-lb:0.7233, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:02.907] iteration:397  t-loss:0.4963, loss-lb:0.4963, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:03.097] iteration:398  t-loss:0.5444, loss-lb:0.5444, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:03.288] iteration:399  t-loss:0.7142, loss-lb:0.7142, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:03.476] iteration:400  t-loss:0.5681, loss-lb:0.5681, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:04.617] iteration:401  t-loss:0.6425, loss-lb:0.6425, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:04.822] iteration:402  t-loss:0.5557, loss-lb:0.5557, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:05.024] iteration:403  t-loss:0.4874, loss-lb:0.4874, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:05.240] iteration:404  t-loss:0.5597, loss-lb:0.5597, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:05.443] iteration:405  t-loss:0.8534, loss-lb:0.8534, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:05.647] iteration:406  t-loss:0.8627, loss-lb:0.8627, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:05.848] iteration:407  t-loss:1.2104, loss-lb:1.2104, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:06.040] iteration:408  t-loss:0.5127, loss-lb:0.5127, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:06.243] iteration:409  t-loss:0.9380, loss-lb:0.9380, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:06.449] iteration:410  t-loss:0.5211, loss-lb:0.5211, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:06.657] iteration:411  t-loss:0.6535, loss-lb:0.6535, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:06.856] iteration:412  t-loss:0.7848, loss-lb:0.7848, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:07.066] iteration:413  t-loss:0.7257, loss-lb:0.7257, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:07.264] iteration:414  t-loss:0.8540, loss-lb:0.8540, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:07.459] iteration:415  t-loss:0.5065, loss-lb:0.5065, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:07.663] iteration:416  t-loss:0.9967, loss-lb:0.9967, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:07.858] iteration:417  t-loss:0.4731, loss-lb:0.4731, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:08.045] iteration:418  t-loss:0.6124, loss-lb:0.6124, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:08.237] iteration:419  t-loss:0.5688, loss-lb:0.5688, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:08.418] iteration:420  t-loss:0.8728, loss-lb:0.8728, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:08.599] iteration:421  t-loss:0.4752, loss-lb:0.4752, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:08.785] iteration:422  t-loss:0.9295, loss-lb:0.9295, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:08.966] iteration:423  t-loss:0.4745, loss-lb:0.4745, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:09.149] iteration:424  t-loss:0.6143, loss-lb:0.6143, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:46:09.328] iteration:425  t-loss:0.5368, loss-lb:0.5368, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:23.770] iteration 425 : dice_score: 0.676533 best_dice: 0.676500
[00:48:23.771]  <<Test>> - Ep:16  - Dice-S/T:53.08/67.65, Best-S:55.50, Best-T:67.65
[00:48:23.771]           - AvgLoss(lb/ulb/all):0.69/0.00/0.71
[00:48:24.851] iteration:426  t-loss:0.5493, loss-lb:0.5493, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:25.071] iteration:427  t-loss:1.0662, loss-lb:1.0662, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:25.263] iteration:428  t-loss:0.5543, loss-lb:0.5543, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:25.464] iteration:429  t-loss:0.7057, loss-lb:0.7057, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:25.643] iteration:430  t-loss:0.6662, loss-lb:0.6662, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:25.833] iteration:431  t-loss:0.5698, loss-lb:0.5698, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:26.028] iteration:432  t-loss:0.7771, loss-lb:0.7771, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:26.227] iteration:433  t-loss:0.5805, loss-lb:0.5805, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:26.422] iteration:434  t-loss:0.5451, loss-lb:0.5451, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:26.612] iteration:435  t-loss:0.4757, loss-lb:0.4757, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:26.803] iteration:436  t-loss:0.8603, loss-lb:0.8603, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:26.994] iteration:437  t-loss:0.8326, loss-lb:0.8326, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:27.189] iteration:438  t-loss:0.6450, loss-lb:0.6450, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:27.380] iteration:439  t-loss:0.4412, loss-lb:0.4412, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:27.576] iteration:440  t-loss:0.3883, loss-lb:0.3883, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:27.770] iteration:441  t-loss:0.8779, loss-lb:0.8779, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:27.966] iteration:442  t-loss:0.7868, loss-lb:0.7868, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:28.151] iteration:443  t-loss:0.4330, loss-lb:0.4330, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:28.331] iteration:444  t-loss:0.5579, loss-lb:0.5579, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:28.516] iteration:445  t-loss:0.6503, loss-lb:0.6503, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:28.698] iteration:446  t-loss:0.8411, loss-lb:0.8411, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:28.879] iteration:447  t-loss:0.5416, loss-lb:0.5416, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:29.060] iteration:448  t-loss:0.8385, loss-lb:0.8385, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:29.245] iteration:449  t-loss:0.5701, loss-lb:0.5701, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:29.428] iteration:450  t-loss:0.5993, loss-lb:0.5993, loss-ulb:0.0000, weight:0.02, lr:0.0010
[00:48:30.484] iteration:451  t-loss:0.7692, loss-lb:0.7692, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:30.687] iteration:452  t-loss:0.6528, loss-lb:0.6528, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:30.882] iteration:453  t-loss:0.8713, loss-lb:0.8713, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:31.076] iteration:454  t-loss:0.6204, loss-lb:0.6204, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:31.278] iteration:455  t-loss:1.0304, loss-lb:1.0304, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:31.478] iteration:456  t-loss:0.3837, loss-lb:0.3837, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:31.679] iteration:457  t-loss:0.6562, loss-lb:0.6562, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:31.879] iteration:458  t-loss:0.5986, loss-lb:0.5986, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:32.080] iteration:459  t-loss:0.3355, loss-lb:0.3355, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:32.278] iteration:460  t-loss:0.8098, loss-lb:0.8098, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:32.482] iteration:461  t-loss:0.6733, loss-lb:0.6733, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:32.684] iteration:462  t-loss:0.5299, loss-lb:0.5299, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:32.908] iteration:463  t-loss:0.3900, loss-lb:0.3900, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:33.100] iteration:464  t-loss:0.4457, loss-lb:0.4457, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:33.295] iteration:465  t-loss:0.5425, loss-lb:0.5425, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:33.488] iteration:466  t-loss:0.5717, loss-lb:0.5717, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:33.680] iteration:467  t-loss:0.6939, loss-lb:0.6939, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:33.868] iteration:468  t-loss:0.5617, loss-lb:0.5617, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:34.052] iteration:469  t-loss:0.8173, loss-lb:0.8173, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:34.231] iteration:470  t-loss:0.6533, loss-lb:0.6533, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:34.415] iteration:471  t-loss:0.7416, loss-lb:0.7416, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:34.598] iteration:472  t-loss:0.6410, loss-lb:0.6410, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:34.779] iteration:473  t-loss:0.5273, loss-lb:0.5273, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:34.962] iteration:474  t-loss:0.4360, loss-lb:0.4360, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:35.141] iteration:475  t-loss:0.3924, loss-lb:0.3924, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:36.251] iteration:476  t-loss:0.5657, loss-lb:0.5657, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:36.463] iteration:477  t-loss:0.6237, loss-lb:0.6237, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:36.680] iteration:478  t-loss:0.9338, loss-lb:0.9338, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:36.881] iteration:479  t-loss:0.4810, loss-lb:0.4810, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:37.078] iteration:480  t-loss:0.8466, loss-lb:0.8466, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:37.270] iteration:481  t-loss:0.4397, loss-lb:0.4397, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:37.469] iteration:482  t-loss:0.5339, loss-lb:0.5339, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:37.660] iteration:483  t-loss:0.5446, loss-lb:0.5446, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:37.848] iteration:484  t-loss:0.4237, loss-lb:0.4237, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:38.038] iteration:485  t-loss:0.5529, loss-lb:0.5529, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:38.231] iteration:486  t-loss:0.4375, loss-lb:0.4375, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:38.425] iteration:487  t-loss:0.7616, loss-lb:0.7616, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:38.620] iteration:488  t-loss:0.5689, loss-lb:0.5689, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:38.812] iteration:489  t-loss:0.8540, loss-lb:0.8540, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:38.998] iteration:490  t-loss:1.7247, loss-lb:1.7247, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:39.189] iteration:491  t-loss:0.4768, loss-lb:0.4768, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:39.375] iteration:492  t-loss:0.6683, loss-lb:0.6683, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:39.564] iteration:493  t-loss:0.4787, loss-lb:0.4787, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:39.745] iteration:494  t-loss:0.5113, loss-lb:0.5113, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:39.929] iteration:495  t-loss:0.4934, loss-lb:0.4934, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:40.128] iteration:496  t-loss:0.8972, loss-lb:0.8972, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:40.328] iteration:497  t-loss:0.7640, loss-lb:0.7640, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:40.527] iteration:498  t-loss:0.4607, loss-lb:0.4607, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:40.720] iteration:499  t-loss:0.7153, loss-lb:0.7153, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:40.923] iteration:500  t-loss:0.5917, loss-lb:0.5917, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:42.604] iteration:501  t-loss:0.8455, loss-lb:0.8455, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:42.837] iteration:502  t-loss:0.4524, loss-lb:0.4524, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:43.060] iteration:503  t-loss:0.5340, loss-lb:0.5340, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:43.287] iteration:504  t-loss:0.9573, loss-lb:0.9573, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:43.501] iteration:505  t-loss:0.5503, loss-lb:0.5503, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:43.722] iteration:506  t-loss:0.6801, loss-lb:0.6801, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:43.942] iteration:507  t-loss:0.8435, loss-lb:0.8435, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:44.164] iteration:508  t-loss:0.8946, loss-lb:0.8946, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:44.370] iteration:509  t-loss:0.4441, loss-lb:0.4441, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:44.571] iteration:510  t-loss:0.3780, loss-lb:0.3780, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:44.769] iteration:511  t-loss:0.4995, loss-lb:0.4995, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:44.971] iteration:512  t-loss:0.8223, loss-lb:0.8223, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:45.157] iteration:513  t-loss:0.6468, loss-lb:0.6468, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:45.345] iteration:514  t-loss:0.6368, loss-lb:0.6368, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:45.531] iteration:515  t-loss:0.4937, loss-lb:0.4937, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:45.714] iteration:516  t-loss:0.2980, loss-lb:0.2980, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:45.894] iteration:517  t-loss:0.5438, loss-lb:0.5438, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:46.076] iteration:518  t-loss:1.1770, loss-lb:1.1770, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:46.256] iteration:519  t-loss:0.5000, loss-lb:0.5000, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:46.436] iteration:520  t-loss:0.5738, loss-lb:0.5738, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:46.614] iteration:521  t-loss:0.4478, loss-lb:0.4478, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:46.795] iteration:522  t-loss:0.7896, loss-lb:0.7896, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:46.971] iteration:523  t-loss:0.4461, loss-lb:0.4461, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:47.150] iteration:524  t-loss:1.0009, loss-lb:1.0009, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:48:47.330] iteration:525  t-loss:0.5808, loss-lb:0.5808, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:09.076] iteration 525 : dice_score: 0.671061 best_dice: 0.676500
[00:51:09.077]  <<Test>> - Ep:20  - Dice-S/T:59.80/67.11, Best-S:59.80, Best-T:67.65
[00:51:09.077]           - AvgLoss(lb/ulb/all):0.64/0.00/0.63
[00:51:10.220] iteration:526  t-loss:1.2653, loss-lb:1.2653, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:10.423] iteration:527  t-loss:0.4818, loss-lb:0.4818, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:10.621] iteration:528  t-loss:0.4606, loss-lb:0.4606, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:10.820] iteration:529  t-loss:0.3763, loss-lb:0.3763, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:11.031] iteration:530  t-loss:0.4946, loss-lb:0.4946, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:11.224] iteration:531  t-loss:0.5980, loss-lb:0.5980, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:11.419] iteration:532  t-loss:0.7549, loss-lb:0.7549, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:11.611] iteration:533  t-loss:0.2948, loss-lb:0.2948, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:11.808] iteration:534  t-loss:0.4272, loss-lb:0.4272, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:12.000] iteration:535  t-loss:0.5747, loss-lb:0.5747, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:12.187] iteration:536  t-loss:0.4527, loss-lb:0.4527, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:12.379] iteration:537  t-loss:0.5224, loss-lb:0.5224, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:12.579] iteration:538  t-loss:0.8565, loss-lb:0.8565, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:12.781] iteration:539  t-loss:0.4947, loss-lb:0.4947, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:12.979] iteration:540  t-loss:0.3756, loss-lb:0.3756, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:13.177] iteration:541  t-loss:0.3928, loss-lb:0.3928, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:13.381] iteration:542  t-loss:0.4113, loss-lb:0.4113, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:13.569] iteration:543  t-loss:0.4851, loss-lb:0.4851, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:13.758] iteration:544  t-loss:0.5307, loss-lb:0.5307, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:13.939] iteration:545  t-loss:0.3660, loss-lb:0.3660, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:14.126] iteration:546  t-loss:0.4895, loss-lb:0.4895, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:14.307] iteration:547  t-loss:0.4749, loss-lb:0.4749, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:14.491] iteration:548  t-loss:0.8614, loss-lb:0.8614, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:14.674] iteration:549  t-loss:0.3676, loss-lb:0.3676, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:14.856] iteration:550  t-loss:0.4693, loss-lb:0.4693, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:15.910] iteration:551  t-loss:0.3900, loss-lb:0.3900, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:16.125] iteration:552  t-loss:0.6915, loss-lb:0.6915, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:16.343] iteration:553  t-loss:0.5106, loss-lb:0.5106, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:16.547] iteration:554  t-loss:0.3993, loss-lb:0.3993, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:16.755] iteration:555  t-loss:0.4032, loss-lb:0.4032, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:16.965] iteration:556  t-loss:0.6419, loss-lb:0.6419, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:17.165] iteration:557  t-loss:0.7632, loss-lb:0.7632, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:17.361] iteration:558  t-loss:0.6592, loss-lb:0.6592, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:17.560] iteration:559  t-loss:0.8994, loss-lb:0.8994, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:17.756] iteration:560  t-loss:0.6489, loss-lb:0.6489, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:17.946] iteration:561  t-loss:0.5088, loss-lb:0.5088, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:18.138] iteration:562  t-loss:0.5132, loss-lb:0.5132, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:18.336] iteration:563  t-loss:0.7068, loss-lb:0.7068, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:18.540] iteration:564  t-loss:0.5300, loss-lb:0.5300, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:18.729] iteration:565  t-loss:0.7255, loss-lb:0.7255, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:18.922] iteration:566  t-loss:0.5287, loss-lb:0.5287, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:19.123] iteration:567  t-loss:0.6633, loss-lb:0.6633, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:19.316] iteration:568  t-loss:0.4885, loss-lb:0.4885, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:19.504] iteration:569  t-loss:0.4717, loss-lb:0.4717, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:19.690] iteration:570  t-loss:0.4119, loss-lb:0.4119, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:19.870] iteration:571  t-loss:0.8567, loss-lb:0.8567, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:20.049] iteration:572  t-loss:0.5703, loss-lb:0.5703, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:20.234] iteration:573  t-loss:0.6884, loss-lb:0.6884, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:20.413] iteration:574  t-loss:0.4005, loss-lb:0.4005, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:20.590] iteration:575  t-loss:0.7922, loss-lb:0.7922, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:21.671] iteration:576  t-loss:0.4967, loss-lb:0.4967, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:21.878] iteration:577  t-loss:0.3866, loss-lb:0.3866, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:22.078] iteration:578  t-loss:0.6272, loss-lb:0.6272, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:22.277] iteration:579  t-loss:0.3218, loss-lb:0.3218, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:22.475] iteration:580  t-loss:0.3921, loss-lb:0.3921, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:22.671] iteration:581  t-loss:0.8850, loss-lb:0.8850, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:22.858] iteration:582  t-loss:0.4619, loss-lb:0.4619, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:23.053] iteration:583  t-loss:0.4010, loss-lb:0.4010, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:23.243] iteration:584  t-loss:0.4442, loss-lb:0.4442, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:23.445] iteration:585  t-loss:0.8926, loss-lb:0.8926, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:23.635] iteration:586  t-loss:0.5599, loss-lb:0.5599, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:23.833] iteration:587  t-loss:0.6074, loss-lb:0.6074, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:24.020] iteration:588  t-loss:0.3946, loss-lb:0.3946, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:24.206] iteration:589  t-loss:0.3863, loss-lb:0.3863, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:24.404] iteration:590  t-loss:0.5162, loss-lb:0.5162, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:24.593] iteration:591  t-loss:0.6725, loss-lb:0.6725, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:24.780] iteration:592  t-loss:0.4503, loss-lb:0.4503, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:24.970] iteration:593  t-loss:0.7224, loss-lb:0.7224, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:25.159] iteration:594  t-loss:0.5293, loss-lb:0.5293, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:25.339] iteration:595  t-loss:0.3594, loss-lb:0.3594, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:25.522] iteration:596  t-loss:0.4301, loss-lb:0.4301, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:25.707] iteration:597  t-loss:0.8361, loss-lb:0.8361, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:25.889] iteration:598  t-loss:0.3248, loss-lb:0.3248, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:26.072] iteration:599  t-loss:0.3439, loss-lb:0.3439, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:26.260] iteration:600  t-loss:0.6404, loss-lb:0.6404, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:27.500] iteration:601  t-loss:0.3333, loss-lb:0.3333, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:27.712] iteration:602  t-loss:0.6150, loss-lb:0.6150, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:27.918] iteration:603  t-loss:1.2025, loss-lb:1.2025, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:28.128] iteration:604  t-loss:0.7158, loss-lb:0.7158, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:28.331] iteration:605  t-loss:0.3242, loss-lb:0.3242, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:28.536] iteration:606  t-loss:0.4850, loss-lb:0.4850, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:28.748] iteration:607  t-loss:0.7238, loss-lb:0.7238, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:28.951] iteration:608  t-loss:0.3640, loss-lb:0.3640, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:29.157] iteration:609  t-loss:0.6890, loss-lb:0.6890, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:29.355] iteration:610  t-loss:0.4602, loss-lb:0.4602, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:29.557] iteration:611  t-loss:0.5188, loss-lb:0.5188, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:29.758] iteration:612  t-loss:0.5597, loss-lb:0.5597, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:29.951] iteration:613  t-loss:0.4677, loss-lb:0.4677, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:30.147] iteration:614  t-loss:1.0043, loss-lb:1.0043, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:30.339] iteration:615  t-loss:0.3659, loss-lb:0.3659, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:30.541] iteration:616  t-loss:0.7185, loss-lb:0.7185, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:30.736] iteration:617  t-loss:0.3397, loss-lb:0.3397, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:30.923] iteration:618  t-loss:0.3904, loss-lb:0.3904, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:31.103] iteration:619  t-loss:0.3640, loss-lb:0.3640, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:31.288] iteration:620  t-loss:0.5278, loss-lb:0.5278, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:31.468] iteration:621  t-loss:0.6744, loss-lb:0.6744, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:31.650] iteration:622  t-loss:0.7331, loss-lb:0.7331, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:31.830] iteration:623  t-loss:0.5995, loss-lb:0.5995, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:32.013] iteration:624  t-loss:0.6842, loss-lb:0.6842, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:51:32.197] iteration:625  t-loss:0.6958, loss-lb:0.6958, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:44.537] iteration 625 : dice_score: 0.717262 best_dice: 0.717300
[00:53:44.538]  <<Test>> - Ep:24  - Dice-S/T:62.35/71.73, Best-S:62.35, Best-T:71.73
[00:53:44.538]           - AvgLoss(lb/ulb/all):0.58/0.00/0.57
[00:53:45.628] iteration:626  t-loss:0.4508, loss-lb:0.4508, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:45.828] iteration:627  t-loss:0.8868, loss-lb:0.8868, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:46.029] iteration:628  t-loss:0.3003, loss-lb:0.3003, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:46.223] iteration:629  t-loss:0.7708, loss-lb:0.7708, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:46.417] iteration:630  t-loss:0.4457, loss-lb:0.4457, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:46.608] iteration:631  t-loss:0.4002, loss-lb:0.4002, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:46.799] iteration:632  t-loss:0.4882, loss-lb:0.4882, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:46.991] iteration:633  t-loss:0.5514, loss-lb:0.5514, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:47.185] iteration:634  t-loss:0.3761, loss-lb:0.3761, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:47.375] iteration:635  t-loss:0.4110, loss-lb:0.4110, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:47.568] iteration:636  t-loss:0.5817, loss-lb:0.5817, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:47.766] iteration:637  t-loss:0.3199, loss-lb:0.3199, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:47.979] iteration:638  t-loss:0.6093, loss-lb:0.6093, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:48.178] iteration:639  t-loss:0.5504, loss-lb:0.5504, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:48.367] iteration:640  t-loss:0.5061, loss-lb:0.5061, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:48.555] iteration:641  t-loss:0.3210, loss-lb:0.3210, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:48.752] iteration:642  t-loss:0.3839, loss-lb:0.3839, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:48.944] iteration:643  t-loss:0.6167, loss-lb:0.6167, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:49.128] iteration:644  t-loss:0.7294, loss-lb:0.7294, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:49.311] iteration:645  t-loss:0.4981, loss-lb:0.4981, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:49.492] iteration:646  t-loss:0.4044, loss-lb:0.4044, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:49.675] iteration:647  t-loss:0.9294, loss-lb:0.9294, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:49.852] iteration:648  t-loss:0.4099, loss-lb:0.4099, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:50.035] iteration:649  t-loss:0.5520, loss-lb:0.5520, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:50.217] iteration:650  t-loss:0.5603, loss-lb:0.5603, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:51.440] iteration:651  t-loss:0.5523, loss-lb:0.5523, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:51.649] iteration:652  t-loss:0.3621, loss-lb:0.3621, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:51.843] iteration:653  t-loss:0.3805, loss-lb:0.3805, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:52.038] iteration:654  t-loss:0.4374, loss-lb:0.4374, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:52.242] iteration:655  t-loss:0.4363, loss-lb:0.4363, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:52.445] iteration:656  t-loss:0.3850, loss-lb:0.3850, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:52.637] iteration:657  t-loss:0.4482, loss-lb:0.4482, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:52.840] iteration:658  t-loss:0.4778, loss-lb:0.4778, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:53.032] iteration:659  t-loss:0.6588, loss-lb:0.6588, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:53.224] iteration:660  t-loss:0.4614, loss-lb:0.4614, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:53.423] iteration:661  t-loss:0.5953, loss-lb:0.5953, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:53.612] iteration:662  t-loss:0.3918, loss-lb:0.3918, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:53.805] iteration:663  t-loss:0.6072, loss-lb:0.6072, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:53.998] iteration:664  t-loss:0.5130, loss-lb:0.5130, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:54.203] iteration:665  t-loss:0.8893, loss-lb:0.8893, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:54.391] iteration:666  t-loss:0.4748, loss-lb:0.4748, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:54.586] iteration:667  t-loss:0.6327, loss-lb:0.6327, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:54.777] iteration:668  t-loss:0.4061, loss-lb:0.4061, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:54.959] iteration:669  t-loss:0.4464, loss-lb:0.4464, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:55.136] iteration:670  t-loss:0.4199, loss-lb:0.4199, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:55.320] iteration:671  t-loss:0.7098, loss-lb:0.7098, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:55.502] iteration:672  t-loss:0.3303, loss-lb:0.3303, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:55.684] iteration:673  t-loss:0.9061, loss-lb:0.9061, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:55.867] iteration:674  t-loss:0.7306, loss-lb:0.7306, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:56.047] iteration:675  t-loss:0.4495, loss-lb:0.4495, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:57.372] iteration:676  t-loss:0.7289, loss-lb:0.7289, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:57.583] iteration:677  t-loss:0.3616, loss-lb:0.3616, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:57.784] iteration:678  t-loss:0.4642, loss-lb:0.4642, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:57.982] iteration:679  t-loss:0.6497, loss-lb:0.6497, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:58.173] iteration:680  t-loss:0.3103, loss-lb:0.3103, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:58.362] iteration:681  t-loss:0.4891, loss-lb:0.4891, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:58.560] iteration:682  t-loss:0.7615, loss-lb:0.7615, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:58.751] iteration:683  t-loss:0.3719, loss-lb:0.3719, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:58.940] iteration:684  t-loss:0.7201, loss-lb:0.7201, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:59.132] iteration:685  t-loss:0.3581, loss-lb:0.3581, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:59.324] iteration:686  t-loss:0.4224, loss-lb:0.4224, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:59.517] iteration:687  t-loss:0.9660, loss-lb:0.9660, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:59.712] iteration:688  t-loss:0.5034, loss-lb:0.5034, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:53:59.917] iteration:689  t-loss:0.7106, loss-lb:0.7106, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:00.109] iteration:690  t-loss:0.4039, loss-lb:0.4039, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:00.300] iteration:691  t-loss:0.3047, loss-lb:0.3047, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:00.493] iteration:692  t-loss:0.4017, loss-lb:0.4017, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:00.681] iteration:693  t-loss:0.6676, loss-lb:0.6676, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:00.866] iteration:694  t-loss:0.8184, loss-lb:0.8184, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:01.049] iteration:695  t-loss:0.5898, loss-lb:0.5898, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:01.230] iteration:696  t-loss:0.4808, loss-lb:0.4808, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:01.411] iteration:697  t-loss:0.4066, loss-lb:0.4066, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:01.595] iteration:698  t-loss:0.7135, loss-lb:0.7135, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:01.774] iteration:699  t-loss:0.4081, loss-lb:0.4081, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:01.958] iteration:700  t-loss:0.8985, loss-lb:0.8985, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:03.159] iteration:701  t-loss:0.5858, loss-lb:0.5858, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:03.356] iteration:702  t-loss:0.3855, loss-lb:0.3855, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:03.569] iteration:703  t-loss:0.4394, loss-lb:0.4394, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:03.776] iteration:704  t-loss:0.6750, loss-lb:0.6750, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:03.979] iteration:705  t-loss:0.6831, loss-lb:0.6831, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:04.173] iteration:706  t-loss:0.6004, loss-lb:0.6004, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:04.369] iteration:707  t-loss:0.5619, loss-lb:0.5619, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:04.562] iteration:708  t-loss:0.4434, loss-lb:0.4434, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:04.748] iteration:709  t-loss:0.4906, loss-lb:0.4906, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:04.941] iteration:710  t-loss:0.5771, loss-lb:0.5771, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:05.136] iteration:711  t-loss:0.6725, loss-lb:0.6725, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:05.330] iteration:712  t-loss:0.5400, loss-lb:0.5400, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:05.518] iteration:713  t-loss:0.2865, loss-lb:0.2865, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:05.707] iteration:714  t-loss:0.3582, loss-lb:0.3582, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:05.899] iteration:715  t-loss:0.3189, loss-lb:0.3189, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:06.090] iteration:716  t-loss:0.4626, loss-lb:0.4626, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:06.277] iteration:717  t-loss:0.5304, loss-lb:0.5304, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:06.466] iteration:718  t-loss:0.6002, loss-lb:0.6002, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:06.648] iteration:719  t-loss:0.7493, loss-lb:0.7493, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:06.834] iteration:720  t-loss:0.6962, loss-lb:0.6962, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:07.016] iteration:721  t-loss:0.5119, loss-lb:0.5119, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:07.199] iteration:722  t-loss:0.4462, loss-lb:0.4462, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:07.382] iteration:723  t-loss:0.7752, loss-lb:0.7752, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:07.566] iteration:724  t-loss:0.2751, loss-lb:0.2751, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:54:07.747] iteration:725  t-loss:0.4233, loss-lb:0.4233, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:26.060] iteration 725 : dice_score: 0.735645 best_dice: 0.735600
[00:56:26.061]  <<Test>> - Ep:28  - Dice-S/T:68.16/73.56, Best-S:68.16, Best-T:73.56
[00:56:26.061]           - AvgLoss(lb/ulb/all):0.52/0.00/0.52
[00:56:27.364] iteration:726  t-loss:0.3214, loss-lb:0.3214, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:27.577] iteration:727  t-loss:0.3808, loss-lb:0.3808, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:27.789] iteration:728  t-loss:0.4956, loss-lb:0.4956, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:28.010] iteration:729  t-loss:0.6690, loss-lb:0.6690, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:28.227] iteration:730  t-loss:0.4923, loss-lb:0.4923, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:28.430] iteration:731  t-loss:0.3822, loss-lb:0.3822, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:28.632] iteration:732  t-loss:0.6437, loss-lb:0.6437, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:28.838] iteration:733  t-loss:0.3301, loss-lb:0.3301, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:29.036] iteration:734  t-loss:0.4153, loss-lb:0.4153, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:29.236] iteration:735  t-loss:0.4297, loss-lb:0.4297, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:29.434] iteration:736  t-loss:0.7777, loss-lb:0.7777, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:29.634] iteration:737  t-loss:0.4738, loss-lb:0.4738, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:29.836] iteration:738  t-loss:0.2846, loss-lb:0.2846, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:30.038] iteration:739  t-loss:0.9320, loss-lb:0.9320, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:30.243] iteration:740  t-loss:0.4609, loss-lb:0.4609, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:30.429] iteration:741  t-loss:0.4231, loss-lb:0.4231, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:30.624] iteration:742  t-loss:0.3558, loss-lb:0.3558, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:30.822] iteration:743  t-loss:0.6166, loss-lb:0.6166, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:31.023] iteration:744  t-loss:0.6122, loss-lb:0.6122, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:31.203] iteration:745  t-loss:0.6912, loss-lb:0.6912, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:31.387] iteration:746  t-loss:0.4335, loss-lb:0.4335, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:31.569] iteration:747  t-loss:0.7472, loss-lb:0.7472, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:31.752] iteration:748  t-loss:0.6296, loss-lb:0.6296, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:31.933] iteration:749  t-loss:0.4373, loss-lb:0.4373, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:32.115] iteration:750  t-loss:0.6519, loss-lb:0.6519, loss-ulb:0.0000, weight:0.03, lr:0.0010
[00:56:33.323] iteration:751  t-loss:0.4367, loss-lb:0.4367, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:33.534] iteration:752  t-loss:0.8594, loss-lb:0.8594, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:33.728] iteration:753  t-loss:0.3678, loss-lb:0.3678, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:33.935] iteration:754  t-loss:0.3855, loss-lb:0.3855, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:34.143] iteration:755  t-loss:0.3791, loss-lb:0.3791, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:34.354] iteration:756  t-loss:0.6613, loss-lb:0.6613, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:34.566] iteration:757  t-loss:0.4553, loss-lb:0.4553, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:34.770] iteration:758  t-loss:0.2910, loss-lb:0.2910, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:34.982] iteration:759  t-loss:0.6733, loss-lb:0.6733, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:35.192] iteration:760  t-loss:0.6656, loss-lb:0.6656, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:35.382] iteration:761  t-loss:0.3584, loss-lb:0.3584, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:35.580] iteration:762  t-loss:0.7500, loss-lb:0.7500, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:35.775] iteration:763  t-loss:0.5855, loss-lb:0.5855, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:35.976] iteration:764  t-loss:0.4702, loss-lb:0.4702, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:36.168] iteration:765  t-loss:0.6481, loss-lb:0.6481, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:36.369] iteration:766  t-loss:0.4970, loss-lb:0.4970, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:36.560] iteration:767  t-loss:0.4343, loss-lb:0.4343, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:36.761] iteration:768  t-loss:0.5037, loss-lb:0.5037, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:36.945] iteration:769  t-loss:0.5723, loss-lb:0.5723, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:37.127] iteration:770  t-loss:0.4555, loss-lb:0.4555, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:37.307] iteration:771  t-loss:0.5476, loss-lb:0.5476, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:37.491] iteration:772  t-loss:0.5071, loss-lb:0.5071, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:37.671] iteration:773  t-loss:0.5493, loss-lb:0.5493, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:37.854] iteration:774  t-loss:0.5032, loss-lb:0.5032, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:38.033] iteration:775  t-loss:0.3540, loss-lb:0.3540, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:39.575] iteration:776  t-loss:0.2900, loss-lb:0.2900, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:39.797] iteration:777  t-loss:0.4411, loss-lb:0.4411, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:40.014] iteration:778  t-loss:0.3837, loss-lb:0.3837, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:40.250] iteration:779  t-loss:0.5717, loss-lb:0.5717, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:40.456] iteration:780  t-loss:0.4394, loss-lb:0.4394, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:40.665] iteration:781  t-loss:0.5589, loss-lb:0.5589, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:40.878] iteration:782  t-loss:0.2766, loss-lb:0.2766, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:41.091] iteration:783  t-loss:0.5009, loss-lb:0.5009, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:41.300] iteration:784  t-loss:0.3429, loss-lb:0.3429, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:41.511] iteration:785  t-loss:0.5981, loss-lb:0.5981, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:41.721] iteration:786  t-loss:0.3775, loss-lb:0.3775, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:41.922] iteration:787  t-loss:0.2776, loss-lb:0.2776, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:42.136] iteration:788  t-loss:0.3740, loss-lb:0.3740, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:42.339] iteration:789  t-loss:0.3829, loss-lb:0.3829, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:42.544] iteration:790  t-loss:0.8461, loss-lb:0.8461, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:42.738] iteration:791  t-loss:0.2439, loss-lb:0.2439, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:42.947] iteration:792  t-loss:0.5232, loss-lb:0.5232, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:43.143] iteration:793  t-loss:0.4382, loss-lb:0.4382, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:43.345] iteration:794  t-loss:0.5170, loss-lb:0.5170, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:43.530] iteration:795  t-loss:0.2554, loss-lb:0.2554, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:43.718] iteration:796  t-loss:0.9364, loss-lb:0.9364, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:43.900] iteration:797  t-loss:0.6150, loss-lb:0.6150, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:44.087] iteration:798  t-loss:0.3257, loss-lb:0.3257, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:44.276] iteration:799  t-loss:0.7310, loss-lb:0.7310, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:44.470] iteration:800  t-loss:0.5095, loss-lb:0.5095, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:45.831] iteration:801  t-loss:0.6306, loss-lb:0.6306, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:46.050] iteration:802  t-loss:0.4740, loss-lb:0.4740, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:46.258] iteration:803  t-loss:0.6036, loss-lb:0.6036, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:46.481] iteration:804  t-loss:0.6887, loss-lb:0.6887, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:46.694] iteration:805  t-loss:0.3574, loss-lb:0.3574, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:46.891] iteration:806  t-loss:0.3190, loss-lb:0.3190, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:47.102] iteration:807  t-loss:0.5378, loss-lb:0.5378, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:47.304] iteration:808  t-loss:0.3210, loss-lb:0.3210, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:47.516] iteration:809  t-loss:0.6996, loss-lb:0.6996, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:47.728] iteration:810  t-loss:0.5553, loss-lb:0.5553, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:47.936] iteration:811  t-loss:0.7544, loss-lb:0.7544, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:48.132] iteration:812  t-loss:0.7552, loss-lb:0.7552, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:48.331] iteration:813  t-loss:0.6422, loss-lb:0.6422, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:48.527] iteration:814  t-loss:0.5612, loss-lb:0.5612, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:48.729] iteration:815  t-loss:0.4115, loss-lb:0.4115, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:48.920] iteration:816  t-loss:0.3345, loss-lb:0.3345, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:49.122] iteration:817  t-loss:0.7275, loss-lb:0.7275, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:49.321] iteration:818  t-loss:0.5508, loss-lb:0.5508, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:49.506] iteration:819  t-loss:0.4878, loss-lb:0.4878, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:49.689] iteration:820  t-loss:0.5598, loss-lb:0.5598, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:49.871] iteration:821  t-loss:0.3487, loss-lb:0.3487, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:50.056] iteration:822  t-loss:0.3267, loss-lb:0.3267, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:50.241] iteration:823  t-loss:0.4812, loss-lb:0.4812, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:50.426] iteration:824  t-loss:0.4624, loss-lb:0.4624, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:56:50.612] iteration:825  t-loss:0.4641, loss-lb:0.4641, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:59:10.385] iteration 825 : dice_score: 0.742222 best_dice: 0.742200
[00:59:10.386]  <<Test>> - Ep:32  - Dice-S/T:9.11/74.22, Best-S:68.16, Best-T:74.22
[00:59:10.386]           - AvgLoss(lb/ulb/all):0.52/0.00/0.52
[00:59:11.427] iteration:826  t-loss:0.3993, loss-lb:0.3993, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:59:11.634] iteration:827  t-loss:0.3701, loss-lb:0.3701, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:59:11.839] iteration:828  t-loss:0.7585, loss-lb:0.7585, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:59:12.046] iteration:829  t-loss:0.6808, loss-lb:0.6808, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:59:12.243] iteration:830  t-loss:1.0372, loss-lb:1.0372, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:59:12.434] iteration:831  t-loss:0.4704, loss-lb:0.4704, loss-ulb:0.0000, weight:0.04, lr:0.0010
[00:59:12.635] iteration:832  t-loss:0.5291, loss-lb:0.5291, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:12.825] iteration:833  t-loss:0.3585, loss-lb:0.3585, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:13.017] iteration:834  t-loss:0.7555, loss-lb:0.7555, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:13.207] iteration:835  t-loss:0.4114, loss-lb:0.4114, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:13.403] iteration:836  t-loss:0.4630, loss-lb:0.4630, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:13.600] iteration:837  t-loss:0.7813, loss-lb:0.7813, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:13.790] iteration:838  t-loss:0.3812, loss-lb:0.3812, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:13.980] iteration:839  t-loss:0.5442, loss-lb:0.5442, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:14.163] iteration:840  t-loss:0.3872, loss-lb:0.3872, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:14.356] iteration:841  t-loss:0.5312, loss-lb:0.5312, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:14.547] iteration:842  t-loss:0.4325, loss-lb:0.4325, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:14.734] iteration:843  t-loss:0.3811, loss-lb:0.3811, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:14.926] iteration:844  t-loss:0.4928, loss-lb:0.4928, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:15.108] iteration:845  t-loss:0.5900, loss-lb:0.5900, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:15.290] iteration:846  t-loss:0.4764, loss-lb:0.4764, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:15.472] iteration:847  t-loss:0.3448, loss-lb:0.3448, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:15.657] iteration:848  t-loss:0.2757, loss-lb:0.2757, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:15.838] iteration:849  t-loss:0.3524, loss-lb:0.3524, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:16.028] iteration:850  t-loss:0.4290, loss-lb:0.4290, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:17.344] iteration:851  t-loss:0.3586, loss-lb:0.3586, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:17.548] iteration:852  t-loss:0.3269, loss-lb:0.3269, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:17.746] iteration:853  t-loss:0.5364, loss-lb:0.5364, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:17.949] iteration:854  t-loss:0.4529, loss-lb:0.4529, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:18.161] iteration:855  t-loss:0.3381, loss-lb:0.3381, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:18.367] iteration:856  t-loss:0.2450, loss-lb:0.2450, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:18.566] iteration:857  t-loss:0.5026, loss-lb:0.5026, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:18.760] iteration:858  t-loss:0.3648, loss-lb:0.3648, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:18.951] iteration:859  t-loss:0.3668, loss-lb:0.3668, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:19.141] iteration:860  t-loss:0.2721, loss-lb:0.2721, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:19.347] iteration:861  t-loss:0.4639, loss-lb:0.4639, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:19.550] iteration:862  t-loss:0.2660, loss-lb:0.2660, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:19.742] iteration:863  t-loss:0.3160, loss-lb:0.3160, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:19.938] iteration:864  t-loss:0.4636, loss-lb:0.4636, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:20.136] iteration:865  t-loss:0.5543, loss-lb:0.5543, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:20.325] iteration:866  t-loss:0.6206, loss-lb:0.6206, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:20.520] iteration:867  t-loss:0.5347, loss-lb:0.5347, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:20.705] iteration:868  t-loss:0.2928, loss-lb:0.2928, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:20.893] iteration:869  t-loss:0.6254, loss-lb:0.6254, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:21.074] iteration:870  t-loss:0.5467, loss-lb:0.5467, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:21.259] iteration:871  t-loss:0.5684, loss-lb:0.5684, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:21.447] iteration:872  t-loss:0.6168, loss-lb:0.6168, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:21.633] iteration:873  t-loss:0.7580, loss-lb:0.7580, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:21.819] iteration:874  t-loss:0.5753, loss-lb:0.5753, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:21.998] iteration:875  t-loss:0.4268, loss-lb:0.4268, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:23.082] iteration:876  t-loss:0.2932, loss-lb:0.2932, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:23.281] iteration:877  t-loss:0.4101, loss-lb:0.4101, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:23.488] iteration:878  t-loss:0.7387, loss-lb:0.7387, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:23.680] iteration:879  t-loss:0.3449, loss-lb:0.3449, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:23.868] iteration:880  t-loss:0.4281, loss-lb:0.4281, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:24.068] iteration:881  t-loss:0.4337, loss-lb:0.4337, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:24.257] iteration:882  t-loss:0.4954, loss-lb:0.4954, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:24.451] iteration:883  t-loss:0.2564, loss-lb:0.2564, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:24.642] iteration:884  t-loss:0.6478, loss-lb:0.6478, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:24.833] iteration:885  t-loss:0.3910, loss-lb:0.3910, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:25.020] iteration:886  t-loss:0.3314, loss-lb:0.3314, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:25.204] iteration:887  t-loss:0.3364, loss-lb:0.3364, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:25.391] iteration:888  t-loss:0.2912, loss-lb:0.2912, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:25.586] iteration:889  t-loss:0.5965, loss-lb:0.5965, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:25.778] iteration:890  t-loss:0.3327, loss-lb:0.3327, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:25.974] iteration:891  t-loss:0.5078, loss-lb:0.5078, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:26.160] iteration:892  t-loss:0.4547, loss-lb:0.4547, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:26.350] iteration:893  t-loss:0.4941, loss-lb:0.4941, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:26.533] iteration:894  t-loss:0.6349, loss-lb:0.6349, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:26.715] iteration:895  t-loss:0.2613, loss-lb:0.2613, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:26.897] iteration:896  t-loss:0.4430, loss-lb:0.4430, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:27.078] iteration:897  t-loss:0.5056, loss-lb:0.5056, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:27.262] iteration:898  t-loss:0.4730, loss-lb:0.4730, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:27.444] iteration:899  t-loss:0.6236, loss-lb:0.6236, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:27.625] iteration:900  t-loss:0.3239, loss-lb:0.3239, loss-ulb:0.0000, weight:0.04, lr:0.0009
[00:59:28.881] iteration:901  t-loss:0.5124, loss-lb:0.5124, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:29.083] iteration:902  t-loss:0.3118, loss-lb:0.3118, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:29.299] iteration:903  t-loss:0.5549, loss-lb:0.5549, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:29.490] iteration:904  t-loss:0.3313, loss-lb:0.3313, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:29.685] iteration:905  t-loss:0.3984, loss-lb:0.3984, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:29.890] iteration:906  t-loss:0.4279, loss-lb:0.4279, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:30.087] iteration:907  t-loss:0.4719, loss-lb:0.4719, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:30.285] iteration:908  t-loss:0.5963, loss-lb:0.5963, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:30.473] iteration:909  t-loss:0.4159, loss-lb:0.4159, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:30.669] iteration:910  t-loss:0.5103, loss-lb:0.5103, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:30.860] iteration:911  t-loss:0.3974, loss-lb:0.3974, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:31.051] iteration:912  t-loss:0.2882, loss-lb:0.2882, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:31.243] iteration:913  t-loss:0.4326, loss-lb:0.4326, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:31.431] iteration:914  t-loss:0.2680, loss-lb:0.2680, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:31.614] iteration:915  t-loss:0.2507, loss-lb:0.2507, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:31.805] iteration:916  t-loss:0.3045, loss-lb:0.3045, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:31.988] iteration:917  t-loss:0.3194, loss-lb:0.3194, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:32.178] iteration:918  t-loss:0.5192, loss-lb:0.5192, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:32.361] iteration:919  t-loss:0.3240, loss-lb:0.3240, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:32.546] iteration:920  t-loss:0.4991, loss-lb:0.4991, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:32.727] iteration:921  t-loss:0.5866, loss-lb:0.5866, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:32.910] iteration:922  t-loss:0.3020, loss-lb:0.3020, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:33.089] iteration:923  t-loss:0.5004, loss-lb:0.5004, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:33.275] iteration:924  t-loss:0.2477, loss-lb:0.2477, loss-ulb:0.0000, weight:0.05, lr:0.0009
[00:59:33.462] iteration:925  t-loss:0.4394, loss-lb:0.4394, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:54.221] iteration 925 : dice_score: 0.749589 best_dice: 0.749600
[01:01:54.222]  <<Test>> - Ep:36  - Dice-S/T:70.76/74.96, Best-S:70.76, Best-T:74.96
[01:01:54.222]           - AvgLoss(lb/ulb/all):0.41/0.00/0.41
[01:01:55.444] iteration:926  t-loss:0.3480, loss-lb:0.3480, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:55.669] iteration:927  t-loss:0.4529, loss-lb:0.4529, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:55.876] iteration:928  t-loss:0.6783, loss-lb:0.6783, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:56.078] iteration:929  t-loss:0.3692, loss-lb:0.3692, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:56.279] iteration:930  t-loss:0.3761, loss-lb:0.3761, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:56.481] iteration:931  t-loss:0.2540, loss-lb:0.2540, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:56.679] iteration:932  t-loss:0.5304, loss-lb:0.5304, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:56.886] iteration:933  t-loss:0.4583, loss-lb:0.4583, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:57.082] iteration:934  t-loss:0.2895, loss-lb:0.2895, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:57.292] iteration:935  t-loss:0.5612, loss-lb:0.5612, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:57.480] iteration:936  t-loss:0.4099, loss-lb:0.4099, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:57.677] iteration:937  t-loss:0.2497, loss-lb:0.2497, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:57.873] iteration:938  t-loss:0.4522, loss-lb:0.4522, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:58.076] iteration:939  t-loss:0.6257, loss-lb:0.6257, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:58.272] iteration:940  t-loss:0.3969, loss-lb:0.3969, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:58.468] iteration:941  t-loss:0.4203, loss-lb:0.4203, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:58.668] iteration:942  t-loss:0.3252, loss-lb:0.3252, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:58.869] iteration:943  t-loss:0.5416, loss-lb:0.5416, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:59.056] iteration:944  t-loss:0.4014, loss-lb:0.4014, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:59.242] iteration:945  t-loss:0.6056, loss-lb:0.6056, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:59.427] iteration:946  t-loss:0.5284, loss-lb:0.5284, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:59.609] iteration:947  t-loss:0.3655, loss-lb:0.3655, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:59.794] iteration:948  t-loss:0.4236, loss-lb:0.4236, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:01:59.980] iteration:949  t-loss:0.7644, loss-lb:0.7644, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:00.162] iteration:950  t-loss:0.5336, loss-lb:0.5336, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:01.388] iteration:951  t-loss:0.6009, loss-lb:0.6009, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:01.618] iteration:952  t-loss:0.4038, loss-lb:0.4038, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:01.838] iteration:953  t-loss:0.5619, loss-lb:0.5619, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:02.066] iteration:954  t-loss:0.4761, loss-lb:0.4761, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:02.270] iteration:955  t-loss:0.3001, loss-lb:0.3001, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:02.482] iteration:956  t-loss:0.4709, loss-lb:0.4709, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:02.698] iteration:957  t-loss:0.5451, loss-lb:0.5451, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:02.895] iteration:958  t-loss:0.2811, loss-lb:0.2811, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:03.112] iteration:959  t-loss:0.6410, loss-lb:0.6410, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:03.326] iteration:960  t-loss:0.6415, loss-lb:0.6415, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:03.529] iteration:961  t-loss:0.5616, loss-lb:0.5616, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:03.737] iteration:962  t-loss:0.5302, loss-lb:0.5302, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:03.962] iteration:963  t-loss:0.8069, loss-lb:0.8069, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:04.166] iteration:964  t-loss:0.3724, loss-lb:0.3724, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:04.371] iteration:965  t-loss:0.4578, loss-lb:0.4578, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:04.577] iteration:966  t-loss:0.4674, loss-lb:0.4674, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:04.778] iteration:967  t-loss:0.5711, loss-lb:0.5711, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:04.965] iteration:968  t-loss:0.4806, loss-lb:0.4806, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:05.145] iteration:969  t-loss:0.3120, loss-lb:0.3120, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:05.323] iteration:970  t-loss:0.2720, loss-lb:0.2720, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:05.503] iteration:971  t-loss:0.2353, loss-lb:0.2353, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:05.687] iteration:972  t-loss:0.4212, loss-lb:0.4212, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:05.873] iteration:973  t-loss:0.5946, loss-lb:0.5946, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:06.054] iteration:974  t-loss:0.7114, loss-lb:0.7114, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:06.230] iteration:975  t-loss:0.2111, loss-lb:0.2111, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:07.435] iteration:976  t-loss:0.3154, loss-lb:0.3154, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:07.635] iteration:977  t-loss:0.2433, loss-lb:0.2433, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:07.831] iteration:978  t-loss:0.4529, loss-lb:0.4529, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:08.048] iteration:979  t-loss:0.2700, loss-lb:0.2700, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:08.252] iteration:980  t-loss:0.5102, loss-lb:0.5102, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:08.467] iteration:981  t-loss:0.3096, loss-lb:0.3096, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:08.679] iteration:982  t-loss:0.3585, loss-lb:0.3585, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:08.885] iteration:983  t-loss:0.3680, loss-lb:0.3680, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:09.088] iteration:984  t-loss:0.7356, loss-lb:0.7356, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:09.281] iteration:985  t-loss:0.2330, loss-lb:0.2330, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:09.472] iteration:986  t-loss:0.4631, loss-lb:0.4631, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:09.666] iteration:987  t-loss:0.2882, loss-lb:0.2882, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:09.862] iteration:988  t-loss:0.4451, loss-lb:0.4451, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:10.056] iteration:989  t-loss:0.3266, loss-lb:0.3266, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:10.246] iteration:990  t-loss:0.4609, loss-lb:0.4609, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:10.440] iteration:991  t-loss:0.5660, loss-lb:0.5660, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:10.641] iteration:992  t-loss:0.5910, loss-lb:0.5910, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:10.832] iteration:993  t-loss:0.3920, loss-lb:0.3920, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:11.017] iteration:994  t-loss:0.4030, loss-lb:0.4030, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:11.196] iteration:995  t-loss:0.2583, loss-lb:0.2583, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:11.378] iteration:996  t-loss:0.4179, loss-lb:0.4179, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:11.558] iteration:997  t-loss:0.3675, loss-lb:0.3675, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:11.741] iteration:998  t-loss:0.3684, loss-lb:0.3684, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:11.922] iteration:999  t-loss:0.2788, loss-lb:0.2788, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:12.103] iteration:1000  t-loss:0.6374, loss-lb:0.6374, loss-ulb:0.0000, weight:0.05, lr:0.0009
[01:02:13.720] iteration:1001  t-loss:0.3465, loss-lb:0.3368, loss-ulb:0.1798, weight:0.05, lr:0.0009
[01:02:14.046] iteration:1002  t-loss:0.3827, loss-lb:0.3714, loss-ulb:0.2098, weight:0.05, lr:0.0009
[01:02:14.364] iteration:1003  t-loss:0.2985, loss-lb:0.2854, loss-ulb:0.2422, weight:0.05, lr:0.0009
[01:02:14.683] iteration:1004  t-loss:0.3844, loss-lb:0.3720, loss-ulb:0.2298, weight:0.05, lr:0.0009
[01:02:15.001] iteration:1005  t-loss:0.5458, loss-lb:0.5207, loss-ulb:0.4652, weight:0.05, lr:0.0009
[01:02:15.321] iteration:1006  t-loss:0.5316, loss-lb:0.4666, loss-ulb:1.2057, weight:0.05, lr:0.0009
[01:02:15.645] iteration:1007  t-loss:0.4112, loss-lb:0.4023, loss-ulb:0.1645, weight:0.05, lr:0.0009
[01:02:15.966] iteration:1008  t-loss:0.6180, loss-lb:0.5915, loss-ulb:0.4917, weight:0.05, lr:0.0009
[01:02:16.288] iteration:1009  t-loss:0.6437, loss-lb:0.5727, loss-ulb:1.3145, weight:0.05, lr:0.0009
[01:02:16.610] iteration:1010  t-loss:0.4453, loss-lb:0.4322, loss-ulb:0.2429, weight:0.05, lr:0.0009
[01:02:16.932] iteration:1011  t-loss:0.3268, loss-lb:0.3096, loss-ulb:0.3203, weight:0.05, lr:0.0009
[01:02:17.254] iteration:1012  t-loss:0.2728, loss-lb:0.2638, loss-ulb:0.1673, weight:0.05, lr:0.0009
[01:02:17.571] iteration:1013  t-loss:0.2611, loss-lb:0.2478, loss-ulb:0.2457, weight:0.05, lr:0.0009
[01:02:17.891] iteration:1014  t-loss:0.3698, loss-lb:0.3510, loss-ulb:0.3484, weight:0.05, lr:0.0009
[01:02:18.209] iteration:1015  t-loss:0.5545, loss-lb:0.5184, loss-ulb:0.6681, weight:0.05, lr:0.0009
[01:02:18.526] iteration:1016  t-loss:0.5221, loss-lb:0.4977, loss-ulb:0.4530, weight:0.05, lr:0.0009
[01:02:18.844] iteration:1017  t-loss:0.5501, loss-lb:0.4855, loss-ulb:1.1952, weight:0.05, lr:0.0009
[01:02:19.157] iteration:1018  t-loss:0.4072, loss-lb:0.3839, loss-ulb:0.4331, weight:0.05, lr:0.0009
[01:02:19.472] iteration:1019  t-loss:0.6663, loss-lb:0.6385, loss-ulb:0.5165, weight:0.05, lr:0.0009
[01:02:19.790] iteration:1020  t-loss:0.6201, loss-lb:0.6073, loss-ulb:0.2370, weight:0.05, lr:0.0009
[01:02:20.105] iteration:1021  t-loss:0.4351, loss-lb:0.4009, loss-ulb:0.6337, weight:0.05, lr:0.0009
[01:02:20.419] iteration:1022  t-loss:0.4566, loss-lb:0.4433, loss-ulb:0.2451, weight:0.05, lr:0.0009
[01:02:20.736] iteration:1023  t-loss:0.3794, loss-lb:0.3707, loss-ulb:0.1622, weight:0.05, lr:0.0009
[01:02:21.049] iteration:1024  t-loss:0.3300, loss-lb:0.3099, loss-ulb:0.3728, weight:0.05, lr:0.0009
[01:02:21.360] iteration:1025  t-loss:0.3988, loss-lb:0.3684, loss-ulb:0.5627, weight:0.05, lr:0.0009
[01:04:36.522] iteration 1025 : dice_score: 0.767941 best_dice: 0.767900
[01:04:36.523]  <<Test>> - Ep:40  - Dice-S/T:69.12/76.79, Best-S:70.76, Best-T:76.79
[01:04:36.523]           - AvgLoss(lb/ulb/all):0.42/0.50/0.46
[01:04:37.658] iteration:1026  t-loss:0.2659, loss-lb:0.2491, loss-ulb:0.3115, weight:0.05, lr:0.0009
[01:04:38.007] iteration:1027  t-loss:0.4997, loss-lb:0.4851, loss-ulb:0.2709, weight:0.05, lr:0.0009
[01:04:38.350] iteration:1028  t-loss:0.4676, loss-lb:0.4515, loss-ulb:0.2971, weight:0.05, lr:0.0009
[01:04:38.670] iteration:1029  t-loss:0.7043, loss-lb:0.6367, loss-ulb:1.2535, weight:0.05, lr:0.0009
[01:04:38.986] iteration:1030  t-loss:0.7228, loss-lb:0.6984, loss-ulb:0.4522, weight:0.05, lr:0.0009
[01:04:39.299] iteration:1031  t-loss:0.4797, loss-lb:0.4563, loss-ulb:0.4335, weight:0.05, lr:0.0009
[01:04:39.613] iteration:1032  t-loss:0.5481, loss-lb:0.4964, loss-ulb:0.9593, weight:0.05, lr:0.0009
[01:04:39.932] iteration:1033  t-loss:0.4503, loss-lb:0.4374, loss-ulb:0.2391, weight:0.05, lr:0.0009
[01:04:40.252] iteration:1034  t-loss:0.3649, loss-lb:0.3471, loss-ulb:0.3312, weight:0.05, lr:0.0009
[01:04:40.587] iteration:1035  t-loss:0.5349, loss-lb:0.5175, loss-ulb:0.3236, weight:0.05, lr:0.0009
[01:04:40.901] iteration:1036  t-loss:0.6632, loss-lb:0.6475, loss-ulb:0.2899, weight:0.05, lr:0.0009
[01:04:41.211] iteration:1037  t-loss:0.3706, loss-lb:0.3036, loss-ulb:1.2408, weight:0.05, lr:0.0009
[01:04:41.524] iteration:1038  t-loss:0.4188, loss-lb:0.4128, loss-ulb:0.1106, weight:0.05, lr:0.0009
[01:04:41.836] iteration:1039  t-loss:0.4015, loss-lb:0.3705, loss-ulb:0.5745, weight:0.05, lr:0.0009
[01:04:42.148] iteration:1040  t-loss:0.4756, loss-lb:0.4277, loss-ulb:0.8889, weight:0.05, lr:0.0009
[01:04:42.478] iteration:1041  t-loss:0.4402, loss-lb:0.4282, loss-ulb:0.2206, weight:0.05, lr:0.0009
[01:04:42.809] iteration:1042  t-loss:0.3189, loss-lb:0.2924, loss-ulb:0.4905, weight:0.05, lr:0.0009
[01:04:43.130] iteration:1043  t-loss:0.5151, loss-lb:0.5043, loss-ulb:0.1995, weight:0.05, lr:0.0009
[01:04:43.459] iteration:1044  t-loss:0.4671, loss-lb:0.4433, loss-ulb:0.4408, weight:0.05, lr:0.0009
[01:04:43.784] iteration:1045  t-loss:0.4676, loss-lb:0.4377, loss-ulb:0.5550, weight:0.05, lr:0.0009
[01:04:44.112] iteration:1046  t-loss:0.3598, loss-lb:0.3361, loss-ulb:0.4381, weight:0.05, lr:0.0009
[01:04:44.426] iteration:1047  t-loss:0.3415, loss-lb:0.3073, loss-ulb:0.6345, weight:0.05, lr:0.0009
[01:04:44.743] iteration:1048  t-loss:0.2703, loss-lb:0.2491, loss-ulb:0.3936, weight:0.05, lr:0.0009
[01:04:45.072] iteration:1049  t-loss:0.5484, loss-lb:0.4818, loss-ulb:1.2348, weight:0.05, lr:0.0009
[01:04:45.388] iteration:1050  t-loss:0.2958, loss-lb:0.2725, loss-ulb:0.4319, weight:0.05, lr:0.0009
[01:04:46.682] iteration:1051  t-loss:0.3229, loss-lb:0.2874, loss-ulb:0.5332, weight:0.07, lr:0.0009
[01:04:47.025] iteration:1052  t-loss:0.2440, loss-lb:0.2307, loss-ulb:0.2004, weight:0.07, lr:0.0009
[01:04:47.368] iteration:1053  t-loss:0.3881, loss-lb:0.3648, loss-ulb:0.3505, weight:0.07, lr:0.0009
[01:04:47.698] iteration:1054  t-loss:0.2990, loss-lb:0.2574, loss-ulb:0.6247, weight:0.07, lr:0.0009
[01:04:48.011] iteration:1055  t-loss:0.4759, loss-lb:0.4177, loss-ulb:0.8741, weight:0.07, lr:0.0009
[01:04:48.326] iteration:1056  t-loss:0.3406, loss-lb:0.3291, loss-ulb:0.1723, weight:0.07, lr:0.0009
[01:04:48.640] iteration:1057  t-loss:0.4610, loss-lb:0.4230, loss-ulb:0.5699, weight:0.07, lr:0.0009
[01:04:48.956] iteration:1058  t-loss:0.5829, loss-lb:0.5057, loss-ulb:1.1614, weight:0.07, lr:0.0009
[01:04:49.268] iteration:1059  t-loss:0.5936, loss-lb:0.5890, loss-ulb:0.0688, weight:0.07, lr:0.0009
[01:04:49.582] iteration:1060  t-loss:0.4658, loss-lb:0.4216, loss-ulb:0.6651, weight:0.07, lr:0.0009
[01:04:49.898] iteration:1061  t-loss:0.4225, loss-lb:0.4096, loss-ulb:0.1947, weight:0.07, lr:0.0009
[01:04:50.214] iteration:1062  t-loss:0.4113, loss-lb:0.3895, loss-ulb:0.3268, weight:0.07, lr:0.0009
[01:04:50.525] iteration:1063  t-loss:0.4331, loss-lb:0.3531, loss-ulb:1.2021, weight:0.07, lr:0.0009
[01:04:50.837] iteration:1064  t-loss:0.2850, loss-lb:0.2307, loss-ulb:0.8171, weight:0.07, lr:0.0009
[01:04:51.148] iteration:1065  t-loss:0.6521, loss-lb:0.6232, loss-ulb:0.4345, weight:0.07, lr:0.0009
[01:04:51.463] iteration:1066  t-loss:0.7195, loss-lb:0.6958, loss-ulb:0.3564, weight:0.07, lr:0.0009
[01:04:51.778] iteration:1067  t-loss:0.4705, loss-lb:0.4132, loss-ulb:0.8603, weight:0.07, lr:0.0009
[01:04:52.095] iteration:1068  t-loss:0.3150, loss-lb:0.3002, loss-ulb:0.2229, weight:0.07, lr:0.0009
[01:04:52.408] iteration:1069  t-loss:0.2610, loss-lb:0.2524, loss-ulb:0.1291, weight:0.07, lr:0.0009
[01:04:52.723] iteration:1070  t-loss:0.3699, loss-lb:0.3300, loss-ulb:0.5995, weight:0.07, lr:0.0009
[01:04:53.037] iteration:1071  t-loss:0.7520, loss-lb:0.7053, loss-ulb:0.7021, weight:0.07, lr:0.0009
[01:04:53.351] iteration:1072  t-loss:1.1377, loss-lb:1.1209, loss-ulb:0.2524, weight:0.07, lr:0.0009
[01:04:53.661] iteration:1073  t-loss:0.3135, loss-lb:0.2915, loss-ulb:0.3307, weight:0.07, lr:0.0009
[01:04:53.973] iteration:1074  t-loss:0.3481, loss-lb:0.3166, loss-ulb:0.4739, weight:0.07, lr:0.0009
[01:04:54.280] iteration:1075  t-loss:0.4415, loss-lb:0.3693, loss-ulb:1.0839, weight:0.07, lr:0.0009
[01:04:55.509] iteration:1076  t-loss:0.6660, loss-lb:0.6521, loss-ulb:0.2086, weight:0.07, lr:0.0009
[01:04:55.833] iteration:1077  t-loss:0.4059, loss-lb:0.3777, loss-ulb:0.4239, weight:0.07, lr:0.0009
[01:04:56.167] iteration:1078  t-loss:0.6830, loss-lb:0.6015, loss-ulb:1.2255, weight:0.07, lr:0.0009
[01:04:56.480] iteration:1079  t-loss:1.4347, loss-lb:1.3901, loss-ulb:0.6711, weight:0.07, lr:0.0009
[01:04:56.797] iteration:1080  t-loss:0.4156, loss-lb:0.3632, loss-ulb:0.7868, weight:0.07, lr:0.0009
[01:04:57.113] iteration:1081  t-loss:0.4022, loss-lb:0.3183, loss-ulb:1.2605, weight:0.07, lr:0.0009
[01:04:57.428] iteration:1082  t-loss:0.5416, loss-lb:0.4548, loss-ulb:1.3043, weight:0.07, lr:0.0009
[01:04:57.742] iteration:1083  t-loss:0.3472, loss-lb:0.3207, loss-ulb:0.3987, weight:0.07, lr:0.0009
[01:04:58.058] iteration:1084  t-loss:0.9433, loss-lb:0.8821, loss-ulb:0.9196, weight:0.07, lr:0.0009
[01:04:58.371] iteration:1085  t-loss:0.7361, loss-lb:0.7256, loss-ulb:0.1571, weight:0.07, lr:0.0009
[01:04:58.691] iteration:1086  t-loss:0.4821, loss-lb:0.4616, loss-ulb:0.3087, weight:0.07, lr:0.0009
[01:04:59.004] iteration:1087  t-loss:0.4903, loss-lb:0.4695, loss-ulb:0.3132, weight:0.07, lr:0.0009
[01:04:59.319] iteration:1088  t-loss:0.6798, loss-lb:0.6429, loss-ulb:0.5534, weight:0.07, lr:0.0009
[01:04:59.639] iteration:1089  t-loss:0.5425, loss-lb:0.4965, loss-ulb:0.6901, weight:0.07, lr:0.0009
[01:04:59.955] iteration:1090  t-loss:0.4455, loss-lb:0.4138, loss-ulb:0.4768, weight:0.07, lr:0.0009
[01:05:00.271] iteration:1091  t-loss:0.5133, loss-lb:0.4809, loss-ulb:0.4871, weight:0.07, lr:0.0009
[01:05:00.587] iteration:1092  t-loss:0.3875, loss-lb:0.3474, loss-ulb:0.6034, weight:0.07, lr:0.0009
[01:05:00.904] iteration:1093  t-loss:0.9253, loss-lb:0.8820, loss-ulb:0.6510, weight:0.07, lr:0.0009
[01:05:01.218] iteration:1094  t-loss:0.5852, loss-lb:0.5775, loss-ulb:0.1149, weight:0.07, lr:0.0009
[01:05:01.527] iteration:1095  t-loss:0.7391, loss-lb:0.6924, loss-ulb:0.7018, weight:0.07, lr:0.0009
[01:05:01.839] iteration:1096  t-loss:0.6708, loss-lb:0.6377, loss-ulb:0.4963, weight:0.07, lr:0.0009
[01:05:02.151] iteration:1097  t-loss:0.4755, loss-lb:0.4350, loss-ulb:0.6092, weight:0.07, lr:0.0009
[01:05:02.465] iteration:1098  t-loss:0.6941, loss-lb:0.6809, loss-ulb:0.1982, weight:0.07, lr:0.0009
[01:05:02.774] iteration:1099  t-loss:0.3407, loss-lb:0.3242, loss-ulb:0.2468, weight:0.07, lr:0.0009
[01:05:03.088] iteration:1100  t-loss:0.5485, loss-lb:0.5201, loss-ulb:0.4270, weight:0.07, lr:0.0009
[01:05:04.535] iteration:1101  t-loss:0.3593, loss-lb:0.3155, loss-ulb:0.6582, weight:0.07, lr:0.0009
[01:05:04.870] iteration:1102  t-loss:0.7378, loss-lb:0.7118, loss-ulb:0.3903, weight:0.07, lr:0.0009
[01:05:05.194] iteration:1103  t-loss:0.4555, loss-lb:0.3896, loss-ulb:0.9916, weight:0.07, lr:0.0009
[01:05:05.511] iteration:1104  t-loss:0.3713, loss-lb:0.3568, loss-ulb:0.2181, weight:0.07, lr:0.0009
[01:05:05.829] iteration:1105  t-loss:0.3758, loss-lb:0.3693, loss-ulb:0.0984, weight:0.07, lr:0.0009
[01:05:06.154] iteration:1106  t-loss:0.4551, loss-lb:0.4292, loss-ulb:0.3894, weight:0.07, lr:0.0009
[01:05:06.471] iteration:1107  t-loss:0.4083, loss-lb:0.3602, loss-ulb:0.7221, weight:0.07, lr:0.0009
[01:05:06.806] iteration:1108  t-loss:0.5905, loss-lb:0.5706, loss-ulb:0.2987, weight:0.07, lr:0.0009
[01:05:07.126] iteration:1109  t-loss:0.5021, loss-lb:0.4830, loss-ulb:0.2869, weight:0.07, lr:0.0009
[01:05:07.451] iteration:1110  t-loss:0.4780, loss-lb:0.4182, loss-ulb:0.8994, weight:0.07, lr:0.0009
[01:05:07.767] iteration:1111  t-loss:0.4836, loss-lb:0.3935, loss-ulb:1.3541, weight:0.07, lr:0.0009
[01:05:08.087] iteration:1112  t-loss:0.5165, loss-lb:0.4664, loss-ulb:0.7530, weight:0.07, lr:0.0009
[01:05:08.405] iteration:1113  t-loss:0.8702, loss-lb:0.8562, loss-ulb:0.2099, weight:0.07, lr:0.0009
[01:05:08.727] iteration:1114  t-loss:0.4930, loss-lb:0.4427, loss-ulb:0.7564, weight:0.07, lr:0.0009
[01:05:09.043] iteration:1115  t-loss:0.6370, loss-lb:0.6141, loss-ulb:0.3437, weight:0.07, lr:0.0009
[01:05:09.363] iteration:1116  t-loss:0.3133, loss-lb:0.2921, loss-ulb:0.3193, weight:0.07, lr:0.0009
[01:05:09.681] iteration:1117  t-loss:0.4364, loss-lb:0.3975, loss-ulb:0.5856, weight:0.07, lr:0.0009
[01:05:09.997] iteration:1118  t-loss:0.8225, loss-lb:0.7341, loss-ulb:1.3280, weight:0.07, lr:0.0009
[01:05:10.308] iteration:1119  t-loss:0.4072, loss-lb:0.3679, loss-ulb:0.5920, weight:0.07, lr:0.0009
[01:05:10.621] iteration:1120  t-loss:0.5871, loss-lb:0.5405, loss-ulb:0.7003, weight:0.07, lr:0.0009
[01:05:10.935] iteration:1121  t-loss:0.5043, loss-lb:0.4915, loss-ulb:0.1923, weight:0.07, lr:0.0009
[01:05:11.246] iteration:1122  t-loss:0.5442, loss-lb:0.5199, loss-ulb:0.3642, weight:0.07, lr:0.0009
[01:05:11.561] iteration:1123  t-loss:0.4079, loss-lb:0.3959, loss-ulb:0.1796, weight:0.07, lr:0.0009
[01:05:11.878] iteration:1124  t-loss:0.3639, loss-lb:0.3494, loss-ulb:0.2176, weight:0.07, lr:0.0009
[01:05:12.191] iteration:1125  t-loss:0.4919, loss-lb:0.4796, loss-ulb:0.1849, weight:0.07, lr:0.0009
[01:07:25.484] iteration 1125 : dice_score: 0.758920 best_dice: 0.767900
[01:07:25.484]  <<Test>> - Ep:44  - Dice-S/T:68.92/75.89, Best-S:70.76, Best-T:76.79
[01:07:25.484]           - AvgLoss(lb/ulb/all):0.47/0.53/0.52
[01:07:26.712] iteration:1126  t-loss:0.3606, loss-lb:0.3402, loss-ulb:0.3066, weight:0.07, lr:0.0009
[01:07:27.066] iteration:1127  t-loss:0.4306, loss-lb:0.3960, loss-ulb:0.5205, weight:0.07, lr:0.0009
[01:07:27.412] iteration:1128  t-loss:0.2499, loss-lb:0.2301, loss-ulb:0.2976, weight:0.07, lr:0.0009
[01:07:27.738] iteration:1129  t-loss:1.0910, loss-lb:1.0327, loss-ulb:0.8766, weight:0.07, lr:0.0009
[01:07:28.059] iteration:1130  t-loss:0.3798, loss-lb:0.3411, loss-ulb:0.5814, weight:0.07, lr:0.0009
[01:07:28.383] iteration:1131  t-loss:0.5715, loss-lb:0.5486, loss-ulb:0.3446, weight:0.07, lr:0.0009
[01:07:28.706] iteration:1132  t-loss:0.2945, loss-lb:0.2774, loss-ulb:0.2576, weight:0.07, lr:0.0009
[01:07:29.027] iteration:1133  t-loss:1.0961, loss-lb:1.0761, loss-ulb:0.3005, weight:0.07, lr:0.0009
[01:07:29.350] iteration:1134  t-loss:0.5032, loss-lb:0.4808, loss-ulb:0.3370, weight:0.07, lr:0.0009
[01:07:29.674] iteration:1135  t-loss:0.5940, loss-lb:0.5845, loss-ulb:0.1432, weight:0.07, lr:0.0009
[01:07:29.991] iteration:1136  t-loss:0.5449, loss-lb:0.4770, loss-ulb:1.0198, weight:0.07, lr:0.0009
[01:07:30.314] iteration:1137  t-loss:0.8094, loss-lb:0.7709, loss-ulb:0.5776, weight:0.07, lr:0.0009
[01:07:30.629] iteration:1138  t-loss:0.5194, loss-lb:0.4887, loss-ulb:0.4615, weight:0.07, lr:0.0009
[01:07:30.942] iteration:1139  t-loss:0.3300, loss-lb:0.2667, loss-ulb:0.9518, weight:0.07, lr:0.0009
[01:07:31.261] iteration:1140  t-loss:0.5699, loss-lb:0.5422, loss-ulb:0.4153, weight:0.07, lr:0.0009
[01:07:31.575] iteration:1141  t-loss:0.5532, loss-lb:0.5469, loss-ulb:0.0943, weight:0.07, lr:0.0009
[01:07:31.889] iteration:1142  t-loss:0.3973, loss-lb:0.3567, loss-ulb:0.6105, weight:0.07, lr:0.0009
[01:07:32.202] iteration:1143  t-loss:0.2656, loss-lb:0.2403, loss-ulb:0.3800, weight:0.07, lr:0.0009
[01:07:32.517] iteration:1144  t-loss:0.4494, loss-lb:0.4199, loss-ulb:0.4430, weight:0.07, lr:0.0009
[01:07:32.828] iteration:1145  t-loss:0.4379, loss-lb:0.4225, loss-ulb:0.2309, weight:0.07, lr:0.0009
[01:07:33.144] iteration:1146  t-loss:0.7292, loss-lb:0.6792, loss-ulb:0.7525, weight:0.07, lr:0.0009
[01:07:33.458] iteration:1147  t-loss:0.6564, loss-lb:0.6158, loss-ulb:0.6108, weight:0.07, lr:0.0009
[01:07:33.774] iteration:1148  t-loss:0.4761, loss-lb:0.4261, loss-ulb:0.7527, weight:0.07, lr:0.0009
[01:07:34.086] iteration:1149  t-loss:0.4290, loss-lb:0.3936, loss-ulb:0.5319, weight:0.07, lr:0.0009
[01:07:34.399] iteration:1150  t-loss:0.3229, loss-lb:0.2912, loss-ulb:0.4775, weight:0.07, lr:0.0009
[01:07:35.913] iteration:1151  t-loss:0.6285, loss-lb:0.5993, loss-ulb:0.4397, weight:0.07, lr:0.0009
[01:07:36.248] iteration:1152  t-loss:0.6803, loss-lb:0.6280, loss-ulb:0.7862, weight:0.07, lr:0.0009
[01:07:36.585] iteration:1153  t-loss:0.3025, loss-lb:0.2647, loss-ulb:0.5673, weight:0.07, lr:0.0009
[01:07:36.915] iteration:1154  t-loss:0.4081, loss-lb:0.3584, loss-ulb:0.7465, weight:0.07, lr:0.0009
[01:07:37.247] iteration:1155  t-loss:0.7642, loss-lb:0.7369, loss-ulb:0.4103, weight:0.07, lr:0.0009
[01:07:37.571] iteration:1156  t-loss:0.4608, loss-lb:0.4026, loss-ulb:0.8754, weight:0.07, lr:0.0009
[01:07:37.889] iteration:1157  t-loss:1.2660, loss-lb:1.2569, loss-ulb:0.1364, weight:0.07, lr:0.0009
[01:07:38.204] iteration:1158  t-loss:0.2678, loss-lb:0.2385, loss-ulb:0.4397, weight:0.07, lr:0.0009
[01:07:38.521] iteration:1159  t-loss:0.3498, loss-lb:0.3204, loss-ulb:0.4421, weight:0.07, lr:0.0009
[01:07:38.850] iteration:1160  t-loss:0.7426, loss-lb:0.7192, loss-ulb:0.3518, weight:0.07, lr:0.0009
[01:07:39.171] iteration:1161  t-loss:0.3000, loss-lb:0.2771, loss-ulb:0.3449, weight:0.07, lr:0.0009
[01:07:39.493] iteration:1162  t-loss:0.2274, loss-lb:0.2224, loss-ulb:0.0755, weight:0.07, lr:0.0009
[01:07:39.820] iteration:1163  t-loss:0.3451, loss-lb:0.3232, loss-ulb:0.3291, weight:0.07, lr:0.0009
[01:07:40.145] iteration:1164  t-loss:0.4434, loss-lb:0.4095, loss-ulb:0.5086, weight:0.07, lr:0.0009
[01:07:40.466] iteration:1165  t-loss:0.5336, loss-lb:0.4911, loss-ulb:0.6389, weight:0.07, lr:0.0009
[01:07:40.782] iteration:1166  t-loss:1.0530, loss-lb:1.0319, loss-ulb:0.3173, weight:0.07, lr:0.0009
[01:07:41.107] iteration:1167  t-loss:0.5200, loss-lb:0.4619, loss-ulb:0.8738, weight:0.07, lr:0.0009
[01:07:41.425] iteration:1168  t-loss:0.6332, loss-lb:0.6111, loss-ulb:0.3324, weight:0.07, lr:0.0009
[01:07:41.741] iteration:1169  t-loss:0.2474, loss-lb:0.2402, loss-ulb:0.1076, weight:0.07, lr:0.0009
[01:07:42.061] iteration:1170  t-loss:0.6747, loss-lb:0.6069, loss-ulb:1.0199, weight:0.07, lr:0.0009
[01:07:42.376] iteration:1171  t-loss:0.3680, loss-lb:0.3414, loss-ulb:0.4000, weight:0.07, lr:0.0009
[01:07:42.691] iteration:1172  t-loss:0.2945, loss-lb:0.2908, loss-ulb:0.0559, weight:0.07, lr:0.0009
[01:07:43.002] iteration:1173  t-loss:0.5018, loss-lb:0.4655, loss-ulb:0.5451, weight:0.07, lr:0.0009
[01:07:43.314] iteration:1174  t-loss:0.6016, loss-lb:0.5488, loss-ulb:0.7935, weight:0.07, lr:0.0009
[01:07:43.630] iteration:1175  t-loss:0.3015, loss-lb:0.2861, loss-ulb:0.2312, weight:0.07, lr:0.0009
[01:07:45.005] iteration:1176  t-loss:0.4035, loss-lb:0.3939, loss-ulb:0.1441, weight:0.07, lr:0.0009
[01:07:45.334] iteration:1177  t-loss:0.3942, loss-lb:0.3890, loss-ulb:0.0788, weight:0.07, lr:0.0009
[01:07:45.661] iteration:1178  t-loss:0.5365, loss-lb:0.4944, loss-ulb:0.6330, weight:0.07, lr:0.0009
[01:07:45.979] iteration:1179  t-loss:0.2617, loss-lb:0.2407, loss-ulb:0.3146, weight:0.07, lr:0.0009
[01:07:46.294] iteration:1180  t-loss:0.2747, loss-lb:0.2584, loss-ulb:0.2445, weight:0.07, lr:0.0009
[01:07:46.609] iteration:1181  t-loss:0.3382, loss-lb:0.3160, loss-ulb:0.3335, weight:0.07, lr:0.0009
[01:07:46.924] iteration:1182  t-loss:0.4602, loss-lb:0.4373, loss-ulb:0.3446, weight:0.07, lr:0.0009
[01:07:47.244] iteration:1183  t-loss:0.3544, loss-lb:0.3405, loss-ulb:0.2093, weight:0.07, lr:0.0009
[01:07:47.555] iteration:1184  t-loss:0.3671, loss-lb:0.2881, loss-ulb:1.1867, weight:0.07, lr:0.0009
[01:07:47.881] iteration:1185  t-loss:0.4924, loss-lb:0.4708, loss-ulb:0.3241, weight:0.07, lr:0.0009
[01:07:48.200] iteration:1186  t-loss:0.3739, loss-lb:0.3377, loss-ulb:0.5436, weight:0.07, lr:0.0009
[01:07:48.531] iteration:1187  t-loss:0.5915, loss-lb:0.5736, loss-ulb:0.2692, weight:0.07, lr:0.0009
[01:07:48.856] iteration:1188  t-loss:0.2592, loss-lb:0.2499, loss-ulb:0.1396, weight:0.07, lr:0.0009
[01:07:49.184] iteration:1189  t-loss:0.7716, loss-lb:0.7176, loss-ulb:0.8108, weight:0.07, lr:0.0009
[01:07:49.508] iteration:1190  t-loss:0.6265, loss-lb:0.5934, loss-ulb:0.4969, weight:0.07, lr:0.0009
[01:07:49.841] iteration:1191  t-loss:0.2972, loss-lb:0.2695, loss-ulb:0.4172, weight:0.07, lr:0.0009
[01:07:50.158] iteration:1192  t-loss:0.3299, loss-lb:0.3134, loss-ulb:0.2477, weight:0.07, lr:0.0009
[01:07:50.473] iteration:1193  t-loss:0.3918, loss-lb:0.3766, loss-ulb:0.2291, weight:0.07, lr:0.0009
[01:07:50.791] iteration:1194  t-loss:0.3810, loss-lb:0.3636, loss-ulb:0.2609, weight:0.07, lr:0.0009
[01:07:51.109] iteration:1195  t-loss:0.3263, loss-lb:0.3034, loss-ulb:0.3446, weight:0.07, lr:0.0009
[01:07:51.423] iteration:1196  t-loss:0.3331, loss-lb:0.3130, loss-ulb:0.3027, weight:0.07, lr:0.0009
[01:07:51.734] iteration:1197  t-loss:0.4624, loss-lb:0.3752, loss-ulb:1.3104, weight:0.07, lr:0.0009
[01:07:52.049] iteration:1198  t-loss:0.3175, loss-lb:0.2994, loss-ulb:0.2726, weight:0.07, lr:0.0009
[01:07:52.363] iteration:1199  t-loss:0.3771, loss-lb:0.3487, loss-ulb:0.4270, weight:0.07, lr:0.0009
[01:07:52.678] iteration:1200  t-loss:0.3434, loss-lb:0.3097, loss-ulb:0.5066, weight:0.07, lr:0.0009
[01:07:54.080] iteration:1201  t-loss:0.6950, loss-lb:0.6317, loss-ulb:0.7765, weight:0.08, lr:0.0009
[01:07:54.417] iteration:1202  t-loss:0.2825, loss-lb:0.2724, loss-ulb:0.1239, weight:0.08, lr:0.0009
[01:07:54.748] iteration:1203  t-loss:0.2082, loss-lb:0.1873, loss-ulb:0.2562, weight:0.08, lr:0.0009
[01:07:55.066] iteration:1204  t-loss:0.3718, loss-lb:0.3609, loss-ulb:0.1338, weight:0.08, lr:0.0009
[01:07:55.393] iteration:1205  t-loss:0.7575, loss-lb:0.7304, loss-ulb:0.3318, weight:0.08, lr:0.0009
[01:07:55.718] iteration:1206  t-loss:0.3800, loss-lb:0.3479, loss-ulb:0.3938, weight:0.08, lr:0.0009
[01:07:56.040] iteration:1207  t-loss:0.3095, loss-lb:0.2460, loss-ulb:0.7781, weight:0.08, lr:0.0009
[01:07:56.359] iteration:1208  t-loss:0.5558, loss-lb:0.5301, loss-ulb:0.3155, weight:0.08, lr:0.0009
[01:07:56.673] iteration:1209  t-loss:0.4303, loss-lb:0.4076, loss-ulb:0.2783, weight:0.08, lr:0.0009
[01:07:56.990] iteration:1210  t-loss:0.4786, loss-lb:0.4503, loss-ulb:0.3476, weight:0.08, lr:0.0009
[01:07:57.304] iteration:1211  t-loss:0.3306, loss-lb:0.2991, loss-ulb:0.3865, weight:0.08, lr:0.0009
[01:07:57.619] iteration:1212  t-loss:1.0059, loss-lb:0.9178, loss-ulb:1.0813, weight:0.08, lr:0.0009
[01:07:57.932] iteration:1213  t-loss:0.4233, loss-lb:0.3883, loss-ulb:0.4293, weight:0.08, lr:0.0009
[01:07:58.248] iteration:1214  t-loss:0.3915, loss-lb:0.3405, loss-ulb:0.6257, weight:0.08, lr:0.0009
[01:07:58.569] iteration:1215  t-loss:0.8374, loss-lb:0.8078, loss-ulb:0.3632, weight:0.08, lr:0.0009
[01:07:58.889] iteration:1216  t-loss:0.7297, loss-lb:0.7144, loss-ulb:0.1871, weight:0.08, lr:0.0009
[01:07:59.208] iteration:1217  t-loss:0.2772, loss-lb:0.2539, loss-ulb:0.2854, weight:0.08, lr:0.0009
[01:07:59.519] iteration:1218  t-loss:0.2317, loss-lb:0.2179, loss-ulb:0.1703, weight:0.08, lr:0.0009
[01:07:59.832] iteration:1219  t-loss:0.5200, loss-lb:0.4899, loss-ulb:0.3691, weight:0.08, lr:0.0009
[01:08:00.142] iteration:1220  t-loss:0.5115, loss-lb:0.4827, loss-ulb:0.3539, weight:0.08, lr:0.0009
[01:08:00.456] iteration:1221  t-loss:0.3084, loss-lb:0.2853, loss-ulb:0.2841, weight:0.08, lr:0.0009
[01:08:00.768] iteration:1222  t-loss:0.3361, loss-lb:0.3300, loss-ulb:0.0741, weight:0.08, lr:0.0009
[01:08:01.079] iteration:1223  t-loss:0.6908, loss-lb:0.5947, loss-ulb:1.1784, weight:0.08, lr:0.0009
[01:08:01.391] iteration:1224  t-loss:0.5432, loss-lb:0.4998, loss-ulb:0.5318, weight:0.08, lr:0.0009
[01:08:01.705] iteration:1225  t-loss:0.5969, loss-lb:0.5001, loss-ulb:1.1876, weight:0.08, lr:0.0009
[01:10:16.369] iteration 1225 : dice_score: 0.763333 best_dice: 0.767900
[01:10:16.370]  <<Test>> - Ep:48  - Dice-S/T:68.79/76.33, Best-S:70.76, Best-T:76.79
[01:10:16.370]           - AvgLoss(lb/ulb/all):0.45/0.48/0.49
[01:10:17.814] iteration:1226  t-loss:0.4245, loss-lb:0.3954, loss-ulb:0.3575, weight:0.08, lr:0.0009
[01:10:18.148] iteration:1227  t-loss:0.5325, loss-lb:0.4975, loss-ulb:0.4290, weight:0.08, lr:0.0009
[01:10:18.512] iteration:1228  t-loss:0.5408, loss-lb:0.5095, loss-ulb:0.3840, weight:0.08, lr:0.0009
[01:10:18.850] iteration:1229  t-loss:0.4096, loss-lb:0.3468, loss-ulb:0.7708, weight:0.08, lr:0.0009
[01:10:19.173] iteration:1230  t-loss:0.3304, loss-lb:0.2719, loss-ulb:0.7175, weight:0.08, lr:0.0009
[01:10:19.503] iteration:1231  t-loss:0.5015, loss-lb:0.4489, loss-ulb:0.6453, weight:0.08, lr:0.0009
[01:10:19.824] iteration:1232  t-loss:0.2675, loss-lb:0.2289, loss-ulb:0.4726, weight:0.08, lr:0.0009
[01:10:20.144] iteration:1233  t-loss:0.4914, loss-lb:0.4567, loss-ulb:0.4247, weight:0.08, lr:0.0009
[01:10:20.469] iteration:1234  t-loss:0.6331, loss-lb:0.6075, loss-ulb:0.3140, weight:0.08, lr:0.0009
[01:10:20.786] iteration:1235  t-loss:0.4688, loss-lb:0.4378, loss-ulb:0.3797, weight:0.08, lr:0.0009
[01:10:21.111] iteration:1236  t-loss:0.2745, loss-lb:0.2429, loss-ulb:0.3884, weight:0.08, lr:0.0009
[01:10:21.435] iteration:1237  t-loss:0.3956, loss-lb:0.3708, loss-ulb:0.3045, weight:0.08, lr:0.0009
[01:10:21.756] iteration:1238  t-loss:0.6197, loss-lb:0.6112, loss-ulb:0.1033, weight:0.08, lr:0.0009
[01:10:22.078] iteration:1239  t-loss:0.4384, loss-lb:0.4273, loss-ulb:0.1368, weight:0.08, lr:0.0009
[01:10:22.394] iteration:1240  t-loss:0.4905, loss-lb:0.3944, loss-ulb:1.1792, weight:0.08, lr:0.0009
[01:10:22.717] iteration:1241  t-loss:0.3944, loss-lb:0.3625, loss-ulb:0.3905, weight:0.08, lr:0.0009
[01:10:23.046] iteration:1242  t-loss:0.7006, loss-lb:0.6912, loss-ulb:0.1147, weight:0.08, lr:0.0009
[01:10:23.364] iteration:1243  t-loss:0.3587, loss-lb:0.3276, loss-ulb:0.3815, weight:0.08, lr:0.0009
[01:10:23.682] iteration:1244  t-loss:0.7407, loss-lb:0.6887, loss-ulb:0.6380, weight:0.08, lr:0.0009
[01:10:23.998] iteration:1245  t-loss:0.4789, loss-lb:0.4386, loss-ulb:0.4946, weight:0.08, lr:0.0009
[01:10:24.310] iteration:1246  t-loss:0.5039, loss-lb:0.4034, loss-ulb:1.2325, weight:0.08, lr:0.0009
[01:10:24.624] iteration:1247  t-loss:0.3775, loss-lb:0.3219, loss-ulb:0.6825, weight:0.08, lr:0.0009
[01:10:24.937] iteration:1248  t-loss:0.4692, loss-lb:0.4133, loss-ulb:0.6855, weight:0.08, lr:0.0009
[01:10:25.250] iteration:1249  t-loss:0.7928, loss-lb:0.7663, loss-ulb:0.3247, weight:0.08, lr:0.0009
[01:10:25.567] iteration:1250  t-loss:0.2594, loss-lb:0.2405, loss-ulb:0.2314, weight:0.08, lr:0.0009
[01:10:27.131] iteration:1251  t-loss:0.3221, loss-lb:0.2887, loss-ulb:0.4090, weight:0.08, lr:0.0009
[01:10:27.472] iteration:1252  t-loss:0.6376, loss-lb:0.5842, loss-ulb:0.6549, weight:0.08, lr:0.0009
[01:10:27.805] iteration:1253  t-loss:0.6242, loss-lb:0.5939, loss-ulb:0.3717, weight:0.08, lr:0.0009
[01:10:28.126] iteration:1254  t-loss:0.7488, loss-lb:0.6917, loss-ulb:0.7000, weight:0.08, lr:0.0009
[01:10:28.452] iteration:1255  t-loss:0.7677, loss-lb:0.7258, loss-ulb:0.5147, weight:0.08, lr:0.0009
[01:10:28.775] iteration:1256  t-loss:0.4742, loss-lb:0.4493, loss-ulb:0.3053, weight:0.08, lr:0.0009
[01:10:29.089] iteration:1257  t-loss:0.4564, loss-lb:0.3951, loss-ulb:0.7513, weight:0.08, lr:0.0009
[01:10:29.407] iteration:1258  t-loss:0.6074, loss-lb:0.4776, loss-ulb:1.5920, weight:0.08, lr:0.0009
[01:10:29.726] iteration:1259  t-loss:0.3402, loss-lb:0.3128, loss-ulb:0.3363, weight:0.08, lr:0.0009
[01:10:30.040] iteration:1260  t-loss:0.4176, loss-lb:0.4109, loss-ulb:0.0826, weight:0.08, lr:0.0009
[01:10:30.358] iteration:1261  t-loss:0.3920, loss-lb:0.3235, loss-ulb:0.8401, weight:0.08, lr:0.0009
[01:10:30.670] iteration:1262  t-loss:0.3731, loss-lb:0.3422, loss-ulb:0.3785, weight:0.08, lr:0.0009
[01:10:30.991] iteration:1263  t-loss:0.3704, loss-lb:0.3435, loss-ulb:0.3296, weight:0.08, lr:0.0009
[01:10:31.303] iteration:1264  t-loss:0.3050, loss-lb:0.2423, loss-ulb:0.7697, weight:0.08, lr:0.0009
[01:10:31.629] iteration:1265  t-loss:0.4728, loss-lb:0.4506, loss-ulb:0.2721, weight:0.08, lr:0.0009
[01:10:31.943] iteration:1266  t-loss:0.4538, loss-lb:0.4259, loss-ulb:0.3431, weight:0.08, lr:0.0009
[01:10:32.266] iteration:1267  t-loss:0.2833, loss-lb:0.2594, loss-ulb:0.2942, weight:0.08, lr:0.0009
[01:10:32.582] iteration:1268  t-loss:0.2521, loss-lb:0.2379, loss-ulb:0.1742, weight:0.08, lr:0.0009
[01:10:32.893] iteration:1269  t-loss:0.7529, loss-lb:0.7005, loss-ulb:0.6430, weight:0.08, lr:0.0009
[01:10:33.204] iteration:1270  t-loss:0.2191, loss-lb:0.2130, loss-ulb:0.0749, weight:0.08, lr:0.0009
[01:10:33.520] iteration:1271  t-loss:0.4808, loss-lb:0.4653, loss-ulb:0.1899, weight:0.08, lr:0.0009
[01:10:33.834] iteration:1272  t-loss:0.5494, loss-lb:0.4953, loss-ulb:0.6638, weight:0.08, lr:0.0009
[01:10:34.150] iteration:1273  t-loss:0.3402, loss-lb:0.3096, loss-ulb:0.3747, weight:0.08, lr:0.0009
[01:10:34.468] iteration:1274  t-loss:0.3296, loss-lb:0.2967, loss-ulb:0.4037, weight:0.08, lr:0.0009
[01:10:34.782] iteration:1275  t-loss:0.3808, loss-lb:0.3262, loss-ulb:0.6695, weight:0.08, lr:0.0009
[01:10:36.305] iteration:1276  t-loss:0.5165, loss-lb:0.4962, loss-ulb:0.2488, weight:0.08, lr:0.0009
[01:10:36.652] iteration:1277  t-loss:0.5887, loss-lb:0.5636, loss-ulb:0.3077, weight:0.08, lr:0.0009
[01:10:36.976] iteration:1278  t-loss:0.3713, loss-lb:0.3441, loss-ulb:0.3332, weight:0.08, lr:0.0009
[01:10:37.306] iteration:1279  t-loss:0.4447, loss-lb:0.4322, loss-ulb:0.1529, weight:0.08, lr:0.0009
[01:10:37.628] iteration:1280  t-loss:0.2890, loss-lb:0.2689, loss-ulb:0.2458, weight:0.08, lr:0.0009
[01:10:37.951] iteration:1281  t-loss:0.5186, loss-lb:0.4270, loss-ulb:1.1236, weight:0.08, lr:0.0009
[01:10:38.266] iteration:1282  t-loss:0.2641, loss-lb:0.2357, loss-ulb:0.3477, weight:0.08, lr:0.0009
[01:10:38.586] iteration:1283  t-loss:0.2265, loss-lb:0.2153, loss-ulb:0.1379, weight:0.08, lr:0.0009
[01:10:38.908] iteration:1284  t-loss:0.3646, loss-lb:0.3372, loss-ulb:0.3357, weight:0.08, lr:0.0009
[01:10:39.229] iteration:1285  t-loss:0.5135, loss-lb:0.4991, loss-ulb:0.1762, weight:0.08, lr:0.0009
[01:10:39.540] iteration:1286  t-loss:0.3274, loss-lb:0.3110, loss-ulb:0.2010, weight:0.08, lr:0.0009
[01:10:39.858] iteration:1287  t-loss:0.4793, loss-lb:0.4545, loss-ulb:0.3049, weight:0.08, lr:0.0009
[01:10:40.180] iteration:1288  t-loss:0.2193, loss-lb:0.2004, loss-ulb:0.2317, weight:0.08, lr:0.0009
[01:10:40.503] iteration:1289  t-loss:0.2930, loss-lb:0.2840, loss-ulb:0.1107, weight:0.08, lr:0.0009
[01:10:40.826] iteration:1290  t-loss:0.3640, loss-lb:0.3509, loss-ulb:0.1607, weight:0.08, lr:0.0009
[01:10:41.145] iteration:1291  t-loss:0.2701, loss-lb:0.2592, loss-ulb:0.1344, weight:0.08, lr:0.0009
[01:10:41.467] iteration:1292  t-loss:0.9192, loss-lb:0.9034, loss-ulb:0.1941, weight:0.08, lr:0.0009
[01:10:41.785] iteration:1293  t-loss:0.3383, loss-lb:0.3337, loss-ulb:0.0562, weight:0.08, lr:0.0009
[01:10:42.097] iteration:1294  t-loss:0.2921, loss-lb:0.2736, loss-ulb:0.2272, weight:0.08, lr:0.0009
[01:10:42.415] iteration:1295  t-loss:0.2875, loss-lb:0.2721, loss-ulb:0.1882, weight:0.08, lr:0.0009
[01:10:42.731] iteration:1296  t-loss:0.3265, loss-lb:0.2939, loss-ulb:0.4005, weight:0.08, lr:0.0009
[01:10:43.045] iteration:1297  t-loss:0.4404, loss-lb:0.4055, loss-ulb:0.4278, weight:0.08, lr:0.0009
[01:10:43.361] iteration:1298  t-loss:0.3598, loss-lb:0.3226, loss-ulb:0.4555, weight:0.08, lr:0.0009
[01:10:43.678] iteration:1299  t-loss:0.4954, loss-lb:0.4581, loss-ulb:0.4574, weight:0.08, lr:0.0009
[01:10:43.994] iteration:1300  t-loss:0.3776, loss-lb:0.3430, loss-ulb:0.4251, weight:0.08, lr:0.0009
[01:10:45.492] iteration:1301  t-loss:0.3395, loss-lb:0.3139, loss-ulb:0.3147, weight:0.08, lr:0.0009
[01:10:45.817] iteration:1302  t-loss:0.5281, loss-lb:0.4940, loss-ulb:0.4183, weight:0.08, lr:0.0009
[01:10:46.146] iteration:1303  t-loss:0.4372, loss-lb:0.4178, loss-ulb:0.2380, weight:0.08, lr:0.0009
[01:10:46.463] iteration:1304  t-loss:0.3064, loss-lb:0.2951, loss-ulb:0.1385, weight:0.08, lr:0.0009
[01:10:46.783] iteration:1305  t-loss:0.3065, loss-lb:0.2789, loss-ulb:0.3380, weight:0.08, lr:0.0009
[01:10:47.101] iteration:1306  t-loss:0.5102, loss-lb:0.4914, loss-ulb:0.2313, weight:0.08, lr:0.0009
[01:10:47.417] iteration:1307  t-loss:0.5426, loss-lb:0.5193, loss-ulb:0.2858, weight:0.08, lr:0.0009
[01:10:47.733] iteration:1308  t-loss:0.9156, loss-lb:0.8526, loss-ulb:0.7716, weight:0.08, lr:0.0009
[01:10:48.049] iteration:1309  t-loss:0.2579, loss-lb:0.2502, loss-ulb:0.0945, weight:0.08, lr:0.0009
[01:10:48.366] iteration:1310  t-loss:0.3017, loss-lb:0.2734, loss-ulb:0.3463, weight:0.08, lr:0.0009
[01:10:48.691] iteration:1311  t-loss:0.3557, loss-lb:0.3229, loss-ulb:0.4025, weight:0.08, lr:0.0009
[01:10:49.011] iteration:1312  t-loss:0.5887, loss-lb:0.5770, loss-ulb:0.1436, weight:0.08, lr:0.0009
[01:10:49.329] iteration:1313  t-loss:0.8851, loss-lb:0.8348, loss-ulb:0.6166, weight:0.08, lr:0.0009
[01:10:49.654] iteration:1314  t-loss:0.3980, loss-lb:0.3780, loss-ulb:0.2454, weight:0.08, lr:0.0009
[01:10:49.976] iteration:1315  t-loss:0.5083, loss-lb:0.4837, loss-ulb:0.3012, weight:0.08, lr:0.0009
[01:10:50.296] iteration:1316  t-loss:0.3771, loss-lb:0.3517, loss-ulb:0.3108, weight:0.08, lr:0.0009
[01:10:50.616] iteration:1317  t-loss:0.4637, loss-lb:0.4546, loss-ulb:0.1118, weight:0.08, lr:0.0009
[01:10:50.933] iteration:1318  t-loss:0.5029, loss-lb:0.4706, loss-ulb:0.3970, weight:0.08, lr:0.0009
[01:10:51.246] iteration:1319  t-loss:0.3969, loss-lb:0.3713, loss-ulb:0.3148, weight:0.08, lr:0.0009
[01:10:51.557] iteration:1320  t-loss:0.4731, loss-lb:0.4662, loss-ulb:0.0845, weight:0.08, lr:0.0009
[01:10:51.877] iteration:1321  t-loss:0.5239, loss-lb:0.5056, loss-ulb:0.2252, weight:0.08, lr:0.0009
[01:10:52.196] iteration:1322  t-loss:0.3446, loss-lb:0.3328, loss-ulb:0.1440, weight:0.08, lr:0.0009
[01:10:52.510] iteration:1323  t-loss:0.3783, loss-lb:0.3651, loss-ulb:0.1622, weight:0.08, lr:0.0009
[01:10:52.824] iteration:1324  t-loss:0.6538, loss-lb:0.6467, loss-ulb:0.0872, weight:0.08, lr:0.0009
[01:10:53.138] iteration:1325  t-loss:0.4469, loss-lb:0.4086, loss-ulb:0.4700, weight:0.08, lr:0.0009
[01:13:13.453] iteration 1325 : dice_score: 0.748726 best_dice: 0.767900
[01:13:13.454]  <<Test>> - Ep:52  - Dice-S/T:71.66/74.87, Best-S:71.66, Best-T:76.79
[01:13:13.454]           - AvgLoss(lb/ulb/all):0.45/0.29/0.49
[01:13:14.736] iteration:1326  t-loss:0.3774, loss-lb:0.3494, loss-ulb:0.3438, weight:0.08, lr:0.0009
[01:13:15.080] iteration:1327  t-loss:0.7038, loss-lb:0.6486, loss-ulb:0.6773, weight:0.08, lr:0.0009
[01:13:15.420] iteration:1328  t-loss:0.5796, loss-lb:0.5197, loss-ulb:0.7346, weight:0.08, lr:0.0009
[01:13:15.769] iteration:1329  t-loss:0.2877, loss-lb:0.2466, loss-ulb:0.5044, weight:0.08, lr:0.0009
[01:13:16.093] iteration:1330  t-loss:0.3997, loss-lb:0.3847, loss-ulb:0.1840, weight:0.08, lr:0.0009
[01:13:16.420] iteration:1331  t-loss:0.3402, loss-lb:0.3263, loss-ulb:0.1715, weight:0.08, lr:0.0009
[01:13:16.745] iteration:1332  t-loss:0.7977, loss-lb:0.7787, loss-ulb:0.2338, weight:0.08, lr:0.0009
[01:13:17.075] iteration:1333  t-loss:0.4251, loss-lb:0.3846, loss-ulb:0.4976, weight:0.08, lr:0.0009
[01:13:17.400] iteration:1334  t-loss:0.4317, loss-lb:0.4069, loss-ulb:0.3045, weight:0.08, lr:0.0009
[01:13:17.726] iteration:1335  t-loss:0.5674, loss-lb:0.5383, loss-ulb:0.3568, weight:0.08, lr:0.0009
[01:13:18.056] iteration:1336  t-loss:0.8216, loss-lb:0.7411, loss-ulb:0.9873, weight:0.08, lr:0.0009
[01:13:18.387] iteration:1337  t-loss:0.6103, loss-lb:0.5857, loss-ulb:0.3016, weight:0.08, lr:0.0009
[01:13:18.707] iteration:1338  t-loss:0.6899, loss-lb:0.6557, loss-ulb:0.4195, weight:0.08, lr:0.0009
[01:13:19.029] iteration:1339  t-loss:0.3290, loss-lb:0.3062, loss-ulb:0.2806, weight:0.08, lr:0.0009
[01:13:19.358] iteration:1340  t-loss:0.4070, loss-lb:0.3711, loss-ulb:0.4408, weight:0.08, lr:0.0009
[01:13:19.677] iteration:1341  t-loss:0.7873, loss-lb:0.7663, loss-ulb:0.2582, weight:0.08, lr:0.0009
[01:13:19.998] iteration:1342  t-loss:0.4123, loss-lb:0.3988, loss-ulb:0.1662, weight:0.08, lr:0.0009
[01:13:20.318] iteration:1343  t-loss:0.7301, loss-lb:0.6766, loss-ulb:0.6562, weight:0.08, lr:0.0009
[01:13:20.629] iteration:1344  t-loss:0.4422, loss-lb:0.4098, loss-ulb:0.3970, weight:0.08, lr:0.0009
[01:13:20.941] iteration:1345  t-loss:0.4401, loss-lb:0.4189, loss-ulb:0.2596, weight:0.08, lr:0.0009
[01:13:21.257] iteration:1346  t-loss:0.5591, loss-lb:0.5382, loss-ulb:0.2561, weight:0.08, lr:0.0009
[01:13:21.570] iteration:1347  t-loss:0.6175, loss-lb:0.5330, loss-ulb:1.0363, weight:0.08, lr:0.0009
[01:13:21.882] iteration:1348  t-loss:0.3846, loss-lb:0.3515, loss-ulb:0.4059, weight:0.08, lr:0.0009
[01:13:22.197] iteration:1349  t-loss:0.6044, loss-lb:0.5409, loss-ulb:0.7784, weight:0.08, lr:0.0009
[01:13:22.512] iteration:1350  t-loss:0.4035, loss-lb:0.3907, loss-ulb:0.1565, weight:0.08, lr:0.0009
[01:13:23.749] iteration:1351  t-loss:0.5104, loss-lb:0.4638, loss-ulb:0.4699, weight:0.10, lr:0.0009
[01:13:24.083] iteration:1352  t-loss:0.5274, loss-lb:0.5153, loss-ulb:0.1220, weight:0.10, lr:0.0009
[01:13:24.406] iteration:1353  t-loss:0.2969, loss-lb:0.2721, loss-ulb:0.2491, weight:0.10, lr:0.0009
[01:13:24.723] iteration:1354  t-loss:0.3843, loss-lb:0.3378, loss-ulb:0.4685, weight:0.10, lr:0.0009
[01:13:25.055] iteration:1355  t-loss:0.5320, loss-lb:0.4852, loss-ulb:0.4709, weight:0.10, lr:0.0009
[01:13:25.390] iteration:1356  t-loss:0.3262, loss-lb:0.2938, loss-ulb:0.3272, weight:0.10, lr:0.0009
[01:13:25.729] iteration:1357  t-loss:0.3481, loss-lb:0.3146, loss-ulb:0.3374, weight:0.10, lr:0.0009
[01:13:26.069] iteration:1358  t-loss:0.2643, loss-lb:0.2432, loss-ulb:0.2120, weight:0.10, lr:0.0009
[01:13:26.398] iteration:1359  t-loss:0.3628, loss-lb:0.3401, loss-ulb:0.2287, weight:0.10, lr:0.0009
[01:13:26.732] iteration:1360  t-loss:0.6634, loss-lb:0.6393, loss-ulb:0.2429, weight:0.10, lr:0.0009
[01:13:27.076] iteration:1361  t-loss:0.4596, loss-lb:0.3765, loss-ulb:0.8379, weight:0.10, lr:0.0009
[01:13:27.401] iteration:1362  t-loss:0.3364, loss-lb:0.3134, loss-ulb:0.2314, weight:0.10, lr:0.0009
[01:13:27.736] iteration:1363  t-loss:0.6137, loss-lb:0.5430, loss-ulb:0.7126, weight:0.10, lr:0.0009
[01:13:28.060] iteration:1364  t-loss:0.2958, loss-lb:0.2763, loss-ulb:0.1967, weight:0.10, lr:0.0009
[01:13:28.384] iteration:1365  t-loss:0.5387, loss-lb:0.4846, loss-ulb:0.5454, weight:0.10, lr:0.0009
[01:13:28.706] iteration:1366  t-loss:0.7468, loss-lb:0.7323, loss-ulb:0.1458, weight:0.10, lr:0.0009
[01:13:29.031] iteration:1367  t-loss:0.4673, loss-lb:0.3936, loss-ulb:0.7423, weight:0.10, lr:0.0009
[01:13:29.345] iteration:1368  t-loss:0.3433, loss-lb:0.2796, loss-ulb:0.6420, weight:0.10, lr:0.0009
[01:13:29.660] iteration:1369  t-loss:0.5539, loss-lb:0.4615, loss-ulb:0.9310, weight:0.10, lr:0.0009
[01:13:29.976] iteration:1370  t-loss:0.3082, loss-lb:0.2945, loss-ulb:0.1384, weight:0.10, lr:0.0009
[01:13:30.291] iteration:1371  t-loss:0.5311, loss-lb:0.4915, loss-ulb:0.3985, weight:0.10, lr:0.0009
[01:13:30.619] iteration:1372  t-loss:0.6274, loss-lb:0.5721, loss-ulb:0.5574, weight:0.10, lr:0.0009
[01:13:30.944] iteration:1373  t-loss:0.2681, loss-lb:0.2356, loss-ulb:0.3273, weight:0.10, lr:0.0009
[01:13:31.264] iteration:1374  t-loss:0.3364, loss-lb:0.2643, loss-ulb:0.7264, weight:0.10, lr:0.0009
[01:13:31.586] iteration:1375  t-loss:0.4903, loss-lb:0.4733, loss-ulb:0.1719, weight:0.10, lr:0.0009
[01:13:33.115] iteration:1376  t-loss:0.3393, loss-lb:0.3140, loss-ulb:0.2546, weight:0.10, lr:0.0009
[01:13:33.450] iteration:1377  t-loss:0.5193, loss-lb:0.4431, loss-ulb:0.7676, weight:0.10, lr:0.0009
[01:13:33.779] iteration:1378  t-loss:0.4155, loss-lb:0.3969, loss-ulb:0.1880, weight:0.10, lr:0.0009
[01:13:34.103] iteration:1379  t-loss:0.2751, loss-lb:0.2550, loss-ulb:0.2028, weight:0.10, lr:0.0009
[01:13:34.423] iteration:1380  t-loss:0.2699, loss-lb:0.2386, loss-ulb:0.3157, weight:0.10, lr:0.0009
[01:13:34.748] iteration:1381  t-loss:0.5224, loss-lb:0.4743, loss-ulb:0.4851, weight:0.10, lr:0.0009
[01:13:35.067] iteration:1382  t-loss:0.6186, loss-lb:0.5555, loss-ulb:0.6354, weight:0.10, lr:0.0009
[01:13:35.389] iteration:1383  t-loss:0.4794, loss-lb:0.4017, loss-ulb:0.7824, weight:0.10, lr:0.0009
[01:13:35.709] iteration:1384  t-loss:0.2952, loss-lb:0.2900, loss-ulb:0.0517, weight:0.10, lr:0.0009
[01:13:36.038] iteration:1385  t-loss:0.4668, loss-lb:0.4436, loss-ulb:0.2337, weight:0.10, lr:0.0009
[01:13:36.355] iteration:1386  t-loss:0.3763, loss-lb:0.3245, loss-ulb:0.5218, weight:0.10, lr:0.0009
[01:13:36.672] iteration:1387  t-loss:0.4596, loss-lb:0.4338, loss-ulb:0.2600, weight:0.10, lr:0.0009
[01:13:36.992] iteration:1388  t-loss:0.3335, loss-lb:0.3049, loss-ulb:0.2876, weight:0.10, lr:0.0009
[01:13:37.328] iteration:1389  t-loss:0.5062, loss-lb:0.4632, loss-ulb:0.4332, weight:0.10, lr:0.0009
[01:13:37.677] iteration:1390  t-loss:0.5374, loss-lb:0.4650, loss-ulb:0.7290, weight:0.10, lr:0.0009
[01:13:38.008] iteration:1391  t-loss:0.3585, loss-lb:0.2979, loss-ulb:0.6110, weight:0.10, lr:0.0009
[01:13:38.348] iteration:1392  t-loss:0.3262, loss-lb:0.3015, loss-ulb:0.2496, weight:0.10, lr:0.0009
[01:13:38.690] iteration:1393  t-loss:0.5265, loss-lb:0.4449, loss-ulb:0.8217, weight:0.10, lr:0.0009
[01:13:39.043] iteration:1394  t-loss:0.3067, loss-lb:0.2684, loss-ulb:0.3858, weight:0.10, lr:0.0009
[01:13:39.395] iteration:1395  t-loss:0.4479, loss-lb:0.3879, loss-ulb:0.6038, weight:0.10, lr:0.0009
[01:13:39.726] iteration:1396  t-loss:0.4493, loss-lb:0.3837, loss-ulb:0.6609, weight:0.10, lr:0.0009
[01:13:40.059] iteration:1397  t-loss:0.2938, loss-lb:0.2763, loss-ulb:0.1763, weight:0.10, lr:0.0009
[01:13:40.398] iteration:1398  t-loss:0.5291, loss-lb:0.4760, loss-ulb:0.5356, weight:0.10, lr:0.0009
[01:13:40.754] iteration:1399  t-loss:0.6911, loss-lb:0.6571, loss-ulb:0.3431, weight:0.10, lr:0.0009
[01:13:41.087] iteration:1400  t-loss:0.3713, loss-lb:0.3092, loss-ulb:0.6259, weight:0.10, lr:0.0009
[01:13:43.105] iteration:1401  t-loss:0.5984, loss-lb:0.5333, loss-ulb:0.6560, weight:0.10, lr:0.0009
[01:13:43.440] iteration:1402  t-loss:0.5503, loss-lb:0.5192, loss-ulb:0.3132, weight:0.10, lr:0.0009
[01:13:43.767] iteration:1403  t-loss:0.3694, loss-lb:0.3266, loss-ulb:0.4311, weight:0.10, lr:0.0009
[01:13:44.087] iteration:1404  t-loss:0.3819, loss-lb:0.3038, loss-ulb:0.7859, weight:0.10, lr:0.0009
[01:13:44.408] iteration:1405  t-loss:0.3980, loss-lb:0.3872, loss-ulb:0.1079, weight:0.10, lr:0.0009
[01:13:44.723] iteration:1406  t-loss:0.3695, loss-lb:0.3143, loss-ulb:0.5560, weight:0.10, lr:0.0009
[01:13:45.052] iteration:1407  t-loss:0.3259, loss-lb:0.2464, loss-ulb:0.8012, weight:0.10, lr:0.0009
[01:13:45.368] iteration:1408  t-loss:0.3377, loss-lb:0.3098, loss-ulb:0.2809, weight:0.10, lr:0.0009
[01:13:45.685] iteration:1409  t-loss:0.5106, loss-lb:0.4338, loss-ulb:0.7741, weight:0.10, lr:0.0009
[01:13:45.999] iteration:1410  t-loss:0.2422, loss-lb:0.2002, loss-ulb:0.4233, weight:0.10, lr:0.0009
[01:13:46.311] iteration:1411  t-loss:0.5600, loss-lb:0.4525, loss-ulb:1.0834, weight:0.10, lr:0.0009
[01:13:46.633] iteration:1412  t-loss:0.4779, loss-lb:0.4575, loss-ulb:0.2049, weight:0.10, lr:0.0009
[01:13:46.974] iteration:1413  t-loss:0.2715, loss-lb:0.2540, loss-ulb:0.1759, weight:0.10, lr:0.0009
[01:13:47.310] iteration:1414  t-loss:0.2523, loss-lb:0.2317, loss-ulb:0.2079, weight:0.10, lr:0.0009
[01:13:47.651] iteration:1415  t-loss:0.3545, loss-lb:0.3225, loss-ulb:0.3226, weight:0.10, lr:0.0009
[01:13:47.996] iteration:1416  t-loss:0.3603, loss-lb:0.3186, loss-ulb:0.4198, weight:0.10, lr:0.0009
[01:13:48.322] iteration:1417  t-loss:0.4345, loss-lb:0.4078, loss-ulb:0.2693, weight:0.10, lr:0.0009
[01:13:48.643] iteration:1418  t-loss:0.3240, loss-lb:0.3032, loss-ulb:0.2103, weight:0.10, lr:0.0009
[01:13:48.956] iteration:1419  t-loss:0.2164, loss-lb:0.2019, loss-ulb:0.1459, weight:0.10, lr:0.0009
[01:13:49.278] iteration:1420  t-loss:0.4871, loss-lb:0.4507, loss-ulb:0.3666, weight:0.10, lr:0.0009
[01:13:49.610] iteration:1421  t-loss:0.4931, loss-lb:0.4844, loss-ulb:0.0877, weight:0.10, lr:0.0009
[01:13:49.935] iteration:1422  t-loss:0.3811, loss-lb:0.3533, loss-ulb:0.2802, weight:0.10, lr:0.0009
[01:13:50.248] iteration:1423  t-loss:0.5661, loss-lb:0.4506, loss-ulb:1.1642, weight:0.10, lr:0.0009
[01:13:50.564] iteration:1424  t-loss:0.2731, loss-lb:0.2258, loss-ulb:0.4770, weight:0.10, lr:0.0009
[01:13:50.879] iteration:1425  t-loss:0.2607, loss-lb:0.2385, loss-ulb:0.2243, weight:0.10, lr:0.0009
[01:15:54.580] iteration 1425 : dice_score: 0.760983 best_dice: 0.767900
[01:15:54.580]  <<Test>> - Ep:56  - Dice-S/T:71.22/76.10, Best-S:71.66, Best-T:76.79
[01:15:54.580]           - AvgLoss(lb/ulb/all):0.35/0.42/0.37
[01:15:56.395] iteration:1426  t-loss:0.2953, loss-lb:0.2742, loss-ulb:0.2120, weight:0.10, lr:0.0009
[01:15:56.762] iteration:1427  t-loss:0.4615, loss-lb:0.4284, loss-ulb:0.3329, weight:0.10, lr:0.0009
[01:15:57.134] iteration:1428  t-loss:0.5294, loss-lb:0.5130, loss-ulb:0.1659, weight:0.10, lr:0.0009
[01:15:57.487] iteration:1429  t-loss:0.1869, loss-lb:0.1775, loss-ulb:0.0950, weight:0.10, lr:0.0009
[01:15:57.829] iteration:1430  t-loss:0.3763, loss-lb:0.3269, loss-ulb:0.4976, weight:0.10, lr:0.0009
[01:15:58.167] iteration:1431  t-loss:0.5652, loss-lb:0.5582, loss-ulb:0.0705, weight:0.10, lr:0.0009
[01:15:58.501] iteration:1432  t-loss:0.5795, loss-lb:0.5659, loss-ulb:0.1371, weight:0.10, lr:0.0009
[01:15:58.823] iteration:1433  t-loss:0.3669, loss-lb:0.2971, loss-ulb:0.7026, weight:0.10, lr:0.0009
[01:15:59.141] iteration:1434  t-loss:0.5979, loss-lb:0.5712, loss-ulb:0.2687, weight:0.10, lr:0.0009
[01:15:59.459] iteration:1435  t-loss:0.4662, loss-lb:0.4232, loss-ulb:0.4326, weight:0.10, lr:0.0009
[01:15:59.775] iteration:1436  t-loss:0.2943, loss-lb:0.1700, loss-ulb:1.2518, weight:0.10, lr:0.0009
[01:16:00.093] iteration:1437  t-loss:0.4259, loss-lb:0.4085, loss-ulb:0.1760, weight:0.10, lr:0.0009
[01:16:00.411] iteration:1438  t-loss:0.4704, loss-lb:0.4604, loss-ulb:0.1007, weight:0.10, lr:0.0009
[01:16:00.725] iteration:1439  t-loss:0.2339, loss-lb:0.2064, loss-ulb:0.2769, weight:0.10, lr:0.0009
[01:16:01.040] iteration:1440  t-loss:0.2667, loss-lb:0.2360, loss-ulb:0.3098, weight:0.10, lr:0.0009
[01:16:01.356] iteration:1441  t-loss:0.2848, loss-lb:0.2274, loss-ulb:0.5787, weight:0.10, lr:0.0009
[01:16:01.675] iteration:1442  t-loss:0.6731, loss-lb:0.6559, loss-ulb:0.1735, weight:0.10, lr:0.0009
[01:16:01.986] iteration:1443  t-loss:0.4177, loss-lb:0.3905, loss-ulb:0.2740, weight:0.10, lr:0.0009
[01:16:02.299] iteration:1444  t-loss:0.3560, loss-lb:0.2892, loss-ulb:0.6733, weight:0.10, lr:0.0009
[01:16:02.615] iteration:1445  t-loss:0.5775, loss-lb:0.5426, loss-ulb:0.3517, weight:0.10, lr:0.0009
[01:16:02.928] iteration:1446  t-loss:0.4894, loss-lb:0.4319, loss-ulb:0.5787, weight:0.10, lr:0.0009
[01:16:03.240] iteration:1447  t-loss:0.3813, loss-lb:0.3423, loss-ulb:0.3927, weight:0.10, lr:0.0009
[01:16:03.553] iteration:1448  t-loss:0.5813, loss-lb:0.5354, loss-ulb:0.4626, weight:0.10, lr:0.0009
[01:16:03.876] iteration:1449  t-loss:0.4220, loss-lb:0.3822, loss-ulb:0.4012, weight:0.10, lr:0.0009
[01:16:04.203] iteration:1450  t-loss:0.4764, loss-lb:0.4521, loss-ulb:0.2446, weight:0.10, lr:0.0009
[01:16:06.381] iteration:1451  t-loss:0.3152, loss-lb:0.2575, loss-ulb:0.5815, weight:0.10, lr:0.0009
[01:16:06.752] iteration:1452  t-loss:0.3836, loss-lb:0.3778, loss-ulb:0.0583, weight:0.10, lr:0.0009
[01:16:07.091] iteration:1453  t-loss:0.3480, loss-lb:0.2767, loss-ulb:0.7184, weight:0.10, lr:0.0009
[01:16:07.434] iteration:1454  t-loss:0.6118, loss-lb:0.6059, loss-ulb:0.0598, weight:0.10, lr:0.0009
[01:16:07.765] iteration:1455  t-loss:0.6651, loss-lb:0.6457, loss-ulb:0.1951, weight:0.10, lr:0.0009
[01:16:08.091] iteration:1456  t-loss:0.4967, loss-lb:0.4360, loss-ulb:0.6117, weight:0.10, lr:0.0009
[01:16:08.415] iteration:1457  t-loss:0.5981, loss-lb:0.5688, loss-ulb:0.2947, weight:0.10, lr:0.0009
[01:16:08.730] iteration:1458  t-loss:0.2794, loss-lb:0.2549, loss-ulb:0.2469, weight:0.10, lr:0.0009
[01:16:09.047] iteration:1459  t-loss:0.3139, loss-lb:0.2839, loss-ulb:0.3019, weight:0.10, lr:0.0009
[01:16:09.362] iteration:1460  t-loss:0.6900, loss-lb:0.6158, loss-ulb:0.7482, weight:0.10, lr:0.0009
[01:16:09.679] iteration:1461  t-loss:0.7513, loss-lb:0.6975, loss-ulb:0.5423, weight:0.10, lr:0.0009
[01:16:09.997] iteration:1462  t-loss:0.4341, loss-lb:0.4177, loss-ulb:0.1653, weight:0.10, lr:0.0009
[01:16:10.311] iteration:1463  t-loss:0.2797, loss-lb:0.2704, loss-ulb:0.0938, weight:0.10, lr:0.0009
[01:16:10.624] iteration:1464  t-loss:0.2599, loss-lb:0.2374, loss-ulb:0.2269, weight:0.10, lr:0.0009
[01:16:10.940] iteration:1465  t-loss:0.3673, loss-lb:0.3346, loss-ulb:0.3296, weight:0.10, lr:0.0009
[01:16:11.256] iteration:1466  t-loss:0.7364, loss-lb:0.7017, loss-ulb:0.3493, weight:0.10, lr:0.0009
[01:16:11.568] iteration:1467  t-loss:0.6008, loss-lb:0.5728, loss-ulb:0.2826, weight:0.10, lr:0.0009
[01:16:11.881] iteration:1468  t-loss:0.4710, loss-lb:0.4147, loss-ulb:0.5671, weight:0.10, lr:0.0009
[01:16:12.194] iteration:1469  t-loss:0.3885, loss-lb:0.3574, loss-ulb:0.3136, weight:0.10, lr:0.0009
[01:16:12.509] iteration:1470  t-loss:0.4920, loss-lb:0.4442, loss-ulb:0.4811, weight:0.10, lr:0.0009
[01:16:12.821] iteration:1471  t-loss:0.3372, loss-lb:0.2859, loss-ulb:0.5167, weight:0.10, lr:0.0009
[01:16:13.134] iteration:1472  t-loss:0.4094, loss-lb:0.3684, loss-ulb:0.4126, weight:0.10, lr:0.0009
[01:16:13.447] iteration:1473  t-loss:0.4901, loss-lb:0.4165, loss-ulb:0.7410, weight:0.10, lr:0.0009
[01:16:13.762] iteration:1474  t-loss:0.5276, loss-lb:0.4961, loss-ulb:0.3175, weight:0.10, lr:0.0009
[01:16:14.077] iteration:1475  t-loss:0.3544, loss-lb:0.3477, loss-ulb:0.0668, weight:0.10, lr:0.0009
[01:16:15.411] iteration:1476  t-loss:0.4042, loss-lb:0.3592, loss-ulb:0.4532, weight:0.10, lr:0.0009
[01:16:15.727] iteration:1477  t-loss:0.3431, loss-lb:0.3221, loss-ulb:0.2114, weight:0.10, lr:0.0009
[01:16:16.048] iteration:1478  t-loss:0.4351, loss-lb:0.3385, loss-ulb:0.9733, weight:0.10, lr:0.0009
[01:16:16.362] iteration:1479  t-loss:0.2421, loss-lb:0.2340, loss-ulb:0.0810, weight:0.10, lr:0.0009
[01:16:16.682] iteration:1480  t-loss:0.3260, loss-lb:0.2990, loss-ulb:0.2719, weight:0.10, lr:0.0009
[01:16:17.000] iteration:1481  t-loss:0.4817, loss-lb:0.4125, loss-ulb:0.6970, weight:0.10, lr:0.0009
[01:16:17.313] iteration:1482  t-loss:0.5675, loss-lb:0.5050, loss-ulb:0.6298, weight:0.10, lr:0.0009
[01:16:17.639] iteration:1483  t-loss:0.4746, loss-lb:0.4214, loss-ulb:0.5363, weight:0.10, lr:0.0009
[01:16:17.961] iteration:1484  t-loss:0.3265, loss-lb:0.3047, loss-ulb:0.2196, weight:0.10, lr:0.0009
[01:16:18.279] iteration:1485  t-loss:0.5708, loss-lb:0.5187, loss-ulb:0.5241, weight:0.10, lr:0.0009
[01:16:18.601] iteration:1486  t-loss:0.4008, loss-lb:0.3752, loss-ulb:0.2581, weight:0.10, lr:0.0009
[01:16:18.916] iteration:1487  t-loss:0.3490, loss-lb:0.3388, loss-ulb:0.1025, weight:0.10, lr:0.0009
[01:16:19.233] iteration:1488  t-loss:0.3305, loss-lb:0.2619, loss-ulb:0.6911, weight:0.10, lr:0.0009
[01:16:19.549] iteration:1489  t-loss:0.3886, loss-lb:0.3542, loss-ulb:0.3468, weight:0.10, lr:0.0009
[01:16:19.873] iteration:1490  t-loss:0.2616, loss-lb:0.2397, loss-ulb:0.2201, weight:0.10, lr:0.0009
[01:16:20.187] iteration:1491  t-loss:0.3163, loss-lb:0.3086, loss-ulb:0.0775, weight:0.10, lr:0.0009
[01:16:20.510] iteration:1492  t-loss:0.5297, loss-lb:0.5075, loss-ulb:0.2236, weight:0.10, lr:0.0009
[01:16:20.828] iteration:1493  t-loss:0.5017, loss-lb:0.4665, loss-ulb:0.3545, weight:0.10, lr:0.0009
[01:16:21.140] iteration:1494  t-loss:0.5100, loss-lb:0.4976, loss-ulb:0.1251, weight:0.10, lr:0.0009
[01:16:21.455] iteration:1495  t-loss:0.4739, loss-lb:0.4281, loss-ulb:0.4608, weight:0.10, lr:0.0009
[01:16:21.768] iteration:1496  t-loss:0.3284, loss-lb:0.2939, loss-ulb:0.3472, weight:0.10, lr:0.0009
[01:16:22.084] iteration:1497  t-loss:0.2671, loss-lb:0.2578, loss-ulb:0.0937, weight:0.10, lr:0.0009
[01:16:22.395] iteration:1498  t-loss:0.3096, loss-lb:0.2538, loss-ulb:0.5618, weight:0.10, lr:0.0009
[01:16:22.707] iteration:1499  t-loss:0.5275, loss-lb:0.4206, loss-ulb:1.0767, weight:0.10, lr:0.0009
[01:16:23.017] iteration:1500  t-loss:0.3914, loss-lb:0.3362, loss-ulb:0.5552, weight:0.10, lr:0.0009
[01:16:24.358] iteration:1501  t-loss:0.3503, loss-lb:0.3161, loss-ulb:0.2850, weight:0.12, lr:0.0009
[01:16:24.698] iteration:1502  t-loss:0.6404, loss-lb:0.5760, loss-ulb:0.5363, weight:0.12, lr:0.0009
[01:16:25.026] iteration:1503  t-loss:0.3762, loss-lb:0.3313, loss-ulb:0.3745, weight:0.12, lr:0.0009
[01:16:25.365] iteration:1504  t-loss:0.4449, loss-lb:0.4233, loss-ulb:0.1798, weight:0.12, lr:0.0009
[01:16:25.687] iteration:1505  t-loss:0.3182, loss-lb:0.2466, loss-ulb:0.5956, weight:0.12, lr:0.0009
[01:16:26.007] iteration:1506  t-loss:0.3323, loss-lb:0.2999, loss-ulb:0.2695, weight:0.12, lr:0.0009
[01:16:26.321] iteration:1507  t-loss:0.4225, loss-lb:0.3999, loss-ulb:0.1877, weight:0.12, lr:0.0009
[01:16:26.637] iteration:1508  t-loss:0.2901, loss-lb:0.2660, loss-ulb:0.2008, weight:0.12, lr:0.0009
[01:16:26.954] iteration:1509  t-loss:0.5797, loss-lb:0.5347, loss-ulb:0.3749, weight:0.12, lr:0.0009
[01:16:27.274] iteration:1510  t-loss:0.3215, loss-lb:0.2893, loss-ulb:0.2678, weight:0.12, lr:0.0009
[01:16:27.603] iteration:1511  t-loss:0.4275, loss-lb:0.3540, loss-ulb:0.6120, weight:0.12, lr:0.0009
[01:16:27.925] iteration:1512  t-loss:0.2650, loss-lb:0.2538, loss-ulb:0.0928, weight:0.12, lr:0.0009
[01:16:28.249] iteration:1513  t-loss:0.3082, loss-lb:0.2890, loss-ulb:0.1600, weight:0.12, lr:0.0009
[01:16:28.575] iteration:1514  t-loss:0.6221, loss-lb:0.6035, loss-ulb:0.1555, weight:0.12, lr:0.0009
[01:16:28.897] iteration:1515  t-loss:0.2888, loss-lb:0.2762, loss-ulb:0.1048, weight:0.12, lr:0.0009
[01:16:29.224] iteration:1516  t-loss:0.4677, loss-lb:0.4369, loss-ulb:0.2571, weight:0.12, lr:0.0009
[01:16:29.542] iteration:1517  t-loss:0.4606, loss-lb:0.3967, loss-ulb:0.5317, weight:0.12, lr:0.0009
[01:16:29.860] iteration:1518  t-loss:0.3093, loss-lb:0.2927, loss-ulb:0.1386, weight:0.12, lr:0.0009
[01:16:30.173] iteration:1519  t-loss:0.2983, loss-lb:0.2623, loss-ulb:0.2992, weight:0.12, lr:0.0009
[01:16:30.490] iteration:1520  t-loss:0.4341, loss-lb:0.3944, loss-ulb:0.3305, weight:0.12, lr:0.0009
[01:16:30.807] iteration:1521  t-loss:0.4068, loss-lb:0.3808, loss-ulb:0.2168, weight:0.12, lr:0.0009
[01:16:31.128] iteration:1522  t-loss:0.4413, loss-lb:0.4152, loss-ulb:0.2173, weight:0.12, lr:0.0009
[01:16:31.443] iteration:1523  t-loss:0.5743, loss-lb:0.4867, loss-ulb:0.7294, weight:0.12, lr:0.0009
[01:16:31.756] iteration:1524  t-loss:0.5059, loss-lb:0.4388, loss-ulb:0.5586, weight:0.12, lr:0.0009
[01:16:32.072] iteration:1525  t-loss:0.3066, loss-lb:0.2698, loss-ulb:0.3066, weight:0.12, lr:0.0009
[01:18:44.956] iteration 1525 : dice_score: 0.776218 best_dice: 0.776200
[01:18:44.956]  <<Test>> - Ep:60  - Dice-S/T:77.36/77.62, Best-S:77.36, Best-T:77.62
[01:18:44.956]           - AvgLoss(lb/ulb/all):0.37/0.30/0.40
[01:18:46.349] iteration:1526  t-loss:0.2814, loss-lb:0.2262, loss-ulb:0.4601, weight:0.12, lr:0.0009
[01:18:46.699] iteration:1527  t-loss:0.5795, loss-lb:0.5362, loss-ulb:0.3608, weight:0.12, lr:0.0009
[01:18:47.023] iteration:1528  t-loss:0.3960, loss-lb:0.2934, loss-ulb:0.8544, weight:0.12, lr:0.0009
[01:18:47.348] iteration:1529  t-loss:0.2906, loss-lb:0.2703, loss-ulb:0.1693, weight:0.12, lr:0.0009
[01:18:47.673] iteration:1530  t-loss:0.4119, loss-lb:0.3707, loss-ulb:0.3431, weight:0.12, lr:0.0009
[01:18:47.992] iteration:1531  t-loss:0.7237, loss-lb:0.6921, loss-ulb:0.2632, weight:0.12, lr:0.0009
[01:18:48.309] iteration:1532  t-loss:0.2930, loss-lb:0.2590, loss-ulb:0.2830, weight:0.12, lr:0.0009
[01:18:48.629] iteration:1533  t-loss:0.4271, loss-lb:0.4137, loss-ulb:0.1114, weight:0.12, lr:0.0009
[01:18:48.945] iteration:1534  t-loss:0.3897, loss-lb:0.3161, loss-ulb:0.6129, weight:0.12, lr:0.0009
[01:18:49.260] iteration:1535  t-loss:0.2377, loss-lb:0.1946, loss-ulb:0.3595, weight:0.12, lr:0.0009
[01:18:49.584] iteration:1536  t-loss:0.4362, loss-lb:0.4166, loss-ulb:0.1634, weight:0.12, lr:0.0009
[01:18:49.905] iteration:1537  t-loss:0.3479, loss-lb:0.3200, loss-ulb:0.2329, weight:0.12, lr:0.0009
[01:18:50.219] iteration:1538  t-loss:0.4179, loss-lb:0.3746, loss-ulb:0.3610, weight:0.12, lr:0.0009
[01:18:50.535] iteration:1539  t-loss:0.3383, loss-lb:0.2887, loss-ulb:0.4128, weight:0.12, lr:0.0009
[01:18:50.856] iteration:1540  t-loss:0.4945, loss-lb:0.4489, loss-ulb:0.3794, weight:0.12, lr:0.0009
[01:18:51.176] iteration:1541  t-loss:0.2845, loss-lb:0.2590, loss-ulb:0.2123, weight:0.12, lr:0.0009
[01:18:51.499] iteration:1542  t-loss:0.3315, loss-lb:0.2992, loss-ulb:0.2689, weight:0.12, lr:0.0009
[01:18:51.812] iteration:1543  t-loss:0.2798, loss-lb:0.2635, loss-ulb:0.1353, weight:0.12, lr:0.0009
[01:18:52.123] iteration:1544  t-loss:0.2760, loss-lb:0.2318, loss-ulb:0.3677, weight:0.12, lr:0.0009
[01:18:52.438] iteration:1545  t-loss:0.4581, loss-lb:0.3793, loss-ulb:0.6559, weight:0.12, lr:0.0009
[01:18:52.748] iteration:1546  t-loss:0.2438, loss-lb:0.2254, loss-ulb:0.1531, weight:0.12, lr:0.0009
[01:18:53.063] iteration:1547  t-loss:0.4848, loss-lb:0.4393, loss-ulb:0.3793, weight:0.12, lr:0.0009
[01:18:53.379] iteration:1548  t-loss:0.6144, loss-lb:0.5371, loss-ulb:0.6436, weight:0.12, lr:0.0009
[01:18:53.693] iteration:1549  t-loss:0.3034, loss-lb:0.2410, loss-ulb:0.5192, weight:0.12, lr:0.0009
[01:18:54.012] iteration:1550  t-loss:0.4495, loss-lb:0.4411, loss-ulb:0.0698, weight:0.12, lr:0.0009
[01:18:55.417] iteration:1551  t-loss:0.6221, loss-lb:0.5475, loss-ulb:0.6209, weight:0.12, lr:0.0009
[01:18:55.776] iteration:1552  t-loss:0.5035, loss-lb:0.4667, loss-ulb:0.3067, weight:0.12, lr:0.0009
[01:18:56.102] iteration:1553  t-loss:0.5510, loss-lb:0.4559, loss-ulb:0.7918, weight:0.12, lr:0.0009
[01:18:56.428] iteration:1554  t-loss:0.3189, loss-lb:0.2981, loss-ulb:0.1736, weight:0.12, lr:0.0009
[01:18:56.748] iteration:1555  t-loss:0.2158, loss-lb:0.2024, loss-ulb:0.1119, weight:0.12, lr:0.0009
[01:18:57.064] iteration:1556  t-loss:0.6296, loss-lb:0.4897, loss-ulb:1.1650, weight:0.12, lr:0.0009
[01:18:57.385] iteration:1557  t-loss:0.3587, loss-lb:0.3462, loss-ulb:0.1041, weight:0.12, lr:0.0009
[01:18:57.704] iteration:1558  t-loss:0.3186, loss-lb:0.2949, loss-ulb:0.1965, weight:0.12, lr:0.0009
[01:18:58.026] iteration:1559  t-loss:0.3942, loss-lb:0.3496, loss-ulb:0.3714, weight:0.12, lr:0.0009
[01:18:58.346] iteration:1560  t-loss:0.7038, loss-lb:0.6405, loss-ulb:0.5265, weight:0.12, lr:0.0009
[01:18:58.667] iteration:1561  t-loss:0.9058, loss-lb:0.8346, loss-ulb:0.5933, weight:0.12, lr:0.0009
[01:18:58.985] iteration:1562  t-loss:0.2908, loss-lb:0.2488, loss-ulb:0.3495, weight:0.12, lr:0.0009
[01:18:59.304] iteration:1563  t-loss:0.3311, loss-lb:0.2563, loss-ulb:0.6229, weight:0.12, lr:0.0009
[01:18:59.619] iteration:1564  t-loss:0.4612, loss-lb:0.4066, loss-ulb:0.4551, weight:0.12, lr:0.0009
[01:18:59.936] iteration:1565  t-loss:0.3031, loss-lb:0.2877, loss-ulb:0.1278, weight:0.12, lr:0.0009
[01:19:00.253] iteration:1566  t-loss:0.6369, loss-lb:0.4959, loss-ulb:1.1737, weight:0.12, lr:0.0009
[01:19:00.569] iteration:1567  t-loss:0.3316, loss-lb:0.3035, loss-ulb:0.2339, weight:0.12, lr:0.0009
[01:19:00.887] iteration:1568  t-loss:0.5981, loss-lb:0.5480, loss-ulb:0.4171, weight:0.12, lr:0.0009
[01:19:01.203] iteration:1569  t-loss:0.8572, loss-lb:0.7963, loss-ulb:0.5073, weight:0.12, lr:0.0009
[01:19:01.517] iteration:1570  t-loss:0.5153, loss-lb:0.4058, loss-ulb:0.9113, weight:0.12, lr:0.0009
[01:19:01.837] iteration:1571  t-loss:0.6414, loss-lb:0.5773, loss-ulb:0.5340, weight:0.12, lr:0.0009
[01:19:02.152] iteration:1572  t-loss:0.3178, loss-lb:0.2787, loss-ulb:0.3259, weight:0.12, lr:0.0009
[01:19:02.471] iteration:1573  t-loss:0.5292, loss-lb:0.5197, loss-ulb:0.0790, weight:0.12, lr:0.0009
[01:19:02.783] iteration:1574  t-loss:0.4691, loss-lb:0.3248, loss-ulb:1.2012, weight:0.12, lr:0.0009
[01:19:03.093] iteration:1575  t-loss:0.5367, loss-lb:0.4988, loss-ulb:0.3160, weight:0.12, lr:0.0009
[01:19:04.245] iteration:1576  t-loss:0.3733, loss-lb:0.3144, loss-ulb:0.4903, weight:0.12, lr:0.0009
[01:19:04.584] iteration:1577  t-loss:0.2579, loss-lb:0.2511, loss-ulb:0.0567, weight:0.12, lr:0.0009
[01:19:04.912] iteration:1578  t-loss:0.7907, loss-lb:0.6454, loss-ulb:1.2103, weight:0.12, lr:0.0009
[01:19:05.249] iteration:1579  t-loss:0.5030, loss-lb:0.4638, loss-ulb:0.3265, weight:0.12, lr:0.0009
[01:19:05.572] iteration:1580  t-loss:0.3057, loss-lb:0.2653, loss-ulb:0.3362, weight:0.12, lr:0.0009
[01:19:05.896] iteration:1581  t-loss:0.4043, loss-lb:0.3055, loss-ulb:0.8224, weight:0.12, lr:0.0009
[01:19:06.217] iteration:1582  t-loss:0.2574, loss-lb:0.2144, loss-ulb:0.3576, weight:0.12, lr:0.0009
[01:19:06.549] iteration:1583  t-loss:0.4924, loss-lb:0.4663, loss-ulb:0.2169, weight:0.12, lr:0.0009
[01:19:06.878] iteration:1584  t-loss:0.6243, loss-lb:0.5430, loss-ulb:0.6774, weight:0.12, lr:0.0009
[01:19:07.200] iteration:1585  t-loss:0.5768, loss-lb:0.4954, loss-ulb:0.6778, weight:0.12, lr:0.0009
[01:19:07.526] iteration:1586  t-loss:0.2709, loss-lb:0.2372, loss-ulb:0.2808, weight:0.12, lr:0.0009
[01:19:07.852] iteration:1587  t-loss:0.2287, loss-lb:0.2055, loss-ulb:0.1938, weight:0.12, lr:0.0009
[01:19:08.170] iteration:1588  t-loss:0.3479, loss-lb:0.2929, loss-ulb:0.4576, weight:0.12, lr:0.0009
[01:19:08.508] iteration:1589  t-loss:0.8711, loss-lb:0.7470, loss-ulb:1.0338, weight:0.12, lr:0.0009
[01:19:08.839] iteration:1590  t-loss:0.3196, loss-lb:0.2776, loss-ulb:0.3497, weight:0.12, lr:0.0009
[01:19:09.170] iteration:1591  t-loss:0.2488, loss-lb:0.2345, loss-ulb:0.1196, weight:0.12, lr:0.0009
[01:19:09.495] iteration:1592  t-loss:0.5197, loss-lb:0.4143, loss-ulb:0.8780, weight:0.12, lr:0.0009
[01:19:09.813] iteration:1593  t-loss:0.4727, loss-lb:0.3899, loss-ulb:0.6893, weight:0.12, lr:0.0009
[01:19:10.135] iteration:1594  t-loss:0.3344, loss-lb:0.2551, loss-ulb:0.6603, weight:0.12, lr:0.0009
[01:19:10.447] iteration:1595  t-loss:0.3700, loss-lb:0.3625, loss-ulb:0.0627, weight:0.12, lr:0.0009
[01:19:10.760] iteration:1596  t-loss:0.3375, loss-lb:0.3254, loss-ulb:0.1007, weight:0.12, lr:0.0009
[01:19:11.074] iteration:1597  t-loss:0.3791, loss-lb:0.3142, loss-ulb:0.5408, weight:0.12, lr:0.0009
[01:19:11.388] iteration:1598  t-loss:0.3363, loss-lb:0.2853, loss-ulb:0.4244, weight:0.12, lr:0.0009
[01:19:11.698] iteration:1599  t-loss:0.8164, loss-lb:0.7005, loss-ulb:0.9650, weight:0.12, lr:0.0009
[01:19:12.011] iteration:1600  t-loss:0.3116, loss-lb:0.2830, loss-ulb:0.2388, weight:0.12, lr:0.0009
[01:19:13.247] iteration:1601  t-loss:0.6513, loss-lb:0.6064, loss-ulb:0.3736, weight:0.12, lr:0.0009
[01:19:13.585] iteration:1602  t-loss:0.5017, loss-lb:0.4812, loss-ulb:0.1709, weight:0.12, lr:0.0009
[01:19:13.910] iteration:1603  t-loss:0.4853, loss-lb:0.4376, loss-ulb:0.3970, weight:0.12, lr:0.0009
[01:19:14.235] iteration:1604  t-loss:0.7360, loss-lb:0.7303, loss-ulb:0.0475, weight:0.12, lr:0.0009
[01:19:14.559] iteration:1605  t-loss:0.6074, loss-lb:0.5356, loss-ulb:0.5982, weight:0.12, lr:0.0009
[01:19:14.879] iteration:1606  t-loss:0.2945, loss-lb:0.2750, loss-ulb:0.1619, weight:0.12, lr:0.0009
[01:19:15.201] iteration:1607  t-loss:0.4707, loss-lb:0.3449, loss-ulb:1.0468, weight:0.12, lr:0.0009
[01:19:15.521] iteration:1608  t-loss:0.3798, loss-lb:0.3218, loss-ulb:0.4831, weight:0.12, lr:0.0009
[01:19:15.846] iteration:1609  t-loss:0.2529, loss-lb:0.2255, loss-ulb:0.2276, weight:0.12, lr:0.0009
[01:19:16.170] iteration:1610  t-loss:0.3612, loss-lb:0.3177, loss-ulb:0.3624, weight:0.12, lr:0.0009
[01:19:16.491] iteration:1611  t-loss:0.5164, loss-lb:0.4402, loss-ulb:0.6342, weight:0.12, lr:0.0009
[01:19:16.810] iteration:1612  t-loss:0.2569, loss-lb:0.2172, loss-ulb:0.3308, weight:0.12, lr:0.0009
[01:19:17.127] iteration:1613  t-loss:0.3866, loss-lb:0.3756, loss-ulb:0.0909, weight:0.12, lr:0.0009
[01:19:17.451] iteration:1614  t-loss:0.5662, loss-lb:0.5140, loss-ulb:0.4343, weight:0.12, lr:0.0009
[01:19:17.770] iteration:1615  t-loss:0.1978, loss-lb:0.1844, loss-ulb:0.1109, weight:0.12, lr:0.0009
[01:19:18.087] iteration:1616  t-loss:0.4533, loss-lb:0.3714, loss-ulb:0.6817, weight:0.12, lr:0.0009
[01:19:18.411] iteration:1617  t-loss:0.4058, loss-lb:0.3602, loss-ulb:0.3794, weight:0.12, lr:0.0009
[01:19:18.726] iteration:1618  t-loss:0.2988, loss-lb:0.2922, loss-ulb:0.0549, weight:0.12, lr:0.0009
[01:19:19.040] iteration:1619  t-loss:0.2873, loss-lb:0.2389, loss-ulb:0.4029, weight:0.12, lr:0.0009
[01:19:19.353] iteration:1620  t-loss:0.5142, loss-lb:0.4927, loss-ulb:0.1785, weight:0.12, lr:0.0009
[01:19:19.669] iteration:1621  t-loss:0.3531, loss-lb:0.3017, loss-ulb:0.4278, weight:0.12, lr:0.0009
[01:19:19.987] iteration:1622  t-loss:0.5651, loss-lb:0.5482, loss-ulb:0.1408, weight:0.12, lr:0.0009
[01:19:20.299] iteration:1623  t-loss:0.2536, loss-lb:0.2316, loss-ulb:0.1831, weight:0.12, lr:0.0009
[01:19:20.612] iteration:1624  t-loss:0.5220, loss-lb:0.4955, loss-ulb:0.2206, weight:0.12, lr:0.0009
[01:19:20.930] iteration:1625  t-loss:0.3660, loss-lb:0.3534, loss-ulb:0.1049, weight:0.12, lr:0.0009
[01:21:31.466] iteration 1625 : dice_score: 0.767250 best_dice: 0.776200
[01:21:31.466]  <<Test>> - Ep:64  - Dice-S/T:73.76/76.73, Best-S:77.36, Best-T:77.62
[01:21:31.466]           - AvgLoss(lb/ulb/all):0.39/0.33/0.39
[01:21:32.760] iteration:1626  t-loss:0.4767, loss-lb:0.4703, loss-ulb:0.0529, weight:0.12, lr:0.0009
[01:21:33.092] iteration:1627  t-loss:0.6506, loss-lb:0.5970, loss-ulb:0.4462, weight:0.12, lr:0.0009
[01:21:33.421] iteration:1628  t-loss:0.3996, loss-lb:0.3211, loss-ulb:0.6536, weight:0.12, lr:0.0009
[01:21:33.742] iteration:1629  t-loss:0.4909, loss-lb:0.4602, loss-ulb:0.2562, weight:0.12, lr:0.0009
[01:21:34.062] iteration:1630  t-loss:0.3357, loss-lb:0.2836, loss-ulb:0.4338, weight:0.12, lr:0.0009
[01:21:34.379] iteration:1631  t-loss:0.4884, loss-lb:0.4773, loss-ulb:0.0926, weight:0.12, lr:0.0009
[01:21:34.696] iteration:1632  t-loss:0.4267, loss-lb:0.4192, loss-ulb:0.0623, weight:0.12, lr:0.0009
[01:21:35.014] iteration:1633  t-loss:0.4269, loss-lb:0.4046, loss-ulb:0.1862, weight:0.12, lr:0.0009
[01:21:35.327] iteration:1634  t-loss:0.3199, loss-lb:0.2586, loss-ulb:0.5106, weight:0.12, lr:0.0009
[01:21:35.649] iteration:1635  t-loss:0.2548, loss-lb:0.2081, loss-ulb:0.3891, weight:0.12, lr:0.0009
[01:21:35.962] iteration:1636  t-loss:0.3470, loss-lb:0.2238, loss-ulb:1.0252, weight:0.12, lr:0.0009
[01:21:36.281] iteration:1637  t-loss:0.3589, loss-lb:0.3223, loss-ulb:0.3047, weight:0.12, lr:0.0009
[01:21:36.596] iteration:1638  t-loss:0.2534, loss-lb:0.2252, loss-ulb:0.2348, weight:0.12, lr:0.0009
[01:21:36.912] iteration:1639  t-loss:0.3140, loss-lb:0.2277, loss-ulb:0.7182, weight:0.12, lr:0.0009
[01:21:37.231] iteration:1640  t-loss:0.4647, loss-lb:0.4189, loss-ulb:0.3815, weight:0.12, lr:0.0009
[01:21:37.551] iteration:1641  t-loss:0.2994, loss-lb:0.2521, loss-ulb:0.3935, weight:0.12, lr:0.0009
[01:21:37.864] iteration:1642  t-loss:0.4561, loss-lb:0.3979, loss-ulb:0.4852, weight:0.12, lr:0.0009
[01:21:38.178] iteration:1643  t-loss:0.4967, loss-lb:0.4591, loss-ulb:0.3126, weight:0.12, lr:0.0009
[01:21:38.491] iteration:1644  t-loss:0.4179, loss-lb:0.2852, loss-ulb:1.1054, weight:0.12, lr:0.0009
[01:21:38.804] iteration:1645  t-loss:0.3257, loss-lb:0.3068, loss-ulb:0.1569, weight:0.12, lr:0.0009
[01:21:39.116] iteration:1646  t-loss:0.3073, loss-lb:0.2861, loss-ulb:0.1767, weight:0.12, lr:0.0009
[01:21:39.432] iteration:1647  t-loss:0.3366, loss-lb:0.3316, loss-ulb:0.0414, weight:0.12, lr:0.0009
[01:21:39.746] iteration:1648  t-loss:0.7201, loss-lb:0.6867, loss-ulb:0.2775, weight:0.12, lr:0.0009
[01:21:40.060] iteration:1649  t-loss:0.4784, loss-lb:0.4642, loss-ulb:0.1187, weight:0.12, lr:0.0009
[01:21:40.375] iteration:1650  t-loss:0.2735, loss-lb:0.2453, loss-ulb:0.2343, weight:0.12, lr:0.0009
[01:21:41.647] iteration:1651  t-loss:0.3836, loss-lb:0.3296, loss-ulb:0.3737, weight:0.14, lr:0.0009
[01:21:41.976] iteration:1652  t-loss:0.3345, loss-lb:0.2812, loss-ulb:0.3693, weight:0.14, lr:0.0009
[01:21:42.299] iteration:1653  t-loss:0.2165, loss-lb:0.2054, loss-ulb:0.0772, weight:0.14, lr:0.0009
[01:21:42.618] iteration:1654  t-loss:0.1875, loss-lb:0.1619, loss-ulb:0.1771, weight:0.14, lr:0.0009
[01:21:42.942] iteration:1655  t-loss:0.2430, loss-lb:0.2187, loss-ulb:0.1685, weight:0.14, lr:0.0009
[01:21:43.256] iteration:1656  t-loss:1.0698, loss-lb:0.9502, loss-ulb:0.8280, weight:0.14, lr:0.0009
[01:21:43.578] iteration:1657  t-loss:0.3790, loss-lb:0.3306, loss-ulb:0.3352, weight:0.14, lr:0.0009
[01:21:43.895] iteration:1658  t-loss:0.3460, loss-lb:0.2624, loss-ulb:0.5788, weight:0.14, lr:0.0009
[01:21:44.211] iteration:1659  t-loss:0.5087, loss-lb:0.3832, loss-ulb:0.8687, weight:0.14, lr:0.0009
[01:21:44.529] iteration:1660  t-loss:0.4282, loss-lb:0.3727, loss-ulb:0.3840, weight:0.14, lr:0.0009
[01:21:44.849] iteration:1661  t-loss:0.2491, loss-lb:0.2178, loss-ulb:0.2167, weight:0.14, lr:0.0009
[01:21:45.168] iteration:1662  t-loss:0.3086, loss-lb:0.2368, loss-ulb:0.4975, weight:0.14, lr:0.0009
[01:21:45.484] iteration:1663  t-loss:0.3141, loss-lb:0.2941, loss-ulb:0.1388, weight:0.14, lr:0.0009
[01:21:45.802] iteration:1664  t-loss:0.3725, loss-lb:0.3388, loss-ulb:0.2333, weight:0.14, lr:0.0009
[01:21:46.127] iteration:1665  t-loss:0.5558, loss-lb:0.5240, loss-ulb:0.2201, weight:0.14, lr:0.0009
[01:21:46.454] iteration:1666  t-loss:0.5461, loss-lb:0.4575, loss-ulb:0.6133, weight:0.14, lr:0.0009
[01:21:46.780] iteration:1667  t-loss:0.4384, loss-lb:0.3911, loss-ulb:0.3280, weight:0.14, lr:0.0009
[01:21:47.099] iteration:1668  t-loss:0.3334, loss-lb:0.2792, loss-ulb:0.3758, weight:0.14, lr:0.0009
[01:21:47.417] iteration:1669  t-loss:0.3041, loss-lb:0.2511, loss-ulb:0.3665, weight:0.14, lr:0.0009
[01:21:47.737] iteration:1670  t-loss:0.5664, loss-lb:0.5267, loss-ulb:0.2748, weight:0.14, lr:0.0009
[01:21:48.054] iteration:1671  t-loss:0.3299, loss-lb:0.3188, loss-ulb:0.0770, weight:0.14, lr:0.0009
[01:21:48.375] iteration:1672  t-loss:0.3358, loss-lb:0.2914, loss-ulb:0.3077, weight:0.14, lr:0.0009
[01:21:48.689] iteration:1673  t-loss:0.3717, loss-lb:0.3233, loss-ulb:0.3346, weight:0.14, lr:0.0009
[01:21:49.006] iteration:1674  t-loss:0.3451, loss-lb:0.2776, loss-ulb:0.4671, weight:0.14, lr:0.0009
[01:21:49.322] iteration:1675  t-loss:0.2418, loss-lb:0.2134, loss-ulb:0.1970, weight:0.14, lr:0.0009
[01:21:50.844] iteration:1676  t-loss:0.7881, loss-lb:0.7477, loss-ulb:0.2793, weight:0.14, lr:0.0009
[01:21:51.190] iteration:1677  t-loss:0.3121, loss-lb:0.2692, loss-ulb:0.2969, weight:0.14, lr:0.0009
[01:21:51.518] iteration:1678  t-loss:0.5129, loss-lb:0.4943, loss-ulb:0.1284, weight:0.14, lr:0.0009
[01:21:51.844] iteration:1679  t-loss:0.2761, loss-lb:0.2545, loss-ulb:0.1498, weight:0.14, lr:0.0009
[01:21:52.162] iteration:1680  t-loss:0.3864, loss-lb:0.3395, loss-ulb:0.3248, weight:0.14, lr:0.0009
[01:21:52.482] iteration:1681  t-loss:0.2904, loss-lb:0.2852, loss-ulb:0.0359, weight:0.14, lr:0.0009
[01:21:52.807] iteration:1682  t-loss:0.4023, loss-lb:0.3627, loss-ulb:0.2740, weight:0.14, lr:0.0009
[01:21:53.121] iteration:1683  t-loss:0.5441, loss-lb:0.5346, loss-ulb:0.0663, weight:0.14, lr:0.0009
[01:21:53.443] iteration:1684  t-loss:0.3412, loss-lb:0.2722, loss-ulb:0.4778, weight:0.14, lr:0.0009
[01:21:53.768] iteration:1685  t-loss:0.6863, loss-lb:0.5920, loss-ulb:0.6530, weight:0.14, lr:0.0009
[01:21:54.085] iteration:1686  t-loss:0.5561, loss-lb:0.4958, loss-ulb:0.4176, weight:0.14, lr:0.0009
[01:21:54.403] iteration:1687  t-loss:0.3190, loss-lb:0.2974, loss-ulb:0.1499, weight:0.14, lr:0.0009
[01:21:54.719] iteration:1688  t-loss:0.2137, loss-lb:0.1802, loss-ulb:0.2316, weight:0.14, lr:0.0009
[01:21:55.038] iteration:1689  t-loss:0.3030, loss-lb:0.2398, loss-ulb:0.4382, weight:0.14, lr:0.0009
[01:21:55.368] iteration:1690  t-loss:0.5203, loss-lb:0.4648, loss-ulb:0.3848, weight:0.14, lr:0.0009
[01:21:55.700] iteration:1691  t-loss:0.3748, loss-lb:0.3502, loss-ulb:0.1703, weight:0.14, lr:0.0009
[01:21:56.020] iteration:1692  t-loss:0.3121, loss-lb:0.2638, loss-ulb:0.3345, weight:0.14, lr:0.0009
[01:21:56.345] iteration:1693  t-loss:0.2835, loss-lb:0.2650, loss-ulb:0.1277, weight:0.14, lr:0.0009
[01:21:56.660] iteration:1694  t-loss:0.3253, loss-lb:0.2649, loss-ulb:0.4180, weight:0.14, lr:0.0009
[01:21:56.979] iteration:1695  t-loss:0.5474, loss-lb:0.4996, loss-ulb:0.3312, weight:0.14, lr:0.0009
[01:21:57.295] iteration:1696  t-loss:0.6502, loss-lb:0.5919, loss-ulb:0.4040, weight:0.14, lr:0.0009
[01:21:57.609] iteration:1697  t-loss:0.9304, loss-lb:0.7674, loss-ulb:1.1288, weight:0.14, lr:0.0009
[01:21:57.935] iteration:1698  t-loss:0.4178, loss-lb:0.3629, loss-ulb:0.3802, weight:0.14, lr:0.0009
[01:21:58.259] iteration:1699  t-loss:0.2489, loss-lb:0.2093, loss-ulb:0.2742, weight:0.14, lr:0.0009
[01:21:58.574] iteration:1700  t-loss:0.4389, loss-lb:0.3589, loss-ulb:0.5533, weight:0.14, lr:0.0009
[01:22:00.381] iteration:1701  t-loss:0.2876, loss-lb:0.2398, loss-ulb:0.3311, weight:0.14, lr:0.0009
[01:22:00.728] iteration:1702  t-loss:0.3476, loss-lb:0.3111, loss-ulb:0.2529, weight:0.14, lr:0.0009
[01:22:01.105] iteration:1703  t-loss:0.3735, loss-lb:0.3269, loss-ulb:0.3230, weight:0.14, lr:0.0009
[01:22:01.476] iteration:1704  t-loss:0.3769, loss-lb:0.3150, loss-ulb:0.4288, weight:0.14, lr:0.0009
[01:22:01.850] iteration:1705  t-loss:0.3116, loss-lb:0.2983, loss-ulb:0.0921, weight:0.14, lr:0.0009
[01:22:02.174] iteration:1706  t-loss:0.3518, loss-lb:0.3445, loss-ulb:0.0506, weight:0.14, lr:0.0009
[01:22:02.496] iteration:1707  t-loss:0.2547, loss-lb:0.2032, loss-ulb:0.3562, weight:0.14, lr:0.0009
[01:22:02.820] iteration:1708  t-loss:0.2916, loss-lb:0.2570, loss-ulb:0.2394, weight:0.14, lr:0.0009
[01:22:03.144] iteration:1709  t-loss:0.3615, loss-lb:0.3218, loss-ulb:0.2747, weight:0.14, lr:0.0009
[01:22:03.467] iteration:1710  t-loss:0.3708, loss-lb:0.3354, loss-ulb:0.2451, weight:0.14, lr:0.0009
[01:22:03.783] iteration:1711  t-loss:0.3239, loss-lb:0.2211, loss-ulb:0.7115, weight:0.14, lr:0.0009
[01:22:04.104] iteration:1712  t-loss:0.3280, loss-lb:0.2613, loss-ulb:0.4616, weight:0.14, lr:0.0009
[01:22:04.423] iteration:1713  t-loss:0.2310, loss-lb:0.1989, loss-ulb:0.2217, weight:0.14, lr:0.0009
[01:22:04.751] iteration:1714  t-loss:0.3588, loss-lb:0.3366, loss-ulb:0.1537, weight:0.14, lr:0.0009
[01:22:05.086] iteration:1715  t-loss:0.3836, loss-lb:0.3285, loss-ulb:0.3814, weight:0.14, lr:0.0009
[01:22:05.411] iteration:1716  t-loss:0.3109, loss-lb:0.2647, loss-ulb:0.3202, weight:0.14, lr:0.0009
[01:22:05.744] iteration:1717  t-loss:0.5460, loss-lb:0.5251, loss-ulb:0.1449, weight:0.14, lr:0.0009
[01:22:06.066] iteration:1718  t-loss:0.3496, loss-lb:0.3456, loss-ulb:0.0279, weight:0.14, lr:0.0009
[01:22:06.380] iteration:1719  t-loss:0.2048, loss-lb:0.1703, loss-ulb:0.2388, weight:0.14, lr:0.0009
[01:22:06.693] iteration:1720  t-loss:0.3891, loss-lb:0.3026, loss-ulb:0.5992, weight:0.14, lr:0.0009
[01:22:07.004] iteration:1721  t-loss:0.4342, loss-lb:0.3158, loss-ulb:0.8200, weight:0.14, lr:0.0009
[01:22:07.316] iteration:1722  t-loss:0.3105, loss-lb:0.2877, loss-ulb:0.1579, weight:0.14, lr:0.0009
[01:22:07.628] iteration:1723  t-loss:0.3637, loss-lb:0.2955, loss-ulb:0.4719, weight:0.14, lr:0.0009
[01:22:07.944] iteration:1724  t-loss:0.3934, loss-lb:0.3108, loss-ulb:0.5723, weight:0.14, lr:0.0009
[01:22:08.257] iteration:1725  t-loss:0.4825, loss-lb:0.4681, loss-ulb:0.0996, weight:0.14, lr:0.0009
[01:24:19.202] iteration 1725 : dice_score: 0.768771 best_dice: 0.776200
[01:24:19.203]  <<Test>> - Ep:68  - Dice-S/T:72.96/76.88, Best-S:77.36, Best-T:77.62
[01:24:19.203]           - AvgLoss(lb/ulb/all):0.30/0.33/0.35
[01:24:20.408] iteration:1726  t-loss:0.4013, loss-lb:0.3297, loss-ulb:0.4960, weight:0.14, lr:0.0009
[01:24:20.753] iteration:1727  t-loss:0.3111, loss-lb:0.2840, loss-ulb:0.1876, weight:0.14, lr:0.0009
[01:24:21.083] iteration:1728  t-loss:0.3235, loss-lb:0.2118, loss-ulb:0.7732, weight:0.14, lr:0.0009
[01:24:21.407] iteration:1729  t-loss:0.4788, loss-lb:0.4591, loss-ulb:0.1360, weight:0.14, lr:0.0009
[01:24:21.725] iteration:1730  t-loss:0.3359, loss-lb:0.2603, loss-ulb:0.5229, weight:0.14, lr:0.0009
[01:24:22.044] iteration:1731  t-loss:0.5337, loss-lb:0.5247, loss-ulb:0.0620, weight:0.14, lr:0.0009
[01:24:22.368] iteration:1732  t-loss:0.5496, loss-lb:0.4625, loss-ulb:0.6030, weight:0.14, lr:0.0009
[01:24:22.691] iteration:1733  t-loss:0.3779, loss-lb:0.2653, loss-ulb:0.7796, weight:0.14, lr:0.0009
[01:24:23.010] iteration:1734  t-loss:0.2915, loss-lb:0.2608, loss-ulb:0.2126, weight:0.14, lr:0.0009
[01:24:23.332] iteration:1735  t-loss:0.3294, loss-lb:0.2797, loss-ulb:0.3441, weight:0.14, lr:0.0009
[01:24:23.660] iteration:1736  t-loss:0.3038, loss-lb:0.2775, loss-ulb:0.1825, weight:0.14, lr:0.0009
[01:24:23.984] iteration:1737  t-loss:0.4615, loss-lb:0.3694, loss-ulb:0.6376, weight:0.14, lr:0.0009
[01:24:24.311] iteration:1738  t-loss:0.3437, loss-lb:0.3190, loss-ulb:0.1705, weight:0.14, lr:0.0009
[01:24:24.636] iteration:1739  t-loss:0.4381, loss-lb:0.3950, loss-ulb:0.2983, weight:0.14, lr:0.0009
[01:24:24.952] iteration:1740  t-loss:0.2642, loss-lb:0.2384, loss-ulb:0.1788, weight:0.14, lr:0.0009
[01:24:25.272] iteration:1741  t-loss:0.2683, loss-lb:0.2386, loss-ulb:0.2054, weight:0.14, lr:0.0009
[01:24:25.591] iteration:1742  t-loss:0.5123, loss-lb:0.4429, loss-ulb:0.4807, weight:0.14, lr:0.0009
[01:24:25.908] iteration:1743  t-loss:0.5528, loss-lb:0.5237, loss-ulb:0.2016, weight:0.14, lr:0.0009
[01:24:26.225] iteration:1744  t-loss:0.5496, loss-lb:0.4113, loss-ulb:0.9582, weight:0.14, lr:0.0009
[01:24:26.541] iteration:1745  t-loss:0.2370, loss-lb:0.2192, loss-ulb:0.1237, weight:0.14, lr:0.0009
[01:24:26.854] iteration:1746  t-loss:0.3143, loss-lb:0.2665, loss-ulb:0.3310, weight:0.14, lr:0.0009
[01:24:27.171] iteration:1747  t-loss:0.2890, loss-lb:0.2180, loss-ulb:0.4917, weight:0.14, lr:0.0009
[01:24:27.486] iteration:1748  t-loss:0.6157, loss-lb:0.5966, loss-ulb:0.1326, weight:0.14, lr:0.0009
[01:24:27.799] iteration:1749  t-loss:0.3855, loss-lb:0.3550, loss-ulb:0.2117, weight:0.14, lr:0.0009
[01:24:28.111] iteration:1750  t-loss:0.3157, loss-lb:0.2994, loss-ulb:0.1131, weight:0.14, lr:0.0009
[01:24:29.641] iteration:1751  t-loss:0.4658, loss-lb:0.4044, loss-ulb:0.4256, weight:0.14, lr:0.0009
[01:24:29.978] iteration:1752  t-loss:0.3025, loss-lb:0.2204, loss-ulb:0.5680, weight:0.14, lr:0.0009
[01:24:30.300] iteration:1753  t-loss:0.4477, loss-lb:0.3817, loss-ulb:0.4566, weight:0.14, lr:0.0009
[01:24:30.631] iteration:1754  t-loss:0.5076, loss-lb:0.4445, loss-ulb:0.4370, weight:0.14, lr:0.0009
[01:24:30.956] iteration:1755  t-loss:0.5116, loss-lb:0.4769, loss-ulb:0.2398, weight:0.14, lr:0.0009
[01:24:31.274] iteration:1756  t-loss:0.4036, loss-lb:0.3212, loss-ulb:0.5708, weight:0.14, lr:0.0009
[01:24:31.595] iteration:1757  t-loss:0.3133, loss-lb:0.2345, loss-ulb:0.5459, weight:0.14, lr:0.0009
[01:24:31.921] iteration:1758  t-loss:0.2286, loss-lb:0.2166, loss-ulb:0.0833, weight:0.14, lr:0.0009
[01:24:32.235] iteration:1759  t-loss:0.3700, loss-lb:0.3102, loss-ulb:0.4140, weight:0.14, lr:0.0009
[01:24:32.557] iteration:1760  t-loss:0.4014, loss-lb:0.3764, loss-ulb:0.1730, weight:0.14, lr:0.0009
[01:24:32.870] iteration:1761  t-loss:0.1924, loss-lb:0.1640, loss-ulb:0.1961, weight:0.14, lr:0.0009
[01:24:33.187] iteration:1762  t-loss:0.4487, loss-lb:0.3941, loss-ulb:0.3775, weight:0.14, lr:0.0009
[01:24:33.507] iteration:1763  t-loss:0.3765, loss-lb:0.3037, loss-ulb:0.5042, weight:0.14, lr:0.0009
[01:24:33.830] iteration:1764  t-loss:0.5224, loss-lb:0.3979, loss-ulb:0.8618, weight:0.14, lr:0.0009
[01:24:34.146] iteration:1765  t-loss:0.2684, loss-lb:0.1960, loss-ulb:0.5014, weight:0.14, lr:0.0009
[01:24:34.462] iteration:1766  t-loss:0.2573, loss-lb:0.1863, loss-ulb:0.4913, weight:0.14, lr:0.0009
[01:24:34.774] iteration:1767  t-loss:0.4579, loss-lb:0.3877, loss-ulb:0.4861, weight:0.14, lr:0.0009
[01:24:35.088] iteration:1768  t-loss:0.4924, loss-lb:0.4725, loss-ulb:0.1377, weight:0.14, lr:0.0009
[01:24:35.400] iteration:1769  t-loss:0.3611, loss-lb:0.2737, loss-ulb:0.6052, weight:0.14, lr:0.0009
[01:24:35.711] iteration:1770  t-loss:0.3005, loss-lb:0.2646, loss-ulb:0.2488, weight:0.14, lr:0.0009
[01:24:36.025] iteration:1771  t-loss:0.5005, loss-lb:0.4205, loss-ulb:0.5536, weight:0.14, lr:0.0009
[01:24:36.341] iteration:1772  t-loss:0.4172, loss-lb:0.3742, loss-ulb:0.2975, weight:0.14, lr:0.0009
[01:24:36.653] iteration:1773  t-loss:0.2369, loss-lb:0.2233, loss-ulb:0.0937, weight:0.14, lr:0.0009
[01:24:36.971] iteration:1774  t-loss:0.2326, loss-lb:0.2038, loss-ulb:0.1995, weight:0.14, lr:0.0009
[01:24:37.286] iteration:1775  t-loss:0.4298, loss-lb:0.4012, loss-ulb:0.1978, weight:0.14, lr:0.0009
[01:24:38.616] iteration:1776  t-loss:0.5920, loss-lb:0.5651, loss-ulb:0.1862, weight:0.14, lr:0.0009
[01:24:38.958] iteration:1777  t-loss:0.3053, loss-lb:0.2881, loss-ulb:0.1188, weight:0.14, lr:0.0009
[01:24:39.294] iteration:1778  t-loss:0.3214, loss-lb:0.2436, loss-ulb:0.5385, weight:0.14, lr:0.0009
[01:24:39.627] iteration:1779  t-loss:0.3963, loss-lb:0.3570, loss-ulb:0.2723, weight:0.14, lr:0.0009
[01:24:39.947] iteration:1780  t-loss:0.3816, loss-lb:0.3477, loss-ulb:0.2349, weight:0.14, lr:0.0009
[01:24:40.274] iteration:1781  t-loss:0.5146, loss-lb:0.4432, loss-ulb:0.4943, weight:0.14, lr:0.0009
[01:24:40.592] iteration:1782  t-loss:0.2820, loss-lb:0.2607, loss-ulb:0.1470, weight:0.14, lr:0.0009
[01:24:40.918] iteration:1783  t-loss:0.5199, loss-lb:0.4546, loss-ulb:0.4522, weight:0.14, lr:0.0009
[01:24:41.237] iteration:1784  t-loss:0.4684, loss-lb:0.4606, loss-ulb:0.0536, weight:0.14, lr:0.0009
[01:24:41.567] iteration:1785  t-loss:0.3380, loss-lb:0.2453, loss-ulb:0.6420, weight:0.14, lr:0.0009
[01:24:41.890] iteration:1786  t-loss:0.2621, loss-lb:0.2006, loss-ulb:0.4262, weight:0.14, lr:0.0009
[01:24:42.216] iteration:1787  t-loss:0.5401, loss-lb:0.4680, loss-ulb:0.4993, weight:0.14, lr:0.0009
[01:24:42.539] iteration:1788  t-loss:0.3131, loss-lb:0.2851, loss-ulb:0.1937, weight:0.14, lr:0.0009
[01:24:42.867] iteration:1789  t-loss:0.4597, loss-lb:0.3859, loss-ulb:0.5106, weight:0.14, lr:0.0009
[01:24:43.186] iteration:1790  t-loss:0.2391, loss-lb:0.2219, loss-ulb:0.1190, weight:0.14, lr:0.0009
[01:24:43.502] iteration:1791  t-loss:0.3103, loss-lb:0.2827, loss-ulb:0.1913, weight:0.14, lr:0.0009
[01:24:43.815] iteration:1792  t-loss:0.2860, loss-lb:0.2571, loss-ulb:0.2002, weight:0.14, lr:0.0009
[01:24:44.129] iteration:1793  t-loss:0.2726, loss-lb:0.2155, loss-ulb:0.3955, weight:0.14, lr:0.0009
[01:24:44.443] iteration:1794  t-loss:0.4071, loss-lb:0.3961, loss-ulb:0.0759, weight:0.14, lr:0.0009
[01:24:44.757] iteration:1795  t-loss:0.2953, loss-lb:0.1709, loss-ulb:0.8617, weight:0.14, lr:0.0009
[01:24:45.070] iteration:1796  t-loss:0.2917, loss-lb:0.2541, loss-ulb:0.2600, weight:0.14, lr:0.0009
[01:24:45.383] iteration:1797  t-loss:0.3131, loss-lb:0.2404, loss-ulb:0.5035, weight:0.14, lr:0.0009
[01:24:45.705] iteration:1798  t-loss:0.2923, loss-lb:0.2690, loss-ulb:0.1614, weight:0.14, lr:0.0009
[01:24:46.026] iteration:1799  t-loss:0.3708, loss-lb:0.3349, loss-ulb:0.2479, weight:0.14, lr:0.0009
[01:24:46.344] iteration:1800  t-loss:0.8299, loss-lb:0.7874, loss-ulb:0.2942, weight:0.14, lr:0.0009
[01:24:47.944] iteration:1801  t-loss:0.5332, loss-lb:0.4314, loss-ulb:0.5902, weight:0.17, lr:0.0009
[01:24:48.299] iteration:1802  t-loss:0.4250, loss-lb:0.4123, loss-ulb:0.0736, weight:0.17, lr:0.0009
[01:24:48.650] iteration:1803  t-loss:0.5768, loss-lb:0.5032, loss-ulb:0.4263, weight:0.17, lr:0.0009
[01:24:49.010] iteration:1804  t-loss:0.2845, loss-lb:0.2250, loss-ulb:0.3451, weight:0.17, lr:0.0009
[01:24:49.380] iteration:1805  t-loss:0.7239, loss-lb:0.7038, loss-ulb:0.1162, weight:0.17, lr:0.0009
[01:24:49.729] iteration:1806  t-loss:0.3284, loss-lb:0.2736, loss-ulb:0.3171, weight:0.17, lr:0.0009
[01:24:50.097] iteration:1807  t-loss:0.6178, loss-lb:0.6028, loss-ulb:0.0869, weight:0.17, lr:0.0009
[01:24:50.462] iteration:1808  t-loss:0.5693, loss-lb:0.5134, loss-ulb:0.3237, weight:0.17, lr:0.0009
[01:24:50.819] iteration:1809  t-loss:0.3743, loss-lb:0.3464, loss-ulb:0.1618, weight:0.17, lr:0.0009
[01:24:51.186] iteration:1810  t-loss:0.5531, loss-lb:0.4511, loss-ulb:0.5912, weight:0.17, lr:0.0009
[01:24:51.553] iteration:1811  t-loss:0.3590, loss-lb:0.2302, loss-ulb:0.7459, weight:0.17, lr:0.0009
[01:24:51.944] iteration:1812  t-loss:0.7116, loss-lb:0.6782, loss-ulb:0.1934, weight:0.17, lr:0.0009
[01:24:52.300] iteration:1813  t-loss:0.3096, loss-lb:0.2682, loss-ulb:0.2398, weight:0.17, lr:0.0009
[01:24:52.648] iteration:1814  t-loss:0.3155, loss-lb:0.2899, loss-ulb:0.1482, weight:0.17, lr:0.0009
[01:24:52.994] iteration:1815  t-loss:0.3725, loss-lb:0.2993, loss-ulb:0.4244, weight:0.17, lr:0.0009
[01:24:53.336] iteration:1816  t-loss:0.2615, loss-lb:0.2258, loss-ulb:0.2069, weight:0.17, lr:0.0009
[01:24:53.655] iteration:1817  t-loss:0.3049, loss-lb:0.2473, loss-ulb:0.3332, weight:0.17, lr:0.0009
[01:24:53.983] iteration:1818  t-loss:0.4884, loss-lb:0.3695, loss-ulb:0.6887, weight:0.17, lr:0.0009
[01:24:54.298] iteration:1819  t-loss:0.2395, loss-lb:0.1934, loss-ulb:0.2667, weight:0.17, lr:0.0009
[01:24:54.608] iteration:1820  t-loss:0.4345, loss-lb:0.3059, loss-ulb:0.7455, weight:0.17, lr:0.0009
[01:24:54.923] iteration:1821  t-loss:0.4906, loss-lb:0.4379, loss-ulb:0.3053, weight:0.17, lr:0.0009
[01:24:55.235] iteration:1822  t-loss:0.5006, loss-lb:0.3408, loss-ulb:0.9256, weight:0.17, lr:0.0009
[01:24:55.549] iteration:1823  t-loss:0.3288, loss-lb:0.2095, loss-ulb:0.6915, weight:0.17, lr:0.0009
[01:24:55.862] iteration:1824  t-loss:0.4328, loss-lb:0.4048, loss-ulb:0.1620, weight:0.17, lr:0.0009
[01:24:56.175] iteration:1825  t-loss:0.4457, loss-lb:0.4155, loss-ulb:0.1752, weight:0.17, lr:0.0009
[01:27:07.323] iteration 1825 : dice_score: 0.772857 best_dice: 0.776200
[01:27:07.323]  <<Test>> - Ep:72  - Dice-S/T:76.15/77.29, Best-S:77.36, Best-T:77.62
[01:27:07.323]           - AvgLoss(lb/ulb/all):0.38/0.39/0.42
[01:27:08.764] iteration:1826  t-loss:0.4615, loss-lb:0.4404, loss-ulb:0.1224, weight:0.17, lr:0.0009
[01:27:09.123] iteration:1827  t-loss:0.4346, loss-lb:0.3225, loss-ulb:0.6496, weight:0.17, lr:0.0009
[01:27:09.469] iteration:1828  t-loss:0.3188, loss-lb:0.2882, loss-ulb:0.1773, weight:0.17, lr:0.0009
[01:27:09.798] iteration:1829  t-loss:0.3574, loss-lb:0.2373, loss-ulb:0.6958, weight:0.17, lr:0.0009
[01:27:10.134] iteration:1830  t-loss:0.3524, loss-lb:0.3364, loss-ulb:0.0927, weight:0.17, lr:0.0009
[01:27:10.463] iteration:1831  t-loss:0.3199, loss-lb:0.2978, loss-ulb:0.1278, weight:0.17, lr:0.0009
[01:27:10.784] iteration:1832  t-loss:0.3384, loss-lb:0.3171, loss-ulb:0.1238, weight:0.17, lr:0.0009
[01:27:11.102] iteration:1833  t-loss:0.2681, loss-lb:0.2626, loss-ulb:0.0318, weight:0.17, lr:0.0009
[01:27:11.425] iteration:1834  t-loss:0.3049, loss-lb:0.2314, loss-ulb:0.4262, weight:0.17, lr:0.0009
[01:27:11.742] iteration:1835  t-loss:0.4063, loss-lb:0.3700, loss-ulb:0.2108, weight:0.17, lr:0.0009
[01:27:12.056] iteration:1836  t-loss:0.2026, loss-lb:0.1593, loss-ulb:0.2504, weight:0.17, lr:0.0009
[01:27:12.370] iteration:1837  t-loss:0.5229, loss-lb:0.4912, loss-ulb:0.1834, weight:0.17, lr:0.0009
[01:27:12.690] iteration:1838  t-loss:0.3051, loss-lb:0.2219, loss-ulb:0.4820, weight:0.17, lr:0.0009
[01:27:13.004] iteration:1839  t-loss:0.3428, loss-lb:0.3303, loss-ulb:0.0725, weight:0.17, lr:0.0009
[01:27:13.316] iteration:1840  t-loss:0.3765, loss-lb:0.2383, loss-ulb:0.8008, weight:0.17, lr:0.0009
[01:27:13.636] iteration:1841  t-loss:0.6095, loss-lb:0.5424, loss-ulb:0.3889, weight:0.17, lr:0.0009
[01:27:13.947] iteration:1842  t-loss:0.2945, loss-lb:0.2282, loss-ulb:0.3840, weight:0.17, lr:0.0009
[01:27:14.256] iteration:1843  t-loss:0.5161, loss-lb:0.3297, loss-ulb:1.0802, weight:0.17, lr:0.0009
[01:27:14.566] iteration:1844  t-loss:0.3324, loss-lb:0.2809, loss-ulb:0.2981, weight:0.17, lr:0.0009
[01:27:14.878] iteration:1845  t-loss:0.3404, loss-lb:0.3128, loss-ulb:0.1597, weight:0.17, lr:0.0009
[01:27:15.190] iteration:1846  t-loss:0.3129, loss-lb:0.2456, loss-ulb:0.3897, weight:0.17, lr:0.0009
[01:27:15.504] iteration:1847  t-loss:0.3395, loss-lb:0.3295, loss-ulb:0.0581, weight:0.17, lr:0.0009
[01:27:15.816] iteration:1848  t-loss:0.2664, loss-lb:0.2523, loss-ulb:0.0815, weight:0.17, lr:0.0009
[01:27:16.133] iteration:1849  t-loss:0.4306, loss-lb:0.3844, loss-ulb:0.2675, weight:0.17, lr:0.0009
[01:27:16.448] iteration:1850  t-loss:0.3654, loss-lb:0.3214, loss-ulb:0.2548, weight:0.17, lr:0.0009
[01:27:17.881] iteration:1851  t-loss:0.5130, loss-lb:0.4730, loss-ulb:0.2320, weight:0.17, lr:0.0009
[01:27:18.222] iteration:1852  t-loss:0.3106, loss-lb:0.2563, loss-ulb:0.3146, weight:0.17, lr:0.0009
[01:27:18.555] iteration:1853  t-loss:0.4877, loss-lb:0.4224, loss-ulb:0.3780, weight:0.17, lr:0.0009
[01:27:18.887] iteration:1854  t-loss:0.3435, loss-lb:0.3060, loss-ulb:0.2174, weight:0.17, lr:0.0009
[01:27:19.206] iteration:1855  t-loss:0.3580, loss-lb:0.3341, loss-ulb:0.1389, weight:0.17, lr:0.0009
[01:27:19.539] iteration:1856  t-loss:0.2871, loss-lb:0.2554, loss-ulb:0.1838, weight:0.17, lr:0.0009
[01:27:19.860] iteration:1857  t-loss:0.2678, loss-lb:0.2519, loss-ulb:0.0924, weight:0.17, lr:0.0009
[01:27:20.177] iteration:1858  t-loss:0.2702, loss-lb:0.2275, loss-ulb:0.2473, weight:0.17, lr:0.0009
[01:27:20.523] iteration:1859  t-loss:0.5465, loss-lb:0.4504, loss-ulb:0.5566, weight:0.17, lr:0.0009
[01:27:20.839] iteration:1860  t-loss:0.2722, loss-lb:0.2247, loss-ulb:0.2752, weight:0.17, lr:0.0009
[01:27:21.163] iteration:1861  t-loss:0.3882, loss-lb:0.3495, loss-ulb:0.2244, weight:0.17, lr:0.0009
[01:27:21.487] iteration:1862  t-loss:0.4174, loss-lb:0.3683, loss-ulb:0.2849, weight:0.17, lr:0.0009
[01:27:21.812] iteration:1863  t-loss:0.2749, loss-lb:0.2555, loss-ulb:0.1122, weight:0.17, lr:0.0009
[01:27:22.140] iteration:1864  t-loss:0.4223, loss-lb:0.3880, loss-ulb:0.1985, weight:0.17, lr:0.0009
[01:27:22.465] iteration:1865  t-loss:0.3053, loss-lb:0.2829, loss-ulb:0.1300, weight:0.17, lr:0.0009
[01:27:22.791] iteration:1866  t-loss:0.3028, loss-lb:0.2854, loss-ulb:0.1008, weight:0.17, lr:0.0009
[01:27:23.113] iteration:1867  t-loss:0.2997, loss-lb:0.2582, loss-ulb:0.2407, weight:0.17, lr:0.0009
[01:27:23.442] iteration:1868  t-loss:0.3315, loss-lb:0.2788, loss-ulb:0.3053, weight:0.17, lr:0.0009
[01:27:23.758] iteration:1869  t-loss:0.5631, loss-lb:0.4424, loss-ulb:0.6990, weight:0.17, lr:0.0009
[01:27:24.075] iteration:1870  t-loss:0.2351, loss-lb:0.2078, loss-ulb:0.1582, weight:0.17, lr:0.0009
[01:27:24.393] iteration:1871  t-loss:0.4256, loss-lb:0.3758, loss-ulb:0.2883, weight:0.17, lr:0.0009
[01:27:24.705] iteration:1872  t-loss:0.4608, loss-lb:0.3406, loss-ulb:0.6962, weight:0.17, lr:0.0009
[01:27:25.017] iteration:1873  t-loss:0.3959, loss-lb:0.3732, loss-ulb:0.1315, weight:0.17, lr:0.0009
[01:27:25.333] iteration:1874  t-loss:0.3399, loss-lb:0.3252, loss-ulb:0.0849, weight:0.17, lr:0.0009
[01:27:25.644] iteration:1875  t-loss:0.7830, loss-lb:0.6281, loss-ulb:0.8978, weight:0.17, lr:0.0009
[01:27:27.203] iteration:1876  t-loss:0.5035, loss-lb:0.3872, loss-ulb:0.6737, weight:0.17, lr:0.0009
[01:27:27.539] iteration:1877  t-loss:0.3988, loss-lb:0.2928, loss-ulb:0.6144, weight:0.17, lr:0.0009
[01:27:27.877] iteration:1878  t-loss:0.5486, loss-lb:0.5168, loss-ulb:0.1845, weight:0.17, lr:0.0009
[01:27:28.195] iteration:1879  t-loss:0.2410, loss-lb:0.2236, loss-ulb:0.1009, weight:0.17, lr:0.0009
[01:27:28.516] iteration:1880  t-loss:0.4726, loss-lb:0.3789, loss-ulb:0.5429, weight:0.17, lr:0.0009
[01:27:28.849] iteration:1881  t-loss:0.5907, loss-lb:0.5342, loss-ulb:0.3274, weight:0.17, lr:0.0009
[01:27:29.170] iteration:1882  t-loss:0.3904, loss-lb:0.2472, loss-ulb:0.8297, weight:0.17, lr:0.0009
[01:27:29.488] iteration:1883  t-loss:0.3909, loss-lb:0.3221, loss-ulb:0.3985, weight:0.17, lr:0.0009
[01:27:29.801] iteration:1884  t-loss:0.3283, loss-lb:0.2135, loss-ulb:0.6651, weight:0.17, lr:0.0009
[01:27:30.126] iteration:1885  t-loss:0.5669, loss-lb:0.4967, loss-ulb:0.4069, weight:0.17, lr:0.0009
[01:27:30.445] iteration:1886  t-loss:0.3867, loss-lb:0.2625, loss-ulb:0.7197, weight:0.17, lr:0.0009
[01:27:30.766] iteration:1887  t-loss:0.2904, loss-lb:0.2629, loss-ulb:0.1597, weight:0.17, lr:0.0009
[01:27:31.089] iteration:1888  t-loss:0.5787, loss-lb:0.5430, loss-ulb:0.2066, weight:0.17, lr:0.0009
[01:27:31.412] iteration:1889  t-loss:0.2880, loss-lb:0.2636, loss-ulb:0.1409, weight:0.17, lr:0.0009
[01:27:31.736] iteration:1890  t-loss:0.5362, loss-lb:0.4886, loss-ulb:0.2760, weight:0.17, lr:0.0009
[01:27:32.052] iteration:1891  t-loss:0.3080, loss-lb:0.2582, loss-ulb:0.2884, weight:0.17, lr:0.0009
[01:27:32.369] iteration:1892  t-loss:0.4750, loss-lb:0.3377, loss-ulb:0.7954, weight:0.17, lr:0.0009
[01:27:32.684] iteration:1893  t-loss:0.6180, loss-lb:0.4456, loss-ulb:0.9989, weight:0.17, lr:0.0009
[01:27:32.998] iteration:1894  t-loss:0.2420, loss-lb:0.1917, loss-ulb:0.2914, weight:0.17, lr:0.0009
[01:27:33.313] iteration:1895  t-loss:0.4818, loss-lb:0.3989, loss-ulb:0.4807, weight:0.17, lr:0.0009
[01:27:33.629] iteration:1896  t-loss:0.4084, loss-lb:0.3709, loss-ulb:0.2172, weight:0.17, lr:0.0009
[01:27:33.945] iteration:1897  t-loss:0.3317, loss-lb:0.2784, loss-ulb:0.3090, weight:0.17, lr:0.0009
[01:27:34.259] iteration:1898  t-loss:0.2581, loss-lb:0.2193, loss-ulb:0.2251, weight:0.17, lr:0.0009
[01:27:34.577] iteration:1899  t-loss:0.4470, loss-lb:0.3762, loss-ulb:0.4103, weight:0.17, lr:0.0009
[01:27:34.901] iteration:1900  t-loss:0.3754, loss-lb:0.3402, loss-ulb:0.2038, weight:0.17, lr:0.0009
[01:27:36.433] iteration:1901  t-loss:0.2516, loss-lb:0.2235, loss-ulb:0.1630, weight:0.17, lr:0.0009
[01:27:36.787] iteration:1902  t-loss:0.7427, loss-lb:0.7218, loss-ulb:0.1214, weight:0.17, lr:0.0009
[01:27:37.119] iteration:1903  t-loss:0.2260, loss-lb:0.1976, loss-ulb:0.1646, weight:0.17, lr:0.0009
[01:27:37.447] iteration:1904  t-loss:0.4418, loss-lb:0.3061, loss-ulb:0.7860, weight:0.17, lr:0.0009
[01:27:37.767] iteration:1905  t-loss:0.4087, loss-lb:0.3080, loss-ulb:0.5840, weight:0.17, lr:0.0009
[01:27:38.088] iteration:1906  t-loss:0.4583, loss-lb:0.4276, loss-ulb:0.1777, weight:0.17, lr:0.0009
[01:27:38.408] iteration:1907  t-loss:0.3008, loss-lb:0.2117, loss-ulb:0.5163, weight:0.17, lr:0.0009
[01:27:38.733] iteration:1908  t-loss:0.2581, loss-lb:0.2409, loss-ulb:0.0996, weight:0.17, lr:0.0009
[01:27:39.060] iteration:1909  t-loss:0.4241, loss-lb:0.2941, loss-ulb:0.7531, weight:0.17, lr:0.0009
[01:27:39.380] iteration:1910  t-loss:0.3075, loss-lb:0.2219, loss-ulb:0.4957, weight:0.17, lr:0.0009
[01:27:39.698] iteration:1911  t-loss:0.2833, loss-lb:0.2497, loss-ulb:0.1948, weight:0.17, lr:0.0009
[01:27:40.033] iteration:1912  t-loss:0.3995, loss-lb:0.3562, loss-ulb:0.2506, weight:0.17, lr:0.0009
[01:27:40.360] iteration:1913  t-loss:0.3591, loss-lb:0.3307, loss-ulb:0.1646, weight:0.17, lr:0.0009
[01:27:40.685] iteration:1914  t-loss:0.5680, loss-lb:0.4299, loss-ulb:0.8005, weight:0.17, lr:0.0009
[01:27:41.003] iteration:1915  t-loss:0.3292, loss-lb:0.2346, loss-ulb:0.5485, weight:0.17, lr:0.0009
[01:27:41.333] iteration:1916  t-loss:0.5138, loss-lb:0.4657, loss-ulb:0.2791, weight:0.17, lr:0.0009
[01:27:41.661] iteration:1917  t-loss:0.6726, loss-lb:0.6548, loss-ulb:0.1029, weight:0.17, lr:0.0009
[01:27:41.988] iteration:1918  t-loss:0.5029, loss-lb:0.3602, loss-ulb:0.8270, weight:0.17, lr:0.0009
[01:27:42.301] iteration:1919  t-loss:0.3257, loss-lb:0.2683, loss-ulb:0.3322, weight:0.17, lr:0.0009
[01:27:42.614] iteration:1920  t-loss:0.2408, loss-lb:0.2002, loss-ulb:0.2353, weight:0.17, lr:0.0009
[01:27:42.933] iteration:1921  t-loss:0.4142, loss-lb:0.3960, loss-ulb:0.1054, weight:0.17, lr:0.0009
[01:27:43.249] iteration:1922  t-loss:0.2762, loss-lb:0.2534, loss-ulb:0.1319, weight:0.17, lr:0.0009
[01:27:43.566] iteration:1923  t-loss:0.5529, loss-lb:0.5305, loss-ulb:0.1296, weight:0.17, lr:0.0009
[01:27:43.881] iteration:1924  t-loss:0.5702, loss-lb:0.4503, loss-ulb:0.6946, weight:0.17, lr:0.0009
[01:27:44.196] iteration:1925  t-loss:0.3723, loss-lb:0.2858, loss-ulb:0.5011, weight:0.17, lr:0.0009
[01:29:53.687] iteration 1925 : dice_score: 0.777640 best_dice: 0.777600
[01:29:53.688]  <<Test>> - Ep:76  - Dice-S/T:74.95/77.76, Best-S:77.36, Best-T:77.76
[01:29:53.688]           - AvgLoss(lb/ulb/all):0.34/0.37/0.41
[01:29:54.971] iteration:1926  t-loss:0.4674, loss-lb:0.4037, loss-ulb:0.3691, weight:0.17, lr:0.0009
[01:29:55.300] iteration:1927  t-loss:0.3570, loss-lb:0.3236, loss-ulb:0.1936, weight:0.17, lr:0.0009
[01:29:55.620] iteration:1928  t-loss:0.4354, loss-lb:0.3128, loss-ulb:0.7105, weight:0.17, lr:0.0009
[01:29:55.953] iteration:1929  t-loss:0.3712, loss-lb:0.2772, loss-ulb:0.5451, weight:0.17, lr:0.0009
[01:29:56.267] iteration:1930  t-loss:0.3753, loss-lb:0.2141, loss-ulb:0.9337, weight:0.17, lr:0.0009
[01:29:56.582] iteration:1931  t-loss:0.3438, loss-lb:0.2616, loss-ulb:0.4763, weight:0.17, lr:0.0009
[01:29:56.898] iteration:1932  t-loss:0.2345, loss-lb:0.2029, loss-ulb:0.1830, weight:0.17, lr:0.0009
[01:29:57.218] iteration:1933  t-loss:0.5834, loss-lb:0.5502, loss-ulb:0.1922, weight:0.17, lr:0.0009
[01:29:57.534] iteration:1934  t-loss:0.8469, loss-lb:0.7615, loss-ulb:0.4949, weight:0.17, lr:0.0009
[01:29:57.852] iteration:1935  t-loss:0.3228, loss-lb:0.2933, loss-ulb:0.1706, weight:0.17, lr:0.0009
[01:29:58.164] iteration:1936  t-loss:0.4414, loss-lb:0.3837, loss-ulb:0.3340, weight:0.17, lr:0.0009
[01:29:58.477] iteration:1937  t-loss:0.3283, loss-lb:0.2776, loss-ulb:0.2938, weight:0.17, lr:0.0009
[01:29:58.798] iteration:1938  t-loss:0.5178, loss-lb:0.4924, loss-ulb:0.1475, weight:0.17, lr:0.0009
[01:29:59.114] iteration:1939  t-loss:0.5439, loss-lb:0.4110, loss-ulb:0.7702, weight:0.17, lr:0.0009
[01:29:59.434] iteration:1940  t-loss:0.4813, loss-lb:0.3941, loss-ulb:0.5052, weight:0.17, lr:0.0009
[01:29:59.747] iteration:1941  t-loss:0.2454, loss-lb:0.2070, loss-ulb:0.2224, weight:0.17, lr:0.0009
[01:30:00.064] iteration:1942  t-loss:0.3469, loss-lb:0.2959, loss-ulb:0.2955, weight:0.17, lr:0.0009
[01:30:00.388] iteration:1943  t-loss:0.9169, loss-lb:0.8321, loss-ulb:0.4915, weight:0.17, lr:0.0009
[01:30:00.702] iteration:1944  t-loss:0.3043, loss-lb:0.2797, loss-ulb:0.1425, weight:0.17, lr:0.0009
[01:30:01.016] iteration:1945  t-loss:0.2900, loss-lb:0.2242, loss-ulb:0.3814, weight:0.17, lr:0.0009
[01:30:01.331] iteration:1946  t-loss:0.3882, loss-lb:0.3013, loss-ulb:0.5036, weight:0.17, lr:0.0009
[01:30:01.648] iteration:1947  t-loss:0.5709, loss-lb:0.5414, loss-ulb:0.1711, weight:0.17, lr:0.0009
[01:30:01.959] iteration:1948  t-loss:0.3442, loss-lb:0.2735, loss-ulb:0.4096, weight:0.17, lr:0.0009
[01:30:02.268] iteration:1949  t-loss:0.4506, loss-lb:0.1827, loss-ulb:1.5525, weight:0.17, lr:0.0009
[01:30:02.578] iteration:1950  t-loss:0.2782, loss-lb:0.2637, loss-ulb:0.0840, weight:0.17, lr:0.0009
[01:30:03.902] iteration:1951  t-loss:0.3055, loss-lb:0.2887, loss-ulb:0.0819, weight:0.20, lr:0.0009
[01:30:04.240] iteration:1952  t-loss:0.2743, loss-lb:0.2432, loss-ulb:0.1522, weight:0.20, lr:0.0009
[01:30:04.587] iteration:1953  t-loss:0.3336, loss-lb:0.2813, loss-ulb:0.2551, weight:0.20, lr:0.0009
[01:30:04.919] iteration:1954  t-loss:0.3676, loss-lb:0.2460, loss-ulb:0.5936, weight:0.20, lr:0.0009
[01:30:05.251] iteration:1955  t-loss:0.2357, loss-lb:0.1940, loss-ulb:0.2036, weight:0.20, lr:0.0009
[01:30:05.585] iteration:1956  t-loss:0.4313, loss-lb:0.2781, loss-ulb:0.7475, weight:0.20, lr:0.0009
[01:30:05.906] iteration:1957  t-loss:0.3187, loss-lb:0.2917, loss-ulb:0.1320, weight:0.20, lr:0.0009
[01:30:06.222] iteration:1958  t-loss:0.3583, loss-lb:0.2900, loss-ulb:0.3331, weight:0.20, lr:0.0009
[01:30:06.544] iteration:1959  t-loss:0.3196, loss-lb:0.3016, loss-ulb:0.0875, weight:0.20, lr:0.0009
[01:30:06.866] iteration:1960  t-loss:0.3221, loss-lb:0.2809, loss-ulb:0.2007, weight:0.20, lr:0.0009
[01:30:07.184] iteration:1961  t-loss:0.2995, loss-lb:0.2614, loss-ulb:0.1858, weight:0.20, lr:0.0009
[01:30:07.511] iteration:1962  t-loss:0.2294, loss-lb:0.2194, loss-ulb:0.0487, weight:0.20, lr:0.0009
[01:30:07.833] iteration:1963  t-loss:0.3603, loss-lb:0.3531, loss-ulb:0.0350, weight:0.20, lr:0.0009
[01:30:08.155] iteration:1964  t-loss:0.2995, loss-lb:0.2563, loss-ulb:0.2110, weight:0.20, lr:0.0009
[01:30:08.478] iteration:1965  t-loss:0.2893, loss-lb:0.2523, loss-ulb:0.1806, weight:0.20, lr:0.0009
[01:30:08.797] iteration:1966  t-loss:0.3360, loss-lb:0.2603, loss-ulb:0.3694, weight:0.20, lr:0.0009
[01:30:09.117] iteration:1967  t-loss:0.3055, loss-lb:0.2113, loss-ulb:0.4596, weight:0.20, lr:0.0009
[01:30:09.435] iteration:1968  t-loss:0.4886, loss-lb:0.4540, loss-ulb:0.1691, weight:0.20, lr:0.0009
[01:30:09.750] iteration:1969  t-loss:0.3152, loss-lb:0.2643, loss-ulb:0.2484, weight:0.20, lr:0.0009
[01:30:10.069] iteration:1970  t-loss:0.2343, loss-lb:0.1946, loss-ulb:0.1941, weight:0.20, lr:0.0009
[01:30:10.385] iteration:1971  t-loss:0.2918, loss-lb:0.2512, loss-ulb:0.1983, weight:0.20, lr:0.0009
[01:30:10.696] iteration:1972  t-loss:0.3594, loss-lb:0.3062, loss-ulb:0.2596, weight:0.20, lr:0.0009
[01:30:11.012] iteration:1973  t-loss:0.3624, loss-lb:0.2949, loss-ulb:0.3294, weight:0.20, lr:0.0009
[01:30:11.324] iteration:1974  t-loss:0.3777, loss-lb:0.2044, loss-ulb:0.8452, weight:0.20, lr:0.0009
[01:30:11.636] iteration:1975  t-loss:0.4280, loss-lb:0.3026, loss-ulb:0.6120, weight:0.20, lr:0.0009
[01:30:12.868] iteration:1976  t-loss:0.3874, loss-lb:0.3204, loss-ulb:0.3268, weight:0.20, lr:0.0009
[01:30:13.198] iteration:1977  t-loss:0.3744, loss-lb:0.3015, loss-ulb:0.3553, weight:0.20, lr:0.0009
[01:30:13.527] iteration:1978  t-loss:0.4651, loss-lb:0.3956, loss-ulb:0.3392, weight:0.20, lr:0.0009
[01:30:13.848] iteration:1979  t-loss:0.4168, loss-lb:0.3104, loss-ulb:0.5190, weight:0.20, lr:0.0009
[01:30:14.180] iteration:1980  t-loss:0.3302, loss-lb:0.2698, loss-ulb:0.2948, weight:0.20, lr:0.0009
[01:30:14.510] iteration:1981  t-loss:0.3611, loss-lb:0.2794, loss-ulb:0.3986, weight:0.20, lr:0.0009
[01:30:14.829] iteration:1982  t-loss:0.4815, loss-lb:0.4518, loss-ulb:0.1446, weight:0.20, lr:0.0009
[01:30:15.145] iteration:1983  t-loss:0.2406, loss-lb:0.2086, loss-ulb:0.1563, weight:0.20, lr:0.0009
[01:30:15.472] iteration:1984  t-loss:0.2630, loss-lb:0.2244, loss-ulb:0.1887, weight:0.20, lr:0.0009
[01:30:15.785] iteration:1985  t-loss:0.2168, loss-lb:0.2056, loss-ulb:0.0546, weight:0.20, lr:0.0009
[01:30:16.109] iteration:1986  t-loss:0.3411, loss-lb:0.3029, loss-ulb:0.1861, weight:0.20, lr:0.0009
[01:30:16.429] iteration:1987  t-loss:0.3221, loss-lb:0.2833, loss-ulb:0.1890, weight:0.20, lr:0.0009
[01:30:16.747] iteration:1988  t-loss:0.6482, loss-lb:0.6345, loss-ulb:0.0666, weight:0.20, lr:0.0009
[01:30:17.065] iteration:1989  t-loss:0.1607, loss-lb:0.1530, loss-ulb:0.0377, weight:0.20, lr:0.0009
[01:30:17.385] iteration:1990  t-loss:0.4037, loss-lb:0.2412, loss-ulb:0.7925, weight:0.20, lr:0.0009
[01:30:17.714] iteration:1991  t-loss:0.5446, loss-lb:0.5284, loss-ulb:0.0789, weight:0.20, lr:0.0009
[01:30:18.037] iteration:1992  t-loss:0.5407, loss-lb:0.3864, loss-ulb:0.7526, weight:0.20, lr:0.0009
[01:30:18.354] iteration:1993  t-loss:0.2892, loss-lb:0.2785, loss-ulb:0.0522, weight:0.20, lr:0.0009
[01:30:18.667] iteration:1994  t-loss:0.3690, loss-lb:0.2788, loss-ulb:0.4399, weight:0.20, lr:0.0009
[01:30:18.983] iteration:1995  t-loss:0.3648, loss-lb:0.2950, loss-ulb:0.3402, weight:0.20, lr:0.0009
[01:30:19.297] iteration:1996  t-loss:0.3108, loss-lb:0.2401, loss-ulb:0.3450, weight:0.20, lr:0.0009
[01:30:19.608] iteration:1997  t-loss:0.4285, loss-lb:0.2987, loss-ulb:0.6329, weight:0.20, lr:0.0009
[01:30:19.923] iteration:1998  t-loss:0.4099, loss-lb:0.3532, loss-ulb:0.2766, weight:0.20, lr:0.0009
[01:30:20.234] iteration:1999  t-loss:0.2803, loss-lb:0.2284, loss-ulb:0.2532, weight:0.20, lr:0.0009
[01:30:20.548] iteration:2000  t-loss:0.3885, loss-lb:0.3307, loss-ulb:0.2819, weight:0.20, lr:0.0009
[01:30:21.838] iteration:2001  t-loss:0.3519, loss-lb:0.3190, loss-ulb:0.1605, weight:0.20, lr:0.0009
[01:30:22.175] iteration:2002  t-loss:0.6486, loss-lb:0.6188, loss-ulb:0.1455, weight:0.20, lr:0.0009
[01:30:22.505] iteration:2003  t-loss:0.4026, loss-lb:0.3601, loss-ulb:0.2073, weight:0.20, lr:0.0009
[01:30:22.823] iteration:2004  t-loss:0.7880, loss-lb:0.6157, loss-ulb:0.8407, weight:0.20, lr:0.0009
[01:30:23.143] iteration:2005  t-loss:0.3242, loss-lb:0.3118, loss-ulb:0.0607, weight:0.20, lr:0.0009
[01:30:23.462] iteration:2006  t-loss:0.5078, loss-lb:0.3860, loss-ulb:0.5945, weight:0.20, lr:0.0009
[01:30:23.789] iteration:2007  t-loss:0.7393, loss-lb:0.6906, loss-ulb:0.2374, weight:0.20, lr:0.0009
[01:30:24.106] iteration:2008  t-loss:0.3406, loss-lb:0.2765, loss-ulb:0.3132, weight:0.20, lr:0.0009
[01:30:24.424] iteration:2009  t-loss:0.2987, loss-lb:0.2260, loss-ulb:0.3547, weight:0.20, lr:0.0009
[01:30:24.750] iteration:2010  t-loss:0.4124, loss-lb:0.3519, loss-ulb:0.2949, weight:0.20, lr:0.0009
[01:30:25.066] iteration:2011  t-loss:0.1941, loss-lb:0.1548, loss-ulb:0.1916, weight:0.20, lr:0.0009
[01:30:25.387] iteration:2012  t-loss:0.2749, loss-lb:0.2682, loss-ulb:0.0326, weight:0.20, lr:0.0009
[01:30:25.709] iteration:2013  t-loss:0.4388, loss-lb:0.3981, loss-ulb:0.1982, weight:0.20, lr:0.0009
[01:30:26.024] iteration:2014  t-loss:0.2210, loss-lb:0.2091, loss-ulb:0.0584, weight:0.20, lr:0.0009
[01:30:26.344] iteration:2015  t-loss:0.2255, loss-lb:0.1811, loss-ulb:0.2166, weight:0.20, lr:0.0009
[01:30:26.659] iteration:2016  t-loss:0.2922, loss-lb:0.2728, loss-ulb:0.0947, weight:0.20, lr:0.0009
[01:30:26.978] iteration:2017  t-loss:0.3602, loss-lb:0.3216, loss-ulb:0.1886, weight:0.20, lr:0.0009
[01:30:27.292] iteration:2018  t-loss:0.2967, loss-lb:0.2475, loss-ulb:0.2402, weight:0.20, lr:0.0009
[01:30:27.607] iteration:2019  t-loss:0.5945, loss-lb:0.5794, loss-ulb:0.0737, weight:0.20, lr:0.0009
[01:30:27.924] iteration:2020  t-loss:0.3276, loss-lb:0.3016, loss-ulb:0.1271, weight:0.20, lr:0.0009
[01:30:28.236] iteration:2021  t-loss:0.2638, loss-lb:0.2374, loss-ulb:0.1290, weight:0.20, lr:0.0009
[01:30:28.549] iteration:2022  t-loss:0.2589, loss-lb:0.2100, loss-ulb:0.2389, weight:0.20, lr:0.0009
[01:30:28.859] iteration:2023  t-loss:0.2943, loss-lb:0.2832, loss-ulb:0.0541, weight:0.20, lr:0.0009
[01:30:29.171] iteration:2024  t-loss:0.3847, loss-lb:0.2001, loss-ulb:0.9006, weight:0.20, lr:0.0009
[01:30:29.487] iteration:2025  t-loss:0.2906, loss-lb:0.2530, loss-ulb:0.1835, weight:0.20, lr:0.0009
[01:32:39.164] iteration 2025 : dice_score: 0.781969 best_dice: 0.782000
[01:32:39.164]  <<Test>> - Ep:80  - Dice-S/T:74.95/78.20, Best-S:77.36, Best-T:78.20
[01:32:39.165]           - AvgLoss(lb/ulb/all):0.33/0.24/0.35
[01:32:40.669] iteration:2026  t-loss:0.3589, loss-lb:0.3253, loss-ulb:0.1641, weight:0.20, lr:0.0009
[01:32:41.008] iteration:2027  t-loss:0.3403, loss-lb:0.3027, loss-ulb:0.1837, weight:0.20, lr:0.0009
[01:32:41.339] iteration:2028  t-loss:0.4399, loss-lb:0.3866, loss-ulb:0.2597, weight:0.20, lr:0.0009
[01:32:41.671] iteration:2029  t-loss:0.3325, loss-lb:0.2685, loss-ulb:0.3119, weight:0.20, lr:0.0009
[01:32:41.991] iteration:2030  t-loss:0.4241, loss-lb:0.3012, loss-ulb:0.5994, weight:0.20, lr:0.0009
[01:32:42.314] iteration:2031  t-loss:0.2757, loss-lb:0.2540, loss-ulb:0.1061, weight:0.20, lr:0.0009
[01:32:42.636] iteration:2032  t-loss:0.2737, loss-lb:0.2487, loss-ulb:0.1222, weight:0.20, lr:0.0009
[01:32:42.958] iteration:2033  t-loss:0.2953, loss-lb:0.2353, loss-ulb:0.2927, weight:0.20, lr:0.0009
[01:32:43.292] iteration:2034  t-loss:0.3916, loss-lb:0.3381, loss-ulb:0.2610, weight:0.20, lr:0.0009
[01:32:43.614] iteration:2035  t-loss:0.2216, loss-lb:0.1870, loss-ulb:0.1689, weight:0.20, lr:0.0009
[01:32:43.935] iteration:2036  t-loss:0.3057, loss-lb:0.2855, loss-ulb:0.0983, weight:0.20, lr:0.0009
[01:32:44.250] iteration:2037  t-loss:0.4593, loss-lb:0.2835, loss-ulb:0.8575, weight:0.20, lr:0.0009
[01:32:44.571] iteration:2038  t-loss:0.2805, loss-lb:0.2714, loss-ulb:0.0442, weight:0.20, lr:0.0009
[01:32:44.899] iteration:2039  t-loss:0.3097, loss-lb:0.2785, loss-ulb:0.1523, weight:0.20, lr:0.0009
[01:32:45.224] iteration:2040  t-loss:0.3963, loss-lb:0.3412, loss-ulb:0.2688, weight:0.20, lr:0.0009
[01:32:45.541] iteration:2041  t-loss:0.3315, loss-lb:0.2773, loss-ulb:0.2646, weight:0.20, lr:0.0009
[01:32:45.857] iteration:2042  t-loss:0.2922, loss-lb:0.2196, loss-ulb:0.3544, weight:0.20, lr:0.0009
[01:32:46.175] iteration:2043  t-loss:0.2718, loss-lb:0.2201, loss-ulb:0.2523, weight:0.20, lr:0.0009
[01:32:46.495] iteration:2044  t-loss:0.2292, loss-lb:0.1814, loss-ulb:0.2334, weight:0.20, lr:0.0009
[01:32:46.813] iteration:2045  t-loss:0.3839, loss-lb:0.2939, loss-ulb:0.4390, weight:0.20, lr:0.0009
[01:32:47.123] iteration:2046  t-loss:0.2317, loss-lb:0.1643, loss-ulb:0.3291, weight:0.20, lr:0.0009
[01:32:47.437] iteration:2047  t-loss:0.4289, loss-lb:0.3754, loss-ulb:0.2610, weight:0.20, lr:0.0009
[01:32:47.752] iteration:2048  t-loss:0.3362, loss-lb:0.2880, loss-ulb:0.2352, weight:0.20, lr:0.0009
[01:32:48.065] iteration:2049  t-loss:0.3438, loss-lb:0.2404, loss-ulb:0.5042, weight:0.20, lr:0.0009
[01:32:48.379] iteration:2050  t-loss:0.3886, loss-lb:0.3726, loss-ulb:0.0783, weight:0.20, lr:0.0009
[01:32:49.772] iteration:2051  t-loss:0.4886, loss-lb:0.3734, loss-ulb:0.5620, weight:0.20, lr:0.0009
[01:32:50.109] iteration:2052  t-loss:0.5590, loss-lb:0.3862, loss-ulb:0.8429, weight:0.20, lr:0.0009
[01:32:50.432] iteration:2053  t-loss:0.3243, loss-lb:0.2908, loss-ulb:0.1636, weight:0.20, lr:0.0009
[01:32:50.748] iteration:2054  t-loss:0.2633, loss-lb:0.2341, loss-ulb:0.1425, weight:0.20, lr:0.0009
[01:32:51.065] iteration:2055  t-loss:0.3694, loss-lb:0.3347, loss-ulb:0.1693, weight:0.20, lr:0.0009
[01:32:51.382] iteration:2056  t-loss:0.2211, loss-lb:0.1691, loss-ulb:0.2541, weight:0.20, lr:0.0009
[01:32:51.698] iteration:2057  t-loss:0.4458, loss-lb:0.3634, loss-ulb:0.4018, weight:0.20, lr:0.0009
[01:32:52.012] iteration:2058  t-loss:0.3597, loss-lb:0.3176, loss-ulb:0.2054, weight:0.20, lr:0.0009
[01:32:52.333] iteration:2059  t-loss:0.3120, loss-lb:0.2753, loss-ulb:0.1791, weight:0.20, lr:0.0009
[01:32:52.647] iteration:2060  t-loss:0.4685, loss-lb:0.3408, loss-ulb:0.6232, weight:0.20, lr:0.0009
[01:32:52.961] iteration:2061  t-loss:0.2407, loss-lb:0.2227, loss-ulb:0.0876, weight:0.20, lr:0.0009
[01:32:53.273] iteration:2062  t-loss:0.2443, loss-lb:0.2162, loss-ulb:0.1371, weight:0.20, lr:0.0009
[01:32:53.595] iteration:2063  t-loss:0.3143, loss-lb:0.2694, loss-ulb:0.2189, weight:0.20, lr:0.0009
[01:32:53.926] iteration:2064  t-loss:0.3862, loss-lb:0.3391, loss-ulb:0.2294, weight:0.20, lr:0.0009
[01:32:54.244] iteration:2065  t-loss:0.2420, loss-lb:0.1784, loss-ulb:0.3103, weight:0.20, lr:0.0009
[01:32:54.558] iteration:2066  t-loss:0.2686, loss-lb:0.2267, loss-ulb:0.2042, weight:0.20, lr:0.0009
[01:32:54.887] iteration:2067  t-loss:0.2671, loss-lb:0.2488, loss-ulb:0.0891, weight:0.20, lr:0.0009
[01:32:55.210] iteration:2068  t-loss:0.3622, loss-lb:0.3373, loss-ulb:0.1217, weight:0.20, lr:0.0009
[01:32:55.525] iteration:2069  t-loss:0.2956, loss-lb:0.1983, loss-ulb:0.4752, weight:0.20, lr:0.0009
[01:32:55.846] iteration:2070  t-loss:0.4096, loss-lb:0.3780, loss-ulb:0.1542, weight:0.20, lr:0.0009
[01:32:56.163] iteration:2071  t-loss:0.4375, loss-lb:0.3617, loss-ulb:0.3698, weight:0.20, lr:0.0009
[01:32:56.482] iteration:2072  t-loss:0.2557, loss-lb:0.2471, loss-ulb:0.0416, weight:0.20, lr:0.0009
[01:32:56.795] iteration:2073  t-loss:0.5220, loss-lb:0.2883, loss-ulb:1.1404, weight:0.20, lr:0.0009
[01:32:57.108] iteration:2074  t-loss:0.3375, loss-lb:0.1764, loss-ulb:0.7859, weight:0.20, lr:0.0009
[01:32:57.431] iteration:2075  t-loss:0.4354, loss-lb:0.3874, loss-ulb:0.2344, weight:0.20, lr:0.0009
[01:32:59.014] iteration:2076  t-loss:0.5428, loss-lb:0.4089, loss-ulb:0.6533, weight:0.20, lr:0.0009
[01:32:59.366] iteration:2077  t-loss:0.6643, loss-lb:0.5563, loss-ulb:0.5270, weight:0.20, lr:0.0009
[01:32:59.689] iteration:2078  t-loss:0.2824, loss-lb:0.1792, loss-ulb:0.5037, weight:0.20, lr:0.0009
[01:33:00.020] iteration:2079  t-loss:0.5208, loss-lb:0.4032, loss-ulb:0.5738, weight:0.20, lr:0.0009
[01:33:00.339] iteration:2080  t-loss:0.3988, loss-lb:0.2896, loss-ulb:0.5329, weight:0.20, lr:0.0009
[01:33:00.660] iteration:2081  t-loss:0.2184, loss-lb:0.1729, loss-ulb:0.2223, weight:0.20, lr:0.0009
[01:33:00.988] iteration:2082  t-loss:0.3280, loss-lb:0.2957, loss-ulb:0.1574, weight:0.20, lr:0.0009
[01:33:01.311] iteration:2083  t-loss:0.3339, loss-lb:0.2374, loss-ulb:0.4712, weight:0.20, lr:0.0009
[01:33:01.628] iteration:2084  t-loss:0.3022, loss-lb:0.2159, loss-ulb:0.4208, weight:0.20, lr:0.0009
[01:33:01.959] iteration:2085  t-loss:0.5584, loss-lb:0.5172, loss-ulb:0.2009, weight:0.20, lr:0.0009
[01:33:02.276] iteration:2086  t-loss:0.2625, loss-lb:0.2460, loss-ulb:0.0808, weight:0.20, lr:0.0009
[01:33:02.593] iteration:2087  t-loss:0.3621, loss-lb:0.3198, loss-ulb:0.2067, weight:0.20, lr:0.0009
[01:33:02.920] iteration:2088  t-loss:0.4185, loss-lb:0.3732, loss-ulb:0.2211, weight:0.20, lr:0.0009
[01:33:03.240] iteration:2089  t-loss:0.4105, loss-lb:0.2863, loss-ulb:0.6064, weight:0.20, lr:0.0009
[01:33:03.562] iteration:2090  t-loss:0.4911, loss-lb:0.4533, loss-ulb:0.1842, weight:0.20, lr:0.0009
[01:33:03.883] iteration:2091  t-loss:0.8863, loss-lb:0.7033, loss-ulb:0.8932, weight:0.20, lr:0.0009
[01:33:04.199] iteration:2092  t-loss:0.2280, loss-lb:0.2028, loss-ulb:0.1227, weight:0.20, lr:0.0009
[01:33:04.510] iteration:2093  t-loss:0.2959, loss-lb:0.2026, loss-ulb:0.4552, weight:0.20, lr:0.0009
[01:33:04.823] iteration:2094  t-loss:0.2683, loss-lb:0.2412, loss-ulb:0.1323, weight:0.20, lr:0.0009
[01:33:05.142] iteration:2095  t-loss:0.3264, loss-lb:0.2495, loss-ulb:0.3753, weight:0.20, lr:0.0009
[01:33:05.457] iteration:2096  t-loss:0.5713, loss-lb:0.5141, loss-ulb:0.2791, weight:0.20, lr:0.0009
[01:33:05.773] iteration:2097  t-loss:0.4879, loss-lb:0.4179, loss-ulb:0.3417, weight:0.20, lr:0.0009
[01:33:06.089] iteration:2098  t-loss:0.4220, loss-lb:0.3894, loss-ulb:0.1591, weight:0.20, lr:0.0009
[01:33:06.402] iteration:2099  t-loss:0.3527, loss-lb:0.2549, loss-ulb:0.4771, weight:0.20, lr:0.0009
[01:33:06.717] iteration:2100  t-loss:0.3720, loss-lb:0.2990, loss-ulb:0.3564, weight:0.20, lr:0.0009
[01:33:07.914] iteration:2101  t-loss:0.3146, loss-lb:0.2674, loss-ulb:0.1951, weight:0.24, lr:0.0009
[01:33:08.250] iteration:2102  t-loss:0.5027, loss-lb:0.3117, loss-ulb:0.7896, weight:0.24, lr:0.0009
[01:33:08.606] iteration:2103  t-loss:0.4980, loss-lb:0.2924, loss-ulb:0.8497, weight:0.24, lr:0.0009
[01:33:08.949] iteration:2104  t-loss:0.7026, loss-lb:0.4319, loss-ulb:1.1189, weight:0.24, lr:0.0009
[01:33:09.278] iteration:2105  t-loss:0.2637, loss-lb:0.2434, loss-ulb:0.0839, weight:0.24, lr:0.0009
[01:33:09.599] iteration:2106  t-loss:0.3033, loss-lb:0.2318, loss-ulb:0.2954, weight:0.24, lr:0.0009
[01:33:09.926] iteration:2107  t-loss:0.4771, loss-lb:0.4256, loss-ulb:0.2128, weight:0.24, lr:0.0009
[01:33:10.242] iteration:2108  t-loss:0.3277, loss-lb:0.3186, loss-ulb:0.0377, weight:0.24, lr:0.0009
[01:33:10.571] iteration:2109  t-loss:0.5414, loss-lb:0.5012, loss-ulb:0.1660, weight:0.24, lr:0.0009
[01:33:10.899] iteration:2110  t-loss:0.7047, loss-lb:0.5492, loss-ulb:0.6430, weight:0.24, lr:0.0009
[01:33:11.221] iteration:2111  t-loss:0.2710, loss-lb:0.2172, loss-ulb:0.2223, weight:0.24, lr:0.0009
[01:33:11.547] iteration:2112  t-loss:0.6654, loss-lb:0.6254, loss-ulb:0.1653, weight:0.24, lr:0.0009
[01:33:11.874] iteration:2113  t-loss:0.3277, loss-lb:0.2742, loss-ulb:0.2214, weight:0.24, lr:0.0009
[01:33:12.192] iteration:2114  t-loss:0.3056, loss-lb:0.2292, loss-ulb:0.3159, weight:0.24, lr:0.0009
[01:33:12.520] iteration:2115  t-loss:0.5137, loss-lb:0.4458, loss-ulb:0.2806, weight:0.24, lr:0.0009
[01:33:12.844] iteration:2116  t-loss:0.6251, loss-lb:0.5783, loss-ulb:0.1931, weight:0.24, lr:0.0009
[01:33:13.165] iteration:2117  t-loss:0.4488, loss-lb:0.3219, loss-ulb:0.5250, weight:0.24, lr:0.0009
[01:33:13.479] iteration:2118  t-loss:0.2900, loss-lb:0.2493, loss-ulb:0.1686, weight:0.24, lr:0.0009
[01:33:13.795] iteration:2119  t-loss:0.4132, loss-lb:0.3448, loss-ulb:0.2830, weight:0.24, lr:0.0009
[01:33:14.109] iteration:2120  t-loss:0.3163, loss-lb:0.2600, loss-ulb:0.2330, weight:0.24, lr:0.0009
[01:33:14.424] iteration:2121  t-loss:0.3475, loss-lb:0.2087, loss-ulb:0.5739, weight:0.24, lr:0.0009
[01:33:14.741] iteration:2122  t-loss:0.3937, loss-lb:0.2756, loss-ulb:0.4879, weight:0.24, lr:0.0009
[01:33:15.054] iteration:2123  t-loss:0.4726, loss-lb:0.2333, loss-ulb:0.9895, weight:0.24, lr:0.0009
[01:33:15.371] iteration:2124  t-loss:0.4115, loss-lb:0.3645, loss-ulb:0.1947, weight:0.24, lr:0.0009
[01:33:15.690] iteration:2125  t-loss:0.6179, loss-lb:0.4406, loss-ulb:0.7331, weight:0.24, lr:0.0009
[01:35:29.889] iteration 2125 : dice_score: 0.780787 best_dice: 0.782000
[01:35:29.889]  <<Test>> - Ep:84  - Dice-S/T:76.79/78.08, Best-S:77.36, Best-T:78.20
[01:35:29.889]           - AvgLoss(lb/ulb/all):0.35/0.35/0.44
[01:35:31.286] iteration:2126  t-loss:0.6615, loss-lb:0.5980, loss-ulb:0.2628, weight:0.24, lr:0.0009
[01:35:31.641] iteration:2127  t-loss:0.3329, loss-lb:0.2797, loss-ulb:0.2199, weight:0.24, lr:0.0009
[01:35:31.984] iteration:2128  t-loss:0.2684, loss-lb:0.2101, loss-ulb:0.2410, weight:0.24, lr:0.0009
[01:35:32.315] iteration:2129  t-loss:0.2622, loss-lb:0.2073, loss-ulb:0.2270, weight:0.24, lr:0.0009
[01:35:32.663] iteration:2130  t-loss:0.2846, loss-lb:0.2553, loss-ulb:0.1213, weight:0.24, lr:0.0009
[01:35:33.008] iteration:2131  t-loss:0.2590, loss-lb:0.2515, loss-ulb:0.0312, weight:0.24, lr:0.0009
[01:35:33.335] iteration:2132  t-loss:0.2958, loss-lb:0.1958, loss-ulb:0.4136, weight:0.24, lr:0.0009
[01:35:33.674] iteration:2133  t-loss:0.4130, loss-lb:0.3360, loss-ulb:0.3186, weight:0.24, lr:0.0009
[01:35:34.007] iteration:2134  t-loss:0.4296, loss-lb:0.3322, loss-ulb:0.4027, weight:0.24, lr:0.0009
[01:35:34.332] iteration:2135  t-loss:0.5662, loss-lb:0.4783, loss-ulb:0.3635, weight:0.24, lr:0.0009
[01:35:34.646] iteration:2136  t-loss:0.3109, loss-lb:0.2407, loss-ulb:0.2902, weight:0.24, lr:0.0009
[01:35:34.972] iteration:2137  t-loss:0.4068, loss-lb:0.2920, loss-ulb:0.4744, weight:0.24, lr:0.0009
[01:35:35.294] iteration:2138  t-loss:0.4317, loss-lb:0.3938, loss-ulb:0.1567, weight:0.24, lr:0.0009
[01:35:35.618] iteration:2139  t-loss:0.3056, loss-lb:0.2663, loss-ulb:0.1625, weight:0.24, lr:0.0009
[01:35:35.943] iteration:2140  t-loss:0.3684, loss-lb:0.3594, loss-ulb:0.0375, weight:0.24, lr:0.0009
[01:35:36.271] iteration:2141  t-loss:0.3988, loss-lb:0.3293, loss-ulb:0.2871, weight:0.24, lr:0.0009
[01:35:36.586] iteration:2142  t-loss:0.2883, loss-lb:0.2072, loss-ulb:0.3353, weight:0.24, lr:0.0009
[01:35:36.903] iteration:2143  t-loss:0.3461, loss-lb:0.3218, loss-ulb:0.1001, weight:0.24, lr:0.0009
[01:35:37.215] iteration:2144  t-loss:0.4279, loss-lb:0.2162, loss-ulb:0.8752, weight:0.24, lr:0.0009
[01:35:37.530] iteration:2145  t-loss:0.3561, loss-lb:0.3199, loss-ulb:0.1498, weight:0.24, lr:0.0009
[01:35:37.846] iteration:2146  t-loss:0.2459, loss-lb:0.1997, loss-ulb:0.1913, weight:0.24, lr:0.0009
[01:35:38.162] iteration:2147  t-loss:0.4725, loss-lb:0.4400, loss-ulb:0.1346, weight:0.24, lr:0.0009
[01:35:38.479] iteration:2148  t-loss:0.2669, loss-lb:0.2033, loss-ulb:0.2629, weight:0.24, lr:0.0009
[01:35:38.795] iteration:2149  t-loss:0.4106, loss-lb:0.3210, loss-ulb:0.3702, weight:0.24, lr:0.0009
[01:35:39.106] iteration:2150  t-loss:0.2709, loss-lb:0.2274, loss-ulb:0.1801, weight:0.24, lr:0.0009
[01:35:40.542] iteration:2151  t-loss:0.4271, loss-lb:0.3443, loss-ulb:0.3423, weight:0.24, lr:0.0009
[01:35:40.903] iteration:2152  t-loss:0.3032, loss-lb:0.2163, loss-ulb:0.3593, weight:0.24, lr:0.0009
[01:35:41.247] iteration:2153  t-loss:0.4385, loss-lb:0.3704, loss-ulb:0.2814, weight:0.24, lr:0.0009
[01:35:41.570] iteration:2154  t-loss:0.3197, loss-lb:0.2808, loss-ulb:0.1609, weight:0.24, lr:0.0009
[01:35:41.900] iteration:2155  t-loss:0.2963, loss-lb:0.2354, loss-ulb:0.2515, weight:0.24, lr:0.0009
[01:35:42.225] iteration:2156  t-loss:0.2892, loss-lb:0.2427, loss-ulb:0.1924, weight:0.24, lr:0.0009
[01:35:42.549] iteration:2157  t-loss:0.2120, loss-lb:0.2026, loss-ulb:0.0388, weight:0.24, lr:0.0009
[01:35:42.873] iteration:2158  t-loss:0.4418, loss-lb:0.3783, loss-ulb:0.2624, weight:0.24, lr:0.0009
[01:35:43.191] iteration:2159  t-loss:0.2227, loss-lb:0.2053, loss-ulb:0.0719, weight:0.24, lr:0.0009
[01:35:43.517] iteration:2160  t-loss:0.3302, loss-lb:0.2635, loss-ulb:0.2759, weight:0.24, lr:0.0009
[01:35:43.841] iteration:2161  t-loss:0.3931, loss-lb:0.3225, loss-ulb:0.2922, weight:0.24, lr:0.0009
[01:35:44.162] iteration:2162  t-loss:0.4966, loss-lb:0.3557, loss-ulb:0.5827, weight:0.24, lr:0.0009
[01:35:44.481] iteration:2163  t-loss:0.3260, loss-lb:0.2601, loss-ulb:0.2725, weight:0.24, lr:0.0009
[01:35:44.798] iteration:2164  t-loss:0.2049, loss-lb:0.1719, loss-ulb:0.1365, weight:0.24, lr:0.0009
[01:35:45.126] iteration:2165  t-loss:0.3654, loss-lb:0.3237, loss-ulb:0.1723, weight:0.24, lr:0.0009
[01:35:45.463] iteration:2166  t-loss:0.7540, loss-lb:0.7066, loss-ulb:0.1958, weight:0.24, lr:0.0009
[01:35:45.785] iteration:2167  t-loss:0.3794, loss-lb:0.3542, loss-ulb:0.1042, weight:0.24, lr:0.0009
[01:35:46.101] iteration:2168  t-loss:0.2497, loss-lb:0.2172, loss-ulb:0.1345, weight:0.24, lr:0.0009
[01:35:46.416] iteration:2169  t-loss:0.4341, loss-lb:0.2949, loss-ulb:0.5756, weight:0.24, lr:0.0009
[01:35:46.730] iteration:2170  t-loss:0.2062, loss-lb:0.1932, loss-ulb:0.0536, weight:0.24, lr:0.0009
[01:35:47.048] iteration:2171  t-loss:0.4992, loss-lb:0.4388, loss-ulb:0.2499, weight:0.24, lr:0.0009
[01:35:47.362] iteration:2172  t-loss:0.6116, loss-lb:0.4710, loss-ulb:0.5812, weight:0.24, lr:0.0009
[01:35:47.675] iteration:2173  t-loss:0.3527, loss-lb:0.2189, loss-ulb:0.5532, weight:0.24, lr:0.0009
[01:35:47.990] iteration:2174  t-loss:0.2704, loss-lb:0.2138, loss-ulb:0.2342, weight:0.24, lr:0.0009
[01:35:48.315] iteration:2175  t-loss:0.3849, loss-lb:0.3463, loss-ulb:0.1599, weight:0.24, lr:0.0009
[01:35:50.441] iteration:2176  t-loss:0.3992, loss-lb:0.3757, loss-ulb:0.0972, weight:0.24, lr:0.0009
[01:35:50.782] iteration:2177  t-loss:0.5006, loss-lb:0.4090, loss-ulb:0.3789, weight:0.24, lr:0.0009
[01:35:51.132] iteration:2178  t-loss:0.4773, loss-lb:0.3882, loss-ulb:0.3684, weight:0.24, lr:0.0009
[01:35:51.499] iteration:2179  t-loss:0.2861, loss-lb:0.2612, loss-ulb:0.1032, weight:0.24, lr:0.0009
[01:35:51.834] iteration:2180  t-loss:0.3652, loss-lb:0.3456, loss-ulb:0.0810, weight:0.24, lr:0.0009
[01:35:52.180] iteration:2181  t-loss:0.3472, loss-lb:0.3039, loss-ulb:0.1789, weight:0.24, lr:0.0009
[01:35:52.506] iteration:2182  t-loss:0.3773, loss-lb:0.2929, loss-ulb:0.3490, weight:0.24, lr:0.0009
[01:35:52.830] iteration:2183  t-loss:0.2523, loss-lb:0.2017, loss-ulb:0.2090, weight:0.24, lr:0.0009
[01:35:53.156] iteration:2184  t-loss:0.5934, loss-lb:0.4479, loss-ulb:0.6016, weight:0.24, lr:0.0009
[01:35:53.472] iteration:2185  t-loss:0.2713, loss-lb:0.1839, loss-ulb:0.3613, weight:0.24, lr:0.0009
[01:35:53.786] iteration:2186  t-loss:0.2253, loss-lb:0.1839, loss-ulb:0.1712, weight:0.24, lr:0.0009
[01:35:54.107] iteration:2187  t-loss:0.3636, loss-lb:0.3098, loss-ulb:0.2224, weight:0.24, lr:0.0009
[01:35:54.425] iteration:2188  t-loss:0.3542, loss-lb:0.3126, loss-ulb:0.1722, weight:0.24, lr:0.0009
[01:35:54.737] iteration:2189  t-loss:0.3804, loss-lb:0.2946, loss-ulb:0.3547, weight:0.24, lr:0.0009
[01:35:55.059] iteration:2190  t-loss:0.5703, loss-lb:0.4871, loss-ulb:0.3440, weight:0.24, lr:0.0009
[01:35:55.379] iteration:2191  t-loss:0.3530, loss-lb:0.3158, loss-ulb:0.1537, weight:0.24, lr:0.0009
[01:35:55.696] iteration:2192  t-loss:0.4626, loss-lb:0.4250, loss-ulb:0.1551, weight:0.24, lr:0.0009
[01:35:56.013] iteration:2193  t-loss:0.5671, loss-lb:0.4281, loss-ulb:0.5746, weight:0.24, lr:0.0009
[01:35:56.325] iteration:2194  t-loss:0.4664, loss-lb:0.3331, loss-ulb:0.5512, weight:0.24, lr:0.0009
[01:35:56.636] iteration:2195  t-loss:0.3258, loss-lb:0.2961, loss-ulb:0.1228, weight:0.24, lr:0.0009
[01:35:56.948] iteration:2196  t-loss:0.3713, loss-lb:0.2987, loss-ulb:0.3003, weight:0.24, lr:0.0009
[01:35:57.265] iteration:2197  t-loss:0.5175, loss-lb:0.4736, loss-ulb:0.1812, weight:0.24, lr:0.0009
[01:35:57.583] iteration:2198  t-loss:0.3031, loss-lb:0.2526, loss-ulb:0.2087, weight:0.24, lr:0.0009
[01:35:57.907] iteration:2199  t-loss:0.4495, loss-lb:0.4400, loss-ulb:0.0392, weight:0.24, lr:0.0009
[01:35:58.238] iteration:2200  t-loss:0.3688, loss-lb:0.3365, loss-ulb:0.1334, weight:0.24, lr:0.0009
[01:36:00.068] iteration:2201  t-loss:0.2073, loss-lb:0.1681, loss-ulb:0.1618, weight:0.24, lr:0.0009
[01:36:00.425] iteration:2202  t-loss:0.4102, loss-lb:0.3061, loss-ulb:0.4305, weight:0.24, lr:0.0009
[01:36:00.782] iteration:2203  t-loss:0.3389, loss-lb:0.2792, loss-ulb:0.2468, weight:0.24, lr:0.0009
[01:36:01.125] iteration:2204  t-loss:0.5338, loss-lb:0.4569, loss-ulb:0.3176, weight:0.24, lr:0.0009
[01:36:01.469] iteration:2205  t-loss:0.4270, loss-lb:0.2858, loss-ulb:0.5839, weight:0.24, lr:0.0009
[01:36:01.799] iteration:2206  t-loss:0.4689, loss-lb:0.3830, loss-ulb:0.3554, weight:0.24, lr:0.0009
[01:36:02.131] iteration:2207  t-loss:0.4699, loss-lb:0.4323, loss-ulb:0.1554, weight:0.24, lr:0.0009
[01:36:02.452] iteration:2208  t-loss:0.3802, loss-lb:0.3414, loss-ulb:0.1605, weight:0.24, lr:0.0009
[01:36:02.766] iteration:2209  t-loss:0.4163, loss-lb:0.3290, loss-ulb:0.3610, weight:0.24, lr:0.0009
[01:36:03.082] iteration:2210  t-loss:0.4485, loss-lb:0.4342, loss-ulb:0.0590, weight:0.24, lr:0.0009
[01:36:03.402] iteration:2211  t-loss:0.4601, loss-lb:0.3350, loss-ulb:0.5170, weight:0.24, lr:0.0009
[01:36:03.717] iteration:2212  t-loss:0.3054, loss-lb:0.1900, loss-ulb:0.4770, weight:0.24, lr:0.0009
[01:36:04.034] iteration:2213  t-loss:0.4285, loss-lb:0.3178, loss-ulb:0.4574, weight:0.24, lr:0.0009
[01:36:04.352] iteration:2214  t-loss:0.3778, loss-lb:0.3610, loss-ulb:0.0692, weight:0.24, lr:0.0009
[01:36:04.672] iteration:2215  t-loss:0.3462, loss-lb:0.3145, loss-ulb:0.1313, weight:0.24, lr:0.0009
[01:36:04.986] iteration:2216  t-loss:0.5254, loss-lb:0.3696, loss-ulb:0.6443, weight:0.24, lr:0.0009
[01:36:05.299] iteration:2217  t-loss:0.2365, loss-lb:0.2122, loss-ulb:0.1004, weight:0.24, lr:0.0009
[01:36:05.613] iteration:2218  t-loss:0.4070, loss-lb:0.3545, loss-ulb:0.2171, weight:0.24, lr:0.0009
[01:36:05.929] iteration:2219  t-loss:0.2145, loss-lb:0.1541, loss-ulb:0.2497, weight:0.24, lr:0.0009
[01:36:06.243] iteration:2220  t-loss:0.3782, loss-lb:0.2565, loss-ulb:0.5029, weight:0.24, lr:0.0009
[01:36:06.558] iteration:2221  t-loss:0.2886, loss-lb:0.2165, loss-ulb:0.2978, weight:0.24, lr:0.0009
[01:36:06.874] iteration:2222  t-loss:0.3289, loss-lb:0.3018, loss-ulb:0.1118, weight:0.24, lr:0.0009
[01:36:07.194] iteration:2223  t-loss:0.3064, loss-lb:0.2595, loss-ulb:0.1940, weight:0.24, lr:0.0009
[01:36:07.509] iteration:2224  t-loss:0.3247, loss-lb:0.2525, loss-ulb:0.2987, weight:0.24, lr:0.0009
[01:36:07.824] iteration:2225  t-loss:0.6242, loss-lb:0.5617, loss-ulb:0.2584, weight:0.24, lr:0.0009
[01:38:29.105] iteration 2225 : dice_score: 0.788772 best_dice: 0.788800
[01:38:29.106]  <<Test>> - Ep:88  - Dice-S/T:78.12/78.88, Best-S:78.12, Best-T:78.88
[01:38:29.106]           - AvgLoss(lb/ulb/all):0.31/0.28/0.39
[01:38:30.554] iteration:2226  t-loss:0.3852, loss-lb:0.3344, loss-ulb:0.2099, weight:0.24, lr:0.0009
[01:38:30.878] iteration:2227  t-loss:0.3095, loss-lb:0.2947, loss-ulb:0.0614, weight:0.24, lr:0.0009
[01:38:31.208] iteration:2228  t-loss:0.5795, loss-lb:0.5287, loss-ulb:0.2098, weight:0.24, lr:0.0009
[01:38:31.532] iteration:2229  t-loss:0.3671, loss-lb:0.3407, loss-ulb:0.1091, weight:0.24, lr:0.0009
[01:38:31.853] iteration:2230  t-loss:0.3675, loss-lb:0.3069, loss-ulb:0.2507, weight:0.24, lr:0.0009
[01:38:32.167] iteration:2231  t-loss:0.2709, loss-lb:0.2143, loss-ulb:0.2339, weight:0.24, lr:0.0009
[01:38:32.484] iteration:2232  t-loss:0.3245, loss-lb:0.2270, loss-ulb:0.4032, weight:0.24, lr:0.0009
[01:38:32.799] iteration:2233  t-loss:0.2723, loss-lb:0.2335, loss-ulb:0.1603, weight:0.24, lr:0.0009
[01:38:33.114] iteration:2234  t-loss:0.2501, loss-lb:0.2083, loss-ulb:0.1727, weight:0.24, lr:0.0009
[01:38:33.433] iteration:2235  t-loss:0.5265, loss-lb:0.4926, loss-ulb:0.1405, weight:0.24, lr:0.0009
[01:38:33.752] iteration:2236  t-loss:0.2720, loss-lb:0.2121, loss-ulb:0.2478, weight:0.24, lr:0.0009
[01:38:34.078] iteration:2237  t-loss:0.4134, loss-lb:0.3579, loss-ulb:0.2295, weight:0.24, lr:0.0009
[01:38:34.395] iteration:2238  t-loss:0.3938, loss-lb:0.3249, loss-ulb:0.2847, weight:0.24, lr:0.0009
[01:38:34.711] iteration:2239  t-loss:0.2339, loss-lb:0.2213, loss-ulb:0.0524, weight:0.24, lr:0.0009
[01:38:35.027] iteration:2240  t-loss:0.3869, loss-lb:0.3708, loss-ulb:0.0666, weight:0.24, lr:0.0009
[01:38:35.344] iteration:2241  t-loss:0.3534, loss-lb:0.2394, loss-ulb:0.4712, weight:0.24, lr:0.0009
[01:38:35.664] iteration:2242  t-loss:0.3061, loss-lb:0.2759, loss-ulb:0.1247, weight:0.24, lr:0.0009
[01:38:35.985] iteration:2243  t-loss:0.4328, loss-lb:0.4256, loss-ulb:0.0300, weight:0.24, lr:0.0009
[01:38:36.304] iteration:2244  t-loss:0.3872, loss-lb:0.2812, loss-ulb:0.4381, weight:0.24, lr:0.0009
[01:38:36.628] iteration:2245  t-loss:0.4388, loss-lb:0.3185, loss-ulb:0.4975, weight:0.24, lr:0.0009
[01:38:36.946] iteration:2246  t-loss:0.3451, loss-lb:0.2522, loss-ulb:0.3841, weight:0.24, lr:0.0009
[01:38:37.264] iteration:2247  t-loss:0.2965, loss-lb:0.2297, loss-ulb:0.2760, weight:0.24, lr:0.0009
[01:38:37.590] iteration:2248  t-loss:0.3482, loss-lb:0.2236, loss-ulb:0.5151, weight:0.24, lr:0.0009
[01:38:37.914] iteration:2249  t-loss:0.5464, loss-lb:0.3128, loss-ulb:0.9658, weight:0.24, lr:0.0009
[01:38:38.232] iteration:2250  t-loss:0.3873, loss-lb:0.2844, loss-ulb:0.4254, weight:0.24, lr:0.0009
[01:38:39.719] iteration:2251  t-loss:0.3044, loss-lb:0.2644, loss-ulb:0.1407, weight:0.28, lr:0.0009
[01:38:40.048] iteration:2252  t-loss:0.1820, loss-lb:0.1563, loss-ulb:0.0907, weight:0.28, lr:0.0009
[01:38:40.383] iteration:2253  t-loss:0.1932, loss-lb:0.1552, loss-ulb:0.1339, weight:0.28, lr:0.0009
[01:38:40.711] iteration:2254  t-loss:0.5351, loss-lb:0.4296, loss-ulb:0.3719, weight:0.28, lr:0.0009
[01:38:41.035] iteration:2255  t-loss:0.3232, loss-lb:0.2816, loss-ulb:0.1465, weight:0.28, lr:0.0009
[01:38:41.349] iteration:2256  t-loss:0.2215, loss-lb:0.2044, loss-ulb:0.0603, weight:0.28, lr:0.0009
[01:38:41.679] iteration:2257  t-loss:0.3868, loss-lb:0.3005, loss-ulb:0.3040, weight:0.28, lr:0.0009
[01:38:42.001] iteration:2258  t-loss:0.2716, loss-lb:0.2144, loss-ulb:0.2019, weight:0.28, lr:0.0009
[01:38:42.324] iteration:2259  t-loss:0.4128, loss-lb:0.3950, loss-ulb:0.0627, weight:0.28, lr:0.0009
[01:38:42.648] iteration:2260  t-loss:0.4316, loss-lb:0.3441, loss-ulb:0.3085, weight:0.28, lr:0.0009
[01:38:42.970] iteration:2261  t-loss:0.4412, loss-lb:0.3445, loss-ulb:0.3407, weight:0.28, lr:0.0009
[01:38:43.288] iteration:2262  t-loss:0.4210, loss-lb:0.3739, loss-ulb:0.1660, weight:0.28, lr:0.0009
[01:38:43.611] iteration:2263  t-loss:0.2798, loss-lb:0.1953, loss-ulb:0.2980, weight:0.28, lr:0.0009
[01:38:43.928] iteration:2264  t-loss:0.5532, loss-lb:0.3103, loss-ulb:0.8565, weight:0.28, lr:0.0009
[01:38:44.251] iteration:2265  t-loss:0.3216, loss-lb:0.3017, loss-ulb:0.0703, weight:0.28, lr:0.0009
[01:38:44.567] iteration:2266  t-loss:0.2394, loss-lb:0.1751, loss-ulb:0.2266, weight:0.28, lr:0.0009
[01:38:44.880] iteration:2267  t-loss:0.3781, loss-lb:0.3679, loss-ulb:0.0358, weight:0.28, lr:0.0009
[01:38:45.193] iteration:2268  t-loss:0.2515, loss-lb:0.1765, loss-ulb:0.2645, weight:0.28, lr:0.0009
[01:38:45.508] iteration:2269  t-loss:0.3706, loss-lb:0.3092, loss-ulb:0.2165, weight:0.28, lr:0.0009
[01:38:45.821] iteration:2270  t-loss:0.4197, loss-lb:0.2952, loss-ulb:0.4390, weight:0.28, lr:0.0009
[01:38:46.137] iteration:2271  t-loss:0.8526, loss-lb:0.7296, loss-ulb:0.4337, weight:0.28, lr:0.0009
[01:38:46.453] iteration:2272  t-loss:0.3794, loss-lb:0.3342, loss-ulb:0.1593, weight:0.28, lr:0.0009
[01:38:46.766] iteration:2273  t-loss:0.2647, loss-lb:0.2328, loss-ulb:0.1126, weight:0.28, lr:0.0009
[01:38:47.079] iteration:2274  t-loss:0.4862, loss-lb:0.4223, loss-ulb:0.2251, weight:0.28, lr:0.0009
[01:38:47.394] iteration:2275  t-loss:0.5611, loss-lb:0.4287, loss-ulb:0.4665, weight:0.28, lr:0.0009
[01:38:48.627] iteration:2276  t-loss:0.4978, loss-lb:0.3674, loss-ulb:0.4597, weight:0.28, lr:0.0009
[01:38:48.959] iteration:2277  t-loss:0.4641, loss-lb:0.3494, loss-ulb:0.4044, weight:0.28, lr:0.0009
[01:38:49.285] iteration:2278  t-loss:0.3428, loss-lb:0.2631, loss-ulb:0.2807, weight:0.28, lr:0.0009
[01:38:49.613] iteration:2279  t-loss:0.3706, loss-lb:0.3451, loss-ulb:0.0901, weight:0.28, lr:0.0009
[01:38:49.950] iteration:2280  t-loss:0.5805, loss-lb:0.5648, loss-ulb:0.0555, weight:0.28, lr:0.0009
[01:38:50.273] iteration:2281  t-loss:0.4720, loss-lb:0.3408, loss-ulb:0.4627, weight:0.28, lr:0.0009
[01:38:50.619] iteration:2282  t-loss:0.3899, loss-lb:0.3437, loss-ulb:0.1629, weight:0.28, lr:0.0009
[01:38:50.953] iteration:2283  t-loss:0.5402, loss-lb:0.4194, loss-ulb:0.4260, weight:0.28, lr:0.0009
[01:38:51.280] iteration:2284  t-loss:0.4845, loss-lb:0.3363, loss-ulb:0.5224, weight:0.28, lr:0.0009
[01:38:51.617] iteration:2285  t-loss:0.3347, loss-lb:0.2702, loss-ulb:0.2275, weight:0.28, lr:0.0009
[01:38:51.949] iteration:2286  t-loss:0.4623, loss-lb:0.3153, loss-ulb:0.5180, weight:0.28, lr:0.0009
[01:38:52.276] iteration:2287  t-loss:0.2759, loss-lb:0.2505, loss-ulb:0.0897, weight:0.28, lr:0.0009
[01:38:52.606] iteration:2288  t-loss:0.4743, loss-lb:0.3894, loss-ulb:0.2992, weight:0.28, lr:0.0009
[01:38:52.933] iteration:2289  t-loss:0.4376, loss-lb:0.2659, loss-ulb:0.6055, weight:0.28, lr:0.0009
[01:38:53.256] iteration:2290  t-loss:0.5181, loss-lb:0.4891, loss-ulb:0.1022, weight:0.28, lr:0.0009
[01:38:53.578] iteration:2291  t-loss:0.5361, loss-lb:0.3759, loss-ulb:0.5646, weight:0.28, lr:0.0009
[01:38:53.906] iteration:2292  t-loss:0.5481, loss-lb:0.3160, loss-ulb:0.8180, weight:0.28, lr:0.0009
[01:38:54.225] iteration:2293  t-loss:0.4157, loss-lb:0.4002, loss-ulb:0.0547, weight:0.28, lr:0.0009
[01:38:54.541] iteration:2294  t-loss:0.2643, loss-lb:0.2031, loss-ulb:0.2159, weight:0.28, lr:0.0009
[01:38:54.856] iteration:2295  t-loss:0.3443, loss-lb:0.2082, loss-ulb:0.4800, weight:0.28, lr:0.0009
[01:38:55.171] iteration:2296  t-loss:0.2860, loss-lb:0.1906, loss-ulb:0.3361, weight:0.28, lr:0.0009
[01:38:55.485] iteration:2297  t-loss:0.2905, loss-lb:0.2734, loss-ulb:0.0604, weight:0.28, lr:0.0009
[01:38:55.803] iteration:2298  t-loss:0.3327, loss-lb:0.2552, loss-ulb:0.2735, weight:0.28, lr:0.0009
[01:38:56.117] iteration:2299  t-loss:0.4640, loss-lb:0.4256, loss-ulb:0.1354, weight:0.28, lr:0.0009
[01:38:56.433] iteration:2300  t-loss:0.4140, loss-lb:0.3865, loss-ulb:0.0970, weight:0.28, lr:0.0009
[01:38:57.889] iteration:2301  t-loss:0.3493, loss-lb:0.2625, loss-ulb:0.3063, weight:0.28, lr:0.0009
[01:38:58.218] iteration:2302  t-loss:0.3669, loss-lb:0.2451, loss-ulb:0.4291, weight:0.28, lr:0.0009
[01:38:58.543] iteration:2303  t-loss:0.6311, loss-lb:0.5260, loss-ulb:0.3706, weight:0.28, lr:0.0009
[01:38:58.862] iteration:2304  t-loss:0.4397, loss-lb:0.3715, loss-ulb:0.2405, weight:0.28, lr:0.0009
[01:38:59.179] iteration:2305  t-loss:0.6660, loss-lb:0.6061, loss-ulb:0.2112, weight:0.28, lr:0.0009
[01:38:59.499] iteration:2306  t-loss:0.2595, loss-lb:0.1784, loss-ulb:0.2858, weight:0.28, lr:0.0009
[01:38:59.816] iteration:2307  t-loss:0.3790, loss-lb:0.2817, loss-ulb:0.3429, weight:0.28, lr:0.0009
[01:39:00.132] iteration:2308  t-loss:0.4471, loss-lb:0.3302, loss-ulb:0.4124, weight:0.28, lr:0.0009
[01:39:00.449] iteration:2309  t-loss:0.4973, loss-lb:0.4866, loss-ulb:0.0377, weight:0.28, lr:0.0009
[01:39:00.767] iteration:2310  t-loss:0.4272, loss-lb:0.3065, loss-ulb:0.4258, weight:0.28, lr:0.0009
[01:39:01.089] iteration:2311  t-loss:0.7237, loss-lb:0.6691, loss-ulb:0.1928, weight:0.28, lr:0.0009
[01:39:01.405] iteration:2312  t-loss:0.3435, loss-lb:0.1934, loss-ulb:0.5293, weight:0.28, lr:0.0009
[01:39:01.718] iteration:2313  t-loss:0.3588, loss-lb:0.2927, loss-ulb:0.2331, weight:0.28, lr:0.0009
[01:39:02.040] iteration:2314  t-loss:0.5150, loss-lb:0.4832, loss-ulb:0.1124, weight:0.28, lr:0.0009
[01:39:02.361] iteration:2315  t-loss:0.5710, loss-lb:0.3272, loss-ulb:0.8595, weight:0.28, lr:0.0009
[01:39:02.678] iteration:2316  t-loss:0.3815, loss-lb:0.2040, loss-ulb:0.6256, weight:0.28, lr:0.0009
[01:39:03.006] iteration:2317  t-loss:0.3362, loss-lb:0.2862, loss-ulb:0.1764, weight:0.28, lr:0.0009
[01:39:03.333] iteration:2318  t-loss:0.6381, loss-lb:0.5366, loss-ulb:0.3579, weight:0.28, lr:0.0009
[01:39:03.656] iteration:2319  t-loss:0.3461, loss-lb:0.2999, loss-ulb:0.1628, weight:0.28, lr:0.0009
[01:39:03.980] iteration:2320  t-loss:0.5637, loss-lb:0.3942, loss-ulb:0.5975, weight:0.28, lr:0.0009
[01:39:04.296] iteration:2321  t-loss:0.3283, loss-lb:0.1913, loss-ulb:0.4830, weight:0.28, lr:0.0009
[01:39:04.613] iteration:2322  t-loss:0.3146, loss-lb:0.2473, loss-ulb:0.2372, weight:0.28, lr:0.0009
[01:39:04.927] iteration:2323  t-loss:0.3707, loss-lb:0.3231, loss-ulb:0.1679, weight:0.28, lr:0.0009
[01:39:05.245] iteration:2324  t-loss:0.3510, loss-lb:0.2989, loss-ulb:0.1840, weight:0.28, lr:0.0009
[01:39:05.559] iteration:2325  t-loss:0.3315, loss-lb:0.2699, loss-ulb:0.2174, weight:0.28, lr:0.0009
[01:41:22.239] iteration 2325 : dice_score: 0.786077 best_dice: 0.788800
[01:41:22.239]  <<Test>> - Ep:92  - Dice-S/T:80.11/78.61, Best-S:80.11, Best-T:78.88
[01:41:22.240]           - AvgLoss(lb/ulb/all):0.34/0.33/0.42
[01:41:23.557] iteration:2326  t-loss:0.5140, loss-lb:0.3863, loss-ulb:0.4503, weight:0.28, lr:0.0009
[01:41:23.895] iteration:2327  t-loss:0.5095, loss-lb:0.2791, loss-ulb:0.8121, weight:0.28, lr:0.0009
[01:41:24.216] iteration:2328  t-loss:0.7940, loss-lb:0.3850, loss-ulb:1.4420, weight:0.28, lr:0.0009
[01:41:24.541] iteration:2329  t-loss:0.5984, loss-lb:0.4885, loss-ulb:0.3872, weight:0.28, lr:0.0009
[01:41:24.862] iteration:2330  t-loss:0.4760, loss-lb:0.4079, loss-ulb:0.2401, weight:0.28, lr:0.0009
[01:41:25.179] iteration:2331  t-loss:0.3341, loss-lb:0.2861, loss-ulb:0.1691, weight:0.28, lr:0.0009
[01:41:25.496] iteration:2332  t-loss:0.5288, loss-lb:0.2076, loss-ulb:1.1323, weight:0.28, lr:0.0009
[01:41:25.818] iteration:2333  t-loss:0.5157, loss-lb:0.4804, loss-ulb:0.1244, weight:0.28, lr:0.0009
[01:41:26.141] iteration:2334  t-loss:0.3274, loss-lb:0.2385, loss-ulb:0.3135, weight:0.28, lr:0.0009
[01:41:26.457] iteration:2335  t-loss:0.2657, loss-lb:0.2347, loss-ulb:0.1091, weight:0.28, lr:0.0009
[01:41:26.771] iteration:2336  t-loss:0.4683, loss-lb:0.2486, loss-ulb:0.7746, weight:0.28, lr:0.0009
[01:41:27.088] iteration:2337  t-loss:0.2824, loss-lb:0.2640, loss-ulb:0.0647, weight:0.28, lr:0.0009
[01:41:27.406] iteration:2338  t-loss:0.2518, loss-lb:0.1877, loss-ulb:0.2260, weight:0.28, lr:0.0009
[01:41:27.721] iteration:2339  t-loss:0.3441, loss-lb:0.2276, loss-ulb:0.4108, weight:0.28, lr:0.0009
[01:41:28.039] iteration:2340  t-loss:0.4276, loss-lb:0.3096, loss-ulb:0.4161, weight:0.28, lr:0.0009
[01:41:28.356] iteration:2341  t-loss:0.4073, loss-lb:0.2709, loss-ulb:0.4808, weight:0.28, lr:0.0009
[01:41:28.674] iteration:2342  t-loss:0.2858, loss-lb:0.2268, loss-ulb:0.2078, weight:0.28, lr:0.0009
[01:41:28.989] iteration:2343  t-loss:0.4197, loss-lb:0.3285, loss-ulb:0.3216, weight:0.28, lr:0.0009
[01:41:29.299] iteration:2344  t-loss:0.3934, loss-lb:0.2789, loss-ulb:0.4038, weight:0.28, lr:0.0009
[01:41:29.615] iteration:2345  t-loss:0.2380, loss-lb:0.1904, loss-ulb:0.1678, weight:0.28, lr:0.0009
[01:41:29.929] iteration:2346  t-loss:0.3003, loss-lb:0.2837, loss-ulb:0.0584, weight:0.28, lr:0.0009
[01:41:30.248] iteration:2347  t-loss:0.5579, loss-lb:0.5187, loss-ulb:0.1382, weight:0.28, lr:0.0009
[01:41:30.563] iteration:2348  t-loss:0.2294, loss-lb:0.1991, loss-ulb:0.1070, weight:0.28, lr:0.0009
[01:41:30.879] iteration:2349  t-loss:0.2147, loss-lb:0.1982, loss-ulb:0.0582, weight:0.28, lr:0.0009
[01:41:31.199] iteration:2350  t-loss:0.3222, loss-lb:0.3136, loss-ulb:0.0302, weight:0.28, lr:0.0009
[01:41:32.435] iteration:2351  t-loss:0.2814, loss-lb:0.2719, loss-ulb:0.0333, weight:0.28, lr:0.0009
[01:41:32.785] iteration:2352  t-loss:0.6175, loss-lb:0.5355, loss-ulb:0.2890, weight:0.28, lr:0.0009
[01:41:33.124] iteration:2353  t-loss:0.3389, loss-lb:0.2446, loss-ulb:0.3324, weight:0.28, lr:0.0009
[01:41:33.457] iteration:2354  t-loss:0.2633, loss-lb:0.2069, loss-ulb:0.1988, weight:0.28, lr:0.0009
[01:41:33.782] iteration:2355  t-loss:0.4274, loss-lb:0.3875, loss-ulb:0.1406, weight:0.28, lr:0.0009
[01:41:34.102] iteration:2356  t-loss:0.3082, loss-lb:0.2735, loss-ulb:0.1223, weight:0.28, lr:0.0009
[01:41:34.423] iteration:2357  t-loss:0.3640, loss-lb:0.3184, loss-ulb:0.1606, weight:0.28, lr:0.0009
[01:41:34.747] iteration:2358  t-loss:0.4885, loss-lb:0.4594, loss-ulb:0.1027, weight:0.28, lr:0.0009
[01:41:35.067] iteration:2359  t-loss:0.1968, loss-lb:0.1648, loss-ulb:0.1126, weight:0.28, lr:0.0009
[01:41:35.382] iteration:2360  t-loss:0.4463, loss-lb:0.2693, loss-ulb:0.6238, weight:0.28, lr:0.0009
[01:41:35.704] iteration:2361  t-loss:0.3606, loss-lb:0.2871, loss-ulb:0.2593, weight:0.28, lr:0.0009
[01:41:36.021] iteration:2362  t-loss:0.5198, loss-lb:0.3495, loss-ulb:0.6007, weight:0.28, lr:0.0009
[01:41:36.345] iteration:2363  t-loss:0.4846, loss-lb:0.4264, loss-ulb:0.2054, weight:0.28, lr:0.0009
[01:41:36.666] iteration:2364  t-loss:0.4600, loss-lb:0.2916, loss-ulb:0.5936, weight:0.28, lr:0.0009
[01:41:36.985] iteration:2365  t-loss:0.2166, loss-lb:0.1803, loss-ulb:0.1281, weight:0.28, lr:0.0009
[01:41:37.303] iteration:2366  t-loss:0.3039, loss-lb:0.2634, loss-ulb:0.1427, weight:0.28, lr:0.0009
[01:41:37.646] iteration:2367  t-loss:0.3387, loss-lb:0.2969, loss-ulb:0.1473, weight:0.28, lr:0.0009
[01:41:37.962] iteration:2368  t-loss:0.3537, loss-lb:0.2764, loss-ulb:0.2726, weight:0.28, lr:0.0009
[01:41:38.274] iteration:2369  t-loss:0.2057, loss-lb:0.1855, loss-ulb:0.0712, weight:0.28, lr:0.0009
[01:41:38.587] iteration:2370  t-loss:0.4395, loss-lb:0.3497, loss-ulb:0.3165, weight:0.28, lr:0.0009
[01:41:38.906] iteration:2371  t-loss:0.2734, loss-lb:0.2068, loss-ulb:0.2350, weight:0.28, lr:0.0009
[01:41:39.217] iteration:2372  t-loss:0.5727, loss-lb:0.5344, loss-ulb:0.1347, weight:0.28, lr:0.0009
[01:41:39.530] iteration:2373  t-loss:0.3371, loss-lb:0.3036, loss-ulb:0.1183, weight:0.28, lr:0.0009
[01:41:39.848] iteration:2374  t-loss:0.6627, loss-lb:0.5799, loss-ulb:0.2920, weight:0.28, lr:0.0009
[01:41:40.165] iteration:2375  t-loss:0.6858, loss-lb:0.6301, loss-ulb:0.1966, weight:0.28, lr:0.0009
[01:41:41.488] iteration:2376  t-loss:0.3060, loss-lb:0.2261, loss-ulb:0.2816, weight:0.28, lr:0.0009
[01:41:41.827] iteration:2377  t-loss:0.3381, loss-lb:0.2601, loss-ulb:0.2752, weight:0.28, lr:0.0009
[01:41:42.157] iteration:2378  t-loss:0.2731, loss-lb:0.2310, loss-ulb:0.1485, weight:0.28, lr:0.0009
[01:41:42.483] iteration:2379  t-loss:0.4939, loss-lb:0.3739, loss-ulb:0.4233, weight:0.28, lr:0.0009
[01:41:42.799] iteration:2380  t-loss:0.3389, loss-lb:0.1761, loss-ulb:0.5742, weight:0.28, lr:0.0009
[01:41:43.131] iteration:2381  t-loss:0.2617, loss-lb:0.1959, loss-ulb:0.2320, weight:0.28, lr:0.0009
[01:41:43.445] iteration:2382  t-loss:0.2484, loss-lb:0.2171, loss-ulb:0.1105, weight:0.28, lr:0.0009
[01:41:43.765] iteration:2383  t-loss:0.4813, loss-lb:0.4253, loss-ulb:0.1973, weight:0.28, lr:0.0009
[01:41:44.084] iteration:2384  t-loss:0.2097, loss-lb:0.1965, loss-ulb:0.0467, weight:0.28, lr:0.0009
[01:41:44.398] iteration:2385  t-loss:0.3312, loss-lb:0.2971, loss-ulb:0.1202, weight:0.28, lr:0.0009
[01:41:44.716] iteration:2386  t-loss:0.3572, loss-lb:0.3129, loss-ulb:0.1562, weight:0.28, lr:0.0009
[01:41:45.031] iteration:2387  t-loss:0.2597, loss-lb:0.1732, loss-ulb:0.3050, weight:0.28, lr:0.0009
[01:41:45.353] iteration:2388  t-loss:0.2787, loss-lb:0.2154, loss-ulb:0.2231, weight:0.28, lr:0.0009
[01:41:45.674] iteration:2389  t-loss:0.4107, loss-lb:0.3007, loss-ulb:0.3878, weight:0.28, lr:0.0009
[01:41:45.991] iteration:2390  t-loss:0.2955, loss-lb:0.2677, loss-ulb:0.0979, weight:0.28, lr:0.0009
[01:41:46.312] iteration:2391  t-loss:0.2696, loss-lb:0.2152, loss-ulb:0.1916, weight:0.28, lr:0.0009
[01:41:46.633] iteration:2392  t-loss:0.2886, loss-lb:0.2052, loss-ulb:0.2941, weight:0.28, lr:0.0009
[01:41:46.953] iteration:2393  t-loss:0.6010, loss-lb:0.4198, loss-ulb:0.6389, weight:0.28, lr:0.0009
[01:41:47.264] iteration:2394  t-loss:0.4332, loss-lb:0.3314, loss-ulb:0.3589, weight:0.28, lr:0.0009
[01:41:47.580] iteration:2395  t-loss:0.2371, loss-lb:0.2141, loss-ulb:0.0810, weight:0.28, lr:0.0009
[01:41:47.897] iteration:2396  t-loss:0.3560, loss-lb:0.2934, loss-ulb:0.2206, weight:0.28, lr:0.0009
[01:41:48.215] iteration:2397  t-loss:0.2592, loss-lb:0.2076, loss-ulb:0.1818, weight:0.28, lr:0.0009
[01:41:48.529] iteration:2398  t-loss:0.4073, loss-lb:0.3715, loss-ulb:0.1262, weight:0.28, lr:0.0009
[01:41:48.844] iteration:2399  t-loss:0.3470, loss-lb:0.3138, loss-ulb:0.1168, weight:0.28, lr:0.0009
[01:41:49.159] iteration:2400  t-loss:0.4755, loss-lb:0.3298, loss-ulb:0.5137, weight:0.28, lr:0.0009
[01:41:50.595] iteration:2401  t-loss:0.5108, loss-lb:0.3504, loss-ulb:0.4850, weight:0.33, lr:0.0009
[01:41:50.922] iteration:2402  t-loss:0.3537, loss-lb:0.2168, loss-ulb:0.4141, weight:0.33, lr:0.0009
[01:41:51.256] iteration:2403  t-loss:0.5263, loss-lb:0.4311, loss-ulb:0.2880, weight:0.33, lr:0.0009
[01:41:51.580] iteration:2404  t-loss:0.6553, loss-lb:0.4036, loss-ulb:0.7612, weight:0.33, lr:0.0009
[01:41:51.905] iteration:2405  t-loss:0.4288, loss-lb:0.3615, loss-ulb:0.2037, weight:0.33, lr:0.0009
[01:41:52.220] iteration:2406  t-loss:0.2648, loss-lb:0.2405, loss-ulb:0.0733, weight:0.33, lr:0.0009
[01:41:52.542] iteration:2407  t-loss:0.4457, loss-lb:0.4190, loss-ulb:0.0808, weight:0.33, lr:0.0009
[01:41:52.861] iteration:2408  t-loss:0.4853, loss-lb:0.4282, loss-ulb:0.1727, weight:0.33, lr:0.0009
[01:41:53.178] iteration:2409  t-loss:0.2315, loss-lb:0.2157, loss-ulb:0.0479, weight:0.33, lr:0.0009
[01:41:53.502] iteration:2410  t-loss:0.5610, loss-lb:0.3282, loss-ulb:0.7042, weight:0.33, lr:0.0009
[01:41:53.820] iteration:2411  t-loss:0.4821, loss-lb:0.3033, loss-ulb:0.5407, weight:0.33, lr:0.0009
[01:41:54.141] iteration:2412  t-loss:0.2526, loss-lb:0.2205, loss-ulb:0.0971, weight:0.33, lr:0.0009
[01:41:54.458] iteration:2413  t-loss:0.3133, loss-lb:0.2184, loss-ulb:0.2871, weight:0.33, lr:0.0009
[01:41:54.777] iteration:2414  t-loss:0.4027, loss-lb:0.3219, loss-ulb:0.2444, weight:0.33, lr:0.0009
[01:41:55.096] iteration:2415  t-loss:0.3199, loss-lb:0.2309, loss-ulb:0.2691, weight:0.33, lr:0.0009
[01:41:55.412] iteration:2416  t-loss:0.2907, loss-lb:0.2575, loss-ulb:0.1004, weight:0.33, lr:0.0009
[01:41:55.733] iteration:2417  t-loss:0.4319, loss-lb:0.3153, loss-ulb:0.3526, weight:0.33, lr:0.0009
[01:41:56.049] iteration:2418  t-loss:0.4623, loss-lb:0.3209, loss-ulb:0.4277, weight:0.33, lr:0.0009
[01:41:56.364] iteration:2419  t-loss:0.3579, loss-lb:0.3106, loss-ulb:0.1430, weight:0.33, lr:0.0009
[01:41:56.682] iteration:2420  t-loss:0.2950, loss-lb:0.2360, loss-ulb:0.1784, weight:0.33, lr:0.0009
[01:41:56.995] iteration:2421  t-loss:0.3137, loss-lb:0.1355, loss-ulb:0.5392, weight:0.33, lr:0.0009
[01:41:57.311] iteration:2422  t-loss:0.4143, loss-lb:0.2463, loss-ulb:0.5083, weight:0.33, lr:0.0009
[01:41:57.628] iteration:2423  t-loss:0.5448, loss-lb:0.4827, loss-ulb:0.1878, weight:0.33, lr:0.0009
[01:41:57.945] iteration:2424  t-loss:0.5065, loss-lb:0.2015, loss-ulb:0.9225, weight:0.33, lr:0.0009
[01:41:58.264] iteration:2425  t-loss:0.5284, loss-lb:0.4780, loss-ulb:0.1523, weight:0.33, lr:0.0009
[01:44:07.864] iteration 2425 : dice_score: 0.789530 best_dice: 0.789500
[01:44:07.865]  <<Test>> - Ep:96  - Dice-S/T:78.52/78.95, Best-S:80.11, Best-T:78.95
[01:44:07.865]           - AvgLoss(lb/ulb/all):0.31/0.30/0.40
[01:44:09.004] iteration:2426  t-loss:0.6572, loss-lb:0.4831, loss-ulb:0.5266, weight:0.33, lr:0.0009
[01:44:09.340] iteration:2427  t-loss:0.3845, loss-lb:0.2710, loss-ulb:0.3432, weight:0.33, lr:0.0009
[01:44:09.662] iteration:2428  t-loss:0.5447, loss-lb:0.5084, loss-ulb:0.1098, weight:0.33, lr:0.0009
[01:44:09.982] iteration:2429  t-loss:0.3714, loss-lb:0.2468, loss-ulb:0.3768, weight:0.33, lr:0.0009
[01:44:10.305] iteration:2430  t-loss:0.4112, loss-lb:0.3486, loss-ulb:0.1894, weight:0.33, lr:0.0009
[01:44:10.626] iteration:2431  t-loss:0.6102, loss-lb:0.4377, loss-ulb:0.5219, weight:0.33, lr:0.0009
[01:44:10.945] iteration:2432  t-loss:0.2610, loss-lb:0.2305, loss-ulb:0.0922, weight:0.33, lr:0.0009
[01:44:11.264] iteration:2433  t-loss:0.5350, loss-lb:0.4412, loss-ulb:0.2837, weight:0.33, lr:0.0009
[01:44:11.589] iteration:2434  t-loss:0.5662, loss-lb:0.5284, loss-ulb:0.1145, weight:0.33, lr:0.0009
[01:44:11.911] iteration:2435  t-loss:0.5292, loss-lb:0.2764, loss-ulb:0.7646, weight:0.33, lr:0.0009
[01:44:12.235] iteration:2436  t-loss:0.3956, loss-lb:0.3141, loss-ulb:0.2465, weight:0.33, lr:0.0009
[01:44:12.551] iteration:2437  t-loss:0.3755, loss-lb:0.2011, loss-ulb:0.5275, weight:0.33, lr:0.0009
[01:44:12.870] iteration:2438  t-loss:0.2325, loss-lb:0.2035, loss-ulb:0.0877, weight:0.33, lr:0.0009
[01:44:13.192] iteration:2439  t-loss:0.3563, loss-lb:0.2468, loss-ulb:0.3313, weight:0.33, lr:0.0009
[01:44:13.514] iteration:2440  t-loss:0.5868, loss-lb:0.3803, loss-ulb:0.6246, weight:0.33, lr:0.0009
[01:44:13.838] iteration:2441  t-loss:0.5728, loss-lb:0.4384, loss-ulb:0.4066, weight:0.33, lr:0.0009
[01:44:14.162] iteration:2442  t-loss:0.3915, loss-lb:0.2500, loss-ulb:0.4280, weight:0.33, lr:0.0009
[01:44:14.475] iteration:2443  t-loss:0.3031, loss-lb:0.2590, loss-ulb:0.1334, weight:0.33, lr:0.0009
[01:44:14.791] iteration:2444  t-loss:0.3250, loss-lb:0.2940, loss-ulb:0.0936, weight:0.33, lr:0.0009
[01:44:15.108] iteration:2445  t-loss:0.6210, loss-lb:0.6005, loss-ulb:0.0619, weight:0.33, lr:0.0009
[01:44:15.421] iteration:2446  t-loss:0.3466, loss-lb:0.2628, loss-ulb:0.2536, weight:0.33, lr:0.0009
[01:44:15.735] iteration:2447  t-loss:0.5212, loss-lb:0.4668, loss-ulb:0.1644, weight:0.33, lr:0.0009
[01:44:16.050] iteration:2448  t-loss:0.2099, loss-lb:0.1772, loss-ulb:0.0989, weight:0.33, lr:0.0009
[01:44:16.364] iteration:2449  t-loss:0.3506, loss-lb:0.2126, loss-ulb:0.4174, weight:0.33, lr:0.0009
[01:44:16.680] iteration:2450  t-loss:0.4033, loss-lb:0.3108, loss-ulb:0.2798, weight:0.33, lr:0.0009
[01:44:17.972] iteration:2451  t-loss:0.2906, loss-lb:0.2346, loss-ulb:0.1693, weight:0.33, lr:0.0009
[01:44:18.302] iteration:2452  t-loss:0.2204, loss-lb:0.2081, loss-ulb:0.0372, weight:0.33, lr:0.0009
[01:44:18.620] iteration:2453  t-loss:0.3251, loss-lb:0.2797, loss-ulb:0.1372, weight:0.33, lr:0.0009
[01:44:18.936] iteration:2454  t-loss:0.4558, loss-lb:0.2754, loss-ulb:0.5455, weight:0.33, lr:0.0009
[01:44:19.252] iteration:2455  t-loss:0.2135, loss-lb:0.1791, loss-ulb:0.1041, weight:0.33, lr:0.0009
[01:44:19.597] iteration:2456  t-loss:0.5143, loss-lb:0.4628, loss-ulb:0.1558, weight:0.33, lr:0.0009
[01:44:19.915] iteration:2457  t-loss:0.4268, loss-lb:0.3905, loss-ulb:0.1099, weight:0.33, lr:0.0009
[01:44:20.234] iteration:2458  t-loss:0.3376, loss-lb:0.2150, loss-ulb:0.3708, weight:0.33, lr:0.0009
[01:44:20.550] iteration:2459  t-loss:0.2685, loss-lb:0.2078, loss-ulb:0.1837, weight:0.33, lr:0.0009
[01:44:20.871] iteration:2460  t-loss:0.3561, loss-lb:0.3354, loss-ulb:0.0627, weight:0.33, lr:0.0009
[01:44:21.193] iteration:2461  t-loss:0.3891, loss-lb:0.3177, loss-ulb:0.2160, weight:0.33, lr:0.0009
[01:44:21.522] iteration:2462  t-loss:0.4401, loss-lb:0.3278, loss-ulb:0.3397, weight:0.33, lr:0.0009
[01:44:21.843] iteration:2463  t-loss:0.3805, loss-lb:0.3302, loss-ulb:0.1520, weight:0.33, lr:0.0009
[01:44:22.170] iteration:2464  t-loss:0.3304, loss-lb:0.2810, loss-ulb:0.1494, weight:0.33, lr:0.0009
[01:44:22.491] iteration:2465  t-loss:0.5414, loss-lb:0.2217, loss-ulb:0.9671, weight:0.33, lr:0.0009
[01:44:22.808] iteration:2466  t-loss:0.4313, loss-lb:0.3103, loss-ulb:0.3658, weight:0.33, lr:0.0009
[01:44:23.133] iteration:2467  t-loss:1.0109, loss-lb:0.8649, loss-ulb:0.4418, weight:0.33, lr:0.0009
[01:44:23.446] iteration:2468  t-loss:0.4139, loss-lb:0.2033, loss-ulb:0.6371, weight:0.33, lr:0.0009
[01:44:23.763] iteration:2469  t-loss:0.3195, loss-lb:0.2852, loss-ulb:0.1040, weight:0.33, lr:0.0009
[01:44:24.081] iteration:2470  t-loss:0.5164, loss-lb:0.3336, loss-ulb:0.5530, weight:0.33, lr:0.0009
[01:44:24.400] iteration:2471  t-loss:0.5205, loss-lb:0.3217, loss-ulb:0.6011, weight:0.33, lr:0.0009
[01:44:24.718] iteration:2472  t-loss:0.4665, loss-lb:0.3876, loss-ulb:0.2388, weight:0.33, lr:0.0009
[01:44:25.038] iteration:2473  t-loss:0.3037, loss-lb:0.2395, loss-ulb:0.1941, weight:0.33, lr:0.0009
[01:44:25.352] iteration:2474  t-loss:0.4410, loss-lb:0.2581, loss-ulb:0.5532, weight:0.33, lr:0.0009
[01:44:25.666] iteration:2475  t-loss:0.4648, loss-lb:0.4533, loss-ulb:0.0349, weight:0.33, lr:0.0009
[01:44:27.178] iteration:2476  t-loss:0.3188, loss-lb:0.2418, loss-ulb:0.2331, weight:0.33, lr:0.0009
[01:44:27.531] iteration:2477  t-loss:0.4486, loss-lb:0.4309, loss-ulb:0.0536, weight:0.33, lr:0.0009
[01:44:27.860] iteration:2478  t-loss:0.2789, loss-lb:0.2345, loss-ulb:0.1342, weight:0.33, lr:0.0009
[01:44:28.194] iteration:2479  t-loss:0.5075, loss-lb:0.3941, loss-ulb:0.3430, weight:0.33, lr:0.0009
[01:44:28.518] iteration:2480  t-loss:0.2853, loss-lb:0.2357, loss-ulb:0.1500, weight:0.33, lr:0.0008
[01:44:28.836] iteration:2481  t-loss:0.3548, loss-lb:0.2859, loss-ulb:0.2084, weight:0.33, lr:0.0008
[01:44:29.157] iteration:2482  t-loss:0.3546, loss-lb:0.2512, loss-ulb:0.3127, weight:0.33, lr:0.0008
[01:44:29.481] iteration:2483  t-loss:0.2879, loss-lb:0.2601, loss-ulb:0.0843, weight:0.33, lr:0.0008
[01:44:29.811] iteration:2484  t-loss:0.3395, loss-lb:0.2999, loss-ulb:0.1200, weight:0.33, lr:0.0008
[01:44:30.135] iteration:2485  t-loss:0.4320, loss-lb:0.2506, loss-ulb:0.5487, weight:0.33, lr:0.0008
[01:44:30.455] iteration:2486  t-loss:0.4269, loss-lb:0.3572, loss-ulb:0.2106, weight:0.33, lr:0.0008
[01:44:30.776] iteration:2487  t-loss:0.3169, loss-lb:0.2251, loss-ulb:0.2779, weight:0.33, lr:0.0008
[01:44:31.094] iteration:2488  t-loss:0.2988, loss-lb:0.2289, loss-ulb:0.2116, weight:0.33, lr:0.0008
[01:44:31.412] iteration:2489  t-loss:0.2759, loss-lb:0.2154, loss-ulb:0.1832, weight:0.33, lr:0.0008
[01:44:31.736] iteration:2490  t-loss:0.3629, loss-lb:0.3038, loss-ulb:0.1788, weight:0.33, lr:0.0008
[01:44:32.059] iteration:2491  t-loss:0.5274, loss-lb:0.3177, loss-ulb:0.6343, weight:0.33, lr:0.0008
[01:44:32.381] iteration:2492  t-loss:0.3435, loss-lb:0.2273, loss-ulb:0.3514, weight:0.33, lr:0.0008
[01:44:32.694] iteration:2493  t-loss:0.5615, loss-lb:0.4275, loss-ulb:0.4054, weight:0.33, lr:0.0008
[01:44:33.006] iteration:2494  t-loss:0.2684, loss-lb:0.2128, loss-ulb:0.1684, weight:0.33, lr:0.0008
[01:44:33.322] iteration:2495  t-loss:0.3098, loss-lb:0.2304, loss-ulb:0.2402, weight:0.33, lr:0.0008
[01:44:33.633] iteration:2496  t-loss:0.3090, loss-lb:0.2653, loss-ulb:0.1322, weight:0.33, lr:0.0008
[01:44:33.945] iteration:2497  t-loss:0.2371, loss-lb:0.1905, loss-ulb:0.1412, weight:0.33, lr:0.0008
[01:44:34.256] iteration:2498  t-loss:0.4749, loss-lb:0.4485, loss-ulb:0.0799, weight:0.33, lr:0.0008
[01:44:34.568] iteration:2499  t-loss:0.4478, loss-lb:0.2764, loss-ulb:0.5183, weight:0.33, lr:0.0008
[01:44:34.880] iteration:2500  t-loss:0.3914, loss-lb:0.2107, loss-ulb:0.5464, weight:0.33, lr:0.0008
[01:44:36.132] iteration:2501  t-loss:0.3295, loss-lb:0.2404, loss-ulb:0.2694, weight:0.33, lr:0.0008
[01:44:36.483] iteration:2502  t-loss:0.4017, loss-lb:0.3420, loss-ulb:0.1806, weight:0.33, lr:0.0008
[01:44:36.822] iteration:2503  t-loss:0.2758, loss-lb:0.2614, loss-ulb:0.0437, weight:0.33, lr:0.0008
[01:44:37.156] iteration:2504  t-loss:0.2366, loss-lb:0.1642, loss-ulb:0.2191, weight:0.33, lr:0.0008
[01:44:37.486] iteration:2505  t-loss:0.3344, loss-lb:0.2805, loss-ulb:0.1629, weight:0.33, lr:0.0008
[01:44:37.808] iteration:2506  t-loss:0.2051, loss-lb:0.1818, loss-ulb:0.0707, weight:0.33, lr:0.0008
[01:44:38.126] iteration:2507  t-loss:0.3569, loss-lb:0.2917, loss-ulb:0.1971, weight:0.33, lr:0.0008
[01:44:38.446] iteration:2508  t-loss:0.5791, loss-lb:0.4665, loss-ulb:0.3407, weight:0.33, lr:0.0008
[01:44:38.766] iteration:2509  t-loss:0.5545, loss-lb:0.3486, loss-ulb:0.6227, weight:0.33, lr:0.0008
[01:44:39.083] iteration:2510  t-loss:0.5023, loss-lb:0.4286, loss-ulb:0.2230, weight:0.33, lr:0.0008
[01:44:39.403] iteration:2511  t-loss:0.3410, loss-lb:0.2662, loss-ulb:0.2260, weight:0.33, lr:0.0008
[01:44:39.728] iteration:2512  t-loss:0.2728, loss-lb:0.2057, loss-ulb:0.2031, weight:0.33, lr:0.0008
[01:44:40.064] iteration:2513  t-loss:0.3914, loss-lb:0.2706, loss-ulb:0.3653, weight:0.33, lr:0.0008
[01:44:40.391] iteration:2514  t-loss:0.5468, loss-lb:0.4309, loss-ulb:0.3503, weight:0.33, lr:0.0008
[01:44:40.716] iteration:2515  t-loss:0.3028, loss-lb:0.2872, loss-ulb:0.0470, weight:0.33, lr:0.0008
[01:44:41.039] iteration:2516  t-loss:0.2644, loss-lb:0.2313, loss-ulb:0.1001, weight:0.33, lr:0.0008
[01:44:41.362] iteration:2517  t-loss:0.2988, loss-lb:0.2592, loss-ulb:0.1197, weight:0.33, lr:0.0008
[01:44:41.679] iteration:2518  t-loss:0.4668, loss-lb:0.3237, loss-ulb:0.4330, weight:0.33, lr:0.0008
[01:44:41.995] iteration:2519  t-loss:0.5335, loss-lb:0.4197, loss-ulb:0.3443, weight:0.33, lr:0.0008
[01:44:42.317] iteration:2520  t-loss:0.2851, loss-lb:0.2363, loss-ulb:0.1476, weight:0.33, lr:0.0008
[01:44:42.632] iteration:2521  t-loss:0.3201, loss-lb:0.1599, loss-ulb:0.4845, weight:0.33, lr:0.0008
[01:44:42.956] iteration:2522  t-loss:0.6394, loss-lb:0.5070, loss-ulb:0.4005, weight:0.33, lr:0.0008
[01:44:43.269] iteration:2523  t-loss:0.5763, loss-lb:0.4862, loss-ulb:0.2727, weight:0.33, lr:0.0008
[01:44:43.586] iteration:2524  t-loss:0.4692, loss-lb:0.3296, loss-ulb:0.4222, weight:0.33, lr:0.0008
[01:44:43.903] iteration:2525  t-loss:0.3296, loss-lb:0.2887, loss-ulb:0.1237, weight:0.33, lr:0.0008
[01:47:00.066] iteration 2525 : dice_score: 0.800215 best_dice: 0.800200
[01:47:00.066]  <<Test>> - Ep:100  - Dice-S/T:74.91/80.02, Best-S:80.11, Best-T:80.02
[01:47:00.066]           - AvgLoss(lb/ulb/all):0.31/0.27/0.41
[01:47:01.507] iteration:2526  t-loss:0.3705, loss-lb:0.3440, loss-ulb:0.0804, weight:0.33, lr:0.0008
[01:47:01.840] iteration:2527  t-loss:0.3065, loss-lb:0.2097, loss-ulb:0.2929, weight:0.33, lr:0.0008
[01:47:02.166] iteration:2528  t-loss:0.4107, loss-lb:0.3420, loss-ulb:0.2077, weight:0.33, lr:0.0008
[01:47:02.487] iteration:2529  t-loss:0.5211, loss-lb:0.4827, loss-ulb:0.1161, weight:0.33, lr:0.0008
[01:47:02.805] iteration:2530  t-loss:0.3999, loss-lb:0.3796, loss-ulb:0.0615, weight:0.33, lr:0.0008
[01:47:03.137] iteration:2531  t-loss:0.3865, loss-lb:0.3075, loss-ulb:0.2388, weight:0.33, lr:0.0008
[01:47:03.480] iteration:2532  t-loss:0.2599, loss-lb:0.1793, loss-ulb:0.2438, weight:0.33, lr:0.0008
[01:47:03.813] iteration:2533  t-loss:0.5309, loss-lb:0.3764, loss-ulb:0.4674, weight:0.33, lr:0.0008
[01:47:04.151] iteration:2534  t-loss:0.3358, loss-lb:0.2936, loss-ulb:0.1276, weight:0.33, lr:0.0008
[01:47:04.497] iteration:2535  t-loss:0.6283, loss-lb:0.3960, loss-ulb:0.7027, weight:0.33, lr:0.0008
[01:47:04.839] iteration:2536  t-loss:0.5193, loss-lb:0.4083, loss-ulb:0.3359, weight:0.33, lr:0.0008
[01:47:05.171] iteration:2537  t-loss:0.3336, loss-lb:0.2074, loss-ulb:0.3817, weight:0.33, lr:0.0008
[01:47:05.512] iteration:2538  t-loss:0.3685, loss-lb:0.3411, loss-ulb:0.0827, weight:0.33, lr:0.0008
[01:47:05.844] iteration:2539  t-loss:0.4377, loss-lb:0.2325, loss-ulb:0.6207, weight:0.33, lr:0.0008
[01:47:06.178] iteration:2540  t-loss:0.3672, loss-lb:0.3351, loss-ulb:0.0972, weight:0.33, lr:0.0008
[01:47:06.504] iteration:2541  t-loss:0.3809, loss-lb:0.2734, loss-ulb:0.3252, weight:0.33, lr:0.0008
[01:47:06.836] iteration:2542  t-loss:0.4165, loss-lb:0.3719, loss-ulb:0.1348, weight:0.33, lr:0.0008
[01:47:07.155] iteration:2543  t-loss:0.3071, loss-lb:0.2459, loss-ulb:0.1852, weight:0.33, lr:0.0008
[01:47:07.471] iteration:2544  t-loss:0.4181, loss-lb:0.2662, loss-ulb:0.4593, weight:0.33, lr:0.0008
[01:47:07.786] iteration:2545  t-loss:0.6483, loss-lb:0.4059, loss-ulb:0.7332, weight:0.33, lr:0.0008
[01:47:08.097] iteration:2546  t-loss:0.2700, loss-lb:0.2500, loss-ulb:0.0607, weight:0.33, lr:0.0008
[01:47:08.410] iteration:2547  t-loss:0.3895, loss-lb:0.3380, loss-ulb:0.1555, weight:0.33, lr:0.0008
[01:47:08.720] iteration:2548  t-loss:0.2508, loss-lb:0.2167, loss-ulb:0.1031, weight:0.33, lr:0.0008
[01:47:09.031] iteration:2549  t-loss:0.7199, loss-lb:0.6614, loss-ulb:0.1769, weight:0.33, lr:0.0008
[01:47:09.341] iteration:2550  t-loss:0.2113, loss-lb:0.1914, loss-ulb:0.0604, weight:0.33, lr:0.0008
[01:47:10.588] iteration:2551  t-loss:0.2964, loss-lb:0.2636, loss-ulb:0.0856, weight:0.38, lr:0.0008
[01:47:10.917] iteration:2552  t-loss:0.3708, loss-lb:0.2942, loss-ulb:0.2000, weight:0.38, lr:0.0008
[01:47:11.238] iteration:2553  t-loss:0.4989, loss-lb:0.3558, loss-ulb:0.3738, weight:0.38, lr:0.0008
[01:47:11.553] iteration:2554  t-loss:0.4683, loss-lb:0.3384, loss-ulb:0.3393, weight:0.38, lr:0.0008
[01:47:11.863] iteration:2555  t-loss:0.3711, loss-lb:0.2318, loss-ulb:0.3637, weight:0.38, lr:0.0008
[01:47:12.179] iteration:2556  t-loss:0.4142, loss-lb:0.3376, loss-ulb:0.2001, weight:0.38, lr:0.0008
[01:47:12.503] iteration:2557  t-loss:0.5987, loss-lb:0.5061, loss-ulb:0.2418, weight:0.38, lr:0.0008
[01:47:12.837] iteration:2558  t-loss:0.6978, loss-lb:0.5445, loss-ulb:0.4003, weight:0.38, lr:0.0008
[01:47:13.173] iteration:2559  t-loss:0.4557, loss-lb:0.3629, loss-ulb:0.2423, weight:0.38, lr:0.0008
[01:47:13.512] iteration:2560  t-loss:0.6431, loss-lb:0.3973, loss-ulb:0.6420, weight:0.38, lr:0.0008
[01:47:13.856] iteration:2561  t-loss:0.4947, loss-lb:0.2153, loss-ulb:0.7295, weight:0.38, lr:0.0008
[01:47:14.193] iteration:2562  t-loss:0.5553, loss-lb:0.5104, loss-ulb:0.1171, weight:0.38, lr:0.0008
[01:47:14.525] iteration:2563  t-loss:0.5390, loss-lb:0.3297, loss-ulb:0.5465, weight:0.38, lr:0.0008
[01:47:14.855] iteration:2564  t-loss:0.2903, loss-lb:0.2235, loss-ulb:0.1746, weight:0.38, lr:0.0008
[01:47:15.188] iteration:2565  t-loss:0.3711, loss-lb:0.2700, loss-ulb:0.2642, weight:0.38, lr:0.0008
[01:47:15.520] iteration:2566  t-loss:0.3484, loss-lb:0.2947, loss-ulb:0.1401, weight:0.38, lr:0.0008
[01:47:15.843] iteration:2567  t-loss:0.5028, loss-lb:0.3781, loss-ulb:0.3258, weight:0.38, lr:0.0008
[01:47:16.167] iteration:2568  t-loss:0.5174, loss-lb:0.3903, loss-ulb:0.3320, weight:0.38, lr:0.0008
[01:47:16.479] iteration:2569  t-loss:0.2410, loss-lb:0.1829, loss-ulb:0.1518, weight:0.38, lr:0.0008
[01:47:16.789] iteration:2570  t-loss:0.3433, loss-lb:0.3026, loss-ulb:0.1064, weight:0.38, lr:0.0008
[01:47:17.109] iteration:2571  t-loss:0.4850, loss-lb:0.4004, loss-ulb:0.2209, weight:0.38, lr:0.0008
[01:47:17.422] iteration:2572  t-loss:0.5242, loss-lb:0.3952, loss-ulb:0.3369, weight:0.38, lr:0.0008
[01:47:17.732] iteration:2573  t-loss:0.3244, loss-lb:0.2320, loss-ulb:0.2413, weight:0.38, lr:0.0008
[01:47:18.043] iteration:2574  t-loss:0.5263, loss-lb:0.5134, loss-ulb:0.0338, weight:0.38, lr:0.0008
[01:47:18.352] iteration:2575  t-loss:0.2817, loss-lb:0.2418, loss-ulb:0.1041, weight:0.38, lr:0.0008
[01:47:19.434] iteration:2576  t-loss:0.4711, loss-lb:0.3579, loss-ulb:0.2954, weight:0.38, lr:0.0008
[01:47:19.762] iteration:2577  t-loss:0.4849, loss-lb:0.3806, loss-ulb:0.2723, weight:0.38, lr:0.0008
[01:47:20.087] iteration:2578  t-loss:0.6426, loss-lb:0.4936, loss-ulb:0.3890, weight:0.38, lr:0.0008
[01:47:20.405] iteration:2579  t-loss:0.2737, loss-lb:0.2111, loss-ulb:0.1634, weight:0.38, lr:0.0008
[01:47:20.724] iteration:2580  t-loss:0.4663, loss-lb:0.3531, loss-ulb:0.2958, weight:0.38, lr:0.0008
[01:47:21.038] iteration:2581  t-loss:0.5115, loss-lb:0.4473, loss-ulb:0.1677, weight:0.38, lr:0.0008
[01:47:21.353] iteration:2582  t-loss:0.5923, loss-lb:0.5727, loss-ulb:0.0511, weight:0.38, lr:0.0008
[01:47:21.672] iteration:2583  t-loss:0.4394, loss-lb:0.3308, loss-ulb:0.2837, weight:0.38, lr:0.0008
[01:47:21.995] iteration:2584  t-loss:0.2614, loss-lb:0.2065, loss-ulb:0.1434, weight:0.38, lr:0.0008
[01:47:22.316] iteration:2585  t-loss:0.2758, loss-lb:0.1983, loss-ulb:0.2024, weight:0.38, lr:0.0008
[01:47:22.637] iteration:2586  t-loss:0.6571, loss-lb:0.4950, loss-ulb:0.4232, weight:0.38, lr:0.0008
[01:47:22.960] iteration:2587  t-loss:0.5604, loss-lb:0.4955, loss-ulb:0.1694, weight:0.38, lr:0.0008
[01:47:23.285] iteration:2588  t-loss:0.3103, loss-lb:0.2559, loss-ulb:0.1422, weight:0.38, lr:0.0008
[01:47:23.606] iteration:2589  t-loss:0.5178, loss-lb:0.3655, loss-ulb:0.3979, weight:0.38, lr:0.0008
[01:47:23.932] iteration:2590  t-loss:0.4303, loss-lb:0.3307, loss-ulb:0.2600, weight:0.38, lr:0.0008
[01:47:24.259] iteration:2591  t-loss:0.6372, loss-lb:0.6209, loss-ulb:0.0426, weight:0.38, lr:0.0008
[01:47:24.581] iteration:2592  t-loss:0.5037, loss-lb:0.3748, loss-ulb:0.3368, weight:0.38, lr:0.0008
[01:47:24.900] iteration:2593  t-loss:0.4106, loss-lb:0.3080, loss-ulb:0.2680, weight:0.38, lr:0.0008
[01:47:25.217] iteration:2594  t-loss:0.4791, loss-lb:0.3549, loss-ulb:0.3244, weight:0.38, lr:0.0008
[01:47:25.533] iteration:2595  t-loss:0.3707, loss-lb:0.1869, loss-ulb:0.4800, weight:0.38, lr:0.0008
[01:47:25.840] iteration:2596  t-loss:0.4788, loss-lb:0.3338, loss-ulb:0.3786, weight:0.38, lr:0.0008
[01:47:26.153] iteration:2597  t-loss:0.2557, loss-lb:0.2047, loss-ulb:0.1332, weight:0.38, lr:0.0008
[01:47:26.466] iteration:2598  t-loss:0.2827, loss-lb:0.2035, loss-ulb:0.2068, weight:0.38, lr:0.0008
[01:47:26.779] iteration:2599  t-loss:0.4017, loss-lb:0.2857, loss-ulb:0.3029, weight:0.38, lr:0.0008
[01:47:27.095] iteration:2600  t-loss:0.3579, loss-lb:0.1540, loss-ulb:0.5325, weight:0.38, lr:0.0008
[01:47:28.470] iteration:2601  t-loss:0.5826, loss-lb:0.2777, loss-ulb:0.7963, weight:0.38, lr:0.0008
[01:47:28.808] iteration:2602  t-loss:0.2827, loss-lb:0.2043, loss-ulb:0.2048, weight:0.38, lr:0.0008
[01:47:29.133] iteration:2603  t-loss:0.3694, loss-lb:0.2880, loss-ulb:0.2127, weight:0.38, lr:0.0008
[01:47:29.450] iteration:2604  t-loss:0.4529, loss-lb:0.3982, loss-ulb:0.1429, weight:0.38, lr:0.0008
[01:47:29.766] iteration:2605  t-loss:0.2803, loss-lb:0.2609, loss-ulb:0.0508, weight:0.38, lr:0.0008
[01:47:30.094] iteration:2606  t-loss:0.5238, loss-lb:0.4673, loss-ulb:0.1476, weight:0.38, lr:0.0008
[01:47:30.415] iteration:2607  t-loss:0.4907, loss-lb:0.4565, loss-ulb:0.0893, weight:0.38, lr:0.0008
[01:47:30.738] iteration:2608  t-loss:0.4715, loss-lb:0.4062, loss-ulb:0.1706, weight:0.38, lr:0.0008
[01:47:31.059] iteration:2609  t-loss:0.4114, loss-lb:0.3687, loss-ulb:0.1116, weight:0.38, lr:0.0008
[01:47:31.386] iteration:2610  t-loss:0.4654, loss-lb:0.2443, loss-ulb:0.5773, weight:0.38, lr:0.0008
[01:47:31.716] iteration:2611  t-loss:0.5516, loss-lb:0.3859, loss-ulb:0.4327, weight:0.38, lr:0.0008
[01:47:32.038] iteration:2612  t-loss:0.3578, loss-lb:0.2451, loss-ulb:0.2942, weight:0.38, lr:0.0008
[01:47:32.364] iteration:2613  t-loss:0.4188, loss-lb:0.3749, loss-ulb:0.1145, weight:0.38, lr:0.0008
[01:47:32.691] iteration:2614  t-loss:0.4429, loss-lb:0.3549, loss-ulb:0.2299, weight:0.38, lr:0.0008
[01:47:33.011] iteration:2615  t-loss:0.2571, loss-lb:0.1994, loss-ulb:0.1506, weight:0.38, lr:0.0008
[01:47:33.326] iteration:2616  t-loss:0.2843, loss-lb:0.2273, loss-ulb:0.1491, weight:0.38, lr:0.0008
[01:47:33.643] iteration:2617  t-loss:0.3042, loss-lb:0.1516, loss-ulb:0.3984, weight:0.38, lr:0.0008
[01:47:33.962] iteration:2618  t-loss:0.5776, loss-lb:0.5048, loss-ulb:0.1902, weight:0.38, lr:0.0008
[01:47:34.275] iteration:2619  t-loss:0.5121, loss-lb:0.3286, loss-ulb:0.4792, weight:0.38, lr:0.0008
[01:47:34.595] iteration:2620  t-loss:0.2172, loss-lb:0.1850, loss-ulb:0.0841, weight:0.38, lr:0.0008
[01:47:34.915] iteration:2621  t-loss:0.3891, loss-lb:0.1564, loss-ulb:0.6079, weight:0.38, lr:0.0008
[01:47:35.230] iteration:2622  t-loss:0.2645, loss-lb:0.2336, loss-ulb:0.0808, weight:0.38, lr:0.0008
[01:47:35.545] iteration:2623  t-loss:0.2953, loss-lb:0.2605, loss-ulb:0.0909, weight:0.38, lr:0.0008
[01:47:35.863] iteration:2624  t-loss:0.2991, loss-lb:0.2756, loss-ulb:0.0614, weight:0.38, lr:0.0008
[01:47:36.179] iteration:2625  t-loss:0.3950, loss-lb:0.3428, loss-ulb:0.1365, weight:0.38, lr:0.0008
[01:49:59.815] iteration 2625 : dice_score: 0.801847 best_dice: 0.801800
[01:49:59.815]  <<Test>> - Ep:104  - Dice-S/T:79.28/80.18, Best-S:80.11, Best-T:80.18
[01:49:59.816]           - AvgLoss(lb/ulb/all):0.30/0.23/0.40
[01:50:01.118] iteration:2626  t-loss:0.3497, loss-lb:0.3005, loss-ulb:0.1286, weight:0.38, lr:0.0008
[01:50:01.448] iteration:2627  t-loss:0.3252, loss-lb:0.3156, loss-ulb:0.0250, weight:0.38, lr:0.0008
[01:50:01.772] iteration:2628  t-loss:0.2088, loss-lb:0.1729, loss-ulb:0.0937, weight:0.38, lr:0.0008
[01:50:02.092] iteration:2629  t-loss:0.2891, loss-lb:0.2567, loss-ulb:0.0846, weight:0.38, lr:0.0008
[01:50:02.414] iteration:2630  t-loss:0.2563, loss-lb:0.2266, loss-ulb:0.0776, weight:0.38, lr:0.0008
[01:50:02.733] iteration:2631  t-loss:0.2743, loss-lb:0.1922, loss-ulb:0.2146, weight:0.38, lr:0.0008
[01:50:03.098] iteration:2632  t-loss:0.2824, loss-lb:0.2438, loss-ulb:0.1008, weight:0.38, lr:0.0008
[01:50:03.414] iteration:2633  t-loss:0.3734, loss-lb:0.2634, loss-ulb:0.2875, weight:0.38, lr:0.0008
[01:50:03.733] iteration:2634  t-loss:0.5085, loss-lb:0.3322, loss-ulb:0.4606, weight:0.38, lr:0.0008
[01:50:04.053] iteration:2635  t-loss:0.2966, loss-lb:0.2575, loss-ulb:0.1019, weight:0.38, lr:0.0008
[01:50:04.368] iteration:2636  t-loss:0.5513, loss-lb:0.4119, loss-ulb:0.3641, weight:0.38, lr:0.0008
[01:50:04.683] iteration:2637  t-loss:0.2515, loss-lb:0.2105, loss-ulb:0.1072, weight:0.38, lr:0.0008
[01:50:05.007] iteration:2638  t-loss:0.7279, loss-lb:0.6217, loss-ulb:0.2775, weight:0.38, lr:0.0008
[01:50:05.329] iteration:2639  t-loss:0.7049, loss-lb:0.6896, loss-ulb:0.0401, weight:0.38, lr:0.0008
[01:50:05.646] iteration:2640  t-loss:0.2118, loss-lb:0.1881, loss-ulb:0.0619, weight:0.38, lr:0.0008
[01:50:05.972] iteration:2641  t-loss:0.3178, loss-lb:0.2066, loss-ulb:0.2906, weight:0.38, lr:0.0008
[01:50:06.292] iteration:2642  t-loss:0.4555, loss-lb:0.3278, loss-ulb:0.3334, weight:0.38, lr:0.0008
[01:50:06.613] iteration:2643  t-loss:0.5217, loss-lb:0.4438, loss-ulb:0.2034, weight:0.38, lr:0.0008
[01:50:06.930] iteration:2644  t-loss:0.5001, loss-lb:0.3915, loss-ulb:0.2836, weight:0.38, lr:0.0008
[01:50:07.251] iteration:2645  t-loss:0.4787, loss-lb:0.3700, loss-ulb:0.2838, weight:0.38, lr:0.0008
[01:50:07.569] iteration:2646  t-loss:0.8113, loss-lb:0.6131, loss-ulb:0.5177, weight:0.38, lr:0.0008
[01:50:07.882] iteration:2647  t-loss:0.2873, loss-lb:0.2336, loss-ulb:0.1401, weight:0.38, lr:0.0008
[01:50:08.202] iteration:2648  t-loss:0.4187, loss-lb:0.3244, loss-ulb:0.2463, weight:0.38, lr:0.0008
[01:50:08.522] iteration:2649  t-loss:0.4446, loss-lb:0.3166, loss-ulb:0.3342, weight:0.38, lr:0.0008
[01:50:08.844] iteration:2650  t-loss:0.3958, loss-lb:0.2904, loss-ulb:0.2752, weight:0.38, lr:0.0008
[01:50:10.343] iteration:2651  t-loss:0.3419, loss-lb:0.2824, loss-ulb:0.1554, weight:0.38, lr:0.0008
[01:50:10.676] iteration:2652  t-loss:0.3604, loss-lb:0.2531, loss-ulb:0.2801, weight:0.38, lr:0.0008
[01:50:11.000] iteration:2653  t-loss:0.4895, loss-lb:0.3196, loss-ulb:0.4437, weight:0.38, lr:0.0008
[01:50:11.321] iteration:2654  t-loss:0.2595, loss-lb:0.2091, loss-ulb:0.1315, weight:0.38, lr:0.0008
[01:50:11.640] iteration:2655  t-loss:0.3287, loss-lb:0.2907, loss-ulb:0.0992, weight:0.38, lr:0.0008
[01:50:11.956] iteration:2656  t-loss:0.2932, loss-lb:0.2362, loss-ulb:0.1488, weight:0.38, lr:0.0008
[01:50:12.271] iteration:2657  t-loss:0.2866, loss-lb:0.2536, loss-ulb:0.0861, weight:0.38, lr:0.0008
[01:50:12.587] iteration:2658  t-loss:0.3463, loss-lb:0.2333, loss-ulb:0.2949, weight:0.38, lr:0.0008
[01:50:12.910] iteration:2659  t-loss:0.2054, loss-lb:0.1548, loss-ulb:0.1322, weight:0.38, lr:0.0008
[01:50:13.227] iteration:2660  t-loss:0.3572, loss-lb:0.2402, loss-ulb:0.3055, weight:0.38, lr:0.0008
[01:50:13.542] iteration:2661  t-loss:0.4641, loss-lb:0.3287, loss-ulb:0.3535, weight:0.38, lr:0.0008
[01:50:13.870] iteration:2662  t-loss:0.2935, loss-lb:0.2195, loss-ulb:0.1933, weight:0.38, lr:0.0008
[01:50:14.202] iteration:2663  t-loss:0.4560, loss-lb:0.4444, loss-ulb:0.0303, weight:0.38, lr:0.0008
[01:50:14.523] iteration:2664  t-loss:0.3350, loss-lb:0.3060, loss-ulb:0.0759, weight:0.38, lr:0.0008
[01:50:14.841] iteration:2665  t-loss:0.3689, loss-lb:0.2819, loss-ulb:0.2273, weight:0.38, lr:0.0008
[01:50:15.177] iteration:2666  t-loss:0.1997, loss-lb:0.1887, loss-ulb:0.0286, weight:0.38, lr:0.0008
[01:50:15.493] iteration:2667  t-loss:0.3053, loss-lb:0.2468, loss-ulb:0.1528, weight:0.38, lr:0.0008
[01:50:15.809] iteration:2668  t-loss:0.3808, loss-lb:0.3037, loss-ulb:0.2013, weight:0.38, lr:0.0008
[01:50:16.123] iteration:2669  t-loss:0.4051, loss-lb:0.2173, loss-ulb:0.4904, weight:0.38, lr:0.0008
[01:50:16.434] iteration:2670  t-loss:0.7017, loss-lb:0.3562, loss-ulb:0.9024, weight:0.38, lr:0.0008
[01:50:16.750] iteration:2671  t-loss:0.4438, loss-lb:0.3689, loss-ulb:0.1956, weight:0.38, lr:0.0008
[01:50:17.067] iteration:2672  t-loss:0.2333, loss-lb:0.1877, loss-ulb:0.1190, weight:0.38, lr:0.0008
[01:50:17.385] iteration:2673  t-loss:0.5414, loss-lb:0.3896, loss-ulb:0.3964, weight:0.38, lr:0.0008
[01:50:17.697] iteration:2674  t-loss:0.2470, loss-lb:0.2317, loss-ulb:0.0398, weight:0.38, lr:0.0008
[01:50:18.011] iteration:2675  t-loss:0.3392, loss-lb:0.2744, loss-ulb:0.1693, weight:0.38, lr:0.0008
[01:50:19.379] iteration:2676  t-loss:0.2857, loss-lb:0.1959, loss-ulb:0.2345, weight:0.38, lr:0.0008
[01:50:19.711] iteration:2677  t-loss:0.3815, loss-lb:0.3695, loss-ulb:0.0311, weight:0.38, lr:0.0008
[01:50:20.042] iteration:2678  t-loss:0.3652, loss-lb:0.3065, loss-ulb:0.1535, weight:0.38, lr:0.0008
[01:50:20.360] iteration:2679  t-loss:0.2788, loss-lb:0.1667, loss-ulb:0.2926, weight:0.38, lr:0.0008
[01:50:20.679] iteration:2680  t-loss:0.3458, loss-lb:0.2616, loss-ulb:0.2199, weight:0.38, lr:0.0008
[01:50:20.998] iteration:2681  t-loss:0.5521, loss-lb:0.3297, loss-ulb:0.5808, weight:0.38, lr:0.0008
[01:50:21.315] iteration:2682  t-loss:0.5479, loss-lb:0.4888, loss-ulb:0.1544, weight:0.38, lr:0.0008
[01:50:21.632] iteration:2683  t-loss:0.3454, loss-lb:0.2764, loss-ulb:0.1802, weight:0.38, lr:0.0008
[01:50:21.956] iteration:2684  t-loss:0.3076, loss-lb:0.1998, loss-ulb:0.2815, weight:0.38, lr:0.0008
[01:50:22.266] iteration:2685  t-loss:0.2996, loss-lb:0.2435, loss-ulb:0.1465, weight:0.38, lr:0.0008
[01:50:22.580] iteration:2686  t-loss:0.3387, loss-lb:0.2666, loss-ulb:0.1884, weight:0.38, lr:0.0008
[01:50:22.900] iteration:2687  t-loss:0.5278, loss-lb:0.3974, loss-ulb:0.3408, weight:0.38, lr:0.0008
[01:50:23.218] iteration:2688  t-loss:0.3565, loss-lb:0.2764, loss-ulb:0.2092, weight:0.38, lr:0.0008
[01:50:23.537] iteration:2689  t-loss:0.2926, loss-lb:0.2276, loss-ulb:0.1699, weight:0.38, lr:0.0008
[01:50:23.857] iteration:2690  t-loss:0.4698, loss-lb:0.4456, loss-ulb:0.0631, weight:0.38, lr:0.0008
[01:50:24.173] iteration:2691  t-loss:0.2892, loss-lb:0.2445, loss-ulb:0.1167, weight:0.38, lr:0.0008
[01:50:24.494] iteration:2692  t-loss:0.6167, loss-lb:0.5260, loss-ulb:0.2367, weight:0.38, lr:0.0008
[01:50:24.811] iteration:2693  t-loss:0.4249, loss-lb:0.3941, loss-ulb:0.0805, weight:0.38, lr:0.0008
[01:50:25.126] iteration:2694  t-loss:0.5521, loss-lb:0.3383, loss-ulb:0.5583, weight:0.38, lr:0.0008
[01:50:25.443] iteration:2695  t-loss:0.5089, loss-lb:0.3171, loss-ulb:0.5009, weight:0.38, lr:0.0008
[01:50:25.758] iteration:2696  t-loss:0.2242, loss-lb:0.1869, loss-ulb:0.0975, weight:0.38, lr:0.0008
[01:50:26.074] iteration:2697  t-loss:0.6347, loss-lb:0.5593, loss-ulb:0.1970, weight:0.38, lr:0.0008
[01:50:26.388] iteration:2698  t-loss:0.3061, loss-lb:0.2157, loss-ulb:0.2360, weight:0.38, lr:0.0008
[01:50:26.702] iteration:2699  t-loss:0.2027, loss-lb:0.1503, loss-ulb:0.1369, weight:0.38, lr:0.0008
[01:50:27.016] iteration:2700  t-loss:0.2089, loss-lb:0.1686, loss-ulb:0.1053, weight:0.38, lr:0.0008
[01:50:28.205] iteration:2701  t-loss:0.3232, loss-lb:0.2811, loss-ulb:0.0956, weight:0.44, lr:0.0008
[01:50:28.530] iteration:2702  t-loss:0.3450, loss-lb:0.2834, loss-ulb:0.1398, weight:0.44, lr:0.0008
[01:50:28.859] iteration:2703  t-loss:0.2527, loss-lb:0.1773, loss-ulb:0.1711, weight:0.44, lr:0.0008
[01:50:29.180] iteration:2704  t-loss:0.7717, loss-lb:0.4063, loss-ulb:0.8292, weight:0.44, lr:0.0008
[01:50:29.494] iteration:2705  t-loss:0.4014, loss-lb:0.1863, loss-ulb:0.4880, weight:0.44, lr:0.0008
[01:50:29.809] iteration:2706  t-loss:0.2555, loss-lb:0.2269, loss-ulb:0.0649, weight:0.44, lr:0.0008
[01:50:30.127] iteration:2707  t-loss:0.6346, loss-lb:0.2750, loss-ulb:0.8160, weight:0.44, lr:0.0008
[01:50:30.443] iteration:2708  t-loss:0.5447, loss-lb:0.5206, loss-ulb:0.0548, weight:0.44, lr:0.0008
[01:50:30.764] iteration:2709  t-loss:0.4563, loss-lb:0.3033, loss-ulb:0.3471, weight:0.44, lr:0.0008
[01:50:31.089] iteration:2710  t-loss:0.2810, loss-lb:0.2055, loss-ulb:0.1713, weight:0.44, lr:0.0008
[01:50:31.406] iteration:2711  t-loss:0.3272, loss-lb:0.2182, loss-ulb:0.2475, weight:0.44, lr:0.0008
[01:50:31.722] iteration:2712  t-loss:0.3184, loss-lb:0.1824, loss-ulb:0.3088, weight:0.44, lr:0.0008
[01:50:32.041] iteration:2713  t-loss:0.2618, loss-lb:0.2306, loss-ulb:0.0708, weight:0.44, lr:0.0008
[01:50:32.361] iteration:2714  t-loss:0.3050, loss-lb:0.1898, loss-ulb:0.2614, weight:0.44, lr:0.0008
[01:50:32.681] iteration:2715  t-loss:0.3012, loss-lb:0.2036, loss-ulb:0.2216, weight:0.44, lr:0.0008
[01:50:33.003] iteration:2716  t-loss:0.8254, loss-lb:0.6061, loss-ulb:0.4977, weight:0.44, lr:0.0008
[01:50:33.328] iteration:2717  t-loss:0.4938, loss-lb:0.2648, loss-ulb:0.5195, weight:0.44, lr:0.0008
[01:50:33.643] iteration:2718  t-loss:0.3320, loss-lb:0.1851, loss-ulb:0.3334, weight:0.44, lr:0.0008
[01:50:33.960] iteration:2719  t-loss:0.3520, loss-lb:0.2704, loss-ulb:0.1851, weight:0.44, lr:0.0008
[01:50:34.277] iteration:2720  t-loss:0.5217, loss-lb:0.3884, loss-ulb:0.3025, weight:0.44, lr:0.0008
[01:50:34.594] iteration:2721  t-loss:0.2650, loss-lb:0.1982, loss-ulb:0.1516, weight:0.44, lr:0.0008
[01:50:34.906] iteration:2722  t-loss:0.2822, loss-lb:0.2503, loss-ulb:0.0724, weight:0.44, lr:0.0008
[01:50:35.220] iteration:2723  t-loss:0.4151, loss-lb:0.3939, loss-ulb:0.0480, weight:0.44, lr:0.0008
[01:50:35.535] iteration:2724  t-loss:0.3956, loss-lb:0.2158, loss-ulb:0.4080, weight:0.44, lr:0.0008
[01:50:35.846] iteration:2725  t-loss:0.2961, loss-lb:0.2586, loss-ulb:0.0850, weight:0.44, lr:0.0008
[01:52:50.760] iteration 2725 : dice_score: 0.804025 best_dice: 0.804000
[01:52:50.760]  <<Test>> - Ep:108  - Dice-S/T:78.66/80.40, Best-S:80.11, Best-T:80.40
[01:52:50.761]           - AvgLoss(lb/ulb/all):0.28/0.26/0.39
[01:52:52.229] iteration:2726  t-loss:0.2925, loss-lb:0.2653, loss-ulb:0.0617, weight:0.44, lr:0.0008
[01:52:52.570] iteration:2727  t-loss:0.4115, loss-lb:0.2349, loss-ulb:0.4006, weight:0.44, lr:0.0008
[01:52:52.898] iteration:2728  t-loss:0.3153, loss-lb:0.2614, loss-ulb:0.1224, weight:0.44, lr:0.0008
[01:52:53.216] iteration:2729  t-loss:0.4511, loss-lb:0.3038, loss-ulb:0.3341, weight:0.44, lr:0.0008
[01:52:53.540] iteration:2730  t-loss:0.3054, loss-lb:0.2581, loss-ulb:0.1073, weight:0.44, lr:0.0008
[01:52:53.856] iteration:2731  t-loss:0.3282, loss-lb:0.2271, loss-ulb:0.2296, weight:0.44, lr:0.0008
[01:52:54.180] iteration:2732  t-loss:0.2673, loss-lb:0.1950, loss-ulb:0.1642, weight:0.44, lr:0.0008
[01:52:54.503] iteration:2733  t-loss:0.3960, loss-lb:0.3357, loss-ulb:0.1367, weight:0.44, lr:0.0008
[01:52:54.819] iteration:2734  t-loss:0.4154, loss-lb:0.2635, loss-ulb:0.3446, weight:0.44, lr:0.0008
[01:52:55.136] iteration:2735  t-loss:0.4888, loss-lb:0.2761, loss-ulb:0.4824, weight:0.44, lr:0.0008
[01:52:55.455] iteration:2736  t-loss:0.4631, loss-lb:0.3295, loss-ulb:0.3033, weight:0.44, lr:0.0008
[01:52:55.777] iteration:2737  t-loss:0.4387, loss-lb:0.2142, loss-ulb:0.5094, weight:0.44, lr:0.0008
[01:52:56.098] iteration:2738  t-loss:0.2883, loss-lb:0.2150, loss-ulb:0.1665, weight:0.44, lr:0.0008
[01:52:56.415] iteration:2739  t-loss:0.7294, loss-lb:0.6647, loss-ulb:0.1468, weight:0.44, lr:0.0008
[01:52:56.727] iteration:2740  t-loss:0.4837, loss-lb:0.3174, loss-ulb:0.3773, weight:0.44, lr:0.0008
[01:52:57.053] iteration:2741  t-loss:0.3518, loss-lb:0.3010, loss-ulb:0.1154, weight:0.44, lr:0.0008
[01:52:57.369] iteration:2742  t-loss:0.2494, loss-lb:0.2238, loss-ulb:0.0582, weight:0.44, lr:0.0008
[01:52:57.687] iteration:2743  t-loss:0.4278, loss-lb:0.3619, loss-ulb:0.1497, weight:0.44, lr:0.0008
[01:52:58.002] iteration:2744  t-loss:0.3550, loss-lb:0.2253, loss-ulb:0.2941, weight:0.44, lr:0.0008
[01:52:58.324] iteration:2745  t-loss:0.3637, loss-lb:0.2371, loss-ulb:0.2873, weight:0.44, lr:0.0008
[01:52:58.652] iteration:2746  t-loss:0.4261, loss-lb:0.3126, loss-ulb:0.2576, weight:0.44, lr:0.0008
[01:52:58.970] iteration:2747  t-loss:0.5953, loss-lb:0.5027, loss-ulb:0.2102, weight:0.44, lr:0.0008
[01:52:59.290] iteration:2748  t-loss:0.2827, loss-lb:0.1944, loss-ulb:0.2005, weight:0.44, lr:0.0008
[01:52:59.603] iteration:2749  t-loss:0.3035, loss-lb:0.2311, loss-ulb:0.1644, weight:0.44, lr:0.0008
[01:52:59.920] iteration:2750  t-loss:0.9262, loss-lb:0.8267, loss-ulb:0.2256, weight:0.44, lr:0.0008
[01:53:01.472] iteration:2751  t-loss:0.2760, loss-lb:0.2105, loss-ulb:0.1488, weight:0.44, lr:0.0008
[01:53:01.816] iteration:2752  t-loss:0.5753, loss-lb:0.4678, loss-ulb:0.2439, weight:0.44, lr:0.0008
[01:53:02.146] iteration:2753  t-loss:0.3987, loss-lb:0.3289, loss-ulb:0.1585, weight:0.44, lr:0.0008
[01:53:02.462] iteration:2754  t-loss:0.3163, loss-lb:0.2539, loss-ulb:0.1416, weight:0.44, lr:0.0008
[01:53:02.784] iteration:2755  t-loss:0.7039, loss-lb:0.4761, loss-ulb:0.5170, weight:0.44, lr:0.0008
[01:53:03.099] iteration:2756  t-loss:0.3279, loss-lb:0.2557, loss-ulb:0.1638, weight:0.44, lr:0.0008
[01:53:03.423] iteration:2757  t-loss:0.4273, loss-lb:0.3305, loss-ulb:0.2197, weight:0.44, lr:0.0008
[01:53:03.748] iteration:2758  t-loss:0.5216, loss-lb:0.4118, loss-ulb:0.2491, weight:0.44, lr:0.0008
[01:53:04.067] iteration:2759  t-loss:0.6665, loss-lb:0.4331, loss-ulb:0.5296, weight:0.44, lr:0.0008
[01:53:04.383] iteration:2760  t-loss:0.5124, loss-lb:0.4610, loss-ulb:0.1166, weight:0.44, lr:0.0008
[01:53:04.700] iteration:2761  t-loss:0.2555, loss-lb:0.2108, loss-ulb:0.1014, weight:0.44, lr:0.0008
[01:53:05.026] iteration:2762  t-loss:0.2803, loss-lb:0.2206, loss-ulb:0.1355, weight:0.44, lr:0.0008
[01:53:05.353] iteration:2763  t-loss:0.6180, loss-lb:0.4869, loss-ulb:0.2975, weight:0.44, lr:0.0008
[01:53:05.671] iteration:2764  t-loss:0.4169, loss-lb:0.2316, loss-ulb:0.4206, weight:0.44, lr:0.0008
[01:53:05.989] iteration:2765  t-loss:0.2931, loss-lb:0.2528, loss-ulb:0.0915, weight:0.44, lr:0.0008
[01:53:06.310] iteration:2766  t-loss:0.4449, loss-lb:0.3961, loss-ulb:0.1109, weight:0.44, lr:0.0008
[01:53:06.627] iteration:2767  t-loss:0.2904, loss-lb:0.2129, loss-ulb:0.1758, weight:0.44, lr:0.0008
[01:53:06.942] iteration:2768  t-loss:0.7065, loss-lb:0.5488, loss-ulb:0.3576, weight:0.44, lr:0.0008
[01:53:07.256] iteration:2769  t-loss:0.4545, loss-lb:0.2193, loss-ulb:0.5337, weight:0.44, lr:0.0008
[01:53:07.567] iteration:2770  t-loss:0.2252, loss-lb:0.2058, loss-ulb:0.0441, weight:0.44, lr:0.0008
[01:53:07.885] iteration:2771  t-loss:0.4259, loss-lb:0.3802, loss-ulb:0.1037, weight:0.44, lr:0.0008
[01:53:08.197] iteration:2772  t-loss:0.5254, loss-lb:0.4757, loss-ulb:0.1126, weight:0.44, lr:0.0008
[01:53:08.507] iteration:2773  t-loss:0.4280, loss-lb:0.2560, loss-ulb:0.3903, weight:0.44, lr:0.0008
[01:53:08.819] iteration:2774  t-loss:0.3811, loss-lb:0.1928, loss-ulb:0.4273, weight:0.44, lr:0.0008
[01:53:09.133] iteration:2775  t-loss:0.4668, loss-lb:0.3000, loss-ulb:0.3786, weight:0.44, lr:0.0008
[01:53:10.592] iteration:2776  t-loss:0.6178, loss-lb:0.5651, loss-ulb:0.1196, weight:0.44, lr:0.0008
[01:53:10.934] iteration:2777  t-loss:0.3377, loss-lb:0.2211, loss-ulb:0.2645, weight:0.44, lr:0.0008
[01:53:11.290] iteration:2778  t-loss:0.7119, loss-lb:0.4620, loss-ulb:0.5671, weight:0.44, lr:0.0008
[01:53:11.606] iteration:2779  t-loss:0.3080, loss-lb:0.2923, loss-ulb:0.0357, weight:0.44, lr:0.0008
[01:53:11.931] iteration:2780  t-loss:0.3741, loss-lb:0.3237, loss-ulb:0.1144, weight:0.44, lr:0.0008
[01:53:12.258] iteration:2781  t-loss:0.3900, loss-lb:0.3714, loss-ulb:0.0422, weight:0.44, lr:0.0008
[01:53:12.578] iteration:2782  t-loss:0.3204, loss-lb:0.2023, loss-ulb:0.2678, weight:0.44, lr:0.0008
[01:53:12.913] iteration:2783  t-loss:0.5602, loss-lb:0.4325, loss-ulb:0.2896, weight:0.44, lr:0.0008
[01:53:13.235] iteration:2784  t-loss:0.3404, loss-lb:0.2347, loss-ulb:0.2399, weight:0.44, lr:0.0008
[01:53:13.552] iteration:2785  t-loss:0.2945, loss-lb:0.2428, loss-ulb:0.1173, weight:0.44, lr:0.0008
[01:53:13.872] iteration:2786  t-loss:0.3561, loss-lb:0.2499, loss-ulb:0.2410, weight:0.44, lr:0.0008
[01:53:14.194] iteration:2787  t-loss:0.4100, loss-lb:0.3418, loss-ulb:0.1547, weight:0.44, lr:0.0008
[01:53:14.512] iteration:2788  t-loss:0.4574, loss-lb:0.3697, loss-ulb:0.1991, weight:0.44, lr:0.0008
[01:53:14.830] iteration:2789  t-loss:0.3578, loss-lb:0.2376, loss-ulb:0.2727, weight:0.44, lr:0.0008
[01:53:15.144] iteration:2790  t-loss:0.2696, loss-lb:0.2492, loss-ulb:0.0461, weight:0.44, lr:0.0008
[01:53:15.462] iteration:2791  t-loss:0.2333, loss-lb:0.2046, loss-ulb:0.0653, weight:0.44, lr:0.0008
[01:53:15.780] iteration:2792  t-loss:0.2660, loss-lb:0.2464, loss-ulb:0.0443, weight:0.44, lr:0.0008
[01:53:16.093] iteration:2793  t-loss:0.2297, loss-lb:0.2153, loss-ulb:0.0326, weight:0.44, lr:0.0008
[01:53:16.411] iteration:2794  t-loss:0.3166, loss-lb:0.2558, loss-ulb:0.1379, weight:0.44, lr:0.0008
[01:53:16.724] iteration:2795  t-loss:0.3704, loss-lb:0.2409, loss-ulb:0.2939, weight:0.44, lr:0.0008
[01:53:17.044] iteration:2796  t-loss:0.3928, loss-lb:0.3345, loss-ulb:0.1323, weight:0.44, lr:0.0008
[01:53:17.360] iteration:2797  t-loss:0.2839, loss-lb:0.2127, loss-ulb:0.1615, weight:0.44, lr:0.0008
[01:53:17.673] iteration:2798  t-loss:0.5392, loss-lb:0.1896, loss-ulb:0.7935, weight:0.44, lr:0.0008
[01:53:17.992] iteration:2799  t-loss:0.4135, loss-lb:0.3130, loss-ulb:0.2281, weight:0.44, lr:0.0008
[01:53:18.306] iteration:2800  t-loss:0.3360, loss-lb:0.2531, loss-ulb:0.1881, weight:0.44, lr:0.0008
[01:53:19.459] iteration:2801  t-loss:0.4468, loss-lb:0.3806, loss-ulb:0.1503, weight:0.44, lr:0.0008
[01:53:19.793] iteration:2802  t-loss:0.4075, loss-lb:0.3108, loss-ulb:0.2194, weight:0.44, lr:0.0008
[01:53:20.120] iteration:2803  t-loss:0.2566, loss-lb:0.1726, loss-ulb:0.1906, weight:0.44, lr:0.0008
[01:53:20.444] iteration:2804  t-loss:0.2556, loss-lb:0.1894, loss-ulb:0.1503, weight:0.44, lr:0.0008
[01:53:20.767] iteration:2805  t-loss:0.4328, loss-lb:0.3905, loss-ulb:0.0961, weight:0.44, lr:0.0008
[01:53:21.088] iteration:2806  t-loss:0.3604, loss-lb:0.3518, loss-ulb:0.0195, weight:0.44, lr:0.0008
[01:53:21.412] iteration:2807  t-loss:0.2847, loss-lb:0.2114, loss-ulb:0.1663, weight:0.44, lr:0.0008
[01:53:21.730] iteration:2808  t-loss:0.3105, loss-lb:0.1558, loss-ulb:0.3511, weight:0.44, lr:0.0008
[01:53:22.051] iteration:2809  t-loss:0.4461, loss-lb:0.3165, loss-ulb:0.2941, weight:0.44, lr:0.0008
[01:53:22.370] iteration:2810  t-loss:0.3416, loss-lb:0.2535, loss-ulb:0.2000, weight:0.44, lr:0.0008
[01:53:22.690] iteration:2811  t-loss:0.3446, loss-lb:0.2834, loss-ulb:0.1387, weight:0.44, lr:0.0008
[01:53:23.014] iteration:2812  t-loss:0.3232, loss-lb:0.2772, loss-ulb:0.1044, weight:0.44, lr:0.0008
[01:53:23.328] iteration:2813  t-loss:0.2178, loss-lb:0.1819, loss-ulb:0.0815, weight:0.44, lr:0.0008
[01:53:23.640] iteration:2814  t-loss:0.5402, loss-lb:0.2403, loss-ulb:0.6805, weight:0.44, lr:0.0008
[01:53:23.963] iteration:2815  t-loss:0.5776, loss-lb:0.4135, loss-ulb:0.3725, weight:0.44, lr:0.0008
[01:53:24.281] iteration:2816  t-loss:0.3128, loss-lb:0.2522, loss-ulb:0.1377, weight:0.44, lr:0.0008
[01:53:24.607] iteration:2817  t-loss:0.3238, loss-lb:0.2141, loss-ulb:0.2489, weight:0.44, lr:0.0008
[01:53:24.923] iteration:2818  t-loss:0.6498, loss-lb:0.3273, loss-ulb:0.7317, weight:0.44, lr:0.0008
[01:53:25.244] iteration:2819  t-loss:0.5364, loss-lb:0.2968, loss-ulb:0.5438, weight:0.44, lr:0.0008
[01:53:25.563] iteration:2820  t-loss:0.3123, loss-lb:0.2512, loss-ulb:0.1386, weight:0.44, lr:0.0008
[01:53:25.886] iteration:2821  t-loss:0.2785, loss-lb:0.2171, loss-ulb:0.1393, weight:0.44, lr:0.0008
[01:53:26.202] iteration:2822  t-loss:0.2833, loss-lb:0.2418, loss-ulb:0.0941, weight:0.44, lr:0.0008
[01:53:26.518] iteration:2823  t-loss:0.3760, loss-lb:0.2812, loss-ulb:0.2152, weight:0.44, lr:0.0008
[01:53:26.835] iteration:2824  t-loss:0.2360, loss-lb:0.2225, loss-ulb:0.0306, weight:0.44, lr:0.0008
[01:53:27.151] iteration:2825  t-loss:0.3436, loss-lb:0.2510, loss-ulb:0.2101, weight:0.44, lr:0.0008
[01:55:40.033] iteration 2825 : dice_score: 0.804632 best_dice: 0.804600
[01:55:40.033]  <<Test>> - Ep:112  - Dice-S/T:80.85/80.46, Best-S:80.85, Best-T:80.46
[01:55:40.033]           - AvgLoss(lb/ulb/all):0.27/0.24/0.37
[01:55:41.316] iteration:2826  t-loss:0.4047, loss-lb:0.3646, loss-ulb:0.0908, weight:0.44, lr:0.0008
[01:55:41.657] iteration:2827  t-loss:0.2338, loss-lb:0.2157, loss-ulb:0.0409, weight:0.44, lr:0.0008
[01:55:41.987] iteration:2828  t-loss:0.3228, loss-lb:0.2407, loss-ulb:0.1863, weight:0.44, lr:0.0008
[01:55:42.307] iteration:2829  t-loss:0.3621, loss-lb:0.2521, loss-ulb:0.2496, weight:0.44, lr:0.0008
[01:55:42.634] iteration:2830  t-loss:0.3918, loss-lb:0.3344, loss-ulb:0.1303, weight:0.44, lr:0.0008
[01:55:42.960] iteration:2831  t-loss:0.3276, loss-lb:0.2093, loss-ulb:0.2684, weight:0.44, lr:0.0008
[01:55:43.283] iteration:2832  t-loss:0.4520, loss-lb:0.3830, loss-ulb:0.1564, weight:0.44, lr:0.0008
[01:55:43.602] iteration:2833  t-loss:0.4790, loss-lb:0.4553, loss-ulb:0.0536, weight:0.44, lr:0.0008
[01:55:43.923] iteration:2834  t-loss:0.3023, loss-lb:0.2063, loss-ulb:0.2178, weight:0.44, lr:0.0008
[01:55:44.243] iteration:2835  t-loss:0.2183, loss-lb:0.1996, loss-ulb:0.0424, weight:0.44, lr:0.0008
[01:55:44.563] iteration:2836  t-loss:0.2995, loss-lb:0.2307, loss-ulb:0.1561, weight:0.44, lr:0.0008
[01:55:44.878] iteration:2837  t-loss:0.5469, loss-lb:0.4983, loss-ulb:0.1103, weight:0.44, lr:0.0008
[01:55:45.203] iteration:2838  t-loss:0.2767, loss-lb:0.2309, loss-ulb:0.1041, weight:0.44, lr:0.0008
[01:55:45.522] iteration:2839  t-loss:0.2575, loss-lb:0.1969, loss-ulb:0.1375, weight:0.44, lr:0.0008
[01:55:45.847] iteration:2840  t-loss:0.4616, loss-lb:0.4068, loss-ulb:0.1243, weight:0.44, lr:0.0008
[01:55:46.173] iteration:2841  t-loss:0.3486, loss-lb:0.2416, loss-ulb:0.2428, weight:0.44, lr:0.0008
[01:55:46.496] iteration:2842  t-loss:0.5126, loss-lb:0.4356, loss-ulb:0.1748, weight:0.44, lr:0.0008
[01:55:46.816] iteration:2843  t-loss:0.4292, loss-lb:0.3337, loss-ulb:0.2167, weight:0.44, lr:0.0008
[01:55:47.132] iteration:2844  t-loss:0.3446, loss-lb:0.3285, loss-ulb:0.0366, weight:0.44, lr:0.0008
[01:55:47.446] iteration:2845  t-loss:0.4074, loss-lb:0.1946, loss-ulb:0.4828, weight:0.44, lr:0.0008
[01:55:47.777] iteration:2846  t-loss:0.5839, loss-lb:0.4461, loss-ulb:0.3125, weight:0.44, lr:0.0008
[01:55:48.106] iteration:2847  t-loss:0.4053, loss-lb:0.2738, loss-ulb:0.2985, weight:0.44, lr:0.0008
[01:55:48.434] iteration:2848  t-loss:0.2588, loss-lb:0.1945, loss-ulb:0.1459, weight:0.44, lr:0.0008
[01:55:48.773] iteration:2849  t-loss:0.3915, loss-lb:0.3160, loss-ulb:0.1712, weight:0.44, lr:0.0008
[01:55:49.104] iteration:2850  t-loss:0.3126, loss-lb:0.2821, loss-ulb:0.0692, weight:0.44, lr:0.0008
[01:55:50.706] iteration:2851  t-loss:0.4753, loss-lb:0.3504, loss-ulb:0.2478, weight:0.50, lr:0.0008
[01:55:51.070] iteration:2852  t-loss:0.4150, loss-lb:0.3620, loss-ulb:0.1053, weight:0.50, lr:0.0008
[01:55:51.413] iteration:2853  t-loss:0.3117, loss-lb:0.1684, loss-ulb:0.2843, weight:0.50, lr:0.0008
[01:55:51.765] iteration:2854  t-loss:0.5409, loss-lb:0.3143, loss-ulb:0.4496, weight:0.50, lr:0.0008
[01:55:52.105] iteration:2855  t-loss:0.3718, loss-lb:0.2943, loss-ulb:0.1537, weight:0.50, lr:0.0008
[01:55:52.432] iteration:2856  t-loss:0.4829, loss-lb:0.3319, loss-ulb:0.2996, weight:0.50, lr:0.0008
[01:55:52.752] iteration:2857  t-loss:0.2802, loss-lb:0.2125, loss-ulb:0.1345, weight:0.50, lr:0.0008
[01:55:53.068] iteration:2858  t-loss:0.6209, loss-lb:0.3282, loss-ulb:0.5808, weight:0.50, lr:0.0008
[01:55:53.384] iteration:2859  t-loss:0.3323, loss-lb:0.2110, loss-ulb:0.2406, weight:0.50, lr:0.0008
[01:55:53.709] iteration:2860  t-loss:0.6751, loss-lb:0.3741, loss-ulb:0.5972, weight:0.50, lr:0.0008
[01:55:54.032] iteration:2861  t-loss:0.9901, loss-lb:0.8905, loss-ulb:0.1976, weight:0.50, lr:0.0008
[01:55:54.348] iteration:2862  t-loss:0.4732, loss-lb:0.2019, loss-ulb:0.5383, weight:0.50, lr:0.0008
[01:55:54.667] iteration:2863  t-loss:0.2977, loss-lb:0.2831, loss-ulb:0.0289, weight:0.50, lr:0.0008
[01:55:54.988] iteration:2864  t-loss:0.4968, loss-lb:0.4695, loss-ulb:0.0541, weight:0.50, lr:0.0008
[01:55:55.310] iteration:2865  t-loss:0.5250, loss-lb:0.4088, loss-ulb:0.2305, weight:0.50, lr:0.0008
[01:55:55.629] iteration:2866  t-loss:0.5161, loss-lb:0.4007, loss-ulb:0.2290, weight:0.50, lr:0.0008
[01:55:55.947] iteration:2867  t-loss:0.2987, loss-lb:0.2039, loss-ulb:0.1882, weight:0.50, lr:0.0008
[01:55:56.260] iteration:2868  t-loss:0.1646, loss-lb:0.1484, loss-ulb:0.0323, weight:0.50, lr:0.0008
[01:55:56.576] iteration:2869  t-loss:0.3285, loss-lb:0.2536, loss-ulb:0.1486, weight:0.50, lr:0.0008
[01:55:56.892] iteration:2870  t-loss:0.3560, loss-lb:0.3301, loss-ulb:0.0515, weight:0.50, lr:0.0008
[01:55:57.219] iteration:2871  t-loss:0.2880, loss-lb:0.2361, loss-ulb:0.1030, weight:0.50, lr:0.0008
[01:55:57.553] iteration:2872  t-loss:0.3001, loss-lb:0.2183, loss-ulb:0.1624, weight:0.50, lr:0.0008
[01:55:57.891] iteration:2873  t-loss:0.5188, loss-lb:0.2574, loss-ulb:0.5185, weight:0.50, lr:0.0008
[01:55:58.236] iteration:2874  t-loss:0.4349, loss-lb:0.2440, loss-ulb:0.3788, weight:0.50, lr:0.0008
[01:55:58.579] iteration:2875  t-loss:0.3301, loss-lb:0.1926, loss-ulb:0.2728, weight:0.50, lr:0.0008
[01:56:00.368] iteration:2876  t-loss:0.3676, loss-lb:0.2680, loss-ulb:0.1975, weight:0.50, lr:0.0008
[01:56:00.719] iteration:2877  t-loss:0.4317, loss-lb:0.3470, loss-ulb:0.1680, weight:0.50, lr:0.0008
[01:56:01.077] iteration:2878  t-loss:0.4569, loss-lb:0.2197, loss-ulb:0.4704, weight:0.50, lr:0.0008
[01:56:01.415] iteration:2879  t-loss:0.2590, loss-lb:0.1822, loss-ulb:0.1523, weight:0.50, lr:0.0008
[01:56:01.780] iteration:2880  t-loss:0.5452, loss-lb:0.3582, loss-ulb:0.3709, weight:0.50, lr:0.0008
[01:56:02.118] iteration:2881  t-loss:0.2471, loss-lb:0.1784, loss-ulb:0.1364, weight:0.50, lr:0.0008
[01:56:02.433] iteration:2882  t-loss:0.5156, loss-lb:0.4871, loss-ulb:0.0567, weight:0.50, lr:0.0008
[01:56:02.747] iteration:2883  t-loss:0.4263, loss-lb:0.3227, loss-ulb:0.2054, weight:0.50, lr:0.0008
[01:56:03.068] iteration:2884  t-loss:0.6753, loss-lb:0.3491, loss-ulb:0.6472, weight:0.50, lr:0.0008
[01:56:03.386] iteration:2885  t-loss:0.2720, loss-lb:0.1614, loss-ulb:0.2194, weight:0.50, lr:0.0008
[01:56:03.701] iteration:2886  t-loss:1.0077, loss-lb:0.5404, loss-ulb:0.9269, weight:0.50, lr:0.0008
[01:56:04.016] iteration:2887  t-loss:0.3210, loss-lb:0.2126, loss-ulb:0.2152, weight:0.50, lr:0.0008
[01:56:04.330] iteration:2888  t-loss:0.3840, loss-lb:0.2989, loss-ulb:0.1687, weight:0.50, lr:0.0008
[01:56:04.647] iteration:2889  t-loss:0.5161, loss-lb:0.3391, loss-ulb:0.3511, weight:0.50, lr:0.0008
[01:56:04.961] iteration:2890  t-loss:0.6633, loss-lb:0.3267, loss-ulb:0.6678, weight:0.50, lr:0.0008
[01:56:05.280] iteration:2891  t-loss:0.3594, loss-lb:0.2304, loss-ulb:0.2558, weight:0.50, lr:0.0008
[01:56:05.593] iteration:2892  t-loss:0.2996, loss-lb:0.2307, loss-ulb:0.1367, weight:0.50, lr:0.0008
[01:56:05.906] iteration:2893  t-loss:0.6725, loss-lb:0.3072, loss-ulb:0.7245, weight:0.50, lr:0.0008
[01:56:06.221] iteration:2894  t-loss:0.6707, loss-lb:0.6021, loss-ulb:0.1360, weight:0.50, lr:0.0008
[01:56:06.542] iteration:2895  t-loss:0.4101, loss-lb:0.2966, loss-ulb:0.2251, weight:0.50, lr:0.0008
[01:56:06.862] iteration:2896  t-loss:0.4265, loss-lb:0.2896, loss-ulb:0.2715, weight:0.50, lr:0.0008
[01:56:07.176] iteration:2897  t-loss:0.3918, loss-lb:0.1916, loss-ulb:0.3970, weight:0.50, lr:0.0008
[01:56:07.492] iteration:2898  t-loss:0.4860, loss-lb:0.2440, loss-ulb:0.4801, weight:0.50, lr:0.0008
[01:56:07.807] iteration:2899  t-loss:0.6957, loss-lb:0.6034, loss-ulb:0.1832, weight:0.50, lr:0.0008
[01:56:08.121] iteration:2900  t-loss:0.2861, loss-lb:0.2230, loss-ulb:0.1250, weight:0.50, lr:0.0008
[01:56:09.496] iteration:2901  t-loss:0.3826, loss-lb:0.2111, loss-ulb:0.3403, weight:0.50, lr:0.0008
[01:56:09.848] iteration:2902  t-loss:0.2701, loss-lb:0.2391, loss-ulb:0.0616, weight:0.50, lr:0.0008
[01:56:10.186] iteration:2903  t-loss:0.5166, loss-lb:0.4113, loss-ulb:0.2089, weight:0.50, lr:0.0008
[01:56:10.522] iteration:2904  t-loss:0.3718, loss-lb:0.3022, loss-ulb:0.1381, weight:0.50, lr:0.0008
[01:56:10.844] iteration:2905  t-loss:0.3123, loss-lb:0.2299, loss-ulb:0.1634, weight:0.50, lr:0.0008
[01:56:11.168] iteration:2906  t-loss:0.3151, loss-lb:0.2438, loss-ulb:0.1414, weight:0.50, lr:0.0008
[01:56:11.502] iteration:2907  t-loss:0.2037, loss-lb:0.1648, loss-ulb:0.0772, weight:0.50, lr:0.0008
[01:56:11.829] iteration:2908  t-loss:0.4447, loss-lb:0.3442, loss-ulb:0.1995, weight:0.50, lr:0.0008
[01:56:12.152] iteration:2909  t-loss:0.3786, loss-lb:0.3239, loss-ulb:0.1084, weight:0.50, lr:0.0008
[01:56:12.470] iteration:2910  t-loss:0.2550, loss-lb:0.2124, loss-ulb:0.0846, weight:0.50, lr:0.0008
[01:56:12.796] iteration:2911  t-loss:0.3417, loss-lb:0.2344, loss-ulb:0.2129, weight:0.50, lr:0.0008
[01:56:13.129] iteration:2912  t-loss:0.3783, loss-lb:0.3279, loss-ulb:0.1001, weight:0.50, lr:0.0008
[01:56:13.449] iteration:2913  t-loss:0.2938, loss-lb:0.1985, loss-ulb:0.1892, weight:0.50, lr:0.0008
[01:56:13.763] iteration:2914  t-loss:0.3229, loss-lb:0.2812, loss-ulb:0.0828, weight:0.50, lr:0.0008
[01:56:14.094] iteration:2915  t-loss:0.5503, loss-lb:0.3904, loss-ulb:0.3172, weight:0.50, lr:0.0008
[01:56:14.422] iteration:2916  t-loss:0.3427, loss-lb:0.2411, loss-ulb:0.2016, weight:0.50, lr:0.0008
[01:56:14.747] iteration:2917  t-loss:0.4595, loss-lb:0.3400, loss-ulb:0.2371, weight:0.50, lr:0.0008
[01:56:15.064] iteration:2918  t-loss:0.3105, loss-lb:0.2226, loss-ulb:0.1745, weight:0.50, lr:0.0008
[01:56:15.380] iteration:2919  t-loss:0.4007, loss-lb:0.2245, loss-ulb:0.3495, weight:0.50, lr:0.0008
[01:56:15.697] iteration:2920  t-loss:0.2839, loss-lb:0.2624, loss-ulb:0.0426, weight:0.50, lr:0.0008
[01:56:16.015] iteration:2921  t-loss:0.7313, loss-lb:0.4892, loss-ulb:0.4804, weight:0.50, lr:0.0008
[01:56:16.334] iteration:2922  t-loss:0.3873, loss-lb:0.2951, loss-ulb:0.1829, weight:0.50, lr:0.0008
[01:56:16.650] iteration:2923  t-loss:0.7490, loss-lb:0.5226, loss-ulb:0.4491, weight:0.50, lr:0.0008
[01:56:16.965] iteration:2924  t-loss:0.3581, loss-lb:0.3347, loss-ulb:0.0465, weight:0.50, lr:0.0008
[01:56:17.282] iteration:2925  t-loss:0.4199, loss-lb:0.3908, loss-ulb:0.0578, weight:0.50, lr:0.0008
[01:58:28.100] iteration 2925 : dice_score: 0.811152 best_dice: 0.811200
[01:58:28.101]  <<Test>> - Ep:116  - Dice-S/T:77.97/81.12, Best-S:80.85, Best-T:81.12
[01:58:28.101]           - AvgLoss(lb/ulb/all):0.30/0.19/0.40
[01:58:29.567] iteration:2926  t-loss:0.4179, loss-lb:0.2415, loss-ulb:0.3499, weight:0.50, lr:0.0008
[01:58:29.913] iteration:2927  t-loss:0.2277, loss-lb:0.1859, loss-ulb:0.0829, weight:0.50, lr:0.0008
[01:58:30.239] iteration:2928  t-loss:0.7525, loss-lb:0.7322, loss-ulb:0.0402, weight:0.50, lr:0.0008
[01:58:30.561] iteration:2929  t-loss:0.3322, loss-lb:0.2577, loss-ulb:0.1478, weight:0.50, lr:0.0008
[01:58:30.884] iteration:2930  t-loss:0.2786, loss-lb:0.2363, loss-ulb:0.0838, weight:0.50, lr:0.0008
[01:58:31.204] iteration:2931  t-loss:0.5203, loss-lb:0.4957, loss-ulb:0.0488, weight:0.50, lr:0.0008
[01:58:31.527] iteration:2932  t-loss:0.3808, loss-lb:0.3232, loss-ulb:0.1142, weight:0.50, lr:0.0008
[01:58:31.843] iteration:2933  t-loss:0.2956, loss-lb:0.2285, loss-ulb:0.1331, weight:0.50, lr:0.0008
[01:58:32.163] iteration:2934  t-loss:0.6781, loss-lb:0.4143, loss-ulb:0.5231, weight:0.50, lr:0.0008
[01:58:32.489] iteration:2935  t-loss:0.3294, loss-lb:0.2999, loss-ulb:0.0586, weight:0.50, lr:0.0008
[01:58:32.812] iteration:2936  t-loss:0.5072, loss-lb:0.3829, loss-ulb:0.2464, weight:0.50, lr:0.0008
[01:58:33.139] iteration:2937  t-loss:0.4474, loss-lb:0.2617, loss-ulb:0.3684, weight:0.50, lr:0.0008
[01:58:33.458] iteration:2938  t-loss:0.4892, loss-lb:0.2506, loss-ulb:0.4734, weight:0.50, lr:0.0008
[01:58:33.775] iteration:2939  t-loss:0.5368, loss-lb:0.1699, loss-ulb:0.7278, weight:0.50, lr:0.0008
[01:58:34.101] iteration:2940  t-loss:0.4004, loss-lb:0.3349, loss-ulb:0.1299, weight:0.50, lr:0.0008
[01:58:34.419] iteration:2941  t-loss:0.4996, loss-lb:0.3752, loss-ulb:0.2468, weight:0.50, lr:0.0008
[01:58:34.737] iteration:2942  t-loss:0.3705, loss-lb:0.2102, loss-ulb:0.3180, weight:0.50, lr:0.0008
[01:58:35.052] iteration:2943  t-loss:0.3823, loss-lb:0.2778, loss-ulb:0.2072, weight:0.50, lr:0.0008
[01:58:35.366] iteration:2944  t-loss:0.8014, loss-lb:0.6241, loss-ulb:0.3517, weight:0.50, lr:0.0008
[01:58:35.677] iteration:2945  t-loss:0.2137, loss-lb:0.1768, loss-ulb:0.0732, weight:0.50, lr:0.0008
[01:58:35.991] iteration:2946  t-loss:0.2483, loss-lb:0.2335, loss-ulb:0.0293, weight:0.50, lr:0.0008
[01:58:36.302] iteration:2947  t-loss:0.7985, loss-lb:0.4778, loss-ulb:0.6363, weight:0.50, lr:0.0008
[01:58:36.619] iteration:2948  t-loss:0.4142, loss-lb:0.2772, loss-ulb:0.2717, weight:0.50, lr:0.0008
[01:58:36.930] iteration:2949  t-loss:0.3569, loss-lb:0.2970, loss-ulb:0.1188, weight:0.50, lr:0.0008
[01:58:37.240] iteration:2950  t-loss:0.3726, loss-lb:0.3442, loss-ulb:0.0563, weight:0.50, lr:0.0008
[01:58:38.413] iteration:2951  t-loss:0.4436, loss-lb:0.3267, loss-ulb:0.2319, weight:0.50, lr:0.0008
[01:58:38.740] iteration:2952  t-loss:0.5555, loss-lb:0.2070, loss-ulb:0.6913, weight:0.50, lr:0.0008
[01:58:39.067] iteration:2953  t-loss:0.5491, loss-lb:0.3878, loss-ulb:0.3199, weight:0.50, lr:0.0008
[01:58:39.383] iteration:2954  t-loss:0.4273, loss-lb:0.3920, loss-ulb:0.0699, weight:0.50, lr:0.0008
[01:58:39.703] iteration:2955  t-loss:0.3220, loss-lb:0.2566, loss-ulb:0.1296, weight:0.50, lr:0.0008
[01:58:40.023] iteration:2956  t-loss:0.4203, loss-lb:0.3296, loss-ulb:0.1798, weight:0.50, lr:0.0008
[01:58:40.347] iteration:2957  t-loss:0.4225, loss-lb:0.2971, loss-ulb:0.2489, weight:0.50, lr:0.0008
[01:58:40.663] iteration:2958  t-loss:0.2921, loss-lb:0.2688, loss-ulb:0.0461, weight:0.50, lr:0.0008
[01:58:40.982] iteration:2959  t-loss:0.3645, loss-lb:0.3394, loss-ulb:0.0499, weight:0.50, lr:0.0008
[01:58:41.308] iteration:2960  t-loss:0.4324, loss-lb:0.3260, loss-ulb:0.2110, weight:0.50, lr:0.0008
[01:58:41.631] iteration:2961  t-loss:0.2726, loss-lb:0.2495, loss-ulb:0.0460, weight:0.50, lr:0.0008
[01:58:41.951] iteration:2962  t-loss:0.2703, loss-lb:0.1805, loss-ulb:0.1782, weight:0.50, lr:0.0008
[01:58:42.270] iteration:2963  t-loss:0.2743, loss-lb:0.2320, loss-ulb:0.0838, weight:0.50, lr:0.0008
[01:58:42.592] iteration:2964  t-loss:0.6158, loss-lb:0.4107, loss-ulb:0.4067, weight:0.50, lr:0.0008
[01:58:42.912] iteration:2965  t-loss:0.2534, loss-lb:0.1853, loss-ulb:0.1351, weight:0.50, lr:0.0008
[01:58:43.235] iteration:2966  t-loss:0.6820, loss-lb:0.5362, loss-ulb:0.2893, weight:0.50, lr:0.0008
[01:58:43.558] iteration:2967  t-loss:0.3109, loss-lb:0.2734, loss-ulb:0.0743, weight:0.50, lr:0.0008
[01:58:43.872] iteration:2968  t-loss:0.1648, loss-lb:0.1300, loss-ulb:0.0691, weight:0.50, lr:0.0008
[01:58:44.188] iteration:2969  t-loss:0.2652, loss-lb:0.2261, loss-ulb:0.0775, weight:0.50, lr:0.0008
[01:58:44.502] iteration:2970  t-loss:0.3362, loss-lb:0.2259, loss-ulb:0.2189, weight:0.50, lr:0.0008
[01:58:44.817] iteration:2971  t-loss:0.3078, loss-lb:0.2032, loss-ulb:0.2075, weight:0.50, lr:0.0008
[01:58:45.135] iteration:2972  t-loss:0.5329, loss-lb:0.4591, loss-ulb:0.1464, weight:0.50, lr:0.0008
[01:58:45.449] iteration:2973  t-loss:0.4089, loss-lb:0.2364, loss-ulb:0.3422, weight:0.50, lr:0.0008
[01:58:45.763] iteration:2974  t-loss:0.5257, loss-lb:0.4719, loss-ulb:0.1067, weight:0.50, lr:0.0008
[01:58:46.075] iteration:2975  t-loss:0.2444, loss-lb:0.2289, loss-ulb:0.0308, weight:0.50, lr:0.0008
[01:58:47.274] iteration:2976  t-loss:0.3262, loss-lb:0.2925, loss-ulb:0.0670, weight:0.50, lr:0.0008
[01:58:47.611] iteration:2977  t-loss:0.4679, loss-lb:0.2545, loss-ulb:0.4233, weight:0.50, lr:0.0008
[01:58:47.945] iteration:2978  t-loss:0.3558, loss-lb:0.3337, loss-ulb:0.0439, weight:0.50, lr:0.0008
[01:58:48.270] iteration:2979  t-loss:0.3795, loss-lb:0.2843, loss-ulb:0.1889, weight:0.50, lr:0.0008
[01:58:48.593] iteration:2980  t-loss:0.4714, loss-lb:0.4400, loss-ulb:0.0622, weight:0.50, lr:0.0008
[01:58:48.910] iteration:2981  t-loss:0.2409, loss-lb:0.1588, loss-ulb:0.1628, weight:0.50, lr:0.0008
[01:58:49.228] iteration:2982  t-loss:0.4303, loss-lb:0.3098, loss-ulb:0.2390, weight:0.50, lr:0.0008
[01:58:49.545] iteration:2983  t-loss:0.3136, loss-lb:0.2253, loss-ulb:0.1752, weight:0.50, lr:0.0008
[01:58:49.862] iteration:2984  t-loss:0.2636, loss-lb:0.2320, loss-ulb:0.0628, weight:0.50, lr:0.0008
[01:58:50.180] iteration:2985  t-loss:0.2503, loss-lb:0.1851, loss-ulb:0.1293, weight:0.50, lr:0.0008
[01:58:50.497] iteration:2986  t-loss:0.4257, loss-lb:0.2877, loss-ulb:0.2737, weight:0.50, lr:0.0008
[01:58:50.818] iteration:2987  t-loss:0.4058, loss-lb:0.3228, loss-ulb:0.1646, weight:0.50, lr:0.0008
[01:58:51.132] iteration:2988  t-loss:0.3535, loss-lb:0.2056, loss-ulb:0.2933, weight:0.50, lr:0.0008
[01:58:51.449] iteration:2989  t-loss:0.2615, loss-lb:0.2200, loss-ulb:0.0822, weight:0.50, lr:0.0008
[01:58:51.762] iteration:2990  t-loss:0.5708, loss-lb:0.1789, loss-ulb:0.7775, weight:0.50, lr:0.0008
[01:58:52.082] iteration:2991  t-loss:0.3189, loss-lb:0.2605, loss-ulb:0.1159, weight:0.50, lr:0.0008
[01:58:52.400] iteration:2992  t-loss:0.4535, loss-lb:0.3042, loss-ulb:0.2962, weight:0.50, lr:0.0008
[01:58:52.713] iteration:2993  t-loss:0.4411, loss-lb:0.2788, loss-ulb:0.3219, weight:0.50, lr:0.0008
[01:58:53.029] iteration:2994  t-loss:0.4157, loss-lb:0.3151, loss-ulb:0.1995, weight:0.50, lr:0.0008
[01:58:53.347] iteration:2995  t-loss:0.4192, loss-lb:0.3156, loss-ulb:0.2055, weight:0.50, lr:0.0008
[01:58:53.660] iteration:2996  t-loss:0.3475, loss-lb:0.2156, loss-ulb:0.2617, weight:0.50, lr:0.0008
[01:58:53.972] iteration:2997  t-loss:0.3830, loss-lb:0.2735, loss-ulb:0.2173, weight:0.50, lr:0.0008
[01:58:54.288] iteration:2998  t-loss:0.4981, loss-lb:0.4265, loss-ulb:0.1422, weight:0.50, lr:0.0008
[01:58:54.603] iteration:2999  t-loss:0.2734, loss-lb:0.2179, loss-ulb:0.1102, weight:0.50, lr:0.0008
[01:58:54.919] iteration:3000  t-loss:0.6931, loss-lb:0.4445, loss-ulb:0.4932, weight:0.50, lr:0.0008
[01:58:56.304] iteration:3001  t-loss:0.8806, loss-lb:0.3347, loss-ulb:0.9526, weight:0.57, lr:0.0008
[01:58:56.633] iteration:3002  t-loss:0.8535, loss-lb:0.4593, loss-ulb:0.6880, weight:0.57, lr:0.0008
[01:58:56.963] iteration:3003  t-loss:0.6983, loss-lb:0.2075, loss-ulb:0.8566, weight:0.57, lr:0.0008
[01:58:57.280] iteration:3004  t-loss:0.6403, loss-lb:0.1972, loss-ulb:0.7732, weight:0.57, lr:0.0008
[01:58:57.599] iteration:3005  t-loss:0.5660, loss-lb:0.4335, loss-ulb:0.2313, weight:0.57, lr:0.0008
[01:58:57.917] iteration:3006  t-loss:0.2343, loss-lb:0.1989, loss-ulb:0.0619, weight:0.57, lr:0.0008
[01:58:58.232] iteration:3007  t-loss:0.4360, loss-lb:0.2476, loss-ulb:0.3288, weight:0.57, lr:0.0008
[01:58:58.553] iteration:3008  t-loss:0.4825, loss-lb:0.3685, loss-ulb:0.1990, weight:0.57, lr:0.0008
[01:58:58.869] iteration:3009  t-loss:0.4354, loss-lb:0.2644, loss-ulb:0.2985, weight:0.57, lr:0.0008
[01:58:59.189] iteration:3010  t-loss:0.3307, loss-lb:0.2375, loss-ulb:0.1625, weight:0.57, lr:0.0008
[01:58:59.514] iteration:3011  t-loss:0.3847, loss-lb:0.3042, loss-ulb:0.1405, weight:0.57, lr:0.0008
[01:58:59.834] iteration:3012  t-loss:0.6674, loss-lb:0.5260, loss-ulb:0.2467, weight:0.57, lr:0.0008
[01:59:00.151] iteration:3013  t-loss:0.3479, loss-lb:0.2082, loss-ulb:0.2438, weight:0.57, lr:0.0008
[01:59:00.472] iteration:3014  t-loss:0.3677, loss-lb:0.2920, loss-ulb:0.1322, weight:0.57, lr:0.0008
[01:59:00.787] iteration:3015  t-loss:0.2815, loss-lb:0.2256, loss-ulb:0.0976, weight:0.57, lr:0.0008
[01:59:01.102] iteration:3016  t-loss:0.2324, loss-lb:0.2146, loss-ulb:0.0311, weight:0.57, lr:0.0008
[01:59:01.424] iteration:3017  t-loss:0.5915, loss-lb:0.3259, loss-ulb:0.4634, weight:0.57, lr:0.0008
[01:59:01.742] iteration:3018  t-loss:0.4637, loss-lb:0.3681, loss-ulb:0.1667, weight:0.57, lr:0.0008
[01:59:02.057] iteration:3019  t-loss:0.4551, loss-lb:0.4328, loss-ulb:0.0390, weight:0.57, lr:0.0008
[01:59:02.370] iteration:3020  t-loss:0.4575, loss-lb:0.4378, loss-ulb:0.0344, weight:0.57, lr:0.0008
[01:59:02.683] iteration:3021  t-loss:0.2802, loss-lb:0.1880, loss-ulb:0.1609, weight:0.57, lr:0.0008
[01:59:02.995] iteration:3022  t-loss:0.2581, loss-lb:0.1891, loss-ulb:0.1203, weight:0.57, lr:0.0008
[01:59:03.309] iteration:3023  t-loss:0.3183, loss-lb:0.2214, loss-ulb:0.1690, weight:0.57, lr:0.0008
[01:59:03.623] iteration:3024  t-loss:1.0187, loss-lb:0.6131, loss-ulb:0.7080, weight:0.57, lr:0.0008
[01:59:03.938] iteration:3025  t-loss:0.2773, loss-lb:0.2331, loss-ulb:0.0773, weight:0.57, lr:0.0008
[02:01:18.596] iteration 3025 : dice_score: 0.794758 best_dice: 0.811200
[02:01:18.597]  <<Test>> - Ep:120  - Dice-S/T:77.35/79.48, Best-S:80.85, Best-T:81.12
[02:01:18.597]           - AvgLoss(lb/ulb/all):0.31/0.19/0.42
[02:01:19.952] iteration:3026  t-loss:0.2598, loss-lb:0.1520, loss-ulb:0.1882, weight:0.57, lr:0.0008
[02:01:20.274] iteration:3027  t-loss:0.4491, loss-lb:0.2405, loss-ulb:0.3640, weight:0.57, lr:0.0008
[02:01:20.600] iteration:3028  t-loss:0.4541, loss-lb:0.4162, loss-ulb:0.0662, weight:0.57, lr:0.0008
[02:01:20.918] iteration:3029  t-loss:0.4155, loss-lb:0.2107, loss-ulb:0.3575, weight:0.57, lr:0.0008
[02:01:21.237] iteration:3030  t-loss:0.3980, loss-lb:0.3523, loss-ulb:0.0797, weight:0.57, lr:0.0008
[02:01:21.553] iteration:3031  t-loss:0.3288, loss-lb:0.2746, loss-ulb:0.0946, weight:0.57, lr:0.0008
[02:01:21.873] iteration:3032  t-loss:0.3016, loss-lb:0.2216, loss-ulb:0.1397, weight:0.57, lr:0.0008
[02:01:22.197] iteration:3033  t-loss:0.3250, loss-lb:0.2483, loss-ulb:0.1339, weight:0.57, lr:0.0008
[02:01:22.515] iteration:3034  t-loss:0.3529, loss-lb:0.3178, loss-ulb:0.0613, weight:0.57, lr:0.0008
[02:01:22.831] iteration:3035  t-loss:0.1918, loss-lb:0.1577, loss-ulb:0.0594, weight:0.57, lr:0.0008
[02:01:23.149] iteration:3036  t-loss:0.4343, loss-lb:0.2772, loss-ulb:0.2741, weight:0.57, lr:0.0008
[02:01:23.462] iteration:3037  t-loss:0.4556, loss-lb:0.2475, loss-ulb:0.3631, weight:0.57, lr:0.0008
[02:01:23.787] iteration:3038  t-loss:0.3633, loss-lb:0.2638, loss-ulb:0.1737, weight:0.57, lr:0.0008
[02:01:24.105] iteration:3039  t-loss:0.2985, loss-lb:0.2505, loss-ulb:0.0839, weight:0.57, lr:0.0008
[02:01:24.424] iteration:3040  t-loss:0.3996, loss-lb:0.1702, loss-ulb:0.4004, weight:0.57, lr:0.0008
[02:01:24.746] iteration:3041  t-loss:0.6447, loss-lb:0.2400, loss-ulb:0.7063, weight:0.57, lr:0.0008
[02:01:25.068] iteration:3042  t-loss:0.3227, loss-lb:0.3026, loss-ulb:0.0351, weight:0.57, lr:0.0008
[02:01:25.381] iteration:3043  t-loss:0.2181, loss-lb:0.1746, loss-ulb:0.0759, weight:0.57, lr:0.0008
[02:01:25.695] iteration:3044  t-loss:0.4131, loss-lb:0.2565, loss-ulb:0.2733, weight:0.57, lr:0.0008
[02:01:26.010] iteration:3045  t-loss:0.5967, loss-lb:0.3498, loss-ulb:0.4309, weight:0.57, lr:0.0008
[02:01:26.321] iteration:3046  t-loss:0.4530, loss-lb:0.2352, loss-ulb:0.3801, weight:0.57, lr:0.0008
[02:01:26.636] iteration:3047  t-loss:0.4918, loss-lb:0.2779, loss-ulb:0.3733, weight:0.57, lr:0.0008
[02:01:26.949] iteration:3048  t-loss:0.3999, loss-lb:0.3089, loss-ulb:0.1588, weight:0.57, lr:0.0008
[02:01:27.264] iteration:3049  t-loss:0.5100, loss-lb:0.1326, loss-ulb:0.6586, weight:0.57, lr:0.0008
[02:01:27.578] iteration:3050  t-loss:0.2965, loss-lb:0.1824, loss-ulb:0.1992, weight:0.57, lr:0.0008
[02:01:28.837] iteration:3051  t-loss:0.4964, loss-lb:0.2986, loss-ulb:0.3453, weight:0.57, lr:0.0008
[02:01:29.186] iteration:3052  t-loss:0.6796, loss-lb:0.5545, loss-ulb:0.2182, weight:0.57, lr:0.0008
[02:01:29.517] iteration:3053  t-loss:0.3032, loss-lb:0.1811, loss-ulb:0.2132, weight:0.57, lr:0.0008
[02:01:29.845] iteration:3054  t-loss:0.4566, loss-lb:0.2284, loss-ulb:0.3982, weight:0.57, lr:0.0008
[02:01:30.170] iteration:3055  t-loss:0.6916, loss-lb:0.5113, loss-ulb:0.3147, weight:0.57, lr:0.0008
[02:01:30.484] iteration:3056  t-loss:0.6046, loss-lb:0.2203, loss-ulb:0.6708, weight:0.57, lr:0.0008
[02:01:30.801] iteration:3057  t-loss:0.5247, loss-lb:0.3837, loss-ulb:0.2459, weight:0.57, lr:0.0008
[02:01:31.122] iteration:3058  t-loss:0.2945, loss-lb:0.2127, loss-ulb:0.1427, weight:0.57, lr:0.0008
[02:01:31.442] iteration:3059  t-loss:0.4051, loss-lb:0.3237, loss-ulb:0.1422, weight:0.57, lr:0.0008
[02:01:31.758] iteration:3060  t-loss:0.4827, loss-lb:0.2528, loss-ulb:0.4013, weight:0.57, lr:0.0008
[02:01:32.076] iteration:3061  t-loss:0.3239, loss-lb:0.2240, loss-ulb:0.1743, weight:0.57, lr:0.0008
[02:01:32.393] iteration:3062  t-loss:0.3241, loss-lb:0.2083, loss-ulb:0.2020, weight:0.57, lr:0.0008
[02:01:32.711] iteration:3063  t-loss:0.3169, loss-lb:0.2239, loss-ulb:0.1623, weight:0.57, lr:0.0008
[02:01:33.027] iteration:3064  t-loss:0.6731, loss-lb:0.3895, loss-ulb:0.4949, weight:0.57, lr:0.0008
[02:01:33.348] iteration:3065  t-loss:0.4794, loss-lb:0.3033, loss-ulb:0.3074, weight:0.57, lr:0.0008
[02:01:33.665] iteration:3066  t-loss:0.4942, loss-lb:0.2367, loss-ulb:0.4493, weight:0.57, lr:0.0008
[02:01:33.985] iteration:3067  t-loss:0.3011, loss-lb:0.2246, loss-ulb:0.1335, weight:0.57, lr:0.0008
[02:01:34.305] iteration:3068  t-loss:0.7558, loss-lb:0.7151, loss-ulb:0.0709, weight:0.57, lr:0.0008
[02:01:34.620] iteration:3069  t-loss:0.4964, loss-lb:0.2373, loss-ulb:0.4521, weight:0.57, lr:0.0008
[02:01:34.934] iteration:3070  t-loss:0.3519, loss-lb:0.2307, loss-ulb:0.2116, weight:0.57, lr:0.0008
[02:01:35.252] iteration:3071  t-loss:0.4192, loss-lb:0.2550, loss-ulb:0.2866, weight:0.57, lr:0.0008
[02:01:35.570] iteration:3072  t-loss:0.4500, loss-lb:0.3745, loss-ulb:0.1318, weight:0.57, lr:0.0008
[02:01:35.886] iteration:3073  t-loss:0.4100, loss-lb:0.1691, loss-ulb:0.4204, weight:0.57, lr:0.0008
[02:01:36.203] iteration:3074  t-loss:0.4277, loss-lb:0.2950, loss-ulb:0.2316, weight:0.57, lr:0.0008
[02:01:36.517] iteration:3075  t-loss:0.2812, loss-lb:0.2565, loss-ulb:0.0431, weight:0.57, lr:0.0008
[02:01:37.846] iteration:3076  t-loss:0.3797, loss-lb:0.2773, loss-ulb:0.1788, weight:0.57, lr:0.0008
[02:01:38.187] iteration:3077  t-loss:0.3335, loss-lb:0.2569, loss-ulb:0.1338, weight:0.57, lr:0.0008
[02:01:38.514] iteration:3078  t-loss:0.2844, loss-lb:0.2114, loss-ulb:0.1275, weight:0.57, lr:0.0008
[02:01:38.832] iteration:3079  t-loss:0.5437, loss-lb:0.2810, loss-ulb:0.4583, weight:0.57, lr:0.0008
[02:01:39.154] iteration:3080  t-loss:0.5579, loss-lb:0.3271, loss-ulb:0.4028, weight:0.57, lr:0.0008
[02:01:39.481] iteration:3081  t-loss:0.5329, loss-lb:0.4529, loss-ulb:0.1395, weight:0.57, lr:0.0008
[02:01:39.805] iteration:3082  t-loss:0.7165, loss-lb:0.4113, loss-ulb:0.5326, weight:0.57, lr:0.0008
[02:01:40.123] iteration:3083  t-loss:0.3710, loss-lb:0.2514, loss-ulb:0.2087, weight:0.57, lr:0.0008
[02:01:40.444] iteration:3084  t-loss:0.3423, loss-lb:0.2637, loss-ulb:0.1372, weight:0.57, lr:0.0008
[02:01:40.766] iteration:3085  t-loss:0.3874, loss-lb:0.2749, loss-ulb:0.1963, weight:0.57, lr:0.0008
[02:01:41.085] iteration:3086  t-loss:0.4339, loss-lb:0.3716, loss-ulb:0.1088, weight:0.57, lr:0.0008
[02:01:41.403] iteration:3087  t-loss:0.4222, loss-lb:0.3169, loss-ulb:0.1839, weight:0.57, lr:0.0008
[02:01:41.723] iteration:3088  t-loss:0.5245, loss-lb:0.1821, loss-ulb:0.5975, weight:0.57, lr:0.0008
[02:01:42.047] iteration:3089  t-loss:0.3973, loss-lb:0.2769, loss-ulb:0.2101, weight:0.57, lr:0.0008
[02:01:42.370] iteration:3090  t-loss:0.4031, loss-lb:0.2437, loss-ulb:0.2781, weight:0.57, lr:0.0008
[02:01:42.687] iteration:3091  t-loss:0.2409, loss-lb:0.2050, loss-ulb:0.0626, weight:0.57, lr:0.0008
[02:01:43.010] iteration:3092  t-loss:0.4130, loss-lb:0.2703, loss-ulb:0.2491, weight:0.57, lr:0.0008
[02:01:43.330] iteration:3093  t-loss:0.3070, loss-lb:0.2310, loss-ulb:0.1327, weight:0.57, lr:0.0008
[02:01:43.650] iteration:3094  t-loss:0.4644, loss-lb:0.4098, loss-ulb:0.0953, weight:0.57, lr:0.0008
[02:01:43.966] iteration:3095  t-loss:0.3082, loss-lb:0.2025, loss-ulb:0.1844, weight:0.57, lr:0.0008
[02:01:44.283] iteration:3096  t-loss:0.5486, loss-lb:0.3634, loss-ulb:0.3234, weight:0.57, lr:0.0008
[02:01:44.600] iteration:3097  t-loss:0.4933, loss-lb:0.3657, loss-ulb:0.2226, weight:0.57, lr:0.0008
[02:01:44.917] iteration:3098  t-loss:0.3655, loss-lb:0.2975, loss-ulb:0.1188, weight:0.57, lr:0.0008
[02:01:45.232] iteration:3099  t-loss:0.6080, loss-lb:0.5129, loss-ulb:0.1661, weight:0.57, lr:0.0008
[02:01:45.549] iteration:3100  t-loss:0.3124, loss-lb:0.1911, loss-ulb:0.2117, weight:0.57, lr:0.0008
[02:01:46.792] iteration:3101  t-loss:0.4991, loss-lb:0.3887, loss-ulb:0.1925, weight:0.57, lr:0.0008
[02:01:47.123] iteration:3102  t-loss:0.3885, loss-lb:0.3403, loss-ulb:0.0841, weight:0.57, lr:0.0008
[02:01:47.444] iteration:3103  t-loss:0.2986, loss-lb:0.1702, loss-ulb:0.2241, weight:0.57, lr:0.0008
[02:01:47.768] iteration:3104  t-loss:0.4674, loss-lb:0.4298, loss-ulb:0.0656, weight:0.57, lr:0.0008
[02:01:48.090] iteration:3105  t-loss:0.2775, loss-lb:0.1911, loss-ulb:0.1507, weight:0.57, lr:0.0008
[02:01:48.410] iteration:3106  t-loss:0.2432, loss-lb:0.2255, loss-ulb:0.0308, weight:0.57, lr:0.0008
[02:01:48.729] iteration:3107  t-loss:0.3044, loss-lb:0.2125, loss-ulb:0.1605, weight:0.57, lr:0.0008
[02:01:49.049] iteration:3108  t-loss:0.2545, loss-lb:0.2112, loss-ulb:0.0755, weight:0.57, lr:0.0008
[02:01:49.369] iteration:3109  t-loss:0.5366, loss-lb:0.4865, loss-ulb:0.0874, weight:0.57, lr:0.0008
[02:01:49.692] iteration:3110  t-loss:0.5749, loss-lb:0.4235, loss-ulb:0.2641, weight:0.57, lr:0.0008
[02:01:50.039] iteration:3111  t-loss:0.2921, loss-lb:0.2017, loss-ulb:0.1577, weight:0.57, lr:0.0008
[02:01:50.369] iteration:3112  t-loss:0.5252, loss-lb:0.4333, loss-ulb:0.1604, weight:0.57, lr:0.0008
[02:01:50.704] iteration:3113  t-loss:0.4389, loss-lb:0.3383, loss-ulb:0.1756, weight:0.57, lr:0.0008
[02:01:51.042] iteration:3114  t-loss:0.7569, loss-lb:0.6189, loss-ulb:0.2410, weight:0.57, lr:0.0008
[02:01:51.386] iteration:3115  t-loss:0.4037, loss-lb:0.3649, loss-ulb:0.0678, weight:0.57, lr:0.0008
[02:01:51.736] iteration:3116  t-loss:0.6621, loss-lb:0.5805, loss-ulb:0.1424, weight:0.57, lr:0.0008
[02:01:52.059] iteration:3117  t-loss:0.4531, loss-lb:0.2881, loss-ulb:0.2881, weight:0.57, lr:0.0008
[02:01:52.383] iteration:3118  t-loss:0.4399, loss-lb:0.3861, loss-ulb:0.0939, weight:0.57, lr:0.0008
[02:01:52.701] iteration:3119  t-loss:0.4687, loss-lb:0.2885, loss-ulb:0.3144, weight:0.57, lr:0.0008
[02:01:53.018] iteration:3120  t-loss:0.4603, loss-lb:0.3940, loss-ulb:0.1157, weight:0.57, lr:0.0008
[02:01:53.332] iteration:3121  t-loss:0.2897, loss-lb:0.1795, loss-ulb:0.1922, weight:0.57, lr:0.0008
[02:01:53.645] iteration:3122  t-loss:0.3182, loss-lb:0.2365, loss-ulb:0.1426, weight:0.57, lr:0.0008
[02:01:53.961] iteration:3123  t-loss:0.3644, loss-lb:0.2607, loss-ulb:0.1809, weight:0.57, lr:0.0008
[02:01:54.283] iteration:3124  t-loss:0.3092, loss-lb:0.1900, loss-ulb:0.2080, weight:0.57, lr:0.0008
[02:01:54.605] iteration:3125  t-loss:0.2942, loss-lb:0.2022, loss-ulb:0.1606, weight:0.57, lr:0.0008
[02:04:06.568] iteration 3125 : dice_score: 0.807956 best_dice: 0.811200
[02:04:06.569]  <<Test>> - Ep:124  - Dice-S/T:24.58/80.80, Best-S:80.85, Best-T:81.12
[02:04:06.569]           - AvgLoss(lb/ulb/all):0.32/0.16/0.42
[02:04:07.806] iteration:3126  t-loss:0.1902, loss-lb:0.1400, loss-ulb:0.0876, weight:0.57, lr:0.0008
[02:04:08.143] iteration:3127  t-loss:0.3791, loss-lb:0.1853, loss-ulb:0.3382, weight:0.57, lr:0.0008
[02:04:08.479] iteration:3128  t-loss:0.4605, loss-lb:0.3467, loss-ulb:0.1985, weight:0.57, lr:0.0008
[02:04:08.800] iteration:3129  t-loss:0.3469, loss-lb:0.2733, loss-ulb:0.1284, weight:0.57, lr:0.0008
[02:04:09.121] iteration:3130  t-loss:0.2319, loss-lb:0.1765, loss-ulb:0.0967, weight:0.57, lr:0.0008
[02:04:09.445] iteration:3131  t-loss:0.4376, loss-lb:0.3501, loss-ulb:0.1527, weight:0.57, lr:0.0008
[02:04:09.772] iteration:3132  t-loss:0.3665, loss-lb:0.2438, loss-ulb:0.2142, weight:0.57, lr:0.0008
[02:04:10.093] iteration:3133  t-loss:0.6651, loss-lb:0.4813, loss-ulb:0.3208, weight:0.57, lr:0.0008
[02:04:10.416] iteration:3134  t-loss:0.4195, loss-lb:0.3013, loss-ulb:0.2063, weight:0.57, lr:0.0008
[02:04:10.734] iteration:3135  t-loss:0.4146, loss-lb:0.1723, loss-ulb:0.4228, weight:0.57, lr:0.0008
[02:04:11.058] iteration:3136  t-loss:0.2536, loss-lb:0.1622, loss-ulb:0.1596, weight:0.57, lr:0.0008
[02:04:11.376] iteration:3137  t-loss:0.5893, loss-lb:0.4570, loss-ulb:0.2308, weight:0.57, lr:0.0008
[02:04:11.693] iteration:3138  t-loss:0.4086, loss-lb:0.3615, loss-ulb:0.0822, weight:0.57, lr:0.0008
[02:04:12.019] iteration:3139  t-loss:0.4529, loss-lb:0.3473, loss-ulb:0.1842, weight:0.57, lr:0.0008
[02:04:12.342] iteration:3140  t-loss:0.3959, loss-lb:0.3657, loss-ulb:0.0527, weight:0.57, lr:0.0008
[02:04:12.657] iteration:3141  t-loss:0.3999, loss-lb:0.2070, loss-ulb:0.3367, weight:0.57, lr:0.0008
[02:04:12.984] iteration:3142  t-loss:0.6871, loss-lb:0.4054, loss-ulb:0.4915, weight:0.57, lr:0.0008
[02:04:13.302] iteration:3143  t-loss:0.5411, loss-lb:0.3505, loss-ulb:0.3327, weight:0.57, lr:0.0008
[02:04:13.616] iteration:3144  t-loss:0.3606, loss-lb:0.2159, loss-ulb:0.2525, weight:0.57, lr:0.0008
[02:04:13.928] iteration:3145  t-loss:0.3574, loss-lb:0.3191, loss-ulb:0.0670, weight:0.57, lr:0.0008
[02:04:14.241] iteration:3146  t-loss:0.6240, loss-lb:0.3958, loss-ulb:0.3983, weight:0.57, lr:0.0008
[02:04:14.556] iteration:3147  t-loss:0.3383, loss-lb:0.2457, loss-ulb:0.1617, weight:0.57, lr:0.0008
[02:04:14.876] iteration:3148  t-loss:0.3010, loss-lb:0.1578, loss-ulb:0.2498, weight:0.57, lr:0.0008
[02:04:15.192] iteration:3149  t-loss:0.2031, loss-lb:0.1878, loss-ulb:0.0268, weight:0.57, lr:0.0008
[02:04:15.506] iteration:3150  t-loss:0.2429, loss-lb:0.1780, loss-ulb:0.1133, weight:0.57, lr:0.0008
[02:04:16.949] iteration:3151  t-loss:0.2894, loss-lb:0.1560, loss-ulb:0.2060, weight:0.65, lr:0.0008
[02:04:17.298] iteration:3152  t-loss:0.5284, loss-lb:0.1597, loss-ulb:0.5696, weight:0.65, lr:0.0008
[02:04:17.631] iteration:3153  t-loss:0.2310, loss-lb:0.1762, loss-ulb:0.0846, weight:0.65, lr:0.0008
[02:04:17.957] iteration:3154  t-loss:0.2915, loss-lb:0.2539, loss-ulb:0.0580, weight:0.65, lr:0.0008
[02:04:18.280] iteration:3155  t-loss:0.2799, loss-lb:0.1870, loss-ulb:0.1435, weight:0.65, lr:0.0008
[02:04:18.602] iteration:3156  t-loss:0.2985, loss-lb:0.2106, loss-ulb:0.1358, weight:0.65, lr:0.0008
[02:04:18.926] iteration:3157  t-loss:0.5324, loss-lb:0.3246, loss-ulb:0.3210, weight:0.65, lr:0.0008
[02:04:19.243] iteration:3158  t-loss:0.2869, loss-lb:0.2205, loss-ulb:0.1025, weight:0.65, lr:0.0008
[02:04:19.568] iteration:3159  t-loss:0.6914, loss-lb:0.6222, loss-ulb:0.1068, weight:0.65, lr:0.0008
[02:04:19.890] iteration:3160  t-loss:0.4478, loss-lb:0.4220, loss-ulb:0.0399, weight:0.65, lr:0.0008
[02:04:20.212] iteration:3161  t-loss:0.3317, loss-lb:0.1911, loss-ulb:0.2171, weight:0.65, lr:0.0008
[02:04:20.532] iteration:3162  t-loss:0.2260, loss-lb:0.2047, loss-ulb:0.0328, weight:0.65, lr:0.0008
[02:04:20.856] iteration:3163  t-loss:0.5536, loss-lb:0.2169, loss-ulb:0.5202, weight:0.65, lr:0.0008
[02:04:21.179] iteration:3164  t-loss:0.4356, loss-lb:0.1965, loss-ulb:0.3695, weight:0.65, lr:0.0008
[02:04:21.504] iteration:3165  t-loss:0.4231, loss-lb:0.3698, loss-ulb:0.0824, weight:0.65, lr:0.0008
[02:04:21.821] iteration:3166  t-loss:0.2456, loss-lb:0.2051, loss-ulb:0.0625, weight:0.65, lr:0.0008
[02:04:22.141] iteration:3167  t-loss:0.3194, loss-lb:0.2895, loss-ulb:0.0463, weight:0.65, lr:0.0008
[02:04:22.457] iteration:3168  t-loss:0.3163, loss-lb:0.2382, loss-ulb:0.1207, weight:0.65, lr:0.0008
[02:04:22.775] iteration:3169  t-loss:0.3949, loss-lb:0.2904, loss-ulb:0.1615, weight:0.65, lr:0.0008
[02:04:23.087] iteration:3170  t-loss:0.3874, loss-lb:0.1860, loss-ulb:0.3112, weight:0.65, lr:0.0008
[02:04:23.401] iteration:3171  t-loss:0.7009, loss-lb:0.5341, loss-ulb:0.2577, weight:0.65, lr:0.0008
[02:04:23.716] iteration:3172  t-loss:0.3771, loss-lb:0.2504, loss-ulb:0.1957, weight:0.65, lr:0.0008
[02:04:24.031] iteration:3173  t-loss:0.3486, loss-lb:0.2308, loss-ulb:0.1821, weight:0.65, lr:0.0008
[02:04:24.345] iteration:3174  t-loss:0.4285, loss-lb:0.2756, loss-ulb:0.2363, weight:0.65, lr:0.0008
[02:04:24.671] iteration:3175  t-loss:0.2666, loss-lb:0.2027, loss-ulb:0.0987, weight:0.65, lr:0.0008
[02:04:25.761] iteration:3176  t-loss:0.2453, loss-lb:0.2227, loss-ulb:0.0349, weight:0.65, lr:0.0008
[02:04:26.090] iteration:3177  t-loss:0.2464, loss-lb:0.1990, loss-ulb:0.0732, weight:0.65, lr:0.0008
[02:04:26.426] iteration:3178  t-loss:0.5403, loss-lb:0.3505, loss-ulb:0.2932, weight:0.65, lr:0.0008
[02:04:26.748] iteration:3179  t-loss:0.4605, loss-lb:0.2030, loss-ulb:0.3978, weight:0.65, lr:0.0008
[02:04:27.069] iteration:3180  t-loss:0.3345, loss-lb:0.2406, loss-ulb:0.1450, weight:0.65, lr:0.0008
[02:04:27.394] iteration:3181  t-loss:0.3586, loss-lb:0.2740, loss-ulb:0.1307, weight:0.65, lr:0.0008
[02:04:27.711] iteration:3182  t-loss:0.2591, loss-lb:0.2054, loss-ulb:0.0831, weight:0.65, lr:0.0008
[02:04:28.033] iteration:3183  t-loss:0.3860, loss-lb:0.2858, loss-ulb:0.1548, weight:0.65, lr:0.0008
[02:04:28.355] iteration:3184  t-loss:0.3150, loss-lb:0.2746, loss-ulb:0.0624, weight:0.65, lr:0.0008
[02:04:28.673] iteration:3185  t-loss:0.5852, loss-lb:0.2340, loss-ulb:0.5426, weight:0.65, lr:0.0008
[02:04:28.995] iteration:3186  t-loss:0.6013, loss-lb:0.2482, loss-ulb:0.5456, weight:0.65, lr:0.0008
[02:04:29.309] iteration:3187  t-loss:0.6402, loss-lb:0.1917, loss-ulb:0.6930, weight:0.65, lr:0.0008
[02:04:29.626] iteration:3188  t-loss:0.2072, loss-lb:0.1777, loss-ulb:0.0456, weight:0.65, lr:0.0008
[02:04:29.950] iteration:3189  t-loss:0.3135, loss-lb:0.2084, loss-ulb:0.1623, weight:0.65, lr:0.0008
[02:04:30.267] iteration:3190  t-loss:0.4704, loss-lb:0.2482, loss-ulb:0.3433, weight:0.65, lr:0.0008
[02:04:30.588] iteration:3191  t-loss:0.4054, loss-lb:0.2010, loss-ulb:0.3159, weight:0.65, lr:0.0008
[02:04:30.916] iteration:3192  t-loss:0.4241, loss-lb:0.3257, loss-ulb:0.1520, weight:0.65, lr:0.0008
[02:04:31.236] iteration:3193  t-loss:0.5827, loss-lb:0.4659, loss-ulb:0.1805, weight:0.65, lr:0.0008
[02:04:31.555] iteration:3194  t-loss:0.3758, loss-lb:0.2730, loss-ulb:0.1588, weight:0.65, lr:0.0008
[02:04:31.873] iteration:3195  t-loss:0.6839, loss-lb:0.2826, loss-ulb:0.6200, weight:0.65, lr:0.0008
[02:04:32.186] iteration:3196  t-loss:0.3183, loss-lb:0.2118, loss-ulb:0.1645, weight:0.65, lr:0.0008
[02:04:32.501] iteration:3197  t-loss:0.2406, loss-lb:0.2199, loss-ulb:0.0321, weight:0.65, lr:0.0008
[02:04:32.825] iteration:3198  t-loss:0.6079, loss-lb:0.3122, loss-ulb:0.4568, weight:0.65, lr:0.0008
[02:04:33.148] iteration:3199  t-loss:0.2755, loss-lb:0.2401, loss-ulb:0.0547, weight:0.65, lr:0.0008
[02:04:33.469] iteration:3200  t-loss:0.4168, loss-lb:0.3890, loss-ulb:0.0429, weight:0.65, lr:0.0008
[02:04:35.090] iteration:3201  t-loss:0.5644, loss-lb:0.4255, loss-ulb:0.2146, weight:0.65, lr:0.0008
[02:04:35.455] iteration:3202  t-loss:0.5316, loss-lb:0.2809, loss-ulb:0.3874, weight:0.65, lr:0.0008
[02:04:35.830] iteration:3203  t-loss:0.3653, loss-lb:0.3128, loss-ulb:0.0810, weight:0.65, lr:0.0008
[02:04:36.185] iteration:3204  t-loss:0.8601, loss-lb:0.5377, loss-ulb:0.4981, weight:0.65, lr:0.0008
[02:04:36.538] iteration:3205  t-loss:0.3198, loss-lb:0.1341, loss-ulb:0.2869, weight:0.65, lr:0.0008
[02:04:36.892] iteration:3206  t-loss:0.4666, loss-lb:0.3807, loss-ulb:0.1327, weight:0.65, lr:0.0008
[02:04:37.237] iteration:3207  t-loss:0.3094, loss-lb:0.2660, loss-ulb:0.0671, weight:0.65, lr:0.0008
[02:04:37.599] iteration:3208  t-loss:0.6005, loss-lb:0.3281, loss-ulb:0.4209, weight:0.65, lr:0.0008
[02:04:37.938] iteration:3209  t-loss:0.4270, loss-lb:0.1978, loss-ulb:0.3541, weight:0.65, lr:0.0008
[02:04:38.278] iteration:3210  t-loss:0.4943, loss-lb:0.1769, loss-ulb:0.4904, weight:0.65, lr:0.0008
[02:04:38.636] iteration:3211  t-loss:0.7087, loss-lb:0.5071, loss-ulb:0.3114, weight:0.65, lr:0.0008
[02:04:38.989] iteration:3212  t-loss:0.2956, loss-lb:0.1449, loss-ulb:0.2328, weight:0.65, lr:0.0008
[02:04:39.316] iteration:3213  t-loss:0.6652, loss-lb:0.3473, loss-ulb:0.4911, weight:0.65, lr:0.0008
[02:04:39.678] iteration:3214  t-loss:0.3665, loss-lb:0.2789, loss-ulb:0.1353, weight:0.65, lr:0.0008
[02:04:40.030] iteration:3215  t-loss:0.6610, loss-lb:0.3536, loss-ulb:0.4750, weight:0.65, lr:0.0008
[02:04:40.358] iteration:3216  t-loss:0.3273, loss-lb:0.2188, loss-ulb:0.1677, weight:0.65, lr:0.0008
[02:04:40.684] iteration:3217  t-loss:0.3460, loss-lb:0.2576, loss-ulb:0.1366, weight:0.65, lr:0.0008
[02:04:41.009] iteration:3218  t-loss:0.4922, loss-lb:0.3174, loss-ulb:0.2701, weight:0.65, lr:0.0008
[02:04:41.324] iteration:3219  t-loss:0.4725, loss-lb:0.3404, loss-ulb:0.2041, weight:0.65, lr:0.0008
[02:04:41.643] iteration:3220  t-loss:0.4882, loss-lb:0.2192, loss-ulb:0.4156, weight:0.65, lr:0.0008
[02:04:41.962] iteration:3221  t-loss:0.2730, loss-lb:0.1815, loss-ulb:0.1413, weight:0.65, lr:0.0008
[02:04:42.276] iteration:3222  t-loss:0.6958, loss-lb:0.1704, loss-ulb:0.8117, weight:0.65, lr:0.0008
[02:04:42.597] iteration:3223  t-loss:0.3508, loss-lb:0.2524, loss-ulb:0.1520, weight:0.65, lr:0.0008
[02:04:42.911] iteration:3224  t-loss:0.5171, loss-lb:0.2845, loss-ulb:0.3595, weight:0.65, lr:0.0008
[02:04:43.227] iteration:3225  t-loss:0.3776, loss-lb:0.2028, loss-ulb:0.2701, weight:0.65, lr:0.0008
[02:06:59.472] iteration 3225 : dice_score: 0.817088 best_dice: 0.817100
[02:06:59.473]  <<Test>> - Ep:128  - Dice-S/T:78.18/81.71, Best-S:80.85, Best-T:81.71
[02:06:59.473]           - AvgLoss(lb/ulb/all):0.28/0.30/0.47
[02:07:00.629] iteration:3226  t-loss:0.4032, loss-lb:0.3107, loss-ulb:0.1429, weight:0.65, lr:0.0008
[02:07:00.955] iteration:3227  t-loss:0.2666, loss-lb:0.2306, loss-ulb:0.0556, weight:0.65, lr:0.0008
[02:07:01.279] iteration:3228  t-loss:0.4088, loss-lb:0.2988, loss-ulb:0.1700, weight:0.65, lr:0.0008
[02:07:01.594] iteration:3229  t-loss:0.5639, loss-lb:0.1798, loss-ulb:0.5933, weight:0.65, lr:0.0008
[02:07:01.927] iteration:3230  t-loss:0.3236, loss-lb:0.2665, loss-ulb:0.0882, weight:0.65, lr:0.0008
[02:07:02.270] iteration:3231  t-loss:0.6877, loss-lb:0.4385, loss-ulb:0.3850, weight:0.65, lr:0.0008
[02:07:02.616] iteration:3232  t-loss:0.3524, loss-lb:0.1643, loss-ulb:0.2907, weight:0.65, lr:0.0008
[02:07:02.948] iteration:3233  t-loss:0.5096, loss-lb:0.2926, loss-ulb:0.3353, weight:0.65, lr:0.0008
[02:07:03.283] iteration:3234  t-loss:0.5523, loss-lb:0.2711, loss-ulb:0.4344, weight:0.65, lr:0.0008
[02:07:03.623] iteration:3235  t-loss:0.3211, loss-lb:0.2069, loss-ulb:0.1765, weight:0.65, lr:0.0008
[02:07:03.975] iteration:3236  t-loss:0.4293, loss-lb:0.3413, loss-ulb:0.1359, weight:0.65, lr:0.0008
[02:07:04.312] iteration:3237  t-loss:0.4166, loss-lb:0.3904, loss-ulb:0.0406, weight:0.65, lr:0.0008
[02:07:04.648] iteration:3238  t-loss:0.3570, loss-lb:0.3315, loss-ulb:0.0395, weight:0.65, lr:0.0008
[02:07:04.996] iteration:3239  t-loss:0.3666, loss-lb:0.3091, loss-ulb:0.0888, weight:0.65, lr:0.0008
[02:07:05.344] iteration:3240  t-loss:0.4036, loss-lb:0.1707, loss-ulb:0.3599, weight:0.65, lr:0.0008
[02:07:05.670] iteration:3241  t-loss:0.5566, loss-lb:0.5386, loss-ulb:0.0278, weight:0.65, lr:0.0008
[02:07:05.993] iteration:3242  t-loss:0.2279, loss-lb:0.1924, loss-ulb:0.0549, weight:0.65, lr:0.0008
[02:07:06.311] iteration:3243  t-loss:0.3952, loss-lb:0.2180, loss-ulb:0.2739, weight:0.65, lr:0.0008
[02:07:06.634] iteration:3244  t-loss:0.3493, loss-lb:0.1969, loss-ulb:0.2354, weight:0.65, lr:0.0008
[02:07:06.950] iteration:3245  t-loss:0.6832, loss-lb:0.3208, loss-ulb:0.5599, weight:0.65, lr:0.0008
[02:07:07.262] iteration:3246  t-loss:0.4976, loss-lb:0.2839, loss-ulb:0.3301, weight:0.65, lr:0.0008
[02:07:07.577] iteration:3247  t-loss:0.4339, loss-lb:0.3285, loss-ulb:0.1629, weight:0.65, lr:0.0008
[02:07:07.889] iteration:3248  t-loss:0.3930, loss-lb:0.3692, loss-ulb:0.0368, weight:0.65, lr:0.0008
[02:07:08.199] iteration:3249  t-loss:0.5767, loss-lb:0.2574, loss-ulb:0.4933, weight:0.65, lr:0.0008
[02:07:08.510] iteration:3250  t-loss:0.3225, loss-lb:0.1945, loss-ulb:0.1978, weight:0.65, lr:0.0008
[02:07:09.617] iteration:3251  t-loss:0.4186, loss-lb:0.2132, loss-ulb:0.3174, weight:0.65, lr:0.0008
[02:07:09.938] iteration:3252  t-loss:0.6422, loss-lb:0.1929, loss-ulb:0.6942, weight:0.65, lr:0.0008
[02:07:10.246] iteration:3253  t-loss:0.3172, loss-lb:0.1867, loss-ulb:0.2016, weight:0.65, lr:0.0008
[02:07:10.564] iteration:3254  t-loss:0.6309, loss-lb:0.4794, loss-ulb:0.2339, weight:0.65, lr:0.0008
[02:07:10.881] iteration:3255  t-loss:0.3230, loss-lb:0.2656, loss-ulb:0.0886, weight:0.65, lr:0.0008
[02:07:11.193] iteration:3256  t-loss:0.2307, loss-lb:0.1802, loss-ulb:0.0779, weight:0.65, lr:0.0008
[02:07:11.510] iteration:3257  t-loss:0.6370, loss-lb:0.4750, loss-ulb:0.2503, weight:0.65, lr:0.0008
[02:07:11.828] iteration:3258  t-loss:0.4830, loss-lb:0.2931, loss-ulb:0.2934, weight:0.65, lr:0.0008
[02:07:12.146] iteration:3259  t-loss:0.4376, loss-lb:0.3207, loss-ulb:0.1806, weight:0.65, lr:0.0008
[02:07:12.467] iteration:3260  t-loss:0.4865, loss-lb:0.3952, loss-ulb:0.1410, weight:0.65, lr:0.0008
[02:07:12.784] iteration:3261  t-loss:0.4768, loss-lb:0.2067, loss-ulb:0.4172, weight:0.65, lr:0.0008
[02:07:13.107] iteration:3262  t-loss:0.3351, loss-lb:0.2776, loss-ulb:0.0888, weight:0.65, lr:0.0008
[02:07:13.424] iteration:3263  t-loss:0.3929, loss-lb:0.2286, loss-ulb:0.2539, weight:0.65, lr:0.0008
[02:07:13.744] iteration:3264  t-loss:0.2823, loss-lb:0.2503, loss-ulb:0.0494, weight:0.65, lr:0.0008
[02:07:14.066] iteration:3265  t-loss:0.6208, loss-lb:0.5489, loss-ulb:0.1112, weight:0.65, lr:0.0008
[02:07:14.385] iteration:3266  t-loss:0.4639, loss-lb:0.2723, loss-ulb:0.2960, weight:0.65, lr:0.0008
[02:07:14.710] iteration:3267  t-loss:0.2980, loss-lb:0.1653, loss-ulb:0.2050, weight:0.65, lr:0.0008
[02:07:15.029] iteration:3268  t-loss:0.7111, loss-lb:0.4693, loss-ulb:0.3736, weight:0.65, lr:0.0008
[02:07:15.346] iteration:3269  t-loss:0.3727, loss-lb:0.3169, loss-ulb:0.0862, weight:0.65, lr:0.0008
[02:07:15.659] iteration:3270  t-loss:0.6300, loss-lb:0.2488, loss-ulb:0.5890, weight:0.65, lr:0.0008
[02:07:15.980] iteration:3271  t-loss:0.3999, loss-lb:0.2646, loss-ulb:0.2091, weight:0.65, lr:0.0008
[02:07:16.297] iteration:3272  t-loss:0.3749, loss-lb:0.2538, loss-ulb:0.1871, weight:0.65, lr:0.0008
[02:07:16.610] iteration:3273  t-loss:0.3890, loss-lb:0.3490, loss-ulb:0.0618, weight:0.65, lr:0.0008
[02:07:16.930] iteration:3274  t-loss:0.4286, loss-lb:0.2907, loss-ulb:0.2130, weight:0.65, lr:0.0008
[02:07:17.246] iteration:3275  t-loss:0.5324, loss-lb:0.4589, loss-ulb:0.1136, weight:0.65, lr:0.0008
[02:07:18.802] iteration:3276  t-loss:0.6554, loss-lb:0.4904, loss-ulb:0.2549, weight:0.65, lr:0.0008
[02:07:19.144] iteration:3277  t-loss:0.3016, loss-lb:0.1938, loss-ulb:0.1666, weight:0.65, lr:0.0008
[02:07:19.475] iteration:3278  t-loss:0.6761, loss-lb:0.3540, loss-ulb:0.4977, weight:0.65, lr:0.0008
[02:07:19.811] iteration:3279  t-loss:0.2239, loss-lb:0.1395, loss-ulb:0.1304, weight:0.65, lr:0.0008
[02:07:20.131] iteration:3280  t-loss:0.5534, loss-lb:0.4172, loss-ulb:0.2105, weight:0.65, lr:0.0008
[02:07:20.450] iteration:3281  t-loss:0.2425, loss-lb:0.1625, loss-ulb:0.1236, weight:0.65, lr:0.0008
[02:07:20.772] iteration:3282  t-loss:0.5181, loss-lb:0.4775, loss-ulb:0.0627, weight:0.65, lr:0.0008
[02:07:21.088] iteration:3283  t-loss:0.7410, loss-lb:0.4256, loss-ulb:0.4872, weight:0.65, lr:0.0008
[02:07:21.413] iteration:3284  t-loss:0.4559, loss-lb:0.1827, loss-ulb:0.4220, weight:0.65, lr:0.0008
[02:07:21.737] iteration:3285  t-loss:0.6196, loss-lb:0.2327, loss-ulb:0.5978, weight:0.65, lr:0.0008
[02:07:22.064] iteration:3286  t-loss:0.3006, loss-lb:0.1847, loss-ulb:0.1790, weight:0.65, lr:0.0008
[02:07:22.390] iteration:3287  t-loss:0.3591, loss-lb:0.1772, loss-ulb:0.2811, weight:0.65, lr:0.0008
[02:07:22.725] iteration:3288  t-loss:0.3513, loss-lb:0.3201, loss-ulb:0.0482, weight:0.65, lr:0.0008
[02:07:23.048] iteration:3289  t-loss:0.4792, loss-lb:0.1961, loss-ulb:0.4375, weight:0.65, lr:0.0008
[02:07:23.379] iteration:3290  t-loss:0.4182, loss-lb:0.3246, loss-ulb:0.1447, weight:0.65, lr:0.0008
[02:07:23.700] iteration:3291  t-loss:0.2051, loss-lb:0.1683, loss-ulb:0.0568, weight:0.65, lr:0.0008
[02:07:24.025] iteration:3292  t-loss:0.5927, loss-lb:0.2876, loss-ulb:0.4713, weight:0.65, lr:0.0008
[02:07:24.345] iteration:3293  t-loss:0.2874, loss-lb:0.2488, loss-ulb:0.0596, weight:0.65, lr:0.0008
[02:07:24.664] iteration:3294  t-loss:0.4813, loss-lb:0.2391, loss-ulb:0.3742, weight:0.65, lr:0.0008
[02:07:24.979] iteration:3295  t-loss:0.4131, loss-lb:0.3192, loss-ulb:0.1451, weight:0.65, lr:0.0008
[02:07:25.296] iteration:3296  t-loss:0.2238, loss-lb:0.2064, loss-ulb:0.0268, weight:0.65, lr:0.0008
[02:07:25.611] iteration:3297  t-loss:0.5047, loss-lb:0.2171, loss-ulb:0.4444, weight:0.65, lr:0.0008
[02:07:25.927] iteration:3298  t-loss:0.3622, loss-lb:0.2075, loss-ulb:0.2389, weight:0.65, lr:0.0008
[02:07:26.248] iteration:3299  t-loss:0.5424, loss-lb:0.2174, loss-ulb:0.5021, weight:0.65, lr:0.0008
[02:07:26.571] iteration:3300  t-loss:0.2866, loss-lb:0.2171, loss-ulb:0.1073, weight:0.65, lr:0.0008
[02:07:28.170] iteration:3301  t-loss:0.3053, loss-lb:0.2609, loss-ulb:0.0610, weight:0.73, lr:0.0008
[02:07:28.522] iteration:3302  t-loss:0.9345, loss-lb:0.7316, loss-ulb:0.2792, weight:0.73, lr:0.0008
[02:07:28.857] iteration:3303  t-loss:0.6278, loss-lb:0.3249, loss-ulb:0.4168, weight:0.73, lr:0.0008
[02:07:29.193] iteration:3304  t-loss:0.6580, loss-lb:0.4612, loss-ulb:0.2709, weight:0.73, lr:0.0008
[02:07:29.524] iteration:3305  t-loss:0.2928, loss-lb:0.2044, loss-ulb:0.1216, weight:0.73, lr:0.0008
[02:07:29.849] iteration:3306  t-loss:0.4524, loss-lb:0.3537, loss-ulb:0.1359, weight:0.73, lr:0.0008
[02:07:30.174] iteration:3307  t-loss:0.3624, loss-lb:0.2005, loss-ulb:0.2228, weight:0.73, lr:0.0008
[02:07:30.507] iteration:3308  t-loss:0.4333, loss-lb:0.3078, loss-ulb:0.1727, weight:0.73, lr:0.0008
[02:07:30.830] iteration:3309  t-loss:0.7833, loss-lb:0.3596, loss-ulb:0.5831, weight:0.73, lr:0.0008
[02:07:31.151] iteration:3310  t-loss:0.5038, loss-lb:0.3604, loss-ulb:0.1974, weight:0.73, lr:0.0008
[02:07:31.475] iteration:3311  t-loss:0.8289, loss-lb:0.5882, loss-ulb:0.3313, weight:0.73, lr:0.0008
[02:07:31.800] iteration:3312  t-loss:0.5404, loss-lb:0.3367, loss-ulb:0.2804, weight:0.73, lr:0.0008
[02:07:32.119] iteration:3313  t-loss:0.5276, loss-lb:0.3539, loss-ulb:0.2390, weight:0.73, lr:0.0008
[02:07:32.438] iteration:3314  t-loss:0.3683, loss-lb:0.2685, loss-ulb:0.1374, weight:0.73, lr:0.0008
[02:07:32.758] iteration:3315  t-loss:0.5154, loss-lb:0.2275, loss-ulb:0.3963, weight:0.73, lr:0.0008
[02:07:33.077] iteration:3316  t-loss:0.3827, loss-lb:0.2681, loss-ulb:0.1577, weight:0.73, lr:0.0008
[02:07:33.397] iteration:3317  t-loss:0.5139, loss-lb:0.4447, loss-ulb:0.0952, weight:0.73, lr:0.0008
[02:07:33.711] iteration:3318  t-loss:0.3716, loss-lb:0.2574, loss-ulb:0.1572, weight:0.73, lr:0.0008
[02:07:34.026] iteration:3319  t-loss:0.5269, loss-lb:0.2123, loss-ulb:0.4328, weight:0.73, lr:0.0008
[02:07:34.340] iteration:3320  t-loss:0.2573, loss-lb:0.2334, loss-ulb:0.0329, weight:0.73, lr:0.0008
[02:07:34.659] iteration:3321  t-loss:0.5941, loss-lb:0.3879, loss-ulb:0.2838, weight:0.73, lr:0.0008
[02:07:34.981] iteration:3322  t-loss:0.3424, loss-lb:0.2477, loss-ulb:0.1304, weight:0.73, lr:0.0008
[02:07:35.299] iteration:3323  t-loss:0.3172, loss-lb:0.2330, loss-ulb:0.1159, weight:0.73, lr:0.0008
[02:07:35.617] iteration:3324  t-loss:0.2778, loss-lb:0.2115, loss-ulb:0.0912, weight:0.73, lr:0.0008
[02:07:35.949] iteration:3325  t-loss:0.2636, loss-lb:0.1657, loss-ulb:0.1347, weight:0.73, lr:0.0008
[02:09:50.385] iteration 3325 : dice_score: 0.819465 best_dice: 0.819500
[02:09:50.385]  <<Test>> - Ep:132  - Dice-S/T:79.60/81.95, Best-S:80.85, Best-T:81.95
[02:09:50.385]           - AvgLoss(lb/ulb/all):0.32/0.22/0.46
[02:09:51.784] iteration:3326  t-loss:0.2900, loss-lb:0.2525, loss-ulb:0.0515, weight:0.73, lr:0.0008
[02:09:52.116] iteration:3327  t-loss:0.5839, loss-lb:0.2238, loss-ulb:0.4955, weight:0.73, lr:0.0008
[02:09:52.436] iteration:3328  t-loss:0.5963, loss-lb:0.2250, loss-ulb:0.5111, weight:0.73, lr:0.0008
[02:09:52.757] iteration:3329  t-loss:0.3166, loss-lb:0.1734, loss-ulb:0.1970, weight:0.73, lr:0.0008
[02:09:53.082] iteration:3330  t-loss:0.4068, loss-lb:0.2530, loss-ulb:0.2117, weight:0.73, lr:0.0008
[02:09:53.402] iteration:3331  t-loss:0.3676, loss-lb:0.2284, loss-ulb:0.1916, weight:0.73, lr:0.0008
[02:09:53.724] iteration:3332  t-loss:0.2781, loss-lb:0.1622, loss-ulb:0.1595, weight:0.73, lr:0.0008
[02:09:54.042] iteration:3333  t-loss:0.2804, loss-lb:0.2665, loss-ulb:0.0192, weight:0.73, lr:0.0008
[02:09:54.360] iteration:3334  t-loss:0.3560, loss-lb:0.1628, loss-ulb:0.2658, weight:0.73, lr:0.0008
[02:09:54.684] iteration:3335  t-loss:0.3808, loss-lb:0.2690, loss-ulb:0.1539, weight:0.73, lr:0.0008
[02:09:55.002] iteration:3336  t-loss:0.4177, loss-lb:0.2662, loss-ulb:0.2086, weight:0.73, lr:0.0008
[02:09:55.320] iteration:3337  t-loss:0.8540, loss-lb:0.1901, loss-ulb:0.9136, weight:0.73, lr:0.0008
[02:09:55.642] iteration:3338  t-loss:0.3554, loss-lb:0.2667, loss-ulb:0.1221, weight:0.73, lr:0.0008
[02:09:55.957] iteration:3339  t-loss:0.5365, loss-lb:0.2441, loss-ulb:0.4025, weight:0.73, lr:0.0008
[02:09:56.279] iteration:3340  t-loss:0.3957, loss-lb:0.3252, loss-ulb:0.0971, weight:0.73, lr:0.0008
[02:09:56.596] iteration:3341  t-loss:0.3744, loss-lb:0.2186, loss-ulb:0.2144, weight:0.73, lr:0.0008
[02:09:56.921] iteration:3342  t-loss:0.4939, loss-lb:0.2665, loss-ulb:0.3129, weight:0.73, lr:0.0008
[02:09:57.239] iteration:3343  t-loss:0.4127, loss-lb:0.3738, loss-ulb:0.0536, weight:0.73, lr:0.0008
[02:09:57.553] iteration:3344  t-loss:0.3995, loss-lb:0.2866, loss-ulb:0.1554, weight:0.73, lr:0.0008
[02:09:57.868] iteration:3345  t-loss:0.3399, loss-lb:0.2236, loss-ulb:0.1601, weight:0.73, lr:0.0008
[02:09:58.185] iteration:3346  t-loss:0.3347, loss-lb:0.2896, loss-ulb:0.0620, weight:0.73, lr:0.0008
[02:09:58.501] iteration:3347  t-loss:0.2853, loss-lb:0.1751, loss-ulb:0.1516, weight:0.73, lr:0.0008
[02:09:58.818] iteration:3348  t-loss:0.2990, loss-lb:0.2658, loss-ulb:0.0457, weight:0.73, lr:0.0008
[02:09:59.134] iteration:3349  t-loss:0.4926, loss-lb:0.1916, loss-ulb:0.4143, weight:0.73, lr:0.0008
[02:09:59.449] iteration:3350  t-loss:0.7364, loss-lb:0.4889, loss-ulb:0.3407, weight:0.73, lr:0.0008
[02:10:01.219] iteration:3351  t-loss:0.5683, loss-lb:0.2691, loss-ulb:0.4118, weight:0.73, lr:0.0008
[02:10:01.572] iteration:3352  t-loss:0.6467, loss-lb:0.2673, loss-ulb:0.5221, weight:0.73, lr:0.0008
[02:10:01.911] iteration:3353  t-loss:0.2614, loss-lb:0.2155, loss-ulb:0.0631, weight:0.73, lr:0.0008
[02:10:02.234] iteration:3354  t-loss:0.2835, loss-lb:0.2261, loss-ulb:0.0789, weight:0.73, lr:0.0008
[02:10:02.560] iteration:3355  t-loss:0.6287, loss-lb:0.4118, loss-ulb:0.2984, weight:0.73, lr:0.0008
[02:10:02.881] iteration:3356  t-loss:0.3283, loss-lb:0.1650, loss-ulb:0.2247, weight:0.73, lr:0.0008
[02:10:03.204] iteration:3357  t-loss:0.4788, loss-lb:0.3556, loss-ulb:0.1695, weight:0.73, lr:0.0008
[02:10:03.533] iteration:3358  t-loss:0.6003, loss-lb:0.2401, loss-ulb:0.4958, weight:0.73, lr:0.0008
[02:10:03.862] iteration:3359  t-loss:0.3682, loss-lb:0.3163, loss-ulb:0.0714, weight:0.73, lr:0.0008
[02:10:04.192] iteration:3360  t-loss:0.4928, loss-lb:0.4343, loss-ulb:0.0806, weight:0.73, lr:0.0008
[02:10:04.515] iteration:3361  t-loss:0.3329, loss-lb:0.1857, loss-ulb:0.2026, weight:0.73, lr:0.0008
[02:10:04.841] iteration:3362  t-loss:0.4171, loss-lb:0.2423, loss-ulb:0.2406, weight:0.73, lr:0.0008
[02:10:05.163] iteration:3363  t-loss:0.3446, loss-lb:0.2105, loss-ulb:0.1846, weight:0.73, lr:0.0008
[02:10:05.488] iteration:3364  t-loss:0.4659, loss-lb:0.2045, loss-ulb:0.3598, weight:0.73, lr:0.0008
[02:10:05.813] iteration:3365  t-loss:0.4377, loss-lb:0.1595, loss-ulb:0.3829, weight:0.73, lr:0.0008
[02:10:06.132] iteration:3366  t-loss:0.3404, loss-lb:0.1492, loss-ulb:0.2631, weight:0.73, lr:0.0008
[02:10:06.447] iteration:3367  t-loss:1.0012, loss-lb:0.2373, loss-ulb:1.0514, weight:0.73, lr:0.0008
[02:10:06.764] iteration:3368  t-loss:0.4627, loss-lb:0.4239, loss-ulb:0.0534, weight:0.73, lr:0.0008
[02:10:07.079] iteration:3369  t-loss:0.2731, loss-lb:0.2405, loss-ulb:0.0448, weight:0.73, lr:0.0008
[02:10:07.392] iteration:3370  t-loss:0.3817, loss-lb:0.3127, loss-ulb:0.0949, weight:0.73, lr:0.0008
[02:10:07.705] iteration:3371  t-loss:0.3373, loss-lb:0.2675, loss-ulb:0.0961, weight:0.73, lr:0.0008
[02:10:08.022] iteration:3372  t-loss:0.2879, loss-lb:0.1805, loss-ulb:0.1478, weight:0.73, lr:0.0008
[02:10:08.343] iteration:3373  t-loss:0.5881, loss-lb:0.4320, loss-ulb:0.2149, weight:0.73, lr:0.0008
[02:10:08.662] iteration:3374  t-loss:0.5294, loss-lb:0.4577, loss-ulb:0.0986, weight:0.73, lr:0.0008
[02:10:08.985] iteration:3375  t-loss:0.2702, loss-lb:0.1933, loss-ulb:0.1058, weight:0.73, lr:0.0008
[02:10:10.306] iteration:3376  t-loss:0.2887, loss-lb:0.1756, loss-ulb:0.1556, weight:0.73, lr:0.0008
[02:10:10.642] iteration:3377  t-loss:0.3376, loss-lb:0.2434, loss-ulb:0.1297, weight:0.73, lr:0.0008
[02:10:11.015] iteration:3378  t-loss:0.5898, loss-lb:0.2705, loss-ulb:0.4395, weight:0.73, lr:0.0008
[02:10:11.338] iteration:3379  t-loss:0.4770, loss-lb:0.3448, loss-ulb:0.1819, weight:0.73, lr:0.0008
[02:10:11.655] iteration:3380  t-loss:0.2900, loss-lb:0.2207, loss-ulb:0.0953, weight:0.73, lr:0.0008
[02:10:11.991] iteration:3381  t-loss:0.3384, loss-lb:0.3066, loss-ulb:0.0438, weight:0.73, lr:0.0008
[02:10:12.315] iteration:3382  t-loss:0.5163, loss-lb:0.3319, loss-ulb:0.2537, weight:0.73, lr:0.0008
[02:10:12.634] iteration:3383  t-loss:0.3267, loss-lb:0.2970, loss-ulb:0.0409, weight:0.73, lr:0.0008
[02:10:12.954] iteration:3384  t-loss:0.2762, loss-lb:0.1900, loss-ulb:0.1186, weight:0.73, lr:0.0008
[02:10:13.278] iteration:3385  t-loss:0.4684, loss-lb:0.3079, loss-ulb:0.2208, weight:0.73, lr:0.0008
[02:10:13.599] iteration:3386  t-loss:0.5342, loss-lb:0.2037, loss-ulb:0.4549, weight:0.73, lr:0.0008
[02:10:13.916] iteration:3387  t-loss:0.5207, loss-lb:0.1801, loss-ulb:0.4687, weight:0.73, lr:0.0008
[02:10:14.232] iteration:3388  t-loss:0.2875, loss-lb:0.2017, loss-ulb:0.1181, weight:0.73, lr:0.0008
[02:10:14.548] iteration:3389  t-loss:0.4572, loss-lb:0.3332, loss-ulb:0.1706, weight:0.73, lr:0.0008
[02:10:14.869] iteration:3390  t-loss:0.4199, loss-lb:0.2007, loss-ulb:0.3017, weight:0.73, lr:0.0008
[02:10:15.187] iteration:3391  t-loss:0.4304, loss-lb:0.3031, loss-ulb:0.1751, weight:0.73, lr:0.0008
[02:10:15.503] iteration:3392  t-loss:0.4502, loss-lb:0.2176, loss-ulb:0.3201, weight:0.73, lr:0.0008
[02:10:15.820] iteration:3393  t-loss:0.3858, loss-lb:0.2306, loss-ulb:0.2136, weight:0.73, lr:0.0008
[02:10:16.134] iteration:3394  t-loss:0.4445, loss-lb:0.3886, loss-ulb:0.0770, weight:0.73, lr:0.0008
[02:10:16.449] iteration:3395  t-loss:0.4366, loss-lb:0.3591, loss-ulb:0.1067, weight:0.73, lr:0.0008
[02:10:16.765] iteration:3396  t-loss:0.3989, loss-lb:0.2614, loss-ulb:0.1893, weight:0.73, lr:0.0008
[02:10:17.084] iteration:3397  t-loss:0.4065, loss-lb:0.2513, loss-ulb:0.2135, weight:0.73, lr:0.0008
[02:10:17.399] iteration:3398  t-loss:0.5091, loss-lb:0.4241, loss-ulb:0.1170, weight:0.73, lr:0.0008
[02:10:17.715] iteration:3399  t-loss:0.8146, loss-lb:0.4484, loss-ulb:0.5040, weight:0.73, lr:0.0008
[02:10:18.035] iteration:3400  t-loss:0.6274, loss-lb:0.2497, loss-ulb:0.5199, weight:0.73, lr:0.0008
[02:10:19.359] iteration:3401  t-loss:0.3411, loss-lb:0.2525, loss-ulb:0.1219, weight:0.73, lr:0.0008
[02:10:19.698] iteration:3402  t-loss:0.4567, loss-lb:0.4123, loss-ulb:0.0611, weight:0.73, lr:0.0008
[02:10:20.024] iteration:3403  t-loss:0.5118, loss-lb:0.2411, loss-ulb:0.3725, weight:0.73, lr:0.0008
[02:10:20.354] iteration:3404  t-loss:0.4861, loss-lb:0.3637, loss-ulb:0.1684, weight:0.73, lr:0.0008
[02:10:20.673] iteration:3405  t-loss:0.2111, loss-lb:0.1867, loss-ulb:0.0336, weight:0.73, lr:0.0008
[02:10:20.997] iteration:3406  t-loss:0.2552, loss-lb:0.2295, loss-ulb:0.0353, weight:0.73, lr:0.0008
[02:10:21.325] iteration:3407  t-loss:0.5152, loss-lb:0.4781, loss-ulb:0.0510, weight:0.73, lr:0.0008
[02:10:21.643] iteration:3408  t-loss:0.3725, loss-lb:0.3339, loss-ulb:0.0531, weight:0.73, lr:0.0008
[02:10:21.959] iteration:3409  t-loss:0.5572, loss-lb:0.2140, loss-ulb:0.4724, weight:0.73, lr:0.0008
[02:10:22.284] iteration:3410  t-loss:0.3093, loss-lb:0.2150, loss-ulb:0.1297, weight:0.73, lr:0.0008
[02:10:22.602] iteration:3411  t-loss:0.4385, loss-lb:0.1893, loss-ulb:0.3430, weight:0.73, lr:0.0008
[02:10:22.918] iteration:3412  t-loss:0.2011, loss-lb:0.1574, loss-ulb:0.0601, weight:0.73, lr:0.0008
[02:10:23.242] iteration:3413  t-loss:0.5713, loss-lb:0.2743, loss-ulb:0.4087, weight:0.73, lr:0.0008
[02:10:23.567] iteration:3414  t-loss:0.6443, loss-lb:0.2372, loss-ulb:0.5602, weight:0.73, lr:0.0008
[02:10:23.891] iteration:3415  t-loss:0.2302, loss-lb:0.2033, loss-ulb:0.0371, weight:0.73, lr:0.0008
[02:10:24.208] iteration:3416  t-loss:0.5183, loss-lb:0.4572, loss-ulb:0.0840, weight:0.73, lr:0.0008
[02:10:24.525] iteration:3417  t-loss:0.6023, loss-lb:0.2266, loss-ulb:0.5170, weight:0.73, lr:0.0008
[02:10:24.844] iteration:3418  t-loss:0.4071, loss-lb:0.2707, loss-ulb:0.1877, weight:0.73, lr:0.0008
[02:10:25.166] iteration:3419  t-loss:0.6852, loss-lb:0.4901, loss-ulb:0.2685, weight:0.73, lr:0.0008
[02:10:25.487] iteration:3420  t-loss:0.6020, loss-lb:0.2803, loss-ulb:0.4427, weight:0.73, lr:0.0008
[02:10:25.809] iteration:3421  t-loss:0.2000, loss-lb:0.1568, loss-ulb:0.0595, weight:0.73, lr:0.0008
[02:10:26.125] iteration:3422  t-loss:0.6458, loss-lb:0.3532, loss-ulb:0.4027, weight:0.73, lr:0.0008
[02:10:26.445] iteration:3423  t-loss:0.6253, loss-lb:0.3010, loss-ulb:0.4464, weight:0.73, lr:0.0008
[02:10:26.770] iteration:3424  t-loss:0.3436, loss-lb:0.2612, loss-ulb:0.1134, weight:0.73, lr:0.0008
[02:10:27.091] iteration:3425  t-loss:0.2853, loss-lb:0.2195, loss-ulb:0.0906, weight:0.73, lr:0.0008
[02:12:35.540] iteration 3425 : dice_score: 0.823053 best_dice: 0.823100
[02:12:35.541]  <<Test>> - Ep:136  - Dice-S/T:79.86/82.31, Best-S:80.85, Best-T:82.31
[02:12:35.541]           - AvgLoss(lb/ulb/all):0.28/0.24/0.45
[02:12:36.669] iteration:3426  t-loss:0.2156, loss-lb:0.1880, loss-ulb:0.0379, weight:0.73, lr:0.0008
[02:12:37.034] iteration:3427  t-loss:0.4313, loss-lb:0.3068, loss-ulb:0.1713, weight:0.73, lr:0.0008
[02:12:37.378] iteration:3428  t-loss:0.7319, loss-lb:0.1712, loss-ulb:0.7717, weight:0.73, lr:0.0008
[02:12:37.730] iteration:3429  t-loss:0.8799, loss-lb:0.6309, loss-ulb:0.3426, weight:0.73, lr:0.0008
[02:12:38.055] iteration:3430  t-loss:0.4942, loss-lb:0.4463, loss-ulb:0.0659, weight:0.73, lr:0.0008
[02:12:38.377] iteration:3431  t-loss:0.4536, loss-lb:0.3700, loss-ulb:0.1151, weight:0.73, lr:0.0008
[02:12:38.698] iteration:3432  t-loss:0.4922, loss-lb:0.3560, loss-ulb:0.1874, weight:0.73, lr:0.0008
[02:12:39.017] iteration:3433  t-loss:0.3523, loss-lb:0.1900, loss-ulb:0.2234, weight:0.73, lr:0.0008
[02:12:39.333] iteration:3434  t-loss:0.2234, loss-lb:0.1680, loss-ulb:0.0763, weight:0.73, lr:0.0008
[02:12:39.653] iteration:3435  t-loss:0.2994, loss-lb:0.2191, loss-ulb:0.1105, weight:0.73, lr:0.0008
[02:12:39.971] iteration:3436  t-loss:0.4699, loss-lb:0.3374, loss-ulb:0.1823, weight:0.73, lr:0.0008
[02:12:40.289] iteration:3437  t-loss:0.3513, loss-lb:0.2357, loss-ulb:0.1590, weight:0.73, lr:0.0008
[02:12:40.612] iteration:3438  t-loss:0.7634, loss-lb:0.6227, loss-ulb:0.1936, weight:0.73, lr:0.0008
[02:12:40.930] iteration:3439  t-loss:0.6409, loss-lb:0.3597, loss-ulb:0.3870, weight:0.73, lr:0.0008
[02:12:41.255] iteration:3440  t-loss:0.3017, loss-lb:0.2217, loss-ulb:0.1101, weight:0.73, lr:0.0008
[02:12:41.585] iteration:3441  t-loss:0.4338, loss-lb:0.3330, loss-ulb:0.1388, weight:0.73, lr:0.0008
[02:12:41.904] iteration:3442  t-loss:0.6231, loss-lb:0.3213, loss-ulb:0.4154, weight:0.73, lr:0.0008
[02:12:42.222] iteration:3443  t-loss:0.3069, loss-lb:0.2186, loss-ulb:0.1216, weight:0.73, lr:0.0008
[02:12:42.544] iteration:3444  t-loss:0.3716, loss-lb:0.2157, loss-ulb:0.2146, weight:0.73, lr:0.0008
[02:12:42.861] iteration:3445  t-loss:0.3545, loss-lb:0.2957, loss-ulb:0.0809, weight:0.73, lr:0.0008
[02:12:43.180] iteration:3446  t-loss:0.3458, loss-lb:0.1467, loss-ulb:0.2741, weight:0.73, lr:0.0008
[02:12:43.502] iteration:3447  t-loss:0.2610, loss-lb:0.1425, loss-ulb:0.1631, weight:0.73, lr:0.0008
[02:12:43.821] iteration:3448  t-loss:0.2133, loss-lb:0.1590, loss-ulb:0.0748, weight:0.73, lr:0.0008
[02:12:44.140] iteration:3449  t-loss:0.3409, loss-lb:0.2917, loss-ulb:0.0678, weight:0.73, lr:0.0008
[02:12:44.465] iteration:3450  t-loss:0.4091, loss-lb:0.3685, loss-ulb:0.0559, weight:0.73, lr:0.0008
[02:12:46.109] iteration:3451  t-loss:0.6930, loss-lb:0.3888, loss-ulb:0.3753, weight:0.81, lr:0.0008
[02:12:46.457] iteration:3452  t-loss:0.4361, loss-lb:0.2841, loss-ulb:0.1876, weight:0.81, lr:0.0008
[02:12:46.828] iteration:3453  t-loss:0.4454, loss-lb:0.3365, loss-ulb:0.1343, weight:0.81, lr:0.0008
[02:12:47.172] iteration:3454  t-loss:0.3541, loss-lb:0.1627, loss-ulb:0.2362, weight:0.81, lr:0.0008
[02:12:47.506] iteration:3455  t-loss:0.3086, loss-lb:0.2282, loss-ulb:0.0992, weight:0.81, lr:0.0008
[02:12:47.829] iteration:3456  t-loss:0.6918, loss-lb:0.6368, loss-ulb:0.0679, weight:0.81, lr:0.0008
[02:12:48.146] iteration:3457  t-loss:0.3408, loss-lb:0.1816, loss-ulb:0.1964, weight:0.81, lr:0.0008
[02:12:48.465] iteration:3458  t-loss:0.2613, loss-lb:0.2074, loss-ulb:0.0665, weight:0.81, lr:0.0008
[02:12:48.787] iteration:3459  t-loss:0.3160, loss-lb:0.2912, loss-ulb:0.0306, weight:0.81, lr:0.0008
[02:12:49.109] iteration:3460  t-loss:0.3511, loss-lb:0.3261, loss-ulb:0.0309, weight:0.81, lr:0.0008
[02:12:49.431] iteration:3461  t-loss:0.3280, loss-lb:0.2544, loss-ulb:0.0909, weight:0.81, lr:0.0008
[02:12:49.763] iteration:3462  t-loss:0.7221, loss-lb:0.6898, loss-ulb:0.0399, weight:0.81, lr:0.0008
[02:12:50.087] iteration:3463  t-loss:0.6672, loss-lb:0.5809, loss-ulb:0.1065, weight:0.81, lr:0.0008
[02:12:50.405] iteration:3464  t-loss:0.5023, loss-lb:0.1982, loss-ulb:0.3752, weight:0.81, lr:0.0008
[02:12:50.734] iteration:3465  t-loss:0.6915, loss-lb:0.2698, loss-ulb:0.5203, weight:0.81, lr:0.0008
[02:12:51.061] iteration:3466  t-loss:0.3233, loss-lb:0.2001, loss-ulb:0.1520, weight:0.81, lr:0.0008
[02:12:51.389] iteration:3467  t-loss:0.4975, loss-lb:0.2746, loss-ulb:0.2750, weight:0.81, lr:0.0008
[02:12:51.709] iteration:3468  t-loss:0.3641, loss-lb:0.1903, loss-ulb:0.2144, weight:0.81, lr:0.0008
[02:12:52.028] iteration:3469  t-loss:0.7049, loss-lb:0.4895, loss-ulb:0.2658, weight:0.81, lr:0.0008
[02:12:52.347] iteration:3470  t-loss:0.4687, loss-lb:0.3454, loss-ulb:0.1521, weight:0.81, lr:0.0008
[02:12:52.669] iteration:3471  t-loss:0.6260, loss-lb:0.3178, loss-ulb:0.3803, weight:0.81, lr:0.0008
[02:12:52.984] iteration:3472  t-loss:0.5956, loss-lb:0.2733, loss-ulb:0.3977, weight:0.81, lr:0.0008
[02:12:53.299] iteration:3473  t-loss:0.4325, loss-lb:0.2246, loss-ulb:0.2564, weight:0.81, lr:0.0008
[02:12:53.614] iteration:3474  t-loss:0.7212, loss-lb:0.3643, loss-ulb:0.4402, weight:0.81, lr:0.0008
[02:12:53.932] iteration:3475  t-loss:0.5191, loss-lb:0.3672, loss-ulb:0.1874, weight:0.81, lr:0.0008
[02:12:55.369] iteration:3476  t-loss:0.2845, loss-lb:0.2290, loss-ulb:0.0684, weight:0.81, lr:0.0008
[02:12:55.720] iteration:3477  t-loss:0.8701, loss-lb:0.4058, loss-ulb:0.5728, weight:0.81, lr:0.0008
[02:12:56.055] iteration:3478  t-loss:0.6297, loss-lb:0.2423, loss-ulb:0.4779, weight:0.81, lr:0.0008
[02:12:56.391] iteration:3479  t-loss:0.3596, loss-lb:0.2520, loss-ulb:0.1327, weight:0.81, lr:0.0008
[02:12:56.713] iteration:3480  t-loss:0.1968, loss-lb:0.1737, loss-ulb:0.0285, weight:0.81, lr:0.0008
[02:12:57.042] iteration:3481  t-loss:0.4907, loss-lb:0.3346, loss-ulb:0.1925, weight:0.81, lr:0.0008
[02:12:57.369] iteration:3482  t-loss:0.2732, loss-lb:0.1461, loss-ulb:0.1568, weight:0.81, lr:0.0008
[02:12:57.702] iteration:3483  t-loss:0.5159, loss-lb:0.3388, loss-ulb:0.2185, weight:0.81, lr:0.0008
[02:12:58.051] iteration:3484  t-loss:0.4390, loss-lb:0.3112, loss-ulb:0.1576, weight:0.81, lr:0.0008
[02:12:58.378] iteration:3485  t-loss:0.5843, loss-lb:0.2690, loss-ulb:0.3890, weight:0.81, lr:0.0008
[02:12:58.709] iteration:3486  t-loss:0.4964, loss-lb:0.4558, loss-ulb:0.0501, weight:0.81, lr:0.0008
[02:12:59.034] iteration:3487  t-loss:0.5331, loss-lb:0.2418, loss-ulb:0.3594, weight:0.81, lr:0.0008
[02:12:59.353] iteration:3488  t-loss:0.2357, loss-lb:0.1882, loss-ulb:0.0586, weight:0.81, lr:0.0008
[02:12:59.678] iteration:3489  t-loss:0.3662, loss-lb:0.2451, loss-ulb:0.1494, weight:0.81, lr:0.0008
[02:13:00.012] iteration:3490  t-loss:0.4133, loss-lb:0.3136, loss-ulb:0.1230, weight:0.81, lr:0.0008
[02:13:00.351] iteration:3491  t-loss:0.6345, loss-lb:0.1875, loss-ulb:0.5515, weight:0.81, lr:0.0008
[02:13:00.679] iteration:3492  t-loss:0.7118, loss-lb:0.1665, loss-ulb:0.6727, weight:0.81, lr:0.0008
[02:13:01.009] iteration:3493  t-loss:0.5462, loss-lb:0.4671, loss-ulb:0.0975, weight:0.81, lr:0.0008
[02:13:01.328] iteration:3494  t-loss:0.7538, loss-lb:0.3907, loss-ulb:0.4480, weight:0.81, lr:0.0008
[02:13:01.641] iteration:3495  t-loss:0.6956, loss-lb:0.3247, loss-ulb:0.4576, weight:0.81, lr:0.0008
[02:13:01.959] iteration:3496  t-loss:0.4147, loss-lb:0.2165, loss-ulb:0.2445, weight:0.81, lr:0.0008
[02:13:02.264] iteration:3497  t-loss:0.3609, loss-lb:0.1945, loss-ulb:0.2052, weight:0.81, lr:0.0008
[02:13:02.579] iteration:3498  t-loss:0.4020, loss-lb:0.2388, loss-ulb:0.2014, weight:0.81, lr:0.0008
[02:13:02.898] iteration:3499  t-loss:0.6166, loss-lb:0.5479, loss-ulb:0.0847, weight:0.81, lr:0.0008
[02:13:03.214] iteration:3500  t-loss:0.7359, loss-lb:0.4126, loss-ulb:0.3988, weight:0.81, lr:0.0008
[02:13:04.548] iteration:3501  t-loss:0.4720, loss-lb:0.2587, loss-ulb:0.2631, weight:0.81, lr:0.0008
[02:13:04.889] iteration:3502  t-loss:0.3516, loss-lb:0.2577, loss-ulb:0.1158, weight:0.81, lr:0.0008
[02:13:05.219] iteration:3503  t-loss:0.5942, loss-lb:0.2273, loss-ulb:0.4527, weight:0.81, lr:0.0008
[02:13:05.541] iteration:3504  t-loss:0.3568, loss-lb:0.2987, loss-ulb:0.0717, weight:0.81, lr:0.0008
[02:13:05.856] iteration:3505  t-loss:0.2556, loss-lb:0.1953, loss-ulb:0.0743, weight:0.81, lr:0.0008
[02:13:06.170] iteration:3506  t-loss:0.2626, loss-lb:0.2143, loss-ulb:0.0596, weight:0.81, lr:0.0008
[02:13:06.486] iteration:3507  t-loss:0.3887, loss-lb:0.1660, loss-ulb:0.2746, weight:0.81, lr:0.0008
[02:13:06.806] iteration:3508  t-loss:0.3912, loss-lb:0.2930, loss-ulb:0.1211, weight:0.81, lr:0.0008
[02:13:07.119] iteration:3509  t-loss:0.2219, loss-lb:0.1894, loss-ulb:0.0402, weight:0.81, lr:0.0008
[02:13:07.433] iteration:3510  t-loss:0.2663, loss-lb:0.1717, loss-ulb:0.1168, weight:0.81, lr:0.0008
[02:13:07.755] iteration:3511  t-loss:0.7941, loss-lb:0.3530, loss-ulb:0.5442, weight:0.81, lr:0.0008
[02:13:08.070] iteration:3512  t-loss:0.5312, loss-lb:0.3938, loss-ulb:0.1695, weight:0.81, lr:0.0008
[02:13:08.392] iteration:3513  t-loss:0.3752, loss-lb:0.2210, loss-ulb:0.1903, weight:0.81, lr:0.0008
[02:13:08.719] iteration:3514  t-loss:0.7092, loss-lb:0.4785, loss-ulb:0.2847, weight:0.81, lr:0.0008
[02:13:09.040] iteration:3515  t-loss:0.2551, loss-lb:0.1783, loss-ulb:0.0947, weight:0.81, lr:0.0008
[02:13:09.359] iteration:3516  t-loss:0.4859, loss-lb:0.3604, loss-ulb:0.1549, weight:0.81, lr:0.0008
[02:13:09.684] iteration:3517  t-loss:0.3214, loss-lb:0.2673, loss-ulb:0.0668, weight:0.81, lr:0.0008
[02:13:10.000] iteration:3518  t-loss:0.5311, loss-lb:0.3987, loss-ulb:0.1634, weight:0.81, lr:0.0008
[02:13:10.314] iteration:3519  t-loss:0.3952, loss-lb:0.2172, loss-ulb:0.2196, weight:0.81, lr:0.0008
[02:13:10.636] iteration:3520  t-loss:0.9798, loss-lb:0.5092, loss-ulb:0.5805, weight:0.81, lr:0.0008
[02:13:10.965] iteration:3521  t-loss:0.5421, loss-lb:0.3208, loss-ulb:0.2730, weight:0.81, lr:0.0008
[02:13:11.280] iteration:3522  t-loss:0.3842, loss-lb:0.3093, loss-ulb:0.0925, weight:0.81, lr:0.0008
[02:13:11.596] iteration:3523  t-loss:0.2405, loss-lb:0.2189, loss-ulb:0.0267, weight:0.81, lr:0.0008
[02:13:11.919] iteration:3524  t-loss:0.2693, loss-lb:0.1992, loss-ulb:0.0865, weight:0.81, lr:0.0008
[02:13:12.236] iteration:3525  t-loss:0.4319, loss-lb:0.4019, loss-ulb:0.0370, weight:0.81, lr:0.0008
[02:15:30.600] iteration 3525 : dice_score: 0.827907 best_dice: 0.827900
[02:15:30.600]  <<Test>> - Ep:140  - Dice-S/T:82.79/82.79, Best-S:82.79, Best-T:82.79
[02:15:30.600]           - AvgLoss(lb/ulb/all):0.28/0.18/0.44
[02:15:32.267] iteration:3526  t-loss:0.2728, loss-lb:0.1856, loss-ulb:0.1076, weight:0.81, lr:0.0008
[02:15:32.605] iteration:3527  t-loss:0.2573, loss-lb:0.2224, loss-ulb:0.0430, weight:0.81, lr:0.0008
[02:15:32.935] iteration:3528  t-loss:0.4398, loss-lb:0.1570, loss-ulb:0.3489, weight:0.81, lr:0.0008
[02:15:33.263] iteration:3529  t-loss:0.5313, loss-lb:0.3651, loss-ulb:0.2050, weight:0.81, lr:0.0008
[02:15:33.581] iteration:3530  t-loss:0.2831, loss-lb:0.2232, loss-ulb:0.0739, weight:0.81, lr:0.0008
[02:15:33.912] iteration:3531  t-loss:0.4121, loss-lb:0.3614, loss-ulb:0.0626, weight:0.81, lr:0.0008
[02:15:34.237] iteration:3532  t-loss:0.7928, loss-lb:0.2888, loss-ulb:0.6217, weight:0.81, lr:0.0008
[02:15:34.560] iteration:3533  t-loss:0.5690, loss-lb:0.3259, loss-ulb:0.2998, weight:0.81, lr:0.0008
[02:15:34.895] iteration:3534  t-loss:0.3844, loss-lb:0.2360, loss-ulb:0.1831, weight:0.81, lr:0.0008
[02:15:35.219] iteration:3535  t-loss:0.4043, loss-lb:0.3580, loss-ulb:0.0571, weight:0.81, lr:0.0008
[02:15:35.537] iteration:3536  t-loss:0.5786, loss-lb:0.2505, loss-ulb:0.4047, weight:0.81, lr:0.0008
[02:15:35.858] iteration:3537  t-loss:0.4112, loss-lb:0.3802, loss-ulb:0.0382, weight:0.81, lr:0.0008
[02:15:36.182] iteration:3538  t-loss:0.4549, loss-lb:0.3604, loss-ulb:0.1166, weight:0.81, lr:0.0008
[02:15:36.512] iteration:3539  t-loss:0.3138, loss-lb:0.1843, loss-ulb:0.1598, weight:0.81, lr:0.0008
[02:15:36.830] iteration:3540  t-loss:0.3715, loss-lb:0.2179, loss-ulb:0.1895, weight:0.81, lr:0.0008
[02:15:37.151] iteration:3541  t-loss:0.2471, loss-lb:0.1937, loss-ulb:0.0659, weight:0.81, lr:0.0008
[02:15:37.470] iteration:3542  t-loss:0.4789, loss-lb:0.2696, loss-ulb:0.2582, weight:0.81, lr:0.0008
[02:15:37.789] iteration:3543  t-loss:0.6172, loss-lb:0.2841, loss-ulb:0.4109, weight:0.81, lr:0.0008
[02:15:38.102] iteration:3544  t-loss:0.3925, loss-lb:0.1970, loss-ulb:0.2412, weight:0.81, lr:0.0008
[02:15:38.423] iteration:3545  t-loss:0.3306, loss-lb:0.2460, loss-ulb:0.1044, weight:0.81, lr:0.0008
[02:15:38.736] iteration:3546  t-loss:0.2988, loss-lb:0.2239, loss-ulb:0.0923, weight:0.81, lr:0.0008
[02:15:39.054] iteration:3547  t-loss:0.9802, loss-lb:0.6116, loss-ulb:0.4547, weight:0.81, lr:0.0008
[02:15:39.370] iteration:3548  t-loss:0.4462, loss-lb:0.3686, loss-ulb:0.0957, weight:0.81, lr:0.0008
[02:15:39.697] iteration:3549  t-loss:0.2025, loss-lb:0.1526, loss-ulb:0.0615, weight:0.81, lr:0.0008
[02:15:40.018] iteration:3550  t-loss:0.3836, loss-lb:0.3434, loss-ulb:0.0496, weight:0.81, lr:0.0008
[02:15:41.521] iteration:3551  t-loss:0.3622, loss-lb:0.3167, loss-ulb:0.0561, weight:0.81, lr:0.0008
[02:15:41.873] iteration:3552  t-loss:0.7125, loss-lb:0.2801, loss-ulb:0.5334, weight:0.81, lr:0.0008
[02:15:42.213] iteration:3553  t-loss:0.5257, loss-lb:0.2322, loss-ulb:0.3621, weight:0.81, lr:0.0008
[02:15:42.559] iteration:3554  t-loss:0.6161, loss-lb:0.2981, loss-ulb:0.3923, weight:0.81, lr:0.0008
[02:15:42.883] iteration:3555  t-loss:0.5078, loss-lb:0.4305, loss-ulb:0.0953, weight:0.81, lr:0.0008
[02:15:43.201] iteration:3556  t-loss:0.4609, loss-lb:0.3103, loss-ulb:0.1858, weight:0.81, lr:0.0008
[02:15:43.533] iteration:3557  t-loss:0.4345, loss-lb:0.3176, loss-ulb:0.1443, weight:0.81, lr:0.0008
[02:15:43.851] iteration:3558  t-loss:0.2990, loss-lb:0.1680, loss-ulb:0.1617, weight:0.81, lr:0.0008
[02:15:44.176] iteration:3559  t-loss:0.2374, loss-lb:0.1876, loss-ulb:0.0615, weight:0.81, lr:0.0008
[02:15:44.506] iteration:3560  t-loss:0.4451, loss-lb:0.3568, loss-ulb:0.1089, weight:0.81, lr:0.0008
[02:15:44.823] iteration:3561  t-loss:0.3219, loss-lb:0.2235, loss-ulb:0.1213, weight:0.81, lr:0.0008
[02:15:45.140] iteration:3562  t-loss:0.9728, loss-lb:0.3834, loss-ulb:0.7271, weight:0.81, lr:0.0008
[02:15:45.461] iteration:3563  t-loss:0.3841, loss-lb:0.3038, loss-ulb:0.0990, weight:0.81, lr:0.0008
[02:15:45.785] iteration:3564  t-loss:0.2874, loss-lb:0.2361, loss-ulb:0.0633, weight:0.81, lr:0.0008
[02:15:46.102] iteration:3565  t-loss:0.4753, loss-lb:0.1754, loss-ulb:0.3700, weight:0.81, lr:0.0008
[02:15:46.422] iteration:3566  t-loss:0.3528, loss-lb:0.3207, loss-ulb:0.0396, weight:0.81, lr:0.0008
[02:15:46.743] iteration:3567  t-loss:0.2269, loss-lb:0.2041, loss-ulb:0.0281, weight:0.81, lr:0.0008
[02:15:47.072] iteration:3568  t-loss:0.7104, loss-lb:0.2742, loss-ulb:0.5381, weight:0.81, lr:0.0008
[02:15:47.408] iteration:3569  t-loss:0.3083, loss-lb:0.2052, loss-ulb:0.1272, weight:0.81, lr:0.0008
[02:15:47.727] iteration:3570  t-loss:0.3425, loss-lb:0.2471, loss-ulb:0.1177, weight:0.81, lr:0.0008
[02:15:48.043] iteration:3571  t-loss:0.2832, loss-lb:0.1474, loss-ulb:0.1676, weight:0.81, lr:0.0008
[02:15:48.360] iteration:3572  t-loss:0.5739, loss-lb:0.1882, loss-ulb:0.4758, weight:0.81, lr:0.0008
[02:15:48.680] iteration:3573  t-loss:0.6110, loss-lb:0.2774, loss-ulb:0.4115, weight:0.81, lr:0.0008
[02:15:48.996] iteration:3574  t-loss:0.3907, loss-lb:0.3008, loss-ulb:0.1109, weight:0.81, lr:0.0008
[02:15:49.315] iteration:3575  t-loss:0.2751, loss-lb:0.2121, loss-ulb:0.0777, weight:0.81, lr:0.0008
[02:15:50.777] iteration:3576  t-loss:0.4767, loss-lb:0.3533, loss-ulb:0.1523, weight:0.81, lr:0.0008
[02:15:51.119] iteration:3577  t-loss:0.2349, loss-lb:0.2126, loss-ulb:0.0276, weight:0.81, lr:0.0008
[02:15:51.462] iteration:3578  t-loss:0.3854, loss-lb:0.3564, loss-ulb:0.0357, weight:0.81, lr:0.0008
[02:15:51.810] iteration:3579  t-loss:0.6495, loss-lb:0.1951, loss-ulb:0.5607, weight:0.81, lr:0.0008
[02:15:52.151] iteration:3580  t-loss:0.3416, loss-lb:0.1892, loss-ulb:0.1880, weight:0.81, lr:0.0008
[02:15:52.480] iteration:3581  t-loss:0.2635, loss-lb:0.1692, loss-ulb:0.1163, weight:0.81, lr:0.0008
[02:15:52.813] iteration:3582  t-loss:0.6842, loss-lb:0.6469, loss-ulb:0.0461, weight:0.81, lr:0.0008
[02:15:53.154] iteration:3583  t-loss:0.5353, loss-lb:0.3685, loss-ulb:0.2057, weight:0.81, lr:0.0008
[02:15:53.477] iteration:3584  t-loss:0.5503, loss-lb:0.2765, loss-ulb:0.3378, weight:0.81, lr:0.0008
[02:15:53.800] iteration:3585  t-loss:0.2985, loss-lb:0.1479, loss-ulb:0.1858, weight:0.81, lr:0.0008
[02:15:54.124] iteration:3586  t-loss:0.2951, loss-lb:0.2371, loss-ulb:0.0716, weight:0.81, lr:0.0008
[02:15:54.442] iteration:3587  t-loss:0.8107, loss-lb:0.1525, loss-ulb:0.8120, weight:0.81, lr:0.0008
[02:15:54.764] iteration:3588  t-loss:0.5625, loss-lb:0.4397, loss-ulb:0.1514, weight:0.81, lr:0.0008
[02:15:55.087] iteration:3589  t-loss:0.5800, loss-lb:0.1786, loss-ulb:0.4952, weight:0.81, lr:0.0008
[02:15:55.406] iteration:3590  t-loss:0.5328, loss-lb:0.4478, loss-ulb:0.1049, weight:0.81, lr:0.0008
[02:15:55.738] iteration:3591  t-loss:0.4480, loss-lb:0.3512, loss-ulb:0.1195, weight:0.81, lr:0.0008
[02:15:56.067] iteration:3592  t-loss:0.4665, loss-lb:0.1455, loss-ulb:0.3960, weight:0.81, lr:0.0008
[02:15:56.393] iteration:3593  t-loss:0.4555, loss-lb:0.4181, loss-ulb:0.0460, weight:0.81, lr:0.0008
[02:15:56.714] iteration:3594  t-loss:0.3805, loss-lb:0.3523, loss-ulb:0.0348, weight:0.81, lr:0.0008
[02:15:57.037] iteration:3595  t-loss:0.2777, loss-lb:0.2576, loss-ulb:0.0247, weight:0.81, lr:0.0008
[02:15:57.366] iteration:3596  t-loss:0.5607, loss-lb:0.4969, loss-ulb:0.0787, weight:0.81, lr:0.0008
[02:15:57.688] iteration:3597  t-loss:0.4187, loss-lb:0.1801, loss-ulb:0.2943, weight:0.81, lr:0.0008
[02:15:58.012] iteration:3598  t-loss:0.4617, loss-lb:0.3844, loss-ulb:0.0954, weight:0.81, lr:0.0008
[02:15:58.351] iteration:3599  t-loss:0.3375, loss-lb:0.2641, loss-ulb:0.0906, weight:0.81, lr:0.0008
[02:15:58.677] iteration:3600  t-loss:0.3500, loss-lb:0.2798, loss-ulb:0.0866, weight:0.81, lr:0.0008
[02:16:00.517] iteration:3601  t-loss:0.7887, loss-lb:0.1987, loss-ulb:0.6565, weight:0.90, lr:0.0008
[02:16:00.919] iteration:3602  t-loss:0.6866, loss-lb:0.2798, loss-ulb:0.4527, weight:0.90, lr:0.0008
[02:16:01.284] iteration:3603  t-loss:0.2406, loss-lb:0.2046, loss-ulb:0.0400, weight:0.90, lr:0.0008
[02:16:01.649] iteration:3604  t-loss:0.5702, loss-lb:0.2010, loss-ulb:0.4108, weight:0.90, lr:0.0008
[02:16:02.049] iteration:3605  t-loss:0.3820, loss-lb:0.2780, loss-ulb:0.1157, weight:0.90, lr:0.0008
[02:16:02.408] iteration:3606  t-loss:0.4079, loss-lb:0.1788, loss-ulb:0.2549, weight:0.90, lr:0.0008
[02:16:02.766] iteration:3607  t-loss:0.2399, loss-lb:0.2033, loss-ulb:0.0408, weight:0.90, lr:0.0008
[02:16:03.123] iteration:3608  t-loss:0.5110, loss-lb:0.2978, loss-ulb:0.2372, weight:0.90, lr:0.0008
[02:16:03.510] iteration:3609  t-loss:0.5392, loss-lb:0.3442, loss-ulb:0.2170, weight:0.90, lr:0.0008
[02:16:03.847] iteration:3610  t-loss:0.3183, loss-lb:0.1258, loss-ulb:0.2142, weight:0.90, lr:0.0008
[02:16:04.170] iteration:3611  t-loss:0.3772, loss-lb:0.2126, loss-ulb:0.1832, weight:0.90, lr:0.0008
[02:16:04.493] iteration:3612  t-loss:0.4586, loss-lb:0.4249, loss-ulb:0.0375, weight:0.90, lr:0.0008
[02:16:04.821] iteration:3613  t-loss:0.3103, loss-lb:0.2911, loss-ulb:0.0213, weight:0.90, lr:0.0008
[02:16:05.144] iteration:3614  t-loss:0.4634, loss-lb:0.3104, loss-ulb:0.1702, weight:0.90, lr:0.0008
[02:16:05.460] iteration:3615  t-loss:0.3140, loss-lb:0.2335, loss-ulb:0.0896, weight:0.90, lr:0.0008
[02:16:05.775] iteration:3616  t-loss:0.6608, loss-lb:0.2121, loss-ulb:0.4993, weight:0.90, lr:0.0008
[02:16:06.094] iteration:3617  t-loss:0.9008, loss-lb:0.1484, loss-ulb:0.8373, weight:0.90, lr:0.0008
[02:16:06.409] iteration:3618  t-loss:0.3601, loss-lb:0.2930, loss-ulb:0.0746, weight:0.90, lr:0.0008
[02:16:06.723] iteration:3619  t-loss:0.2853, loss-lb:0.1408, loss-ulb:0.1608, weight:0.90, lr:0.0008
[02:16:07.037] iteration:3620  t-loss:0.5871, loss-lb:0.3544, loss-ulb:0.2590, weight:0.90, lr:0.0008
[02:16:07.355] iteration:3621  t-loss:0.4973, loss-lb:0.1895, loss-ulb:0.3425, weight:0.90, lr:0.0008
[02:16:07.681] iteration:3622  t-loss:0.2638, loss-lb:0.2038, loss-ulb:0.0668, weight:0.90, lr:0.0008
[02:16:08.011] iteration:3623  t-loss:0.5803, loss-lb:0.3456, loss-ulb:0.2611, weight:0.90, lr:0.0008
[02:16:08.335] iteration:3624  t-loss:0.2396, loss-lb:0.1824, loss-ulb:0.0637, weight:0.90, lr:0.0008
[02:16:08.660] iteration:3625  t-loss:0.5466, loss-lb:0.2261, loss-ulb:0.3566, weight:0.90, lr:0.0008
[02:18:30.879] iteration 3625 : dice_score: 0.829707 best_dice: 0.829700
[02:18:30.880]  <<Test>> - Ep:144  - Dice-S/T:74.79/82.97, Best-S:82.79, Best-T:82.97
[02:18:30.881]           - AvgLoss(lb/ulb/all):0.24/0.22/0.44
[02:18:32.317] iteration:3626  t-loss:0.4328, loss-lb:0.2565, loss-ulb:0.1962, weight:0.90, lr:0.0008
[02:18:32.645] iteration:3627  t-loss:1.1533, loss-lb:0.4033, loss-ulb:0.8346, weight:0.90, lr:0.0008
[02:18:32.982] iteration:3628  t-loss:0.4312, loss-lb:0.3096, loss-ulb:0.1353, weight:0.90, lr:0.0008
[02:18:33.310] iteration:3629  t-loss:0.4519, loss-lb:0.3103, loss-ulb:0.1576, weight:0.90, lr:0.0008
[02:18:33.649] iteration:3630  t-loss:0.5926, loss-lb:0.4139, loss-ulb:0.1989, weight:0.90, lr:0.0008
[02:18:33.986] iteration:3631  t-loss:0.2678, loss-lb:0.2377, loss-ulb:0.0335, weight:0.90, lr:0.0008
[02:18:34.339] iteration:3632  t-loss:0.4012, loss-lb:0.2154, loss-ulb:0.2067, weight:0.90, lr:0.0008
[02:18:34.688] iteration:3633  t-loss:0.4264, loss-lb:0.2860, loss-ulb:0.1562, weight:0.90, lr:0.0008
[02:18:35.016] iteration:3634  t-loss:0.3809, loss-lb:0.2387, loss-ulb:0.1582, weight:0.90, lr:0.0008
[02:18:35.347] iteration:3635  t-loss:0.3259, loss-lb:0.2029, loss-ulb:0.1369, weight:0.90, lr:0.0008
[02:18:35.678] iteration:3636  t-loss:0.4845, loss-lb:0.3414, loss-ulb:0.1591, weight:0.90, lr:0.0008
[02:18:35.995] iteration:3637  t-loss:0.5392, loss-lb:0.4850, loss-ulb:0.0603, weight:0.90, lr:0.0008
[02:18:36.315] iteration:3638  t-loss:0.6014, loss-lb:0.5077, loss-ulb:0.1042, weight:0.90, lr:0.0008
[02:18:36.638] iteration:3639  t-loss:0.7047, loss-lb:0.2540, loss-ulb:0.5015, weight:0.90, lr:0.0008
[02:18:36.956] iteration:3640  t-loss:0.6757, loss-lb:0.3697, loss-ulb:0.3406, weight:0.90, lr:0.0008
[02:18:37.269] iteration:3641  t-loss:0.4027, loss-lb:0.1698, loss-ulb:0.2591, weight:0.90, lr:0.0008
[02:18:37.591] iteration:3642  t-loss:0.5474, loss-lb:0.4115, loss-ulb:0.1512, weight:0.90, lr:0.0008
[02:18:37.911] iteration:3643  t-loss:0.3589, loss-lb:0.2546, loss-ulb:0.1161, weight:0.90, lr:0.0008
[02:18:38.235] iteration:3644  t-loss:0.4739, loss-lb:0.4357, loss-ulb:0.0426, weight:0.90, lr:0.0008
[02:18:38.549] iteration:3645  t-loss:0.2585, loss-lb:0.1600, loss-ulb:0.1096, weight:0.90, lr:0.0008
[02:18:38.869] iteration:3646  t-loss:0.7215, loss-lb:0.3404, loss-ulb:0.4241, weight:0.90, lr:0.0008
[02:18:39.187] iteration:3647  t-loss:0.7779, loss-lb:0.7262, loss-ulb:0.0576, weight:0.90, lr:0.0008
[02:18:39.510] iteration:3648  t-loss:0.4571, loss-lb:0.3582, loss-ulb:0.1100, weight:0.90, lr:0.0008
[02:18:39.826] iteration:3649  t-loss:0.3453, loss-lb:0.1885, loss-ulb:0.1745, weight:0.90, lr:0.0008
[02:18:40.139] iteration:3650  t-loss:0.4492, loss-lb:0.2707, loss-ulb:0.1987, weight:0.90, lr:0.0008
[02:18:41.461] iteration:3651  t-loss:0.4785, loss-lb:0.3110, loss-ulb:0.1864, weight:0.90, lr:0.0008
[02:18:41.804] iteration:3652  t-loss:0.4021, loss-lb:0.2451, loss-ulb:0.1748, weight:0.90, lr:0.0008
[02:18:42.150] iteration:3653  t-loss:0.5658, loss-lb:0.4972, loss-ulb:0.0763, weight:0.90, lr:0.0008
[02:18:42.503] iteration:3654  t-loss:0.4112, loss-lb:0.2709, loss-ulb:0.1562, weight:0.90, lr:0.0008
[02:18:42.845] iteration:3655  t-loss:0.4618, loss-lb:0.2059, loss-ulb:0.2848, weight:0.90, lr:0.0008
[02:18:43.190] iteration:3656  t-loss:0.2546, loss-lb:0.2173, loss-ulb:0.0415, weight:0.90, lr:0.0008
[02:18:43.525] iteration:3657  t-loss:0.2371, loss-lb:0.1779, loss-ulb:0.0659, weight:0.90, lr:0.0008
[02:18:43.883] iteration:3658  t-loss:0.4403, loss-lb:0.2036, loss-ulb:0.2634, weight:0.90, lr:0.0008
[02:18:44.229] iteration:3659  t-loss:0.4155, loss-lb:0.2584, loss-ulb:0.1749, weight:0.90, lr:0.0008
[02:18:44.587] iteration:3660  t-loss:0.3779, loss-lb:0.2431, loss-ulb:0.1500, weight:0.90, lr:0.0008
[02:18:44.936] iteration:3661  t-loss:0.4280, loss-lb:0.3020, loss-ulb:0.1403, weight:0.90, lr:0.0008
[02:18:45.271] iteration:3662  t-loss:0.7542, loss-lb:0.2656, loss-ulb:0.5437, weight:0.90, lr:0.0008
[02:18:45.600] iteration:3663  t-loss:0.7266, loss-lb:0.3168, loss-ulb:0.4560, weight:0.90, lr:0.0008
[02:18:45.940] iteration:3664  t-loss:0.7610, loss-lb:0.4463, loss-ulb:0.3502, weight:0.90, lr:0.0008
[02:18:46.266] iteration:3665  t-loss:0.3055, loss-lb:0.2216, loss-ulb:0.0934, weight:0.90, lr:0.0008
[02:18:46.586] iteration:3666  t-loss:0.5230, loss-lb:0.1603, loss-ulb:0.4036, weight:0.90, lr:0.0008
[02:18:46.915] iteration:3667  t-loss:0.3718, loss-lb:0.2321, loss-ulb:0.1555, weight:0.90, lr:0.0008
[02:18:47.242] iteration:3668  t-loss:0.8006, loss-lb:0.4842, loss-ulb:0.3521, weight:0.90, lr:0.0008
[02:18:47.557] iteration:3669  t-loss:0.4731, loss-lb:0.3945, loss-ulb:0.0874, weight:0.90, lr:0.0008
[02:18:47.872] iteration:3670  t-loss:0.6847, loss-lb:0.2235, loss-ulb:0.5132, weight:0.90, lr:0.0008
[02:18:48.190] iteration:3671  t-loss:0.3042, loss-lb:0.1847, loss-ulb:0.1329, weight:0.90, lr:0.0008
[02:18:48.503] iteration:3672  t-loss:0.5943, loss-lb:0.2846, loss-ulb:0.3447, weight:0.90, lr:0.0008
[02:18:48.817] iteration:3673  t-loss:0.3194, loss-lb:0.2218, loss-ulb:0.1086, weight:0.90, lr:0.0008
[02:18:49.131] iteration:3674  t-loss:0.5112, loss-lb:0.2314, loss-ulb:0.3114, weight:0.90, lr:0.0008
[02:18:49.443] iteration:3675  t-loss:0.4044, loss-lb:0.2326, loss-ulb:0.1912, weight:0.90, lr:0.0008
[02:18:50.648] iteration:3676  t-loss:0.4217, loss-lb:0.3647, loss-ulb:0.0634, weight:0.90, lr:0.0008
[02:18:50.983] iteration:3677  t-loss:0.5925, loss-lb:0.3329, loss-ulb:0.2890, weight:0.90, lr:0.0008
[02:18:51.309] iteration:3678  t-loss:0.4923, loss-lb:0.2801, loss-ulb:0.2360, weight:0.90, lr:0.0008
[02:18:51.641] iteration:3679  t-loss:0.5726, loss-lb:0.3190, loss-ulb:0.2821, weight:0.90, lr:0.0008
[02:18:51.975] iteration:3680  t-loss:0.4767, loss-lb:0.2643, loss-ulb:0.2364, weight:0.90, lr:0.0008
[02:18:52.314] iteration:3681  t-loss:0.7527, loss-lb:0.1694, loss-ulb:0.6490, weight:0.90, lr:0.0008
[02:18:52.655] iteration:3682  t-loss:0.4639, loss-lb:0.2878, loss-ulb:0.1960, weight:0.90, lr:0.0008
[02:18:52.989] iteration:3683  t-loss:0.4193, loss-lb:0.1887, loss-ulb:0.2566, weight:0.90, lr:0.0008
[02:18:53.316] iteration:3684  t-loss:0.4015, loss-lb:0.2438, loss-ulb:0.1755, weight:0.90, lr:0.0008
[02:18:53.639] iteration:3685  t-loss:0.4989, loss-lb:0.2258, loss-ulb:0.3039, weight:0.90, lr:0.0008
[02:18:53.970] iteration:3686  t-loss:0.2327, loss-lb:0.1759, loss-ulb:0.0632, weight:0.90, lr:0.0008
[02:18:54.303] iteration:3687  t-loss:0.4323, loss-lb:0.3405, loss-ulb:0.1021, weight:0.90, lr:0.0008
[02:18:54.626] iteration:3688  t-loss:0.2482, loss-lb:0.1464, loss-ulb:0.1133, weight:0.90, lr:0.0008
[02:18:54.968] iteration:3689  t-loss:0.4090, loss-lb:0.3202, loss-ulb:0.0989, weight:0.90, lr:0.0008
[02:18:55.304] iteration:3690  t-loss:0.3869, loss-lb:0.3333, loss-ulb:0.0597, weight:0.90, lr:0.0008
[02:18:55.636] iteration:3691  t-loss:0.6444, loss-lb:0.4449, loss-ulb:0.2220, weight:0.90, lr:0.0008
[02:18:55.960] iteration:3692  t-loss:0.6312, loss-lb:0.1757, loss-ulb:0.5070, weight:0.90, lr:0.0008
[02:18:56.280] iteration:3693  t-loss:0.3081, loss-lb:0.2199, loss-ulb:0.0982, weight:0.90, lr:0.0008
[02:18:56.600] iteration:3694  t-loss:0.4339, loss-lb:0.2867, loss-ulb:0.1638, weight:0.90, lr:0.0008
[02:18:56.918] iteration:3695  t-loss:0.6231, loss-lb:0.1774, loss-ulb:0.4959, weight:0.90, lr:0.0008
[02:18:57.234] iteration:3696  t-loss:1.0075, loss-lb:0.3781, loss-ulb:0.7004, weight:0.90, lr:0.0008
[02:18:57.552] iteration:3697  t-loss:0.5422, loss-lb:0.1672, loss-ulb:0.4173, weight:0.90, lr:0.0008
[02:18:57.864] iteration:3698  t-loss:0.9308, loss-lb:0.2379, loss-ulb:0.7711, weight:0.90, lr:0.0008
[02:18:58.179] iteration:3699  t-loss:0.5599, loss-lb:0.3236, loss-ulb:0.2630, weight:0.90, lr:0.0008
[02:18:58.494] iteration:3700  t-loss:0.2297, loss-lb:0.1894, loss-ulb:0.0448, weight:0.90, lr:0.0008
[02:18:59.791] iteration:3701  t-loss:0.6185, loss-lb:0.3833, loss-ulb:0.2617, weight:0.90, lr:0.0008
[02:19:00.122] iteration:3702  t-loss:0.4847, loss-lb:0.3305, loss-ulb:0.1715, weight:0.90, lr:0.0008
[02:19:00.443] iteration:3703  t-loss:0.3008, loss-lb:0.1417, loss-ulb:0.1771, weight:0.90, lr:0.0008
[02:19:00.759] iteration:3704  t-loss:0.6487, loss-lb:0.2421, loss-ulb:0.4525, weight:0.90, lr:0.0008
[02:19:01.080] iteration:3705  t-loss:0.4640, loss-lb:0.3496, loss-ulb:0.1273, weight:0.90, lr:0.0008
[02:19:01.402] iteration:3706  t-loss:0.3042, loss-lb:0.1792, loss-ulb:0.1391, weight:0.90, lr:0.0008
[02:19:01.726] iteration:3707  t-loss:0.2973, loss-lb:0.1901, loss-ulb:0.1193, weight:0.90, lr:0.0008
[02:19:02.041] iteration:3708  t-loss:0.4728, loss-lb:0.2659, loss-ulb:0.2301, weight:0.90, lr:0.0008
[02:19:02.362] iteration:3709  t-loss:0.3180, loss-lb:0.1782, loss-ulb:0.1556, weight:0.90, lr:0.0008
[02:19:02.682] iteration:3710  t-loss:0.3822, loss-lb:0.2010, loss-ulb:0.2017, weight:0.90, lr:0.0008
[02:19:03.001] iteration:3711  t-loss:0.5499, loss-lb:0.2804, loss-ulb:0.3000, weight:0.90, lr:0.0008
[02:19:03.318] iteration:3712  t-loss:0.2037, loss-lb:0.1397, loss-ulb:0.0712, weight:0.90, lr:0.0008
[02:19:03.635] iteration:3713  t-loss:0.3473, loss-lb:0.3064, loss-ulb:0.0456, weight:0.90, lr:0.0008
[02:19:03.954] iteration:3714  t-loss:0.8951, loss-lb:0.1886, loss-ulb:0.7862, weight:0.90, lr:0.0008
[02:19:04.281] iteration:3715  t-loss:0.5302, loss-lb:0.4420, loss-ulb:0.0981, weight:0.90, lr:0.0008
[02:19:04.602] iteration:3716  t-loss:1.2247, loss-lb:0.3578, loss-ulb:0.9647, weight:0.90, lr:0.0008
[02:19:04.922] iteration:3717  t-loss:0.5277, loss-lb:0.2711, loss-ulb:0.2855, weight:0.90, lr:0.0008
[02:19:05.241] iteration:3718  t-loss:0.3549, loss-lb:0.2515, loss-ulb:0.1150, weight:0.90, lr:0.0008
[02:19:05.557] iteration:3719  t-loss:0.3270, loss-lb:0.2963, loss-ulb:0.0341, weight:0.90, lr:0.0008
[02:19:05.871] iteration:3720  t-loss:0.3166, loss-lb:0.2770, loss-ulb:0.0440, weight:0.90, lr:0.0008
[02:19:06.184] iteration:3721  t-loss:0.5240, loss-lb:0.2098, loss-ulb:0.3496, weight:0.90, lr:0.0008
[02:19:06.504] iteration:3722  t-loss:0.6692, loss-lb:0.4545, loss-ulb:0.2390, weight:0.90, lr:0.0008
[02:19:06.822] iteration:3723  t-loss:0.4610, loss-lb:0.3806, loss-ulb:0.0895, weight:0.90, lr:0.0008
[02:19:07.140] iteration:3724  t-loss:0.4265, loss-lb:0.3953, loss-ulb:0.0347, weight:0.90, lr:0.0008
[02:19:07.456] iteration:3725  t-loss:0.4308, loss-lb:0.2917, loss-ulb:0.1548, weight:0.90, lr:0.0008
[02:21:36.222] iteration 3725 : dice_score: 0.826495 best_dice: 0.829700
[02:21:36.222]  <<Test>> - Ep:148  - Dice-S/T:44.59/82.65, Best-S:82.79, Best-T:82.97
[02:21:36.222]           - AvgLoss(lb/ulb/all):0.28/0.22/0.48
[02:21:37.357] iteration:3726  t-loss:0.6428, loss-lb:0.3821, loss-ulb:0.2901, weight:0.90, lr:0.0008
[02:21:37.686] iteration:3727  t-loss:0.8269, loss-lb:0.3131, loss-ulb:0.5717, weight:0.90, lr:0.0008
[02:21:38.032] iteration:3728  t-loss:0.3632, loss-lb:0.2605, loss-ulb:0.1143, weight:0.90, lr:0.0008
[02:21:38.373] iteration:3729  t-loss:0.4529, loss-lb:0.2355, loss-ulb:0.2419, weight:0.90, lr:0.0008
[02:21:38.726] iteration:3730  t-loss:0.3500, loss-lb:0.2621, loss-ulb:0.0978, weight:0.90, lr:0.0008
[02:21:39.056] iteration:3731  t-loss:0.3178, loss-lb:0.1950, loss-ulb:0.1366, weight:0.90, lr:0.0008
[02:21:39.396] iteration:3732  t-loss:0.3194, loss-lb:0.1849, loss-ulb:0.1497, weight:0.90, lr:0.0008
[02:21:39.743] iteration:3733  t-loss:0.2879, loss-lb:0.2589, loss-ulb:0.0323, weight:0.90, lr:0.0008
[02:21:40.090] iteration:3734  t-loss:0.3139, loss-lb:0.1697, loss-ulb:0.1605, weight:0.90, lr:0.0008
[02:21:40.439] iteration:3735  t-loss:0.4611, loss-lb:0.1483, loss-ulb:0.3480, weight:0.90, lr:0.0008
[02:21:40.773] iteration:3736  t-loss:0.4802, loss-lb:0.3799, loss-ulb:0.1116, weight:0.90, lr:0.0008
[02:21:41.117] iteration:3737  t-loss:0.5575, loss-lb:0.2845, loss-ulb:0.3038, weight:0.90, lr:0.0008
[02:21:41.448] iteration:3738  t-loss:0.2934, loss-lb:0.1937, loss-ulb:0.1109, weight:0.90, lr:0.0008
[02:21:41.784] iteration:3739  t-loss:0.2607, loss-lb:0.1964, loss-ulb:0.0715, weight:0.90, lr:0.0008
[02:21:42.136] iteration:3740  t-loss:1.4830, loss-lb:0.3387, loss-ulb:1.2734, weight:0.90, lr:0.0008
[02:21:42.472] iteration:3741  t-loss:0.3094, loss-lb:0.1822, loss-ulb:0.1415, weight:0.90, lr:0.0008
[02:21:42.809] iteration:3742  t-loss:0.5082, loss-lb:0.3099, loss-ulb:0.2207, weight:0.90, lr:0.0008
[02:21:43.131] iteration:3743  t-loss:0.4014, loss-lb:0.2186, loss-ulb:0.2035, weight:0.90, lr:0.0008
[02:21:43.457] iteration:3744  t-loss:0.5523, loss-lb:0.2366, loss-ulb:0.3513, weight:0.90, lr:0.0008
[02:21:43.784] iteration:3745  t-loss:0.7809, loss-lb:0.6101, loss-ulb:0.1902, weight:0.90, lr:0.0008
[02:21:44.105] iteration:3746  t-loss:0.2763, loss-lb:0.2119, loss-ulb:0.0717, weight:0.90, lr:0.0008
[02:21:44.422] iteration:3747  t-loss:0.4652, loss-lb:0.3945, loss-ulb:0.0787, weight:0.90, lr:0.0008
[02:21:44.738] iteration:3748  t-loss:0.6806, loss-lb:0.3392, loss-ulb:0.3799, weight:0.90, lr:0.0008
[02:21:45.053] iteration:3749  t-loss:0.4868, loss-lb:0.2785, loss-ulb:0.2318, weight:0.90, lr:0.0008
[02:21:45.366] iteration:3750  t-loss:0.7672, loss-lb:0.5407, loss-ulb:0.2521, weight:0.90, lr:0.0008
[02:21:46.688] iteration:3751  t-loss:0.7521, loss-lb:0.4111, loss-ulb:0.3444, weight:0.99, lr:0.0008
[02:21:47.028] iteration:3752  t-loss:0.8318, loss-lb:0.2731, loss-ulb:0.5643, weight:0.99, lr:0.0008
[02:21:47.365] iteration:3753  t-loss:0.6143, loss-lb:0.1498, loss-ulb:0.4691, weight:0.99, lr:0.0008
[02:21:47.693] iteration:3754  t-loss:0.3548, loss-lb:0.2559, loss-ulb:0.0999, weight:0.99, lr:0.0008
[02:21:48.033] iteration:3755  t-loss:0.6105, loss-lb:0.2463, loss-ulb:0.3679, weight:0.99, lr:0.0008
[02:21:48.370] iteration:3756  t-loss:0.4431, loss-lb:0.3751, loss-ulb:0.0687, weight:0.99, lr:0.0008
[02:21:48.698] iteration:3757  t-loss:0.2709, loss-lb:0.1806, loss-ulb:0.0911, weight:0.99, lr:0.0008
[02:21:49.025] iteration:3758  t-loss:0.3738, loss-lb:0.2295, loss-ulb:0.1458, weight:0.99, lr:0.0008
[02:21:49.348] iteration:3759  t-loss:0.9185, loss-lb:0.3010, loss-ulb:0.6237, weight:0.99, lr:0.0008
[02:21:49.671] iteration:3760  t-loss:0.2937, loss-lb:0.2487, loss-ulb:0.0455, weight:0.99, lr:0.0008
[02:21:49.991] iteration:3761  t-loss:1.0328, loss-lb:0.2885, loss-ulb:0.7517, weight:0.99, lr:0.0008
[02:21:50.312] iteration:3762  t-loss:0.4637, loss-lb:0.2442, loss-ulb:0.2218, weight:0.99, lr:0.0008
[02:21:50.638] iteration:3763  t-loss:0.4938, loss-lb:0.2251, loss-ulb:0.2714, weight:0.99, lr:0.0008
[02:21:50.960] iteration:3764  t-loss:0.4598, loss-lb:0.3507, loss-ulb:0.1103, weight:0.99, lr:0.0008
[02:21:51.282] iteration:3765  t-loss:0.6418, loss-lb:0.1514, loss-ulb:0.4953, weight:0.99, lr:0.0008
[02:21:51.607] iteration:3766  t-loss:0.5132, loss-lb:0.2712, loss-ulb:0.2445, weight:0.99, lr:0.0008
[02:21:51.927] iteration:3767  t-loss:0.8350, loss-lb:0.1807, loss-ulb:0.6608, weight:0.99, lr:0.0008
[02:21:52.249] iteration:3768  t-loss:0.2355, loss-lb:0.1850, loss-ulb:0.0510, weight:0.99, lr:0.0008
[02:21:52.573] iteration:3769  t-loss:0.4545, loss-lb:0.2443, loss-ulb:0.2124, weight:0.99, lr:0.0008
[02:21:52.899] iteration:3770  t-loss:0.6759, loss-lb:0.3268, loss-ulb:0.3526, weight:0.99, lr:0.0008
[02:21:53.219] iteration:3771  t-loss:0.4798, loss-lb:0.2779, loss-ulb:0.2039, weight:0.99, lr:0.0008
[02:21:53.548] iteration:3772  t-loss:0.2326, loss-lb:0.1989, loss-ulb:0.0340, weight:0.99, lr:0.0008
[02:21:53.878] iteration:3773  t-loss:0.9952, loss-lb:0.4742, loss-ulb:0.5262, weight:0.99, lr:0.0008
[02:21:54.197] iteration:3774  t-loss:0.5259, loss-lb:0.1873, loss-ulb:0.3419, weight:0.99, lr:0.0008
[02:21:54.514] iteration:3775  t-loss:1.1521, loss-lb:0.3524, loss-ulb:0.8077, weight:0.99, lr:0.0008
[02:21:55.811] iteration:3776  t-loss:0.2669, loss-lb:0.1881, loss-ulb:0.0796, weight:0.99, lr:0.0008
[02:21:56.149] iteration:3777  t-loss:0.9049, loss-lb:0.2550, loss-ulb:0.6564, weight:0.99, lr:0.0008
[02:21:56.501] iteration:3778  t-loss:0.6676, loss-lb:0.4664, loss-ulb:0.2032, weight:0.99, lr:0.0008
[02:21:56.846] iteration:3779  t-loss:0.5618, loss-lb:0.4307, loss-ulb:0.1324, weight:0.99, lr:0.0008
[02:21:57.188] iteration:3780  t-loss:0.5381, loss-lb:0.1768, loss-ulb:0.3649, weight:0.99, lr:0.0008
[02:21:57.532] iteration:3781  t-loss:0.3384, loss-lb:0.1765, loss-ulb:0.1635, weight:0.99, lr:0.0008
[02:21:57.879] iteration:3782  t-loss:0.4614, loss-lb:0.3594, loss-ulb:0.1030, weight:0.99, lr:0.0008
[02:21:58.205] iteration:3783  t-loss:0.7027, loss-lb:0.2378, loss-ulb:0.4696, weight:0.99, lr:0.0008
[02:21:58.546] iteration:3784  t-loss:0.6354, loss-lb:0.4616, loss-ulb:0.1755, weight:0.99, lr:0.0008
[02:21:58.887] iteration:3785  t-loss:0.6662, loss-lb:0.3191, loss-ulb:0.3506, weight:0.99, lr:0.0008
[02:21:59.222] iteration:3786  t-loss:0.5376, loss-lb:0.3395, loss-ulb:0.2000, weight:0.99, lr:0.0008
[02:21:59.546] iteration:3787  t-loss:0.4311, loss-lb:0.2293, loss-ulb:0.2038, weight:0.99, lr:0.0008
[02:21:59.868] iteration:3788  t-loss:0.3052, loss-lb:0.2128, loss-ulb:0.0933, weight:0.99, lr:0.0008
[02:22:00.200] iteration:3789  t-loss:0.4244, loss-lb:0.3690, loss-ulb:0.0560, weight:0.99, lr:0.0008
[02:22:00.526] iteration:3790  t-loss:0.5253, loss-lb:0.4859, loss-ulb:0.0398, weight:0.99, lr:0.0008
[02:22:00.852] iteration:3791  t-loss:0.4829, loss-lb:0.3491, loss-ulb:0.1352, weight:0.99, lr:0.0008
[02:22:01.177] iteration:3792  t-loss:0.4197, loss-lb:0.2905, loss-ulb:0.1305, weight:0.99, lr:0.0008
[02:22:01.499] iteration:3793  t-loss:0.4814, loss-lb:0.2432, loss-ulb:0.2406, weight:0.99, lr:0.0008
[02:22:01.813] iteration:3794  t-loss:0.3961, loss-lb:0.1684, loss-ulb:0.2300, weight:0.99, lr:0.0008
[02:22:02.131] iteration:3795  t-loss:0.5818, loss-lb:0.2663, loss-ulb:0.3187, weight:0.99, lr:0.0008
[02:22:02.453] iteration:3796  t-loss:0.4935, loss-lb:0.3510, loss-ulb:0.1439, weight:0.99, lr:0.0008
[02:22:02.772] iteration:3797  t-loss:0.5124, loss-lb:0.2527, loss-ulb:0.2623, weight:0.99, lr:0.0008
[02:22:03.090] iteration:3798  t-loss:0.4045, loss-lb:0.2376, loss-ulb:0.1686, weight:0.99, lr:0.0008
[02:22:03.401] iteration:3799  t-loss:0.6487, loss-lb:0.2250, loss-ulb:0.4279, weight:0.99, lr:0.0008
[02:22:03.714] iteration:3800  t-loss:0.2653, loss-lb:0.1786, loss-ulb:0.0876, weight:0.99, lr:0.0008
[02:22:05.028] iteration:3801  t-loss:0.2347, loss-lb:0.1872, loss-ulb:0.0479, weight:0.99, lr:0.0008
[02:22:05.356] iteration:3802  t-loss:0.8263, loss-lb:0.2199, loss-ulb:0.6125, weight:0.99, lr:0.0008
[02:22:05.679] iteration:3803  t-loss:0.2288, loss-lb:0.1865, loss-ulb:0.0427, weight:0.99, lr:0.0008
[02:22:05.997] iteration:3804  t-loss:0.3829, loss-lb:0.2169, loss-ulb:0.1677, weight:0.99, lr:0.0008
[02:22:06.329] iteration:3805  t-loss:1.1774, loss-lb:0.3721, loss-ulb:0.8134, weight:0.99, lr:0.0008
[02:22:06.661] iteration:3806  t-loss:0.6022, loss-lb:0.2938, loss-ulb:0.3115, weight:0.99, lr:0.0008
[02:22:06.989] iteration:3807  t-loss:0.2577, loss-lb:0.1468, loss-ulb:0.1120, weight:0.99, lr:0.0008
[02:22:07.327] iteration:3808  t-loss:0.7242, loss-lb:0.1923, loss-ulb:0.5372, weight:0.99, lr:0.0008
[02:22:07.664] iteration:3809  t-loss:0.6079, loss-lb:0.4512, loss-ulb:0.1583, weight:0.99, lr:0.0008
[02:22:07.996] iteration:3810  t-loss:0.5147, loss-lb:0.3086, loss-ulb:0.2081, weight:0.99, lr:0.0008
[02:22:08.331] iteration:3811  t-loss:0.2561, loss-lb:0.2272, loss-ulb:0.0292, weight:0.99, lr:0.0008
[02:22:08.659] iteration:3812  t-loss:0.6229, loss-lb:0.5491, loss-ulb:0.0745, weight:0.99, lr:0.0008
[02:22:08.988] iteration:3813  t-loss:0.8463, loss-lb:0.2202, loss-ulb:0.6324, weight:0.99, lr:0.0008
[02:22:09.317] iteration:3814  t-loss:0.4036, loss-lb:0.2449, loss-ulb:0.1603, weight:0.99, lr:0.0008
[02:22:09.649] iteration:3815  t-loss:0.4104, loss-lb:0.1830, loss-ulb:0.2296, weight:0.99, lr:0.0008
[02:22:09.974] iteration:3816  t-loss:0.6040, loss-lb:0.3430, loss-ulb:0.2637, weight:0.99, lr:0.0008
[02:22:10.291] iteration:3817  t-loss:0.3513, loss-lb:0.2417, loss-ulb:0.1107, weight:0.99, lr:0.0008
[02:22:10.615] iteration:3818  t-loss:0.4235, loss-lb:0.1940, loss-ulb:0.2317, weight:0.99, lr:0.0008
[02:22:10.933] iteration:3819  t-loss:0.1942, loss-lb:0.1559, loss-ulb:0.0387, weight:0.99, lr:0.0008
[02:22:11.252] iteration:3820  t-loss:0.3831, loss-lb:0.2180, loss-ulb:0.1668, weight:0.99, lr:0.0008
[02:22:11.570] iteration:3821  t-loss:0.3439, loss-lb:0.1814, loss-ulb:0.1641, weight:0.99, lr:0.0008
[02:22:11.887] iteration:3822  t-loss:0.5527, loss-lb:0.2024, loss-ulb:0.3538, weight:0.99, lr:0.0008
[02:22:12.202] iteration:3823  t-loss:0.2274, loss-lb:0.1815, loss-ulb:0.0463, weight:0.99, lr:0.0008
[02:22:12.520] iteration:3824  t-loss:0.8698, loss-lb:0.3990, loss-ulb:0.4755, weight:0.99, lr:0.0008
[02:22:12.835] iteration:3825  t-loss:0.3218, loss-lb:0.1682, loss-ulb:0.1551, weight:0.99, lr:0.0008
[02:24:38.665] iteration 3825 : dice_score: 0.819790 best_dice: 0.829700
[02:24:38.665]  <<Test>> - Ep:152  - Dice-S/T:81.25/81.98, Best-S:82.79, Best-T:82.97
[02:24:38.665]           - AvgLoss(lb/ulb/all):0.25/0.22/0.48
[02:24:39.820] iteration:3826  t-loss:0.2306, loss-lb:0.1795, loss-ulb:0.0516, weight:0.99, lr:0.0008
[02:24:40.159] iteration:3827  t-loss:0.5461, loss-lb:0.3060, loss-ulb:0.2424, weight:0.99, lr:0.0008
[02:24:40.482] iteration:3828  t-loss:0.3005, loss-lb:0.2161, loss-ulb:0.0853, weight:0.99, lr:0.0008
[02:24:40.798] iteration:3829  t-loss:0.3796, loss-lb:0.2231, loss-ulb:0.1581, weight:0.99, lr:0.0008
[02:24:41.115] iteration:3830  t-loss:0.3958, loss-lb:0.2486, loss-ulb:0.1487, weight:0.99, lr:0.0008
[02:24:41.435] iteration:3831  t-loss:0.5963, loss-lb:0.2589, loss-ulb:0.3407, weight:0.99, lr:0.0008
[02:24:41.767] iteration:3832  t-loss:0.3232, loss-lb:0.2178, loss-ulb:0.1064, weight:0.99, lr:0.0008
[02:24:42.094] iteration:3833  t-loss:0.3183, loss-lb:0.1581, loss-ulb:0.1617, weight:0.99, lr:0.0008
[02:24:42.444] iteration:3834  t-loss:0.8692, loss-lb:0.4282, loss-ulb:0.4454, weight:0.99, lr:0.0008
[02:24:42.777] iteration:3835  t-loss:0.3166, loss-lb:0.2807, loss-ulb:0.0363, weight:0.99, lr:0.0008
[02:24:43.107] iteration:3836  t-loss:0.3569, loss-lb:0.1531, loss-ulb:0.2059, weight:0.99, lr:0.0008
[02:24:43.445] iteration:3837  t-loss:1.2171, loss-lb:0.4529, loss-ulb:0.7718, weight:0.99, lr:0.0008
[02:24:43.776] iteration:3838  t-loss:0.8286, loss-lb:0.3154, loss-ulb:0.5184, weight:0.99, lr:0.0008
[02:24:44.108] iteration:3839  t-loss:0.7745, loss-lb:0.2087, loss-ulb:0.5715, weight:0.99, lr:0.0008
[02:24:44.430] iteration:3840  t-loss:0.6052, loss-lb:0.2409, loss-ulb:0.3679, weight:0.99, lr:0.0008
[02:24:44.750] iteration:3841  t-loss:0.3869, loss-lb:0.2898, loss-ulb:0.0980, weight:0.99, lr:0.0008
[02:24:45.082] iteration:3842  t-loss:0.4992, loss-lb:0.2914, loss-ulb:0.2099, weight:0.99, lr:0.0008
[02:24:45.407] iteration:3843  t-loss:0.3953, loss-lb:0.2068, loss-ulb:0.1903, weight:0.99, lr:0.0008
[02:24:45.726] iteration:3844  t-loss:0.2321, loss-lb:0.1717, loss-ulb:0.0610, weight:0.99, lr:0.0008
[02:24:46.044] iteration:3845  t-loss:0.3608, loss-lb:0.3165, loss-ulb:0.0448, weight:0.99, lr:0.0008
[02:24:46.366] iteration:3846  t-loss:0.5204, loss-lb:0.3851, loss-ulb:0.1367, weight:0.99, lr:0.0008
[02:24:46.684] iteration:3847  t-loss:0.9165, loss-lb:0.4756, loss-ulb:0.4454, weight:0.99, lr:0.0008
[02:24:47.000] iteration:3848  t-loss:0.5743, loss-lb:0.1496, loss-ulb:0.4289, weight:0.99, lr:0.0008
[02:24:47.324] iteration:3849  t-loss:0.3985, loss-lb:0.3346, loss-ulb:0.0646, weight:0.99, lr:0.0008
[02:24:47.640] iteration:3850  t-loss:0.4153, loss-lb:0.1991, loss-ulb:0.2183, weight:0.99, lr:0.0008
[02:24:49.020] iteration:3851  t-loss:0.7213, loss-lb:0.3538, loss-ulb:0.3713, weight:0.99, lr:0.0008
[02:24:49.369] iteration:3852  t-loss:0.1749, loss-lb:0.1393, loss-ulb:0.0360, weight:0.99, lr:0.0008
[02:24:49.697] iteration:3853  t-loss:0.6303, loss-lb:0.3034, loss-ulb:0.3302, weight:0.99, lr:0.0008
[02:24:50.011] iteration:3854  t-loss:0.3505, loss-lb:0.2864, loss-ulb:0.0648, weight:0.99, lr:0.0008
[02:24:50.324] iteration:3855  t-loss:0.2393, loss-lb:0.1833, loss-ulb:0.0565, weight:0.99, lr:0.0008
[02:24:50.657] iteration:3856  t-loss:0.7035, loss-lb:0.4738, loss-ulb:0.2320, weight:0.99, lr:0.0008
[02:24:50.984] iteration:3857  t-loss:0.3052, loss-lb:0.1920, loss-ulb:0.1143, weight:0.99, lr:0.0008
[02:24:51.346] iteration:3858  t-loss:0.6147, loss-lb:0.2643, loss-ulb:0.3539, weight:0.99, lr:0.0008
[02:24:51.680] iteration:3859  t-loss:0.4921, loss-lb:0.2284, loss-ulb:0.2663, weight:0.99, lr:0.0008
[02:24:52.016] iteration:3860  t-loss:0.3797, loss-lb:0.3230, loss-ulb:0.0572, weight:0.99, lr:0.0008
[02:24:52.372] iteration:3861  t-loss:0.7552, loss-lb:0.5642, loss-ulb:0.1929, weight:0.99, lr:0.0008
[02:24:52.699] iteration:3862  t-loss:0.3560, loss-lb:0.2712, loss-ulb:0.0856, weight:0.99, lr:0.0008
[02:24:53.026] iteration:3863  t-loss:0.2981, loss-lb:0.2169, loss-ulb:0.0820, weight:0.99, lr:0.0008
[02:24:53.362] iteration:3864  t-loss:0.4125, loss-lb:0.2559, loss-ulb:0.1582, weight:0.99, lr:0.0008
[02:24:53.695] iteration:3865  t-loss:0.9643, loss-lb:0.2822, loss-ulb:0.6889, weight:0.99, lr:0.0008
[02:24:54.018] iteration:3866  t-loss:0.2738, loss-lb:0.1505, loss-ulb:0.1245, weight:0.99, lr:0.0008
[02:24:54.351] iteration:3867  t-loss:0.5372, loss-lb:0.3103, loss-ulb:0.2292, weight:0.99, lr:0.0008
[02:24:54.677] iteration:3868  t-loss:0.7632, loss-lb:0.4500, loss-ulb:0.3164, weight:0.99, lr:0.0008
[02:24:55.000] iteration:3869  t-loss:0.4843, loss-lb:0.4517, loss-ulb:0.0329, weight:0.99, lr:0.0008
[02:24:55.323] iteration:3870  t-loss:0.5464, loss-lb:0.3526, loss-ulb:0.1957, weight:0.99, lr:0.0008
[02:24:55.645] iteration:3871  t-loss:0.4621, loss-lb:0.3434, loss-ulb:0.1198, weight:0.99, lr:0.0008
[02:24:55.962] iteration:3872  t-loss:0.3790, loss-lb:0.3051, loss-ulb:0.0747, weight:0.99, lr:0.0008
[02:24:56.281] iteration:3873  t-loss:0.2464, loss-lb:0.1717, loss-ulb:0.0755, weight:0.99, lr:0.0008
[02:24:56.594] iteration:3874  t-loss:0.3872, loss-lb:0.3030, loss-ulb:0.0850, weight:0.99, lr:0.0008
[02:24:56.910] iteration:3875  t-loss:0.3446, loss-lb:0.2739, loss-ulb:0.0714, weight:0.99, lr:0.0008
[02:24:58.064] iteration:3876  t-loss:0.4191, loss-lb:0.2870, loss-ulb:0.1335, weight:0.99, lr:0.0008
[02:24:58.403] iteration:3877  t-loss:0.5621, loss-lb:0.2242, loss-ulb:0.3412, weight:0.99, lr:0.0008
[02:24:58.736] iteration:3878  t-loss:0.5388, loss-lb:0.4818, loss-ulb:0.0576, weight:0.99, lr:0.0008
[02:24:59.062] iteration:3879  t-loss:0.5619, loss-lb:0.3525, loss-ulb:0.2114, weight:0.99, lr:0.0008
[02:24:59.398] iteration:3880  t-loss:0.4345, loss-lb:0.3507, loss-ulb:0.0846, weight:0.99, lr:0.0008
[02:24:59.735] iteration:3881  t-loss:0.4062, loss-lb:0.2737, loss-ulb:0.1338, weight:0.99, lr:0.0008
[02:25:00.078] iteration:3882  t-loss:0.6831, loss-lb:0.3504, loss-ulb:0.3360, weight:0.99, lr:0.0008
[02:25:00.425] iteration:3883  t-loss:0.8113, loss-lb:0.1936, loss-ulb:0.6239, weight:0.99, lr:0.0008
[02:25:00.773] iteration:3884  t-loss:0.7057, loss-lb:0.2697, loss-ulb:0.4404, weight:0.99, lr:0.0008
[02:25:01.123] iteration:3885  t-loss:0.5020, loss-lb:0.3684, loss-ulb:0.1349, weight:0.99, lr:0.0008
[02:25:01.462] iteration:3886  t-loss:0.6492, loss-lb:0.5546, loss-ulb:0.0956, weight:0.99, lr:0.0008
[02:25:01.797] iteration:3887  t-loss:0.9372, loss-lb:0.6172, loss-ulb:0.3232, weight:0.99, lr:0.0008
[02:25:02.125] iteration:3888  t-loss:0.4645, loss-lb:0.2457, loss-ulb:0.2209, weight:0.99, lr:0.0008
[02:25:02.449] iteration:3889  t-loss:0.3832, loss-lb:0.1735, loss-ulb:0.2117, weight:0.99, lr:0.0008
[02:25:02.772] iteration:3890  t-loss:0.2731, loss-lb:0.2311, loss-ulb:0.0425, weight:0.99, lr:0.0008
[02:25:03.096] iteration:3891  t-loss:0.3798, loss-lb:0.2478, loss-ulb:0.1333, weight:0.99, lr:0.0008
[02:25:03.416] iteration:3892  t-loss:0.4558, loss-lb:0.3769, loss-ulb:0.0797, weight:0.99, lr:0.0008
[02:25:03.736] iteration:3893  t-loss:0.6838, loss-lb:0.3126, loss-ulb:0.3749, weight:0.99, lr:0.0008
[02:25:04.060] iteration:3894  t-loss:0.4024, loss-lb:0.3669, loss-ulb:0.0358, weight:0.99, lr:0.0008
[02:25:04.380] iteration:3895  t-loss:0.6807, loss-lb:0.6166, loss-ulb:0.0647, weight:0.99, lr:0.0008
[02:25:04.698] iteration:3896  t-loss:0.2394, loss-lb:0.2030, loss-ulb:0.0368, weight:0.99, lr:0.0008
[02:25:05.020] iteration:3897  t-loss:0.3140, loss-lb:0.2132, loss-ulb:0.1017, weight:0.99, lr:0.0008
[02:25:05.339] iteration:3898  t-loss:0.3687, loss-lb:0.2119, loss-ulb:0.1584, weight:0.99, lr:0.0008
[02:25:05.659] iteration:3899  t-loss:0.3788, loss-lb:0.3130, loss-ulb:0.0665, weight:0.99, lr:0.0008
[02:25:05.975] iteration:3900  t-loss:0.2543, loss-lb:0.1679, loss-ulb:0.0872, weight:0.99, lr:0.0008
[02:25:07.327] iteration:3901  t-loss:0.5713, loss-lb:0.4108, loss-ulb:0.1481, weight:1.08, lr:0.0008
[02:25:07.673] iteration:3902  t-loss:0.4249, loss-lb:0.2506, loss-ulb:0.1608, weight:1.08, lr:0.0008
[02:25:08.002] iteration:3903  t-loss:0.4745, loss-lb:0.3664, loss-ulb:0.0997, weight:1.08, lr:0.0008
[02:25:08.332] iteration:3904  t-loss:0.2355, loss-lb:0.1548, loss-ulb:0.0745, weight:1.08, lr:0.0008
[02:25:08.659] iteration:3905  t-loss:0.2333, loss-lb:0.1809, loss-ulb:0.0484, weight:1.08, lr:0.0008
[02:25:08.980] iteration:3906  t-loss:0.8765, loss-lb:0.4283, loss-ulb:0.4136, weight:1.08, lr:0.0008
[02:25:09.302] iteration:3907  t-loss:0.2613, loss-lb:0.2234, loss-ulb:0.0349, weight:1.08, lr:0.0008
[02:25:09.628] iteration:3908  t-loss:0.5869, loss-lb:0.3404, loss-ulb:0.2275, weight:1.08, lr:0.0008
[02:25:09.955] iteration:3909  t-loss:0.4414, loss-lb:0.2529, loss-ulb:0.1739, weight:1.08, lr:0.0008
[02:25:10.282] iteration:3910  t-loss:0.9390, loss-lb:0.4501, loss-ulb:0.4510, weight:1.08, lr:0.0008
[02:25:10.605] iteration:3911  t-loss:0.6010, loss-lb:0.5482, loss-ulb:0.0487, weight:1.08, lr:0.0008
[02:25:10.934] iteration:3912  t-loss:0.7878, loss-lb:0.6473, loss-ulb:0.1296, weight:1.08, lr:0.0008
[02:25:11.258] iteration:3913  t-loss:0.3608, loss-lb:0.3297, loss-ulb:0.0287, weight:1.08, lr:0.0008
[02:25:11.573] iteration:3914  t-loss:0.2702, loss-lb:0.1741, loss-ulb:0.0886, weight:1.08, lr:0.0008
[02:25:11.893] iteration:3915  t-loss:0.3579, loss-lb:0.3019, loss-ulb:0.0516, weight:1.08, lr:0.0008
[02:25:12.219] iteration:3916  t-loss:0.4033, loss-lb:0.3191, loss-ulb:0.0777, weight:1.08, lr:0.0008
[02:25:12.538] iteration:3917  t-loss:0.2559, loss-lb:0.1982, loss-ulb:0.0532, weight:1.08, lr:0.0008
[02:25:12.859] iteration:3918  t-loss:0.5011, loss-lb:0.3050, loss-ulb:0.1809, weight:1.08, lr:0.0008
[02:25:13.182] iteration:3919  t-loss:0.7402, loss-lb:0.6965, loss-ulb:0.0403, weight:1.08, lr:0.0008
[02:25:13.499] iteration:3920  t-loss:0.8146, loss-lb:0.3162, loss-ulb:0.4598, weight:1.08, lr:0.0008
[02:25:13.815] iteration:3921  t-loss:0.2986, loss-lb:0.1797, loss-ulb:0.1097, weight:1.08, lr:0.0008
[02:25:14.137] iteration:3922  t-loss:0.5687, loss-lb:0.3560, loss-ulb:0.1962, weight:1.08, lr:0.0008
[02:25:14.451] iteration:3923  t-loss:0.2872, loss-lb:0.2465, loss-ulb:0.0375, weight:1.08, lr:0.0008
[02:25:14.766] iteration:3924  t-loss:0.4226, loss-lb:0.1932, loss-ulb:0.2116, weight:1.08, lr:0.0008
[02:25:15.086] iteration:3925  t-loss:0.3895, loss-lb:0.2156, loss-ulb:0.1604, weight:1.08, lr:0.0008
[02:27:28.424] iteration 3925 : dice_score: 0.826727 best_dice: 0.829700
[02:27:28.425]  <<Test>> - Ep:156  - Dice-S/T:79.43/82.67, Best-S:82.79, Best-T:82.97
[02:27:28.425]           - AvgLoss(lb/ulb/all):0.32/0.16/0.51
[02:27:29.665] iteration:3926  t-loss:0.2600, loss-lb:0.1822, loss-ulb:0.0718, weight:1.08, lr:0.0008
[02:27:29.998] iteration:3927  t-loss:0.4357, loss-lb:0.2102, loss-ulb:0.2080, weight:1.08, lr:0.0008
[02:27:30.324] iteration:3928  t-loss:0.4977, loss-lb:0.2319, loss-ulb:0.2453, weight:1.08, lr:0.0008
[02:27:30.644] iteration:3929  t-loss:0.3317, loss-lb:0.3090, loss-ulb:0.0210, weight:1.08, lr:0.0008
[02:27:30.968] iteration:3930  t-loss:0.3090, loss-lb:0.2839, loss-ulb:0.0232, weight:1.08, lr:0.0008
[02:27:31.290] iteration:3931  t-loss:0.2774, loss-lb:0.1935, loss-ulb:0.0774, weight:1.08, lr:0.0008
[02:27:31.613] iteration:3932  t-loss:0.7778, loss-lb:0.2290, loss-ulb:0.5063, weight:1.08, lr:0.0008
[02:27:31.936] iteration:3933  t-loss:0.2762, loss-lb:0.1865, loss-ulb:0.0827, weight:1.08, lr:0.0008
[02:27:32.265] iteration:3934  t-loss:0.6492, loss-lb:0.2546, loss-ulb:0.3640, weight:1.08, lr:0.0008
[02:27:32.586] iteration:3935  t-loss:0.6895, loss-lb:0.2131, loss-ulb:0.4395, weight:1.08, lr:0.0008
[02:27:32.902] iteration:3936  t-loss:0.4244, loss-lb:0.1922, loss-ulb:0.2143, weight:1.08, lr:0.0008
[02:27:33.229] iteration:3937  t-loss:0.3834, loss-lb:0.1988, loss-ulb:0.1703, weight:1.08, lr:0.0008
[02:27:33.552] iteration:3938  t-loss:0.3891, loss-lb:0.3186, loss-ulb:0.0650, weight:1.08, lr:0.0008
[02:27:33.867] iteration:3939  t-loss:0.2299, loss-lb:0.1682, loss-ulb:0.0569, weight:1.08, lr:0.0008
[02:27:34.195] iteration:3940  t-loss:0.3115, loss-lb:0.1566, loss-ulb:0.1429, weight:1.08, lr:0.0008
[02:27:34.520] iteration:3941  t-loss:0.5110, loss-lb:0.3895, loss-ulb:0.1122, weight:1.08, lr:0.0008
[02:27:34.840] iteration:3942  t-loss:0.2878, loss-lb:0.2302, loss-ulb:0.0531, weight:1.08, lr:0.0008
[02:27:35.161] iteration:3943  t-loss:0.3011, loss-lb:0.1846, loss-ulb:0.1075, weight:1.08, lr:0.0008
[02:27:35.475] iteration:3944  t-loss:0.5606, loss-lb:0.2888, loss-ulb:0.2508, weight:1.08, lr:0.0008
[02:27:35.782] iteration:3945  t-loss:0.5080, loss-lb:0.1843, loss-ulb:0.2986, weight:1.08, lr:0.0008
[02:27:36.101] iteration:3946  t-loss:0.6146, loss-lb:0.3621, loss-ulb:0.2329, weight:1.08, lr:0.0008
[02:27:36.420] iteration:3947  t-loss:0.6170, loss-lb:0.3190, loss-ulb:0.2749, weight:1.08, lr:0.0008
[02:27:36.736] iteration:3948  t-loss:0.3818, loss-lb:0.3525, loss-ulb:0.0271, weight:1.08, lr:0.0008
[02:27:37.051] iteration:3949  t-loss:0.4538, loss-lb:0.1651, loss-ulb:0.2663, weight:1.08, lr:0.0008
[02:27:37.371] iteration:3950  t-loss:0.3675, loss-lb:0.2864, loss-ulb:0.0748, weight:1.08, lr:0.0008
[02:27:38.852] iteration:3951  t-loss:0.2886, loss-lb:0.1812, loss-ulb:0.0991, weight:1.08, lr:0.0008
[02:27:39.186] iteration:3952  t-loss:0.2016, loss-lb:0.1605, loss-ulb:0.0379, weight:1.08, lr:0.0008
[02:27:39.503] iteration:3953  t-loss:0.8803, loss-lb:0.1900, loss-ulb:0.6369, weight:1.08, lr:0.0008
[02:27:39.826] iteration:3954  t-loss:0.4302, loss-lb:0.1750, loss-ulb:0.2354, weight:1.08, lr:0.0008
[02:27:40.162] iteration:3955  t-loss:0.2381, loss-lb:0.2047, loss-ulb:0.0308, weight:1.08, lr:0.0008
[02:27:40.490] iteration:3956  t-loss:0.2394, loss-lb:0.2107, loss-ulb:0.0266, weight:1.08, lr:0.0008
[02:27:40.818] iteration:3957  t-loss:0.5510, loss-lb:0.2347, loss-ulb:0.2918, weight:1.08, lr:0.0008
[02:27:41.166] iteration:3958  t-loss:0.6124, loss-lb:0.3780, loss-ulb:0.2162, weight:1.08, lr:0.0008
[02:27:41.490] iteration:3959  t-loss:0.2174, loss-lb:0.1520, loss-ulb:0.0604, weight:1.08, lr:0.0008
[02:27:41.808] iteration:3960  t-loss:0.2720, loss-lb:0.1629, loss-ulb:0.1007, weight:1.08, lr:0.0008
[02:27:42.142] iteration:3961  t-loss:0.6111, loss-lb:0.2468, loss-ulb:0.3361, weight:1.08, lr:0.0008
[02:27:42.464] iteration:3962  t-loss:0.4945, loss-lb:0.3573, loss-ulb:0.1266, weight:1.08, lr:0.0008
[02:27:42.788] iteration:3963  t-loss:0.8851, loss-lb:0.1613, loss-ulb:0.6678, weight:1.08, lr:0.0008
[02:27:43.115] iteration:3964  t-loss:0.5261, loss-lb:0.2372, loss-ulb:0.2665, weight:1.08, lr:0.0008
[02:27:43.449] iteration:3965  t-loss:0.4445, loss-lb:0.2736, loss-ulb:0.1576, weight:1.08, lr:0.0008
[02:27:43.775] iteration:3966  t-loss:0.8667, loss-lb:0.2478, loss-ulb:0.5710, weight:1.08, lr:0.0008
[02:27:44.098] iteration:3967  t-loss:0.3741, loss-lb:0.2499, loss-ulb:0.1146, weight:1.08, lr:0.0008
[02:27:44.423] iteration:3968  t-loss:0.7034, loss-lb:0.2893, loss-ulb:0.3821, weight:1.08, lr:0.0008
[02:27:44.736] iteration:3969  t-loss:0.8798, loss-lb:0.1547, loss-ulb:0.6689, weight:1.08, lr:0.0008
[02:27:45.053] iteration:3970  t-loss:0.7926, loss-lb:0.5642, loss-ulb:0.2106, weight:1.08, lr:0.0008
[02:27:45.367] iteration:3971  t-loss:0.3358, loss-lb:0.2118, loss-ulb:0.1144, weight:1.08, lr:0.0008
[02:27:45.681] iteration:3972  t-loss:0.3219, loss-lb:0.1684, loss-ulb:0.1417, weight:1.08, lr:0.0008
[02:27:45.997] iteration:3973  t-loss:0.5161, loss-lb:0.2871, loss-ulb:0.2112, weight:1.08, lr:0.0008
[02:27:46.313] iteration:3974  t-loss:0.4060, loss-lb:0.2139, loss-ulb:0.1772, weight:1.08, lr:0.0008
[02:27:46.628] iteration:3975  t-loss:0.3326, loss-lb:0.1470, loss-ulb:0.1712, weight:1.08, lr:0.0008
[02:27:47.794] iteration:3976  t-loss:0.3432, loss-lb:0.2562, loss-ulb:0.0803, weight:1.08, lr:0.0008
[02:27:48.127] iteration:3977  t-loss:0.3096, loss-lb:0.2269, loss-ulb:0.0763, weight:1.08, lr:0.0008
[02:27:48.447] iteration:3978  t-loss:0.1922, loss-lb:0.1535, loss-ulb:0.0358, weight:1.08, lr:0.0008
[02:27:48.776] iteration:3979  t-loss:0.7225, loss-lb:0.3753, loss-ulb:0.3204, weight:1.08, lr:0.0008
[02:27:49.101] iteration:3980  t-loss:0.3001, loss-lb:0.2520, loss-ulb:0.0443, weight:1.08, lr:0.0008
[02:27:49.433] iteration:3981  t-loss:0.3644, loss-lb:0.3123, loss-ulb:0.0481, weight:1.08, lr:0.0008
[02:27:49.760] iteration:3982  t-loss:0.3536, loss-lb:0.1813, loss-ulb:0.1589, weight:1.08, lr:0.0008
[02:27:50.079] iteration:3983  t-loss:0.2334, loss-lb:0.1690, loss-ulb:0.0594, weight:1.08, lr:0.0008
[02:27:50.397] iteration:3984  t-loss:0.2659, loss-lb:0.1567, loss-ulb:0.1007, weight:1.08, lr:0.0008
[02:27:50.722] iteration:3985  t-loss:0.8551, loss-lb:0.2486, loss-ulb:0.5596, weight:1.08, lr:0.0008
[02:27:51.056] iteration:3986  t-loss:0.7896, loss-lb:0.3922, loss-ulb:0.3667, weight:1.08, lr:0.0008
[02:27:51.391] iteration:3987  t-loss:0.2952, loss-lb:0.2404, loss-ulb:0.0506, weight:1.08, lr:0.0008
[02:27:51.728] iteration:3988  t-loss:0.9450, loss-lb:0.4948, loss-ulb:0.4153, weight:1.08, lr:0.0008
[02:27:52.060] iteration:3989  t-loss:0.3007, loss-lb:0.1773, loss-ulb:0.1139, weight:1.08, lr:0.0008
[02:27:52.412] iteration:3990  t-loss:0.2369, loss-lb:0.1604, loss-ulb:0.0706, weight:1.08, lr:0.0008
[02:27:52.745] iteration:3991  t-loss:0.4954, loss-lb:0.2378, loss-ulb:0.2377, weight:1.08, lr:0.0008
[02:27:53.078] iteration:3992  t-loss:0.5367, loss-lb:0.3474, loss-ulb:0.1746, weight:1.08, lr:0.0008
[02:27:53.400] iteration:3993  t-loss:0.2210, loss-lb:0.1850, loss-ulb:0.0332, weight:1.08, lr:0.0008
[02:27:53.723] iteration:3994  t-loss:0.3201, loss-lb:0.2348, loss-ulb:0.0787, weight:1.08, lr:0.0008
[02:27:54.052] iteration:3995  t-loss:1.0297, loss-lb:0.3277, loss-ulb:0.6476, weight:1.08, lr:0.0008
[02:27:54.368] iteration:3996  t-loss:0.2889, loss-lb:0.2233, loss-ulb:0.0605, weight:1.08, lr:0.0008
[02:27:54.698] iteration:3997  t-loss:0.5213, loss-lb:0.2754, loss-ulb:0.2269, weight:1.08, lr:0.0008
[02:27:55.016] iteration:3998  t-loss:0.6275, loss-lb:0.2684, loss-ulb:0.3312, weight:1.08, lr:0.0008
[02:27:55.333] iteration:3999  t-loss:0.3589, loss-lb:0.1896, loss-ulb:0.1562, weight:1.08, lr:0.0008
[02:27:55.645] iteration:4000  t-loss:0.2387, loss-lb:0.1624, loss-ulb:0.0704, weight:1.08, lr:0.0008
[02:27:56.899] iteration:4001  t-loss:1.0064, loss-lb:0.6365, loss-ulb:0.3412, weight:1.08, lr:0.0008
[02:27:57.236] iteration:4002  t-loss:0.4343, loss-lb:0.1874, loss-ulb:0.2278, weight:1.08, lr:0.0008
[02:27:57.558] iteration:4003  t-loss:0.4945, loss-lb:0.3725, loss-ulb:0.1125, weight:1.08, lr:0.0008
[02:27:57.874] iteration:4004  t-loss:0.5754, loss-lb:0.2021, loss-ulb:0.3444, weight:1.08, lr:0.0008
[02:27:58.195] iteration:4005  t-loss:0.2645, loss-lb:0.2042, loss-ulb:0.0557, weight:1.08, lr:0.0008
[02:27:58.513] iteration:4006  t-loss:0.5620, loss-lb:0.3637, loss-ulb:0.1830, weight:1.08, lr:0.0008
[02:27:58.826] iteration:4007  t-loss:0.7285, loss-lb:0.1955, loss-ulb:0.4917, weight:1.08, lr:0.0008
[02:27:59.141] iteration:4008  t-loss:0.3163, loss-lb:0.2071, loss-ulb:0.1008, weight:1.08, lr:0.0008
[02:27:59.458] iteration:4009  t-loss:0.3258, loss-lb:0.2610, loss-ulb:0.0597, weight:1.08, lr:0.0008
[02:27:59.774] iteration:4010  t-loss:0.6936, loss-lb:0.4062, loss-ulb:0.2651, weight:1.08, lr:0.0008
[02:28:00.092] iteration:4011  t-loss:0.6513, loss-lb:0.2990, loss-ulb:0.3249, weight:1.08, lr:0.0008
[02:28:00.412] iteration:4012  t-loss:0.2873, loss-lb:0.2273, loss-ulb:0.0554, weight:1.08, lr:0.0008
[02:28:00.736] iteration:4013  t-loss:0.5700, loss-lb:0.4705, loss-ulb:0.0917, weight:1.08, lr:0.0008
[02:28:01.085] iteration:4014  t-loss:0.7752, loss-lb:0.2346, loss-ulb:0.4987, weight:1.08, lr:0.0008
[02:28:01.421] iteration:4015  t-loss:0.6118, loss-lb:0.2636, loss-ulb:0.3211, weight:1.08, lr:0.0008
[02:28:01.759] iteration:4016  t-loss:0.4613, loss-lb:0.2852, loss-ulb:0.1625, weight:1.08, lr:0.0008
[02:28:02.096] iteration:4017  t-loss:0.8436, loss-lb:0.3535, loss-ulb:0.4521, weight:1.08, lr:0.0008
[02:28:02.424] iteration:4018  t-loss:0.4095, loss-lb:0.2484, loss-ulb:0.1486, weight:1.08, lr:0.0008
[02:28:02.749] iteration:4019  t-loss:0.5241, loss-lb:0.3185, loss-ulb:0.1896, weight:1.08, lr:0.0008
[02:28:03.063] iteration:4020  t-loss:0.2196, loss-lb:0.1787, loss-ulb:0.0377, weight:1.08, lr:0.0008
[02:28:03.381] iteration:4021  t-loss:0.6848, loss-lb:0.1750, loss-ulb:0.4703, weight:1.08, lr:0.0008
[02:28:03.699] iteration:4022  t-loss:0.6320, loss-lb:0.2058, loss-ulb:0.3932, weight:1.08, lr:0.0008
[02:28:04.015] iteration:4023  t-loss:0.3772, loss-lb:0.2924, loss-ulb:0.0783, weight:1.08, lr:0.0008
[02:28:04.329] iteration:4024  t-loss:1.4237, loss-lb:0.2957, loss-ulb:1.0406, weight:1.08, lr:0.0008
[02:28:04.648] iteration:4025  t-loss:0.7547, loss-lb:0.5382, loss-ulb:0.1997, weight:1.08, lr:0.0008
[02:30:17.586] iteration 4025 : dice_score: 0.828464 best_dice: 0.829700
[02:30:17.586]  <<Test>> - Ep:160  - Dice-S/T:81.63/82.85, Best-S:82.79, Best-T:82.97
[02:30:17.586]           - AvgLoss(lb/ulb/all):0.30/0.28/0.59
[02:30:18.872] iteration:4026  t-loss:0.4028, loss-lb:0.2416, loss-ulb:0.1488, weight:1.08, lr:0.0008
[02:30:19.196] iteration:4027  t-loss:0.5606, loss-lb:0.2963, loss-ulb:0.2439, weight:1.08, lr:0.0008
[02:30:19.518] iteration:4028  t-loss:0.5956, loss-lb:0.2769, loss-ulb:0.2941, weight:1.08, lr:0.0008
[02:30:19.847] iteration:4029  t-loss:0.3665, loss-lb:0.2171, loss-ulb:0.1379, weight:1.08, lr:0.0008
[02:30:20.176] iteration:4030  t-loss:0.4609, loss-lb:0.2131, loss-ulb:0.2286, weight:1.08, lr:0.0008
[02:30:20.497] iteration:4031  t-loss:0.3501, loss-lb:0.1810, loss-ulb:0.1560, weight:1.08, lr:0.0008
[02:30:20.827] iteration:4032  t-loss:1.1989, loss-lb:0.4052, loss-ulb:0.7322, weight:1.08, lr:0.0008
[02:30:21.153] iteration:4033  t-loss:0.5321, loss-lb:0.2718, loss-ulb:0.2402, weight:1.08, lr:0.0008
[02:30:21.477] iteration:4034  t-loss:0.3575, loss-lb:0.1979, loss-ulb:0.1472, weight:1.08, lr:0.0008
[02:30:21.798] iteration:4035  t-loss:0.3826, loss-lb:0.2512, loss-ulb:0.1212, weight:1.08, lr:0.0008
[02:30:22.114] iteration:4036  t-loss:0.5188, loss-lb:0.2320, loss-ulb:0.2646, weight:1.08, lr:0.0008
[02:30:22.444] iteration:4037  t-loss:0.4718, loss-lb:0.3642, loss-ulb:0.0993, weight:1.08, lr:0.0008
[02:30:22.786] iteration:4038  t-loss:0.8569, loss-lb:0.3359, loss-ulb:0.4807, weight:1.08, lr:0.0008
[02:30:23.116] iteration:4039  t-loss:0.5256, loss-lb:0.3144, loss-ulb:0.1949, weight:1.08, lr:0.0008
[02:30:23.457] iteration:4040  t-loss:0.4538, loss-lb:0.2587, loss-ulb:0.1801, weight:1.08, lr:0.0008
[02:30:23.783] iteration:4041  t-loss:0.4208, loss-lb:0.2560, loss-ulb:0.1520, weight:1.08, lr:0.0008
[02:30:24.115] iteration:4042  t-loss:0.5885, loss-lb:0.3363, loss-ulb:0.2327, weight:1.08, lr:0.0008
[02:30:24.434] iteration:4043  t-loss:0.6177, loss-lb:0.1690, loss-ulb:0.4139, weight:1.08, lr:0.0008
[02:30:24.758] iteration:4044  t-loss:0.2981, loss-lb:0.1879, loss-ulb:0.1017, weight:1.08, lr:0.0008
[02:30:25.072] iteration:4045  t-loss:0.2916, loss-lb:0.2301, loss-ulb:0.0568, weight:1.08, lr:0.0008
[02:30:25.387] iteration:4046  t-loss:0.2569, loss-lb:0.2083, loss-ulb:0.0448, weight:1.08, lr:0.0008
[02:30:25.712] iteration:4047  t-loss:1.0597, loss-lb:0.2655, loss-ulb:0.7327, weight:1.08, lr:0.0008
[02:30:26.032] iteration:4048  t-loss:0.3723, loss-lb:0.3188, loss-ulb:0.0493, weight:1.08, lr:0.0008
[02:30:26.347] iteration:4049  t-loss:0.2120, loss-lb:0.1611, loss-ulb:0.0469, weight:1.08, lr:0.0008
[02:30:26.665] iteration:4050  t-loss:0.5213, loss-lb:0.3642, loss-ulb:0.1449, weight:1.08, lr:0.0008
[02:30:28.112] iteration:4051  t-loss:0.5942, loss-lb:0.2891, loss-ulb:0.2587, weight:1.18, lr:0.0008
[02:30:28.472] iteration:4052  t-loss:0.5860, loss-lb:0.2054, loss-ulb:0.3227, weight:1.18, lr:0.0008
[02:30:28.810] iteration:4053  t-loss:0.4052, loss-lb:0.2858, loss-ulb:0.1012, weight:1.18, lr:0.0008
[02:30:29.142] iteration:4054  t-loss:0.3449, loss-lb:0.2000, loss-ulb:0.1229, weight:1.18, lr:0.0008
[02:30:29.463] iteration:4055  t-loss:0.6941, loss-lb:0.3427, loss-ulb:0.2979, weight:1.18, lr:0.0008
[02:30:29.799] iteration:4056  t-loss:0.5372, loss-lb:0.4051, loss-ulb:0.1120, weight:1.18, lr:0.0008
[02:30:30.133] iteration:4057  t-loss:0.3121, loss-lb:0.2765, loss-ulb:0.0302, weight:1.18, lr:0.0008
[02:30:30.457] iteration:4058  t-loss:0.4854, loss-lb:0.1886, loss-ulb:0.2516, weight:1.18, lr:0.0008
[02:30:30.783] iteration:4059  t-loss:1.1484, loss-lb:0.2590, loss-ulb:0.7541, weight:1.18, lr:0.0008
[02:30:31.116] iteration:4060  t-loss:0.2840, loss-lb:0.1972, loss-ulb:0.0735, weight:1.18, lr:0.0008
[02:30:31.441] iteration:4061  t-loss:0.4791, loss-lb:0.2272, loss-ulb:0.2136, weight:1.18, lr:0.0008
[02:30:31.760] iteration:4062  t-loss:0.5895, loss-lb:0.3416, loss-ulb:0.2102, weight:1.18, lr:0.0008
[02:30:32.082] iteration:4063  t-loss:0.3966, loss-lb:0.2624, loss-ulb:0.1138, weight:1.18, lr:0.0008
[02:30:32.412] iteration:4064  t-loss:0.5658, loss-lb:0.3042, loss-ulb:0.2218, weight:1.18, lr:0.0008
[02:30:32.739] iteration:4065  t-loss:1.1784, loss-lb:0.2522, loss-ulb:0.7853, weight:1.18, lr:0.0008
[02:30:33.067] iteration:4066  t-loss:0.3714, loss-lb:0.1945, loss-ulb:0.1500, weight:1.18, lr:0.0008
[02:30:33.389] iteration:4067  t-loss:0.7469, loss-lb:0.2166, loss-ulb:0.4496, weight:1.18, lr:0.0008
[02:30:33.710] iteration:4068  t-loss:0.4337, loss-lb:0.1597, loss-ulb:0.2323, weight:1.18, lr:0.0008
[02:30:34.030] iteration:4069  t-loss:0.5158, loss-lb:0.3008, loss-ulb:0.1823, weight:1.18, lr:0.0008
[02:30:34.350] iteration:4070  t-loss:1.2303, loss-lb:0.6665, loss-ulb:0.4781, weight:1.18, lr:0.0008
[02:30:34.663] iteration:4071  t-loss:1.3270, loss-lb:0.5420, loss-ulb:0.6656, weight:1.18, lr:0.0008
[02:30:34.976] iteration:4072  t-loss:1.0029, loss-lb:0.3123, loss-ulb:0.5855, weight:1.18, lr:0.0008
[02:30:35.291] iteration:4073  t-loss:1.2431, loss-lb:0.3379, loss-ulb:0.7675, weight:1.18, lr:0.0008
[02:30:35.609] iteration:4074  t-loss:0.3075, loss-lb:0.1914, loss-ulb:0.0984, weight:1.18, lr:0.0008
[02:30:35.927] iteration:4075  t-loss:0.3411, loss-lb:0.2307, loss-ulb:0.0935, weight:1.18, lr:0.0008
[02:30:37.459] iteration:4076  t-loss:0.6658, loss-lb:0.4555, loss-ulb:0.1783, weight:1.18, lr:0.0008
[02:30:37.810] iteration:4077  t-loss:0.4286, loss-lb:0.3084, loss-ulb:0.1019, weight:1.18, lr:0.0008
[02:30:38.153] iteration:4078  t-loss:0.8799, loss-lb:0.4218, loss-ulb:0.3884, weight:1.18, lr:0.0008
[02:30:38.498] iteration:4079  t-loss:0.3651, loss-lb:0.2898, loss-ulb:0.0639, weight:1.18, lr:0.0008
[02:30:38.829] iteration:4080  t-loss:0.3254, loss-lb:0.2397, loss-ulb:0.0726, weight:1.18, lr:0.0008
[02:30:39.155] iteration:4081  t-loss:0.5452, loss-lb:0.2244, loss-ulb:0.2720, weight:1.18, lr:0.0008
[02:30:39.477] iteration:4082  t-loss:0.4277, loss-lb:0.2390, loss-ulb:0.1600, weight:1.18, lr:0.0008
[02:30:39.805] iteration:4083  t-loss:0.7604, loss-lb:0.5412, loss-ulb:0.1859, weight:1.18, lr:0.0008
[02:30:40.126] iteration:4084  t-loss:0.8593, loss-lb:0.1952, loss-ulb:0.5631, weight:1.18, lr:0.0008
[02:30:40.447] iteration:4085  t-loss:0.2309, loss-lb:0.1735, loss-ulb:0.0487, weight:1.18, lr:0.0008
[02:30:40.772] iteration:4086  t-loss:0.6758, loss-lb:0.3633, loss-ulb:0.2649, weight:1.18, lr:0.0008
[02:30:41.100] iteration:4087  t-loss:1.0329, loss-lb:0.8633, loss-ulb:0.1438, weight:1.18, lr:0.0008
[02:30:41.431] iteration:4088  t-loss:0.3927, loss-lb:0.2823, loss-ulb:0.0936, weight:1.18, lr:0.0008
[02:30:41.759] iteration:4089  t-loss:0.6144, loss-lb:0.2570, loss-ulb:0.3030, weight:1.18, lr:0.0008
[02:30:42.084] iteration:4090  t-loss:0.3898, loss-lb:0.1758, loss-ulb:0.1815, weight:1.18, lr:0.0008
[02:30:42.406] iteration:4091  t-loss:0.5429, loss-lb:0.3261, loss-ulb:0.1838, weight:1.18, lr:0.0008
[02:30:42.740] iteration:4092  t-loss:0.3237, loss-lb:0.2186, loss-ulb:0.0891, weight:1.18, lr:0.0008
[02:30:43.058] iteration:4093  t-loss:0.7213, loss-lb:0.3720, loss-ulb:0.2962, weight:1.18, lr:0.0008
[02:30:43.375] iteration:4094  t-loss:0.3163, loss-lb:0.2207, loss-ulb:0.0810, weight:1.18, lr:0.0008
[02:30:43.692] iteration:4095  t-loss:0.9261, loss-lb:0.4444, loss-ulb:0.4084, weight:1.18, lr:0.0008
[02:30:44.011] iteration:4096  t-loss:0.5866, loss-lb:0.3748, loss-ulb:0.1796, weight:1.18, lr:0.0008
[02:30:44.332] iteration:4097  t-loss:0.5196, loss-lb:0.2986, loss-ulb:0.1874, weight:1.18, lr:0.0008
[02:30:44.648] iteration:4098  t-loss:0.5083, loss-lb:0.3569, loss-ulb:0.1284, weight:1.18, lr:0.0008
[02:30:44.962] iteration:4099  t-loss:0.5018, loss-lb:0.4505, loss-ulb:0.0436, weight:1.18, lr:0.0008
[02:30:45.276] iteration:4100  t-loss:0.3893, loss-lb:0.2325, loss-ulb:0.1329, weight:1.18, lr:0.0008
[02:30:46.485] iteration:4101  t-loss:0.6717, loss-lb:0.1664, loss-ulb:0.4284, weight:1.18, lr:0.0008
[02:30:46.829] iteration:4102  t-loss:1.0419, loss-lb:0.4262, loss-ulb:0.5221, weight:1.18, lr:0.0008
[02:30:47.162] iteration:4103  t-loss:0.5968, loss-lb:0.3257, loss-ulb:0.2298, weight:1.18, lr:0.0008
[02:30:47.492] iteration:4104  t-loss:0.3251, loss-lb:0.2102, loss-ulb:0.0974, weight:1.18, lr:0.0008
[02:30:47.810] iteration:4105  t-loss:0.9040, loss-lb:0.1753, loss-ulb:0.6178, weight:1.18, lr:0.0007
[02:30:48.128] iteration:4106  t-loss:0.2296, loss-lb:0.1946, loss-ulb:0.0297, weight:1.18, lr:0.0007
[02:30:48.454] iteration:4107  t-loss:0.6240, loss-lb:0.3357, loss-ulb:0.2445, weight:1.18, lr:0.0007
[02:30:48.772] iteration:4108  t-loss:0.5833, loss-lb:0.1995, loss-ulb:0.3254, weight:1.18, lr:0.0007
[02:30:49.092] iteration:4109  t-loss:0.6763, loss-lb:0.4841, loss-ulb:0.1630, weight:1.18, lr:0.0007
[02:30:49.410] iteration:4110  t-loss:0.8716, loss-lb:0.2898, loss-ulb:0.4933, weight:1.18, lr:0.0007
[02:30:49.729] iteration:4111  t-loss:0.5116, loss-lb:0.2251, loss-ulb:0.2429, weight:1.18, lr:0.0007
[02:30:50.045] iteration:4112  t-loss:0.5952, loss-lb:0.2276, loss-ulb:0.3116, weight:1.18, lr:0.0007
[02:30:50.361] iteration:4113  t-loss:0.2644, loss-lb:0.1938, loss-ulb:0.0599, weight:1.18, lr:0.0007
[02:30:50.680] iteration:4114  t-loss:0.3377, loss-lb:0.1545, loss-ulb:0.1553, weight:1.18, lr:0.0007
[02:30:51.001] iteration:4115  t-loss:0.5237, loss-lb:0.3964, loss-ulb:0.1080, weight:1.18, lr:0.0007
[02:30:51.316] iteration:4116  t-loss:0.5300, loss-lb:0.4802, loss-ulb:0.0422, weight:1.18, lr:0.0007
[02:30:51.634] iteration:4117  t-loss:0.6835, loss-lb:0.2272, loss-ulb:0.3868, weight:1.18, lr:0.0007
[02:30:51.947] iteration:4118  t-loss:0.4081, loss-lb:0.2197, loss-ulb:0.1598, weight:1.18, lr:0.0007
[02:30:52.262] iteration:4119  t-loss:0.5298, loss-lb:0.4846, loss-ulb:0.0383, weight:1.18, lr:0.0007
[02:30:52.578] iteration:4120  t-loss:0.6835, loss-lb:0.4489, loss-ulb:0.1989, weight:1.18, lr:0.0007
[02:30:52.892] iteration:4121  t-loss:0.2833, loss-lb:0.1990, loss-ulb:0.0715, weight:1.18, lr:0.0007
[02:30:53.210] iteration:4122  t-loss:0.4104, loss-lb:0.2515, loss-ulb:0.1347, weight:1.18, lr:0.0007
[02:30:53.527] iteration:4123  t-loss:0.3989, loss-lb:0.3189, loss-ulb:0.0678, weight:1.18, lr:0.0007
[02:30:53.844] iteration:4124  t-loss:0.5800, loss-lb:0.1780, loss-ulb:0.3408, weight:1.18, lr:0.0007
[02:30:54.162] iteration:4125  t-loss:0.3836, loss-lb:0.3266, loss-ulb:0.0483, weight:1.18, lr:0.0007
[02:33:01.612] iteration 4125 : dice_score: 0.831345 best_dice: 0.831300
[02:33:01.613]  <<Test>> - Ep:164  - Dice-S/T:81.62/83.13, Best-S:82.79, Best-T:83.13
[02:33:01.613]           - AvgLoss(lb/ulb/all):0.29/0.18/0.51
[02:33:02.764] iteration:4126  t-loss:0.2017, loss-lb:0.1580, loss-ulb:0.0371, weight:1.18, lr:0.0007
[02:33:03.110] iteration:4127  t-loss:0.7235, loss-lb:0.6174, loss-ulb:0.0900, weight:1.18, lr:0.0007
[02:33:03.451] iteration:4128  t-loss:0.2883, loss-lb:0.2176, loss-ulb:0.0600, weight:1.18, lr:0.0007
[02:33:03.775] iteration:4129  t-loss:0.3801, loss-lb:0.2216, loss-ulb:0.1344, weight:1.18, lr:0.0007
[02:33:04.095] iteration:4130  t-loss:0.6273, loss-lb:0.1808, loss-ulb:0.3786, weight:1.18, lr:0.0007
[02:33:04.422] iteration:4131  t-loss:0.5864, loss-lb:0.2956, loss-ulb:0.2466, weight:1.18, lr:0.0007
[02:33:04.738] iteration:4132  t-loss:0.3764, loss-lb:0.2512, loss-ulb:0.1061, weight:1.18, lr:0.0007
[02:33:05.063] iteration:4133  t-loss:0.2539, loss-lb:0.1828, loss-ulb:0.0603, weight:1.18, lr:0.0007
[02:33:05.383] iteration:4134  t-loss:0.6198, loss-lb:0.2692, loss-ulb:0.2972, weight:1.18, lr:0.0007
[02:33:05.712] iteration:4135  t-loss:0.4561, loss-lb:0.4140, loss-ulb:0.0357, weight:1.18, lr:0.0007
[02:33:06.036] iteration:4136  t-loss:0.3961, loss-lb:0.2627, loss-ulb:0.1132, weight:1.18, lr:0.0007
[02:33:06.362] iteration:4137  t-loss:0.4131, loss-lb:0.2349, loss-ulb:0.1511, weight:1.18, lr:0.0007
[02:33:06.682] iteration:4138  t-loss:0.8501, loss-lb:0.4123, loss-ulb:0.3712, weight:1.18, lr:0.0007
[02:33:07.002] iteration:4139  t-loss:0.4693, loss-lb:0.3122, loss-ulb:0.1332, weight:1.18, lr:0.0007
[02:33:07.325] iteration:4140  t-loss:0.8589, loss-lb:0.7601, loss-ulb:0.0837, weight:1.18, lr:0.0007
[02:33:07.647] iteration:4141  t-loss:0.4663, loss-lb:0.3455, loss-ulb:0.1024, weight:1.18, lr:0.0007
[02:33:07.961] iteration:4142  t-loss:0.3070, loss-lb:0.1421, loss-ulb:0.1398, weight:1.18, lr:0.0007
[02:33:08.274] iteration:4143  t-loss:0.5656, loss-lb:0.2416, loss-ulb:0.2748, weight:1.18, lr:0.0007
[02:33:08.587] iteration:4144  t-loss:0.9287, loss-lb:0.2431, loss-ulb:0.5813, weight:1.18, lr:0.0007
[02:33:08.901] iteration:4145  t-loss:0.4345, loss-lb:0.2647, loss-ulb:0.1440, weight:1.18, lr:0.0007
[02:33:09.212] iteration:4146  t-loss:0.2275, loss-lb:0.1744, loss-ulb:0.0450, weight:1.18, lr:0.0007
[02:33:09.522] iteration:4147  t-loss:0.3017, loss-lb:0.1814, loss-ulb:0.1020, weight:1.18, lr:0.0007
[02:33:09.839] iteration:4148  t-loss:0.5006, loss-lb:0.2370, loss-ulb:0.2235, weight:1.18, lr:0.0007
[02:33:10.150] iteration:4149  t-loss:0.4262, loss-lb:0.3355, loss-ulb:0.0769, weight:1.18, lr:0.0007
[02:33:10.464] iteration:4150  t-loss:0.5364, loss-lb:0.2625, loss-ulb:0.2323, weight:1.18, lr:0.0007
[02:33:11.630] iteration:4151  t-loss:0.8377, loss-lb:0.3007, loss-ulb:0.4554, weight:1.18, lr:0.0007
[02:33:11.958] iteration:4152  t-loss:0.4884, loss-lb:0.3443, loss-ulb:0.1222, weight:1.18, lr:0.0007
[02:33:12.280] iteration:4153  t-loss:0.4321, loss-lb:0.2477, loss-ulb:0.1563, weight:1.18, lr:0.0007
[02:33:12.596] iteration:4154  t-loss:0.3885, loss-lb:0.1802, loss-ulb:0.1766, weight:1.18, lr:0.0007
[02:33:12.920] iteration:4155  t-loss:0.3705, loss-lb:0.1964, loss-ulb:0.1477, weight:1.18, lr:0.0007
[02:33:13.239] iteration:4156  t-loss:0.6188, loss-lb:0.5160, loss-ulb:0.0871, weight:1.18, lr:0.0007
[02:33:13.554] iteration:4157  t-loss:0.2414, loss-lb:0.1571, loss-ulb:0.0716, weight:1.18, lr:0.0007
[02:33:13.880] iteration:4158  t-loss:0.5137, loss-lb:0.3030, loss-ulb:0.1786, weight:1.18, lr:0.0007
[02:33:14.205] iteration:4159  t-loss:0.7570, loss-lb:0.7112, loss-ulb:0.0388, weight:1.18, lr:0.0007
[02:33:14.526] iteration:4160  t-loss:0.2857, loss-lb:0.1685, loss-ulb:0.0994, weight:1.18, lr:0.0007
[02:33:14.850] iteration:4161  t-loss:0.3811, loss-lb:0.2695, loss-ulb:0.0946, weight:1.18, lr:0.0007
[02:33:15.174] iteration:4162  t-loss:0.4052, loss-lb:0.2387, loss-ulb:0.1411, weight:1.18, lr:0.0007
[02:33:15.494] iteration:4163  t-loss:0.8410, loss-lb:0.3078, loss-ulb:0.4521, weight:1.18, lr:0.0007
[02:33:15.821] iteration:4164  t-loss:0.4339, loss-lb:0.2299, loss-ulb:0.1729, weight:1.18, lr:0.0007
[02:33:16.140] iteration:4165  t-loss:0.6015, loss-lb:0.1626, loss-ulb:0.3721, weight:1.18, lr:0.0007
[02:33:16.452] iteration:4166  t-loss:0.4576, loss-lb:0.3439, loss-ulb:0.0964, weight:1.18, lr:0.0007
[02:33:16.774] iteration:4167  t-loss:0.5121, loss-lb:0.2225, loss-ulb:0.2455, weight:1.18, lr:0.0007
[02:33:17.089] iteration:4168  t-loss:0.3076, loss-lb:0.2353, loss-ulb:0.0613, weight:1.18, lr:0.0007
[02:33:17.408] iteration:4169  t-loss:0.6238, loss-lb:0.4472, loss-ulb:0.1497, weight:1.18, lr:0.0007
[02:33:17.721] iteration:4170  t-loss:0.8343, loss-lb:0.2331, loss-ulb:0.5097, weight:1.18, lr:0.0007
[02:33:18.034] iteration:4171  t-loss:0.5888, loss-lb:0.1970, loss-ulb:0.3323, weight:1.18, lr:0.0007
[02:33:18.349] iteration:4172  t-loss:0.7529, loss-lb:0.1778, loss-ulb:0.4876, weight:1.18, lr:0.0007
[02:33:18.667] iteration:4173  t-loss:0.8167, loss-lb:0.5828, loss-ulb:0.1983, weight:1.18, lr:0.0007
[02:33:18.983] iteration:4174  t-loss:0.6241, loss-lb:0.5168, loss-ulb:0.0910, weight:1.18, lr:0.0007
[02:33:19.296] iteration:4175  t-loss:0.3369, loss-lb:0.2333, loss-ulb:0.0879, weight:1.18, lr:0.0007
[02:33:20.642] iteration:4176  t-loss:0.8299, loss-lb:0.2158, loss-ulb:0.5207, weight:1.18, lr:0.0007
[02:33:20.979] iteration:4177  t-loss:0.7556, loss-lb:0.5945, loss-ulb:0.1366, weight:1.18, lr:0.0007
[02:33:21.302] iteration:4178  t-loss:0.4201, loss-lb:0.2506, loss-ulb:0.1437, weight:1.18, lr:0.0007
[02:33:21.627] iteration:4179  t-loss:0.5093, loss-lb:0.3029, loss-ulb:0.1750, weight:1.18, lr:0.0007
[02:33:21.944] iteration:4180  t-loss:0.2678, loss-lb:0.1944, loss-ulb:0.0622, weight:1.18, lr:0.0007
[02:33:22.260] iteration:4181  t-loss:0.6954, loss-lb:0.1943, loss-ulb:0.4249, weight:1.18, lr:0.0007
[02:33:22.572] iteration:4182  t-loss:0.3924, loss-lb:0.2038, loss-ulb:0.1599, weight:1.18, lr:0.0007
[02:33:22.893] iteration:4183  t-loss:0.4780, loss-lb:0.2515, loss-ulb:0.1921, weight:1.18, lr:0.0007
[02:33:23.218] iteration:4184  t-loss:0.4375, loss-lb:0.2496, loss-ulb:0.1593, weight:1.18, lr:0.0007
[02:33:23.535] iteration:4185  t-loss:0.6867, loss-lb:0.2845, loss-ulb:0.3411, weight:1.18, lr:0.0007
[02:33:23.919] iteration:4186  t-loss:0.3821, loss-lb:0.1641, loss-ulb:0.1848, weight:1.18, lr:0.0007
[02:33:24.238] iteration:4187  t-loss:0.8906, loss-lb:0.5747, loss-ulb:0.2679, weight:1.18, lr:0.0007
[02:33:24.556] iteration:4188  t-loss:0.7945, loss-lb:0.5964, loss-ulb:0.1680, weight:1.18, lr:0.0007
[02:33:24.874] iteration:4189  t-loss:0.3307, loss-lb:0.1561, loss-ulb:0.1481, weight:1.18, lr:0.0007
[02:33:25.191] iteration:4190  t-loss:0.3577, loss-lb:0.3222, loss-ulb:0.0301, weight:1.18, lr:0.0007
[02:33:25.507] iteration:4191  t-loss:0.2867, loss-lb:0.2002, loss-ulb:0.0733, weight:1.18, lr:0.0007
[02:33:25.824] iteration:4192  t-loss:0.4064, loss-lb:0.2164, loss-ulb:0.1611, weight:1.18, lr:0.0007
[02:33:26.137] iteration:4193  t-loss:0.5027, loss-lb:0.2509, loss-ulb:0.2135, weight:1.18, lr:0.0007
[02:33:26.451] iteration:4194  t-loss:0.7970, loss-lb:0.4338, loss-ulb:0.3079, weight:1.18, lr:0.0007
[02:33:26.769] iteration:4195  t-loss:0.7175, loss-lb:0.4927, loss-ulb:0.1906, weight:1.18, lr:0.0007
[02:33:27.082] iteration:4196  t-loss:0.3198, loss-lb:0.2461, loss-ulb:0.0625, weight:1.18, lr:0.0007
[02:33:27.397] iteration:4197  t-loss:0.8862, loss-lb:0.3180, loss-ulb:0.4817, weight:1.18, lr:0.0007
[02:33:27.708] iteration:4198  t-loss:0.6416, loss-lb:0.2175, loss-ulb:0.3596, weight:1.18, lr:0.0007
[02:33:28.025] iteration:4199  t-loss:0.3748, loss-lb:0.2207, loss-ulb:0.1306, weight:1.18, lr:0.0007
[02:33:28.341] iteration:4200  t-loss:0.3947, loss-lb:0.1429, loss-ulb:0.2135, weight:1.18, lr:0.0007
[02:33:29.637] iteration:4201  t-loss:0.3428, loss-lb:0.1435, loss-ulb:0.1562, weight:1.28, lr:0.0007
[02:33:29.969] iteration:4202  t-loss:0.7965, loss-lb:0.1590, loss-ulb:0.4999, weight:1.28, lr:0.0007
[02:33:30.289] iteration:4203  t-loss:1.1208, loss-lb:0.2845, loss-ulb:0.6558, weight:1.28, lr:0.0007
[02:33:30.614] iteration:4204  t-loss:0.6529, loss-lb:0.3961, loss-ulb:0.2013, weight:1.28, lr:0.0007
[02:33:30.936] iteration:4205  t-loss:0.6224, loss-lb:0.4668, loss-ulb:0.1220, weight:1.28, lr:0.0007
[02:33:31.252] iteration:4206  t-loss:0.4495, loss-lb:0.2226, loss-ulb:0.1779, weight:1.28, lr:0.0007
[02:33:31.571] iteration:4207  t-loss:0.4842, loss-lb:0.2261, loss-ulb:0.2024, weight:1.28, lr:0.0007
[02:33:31.889] iteration:4208  t-loss:0.3684, loss-lb:0.1713, loss-ulb:0.1546, weight:1.28, lr:0.0007
[02:33:32.206] iteration:4209  t-loss:0.2606, loss-lb:0.2067, loss-ulb:0.0423, weight:1.28, lr:0.0007
[02:33:32.523] iteration:4210  t-loss:0.2853, loss-lb:0.1967, loss-ulb:0.0695, weight:1.28, lr:0.0007
[02:33:32.843] iteration:4211  t-loss:1.0332, loss-lb:0.2191, loss-ulb:0.6384, weight:1.28, lr:0.0007
[02:33:33.163] iteration:4212  t-loss:0.2902, loss-lb:0.2512, loss-ulb:0.0305, weight:1.28, lr:0.0007
[02:33:33.480] iteration:4213  t-loss:0.3551, loss-lb:0.3023, loss-ulb:0.0414, weight:1.28, lr:0.0007
[02:33:33.798] iteration:4214  t-loss:0.4303, loss-lb:0.1918, loss-ulb:0.1870, weight:1.28, lr:0.0007
[02:33:34.116] iteration:4215  t-loss:0.4590, loss-lb:0.2014, loss-ulb:0.2020, weight:1.28, lr:0.0007
[02:33:34.434] iteration:4216  t-loss:0.3762, loss-lb:0.2375, loss-ulb:0.1088, weight:1.28, lr:0.0007
[02:33:34.754] iteration:4217  t-loss:0.4948, loss-lb:0.2957, loss-ulb:0.1561, weight:1.28, lr:0.0007
[02:33:35.067] iteration:4218  t-loss:0.2098, loss-lb:0.1731, loss-ulb:0.0288, weight:1.28, lr:0.0007
[02:33:35.384] iteration:4219  t-loss:0.9842, loss-lb:0.4684, loss-ulb:0.4045, weight:1.28, lr:0.0007
[02:33:35.698] iteration:4220  t-loss:0.3732, loss-lb:0.3003, loss-ulb:0.0572, weight:1.28, lr:0.0007
[02:33:36.016] iteration:4221  t-loss:0.5472, loss-lb:0.2900, loss-ulb:0.2017, weight:1.28, lr:0.0007
[02:33:36.333] iteration:4222  t-loss:0.3676, loss-lb:0.1890, loss-ulb:0.1401, weight:1.28, lr:0.0007
[02:33:36.645] iteration:4223  t-loss:0.5837, loss-lb:0.5220, loss-ulb:0.0484, weight:1.28, lr:0.0007
[02:33:36.960] iteration:4224  t-loss:0.5048, loss-lb:0.3023, loss-ulb:0.1588, weight:1.28, lr:0.0007
[02:33:37.273] iteration:4225  t-loss:0.3037, loss-lb:0.1683, loss-ulb:0.1062, weight:1.28, lr:0.0007
[02:35:40.939] iteration 4225 : dice_score: 0.833878 best_dice: 0.833900
[02:35:40.940]  <<Test>> - Ep:168  - Dice-S/T:75.31/83.39, Best-S:82.79, Best-T:83.39
[02:35:40.940]           - AvgLoss(lb/ulb/all):0.26/0.16/0.46
[02:35:42.200] iteration:4226  t-loss:0.2425, loss-lb:0.1885, loss-ulb:0.0424, weight:1.28, lr:0.0007
[02:35:42.544] iteration:4227  t-loss:0.9314, loss-lb:0.4012, loss-ulb:0.4158, weight:1.28, lr:0.0007
[02:35:42.874] iteration:4228  t-loss:0.3315, loss-lb:0.1749, loss-ulb:0.1228, weight:1.28, lr:0.0007
[02:35:43.193] iteration:4229  t-loss:0.3750, loss-lb:0.1510, loss-ulb:0.1757, weight:1.28, lr:0.0007
[02:35:43.516] iteration:4230  t-loss:1.1386, loss-lb:0.1982, loss-ulb:0.7375, weight:1.28, lr:0.0007
[02:35:43.842] iteration:4231  t-loss:0.2452, loss-lb:0.1655, loss-ulb:0.0625, weight:1.28, lr:0.0007
[02:35:44.165] iteration:4232  t-loss:0.9731, loss-lb:0.3034, loss-ulb:0.5252, weight:1.28, lr:0.0007
[02:35:44.500] iteration:4233  t-loss:0.3431, loss-lb:0.2226, loss-ulb:0.0944, weight:1.28, lr:0.0007
[02:35:44.822] iteration:4234  t-loss:0.3709, loss-lb:0.1976, loss-ulb:0.1359, weight:1.28, lr:0.0007
[02:35:45.142] iteration:4235  t-loss:0.5128, loss-lb:0.2079, loss-ulb:0.2391, weight:1.28, lr:0.0007
[02:35:45.466] iteration:4236  t-loss:0.5189, loss-lb:0.3486, loss-ulb:0.1335, weight:1.28, lr:0.0007
[02:35:45.792] iteration:4237  t-loss:0.4374, loss-lb:0.3061, loss-ulb:0.1029, weight:1.28, lr:0.0007
[02:35:46.112] iteration:4238  t-loss:0.3965, loss-lb:0.2810, loss-ulb:0.0906, weight:1.28, lr:0.0007
[02:35:46.427] iteration:4239  t-loss:0.8263, loss-lb:0.4301, loss-ulb:0.3107, weight:1.28, lr:0.0007
[02:35:46.751] iteration:4240  t-loss:0.9177, loss-lb:0.3164, loss-ulb:0.4715, weight:1.28, lr:0.0007
[02:35:47.066] iteration:4241  t-loss:0.3767, loss-lb:0.3318, loss-ulb:0.0352, weight:1.28, lr:0.0007
[02:35:47.381] iteration:4242  t-loss:0.4148, loss-lb:0.3660, loss-ulb:0.0383, weight:1.28, lr:0.0007
[02:35:47.692] iteration:4243  t-loss:0.2723, loss-lb:0.1381, loss-ulb:0.1052, weight:1.28, lr:0.0007
[02:35:48.005] iteration:4244  t-loss:0.9796, loss-lb:0.2751, loss-ulb:0.5525, weight:1.28, lr:0.0007
[02:35:48.323] iteration:4245  t-loss:0.6305, loss-lb:0.2914, loss-ulb:0.2659, weight:1.28, lr:0.0007
[02:35:48.635] iteration:4246  t-loss:0.2119, loss-lb:0.1672, loss-ulb:0.0351, weight:1.28, lr:0.0007
[02:35:48.948] iteration:4247  t-loss:0.2836, loss-lb:0.2256, loss-ulb:0.0455, weight:1.28, lr:0.0007
[02:35:49.263] iteration:4248  t-loss:0.5049, loss-lb:0.3436, loss-ulb:0.1265, weight:1.28, lr:0.0007
[02:35:49.580] iteration:4249  t-loss:0.5698, loss-lb:0.2963, loss-ulb:0.2145, weight:1.28, lr:0.0007
[02:35:49.895] iteration:4250  t-loss:0.2906, loss-lb:0.1863, loss-ulb:0.0818, weight:1.28, lr:0.0007
[02:35:51.222] iteration:4251  t-loss:0.4215, loss-lb:0.2668, loss-ulb:0.1213, weight:1.28, lr:0.0007
[02:35:51.551] iteration:4252  t-loss:0.5659, loss-lb:0.2355, loss-ulb:0.2591, weight:1.28, lr:0.0007
[02:35:51.874] iteration:4253  t-loss:0.4498, loss-lb:0.3237, loss-ulb:0.0989, weight:1.28, lr:0.0007
[02:35:52.191] iteration:4254  t-loss:0.3208, loss-lb:0.1271, loss-ulb:0.1519, weight:1.28, lr:0.0007
[02:35:52.508] iteration:4255  t-loss:0.6826, loss-lb:0.1653, loss-ulb:0.4057, weight:1.28, lr:0.0007
[02:35:52.825] iteration:4256  t-loss:0.4959, loss-lb:0.4733, loss-ulb:0.0177, weight:1.28, lr:0.0007
[02:35:53.151] iteration:4257  t-loss:0.9264, loss-lb:0.3624, loss-ulb:0.4423, weight:1.28, lr:0.0007
[02:35:53.471] iteration:4258  t-loss:0.5852, loss-lb:0.2644, loss-ulb:0.2516, weight:1.28, lr:0.0007
[02:35:53.788] iteration:4259  t-loss:0.2602, loss-lb:0.1990, loss-ulb:0.0481, weight:1.28, lr:0.0007
[02:35:54.117] iteration:4260  t-loss:0.5053, loss-lb:0.3689, loss-ulb:0.1070, weight:1.28, lr:0.0007
[02:35:54.438] iteration:4261  t-loss:0.4829, loss-lb:0.2231, loss-ulb:0.2037, weight:1.28, lr:0.0007
[02:35:54.763] iteration:4262  t-loss:0.6145, loss-lb:0.3138, loss-ulb:0.2358, weight:1.28, lr:0.0007
[02:35:55.083] iteration:4263  t-loss:1.5298, loss-lb:0.5465, loss-ulb:0.7711, weight:1.28, lr:0.0007
[02:35:55.411] iteration:4264  t-loss:0.8917, loss-lb:0.3549, loss-ulb:0.4209, weight:1.28, lr:0.0007
[02:35:55.728] iteration:4265  t-loss:0.4179, loss-lb:0.2116, loss-ulb:0.1617, weight:1.28, lr:0.0007
[02:35:56.052] iteration:4266  t-loss:0.4070, loss-lb:0.2867, loss-ulb:0.0943, weight:1.28, lr:0.0007
[02:35:56.369] iteration:4267  t-loss:0.3364, loss-lb:0.3064, loss-ulb:0.0235, weight:1.28, lr:0.0007
[02:35:56.692] iteration:4268  t-loss:0.5886, loss-lb:0.3160, loss-ulb:0.2137, weight:1.28, lr:0.0007
[02:35:57.004] iteration:4269  t-loss:0.3305, loss-lb:0.1376, loss-ulb:0.1512, weight:1.28, lr:0.0007
[02:35:57.321] iteration:4270  t-loss:0.3898, loss-lb:0.2337, loss-ulb:0.1224, weight:1.28, lr:0.0007
[02:35:57.639] iteration:4271  t-loss:0.7817, loss-lb:0.2893, loss-ulb:0.3861, weight:1.28, lr:0.0007
[02:35:57.956] iteration:4272  t-loss:0.5919, loss-lb:0.3516, loss-ulb:0.1884, weight:1.28, lr:0.0007
[02:35:58.269] iteration:4273  t-loss:0.8701, loss-lb:0.1821, loss-ulb:0.5395, weight:1.28, lr:0.0007
[02:35:58.586] iteration:4274  t-loss:0.4525, loss-lb:0.3562, loss-ulb:0.0755, weight:1.28, lr:0.0007
[02:35:58.900] iteration:4275  t-loss:0.2450, loss-lb:0.2010, loss-ulb:0.0345, weight:1.28, lr:0.0007
[02:36:00.300] iteration:4276  t-loss:0.4127, loss-lb:0.2558, loss-ulb:0.1230, weight:1.28, lr:0.0007
[02:36:00.623] iteration:4277  t-loss:0.7211, loss-lb:0.2460, loss-ulb:0.3725, weight:1.28, lr:0.0007
[02:36:00.951] iteration:4278  t-loss:0.4412, loss-lb:0.2502, loss-ulb:0.1498, weight:1.28, lr:0.0007
[02:36:01.268] iteration:4279  t-loss:0.9647, loss-lb:0.3380, loss-ulb:0.4915, weight:1.28, lr:0.0007
[02:36:01.590] iteration:4280  t-loss:0.3079, loss-lb:0.2139, loss-ulb:0.0737, weight:1.28, lr:0.0007
[02:36:01.911] iteration:4281  t-loss:0.5142, loss-lb:0.3721, loss-ulb:0.1114, weight:1.28, lr:0.0007
[02:36:02.231] iteration:4282  t-loss:0.8667, loss-lb:0.6466, loss-ulb:0.1726, weight:1.28, lr:0.0007
[02:36:02.549] iteration:4283  t-loss:0.8366, loss-lb:0.1864, loss-ulb:0.5098, weight:1.28, lr:0.0007
[02:36:02.865] iteration:4284  t-loss:0.3717, loss-lb:0.2339, loss-ulb:0.1080, weight:1.28, lr:0.0007
[02:36:03.184] iteration:4285  t-loss:0.3847, loss-lb:0.1542, loss-ulb:0.1808, weight:1.28, lr:0.0007
[02:36:03.503] iteration:4286  t-loss:0.4868, loss-lb:0.3281, loss-ulb:0.1245, weight:1.28, lr:0.0007
[02:36:03.823] iteration:4287  t-loss:0.5522, loss-lb:0.2532, loss-ulb:0.2344, weight:1.28, lr:0.0007
[02:36:04.149] iteration:4288  t-loss:0.3978, loss-lb:0.1936, loss-ulb:0.1601, weight:1.28, lr:0.0007
[02:36:04.478] iteration:4289  t-loss:0.3581, loss-lb:0.2429, loss-ulb:0.0904, weight:1.28, lr:0.0007
[02:36:04.801] iteration:4290  t-loss:0.3048, loss-lb:0.2107, loss-ulb:0.0738, weight:1.28, lr:0.0007
[02:36:05.122] iteration:4291  t-loss:0.5313, loss-lb:0.2135, loss-ulb:0.2492, weight:1.28, lr:0.0007
[02:36:05.449] iteration:4292  t-loss:0.4017, loss-lb:0.3377, loss-ulb:0.0502, weight:1.28, lr:0.0007
[02:36:05.782] iteration:4293  t-loss:0.5526, loss-lb:0.2856, loss-ulb:0.2093, weight:1.28, lr:0.0007
[02:36:06.099] iteration:4294  t-loss:0.2322, loss-lb:0.2043, loss-ulb:0.0219, weight:1.28, lr:0.0007
[02:36:06.416] iteration:4295  t-loss:0.6622, loss-lb:0.1643, loss-ulb:0.3904, weight:1.28, lr:0.0007
[02:36:06.736] iteration:4296  t-loss:0.5042, loss-lb:0.3461, loss-ulb:0.1240, weight:1.28, lr:0.0007
[02:36:07.055] iteration:4297  t-loss:0.6437, loss-lb:0.2703, loss-ulb:0.2928, weight:1.28, lr:0.0007
[02:36:07.374] iteration:4298  t-loss:0.5534, loss-lb:0.3201, loss-ulb:0.1830, weight:1.28, lr:0.0007
[02:36:07.688] iteration:4299  t-loss:0.3277, loss-lb:0.2396, loss-ulb:0.0691, weight:1.28, lr:0.0007
[02:36:08.006] iteration:4300  t-loss:0.3753, loss-lb:0.2205, loss-ulb:0.1213, weight:1.28, lr:0.0007
[02:36:09.293] iteration:4301  t-loss:0.3989, loss-lb:0.2762, loss-ulb:0.0963, weight:1.28, lr:0.0007
[02:36:09.647] iteration:4302  t-loss:0.5108, loss-lb:0.3027, loss-ulb:0.1632, weight:1.28, lr:0.0007
[02:36:09.979] iteration:4303  t-loss:0.6758, loss-lb:0.2811, loss-ulb:0.3095, weight:1.28, lr:0.0007
[02:36:10.326] iteration:4304  t-loss:0.4370, loss-lb:0.3050, loss-ulb:0.1035, weight:1.28, lr:0.0007
[02:36:10.657] iteration:4305  t-loss:0.3582, loss-lb:0.1978, loss-ulb:0.1258, weight:1.28, lr:0.0007
[02:36:10.982] iteration:4306  t-loss:0.3392, loss-lb:0.3164, loss-ulb:0.0178, weight:1.28, lr:0.0007
[02:36:11.308] iteration:4307  t-loss:0.6566, loss-lb:0.3677, loss-ulb:0.2266, weight:1.28, lr:0.0007
[02:36:11.635] iteration:4308  t-loss:0.3593, loss-lb:0.1962, loss-ulb:0.1280, weight:1.28, lr:0.0007
[02:36:11.956] iteration:4309  t-loss:0.3492, loss-lb:0.2296, loss-ulb:0.0938, weight:1.28, lr:0.0007
[02:36:12.275] iteration:4310  t-loss:0.2703, loss-lb:0.1353, loss-ulb:0.1059, weight:1.28, lr:0.0007
[02:36:12.597] iteration:4311  t-loss:0.4147, loss-lb:0.2216, loss-ulb:0.1514, weight:1.28, lr:0.0007
[02:36:12.918] iteration:4312  t-loss:0.5650, loss-lb:0.2882, loss-ulb:0.2170, weight:1.28, lr:0.0007
[02:36:13.242] iteration:4313  t-loss:0.3958, loss-lb:0.1618, loss-ulb:0.1835, weight:1.28, lr:0.0007
[02:36:13.558] iteration:4314  t-loss:0.2423, loss-lb:0.1775, loss-ulb:0.0508, weight:1.28, lr:0.0007
[02:36:13.876] iteration:4315  t-loss:0.3123, loss-lb:0.1669, loss-ulb:0.1140, weight:1.28, lr:0.0007
[02:36:14.194] iteration:4316  t-loss:0.2291, loss-lb:0.1907, loss-ulb:0.0301, weight:1.28, lr:0.0007
[02:36:14.522] iteration:4317  t-loss:0.7096, loss-lb:0.1798, loss-ulb:0.4154, weight:1.28, lr:0.0007
[02:36:14.844] iteration:4318  t-loss:0.4229, loss-lb:0.3188, loss-ulb:0.0816, weight:1.28, lr:0.0007
[02:36:15.162] iteration:4319  t-loss:0.2839, loss-lb:0.2223, loss-ulb:0.0483, weight:1.28, lr:0.0007
[02:36:15.486] iteration:4320  t-loss:0.3878, loss-lb:0.2779, loss-ulb:0.0862, weight:1.28, lr:0.0007
[02:36:15.804] iteration:4321  t-loss:0.6172, loss-lb:0.3423, loss-ulb:0.2156, weight:1.28, lr:0.0007
[02:36:16.115] iteration:4322  t-loss:0.3109, loss-lb:0.2345, loss-ulb:0.0599, weight:1.28, lr:0.0007
[02:36:16.432] iteration:4323  t-loss:0.3615, loss-lb:0.2800, loss-ulb:0.0639, weight:1.28, lr:0.0007
[02:36:16.749] iteration:4324  t-loss:0.3531, loss-lb:0.1990, loss-ulb:0.1208, weight:1.28, lr:0.0007
[02:36:17.070] iteration:4325  t-loss:0.3512, loss-lb:0.2187, loss-ulb:0.1039, weight:1.28, lr:0.0007
[02:38:39.163] iteration 4325 : dice_score: 0.833331 best_dice: 0.833900
[02:38:39.164]  <<Test>> - Ep:172  - Dice-S/T:82.67/83.33, Best-S:82.79, Best-T:83.39
[02:38:39.164]           - AvgLoss(lb/ulb/all):0.24/0.13/0.40
[02:38:40.068] iteration:4326  t-loss:0.2868, loss-lb:0.1655, loss-ulb:0.0951, weight:1.28, lr:0.0007
[02:38:40.399] iteration:4327  t-loss:0.2892, loss-lb:0.2344, loss-ulb:0.0430, weight:1.28, lr:0.0007
[02:38:40.715] iteration:4328  t-loss:0.3864, loss-lb:0.1908, loss-ulb:0.1534, weight:1.28, lr:0.0007
[02:38:41.030] iteration:4329  t-loss:0.5369, loss-lb:0.4529, loss-ulb:0.0659, weight:1.28, lr:0.0007
[02:38:41.346] iteration:4330  t-loss:0.2708, loss-lb:0.1694, loss-ulb:0.0795, weight:1.28, lr:0.0007
[02:38:41.664] iteration:4331  t-loss:0.3150, loss-lb:0.2753, loss-ulb:0.0312, weight:1.28, lr:0.0007
[02:38:41.977] iteration:4332  t-loss:0.2577, loss-lb:0.2144, loss-ulb:0.0340, weight:1.28, lr:0.0007
[02:38:42.293] iteration:4333  t-loss:0.4554, loss-lb:0.2957, loss-ulb:0.1252, weight:1.28, lr:0.0007
[02:38:42.608] iteration:4334  t-loss:0.2014, loss-lb:0.1665, loss-ulb:0.0273, weight:1.28, lr:0.0007
[02:38:42.926] iteration:4335  t-loss:0.9238, loss-lb:0.1929, loss-ulb:0.5732, weight:1.28, lr:0.0007
[02:38:43.247] iteration:4336  t-loss:0.4479, loss-lb:0.2357, loss-ulb:0.1664, weight:1.28, lr:0.0007
[02:38:43.564] iteration:4337  t-loss:0.5906, loss-lb:0.5192, loss-ulb:0.0560, weight:1.28, lr:0.0007
[02:38:43.884] iteration:4338  t-loss:0.3293, loss-lb:0.2340, loss-ulb:0.0747, weight:1.28, lr:0.0007
[02:38:44.203] iteration:4339  t-loss:0.3980, loss-lb:0.3070, loss-ulb:0.0714, weight:1.28, lr:0.0007
[02:38:44.521] iteration:4340  t-loss:0.4921, loss-lb:0.1892, loss-ulb:0.2375, weight:1.28, lr:0.0007
[02:38:44.838] iteration:4341  t-loss:0.3564, loss-lb:0.1546, loss-ulb:0.1583, weight:1.28, lr:0.0007
[02:38:45.155] iteration:4342  t-loss:0.7803, loss-lb:0.2458, loss-ulb:0.4191, weight:1.28, lr:0.0007
[02:38:45.472] iteration:4343  t-loss:0.3411, loss-lb:0.1472, loss-ulb:0.1521, weight:1.28, lr:0.0007
[02:38:45.787] iteration:4344  t-loss:0.3434, loss-lb:0.3060, loss-ulb:0.0293, weight:1.28, lr:0.0007
[02:38:46.103] iteration:4345  t-loss:0.9787, loss-lb:0.3594, loss-ulb:0.4856, weight:1.28, lr:0.0007
[02:38:46.414] iteration:4346  t-loss:0.6249, loss-lb:0.1983, loss-ulb:0.3345, weight:1.28, lr:0.0007
[02:38:46.730] iteration:4347  t-loss:0.5384, loss-lb:0.4413, loss-ulb:0.0761, weight:1.28, lr:0.0007
[02:38:47.043] iteration:4348  t-loss:0.3364, loss-lb:0.1792, loss-ulb:0.1232, weight:1.28, lr:0.0007
[02:38:47.356] iteration:4349  t-loss:0.3057, loss-lb:0.2461, loss-ulb:0.0467, weight:1.28, lr:0.0007
[02:38:47.668] iteration:4350  t-loss:0.3877, loss-lb:0.3111, loss-ulb:0.0601, weight:1.28, lr:0.0007
[02:38:49.024] iteration:4351  t-loss:1.1923, loss-lb:0.4180, loss-ulb:0.5650, weight:1.37, lr:0.0007
[02:38:49.351] iteration:4352  t-loss:0.6536, loss-lb:0.1549, loss-ulb:0.3639, weight:1.37, lr:0.0007
[02:38:49.667] iteration:4353  t-loss:0.3422, loss-lb:0.2930, loss-ulb:0.0359, weight:1.37, lr:0.0007
[02:38:49.985] iteration:4354  t-loss:1.0731, loss-lb:0.1911, loss-ulb:0.6437, weight:1.37, lr:0.0007
[02:38:50.305] iteration:4355  t-loss:0.4079, loss-lb:0.1948, loss-ulb:0.1556, weight:1.37, lr:0.0007
[02:38:50.622] iteration:4356  t-loss:0.2626, loss-lb:0.1738, loss-ulb:0.0648, weight:1.37, lr:0.0007
[02:38:50.943] iteration:4357  t-loss:0.6243, loss-lb:0.3285, loss-ulb:0.2159, weight:1.37, lr:0.0007
[02:38:51.259] iteration:4358  t-loss:0.7388, loss-lb:0.2099, loss-ulb:0.3860, weight:1.37, lr:0.0007
[02:38:51.576] iteration:4359  t-loss:0.2020, loss-lb:0.1418, loss-ulb:0.0439, weight:1.37, lr:0.0007
[02:38:51.892] iteration:4360  t-loss:0.4871, loss-lb:0.1569, loss-ulb:0.2410, weight:1.37, lr:0.0007
[02:38:52.212] iteration:4361  t-loss:0.5210, loss-lb:0.4035, loss-ulb:0.0858, weight:1.37, lr:0.0007
[02:38:52.525] iteration:4362  t-loss:0.8750, loss-lb:0.2688, loss-ulb:0.4424, weight:1.37, lr:0.0007
[02:38:52.838] iteration:4363  t-loss:0.3041, loss-lb:0.1782, loss-ulb:0.0919, weight:1.37, lr:0.0007
[02:38:53.153] iteration:4364  t-loss:0.4568, loss-lb:0.3441, loss-ulb:0.0823, weight:1.37, lr:0.0007
[02:38:53.477] iteration:4365  t-loss:0.4096, loss-lb:0.3298, loss-ulb:0.0582, weight:1.37, lr:0.0007
[02:38:53.794] iteration:4366  t-loss:0.5874, loss-lb:0.2334, loss-ulb:0.2584, weight:1.37, lr:0.0007
[02:38:54.110] iteration:4367  t-loss:0.9504, loss-lb:0.2654, loss-ulb:0.4999, weight:1.37, lr:0.0007
[02:38:54.424] iteration:4368  t-loss:0.7798, loss-lb:0.2201, loss-ulb:0.4084, weight:1.37, lr:0.0007
[02:38:54.739] iteration:4369  t-loss:0.5965, loss-lb:0.3151, loss-ulb:0.2053, weight:1.37, lr:0.0007
[02:38:55.055] iteration:4370  t-loss:1.1696, loss-lb:0.4563, loss-ulb:0.5205, weight:1.37, lr:0.0007
[02:38:55.367] iteration:4371  t-loss:0.3960, loss-lb:0.1630, loss-ulb:0.1700, weight:1.37, lr:0.0007
[02:38:55.678] iteration:4372  t-loss:0.3544, loss-lb:0.2105, loss-ulb:0.1050, weight:1.37, lr:0.0007
[02:38:55.995] iteration:4373  t-loss:1.0528, loss-lb:0.2809, loss-ulb:0.5633, weight:1.37, lr:0.0007
[02:38:56.311] iteration:4374  t-loss:0.4860, loss-lb:0.2368, loss-ulb:0.1818, weight:1.37, lr:0.0007
[02:38:56.625] iteration:4375  t-loss:0.5435, loss-lb:0.3543, loss-ulb:0.1381, weight:1.37, lr:0.0007
[02:38:57.904] iteration:4376  t-loss:0.2958, loss-lb:0.1564, loss-ulb:0.1017, weight:1.37, lr:0.0007
[02:38:58.240] iteration:4377  t-loss:0.4812, loss-lb:0.3350, loss-ulb:0.1067, weight:1.37, lr:0.0007
[02:38:58.562] iteration:4378  t-loss:0.3442, loss-lb:0.2195, loss-ulb:0.0910, weight:1.37, lr:0.0007
[02:38:58.880] iteration:4379  t-loss:0.4321, loss-lb:0.2426, loss-ulb:0.1383, weight:1.37, lr:0.0007
[02:38:59.194] iteration:4380  t-loss:0.4394, loss-lb:0.3537, loss-ulb:0.0625, weight:1.37, lr:0.0007
[02:38:59.513] iteration:4381  t-loss:0.3565, loss-lb:0.1680, loss-ulb:0.1376, weight:1.37, lr:0.0007
[02:38:59.833] iteration:4382  t-loss:0.5947, loss-lb:0.3712, loss-ulb:0.1630, weight:1.37, lr:0.0007
[02:39:00.153] iteration:4383  t-loss:0.4479, loss-lb:0.2986, loss-ulb:0.1090, weight:1.37, lr:0.0007
[02:39:00.477] iteration:4384  t-loss:0.5663, loss-lb:0.2098, loss-ulb:0.2601, weight:1.37, lr:0.0007
[02:39:00.795] iteration:4385  t-loss:0.6375, loss-lb:0.1758, loss-ulb:0.3369, weight:1.37, lr:0.0007
[02:39:01.116] iteration:4386  t-loss:0.5711, loss-lb:0.3216, loss-ulb:0.1821, weight:1.37, lr:0.0007
[02:39:01.441] iteration:4387  t-loss:0.4998, loss-lb:0.2283, loss-ulb:0.1982, weight:1.37, lr:0.0007
[02:39:01.759] iteration:4388  t-loss:0.3237, loss-lb:0.1494, loss-ulb:0.1272, weight:1.37, lr:0.0007
[02:39:02.076] iteration:4389  t-loss:0.9081, loss-lb:0.3867, loss-ulb:0.3805, weight:1.37, lr:0.0007
[02:39:02.391] iteration:4390  t-loss:0.3527, loss-lb:0.3063, loss-ulb:0.0339, weight:1.37, lr:0.0007
[02:39:02.715] iteration:4391  t-loss:0.6554, loss-lb:0.3838, loss-ulb:0.1982, weight:1.37, lr:0.0007
[02:39:03.032] iteration:4392  t-loss:0.4679, loss-lb:0.3556, loss-ulb:0.0820, weight:1.37, lr:0.0007
[02:39:03.349] iteration:4393  t-loss:0.7885, loss-lb:0.3872, loss-ulb:0.2928, weight:1.37, lr:0.0007
[02:39:03.661] iteration:4394  t-loss:0.3678, loss-lb:0.1641, loss-ulb:0.1487, weight:1.37, lr:0.0007
[02:39:03.975] iteration:4395  t-loss:0.3227, loss-lb:0.1864, loss-ulb:0.0995, weight:1.37, lr:0.0007
[02:39:04.292] iteration:4396  t-loss:1.1222, loss-lb:0.2658, loss-ulb:0.6250, weight:1.37, lr:0.0007
[02:39:04.606] iteration:4397  t-loss:0.5569, loss-lb:0.2882, loss-ulb:0.1961, weight:1.37, lr:0.0007
[02:39:04.924] iteration:4398  t-loss:0.2792, loss-lb:0.1560, loss-ulb:0.0899, weight:1.37, lr:0.0007
[02:39:05.239] iteration:4399  t-loss:0.3975, loss-lb:0.1642, loss-ulb:0.1702, weight:1.37, lr:0.0007
[02:39:05.556] iteration:4400  t-loss:0.6769, loss-lb:0.2803, loss-ulb:0.2894, weight:1.37, lr:0.0007
[02:39:06.957] iteration:4401  t-loss:0.2610, loss-lb:0.2108, loss-ulb:0.0366, weight:1.37, lr:0.0007
[02:39:07.289] iteration:4402  t-loss:0.5275, loss-lb:0.1873, loss-ulb:0.2483, weight:1.37, lr:0.0007
[02:39:07.619] iteration:4403  t-loss:0.7600, loss-lb:0.3675, loss-ulb:0.2864, weight:1.37, lr:0.0007
[02:39:07.941] iteration:4404  t-loss:0.2936, loss-lb:0.1464, loss-ulb:0.1074, weight:1.37, lr:0.0007
[02:39:08.262] iteration:4405  t-loss:1.0935, loss-lb:0.5689, loss-ulb:0.3828, weight:1.37, lr:0.0007
[02:39:08.583] iteration:4406  t-loss:0.9546, loss-lb:0.1773, loss-ulb:0.5672, weight:1.37, lr:0.0007
[02:39:08.905] iteration:4407  t-loss:0.4074, loss-lb:0.2839, loss-ulb:0.0901, weight:1.37, lr:0.0007
[02:39:09.233] iteration:4408  t-loss:0.4229, loss-lb:0.3213, loss-ulb:0.0741, weight:1.37, lr:0.0007
[02:39:09.558] iteration:4409  t-loss:0.6433, loss-lb:0.3777, loss-ulb:0.1939, weight:1.37, lr:0.0007
[02:39:09.882] iteration:4410  t-loss:1.3953, loss-lb:0.2900, loss-ulb:0.8066, weight:1.37, lr:0.0007
[02:39:10.202] iteration:4411  t-loss:0.4923, loss-lb:0.2232, loss-ulb:0.1964, weight:1.37, lr:0.0007
[02:39:10.523] iteration:4412  t-loss:0.3350, loss-lb:0.1990, loss-ulb:0.0992, weight:1.37, lr:0.0007
[02:39:10.843] iteration:4413  t-loss:0.3931, loss-lb:0.1835, loss-ulb:0.1530, weight:1.37, lr:0.0007
[02:39:11.166] iteration:4414  t-loss:0.3686, loss-lb:0.2646, loss-ulb:0.0759, weight:1.37, lr:0.0007
[02:39:11.487] iteration:4415  t-loss:0.9799, loss-lb:0.2495, loss-ulb:0.5330, weight:1.37, lr:0.0007
[02:39:11.803] iteration:4416  t-loss:0.8130, loss-lb:0.4757, loss-ulb:0.2462, weight:1.37, lr:0.0007
[02:39:12.125] iteration:4417  t-loss:0.5335, loss-lb:0.2913, loss-ulb:0.1768, weight:1.37, lr:0.0007
[02:39:12.439] iteration:4418  t-loss:0.2965, loss-lb:0.1924, loss-ulb:0.0759, weight:1.37, lr:0.0007
[02:39:12.752] iteration:4419  t-loss:0.3668, loss-lb:0.1715, loss-ulb:0.1425, weight:1.37, lr:0.0007
[02:39:13.070] iteration:4420  t-loss:0.5413, loss-lb:0.2905, loss-ulb:0.1831, weight:1.37, lr:0.0007
[02:39:13.387] iteration:4421  t-loss:1.4311, loss-lb:0.3550, loss-ulb:0.7853, weight:1.37, lr:0.0007
[02:39:13.700] iteration:4422  t-loss:1.2350, loss-lb:0.2468, loss-ulb:0.7212, weight:1.37, lr:0.0007
[02:39:14.018] iteration:4423  t-loss:0.6367, loss-lb:0.3715, loss-ulb:0.1936, weight:1.37, lr:0.0007
[02:39:14.336] iteration:4424  t-loss:0.3686, loss-lb:0.2089, loss-ulb:0.1166, weight:1.37, lr:0.0007
[02:39:14.654] iteration:4425  t-loss:0.9562, loss-lb:0.7667, loss-ulb:0.1382, weight:1.37, lr:0.0007
[02:41:19.799] iteration 4425 : dice_score: 0.831756 best_dice: 0.833900
[02:41:19.799]  <<Test>> - Ep:176  - Dice-S/T:74.87/83.18, Best-S:82.79, Best-T:83.39
[02:41:19.799]           - AvgLoss(lb/ulb/all):0.30/0.28/0.68
[02:41:21.022] iteration:4426  t-loss:0.5667, loss-lb:0.3151, loss-ulb:0.1836, weight:1.37, lr:0.0007
[02:41:21.363] iteration:4427  t-loss:0.4741, loss-lb:0.3269, loss-ulb:0.1074, weight:1.37, lr:0.0007
[02:41:21.696] iteration:4428  t-loss:0.9208, loss-lb:0.4448, loss-ulb:0.3474, weight:1.37, lr:0.0007
[02:41:22.020] iteration:4429  t-loss:0.7535, loss-lb:0.5334, loss-ulb:0.1607, weight:1.37, lr:0.0007
[02:41:22.339] iteration:4430  t-loss:0.5029, loss-lb:0.2547, loss-ulb:0.1811, weight:1.37, lr:0.0007
[02:41:22.666] iteration:4431  t-loss:0.4614, loss-lb:0.1911, loss-ulb:0.1972, weight:1.37, lr:0.0007
[02:41:22.988] iteration:4432  t-loss:0.5878, loss-lb:0.1964, loss-ulb:0.2857, weight:1.37, lr:0.0007
[02:41:23.313] iteration:4433  t-loss:0.4960, loss-lb:0.2862, loss-ulb:0.1531, weight:1.37, lr:0.0007
[02:41:23.636] iteration:4434  t-loss:0.8325, loss-lb:0.2118, loss-ulb:0.4529, weight:1.37, lr:0.0007
[02:41:23.958] iteration:4435  t-loss:0.6172, loss-lb:0.3078, loss-ulb:0.2258, weight:1.37, lr:0.0007
[02:41:24.275] iteration:4436  t-loss:0.5443, loss-lb:0.4675, loss-ulb:0.0561, weight:1.37, lr:0.0007
[02:41:24.591] iteration:4437  t-loss:0.3927, loss-lb:0.2373, loss-ulb:0.1134, weight:1.37, lr:0.0007
[02:41:24.912] iteration:4438  t-loss:1.0713, loss-lb:0.4337, loss-ulb:0.4653, weight:1.37, lr:0.0007
[02:41:25.238] iteration:4439  t-loss:0.4755, loss-lb:0.1894, loss-ulb:0.2088, weight:1.37, lr:0.0007
[02:41:25.560] iteration:4440  t-loss:0.5394, loss-lb:0.2468, loss-ulb:0.2136, weight:1.37, lr:0.0007
[02:41:25.875] iteration:4441  t-loss:0.8521, loss-lb:0.2358, loss-ulb:0.4498, weight:1.37, lr:0.0007
[02:41:26.196] iteration:4442  t-loss:0.6134, loss-lb:0.3788, loss-ulb:0.1712, weight:1.37, lr:0.0007
[02:41:26.510] iteration:4443  t-loss:0.3808, loss-lb:0.3421, loss-ulb:0.0282, weight:1.37, lr:0.0007
[02:41:26.822] iteration:4444  t-loss:0.4385, loss-lb:0.3913, loss-ulb:0.0345, weight:1.37, lr:0.0007
[02:41:27.135] iteration:4445  t-loss:0.4743, loss-lb:0.1331, loss-ulb:0.2490, weight:1.37, lr:0.0007
[02:41:27.450] iteration:4446  t-loss:0.3925, loss-lb:0.2648, loss-ulb:0.0933, weight:1.37, lr:0.0007
[02:41:27.765] iteration:4447  t-loss:0.4714, loss-lb:0.2962, loss-ulb:0.1278, weight:1.37, lr:0.0007
[02:41:28.082] iteration:4448  t-loss:0.3712, loss-lb:0.1636, loss-ulb:0.1515, weight:1.37, lr:0.0007
[02:41:28.396] iteration:4449  t-loss:0.6050, loss-lb:0.3775, loss-ulb:0.1660, weight:1.37, lr:0.0007
[02:41:28.712] iteration:4450  t-loss:0.4706, loss-lb:0.2832, loss-ulb:0.1368, weight:1.37, lr:0.0007
[02:41:30.067] iteration:4451  t-loss:0.7174, loss-lb:0.3873, loss-ulb:0.2409, weight:1.37, lr:0.0007
[02:41:30.407] iteration:4452  t-loss:0.5969, loss-lb:0.3581, loss-ulb:0.1743, weight:1.37, lr:0.0007
[02:41:30.738] iteration:4453  t-loss:0.4213, loss-lb:0.2328, loss-ulb:0.1376, weight:1.37, lr:0.0007
[02:41:31.069] iteration:4454  t-loss:0.3682, loss-lb:0.3133, loss-ulb:0.0400, weight:1.37, lr:0.0007
[02:41:31.387] iteration:4455  t-loss:0.6280, loss-lb:0.3718, loss-ulb:0.1870, weight:1.37, lr:0.0007
[02:41:31.705] iteration:4456  t-loss:0.4128, loss-lb:0.3713, loss-ulb:0.0303, weight:1.37, lr:0.0007
[02:41:32.031] iteration:4457  t-loss:0.6858, loss-lb:0.3110, loss-ulb:0.2735, weight:1.37, lr:0.0007
[02:41:32.351] iteration:4458  t-loss:0.2189, loss-lb:0.1502, loss-ulb:0.0502, weight:1.37, lr:0.0007
[02:41:32.674] iteration:4459  t-loss:0.3668, loss-lb:0.2832, loss-ulb:0.0610, weight:1.37, lr:0.0007
[02:41:32.994] iteration:4460  t-loss:1.0127, loss-lb:0.5768, loss-ulb:0.3181, weight:1.37, lr:0.0007
[02:41:33.317] iteration:4461  t-loss:0.5277, loss-lb:0.3549, loss-ulb:0.1261, weight:1.37, lr:0.0007
[02:41:33.640] iteration:4462  t-loss:0.6141, loss-lb:0.2238, loss-ulb:0.2848, weight:1.37, lr:0.0007
[02:41:33.957] iteration:4463  t-loss:0.3963, loss-lb:0.1703, loss-ulb:0.1649, weight:1.37, lr:0.0007
[02:41:34.275] iteration:4464  t-loss:0.7808, loss-lb:0.1542, loss-ulb:0.4572, weight:1.37, lr:0.0007
[02:41:34.598] iteration:4465  t-loss:0.4808, loss-lb:0.3420, loss-ulb:0.1013, weight:1.37, lr:0.0007
[02:41:34.919] iteration:4466  t-loss:0.4240, loss-lb:0.2184, loss-ulb:0.1501, weight:1.37, lr:0.0007
[02:41:35.239] iteration:4467  t-loss:0.9897, loss-lb:0.2133, loss-ulb:0.5666, weight:1.37, lr:0.0007
[02:41:35.558] iteration:4468  t-loss:0.4349, loss-lb:0.2742, loss-ulb:0.1173, weight:1.37, lr:0.0007
[02:41:35.876] iteration:4469  t-loss:0.4088, loss-lb:0.3170, loss-ulb:0.0670, weight:1.37, lr:0.0007
[02:41:36.192] iteration:4470  t-loss:0.8522, loss-lb:0.1748, loss-ulb:0.4943, weight:1.37, lr:0.0007
[02:41:36.509] iteration:4471  t-loss:0.3712, loss-lb:0.1858, loss-ulb:0.1353, weight:1.37, lr:0.0007
[02:41:36.830] iteration:4472  t-loss:0.6276, loss-lb:0.4324, loss-ulb:0.1425, weight:1.37, lr:0.0007
[02:41:37.148] iteration:4473  t-loss:0.3774, loss-lb:0.1791, loss-ulb:0.1448, weight:1.37, lr:0.0007
[02:41:37.465] iteration:4474  t-loss:0.6366, loss-lb:0.4588, loss-ulb:0.1298, weight:1.37, lr:0.0007
[02:41:37.779] iteration:4475  t-loss:0.2445, loss-lb:0.2026, loss-ulb:0.0306, weight:1.37, lr:0.0007
[02:41:38.971] iteration:4476  t-loss:0.3813, loss-lb:0.1758, loss-ulb:0.1500, weight:1.37, lr:0.0007
[02:41:39.315] iteration:4477  t-loss:0.4653, loss-lb:0.2634, loss-ulb:0.1473, weight:1.37, lr:0.0007
[02:41:39.643] iteration:4478  t-loss:0.2740, loss-lb:0.2325, loss-ulb:0.0303, weight:1.37, lr:0.0007
[02:41:39.966] iteration:4479  t-loss:0.6633, loss-lb:0.3312, loss-ulb:0.2424, weight:1.37, lr:0.0007
[02:41:40.290] iteration:4480  t-loss:0.4807, loss-lb:0.2863, loss-ulb:0.1418, weight:1.37, lr:0.0007
[02:41:40.616] iteration:4481  t-loss:0.4468, loss-lb:0.2852, loss-ulb:0.1179, weight:1.37, lr:0.0007
[02:41:40.935] iteration:4482  t-loss:0.6534, loss-lb:0.3408, loss-ulb:0.2281, weight:1.37, lr:0.0007
[02:41:41.252] iteration:4483  t-loss:0.2786, loss-lb:0.1524, loss-ulb:0.0921, weight:1.37, lr:0.0007
[02:41:41.575] iteration:4484  t-loss:1.1123, loss-lb:0.4477, loss-ulb:0.4850, weight:1.37, lr:0.0007
[02:41:41.901] iteration:4485  t-loss:0.5200, loss-lb:0.3203, loss-ulb:0.1457, weight:1.37, lr:0.0007
[02:41:42.222] iteration:4486  t-loss:0.4561, loss-lb:0.2179, loss-ulb:0.1738, weight:1.37, lr:0.0007
[02:41:42.540] iteration:4487  t-loss:0.4106, loss-lb:0.3791, loss-ulb:0.0230, weight:1.37, lr:0.0007
[02:41:42.855] iteration:4488  t-loss:0.2991, loss-lb:0.2362, loss-ulb:0.0459, weight:1.37, lr:0.0007
[02:41:43.177] iteration:4489  t-loss:0.3649, loss-lb:0.2358, loss-ulb:0.0942, weight:1.37, lr:0.0007
[02:41:43.492] iteration:4490  t-loss:0.3732, loss-lb:0.2817, loss-ulb:0.0668, weight:1.37, lr:0.0007
[02:41:43.810] iteration:4491  t-loss:0.6347, loss-lb:0.2673, loss-ulb:0.2682, weight:1.37, lr:0.0007
[02:41:44.134] iteration:4492  t-loss:0.6131, loss-lb:0.5601, loss-ulb:0.0386, weight:1.37, lr:0.0007
[02:41:44.449] iteration:4493  t-loss:0.5761, loss-lb:0.2830, loss-ulb:0.2139, weight:1.37, lr:0.0007
[02:41:44.762] iteration:4494  t-loss:0.2220, loss-lb:0.1786, loss-ulb:0.0316, weight:1.37, lr:0.0007
[02:41:45.080] iteration:4495  t-loss:0.5679, loss-lb:0.2634, loss-ulb:0.2222, weight:1.37, lr:0.0007
[02:41:45.398] iteration:4496  t-loss:0.5916, loss-lb:0.4075, loss-ulb:0.1343, weight:1.37, lr:0.0007
[02:41:45.711] iteration:4497  t-loss:0.2258, loss-lb:0.1726, loss-ulb:0.0388, weight:1.37, lr:0.0007
[02:41:46.025] iteration:4498  t-loss:0.9651, loss-lb:0.2092, loss-ulb:0.5516, weight:1.37, lr:0.0007
[02:41:46.341] iteration:4499  t-loss:0.4902, loss-lb:0.1665, loss-ulb:0.2363, weight:1.37, lr:0.0007
[02:41:46.658] iteration:4500  t-loss:0.6404, loss-lb:0.3455, loss-ulb:0.2152, weight:1.37, lr:0.0007
[02:41:47.823] iteration:4501  t-loss:0.4411, loss-lb:0.1750, loss-ulb:0.1819, weight:1.46, lr:0.0007
[02:41:48.163] iteration:4502  t-loss:0.6359, loss-lb:0.3670, loss-ulb:0.1838, weight:1.46, lr:0.0007
[02:41:48.496] iteration:4503  t-loss:0.3683, loss-lb:0.1766, loss-ulb:0.1311, weight:1.46, lr:0.0007
[02:41:48.830] iteration:4504  t-loss:0.4842, loss-lb:0.2827, loss-ulb:0.1377, weight:1.46, lr:0.0007
[02:41:49.182] iteration:4505  t-loss:0.4980, loss-lb:0.2651, loss-ulb:0.1592, weight:1.46, lr:0.0007
[02:41:49.506] iteration:4506  t-loss:0.6037, loss-lb:0.3834, loss-ulb:0.1505, weight:1.46, lr:0.0007
[02:41:49.826] iteration:4507  t-loss:0.3274, loss-lb:0.2576, loss-ulb:0.0477, weight:1.46, lr:0.0007
[02:41:50.145] iteration:4508  t-loss:0.5595, loss-lb:0.2737, loss-ulb:0.1954, weight:1.46, lr:0.0007
[02:41:50.473] iteration:4509  t-loss:1.0118, loss-lb:0.1967, loss-ulb:0.5571, weight:1.46, lr:0.0007
[02:41:50.792] iteration:4510  t-loss:0.3573, loss-lb:0.1793, loss-ulb:0.1216, weight:1.46, lr:0.0007
[02:41:51.109] iteration:4511  t-loss:0.2936, loss-lb:0.1899, loss-ulb:0.0709, weight:1.46, lr:0.0007
[02:41:51.435] iteration:4512  t-loss:0.4436, loss-lb:0.3033, loss-ulb:0.0959, weight:1.46, lr:0.0007
[02:41:51.758] iteration:4513  t-loss:0.4687, loss-lb:0.3644, loss-ulb:0.0712, weight:1.46, lr:0.0007
[02:41:52.080] iteration:4514  t-loss:0.5901, loss-lb:0.2963, loss-ulb:0.2008, weight:1.46, lr:0.0007
[02:41:52.395] iteration:4515  t-loss:0.2926, loss-lb:0.2333, loss-ulb:0.0405, weight:1.46, lr:0.0007
[02:41:52.717] iteration:4516  t-loss:0.4364, loss-lb:0.2854, loss-ulb:0.1032, weight:1.46, lr:0.0007
[02:41:53.036] iteration:4517  t-loss:0.2975, loss-lb:0.1574, loss-ulb:0.0957, weight:1.46, lr:0.0007
[02:41:53.352] iteration:4518  t-loss:0.3627, loss-lb:0.3272, loss-ulb:0.0242, weight:1.46, lr:0.0007
[02:41:53.670] iteration:4519  t-loss:0.6724, loss-lb:0.3464, loss-ulb:0.2228, weight:1.46, lr:0.0007
[02:41:53.988] iteration:4520  t-loss:0.3889, loss-lb:0.1552, loss-ulb:0.1597, weight:1.46, lr:0.0007
[02:41:54.306] iteration:4521  t-loss:0.2850, loss-lb:0.1461, loss-ulb:0.0949, weight:1.46, lr:0.0007
[02:41:54.620] iteration:4522  t-loss:1.1110, loss-lb:0.2191, loss-ulb:0.6095, weight:1.46, lr:0.0007
[02:41:54.937] iteration:4523  t-loss:0.7734, loss-lb:0.2780, loss-ulb:0.3386, weight:1.46, lr:0.0007
[02:41:55.250] iteration:4524  t-loss:0.4881, loss-lb:0.3034, loss-ulb:0.1262, weight:1.46, lr:0.0007
[02:41:55.566] iteration:4525  t-loss:0.6044, loss-lb:0.4600, loss-ulb:0.0987, weight:1.46, lr:0.0007
[02:43:58.933] iteration 4525 : dice_score: 0.831717 best_dice: 0.833900
[02:43:58.934]  <<Test>> - Ep:180  - Dice-S/T:82.87/83.17, Best-S:82.87, Best-T:83.39
[02:43:58.934]           - AvgLoss(lb/ulb/all):0.26/0.17/0.52
[02:44:00.031] iteration:4526  t-loss:0.4253, loss-lb:0.2655, loss-ulb:0.1092, weight:1.46, lr:0.0007
[02:44:00.359] iteration:4527  t-loss:0.4638, loss-lb:0.2445, loss-ulb:0.1499, weight:1.46, lr:0.0007
[02:44:00.679] iteration:4528  t-loss:1.6247, loss-lb:0.2345, loss-ulb:0.9501, weight:1.46, lr:0.0007
[02:44:00.998] iteration:4529  t-loss:0.5292, loss-lb:0.3356, loss-ulb:0.1323, weight:1.46, lr:0.0007
[02:44:01.310] iteration:4530  t-loss:0.3291, loss-lb:0.1277, loss-ulb:0.1376, weight:1.46, lr:0.0007
[02:44:01.627] iteration:4531  t-loss:0.5491, loss-lb:0.2021, loss-ulb:0.2371, weight:1.46, lr:0.0007
[02:44:01.946] iteration:4532  t-loss:0.6095, loss-lb:0.3901, loss-ulb:0.1499, weight:1.46, lr:0.0007
[02:44:02.263] iteration:4533  t-loss:0.6932, loss-lb:0.1905, loss-ulb:0.3435, weight:1.46, lr:0.0007
[02:44:02.586] iteration:4534  t-loss:0.3318, loss-lb:0.2144, loss-ulb:0.0803, weight:1.46, lr:0.0007
[02:44:02.907] iteration:4535  t-loss:1.2590, loss-lb:0.2000, loss-ulb:0.7238, weight:1.46, lr:0.0007
[02:44:03.223] iteration:4536  t-loss:1.1218, loss-lb:0.2041, loss-ulb:0.6272, weight:1.46, lr:0.0007
[02:44:03.547] iteration:4537  t-loss:0.4945, loss-lb:0.2468, loss-ulb:0.1693, weight:1.46, lr:0.0007
[02:44:03.865] iteration:4538  t-loss:0.4417, loss-lb:0.1709, loss-ulb:0.1851, weight:1.46, lr:0.0007
[02:44:04.183] iteration:4539  t-loss:0.6357, loss-lb:0.2348, loss-ulb:0.2740, weight:1.46, lr:0.0007
[02:44:04.503] iteration:4540  t-loss:1.0848, loss-lb:0.3539, loss-ulb:0.4995, weight:1.46, lr:0.0007
[02:44:04.827] iteration:4541  t-loss:0.6460, loss-lb:0.4924, loss-ulb:0.1050, weight:1.46, lr:0.0007
[02:44:05.142] iteration:4542  t-loss:0.4840, loss-lb:0.1995, loss-ulb:0.1944, weight:1.46, lr:0.0007
[02:44:05.464] iteration:4543  t-loss:0.4351, loss-lb:0.2404, loss-ulb:0.1331, weight:1.46, lr:0.0007
[02:44:05.778] iteration:4544  t-loss:0.5006, loss-lb:0.1739, loss-ulb:0.2233, weight:1.46, lr:0.0007
[02:44:06.093] iteration:4545  t-loss:0.2589, loss-lb:0.1531, loss-ulb:0.0723, weight:1.46, lr:0.0007
[02:44:06.406] iteration:4546  t-loss:1.1437, loss-lb:0.3340, loss-ulb:0.5534, weight:1.46, lr:0.0007
[02:44:06.720] iteration:4547  t-loss:0.5677, loss-lb:0.2241, loss-ulb:0.2349, weight:1.46, lr:0.0007
[02:44:07.034] iteration:4548  t-loss:0.7256, loss-lb:0.3392, loss-ulb:0.2640, weight:1.46, lr:0.0007
[02:44:07.345] iteration:4549  t-loss:0.3153, loss-lb:0.2358, loss-ulb:0.0544, weight:1.46, lr:0.0007
[02:44:07.657] iteration:4550  t-loss:0.3196, loss-lb:0.2418, loss-ulb:0.0531, weight:1.46, lr:0.0007
[02:44:08.805] iteration:4551  t-loss:0.3156, loss-lb:0.1453, loss-ulb:0.1164, weight:1.46, lr:0.0007
[02:44:09.150] iteration:4552  t-loss:0.6466, loss-lb:0.4171, loss-ulb:0.1569, weight:1.46, lr:0.0007
[02:44:09.476] iteration:4553  t-loss:0.3182, loss-lb:0.1724, loss-ulb:0.0996, weight:1.46, lr:0.0007
[02:44:09.803] iteration:4554  t-loss:0.5896, loss-lb:0.4751, loss-ulb:0.0783, weight:1.46, lr:0.0007
[02:44:10.125] iteration:4555  t-loss:0.3886, loss-lb:0.2029, loss-ulb:0.1269, weight:1.46, lr:0.0007
[02:44:10.451] iteration:4556  t-loss:0.9161, loss-lb:0.2972, loss-ulb:0.4230, weight:1.46, lr:0.0007
[02:44:10.767] iteration:4557  t-loss:0.3126, loss-lb:0.1903, loss-ulb:0.0836, weight:1.46, lr:0.0007
[02:44:11.089] iteration:4558  t-loss:0.6269, loss-lb:0.3430, loss-ulb:0.1940, weight:1.46, lr:0.0007
[02:44:11.407] iteration:4559  t-loss:0.3601, loss-lb:0.2657, loss-ulb:0.0645, weight:1.46, lr:0.0007
[02:44:11.722] iteration:4560  t-loss:0.2757, loss-lb:0.1978, loss-ulb:0.0532, weight:1.46, lr:0.0007
[02:44:12.041] iteration:4561  t-loss:0.6862, loss-lb:0.4678, loss-ulb:0.1493, weight:1.46, lr:0.0007
[02:44:12.363] iteration:4562  t-loss:0.8173, loss-lb:0.5492, loss-ulb:0.1832, weight:1.46, lr:0.0007
[02:44:12.680] iteration:4563  t-loss:0.7875, loss-lb:0.5209, loss-ulb:0.1822, weight:1.46, lr:0.0007
[02:44:12.995] iteration:4564  t-loss:0.6203, loss-lb:0.3300, loss-ulb:0.1984, weight:1.46, lr:0.0007
[02:44:13.315] iteration:4565  t-loss:0.5518, loss-lb:0.2919, loss-ulb:0.1776, weight:1.46, lr:0.0007
[02:44:13.633] iteration:4566  t-loss:0.2484, loss-lb:0.1942, loss-ulb:0.0371, weight:1.46, lr:0.0007
[02:44:13.951] iteration:4567  t-loss:0.4697, loss-lb:0.3830, loss-ulb:0.0593, weight:1.46, lr:0.0007
[02:44:14.270] iteration:4568  t-loss:0.5013, loss-lb:0.2642, loss-ulb:0.1620, weight:1.46, lr:0.0007
[02:44:14.583] iteration:4569  t-loss:0.5149, loss-lb:0.4010, loss-ulb:0.0778, weight:1.46, lr:0.0007
[02:44:14.896] iteration:4570  t-loss:0.4556, loss-lb:0.3313, loss-ulb:0.0850, weight:1.46, lr:0.0007
[02:44:15.210] iteration:4571  t-loss:0.3941, loss-lb:0.1719, loss-ulb:0.1519, weight:1.46, lr:0.0007
[02:44:15.523] iteration:4572  t-loss:0.3111, loss-lb:0.2350, loss-ulb:0.0520, weight:1.46, lr:0.0007
[02:44:15.839] iteration:4573  t-loss:0.3422, loss-lb:0.1735, loss-ulb:0.1153, weight:1.46, lr:0.0007
[02:44:16.149] iteration:4574  t-loss:0.8245, loss-lb:0.1744, loss-ulb:0.4443, weight:1.46, lr:0.0007
[02:44:16.462] iteration:4575  t-loss:0.9840, loss-lb:0.3042, loss-ulb:0.4646, weight:1.46, lr:0.0007
[02:44:17.531] iteration:4576  t-loss:0.6497, loss-lb:0.2989, loss-ulb:0.2397, weight:1.46, lr:0.0007
[02:44:17.863] iteration:4577  t-loss:0.4875, loss-lb:0.1895, loss-ulb:0.2037, weight:1.46, lr:0.0007
[02:44:18.192] iteration:4578  t-loss:0.5509, loss-lb:0.2898, loss-ulb:0.1784, weight:1.46, lr:0.0007
[02:44:18.513] iteration:4579  t-loss:0.3965, loss-lb:0.3373, loss-ulb:0.0405, weight:1.46, lr:0.0007
[02:44:18.834] iteration:4580  t-loss:0.2328, loss-lb:0.1911, loss-ulb:0.0285, weight:1.46, lr:0.0007
[02:44:19.155] iteration:4581  t-loss:0.4033, loss-lb:0.2611, loss-ulb:0.0972, weight:1.46, lr:0.0007
[02:44:19.475] iteration:4582  t-loss:0.9062, loss-lb:0.4452, loss-ulb:0.3151, weight:1.46, lr:0.0007
[02:44:19.793] iteration:4583  t-loss:0.9905, loss-lb:0.1930, loss-ulb:0.5450, weight:1.46, lr:0.0007
[02:44:20.117] iteration:4584  t-loss:0.8035, loss-lb:0.2869, loss-ulb:0.3530, weight:1.46, lr:0.0007
[02:44:20.433] iteration:4585  t-loss:0.3250, loss-lb:0.2547, loss-ulb:0.0481, weight:1.46, lr:0.0007
[02:44:20.753] iteration:4586  t-loss:0.4691, loss-lb:0.4325, loss-ulb:0.0250, weight:1.46, lr:0.0007
[02:44:21.073] iteration:4587  t-loss:0.3080, loss-lb:0.1663, loss-ulb:0.0968, weight:1.46, lr:0.0007
[02:44:21.393] iteration:4588  t-loss:0.5694, loss-lb:0.2190, loss-ulb:0.2395, weight:1.46, lr:0.0007
[02:44:21.711] iteration:4589  t-loss:0.7026, loss-lb:0.5025, loss-ulb:0.1368, weight:1.46, lr:0.0007
[02:44:22.031] iteration:4590  t-loss:0.9470, loss-lb:0.2255, loss-ulb:0.4931, weight:1.46, lr:0.0007
[02:44:22.348] iteration:4591  t-loss:1.1427, loss-lb:0.5868, loss-ulb:0.3799, weight:1.46, lr:0.0007
[02:44:22.666] iteration:4592  t-loss:0.4108, loss-lb:0.2395, loss-ulb:0.1171, weight:1.46, lr:0.0007
[02:44:22.984] iteration:4593  t-loss:1.1475, loss-lb:0.1939, loss-ulb:0.6517, weight:1.46, lr:0.0007
[02:44:23.299] iteration:4594  t-loss:0.8146, loss-lb:0.1835, loss-ulb:0.4313, weight:1.46, lr:0.0007
[02:44:23.613] iteration:4595  t-loss:0.3690, loss-lb:0.3299, loss-ulb:0.0267, weight:1.46, lr:0.0007
[02:44:23.929] iteration:4596  t-loss:0.3648, loss-lb:0.2007, loss-ulb:0.1122, weight:1.46, lr:0.0007
[02:44:24.244] iteration:4597  t-loss:0.5242, loss-lb:0.2763, loss-ulb:0.1694, weight:1.46, lr:0.0007
[02:44:24.561] iteration:4598  t-loss:0.6537, loss-lb:0.2313, loss-ulb:0.2887, weight:1.46, lr:0.0007
[02:44:24.878] iteration:4599  t-loss:0.4252, loss-lb:0.3012, loss-ulb:0.0847, weight:1.46, lr:0.0007
[02:44:25.194] iteration:4600  t-loss:1.1543, loss-lb:0.3129, loss-ulb:0.5750, weight:1.46, lr:0.0007
[02:44:26.433] iteration:4601  t-loss:0.3615, loss-lb:0.1706, loss-ulb:0.1305, weight:1.46, lr:0.0007
[02:44:26.777] iteration:4602  t-loss:0.3289, loss-lb:0.1690, loss-ulb:0.1093, weight:1.46, lr:0.0007
[02:44:27.103] iteration:4603  t-loss:0.5508, loss-lb:0.2812, loss-ulb:0.1843, weight:1.46, lr:0.0007
[02:44:27.425] iteration:4604  t-loss:0.5075, loss-lb:0.1369, loss-ulb:0.2533, weight:1.46, lr:0.0007
[02:44:27.745] iteration:4605  t-loss:0.6282, loss-lb:0.1947, loss-ulb:0.2963, weight:1.46, lr:0.0007
[02:44:28.066] iteration:4606  t-loss:0.6100, loss-lb:0.4098, loss-ulb:0.1368, weight:1.46, lr:0.0007
[02:44:28.384] iteration:4607  t-loss:0.2599, loss-lb:0.2227, loss-ulb:0.0254, weight:1.46, lr:0.0007
[02:44:28.713] iteration:4608  t-loss:0.4362, loss-lb:0.1812, loss-ulb:0.1743, weight:1.46, lr:0.0007
[02:44:29.035] iteration:4609  t-loss:0.4473, loss-lb:0.2549, loss-ulb:0.1315, weight:1.46, lr:0.0007
[02:44:29.356] iteration:4610  t-loss:0.3638, loss-lb:0.1650, loss-ulb:0.1359, weight:1.46, lr:0.0007
[02:44:29.671] iteration:4611  t-loss:0.7079, loss-lb:0.2273, loss-ulb:0.3285, weight:1.46, lr:0.0007
[02:44:29.986] iteration:4612  t-loss:0.2461, loss-lb:0.1819, loss-ulb:0.0439, weight:1.46, lr:0.0007
[02:44:30.309] iteration:4613  t-loss:0.8635, loss-lb:0.3756, loss-ulb:0.3334, weight:1.46, lr:0.0007
[02:44:30.626] iteration:4614  t-loss:0.3712, loss-lb:0.1692, loss-ulb:0.1381, weight:1.46, lr:0.0007
[02:44:30.943] iteration:4615  t-loss:0.4383, loss-lb:0.1846, loss-ulb:0.1734, weight:1.46, lr:0.0007
[02:44:31.259] iteration:4616  t-loss:1.0705, loss-lb:0.3345, loss-ulb:0.5030, weight:1.46, lr:0.0007
[02:44:31.577] iteration:4617  t-loss:0.5331, loss-lb:0.4618, loss-ulb:0.0487, weight:1.46, lr:0.0007
[02:44:31.889] iteration:4618  t-loss:0.7036, loss-lb:0.2095, loss-ulb:0.3377, weight:1.46, lr:0.0007
[02:44:32.202] iteration:4619  t-loss:0.4430, loss-lb:0.2267, loss-ulb:0.1478, weight:1.46, lr:0.0007
[02:44:32.515] iteration:4620  t-loss:0.6816, loss-lb:0.5580, loss-ulb:0.0845, weight:1.46, lr:0.0007
[02:44:32.830] iteration:4621  t-loss:0.4834, loss-lb:0.1557, loss-ulb:0.2239, weight:1.46, lr:0.0007
[02:44:33.145] iteration:4622  t-loss:0.4170, loss-lb:0.2910, loss-ulb:0.0862, weight:1.46, lr:0.0007
[02:44:33.461] iteration:4623  t-loss:0.8123, loss-lb:0.4206, loss-ulb:0.2677, weight:1.46, lr:0.0007
[02:44:33.777] iteration:4624  t-loss:0.5767, loss-lb:0.3750, loss-ulb:0.1378, weight:1.46, lr:0.0007
[02:44:34.093] iteration:4625  t-loss:0.5345, loss-lb:0.3569, loss-ulb:0.1214, weight:1.46, lr:0.0007
[02:46:27.647] iteration 4625 : dice_score: 0.833063 best_dice: 0.833900
[02:46:27.647]  <<Test>> - Ep:184  - Dice-S/T:71.85/83.31, Best-S:82.87, Best-T:83.39
[02:46:27.647]           - AvgLoss(lb/ulb/all):0.27/0.18/0.55
[02:46:28.998] iteration:4626  t-loss:1.4197, loss-lb:0.3980, loss-ulb:0.6983, weight:1.46, lr:0.0007
[02:46:29.326] iteration:4627  t-loss:0.5695, loss-lb:0.2635, loss-ulb:0.2091, weight:1.46, lr:0.0007
[02:46:29.661] iteration:4628  t-loss:0.5429, loss-lb:0.2664, loss-ulb:0.1890, weight:1.46, lr:0.0007
[02:46:29.985] iteration:4629  t-loss:0.3865, loss-lb:0.2447, loss-ulb:0.0969, weight:1.46, lr:0.0007
[02:46:30.300] iteration:4630  t-loss:0.3355, loss-lb:0.2391, loss-ulb:0.0659, weight:1.46, lr:0.0007
[02:46:30.617] iteration:4631  t-loss:0.4150, loss-lb:0.2151, loss-ulb:0.1366, weight:1.46, lr:0.0007
[02:46:30.945] iteration:4632  t-loss:0.8837, loss-lb:0.4492, loss-ulb:0.2969, weight:1.46, lr:0.0007
[02:46:31.266] iteration:4633  t-loss:0.5327, loss-lb:0.3446, loss-ulb:0.1285, weight:1.46, lr:0.0007
[02:46:31.581] iteration:4634  t-loss:1.0261, loss-lb:0.3981, loss-ulb:0.4292, weight:1.46, lr:0.0007
[02:46:31.904] iteration:4635  t-loss:0.4180, loss-lb:0.3746, loss-ulb:0.0297, weight:1.46, lr:0.0007
[02:46:32.230] iteration:4636  t-loss:0.6862, loss-lb:0.4890, loss-ulb:0.1348, weight:1.46, lr:0.0007
[02:46:32.550] iteration:4637  t-loss:0.5733, loss-lb:0.3660, loss-ulb:0.1417, weight:1.46, lr:0.0007
[02:46:32.861] iteration:4638  t-loss:0.3210, loss-lb:0.2555, loss-ulb:0.0448, weight:1.46, lr:0.0007
[02:46:33.184] iteration:4639  t-loss:0.6212, loss-lb:0.3693, loss-ulb:0.1721, weight:1.46, lr:0.0007
[02:46:33.502] iteration:4640  t-loss:1.2230, loss-lb:0.2099, loss-ulb:0.6924, weight:1.46, lr:0.0007
[02:46:33.825] iteration:4641  t-loss:0.4544, loss-lb:0.2572, loss-ulb:0.1348, weight:1.46, lr:0.0007
[02:46:34.141] iteration:4642  t-loss:0.3210, loss-lb:0.1988, loss-ulb:0.0835, weight:1.46, lr:0.0007
[02:46:34.453] iteration:4643  t-loss:0.3837, loss-lb:0.1909, loss-ulb:0.1317, weight:1.46, lr:0.0007
[02:46:34.768] iteration:4644  t-loss:0.7227, loss-lb:0.3185, loss-ulb:0.2763, weight:1.46, lr:0.0007
[02:46:35.083] iteration:4645  t-loss:0.7223, loss-lb:0.4340, loss-ulb:0.1971, weight:1.46, lr:0.0007
[02:46:35.395] iteration:4646  t-loss:0.5481, loss-lb:0.2001, loss-ulb:0.2378, weight:1.46, lr:0.0007
[02:46:35.709] iteration:4647  t-loss:0.5332, loss-lb:0.1921, loss-ulb:0.2331, weight:1.46, lr:0.0007
[02:46:36.020] iteration:4648  t-loss:0.4314, loss-lb:0.2200, loss-ulb:0.1445, weight:1.46, lr:0.0007
[02:46:36.331] iteration:4649  t-loss:0.2636, loss-lb:0.2319, loss-ulb:0.0216, weight:1.46, lr:0.0007
[02:46:36.642] iteration:4650  t-loss:0.7620, loss-lb:0.2208, loss-ulb:0.3699, weight:1.46, lr:0.0007
[02:46:38.087] iteration:4651  t-loss:1.3056, loss-lb:0.4208, loss-ulb:0.5698, weight:1.55, lr:0.0007
[02:46:38.410] iteration:4652  t-loss:0.4115, loss-lb:0.1481, loss-ulb:0.1696, weight:1.55, lr:0.0007
[02:46:38.732] iteration:4653  t-loss:0.6612, loss-lb:0.4343, loss-ulb:0.1461, weight:1.55, lr:0.0007
[02:46:39.057] iteration:4654  t-loss:0.4866, loss-lb:0.2796, loss-ulb:0.1333, weight:1.55, lr:0.0007
[02:46:39.375] iteration:4655  t-loss:0.2738, loss-lb:0.1239, loss-ulb:0.0966, weight:1.55, lr:0.0007
[02:46:39.696] iteration:4656  t-loss:0.6517, loss-lb:0.4026, loss-ulb:0.1605, weight:1.55, lr:0.0007
[02:46:40.014] iteration:4657  t-loss:0.2395, loss-lb:0.1918, loss-ulb:0.0307, weight:1.55, lr:0.0007
[02:46:40.340] iteration:4658  t-loss:0.4876, loss-lb:0.2987, loss-ulb:0.1216, weight:1.55, lr:0.0007
[02:46:40.655] iteration:4659  t-loss:0.3022, loss-lb:0.1862, loss-ulb:0.0747, weight:1.55, lr:0.0007
[02:46:40.969] iteration:4660  t-loss:0.3660, loss-lb:0.2481, loss-ulb:0.0760, weight:1.55, lr:0.0007
[02:46:41.286] iteration:4661  t-loss:0.3228, loss-lb:0.1831, loss-ulb:0.0899, weight:1.55, lr:0.0007
[02:46:41.603] iteration:4662  t-loss:0.2362, loss-lb:0.1340, loss-ulb:0.0658, weight:1.55, lr:0.0007
[02:46:41.923] iteration:4663  t-loss:0.4557, loss-lb:0.2592, loss-ulb:0.1266, weight:1.55, lr:0.0007
[02:46:42.244] iteration:4664  t-loss:0.5236, loss-lb:0.3633, loss-ulb:0.1032, weight:1.55, lr:0.0007
[02:46:42.560] iteration:4665  t-loss:0.2554, loss-lb:0.1485, loss-ulb:0.0688, weight:1.55, lr:0.0007
[02:46:42.878] iteration:4666  t-loss:0.3705, loss-lb:0.2647, loss-ulb:0.0681, weight:1.55, lr:0.0007
[02:46:43.199] iteration:4667  t-loss:0.9375, loss-lb:0.4861, loss-ulb:0.2907, weight:1.55, lr:0.0007
[02:46:43.515] iteration:4668  t-loss:0.4303, loss-lb:0.2122, loss-ulb:0.1404, weight:1.55, lr:0.0007
[02:46:43.829] iteration:4669  t-loss:0.3631, loss-lb:0.1379, loss-ulb:0.1450, weight:1.55, lr:0.0007
[02:46:44.145] iteration:4670  t-loss:0.4633, loss-lb:0.3136, loss-ulb:0.0964, weight:1.55, lr:0.0007
[02:46:44.457] iteration:4671  t-loss:0.3825, loss-lb:0.3326, loss-ulb:0.0321, weight:1.55, lr:0.0007
[02:46:44.769] iteration:4672  t-loss:0.3892, loss-lb:0.1360, loss-ulb:0.1631, weight:1.55, lr:0.0007
[02:46:45.083] iteration:4673  t-loss:0.5994, loss-lb:0.3722, loss-ulb:0.1463, weight:1.55, lr:0.0007
[02:46:45.399] iteration:4674  t-loss:0.4968, loss-lb:0.2794, loss-ulb:0.1400, weight:1.55, lr:0.0007
[02:46:45.714] iteration:4675  t-loss:1.7521, loss-lb:0.2073, loss-ulb:0.9949, weight:1.55, lr:0.0007
[02:46:47.047] iteration:4676  t-loss:0.8352, loss-lb:0.2947, loss-ulb:0.3481, weight:1.55, lr:0.0007
[02:46:47.379] iteration:4677  t-loss:0.5969, loss-lb:0.3573, loss-ulb:0.1543, weight:1.55, lr:0.0007
[02:46:47.708] iteration:4678  t-loss:0.4805, loss-lb:0.2874, loss-ulb:0.1243, weight:1.55, lr:0.0007
[02:46:48.027] iteration:4679  t-loss:0.5380, loss-lb:0.2688, loss-ulb:0.1733, weight:1.55, lr:0.0007
[02:46:48.341] iteration:4680  t-loss:0.3255, loss-lb:0.1954, loss-ulb:0.0838, weight:1.55, lr:0.0007
[02:46:48.660] iteration:4681  t-loss:0.3758, loss-lb:0.1865, loss-ulb:0.1219, weight:1.55, lr:0.0007
[02:46:48.978] iteration:4682  t-loss:0.4373, loss-lb:0.3227, loss-ulb:0.0738, weight:1.55, lr:0.0007
[02:46:49.297] iteration:4683  t-loss:0.4760, loss-lb:0.3038, loss-ulb:0.1109, weight:1.55, lr:0.0007
[02:46:49.619] iteration:4684  t-loss:0.7137, loss-lb:0.4350, loss-ulb:0.1795, weight:1.55, lr:0.0007
[02:46:49.938] iteration:4685  t-loss:1.4076, loss-lb:0.3331, loss-ulb:0.6920, weight:1.55, lr:0.0007
[02:46:50.258] iteration:4686  t-loss:0.8068, loss-lb:0.1739, loss-ulb:0.4076, weight:1.55, lr:0.0007
[02:46:50.577] iteration:4687  t-loss:0.3472, loss-lb:0.2769, loss-ulb:0.0452, weight:1.55, lr:0.0007
[02:46:50.895] iteration:4688  t-loss:0.4216, loss-lb:0.1788, loss-ulb:0.1564, weight:1.55, lr:0.0007
[02:46:51.213] iteration:4689  t-loss:0.5109, loss-lb:0.2348, loss-ulb:0.1778, weight:1.55, lr:0.0007
[02:46:51.530] iteration:4690  t-loss:0.5071, loss-lb:0.4347, loss-ulb:0.0467, weight:1.55, lr:0.0007
[02:46:51.849] iteration:4691  t-loss:0.6141, loss-lb:0.3809, loss-ulb:0.1502, weight:1.55, lr:0.0007
[02:46:52.168] iteration:4692  t-loss:0.6426, loss-lb:0.3779, loss-ulb:0.1705, weight:1.55, lr:0.0007
[02:46:52.483] iteration:4693  t-loss:0.4413, loss-lb:0.1580, loss-ulb:0.1824, weight:1.55, lr:0.0007
[02:46:52.798] iteration:4694  t-loss:0.4508, loss-lb:0.1750, loss-ulb:0.1776, weight:1.55, lr:0.0007
[02:46:53.113] iteration:4695  t-loss:0.6643, loss-lb:0.2691, loss-ulb:0.2545, weight:1.55, lr:0.0007
[02:46:53.425] iteration:4696  t-loss:0.3202, loss-lb:0.2569, loss-ulb:0.0408, weight:1.55, lr:0.0007
[02:46:53.740] iteration:4697  t-loss:0.5743, loss-lb:0.5214, loss-ulb:0.0341, weight:1.55, lr:0.0007
[02:46:54.056] iteration:4698  t-loss:1.0524, loss-lb:0.4867, loss-ulb:0.3643, weight:1.55, lr:0.0007
[02:46:54.368] iteration:4699  t-loss:0.2154, loss-lb:0.1696, loss-ulb:0.0295, weight:1.55, lr:0.0007
[02:46:54.685] iteration:4700  t-loss:0.2587, loss-lb:0.1485, loss-ulb:0.0709, weight:1.55, lr:0.0007
[02:46:55.883] iteration:4701  t-loss:0.4193, loss-lb:0.2064, loss-ulb:0.1371, weight:1.55, lr:0.0007
[02:46:56.220] iteration:4702  t-loss:0.3390, loss-lb:0.1747, loss-ulb:0.1058, weight:1.55, lr:0.0007
[02:46:56.557] iteration:4703  t-loss:0.4940, loss-lb:0.2625, loss-ulb:0.1491, weight:1.55, lr:0.0007
[02:46:56.883] iteration:4704  t-loss:0.9470, loss-lb:0.2668, loss-ulb:0.4381, weight:1.55, lr:0.0007
[02:46:57.203] iteration:4705  t-loss:1.4072, loss-lb:0.2964, loss-ulb:0.7154, weight:1.55, lr:0.0007
[02:46:57.522] iteration:4706  t-loss:0.5470, loss-lb:0.2672, loss-ulb:0.1802, weight:1.55, lr:0.0007
[02:46:57.841] iteration:4707  t-loss:0.5162, loss-lb:0.3715, loss-ulb:0.0932, weight:1.55, lr:0.0007
[02:46:58.158] iteration:4708  t-loss:0.3111, loss-lb:0.1595, loss-ulb:0.0976, weight:1.55, lr:0.0007
[02:46:58.476] iteration:4709  t-loss:0.5593, loss-lb:0.3684, loss-ulb:0.1229, weight:1.55, lr:0.0007
[02:46:58.791] iteration:4710  t-loss:0.5381, loss-lb:0.4273, loss-ulb:0.0713, weight:1.55, lr:0.0007
[02:46:59.111] iteration:4711  t-loss:0.4994, loss-lb:0.2621, loss-ulb:0.1528, weight:1.55, lr:0.0007
[02:46:59.429] iteration:4712  t-loss:0.4403, loss-lb:0.2546, loss-ulb:0.1196, weight:1.55, lr:0.0007
[02:46:59.745] iteration:4713  t-loss:0.3245, loss-lb:0.2950, loss-ulb:0.0190, weight:1.55, lr:0.0007
[02:47:00.058] iteration:4714  t-loss:1.0800, loss-lb:0.2425, loss-ulb:0.5394, weight:1.55, lr:0.0007
[02:47:00.378] iteration:4715  t-loss:0.2893, loss-lb:0.1623, loss-ulb:0.0818, weight:1.55, lr:0.0007
[02:47:00.694] iteration:4716  t-loss:0.5264, loss-lb:0.3591, loss-ulb:0.1078, weight:1.55, lr:0.0007
[02:47:01.013] iteration:4717  t-loss:0.5106, loss-lb:0.3313, loss-ulb:0.1155, weight:1.55, lr:0.0007
[02:47:01.325] iteration:4718  t-loss:0.3712, loss-lb:0.2362, loss-ulb:0.0869, weight:1.55, lr:0.0007
[02:47:01.639] iteration:4719  t-loss:0.5895, loss-lb:0.2527, loss-ulb:0.2169, weight:1.55, lr:0.0007
[02:47:01.957] iteration:4720  t-loss:0.9410, loss-lb:0.3055, loss-ulb:0.4092, weight:1.55, lr:0.0007
[02:47:02.275] iteration:4721  t-loss:0.3297, loss-lb:0.2701, loss-ulb:0.0383, weight:1.55, lr:0.0007
[02:47:02.594] iteration:4722  t-loss:0.4971, loss-lb:0.3356, loss-ulb:0.1040, weight:1.55, lr:0.0007
[02:47:02.910] iteration:4723  t-loss:1.1938, loss-lb:0.4790, loss-ulb:0.4603, weight:1.55, lr:0.0007
[02:47:03.224] iteration:4724  t-loss:0.3886, loss-lb:0.2545, loss-ulb:0.0864, weight:1.55, lr:0.0007
[02:47:03.540] iteration:4725  t-loss:0.5573, loss-lb:0.4948, loss-ulb:0.0402, weight:1.55, lr:0.0007
[02:48:55.225] iteration 4725 : dice_score: 0.831377 best_dice: 0.833900
[02:48:55.225]  <<Test>> - Ep:188  - Dice-S/T:81.43/83.14, Best-S:82.87, Best-T:83.39
[02:48:55.225]           - AvgLoss(lb/ulb/all):0.29/0.16/0.55
[02:48:56.615] iteration:4726  t-loss:0.9161, loss-lb:0.1269, loss-ulb:0.5082, weight:1.55, lr:0.0007
[02:48:56.969] iteration:4727  t-loss:0.6018, loss-lb:0.4201, loss-ulb:0.1170, weight:1.55, lr:0.0007
[02:48:57.301] iteration:4728  t-loss:0.4770, loss-lb:0.1616, loss-ulb:0.2031, weight:1.55, lr:0.0007
[02:48:57.618] iteration:4729  t-loss:0.3027, loss-lb:0.2045, loss-ulb:0.0633, weight:1.55, lr:0.0007
[02:48:57.938] iteration:4730  t-loss:0.4119, loss-lb:0.3179, loss-ulb:0.0605, weight:1.55, lr:0.0007
[02:48:58.255] iteration:4731  t-loss:0.3727, loss-lb:0.2235, loss-ulb:0.0961, weight:1.55, lr:0.0007
[02:48:58.571] iteration:4732  t-loss:0.4516, loss-lb:0.2404, loss-ulb:0.1360, weight:1.55, lr:0.0007
[02:48:58.884] iteration:4733  t-loss:0.4470, loss-lb:0.1871, loss-ulb:0.1674, weight:1.55, lr:0.0007
[02:48:59.196] iteration:4734  t-loss:1.3361, loss-lb:0.5506, loss-ulb:0.5059, weight:1.55, lr:0.0007
[02:48:59.511] iteration:4735  t-loss:0.3077, loss-lb:0.1712, loss-ulb:0.0879, weight:1.55, lr:0.0007
[02:48:59.824] iteration:4736  t-loss:0.3676, loss-lb:0.1478, loss-ulb:0.1415, weight:1.55, lr:0.0007
[02:49:00.140] iteration:4737  t-loss:0.3107, loss-lb:0.2250, loss-ulb:0.0552, weight:1.55, lr:0.0007
[02:49:00.458] iteration:4738  t-loss:0.4412, loss-lb:0.2807, loss-ulb:0.1034, weight:1.55, lr:0.0007
[02:49:00.778] iteration:4739  t-loss:0.3241, loss-lb:0.2794, loss-ulb:0.0288, weight:1.55, lr:0.0007
[02:49:01.102] iteration:4740  t-loss:0.4928, loss-lb:0.2203, loss-ulb:0.1755, weight:1.55, lr:0.0007
[02:49:01.422] iteration:4741  t-loss:0.3181, loss-lb:0.2860, loss-ulb:0.0207, weight:1.55, lr:0.0007
[02:49:01.740] iteration:4742  t-loss:0.2794, loss-lb:0.1891, loss-ulb:0.0582, weight:1.55, lr:0.0007
[02:49:02.057] iteration:4743  t-loss:0.3174, loss-lb:0.2790, loss-ulb:0.0247, weight:1.55, lr:0.0007
[02:49:02.372] iteration:4744  t-loss:0.3765, loss-lb:0.1924, loss-ulb:0.1186, weight:1.55, lr:0.0007
[02:49:02.684] iteration:4745  t-loss:0.7650, loss-lb:0.1759, loss-ulb:0.3794, weight:1.55, lr:0.0007
[02:49:02.997] iteration:4746  t-loss:0.3973, loss-lb:0.2155, loss-ulb:0.1171, weight:1.55, lr:0.0007
[02:49:03.309] iteration:4747  t-loss:0.5702, loss-lb:0.2158, loss-ulb:0.2282, weight:1.55, lr:0.0007
[02:49:03.623] iteration:4748  t-loss:0.7943, loss-lb:0.2944, loss-ulb:0.3220, weight:1.55, lr:0.0007
[02:49:03.943] iteration:4749  t-loss:0.2173, loss-lb:0.1434, loss-ulb:0.0476, weight:1.55, lr:0.0007
[02:49:04.260] iteration:4750  t-loss:0.4402, loss-lb:0.2683, loss-ulb:0.1108, weight:1.55, lr:0.0007
[02:49:05.539] iteration:4751  t-loss:0.4115, loss-lb:0.2066, loss-ulb:0.1319, weight:1.55, lr:0.0007
[02:49:05.871] iteration:4752  t-loss:0.2775, loss-lb:0.1773, loss-ulb:0.0646, weight:1.55, lr:0.0007
[02:49:06.201] iteration:4753  t-loss:0.5135, loss-lb:0.3002, loss-ulb:0.1374, weight:1.55, lr:0.0007
[02:49:06.522] iteration:4754  t-loss:0.6431, loss-lb:0.1577, loss-ulb:0.3126, weight:1.55, lr:0.0007
[02:49:06.858] iteration:4755  t-loss:0.4916, loss-lb:0.2840, loss-ulb:0.1337, weight:1.55, lr:0.0007
[02:49:07.199] iteration:4756  t-loss:0.2742, loss-lb:0.2454, loss-ulb:0.0186, weight:1.55, lr:0.0007
[02:49:07.520] iteration:4757  t-loss:0.3095, loss-lb:0.2672, loss-ulb:0.0272, weight:1.55, lr:0.0007
[02:49:07.839] iteration:4758  t-loss:0.3921, loss-lb:0.2626, loss-ulb:0.0834, weight:1.55, lr:0.0007
[02:49:08.159] iteration:4759  t-loss:0.4707, loss-lb:0.3739, loss-ulb:0.0623, weight:1.55, lr:0.0007
[02:49:08.474] iteration:4760  t-loss:0.3943, loss-lb:0.1918, loss-ulb:0.1304, weight:1.55, lr:0.0007
[02:49:08.791] iteration:4761  t-loss:1.0120, loss-lb:0.5524, loss-ulb:0.2960, weight:1.55, lr:0.0007
[02:49:09.117] iteration:4762  t-loss:0.4071, loss-lb:0.2600, loss-ulb:0.0947, weight:1.55, lr:0.0007
[02:49:09.439] iteration:4763  t-loss:0.3096, loss-lb:0.1984, loss-ulb:0.0716, weight:1.55, lr:0.0007
[02:49:09.773] iteration:4764  t-loss:0.4818, loss-lb:0.3158, loss-ulb:0.1069, weight:1.55, lr:0.0007
[02:49:10.095] iteration:4765  t-loss:0.5488, loss-lb:0.2441, loss-ulb:0.1962, weight:1.55, lr:0.0007
[02:49:10.437] iteration:4766  t-loss:0.4384, loss-lb:0.2522, loss-ulb:0.1199, weight:1.55, lr:0.0007
[02:49:10.758] iteration:4767  t-loss:0.7577, loss-lb:0.1972, loss-ulb:0.3610, weight:1.55, lr:0.0007
[02:49:11.082] iteration:4768  t-loss:0.9622, loss-lb:0.1708, loss-ulb:0.5097, weight:1.55, lr:0.0007
[02:49:11.404] iteration:4769  t-loss:0.5501, loss-lb:0.4098, loss-ulb:0.0903, weight:1.55, lr:0.0007
[02:49:11.718] iteration:4770  t-loss:0.2825, loss-lb:0.2214, loss-ulb:0.0394, weight:1.55, lr:0.0007
[02:49:12.032] iteration:4771  t-loss:1.5304, loss-lb:0.4753, loss-ulb:0.6795, weight:1.55, lr:0.0007
[02:49:12.345] iteration:4772  t-loss:0.5481, loss-lb:0.1870, loss-ulb:0.2325, weight:1.55, lr:0.0007
[02:49:12.662] iteration:4773  t-loss:0.5071, loss-lb:0.3211, loss-ulb:0.1198, weight:1.55, lr:0.0007
[02:49:12.979] iteration:4774  t-loss:0.2832, loss-lb:0.1553, loss-ulb:0.0824, weight:1.55, lr:0.0007
[02:49:13.293] iteration:4775  t-loss:0.4571, loss-lb:0.1851, loss-ulb:0.1752, weight:1.55, lr:0.0007
[02:49:14.537] iteration:4776  t-loss:1.1737, loss-lb:0.3510, loss-ulb:0.5298, weight:1.55, lr:0.0007
[02:49:14.869] iteration:4777  t-loss:0.9818, loss-lb:0.2086, loss-ulb:0.4980, weight:1.55, lr:0.0007
[02:49:15.202] iteration:4778  t-loss:0.4907, loss-lb:0.2620, loss-ulb:0.1473, weight:1.55, lr:0.0007
[02:49:15.540] iteration:4779  t-loss:0.4466, loss-lb:0.2518, loss-ulb:0.1255, weight:1.55, lr:0.0007
[02:49:15.860] iteration:4780  t-loss:0.6622, loss-lb:0.2978, loss-ulb:0.2347, weight:1.55, lr:0.0007
[02:49:16.172] iteration:4781  t-loss:0.3079, loss-lb:0.1776, loss-ulb:0.0839, weight:1.55, lr:0.0007
[02:49:16.489] iteration:4782  t-loss:0.6805, loss-lb:0.1965, loss-ulb:0.3117, weight:1.55, lr:0.0007
[02:49:16.805] iteration:4783  t-loss:0.5183, loss-lb:0.4190, loss-ulb:0.0640, weight:1.55, lr:0.0007
[02:49:17.138] iteration:4784  t-loss:1.1229, loss-lb:0.2151, loss-ulb:0.5847, weight:1.55, lr:0.0007
[02:49:17.460] iteration:4785  t-loss:0.3084, loss-lb:0.2023, loss-ulb:0.0683, weight:1.55, lr:0.0007
[02:49:17.798] iteration:4786  t-loss:0.8144, loss-lb:0.2350, loss-ulb:0.3731, weight:1.55, lr:0.0007
[02:49:18.149] iteration:4787  t-loss:0.7671, loss-lb:0.3593, loss-ulb:0.2627, weight:1.55, lr:0.0007
[02:49:18.485] iteration:4788  t-loss:0.6652, loss-lb:0.4573, loss-ulb:0.1339, weight:1.55, lr:0.0007
[02:49:18.816] iteration:4789  t-loss:0.3687, loss-lb:0.2644, loss-ulb:0.0672, weight:1.55, lr:0.0007
[02:49:19.154] iteration:4790  t-loss:0.3314, loss-lb:0.1730, loss-ulb:0.1020, weight:1.55, lr:0.0007
[02:49:19.491] iteration:4791  t-loss:0.4304, loss-lb:0.3041, loss-ulb:0.0813, weight:1.55, lr:0.0007
[02:49:19.825] iteration:4792  t-loss:1.0905, loss-lb:0.2159, loss-ulb:0.5633, weight:1.55, lr:0.0007
[02:49:20.150] iteration:4793  t-loss:0.4491, loss-lb:0.2938, loss-ulb:0.1000, weight:1.55, lr:0.0007
[02:49:20.470] iteration:4794  t-loss:0.6594, loss-lb:0.2571, loss-ulb:0.2591, weight:1.55, lr:0.0007
[02:49:20.785] iteration:4795  t-loss:0.2756, loss-lb:0.1858, loss-ulb:0.0579, weight:1.55, lr:0.0007
[02:49:21.107] iteration:4796  t-loss:0.3252, loss-lb:0.1723, loss-ulb:0.0985, weight:1.55, lr:0.0007
[02:49:21.426] iteration:4797  t-loss:0.4292, loss-lb:0.3288, loss-ulb:0.0647, weight:1.55, lr:0.0007
[02:49:21.759] iteration:4798  t-loss:0.4230, loss-lb:0.2546, loss-ulb:0.1085, weight:1.55, lr:0.0007
[02:49:22.076] iteration:4799  t-loss:0.2251, loss-lb:0.1539, loss-ulb:0.0459, weight:1.55, lr:0.0007
[02:49:22.400] iteration:4800  t-loss:0.3751, loss-lb:0.2149, loss-ulb:0.1032, weight:1.55, lr:0.0007
[02:49:23.720] iteration:4801  t-loss:0.4032, loss-lb:0.1790, loss-ulb:0.1370, weight:1.64, lr:0.0007
[02:49:24.070] iteration:4802  t-loss:0.4198, loss-lb:0.2788, loss-ulb:0.0861, weight:1.64, lr:0.0007
[02:49:24.406] iteration:4803  t-loss:0.5198, loss-lb:0.2817, loss-ulb:0.1454, weight:1.64, lr:0.0007
[02:49:24.733] iteration:4804  t-loss:0.4520, loss-lb:0.3292, loss-ulb:0.0750, weight:1.64, lr:0.0007
[02:49:25.053] iteration:4805  t-loss:0.3088, loss-lb:0.2769, loss-ulb:0.0195, weight:1.64, lr:0.0007
[02:49:25.384] iteration:4806  t-loss:0.4321, loss-lb:0.1675, loss-ulb:0.1616, weight:1.64, lr:0.0007
[02:49:25.718] iteration:4807  t-loss:0.4095, loss-lb:0.1686, loss-ulb:0.1471, weight:1.64, lr:0.0007
[02:49:26.034] iteration:4808  t-loss:0.3686, loss-lb:0.1834, loss-ulb:0.1131, weight:1.64, lr:0.0007
[02:49:26.352] iteration:4809  t-loss:0.3210, loss-lb:0.2458, loss-ulb:0.0459, weight:1.64, lr:0.0007
[02:49:26.668] iteration:4810  t-loss:0.5972, loss-lb:0.3968, loss-ulb:0.1224, weight:1.64, lr:0.0007
[02:49:26.984] iteration:4811  t-loss:0.4577, loss-lb:0.1632, loss-ulb:0.1799, weight:1.64, lr:0.0007
[02:49:27.296] iteration:4812  t-loss:0.5960, loss-lb:0.4742, loss-ulb:0.0743, weight:1.64, lr:0.0007
[02:49:27.611] iteration:4813  t-loss:0.9872, loss-lb:0.1519, loss-ulb:0.5101, weight:1.64, lr:0.0007
[02:49:27.929] iteration:4814  t-loss:0.4158, loss-lb:0.1508, loss-ulb:0.1618, weight:1.64, lr:0.0007
[02:49:28.247] iteration:4815  t-loss:0.7394, loss-lb:0.3074, loss-ulb:0.2638, weight:1.64, lr:0.0007
[02:49:28.567] iteration:4816  t-loss:0.5795, loss-lb:0.3789, loss-ulb:0.1225, weight:1.64, lr:0.0007
[02:49:28.892] iteration:4817  t-loss:0.8310, loss-lb:0.1890, loss-ulb:0.3921, weight:1.64, lr:0.0007
[02:49:29.212] iteration:4818  t-loss:0.4734, loss-lb:0.1624, loss-ulb:0.1899, weight:1.64, lr:0.0007
[02:49:29.534] iteration:4819  t-loss:0.3845, loss-lb:0.3267, loss-ulb:0.0353, weight:1.64, lr:0.0007
[02:49:29.850] iteration:4820  t-loss:0.3157, loss-lb:0.1719, loss-ulb:0.0879, weight:1.64, lr:0.0007
[02:49:30.167] iteration:4821  t-loss:0.3812, loss-lb:0.3117, loss-ulb:0.0424, weight:1.64, lr:0.0007
[02:49:30.487] iteration:4822  t-loss:1.4648, loss-lb:0.4910, loss-ulb:0.5947, weight:1.64, lr:0.0007
[02:49:30.802] iteration:4823  t-loss:0.7394, loss-lb:0.1844, loss-ulb:0.3389, weight:1.64, lr:0.0007
[02:49:31.117] iteration:4824  t-loss:1.0124, loss-lb:0.2934, loss-ulb:0.4391, weight:1.64, lr:0.0007
[02:49:31.437] iteration:4825  t-loss:0.5427, loss-lb:0.2660, loss-ulb:0.1690, weight:1.64, lr:0.0007
[02:51:24.604] iteration 4825 : dice_score: 0.830080 best_dice: 0.833900
[02:51:24.604]  <<Test>> - Ep:192  - Dice-S/T:82.88/83.01, Best-S:82.88, Best-T:83.39
[02:51:24.604]           - AvgLoss(lb/ulb/all):0.26/0.21/0.60
[02:51:25.908] iteration:4826  t-loss:0.6167, loss-lb:0.3477, loss-ulb:0.1643, weight:1.64, lr:0.0007
[02:51:26.250] iteration:4827  t-loss:0.6207, loss-lb:0.2489, loss-ulb:0.2271, weight:1.64, lr:0.0007
[02:51:26.572] iteration:4828  t-loss:0.2663, loss-lb:0.1869, loss-ulb:0.0485, weight:1.64, lr:0.0007
[02:51:26.896] iteration:4829  t-loss:0.4685, loss-lb:0.3506, loss-ulb:0.0719, weight:1.64, lr:0.0007
[02:51:27.217] iteration:4830  t-loss:0.3452, loss-lb:0.2107, loss-ulb:0.0821, weight:1.64, lr:0.0007
[02:51:27.535] iteration:4831  t-loss:0.8573, loss-lb:0.2747, loss-ulb:0.3558, weight:1.64, lr:0.0007
[02:51:27.853] iteration:4832  t-loss:0.3752, loss-lb:0.2454, loss-ulb:0.0792, weight:1.64, lr:0.0007
[02:51:28.175] iteration:4833  t-loss:0.5142, loss-lb:0.2176, loss-ulb:0.1811, weight:1.64, lr:0.0007
[02:51:28.497] iteration:4834  t-loss:0.7733, loss-lb:0.3352, loss-ulb:0.2676, weight:1.64, lr:0.0007
[02:51:28.821] iteration:4835  t-loss:0.3726, loss-lb:0.2659, loss-ulb:0.0652, weight:1.64, lr:0.0007
[02:51:29.138] iteration:4836  t-loss:1.2238, loss-lb:0.2485, loss-ulb:0.5956, weight:1.64, lr:0.0007
[02:51:29.459] iteration:4837  t-loss:0.5671, loss-lb:0.2336, loss-ulb:0.2036, weight:1.64, lr:0.0007
[02:51:29.781] iteration:4838  t-loss:0.5536, loss-lb:0.3486, loss-ulb:0.1252, weight:1.64, lr:0.0007
[02:51:30.099] iteration:4839  t-loss:0.6749, loss-lb:0.1895, loss-ulb:0.2964, weight:1.64, lr:0.0007
[02:51:30.416] iteration:4840  t-loss:0.3921, loss-lb:0.2625, loss-ulb:0.0791, weight:1.64, lr:0.0007
[02:51:30.734] iteration:4841  t-loss:0.3726, loss-lb:0.1406, loss-ulb:0.1417, weight:1.64, lr:0.0007
[02:51:31.050] iteration:4842  t-loss:1.0411, loss-lb:0.6199, loss-ulb:0.2573, weight:1.64, lr:0.0007
[02:51:31.363] iteration:4843  t-loss:0.2457, loss-lb:0.1731, loss-ulb:0.0443, weight:1.64, lr:0.0007
[02:51:31.676] iteration:4844  t-loss:0.1904, loss-lb:0.1178, loss-ulb:0.0443, weight:1.64, lr:0.0007
[02:51:31.990] iteration:4845  t-loss:0.4209, loss-lb:0.2216, loss-ulb:0.1217, weight:1.64, lr:0.0007
[02:51:32.304] iteration:4846  t-loss:0.4429, loss-lb:0.1892, loss-ulb:0.1549, weight:1.64, lr:0.0007
[02:51:32.620] iteration:4847  t-loss:0.4749, loss-lb:0.2674, loss-ulb:0.1267, weight:1.64, lr:0.0007
[02:51:32.933] iteration:4848  t-loss:0.6098, loss-lb:0.2774, loss-ulb:0.2030, weight:1.64, lr:0.0007
[02:51:33.248] iteration:4849  t-loss:0.5102, loss-lb:0.1764, loss-ulb:0.2038, weight:1.64, lr:0.0007
[02:51:33.560] iteration:4850  t-loss:0.7180, loss-lb:0.2448, loss-ulb:0.2890, weight:1.64, lr:0.0007
[02:51:34.589] iteration:4851  t-loss:1.0696, loss-lb:0.1978, loss-ulb:0.5324, weight:1.64, lr:0.0007
[02:51:34.912] iteration:4852  t-loss:0.3097, loss-lb:0.1758, loss-ulb:0.0818, weight:1.64, lr:0.0007
[02:51:35.233] iteration:4853  t-loss:0.9916, loss-lb:0.2372, loss-ulb:0.4607, weight:1.64, lr:0.0007
[02:51:35.557] iteration:4854  t-loss:1.4181, loss-lb:0.2901, loss-ulb:0.6889, weight:1.64, lr:0.0007
[02:51:35.884] iteration:4855  t-loss:0.3984, loss-lb:0.2969, loss-ulb:0.0620, weight:1.64, lr:0.0007
[02:51:36.212] iteration:4856  t-loss:0.5677, loss-lb:0.4771, loss-ulb:0.0553, weight:1.64, lr:0.0007
[02:51:36.535] iteration:4857  t-loss:0.4957, loss-lb:0.3770, loss-ulb:0.0725, weight:1.64, lr:0.0007
[02:51:36.863] iteration:4858  t-loss:0.3688, loss-lb:0.2266, loss-ulb:0.0869, weight:1.64, lr:0.0007
[02:51:37.184] iteration:4859  t-loss:0.2556, loss-lb:0.1963, loss-ulb:0.0362, weight:1.64, lr:0.0007
[02:51:37.508] iteration:4860  t-loss:1.5656, loss-lb:0.3129, loss-ulb:0.7650, weight:1.64, lr:0.0007
[02:51:37.830] iteration:4861  t-loss:0.4343, loss-lb:0.2166, loss-ulb:0.1329, weight:1.64, lr:0.0007
[02:51:38.153] iteration:4862  t-loss:0.2421, loss-lb:0.1470, loss-ulb:0.0580, weight:1.64, lr:0.0007
[02:51:38.469] iteration:4863  t-loss:0.2498, loss-lb:0.1948, loss-ulb:0.0336, weight:1.64, lr:0.0007
[02:51:38.789] iteration:4864  t-loss:0.3585, loss-lb:0.2176, loss-ulb:0.0860, weight:1.64, lr:0.0007
[02:51:39.111] iteration:4865  t-loss:0.5624, loss-lb:0.3928, loss-ulb:0.1036, weight:1.64, lr:0.0007
[02:51:39.427] iteration:4866  t-loss:0.3011, loss-lb:0.1543, loss-ulb:0.0897, weight:1.64, lr:0.0007
[02:51:39.745] iteration:4867  t-loss:0.1856, loss-lb:0.1371, loss-ulb:0.0296, weight:1.64, lr:0.0007
[02:51:40.059] iteration:4868  t-loss:0.9211, loss-lb:0.2585, loss-ulb:0.4047, weight:1.64, lr:0.0007
[02:51:40.376] iteration:4869  t-loss:0.2196, loss-lb:0.1619, loss-ulb:0.0353, weight:1.64, lr:0.0007
[02:51:40.690] iteration:4870  t-loss:0.7064, loss-lb:0.3308, loss-ulb:0.2294, weight:1.64, lr:0.0007
[02:51:41.007] iteration:4871  t-loss:0.6272, loss-lb:0.2069, loss-ulb:0.2567, weight:1.64, lr:0.0007
[02:51:41.327] iteration:4872  t-loss:0.5473, loss-lb:0.1812, loss-ulb:0.2236, weight:1.64, lr:0.0007
[02:51:41.644] iteration:4873  t-loss:0.3844, loss-lb:0.1913, loss-ulb:0.1179, weight:1.64, lr:0.0007
[02:51:41.960] iteration:4874  t-loss:1.1854, loss-lb:0.2779, loss-ulb:0.5542, weight:1.64, lr:0.0007
[02:51:42.285] iteration:4875  t-loss:0.3101, loss-lb:0.2592, loss-ulb:0.0311, weight:1.64, lr:0.0007
[02:51:43.527] iteration:4876  t-loss:0.3527, loss-lb:0.2497, loss-ulb:0.0629, weight:1.64, lr:0.0007
[02:51:43.851] iteration:4877  t-loss:0.5924, loss-lb:0.1950, loss-ulb:0.2427, weight:1.64, lr:0.0007
[02:51:44.174] iteration:4878  t-loss:0.2752, loss-lb:0.2305, loss-ulb:0.0273, weight:1.64, lr:0.0007
[02:51:44.505] iteration:4879  t-loss:0.5043, loss-lb:0.2270, loss-ulb:0.1693, weight:1.64, lr:0.0007
[02:51:44.826] iteration:4880  t-loss:0.4901, loss-lb:0.4391, loss-ulb:0.0311, weight:1.64, lr:0.0007
[02:51:45.144] iteration:4881  t-loss:0.2666, loss-lb:0.2086, loss-ulb:0.0354, weight:1.64, lr:0.0007
[02:51:45.472] iteration:4882  t-loss:0.4577, loss-lb:0.3087, loss-ulb:0.0909, weight:1.64, lr:0.0007
[02:51:45.805] iteration:4883  t-loss:1.1116, loss-lb:0.2799, loss-ulb:0.5079, weight:1.64, lr:0.0007
[02:51:46.132] iteration:4884  t-loss:0.5696, loss-lb:0.2002, loss-ulb:0.2256, weight:1.64, lr:0.0007
[02:51:46.463] iteration:4885  t-loss:0.4439, loss-lb:0.3001, loss-ulb:0.0878, weight:1.64, lr:0.0007
[02:51:46.795] iteration:4886  t-loss:0.7399, loss-lb:0.1980, loss-ulb:0.3309, weight:1.64, lr:0.0007
[02:51:47.115] iteration:4887  t-loss:0.4101, loss-lb:0.3624, loss-ulb:0.0292, weight:1.64, lr:0.0007
[02:51:47.442] iteration:4888  t-loss:0.5099, loss-lb:0.1349, loss-ulb:0.2290, weight:1.64, lr:0.0007
[02:51:47.758] iteration:4889  t-loss:0.2966, loss-lb:0.2604, loss-ulb:0.0221, weight:1.64, lr:0.0007
[02:51:48.076] iteration:4890  t-loss:0.3477, loss-lb:0.2580, loss-ulb:0.0548, weight:1.64, lr:0.0007
[02:51:48.398] iteration:4891  t-loss:0.5685, loss-lb:0.3170, loss-ulb:0.1536, weight:1.64, lr:0.0007
[02:51:48.724] iteration:4892  t-loss:0.4791, loss-lb:0.2972, loss-ulb:0.1111, weight:1.64, lr:0.0007
[02:51:49.046] iteration:4893  t-loss:0.5330, loss-lb:0.1575, loss-ulb:0.2294, weight:1.64, lr:0.0007
[02:51:49.364] iteration:4894  t-loss:0.4291, loss-lb:0.1727, loss-ulb:0.1566, weight:1.64, lr:0.0007
[02:51:49.682] iteration:4895  t-loss:0.3261, loss-lb:0.2322, loss-ulb:0.0574, weight:1.64, lr:0.0007
[02:51:50.001] iteration:4896  t-loss:0.5794, loss-lb:0.1785, loss-ulb:0.2448, weight:1.64, lr:0.0007
[02:51:50.316] iteration:4897  t-loss:0.3838, loss-lb:0.1904, loss-ulb:0.1181, weight:1.64, lr:0.0007
[02:51:50.635] iteration:4898  t-loss:0.3346, loss-lb:0.1859, loss-ulb:0.0908, weight:1.64, lr:0.0007
[02:51:50.949] iteration:4899  t-loss:0.2559, loss-lb:0.1495, loss-ulb:0.0650, weight:1.64, lr:0.0007
[02:51:51.266] iteration:4900  t-loss:0.5856, loss-lb:0.3358, loss-ulb:0.1526, weight:1.64, lr:0.0007
[02:51:52.553] iteration:4901  t-loss:0.3939, loss-lb:0.3549, loss-ulb:0.0238, weight:1.64, lr:0.0007
[02:51:52.887] iteration:4902  t-loss:0.3488, loss-lb:0.2581, loss-ulb:0.0554, weight:1.64, lr:0.0007
[02:51:53.222] iteration:4903  t-loss:0.3729, loss-lb:0.1813, loss-ulb:0.1170, weight:1.64, lr:0.0007
[02:51:53.544] iteration:4904  t-loss:0.2994, loss-lb:0.2401, loss-ulb:0.0362, weight:1.64, lr:0.0007
[02:51:53.866] iteration:4905  t-loss:0.3270, loss-lb:0.1861, loss-ulb:0.0860, weight:1.64, lr:0.0007
[02:51:54.193] iteration:4906  t-loss:0.2414, loss-lb:0.1537, loss-ulb:0.0536, weight:1.64, lr:0.0007
[02:51:54.518] iteration:4907  t-loss:0.4718, loss-lb:0.3151, loss-ulb:0.0957, weight:1.64, lr:0.0007
[02:51:54.846] iteration:4908  t-loss:0.6690, loss-lb:0.3652, loss-ulb:0.1856, weight:1.64, lr:0.0007
[02:51:55.167] iteration:4909  t-loss:0.9394, loss-lb:0.2722, loss-ulb:0.4074, weight:1.64, lr:0.0007
[02:51:55.493] iteration:4910  t-loss:0.3470, loss-lb:0.1714, loss-ulb:0.1072, weight:1.64, lr:0.0007
[02:51:55.812] iteration:4911  t-loss:0.6437, loss-lb:0.2619, loss-ulb:0.2332, weight:1.64, lr:0.0007
[02:51:56.129] iteration:4912  t-loss:0.4879, loss-lb:0.2946, loss-ulb:0.1181, weight:1.64, lr:0.0007
[02:51:56.446] iteration:4913  t-loss:0.9502, loss-lb:0.2265, loss-ulb:0.4420, weight:1.64, lr:0.0007
[02:51:56.761] iteration:4914  t-loss:0.3980, loss-lb:0.3284, loss-ulb:0.0425, weight:1.64, lr:0.0007
[02:51:57.078] iteration:4915  t-loss:0.4719, loss-lb:0.3389, loss-ulb:0.0813, weight:1.64, lr:0.0007
[02:51:57.397] iteration:4916  t-loss:0.3922, loss-lb:0.2465, loss-ulb:0.0889, weight:1.64, lr:0.0007
[02:51:57.720] iteration:4917  t-loss:0.6226, loss-lb:0.5081, loss-ulb:0.0699, weight:1.64, lr:0.0007
[02:51:58.040] iteration:4918  t-loss:0.3119, loss-lb:0.2360, loss-ulb:0.0463, weight:1.64, lr:0.0007
[02:51:58.355] iteration:4919  t-loss:0.2204, loss-lb:0.1573, loss-ulb:0.0385, weight:1.64, lr:0.0007
[02:51:58.672] iteration:4920  t-loss:0.7542, loss-lb:0.3159, loss-ulb:0.2677, weight:1.64, lr:0.0007
[02:51:58.993] iteration:4921  t-loss:0.4455, loss-lb:0.1826, loss-ulb:0.1606, weight:1.64, lr:0.0007
[02:51:59.311] iteration:4922  t-loss:0.5948, loss-lb:0.1784, loss-ulb:0.2543, weight:1.64, lr:0.0007
[02:51:59.634] iteration:4923  t-loss:0.7110, loss-lb:0.3815, loss-ulb:0.2012, weight:1.64, lr:0.0007
[02:51:59.953] iteration:4924  t-loss:0.7568, loss-lb:0.4850, loss-ulb:0.1660, weight:1.64, lr:0.0007
[02:52:00.271] iteration:4925  t-loss:0.6626, loss-lb:0.4073, loss-ulb:0.1559, weight:1.64, lr:0.0007
[02:53:56.433] iteration 4925 : dice_score: 0.834722 best_dice: 0.834700
[02:53:56.433]  <<Test>> - Ep:196  - Dice-S/T:79.68/83.47, Best-S:82.88, Best-T:83.47
[02:53:56.433]           - AvgLoss(lb/ulb/all):0.28/0.16/0.55
[02:53:57.726] iteration:4926  t-loss:0.5248, loss-lb:0.2073, loss-ulb:0.1939, weight:1.64, lr:0.0007
[02:53:58.071] iteration:4927  t-loss:0.9339, loss-lb:0.4597, loss-ulb:0.2896, weight:1.64, lr:0.0007
[02:53:58.399] iteration:4928  t-loss:0.6868, loss-lb:0.4679, loss-ulb:0.1337, weight:1.64, lr:0.0007
[02:53:58.719] iteration:4929  t-loss:0.3182, loss-lb:0.2234, loss-ulb:0.0579, weight:1.64, lr:0.0007
[02:53:59.036] iteration:4930  t-loss:0.2888, loss-lb:0.1649, loss-ulb:0.0757, weight:1.64, lr:0.0007
[02:53:59.363] iteration:4931  t-loss:0.2822, loss-lb:0.1540, loss-ulb:0.0783, weight:1.64, lr:0.0007
[02:53:59.687] iteration:4932  t-loss:0.4321, loss-lb:0.1814, loss-ulb:0.1531, weight:1.64, lr:0.0007
[02:54:00.012] iteration:4933  t-loss:0.8385, loss-lb:0.4379, loss-ulb:0.2447, weight:1.64, lr:0.0007
[02:54:00.327] iteration:4934  t-loss:0.4128, loss-lb:0.1631, loss-ulb:0.1525, weight:1.64, lr:0.0007
[02:54:00.643] iteration:4935  t-loss:0.8419, loss-lb:0.4498, loss-ulb:0.2395, weight:1.64, lr:0.0007
[02:54:00.959] iteration:4936  t-loss:0.2806, loss-lb:0.1898, loss-ulb:0.0555, weight:1.64, lr:0.0007
[02:54:01.278] iteration:4937  t-loss:0.4094, loss-lb:0.3341, loss-ulb:0.0460, weight:1.64, lr:0.0007
[02:54:01.592] iteration:4938  t-loss:0.7797, loss-lb:0.2050, loss-ulb:0.3510, weight:1.64, lr:0.0007
[02:54:01.906] iteration:4939  t-loss:0.3723, loss-lb:0.1539, loss-ulb:0.1333, weight:1.64, lr:0.0007
[02:54:02.227] iteration:4940  t-loss:0.4584, loss-lb:0.1835, loss-ulb:0.1679, weight:1.64, lr:0.0007
[02:54:02.543] iteration:4941  t-loss:0.4681, loss-lb:0.2840, loss-ulb:0.1124, weight:1.64, lr:0.0007
[02:54:02.859] iteration:4942  t-loss:0.3894, loss-lb:0.3268, loss-ulb:0.0382, weight:1.64, lr:0.0007
[02:54:03.180] iteration:4943  t-loss:0.4809, loss-lb:0.2875, loss-ulb:0.1181, weight:1.64, lr:0.0007
[02:54:03.494] iteration:4944  t-loss:0.8825, loss-lb:0.4515, loss-ulb:0.2632, weight:1.64, lr:0.0007
[02:54:03.806] iteration:4945  t-loss:0.2680, loss-lb:0.2107, loss-ulb:0.0350, weight:1.64, lr:0.0007
[02:54:04.119] iteration:4946  t-loss:0.4204, loss-lb:0.1860, loss-ulb:0.1432, weight:1.64, lr:0.0007
[02:54:04.434] iteration:4947  t-loss:0.6870, loss-lb:0.4511, loss-ulb:0.1441, weight:1.64, lr:0.0007
[02:54:04.748] iteration:4948  t-loss:0.5925, loss-lb:0.1908, loss-ulb:0.2453, weight:1.64, lr:0.0007
[02:54:05.064] iteration:4949  t-loss:0.8276, loss-lb:0.3651, loss-ulb:0.2825, weight:1.64, lr:0.0007
[02:54:05.378] iteration:4950  t-loss:0.4851, loss-lb:0.2074, loss-ulb:0.1696, weight:1.64, lr:0.0007
[02:54:06.537] iteration:4951  t-loss:0.2828, loss-lb:0.2123, loss-ulb:0.0411, weight:1.72, lr:0.0007
[02:54:06.877] iteration:4952  t-loss:0.4206, loss-lb:0.3595, loss-ulb:0.0356, weight:1.72, lr:0.0007
[02:54:07.207] iteration:4953  t-loss:0.4136, loss-lb:0.2000, loss-ulb:0.1245, weight:1.72, lr:0.0007
[02:54:07.521] iteration:4954  t-loss:0.5648, loss-lb:0.1570, loss-ulb:0.2377, weight:1.72, lr:0.0007
[02:54:07.842] iteration:4955  t-loss:1.2674, loss-lb:0.5334, loss-ulb:0.4277, weight:1.72, lr:0.0007
[02:54:08.157] iteration:4956  t-loss:0.2455, loss-lb:0.2040, loss-ulb:0.0242, weight:1.72, lr:0.0007
[02:54:08.474] iteration:4957  t-loss:0.8178, loss-lb:0.1361, loss-ulb:0.3973, weight:1.72, lr:0.0007
[02:54:08.788] iteration:4958  t-loss:0.2709, loss-lb:0.2164, loss-ulb:0.0317, weight:1.72, lr:0.0007
[02:54:09.113] iteration:4959  t-loss:0.3877, loss-lb:0.1888, loss-ulb:0.1159, weight:1.72, lr:0.0007
[02:54:09.440] iteration:4960  t-loss:0.3105, loss-lb:0.2622, loss-ulb:0.0281, weight:1.72, lr:0.0007
[02:54:09.755] iteration:4961  t-loss:0.2382, loss-lb:0.1749, loss-ulb:0.0369, weight:1.72, lr:0.0007
[02:54:10.070] iteration:4962  t-loss:0.5058, loss-lb:0.2408, loss-ulb:0.1544, weight:1.72, lr:0.0007
[02:54:10.390] iteration:4963  t-loss:1.1564, loss-lb:0.4117, loss-ulb:0.4339, weight:1.72, lr:0.0007
[02:54:10.713] iteration:4964  t-loss:0.5578, loss-lb:0.2563, loss-ulb:0.1757, weight:1.72, lr:0.0007
[02:54:11.033] iteration:4965  t-loss:1.0693, loss-lb:0.3412, loss-ulb:0.4243, weight:1.72, lr:0.0007
[02:54:11.353] iteration:4966  t-loss:0.6007, loss-lb:0.3515, loss-ulb:0.1453, weight:1.72, lr:0.0007
[02:54:11.676] iteration:4967  t-loss:0.8011, loss-lb:0.3673, loss-ulb:0.2528, weight:1.72, lr:0.0007
[02:54:11.997] iteration:4968  t-loss:0.3440, loss-lb:0.1705, loss-ulb:0.1011, weight:1.72, lr:0.0007
[02:54:12.313] iteration:4969  t-loss:0.6627, loss-lb:0.3451, loss-ulb:0.1851, weight:1.72, lr:0.0007
[02:54:12.628] iteration:4970  t-loss:0.6488, loss-lb:0.2532, loss-ulb:0.2305, weight:1.72, lr:0.0007
[02:54:12.944] iteration:4971  t-loss:0.2127, loss-lb:0.1737, loss-ulb:0.0227, weight:1.72, lr:0.0007
[02:54:13.257] iteration:4972  t-loss:0.4272, loss-lb:0.2070, loss-ulb:0.1283, weight:1.72, lr:0.0007
[02:54:13.572] iteration:4973  t-loss:0.5250, loss-lb:0.2745, loss-ulb:0.1460, weight:1.72, lr:0.0007
[02:54:13.886] iteration:4974  t-loss:0.3763, loss-lb:0.1693, loss-ulb:0.1206, weight:1.72, lr:0.0007
[02:54:14.198] iteration:4975  t-loss:0.1878, loss-lb:0.1501, loss-ulb:0.0220, weight:1.72, lr:0.0007
[02:54:15.421] iteration:4976  t-loss:0.2955, loss-lb:0.2390, loss-ulb:0.0329, weight:1.72, lr:0.0007
[02:54:15.760] iteration:4977  t-loss:0.4231, loss-lb:0.1973, loss-ulb:0.1316, weight:1.72, lr:0.0007
[02:54:16.093] iteration:4978  t-loss:0.5182, loss-lb:0.3672, loss-ulb:0.0880, weight:1.72, lr:0.0007
[02:54:16.415] iteration:4979  t-loss:0.4585, loss-lb:0.3312, loss-ulb:0.0742, weight:1.72, lr:0.0007
[02:54:16.737] iteration:4980  t-loss:0.6206, loss-lb:0.3558, loss-ulb:0.1543, weight:1.72, lr:0.0007
[02:54:17.053] iteration:4981  t-loss:0.2128, loss-lb:0.1328, loss-ulb:0.0467, weight:1.72, lr:0.0007
[02:54:17.375] iteration:4982  t-loss:0.5562, loss-lb:0.1924, loss-ulb:0.2120, weight:1.72, lr:0.0007
[02:54:17.699] iteration:4983  t-loss:0.8977, loss-lb:0.2295, loss-ulb:0.3894, weight:1.72, lr:0.0007
[02:54:18.016] iteration:4984  t-loss:0.3111, loss-lb:0.2459, loss-ulb:0.0380, weight:1.72, lr:0.0007
[02:54:18.332] iteration:4985  t-loss:0.4737, loss-lb:0.3765, loss-ulb:0.0566, weight:1.72, lr:0.0007
[02:54:18.654] iteration:4986  t-loss:0.3608, loss-lb:0.1787, loss-ulb:0.1061, weight:1.72, lr:0.0007
[02:54:18.974] iteration:4987  t-loss:0.5156, loss-lb:0.2982, loss-ulb:0.1267, weight:1.72, lr:0.0007
[02:54:19.290] iteration:4988  t-loss:0.2373, loss-lb:0.1657, loss-ulb:0.0417, weight:1.72, lr:0.0007
[02:54:19.608] iteration:4989  t-loss:0.4164, loss-lb:0.2086, loss-ulb:0.1211, weight:1.72, lr:0.0007
[02:54:19.926] iteration:4990  t-loss:0.2903, loss-lb:0.1725, loss-ulb:0.0686, weight:1.72, lr:0.0007
[02:54:20.243] iteration:4991  t-loss:0.1958, loss-lb:0.1570, loss-ulb:0.0227, weight:1.72, lr:0.0007
[02:54:20.561] iteration:4992  t-loss:0.9458, loss-lb:0.2236, loss-ulb:0.4209, weight:1.72, lr:0.0007
[02:54:20.877] iteration:4993  t-loss:1.1380, loss-lb:0.1791, loss-ulb:0.5588, weight:1.72, lr:0.0007
[02:54:21.192] iteration:4994  t-loss:0.5016, loss-lb:0.2320, loss-ulb:0.1571, weight:1.72, lr:0.0007
[02:54:21.507] iteration:4995  t-loss:0.2681, loss-lb:0.2171, loss-ulb:0.0297, weight:1.72, lr:0.0007
[02:54:21.822] iteration:4996  t-loss:1.8187, loss-lb:0.2917, loss-ulb:0.8898, weight:1.72, lr:0.0007
[02:54:22.135] iteration:4997  t-loss:0.4555, loss-lb:0.3240, loss-ulb:0.0766, weight:1.72, lr:0.0007
[02:54:22.452] iteration:4998  t-loss:0.3406, loss-lb:0.1734, loss-ulb:0.0975, weight:1.72, lr:0.0007
[02:54:22.766] iteration:4999  t-loss:0.3396, loss-lb:0.3043, loss-ulb:0.0206, weight:1.72, lr:0.0007
[02:54:23.081] iteration:5000  t-loss:1.1348, loss-lb:0.4029, loss-ulb:0.4265, weight:1.72, lr:0.0007
[02:54:24.256] iteration:5001  t-loss:0.4854, loss-lb:0.2960, loss-ulb:0.1103, weight:1.72, lr:0.0007
[02:54:24.591] iteration:5002  t-loss:0.7815, loss-lb:0.2084, loss-ulb:0.3340, weight:1.72, lr:0.0007
[02:54:24.918] iteration:5003  t-loss:0.5514, loss-lb:0.1851, loss-ulb:0.2135, weight:1.72, lr:0.0007
[02:54:25.252] iteration:5004  t-loss:0.3425, loss-lb:0.1536, loss-ulb:0.1100, weight:1.72, lr:0.0007
[02:54:25.575] iteration:5005  t-loss:0.4823, loss-lb:0.3411, loss-ulb:0.0823, weight:1.72, lr:0.0007
[02:54:25.895] iteration:5006  t-loss:0.5403, loss-lb:0.2524, loss-ulb:0.1677, weight:1.72, lr:0.0007
[02:54:26.217] iteration:5007  t-loss:0.4837, loss-lb:0.1675, loss-ulb:0.1843, weight:1.72, lr:0.0007
[02:54:26.538] iteration:5008  t-loss:0.1873, loss-lb:0.1368, loss-ulb:0.0294, weight:1.72, lr:0.0007
[02:54:26.858] iteration:5009  t-loss:0.6155, loss-lb:0.4015, loss-ulb:0.1247, weight:1.72, lr:0.0007
[02:54:27.175] iteration:5010  t-loss:0.6723, loss-lb:0.2207, loss-ulb:0.2632, weight:1.72, lr:0.0007
[02:54:27.498] iteration:5011  t-loss:0.3381, loss-lb:0.1963, loss-ulb:0.0826, weight:1.72, lr:0.0007
[02:54:27.814] iteration:5012  t-loss:0.3914, loss-lb:0.3171, loss-ulb:0.0433, weight:1.72, lr:0.0007
[02:54:28.131] iteration:5013  t-loss:0.2572, loss-lb:0.1819, loss-ulb:0.0438, weight:1.72, lr:0.0007
[02:54:28.447] iteration:5014  t-loss:0.4292, loss-lb:0.1623, loss-ulb:0.1556, weight:1.72, lr:0.0007
[02:54:28.766] iteration:5015  t-loss:0.4428, loss-lb:0.3076, loss-ulb:0.0788, weight:1.72, lr:0.0007
[02:54:29.086] iteration:5016  t-loss:0.5908, loss-lb:0.4560, loss-ulb:0.0786, weight:1.72, lr:0.0007
[02:54:29.401] iteration:5017  t-loss:0.4000, loss-lb:0.2133, loss-ulb:0.1088, weight:1.72, lr:0.0007
[02:54:29.715] iteration:5018  t-loss:0.3887, loss-lb:0.2170, loss-ulb:0.1001, weight:1.72, lr:0.0007
[02:54:30.030] iteration:5019  t-loss:0.4725, loss-lb:0.2623, loss-ulb:0.1225, weight:1.72, lr:0.0007
[02:54:30.343] iteration:5020  t-loss:0.2652, loss-lb:0.2003, loss-ulb:0.0378, weight:1.72, lr:0.0007
[02:54:30.658] iteration:5021  t-loss:0.4388, loss-lb:0.3685, loss-ulb:0.0410, weight:1.72, lr:0.0007
[02:54:30.972] iteration:5022  t-loss:0.2111, loss-lb:0.1559, loss-ulb:0.0322, weight:1.72, lr:0.0007
[02:54:31.286] iteration:5023  t-loss:0.5719, loss-lb:0.2680, loss-ulb:0.1770, weight:1.72, lr:0.0007
[02:54:31.607] iteration:5024  t-loss:0.4083, loss-lb:0.2839, loss-ulb:0.0725, weight:1.72, lr:0.0007
[02:54:31.922] iteration:5025  t-loss:0.2044, loss-lb:0.1337, loss-ulb:0.0412, weight:1.72, lr:0.0007
[02:56:33.874] iteration 5025 : dice_score: 0.831741 best_dice: 0.834700
[02:56:33.874]  <<Test>> - Ep:200  - Dice-S/T:82.71/83.17, Best-S:82.88, Best-T:83.47
[02:56:33.874]           - AvgLoss(lb/ulb/all):0.24/0.10/0.42
[02:56:34.877] iteration:5026  t-loss:0.3652, loss-lb:0.3327, loss-ulb:0.0190, weight:1.72, lr:0.0007
[02:56:35.208] iteration:5027  t-loss:0.7696, loss-lb:0.3941, loss-ulb:0.2189, weight:1.72, lr:0.0007
[02:56:35.524] iteration:5028  t-loss:1.2690, loss-lb:0.1679, loss-ulb:0.6417, weight:1.72, lr:0.0007
[02:56:35.837] iteration:5029  t-loss:0.2639, loss-lb:0.2324, loss-ulb:0.0183, weight:1.72, lr:0.0007
[02:56:36.155] iteration:5030  t-loss:0.8764, loss-lb:0.2858, loss-ulb:0.3442, weight:1.72, lr:0.0007
[02:56:36.468] iteration:5031  t-loss:0.8153, loss-lb:0.1506, loss-ulb:0.3874, weight:1.72, lr:0.0007
[02:56:36.784] iteration:5032  t-loss:0.4823, loss-lb:0.2249, loss-ulb:0.1500, weight:1.72, lr:0.0007
[02:56:37.099] iteration:5033  t-loss:0.4394, loss-lb:0.2896, loss-ulb:0.0873, weight:1.72, lr:0.0007
[02:56:37.417] iteration:5034  t-loss:0.4147, loss-lb:0.2725, loss-ulb:0.0828, weight:1.72, lr:0.0007
[02:56:37.732] iteration:5035  t-loss:0.8827, loss-lb:0.2294, loss-ulb:0.3807, weight:1.72, lr:0.0007
[02:56:38.045] iteration:5036  t-loss:0.2322, loss-lb:0.1685, loss-ulb:0.0371, weight:1.72, lr:0.0007
[02:56:38.356] iteration:5037  t-loss:0.2912, loss-lb:0.2263, loss-ulb:0.0379, weight:1.72, lr:0.0007
[02:56:38.672] iteration:5038  t-loss:0.6701, loss-lb:0.1523, loss-ulb:0.3018, weight:1.72, lr:0.0007
[02:56:38.988] iteration:5039  t-loss:0.5906, loss-lb:0.3415, loss-ulb:0.1452, weight:1.72, lr:0.0007
[02:56:39.301] iteration:5040  t-loss:0.3825, loss-lb:0.2051, loss-ulb:0.1034, weight:1.72, lr:0.0007
[02:56:39.615] iteration:5041  t-loss:0.7049, loss-lb:0.3396, loss-ulb:0.2129, weight:1.72, lr:0.0007
[02:56:39.930] iteration:5042  t-loss:0.7107, loss-lb:0.1932, loss-ulb:0.3015, weight:1.72, lr:0.0007
[02:56:40.242] iteration:5043  t-loss:0.5717, loss-lb:0.5302, loss-ulb:0.0242, weight:1.72, lr:0.0007
[02:56:40.556] iteration:5044  t-loss:0.5777, loss-lb:0.1570, loss-ulb:0.2452, weight:1.72, lr:0.0007
[02:56:40.871] iteration:5045  t-loss:0.5030, loss-lb:0.1732, loss-ulb:0.1922, weight:1.72, lr:0.0007
[02:56:41.187] iteration:5046  t-loss:0.3370, loss-lb:0.2759, loss-ulb:0.0356, weight:1.72, lr:0.0007
[02:56:41.503] iteration:5047  t-loss:0.7355, loss-lb:0.3529, loss-ulb:0.2230, weight:1.72, lr:0.0007
[02:56:41.827] iteration:5048  t-loss:0.4071, loss-lb:0.2051, loss-ulb:0.1177, weight:1.72, lr:0.0007
[02:56:42.144] iteration:5049  t-loss:0.2670, loss-lb:0.1920, loss-ulb:0.0437, weight:1.72, lr:0.0007
[02:56:42.467] iteration:5050  t-loss:0.7256, loss-lb:0.2300, loss-ulb:0.2888, weight:1.72, lr:0.0007
[02:56:43.758] iteration:5051  t-loss:0.3071, loss-lb:0.1858, loss-ulb:0.0706, weight:1.72, lr:0.0007
[02:56:44.090] iteration:5052  t-loss:0.3834, loss-lb:0.1838, loss-ulb:0.1163, weight:1.72, lr:0.0007
[02:56:44.421] iteration:5053  t-loss:0.6524, loss-lb:0.3810, loss-ulb:0.1581, weight:1.72, lr:0.0007
[02:56:44.738] iteration:5054  t-loss:0.5738, loss-lb:0.1893, loss-ulb:0.2240, weight:1.72, lr:0.0007
[02:56:45.052] iteration:5055  t-loss:0.7629, loss-lb:0.2024, loss-ulb:0.3267, weight:1.72, lr:0.0007
[02:56:45.376] iteration:5056  t-loss:0.6903, loss-lb:0.5213, loss-ulb:0.0985, weight:1.72, lr:0.0007
[02:56:45.693] iteration:5057  t-loss:0.4504, loss-lb:0.3269, loss-ulb:0.0719, weight:1.72, lr:0.0007
[02:56:46.011] iteration:5058  t-loss:0.4760, loss-lb:0.2488, loss-ulb:0.1324, weight:1.72, lr:0.0007
[02:56:46.332] iteration:5059  t-loss:0.4132, loss-lb:0.2836, loss-ulb:0.0756, weight:1.72, lr:0.0007
[02:56:46.651] iteration:5060  t-loss:0.3722, loss-lb:0.1506, loss-ulb:0.1291, weight:1.72, lr:0.0007
[02:56:46.968] iteration:5061  t-loss:0.3852, loss-lb:0.1668, loss-ulb:0.1273, weight:1.72, lr:0.0007
[02:56:47.284] iteration:5062  t-loss:0.3107, loss-lb:0.2591, loss-ulb:0.0301, weight:1.72, lr:0.0007
[02:56:47.601] iteration:5063  t-loss:0.4289, loss-lb:0.1943, loss-ulb:0.1367, weight:1.72, lr:0.0007
[02:56:47.922] iteration:5064  t-loss:0.5108, loss-lb:0.2197, loss-ulb:0.1697, weight:1.72, lr:0.0007
[02:56:48.243] iteration:5065  t-loss:0.6209, loss-lb:0.3390, loss-ulb:0.1643, weight:1.72, lr:0.0007
[02:56:48.561] iteration:5066  t-loss:0.2312, loss-lb:0.1385, loss-ulb:0.0540, weight:1.72, lr:0.0007
[02:56:48.881] iteration:5067  t-loss:0.4478, loss-lb:0.3413, loss-ulb:0.0621, weight:1.72, lr:0.0007
[02:56:49.197] iteration:5068  t-loss:0.5883, loss-lb:0.2681, loss-ulb:0.1866, weight:1.72, lr:0.0007
[02:56:49.511] iteration:5069  t-loss:0.3171, loss-lb:0.2115, loss-ulb:0.0615, weight:1.72, lr:0.0007
[02:56:49.827] iteration:5070  t-loss:0.5002, loss-lb:0.1798, loss-ulb:0.1867, weight:1.72, lr:0.0007
[02:56:50.139] iteration:5071  t-loss:0.4738, loss-lb:0.2077, loss-ulb:0.1551, weight:1.72, lr:0.0007
[02:56:50.455] iteration:5072  t-loss:0.5681, loss-lb:0.3486, loss-ulb:0.1279, weight:1.72, lr:0.0007
[02:56:50.770] iteration:5073  t-loss:0.3874, loss-lb:0.1609, loss-ulb:0.1320, weight:1.72, lr:0.0007
[02:56:51.083] iteration:5074  t-loss:0.2899, loss-lb:0.2018, loss-ulb:0.0514, weight:1.72, lr:0.0007
[02:56:51.399] iteration:5075  t-loss:0.2408, loss-lb:0.1779, loss-ulb:0.0367, weight:1.72, lr:0.0007
[02:56:52.618] iteration:5076  t-loss:0.2213, loss-lb:0.1584, loss-ulb:0.0367, weight:1.72, lr:0.0007
[02:56:52.939] iteration:5077  t-loss:0.3637, loss-lb:0.1682, loss-ulb:0.1140, weight:1.72, lr:0.0007
[02:56:53.257] iteration:5078  t-loss:1.0006, loss-lb:0.2073, loss-ulb:0.4623, weight:1.72, lr:0.0007
[02:56:53.570] iteration:5079  t-loss:0.2556, loss-lb:0.1734, loss-ulb:0.0479, weight:1.72, lr:0.0007
[02:56:53.889] iteration:5080  t-loss:0.4110, loss-lb:0.3721, loss-ulb:0.0227, weight:1.72, lr:0.0007
[02:56:54.210] iteration:5081  t-loss:1.0009, loss-lb:0.4574, loss-ulb:0.3167, weight:1.72, lr:0.0007
[02:56:54.528] iteration:5082  t-loss:0.3540, loss-lb:0.2422, loss-ulb:0.0652, weight:1.72, lr:0.0007
[02:56:54.842] iteration:5083  t-loss:0.3978, loss-lb:0.3602, loss-ulb:0.0219, weight:1.72, lr:0.0007
[02:56:55.159] iteration:5084  t-loss:0.3739, loss-lb:0.3189, loss-ulb:0.0320, weight:1.72, lr:0.0007
[02:56:55.475] iteration:5085  t-loss:0.4258, loss-lb:0.1312, loss-ulb:0.1717, weight:1.72, lr:0.0007
[02:56:55.794] iteration:5086  t-loss:0.6125, loss-lb:0.3777, loss-ulb:0.1369, weight:1.72, lr:0.0007
[02:56:56.113] iteration:5087  t-loss:0.7555, loss-lb:0.5207, loss-ulb:0.1368, weight:1.72, lr:0.0007
[02:56:56.432] iteration:5088  t-loss:0.7018, loss-lb:0.3428, loss-ulb:0.2092, weight:1.72, lr:0.0007
[02:56:56.751] iteration:5089  t-loss:0.5944, loss-lb:0.2320, loss-ulb:0.2112, weight:1.72, lr:0.0007
[02:56:57.064] iteration:5090  t-loss:0.2791, loss-lb:0.2212, loss-ulb:0.0338, weight:1.72, lr:0.0007
[02:56:57.378] iteration:5091  t-loss:1.5534, loss-lb:0.2714, loss-ulb:0.7471, weight:1.72, lr:0.0007
[02:56:57.700] iteration:5092  t-loss:0.6983, loss-lb:0.3777, loss-ulb:0.1868, weight:1.72, lr:0.0007
[02:56:58.014] iteration:5093  t-loss:0.8702, loss-lb:0.1856, loss-ulb:0.3989, weight:1.72, lr:0.0007
[02:56:58.329] iteration:5094  t-loss:0.3931, loss-lb:0.2200, loss-ulb:0.1009, weight:1.72, lr:0.0007
[02:56:58.643] iteration:5095  t-loss:0.5135, loss-lb:0.3068, loss-ulb:0.1205, weight:1.72, lr:0.0007
[02:56:58.959] iteration:5096  t-loss:0.5925, loss-lb:0.3402, loss-ulb:0.1470, weight:1.72, lr:0.0007
[02:56:59.274] iteration:5097  t-loss:0.8765, loss-lb:0.5203, loss-ulb:0.2076, weight:1.72, lr:0.0007
[02:56:59.587] iteration:5098  t-loss:0.6980, loss-lb:0.2079, loss-ulb:0.2856, weight:1.72, lr:0.0007
[02:56:59.901] iteration:5099  t-loss:0.3342, loss-lb:0.2697, loss-ulb:0.0376, weight:1.72, lr:0.0007
[02:57:00.217] iteration:5100  t-loss:0.5425, loss-lb:0.2531, loss-ulb:0.1686, weight:1.72, lr:0.0007
[02:57:01.252] iteration:5101  t-loss:0.2354, loss-lb:0.1679, loss-ulb:0.0378, weight:1.79, lr:0.0007
[02:57:01.592] iteration:5102  t-loss:0.5263, loss-lb:0.3303, loss-ulb:0.1097, weight:1.79, lr:0.0007
[02:57:01.916] iteration:5103  t-loss:0.8929, loss-lb:0.2321, loss-ulb:0.3698, weight:1.79, lr:0.0007
[02:57:02.233] iteration:5104  t-loss:0.4707, loss-lb:0.1507, loss-ulb:0.1790, weight:1.79, lr:0.0007
[02:57:02.552] iteration:5105  t-loss:0.2572, loss-lb:0.2065, loss-ulb:0.0284, weight:1.79, lr:0.0007
[02:57:02.871] iteration:5106  t-loss:0.6572, loss-lb:0.3293, loss-ulb:0.1835, weight:1.79, lr:0.0007
[02:57:03.188] iteration:5107  t-loss:0.3344, loss-lb:0.1835, loss-ulb:0.0844, weight:1.79, lr:0.0007
[02:57:03.507] iteration:5108  t-loss:0.4305, loss-lb:0.2776, loss-ulb:0.0856, weight:1.79, lr:0.0007
[02:57:03.830] iteration:5109  t-loss:0.4359, loss-lb:0.2052, loss-ulb:0.1291, weight:1.79, lr:0.0007
[02:57:04.148] iteration:5110  t-loss:0.7269, loss-lb:0.2018, loss-ulb:0.2938, weight:1.79, lr:0.0007
[02:57:04.465] iteration:5111  t-loss:0.5311, loss-lb:0.2254, loss-ulb:0.1711, weight:1.79, lr:0.0007
[02:57:04.781] iteration:5112  t-loss:0.3782, loss-lb:0.3342, loss-ulb:0.0246, weight:1.79, lr:0.0007
[02:57:05.097] iteration:5113  t-loss:0.3236, loss-lb:0.2072, loss-ulb:0.0652, weight:1.79, lr:0.0007
[02:57:05.414] iteration:5114  t-loss:0.6275, loss-lb:0.1685, loss-ulb:0.2568, weight:1.79, lr:0.0007
[02:57:05.731] iteration:5115  t-loss:0.6356, loss-lb:0.2601, loss-ulb:0.2101, weight:1.79, lr:0.0007
[02:57:06.044] iteration:5116  t-loss:0.7744, loss-lb:0.1774, loss-ulb:0.3341, weight:1.79, lr:0.0007
[02:57:06.362] iteration:5117  t-loss:1.0430, loss-lb:0.4823, loss-ulb:0.3137, weight:1.79, lr:0.0007
[02:57:06.676] iteration:5118  t-loss:0.3594, loss-lb:0.2440, loss-ulb:0.0645, weight:1.79, lr:0.0007
[02:57:06.995] iteration:5119  t-loss:0.5981, loss-lb:0.5106, loss-ulb:0.0490, weight:1.79, lr:0.0007
[02:57:07.311] iteration:5120  t-loss:0.4536, loss-lb:0.1585, loss-ulb:0.1651, weight:1.79, lr:0.0007
[02:57:07.627] iteration:5121  t-loss:0.8641, loss-lb:0.2513, loss-ulb:0.3429, weight:1.79, lr:0.0007
[02:57:07.941] iteration:5122  t-loss:0.4161, loss-lb:0.2533, loss-ulb:0.0911, weight:1.79, lr:0.0007
[02:57:08.256] iteration:5123  t-loss:0.8284, loss-lb:0.2081, loss-ulb:0.3471, weight:1.79, lr:0.0007
[02:57:08.570] iteration:5124  t-loss:1.1472, loss-lb:0.3596, loss-ulb:0.4407, weight:1.79, lr:0.0007
[02:57:08.884] iteration:5125  t-loss:0.5684, loss-lb:0.1988, loss-ulb:0.2069, weight:1.79, lr:0.0007
[02:59:11.802] iteration 5125 : dice_score: 0.840708 best_dice: 0.840700
[02:59:11.803]  <<Test>> - Ep:204  - Dice-S/T:69.25/84.07, Best-S:82.88, Best-T:84.07
[02:59:11.803]           - AvgLoss(lb/ulb/all):0.25/0.19/0.61
[02:59:13.239] iteration:5126  t-loss:0.4199, loss-lb:0.3573, loss-ulb:0.0350, weight:1.79, lr:0.0007
[02:59:13.574] iteration:5127  t-loss:0.3464, loss-lb:0.1941, loss-ulb:0.0852, weight:1.79, lr:0.0007
[02:59:13.897] iteration:5128  t-loss:0.4199, loss-lb:0.1554, loss-ulb:0.1480, weight:1.79, lr:0.0007
[02:59:14.217] iteration:5129  t-loss:0.3458, loss-lb:0.2569, loss-ulb:0.0498, weight:1.79, lr:0.0007
[02:59:14.529] iteration:5130  t-loss:0.8315, loss-lb:0.2236, loss-ulb:0.3401, weight:1.79, lr:0.0007
[02:59:14.850] iteration:5131  t-loss:0.5133, loss-lb:0.2561, loss-ulb:0.1439, weight:1.79, lr:0.0007
[02:59:15.174] iteration:5132  t-loss:0.5432, loss-lb:0.3202, loss-ulb:0.1248, weight:1.79, lr:0.0007
[02:59:15.487] iteration:5133  t-loss:0.3185, loss-lb:0.1747, loss-ulb:0.0805, weight:1.79, lr:0.0007
[02:59:15.802] iteration:5134  t-loss:1.5270, loss-lb:0.5832, loss-ulb:0.5281, weight:1.79, lr:0.0007
[02:59:16.121] iteration:5135  t-loss:0.3667, loss-lb:0.1908, loss-ulb:0.0984, weight:1.79, lr:0.0007
[02:59:16.440] iteration:5136  t-loss:0.5354, loss-lb:0.1890, loss-ulb:0.1939, weight:1.79, lr:0.0007
[02:59:16.762] iteration:5137  t-loss:0.4779, loss-lb:0.2798, loss-ulb:0.1108, weight:1.79, lr:0.0007
[02:59:17.082] iteration:5138  t-loss:1.0477, loss-lb:0.1657, loss-ulb:0.4935, weight:1.79, lr:0.0007
[02:59:17.403] iteration:5139  t-loss:1.1513, loss-lb:0.1783, loss-ulb:0.5445, weight:1.79, lr:0.0007
[02:59:17.722] iteration:5140  t-loss:0.3241, loss-lb:0.2401, loss-ulb:0.0470, weight:1.79, lr:0.0007
[02:59:18.043] iteration:5141  t-loss:0.3180, loss-lb:0.2269, loss-ulb:0.0510, weight:1.79, lr:0.0007
[02:59:18.365] iteration:5142  t-loss:0.6693, loss-lb:0.3907, loss-ulb:0.1559, weight:1.79, lr:0.0007
[02:59:18.679] iteration:5143  t-loss:0.4962, loss-lb:0.3344, loss-ulb:0.0905, weight:1.79, lr:0.0007
[02:59:18.996] iteration:5144  t-loss:0.6372, loss-lb:0.4036, loss-ulb:0.1307, weight:1.79, lr:0.0007
[02:59:19.308] iteration:5145  t-loss:1.8004, loss-lb:0.2632, loss-ulb:0.8601, weight:1.79, lr:0.0007
[02:59:19.621] iteration:5146  t-loss:0.4329, loss-lb:0.3179, loss-ulb:0.0643, weight:1.79, lr:0.0007
[02:59:19.933] iteration:5147  t-loss:0.3718, loss-lb:0.1787, loss-ulb:0.1080, weight:1.79, lr:0.0007
[02:59:20.246] iteration:5148  t-loss:0.4448, loss-lb:0.1962, loss-ulb:0.1391, weight:1.79, lr:0.0007
[02:59:20.560] iteration:5149  t-loss:0.6077, loss-lb:0.2782, loss-ulb:0.1844, weight:1.79, lr:0.0007
[02:59:20.875] iteration:5150  t-loss:0.6366, loss-lb:0.3170, loss-ulb:0.1788, weight:1.79, lr:0.0007
[02:59:22.027] iteration:5151  t-loss:0.7612, loss-lb:0.4599, loss-ulb:0.1686, weight:1.79, lr:0.0007
[02:59:22.369] iteration:5152  t-loss:0.8109, loss-lb:0.2331, loss-ulb:0.3233, weight:1.79, lr:0.0007
[02:59:22.698] iteration:5153  t-loss:0.7036, loss-lb:0.1907, loss-ulb:0.2870, weight:1.79, lr:0.0007
[02:59:23.018] iteration:5154  t-loss:0.3553, loss-lb:0.2877, loss-ulb:0.0378, weight:1.79, lr:0.0007
[02:59:23.340] iteration:5155  t-loss:0.9230, loss-lb:0.1988, loss-ulb:0.4052, weight:1.79, lr:0.0007
[02:59:23.661] iteration:5156  t-loss:0.5694, loss-lb:0.2762, loss-ulb:0.1640, weight:1.79, lr:0.0007
[02:59:23.979] iteration:5157  t-loss:0.5326, loss-lb:0.1846, loss-ulb:0.1947, weight:1.79, lr:0.0007
[02:59:24.296] iteration:5158  t-loss:1.1561, loss-lb:0.2674, loss-ulb:0.4973, weight:1.79, lr:0.0007
[02:59:24.619] iteration:5159  t-loss:0.4671, loss-lb:0.2142, loss-ulb:0.1415, weight:1.79, lr:0.0007
[02:59:24.934] iteration:5160  t-loss:0.2681, loss-lb:0.1547, loss-ulb:0.0634, weight:1.79, lr:0.0007
[02:59:25.248] iteration:5161  t-loss:1.1856, loss-lb:0.1578, loss-ulb:0.5751, weight:1.79, lr:0.0007
[02:59:25.566] iteration:5162  t-loss:0.6642, loss-lb:0.4662, loss-ulb:0.1108, weight:1.79, lr:0.0007
[02:59:25.888] iteration:5163  t-loss:0.2667, loss-lb:0.2084, loss-ulb:0.0326, weight:1.79, lr:0.0007
[02:59:26.205] iteration:5164  t-loss:0.2989, loss-lb:0.2268, loss-ulb:0.0403, weight:1.79, lr:0.0007
[02:59:26.524] iteration:5165  t-loss:1.9160, loss-lb:0.4731, loss-ulb:0.8074, weight:1.79, lr:0.0007
[02:59:26.847] iteration:5166  t-loss:0.6679, loss-lb:0.2305, loss-ulb:0.2447, weight:1.79, lr:0.0007
[02:59:27.166] iteration:5167  t-loss:0.4946, loss-lb:0.1906, loss-ulb:0.1701, weight:1.79, lr:0.0007
[02:59:27.488] iteration:5168  t-loss:0.4874, loss-lb:0.2631, loss-ulb:0.1255, weight:1.79, lr:0.0007
[02:59:27.805] iteration:5169  t-loss:0.5315, loss-lb:0.2846, loss-ulb:0.1381, weight:1.79, lr:0.0007
[02:59:28.117] iteration:5170  t-loss:1.1414, loss-lb:0.1866, loss-ulb:0.5342, weight:1.79, lr:0.0007
[02:59:28.434] iteration:5171  t-loss:0.5333, loss-lb:0.1748, loss-ulb:0.2006, weight:1.79, lr:0.0007
[02:59:28.752] iteration:5172  t-loss:0.4125, loss-lb:0.2245, loss-ulb:0.1052, weight:1.79, lr:0.0007
[02:59:29.069] iteration:5173  t-loss:0.5124, loss-lb:0.2289, loss-ulb:0.1586, weight:1.79, lr:0.0007
[02:59:29.380] iteration:5174  t-loss:0.8494, loss-lb:0.2226, loss-ulb:0.3507, weight:1.79, lr:0.0007
[02:59:29.694] iteration:5175  t-loss:1.1247, loss-lb:0.2443, loss-ulb:0.4926, weight:1.79, lr:0.0007
[02:59:30.831] iteration:5176  t-loss:0.5474, loss-lb:0.3926, loss-ulb:0.0866, weight:1.79, lr:0.0007
[02:59:31.171] iteration:5177  t-loss:0.4676, loss-lb:0.3970, loss-ulb:0.0395, weight:1.79, lr:0.0007
[02:59:31.491] iteration:5178  t-loss:1.1609, loss-lb:0.3163, loss-ulb:0.4726, weight:1.79, lr:0.0007
[02:59:31.809] iteration:5179  t-loss:0.7483, loss-lb:0.3089, loss-ulb:0.2459, weight:1.79, lr:0.0007
[02:59:32.126] iteration:5180  t-loss:0.3093, loss-lb:0.2692, loss-ulb:0.0224, weight:1.79, lr:0.0007
[02:59:32.443] iteration:5181  t-loss:0.8782, loss-lb:0.1698, loss-ulb:0.3964, weight:1.79, lr:0.0007
[02:59:32.768] iteration:5182  t-loss:0.6775, loss-lb:0.2584, loss-ulb:0.2345, weight:1.79, lr:0.0007
[02:59:33.091] iteration:5183  t-loss:0.3458, loss-lb:0.2898, loss-ulb:0.0313, weight:1.79, lr:0.0007
[02:59:33.414] iteration:5184  t-loss:0.2790, loss-lb:0.2258, loss-ulb:0.0298, weight:1.79, lr:0.0007
[02:59:33.731] iteration:5185  t-loss:0.4578, loss-lb:0.1746, loss-ulb:0.1584, weight:1.79, lr:0.0007
[02:59:34.052] iteration:5186  t-loss:1.0630, loss-lb:0.2492, loss-ulb:0.4554, weight:1.79, lr:0.0007
[02:59:34.372] iteration:5187  t-loss:0.7422, loss-lb:0.1698, loss-ulb:0.3203, weight:1.79, lr:0.0007
[02:59:34.691] iteration:5188  t-loss:0.2742, loss-lb:0.2047, loss-ulb:0.0389, weight:1.79, lr:0.0007
[02:59:35.021] iteration:5189  t-loss:0.5904, loss-lb:0.3109, loss-ulb:0.1564, weight:1.79, lr:0.0007
[02:59:35.339] iteration:5190  t-loss:0.1614, loss-lb:0.1253, loss-ulb:0.0202, weight:1.79, lr:0.0007
[02:59:35.661] iteration:5191  t-loss:1.0265, loss-lb:0.3130, loss-ulb:0.3992, weight:1.79, lr:0.0007
[02:59:35.984] iteration:5192  t-loss:0.5864, loss-lb:0.3492, loss-ulb:0.1328, weight:1.79, lr:0.0007
[02:59:36.309] iteration:5193  t-loss:0.4618, loss-lb:0.2110, loss-ulb:0.1403, weight:1.79, lr:0.0007
[02:59:36.625] iteration:5194  t-loss:0.3347, loss-lb:0.2564, loss-ulb:0.0438, weight:1.79, lr:0.0007
[02:59:36.937] iteration:5195  t-loss:0.2793, loss-lb:0.1379, loss-ulb:0.0792, weight:1.79, lr:0.0007
[02:59:37.254] iteration:5196  t-loss:0.4850, loss-lb:0.3705, loss-ulb:0.0641, weight:1.79, lr:0.0007
[02:59:37.566] iteration:5197  t-loss:0.2688, loss-lb:0.1828, loss-ulb:0.0481, weight:1.79, lr:0.0007
[02:59:37.881] iteration:5198  t-loss:0.5993, loss-lb:0.3174, loss-ulb:0.1578, weight:1.79, lr:0.0007
[02:59:38.196] iteration:5199  t-loss:0.4685, loss-lb:0.4317, loss-ulb:0.0205, weight:1.79, lr:0.0007
[02:59:38.514] iteration:5200  t-loss:0.8675, loss-lb:0.3954, loss-ulb:0.2642, weight:1.79, lr:0.0007
[02:59:39.731] iteration:5201  t-loss:0.4827, loss-lb:0.2363, loss-ulb:0.1379, weight:1.79, lr:0.0007
[02:59:40.074] iteration:5202  t-loss:0.3702, loss-lb:0.2652, loss-ulb:0.0588, weight:1.79, lr:0.0007
[02:59:40.404] iteration:5203  t-loss:0.6642, loss-lb:0.2447, loss-ulb:0.2347, weight:1.79, lr:0.0007
[02:59:40.728] iteration:5204  t-loss:0.3382, loss-lb:0.1946, loss-ulb:0.0803, weight:1.79, lr:0.0007
[02:59:41.053] iteration:5205  t-loss:0.4396, loss-lb:0.2990, loss-ulb:0.0787, weight:1.79, lr:0.0007
[02:59:41.372] iteration:5206  t-loss:0.6562, loss-lb:0.3161, loss-ulb:0.1903, weight:1.79, lr:0.0007
[02:59:41.692] iteration:5207  t-loss:0.5486, loss-lb:0.2246, loss-ulb:0.1813, weight:1.79, lr:0.0007
[02:59:42.011] iteration:5208  t-loss:0.4684, loss-lb:0.2041, loss-ulb:0.1479, weight:1.79, lr:0.0007
[02:59:42.331] iteration:5209  t-loss:0.3279, loss-lb:0.2583, loss-ulb:0.0389, weight:1.79, lr:0.0007
[02:59:42.651] iteration:5210  t-loss:0.3196, loss-lb:0.1993, loss-ulb:0.0674, weight:1.79, lr:0.0007
[02:59:42.972] iteration:5211  t-loss:0.7690, loss-lb:0.4386, loss-ulb:0.1849, weight:1.79, lr:0.0007
[02:59:43.292] iteration:5212  t-loss:0.9449, loss-lb:0.2843, loss-ulb:0.3696, weight:1.79, lr:0.0007
[02:59:43.621] iteration:5213  t-loss:0.3587, loss-lb:0.2130, loss-ulb:0.0815, weight:1.79, lr:0.0007
[02:59:43.939] iteration:5214  t-loss:0.3792, loss-lb:0.1739, loss-ulb:0.1148, weight:1.79, lr:0.0007
[02:59:44.259] iteration:5215  t-loss:0.4056, loss-lb:0.1731, loss-ulb:0.1301, weight:1.79, lr:0.0007
[02:59:44.580] iteration:5216  t-loss:0.8101, loss-lb:0.2246, loss-ulb:0.3276, weight:1.79, lr:0.0007
[02:59:44.900] iteration:5217  t-loss:0.3736, loss-lb:0.2544, loss-ulb:0.0667, weight:1.79, lr:0.0007
[02:59:45.218] iteration:5218  t-loss:0.9688, loss-lb:0.2101, loss-ulb:0.4245, weight:1.79, lr:0.0007
[02:59:45.538] iteration:5219  t-loss:0.4001, loss-lb:0.1770, loss-ulb:0.1249, weight:1.79, lr:0.0007
[02:59:45.856] iteration:5220  t-loss:0.3419, loss-lb:0.2446, loss-ulb:0.0544, weight:1.79, lr:0.0007
[02:59:46.172] iteration:5221  t-loss:0.7322, loss-lb:0.2501, loss-ulb:0.2698, weight:1.79, lr:0.0007
[02:59:46.490] iteration:5222  t-loss:0.3735, loss-lb:0.1516, loss-ulb:0.1241, weight:1.79, lr:0.0007
[02:59:46.807] iteration:5223  t-loss:0.5610, loss-lb:0.3214, loss-ulb:0.1341, weight:1.79, lr:0.0007
[02:59:47.124] iteration:5224  t-loss:0.4853, loss-lb:0.4222, loss-ulb:0.0353, weight:1.79, lr:0.0007
[02:59:47.443] iteration:5225  t-loss:0.8486, loss-lb:0.2273, loss-ulb:0.3476, weight:1.79, lr:0.0007
[03:01:42.331] iteration 5225 : dice_score: 0.830877 best_dice: 0.840700
[03:01:42.331]  <<Test>> - Ep:208  - Dice-S/T:81.52/83.09, Best-S:82.88, Best-T:84.07
[03:01:42.331]           - AvgLoss(lb/ulb/all):0.25/0.17/0.55
[03:01:43.434] iteration:5226  t-loss:0.5984, loss-lb:0.2307, loss-ulb:0.2058, weight:1.79, lr:0.0007
[03:01:43.756] iteration:5227  t-loss:0.4118, loss-lb:0.2609, loss-ulb:0.0844, weight:1.79, lr:0.0007
[03:01:44.074] iteration:5228  t-loss:0.6780, loss-lb:0.3403, loss-ulb:0.1889, weight:1.79, lr:0.0007
[03:01:44.387] iteration:5229  t-loss:0.7196, loss-lb:0.1450, loss-ulb:0.3215, weight:1.79, lr:0.0007
[03:01:44.701] iteration:5230  t-loss:0.3238, loss-lb:0.1598, loss-ulb:0.0918, weight:1.79, lr:0.0007
[03:01:45.015] iteration:5231  t-loss:0.4297, loss-lb:0.1646, loss-ulb:0.1484, weight:1.79, lr:0.0007
[03:01:45.328] iteration:5232  t-loss:0.2392, loss-lb:0.1573, loss-ulb:0.0458, weight:1.79, lr:0.0007
[03:01:45.642] iteration:5233  t-loss:0.9952, loss-lb:0.1991, loss-ulb:0.4454, weight:1.79, lr:0.0007
[03:01:45.956] iteration:5234  t-loss:0.6501, loss-lb:0.2005, loss-ulb:0.2515, weight:1.79, lr:0.0007
[03:01:46.273] iteration:5235  t-loss:0.5966, loss-lb:0.3146, loss-ulb:0.1578, weight:1.79, lr:0.0007
[03:01:46.587] iteration:5236  t-loss:0.3439, loss-lb:0.1996, loss-ulb:0.0808, weight:1.79, lr:0.0007
[03:01:46.902] iteration:5237  t-loss:0.5896, loss-lb:0.2109, loss-ulb:0.2119, weight:1.79, lr:0.0007
[03:01:47.220] iteration:5238  t-loss:0.4302, loss-lb:0.3254, loss-ulb:0.0586, weight:1.79, lr:0.0007
[03:01:47.533] iteration:5239  t-loss:0.9149, loss-lb:0.2012, loss-ulb:0.3993, weight:1.79, lr:0.0007
[03:01:47.848] iteration:5240  t-loss:0.2776, loss-lb:0.1923, loss-ulb:0.0477, weight:1.79, lr:0.0007
[03:01:48.161] iteration:5241  t-loss:1.4036, loss-lb:0.1341, loss-ulb:0.7103, weight:1.79, lr:0.0007
[03:01:48.481] iteration:5242  t-loss:0.1922, loss-lb:0.1477, loss-ulb:0.0249, weight:1.79, lr:0.0007
[03:01:48.798] iteration:5243  t-loss:0.2321, loss-lb:0.1298, loss-ulb:0.0572, weight:1.79, lr:0.0007
[03:01:49.113] iteration:5244  t-loss:0.4194, loss-lb:0.2673, loss-ulb:0.0851, weight:1.79, lr:0.0007
[03:01:49.432] iteration:5245  t-loss:0.4921, loss-lb:0.2044, loss-ulb:0.1610, weight:1.79, lr:0.0007
[03:01:49.750] iteration:5246  t-loss:0.6605, loss-lb:0.2060, loss-ulb:0.2543, weight:1.79, lr:0.0007
[03:01:50.065] iteration:5247  t-loss:0.5156, loss-lb:0.3065, loss-ulb:0.1170, weight:1.79, lr:0.0007
[03:01:50.377] iteration:5248  t-loss:0.9472, loss-lb:0.1659, loss-ulb:0.4372, weight:1.79, lr:0.0007
[03:01:50.693] iteration:5249  t-loss:0.3709, loss-lb:0.1754, loss-ulb:0.1094, weight:1.79, lr:0.0007
[03:01:51.009] iteration:5250  t-loss:0.2737, loss-lb:0.1911, loss-ulb:0.0462, weight:1.79, lr:0.0007
[03:01:52.239] iteration:5251  t-loss:0.3645, loss-lb:0.1858, loss-ulb:0.0966, weight:1.85, lr:0.0007
[03:01:52.576] iteration:5252  t-loss:0.4899, loss-lb:0.1656, loss-ulb:0.1754, weight:1.85, lr:0.0007
[03:01:52.915] iteration:5253  t-loss:1.2367, loss-lb:0.3250, loss-ulb:0.4929, weight:1.85, lr:0.0007
[03:01:53.255] iteration:5254  t-loss:0.7387, loss-lb:0.4416, loss-ulb:0.1606, weight:1.85, lr:0.0007
[03:01:53.574] iteration:5255  t-loss:0.4958, loss-lb:0.2195, loss-ulb:0.1494, weight:1.85, lr:0.0007
[03:01:53.899] iteration:5256  t-loss:0.5755, loss-lb:0.5193, loss-ulb:0.0304, weight:1.85, lr:0.0007
[03:01:54.221] iteration:5257  t-loss:0.6075, loss-lb:0.4698, loss-ulb:0.0745, weight:1.85, lr:0.0007
[03:01:54.538] iteration:5258  t-loss:1.1184, loss-lb:0.3252, loss-ulb:0.4289, weight:1.85, lr:0.0007
[03:01:54.857] iteration:5259  t-loss:0.3596, loss-lb:0.2252, loss-ulb:0.0726, weight:1.85, lr:0.0007
[03:01:55.178] iteration:5260  t-loss:0.3720, loss-lb:0.3436, loss-ulb:0.0153, weight:1.85, lr:0.0007
[03:01:55.499] iteration:5261  t-loss:0.2605, loss-lb:0.1616, loss-ulb:0.0535, weight:1.85, lr:0.0007
[03:01:55.826] iteration:5262  t-loss:0.4885, loss-lb:0.2299, loss-ulb:0.1398, weight:1.85, lr:0.0007
[03:01:56.144] iteration:5263  t-loss:0.3793, loss-lb:0.2480, loss-ulb:0.0710, weight:1.85, lr:0.0007
[03:01:56.465] iteration:5264  t-loss:0.5529, loss-lb:0.2902, loss-ulb:0.1420, weight:1.85, lr:0.0007
[03:01:56.777] iteration:5265  t-loss:1.0238, loss-lb:0.1899, loss-ulb:0.4508, weight:1.85, lr:0.0007
[03:01:57.099] iteration:5266  t-loss:1.9045, loss-lb:0.2574, loss-ulb:0.8905, weight:1.85, lr:0.0007
[03:01:57.418] iteration:5267  t-loss:0.3039, loss-lb:0.1930, loss-ulb:0.0600, weight:1.85, lr:0.0007
[03:01:57.733] iteration:5268  t-loss:0.3826, loss-lb:0.2025, loss-ulb:0.0974, weight:1.85, lr:0.0007
[03:01:58.051] iteration:5269  t-loss:1.4182, loss-lb:0.7053, loss-ulb:0.3854, weight:1.85, lr:0.0007
[03:01:58.367] iteration:5270  t-loss:0.8402, loss-lb:0.3633, loss-ulb:0.2578, weight:1.85, lr:0.0007
[03:01:58.684] iteration:5271  t-loss:0.6728, loss-lb:0.3531, loss-ulb:0.1729, weight:1.85, lr:0.0007
[03:01:59.002] iteration:5272  t-loss:0.4652, loss-lb:0.2523, loss-ulb:0.1151, weight:1.85, lr:0.0007
[03:01:59.322] iteration:5273  t-loss:0.4485, loss-lb:0.2389, loss-ulb:0.1133, weight:1.85, lr:0.0007
[03:01:59.635] iteration:5274  t-loss:0.3484, loss-lb:0.1888, loss-ulb:0.0863, weight:1.85, lr:0.0007
[03:01:59.948] iteration:5275  t-loss:0.5592, loss-lb:0.3783, loss-ulb:0.0978, weight:1.85, lr:0.0007
[03:02:01.156] iteration:5276  t-loss:0.5375, loss-lb:0.1453, loss-ulb:0.2121, weight:1.85, lr:0.0007
[03:02:01.489] iteration:5277  t-loss:0.4002, loss-lb:0.2224, loss-ulb:0.0961, weight:1.85, lr:0.0007
[03:02:01.815] iteration:5278  t-loss:0.4738, loss-lb:0.1685, loss-ulb:0.1651, weight:1.85, lr:0.0007
[03:02:02.141] iteration:5279  t-loss:0.3780, loss-lb:0.1749, loss-ulb:0.1098, weight:1.85, lr:0.0007
[03:02:02.461] iteration:5280  t-loss:0.2912, loss-lb:0.2192, loss-ulb:0.0390, weight:1.85, lr:0.0007
[03:02:02.788] iteration:5281  t-loss:0.6329, loss-lb:0.3993, loss-ulb:0.1263, weight:1.85, lr:0.0007
[03:02:03.132] iteration:5282  t-loss:0.6997, loss-lb:0.4279, loss-ulb:0.1470, weight:1.85, lr:0.0007
[03:02:03.454] iteration:5283  t-loss:0.6305, loss-lb:0.1401, loss-ulb:0.2652, weight:1.85, lr:0.0007
[03:02:03.772] iteration:5284  t-loss:0.5830, loss-lb:0.3966, loss-ulb:0.1008, weight:1.85, lr:0.0007
[03:02:04.087] iteration:5285  t-loss:0.3713, loss-lb:0.2848, loss-ulb:0.0468, weight:1.85, lr:0.0007
[03:02:04.403] iteration:5286  t-loss:0.4030, loss-lb:0.1778, loss-ulb:0.1218, weight:1.85, lr:0.0007
[03:02:04.724] iteration:5287  t-loss:0.4758, loss-lb:0.2609, loss-ulb:0.1162, weight:1.85, lr:0.0007
[03:02:05.050] iteration:5288  t-loss:0.4168, loss-lb:0.2774, loss-ulb:0.0754, weight:1.85, lr:0.0007
[03:02:05.366] iteration:5289  t-loss:0.5025, loss-lb:0.3530, loss-ulb:0.0809, weight:1.85, lr:0.0007
[03:02:05.686] iteration:5290  t-loss:0.2785, loss-lb:0.2284, loss-ulb:0.0271, weight:1.85, lr:0.0007
[03:02:06.004] iteration:5291  t-loss:1.3555, loss-lb:0.1893, loss-ulb:0.6305, weight:1.85, lr:0.0007
[03:02:06.320] iteration:5292  t-loss:0.2238, loss-lb:0.1819, loss-ulb:0.0226, weight:1.85, lr:0.0007
[03:02:06.637] iteration:5293  t-loss:0.3369, loss-lb:0.1517, loss-ulb:0.1001, weight:1.85, lr:0.0007
[03:02:06.951] iteration:5294  t-loss:0.2754, loss-lb:0.2240, loss-ulb:0.0278, weight:1.85, lr:0.0007
[03:02:07.266] iteration:5295  t-loss:0.5481, loss-lb:0.2532, loss-ulb:0.1594, weight:1.85, lr:0.0007
[03:02:07.584] iteration:5296  t-loss:0.4749, loss-lb:0.4094, loss-ulb:0.0354, weight:1.85, lr:0.0007
[03:02:07.903] iteration:5297  t-loss:0.5171, loss-lb:0.4271, loss-ulb:0.0487, weight:1.85, lr:0.0007
[03:02:08.219] iteration:5298  t-loss:0.5596, loss-lb:0.2525, loss-ulb:0.1660, weight:1.85, lr:0.0007
[03:02:08.535] iteration:5299  t-loss:0.4010, loss-lb:0.2668, loss-ulb:0.0725, weight:1.85, lr:0.0007
[03:02:08.851] iteration:5300  t-loss:0.6053, loss-lb:0.4209, loss-ulb:0.0997, weight:1.85, lr:0.0007
[03:02:09.939] iteration:5301  t-loss:1.0241, loss-lb:0.2846, loss-ulb:0.3998, weight:1.85, lr:0.0007
[03:02:10.269] iteration:5302  t-loss:0.3626, loss-lb:0.2692, loss-ulb:0.0505, weight:1.85, lr:0.0007
[03:02:10.591] iteration:5303  t-loss:0.5204, loss-lb:0.2859, loss-ulb:0.1267, weight:1.85, lr:0.0007
[03:02:10.906] iteration:5304  t-loss:0.3895, loss-lb:0.2557, loss-ulb:0.0723, weight:1.85, lr:0.0007
[03:02:11.222] iteration:5305  t-loss:0.6756, loss-lb:0.3003, loss-ulb:0.2029, weight:1.85, lr:0.0007
[03:02:11.535] iteration:5306  t-loss:0.4760, loss-lb:0.1656, loss-ulb:0.1678, weight:1.85, lr:0.0007
[03:02:11.849] iteration:5307  t-loss:0.3025, loss-lb:0.2002, loss-ulb:0.0553, weight:1.85, lr:0.0007
[03:02:12.164] iteration:5308  t-loss:0.9680, loss-lb:0.2618, loss-ulb:0.3818, weight:1.85, lr:0.0007
[03:02:12.482] iteration:5309  t-loss:0.3147, loss-lb:0.1636, loss-ulb:0.0817, weight:1.85, lr:0.0007
[03:02:12.792] iteration:5310  t-loss:1.1684, loss-lb:0.2515, loss-ulb:0.4957, weight:1.85, lr:0.0007
[03:02:13.111] iteration:5311  t-loss:0.6085, loss-lb:0.4187, loss-ulb:0.1026, weight:1.85, lr:0.0007
[03:02:13.429] iteration:5312  t-loss:0.5354, loss-lb:0.3558, loss-ulb:0.0971, weight:1.85, lr:0.0007
[03:02:13.748] iteration:5313  t-loss:1.3917, loss-lb:0.3074, loss-ulb:0.5862, weight:1.85, lr:0.0007
[03:02:14.068] iteration:5314  t-loss:0.5632, loss-lb:0.2155, loss-ulb:0.1879, weight:1.85, lr:0.0007
[03:02:14.387] iteration:5315  t-loss:0.4178, loss-lb:0.2574, loss-ulb:0.0867, weight:1.85, lr:0.0007
[03:02:14.703] iteration:5316  t-loss:0.4989, loss-lb:0.1844, loss-ulb:0.1700, weight:1.85, lr:0.0007
[03:02:15.020] iteration:5317  t-loss:0.5255, loss-lb:0.2091, loss-ulb:0.1710, weight:1.85, lr:0.0007
[03:02:15.331] iteration:5318  t-loss:1.5959, loss-lb:0.2071, loss-ulb:0.7508, weight:1.85, lr:0.0007
[03:02:15.647] iteration:5319  t-loss:0.6759, loss-lb:0.2232, loss-ulb:0.2447, weight:1.85, lr:0.0007
[03:02:15.961] iteration:5320  t-loss:1.4872, loss-lb:0.1614, loss-ulb:0.7168, weight:1.85, lr:0.0007
[03:02:16.276] iteration:5321  t-loss:0.4870, loss-lb:0.1908, loss-ulb:0.1601, weight:1.85, lr:0.0007
[03:02:16.591] iteration:5322  t-loss:0.6399, loss-lb:0.2503, loss-ulb:0.2106, weight:1.85, lr:0.0007
[03:02:16.908] iteration:5323  t-loss:0.3072, loss-lb:0.1826, loss-ulb:0.0673, weight:1.85, lr:0.0007
[03:02:17.222] iteration:5324  t-loss:1.3030, loss-lb:0.2990, loss-ulb:0.5428, weight:1.85, lr:0.0007
[03:02:17.541] iteration:5325  t-loss:0.6977, loss-lb:0.4586, loss-ulb:0.1293, weight:1.85, lr:0.0007
[03:04:15.437] iteration 5325 : dice_score: 0.841188 best_dice: 0.841200
[03:04:15.437]  <<Test>> - Ep:212  - Dice-S/T:83.27/84.12, Best-S:83.27, Best-T:84.12
[03:04:15.437]           - AvgLoss(lb/ulb/all):0.25/0.27/0.75
[03:04:16.466] iteration:5326  t-loss:0.5505, loss-lb:0.2437, loss-ulb:0.1659, weight:1.85, lr:0.0007
[03:04:16.789] iteration:5327  t-loss:0.6243, loss-lb:0.2694, loss-ulb:0.1919, weight:1.85, lr:0.0007
[03:04:17.103] iteration:5328  t-loss:0.2510, loss-lb:0.1770, loss-ulb:0.0400, weight:1.85, lr:0.0007
[03:04:17.418] iteration:5329  t-loss:0.3908, loss-lb:0.3584, loss-ulb:0.0175, weight:1.85, lr:0.0007
[03:04:17.733] iteration:5330  t-loss:0.4132, loss-lb:0.3440, loss-ulb:0.0374, weight:1.85, lr:0.0007
[03:04:18.049] iteration:5331  t-loss:0.5059, loss-lb:0.1363, loss-ulb:0.1998, weight:1.85, lr:0.0007
[03:04:18.368] iteration:5332  t-loss:0.5442, loss-lb:0.1865, loss-ulb:0.1934, weight:1.85, lr:0.0007
[03:04:18.679] iteration:5333  t-loss:0.5864, loss-lb:0.2550, loss-ulb:0.1791, weight:1.85, lr:0.0007
[03:04:18.994] iteration:5334  t-loss:0.3557, loss-lb:0.1502, loss-ulb:0.1111, weight:1.85, lr:0.0007
[03:04:19.310] iteration:5335  t-loss:0.5155, loss-lb:0.1919, loss-ulb:0.1750, weight:1.85, lr:0.0007
[03:04:19.627] iteration:5336  t-loss:0.4175, loss-lb:0.3596, loss-ulb:0.0313, weight:1.85, lr:0.0007
[03:04:19.939] iteration:5337  t-loss:0.7296, loss-lb:0.2635, loss-ulb:0.2520, weight:1.85, lr:0.0007
[03:04:20.252] iteration:5338  t-loss:0.1911, loss-lb:0.1320, loss-ulb:0.0320, weight:1.85, lr:0.0007
[03:04:20.574] iteration:5339  t-loss:0.6405, loss-lb:0.3196, loss-ulb:0.1735, weight:1.85, lr:0.0007
[03:04:20.890] iteration:5340  t-loss:0.2887, loss-lb:0.2191, loss-ulb:0.0376, weight:1.85, lr:0.0007
[03:04:21.202] iteration:5341  t-loss:0.4942, loss-lb:0.1656, loss-ulb:0.1777, weight:1.85, lr:0.0007
[03:04:21.516] iteration:5342  t-loss:0.3028, loss-lb:0.2487, loss-ulb:0.0292, weight:1.85, lr:0.0007
[03:04:21.835] iteration:5343  t-loss:0.4786, loss-lb:0.4172, loss-ulb:0.0332, weight:1.85, lr:0.0007
[03:04:22.151] iteration:5344  t-loss:0.3597, loss-lb:0.2374, loss-ulb:0.0661, weight:1.85, lr:0.0007
[03:04:22.466] iteration:5345  t-loss:0.2363, loss-lb:0.1744, loss-ulb:0.0334, weight:1.85, lr:0.0007
[03:04:22.780] iteration:5346  t-loss:1.0104, loss-lb:0.2228, loss-ulb:0.4258, weight:1.85, lr:0.0007
[03:04:23.095] iteration:5347  t-loss:0.3391, loss-lb:0.2632, loss-ulb:0.0410, weight:1.85, lr:0.0007
[03:04:23.408] iteration:5348  t-loss:0.4257, loss-lb:0.1891, loss-ulb:0.1279, weight:1.85, lr:0.0007
[03:04:23.720] iteration:5349  t-loss:0.7144, loss-lb:0.6391, loss-ulb:0.0407, weight:1.85, lr:0.0007
[03:04:24.033] iteration:5350  t-loss:0.5601, loss-lb:0.2206, loss-ulb:0.1835, weight:1.85, lr:0.0007
[03:04:25.121] iteration:5351  t-loss:0.5252, loss-lb:0.2519, loss-ulb:0.1478, weight:1.85, lr:0.0007
[03:04:25.447] iteration:5352  t-loss:0.3809, loss-lb:0.2506, loss-ulb:0.0704, weight:1.85, lr:0.0007
[03:04:25.770] iteration:5353  t-loss:0.4225, loss-lb:0.2251, loss-ulb:0.1067, weight:1.85, lr:0.0007
[03:04:26.090] iteration:5354  t-loss:0.5364, loss-lb:0.3188, loss-ulb:0.1176, weight:1.85, lr:0.0007
[03:04:26.405] iteration:5355  t-loss:1.3318, loss-lb:0.2356, loss-ulb:0.5926, weight:1.85, lr:0.0007
[03:04:26.721] iteration:5356  t-loss:0.2010, loss-lb:0.1509, loss-ulb:0.0271, weight:1.85, lr:0.0007
[03:04:27.038] iteration:5357  t-loss:0.6042, loss-lb:0.3415, loss-ulb:0.1420, weight:1.85, lr:0.0007
[03:04:27.354] iteration:5358  t-loss:1.0412, loss-lb:0.2366, loss-ulb:0.4350, weight:1.85, lr:0.0007
[03:04:27.675] iteration:5359  t-loss:0.5804, loss-lb:0.3862, loss-ulb:0.1050, weight:1.85, lr:0.0007
[03:04:27.994] iteration:5360  t-loss:0.3612, loss-lb:0.2624, loss-ulb:0.0534, weight:1.85, lr:0.0007
[03:04:28.313] iteration:5361  t-loss:0.8775, loss-lb:0.3452, loss-ulb:0.2878, weight:1.85, lr:0.0007
[03:04:28.628] iteration:5362  t-loss:0.4563, loss-lb:0.2744, loss-ulb:0.0983, weight:1.85, lr:0.0007
[03:04:28.949] iteration:5363  t-loss:0.8170, loss-lb:0.4018, loss-ulb:0.2245, weight:1.85, lr:0.0007
[03:04:29.266] iteration:5364  t-loss:0.8586, loss-lb:0.2322, loss-ulb:0.3386, weight:1.85, lr:0.0007
[03:04:29.582] iteration:5365  t-loss:0.4632, loss-lb:0.2670, loss-ulb:0.1061, weight:1.85, lr:0.0007
[03:04:29.896] iteration:5366  t-loss:0.3385, loss-lb:0.2716, loss-ulb:0.0362, weight:1.85, lr:0.0007
[03:04:30.215] iteration:5367  t-loss:1.1618, loss-lb:0.3501, loss-ulb:0.4388, weight:1.85, lr:0.0007
[03:04:30.532] iteration:5368  t-loss:0.8370, loss-lb:0.3233, loss-ulb:0.2777, weight:1.85, lr:0.0007
[03:04:30.846] iteration:5369  t-loss:0.5340, loss-lb:0.4457, loss-ulb:0.0477, weight:1.85, lr:0.0007
[03:04:31.159] iteration:5370  t-loss:0.6958, loss-lb:0.2576, loss-ulb:0.2369, weight:1.85, lr:0.0007
[03:04:31.475] iteration:5371  t-loss:0.3574, loss-lb:0.1675, loss-ulb:0.1027, weight:1.85, lr:0.0007
[03:04:31.786] iteration:5372  t-loss:0.3678, loss-lb:0.2250, loss-ulb:0.0772, weight:1.85, lr:0.0007
[03:04:32.102] iteration:5373  t-loss:0.6828, loss-lb:0.3801, loss-ulb:0.1636, weight:1.85, lr:0.0007
[03:04:32.416] iteration:5374  t-loss:1.5736, loss-lb:0.4277, loss-ulb:0.6195, weight:1.85, lr:0.0007
[03:04:32.732] iteration:5375  t-loss:0.6884, loss-lb:0.3025, loss-ulb:0.2086, weight:1.85, lr:0.0007
[03:04:33.906] iteration:5376  t-loss:0.3808, loss-lb:0.2091, loss-ulb:0.0928, weight:1.85, lr:0.0007
[03:04:34.244] iteration:5377  t-loss:1.0918, loss-lb:0.2691, loss-ulb:0.4448, weight:1.85, lr:0.0007
[03:04:34.568] iteration:5378  t-loss:0.4632, loss-lb:0.1868, loss-ulb:0.1494, weight:1.85, lr:0.0007
[03:04:34.893] iteration:5379  t-loss:0.7794, loss-lb:0.3321, loss-ulb:0.2418, weight:1.85, lr:0.0007
[03:04:35.211] iteration:5380  t-loss:0.4224, loss-lb:0.2436, loss-ulb:0.0967, weight:1.85, lr:0.0007
[03:04:35.530] iteration:5381  t-loss:0.2750, loss-lb:0.2244, loss-ulb:0.0274, weight:1.85, lr:0.0007
[03:04:35.849] iteration:5382  t-loss:0.3583, loss-lb:0.2481, loss-ulb:0.0596, weight:1.85, lr:0.0007
[03:04:36.168] iteration:5383  t-loss:1.1200, loss-lb:0.4195, loss-ulb:0.3787, weight:1.85, lr:0.0007
[03:04:36.486] iteration:5384  t-loss:0.8479, loss-lb:0.1455, loss-ulb:0.3797, weight:1.85, lr:0.0007
[03:04:36.802] iteration:5385  t-loss:0.3124, loss-lb:0.2036, loss-ulb:0.0588, weight:1.85, lr:0.0007
[03:04:37.123] iteration:5386  t-loss:0.4983, loss-lb:0.2842, loss-ulb:0.1157, weight:1.85, lr:0.0007
[03:04:37.441] iteration:5387  t-loss:0.4121, loss-lb:0.2376, loss-ulb:0.0943, weight:1.85, lr:0.0007
[03:04:37.757] iteration:5388  t-loss:0.5342, loss-lb:0.2989, loss-ulb:0.1272, weight:1.85, lr:0.0007
[03:04:38.074] iteration:5389  t-loss:0.6826, loss-lb:0.2046, loss-ulb:0.2584, weight:1.85, lr:0.0007
[03:04:38.391] iteration:5390  t-loss:0.3333, loss-lb:0.1861, loss-ulb:0.0796, weight:1.85, lr:0.0007
[03:04:38.708] iteration:5391  t-loss:0.3272, loss-lb:0.2417, loss-ulb:0.0462, weight:1.85, lr:0.0007
[03:04:39.026] iteration:5392  t-loss:0.6796, loss-lb:0.3152, loss-ulb:0.1970, weight:1.85, lr:0.0007
[03:04:39.338] iteration:5393  t-loss:0.2646, loss-lb:0.1417, loss-ulb:0.0664, weight:1.85, lr:0.0007
[03:04:39.651] iteration:5394  t-loss:1.4556, loss-lb:0.4022, loss-ulb:0.5695, weight:1.85, lr:0.0007
[03:04:39.964] iteration:5395  t-loss:0.4667, loss-lb:0.2380, loss-ulb:0.1237, weight:1.85, lr:0.0007
[03:04:40.278] iteration:5396  t-loss:0.4517, loss-lb:0.1959, loss-ulb:0.1383, weight:1.85, lr:0.0007
[03:04:40.590] iteration:5397  t-loss:1.1955, loss-lb:0.2443, loss-ulb:0.5143, weight:1.85, lr:0.0007
[03:04:40.904] iteration:5398  t-loss:0.6044, loss-lb:0.3169, loss-ulb:0.1554, weight:1.85, lr:0.0007
[03:04:41.220] iteration:5399  t-loss:0.3827, loss-lb:0.2422, loss-ulb:0.0760, weight:1.85, lr:0.0007
[03:04:41.534] iteration:5400  t-loss:0.9898, loss-lb:0.4171, loss-ulb:0.3096, weight:1.85, lr:0.0007
[03:04:42.849] iteration:5401  t-loss:1.0535, loss-lb:0.1840, loss-ulb:0.4570, weight:1.90, lr:0.0007
[03:04:43.183] iteration:5402  t-loss:0.4053, loss-lb:0.1714, loss-ulb:0.1230, weight:1.90, lr:0.0007
[03:04:43.512] iteration:5403  t-loss:1.2708, loss-lb:0.4226, loss-ulb:0.4458, weight:1.90, lr:0.0007
[03:04:43.828] iteration:5404  t-loss:0.2067, loss-lb:0.1499, loss-ulb:0.0299, weight:1.90, lr:0.0007
[03:04:44.147] iteration:5405  t-loss:0.8362, loss-lb:0.1950, loss-ulb:0.3370, weight:1.90, lr:0.0007
[03:04:44.472] iteration:5406  t-loss:1.1549, loss-lb:0.5399, loss-ulb:0.3233, weight:1.90, lr:0.0007
[03:04:44.797] iteration:5407  t-loss:0.4126, loss-lb:0.2141, loss-ulb:0.1044, weight:1.90, lr:0.0007
[03:04:45.119] iteration:5408  t-loss:0.2689, loss-lb:0.1792, loss-ulb:0.0471, weight:1.90, lr:0.0007
[03:04:45.445] iteration:5409  t-loss:1.1978, loss-lb:0.4475, loss-ulb:0.3944, weight:1.90, lr:0.0007
[03:04:45.771] iteration:5410  t-loss:0.2968, loss-lb:0.2256, loss-ulb:0.0374, weight:1.90, lr:0.0007
[03:04:46.100] iteration:5411  t-loss:0.5889, loss-lb:0.3329, loss-ulb:0.1346, weight:1.90, lr:0.0007
[03:04:46.423] iteration:5412  t-loss:0.2984, loss-lb:0.2377, loss-ulb:0.0319, weight:1.90, lr:0.0007
[03:04:46.742] iteration:5413  t-loss:0.3860, loss-lb:0.2481, loss-ulb:0.0725, weight:1.90, lr:0.0007
[03:04:47.063] iteration:5414  t-loss:0.4052, loss-lb:0.3496, loss-ulb:0.0292, weight:1.90, lr:0.0007
[03:04:47.381] iteration:5415  t-loss:0.5815, loss-lb:0.1951, loss-ulb:0.2031, weight:1.90, lr:0.0007
[03:04:47.707] iteration:5416  t-loss:1.3850, loss-lb:0.4301, loss-ulb:0.5019, weight:1.90, lr:0.0007
[03:04:48.033] iteration:5417  t-loss:1.3982, loss-lb:0.2508, loss-ulb:0.6031, weight:1.90, lr:0.0007
[03:04:48.353] iteration:5418  t-loss:0.5972, loss-lb:0.4656, loss-ulb:0.0692, weight:1.90, lr:0.0007
[03:04:48.667] iteration:5419  t-loss:0.4139, loss-lb:0.3396, loss-ulb:0.0390, weight:1.90, lr:0.0007
[03:04:48.982] iteration:5420  t-loss:0.6948, loss-lb:0.1597, loss-ulb:0.2812, weight:1.90, lr:0.0007
[03:04:49.297] iteration:5421  t-loss:0.2978, loss-lb:0.2348, loss-ulb:0.0331, weight:1.90, lr:0.0007
[03:04:49.612] iteration:5422  t-loss:0.5820, loss-lb:0.2195, loss-ulb:0.1905, weight:1.90, lr:0.0007
[03:04:49.929] iteration:5423  t-loss:0.4795, loss-lb:0.3950, loss-ulb:0.0444, weight:1.90, lr:0.0007
[03:04:50.245] iteration:5424  t-loss:0.4253, loss-lb:0.2332, loss-ulb:0.1010, weight:1.90, lr:0.0007
[03:04:50.560] iteration:5425  t-loss:0.5043, loss-lb:0.1846, loss-ulb:0.1680, weight:1.90, lr:0.0007
[03:06:45.643] iteration 5425 : dice_score: 0.843401 best_dice: 0.843400
[03:06:45.643]  <<Test>> - Ep:216  - Dice-S/T:82.78/84.34, Best-S:83.27, Best-T:84.34
[03:06:45.643]           - AvgLoss(lb/ulb/all):0.28/0.17/0.62
[03:06:46.802] iteration:5426  t-loss:0.3123, loss-lb:0.2106, loss-ulb:0.0535, weight:1.90, lr:0.0007
[03:06:47.127] iteration:5427  t-loss:0.3148, loss-lb:0.1712, loss-ulb:0.0755, weight:1.90, lr:0.0007
[03:06:47.445] iteration:5428  t-loss:0.3345, loss-lb:0.1641, loss-ulb:0.0896, weight:1.90, lr:0.0007
[03:06:47.761] iteration:5429  t-loss:0.5726, loss-lb:0.1765, loss-ulb:0.2082, weight:1.90, lr:0.0007
[03:06:48.079] iteration:5430  t-loss:0.5920, loss-lb:0.1780, loss-ulb:0.2176, weight:1.90, lr:0.0007
[03:06:48.394] iteration:5431  t-loss:0.3319, loss-lb:0.2536, loss-ulb:0.0411, weight:1.90, lr:0.0007
[03:06:48.709] iteration:5432  t-loss:0.2594, loss-lb:0.1338, loss-ulb:0.0660, weight:1.90, lr:0.0007
[03:06:49.023] iteration:5433  t-loss:0.5148, loss-lb:0.2825, loss-ulb:0.1221, weight:1.90, lr:0.0007
[03:06:49.338] iteration:5434  t-loss:0.6833, loss-lb:0.1860, loss-ulb:0.2614, weight:1.90, lr:0.0007
[03:06:49.656] iteration:5435  t-loss:0.5499, loss-lb:0.1187, loss-ulb:0.2267, weight:1.90, lr:0.0007
[03:06:49.972] iteration:5436  t-loss:0.5234, loss-lb:0.2111, loss-ulb:0.1642, weight:1.90, lr:0.0007
[03:06:50.288] iteration:5437  t-loss:0.6652, loss-lb:0.3296, loss-ulb:0.1764, weight:1.90, lr:0.0007
[03:06:50.603] iteration:5438  t-loss:0.5348, loss-lb:0.3170, loss-ulb:0.1145, weight:1.90, lr:0.0007
[03:06:50.918] iteration:5439  t-loss:0.3438, loss-lb:0.2319, loss-ulb:0.0588, weight:1.90, lr:0.0007
[03:06:51.236] iteration:5440  t-loss:0.2977, loss-lb:0.2534, loss-ulb:0.0232, weight:1.90, lr:0.0007
[03:06:51.554] iteration:5441  t-loss:0.7181, loss-lb:0.3815, loss-ulb:0.1769, weight:1.90, lr:0.0007
[03:06:51.878] iteration:5442  t-loss:0.5598, loss-lb:0.3201, loss-ulb:0.1260, weight:1.90, lr:0.0007
[03:06:52.196] iteration:5443  t-loss:0.4695, loss-lb:0.2822, loss-ulb:0.0985, weight:1.90, lr:0.0007
[03:06:52.512] iteration:5444  t-loss:0.2800, loss-lb:0.1700, loss-ulb:0.0578, weight:1.90, lr:0.0007
[03:06:52.828] iteration:5445  t-loss:0.7782, loss-lb:0.3646, loss-ulb:0.2175, weight:1.90, lr:0.0007
[03:06:53.144] iteration:5446  t-loss:0.4870, loss-lb:0.2977, loss-ulb:0.0995, weight:1.90, lr:0.0007
[03:06:53.461] iteration:5447  t-loss:1.4100, loss-lb:0.2634, loss-ulb:0.6027, weight:1.90, lr:0.0007
[03:06:53.778] iteration:5448  t-loss:0.5624, loss-lb:0.2756, loss-ulb:0.1508, weight:1.90, lr:0.0007
[03:06:54.094] iteration:5449  t-loss:0.4448, loss-lb:0.2364, loss-ulb:0.1095, weight:1.90, lr:0.0007
[03:06:54.412] iteration:5450  t-loss:0.4648, loss-lb:0.1924, loss-ulb:0.1432, weight:1.90, lr:0.0007
[03:06:55.652] iteration:5451  t-loss:0.3977, loss-lb:0.3541, loss-ulb:0.0229, weight:1.90, lr:0.0007
[03:06:55.998] iteration:5452  t-loss:0.4648, loss-lb:0.2165, loss-ulb:0.1305, weight:1.90, lr:0.0007
[03:06:56.326] iteration:5453  t-loss:0.3540, loss-lb:0.2623, loss-ulb:0.0482, weight:1.90, lr:0.0007
[03:06:56.650] iteration:5454  t-loss:0.3854, loss-lb:0.2642, loss-ulb:0.0637, weight:1.90, lr:0.0007
[03:06:56.970] iteration:5455  t-loss:0.3403, loss-lb:0.2537, loss-ulb:0.0455, weight:1.90, lr:0.0007
[03:06:57.285] iteration:5456  t-loss:0.3481, loss-lb:0.2304, loss-ulb:0.0619, weight:1.90, lr:0.0007
[03:06:57.610] iteration:5457  t-loss:0.3318, loss-lb:0.2141, loss-ulb:0.0619, weight:1.90, lr:0.0007
[03:06:57.932] iteration:5458  t-loss:0.4154, loss-lb:0.1760, loss-ulb:0.1259, weight:1.90, lr:0.0007
[03:06:58.254] iteration:5459  t-loss:0.2762, loss-lb:0.1887, loss-ulb:0.0460, weight:1.90, lr:0.0007
[03:06:58.577] iteration:5460  t-loss:0.3005, loss-lb:0.2277, loss-ulb:0.0382, weight:1.90, lr:0.0007
[03:06:58.907] iteration:5461  t-loss:0.3887, loss-lb:0.2033, loss-ulb:0.0975, weight:1.90, lr:0.0007
[03:06:59.230] iteration:5462  t-loss:0.3397, loss-lb:0.1436, loss-ulb:0.1031, weight:1.90, lr:0.0007
[03:06:59.550] iteration:5463  t-loss:0.2467, loss-lb:0.1744, loss-ulb:0.0380, weight:1.90, lr:0.0007
[03:06:59.873] iteration:5464  t-loss:1.2719, loss-lb:0.3190, loss-ulb:0.5009, weight:1.90, lr:0.0007
[03:07:00.193] iteration:5465  t-loss:0.7836, loss-lb:0.3075, loss-ulb:0.2502, weight:1.90, lr:0.0007
[03:07:00.514] iteration:5466  t-loss:0.4085, loss-lb:0.1852, loss-ulb:0.1174, weight:1.90, lr:0.0007
[03:07:00.835] iteration:5467  t-loss:0.8759, loss-lb:0.1217, loss-ulb:0.3964, weight:1.90, lr:0.0007
[03:07:01.156] iteration:5468  t-loss:0.4177, loss-lb:0.3606, loss-ulb:0.0301, weight:1.90, lr:0.0007
[03:07:01.473] iteration:5469  t-loss:1.5567, loss-lb:0.2085, loss-ulb:0.7087, weight:1.90, lr:0.0007
[03:07:01.789] iteration:5470  t-loss:0.5824, loss-lb:0.2906, loss-ulb:0.1534, weight:1.90, lr:0.0007
[03:07:02.106] iteration:5471  t-loss:0.5427, loss-lb:0.2214, loss-ulb:0.1689, weight:1.90, lr:0.0007
[03:07:02.422] iteration:5472  t-loss:0.5661, loss-lb:0.2162, loss-ulb:0.1839, weight:1.90, lr:0.0007
[03:07:02.737] iteration:5473  t-loss:0.4153, loss-lb:0.3408, loss-ulb:0.0391, weight:1.90, lr:0.0007
[03:07:03.053] iteration:5474  t-loss:0.6181, loss-lb:0.2168, loss-ulb:0.2109, weight:1.90, lr:0.0007
[03:07:03.368] iteration:5475  t-loss:0.6207, loss-lb:0.4008, loss-ulb:0.1156, weight:1.90, lr:0.0007
[03:07:04.548] iteration:5476  t-loss:0.3689, loss-lb:0.2931, loss-ulb:0.0398, weight:1.90, lr:0.0007
[03:07:04.873] iteration:5477  t-loss:0.6462, loss-lb:0.1542, loss-ulb:0.2586, weight:1.90, lr:0.0007
[03:07:05.196] iteration:5478  t-loss:0.4647, loss-lb:0.2860, loss-ulb:0.0940, weight:1.90, lr:0.0007
[03:07:05.514] iteration:5479  t-loss:0.7099, loss-lb:0.3194, loss-ulb:0.2053, weight:1.90, lr:0.0007
[03:07:05.829] iteration:5480  t-loss:0.5726, loss-lb:0.2718, loss-ulb:0.1581, weight:1.90, lr:0.0007
[03:07:06.146] iteration:5481  t-loss:0.3314, loss-lb:0.1871, loss-ulb:0.0759, weight:1.90, lr:0.0007
[03:07:06.465] iteration:5482  t-loss:0.5361, loss-lb:0.3621, loss-ulb:0.0914, weight:1.90, lr:0.0007
[03:07:06.791] iteration:5483  t-loss:0.9286, loss-lb:0.2469, loss-ulb:0.3584, weight:1.90, lr:0.0007
[03:07:07.110] iteration:5484  t-loss:0.4175, loss-lb:0.2761, loss-ulb:0.0743, weight:1.90, lr:0.0007
[03:07:07.441] iteration:5485  t-loss:0.6059, loss-lb:0.2358, loss-ulb:0.1946, weight:1.90, lr:0.0007
[03:07:07.761] iteration:5486  t-loss:0.9382, loss-lb:0.3215, loss-ulb:0.3242, weight:1.90, lr:0.0007
[03:07:08.084] iteration:5487  t-loss:0.3873, loss-lb:0.2758, loss-ulb:0.0586, weight:1.90, lr:0.0007
[03:07:08.405] iteration:5488  t-loss:0.7198, loss-lb:0.1945, loss-ulb:0.2761, weight:1.90, lr:0.0007
[03:07:08.729] iteration:5489  t-loss:0.3494, loss-lb:0.2881, loss-ulb:0.0322, weight:1.90, lr:0.0007
[03:07:09.063] iteration:5490  t-loss:0.3539, loss-lb:0.2529, loss-ulb:0.0530, weight:1.90, lr:0.0007
[03:07:09.380] iteration:5491  t-loss:0.4739, loss-lb:0.1920, loss-ulb:0.1482, weight:1.90, lr:0.0007
[03:07:09.702] iteration:5492  t-loss:0.4133, loss-lb:0.1989, loss-ulb:0.1127, weight:1.90, lr:0.0007
[03:07:10.027] iteration:5493  t-loss:0.4062, loss-lb:0.2536, loss-ulb:0.0802, weight:1.90, lr:0.0007
[03:07:10.347] iteration:5494  t-loss:0.7956, loss-lb:0.4212, loss-ulb:0.1968, weight:1.90, lr:0.0007
[03:07:10.667] iteration:5495  t-loss:0.4783, loss-lb:0.1654, loss-ulb:0.1645, weight:1.90, lr:0.0007
[03:07:10.986] iteration:5496  t-loss:0.3743, loss-lb:0.3015, loss-ulb:0.0382, weight:1.90, lr:0.0007
[03:07:11.307] iteration:5497  t-loss:0.6593, loss-lb:0.4290, loss-ulb:0.1210, weight:1.90, lr:0.0007
[03:07:11.622] iteration:5498  t-loss:0.5295, loss-lb:0.2844, loss-ulb:0.1288, weight:1.90, lr:0.0007
[03:07:11.946] iteration:5499  t-loss:0.4820, loss-lb:0.2359, loss-ulb:0.1294, weight:1.90, lr:0.0007
[03:07:12.258] iteration:5500  t-loss:0.1887, loss-lb:0.1543, loss-ulb:0.0181, weight:1.90, lr:0.0007
[03:07:13.494] iteration:5501  t-loss:0.5479, loss-lb:0.1560, loss-ulb:0.2060, weight:1.90, lr:0.0007
[03:07:13.821] iteration:5502  t-loss:0.2943, loss-lb:0.1746, loss-ulb:0.0629, weight:1.90, lr:0.0007
[03:07:14.149] iteration:5503  t-loss:0.7190, loss-lb:0.2456, loss-ulb:0.2488, weight:1.90, lr:0.0007
[03:07:14.476] iteration:5504  t-loss:0.5662, loss-lb:0.2548, loss-ulb:0.1637, weight:1.90, lr:0.0007
[03:07:14.798] iteration:5505  t-loss:0.4399, loss-lb:0.3109, loss-ulb:0.0678, weight:1.90, lr:0.0007
[03:07:15.123] iteration:5506  t-loss:0.5042, loss-lb:0.2907, loss-ulb:0.1122, weight:1.90, lr:0.0007
[03:07:15.445] iteration:5507  t-loss:0.6236, loss-lb:0.1316, loss-ulb:0.2586, weight:1.90, lr:0.0007
[03:07:15.765] iteration:5508  t-loss:0.9712, loss-lb:0.2664, loss-ulb:0.3705, weight:1.90, lr:0.0007
[03:07:16.083] iteration:5509  t-loss:0.5374, loss-lb:0.2856, loss-ulb:0.1324, weight:1.90, lr:0.0007
[03:07:16.405] iteration:5510  t-loss:0.7708, loss-lb:0.2026, loss-ulb:0.2987, weight:1.90, lr:0.0007
[03:07:16.721] iteration:5511  t-loss:0.3016, loss-lb:0.2321, loss-ulb:0.0365, weight:1.90, lr:0.0007
[03:07:17.039] iteration:5512  t-loss:1.0589, loss-lb:0.2208, loss-ulb:0.4405, weight:1.90, lr:0.0007
[03:07:17.357] iteration:5513  t-loss:0.4315, loss-lb:0.2134, loss-ulb:0.1146, weight:1.90, lr:0.0007
[03:07:17.674] iteration:5514  t-loss:1.4681, loss-lb:0.2701, loss-ulb:0.6297, weight:1.90, lr:0.0007
[03:07:17.991] iteration:5515  t-loss:0.9154, loss-lb:0.3627, loss-ulb:0.2905, weight:1.90, lr:0.0007
[03:07:18.306] iteration:5516  t-loss:1.1144, loss-lb:0.2764, loss-ulb:0.4405, weight:1.90, lr:0.0007
[03:07:18.627] iteration:5517  t-loss:1.1722, loss-lb:0.5207, loss-ulb:0.3424, weight:1.90, lr:0.0007
[03:07:18.939] iteration:5518  t-loss:0.4718, loss-lb:0.3831, loss-ulb:0.0466, weight:1.90, lr:0.0007
[03:07:19.256] iteration:5519  t-loss:1.2136, loss-lb:0.7928, loss-ulb:0.2212, weight:1.90, lr:0.0007
[03:07:19.571] iteration:5520  t-loss:0.2485, loss-lb:0.1540, loss-ulb:0.0496, weight:1.90, lr:0.0007
[03:07:19.887] iteration:5521  t-loss:0.4254, loss-lb:0.3069, loss-ulb:0.0623, weight:1.90, lr:0.0007
[03:07:20.201] iteration:5522  t-loss:0.4344, loss-lb:0.2804, loss-ulb:0.0810, weight:1.90, lr:0.0007
[03:07:20.516] iteration:5523  t-loss:0.4210, loss-lb:0.1894, loss-ulb:0.1217, weight:1.90, lr:0.0007
[03:07:20.832] iteration:5524  t-loss:0.9383, loss-lb:0.3076, loss-ulb:0.3315, weight:1.90, lr:0.0007
[03:07:21.147] iteration:5525  t-loss:0.5314, loss-lb:0.2265, loss-ulb:0.1603, weight:1.90, lr:0.0007
[03:09:20.108] iteration 5525 : dice_score: 0.837267 best_dice: 0.843400
[03:09:20.108]  <<Test>> - Ep:220  - Dice-S/T:82.76/83.73, Best-S:83.27, Best-T:84.34
[03:09:20.108]           - AvgLoss(lb/ulb/all):0.28/0.23/0.73
[03:09:21.390] iteration:5526  t-loss:0.6826, loss-lb:0.1738, loss-ulb:0.2674, weight:1.90, lr:0.0007
[03:09:21.748] iteration:5527  t-loss:0.4928, loss-lb:0.3071, loss-ulb:0.0976, weight:1.90, lr:0.0007
[03:09:22.083] iteration:5528  t-loss:0.3250, loss-lb:0.2731, loss-ulb:0.0273, weight:1.90, lr:0.0007
[03:09:22.408] iteration:5529  t-loss:0.7362, loss-lb:0.3120, loss-ulb:0.2230, weight:1.90, lr:0.0007
[03:09:22.727] iteration:5530  t-loss:0.5387, loss-lb:0.2002, loss-ulb:0.1779, weight:1.90, lr:0.0007
[03:09:23.042] iteration:5531  t-loss:0.2446, loss-lb:0.1901, loss-ulb:0.0286, weight:1.90, lr:0.0007
[03:09:23.358] iteration:5532  t-loss:0.7359, loss-lb:0.1742, loss-ulb:0.2952, weight:1.90, lr:0.0007
[03:09:23.671] iteration:5533  t-loss:1.7104, loss-lb:0.2252, loss-ulb:0.7807, weight:1.90, lr:0.0007
[03:09:23.986] iteration:5534  t-loss:0.3470, loss-lb:0.2687, loss-ulb:0.0411, weight:1.90, lr:0.0007
[03:09:24.303] iteration:5535  t-loss:0.5491, loss-lb:0.2458, loss-ulb:0.1594, weight:1.90, lr:0.0007
[03:09:24.622] iteration:5536  t-loss:0.5219, loss-lb:0.2850, loss-ulb:0.1245, weight:1.90, lr:0.0007
[03:09:24.931] iteration:5537  t-loss:0.6243, loss-lb:0.2259, loss-ulb:0.2094, weight:1.90, lr:0.0007
[03:09:25.250] iteration:5538  t-loss:0.6786, loss-lb:0.4552, loss-ulb:0.1174, weight:1.90, lr:0.0007
[03:09:25.568] iteration:5539  t-loss:0.6154, loss-lb:0.4652, loss-ulb:0.0790, weight:1.90, lr:0.0007
[03:09:25.884] iteration:5540  t-loss:1.4258, loss-lb:0.2182, loss-ulb:0.6348, weight:1.90, lr:0.0007
[03:09:26.199] iteration:5541  t-loss:0.3981, loss-lb:0.3544, loss-ulb:0.0230, weight:1.90, lr:0.0007
[03:09:26.516] iteration:5542  t-loss:1.1046, loss-lb:0.2121, loss-ulb:0.4691, weight:1.90, lr:0.0007
[03:09:26.827] iteration:5543  t-loss:0.4463, loss-lb:0.3468, loss-ulb:0.0523, weight:1.90, lr:0.0007
[03:09:27.141] iteration:5544  t-loss:0.8101, loss-lb:0.2008, loss-ulb:0.3203, weight:1.90, lr:0.0007
[03:09:27.451] iteration:5545  t-loss:0.6208, loss-lb:0.3451, loss-ulb:0.1449, weight:1.90, lr:0.0007
[03:09:27.765] iteration:5546  t-loss:1.5238, loss-lb:0.4367, loss-ulb:0.5714, weight:1.90, lr:0.0007
[03:09:28.080] iteration:5547  t-loss:0.5662, loss-lb:0.3667, loss-ulb:0.1048, weight:1.90, lr:0.0007
[03:09:28.393] iteration:5548  t-loss:0.7083, loss-lb:0.4812, loss-ulb:0.1194, weight:1.90, lr:0.0007
[03:09:28.708] iteration:5549  t-loss:0.3119, loss-lb:0.1628, loss-ulb:0.0784, weight:1.90, lr:0.0007
[03:09:29.023] iteration:5550  t-loss:0.6812, loss-lb:0.4897, loss-ulb:0.1006, weight:1.90, lr:0.0007
[03:09:30.148] iteration:5551  t-loss:0.4246, loss-lb:0.1518, loss-ulb:0.1403, weight:1.94, lr:0.0007
[03:09:30.470] iteration:5552  t-loss:0.5723, loss-lb:0.2962, loss-ulb:0.1420, weight:1.94, lr:0.0007
[03:09:30.792] iteration:5553  t-loss:0.4857, loss-lb:0.1665, loss-ulb:0.1641, weight:1.94, lr:0.0007
[03:09:31.119] iteration:5554  t-loss:0.6011, loss-lb:0.3472, loss-ulb:0.1306, weight:1.94, lr:0.0007
[03:09:31.442] iteration:5555  t-loss:0.8057, loss-lb:0.4118, loss-ulb:0.2026, weight:1.94, lr:0.0007
[03:09:31.767] iteration:5556  t-loss:0.6683, loss-lb:0.4116, loss-ulb:0.1320, weight:1.94, lr:0.0007
[03:09:32.086] iteration:5557  t-loss:1.1656, loss-lb:0.1899, loss-ulb:0.5018, weight:1.94, lr:0.0007
[03:09:32.408] iteration:5558  t-loss:0.6980, loss-lb:0.3607, loss-ulb:0.1735, weight:1.94, lr:0.0007
[03:09:32.730] iteration:5559  t-loss:0.8682, loss-lb:0.1698, loss-ulb:0.3592, weight:1.94, lr:0.0007
[03:09:33.058] iteration:5560  t-loss:0.6034, loss-lb:0.3184, loss-ulb:0.1466, weight:1.94, lr:0.0007
[03:09:33.381] iteration:5561  t-loss:0.5568, loss-lb:0.3275, loss-ulb:0.1179, weight:1.94, lr:0.0007
[03:09:33.701] iteration:5562  t-loss:0.2918, loss-lb:0.1894, loss-ulb:0.0527, weight:1.94, lr:0.0007
[03:09:34.022] iteration:5563  t-loss:0.3588, loss-lb:0.2978, loss-ulb:0.0314, weight:1.94, lr:0.0007
[03:09:34.341] iteration:5564  t-loss:0.9551, loss-lb:0.2997, loss-ulb:0.3370, weight:1.94, lr:0.0007
[03:09:34.660] iteration:5565  t-loss:0.5964, loss-lb:0.3505, loss-ulb:0.1265, weight:1.94, lr:0.0007
[03:09:34.980] iteration:5566  t-loss:0.6067, loss-lb:0.3412, loss-ulb:0.1365, weight:1.94, lr:0.0007
[03:09:35.303] iteration:5567  t-loss:0.5672, loss-lb:0.2001, loss-ulb:0.1888, weight:1.94, lr:0.0007
[03:09:35.622] iteration:5568  t-loss:0.5344, loss-lb:0.2240, loss-ulb:0.1596, weight:1.94, lr:0.0007
[03:09:35.939] iteration:5569  t-loss:0.4671, loss-lb:0.1650, loss-ulb:0.1553, weight:1.94, lr:0.0007
[03:09:36.256] iteration:5570  t-loss:0.5335, loss-lb:0.2107, loss-ulb:0.1660, weight:1.94, lr:0.0007
[03:09:36.571] iteration:5571  t-loss:0.9331, loss-lb:0.2485, loss-ulb:0.3521, weight:1.94, lr:0.0007
[03:09:36.886] iteration:5572  t-loss:0.5073, loss-lb:0.3562, loss-ulb:0.0777, weight:1.94, lr:0.0007
[03:09:37.198] iteration:5573  t-loss:0.5266, loss-lb:0.1411, loss-ulb:0.1982, weight:1.94, lr:0.0007
[03:09:37.515] iteration:5574  t-loss:1.0370, loss-lb:0.2068, loss-ulb:0.4269, weight:1.94, lr:0.0007
[03:09:37.831] iteration:5575  t-loss:0.5280, loss-lb:0.2564, loss-ulb:0.1397, weight:1.94, lr:0.0007
[03:09:39.097] iteration:5576  t-loss:1.1801, loss-lb:0.3589, loss-ulb:0.4223, weight:1.94, lr:0.0007
[03:09:39.427] iteration:5577  t-loss:1.0214, loss-lb:0.2510, loss-ulb:0.3961, weight:1.94, lr:0.0007
[03:09:39.745] iteration:5578  t-loss:0.2985, loss-lb:0.2155, loss-ulb:0.0427, weight:1.94, lr:0.0007
[03:09:40.062] iteration:5579  t-loss:0.5958, loss-lb:0.2262, loss-ulb:0.1901, weight:1.94, lr:0.0007
[03:09:40.378] iteration:5580  t-loss:0.4643, loss-lb:0.1738, loss-ulb:0.1494, weight:1.94, lr:0.0007
[03:09:40.696] iteration:5581  t-loss:0.3310, loss-lb:0.2491, loss-ulb:0.0421, weight:1.94, lr:0.0007
[03:09:41.017] iteration:5582  t-loss:0.3397, loss-lb:0.1954, loss-ulb:0.0742, weight:1.94, lr:0.0007
[03:09:41.331] iteration:5583  t-loss:1.6835, loss-lb:0.1908, loss-ulb:0.7676, weight:1.94, lr:0.0007
[03:09:41.648] iteration:5584  t-loss:0.5542, loss-lb:0.1321, loss-ulb:0.2171, weight:1.94, lr:0.0007
[03:09:41.969] iteration:5585  t-loss:0.6072, loss-lb:0.2007, loss-ulb:0.2091, weight:1.94, lr:0.0007
[03:09:42.332] iteration:5586  t-loss:0.4228, loss-lb:0.3566, loss-ulb:0.0341, weight:1.94, lr:0.0007
[03:09:42.649] iteration:5587  t-loss:0.4209, loss-lb:0.2258, loss-ulb:0.1004, weight:1.94, lr:0.0007
[03:09:42.966] iteration:5588  t-loss:0.3736, loss-lb:0.2216, loss-ulb:0.0781, weight:1.94, lr:0.0007
[03:09:43.280] iteration:5589  t-loss:0.4105, loss-lb:0.1684, loss-ulb:0.1245, weight:1.94, lr:0.0007
[03:09:43.594] iteration:5590  t-loss:1.7147, loss-lb:0.3377, loss-ulb:0.7081, weight:1.94, lr:0.0007
[03:09:43.909] iteration:5591  t-loss:0.3591, loss-lb:0.1657, loss-ulb:0.0994, weight:1.94, lr:0.0007
[03:09:44.224] iteration:5592  t-loss:1.3645, loss-lb:0.1355, loss-ulb:0.6321, weight:1.94, lr:0.0007
[03:09:44.535] iteration:5593  t-loss:0.4262, loss-lb:0.3666, loss-ulb:0.0306, weight:1.94, lr:0.0007
[03:09:44.853] iteration:5594  t-loss:0.6313, loss-lb:0.4972, loss-ulb:0.0689, weight:1.94, lr:0.0007
[03:09:45.172] iteration:5595  t-loss:0.3848, loss-lb:0.1651, loss-ulb:0.1130, weight:1.94, lr:0.0007
[03:09:45.485] iteration:5596  t-loss:0.3466, loss-lb:0.1609, loss-ulb:0.0955, weight:1.94, lr:0.0007
[03:09:45.803] iteration:5597  t-loss:0.2674, loss-lb:0.1539, loss-ulb:0.0584, weight:1.94, lr:0.0007
[03:09:46.116] iteration:5598  t-loss:0.7824, loss-lb:0.2845, loss-ulb:0.2561, weight:1.94, lr:0.0007
[03:09:46.436] iteration:5599  t-loss:0.6613, loss-lb:0.2398, loss-ulb:0.2168, weight:1.94, lr:0.0007
[03:09:46.758] iteration:5600  t-loss:1.0290, loss-lb:0.2728, loss-ulb:0.3889, weight:1.94, lr:0.0007
[03:09:47.971] iteration:5601  t-loss:1.1671, loss-lb:0.4422, loss-ulb:0.3728, weight:1.94, lr:0.0007
[03:09:48.310] iteration:5602  t-loss:1.0737, loss-lb:0.3477, loss-ulb:0.3734, weight:1.94, lr:0.0007
[03:09:48.643] iteration:5603  t-loss:0.7923, loss-lb:0.2451, loss-ulb:0.2814, weight:1.94, lr:0.0007
[03:09:48.964] iteration:5604  t-loss:0.3463, loss-lb:0.2467, loss-ulb:0.0512, weight:1.94, lr:0.0007
[03:09:49.299] iteration:5605  t-loss:0.4351, loss-lb:0.3047, loss-ulb:0.0671, weight:1.94, lr:0.0007
[03:09:49.624] iteration:5606  t-loss:0.3680, loss-lb:0.1541, loss-ulb:0.1100, weight:1.94, lr:0.0007
[03:09:49.936] iteration:5607  t-loss:1.2390, loss-lb:0.2371, loss-ulb:0.5152, weight:1.94, lr:0.0007
[03:09:50.249] iteration:5608  t-loss:0.7251, loss-lb:0.1975, loss-ulb:0.2713, weight:1.94, lr:0.0007
[03:09:50.566] iteration:5609  t-loss:1.0290, loss-lb:0.2469, loss-ulb:0.4022, weight:1.94, lr:0.0007
[03:09:50.887] iteration:5610  t-loss:0.5261, loss-lb:0.1513, loss-ulb:0.1928, weight:1.94, lr:0.0007
[03:09:51.204] iteration:5611  t-loss:0.5575, loss-lb:0.1791, loss-ulb:0.1946, weight:1.94, lr:0.0007
[03:09:51.530] iteration:5612  t-loss:0.7907, loss-lb:0.3810, loss-ulb:0.2107, weight:1.94, lr:0.0007
[03:09:51.848] iteration:5613  t-loss:0.3727, loss-lb:0.2174, loss-ulb:0.0798, weight:1.94, lr:0.0007
[03:09:52.167] iteration:5614  t-loss:0.3418, loss-lb:0.2741, loss-ulb:0.0348, weight:1.94, lr:0.0007
[03:09:52.484] iteration:5615  t-loss:0.4040, loss-lb:0.3322, loss-ulb:0.0369, weight:1.94, lr:0.0007
[03:09:52.802] iteration:5616  t-loss:0.5033, loss-lb:0.1884, loss-ulb:0.1620, weight:1.94, lr:0.0007
[03:09:53.119] iteration:5617  t-loss:0.4488, loss-lb:0.1994, loss-ulb:0.1283, weight:1.94, lr:0.0007
[03:09:53.435] iteration:5618  t-loss:0.3656, loss-lb:0.3268, loss-ulb:0.0200, weight:1.94, lr:0.0007
[03:09:53.748] iteration:5619  t-loss:0.2958, loss-lb:0.1730, loss-ulb:0.0631, weight:1.94, lr:0.0007
[03:09:54.064] iteration:5620  t-loss:1.1298, loss-lb:0.2470, loss-ulb:0.4540, weight:1.94, lr:0.0007
[03:09:54.381] iteration:5621  t-loss:0.2688, loss-lb:0.1396, loss-ulb:0.0664, weight:1.94, lr:0.0007
[03:09:54.694] iteration:5622  t-loss:0.2842, loss-lb:0.1881, loss-ulb:0.0494, weight:1.94, lr:0.0007
[03:09:55.006] iteration:5623  t-loss:0.8298, loss-lb:0.2079, loss-ulb:0.3198, weight:1.94, lr:0.0007
[03:09:55.318] iteration:5624  t-loss:0.8350, loss-lb:0.2075, loss-ulb:0.3227, weight:1.94, lr:0.0007
[03:09:55.632] iteration:5625  t-loss:0.3229, loss-lb:0.2238, loss-ulb:0.0510, weight:1.94, lr:0.0007
[03:11:51.413] iteration 5625 : dice_score: 0.839528 best_dice: 0.843400
[03:11:51.413]  <<Test>> - Ep:224  - Dice-S/T:82.07/83.95, Best-S:83.27, Best-T:84.34
[03:11:51.413]           - AvgLoss(lb/ulb/all):0.24/0.18/0.58
[03:11:52.491] iteration:5626  t-loss:0.3479, loss-lb:0.2617, loss-ulb:0.0443, weight:1.94, lr:0.0007
[03:11:52.818] iteration:5627  t-loss:0.8237, loss-lb:0.1532, loss-ulb:0.3448, weight:1.94, lr:0.0007
[03:11:53.138] iteration:5628  t-loss:0.6322, loss-lb:0.1707, loss-ulb:0.2373, weight:1.94, lr:0.0007
[03:11:53.457] iteration:5629  t-loss:1.3382, loss-lb:0.2990, loss-ulb:0.5344, weight:1.94, lr:0.0007
[03:11:53.775] iteration:5630  t-loss:1.1382, loss-lb:0.2885, loss-ulb:0.4370, weight:1.94, lr:0.0007
[03:11:54.097] iteration:5631  t-loss:0.2667, loss-lb:0.2024, loss-ulb:0.0330, weight:1.94, lr:0.0007
[03:11:54.427] iteration:5632  t-loss:0.6453, loss-lb:0.4247, loss-ulb:0.1134, weight:1.94, lr:0.0007
[03:11:54.743] iteration:5633  t-loss:0.3447, loss-lb:0.2781, loss-ulb:0.0342, weight:1.94, lr:0.0007
[03:11:55.052] iteration:5634  t-loss:0.2693, loss-lb:0.1404, loss-ulb:0.0663, weight:1.94, lr:0.0007
[03:11:55.372] iteration:5635  t-loss:0.2817, loss-lb:0.2454, loss-ulb:0.0187, weight:1.94, lr:0.0007
[03:11:55.711] iteration:5636  t-loss:0.4328, loss-lb:0.2879, loss-ulb:0.0745, weight:1.94, lr:0.0007
[03:11:56.029] iteration:5637  t-loss:0.3537, loss-lb:0.3128, loss-ulb:0.0210, weight:1.94, lr:0.0007
[03:11:56.349] iteration:5638  t-loss:0.4302, loss-lb:0.2153, loss-ulb:0.1105, weight:1.94, lr:0.0007
[03:11:56.677] iteration:5639  t-loss:0.4809, loss-lb:0.3061, loss-ulb:0.0899, weight:1.94, lr:0.0007
[03:11:56.993] iteration:5640  t-loss:0.8079, loss-lb:0.1969, loss-ulb:0.3142, weight:1.94, lr:0.0007
[03:11:57.313] iteration:5641  t-loss:0.4975, loss-lb:0.2360, loss-ulb:0.1345, weight:1.94, lr:0.0007
[03:11:57.630] iteration:5642  t-loss:0.4314, loss-lb:0.1859, loss-ulb:0.1262, weight:1.94, lr:0.0007
[03:11:57.949] iteration:5643  t-loss:0.9302, loss-lb:0.2192, loss-ulb:0.3656, weight:1.94, lr:0.0007
[03:11:58.263] iteration:5644  t-loss:0.4360, loss-lb:0.2674, loss-ulb:0.0867, weight:1.94, lr:0.0007
[03:11:58.581] iteration:5645  t-loss:0.3896, loss-lb:0.3192, loss-ulb:0.0362, weight:1.94, lr:0.0007
[03:11:58.897] iteration:5646  t-loss:0.9486, loss-lb:0.1909, loss-ulb:0.3896, weight:1.94, lr:0.0007
[03:11:59.209] iteration:5647  t-loss:1.2436, loss-lb:0.4081, loss-ulb:0.4297, weight:1.94, lr:0.0007
[03:11:59.526] iteration:5648  t-loss:1.4271, loss-lb:0.3269, loss-ulb:0.5658, weight:1.94, lr:0.0007
[03:11:59.839] iteration:5649  t-loss:1.2742, loss-lb:0.1635, loss-ulb:0.5712, weight:1.94, lr:0.0007
[03:12:00.153] iteration:5650  t-loss:0.4216, loss-lb:0.3715, loss-ulb:0.0258, weight:1.94, lr:0.0007
[03:12:01.298] iteration:5651  t-loss:0.4204, loss-lb:0.2166, loss-ulb:0.1048, weight:1.94, lr:0.0007
[03:12:01.629] iteration:5652  t-loss:0.4145, loss-lb:0.2731, loss-ulb:0.0727, weight:1.94, lr:0.0007
[03:12:01.948] iteration:5653  t-loss:0.6187, loss-lb:0.1667, loss-ulb:0.2324, weight:1.94, lr:0.0007
[03:12:02.268] iteration:5654  t-loss:0.4798, loss-lb:0.2275, loss-ulb:0.1298, weight:1.94, lr:0.0007
[03:12:02.596] iteration:5655  t-loss:0.4554, loss-lb:0.3968, loss-ulb:0.0301, weight:1.94, lr:0.0007
[03:12:02.955] iteration:5656  t-loss:0.3857, loss-lb:0.3284, loss-ulb:0.0295, weight:1.94, lr:0.0007
[03:12:03.305] iteration:5657  t-loss:0.4495, loss-lb:0.1666, loss-ulb:0.1455, weight:1.94, lr:0.0007
[03:12:03.641] iteration:5658  t-loss:0.2563, loss-lb:0.2092, loss-ulb:0.0242, weight:1.94, lr:0.0007
[03:12:03.970] iteration:5659  t-loss:0.4915, loss-lb:0.3402, loss-ulb:0.0778, weight:1.94, lr:0.0007
[03:12:04.287] iteration:5660  t-loss:1.6651, loss-lb:0.2901, loss-ulb:0.7071, weight:1.94, lr:0.0007
[03:12:04.618] iteration:5661  t-loss:0.2911, loss-lb:0.2471, loss-ulb:0.0226, weight:1.94, lr:0.0007
[03:12:04.939] iteration:5662  t-loss:0.4758, loss-lb:0.1267, loss-ulb:0.1795, weight:1.94, lr:0.0007
[03:12:05.259] iteration:5663  t-loss:0.6152, loss-lb:0.2070, loss-ulb:0.2099, weight:1.94, lr:0.0007
[03:12:05.580] iteration:5664  t-loss:0.5008, loss-lb:0.2123, loss-ulb:0.1484, weight:1.94, lr:0.0007
[03:12:05.910] iteration:5665  t-loss:0.3475, loss-lb:0.2776, loss-ulb:0.0360, weight:1.94, lr:0.0007
[03:12:06.228] iteration:5666  t-loss:1.4331, loss-lb:0.2262, loss-ulb:0.6207, weight:1.94, lr:0.0007
[03:12:06.545] iteration:5667  t-loss:0.5737, loss-lb:0.2116, loss-ulb:0.1862, weight:1.94, lr:0.0007
[03:12:06.863] iteration:5668  t-loss:0.3151, loss-lb:0.1737, loss-ulb:0.0727, weight:1.94, lr:0.0007
[03:12:07.176] iteration:5669  t-loss:0.3719, loss-lb:0.2634, loss-ulb:0.0558, weight:1.94, lr:0.0007
[03:12:07.490] iteration:5670  t-loss:0.1999, loss-lb:0.1261, loss-ulb:0.0380, weight:1.94, lr:0.0007
[03:12:07.804] iteration:5671  t-loss:0.4024, loss-lb:0.1929, loss-ulb:0.1077, weight:1.94, lr:0.0007
[03:12:08.126] iteration:5672  t-loss:0.4427, loss-lb:0.2448, loss-ulb:0.1018, weight:1.94, lr:0.0007
[03:12:08.435] iteration:5673  t-loss:0.5808, loss-lb:0.1625, loss-ulb:0.2152, weight:1.94, lr:0.0007
[03:12:08.749] iteration:5674  t-loss:0.3881, loss-lb:0.1911, loss-ulb:0.1013, weight:1.94, lr:0.0007
[03:12:09.061] iteration:5675  t-loss:0.2347, loss-lb:0.1589, loss-ulb:0.0390, weight:1.94, lr:0.0007
[03:12:10.375] iteration:5676  t-loss:0.3496, loss-lb:0.1258, loss-ulb:0.1151, weight:1.94, lr:0.0007
[03:12:10.727] iteration:5677  t-loss:0.6163, loss-lb:0.3550, loss-ulb:0.1344, weight:1.94, lr:0.0007
[03:12:11.060] iteration:5678  t-loss:0.5433, loss-lb:0.2585, loss-ulb:0.1464, weight:1.94, lr:0.0007
[03:12:11.385] iteration:5679  t-loss:0.7909, loss-lb:0.3663, loss-ulb:0.2184, weight:1.94, lr:0.0007
[03:12:11.704] iteration:5680  t-loss:0.4399, loss-lb:0.1668, loss-ulb:0.1405, weight:1.94, lr:0.0007
[03:12:12.024] iteration:5681  t-loss:0.2954, loss-lb:0.1708, loss-ulb:0.0641, weight:1.94, lr:0.0007
[03:12:12.355] iteration:5682  t-loss:0.5843, loss-lb:0.4355, loss-ulb:0.0765, weight:1.94, lr:0.0007
[03:12:12.686] iteration:5683  t-loss:1.0905, loss-lb:0.2872, loss-ulb:0.4132, weight:1.94, lr:0.0007
[03:12:13.011] iteration:5684  t-loss:0.2451, loss-lb:0.1963, loss-ulb:0.0251, weight:1.94, lr:0.0007
[03:12:13.339] iteration:5685  t-loss:0.6931, loss-lb:0.2733, loss-ulb:0.2159, weight:1.94, lr:0.0007
[03:12:13.656] iteration:5686  t-loss:0.8250, loss-lb:0.1874, loss-ulb:0.3279, weight:1.94, lr:0.0007
[03:12:13.977] iteration:5687  t-loss:0.5082, loss-lb:0.3041, loss-ulb:0.1050, weight:1.94, lr:0.0007
[03:12:14.293] iteration:5688  t-loss:0.2567, loss-lb:0.1464, loss-ulb:0.0568, weight:1.94, lr:0.0007
[03:12:14.608] iteration:5689  t-loss:0.4490, loss-lb:0.2068, loss-ulb:0.1245, weight:1.94, lr:0.0007
[03:12:14.928] iteration:5690  t-loss:0.3502, loss-lb:0.1974, loss-ulb:0.0786, weight:1.94, lr:0.0007
[03:12:15.246] iteration:5691  t-loss:0.3967, loss-lb:0.1801, loss-ulb:0.1114, weight:1.94, lr:0.0007
[03:12:15.567] iteration:5692  t-loss:0.6529, loss-lb:0.3482, loss-ulb:0.1567, weight:1.94, lr:0.0007
[03:12:15.885] iteration:5693  t-loss:0.3135, loss-lb:0.2502, loss-ulb:0.0325, weight:1.94, lr:0.0007
[03:12:16.205] iteration:5694  t-loss:0.6387, loss-lb:0.2746, loss-ulb:0.1873, weight:1.94, lr:0.0007
[03:12:16.522] iteration:5695  t-loss:0.3664, loss-lb:0.2911, loss-ulb:0.0387, weight:1.94, lr:0.0007
[03:12:16.839] iteration:5696  t-loss:0.5019, loss-lb:0.2196, loss-ulb:0.1452, weight:1.94, lr:0.0007
[03:12:17.153] iteration:5697  t-loss:0.3861, loss-lb:0.1299, loss-ulb:0.1318, weight:1.94, lr:0.0007
[03:12:17.470] iteration:5698  t-loss:0.4722, loss-lb:0.1988, loss-ulb:0.1406, weight:1.94, lr:0.0007
[03:12:17.785] iteration:5699  t-loss:0.7652, loss-lb:0.1482, loss-ulb:0.3173, weight:1.94, lr:0.0007
[03:12:18.101] iteration:5700  t-loss:0.3628, loss-lb:0.1753, loss-ulb:0.0965, weight:1.94, lr:0.0007
[03:12:19.435] iteration:5701  t-loss:0.6983, loss-lb:0.3988, loss-ulb:0.1516, weight:1.98, lr:0.0007
[03:12:19.768] iteration:5702  t-loss:0.8175, loss-lb:0.1862, loss-ulb:0.3197, weight:1.98, lr:0.0007
[03:12:20.090] iteration:5703  t-loss:0.2486, loss-lb:0.1850, loss-ulb:0.0322, weight:1.98, lr:0.0007
[03:12:20.410] iteration:5704  t-loss:0.6594, loss-lb:0.1860, loss-ulb:0.2397, weight:1.98, lr:0.0007
[03:12:20.732] iteration:5705  t-loss:1.1335, loss-lb:0.2540, loss-ulb:0.4453, weight:1.98, lr:0.0007
[03:12:21.054] iteration:5706  t-loss:0.2760, loss-lb:0.1616, loss-ulb:0.0579, weight:1.98, lr:0.0007
[03:12:21.380] iteration:5707  t-loss:0.5279, loss-lb:0.3863, loss-ulb:0.0717, weight:1.98, lr:0.0006
[03:12:21.707] iteration:5708  t-loss:0.5788, loss-lb:0.2177, loss-ulb:0.1828, weight:1.98, lr:0.0006
[03:12:22.026] iteration:5709  t-loss:0.2274, loss-lb:0.1506, loss-ulb:0.0389, weight:1.98, lr:0.0006
[03:12:22.348] iteration:5710  t-loss:0.5556, loss-lb:0.3046, loss-ulb:0.1270, weight:1.98, lr:0.0006
[03:12:22.671] iteration:5711  t-loss:0.4202, loss-lb:0.3206, loss-ulb:0.0504, weight:1.98, lr:0.0006
[03:12:22.993] iteration:5712  t-loss:0.9786, loss-lb:0.1812, loss-ulb:0.4037, weight:1.98, lr:0.0006
[03:12:23.313] iteration:5713  t-loss:1.3328, loss-lb:0.1792, loss-ulb:0.5841, weight:1.98, lr:0.0006
[03:12:23.627] iteration:5714  t-loss:0.5931, loss-lb:0.1650, loss-ulb:0.2167, weight:1.98, lr:0.0006
[03:12:23.945] iteration:5715  t-loss:0.8318, loss-lb:0.4784, loss-ulb:0.1789, weight:1.98, lr:0.0006
[03:12:24.268] iteration:5716  t-loss:0.7446, loss-lb:0.3717, loss-ulb:0.1888, weight:1.98, lr:0.0006
[03:12:24.588] iteration:5717  t-loss:0.5139, loss-lb:0.1746, loss-ulb:0.1718, weight:1.98, lr:0.0006
[03:12:24.907] iteration:5718  t-loss:0.6682, loss-lb:0.1546, loss-ulb:0.2600, weight:1.98, lr:0.0006
[03:12:25.229] iteration:5719  t-loss:0.6159, loss-lb:0.4327, loss-ulb:0.0928, weight:1.98, lr:0.0006
[03:12:25.545] iteration:5720  t-loss:0.6854, loss-lb:0.3301, loss-ulb:0.1799, weight:1.98, lr:0.0006
[03:12:25.860] iteration:5721  t-loss:0.3101, loss-lb:0.2243, loss-ulb:0.0434, weight:1.98, lr:0.0006
[03:12:26.164] iteration:5722  t-loss:0.8931, loss-lb:0.3906, loss-ulb:0.2544, weight:1.98, lr:0.0006
[03:12:26.478] iteration:5723  t-loss:2.5283, loss-lb:0.4188, loss-ulb:1.0680, weight:1.98, lr:0.0006
[03:12:26.795] iteration:5724  t-loss:1.1899, loss-lb:0.2025, loss-ulb:0.4999, weight:1.98, lr:0.0006
[03:12:27.111] iteration:5725  t-loss:0.3899, loss-lb:0.1629, loss-ulb:0.1149, weight:1.98, lr:0.0006
[03:14:34.332] iteration 5725 : dice_score: 0.835166 best_dice: 0.843400
[03:14:34.332]  <<Test>> - Ep:228  - Dice-S/T:76.59/83.52, Best-S:83.27, Best-T:84.34
[03:14:34.332]           - AvgLoss(lb/ulb/all):0.26/0.24/0.74
[03:14:35.581] iteration:5726  t-loss:0.4888, loss-lb:0.1508, loss-ulb:0.1711, weight:1.98, lr:0.0006
[03:14:35.911] iteration:5727  t-loss:0.5849, loss-lb:0.1825, loss-ulb:0.2037, weight:1.98, lr:0.0006
[03:14:36.239] iteration:5728  t-loss:0.8279, loss-lb:0.4245, loss-ulb:0.2042, weight:1.98, lr:0.0006
[03:14:36.573] iteration:5729  t-loss:0.3755, loss-lb:0.2042, loss-ulb:0.0867, weight:1.98, lr:0.0006
[03:14:36.894] iteration:5730  t-loss:0.5027, loss-lb:0.2539, loss-ulb:0.1260, weight:1.98, lr:0.0006
[03:14:37.213] iteration:5731  t-loss:0.4631, loss-lb:0.2977, loss-ulb:0.0838, weight:1.98, lr:0.0006
[03:14:37.525] iteration:5732  t-loss:1.7140, loss-lb:0.3561, loss-ulb:0.6875, weight:1.98, lr:0.0006
[03:14:37.838] iteration:5733  t-loss:0.4750, loss-lb:0.2902, loss-ulb:0.0936, weight:1.98, lr:0.0006
[03:14:38.154] iteration:5734  t-loss:0.7280, loss-lb:0.1875, loss-ulb:0.2737, weight:1.98, lr:0.0006
[03:14:38.479] iteration:5735  t-loss:0.5839, loss-lb:0.2538, loss-ulb:0.1671, weight:1.98, lr:0.0006
[03:14:38.804] iteration:5736  t-loss:0.4680, loss-lb:0.1697, loss-ulb:0.1510, weight:1.98, lr:0.0006
[03:14:39.121] iteration:5737  t-loss:0.3607, loss-lb:0.2051, loss-ulb:0.0788, weight:1.98, lr:0.0006
[03:14:39.437] iteration:5738  t-loss:0.4009, loss-lb:0.1549, loss-ulb:0.1245, weight:1.98, lr:0.0006
[03:14:39.785] iteration:5739  t-loss:1.4130, loss-lb:0.3544, loss-ulb:0.5360, weight:1.98, lr:0.0006
[03:14:40.123] iteration:5740  t-loss:0.4363, loss-lb:0.2457, loss-ulb:0.0965, weight:1.98, lr:0.0006
[03:14:40.459] iteration:5741  t-loss:1.0851, loss-lb:0.1926, loss-ulb:0.4519, weight:1.98, lr:0.0006
[03:14:40.783] iteration:5742  t-loss:0.2556, loss-lb:0.1696, loss-ulb:0.0436, weight:1.98, lr:0.0006
[03:14:41.110] iteration:5743  t-loss:0.3845, loss-lb:0.3405, loss-ulb:0.0223, weight:1.98, lr:0.0006
[03:14:41.427] iteration:5744  t-loss:0.5411, loss-lb:0.3106, loss-ulb:0.1167, weight:1.98, lr:0.0006
[03:14:41.747] iteration:5745  t-loss:0.5536, loss-lb:0.2404, loss-ulb:0.1586, weight:1.98, lr:0.0006
[03:14:42.061] iteration:5746  t-loss:0.3319, loss-lb:0.2009, loss-ulb:0.0663, weight:1.98, lr:0.0006
[03:14:42.373] iteration:5747  t-loss:0.4401, loss-lb:0.2260, loss-ulb:0.1084, weight:1.98, lr:0.0006
[03:14:42.687] iteration:5748  t-loss:0.4289, loss-lb:0.2398, loss-ulb:0.0957, weight:1.98, lr:0.0006
[03:14:43.010] iteration:5749  t-loss:0.3463, loss-lb:0.2272, loss-ulb:0.0603, weight:1.98, lr:0.0006
[03:14:43.332] iteration:5750  t-loss:0.4866, loss-lb:0.1793, loss-ulb:0.1556, weight:1.98, lr:0.0006
[03:14:44.978] iteration:5751  t-loss:0.9902, loss-lb:0.2109, loss-ulb:0.3945, weight:1.98, lr:0.0006
[03:14:45.339] iteration:5752  t-loss:0.9188, loss-lb:0.2968, loss-ulb:0.3149, weight:1.98, lr:0.0006
[03:14:45.691] iteration:5753  t-loss:0.2720, loss-lb:0.1801, loss-ulb:0.0465, weight:1.98, lr:0.0006
[03:14:46.036] iteration:5754  t-loss:0.4453, loss-lb:0.2834, loss-ulb:0.0820, weight:1.98, lr:0.0006
[03:14:46.374] iteration:5755  t-loss:1.3970, loss-lb:0.4063, loss-ulb:0.5016, weight:1.98, lr:0.0006
[03:14:46.692] iteration:5756  t-loss:0.4031, loss-lb:0.2178, loss-ulb:0.0938, weight:1.98, lr:0.0006
[03:14:47.008] iteration:5757  t-loss:0.3077, loss-lb:0.1530, loss-ulb:0.0783, weight:1.98, lr:0.0006
[03:14:47.323] iteration:5758  t-loss:0.6161, loss-lb:0.3284, loss-ulb:0.1457, weight:1.98, lr:0.0006
[03:14:47.642] iteration:5759  t-loss:0.5784, loss-lb:0.2803, loss-ulb:0.1509, weight:1.98, lr:0.0006
[03:14:47.961] iteration:5760  t-loss:0.6478, loss-lb:0.4379, loss-ulb:0.1063, weight:1.98, lr:0.0006
[03:14:48.276] iteration:5761  t-loss:0.5004, loss-lb:0.3095, loss-ulb:0.0967, weight:1.98, lr:0.0006
[03:14:48.603] iteration:5762  t-loss:0.2668, loss-lb:0.1775, loss-ulb:0.0452, weight:1.98, lr:0.0006
[03:14:48.941] iteration:5763  t-loss:0.5583, loss-lb:0.1609, loss-ulb:0.2012, weight:1.98, lr:0.0006
[03:14:49.280] iteration:5764  t-loss:0.3383, loss-lb:0.2204, loss-ulb:0.0597, weight:1.98, lr:0.0006
[03:14:49.603] iteration:5765  t-loss:0.3564, loss-lb:0.2167, loss-ulb:0.0707, weight:1.98, lr:0.0006
[03:14:49.937] iteration:5766  t-loss:1.1768, loss-lb:0.2849, loss-ulb:0.4515, weight:1.98, lr:0.0006
[03:14:50.253] iteration:5767  t-loss:0.2683, loss-lb:0.2188, loss-ulb:0.0251, weight:1.98, lr:0.0006
[03:14:50.578] iteration:5768  t-loss:0.7383, loss-lb:0.2742, loss-ulb:0.2349, weight:1.98, lr:0.0006
[03:14:50.899] iteration:5769  t-loss:0.6534, loss-lb:0.2654, loss-ulb:0.1964, weight:1.98, lr:0.0006
[03:14:51.212] iteration:5770  t-loss:0.2980, loss-lb:0.2619, loss-ulb:0.0182, weight:1.98, lr:0.0006
[03:14:51.528] iteration:5771  t-loss:0.6213, loss-lb:0.2813, loss-ulb:0.1722, weight:1.98, lr:0.0006
[03:14:51.844] iteration:5772  t-loss:0.4011, loss-lb:0.1935, loss-ulb:0.1051, weight:1.98, lr:0.0006
[03:14:52.159] iteration:5773  t-loss:0.4344, loss-lb:0.2194, loss-ulb:0.1089, weight:1.98, lr:0.0006
[03:14:52.473] iteration:5774  t-loss:0.2787, loss-lb:0.1754, loss-ulb:0.0523, weight:1.98, lr:0.0006
[03:14:52.792] iteration:5775  t-loss:0.2489, loss-lb:0.1785, loss-ulb:0.0357, weight:1.98, lr:0.0006
[03:14:54.219] iteration:5776  t-loss:0.4064, loss-lb:0.2646, loss-ulb:0.0718, weight:1.98, lr:0.0006
[03:14:54.558] iteration:5777  t-loss:0.2097, loss-lb:0.1534, loss-ulb:0.0285, weight:1.98, lr:0.0006
[03:14:54.890] iteration:5778  t-loss:0.4264, loss-lb:0.3841, loss-ulb:0.0214, weight:1.98, lr:0.0006
[03:14:55.222] iteration:5779  t-loss:0.4846, loss-lb:0.2422, loss-ulb:0.1228, weight:1.98, lr:0.0006
[03:14:55.544] iteration:5780  t-loss:0.3066, loss-lb:0.1698, loss-ulb:0.0693, weight:1.98, lr:0.0006
[03:14:55.864] iteration:5781  t-loss:0.5476, loss-lb:0.4274, loss-ulb:0.0609, weight:1.98, lr:0.0006
[03:14:56.181] iteration:5782  t-loss:0.3107, loss-lb:0.1805, loss-ulb:0.0659, weight:1.98, lr:0.0006
[03:14:56.499] iteration:5783  t-loss:0.5373, loss-lb:0.3428, loss-ulb:0.0985, weight:1.98, lr:0.0006
[03:14:56.816] iteration:5784  t-loss:0.6575, loss-lb:0.2724, loss-ulb:0.1950, weight:1.98, lr:0.0006
[03:14:57.133] iteration:5785  t-loss:0.4135, loss-lb:0.2576, loss-ulb:0.0789, weight:1.98, lr:0.0006
[03:14:57.452] iteration:5786  t-loss:0.2749, loss-lb:0.2261, loss-ulb:0.0247, weight:1.98, lr:0.0006
[03:14:57.771] iteration:5787  t-loss:0.4348, loss-lb:0.1600, loss-ulb:0.1391, weight:1.98, lr:0.0006
[03:14:58.090] iteration:5788  t-loss:0.5328, loss-lb:0.2159, loss-ulb:0.1605, weight:1.98, lr:0.0006
[03:14:58.405] iteration:5789  t-loss:0.4416, loss-lb:0.2169, loss-ulb:0.1137, weight:1.98, lr:0.0006
[03:14:58.721] iteration:5790  t-loss:0.3455, loss-lb:0.1907, loss-ulb:0.0784, weight:1.98, lr:0.0006
[03:14:59.043] iteration:5791  t-loss:0.6792, loss-lb:0.3596, loss-ulb:0.1618, weight:1.98, lr:0.0006
[03:14:59.359] iteration:5792  t-loss:0.4153, loss-lb:0.2576, loss-ulb:0.0798, weight:1.98, lr:0.0006
[03:14:59.674] iteration:5793  t-loss:0.6995, loss-lb:0.3223, loss-ulb:0.1910, weight:1.98, lr:0.0006
[03:14:59.991] iteration:5794  t-loss:0.6169, loss-lb:0.4784, loss-ulb:0.0701, weight:1.98, lr:0.0006
[03:15:00.305] iteration:5795  t-loss:0.3147, loss-lb:0.1872, loss-ulb:0.0645, weight:1.98, lr:0.0006
[03:15:00.621] iteration:5796  t-loss:0.3746, loss-lb:0.2464, loss-ulb:0.0649, weight:1.98, lr:0.0006
[03:15:00.939] iteration:5797  t-loss:0.3268, loss-lb:0.1630, loss-ulb:0.0829, weight:1.98, lr:0.0006
[03:15:01.255] iteration:5798  t-loss:0.7544, loss-lb:0.4717, loss-ulb:0.1431, weight:1.98, lr:0.0006
[03:15:01.572] iteration:5799  t-loss:1.1547, loss-lb:0.2396, loss-ulb:0.4633, weight:1.98, lr:0.0006
[03:15:01.888] iteration:5800  t-loss:1.0882, loss-lb:0.2082, loss-ulb:0.4455, weight:1.98, lr:0.0006
[03:15:03.309] iteration:5801  t-loss:1.3283, loss-lb:0.2015, loss-ulb:0.5705, weight:1.98, lr:0.0006
[03:15:03.647] iteration:5802  t-loss:1.2396, loss-lb:0.2081, loss-ulb:0.5222, weight:1.98, lr:0.0006
[03:15:03.971] iteration:5803  t-loss:0.7729, loss-lb:0.1638, loss-ulb:0.3084, weight:1.98, lr:0.0006
[03:15:04.289] iteration:5804  t-loss:1.2042, loss-lb:0.1886, loss-ulb:0.5142, weight:1.98, lr:0.0006
[03:15:04.605] iteration:5805  t-loss:0.2888, loss-lb:0.1902, loss-ulb:0.0499, weight:1.98, lr:0.0006
[03:15:04.925] iteration:5806  t-loss:1.1872, loss-lb:0.3197, loss-ulb:0.4392, weight:1.98, lr:0.0006
[03:15:05.248] iteration:5807  t-loss:0.4701, loss-lb:0.1824, loss-ulb:0.1457, weight:1.98, lr:0.0006
[03:15:05.572] iteration:5808  t-loss:0.6843, loss-lb:0.3979, loss-ulb:0.1450, weight:1.98, lr:0.0006
[03:15:05.901] iteration:5809  t-loss:0.2825, loss-lb:0.1447, loss-ulb:0.0697, weight:1.98, lr:0.0006
[03:15:06.228] iteration:5810  t-loss:0.5401, loss-lb:0.2635, loss-ulb:0.1400, weight:1.98, lr:0.0006
[03:15:06.556] iteration:5811  t-loss:0.4100, loss-lb:0.3174, loss-ulb:0.0469, weight:1.98, lr:0.0006
[03:15:06.880] iteration:5812  t-loss:0.2738, loss-lb:0.2139, loss-ulb:0.0303, weight:1.98, lr:0.0006
[03:15:07.210] iteration:5813  t-loss:0.6243, loss-lb:0.2469, loss-ulb:0.1911, weight:1.98, lr:0.0006
[03:15:07.528] iteration:5814  t-loss:0.2626, loss-lb:0.1813, loss-ulb:0.0412, weight:1.98, lr:0.0006
[03:15:07.853] iteration:5815  t-loss:0.5264, loss-lb:0.3979, loss-ulb:0.0650, weight:1.98, lr:0.0006
[03:15:08.178] iteration:5816  t-loss:0.8939, loss-lb:0.2613, loss-ulb:0.3203, weight:1.98, lr:0.0006
[03:15:08.498] iteration:5817  t-loss:0.7980, loss-lb:0.5003, loss-ulb:0.1507, weight:1.98, lr:0.0006
[03:15:08.817] iteration:5818  t-loss:0.6729, loss-lb:0.1725, loss-ulb:0.2534, weight:1.98, lr:0.0006
[03:15:09.132] iteration:5819  t-loss:0.5272, loss-lb:0.2245, loss-ulb:0.1532, weight:1.98, lr:0.0006
[03:15:09.450] iteration:5820  t-loss:0.4537, loss-lb:0.2510, loss-ulb:0.1027, weight:1.98, lr:0.0006
[03:15:09.766] iteration:5821  t-loss:0.2647, loss-lb:0.2256, loss-ulb:0.0198, weight:1.98, lr:0.0006
[03:15:10.080] iteration:5822  t-loss:0.4527, loss-lb:0.2125, loss-ulb:0.1216, weight:1.98, lr:0.0006
[03:15:10.394] iteration:5823  t-loss:0.5643, loss-lb:0.1577, loss-ulb:0.2058, weight:1.98, lr:0.0006
[03:15:10.717] iteration:5824  t-loss:0.5183, loss-lb:0.2767, loss-ulb:0.1223, weight:1.98, lr:0.0006
[03:15:11.032] iteration:5825  t-loss:0.3926, loss-lb:0.2234, loss-ulb:0.0857, weight:1.98, lr:0.0006
[03:17:16.483] iteration 5825 : dice_score: 0.838189 best_dice: 0.843400
[03:17:16.483]  <<Test>> - Ep:232  - Dice-S/T:83.13/83.82, Best-S:83.27, Best-T:84.34
[03:17:16.483]           - AvgLoss(lb/ulb/all):0.24/0.14/0.54
[03:17:17.493] iteration:5826  t-loss:0.6374, loss-lb:0.2647, loss-ulb:0.1887, weight:1.98, lr:0.0006
[03:17:17.830] iteration:5827  t-loss:0.5670, loss-lb:0.2704, loss-ulb:0.1502, weight:1.98, lr:0.0006
[03:17:18.155] iteration:5828  t-loss:0.8729, loss-lb:0.3928, loss-ulb:0.2431, weight:1.98, lr:0.0006
[03:17:18.478] iteration:5829  t-loss:0.4938, loss-lb:0.3556, loss-ulb:0.0700, weight:1.98, lr:0.0006
[03:17:18.823] iteration:5830  t-loss:0.8016, loss-lb:0.1610, loss-ulb:0.3244, weight:1.98, lr:0.0006
[03:17:19.156] iteration:5831  t-loss:0.3060, loss-lb:0.1626, loss-ulb:0.0726, weight:1.98, lr:0.0006
[03:17:19.510] iteration:5832  t-loss:0.5511, loss-lb:0.3098, loss-ulb:0.1222, weight:1.98, lr:0.0006
[03:17:19.839] iteration:5833  t-loss:0.6739, loss-lb:0.1940, loss-ulb:0.2429, weight:1.98, lr:0.0006
[03:17:20.173] iteration:5834  t-loss:1.4426, loss-lb:0.2606, loss-ulb:0.5984, weight:1.98, lr:0.0006
[03:17:20.506] iteration:5835  t-loss:1.6089, loss-lb:0.2332, loss-ulb:0.6965, weight:1.98, lr:0.0006
[03:17:20.829] iteration:5836  t-loss:0.2930, loss-lb:0.2106, loss-ulb:0.0417, weight:1.98, lr:0.0006
[03:17:21.148] iteration:5837  t-loss:0.3058, loss-lb:0.2560, loss-ulb:0.0252, weight:1.98, lr:0.0006
[03:17:21.468] iteration:5838  t-loss:1.1145, loss-lb:0.2256, loss-ulb:0.4500, weight:1.98, lr:0.0006
[03:17:21.793] iteration:5839  t-loss:0.5335, loss-lb:0.1870, loss-ulb:0.1754, weight:1.98, lr:0.0006
[03:17:22.108] iteration:5840  t-loss:0.2571, loss-lb:0.1740, loss-ulb:0.0420, weight:1.98, lr:0.0006
[03:17:22.427] iteration:5841  t-loss:0.7448, loss-lb:0.2570, loss-ulb:0.2470, weight:1.98, lr:0.0006
[03:17:22.742] iteration:5842  t-loss:0.2924, loss-lb:0.1741, loss-ulb:0.0599, weight:1.98, lr:0.0006
[03:17:23.056] iteration:5843  t-loss:0.2133, loss-lb:0.1703, loss-ulb:0.0218, weight:1.98, lr:0.0006
[03:17:23.374] iteration:5844  t-loss:0.3157, loss-lb:0.1583, loss-ulb:0.0797, weight:1.98, lr:0.0006
[03:17:23.692] iteration:5845  t-loss:0.6392, loss-lb:0.2449, loss-ulb:0.1996, weight:1.98, lr:0.0006
[03:17:24.011] iteration:5846  t-loss:0.5750, loss-lb:0.2404, loss-ulb:0.1694, weight:1.98, lr:0.0006
[03:17:24.323] iteration:5847  t-loss:0.2893, loss-lb:0.2219, loss-ulb:0.0341, weight:1.98, lr:0.0006
[03:17:24.635] iteration:5848  t-loss:0.8534, loss-lb:0.2484, loss-ulb:0.3063, weight:1.98, lr:0.0006
[03:17:24.945] iteration:5849  t-loss:0.2418, loss-lb:0.1822, loss-ulb:0.0301, weight:1.98, lr:0.0006
[03:17:25.262] iteration:5850  t-loss:0.9716, loss-lb:0.2843, loss-ulb:0.3480, weight:1.98, lr:0.0006
[03:17:26.486] iteration:5851  t-loss:0.7607, loss-lb:0.2897, loss-ulb:0.2363, weight:1.99, lr:0.0006
[03:17:26.825] iteration:5852  t-loss:0.4878, loss-lb:0.3790, loss-ulb:0.0545, weight:1.99, lr:0.0006
[03:17:27.153] iteration:5853  t-loss:0.3164, loss-lb:0.1282, loss-ulb:0.0944, weight:1.99, lr:0.0006
[03:17:27.485] iteration:5854  t-loss:0.6213, loss-lb:0.3034, loss-ulb:0.1594, weight:1.99, lr:0.0006
[03:17:27.834] iteration:5855  t-loss:1.6673, loss-lb:0.3036, loss-ulb:0.6840, weight:1.99, lr:0.0006
[03:17:28.172] iteration:5856  t-loss:0.3933, loss-lb:0.1974, loss-ulb:0.0983, weight:1.99, lr:0.0006
[03:17:28.524] iteration:5857  t-loss:0.4686, loss-lb:0.3675, loss-ulb:0.0507, weight:1.99, lr:0.0006
[03:17:28.862] iteration:5858  t-loss:0.6284, loss-lb:0.2580, loss-ulb:0.1858, weight:1.99, lr:0.0006
[03:17:29.188] iteration:5859  t-loss:1.5049, loss-lb:0.3840, loss-ulb:0.5622, weight:1.99, lr:0.0006
[03:17:29.516] iteration:5860  t-loss:0.6739, loss-lb:0.2295, loss-ulb:0.2229, weight:1.99, lr:0.0006
[03:17:29.833] iteration:5861  t-loss:0.6795, loss-lb:0.1921, loss-ulb:0.2444, weight:1.99, lr:0.0006
[03:17:30.161] iteration:5862  t-loss:0.5807, loss-lb:0.4417, loss-ulb:0.0697, weight:1.99, lr:0.0006
[03:17:30.486] iteration:5863  t-loss:0.7991, loss-lb:0.3087, loss-ulb:0.2460, weight:1.99, lr:0.0006
[03:17:30.805] iteration:5864  t-loss:0.4089, loss-lb:0.1678, loss-ulb:0.1209, weight:1.99, lr:0.0006
[03:17:31.127] iteration:5865  t-loss:0.8517, loss-lb:0.4212, loss-ulb:0.2159, weight:1.99, lr:0.0006
[03:17:31.446] iteration:5866  t-loss:0.7050, loss-lb:0.4294, loss-ulb:0.1382, weight:1.99, lr:0.0006
[03:17:31.766] iteration:5867  t-loss:0.4445, loss-lb:0.3237, loss-ulb:0.0606, weight:1.99, lr:0.0006
[03:17:32.082] iteration:5868  t-loss:0.5847, loss-lb:0.3414, loss-ulb:0.1220, weight:1.99, lr:0.0006
[03:17:32.401] iteration:5869  t-loss:0.7319, loss-lb:0.6355, loss-ulb:0.0484, weight:1.99, lr:0.0006
[03:17:32.717] iteration:5870  t-loss:0.4846, loss-lb:0.2490, loss-ulb:0.1182, weight:1.99, lr:0.0006
[03:17:33.031] iteration:5871  t-loss:0.2963, loss-lb:0.2220, loss-ulb:0.0373, weight:1.99, lr:0.0006
[03:17:33.344] iteration:5872  t-loss:0.9262, loss-lb:0.3707, loss-ulb:0.2786, weight:1.99, lr:0.0006
[03:17:33.658] iteration:5873  t-loss:0.5691, loss-lb:0.2491, loss-ulb:0.1605, weight:1.99, lr:0.0006
[03:17:33.972] iteration:5874  t-loss:0.5123, loss-lb:0.2526, loss-ulb:0.1303, weight:1.99, lr:0.0006
[03:17:34.286] iteration:5875  t-loss:0.2850, loss-lb:0.2222, loss-ulb:0.0315, weight:1.99, lr:0.0006
[03:17:35.579] iteration:5876  t-loss:0.2650, loss-lb:0.1864, loss-ulb:0.0395, weight:1.99, lr:0.0006
[03:17:35.919] iteration:5877  t-loss:1.3693, loss-lb:0.2672, loss-ulb:0.5528, weight:1.99, lr:0.0006
[03:17:36.246] iteration:5878  t-loss:0.3825, loss-lb:0.2343, loss-ulb:0.0744, weight:1.99, lr:0.0006
[03:17:36.568] iteration:5879  t-loss:1.0733, loss-lb:0.3856, loss-ulb:0.3450, weight:1.99, lr:0.0006
[03:17:36.888] iteration:5880  t-loss:0.4038, loss-lb:0.3210, loss-ulb:0.0416, weight:1.99, lr:0.0006
[03:17:37.207] iteration:5881  t-loss:0.9013, loss-lb:0.1576, loss-ulb:0.3730, weight:1.99, lr:0.0006
[03:17:37.527] iteration:5882  t-loss:0.4995, loss-lb:0.1752, loss-ulb:0.1627, weight:1.99, lr:0.0006
[03:17:37.850] iteration:5883  t-loss:0.4617, loss-lb:0.2969, loss-ulb:0.0827, weight:1.99, lr:0.0006
[03:17:38.170] iteration:5884  t-loss:0.6377, loss-lb:0.3523, loss-ulb:0.1432, weight:1.99, lr:0.0006
[03:17:38.486] iteration:5885  t-loss:0.4349, loss-lb:0.1739, loss-ulb:0.1309, weight:1.99, lr:0.0006
[03:17:38.808] iteration:5886  t-loss:0.5561, loss-lb:0.2920, loss-ulb:0.1325, weight:1.99, lr:0.0006
[03:17:39.128] iteration:5887  t-loss:0.6914, loss-lb:0.2989, loss-ulb:0.1969, weight:1.99, lr:0.0006
[03:17:39.448] iteration:5888  t-loss:0.5454, loss-lb:0.1990, loss-ulb:0.1737, weight:1.99, lr:0.0006
[03:17:39.766] iteration:5889  t-loss:0.5268, loss-lb:0.2217, loss-ulb:0.1531, weight:1.99, lr:0.0006
[03:17:40.082] iteration:5890  t-loss:0.3713, loss-lb:0.1762, loss-ulb:0.0979, weight:1.99, lr:0.0006
[03:17:40.400] iteration:5891  t-loss:0.5861, loss-lb:0.2284, loss-ulb:0.1794, weight:1.99, lr:0.0006
[03:17:40.721] iteration:5892  t-loss:0.5738, loss-lb:0.1788, loss-ulb:0.1981, weight:1.99, lr:0.0006
[03:17:41.037] iteration:5893  t-loss:0.8248, loss-lb:0.1563, loss-ulb:0.3353, weight:1.99, lr:0.0006
[03:17:41.354] iteration:5894  t-loss:0.3953, loss-lb:0.2120, loss-ulb:0.0920, weight:1.99, lr:0.0006
[03:17:41.670] iteration:5895  t-loss:0.6286, loss-lb:0.3237, loss-ulb:0.1529, weight:1.99, lr:0.0006
[03:17:41.987] iteration:5896  t-loss:0.3483, loss-lb:0.2588, loss-ulb:0.0449, weight:1.99, lr:0.0006
[03:17:42.317] iteration:5897  t-loss:1.1336, loss-lb:0.2021, loss-ulb:0.4672, weight:1.99, lr:0.0006
[03:17:42.644] iteration:5898  t-loss:0.7210, loss-lb:0.2622, loss-ulb:0.2301, weight:1.99, lr:0.0006
[03:17:42.958] iteration:5899  t-loss:0.2155, loss-lb:0.1686, loss-ulb:0.0235, weight:1.99, lr:0.0006
[03:17:43.274] iteration:5900  t-loss:0.4637, loss-lb:0.1901, loss-ulb:0.1372, weight:1.99, lr:0.0006
[03:17:44.653] iteration:5901  t-loss:0.2907, loss-lb:0.2135, loss-ulb:0.0387, weight:1.99, lr:0.0006
[03:17:45.028] iteration:5902  t-loss:0.6470, loss-lb:0.1963, loss-ulb:0.2261, weight:1.99, lr:0.0006
[03:17:45.365] iteration:5903  t-loss:0.2868, loss-lb:0.2094, loss-ulb:0.0388, weight:1.99, lr:0.0006
[03:17:45.703] iteration:5904  t-loss:0.9400, loss-lb:0.3484, loss-ulb:0.2968, weight:1.99, lr:0.0006
[03:17:46.022] iteration:5905  t-loss:0.4643, loss-lb:0.1979, loss-ulb:0.1336, weight:1.99, lr:0.0006
[03:17:46.346] iteration:5906  t-loss:0.4559, loss-lb:0.2757, loss-ulb:0.0904, weight:1.99, lr:0.0006
[03:17:46.658] iteration:5907  t-loss:0.3165, loss-lb:0.1893, loss-ulb:0.0638, weight:1.99, lr:0.0006
[03:17:46.981] iteration:5908  t-loss:0.6809, loss-lb:0.3007, loss-ulb:0.1907, weight:1.99, lr:0.0006
[03:17:47.300] iteration:5909  t-loss:0.5132, loss-lb:0.2291, loss-ulb:0.1425, weight:1.99, lr:0.0006
[03:17:47.619] iteration:5910  t-loss:0.5370, loss-lb:0.1721, loss-ulb:0.1830, weight:1.99, lr:0.0006
[03:17:47.943] iteration:5911  t-loss:0.3482, loss-lb:0.2023, loss-ulb:0.0732, weight:1.99, lr:0.0006
[03:17:48.264] iteration:5912  t-loss:0.2377, loss-lb:0.1608, loss-ulb:0.0386, weight:1.99, lr:0.0006
[03:17:48.580] iteration:5913  t-loss:0.3656, loss-lb:0.2625, loss-ulb:0.0517, weight:1.99, lr:0.0006
[03:17:48.903] iteration:5914  t-loss:0.3116, loss-lb:0.2548, loss-ulb:0.0285, weight:1.99, lr:0.0006
[03:17:49.219] iteration:5915  t-loss:0.4624, loss-lb:0.2339, loss-ulb:0.1146, weight:1.99, lr:0.0006
[03:17:49.535] iteration:5916  t-loss:0.2113, loss-lb:0.1660, loss-ulb:0.0227, weight:1.99, lr:0.0006
[03:17:49.853] iteration:5917  t-loss:0.4160, loss-lb:0.2182, loss-ulb:0.0992, weight:1.99, lr:0.0006
[03:17:50.169] iteration:5918  t-loss:0.3906, loss-lb:0.1700, loss-ulb:0.1106, weight:1.99, lr:0.0006
[03:17:50.483] iteration:5919  t-loss:0.3197, loss-lb:0.1209, loss-ulb:0.0997, weight:1.99, lr:0.0006
[03:17:50.802] iteration:5920  t-loss:1.3248, loss-lb:0.2517, loss-ulb:0.5382, weight:1.99, lr:0.0006
[03:17:51.123] iteration:5921  t-loss:0.3639, loss-lb:0.2200, loss-ulb:0.0722, weight:1.99, lr:0.0006
[03:17:51.446] iteration:5922  t-loss:0.4597, loss-lb:0.2248, loss-ulb:0.1178, weight:1.99, lr:0.0006
[03:17:51.766] iteration:5923  t-loss:0.4479, loss-lb:0.1913, loss-ulb:0.1287, weight:1.99, lr:0.0006
[03:17:52.091] iteration:5924  t-loss:0.6061, loss-lb:0.3894, loss-ulb:0.1087, weight:1.99, lr:0.0006
[03:17:52.420] iteration:5925  t-loss:0.5314, loss-lb:0.3006, loss-ulb:0.1158, weight:1.99, lr:0.0006
[03:20:01.363] iteration 5925 : dice_score: 0.838479 best_dice: 0.843400
[03:20:01.363]  <<Test>> - Ep:236  - Dice-S/T:81.25/83.85, Best-S:83.27, Best-T:84.34
[03:20:01.363]           - AvgLoss(lb/ulb/all):0.23/0.12/0.47
[03:20:02.501] iteration:5926  t-loss:1.1232, loss-lb:0.1871, loss-ulb:0.4695, weight:1.99, lr:0.0006
[03:20:02.838] iteration:5927  t-loss:0.5823, loss-lb:0.3146, loss-ulb:0.1343, weight:1.99, lr:0.0006
[03:20:03.163] iteration:5928  t-loss:0.2941, loss-lb:0.2438, loss-ulb:0.0252, weight:1.99, lr:0.0006
[03:20:03.498] iteration:5929  t-loss:0.4230, loss-lb:0.2227, loss-ulb:0.1005, weight:1.99, lr:0.0006
[03:20:03.853] iteration:5930  t-loss:1.2034, loss-lb:0.4203, loss-ulb:0.3928, weight:1.99, lr:0.0006
[03:20:04.191] iteration:5931  t-loss:0.5077, loss-lb:0.4017, loss-ulb:0.0532, weight:1.99, lr:0.0006
[03:20:04.553] iteration:5932  t-loss:0.4439, loss-lb:0.2955, loss-ulb:0.0744, weight:1.99, lr:0.0006
[03:20:04.879] iteration:5933  t-loss:0.5893, loss-lb:0.3703, loss-ulb:0.1098, weight:1.99, lr:0.0006
[03:20:05.207] iteration:5934  t-loss:0.3575, loss-lb:0.1530, loss-ulb:0.1026, weight:1.99, lr:0.0006
[03:20:05.541] iteration:5935  t-loss:0.4125, loss-lb:0.2043, loss-ulb:0.1045, weight:1.99, lr:0.0006
[03:20:05.865] iteration:5936  t-loss:0.4226, loss-lb:0.1431, loss-ulb:0.1402, weight:1.99, lr:0.0006
[03:20:06.194] iteration:5937  t-loss:1.2082, loss-lb:0.2664, loss-ulb:0.4723, weight:1.99, lr:0.0006
[03:20:06.534] iteration:5938  t-loss:0.5647, loss-lb:0.3452, loss-ulb:0.1101, weight:1.99, lr:0.0006
[03:20:06.855] iteration:5939  t-loss:0.2509, loss-lb:0.2060, loss-ulb:0.0225, weight:1.99, lr:0.0006
[03:20:07.175] iteration:5940  t-loss:0.4470, loss-lb:0.2404, loss-ulb:0.1036, weight:1.99, lr:0.0006
[03:20:07.510] iteration:5941  t-loss:0.5784, loss-lb:0.1873, loss-ulb:0.1962, weight:1.99, lr:0.0006
[03:20:07.835] iteration:5942  t-loss:0.5323, loss-lb:0.2078, loss-ulb:0.1627, weight:1.99, lr:0.0006
[03:20:08.155] iteration:5943  t-loss:0.3150, loss-lb:0.1547, loss-ulb:0.0804, weight:1.99, lr:0.0006
[03:20:08.472] iteration:5944  t-loss:0.5878, loss-lb:0.1721, loss-ulb:0.2085, weight:1.99, lr:0.0006
[03:20:08.788] iteration:5945  t-loss:0.4305, loss-lb:0.3162, loss-ulb:0.0573, weight:1.99, lr:0.0006
[03:20:09.104] iteration:5946  t-loss:1.2661, loss-lb:0.2752, loss-ulb:0.4970, weight:1.99, lr:0.0006
[03:20:09.418] iteration:5947  t-loss:0.3352, loss-lb:0.1882, loss-ulb:0.0737, weight:1.99, lr:0.0006
[03:20:09.727] iteration:5948  t-loss:0.2746, loss-lb:0.2062, loss-ulb:0.0343, weight:1.99, lr:0.0006
[03:20:10.037] iteration:5949  t-loss:0.3693, loss-lb:0.1845, loss-ulb:0.0927, weight:1.99, lr:0.0006
[03:20:10.346] iteration:5950  t-loss:0.8270, loss-lb:0.1943, loss-ulb:0.3173, weight:1.99, lr:0.0006
[03:20:11.487] iteration:5951  t-loss:0.5136, loss-lb:0.2198, loss-ulb:0.1473, weight:1.99, lr:0.0006
[03:20:11.818] iteration:5952  t-loss:0.2539, loss-lb:0.1932, loss-ulb:0.0305, weight:1.99, lr:0.0006
[03:20:12.145] iteration:5953  t-loss:0.6970, loss-lb:0.2540, loss-ulb:0.2222, weight:1.99, lr:0.0006
[03:20:12.481] iteration:5954  t-loss:0.2756, loss-lb:0.2097, loss-ulb:0.0330, weight:1.99, lr:0.0006
[03:20:12.818] iteration:5955  t-loss:0.3026, loss-lb:0.1763, loss-ulb:0.0634, weight:1.99, lr:0.0006
[03:20:13.153] iteration:5956  t-loss:0.5619, loss-lb:0.2145, loss-ulb:0.1742, weight:1.99, lr:0.0006
[03:20:13.474] iteration:5957  t-loss:0.5090, loss-lb:0.3261, loss-ulb:0.0917, weight:1.99, lr:0.0006
[03:20:13.795] iteration:5958  t-loss:0.7229, loss-lb:0.3362, loss-ulb:0.1940, weight:1.99, lr:0.0006
[03:20:14.114] iteration:5959  t-loss:0.7752, loss-lb:0.3901, loss-ulb:0.1931, weight:1.99, lr:0.0006
[03:20:14.439] iteration:5960  t-loss:0.3596, loss-lb:0.1731, loss-ulb:0.0935, weight:1.99, lr:0.0006
[03:20:14.769] iteration:5961  t-loss:0.3766, loss-lb:0.2438, loss-ulb:0.0666, weight:1.99, lr:0.0006
[03:20:15.091] iteration:5962  t-loss:1.0120, loss-lb:0.1578, loss-ulb:0.4284, weight:1.99, lr:0.0006
[03:20:15.417] iteration:5963  t-loss:0.2779, loss-lb:0.2036, loss-ulb:0.0373, weight:1.99, lr:0.0006
[03:20:15.743] iteration:5964  t-loss:0.3358, loss-lb:0.2889, loss-ulb:0.0235, weight:1.99, lr:0.0006
[03:20:16.075] iteration:5965  t-loss:0.2688, loss-lb:0.2165, loss-ulb:0.0262, weight:1.99, lr:0.0006
[03:20:16.399] iteration:5966  t-loss:0.5690, loss-lb:0.1813, loss-ulb:0.1945, weight:1.99, lr:0.0006
[03:20:16.733] iteration:5967  t-loss:0.3688, loss-lb:0.2097, loss-ulb:0.0798, weight:1.99, lr:0.0006
[03:20:17.055] iteration:5968  t-loss:0.4206, loss-lb:0.2630, loss-ulb:0.0791, weight:1.99, lr:0.0006
[03:20:17.371] iteration:5969  t-loss:0.2912, loss-lb:0.2115, loss-ulb:0.0399, weight:1.99, lr:0.0006
[03:20:17.689] iteration:5970  t-loss:0.3559, loss-lb:0.1741, loss-ulb:0.0912, weight:1.99, lr:0.0006
[03:20:18.010] iteration:5971  t-loss:0.4661, loss-lb:0.1947, loss-ulb:0.1361, weight:1.99, lr:0.0006
[03:20:18.329] iteration:5972  t-loss:0.7501, loss-lb:0.2539, loss-ulb:0.2489, weight:1.99, lr:0.0006
[03:20:18.647] iteration:5973  t-loss:0.2694, loss-lb:0.1844, loss-ulb:0.0427, weight:1.99, lr:0.0006
[03:20:18.962] iteration:5974  t-loss:0.4495, loss-lb:0.2281, loss-ulb:0.1111, weight:1.99, lr:0.0006
[03:20:19.276] iteration:5975  t-loss:0.4453, loss-lb:0.2566, loss-ulb:0.0946, weight:1.99, lr:0.0006
[03:20:20.403] iteration:5976  t-loss:0.4485, loss-lb:0.2893, loss-ulb:0.0799, weight:1.99, lr:0.0006
[03:20:20.733] iteration:5977  t-loss:0.3704, loss-lb:0.1685, loss-ulb:0.1012, weight:1.99, lr:0.0006
[03:20:21.073] iteration:5978  t-loss:0.5935, loss-lb:0.1785, loss-ulb:0.2082, weight:1.99, lr:0.0006
[03:20:21.409] iteration:5979  t-loss:0.3366, loss-lb:0.2958, loss-ulb:0.0205, weight:1.99, lr:0.0006
[03:20:21.756] iteration:5980  t-loss:1.0657, loss-lb:0.2317, loss-ulb:0.4183, weight:1.99, lr:0.0006
[03:20:22.092] iteration:5981  t-loss:0.3810, loss-lb:0.1967, loss-ulb:0.0924, weight:1.99, lr:0.0006
[03:20:22.431] iteration:5982  t-loss:0.3595, loss-lb:0.2316, loss-ulb:0.0642, weight:1.99, lr:0.0006
[03:20:22.751] iteration:5983  t-loss:0.2644, loss-lb:0.1885, loss-ulb:0.0380, weight:1.99, lr:0.0006
[03:20:23.074] iteration:5984  t-loss:0.2412, loss-lb:0.1746, loss-ulb:0.0334, weight:1.99, lr:0.0006
[03:20:23.402] iteration:5985  t-loss:0.3073, loss-lb:0.1487, loss-ulb:0.0795, weight:1.99, lr:0.0006
[03:20:23.719] iteration:5986  t-loss:0.3503, loss-lb:0.2040, loss-ulb:0.0734, weight:1.99, lr:0.0006
[03:20:24.037] iteration:5987  t-loss:0.5989, loss-lb:0.4178, loss-ulb:0.0909, weight:1.99, lr:0.0006
[03:20:24.366] iteration:5988  t-loss:0.3678, loss-lb:0.1691, loss-ulb:0.0997, weight:1.99, lr:0.0006
[03:20:24.695] iteration:5989  t-loss:1.0548, loss-lb:0.4141, loss-ulb:0.3213, weight:1.99, lr:0.0006
[03:20:25.016] iteration:5990  t-loss:0.6090, loss-lb:0.1714, loss-ulb:0.2195, weight:1.99, lr:0.0006
[03:20:25.346] iteration:5991  t-loss:0.3778, loss-lb:0.2999, loss-ulb:0.0391, weight:1.99, lr:0.0006
[03:20:25.677] iteration:5992  t-loss:0.5309, loss-lb:0.3002, loss-ulb:0.1157, weight:1.99, lr:0.0006
[03:20:25.994] iteration:5993  t-loss:0.4269, loss-lb:0.2231, loss-ulb:0.1022, weight:1.99, lr:0.0006
[03:20:26.314] iteration:5994  t-loss:0.4840, loss-lb:0.3017, loss-ulb:0.0914, weight:1.99, lr:0.0006
[03:20:26.631] iteration:5995  t-loss:0.4774, loss-lb:0.2103, loss-ulb:0.1339, weight:1.99, lr:0.0006
[03:20:26.944] iteration:5996  t-loss:0.7562, loss-lb:0.2205, loss-ulb:0.2687, weight:1.99, lr:0.0006
[03:20:27.256] iteration:5997  t-loss:0.4099, loss-lb:0.3420, loss-ulb:0.0341, weight:1.99, lr:0.0006
[03:20:27.571] iteration:5998  t-loss:0.7007, loss-lb:0.2618, loss-ulb:0.2202, weight:1.99, lr:0.0006
[03:20:27.884] iteration:5999  t-loss:0.3717, loss-lb:0.2209, loss-ulb:0.0756, weight:1.99, lr:0.0006
[03:20:28.198] iteration:6000  t-loss:0.4703, loss-lb:0.3681, loss-ulb:0.0513, weight:1.99, lr:0.0006
[03:20:29.239] iteration:6001  t-loss:0.4247, loss-lb:0.1815, loss-ulb:0.1216, weight:2.00, lr:0.0006
[03:20:29.575] iteration:6002  t-loss:0.4571, loss-lb:0.3753, loss-ulb:0.0409, weight:2.00, lr:0.0006
[03:20:29.927] iteration:6003  t-loss:0.4552, loss-lb:0.2502, loss-ulb:0.1025, weight:2.00, lr:0.0006
[03:20:30.252] iteration:6004  t-loss:0.2025, loss-lb:0.1452, loss-ulb:0.0286, weight:2.00, lr:0.0006
[03:20:30.578] iteration:6005  t-loss:0.4169, loss-lb:0.2010, loss-ulb:0.1080, weight:2.00, lr:0.0006
[03:20:30.905] iteration:6006  t-loss:0.4876, loss-lb:0.2694, loss-ulb:0.1091, weight:2.00, lr:0.0006
[03:20:31.227] iteration:6007  t-loss:0.3282, loss-lb:0.1785, loss-ulb:0.0749, weight:2.00, lr:0.0006
[03:20:31.549] iteration:6008  t-loss:0.3994, loss-lb:0.1664, loss-ulb:0.1165, weight:2.00, lr:0.0006
[03:20:31.870] iteration:6009  t-loss:0.8597, loss-lb:0.1436, loss-ulb:0.3581, weight:2.00, lr:0.0006
[03:20:32.187] iteration:6010  t-loss:0.5165, loss-lb:0.2045, loss-ulb:0.1560, weight:2.00, lr:0.0006
[03:20:32.508] iteration:6011  t-loss:0.3551, loss-lb:0.1422, loss-ulb:0.1064, weight:2.00, lr:0.0006
[03:20:32.829] iteration:6012  t-loss:0.4572, loss-lb:0.2606, loss-ulb:0.0983, weight:2.00, lr:0.0006
[03:20:33.156] iteration:6013  t-loss:1.3582, loss-lb:0.4115, loss-ulb:0.4733, weight:2.00, lr:0.0006
[03:20:33.473] iteration:6014  t-loss:0.3859, loss-lb:0.1462, loss-ulb:0.1198, weight:2.00, lr:0.0006
[03:20:33.796] iteration:6015  t-loss:0.2442, loss-lb:0.2046, loss-ulb:0.0198, weight:2.00, lr:0.0006
[03:20:34.121] iteration:6016  t-loss:0.6855, loss-lb:0.2982, loss-ulb:0.1936, weight:2.00, lr:0.0006
[03:20:34.445] iteration:6017  t-loss:1.0476, loss-lb:0.1403, loss-ulb:0.4537, weight:2.00, lr:0.0006
[03:20:34.764] iteration:6018  t-loss:0.3039, loss-lb:0.2125, loss-ulb:0.0457, weight:2.00, lr:0.0006
[03:20:35.083] iteration:6019  t-loss:0.6108, loss-lb:0.2389, loss-ulb:0.1860, weight:2.00, lr:0.0006
[03:20:35.399] iteration:6020  t-loss:0.2694, loss-lb:0.1681, loss-ulb:0.0507, weight:2.00, lr:0.0006
[03:20:35.716] iteration:6021  t-loss:0.6674, loss-lb:0.5928, loss-ulb:0.0373, weight:2.00, lr:0.0006
[03:20:36.032] iteration:6022  t-loss:0.2776, loss-lb:0.1958, loss-ulb:0.0409, weight:2.00, lr:0.0006
[03:20:36.348] iteration:6023  t-loss:0.4507, loss-lb:0.1746, loss-ulb:0.1380, weight:2.00, lr:0.0006
[03:20:36.658] iteration:6024  t-loss:0.5051, loss-lb:0.1485, loss-ulb:0.1783, weight:2.00, lr:0.0006
[03:20:36.975] iteration:6025  t-loss:0.3268, loss-lb:0.2067, loss-ulb:0.0600, weight:2.00, lr:0.0006
[03:22:43.413] iteration 6025 : dice_score: 0.839109 best_dice: 0.843400
[03:22:43.413]  <<Test>> - Ep:240  - Dice-S/T:82.86/83.91, Best-S:83.27, Best-T:84.34
[03:22:43.413]           - AvgLoss(lb/ulb/all):0.23/0.15/0.53
[03:22:44.822] iteration:6026  t-loss:0.2827, loss-lb:0.1324, loss-ulb:0.0751, weight:2.00, lr:0.0006
[03:22:45.142] iteration:6027  t-loss:0.2891, loss-lb:0.2069, loss-ulb:0.0411, weight:2.00, lr:0.0006
[03:22:45.459] iteration:6028  t-loss:0.2748, loss-lb:0.1886, loss-ulb:0.0431, weight:2.00, lr:0.0006
[03:22:45.772] iteration:6029  t-loss:0.6145, loss-lb:0.2543, loss-ulb:0.1801, weight:2.00, lr:0.0006
[03:22:46.091] iteration:6030  t-loss:0.2549, loss-lb:0.2018, loss-ulb:0.0265, weight:2.00, lr:0.0006
[03:22:46.404] iteration:6031  t-loss:0.3201, loss-lb:0.1939, loss-ulb:0.0631, weight:2.00, lr:0.0006
[03:22:46.718] iteration:6032  t-loss:0.4316, loss-lb:0.1629, loss-ulb:0.1344, weight:2.00, lr:0.0006
[03:22:47.033] iteration:6033  t-loss:0.4289, loss-lb:0.2364, loss-ulb:0.0962, weight:2.00, lr:0.0006
[03:22:47.353] iteration:6034  t-loss:0.6005, loss-lb:0.1949, loss-ulb:0.2028, weight:2.00, lr:0.0006
[03:22:47.703] iteration:6035  t-loss:0.5492, loss-lb:0.1876, loss-ulb:0.1808, weight:2.00, lr:0.0006
[03:22:48.039] iteration:6036  t-loss:0.4095, loss-lb:0.2685, loss-ulb:0.0705, weight:2.00, lr:0.0006
[03:22:48.365] iteration:6037  t-loss:0.5159, loss-lb:0.2396, loss-ulb:0.1382, weight:2.00, lr:0.0006
[03:22:48.693] iteration:6038  t-loss:0.4190, loss-lb:0.2078, loss-ulb:0.1056, weight:2.00, lr:0.0006
[03:22:49.011] iteration:6039  t-loss:0.5013, loss-lb:0.3710, loss-ulb:0.0651, weight:2.00, lr:0.0006
[03:22:49.328] iteration:6040  t-loss:0.4163, loss-lb:0.1684, loss-ulb:0.1239, weight:2.00, lr:0.0006
[03:22:49.656] iteration:6041  t-loss:0.2898, loss-lb:0.1405, loss-ulb:0.0746, weight:2.00, lr:0.0006
[03:22:49.977] iteration:6042  t-loss:0.3864, loss-lb:0.1925, loss-ulb:0.0970, weight:2.00, lr:0.0006
[03:22:50.294] iteration:6043  t-loss:0.3986, loss-lb:0.1954, loss-ulb:0.1016, weight:2.00, lr:0.0006
[03:22:50.607] iteration:6044  t-loss:0.9969, loss-lb:0.1704, loss-ulb:0.4133, weight:2.00, lr:0.0006
[03:22:50.921] iteration:6045  t-loss:0.3231, loss-lb:0.1903, loss-ulb:0.0664, weight:2.00, lr:0.0006
[03:22:51.239] iteration:6046  t-loss:0.3455, loss-lb:0.2235, loss-ulb:0.0610, weight:2.00, lr:0.0006
[03:22:51.553] iteration:6047  t-loss:0.6191, loss-lb:0.3034, loss-ulb:0.1578, weight:2.00, lr:0.0006
[03:22:51.868] iteration:6048  t-loss:0.8932, loss-lb:0.1471, loss-ulb:0.3731, weight:2.00, lr:0.0006
[03:22:52.183] iteration:6049  t-loss:0.7397, loss-lb:0.3380, loss-ulb:0.2009, weight:2.00, lr:0.0006
[03:22:52.499] iteration:6050  t-loss:1.1873, loss-lb:0.3341, loss-ulb:0.4266, weight:2.00, lr:0.0006
[03:22:53.627] iteration:6051  t-loss:0.4193, loss-lb:0.2601, loss-ulb:0.0796, weight:2.00, lr:0.0006
[03:22:53.953] iteration:6052  t-loss:0.3674, loss-lb:0.2162, loss-ulb:0.0756, weight:2.00, lr:0.0006
[03:22:54.271] iteration:6053  t-loss:0.3472, loss-lb:0.2584, loss-ulb:0.0444, weight:2.00, lr:0.0006
[03:22:54.582] iteration:6054  t-loss:0.2088, loss-lb:0.1685, loss-ulb:0.0201, weight:2.00, lr:0.0006
[03:22:54.898] iteration:6055  t-loss:0.7447, loss-lb:0.2972, loss-ulb:0.2237, weight:2.00, lr:0.0006
[03:22:55.212] iteration:6056  t-loss:0.2672, loss-lb:0.1820, loss-ulb:0.0426, weight:2.00, lr:0.0006
[03:22:55.527] iteration:6057  t-loss:0.3321, loss-lb:0.1716, loss-ulb:0.0802, weight:2.00, lr:0.0006
[03:22:55.851] iteration:6058  t-loss:0.3870, loss-lb:0.2659, loss-ulb:0.0606, weight:2.00, lr:0.0006
[03:22:56.183] iteration:6059  t-loss:0.2947, loss-lb:0.2307, loss-ulb:0.0320, weight:2.00, lr:0.0006
[03:22:56.533] iteration:6060  t-loss:0.8823, loss-lb:0.1836, loss-ulb:0.3493, weight:2.00, lr:0.0006
[03:22:56.863] iteration:6061  t-loss:0.4431, loss-lb:0.2025, loss-ulb:0.1203, weight:2.00, lr:0.0006
[03:22:57.200] iteration:6062  t-loss:0.9715, loss-lb:0.1729, loss-ulb:0.3993, weight:2.00, lr:0.0006
[03:22:57.522] iteration:6063  t-loss:0.9967, loss-lb:0.2366, loss-ulb:0.3800, weight:2.00, lr:0.0006
[03:22:57.843] iteration:6064  t-loss:0.3341, loss-lb:0.2251, loss-ulb:0.0545, weight:2.00, lr:0.0006
[03:22:58.173] iteration:6065  t-loss:0.7461, loss-lb:0.1859, loss-ulb:0.2801, weight:2.00, lr:0.0006
[03:22:58.497] iteration:6066  t-loss:0.2634, loss-lb:0.1813, loss-ulb:0.0411, weight:2.00, lr:0.0006
[03:22:58.813] iteration:6067  t-loss:0.2749, loss-lb:0.1713, loss-ulb:0.0518, weight:2.00, lr:0.0006
[03:22:59.136] iteration:6068  t-loss:0.6184, loss-lb:0.2782, loss-ulb:0.1701, weight:2.00, lr:0.0006
[03:22:59.452] iteration:6069  t-loss:0.2415, loss-lb:0.1562, loss-ulb:0.0426, weight:2.00, lr:0.0006
[03:22:59.768] iteration:6070  t-loss:0.3534, loss-lb:0.2315, loss-ulb:0.0610, weight:2.00, lr:0.0006
[03:23:00.083] iteration:6071  t-loss:0.3937, loss-lb:0.1982, loss-ulb:0.0978, weight:2.00, lr:0.0006
[03:23:00.400] iteration:6072  t-loss:0.6097, loss-lb:0.1755, loss-ulb:0.2171, weight:2.00, lr:0.0006
[03:23:00.715] iteration:6073  t-loss:0.7959, loss-lb:0.3704, loss-ulb:0.2127, weight:2.00, lr:0.0006
[03:23:01.030] iteration:6074  t-loss:0.9594, loss-lb:0.2185, loss-ulb:0.3704, weight:2.00, lr:0.0006
[03:23:01.341] iteration:6075  t-loss:0.4646, loss-lb:0.2595, loss-ulb:0.1026, weight:2.00, lr:0.0006
[03:23:02.437] iteration:6076  t-loss:0.5269, loss-lb:0.1741, loss-ulb:0.1764, weight:2.00, lr:0.0006
[03:23:02.769] iteration:6077  t-loss:0.2347, loss-lb:0.1606, loss-ulb:0.0370, weight:2.00, lr:0.0006
[03:23:03.109] iteration:6078  t-loss:0.5018, loss-lb:0.3084, loss-ulb:0.0967, weight:2.00, lr:0.0006
[03:23:03.432] iteration:6079  t-loss:0.3353, loss-lb:0.2368, loss-ulb:0.0493, weight:2.00, lr:0.0006
[03:23:03.746] iteration:6080  t-loss:0.5801, loss-lb:0.2311, loss-ulb:0.1745, weight:2.00, lr:0.0006
[03:23:04.065] iteration:6081  t-loss:0.4081, loss-lb:0.3644, loss-ulb:0.0218, weight:2.00, lr:0.0006
[03:23:04.386] iteration:6082  t-loss:0.3423, loss-lb:0.1931, loss-ulb:0.0746, weight:2.00, lr:0.0006
[03:23:04.712] iteration:6083  t-loss:0.2519, loss-lb:0.1964, loss-ulb:0.0277, weight:2.00, lr:0.0006
[03:23:05.055] iteration:6084  t-loss:0.5323, loss-lb:0.2214, loss-ulb:0.1554, weight:2.00, lr:0.0006
[03:23:05.386] iteration:6085  t-loss:0.5433, loss-lb:0.2232, loss-ulb:0.1601, weight:2.00, lr:0.0006
[03:23:05.727] iteration:6086  t-loss:1.0821, loss-lb:0.1187, loss-ulb:0.4817, weight:2.00, lr:0.0006
[03:23:06.061] iteration:6087  t-loss:0.3755, loss-lb:0.2120, loss-ulb:0.0818, weight:2.00, lr:0.0006
[03:23:06.377] iteration:6088  t-loss:0.2498, loss-lb:0.1928, loss-ulb:0.0285, weight:2.00, lr:0.0006
[03:23:06.696] iteration:6089  t-loss:0.4495, loss-lb:0.4193, loss-ulb:0.0151, weight:2.00, lr:0.0006
[03:23:07.018] iteration:6090  t-loss:0.4470, loss-lb:0.2313, loss-ulb:0.1079, weight:2.00, lr:0.0006
[03:23:07.343] iteration:6091  t-loss:0.2852, loss-lb:0.2477, loss-ulb:0.0187, weight:2.00, lr:0.0006
[03:23:07.660] iteration:6092  t-loss:0.8505, loss-lb:0.1964, loss-ulb:0.3271, weight:2.00, lr:0.0006
[03:23:07.977] iteration:6093  t-loss:0.6163, loss-lb:0.2187, loss-ulb:0.1988, weight:2.00, lr:0.0006
[03:23:08.295] iteration:6094  t-loss:0.3337, loss-lb:0.2011, loss-ulb:0.0663, weight:2.00, lr:0.0006
[03:23:08.607] iteration:6095  t-loss:0.3909, loss-lb:0.1575, loss-ulb:0.1167, weight:2.00, lr:0.0006
[03:23:08.925] iteration:6096  t-loss:0.3044, loss-lb:0.1468, loss-ulb:0.0788, weight:2.00, lr:0.0006
[03:23:09.243] iteration:6097  t-loss:0.5902, loss-lb:0.2675, loss-ulb:0.1614, weight:2.00, lr:0.0006
[03:23:09.557] iteration:6098  t-loss:0.4685, loss-lb:0.2260, loss-ulb:0.1212, weight:2.00, lr:0.0006
[03:23:09.875] iteration:6099  t-loss:0.4005, loss-lb:0.2550, loss-ulb:0.0728, weight:2.00, lr:0.0006
[03:23:10.191] iteration:6100  t-loss:0.4190, loss-lb:0.1874, loss-ulb:0.1158, weight:2.00, lr:0.0006
[03:23:11.435] iteration:6101  t-loss:0.5677, loss-lb:0.3012, loss-ulb:0.1333, weight:2.00, lr:0.0006
[03:23:11.761] iteration:6102  t-loss:0.2981, loss-lb:0.2393, loss-ulb:0.0294, weight:2.00, lr:0.0006
[03:23:12.078] iteration:6103  t-loss:0.3308, loss-lb:0.2334, loss-ulb:0.0487, weight:2.00, lr:0.0006
[03:23:12.403] iteration:6104  t-loss:0.3952, loss-lb:0.3001, loss-ulb:0.0476, weight:2.00, lr:0.0006
[03:23:12.722] iteration:6105  t-loss:0.5709, loss-lb:0.3720, loss-ulb:0.0995, weight:2.00, lr:0.0006
[03:23:13.041] iteration:6106  t-loss:0.3307, loss-lb:0.1706, loss-ulb:0.0800, weight:2.00, lr:0.0006
[03:23:13.360] iteration:6107  t-loss:0.7948, loss-lb:0.2220, loss-ulb:0.2864, weight:2.00, lr:0.0006
[03:23:13.678] iteration:6108  t-loss:0.2650, loss-lb:0.1524, loss-ulb:0.0563, weight:2.00, lr:0.0006
[03:23:14.003] iteration:6109  t-loss:0.2755, loss-lb:0.1488, loss-ulb:0.0633, weight:2.00, lr:0.0006
[03:23:14.323] iteration:6110  t-loss:0.3814, loss-lb:0.1679, loss-ulb:0.1067, weight:2.00, lr:0.0006
[03:23:14.641] iteration:6111  t-loss:0.4230, loss-lb:0.1690, loss-ulb:0.1270, weight:2.00, lr:0.0006
[03:23:14.964] iteration:6112  t-loss:0.5824, loss-lb:0.2374, loss-ulb:0.1725, weight:2.00, lr:0.0006
[03:23:15.282] iteration:6113  t-loss:0.3202, loss-lb:0.1587, loss-ulb:0.0807, weight:2.00, lr:0.0006
[03:23:15.604] iteration:6114  t-loss:0.3320, loss-lb:0.2757, loss-ulb:0.0281, weight:2.00, lr:0.0006
[03:23:15.924] iteration:6115  t-loss:0.2729, loss-lb:0.2399, loss-ulb:0.0165, weight:2.00, lr:0.0006
[03:23:16.250] iteration:6116  t-loss:1.5471, loss-lb:0.2242, loss-ulb:0.6615, weight:2.00, lr:0.0006
[03:23:16.571] iteration:6117  t-loss:0.5715, loss-lb:0.1762, loss-ulb:0.1977, weight:2.00, lr:0.0006
[03:23:16.890] iteration:6118  t-loss:0.3486, loss-lb:0.2839, loss-ulb:0.0323, weight:2.00, lr:0.0006
[03:23:17.207] iteration:6119  t-loss:0.5809, loss-lb:0.5206, loss-ulb:0.0301, weight:2.00, lr:0.0006
[03:23:17.525] iteration:6120  t-loss:0.5363, loss-lb:0.2005, loss-ulb:0.1679, weight:2.00, lr:0.0006
[03:23:17.844] iteration:6121  t-loss:0.3632, loss-lb:0.2994, loss-ulb:0.0319, weight:2.00, lr:0.0006
[03:23:18.158] iteration:6122  t-loss:0.2581, loss-lb:0.1988, loss-ulb:0.0296, weight:2.00, lr:0.0006
[03:23:18.478] iteration:6123  t-loss:0.6414, loss-lb:0.4183, loss-ulb:0.1115, weight:2.00, lr:0.0006
[03:23:18.794] iteration:6124  t-loss:0.3729, loss-lb:0.3127, loss-ulb:0.0301, weight:2.00, lr:0.0006
[03:23:19.111] iteration:6125  t-loss:0.5446, loss-lb:0.1644, loss-ulb:0.1901, weight:2.00, lr:0.0006
[03:25:16.647] iteration 6125 : dice_score: 0.840746 best_dice: 0.843400
[03:25:16.647]  <<Test>> - Ep:244  - Dice-S/T:81.44/84.07, Best-S:83.27, Best-T:84.34
[03:25:16.647]           - AvgLoss(lb/ulb/all):0.25/0.13/0.49
[03:25:17.803] iteration:6126  t-loss:0.2480, loss-lb:0.2028, loss-ulb:0.0226, weight:2.00, lr:0.0006
[03:25:18.131] iteration:6127  t-loss:0.6464, loss-lb:0.2694, loss-ulb:0.1885, weight:2.00, lr:0.0006
[03:25:18.458] iteration:6128  t-loss:0.6254, loss-lb:0.3879, loss-ulb:0.1188, weight:2.00, lr:0.0006
[03:25:18.772] iteration:6129  t-loss:0.2981, loss-lb:0.1588, loss-ulb:0.0696, weight:2.00, lr:0.0006
[03:25:19.085] iteration:6130  t-loss:0.3210, loss-lb:0.1795, loss-ulb:0.0708, weight:2.00, lr:0.0006
[03:25:19.399] iteration:6131  t-loss:0.2895, loss-lb:0.2241, loss-ulb:0.0327, weight:2.00, lr:0.0006
[03:25:19.713] iteration:6132  t-loss:0.2810, loss-lb:0.1770, loss-ulb:0.0520, weight:2.00, lr:0.0006
[03:25:20.029] iteration:6133  t-loss:0.4304, loss-lb:0.3671, loss-ulb:0.0316, weight:2.00, lr:0.0006
[03:25:20.343] iteration:6134  t-loss:0.2814, loss-lb:0.1602, loss-ulb:0.0606, weight:2.00, lr:0.0006
[03:25:20.658] iteration:6135  t-loss:0.4023, loss-lb:0.1708, loss-ulb:0.1158, weight:2.00, lr:0.0006
[03:25:20.970] iteration:6136  t-loss:0.6722, loss-lb:0.2504, loss-ulb:0.2109, weight:2.00, lr:0.0006
[03:25:21.290] iteration:6137  t-loss:0.7913, loss-lb:0.4566, loss-ulb:0.1674, weight:2.00, lr:0.0006
[03:25:21.611] iteration:6138  t-loss:0.4846, loss-lb:0.2123, loss-ulb:0.1361, weight:2.00, lr:0.0006
[03:25:21.929] iteration:6139  t-loss:0.6606, loss-lb:0.2915, loss-ulb:0.1845, weight:2.00, lr:0.0006
[03:25:22.251] iteration:6140  t-loss:0.5497, loss-lb:0.3440, loss-ulb:0.1028, weight:2.00, lr:0.0006
[03:25:22.573] iteration:6141  t-loss:0.9860, loss-lb:0.5145, loss-ulb:0.2358, weight:2.00, lr:0.0006
[03:25:22.893] iteration:6142  t-loss:0.2681, loss-lb:0.2075, loss-ulb:0.0303, weight:2.00, lr:0.0006
[03:25:23.210] iteration:6143  t-loss:0.4237, loss-lb:0.2824, loss-ulb:0.0706, weight:2.00, lr:0.0006
[03:25:23.535] iteration:6144  t-loss:0.5276, loss-lb:0.2745, loss-ulb:0.1266, weight:2.00, lr:0.0006
[03:25:23.851] iteration:6145  t-loss:0.4764, loss-lb:0.1843, loss-ulb:0.1461, weight:2.00, lr:0.0006
[03:25:24.166] iteration:6146  t-loss:0.3236, loss-lb:0.2363, loss-ulb:0.0437, weight:2.00, lr:0.0006
[03:25:24.480] iteration:6147  t-loss:0.4103, loss-lb:0.1869, loss-ulb:0.1117, weight:2.00, lr:0.0006
[03:25:24.798] iteration:6148  t-loss:0.5583, loss-lb:0.2147, loss-ulb:0.1718, weight:2.00, lr:0.0006
[03:25:25.114] iteration:6149  t-loss:1.2761, loss-lb:0.1829, loss-ulb:0.5466, weight:2.00, lr:0.0006
[03:25:25.436] iteration:6150  t-loss:0.8297, loss-lb:0.3632, loss-ulb:0.2332, weight:2.00, lr:0.0006
[03:25:26.670] iteration:6151  t-loss:0.4458, loss-lb:0.2341, loss-ulb:0.1058, weight:2.00, lr:0.0006
[03:25:26.995] iteration:6152  t-loss:0.7862, loss-lb:0.2749, loss-ulb:0.2557, weight:2.00, lr:0.0006
[03:25:27.321] iteration:6153  t-loss:0.3401, loss-lb:0.2763, loss-ulb:0.0319, weight:2.00, lr:0.0006
[03:25:27.642] iteration:6154  t-loss:0.2982, loss-lb:0.2225, loss-ulb:0.0378, weight:2.00, lr:0.0006
[03:25:27.959] iteration:6155  t-loss:0.2794, loss-lb:0.1551, loss-ulb:0.0621, weight:2.00, lr:0.0006
[03:25:28.278] iteration:6156  t-loss:0.5276, loss-lb:0.2000, loss-ulb:0.1638, weight:2.00, lr:0.0006
[03:25:28.601] iteration:6157  t-loss:0.4103, loss-lb:0.2741, loss-ulb:0.0681, weight:2.00, lr:0.0006
[03:25:28.919] iteration:6158  t-loss:0.2980, loss-lb:0.2104, loss-ulb:0.0438, weight:2.00, lr:0.0006
[03:25:29.236] iteration:6159  t-loss:0.6407, loss-lb:0.2262, loss-ulb:0.2072, weight:2.00, lr:0.0006
[03:25:29.556] iteration:6160  t-loss:0.7107, loss-lb:0.5348, loss-ulb:0.0879, weight:2.00, lr:0.0006
[03:25:29.877] iteration:6161  t-loss:0.4199, loss-lb:0.1665, loss-ulb:0.1267, weight:2.00, lr:0.0006
[03:25:30.201] iteration:6162  t-loss:0.4009, loss-lb:0.3245, loss-ulb:0.0382, weight:2.00, lr:0.0006
[03:25:30.529] iteration:6163  t-loss:0.7244, loss-lb:0.3471, loss-ulb:0.1887, weight:2.00, lr:0.0006
[03:25:30.856] iteration:6164  t-loss:0.4655, loss-lb:0.2284, loss-ulb:0.1185, weight:2.00, lr:0.0006
[03:25:31.176] iteration:6165  t-loss:0.2389, loss-lb:0.1605, loss-ulb:0.0392, weight:2.00, lr:0.0006
[03:25:31.500] iteration:6166  t-loss:0.5953, loss-lb:0.1605, loss-ulb:0.2174, weight:2.00, lr:0.0006
[03:25:31.816] iteration:6167  t-loss:0.2596, loss-lb:0.1621, loss-ulb:0.0488, weight:2.00, lr:0.0006
[03:25:32.135] iteration:6168  t-loss:0.9637, loss-lb:0.2718, loss-ulb:0.3460, weight:2.00, lr:0.0006
[03:25:32.451] iteration:6169  t-loss:0.3856, loss-lb:0.1551, loss-ulb:0.1153, weight:2.00, lr:0.0006
[03:25:32.768] iteration:6170  t-loss:0.3742, loss-lb:0.2133, loss-ulb:0.0804, weight:2.00, lr:0.0006
[03:25:33.082] iteration:6171  t-loss:0.3048, loss-lb:0.1612, loss-ulb:0.0718, weight:2.00, lr:0.0006
[03:25:33.400] iteration:6172  t-loss:0.6364, loss-lb:0.3408, loss-ulb:0.1478, weight:2.00, lr:0.0006
[03:25:33.720] iteration:6173  t-loss:0.2537, loss-lb:0.1873, loss-ulb:0.0332, weight:2.00, lr:0.0006
[03:25:34.035] iteration:6174  t-loss:0.6836, loss-lb:0.6252, loss-ulb:0.0292, weight:2.00, lr:0.0006
[03:25:34.351] iteration:6175  t-loss:0.3427, loss-lb:0.2255, loss-ulb:0.0586, weight:2.00, lr:0.0006
[03:25:35.752] iteration:6176  t-loss:0.3738, loss-lb:0.1793, loss-ulb:0.0973, weight:2.00, lr:0.0006
[03:25:36.092] iteration:6177  t-loss:0.4559, loss-lb:0.2036, loss-ulb:0.1262, weight:2.00, lr:0.0006
[03:25:36.426] iteration:6178  t-loss:0.3899, loss-lb:0.1672, loss-ulb:0.1113, weight:2.00, lr:0.0006
[03:25:36.748] iteration:6179  t-loss:0.3396, loss-lb:0.2334, loss-ulb:0.0531, weight:2.00, lr:0.0006
[03:25:37.069] iteration:6180  t-loss:0.2931, loss-lb:0.1691, loss-ulb:0.0620, weight:2.00, lr:0.0006
[03:25:37.397] iteration:6181  t-loss:0.3363, loss-lb:0.2739, loss-ulb:0.0312, weight:2.00, lr:0.0006
[03:25:37.727] iteration:6182  t-loss:0.5113, loss-lb:0.2850, loss-ulb:0.1131, weight:2.00, lr:0.0006
[03:25:38.042] iteration:6183  t-loss:0.3439, loss-lb:0.1578, loss-ulb:0.0930, weight:2.00, lr:0.0006
[03:25:38.360] iteration:6184  t-loss:0.4318, loss-lb:0.2646, loss-ulb:0.0836, weight:2.00, lr:0.0006
[03:25:38.681] iteration:6185  t-loss:0.4683, loss-lb:0.2568, loss-ulb:0.1057, weight:2.00, lr:0.0006
[03:25:39.006] iteration:6186  t-loss:0.4073, loss-lb:0.2369, loss-ulb:0.0852, weight:2.00, lr:0.0006
[03:25:39.342] iteration:6187  t-loss:0.4277, loss-lb:0.1491, loss-ulb:0.1393, weight:2.00, lr:0.0006
[03:25:39.664] iteration:6188  t-loss:0.2002, loss-lb:0.1551, loss-ulb:0.0225, weight:2.00, lr:0.0006
[03:25:39.982] iteration:6189  t-loss:0.1792, loss-lb:0.1244, loss-ulb:0.0274, weight:2.00, lr:0.0006
[03:25:40.301] iteration:6190  t-loss:0.1928, loss-lb:0.1538, loss-ulb:0.0195, weight:2.00, lr:0.0006
[03:25:40.628] iteration:6191  t-loss:0.3994, loss-lb:0.3484, loss-ulb:0.0255, weight:2.00, lr:0.0006
[03:25:40.949] iteration:6192  t-loss:1.9884, loss-lb:0.3551, loss-ulb:0.8166, weight:2.00, lr:0.0006
[03:25:41.267] iteration:6193  t-loss:0.3734, loss-lb:0.2529, loss-ulb:0.0602, weight:2.00, lr:0.0006
[03:25:41.584] iteration:6194  t-loss:0.3166, loss-lb:0.1782, loss-ulb:0.0692, weight:2.00, lr:0.0006
[03:25:41.898] iteration:6195  t-loss:0.2902, loss-lb:0.2496, loss-ulb:0.0203, weight:2.00, lr:0.0006
[03:25:42.214] iteration:6196  t-loss:0.4533, loss-lb:0.2941, loss-ulb:0.0796, weight:2.00, lr:0.0006
[03:25:42.536] iteration:6197  t-loss:0.5865, loss-lb:0.2957, loss-ulb:0.1454, weight:2.00, lr:0.0006
[03:25:42.850] iteration:6198  t-loss:0.5445, loss-lb:0.3500, loss-ulb:0.0972, weight:2.00, lr:0.0006
[03:25:43.167] iteration:6199  t-loss:0.3025, loss-lb:0.1995, loss-ulb:0.0515, weight:2.00, lr:0.0006
[03:25:43.485] iteration:6200  t-loss:0.4039, loss-lb:0.1757, loss-ulb:0.1141, weight:2.00, lr:0.0006
[03:25:44.815] iteration:6201  t-loss:0.3276, loss-lb:0.2684, loss-ulb:0.0296, weight:2.00, lr:0.0006
[03:25:45.153] iteration:6202  t-loss:0.5458, loss-lb:0.3594, loss-ulb:0.0932, weight:2.00, lr:0.0006
[03:25:45.474] iteration:6203  t-loss:0.3458, loss-lb:0.1795, loss-ulb:0.0831, weight:2.00, lr:0.0006
[03:25:45.788] iteration:6204  t-loss:0.1652, loss-lb:0.1291, loss-ulb:0.0180, weight:2.00, lr:0.0006
[03:25:46.103] iteration:6205  t-loss:0.2578, loss-lb:0.1402, loss-ulb:0.0588, weight:2.00, lr:0.0006
[03:25:46.423] iteration:6206  t-loss:1.0309, loss-lb:0.3307, loss-ulb:0.3501, weight:2.00, lr:0.0006
[03:25:46.736] iteration:6207  t-loss:0.2708, loss-lb:0.2184, loss-ulb:0.0262, weight:2.00, lr:0.0006
[03:25:47.051] iteration:6208  t-loss:0.4126, loss-lb:0.1533, loss-ulb:0.1297, weight:2.00, lr:0.0006
[03:25:47.371] iteration:6209  t-loss:0.2679, loss-lb:0.1847, loss-ulb:0.0416, weight:2.00, lr:0.0006
[03:25:47.688] iteration:6210  t-loss:0.4531, loss-lb:0.1906, loss-ulb:0.1312, weight:2.00, lr:0.0006
[03:25:48.006] iteration:6211  t-loss:0.3411, loss-lb:0.2314, loss-ulb:0.0548, weight:2.00, lr:0.0006
[03:25:48.332] iteration:6212  t-loss:0.4954, loss-lb:0.2900, loss-ulb:0.1027, weight:2.00, lr:0.0006
[03:25:48.655] iteration:6213  t-loss:0.5286, loss-lb:0.2951, loss-ulb:0.1167, weight:2.00, lr:0.0006
[03:25:48.971] iteration:6214  t-loss:1.0964, loss-lb:0.4805, loss-ulb:0.3079, weight:2.00, lr:0.0006
[03:25:49.294] iteration:6215  t-loss:0.3545, loss-lb:0.1438, loss-ulb:0.1054, weight:2.00, lr:0.0006
[03:25:49.622] iteration:6216  t-loss:0.5209, loss-lb:0.2238, loss-ulb:0.1485, weight:2.00, lr:0.0006
[03:25:49.949] iteration:6217  t-loss:0.4922, loss-lb:0.3422, loss-ulb:0.0750, weight:2.00, lr:0.0006
[03:25:50.273] iteration:6218  t-loss:0.3375, loss-lb:0.2866, loss-ulb:0.0254, weight:2.00, lr:0.0006
[03:25:50.595] iteration:6219  t-loss:0.6721, loss-lb:0.4233, loss-ulb:0.1244, weight:2.00, lr:0.0006
[03:25:50.917] iteration:6220  t-loss:0.4371, loss-lb:0.2255, loss-ulb:0.1058, weight:2.00, lr:0.0006
[03:25:51.233] iteration:6221  t-loss:0.8409, loss-lb:0.1825, loss-ulb:0.3292, weight:2.00, lr:0.0006
[03:25:51.553] iteration:6222  t-loss:0.3778, loss-lb:0.1941, loss-ulb:0.0918, weight:2.00, lr:0.0006
[03:25:51.873] iteration:6223  t-loss:0.5410, loss-lb:0.2521, loss-ulb:0.1445, weight:2.00, lr:0.0006
[03:25:52.192] iteration:6224  t-loss:0.4504, loss-lb:0.3131, loss-ulb:0.0687, weight:2.00, lr:0.0006
[03:25:52.515] iteration:6225  t-loss:0.3927, loss-lb:0.3395, loss-ulb:0.0266, weight:2.00, lr:0.0006
[03:27:49.549] iteration 6225 : dice_score: 0.843894 best_dice: 0.843900
[03:27:49.550]  <<Test>> - Ep:248  - Dice-S/T:83.18/84.39, Best-S:83.27, Best-T:84.39
[03:27:49.550]           - AvgLoss(lb/ulb/all):0.26/0.13/0.52
[03:27:50.674] iteration:6226  t-loss:0.5504, loss-lb:0.3620, loss-ulb:0.0942, weight:2.00, lr:0.0006
[03:27:51.005] iteration:6227  t-loss:0.5916, loss-lb:0.2294, loss-ulb:0.1811, weight:2.00, lr:0.0006
[03:27:51.324] iteration:6228  t-loss:0.3682, loss-lb:0.1408, loss-ulb:0.1137, weight:2.00, lr:0.0006
[03:27:51.639] iteration:6229  t-loss:0.5288, loss-lb:0.1591, loss-ulb:0.1848, weight:2.00, lr:0.0006
[03:27:51.954] iteration:6230  t-loss:0.2538, loss-lb:0.2098, loss-ulb:0.0220, weight:2.00, lr:0.0006
[03:27:52.268] iteration:6231  t-loss:0.6859, loss-lb:0.1568, loss-ulb:0.2646, weight:2.00, lr:0.0006
[03:27:52.584] iteration:6232  t-loss:0.4882, loss-lb:0.1879, loss-ulb:0.1502, weight:2.00, lr:0.0006
[03:27:52.897] iteration:6233  t-loss:0.4310, loss-lb:0.1905, loss-ulb:0.1203, weight:2.00, lr:0.0006
[03:27:53.211] iteration:6234  t-loss:0.2820, loss-lb:0.2203, loss-ulb:0.0308, weight:2.00, lr:0.0006
[03:27:53.527] iteration:6235  t-loss:0.3483, loss-lb:0.2038, loss-ulb:0.0722, weight:2.00, lr:0.0006
[03:27:53.843] iteration:6236  t-loss:0.4680, loss-lb:0.3632, loss-ulb:0.0524, weight:2.00, lr:0.0006
[03:27:54.159] iteration:6237  t-loss:0.3131, loss-lb:0.1856, loss-ulb:0.0637, weight:2.00, lr:0.0006
[03:27:54.478] iteration:6238  t-loss:0.6361, loss-lb:0.1594, loss-ulb:0.2384, weight:2.00, lr:0.0006
[03:27:54.797] iteration:6239  t-loss:0.7652, loss-lb:0.1820, loss-ulb:0.2916, weight:2.00, lr:0.0006
[03:27:55.111] iteration:6240  t-loss:0.5565, loss-lb:0.2018, loss-ulb:0.1773, weight:2.00, lr:0.0006
[03:27:55.423] iteration:6241  t-loss:0.2247, loss-lb:0.1767, loss-ulb:0.0240, weight:2.00, lr:0.0006
[03:27:55.741] iteration:6242  t-loss:0.7312, loss-lb:0.1946, loss-ulb:0.2683, weight:2.00, lr:0.0006
[03:27:56.056] iteration:6243  t-loss:0.6263, loss-lb:0.1365, loss-ulb:0.2449, weight:2.00, lr:0.0006
[03:27:56.369] iteration:6244  t-loss:0.4491, loss-lb:0.3955, loss-ulb:0.0268, weight:2.00, lr:0.0006
[03:27:56.680] iteration:6245  t-loss:0.3774, loss-lb:0.1852, loss-ulb:0.0961, weight:2.00, lr:0.0006
[03:27:56.995] iteration:6246  t-loss:0.4260, loss-lb:0.2710, loss-ulb:0.0775, weight:2.00, lr:0.0006
[03:27:57.309] iteration:6247  t-loss:0.8506, loss-lb:0.2962, loss-ulb:0.2772, weight:2.00, lr:0.0006
[03:27:57.622] iteration:6248  t-loss:0.6914, loss-lb:0.1510, loss-ulb:0.2702, weight:2.00, lr:0.0006
[03:27:57.937] iteration:6249  t-loss:0.6056, loss-lb:0.1995, loss-ulb:0.2031, weight:2.00, lr:0.0006
[03:27:58.255] iteration:6250  t-loss:0.5957, loss-lb:0.3212, loss-ulb:0.1373, weight:2.00, lr:0.0006
[03:27:59.663] iteration:6251  t-loss:0.4098, loss-lb:0.2152, loss-ulb:0.0973, weight:2.00, lr:0.0006
[03:27:59.999] iteration:6252  t-loss:0.5529, loss-lb:0.3065, loss-ulb:0.1232, weight:2.00, lr:0.0006
[03:28:00.317] iteration:6253  t-loss:0.4863, loss-lb:0.2471, loss-ulb:0.1196, weight:2.00, lr:0.0006
[03:28:00.637] iteration:6254  t-loss:0.5668, loss-lb:0.2833, loss-ulb:0.1418, weight:2.00, lr:0.0006
[03:28:00.957] iteration:6255  t-loss:0.5696, loss-lb:0.2604, loss-ulb:0.1546, weight:2.00, lr:0.0006
[03:28:01.277] iteration:6256  t-loss:0.5767, loss-lb:0.3603, loss-ulb:0.1082, weight:2.00, lr:0.0006
[03:28:01.598] iteration:6257  t-loss:0.5564, loss-lb:0.3474, loss-ulb:0.1045, weight:2.00, lr:0.0006
[03:28:01.917] iteration:6258  t-loss:0.4114, loss-lb:0.2587, loss-ulb:0.0763, weight:2.00, lr:0.0006
[03:28:02.236] iteration:6259  t-loss:0.4961, loss-lb:0.4375, loss-ulb:0.0293, weight:2.00, lr:0.0006
[03:28:02.557] iteration:6260  t-loss:0.5892, loss-lb:0.1826, loss-ulb:0.2033, weight:2.00, lr:0.0006
[03:28:02.872] iteration:6261  t-loss:0.4283, loss-lb:0.2145, loss-ulb:0.1069, weight:2.00, lr:0.0006
[03:28:03.191] iteration:6262  t-loss:0.4335, loss-lb:0.2232, loss-ulb:0.1052, weight:2.00, lr:0.0006
[03:28:03.510] iteration:6263  t-loss:0.4887, loss-lb:0.1655, loss-ulb:0.1616, weight:2.00, lr:0.0006
[03:28:03.829] iteration:6264  t-loss:0.3905, loss-lb:0.1851, loss-ulb:0.1027, weight:2.00, lr:0.0006
[03:28:04.147] iteration:6265  t-loss:0.5813, loss-lb:0.2956, loss-ulb:0.1428, weight:2.00, lr:0.0006
[03:28:04.464] iteration:6266  t-loss:0.4853, loss-lb:0.2011, loss-ulb:0.1421, weight:2.00, lr:0.0006
[03:28:04.782] iteration:6267  t-loss:0.6809, loss-lb:0.2760, loss-ulb:0.2025, weight:2.00, lr:0.0006
[03:28:05.097] iteration:6268  t-loss:0.3089, loss-lb:0.2487, loss-ulb:0.0301, weight:2.00, lr:0.0006
[03:28:05.414] iteration:6269  t-loss:0.5160, loss-lb:0.3416, loss-ulb:0.0872, weight:2.00, lr:0.0006
[03:28:05.730] iteration:6270  t-loss:0.5462, loss-lb:0.2388, loss-ulb:0.1537, weight:2.00, lr:0.0006
[03:28:06.045] iteration:6271  t-loss:0.5814, loss-lb:0.5163, loss-ulb:0.0326, weight:2.00, lr:0.0006
[03:28:06.358] iteration:6272  t-loss:0.7427, loss-lb:0.6562, loss-ulb:0.0432, weight:2.00, lr:0.0006
[03:28:06.671] iteration:6273  t-loss:0.2400, loss-lb:0.1820, loss-ulb:0.0290, weight:2.00, lr:0.0006
[03:28:06.986] iteration:6274  t-loss:0.4265, loss-lb:0.2412, loss-ulb:0.0926, weight:2.00, lr:0.0006
[03:28:07.299] iteration:6275  t-loss:0.4890, loss-lb:0.2777, loss-ulb:0.1057, weight:2.00, lr:0.0006
[03:28:08.492] iteration:6276  t-loss:0.3191, loss-lb:0.2591, loss-ulb:0.0300, weight:2.00, lr:0.0006
[03:28:08.821] iteration:6277  t-loss:0.8286, loss-lb:0.1811, loss-ulb:0.3238, weight:2.00, lr:0.0006
[03:28:09.140] iteration:6278  t-loss:0.2580, loss-lb:0.1914, loss-ulb:0.0333, weight:2.00, lr:0.0006
[03:28:09.459] iteration:6279  t-loss:0.4102, loss-lb:0.3133, loss-ulb:0.0484, weight:2.00, lr:0.0006
[03:28:09.775] iteration:6280  t-loss:0.2929, loss-lb:0.1860, loss-ulb:0.0535, weight:2.00, lr:0.0006
[03:28:10.094] iteration:6281  t-loss:0.4259, loss-lb:0.2178, loss-ulb:0.1041, weight:2.00, lr:0.0006
[03:28:10.412] iteration:6282  t-loss:0.2510, loss-lb:0.1931, loss-ulb:0.0289, weight:2.00, lr:0.0006
[03:28:10.728] iteration:6283  t-loss:0.5477, loss-lb:0.1652, loss-ulb:0.1912, weight:2.00, lr:0.0006
[03:28:11.050] iteration:6284  t-loss:0.7417, loss-lb:0.3791, loss-ulb:0.1813, weight:2.00, lr:0.0006
[03:28:11.369] iteration:6285  t-loss:0.3538, loss-lb:0.3148, loss-ulb:0.0195, weight:2.00, lr:0.0006
[03:28:11.686] iteration:6286  t-loss:0.2808, loss-lb:0.1613, loss-ulb:0.0598, weight:2.00, lr:0.0006
[03:28:12.003] iteration:6287  t-loss:0.5100, loss-lb:0.2963, loss-ulb:0.1068, weight:2.00, lr:0.0006
[03:28:12.319] iteration:6288  t-loss:0.3451, loss-lb:0.2367, loss-ulb:0.0542, weight:2.00, lr:0.0006
[03:28:12.636] iteration:6289  t-loss:0.3818, loss-lb:0.2051, loss-ulb:0.0883, weight:2.00, lr:0.0006
[03:28:12.950] iteration:6290  t-loss:0.2469, loss-lb:0.1912, loss-ulb:0.0279, weight:2.00, lr:0.0006
[03:28:13.267] iteration:6291  t-loss:0.5349, loss-lb:0.1976, loss-ulb:0.1687, weight:2.00, lr:0.0006
[03:28:13.583] iteration:6292  t-loss:0.2288, loss-lb:0.1641, loss-ulb:0.0324, weight:2.00, lr:0.0006
[03:28:13.897] iteration:6293  t-loss:0.3738, loss-lb:0.2725, loss-ulb:0.0507, weight:2.00, lr:0.0006
[03:28:14.213] iteration:6294  t-loss:0.5347, loss-lb:0.1896, loss-ulb:0.1725, weight:2.00, lr:0.0006
[03:28:14.524] iteration:6295  t-loss:0.2442, loss-lb:0.1735, loss-ulb:0.0353, weight:2.00, lr:0.0006
[03:28:14.839] iteration:6296  t-loss:0.2843, loss-lb:0.2332, loss-ulb:0.0255, weight:2.00, lr:0.0006
[03:28:15.154] iteration:6297  t-loss:0.5317, loss-lb:0.2841, loss-ulb:0.1238, weight:2.00, lr:0.0006
[03:28:15.469] iteration:6298  t-loss:0.2833, loss-lb:0.1279, loss-ulb:0.0777, weight:2.00, lr:0.0006
[03:28:15.782] iteration:6299  t-loss:0.2964, loss-lb:0.2580, loss-ulb:0.0192, weight:2.00, lr:0.0006
[03:28:16.096] iteration:6300  t-loss:0.4356, loss-lb:0.3303, loss-ulb:0.0527, weight:2.00, lr:0.0006
[03:28:17.354] iteration:6301  t-loss:0.9002, loss-lb:0.4328, loss-ulb:0.2337, weight:2.00, lr:0.0006
[03:28:17.691] iteration:6302  t-loss:0.3831, loss-lb:0.3015, loss-ulb:0.0408, weight:2.00, lr:0.0006
[03:28:18.024] iteration:6303  t-loss:0.4241, loss-lb:0.2791, loss-ulb:0.0725, weight:2.00, lr:0.0006
[03:28:18.345] iteration:6304  t-loss:0.3072, loss-lb:0.1675, loss-ulb:0.0698, weight:2.00, lr:0.0006
[03:28:18.662] iteration:6305  t-loss:0.2840, loss-lb:0.1785, loss-ulb:0.0528, weight:2.00, lr:0.0006
[03:28:18.977] iteration:6306  t-loss:0.2594, loss-lb:0.2106, loss-ulb:0.0244, weight:2.00, lr:0.0006
[03:28:19.294] iteration:6307  t-loss:0.2970, loss-lb:0.2374, loss-ulb:0.0298, weight:2.00, lr:0.0006
[03:28:19.616] iteration:6308  t-loss:0.3305, loss-lb:0.2811, loss-ulb:0.0247, weight:2.00, lr:0.0006
[03:28:19.932] iteration:6309  t-loss:0.3687, loss-lb:0.2002, loss-ulb:0.0842, weight:2.00, lr:0.0006
[03:28:20.254] iteration:6310  t-loss:1.0507, loss-lb:0.4373, loss-ulb:0.3067, weight:2.00, lr:0.0006
[03:28:20.576] iteration:6311  t-loss:0.5445, loss-lb:0.3014, loss-ulb:0.1216, weight:2.00, lr:0.0006
[03:28:20.896] iteration:6312  t-loss:0.5084, loss-lb:0.1678, loss-ulb:0.1703, weight:2.00, lr:0.0006
[03:28:21.212] iteration:6313  t-loss:0.2779, loss-lb:0.2278, loss-ulb:0.0251, weight:2.00, lr:0.0006
[03:28:21.529] iteration:6314  t-loss:0.3245, loss-lb:0.2477, loss-ulb:0.0384, weight:2.00, lr:0.0006
[03:28:21.845] iteration:6315  t-loss:0.1967, loss-lb:0.1174, loss-ulb:0.0396, weight:2.00, lr:0.0006
[03:28:22.165] iteration:6316  t-loss:0.2845, loss-lb:0.2473, loss-ulb:0.0186, weight:2.00, lr:0.0006
[03:28:22.486] iteration:6317  t-loss:0.4477, loss-lb:0.2838, loss-ulb:0.0820, weight:2.00, lr:0.0006
[03:28:22.804] iteration:6318  t-loss:0.4185, loss-lb:0.2308, loss-ulb:0.0938, weight:2.00, lr:0.0006
[03:28:23.123] iteration:6319  t-loss:0.5463, loss-lb:0.2392, loss-ulb:0.1536, weight:2.00, lr:0.0006
[03:28:23.442] iteration:6320  t-loss:0.4020, loss-lb:0.3218, loss-ulb:0.0401, weight:2.00, lr:0.0006
[03:28:23.749] iteration:6321  t-loss:0.3359, loss-lb:0.1766, loss-ulb:0.0797, weight:2.00, lr:0.0006
[03:28:24.063] iteration:6322  t-loss:0.2634, loss-lb:0.1766, loss-ulb:0.0434, weight:2.00, lr:0.0006
[03:28:24.378] iteration:6323  t-loss:0.3594, loss-lb:0.1429, loss-ulb:0.1082, weight:2.00, lr:0.0006
[03:28:24.694] iteration:6324  t-loss:0.7008, loss-lb:0.3764, loss-ulb:0.1622, weight:2.00, lr:0.0006
[03:28:25.009] iteration:6325  t-loss:0.4672, loss-lb:0.2771, loss-ulb:0.0950, weight:2.00, lr:0.0006
[03:30:23.243] iteration 6325 : dice_score: 0.841300 best_dice: 0.843900
[03:30:23.243]  <<Test>> - Ep:252  - Dice-S/T:82.79/84.13, Best-S:83.27, Best-T:84.39
[03:30:23.243]           - AvgLoss(lb/ulb/all):0.25/0.09/0.42
[03:30:24.334] iteration:6326  t-loss:0.5529, loss-lb:0.5086, loss-ulb:0.0222, weight:2.00, lr:0.0006
[03:30:24.668] iteration:6327  t-loss:0.3826, loss-lb:0.1935, loss-ulb:0.0945, weight:2.00, lr:0.0006
[03:30:24.996] iteration:6328  t-loss:0.6062, loss-lb:0.3565, loss-ulb:0.1249, weight:2.00, lr:0.0006
[03:30:25.314] iteration:6329  t-loss:0.3810, loss-lb:0.1748, loss-ulb:0.1031, weight:2.00, lr:0.0006
[03:30:25.631] iteration:6330  t-loss:0.5688, loss-lb:0.3632, loss-ulb:0.1028, weight:2.00, lr:0.0006
[03:30:25.949] iteration:6331  t-loss:0.2027, loss-lb:0.1524, loss-ulb:0.0251, weight:2.00, lr:0.0006
[03:30:26.268] iteration:6332  t-loss:0.2312, loss-lb:0.1928, loss-ulb:0.0192, weight:2.00, lr:0.0006
[03:30:26.585] iteration:6333  t-loss:0.4394, loss-lb:0.1278, loss-ulb:0.1558, weight:2.00, lr:0.0006
[03:30:26.900] iteration:6334  t-loss:0.3549, loss-lb:0.1673, loss-ulb:0.0938, weight:2.00, lr:0.0006
[03:30:27.220] iteration:6335  t-loss:0.6919, loss-lb:0.2864, loss-ulb:0.2027, weight:2.00, lr:0.0006
[03:30:27.538] iteration:6336  t-loss:0.5164, loss-lb:0.2798, loss-ulb:0.1183, weight:2.00, lr:0.0006
[03:30:27.857] iteration:6337  t-loss:0.3578, loss-lb:0.3092, loss-ulb:0.0243, weight:2.00, lr:0.0006
[03:30:28.174] iteration:6338  t-loss:0.6919, loss-lb:0.1843, loss-ulb:0.2538, weight:2.00, lr:0.0006
[03:30:28.489] iteration:6339  t-loss:0.2412, loss-lb:0.1868, loss-ulb:0.0272, weight:2.00, lr:0.0006
[03:30:28.807] iteration:6340  t-loss:0.5038, loss-lb:0.1476, loss-ulb:0.1781, weight:2.00, lr:0.0006
[03:30:29.123] iteration:6341  t-loss:0.3565, loss-lb:0.2225, loss-ulb:0.0670, weight:2.00, lr:0.0006
[03:30:29.441] iteration:6342  t-loss:0.3094, loss-lb:0.2397, loss-ulb:0.0348, weight:2.00, lr:0.0006
[03:30:29.753] iteration:6343  t-loss:0.2047, loss-lb:0.1594, loss-ulb:0.0226, weight:2.00, lr:0.0006
[03:30:30.070] iteration:6344  t-loss:0.4064, loss-lb:0.2592, loss-ulb:0.0736, weight:2.00, lr:0.0006
[03:30:30.384] iteration:6345  t-loss:0.3222, loss-lb:0.2281, loss-ulb:0.0470, weight:2.00, lr:0.0006
[03:30:30.704] iteration:6346  t-loss:0.5434, loss-lb:0.3601, loss-ulb:0.0916, weight:2.00, lr:0.0006
[03:30:31.020] iteration:6347  t-loss:0.6405, loss-lb:0.2948, loss-ulb:0.1729, weight:2.00, lr:0.0006
[03:30:31.335] iteration:6348  t-loss:0.6299, loss-lb:0.1623, loss-ulb:0.2338, weight:2.00, lr:0.0006
[03:30:31.663] iteration:6349  t-loss:0.3453, loss-lb:0.1515, loss-ulb:0.0969, weight:2.00, lr:0.0006
[03:30:31.980] iteration:6350  t-loss:0.2923, loss-lb:0.1790, loss-ulb:0.0567, weight:2.00, lr:0.0006
[03:30:33.159] iteration:6351  t-loss:0.4630, loss-lb:0.2368, loss-ulb:0.1131, weight:2.00, lr:0.0006
[03:30:33.494] iteration:6352  t-loss:0.5108, loss-lb:0.1846, loss-ulb:0.1631, weight:2.00, lr:0.0006
[03:30:33.826] iteration:6353  t-loss:0.4608, loss-lb:0.2043, loss-ulb:0.1282, weight:2.00, lr:0.0006
[03:30:34.151] iteration:6354  t-loss:0.5175, loss-lb:0.2493, loss-ulb:0.1341, weight:2.00, lr:0.0006
[03:30:34.468] iteration:6355  t-loss:0.2972, loss-lb:0.1916, loss-ulb:0.0528, weight:2.00, lr:0.0006
[03:30:34.786] iteration:6356  t-loss:0.5050, loss-lb:0.1814, loss-ulb:0.1618, weight:2.00, lr:0.0006
[03:30:35.105] iteration:6357  t-loss:0.4897, loss-lb:0.1968, loss-ulb:0.1464, weight:2.00, lr:0.0006
[03:30:35.421] iteration:6358  t-loss:0.4911, loss-lb:0.1896, loss-ulb:0.1507, weight:2.00, lr:0.0006
[03:30:35.742] iteration:6359  t-loss:0.4372, loss-lb:0.1637, loss-ulb:0.1368, weight:2.00, lr:0.0006
[03:30:36.061] iteration:6360  t-loss:0.8393, loss-lb:0.2019, loss-ulb:0.3187, weight:2.00, lr:0.0006
[03:30:36.383] iteration:6361  t-loss:0.3460, loss-lb:0.1724, loss-ulb:0.0868, weight:2.00, lr:0.0006
[03:30:36.701] iteration:6362  t-loss:0.3748, loss-lb:0.2488, loss-ulb:0.0630, weight:2.00, lr:0.0006
[03:30:37.018] iteration:6363  t-loss:0.5464, loss-lb:0.1450, loss-ulb:0.2007, weight:2.00, lr:0.0006
[03:30:37.334] iteration:6364  t-loss:0.2644, loss-lb:0.1492, loss-ulb:0.0576, weight:2.00, lr:0.0006
[03:30:37.654] iteration:6365  t-loss:0.4692, loss-lb:0.3012, loss-ulb:0.0840, weight:2.00, lr:0.0006
[03:30:37.972] iteration:6366  t-loss:0.4959, loss-lb:0.2041, loss-ulb:0.1459, weight:2.00, lr:0.0006
[03:30:38.291] iteration:6367  t-loss:0.3220, loss-lb:0.2382, loss-ulb:0.0419, weight:2.00, lr:0.0006
[03:30:38.606] iteration:6368  t-loss:0.4718, loss-lb:0.1674, loss-ulb:0.1522, weight:2.00, lr:0.0006
[03:30:38.919] iteration:6369  t-loss:0.2729, loss-lb:0.1960, loss-ulb:0.0385, weight:2.00, lr:0.0006
[03:30:39.233] iteration:6370  t-loss:0.4968, loss-lb:0.1709, loss-ulb:0.1630, weight:2.00, lr:0.0006
[03:30:39.548] iteration:6371  t-loss:0.2267, loss-lb:0.1597, loss-ulb:0.0335, weight:2.00, lr:0.0006
[03:30:39.860] iteration:6372  t-loss:0.4823, loss-lb:0.2027, loss-ulb:0.1398, weight:2.00, lr:0.0006
[03:30:40.178] iteration:6373  t-loss:0.4785, loss-lb:0.2632, loss-ulb:0.1076, weight:2.00, lr:0.0006
[03:30:40.491] iteration:6374  t-loss:0.2900, loss-lb:0.2141, loss-ulb:0.0380, weight:2.00, lr:0.0006
[03:30:40.807] iteration:6375  t-loss:0.5360, loss-lb:0.1963, loss-ulb:0.1699, weight:2.00, lr:0.0006
[03:30:42.056] iteration:6376  t-loss:0.6318, loss-lb:0.3088, loss-ulb:0.1615, weight:2.00, lr:0.0006
[03:30:42.388] iteration:6377  t-loss:0.2417, loss-lb:0.2100, loss-ulb:0.0158, weight:2.00, lr:0.0006
[03:30:42.712] iteration:6378  t-loss:0.3434, loss-lb:0.2953, loss-ulb:0.0240, weight:2.00, lr:0.0006
[03:30:43.032] iteration:6379  t-loss:0.9815, loss-lb:0.3653, loss-ulb:0.3081, weight:2.00, lr:0.0006
[03:30:43.351] iteration:6380  t-loss:0.3021, loss-lb:0.1453, loss-ulb:0.0784, weight:2.00, lr:0.0006
[03:30:43.668] iteration:6381  t-loss:0.5076, loss-lb:0.1641, loss-ulb:0.1717, weight:2.00, lr:0.0006
[03:30:43.988] iteration:6382  t-loss:0.4040, loss-lb:0.2616, loss-ulb:0.0712, weight:2.00, lr:0.0006
[03:30:44.307] iteration:6383  t-loss:0.4075, loss-lb:0.2635, loss-ulb:0.0720, weight:2.00, lr:0.0006
[03:30:44.624] iteration:6384  t-loss:0.4154, loss-lb:0.3769, loss-ulb:0.0192, weight:2.00, lr:0.0006
[03:30:44.940] iteration:6385  t-loss:0.5699, loss-lb:0.1945, loss-ulb:0.1877, weight:2.00, lr:0.0006
[03:30:45.256] iteration:6386  t-loss:0.3165, loss-lb:0.2592, loss-ulb:0.0287, weight:2.00, lr:0.0006
[03:30:45.578] iteration:6387  t-loss:0.2579, loss-lb:0.1963, loss-ulb:0.0308, weight:2.00, lr:0.0006
[03:30:45.902] iteration:6388  t-loss:0.4067, loss-lb:0.2060, loss-ulb:0.1004, weight:2.00, lr:0.0006
[03:30:46.221] iteration:6389  t-loss:0.2682, loss-lb:0.1783, loss-ulb:0.0449, weight:2.00, lr:0.0006
[03:30:46.539] iteration:6390  t-loss:0.4544, loss-lb:0.3475, loss-ulb:0.0534, weight:2.00, lr:0.0006
[03:30:46.867] iteration:6391  t-loss:0.5510, loss-lb:0.3604, loss-ulb:0.0953, weight:2.00, lr:0.0006
[03:30:47.192] iteration:6392  t-loss:0.3746, loss-lb:0.1954, loss-ulb:0.0896, weight:2.00, lr:0.0006
[03:30:47.513] iteration:6393  t-loss:0.2142, loss-lb:0.1543, loss-ulb:0.0300, weight:2.00, lr:0.0006
[03:30:47.828] iteration:6394  t-loss:0.2792, loss-lb:0.1531, loss-ulb:0.0630, weight:2.00, lr:0.0006
[03:30:48.149] iteration:6395  t-loss:0.3345, loss-lb:0.1981, loss-ulb:0.0682, weight:2.00, lr:0.0006
[03:30:48.467] iteration:6396  t-loss:0.2701, loss-lb:0.1873, loss-ulb:0.0414, weight:2.00, lr:0.0006
[03:30:48.782] iteration:6397  t-loss:0.3635, loss-lb:0.1832, loss-ulb:0.0901, weight:2.00, lr:0.0006
[03:30:49.096] iteration:6398  t-loss:0.8057, loss-lb:0.2419, loss-ulb:0.2819, weight:2.00, lr:0.0006
[03:30:49.412] iteration:6399  t-loss:0.3854, loss-lb:0.3227, loss-ulb:0.0313, weight:2.00, lr:0.0006
[03:30:49.726] iteration:6400  t-loss:0.2930, loss-lb:0.1839, loss-ulb:0.0545, weight:2.00, lr:0.0006
[03:30:50.745] iteration:6401  t-loss:0.2615, loss-lb:0.1967, loss-ulb:0.0324, weight:2.00, lr:0.0006
[03:30:51.075] iteration:6402  t-loss:0.1803, loss-lb:0.1319, loss-ulb:0.0242, weight:2.00, lr:0.0006
[03:30:51.402] iteration:6403  t-loss:0.4318, loss-lb:0.2250, loss-ulb:0.1034, weight:2.00, lr:0.0006
[03:30:51.721] iteration:6404  t-loss:0.3373, loss-lb:0.2629, loss-ulb:0.0372, weight:2.00, lr:0.0006
[03:30:52.042] iteration:6405  t-loss:0.4162, loss-lb:0.1719, loss-ulb:0.1221, weight:2.00, lr:0.0006
[03:30:52.369] iteration:6406  t-loss:0.3148, loss-lb:0.2318, loss-ulb:0.0415, weight:2.00, lr:0.0006
[03:30:52.695] iteration:6407  t-loss:0.3210, loss-lb:0.1756, loss-ulb:0.0727, weight:2.00, lr:0.0006
[03:30:53.017] iteration:6408  t-loss:0.4307, loss-lb:0.3154, loss-ulb:0.0577, weight:2.00, lr:0.0006
[03:30:53.349] iteration:6409  t-loss:0.4189, loss-lb:0.2544, loss-ulb:0.0822, weight:2.00, lr:0.0006
[03:30:53.667] iteration:6410  t-loss:0.5120, loss-lb:0.2147, loss-ulb:0.1487, weight:2.00, lr:0.0006
[03:30:53.985] iteration:6411  t-loss:0.4927, loss-lb:0.1811, loss-ulb:0.1558, weight:2.00, lr:0.0006
[03:30:54.301] iteration:6412  t-loss:0.2552, loss-lb:0.1639, loss-ulb:0.0456, weight:2.00, lr:0.0006
[03:30:54.619] iteration:6413  t-loss:0.5634, loss-lb:0.4924, loss-ulb:0.0355, weight:2.00, lr:0.0006
[03:30:54.939] iteration:6414  t-loss:0.3418, loss-lb:0.3133, loss-ulb:0.0142, weight:2.00, lr:0.0006
[03:30:55.255] iteration:6415  t-loss:0.3409, loss-lb:0.3013, loss-ulb:0.0198, weight:2.00, lr:0.0006
[03:30:55.575] iteration:6416  t-loss:0.5598, loss-lb:0.2142, loss-ulb:0.1728, weight:2.00, lr:0.0006
[03:30:55.897] iteration:6417  t-loss:0.1974, loss-lb:0.1393, loss-ulb:0.0291, weight:2.00, lr:0.0006
[03:30:56.219] iteration:6418  t-loss:0.5712, loss-lb:0.1931, loss-ulb:0.1891, weight:2.00, lr:0.0006
[03:30:56.539] iteration:6419  t-loss:0.4666, loss-lb:0.2174, loss-ulb:0.1246, weight:2.00, lr:0.0006
[03:30:56.861] iteration:6420  t-loss:0.3744, loss-lb:0.2541, loss-ulb:0.0602, weight:2.00, lr:0.0006
[03:30:57.186] iteration:6421  t-loss:0.5894, loss-lb:0.2778, loss-ulb:0.1558, weight:2.00, lr:0.0006
[03:30:57.503] iteration:6422  t-loss:0.2309, loss-lb:0.1299, loss-ulb:0.0505, weight:2.00, lr:0.0006
[03:30:57.830] iteration:6423  t-loss:0.2330, loss-lb:0.1433, loss-ulb:0.0448, weight:2.00, lr:0.0006
[03:30:58.148] iteration:6424  t-loss:0.4400, loss-lb:0.3506, loss-ulb:0.0447, weight:2.00, lr:0.0006
[03:30:58.464] iteration:6425  t-loss:0.6292, loss-lb:0.3028, loss-ulb:0.1632, weight:2.00, lr:0.0006
[03:32:51.413] iteration 6425 : dice_score: 0.843351 best_dice: 0.843900
[03:32:51.414]  <<Test>> - Ep:256  - Dice-S/T:82.96/84.34, Best-S:83.27, Best-T:84.39
[03:32:51.414]           - AvgLoss(lb/ulb/all):0.23/0.09/0.41
[03:32:52.606] iteration:6426  t-loss:0.3984, loss-lb:0.2919, loss-ulb:0.0533, weight:2.00, lr:0.0006
[03:32:52.936] iteration:6427  t-loss:0.2446, loss-lb:0.2101, loss-ulb:0.0172, weight:2.00, lr:0.0006
[03:32:53.258] iteration:6428  t-loss:0.1852, loss-lb:0.1204, loss-ulb:0.0324, weight:2.00, lr:0.0006
[03:32:53.578] iteration:6429  t-loss:0.3150, loss-lb:0.2580, loss-ulb:0.0285, weight:2.00, lr:0.0006
[03:32:53.902] iteration:6430  t-loss:0.5792, loss-lb:0.2679, loss-ulb:0.1557, weight:2.00, lr:0.0006
[03:32:54.221] iteration:6431  t-loss:0.3518, loss-lb:0.2337, loss-ulb:0.0590, weight:2.00, lr:0.0006
[03:32:54.542] iteration:6432  t-loss:0.5416, loss-lb:0.1436, loss-ulb:0.1990, weight:2.00, lr:0.0006
[03:32:54.866] iteration:6433  t-loss:0.3254, loss-lb:0.1981, loss-ulb:0.0637, weight:2.00, lr:0.0006
[03:32:55.185] iteration:6434  t-loss:0.3035, loss-lb:0.1698, loss-ulb:0.0669, weight:2.00, lr:0.0006
[03:32:55.501] iteration:6435  t-loss:0.4366, loss-lb:0.3317, loss-ulb:0.0525, weight:2.00, lr:0.0006
[03:32:55.821] iteration:6436  t-loss:0.5423, loss-lb:0.2753, loss-ulb:0.1335, weight:2.00, lr:0.0006
[03:32:56.141] iteration:6437  t-loss:0.3016, loss-lb:0.1855, loss-ulb:0.0580, weight:2.00, lr:0.0006
[03:32:56.459] iteration:6438  t-loss:0.5672, loss-lb:0.3595, loss-ulb:0.1038, weight:2.00, lr:0.0006
[03:32:56.774] iteration:6439  t-loss:0.2777, loss-lb:0.1971, loss-ulb:0.0403, weight:2.00, lr:0.0006
[03:32:57.095] iteration:6440  t-loss:0.3720, loss-lb:0.1429, loss-ulb:0.1146, weight:2.00, lr:0.0006
[03:32:57.414] iteration:6441  t-loss:0.2935, loss-lb:0.1766, loss-ulb:0.0584, weight:2.00, lr:0.0006
[03:32:57.729] iteration:6442  t-loss:0.4165, loss-lb:0.2002, loss-ulb:0.1081, weight:2.00, lr:0.0006
[03:32:58.046] iteration:6443  t-loss:0.3185, loss-lb:0.2513, loss-ulb:0.0336, weight:2.00, lr:0.0006
[03:32:58.359] iteration:6444  t-loss:0.2392, loss-lb:0.1676, loss-ulb:0.0358, weight:2.00, lr:0.0006
[03:32:58.673] iteration:6445  t-loss:0.2434, loss-lb:0.1860, loss-ulb:0.0287, weight:2.00, lr:0.0006
[03:32:58.988] iteration:6446  t-loss:0.6348, loss-lb:0.3741, loss-ulb:0.1304, weight:2.00, lr:0.0006
[03:32:59.303] iteration:6447  t-loss:0.5308, loss-lb:0.3378, loss-ulb:0.0965, weight:2.00, lr:0.0006
[03:32:59.613] iteration:6448  t-loss:0.6666, loss-lb:0.3474, loss-ulb:0.1596, weight:2.00, lr:0.0006
[03:32:59.926] iteration:6449  t-loss:0.3249, loss-lb:0.2823, loss-ulb:0.0213, weight:2.00, lr:0.0006
[03:33:00.238] iteration:6450  t-loss:0.2393, loss-lb:0.1895, loss-ulb:0.0249, weight:2.00, lr:0.0006
[03:33:01.399] iteration:6451  t-loss:0.3908, loss-lb:0.1901, loss-ulb:0.1004, weight:2.00, lr:0.0006
[03:33:01.728] iteration:6452  t-loss:0.4033, loss-lb:0.1240, loss-ulb:0.1396, weight:2.00, lr:0.0006
[03:33:02.058] iteration:6453  t-loss:0.4341, loss-lb:0.2854, loss-ulb:0.0744, weight:2.00, lr:0.0006
[03:33:02.383] iteration:6454  t-loss:0.6029, loss-lb:0.2573, loss-ulb:0.1728, weight:2.00, lr:0.0006
[03:33:02.702] iteration:6455  t-loss:0.3489, loss-lb:0.1696, loss-ulb:0.0896, weight:2.00, lr:0.0006
[03:33:03.027] iteration:6456  t-loss:0.2862, loss-lb:0.1904, loss-ulb:0.0479, weight:2.00, lr:0.0006
[03:33:03.355] iteration:6457  t-loss:0.5278, loss-lb:0.1931, loss-ulb:0.1673, weight:2.00, lr:0.0006
[03:33:03.680] iteration:6458  t-loss:0.4617, loss-lb:0.2722, loss-ulb:0.0948, weight:2.00, lr:0.0006
[03:33:03.996] iteration:6459  t-loss:0.2385, loss-lb:0.1625, loss-ulb:0.0380, weight:2.00, lr:0.0006
[03:33:04.317] iteration:6460  t-loss:0.8657, loss-lb:0.1960, loss-ulb:0.3348, weight:2.00, lr:0.0006
[03:33:04.638] iteration:6461  t-loss:0.4054, loss-lb:0.2490, loss-ulb:0.0782, weight:2.00, lr:0.0006
[03:33:04.957] iteration:6462  t-loss:0.3828, loss-lb:0.1783, loss-ulb:0.1022, weight:2.00, lr:0.0006
[03:33:05.279] iteration:6463  t-loss:0.3588, loss-lb:0.2750, loss-ulb:0.0419, weight:2.00, lr:0.0006
[03:33:05.596] iteration:6464  t-loss:0.7661, loss-lb:0.3439, loss-ulb:0.2111, weight:2.00, lr:0.0006
[03:33:05.911] iteration:6465  t-loss:0.8301, loss-lb:0.1925, loss-ulb:0.3188, weight:2.00, lr:0.0006
[03:33:06.226] iteration:6466  t-loss:0.8430, loss-lb:0.2113, loss-ulb:0.3158, weight:2.00, lr:0.0006
[03:33:06.539] iteration:6467  t-loss:0.4751, loss-lb:0.1587, loss-ulb:0.1582, weight:2.00, lr:0.0006
[03:33:06.854] iteration:6468  t-loss:0.3731, loss-lb:0.1931, loss-ulb:0.0900, weight:2.00, lr:0.0006
[03:33:07.167] iteration:6469  t-loss:0.2313, loss-lb:0.1800, loss-ulb:0.0256, weight:2.00, lr:0.0006
[03:33:07.481] iteration:6470  t-loss:0.1644, loss-lb:0.1276, loss-ulb:0.0184, weight:2.00, lr:0.0006
[03:33:07.796] iteration:6471  t-loss:0.2749, loss-lb:0.2043, loss-ulb:0.0353, weight:2.00, lr:0.0006
[03:33:08.114] iteration:6472  t-loss:0.8492, loss-lb:0.2662, loss-ulb:0.2915, weight:2.00, lr:0.0006
[03:33:08.431] iteration:6473  t-loss:0.3625, loss-lb:0.1813, loss-ulb:0.0906, weight:2.00, lr:0.0006
[03:33:08.746] iteration:6474  t-loss:0.2453, loss-lb:0.2067, loss-ulb:0.0193, weight:2.00, lr:0.0006
[03:33:09.058] iteration:6475  t-loss:0.2624, loss-lb:0.1461, loss-ulb:0.0581, weight:2.00, lr:0.0006
[03:33:10.147] iteration:6476  t-loss:0.4082, loss-lb:0.2883, loss-ulb:0.0600, weight:2.00, lr:0.0006
[03:33:10.476] iteration:6477  t-loss:0.5308, loss-lb:0.3280, loss-ulb:0.1014, weight:2.00, lr:0.0006
[03:33:10.805] iteration:6478  t-loss:0.4568, loss-lb:0.2118, loss-ulb:0.1225, weight:2.00, lr:0.0006
[03:33:11.130] iteration:6479  t-loss:0.3581, loss-lb:0.2806, loss-ulb:0.0387, weight:2.00, lr:0.0006
[03:33:11.457] iteration:6480  t-loss:0.3909, loss-lb:0.3550, loss-ulb:0.0179, weight:2.00, lr:0.0006
[03:33:11.788] iteration:6481  t-loss:0.5590, loss-lb:0.1824, loss-ulb:0.1883, weight:2.00, lr:0.0006
[03:33:12.129] iteration:6482  t-loss:0.5592, loss-lb:0.3160, loss-ulb:0.1216, weight:2.00, lr:0.0006
[03:33:12.457] iteration:6483  t-loss:0.2596, loss-lb:0.1558, loss-ulb:0.0519, weight:2.00, lr:0.0006
[03:33:12.780] iteration:6484  t-loss:0.3621, loss-lb:0.2062, loss-ulb:0.0780, weight:2.00, lr:0.0006
[03:33:13.104] iteration:6485  t-loss:0.5093, loss-lb:0.2197, loss-ulb:0.1448, weight:2.00, lr:0.0006
[03:33:13.429] iteration:6486  t-loss:0.2410, loss-lb:0.1681, loss-ulb:0.0365, weight:2.00, lr:0.0006
[03:33:13.753] iteration:6487  t-loss:0.3710, loss-lb:0.2287, loss-ulb:0.0711, weight:2.00, lr:0.0006
[03:33:14.070] iteration:6488  t-loss:0.1969, loss-lb:0.1452, loss-ulb:0.0258, weight:2.00, lr:0.0006
[03:33:14.398] iteration:6489  t-loss:0.3179, loss-lb:0.2660, loss-ulb:0.0260, weight:2.00, lr:0.0006
[03:33:14.718] iteration:6490  t-loss:0.3823, loss-lb:0.1701, loss-ulb:0.1061, weight:2.00, lr:0.0006
[03:33:15.042] iteration:6491  t-loss:0.7116, loss-lb:0.3871, loss-ulb:0.1623, weight:2.00, lr:0.0006
[03:33:15.368] iteration:6492  t-loss:0.4639, loss-lb:0.2666, loss-ulb:0.0986, weight:2.00, lr:0.0006
[03:33:15.688] iteration:6493  t-loss:0.5617, loss-lb:0.2284, loss-ulb:0.1667, weight:2.00, lr:0.0006
[03:33:16.002] iteration:6494  t-loss:0.4862, loss-lb:0.2106, loss-ulb:0.1378, weight:2.00, lr:0.0006
[03:33:16.316] iteration:6495  t-loss:0.2737, loss-lb:0.1719, loss-ulb:0.0509, weight:2.00, lr:0.0006
[03:33:16.628] iteration:6496  t-loss:0.4102, loss-lb:0.2045, loss-ulb:0.1029, weight:2.00, lr:0.0006
[03:33:16.939] iteration:6497  t-loss:0.2602, loss-lb:0.1184, loss-ulb:0.0709, weight:2.00, lr:0.0006
[03:33:17.253] iteration:6498  t-loss:0.4766, loss-lb:0.2664, loss-ulb:0.1051, weight:2.00, lr:0.0006
[03:33:17.567] iteration:6499  t-loss:0.3427, loss-lb:0.2009, loss-ulb:0.0709, weight:2.00, lr:0.0006
[03:33:17.883] iteration:6500  t-loss:0.3925, loss-lb:0.2716, loss-ulb:0.0605, weight:2.00, lr:0.0006
[03:33:19.074] iteration:6501  t-loss:0.8596, loss-lb:0.2125, loss-ulb:0.3235, weight:2.00, lr:0.0006
[03:33:19.398] iteration:6502  t-loss:0.4141, loss-lb:0.2938, loss-ulb:0.0602, weight:2.00, lr:0.0006
[03:33:19.718] iteration:6503  t-loss:0.6430, loss-lb:0.3327, loss-ulb:0.1551, weight:2.00, lr:0.0006
[03:33:20.035] iteration:6504  t-loss:0.2567, loss-lb:0.1905, loss-ulb:0.0331, weight:2.00, lr:0.0006
[03:33:20.355] iteration:6505  t-loss:0.3291, loss-lb:0.1438, loss-ulb:0.0927, weight:2.00, lr:0.0006
[03:33:20.677] iteration:6506  t-loss:0.3481, loss-lb:0.1626, loss-ulb:0.0927, weight:2.00, lr:0.0006
[03:33:21.002] iteration:6507  t-loss:0.5545, loss-lb:0.3370, loss-ulb:0.1088, weight:2.00, lr:0.0006
[03:33:21.326] iteration:6508  t-loss:0.1559, loss-lb:0.1078, loss-ulb:0.0241, weight:2.00, lr:0.0006
[03:33:21.643] iteration:6509  t-loss:0.4607, loss-lb:0.1870, loss-ulb:0.1368, weight:2.00, lr:0.0006
[03:33:21.969] iteration:6510  t-loss:0.3507, loss-lb:0.1954, loss-ulb:0.0777, weight:2.00, lr:0.0006
[03:33:22.291] iteration:6511  t-loss:0.3831, loss-lb:0.1568, loss-ulb:0.1132, weight:2.00, lr:0.0006
[03:33:22.609] iteration:6512  t-loss:0.4635, loss-lb:0.3130, loss-ulb:0.0752, weight:2.00, lr:0.0006
[03:33:22.928] iteration:6513  t-loss:0.2931, loss-lb:0.1892, loss-ulb:0.0519, weight:2.00, lr:0.0006
[03:33:23.252] iteration:6514  t-loss:0.3892, loss-lb:0.2051, loss-ulb:0.0921, weight:2.00, lr:0.0006
[03:33:23.580] iteration:6515  t-loss:0.4925, loss-lb:0.2431, loss-ulb:0.1247, weight:2.00, lr:0.0006
[03:33:23.900] iteration:6516  t-loss:0.3424, loss-lb:0.2358, loss-ulb:0.0533, weight:2.00, lr:0.0006
[03:33:24.220] iteration:6517  t-loss:0.2895, loss-lb:0.1340, loss-ulb:0.0777, weight:2.00, lr:0.0006
[03:33:24.540] iteration:6518  t-loss:0.7051, loss-lb:0.5715, loss-ulb:0.0668, weight:2.00, lr:0.0006
[03:33:24.854] iteration:6519  t-loss:0.4198, loss-lb:0.2946, loss-ulb:0.0626, weight:2.00, lr:0.0006
[03:33:25.173] iteration:6520  t-loss:0.3187, loss-lb:0.2176, loss-ulb:0.0505, weight:2.00, lr:0.0006
[03:33:25.491] iteration:6521  t-loss:0.2123, loss-lb:0.1434, loss-ulb:0.0344, weight:2.00, lr:0.0006
[03:33:25.807] iteration:6522  t-loss:0.3807, loss-lb:0.1456, loss-ulb:0.1175, weight:2.00, lr:0.0006
[03:33:26.123] iteration:6523  t-loss:0.5344, loss-lb:0.2827, loss-ulb:0.1259, weight:2.00, lr:0.0006
[03:33:26.439] iteration:6524  t-loss:0.3093, loss-lb:0.2579, loss-ulb:0.0257, weight:2.00, lr:0.0006
[03:33:26.755] iteration:6525  t-loss:0.4711, loss-lb:0.3133, loss-ulb:0.0789, weight:2.00, lr:0.0006
[03:35:22.379] iteration 6525 : dice_score: 0.845223 best_dice: 0.845200
[03:35:22.379]  <<Test>> - Ep:260  - Dice-S/T:83.48/84.52, Best-S:83.48, Best-T:84.52
[03:35:22.380]           - AvgLoss(lb/ulb/all):0.23/0.08/0.39
[03:35:23.553] iteration:6526  t-loss:0.4475, loss-lb:0.1808, loss-ulb:0.1334, weight:2.00, lr:0.0006
[03:35:23.900] iteration:6527  t-loss:0.5235, loss-lb:0.2231, loss-ulb:0.1502, weight:2.00, lr:0.0006
[03:35:24.229] iteration:6528  t-loss:0.4555, loss-lb:0.2326, loss-ulb:0.1115, weight:2.00, lr:0.0006
[03:35:24.553] iteration:6529  t-loss:0.4962, loss-lb:0.2143, loss-ulb:0.1409, weight:2.00, lr:0.0006
[03:35:24.873] iteration:6530  t-loss:0.2151, loss-lb:0.1787, loss-ulb:0.0182, weight:2.00, lr:0.0006
[03:35:25.192] iteration:6531  t-loss:0.1962, loss-lb:0.1453, loss-ulb:0.0254, weight:2.00, lr:0.0006
[03:35:25.518] iteration:6532  t-loss:0.3765, loss-lb:0.2047, loss-ulb:0.0859, weight:2.00, lr:0.0006
[03:35:25.839] iteration:6533  t-loss:0.5295, loss-lb:0.3729, loss-ulb:0.0783, weight:2.00, lr:0.0006
[03:35:26.169] iteration:6534  t-loss:0.3244, loss-lb:0.2420, loss-ulb:0.0412, weight:2.00, lr:0.0006
[03:35:26.491] iteration:6535  t-loss:0.4767, loss-lb:0.1929, loss-ulb:0.1419, weight:2.00, lr:0.0006
[03:35:26.808] iteration:6536  t-loss:0.2889, loss-lb:0.1493, loss-ulb:0.0698, weight:2.00, lr:0.0006
[03:35:27.125] iteration:6537  t-loss:0.2342, loss-lb:0.1913, loss-ulb:0.0214, weight:2.00, lr:0.0006
[03:35:27.443] iteration:6538  t-loss:0.3478, loss-lb:0.2718, loss-ulb:0.0380, weight:2.00, lr:0.0006
[03:35:27.763] iteration:6539  t-loss:0.7086, loss-lb:0.1829, loss-ulb:0.2628, weight:2.00, lr:0.0006
[03:35:28.081] iteration:6540  t-loss:0.2870, loss-lb:0.2293, loss-ulb:0.0288, weight:2.00, lr:0.0006
[03:35:28.397] iteration:6541  t-loss:0.2845, loss-lb:0.2265, loss-ulb:0.0290, weight:2.00, lr:0.0006
[03:35:28.714] iteration:6542  t-loss:0.4526, loss-lb:0.3216, loss-ulb:0.0655, weight:2.00, lr:0.0006
[03:35:29.025] iteration:6543  t-loss:0.2982, loss-lb:0.2528, loss-ulb:0.0227, weight:2.00, lr:0.0006
[03:35:29.338] iteration:6544  t-loss:0.2825, loss-lb:0.2341, loss-ulb:0.0242, weight:2.00, lr:0.0006
[03:35:29.654] iteration:6545  t-loss:0.4787, loss-lb:0.3088, loss-ulb:0.0850, weight:2.00, lr:0.0006
[03:35:29.966] iteration:6546  t-loss:0.3747, loss-lb:0.2779, loss-ulb:0.0484, weight:2.00, lr:0.0006
[03:35:30.281] iteration:6547  t-loss:0.4352, loss-lb:0.2617, loss-ulb:0.0868, weight:2.00, lr:0.0006
[03:35:30.598] iteration:6548  t-loss:0.3002, loss-lb:0.2619, loss-ulb:0.0192, weight:2.00, lr:0.0006
[03:35:30.912] iteration:6549  t-loss:0.4001, loss-lb:0.3053, loss-ulb:0.0474, weight:2.00, lr:0.0006
[03:35:31.224] iteration:6550  t-loss:0.3270, loss-lb:0.2532, loss-ulb:0.0369, weight:2.00, lr:0.0006
[03:35:32.498] iteration:6551  t-loss:0.5347, loss-lb:0.3984, loss-ulb:0.0681, weight:2.00, lr:0.0006
[03:35:32.830] iteration:6552  t-loss:0.3054, loss-lb:0.2489, loss-ulb:0.0283, weight:2.00, lr:0.0006
[03:35:33.161] iteration:6553  t-loss:0.3887, loss-lb:0.1711, loss-ulb:0.1088, weight:2.00, lr:0.0006
[03:35:33.479] iteration:6554  t-loss:0.3398, loss-lb:0.1899, loss-ulb:0.0749, weight:2.00, lr:0.0006
[03:35:33.794] iteration:6555  t-loss:0.2711, loss-lb:0.2251, loss-ulb:0.0230, weight:2.00, lr:0.0006
[03:35:34.111] iteration:6556  t-loss:0.9031, loss-lb:0.2677, loss-ulb:0.3177, weight:2.00, lr:0.0006
[03:35:34.425] iteration:6557  t-loss:0.2535, loss-lb:0.2139, loss-ulb:0.0198, weight:2.00, lr:0.0006
[03:35:34.741] iteration:6558  t-loss:0.2082, loss-lb:0.1462, loss-ulb:0.0310, weight:2.00, lr:0.0006
[03:35:35.053] iteration:6559  t-loss:0.3291, loss-lb:0.1669, loss-ulb:0.0811, weight:2.00, lr:0.0006
[03:35:35.372] iteration:6560  t-loss:0.3455, loss-lb:0.2082, loss-ulb:0.0686, weight:2.00, lr:0.0006
[03:35:35.696] iteration:6561  t-loss:0.7884, loss-lb:0.4236, loss-ulb:0.1824, weight:2.00, lr:0.0006
[03:35:36.017] iteration:6562  t-loss:0.3622, loss-lb:0.1916, loss-ulb:0.0853, weight:2.00, lr:0.0006
[03:35:36.332] iteration:6563  t-loss:0.3789, loss-lb:0.1847, loss-ulb:0.0971, weight:2.00, lr:0.0006
[03:35:36.649] iteration:6564  t-loss:0.2324, loss-lb:0.1919, loss-ulb:0.0203, weight:2.00, lr:0.0006
[03:35:36.967] iteration:6565  t-loss:0.2389, loss-lb:0.1849, loss-ulb:0.0270, weight:2.00, lr:0.0006
[03:35:37.285] iteration:6566  t-loss:0.4934, loss-lb:0.1855, loss-ulb:0.1539, weight:2.00, lr:0.0006
[03:35:37.607] iteration:6567  t-loss:0.3817, loss-lb:0.2039, loss-ulb:0.0889, weight:2.00, lr:0.0006
[03:35:37.925] iteration:6568  t-loss:0.4525, loss-lb:0.1717, loss-ulb:0.1404, weight:2.00, lr:0.0006
[03:35:38.241] iteration:6569  t-loss:0.5150, loss-lb:0.1482, loss-ulb:0.1834, weight:2.00, lr:0.0006
[03:35:38.555] iteration:6570  t-loss:0.3428, loss-lb:0.1669, loss-ulb:0.0879, weight:2.00, lr:0.0006
[03:35:38.870] iteration:6571  t-loss:0.2165, loss-lb:0.1646, loss-ulb:0.0259, weight:2.00, lr:0.0006
[03:35:39.183] iteration:6572  t-loss:0.1817, loss-lb:0.1463, loss-ulb:0.0177, weight:2.00, lr:0.0006
[03:35:39.496] iteration:6573  t-loss:0.2563, loss-lb:0.1926, loss-ulb:0.0319, weight:2.00, lr:0.0006
[03:35:39.810] iteration:6574  t-loss:0.2667, loss-lb:0.2102, loss-ulb:0.0282, weight:2.00, lr:0.0006
[03:35:40.125] iteration:6575  t-loss:0.3963, loss-lb:0.1951, loss-ulb:0.1006, weight:2.00, lr:0.0006
[03:35:41.411] iteration:6576  t-loss:0.4569, loss-lb:0.1707, loss-ulb:0.1431, weight:2.00, lr:0.0006
[03:35:41.737] iteration:6577  t-loss:0.3891, loss-lb:0.3134, loss-ulb:0.0378, weight:2.00, lr:0.0006
[03:35:42.064] iteration:6578  t-loss:0.2945, loss-lb:0.2413, loss-ulb:0.0266, weight:2.00, lr:0.0006
[03:35:42.383] iteration:6579  t-loss:0.3597, loss-lb:0.3124, loss-ulb:0.0236, weight:2.00, lr:0.0006
[03:35:42.699] iteration:6580  t-loss:0.2362, loss-lb:0.1511, loss-ulb:0.0426, weight:2.00, lr:0.0006
[03:35:43.017] iteration:6581  t-loss:0.2762, loss-lb:0.2206, loss-ulb:0.0278, weight:2.00, lr:0.0006
[03:35:43.336] iteration:6582  t-loss:0.7201, loss-lb:0.2419, loss-ulb:0.2391, weight:2.00, lr:0.0006
[03:35:43.653] iteration:6583  t-loss:0.3548, loss-lb:0.1438, loss-ulb:0.1055, weight:2.00, lr:0.0006
[03:35:43.970] iteration:6584  t-loss:0.3670, loss-lb:0.1329, loss-ulb:0.1171, weight:2.00, lr:0.0006
[03:35:44.294] iteration:6585  t-loss:0.7134, loss-lb:0.2743, loss-ulb:0.2196, weight:2.00, lr:0.0006
[03:35:44.611] iteration:6586  t-loss:0.6855, loss-lb:0.3944, loss-ulb:0.1455, weight:2.00, lr:0.0006
[03:35:44.925] iteration:6587  t-loss:0.2275, loss-lb:0.1880, loss-ulb:0.0197, weight:2.00, lr:0.0006
[03:35:45.248] iteration:6588  t-loss:0.4636, loss-lb:0.2455, loss-ulb:0.1091, weight:2.00, lr:0.0006
[03:35:45.564] iteration:6589  t-loss:0.3983, loss-lb:0.2527, loss-ulb:0.0728, weight:2.00, lr:0.0006
[03:35:45.881] iteration:6590  t-loss:0.2476, loss-lb:0.2074, loss-ulb:0.0201, weight:2.00, lr:0.0006
[03:35:46.202] iteration:6591  t-loss:0.6119, loss-lb:0.3175, loss-ulb:0.1472, weight:2.00, lr:0.0006
[03:35:46.520] iteration:6592  t-loss:0.3511, loss-lb:0.1370, loss-ulb:0.1071, weight:2.00, lr:0.0006
[03:35:46.837] iteration:6593  t-loss:1.1285, loss-lb:0.3616, loss-ulb:0.3834, weight:2.00, lr:0.0006
[03:35:47.151] iteration:6594  t-loss:0.2060, loss-lb:0.1551, loss-ulb:0.0254, weight:2.00, lr:0.0006
[03:35:47.467] iteration:6595  t-loss:0.4152, loss-lb:0.1679, loss-ulb:0.1236, weight:2.00, lr:0.0006
[03:35:47.779] iteration:6596  t-loss:0.2820, loss-lb:0.1911, loss-ulb:0.0455, weight:2.00, lr:0.0006
[03:35:48.093] iteration:6597  t-loss:0.3525, loss-lb:0.2891, loss-ulb:0.0317, weight:2.00, lr:0.0006
[03:35:48.408] iteration:6598  t-loss:0.4094, loss-lb:0.1963, loss-ulb:0.1065, weight:2.00, lr:0.0006
[03:35:48.724] iteration:6599  t-loss:0.6241, loss-lb:0.2734, loss-ulb:0.1754, weight:2.00, lr:0.0006
[03:35:49.041] iteration:6600  t-loss:0.5817, loss-lb:0.3687, loss-ulb:0.1065, weight:2.00, lr:0.0006
[03:35:50.460] iteration:6601  t-loss:0.4267, loss-lb:0.2113, loss-ulb:0.1077, weight:2.00, lr:0.0006
[03:35:50.790] iteration:6602  t-loss:0.3488, loss-lb:0.2713, loss-ulb:0.0388, weight:2.00, lr:0.0006
[03:35:51.115] iteration:6603  t-loss:0.3078, loss-lb:0.2504, loss-ulb:0.0287, weight:2.00, lr:0.0006
[03:35:51.434] iteration:6604  t-loss:0.5064, loss-lb:0.2250, loss-ulb:0.1407, weight:2.00, lr:0.0006
[03:35:51.760] iteration:6605  t-loss:0.6516, loss-lb:0.2496, loss-ulb:0.2010, weight:2.00, lr:0.0006
[03:35:52.079] iteration:6606  t-loss:0.4640, loss-lb:0.1945, loss-ulb:0.1348, weight:2.00, lr:0.0006
[03:35:52.396] iteration:6607  t-loss:0.4982, loss-lb:0.2508, loss-ulb:0.1237, weight:2.00, lr:0.0006
[03:35:52.715] iteration:6608  t-loss:0.5585, loss-lb:0.2975, loss-ulb:0.1305, weight:2.00, lr:0.0006
[03:35:53.031] iteration:6609  t-loss:0.4378, loss-lb:0.3255, loss-ulb:0.0562, weight:2.00, lr:0.0006
[03:35:53.354] iteration:6610  t-loss:0.4291, loss-lb:0.3768, loss-ulb:0.0261, weight:2.00, lr:0.0006
[03:35:53.675] iteration:6611  t-loss:0.5078, loss-lb:0.2905, loss-ulb:0.1086, weight:2.00, lr:0.0006
[03:35:53.994] iteration:6612  t-loss:0.6173, loss-lb:0.3484, loss-ulb:0.1344, weight:2.00, lr:0.0006
[03:35:54.308] iteration:6613  t-loss:0.2346, loss-lb:0.1572, loss-ulb:0.0387, weight:2.00, lr:0.0006
[03:35:54.705] iteration:6614  t-loss:0.2739, loss-lb:0.2203, loss-ulb:0.0268, weight:2.00, lr:0.0006
[03:35:55.025] iteration:6615  t-loss:0.5877, loss-lb:0.2534, loss-ulb:0.1671, weight:2.00, lr:0.0006
[03:35:55.341] iteration:6616  t-loss:0.2456, loss-lb:0.1897, loss-ulb:0.0279, weight:2.00, lr:0.0006
[03:35:55.661] iteration:6617  t-loss:0.8914, loss-lb:0.1935, loss-ulb:0.3490, weight:2.00, lr:0.0006
[03:35:55.974] iteration:6618  t-loss:0.5074, loss-lb:0.2914, loss-ulb:0.1080, weight:2.00, lr:0.0006
[03:35:56.289] iteration:6619  t-loss:0.2212, loss-lb:0.1513, loss-ulb:0.0350, weight:2.00, lr:0.0006
[03:35:56.610] iteration:6620  t-loss:0.5067, loss-lb:0.4233, loss-ulb:0.0417, weight:2.00, lr:0.0006
[03:35:56.928] iteration:6621  t-loss:0.4447, loss-lb:0.2924, loss-ulb:0.0762, weight:2.00, lr:0.0006
[03:35:57.243] iteration:6622  t-loss:0.2321, loss-lb:0.1875, loss-ulb:0.0223, weight:2.00, lr:0.0006
[03:35:57.560] iteration:6623  t-loss:0.3928, loss-lb:0.3034, loss-ulb:0.0447, weight:2.00, lr:0.0006
[03:35:57.873] iteration:6624  t-loss:0.2452, loss-lb:0.1372, loss-ulb:0.0540, weight:2.00, lr:0.0006
[03:35:58.186] iteration:6625  t-loss:0.3684, loss-lb:0.1504, loss-ulb:0.1090, weight:2.00, lr:0.0006
[03:37:55.496] iteration 6625 : dice_score: 0.844663 best_dice: 0.845200
[03:37:55.496]  <<Test>> - Ep:264  - Dice-S/T:81.55/84.47, Best-S:83.48, Best-T:84.52
[03:37:55.496]           - AvgLoss(lb/ulb/all):0.25/0.09/0.43
[03:37:56.753] iteration:6626  t-loss:0.3840, loss-lb:0.1732, loss-ulb:0.1054, weight:2.00, lr:0.0006
[03:37:57.077] iteration:6627  t-loss:0.4816, loss-lb:0.2246, loss-ulb:0.1285, weight:2.00, lr:0.0006
[03:37:57.395] iteration:6628  t-loss:0.3751, loss-lb:0.2558, loss-ulb:0.0596, weight:2.00, lr:0.0006
[03:37:57.713] iteration:6629  t-loss:0.3161, loss-lb:0.1637, loss-ulb:0.0762, weight:2.00, lr:0.0006
[03:37:58.029] iteration:6630  t-loss:0.3513, loss-lb:0.1643, loss-ulb:0.0935, weight:2.00, lr:0.0006
[03:37:58.346] iteration:6631  t-loss:0.3397, loss-lb:0.2912, loss-ulb:0.0243, weight:2.00, lr:0.0006
[03:37:58.662] iteration:6632  t-loss:0.3745, loss-lb:0.1938, loss-ulb:0.0903, weight:2.00, lr:0.0006
[03:37:58.981] iteration:6633  t-loss:0.6678, loss-lb:0.3376, loss-ulb:0.1651, weight:2.00, lr:0.0006
[03:37:59.297] iteration:6634  t-loss:0.2219, loss-lb:0.1423, loss-ulb:0.0398, weight:2.00, lr:0.0006
[03:37:59.616] iteration:6635  t-loss:0.4120, loss-lb:0.3017, loss-ulb:0.0552, weight:2.00, lr:0.0006
[03:37:59.931] iteration:6636  t-loss:0.3101, loss-lb:0.2697, loss-ulb:0.0202, weight:2.00, lr:0.0006
[03:38:00.249] iteration:6637  t-loss:0.5352, loss-lb:0.3140, loss-ulb:0.1106, weight:2.00, lr:0.0006
[03:38:00.567] iteration:6638  t-loss:0.6068, loss-lb:0.2683, loss-ulb:0.1692, weight:2.00, lr:0.0006
[03:38:00.886] iteration:6639  t-loss:0.5214, loss-lb:0.3544, loss-ulb:0.0835, weight:2.00, lr:0.0006
[03:38:01.201] iteration:6640  t-loss:0.3845, loss-lb:0.3195, loss-ulb:0.0325, weight:2.00, lr:0.0006
[03:38:01.522] iteration:6641  t-loss:0.4372, loss-lb:0.2110, loss-ulb:0.1131, weight:2.00, lr:0.0006
[03:38:01.838] iteration:6642  t-loss:0.3438, loss-lb:0.1878, loss-ulb:0.0780, weight:2.00, lr:0.0006
[03:38:02.151] iteration:6643  t-loss:0.3139, loss-lb:0.2607, loss-ulb:0.0266, weight:2.00, lr:0.0006
[03:38:02.465] iteration:6644  t-loss:0.3428, loss-lb:0.1772, loss-ulb:0.0828, weight:2.00, lr:0.0006
[03:38:02.779] iteration:6645  t-loss:0.3483, loss-lb:0.1734, loss-ulb:0.0874, weight:2.00, lr:0.0006
[03:38:03.092] iteration:6646  t-loss:0.4215, loss-lb:0.1596, loss-ulb:0.1309, weight:2.00, lr:0.0006
[03:38:03.408] iteration:6647  t-loss:0.4574, loss-lb:0.3250, loss-ulb:0.0662, weight:2.00, lr:0.0006
[03:38:03.721] iteration:6648  t-loss:0.4139, loss-lb:0.2058, loss-ulb:0.1041, weight:2.00, lr:0.0006
[03:38:04.038] iteration:6649  t-loss:0.3265, loss-lb:0.1760, loss-ulb:0.0753, weight:2.00, lr:0.0006
[03:38:04.351] iteration:6650  t-loss:0.6856, loss-lb:0.2617, loss-ulb:0.2120, weight:2.00, lr:0.0006
[03:38:05.541] iteration:6651  t-loss:0.2690, loss-lb:0.1871, loss-ulb:0.0410, weight:2.00, lr:0.0006
[03:38:05.865] iteration:6652  t-loss:0.2609, loss-lb:0.2096, loss-ulb:0.0256, weight:2.00, lr:0.0006
[03:38:06.181] iteration:6653  t-loss:0.4636, loss-lb:0.2274, loss-ulb:0.1181, weight:2.00, lr:0.0006
[03:38:06.496] iteration:6654  t-loss:0.6314, loss-lb:0.1417, loss-ulb:0.2449, weight:2.00, lr:0.0006
[03:38:06.814] iteration:6655  t-loss:0.5877, loss-lb:0.3839, loss-ulb:0.1019, weight:2.00, lr:0.0006
[03:38:07.131] iteration:6656  t-loss:0.3987, loss-lb:0.2160, loss-ulb:0.0914, weight:2.00, lr:0.0006
[03:38:07.447] iteration:6657  t-loss:0.3097, loss-lb:0.1429, loss-ulb:0.0834, weight:2.00, lr:0.0006
[03:38:07.777] iteration:6658  t-loss:0.3188, loss-lb:0.2412, loss-ulb:0.0388, weight:2.00, lr:0.0006
[03:38:08.102] iteration:6659  t-loss:0.2595, loss-lb:0.1459, loss-ulb:0.0568, weight:2.00, lr:0.0006
[03:38:08.419] iteration:6660  t-loss:0.3084, loss-lb:0.2574, loss-ulb:0.0255, weight:2.00, lr:0.0006
[03:38:08.743] iteration:6661  t-loss:0.3941, loss-lb:0.2348, loss-ulb:0.0796, weight:2.00, lr:0.0006
[03:38:09.064] iteration:6662  t-loss:0.7458, loss-lb:0.2697, loss-ulb:0.2380, weight:2.00, lr:0.0006
[03:38:09.379] iteration:6663  t-loss:0.5112, loss-lb:0.1674, loss-ulb:0.1719, weight:2.00, lr:0.0006
[03:38:09.698] iteration:6664  t-loss:0.4530, loss-lb:0.2354, loss-ulb:0.1088, weight:2.00, lr:0.0006
[03:38:10.015] iteration:6665  t-loss:0.4696, loss-lb:0.2115, loss-ulb:0.1290, weight:2.00, lr:0.0006
[03:38:10.332] iteration:6666  t-loss:0.3083, loss-lb:0.1580, loss-ulb:0.0752, weight:2.00, lr:0.0006
[03:38:10.649] iteration:6667  t-loss:0.8014, loss-lb:0.2880, loss-ulb:0.2567, weight:2.00, lr:0.0006
[03:38:10.968] iteration:6668  t-loss:0.6169, loss-lb:0.3948, loss-ulb:0.1110, weight:2.00, lr:0.0006
[03:38:11.283] iteration:6669  t-loss:0.4614, loss-lb:0.1324, loss-ulb:0.1645, weight:2.00, lr:0.0006
[03:38:11.599] iteration:6670  t-loss:0.3871, loss-lb:0.1855, loss-ulb:0.1008, weight:2.00, lr:0.0006
[03:38:11.913] iteration:6671  t-loss:0.2208, loss-lb:0.1752, loss-ulb:0.0228, weight:2.00, lr:0.0006
[03:38:12.227] iteration:6672  t-loss:0.1840, loss-lb:0.1244, loss-ulb:0.0298, weight:2.00, lr:0.0006
[03:38:12.542] iteration:6673  t-loss:0.6180, loss-lb:0.1653, loss-ulb:0.2264, weight:2.00, lr:0.0006
[03:38:12.859] iteration:6674  t-loss:0.7087, loss-lb:0.3282, loss-ulb:0.1902, weight:2.00, lr:0.0006
[03:38:13.176] iteration:6675  t-loss:0.5617, loss-lb:0.1333, loss-ulb:0.2142, weight:2.00, lr:0.0006
[03:38:14.560] iteration:6676  t-loss:0.4814, loss-lb:0.2482, loss-ulb:0.1166, weight:2.00, lr:0.0006
[03:38:14.880] iteration:6677  t-loss:0.7798, loss-lb:0.1289, loss-ulb:0.3254, weight:2.00, lr:0.0006
[03:38:15.199] iteration:6678  t-loss:0.5380, loss-lb:0.3305, loss-ulb:0.1038, weight:2.00, lr:0.0006
[03:38:15.521] iteration:6679  t-loss:0.5946, loss-lb:0.3390, loss-ulb:0.1278, weight:2.00, lr:0.0006
[03:38:15.857] iteration:6680  t-loss:0.2863, loss-lb:0.1735, loss-ulb:0.0564, weight:2.00, lr:0.0006
[03:38:16.177] iteration:6681  t-loss:0.6277, loss-lb:0.3709, loss-ulb:0.1284, weight:2.00, lr:0.0006
[03:38:16.498] iteration:6682  t-loss:0.6427, loss-lb:0.2620, loss-ulb:0.1904, weight:2.00, lr:0.0006
[03:38:16.817] iteration:6683  t-loss:0.4203, loss-lb:0.1487, loss-ulb:0.1358, weight:2.00, lr:0.0006
[03:38:17.136] iteration:6684  t-loss:0.4791, loss-lb:0.3137, loss-ulb:0.0827, weight:2.00, lr:0.0006
[03:38:17.457] iteration:6685  t-loss:0.3671, loss-lb:0.3154, loss-ulb:0.0259, weight:2.00, lr:0.0006
[03:38:17.777] iteration:6686  t-loss:0.4940, loss-lb:0.2441, loss-ulb:0.1249, weight:2.00, lr:0.0006
[03:38:18.094] iteration:6687  t-loss:0.2957, loss-lb:0.2228, loss-ulb:0.0365, weight:2.00, lr:0.0006
[03:38:18.413] iteration:6688  t-loss:0.3082, loss-lb:0.1724, loss-ulb:0.0679, weight:2.00, lr:0.0006
[03:38:18.732] iteration:6689  t-loss:0.3852, loss-lb:0.2283, loss-ulb:0.0785, weight:2.00, lr:0.0006
[03:38:19.049] iteration:6690  t-loss:0.2651, loss-lb:0.1999, loss-ulb:0.0326, weight:2.00, lr:0.0006
[03:38:19.372] iteration:6691  t-loss:0.2283, loss-lb:0.1763, loss-ulb:0.0260, weight:2.00, lr:0.0006
[03:38:19.690] iteration:6692  t-loss:0.1966, loss-lb:0.1426, loss-ulb:0.0270, weight:2.00, lr:0.0006
[03:38:20.008] iteration:6693  t-loss:0.3080, loss-lb:0.2657, loss-ulb:0.0211, weight:2.00, lr:0.0006
[03:38:20.323] iteration:6694  t-loss:0.6222, loss-lb:0.3249, loss-ulb:0.1487, weight:2.00, lr:0.0006
[03:38:20.637] iteration:6695  t-loss:0.2740, loss-lb:0.1659, loss-ulb:0.0541, weight:2.00, lr:0.0006
[03:38:20.950] iteration:6696  t-loss:0.4232, loss-lb:0.1982, loss-ulb:0.1125, weight:2.00, lr:0.0006
[03:38:21.264] iteration:6697  t-loss:0.3381, loss-lb:0.1508, loss-ulb:0.0937, weight:2.00, lr:0.0006
[03:38:21.579] iteration:6698  t-loss:0.5767, loss-lb:0.1502, loss-ulb:0.2133, weight:2.00, lr:0.0006
[03:38:21.892] iteration:6699  t-loss:1.0507, loss-lb:0.1566, loss-ulb:0.4471, weight:2.00, lr:0.0006
[03:38:22.206] iteration:6700  t-loss:0.3966, loss-lb:0.3349, loss-ulb:0.0309, weight:2.00, lr:0.0006
[03:38:23.424] iteration:6701  t-loss:0.5453, loss-lb:0.1940, loss-ulb:0.1756, weight:2.00, lr:0.0006
[03:38:23.753] iteration:6702  t-loss:0.3516, loss-lb:0.1717, loss-ulb:0.0899, weight:2.00, lr:0.0006
[03:38:24.072] iteration:6703  t-loss:0.3028, loss-lb:0.2410, loss-ulb:0.0309, weight:2.00, lr:0.0006
[03:38:24.387] iteration:6704  t-loss:0.5935, loss-lb:0.2430, loss-ulb:0.1752, weight:2.00, lr:0.0006
[03:38:24.704] iteration:6705  t-loss:0.6955, loss-lb:0.3801, loss-ulb:0.1577, weight:2.00, lr:0.0006
[03:38:25.020] iteration:6706  t-loss:0.3385, loss-lb:0.2749, loss-ulb:0.0318, weight:2.00, lr:0.0006
[03:38:25.336] iteration:6707  t-loss:0.5773, loss-lb:0.1850, loss-ulb:0.1962, weight:2.00, lr:0.0006
[03:38:25.652] iteration:6708  t-loss:0.3078, loss-lb:0.2502, loss-ulb:0.0288, weight:2.00, lr:0.0006
[03:38:25.972] iteration:6709  t-loss:0.3606, loss-lb:0.2918, loss-ulb:0.0344, weight:2.00, lr:0.0006
[03:38:26.290] iteration:6710  t-loss:0.3949, loss-lb:0.2221, loss-ulb:0.0864, weight:2.00, lr:0.0006
[03:38:26.612] iteration:6711  t-loss:0.3644, loss-lb:0.1738, loss-ulb:0.0953, weight:2.00, lr:0.0006
[03:38:26.934] iteration:6712  t-loss:0.3915, loss-lb:0.1657, loss-ulb:0.1129, weight:2.00, lr:0.0006
[03:38:27.253] iteration:6713  t-loss:0.3557, loss-lb:0.1904, loss-ulb:0.0826, weight:2.00, lr:0.0006
[03:38:27.572] iteration:6714  t-loss:0.2979, loss-lb:0.2335, loss-ulb:0.0322, weight:2.00, lr:0.0006
[03:38:27.893] iteration:6715  t-loss:0.9327, loss-lb:0.2867, loss-ulb:0.3230, weight:2.00, lr:0.0006
[03:38:28.215] iteration:6716  t-loss:0.3890, loss-lb:0.2301, loss-ulb:0.0795, weight:2.00, lr:0.0006
[03:38:28.535] iteration:6717  t-loss:0.4389, loss-lb:0.2076, loss-ulb:0.1157, weight:2.00, lr:0.0006
[03:38:28.850] iteration:6718  t-loss:0.3347, loss-lb:0.2338, loss-ulb:0.0504, weight:2.00, lr:0.0006
[03:38:29.162] iteration:6719  t-loss:0.3136, loss-lb:0.2213, loss-ulb:0.0461, weight:2.00, lr:0.0006
[03:38:29.477] iteration:6720  t-loss:0.2438, loss-lb:0.1249, loss-ulb:0.0594, weight:2.00, lr:0.0006
[03:38:29.792] iteration:6721  t-loss:0.3049, loss-lb:0.1663, loss-ulb:0.0693, weight:2.00, lr:0.0006
[03:38:30.105] iteration:6722  t-loss:0.4054, loss-lb:0.1772, loss-ulb:0.1141, weight:2.00, lr:0.0006
[03:38:30.422] iteration:6723  t-loss:0.5262, loss-lb:0.2505, loss-ulb:0.1379, weight:2.00, lr:0.0006
[03:38:30.736] iteration:6724  t-loss:0.4195, loss-lb:0.3765, loss-ulb:0.0215, weight:2.00, lr:0.0006
[03:38:31.054] iteration:6725  t-loss:0.6365, loss-lb:0.2429, loss-ulb:0.1968, weight:2.00, lr:0.0006
[03:40:25.977] iteration 6725 : dice_score: 0.846049 best_dice: 0.846000
[03:40:25.977]  <<Test>> - Ep:268  - Dice-S/T:84.07/84.60, Best-S:84.07, Best-T:84.60
[03:40:25.977]           - AvgLoss(lb/ulb/all):0.23/0.10/0.42
[03:40:27.207] iteration:6726  t-loss:0.4062, loss-lb:0.1979, loss-ulb:0.1041, weight:2.00, lr:0.0006
[03:40:27.535] iteration:6727  t-loss:0.8894, loss-lb:0.2197, loss-ulb:0.3348, weight:2.00, lr:0.0006
[03:40:27.855] iteration:6728  t-loss:0.3214, loss-lb:0.1566, loss-ulb:0.0824, weight:2.00, lr:0.0006
[03:40:28.167] iteration:6729  t-loss:0.8733, loss-lb:0.1942, loss-ulb:0.3395, weight:2.00, lr:0.0006
[03:40:28.482] iteration:6730  t-loss:0.3496, loss-lb:0.1292, loss-ulb:0.1102, weight:2.00, lr:0.0006
[03:40:28.797] iteration:6731  t-loss:0.6814, loss-lb:0.3563, loss-ulb:0.1626, weight:2.00, lr:0.0006
[03:40:29.117] iteration:6732  t-loss:0.3426, loss-lb:0.1600, loss-ulb:0.0913, weight:2.00, lr:0.0006
[03:40:29.436] iteration:6733  t-loss:0.3586, loss-lb:0.2536, loss-ulb:0.0525, weight:2.00, lr:0.0006
[03:40:29.755] iteration:6734  t-loss:0.5750, loss-lb:0.3506, loss-ulb:0.1122, weight:2.00, lr:0.0006
[03:40:30.074] iteration:6735  t-loss:0.2384, loss-lb:0.1862, loss-ulb:0.0261, weight:2.00, lr:0.0006
[03:40:30.396] iteration:6736  t-loss:0.5832, loss-lb:0.1741, loss-ulb:0.2046, weight:2.00, lr:0.0006
[03:40:30.714] iteration:6737  t-loss:0.2782, loss-lb:0.1878, loss-ulb:0.0452, weight:2.00, lr:0.0006
[03:40:31.041] iteration:6738  t-loss:0.5524, loss-lb:0.2468, loss-ulb:0.1528, weight:2.00, lr:0.0006
[03:40:31.362] iteration:6739  t-loss:0.5019, loss-lb:0.3187, loss-ulb:0.0916, weight:2.00, lr:0.0006
[03:40:31.677] iteration:6740  t-loss:0.2026, loss-lb:0.1518, loss-ulb:0.0254, weight:2.00, lr:0.0006
[03:40:31.997] iteration:6741  t-loss:0.4799, loss-lb:0.1832, loss-ulb:0.1483, weight:2.00, lr:0.0006
[03:40:32.312] iteration:6742  t-loss:0.2571, loss-lb:0.1755, loss-ulb:0.0408, weight:2.00, lr:0.0006
[03:40:32.625] iteration:6743  t-loss:0.2102, loss-lb:0.1650, loss-ulb:0.0226, weight:2.00, lr:0.0006
[03:40:32.937] iteration:6744  t-loss:0.3927, loss-lb:0.2084, loss-ulb:0.0921, weight:2.00, lr:0.0006
[03:40:33.253] iteration:6745  t-loss:0.3677, loss-lb:0.2700, loss-ulb:0.0488, weight:2.00, lr:0.0006
[03:40:33.575] iteration:6746  t-loss:0.3652, loss-lb:0.1759, loss-ulb:0.0947, weight:2.00, lr:0.0006
[03:40:33.889] iteration:6747  t-loss:0.3989, loss-lb:0.2340, loss-ulb:0.0825, weight:2.00, lr:0.0006
[03:40:34.202] iteration:6748  t-loss:0.3607, loss-lb:0.1476, loss-ulb:0.1065, weight:2.00, lr:0.0006
[03:40:34.514] iteration:6749  t-loss:0.3983, loss-lb:0.2738, loss-ulb:0.0622, weight:2.00, lr:0.0006
[03:40:34.827] iteration:6750  t-loss:0.4466, loss-lb:0.1611, loss-ulb:0.1428, weight:2.00, lr:0.0006
[03:40:36.131] iteration:6751  t-loss:0.2005, loss-lb:0.1604, loss-ulb:0.0200, weight:2.00, lr:0.0006
[03:40:36.471] iteration:6752  t-loss:0.7379, loss-lb:0.2933, loss-ulb:0.2223, weight:2.00, lr:0.0006
[03:40:36.794] iteration:6753  t-loss:0.2373, loss-lb:0.1349, loss-ulb:0.0512, weight:2.00, lr:0.0006
[03:40:37.107] iteration:6754  t-loss:0.2666, loss-lb:0.2011, loss-ulb:0.0327, weight:2.00, lr:0.0006
[03:40:37.426] iteration:6755  t-loss:0.4162, loss-lb:0.2631, loss-ulb:0.0766, weight:2.00, lr:0.0006
[03:40:37.749] iteration:6756  t-loss:0.4688, loss-lb:0.2472, loss-ulb:0.1108, weight:2.00, lr:0.0006
[03:40:38.064] iteration:6757  t-loss:0.5454, loss-lb:0.1479, loss-ulb:0.1987, weight:2.00, lr:0.0006
[03:40:38.382] iteration:6758  t-loss:0.5257, loss-lb:0.3132, loss-ulb:0.1063, weight:2.00, lr:0.0006
[03:40:38.696] iteration:6759  t-loss:0.4178, loss-lb:0.1856, loss-ulb:0.1161, weight:2.00, lr:0.0006
[03:40:39.013] iteration:6760  t-loss:0.2634, loss-lb:0.2138, loss-ulb:0.0248, weight:2.00, lr:0.0006
[03:40:39.331] iteration:6761  t-loss:0.3440, loss-lb:0.2413, loss-ulb:0.0513, weight:2.00, lr:0.0006
[03:40:39.647] iteration:6762  t-loss:0.4075, loss-lb:0.1689, loss-ulb:0.1193, weight:2.00, lr:0.0006
[03:40:39.966] iteration:6763  t-loss:0.6751, loss-lb:0.2161, loss-ulb:0.2295, weight:2.00, lr:0.0006
[03:40:40.282] iteration:6764  t-loss:0.6203, loss-lb:0.2013, loss-ulb:0.2095, weight:2.00, lr:0.0006
[03:40:40.610] iteration:6765  t-loss:0.6391, loss-lb:0.2193, loss-ulb:0.2099, weight:2.00, lr:0.0006
[03:40:40.926] iteration:6766  t-loss:0.3276, loss-lb:0.2606, loss-ulb:0.0335, weight:2.00, lr:0.0006
[03:40:41.247] iteration:6767  t-loss:0.1866, loss-lb:0.1148, loss-ulb:0.0359, weight:2.00, lr:0.0006
[03:40:41.562] iteration:6768  t-loss:0.5039, loss-lb:0.1950, loss-ulb:0.1545, weight:2.00, lr:0.0006
[03:40:41.878] iteration:6769  t-loss:0.5483, loss-lb:0.2149, loss-ulb:0.1667, weight:2.00, lr:0.0006
[03:40:42.192] iteration:6770  t-loss:0.1946, loss-lb:0.1546, loss-ulb:0.0200, weight:2.00, lr:0.0006
[03:40:42.510] iteration:6771  t-loss:0.3360, loss-lb:0.2820, loss-ulb:0.0270, weight:2.00, lr:0.0006
[03:40:42.827] iteration:6772  t-loss:0.5388, loss-lb:0.3554, loss-ulb:0.0917, weight:2.00, lr:0.0006
[03:40:43.141] iteration:6773  t-loss:0.1889, loss-lb:0.1545, loss-ulb:0.0172, weight:2.00, lr:0.0006
[03:40:43.459] iteration:6774  t-loss:0.3415, loss-lb:0.2196, loss-ulb:0.0610, weight:2.00, lr:0.0006
[03:40:43.778] iteration:6775  t-loss:0.4946, loss-lb:0.1869, loss-ulb:0.1538, weight:2.00, lr:0.0006
[03:40:45.115] iteration:6776  t-loss:0.5999, loss-lb:0.2790, loss-ulb:0.1604, weight:2.00, lr:0.0006
[03:40:45.438] iteration:6777  t-loss:0.1782, loss-lb:0.1357, loss-ulb:0.0213, weight:2.00, lr:0.0006
[03:40:45.766] iteration:6778  t-loss:0.2816, loss-lb:0.2254, loss-ulb:0.0281, weight:2.00, lr:0.0006
[03:40:46.087] iteration:6779  t-loss:0.4250, loss-lb:0.1802, loss-ulb:0.1224, weight:2.00, lr:0.0006
[03:40:46.406] iteration:6780  t-loss:0.4269, loss-lb:0.3278, loss-ulb:0.0496, weight:2.00, lr:0.0006
[03:40:46.732] iteration:6781  t-loss:0.2731, loss-lb:0.2278, loss-ulb:0.0226, weight:2.00, lr:0.0006
[03:40:47.054] iteration:6782  t-loss:0.4250, loss-lb:0.3759, loss-ulb:0.0245, weight:2.00, lr:0.0006
[03:40:47.377] iteration:6783  t-loss:0.3722, loss-lb:0.2363, loss-ulb:0.0680, weight:2.00, lr:0.0006
[03:40:47.693] iteration:6784  t-loss:0.4743, loss-lb:0.4314, loss-ulb:0.0214, weight:2.00, lr:0.0006
[03:40:48.008] iteration:6785  t-loss:0.3872, loss-lb:0.3252, loss-ulb:0.0310, weight:2.00, lr:0.0006
[03:40:48.327] iteration:6786  t-loss:0.3883, loss-lb:0.1590, loss-ulb:0.1146, weight:2.00, lr:0.0006
[03:40:48.650] iteration:6787  t-loss:0.2829, loss-lb:0.2452, loss-ulb:0.0188, weight:2.00, lr:0.0006
[03:40:48.964] iteration:6788  t-loss:0.3850, loss-lb:0.1611, loss-ulb:0.1119, weight:2.00, lr:0.0006
[03:40:49.281] iteration:6789  t-loss:0.3311, loss-lb:0.2064, loss-ulb:0.0623, weight:2.00, lr:0.0006
[03:40:49.602] iteration:6790  t-loss:0.6396, loss-lb:0.2760, loss-ulb:0.1818, weight:2.00, lr:0.0006
[03:40:49.919] iteration:6791  t-loss:0.3808, loss-lb:0.1735, loss-ulb:0.1036, weight:2.00, lr:0.0006
[03:40:50.236] iteration:6792  t-loss:0.4683, loss-lb:0.1681, loss-ulb:0.1501, weight:2.00, lr:0.0006
[03:40:50.550] iteration:6793  t-loss:0.3647, loss-lb:0.2054, loss-ulb:0.0797, weight:2.00, lr:0.0006
[03:40:50.864] iteration:6794  t-loss:0.3963, loss-lb:0.2035, loss-ulb:0.0964, weight:2.00, lr:0.0006
[03:40:51.176] iteration:6795  t-loss:0.1861, loss-lb:0.1332, loss-ulb:0.0264, weight:2.00, lr:0.0006
[03:40:51.490] iteration:6796  t-loss:0.5200, loss-lb:0.1807, loss-ulb:0.1697, weight:2.00, lr:0.0006
[03:40:51.807] iteration:6797  t-loss:0.4692, loss-lb:0.2735, loss-ulb:0.0979, weight:2.00, lr:0.0006
[03:40:52.123] iteration:6798  t-loss:0.8936, loss-lb:0.5053, loss-ulb:0.1941, weight:2.00, lr:0.0006
[03:40:52.437] iteration:6799  t-loss:0.2530, loss-lb:0.2141, loss-ulb:0.0195, weight:2.00, lr:0.0006
[03:40:52.753] iteration:6800  t-loss:0.2196, loss-lb:0.1650, loss-ulb:0.0273, weight:2.00, lr:0.0006
[03:40:53.737] iteration:6801  t-loss:0.2036, loss-lb:0.1650, loss-ulb:0.0193, weight:2.00, lr:0.0006
[03:40:54.081] iteration:6802  t-loss:0.6094, loss-lb:0.2442, loss-ulb:0.1826, weight:2.00, lr:0.0006
[03:40:54.411] iteration:6803  t-loss:0.5023, loss-lb:0.2570, loss-ulb:0.1226, weight:2.00, lr:0.0006
[03:40:54.728] iteration:6804  t-loss:0.3358, loss-lb:0.1924, loss-ulb:0.0717, weight:2.00, lr:0.0006
[03:40:55.047] iteration:6805  t-loss:0.4091, loss-lb:0.1824, loss-ulb:0.1133, weight:2.00, lr:0.0006
[03:40:55.367] iteration:6806  t-loss:0.4407, loss-lb:0.2372, loss-ulb:0.1017, weight:2.00, lr:0.0006
[03:40:55.686] iteration:6807  t-loss:0.6980, loss-lb:0.5617, loss-ulb:0.0681, weight:2.00, lr:0.0006
[03:40:56.000] iteration:6808  t-loss:0.2504, loss-lb:0.1556, loss-ulb:0.0474, weight:2.00, lr:0.0006
[03:40:56.320] iteration:6809  t-loss:0.2745, loss-lb:0.2108, loss-ulb:0.0319, weight:2.00, lr:0.0006
[03:40:56.651] iteration:6810  t-loss:0.4331, loss-lb:0.2392, loss-ulb:0.0970, weight:2.00, lr:0.0006
[03:40:57.045] iteration:6811  t-loss:0.4418, loss-lb:0.1501, loss-ulb:0.1458, weight:2.00, lr:0.0006
[03:40:57.359] iteration:6812  t-loss:0.2874, loss-lb:0.2429, loss-ulb:0.0222, weight:2.00, lr:0.0006
[03:40:57.677] iteration:6813  t-loss:0.4431, loss-lb:0.2132, loss-ulb:0.1150, weight:2.00, lr:0.0006
[03:40:57.996] iteration:6814  t-loss:0.4074, loss-lb:0.2326, loss-ulb:0.0874, weight:2.00, lr:0.0006
[03:40:58.317] iteration:6815  t-loss:0.3589, loss-lb:0.2819, loss-ulb:0.0385, weight:2.00, lr:0.0006
[03:40:58.633] iteration:6816  t-loss:0.3400, loss-lb:0.2312, loss-ulb:0.0544, weight:2.00, lr:0.0006
[03:40:58.953] iteration:6817  t-loss:0.3537, loss-lb:0.1755, loss-ulb:0.0891, weight:2.00, lr:0.0006
[03:40:59.269] iteration:6818  t-loss:0.4117, loss-lb:0.1309, loss-ulb:0.1404, weight:2.00, lr:0.0006
[03:40:59.584] iteration:6819  t-loss:0.4095, loss-lb:0.3576, loss-ulb:0.0260, weight:2.00, lr:0.0006
[03:40:59.898] iteration:6820  t-loss:0.3156, loss-lb:0.2208, loss-ulb:0.0474, weight:2.00, lr:0.0006
[03:41:00.216] iteration:6821  t-loss:0.4143, loss-lb:0.2463, loss-ulb:0.0840, weight:2.00, lr:0.0006
[03:41:00.529] iteration:6822  t-loss:0.3115, loss-lb:0.2747, loss-ulb:0.0184, weight:2.00, lr:0.0006
[03:41:00.844] iteration:6823  t-loss:0.4412, loss-lb:0.1543, loss-ulb:0.1434, weight:2.00, lr:0.0006
[03:41:01.161] iteration:6824  t-loss:0.5350, loss-lb:0.2278, loss-ulb:0.1536, weight:2.00, lr:0.0006
[03:41:01.474] iteration:6825  t-loss:0.2355, loss-lb:0.1594, loss-ulb:0.0380, weight:2.00, lr:0.0006
[03:42:58.567] iteration 6825 : dice_score: 0.844810 best_dice: 0.846000
[03:42:58.567]  <<Test>> - Ep:272  - Dice-S/T:83.83/84.48, Best-S:84.07, Best-T:84.60
[03:42:58.567]           - AvgLoss(lb/ulb/all):0.23/0.08/0.39
[03:42:59.813] iteration:6826  t-loss:0.3952, loss-lb:0.1732, loss-ulb:0.1110, weight:2.00, lr:0.0006
[03:43:00.152] iteration:6827  t-loss:0.3419, loss-lb:0.1875, loss-ulb:0.0772, weight:2.00, lr:0.0006
[03:43:00.476] iteration:6828  t-loss:0.2211, loss-lb:0.1432, loss-ulb:0.0390, weight:2.00, lr:0.0006
[03:43:00.807] iteration:6829  t-loss:0.5872, loss-lb:0.1310, loss-ulb:0.2281, weight:2.00, lr:0.0006
[03:43:01.130] iteration:6830  t-loss:0.5625, loss-lb:0.3901, loss-ulb:0.0862, weight:2.00, lr:0.0006
[03:43:01.453] iteration:6831  t-loss:0.3688, loss-lb:0.3037, loss-ulb:0.0325, weight:2.00, lr:0.0006
[03:43:01.768] iteration:6832  t-loss:0.5241, loss-lb:0.3440, loss-ulb:0.0900, weight:2.00, lr:0.0006
[03:43:02.087] iteration:6833  t-loss:0.2971, loss-lb:0.2362, loss-ulb:0.0304, weight:2.00, lr:0.0006
[03:43:02.411] iteration:6834  t-loss:0.4574, loss-lb:0.1820, loss-ulb:0.1377, weight:2.00, lr:0.0006
[03:43:02.728] iteration:6835  t-loss:0.4310, loss-lb:0.1946, loss-ulb:0.1182, weight:2.00, lr:0.0006
[03:43:03.043] iteration:6836  t-loss:0.2453, loss-lb:0.1833, loss-ulb:0.0310, weight:2.00, lr:0.0006
[03:43:03.364] iteration:6837  t-loss:0.2642, loss-lb:0.1369, loss-ulb:0.0637, weight:2.00, lr:0.0006
[03:43:03.686] iteration:6838  t-loss:0.2471, loss-lb:0.1901, loss-ulb:0.0285, weight:2.00, lr:0.0006
[03:43:04.008] iteration:6839  t-loss:0.4174, loss-lb:0.1430, loss-ulb:0.1372, weight:2.00, lr:0.0006
[03:43:04.323] iteration:6840  t-loss:0.3508, loss-lb:0.2135, loss-ulb:0.0687, weight:2.00, lr:0.0006
[03:43:04.650] iteration:6841  t-loss:0.4261, loss-lb:0.2746, loss-ulb:0.0758, weight:2.00, lr:0.0006
[03:43:04.968] iteration:6842  t-loss:0.5098, loss-lb:0.3209, loss-ulb:0.0944, weight:2.00, lr:0.0006
[03:43:05.283] iteration:6843  t-loss:0.4007, loss-lb:0.2154, loss-ulb:0.0926, weight:2.00, lr:0.0006
[03:43:05.599] iteration:6844  t-loss:0.6182, loss-lb:0.5417, loss-ulb:0.0383, weight:2.00, lr:0.0006
[03:43:05.914] iteration:6845  t-loss:0.5652, loss-lb:0.2404, loss-ulb:0.1624, weight:2.00, lr:0.0006
[03:43:06.226] iteration:6846  t-loss:0.3290, loss-lb:0.2120, loss-ulb:0.0585, weight:2.00, lr:0.0006
[03:43:06.541] iteration:6847  t-loss:0.4891, loss-lb:0.2846, loss-ulb:0.1022, weight:2.00, lr:0.0006
[03:43:06.856] iteration:6848  t-loss:0.4606, loss-lb:0.2723, loss-ulb:0.0942, weight:2.00, lr:0.0006
[03:43:07.170] iteration:6849  t-loss:0.3342, loss-lb:0.2149, loss-ulb:0.0596, weight:2.00, lr:0.0006
[03:43:07.486] iteration:6850  t-loss:0.4092, loss-lb:0.2605, loss-ulb:0.0744, weight:2.00, lr:0.0006
[03:43:08.892] iteration:6851  t-loss:0.2567, loss-lb:0.1795, loss-ulb:0.0386, weight:2.00, lr:0.0006
[03:43:09.220] iteration:6852  t-loss:0.4052, loss-lb:0.1393, loss-ulb:0.1329, weight:2.00, lr:0.0006
[03:43:09.545] iteration:6853  t-loss:0.2164, loss-lb:0.1598, loss-ulb:0.0283, weight:2.00, lr:0.0006
[03:43:09.857] iteration:6854  t-loss:0.4431, loss-lb:0.1556, loss-ulb:0.1438, weight:2.00, lr:0.0006
[03:43:10.173] iteration:6855  t-loss:0.3912, loss-lb:0.3337, loss-ulb:0.0288, weight:2.00, lr:0.0006
[03:43:10.489] iteration:6856  t-loss:0.2378, loss-lb:0.1871, loss-ulb:0.0253, weight:2.00, lr:0.0006
[03:43:10.805] iteration:6857  t-loss:0.3681, loss-lb:0.1811, loss-ulb:0.0935, weight:2.00, lr:0.0006
[03:43:11.122] iteration:6858  t-loss:0.4237, loss-lb:0.2177, loss-ulb:0.1030, weight:2.00, lr:0.0006
[03:43:11.440] iteration:6859  t-loss:0.3530, loss-lb:0.2944, loss-ulb:0.0293, weight:2.00, lr:0.0006
[03:43:11.760] iteration:6860  t-loss:0.3551, loss-lb:0.1770, loss-ulb:0.0890, weight:2.00, lr:0.0006
[03:43:12.075] iteration:6861  t-loss:0.2317, loss-lb:0.1419, loss-ulb:0.0449, weight:2.00, lr:0.0006
[03:43:12.398] iteration:6862  t-loss:0.4049, loss-lb:0.1755, loss-ulb:0.1147, weight:2.00, lr:0.0006
[03:43:12.721] iteration:6863  t-loss:0.2409, loss-lb:0.1596, loss-ulb:0.0407, weight:2.00, lr:0.0006
[03:43:13.053] iteration:6864  t-loss:0.6842, loss-lb:0.3305, loss-ulb:0.1769, weight:2.00, lr:0.0006
[03:43:13.376] iteration:6865  t-loss:0.3951, loss-lb:0.2393, loss-ulb:0.0779, weight:2.00, lr:0.0006
[03:43:13.695] iteration:6866  t-loss:0.3336, loss-lb:0.1433, loss-ulb:0.0951, weight:2.00, lr:0.0006
[03:43:14.021] iteration:6867  t-loss:0.6843, loss-lb:0.3284, loss-ulb:0.1780, weight:2.00, lr:0.0006
[03:43:14.338] iteration:6868  t-loss:0.2890, loss-lb:0.1595, loss-ulb:0.0648, weight:2.00, lr:0.0006
[03:43:14.653] iteration:6869  t-loss:0.4468, loss-lb:0.1830, loss-ulb:0.1319, weight:2.00, lr:0.0006
[03:43:14.965] iteration:6870  t-loss:0.2286, loss-lb:0.1422, loss-ulb:0.0432, weight:2.00, lr:0.0006
[03:43:15.282] iteration:6871  t-loss:0.4709, loss-lb:0.2020, loss-ulb:0.1344, weight:2.00, lr:0.0006
[03:43:15.600] iteration:6872  t-loss:0.4111, loss-lb:0.2742, loss-ulb:0.0684, weight:2.00, lr:0.0006
[03:43:15.914] iteration:6873  t-loss:0.3304, loss-lb:0.1699, loss-ulb:0.0802, weight:2.00, lr:0.0006
[03:43:16.228] iteration:6874  t-loss:0.2333, loss-lb:0.1742, loss-ulb:0.0296, weight:2.00, lr:0.0006
[03:43:16.544] iteration:6875  t-loss:0.4078, loss-lb:0.2364, loss-ulb:0.0857, weight:2.00, lr:0.0006
[03:43:17.738] iteration:6876  t-loss:0.5574, loss-lb:0.1943, loss-ulb:0.1815, weight:2.00, lr:0.0006
[03:43:18.066] iteration:6877  t-loss:0.3932, loss-lb:0.1977, loss-ulb:0.0978, weight:2.00, lr:0.0006
[03:43:18.391] iteration:6878  t-loss:0.1682, loss-lb:0.1301, loss-ulb:0.0191, weight:2.00, lr:0.0006
[03:43:18.705] iteration:6879  t-loss:0.2358, loss-lb:0.1970, loss-ulb:0.0194, weight:2.00, lr:0.0006
[03:43:19.027] iteration:6880  t-loss:0.3071, loss-lb:0.2398, loss-ulb:0.0337, weight:2.00, lr:0.0006
[03:43:19.345] iteration:6881  t-loss:0.2489, loss-lb:0.2053, loss-ulb:0.0218, weight:2.00, lr:0.0006
[03:43:19.668] iteration:6882  t-loss:0.4596, loss-lb:0.2864, loss-ulb:0.0866, weight:2.00, lr:0.0006
[03:43:19.983] iteration:6883  t-loss:0.3447, loss-lb:0.1919, loss-ulb:0.0764, weight:2.00, lr:0.0006
[03:43:20.304] iteration:6884  t-loss:0.4076, loss-lb:0.2702, loss-ulb:0.0687, weight:2.00, lr:0.0006
[03:43:20.619] iteration:6885  t-loss:0.5265, loss-lb:0.1503, loss-ulb:0.1881, weight:2.00, lr:0.0006
[03:43:20.942] iteration:6886  t-loss:0.4944, loss-lb:0.2809, loss-ulb:0.1067, weight:2.00, lr:0.0006
[03:43:21.259] iteration:6887  t-loss:0.3930, loss-lb:0.1340, loss-ulb:0.1295, weight:2.00, lr:0.0006
[03:43:21.579] iteration:6888  t-loss:0.3012, loss-lb:0.1588, loss-ulb:0.0712, weight:2.00, lr:0.0006
[03:43:21.898] iteration:6889  t-loss:0.3755, loss-lb:0.3475, loss-ulb:0.0140, weight:2.00, lr:0.0006
[03:43:22.217] iteration:6890  t-loss:0.3485, loss-lb:0.1852, loss-ulb:0.0816, weight:2.00, lr:0.0006
[03:43:22.533] iteration:6891  t-loss:0.3291, loss-lb:0.1330, loss-ulb:0.0981, weight:2.00, lr:0.0006
[03:43:22.849] iteration:6892  t-loss:0.2319, loss-lb:0.1750, loss-ulb:0.0285, weight:2.00, lr:0.0006
[03:43:23.163] iteration:6893  t-loss:0.4471, loss-lb:0.1398, loss-ulb:0.1536, weight:2.00, lr:0.0006
[03:43:23.478] iteration:6894  t-loss:0.5687, loss-lb:0.2029, loss-ulb:0.1829, weight:2.00, lr:0.0006
[03:43:23.794] iteration:6895  t-loss:0.4375, loss-lb:0.2350, loss-ulb:0.1012, weight:2.00, lr:0.0006
[03:43:24.111] iteration:6896  t-loss:0.4825, loss-lb:0.3178, loss-ulb:0.0823, weight:2.00, lr:0.0006
[03:43:24.425] iteration:6897  t-loss:0.2233, loss-lb:0.1805, loss-ulb:0.0214, weight:2.00, lr:0.0006
[03:43:24.740] iteration:6898  t-loss:0.4374, loss-lb:0.3805, loss-ulb:0.0285, weight:2.00, lr:0.0006
[03:43:25.056] iteration:6899  t-loss:0.4555, loss-lb:0.1805, loss-ulb:0.1375, weight:2.00, lr:0.0006
[03:43:25.370] iteration:6900  t-loss:0.1822, loss-lb:0.1256, loss-ulb:0.0283, weight:2.00, lr:0.0006
[03:43:26.469] iteration:6901  t-loss:0.3396, loss-lb:0.1887, loss-ulb:0.0755, weight:2.00, lr:0.0006
[03:43:26.806] iteration:6902  t-loss:0.3628, loss-lb:0.2536, loss-ulb:0.0546, weight:2.00, lr:0.0006
[03:43:27.136] iteration:6903  t-loss:0.3864, loss-lb:0.1834, loss-ulb:0.1015, weight:2.00, lr:0.0006
[03:43:27.455] iteration:6904  t-loss:0.2502, loss-lb:0.1787, loss-ulb:0.0357, weight:2.00, lr:0.0006
[03:43:27.773] iteration:6905  t-loss:0.5134, loss-lb:0.2027, loss-ulb:0.1553, weight:2.00, lr:0.0006
[03:43:28.094] iteration:6906  t-loss:0.5324, loss-lb:0.2938, loss-ulb:0.1193, weight:2.00, lr:0.0006
[03:43:28.409] iteration:6907  t-loss:0.2093, loss-lb:0.1732, loss-ulb:0.0181, weight:2.00, lr:0.0006
[03:43:28.735] iteration:6908  t-loss:0.2509, loss-lb:0.2095, loss-ulb:0.0207, weight:2.00, lr:0.0006
[03:43:29.054] iteration:6909  t-loss:0.5209, loss-lb:0.3586, loss-ulb:0.0811, weight:2.00, lr:0.0006
[03:43:29.372] iteration:6910  t-loss:0.2203, loss-lb:0.1720, loss-ulb:0.0241, weight:2.00, lr:0.0006
[03:43:29.688] iteration:6911  t-loss:1.2653, loss-lb:0.1597, loss-ulb:0.5528, weight:2.00, lr:0.0006
[03:43:30.010] iteration:6912  t-loss:0.4617, loss-lb:0.3035, loss-ulb:0.0791, weight:2.00, lr:0.0006
[03:43:30.330] iteration:6913  t-loss:0.4616, loss-lb:0.1176, loss-ulb:0.1720, weight:2.00, lr:0.0006
[03:43:30.648] iteration:6914  t-loss:0.2593, loss-lb:0.2171, loss-ulb:0.0211, weight:2.00, lr:0.0006
[03:43:30.970] iteration:6915  t-loss:0.4181, loss-lb:0.2218, loss-ulb:0.0981, weight:2.00, lr:0.0006
[03:43:31.292] iteration:6916  t-loss:0.6492, loss-lb:0.3317, loss-ulb:0.1587, weight:2.00, lr:0.0006
[03:43:31.615] iteration:6917  t-loss:0.5196, loss-lb:0.1843, loss-ulb:0.1676, weight:2.00, lr:0.0006
[03:43:31.929] iteration:6918  t-loss:0.2162, loss-lb:0.1790, loss-ulb:0.0186, weight:2.00, lr:0.0006
[03:43:32.249] iteration:6919  t-loss:0.4940, loss-lb:0.2603, loss-ulb:0.1168, weight:2.00, lr:0.0006
[03:43:32.569] iteration:6920  t-loss:0.5691, loss-lb:0.3414, loss-ulb:0.1138, weight:2.00, lr:0.0006
[03:43:32.884] iteration:6921  t-loss:0.4233, loss-lb:0.1468, loss-ulb:0.1382, weight:2.00, lr:0.0006
[03:43:33.198] iteration:6922  t-loss:0.1947, loss-lb:0.1365, loss-ulb:0.0291, weight:2.00, lr:0.0006
[03:43:33.515] iteration:6923  t-loss:0.5254, loss-lb:0.1610, loss-ulb:0.1822, weight:2.00, lr:0.0006
[03:43:33.831] iteration:6924  t-loss:0.4141, loss-lb:0.1823, loss-ulb:0.1159, weight:2.00, lr:0.0006
[03:43:34.146] iteration:6925  t-loss:0.5239, loss-lb:0.1745, loss-ulb:0.1747, weight:2.00, lr:0.0006
[03:45:37.009] iteration 6925 : dice_score: 0.844614 best_dice: 0.846000
[03:45:37.009]  <<Test>> - Ep:276  - Dice-S/T:83.69/84.46, Best-S:84.07, Best-T:84.60
[03:45:37.009]           - AvgLoss(lb/ulb/all):0.21/0.12/0.46
[03:45:38.448] iteration:6926  t-loss:0.2926, loss-lb:0.2516, loss-ulb:0.0205, weight:2.00, lr:0.0006
[03:45:38.797] iteration:6927  t-loss:0.7197, loss-lb:0.2031, loss-ulb:0.2583, weight:2.00, lr:0.0006
[03:45:39.126] iteration:6928  t-loss:0.5099, loss-lb:0.1447, loss-ulb:0.1826, weight:2.00, lr:0.0006
[03:45:39.440] iteration:6929  t-loss:0.3503, loss-lb:0.1803, loss-ulb:0.0850, weight:2.00, lr:0.0006
[03:45:39.756] iteration:6930  t-loss:0.4719, loss-lb:0.2685, loss-ulb:0.1017, weight:2.00, lr:0.0006
[03:45:40.069] iteration:6931  t-loss:0.5245, loss-lb:0.1675, loss-ulb:0.1785, weight:2.00, lr:0.0006
[03:45:40.390] iteration:6932  t-loss:0.4341, loss-lb:0.2030, loss-ulb:0.1155, weight:2.00, lr:0.0006
[03:45:40.710] iteration:6933  t-loss:0.6330, loss-lb:0.2327, loss-ulb:0.2002, weight:2.00, lr:0.0006
[03:45:41.031] iteration:6934  t-loss:0.4025, loss-lb:0.2360, loss-ulb:0.0833, weight:2.00, lr:0.0006
[03:45:41.364] iteration:6935  t-loss:0.6258, loss-lb:0.3474, loss-ulb:0.1392, weight:2.00, lr:0.0006
[03:45:41.707] iteration:6936  t-loss:0.7539, loss-lb:0.2517, loss-ulb:0.2511, weight:2.00, lr:0.0006
[03:45:42.054] iteration:6937  t-loss:0.2013, loss-lb:0.1505, loss-ulb:0.0254, weight:2.00, lr:0.0006
[03:45:42.402] iteration:6938  t-loss:0.3635, loss-lb:0.1921, loss-ulb:0.0857, weight:2.00, lr:0.0006
[03:45:42.752] iteration:6939  t-loss:0.3912, loss-lb:0.2051, loss-ulb:0.0931, weight:2.00, lr:0.0006
[03:45:43.093] iteration:6940  t-loss:0.5976, loss-lb:0.2984, loss-ulb:0.1496, weight:2.00, lr:0.0006
[03:45:43.431] iteration:6941  t-loss:0.2004, loss-lb:0.1533, loss-ulb:0.0236, weight:2.00, lr:0.0006
[03:45:43.756] iteration:6942  t-loss:0.3296, loss-lb:0.2327, loss-ulb:0.0485, weight:2.00, lr:0.0006
[03:45:44.072] iteration:6943  t-loss:0.2641, loss-lb:0.1889, loss-ulb:0.0376, weight:2.00, lr:0.0006
[03:45:44.387] iteration:6944  t-loss:0.5256, loss-lb:0.1474, loss-ulb:0.1891, weight:2.00, lr:0.0006
[03:45:44.702] iteration:6945  t-loss:0.2362, loss-lb:0.1802, loss-ulb:0.0280, weight:2.00, lr:0.0006
[03:45:45.019] iteration:6946  t-loss:0.4684, loss-lb:0.2694, loss-ulb:0.0995, weight:2.00, lr:0.0006
[03:45:45.337] iteration:6947  t-loss:0.7642, loss-lb:0.1745, loss-ulb:0.2948, weight:2.00, lr:0.0006
[03:45:45.654] iteration:6948  t-loss:0.2599, loss-lb:0.2069, loss-ulb:0.0265, weight:2.00, lr:0.0006
[03:45:45.971] iteration:6949  t-loss:0.2695, loss-lb:0.1642, loss-ulb:0.0526, weight:2.00, lr:0.0006
[03:45:46.287] iteration:6950  t-loss:0.3081, loss-lb:0.2103, loss-ulb:0.0489, weight:2.00, lr:0.0006
[03:45:47.717] iteration:6951  t-loss:0.4249, loss-lb:0.1536, loss-ulb:0.1357, weight:2.00, lr:0.0006
[03:45:48.047] iteration:6952  t-loss:0.6302, loss-lb:0.4072, loss-ulb:0.1115, weight:2.00, lr:0.0006
[03:45:48.365] iteration:6953  t-loss:0.4005, loss-lb:0.2900, loss-ulb:0.0552, weight:2.00, lr:0.0006
[03:45:48.679] iteration:6954  t-loss:0.5506, loss-lb:0.1639, loss-ulb:0.1934, weight:2.00, lr:0.0006
[03:45:48.993] iteration:6955  t-loss:0.3672, loss-lb:0.2043, loss-ulb:0.0815, weight:2.00, lr:0.0006
[03:45:49.309] iteration:6956  t-loss:0.4279, loss-lb:0.1930, loss-ulb:0.1175, weight:2.00, lr:0.0006
[03:45:49.623] iteration:6957  t-loss:0.3843, loss-lb:0.1657, loss-ulb:0.1093, weight:2.00, lr:0.0006
[03:45:49.942] iteration:6958  t-loss:0.4039, loss-lb:0.2012, loss-ulb:0.1013, weight:2.00, lr:0.0006
[03:45:50.268] iteration:6959  t-loss:0.2534, loss-lb:0.1728, loss-ulb:0.0403, weight:2.00, lr:0.0006
[03:45:50.595] iteration:6960  t-loss:0.4328, loss-lb:0.2211, loss-ulb:0.1058, weight:2.00, lr:0.0006
[03:45:50.929] iteration:6961  t-loss:0.3579, loss-lb:0.2323, loss-ulb:0.0628, weight:2.00, lr:0.0006
[03:45:51.264] iteration:6962  t-loss:0.3313, loss-lb:0.2579, loss-ulb:0.0367, weight:2.00, lr:0.0006
[03:45:51.594] iteration:6963  t-loss:0.4886, loss-lb:0.1603, loss-ulb:0.1641, weight:2.00, lr:0.0006
[03:45:51.915] iteration:6964  t-loss:0.3551, loss-lb:0.1863, loss-ulb:0.0844, weight:2.00, lr:0.0006
[03:45:52.236] iteration:6965  t-loss:0.6011, loss-lb:0.2330, loss-ulb:0.1840, weight:2.00, lr:0.0006
[03:45:52.564] iteration:6966  t-loss:0.3565, loss-lb:0.2547, loss-ulb:0.0509, weight:2.00, lr:0.0006
[03:45:52.881] iteration:6967  t-loss:0.3238, loss-lb:0.1810, loss-ulb:0.0714, weight:2.00, lr:0.0006
[03:45:53.202] iteration:6968  t-loss:0.2705, loss-lb:0.1679, loss-ulb:0.0513, weight:2.00, lr:0.0006
[03:45:53.528] iteration:6969  t-loss:0.8013, loss-lb:0.1746, loss-ulb:0.3134, weight:2.00, lr:0.0006
[03:45:53.848] iteration:6970  t-loss:0.3385, loss-lb:0.1550, loss-ulb:0.0917, weight:2.00, lr:0.0006
[03:45:54.164] iteration:6971  t-loss:0.2859, loss-lb:0.1516, loss-ulb:0.0671, weight:2.00, lr:0.0006
[03:45:54.492] iteration:6972  t-loss:0.6787, loss-lb:0.3553, loss-ulb:0.1617, weight:2.00, lr:0.0006
[03:45:54.817] iteration:6973  t-loss:0.3502, loss-lb:0.2786, loss-ulb:0.0358, weight:2.00, lr:0.0006
[03:45:55.137] iteration:6974  t-loss:0.2981, loss-lb:0.2168, loss-ulb:0.0406, weight:2.00, lr:0.0006
[03:45:55.462] iteration:6975  t-loss:0.6608, loss-lb:0.4520, loss-ulb:0.1044, weight:2.00, lr:0.0006
[03:45:57.015] iteration:6976  t-loss:0.4100, loss-lb:0.1933, loss-ulb:0.1084, weight:2.00, lr:0.0006
[03:45:57.370] iteration:6977  t-loss:0.4112, loss-lb:0.3358, loss-ulb:0.0377, weight:2.00, lr:0.0006
[03:45:57.707] iteration:6978  t-loss:0.4391, loss-lb:0.3778, loss-ulb:0.0307, weight:2.00, lr:0.0006
[03:45:58.023] iteration:6979  t-loss:0.2843, loss-lb:0.2126, loss-ulb:0.0358, weight:2.00, lr:0.0006
[03:45:58.341] iteration:6980  t-loss:0.3646, loss-lb:0.1663, loss-ulb:0.0991, weight:2.00, lr:0.0006
[03:45:58.657] iteration:6981  t-loss:0.6915, loss-lb:0.6138, loss-ulb:0.0388, weight:2.00, lr:0.0006
[03:45:58.981] iteration:6982  t-loss:0.4673, loss-lb:0.1747, loss-ulb:0.1463, weight:2.00, lr:0.0006
[03:45:59.301] iteration:6983  t-loss:0.3050, loss-lb:0.2322, loss-ulb:0.0364, weight:2.00, lr:0.0006
[03:45:59.622] iteration:6984  t-loss:0.3447, loss-lb:0.2808, loss-ulb:0.0319, weight:2.00, lr:0.0006
[03:45:59.947] iteration:6985  t-loss:0.3372, loss-lb:0.2006, loss-ulb:0.0683, weight:2.00, lr:0.0006
[03:46:00.268] iteration:6986  t-loss:0.9079, loss-lb:0.5253, loss-ulb:0.1913, weight:2.00, lr:0.0006
[03:46:00.590] iteration:6987  t-loss:0.2344, loss-lb:0.1687, loss-ulb:0.0329, weight:2.00, lr:0.0006
[03:46:00.912] iteration:6988  t-loss:0.3309, loss-lb:0.1903, loss-ulb:0.0703, weight:2.00, lr:0.0006
[03:46:01.249] iteration:6989  t-loss:0.4170, loss-lb:0.1678, loss-ulb:0.1246, weight:2.00, lr:0.0006
[03:46:01.568] iteration:6990  t-loss:0.3835, loss-lb:0.2935, loss-ulb:0.0450, weight:2.00, lr:0.0006
[03:46:01.884] iteration:6991  t-loss:0.4823, loss-lb:0.1851, loss-ulb:0.1486, weight:2.00, lr:0.0006
[03:46:02.206] iteration:6992  t-loss:0.5565, loss-lb:0.3049, loss-ulb:0.1258, weight:2.00, lr:0.0006
[03:46:02.524] iteration:6993  t-loss:0.5620, loss-lb:0.3143, loss-ulb:0.1238, weight:2.00, lr:0.0006
[03:46:02.841] iteration:6994  t-loss:0.3587, loss-lb:0.1845, loss-ulb:0.0871, weight:2.00, lr:0.0006
[03:46:03.159] iteration:6995  t-loss:0.3302, loss-lb:0.2819, loss-ulb:0.0242, weight:2.00, lr:0.0006
[03:46:03.476] iteration:6996  t-loss:0.4019, loss-lb:0.2152, loss-ulb:0.0934, weight:2.00, lr:0.0006
[03:46:03.791] iteration:6997  t-loss:0.2909, loss-lb:0.1408, loss-ulb:0.0750, weight:2.00, lr:0.0006
[03:46:04.105] iteration:6998  t-loss:0.3093, loss-lb:0.2562, loss-ulb:0.0266, weight:2.00, lr:0.0006
[03:46:04.420] iteration:6999  t-loss:0.2416, loss-lb:0.2027, loss-ulb:0.0194, weight:2.00, lr:0.0006
[03:46:04.737] iteration:7000  t-loss:0.3451, loss-lb:0.2373, loss-ulb:0.0539, weight:2.00, lr:0.0006
[03:46:06.050] iteration:7001  t-loss:0.4838, loss-lb:0.2223, loss-ulb:0.1308, weight:2.00, lr:0.0006
[03:46:06.385] iteration:7002  t-loss:0.4820, loss-lb:0.1839, loss-ulb:0.1490, weight:2.00, lr:0.0006
[03:46:06.722] iteration:7003  t-loss:0.2275, loss-lb:0.1486, loss-ulb:0.0394, weight:2.00, lr:0.0006
[03:46:07.061] iteration:7004  t-loss:0.2612, loss-lb:0.1983, loss-ulb:0.0314, weight:2.00, lr:0.0006
[03:46:07.397] iteration:7005  t-loss:0.2264, loss-lb:0.1580, loss-ulb:0.0342, weight:2.00, lr:0.0006
[03:46:07.735] iteration:7006  t-loss:0.6323, loss-lb:0.3641, loss-ulb:0.1341, weight:2.00, lr:0.0006
[03:46:08.062] iteration:7007  t-loss:0.5556, loss-lb:0.2363, loss-ulb:0.1596, weight:2.00, lr:0.0006
[03:46:08.398] iteration:7008  t-loss:0.2959, loss-lb:0.2638, loss-ulb:0.0160, weight:2.00, lr:0.0006
[03:46:08.739] iteration:7009  t-loss:0.5734, loss-lb:0.2888, loss-ulb:0.1423, weight:2.00, lr:0.0006
[03:46:09.067] iteration:7010  t-loss:0.7311, loss-lb:0.1986, loss-ulb:0.2663, weight:2.00, lr:0.0006
[03:46:09.398] iteration:7011  t-loss:0.4728, loss-lb:0.2181, loss-ulb:0.1274, weight:2.00, lr:0.0006
[03:46:09.723] iteration:7012  t-loss:0.3793, loss-lb:0.1754, loss-ulb:0.1019, weight:2.00, lr:0.0006
[03:46:10.054] iteration:7013  t-loss:0.2536, loss-lb:0.1738, loss-ulb:0.0399, weight:2.00, lr:0.0006
[03:46:10.378] iteration:7014  t-loss:0.4713, loss-lb:0.3589, loss-ulb:0.0562, weight:2.00, lr:0.0006
[03:46:10.701] iteration:7015  t-loss:0.3120, loss-lb:0.2641, loss-ulb:0.0240, weight:2.00, lr:0.0006
[03:46:11.017] iteration:7016  t-loss:0.1752, loss-lb:0.1425, loss-ulb:0.0164, weight:2.00, lr:0.0006
[03:46:11.332] iteration:7017  t-loss:0.1999, loss-lb:0.1377, loss-ulb:0.0311, weight:2.00, lr:0.0006
[03:46:11.646] iteration:7018  t-loss:0.2365, loss-lb:0.1811, loss-ulb:0.0277, weight:2.00, lr:0.0006
[03:46:11.964] iteration:7019  t-loss:0.3544, loss-lb:0.2328, loss-ulb:0.0608, weight:2.00, lr:0.0006
[03:46:12.282] iteration:7020  t-loss:0.5878, loss-lb:0.3138, loss-ulb:0.1370, weight:2.00, lr:0.0006
[03:46:12.599] iteration:7021  t-loss:0.3281, loss-lb:0.2041, loss-ulb:0.0620, weight:2.00, lr:0.0006
[03:46:12.916] iteration:7022  t-loss:0.5164, loss-lb:0.2687, loss-ulb:0.1238, weight:2.00, lr:0.0006
[03:46:13.235] iteration:7023  t-loss:0.2870, loss-lb:0.2341, loss-ulb:0.0265, weight:2.00, lr:0.0006
[03:46:13.551] iteration:7024  t-loss:0.2138, loss-lb:0.1675, loss-ulb:0.0231, weight:2.00, lr:0.0006
[03:46:13.869] iteration:7025  t-loss:0.3961, loss-lb:0.2840, loss-ulb:0.0560, weight:2.00, lr:0.0006
[03:48:21.835] iteration 7025 : dice_score: 0.842256 best_dice: 0.846000
[03:48:21.835]  <<Test>> - Ep:280  - Dice-S/T:78.84/84.23, Best-S:84.07, Best-T:84.60
[03:48:21.835]           - AvgLoss(lb/ulb/all):0.22/0.08/0.40
[03:48:23.027] iteration:7026  t-loss:0.2784, loss-lb:0.1771, loss-ulb:0.0507, weight:2.00, lr:0.0006
[03:48:23.372] iteration:7027  t-loss:0.3457, loss-lb:0.1705, loss-ulb:0.0876, weight:2.00, lr:0.0006
[03:48:23.715] iteration:7028  t-loss:0.4929, loss-lb:0.1483, loss-ulb:0.1723, weight:2.00, lr:0.0006
[03:48:24.046] iteration:7029  t-loss:0.3101, loss-lb:0.2077, loss-ulb:0.0512, weight:2.00, lr:0.0006
[03:48:24.369] iteration:7030  t-loss:0.4642, loss-lb:0.2710, loss-ulb:0.0966, weight:2.00, lr:0.0006
[03:48:24.695] iteration:7031  t-loss:0.1827, loss-lb:0.1419, loss-ulb:0.0204, weight:2.00, lr:0.0006
[03:48:25.015] iteration:7032  t-loss:0.4244, loss-lb:0.1845, loss-ulb:0.1199, weight:2.00, lr:0.0006
[03:48:25.330] iteration:7033  t-loss:0.3348, loss-lb:0.2755, loss-ulb:0.0296, weight:2.00, lr:0.0006
[03:48:25.644] iteration:7034  t-loss:0.2849, loss-lb:0.2043, loss-ulb:0.0403, weight:2.00, lr:0.0006
[03:48:25.957] iteration:7035  t-loss:0.2886, loss-lb:0.1791, loss-ulb:0.0547, weight:2.00, lr:0.0006
[03:48:26.274] iteration:7036  t-loss:0.6354, loss-lb:0.2511, loss-ulb:0.1921, weight:2.00, lr:0.0006
[03:48:26.587] iteration:7037  t-loss:1.0973, loss-lb:0.1656, loss-ulb:0.4659, weight:2.00, lr:0.0006
[03:48:26.900] iteration:7038  t-loss:0.4627, loss-lb:0.1925, loss-ulb:0.1351, weight:2.00, lr:0.0006
[03:48:27.214] iteration:7039  t-loss:0.2846, loss-lb:0.2411, loss-ulb:0.0217, weight:2.00, lr:0.0006
[03:48:27.530] iteration:7040  t-loss:0.4678, loss-lb:0.1941, loss-ulb:0.1369, weight:2.00, lr:0.0006
[03:48:27.844] iteration:7041  t-loss:0.2814, loss-lb:0.2202, loss-ulb:0.0306, weight:2.00, lr:0.0006
[03:48:28.177] iteration:7042  t-loss:0.4998, loss-lb:0.3271, loss-ulb:0.0864, weight:2.00, lr:0.0006
[03:48:28.517] iteration:7043  t-loss:0.2725, loss-lb:0.1629, loss-ulb:0.0548, weight:2.00, lr:0.0006
[03:48:28.844] iteration:7044  t-loss:0.2288, loss-lb:0.1822, loss-ulb:0.0233, weight:2.00, lr:0.0006
[03:48:29.175] iteration:7045  t-loss:0.4447, loss-lb:0.1894, loss-ulb:0.1277, weight:2.00, lr:0.0006
[03:48:29.495] iteration:7046  t-loss:0.6748, loss-lb:0.1468, loss-ulb:0.2640, weight:2.00, lr:0.0006
[03:48:29.813] iteration:7047  t-loss:0.2727, loss-lb:0.2236, loss-ulb:0.0246, weight:2.00, lr:0.0006
[03:48:30.131] iteration:7048  t-loss:0.4817, loss-lb:0.4262, loss-ulb:0.0277, weight:2.00, lr:0.0006
[03:48:30.448] iteration:7049  t-loss:0.5381, loss-lb:0.4010, loss-ulb:0.0685, weight:2.00, lr:0.0006
[03:48:30.764] iteration:7050  t-loss:0.4775, loss-lb:0.2720, loss-ulb:0.1028, weight:2.00, lr:0.0006
[03:48:32.339] iteration:7051  t-loss:0.6424, loss-lb:0.1629, loss-ulb:0.2397, weight:2.00, lr:0.0006
[03:48:32.692] iteration:7052  t-loss:0.3625, loss-lb:0.2657, loss-ulb:0.0484, weight:2.00, lr:0.0006
[03:48:33.033] iteration:7053  t-loss:0.4431, loss-lb:0.1697, loss-ulb:0.1367, weight:2.00, lr:0.0006
[03:48:33.366] iteration:7054  t-loss:0.7118, loss-lb:0.2816, loss-ulb:0.2151, weight:2.00, lr:0.0006
[03:48:33.700] iteration:7055  t-loss:0.5965, loss-lb:0.3826, loss-ulb:0.1069, weight:2.00, lr:0.0006
[03:48:34.021] iteration:7056  t-loss:0.3375, loss-lb:0.2754, loss-ulb:0.0311, weight:2.00, lr:0.0006
[03:48:34.349] iteration:7057  t-loss:0.6779, loss-lb:0.2700, loss-ulb:0.2039, weight:2.00, lr:0.0006
[03:48:34.665] iteration:7058  t-loss:0.4220, loss-lb:0.2367, loss-ulb:0.0926, weight:2.00, lr:0.0006
[03:48:34.979] iteration:7059  t-loss:0.2585, loss-lb:0.2112, loss-ulb:0.0236, weight:2.00, lr:0.0006
[03:48:35.292] iteration:7060  t-loss:0.2132, loss-lb:0.1413, loss-ulb:0.0359, weight:2.00, lr:0.0006
[03:48:35.609] iteration:7061  t-loss:0.4986, loss-lb:0.1632, loss-ulb:0.1677, weight:2.00, lr:0.0006
[03:48:35.923] iteration:7062  t-loss:0.5480, loss-lb:0.2251, loss-ulb:0.1614, weight:2.00, lr:0.0006
[03:48:36.237] iteration:7063  t-loss:0.2069, loss-lb:0.1467, loss-ulb:0.0301, weight:2.00, lr:0.0006
[03:48:36.567] iteration:7064  t-loss:0.3484, loss-lb:0.2844, loss-ulb:0.0320, weight:2.00, lr:0.0006
[03:48:36.898] iteration:7065  t-loss:0.5846, loss-lb:0.2756, loss-ulb:0.1545, weight:2.00, lr:0.0006
[03:48:37.231] iteration:7066  t-loss:0.4735, loss-lb:0.1200, loss-ulb:0.1768, weight:2.00, lr:0.0006
[03:48:37.568] iteration:7067  t-loss:0.3239, loss-lb:0.1780, loss-ulb:0.0729, weight:2.00, lr:0.0006
[03:48:37.900] iteration:7068  t-loss:0.6492, loss-lb:0.3889, loss-ulb:0.1301, weight:2.00, lr:0.0006
[03:48:38.213] iteration:7069  t-loss:0.4448, loss-lb:0.1622, loss-ulb:0.1413, weight:2.00, lr:0.0006
[03:48:38.529] iteration:7070  t-loss:0.5767, loss-lb:0.2143, loss-ulb:0.1812, weight:2.00, lr:0.0006
[03:48:38.843] iteration:7071  t-loss:0.2656, loss-lb:0.1659, loss-ulb:0.0498, weight:2.00, lr:0.0006
[03:48:39.156] iteration:7072  t-loss:0.2490, loss-lb:0.1469, loss-ulb:0.0510, weight:2.00, lr:0.0006
[03:48:39.474] iteration:7073  t-loss:0.3839, loss-lb:0.2790, loss-ulb:0.0525, weight:2.00, lr:0.0006
[03:48:39.792] iteration:7074  t-loss:0.2331, loss-lb:0.1935, loss-ulb:0.0198, weight:2.00, lr:0.0006
[03:48:40.110] iteration:7075  t-loss:0.3435, loss-lb:0.3003, loss-ulb:0.0216, weight:2.00, lr:0.0006
[03:48:41.478] iteration:7076  t-loss:0.9193, loss-lb:0.3747, loss-ulb:0.2723, weight:2.00, lr:0.0006
[03:48:41.827] iteration:7077  t-loss:0.3565, loss-lb:0.1183, loss-ulb:0.1191, weight:2.00, lr:0.0006
[03:48:42.160] iteration:7078  t-loss:0.2293, loss-lb:0.1746, loss-ulb:0.0273, weight:2.00, lr:0.0006
[03:48:42.492] iteration:7079  t-loss:0.2137, loss-lb:0.1744, loss-ulb:0.0197, weight:2.00, lr:0.0006
[03:48:42.820] iteration:7080  t-loss:0.6433, loss-lb:0.4711, loss-ulb:0.0861, weight:2.00, lr:0.0006
[03:48:43.142] iteration:7081  t-loss:0.5103, loss-lb:0.3264, loss-ulb:0.0920, weight:2.00, lr:0.0006
[03:48:43.458] iteration:7082  t-loss:0.3490, loss-lb:0.2464, loss-ulb:0.0513, weight:2.00, lr:0.0006
[03:48:43.772] iteration:7083  t-loss:0.5935, loss-lb:0.3301, loss-ulb:0.1317, weight:2.00, lr:0.0006
[03:48:44.085] iteration:7084  t-loss:0.2491, loss-lb:0.2043, loss-ulb:0.0224, weight:2.00, lr:0.0006
[03:48:44.397] iteration:7085  t-loss:0.2261, loss-lb:0.1690, loss-ulb:0.0286, weight:2.00, lr:0.0006
[03:48:44.716] iteration:7086  t-loss:0.3801, loss-lb:0.2200, loss-ulb:0.0800, weight:2.00, lr:0.0006
[03:48:45.030] iteration:7087  t-loss:0.2720, loss-lb:0.2190, loss-ulb:0.0265, weight:2.00, lr:0.0006
[03:48:45.355] iteration:7088  t-loss:0.5499, loss-lb:0.3649, loss-ulb:0.0925, weight:2.00, lr:0.0006
[03:48:45.670] iteration:7089  t-loss:0.3398, loss-lb:0.1608, loss-ulb:0.0895, weight:2.00, lr:0.0006
[03:48:45.990] iteration:7090  t-loss:0.2535, loss-lb:0.2110, loss-ulb:0.0212, weight:2.00, lr:0.0006
[03:48:46.312] iteration:7091  t-loss:0.2145, loss-lb:0.1607, loss-ulb:0.0269, weight:2.00, lr:0.0006
[03:48:46.632] iteration:7092  t-loss:0.4706, loss-lb:0.2128, loss-ulb:0.1289, weight:2.00, lr:0.0006
[03:48:46.950] iteration:7093  t-loss:0.4181, loss-lb:0.2432, loss-ulb:0.0874, weight:2.00, lr:0.0006
[03:48:47.266] iteration:7094  t-loss:0.2327, loss-lb:0.1767, loss-ulb:0.0280, weight:2.00, lr:0.0006
[03:48:47.585] iteration:7095  t-loss:0.3223, loss-lb:0.1381, loss-ulb:0.0921, weight:2.00, lr:0.0006
[03:48:47.904] iteration:7096  t-loss:1.1423, loss-lb:0.2378, loss-ulb:0.4523, weight:2.00, lr:0.0006
[03:48:48.222] iteration:7097  t-loss:0.3894, loss-lb:0.2032, loss-ulb:0.0931, weight:2.00, lr:0.0006
[03:48:48.536] iteration:7098  t-loss:0.5679, loss-lb:0.3820, loss-ulb:0.0930, weight:2.00, lr:0.0006
[03:48:48.854] iteration:7099  t-loss:0.4181, loss-lb:0.1650, loss-ulb:0.1266, weight:2.00, lr:0.0006
[03:48:49.171] iteration:7100  t-loss:0.3955, loss-lb:0.1501, loss-ulb:0.1227, weight:2.00, lr:0.0006
[03:48:50.678] iteration:7101  t-loss:0.3854, loss-lb:0.2196, loss-ulb:0.0829, weight:2.00, lr:0.0006
[03:48:51.019] iteration:7102  t-loss:0.3601, loss-lb:0.2899, loss-ulb:0.0351, weight:2.00, lr:0.0006
[03:48:51.341] iteration:7103  t-loss:0.5695, loss-lb:0.1603, loss-ulb:0.2046, weight:2.00, lr:0.0006
[03:48:51.663] iteration:7104  t-loss:0.4830, loss-lb:0.4436, loss-ulb:0.0197, weight:2.00, lr:0.0006
[03:48:51.985] iteration:7105  t-loss:0.4141, loss-lb:0.1213, loss-ulb:0.1464, weight:2.00, lr:0.0006
[03:48:52.307] iteration:7106  t-loss:0.2413, loss-lb:0.1773, loss-ulb:0.0320, weight:2.00, lr:0.0006
[03:48:52.625] iteration:7107  t-loss:0.4013, loss-lb:0.1515, loss-ulb:0.1249, weight:2.00, lr:0.0006
[03:48:52.946] iteration:7108  t-loss:0.4463, loss-lb:0.2612, loss-ulb:0.0925, weight:2.00, lr:0.0006
[03:48:53.266] iteration:7109  t-loss:0.2488, loss-lb:0.1933, loss-ulb:0.0277, weight:2.00, lr:0.0006
[03:48:53.588] iteration:7110  t-loss:0.2254, loss-lb:0.1521, loss-ulb:0.0367, weight:2.00, lr:0.0006
[03:48:53.916] iteration:7111  t-loss:0.6670, loss-lb:0.4006, loss-ulb:0.1332, weight:2.00, lr:0.0006
[03:48:54.242] iteration:7112  t-loss:0.5404, loss-lb:0.3905, loss-ulb:0.0749, weight:2.00, lr:0.0006
[03:48:54.567] iteration:7113  t-loss:0.4584, loss-lb:0.2136, loss-ulb:0.1224, weight:2.00, lr:0.0006
[03:48:54.891] iteration:7114  t-loss:0.3226, loss-lb:0.1259, loss-ulb:0.0984, weight:2.00, lr:0.0006
[03:48:55.213] iteration:7115  t-loss:0.5432, loss-lb:0.1629, loss-ulb:0.1902, weight:2.00, lr:0.0006
[03:48:55.530] iteration:7116  t-loss:0.2408, loss-lb:0.1837, loss-ulb:0.0286, weight:2.00, lr:0.0006
[03:48:55.853] iteration:7117  t-loss:0.4438, loss-lb:0.2477, loss-ulb:0.0980, weight:2.00, lr:0.0006
[03:48:56.174] iteration:7118  t-loss:0.6102, loss-lb:0.4330, loss-ulb:0.0886, weight:2.00, lr:0.0006
[03:48:56.488] iteration:7119  t-loss:0.2901, loss-lb:0.1764, loss-ulb:0.0569, weight:2.00, lr:0.0006
[03:48:56.805] iteration:7120  t-loss:0.2977, loss-lb:0.1960, loss-ulb:0.0509, weight:2.00, lr:0.0006
[03:48:57.121] iteration:7121  t-loss:0.4041, loss-lb:0.3160, loss-ulb:0.0441, weight:2.00, lr:0.0006
[03:48:57.434] iteration:7122  t-loss:0.2730, loss-lb:0.1856, loss-ulb:0.0437, weight:2.00, lr:0.0006
[03:48:57.747] iteration:7123  t-loss:0.4033, loss-lb:0.1760, loss-ulb:0.1137, weight:2.00, lr:0.0006
[03:48:58.066] iteration:7124  t-loss:0.4559, loss-lb:0.1898, loss-ulb:0.1331, weight:2.00, lr:0.0006
[03:48:58.381] iteration:7125  t-loss:0.1922, loss-lb:0.1469, loss-ulb:0.0227, weight:2.00, lr:0.0006
[03:51:04.518] iteration 7125 : dice_score: 0.842776 best_dice: 0.846000
[03:51:04.518]  <<Test>> - Ep:284  - Dice-S/T:82.60/84.28, Best-S:84.07, Best-T:84.60
[03:51:04.518]           - AvgLoss(lb/ulb/all):0.23/0.08/0.39
[03:51:06.032] iteration:7126  t-loss:0.6051, loss-lb:0.2219, loss-ulb:0.1916, weight:2.00, lr:0.0006
[03:51:06.378] iteration:7127  t-loss:0.4538, loss-lb:0.2776, loss-ulb:0.0881, weight:2.00, lr:0.0006
[03:51:06.712] iteration:7128  t-loss:0.3602, loss-lb:0.2980, loss-ulb:0.0311, weight:2.00, lr:0.0006
[03:51:07.046] iteration:7129  t-loss:0.4082, loss-lb:0.3194, loss-ulb:0.0444, weight:2.00, lr:0.0006
[03:51:07.371] iteration:7130  t-loss:0.2678, loss-lb:0.2104, loss-ulb:0.0287, weight:2.00, lr:0.0006
[03:51:07.695] iteration:7131  t-loss:0.4026, loss-lb:0.1772, loss-ulb:0.1127, weight:2.00, lr:0.0006
[03:51:08.011] iteration:7132  t-loss:0.2298, loss-lb:0.1655, loss-ulb:0.0321, weight:2.00, lr:0.0006
[03:51:08.336] iteration:7133  t-loss:0.4918, loss-lb:0.2002, loss-ulb:0.1458, weight:2.00, lr:0.0006
[03:51:08.666] iteration:7134  t-loss:0.2794, loss-lb:0.2417, loss-ulb:0.0189, weight:2.00, lr:0.0006
[03:51:08.993] iteration:7135  t-loss:0.1944, loss-lb:0.1524, loss-ulb:0.0210, weight:2.00, lr:0.0006
[03:51:09.329] iteration:7136  t-loss:0.5854, loss-lb:0.1682, loss-ulb:0.2086, weight:2.00, lr:0.0006
[03:51:09.656] iteration:7137  t-loss:0.3115, loss-lb:0.1754, loss-ulb:0.0680, weight:2.00, lr:0.0006
[03:51:09.977] iteration:7138  t-loss:0.2248, loss-lb:0.1507, loss-ulb:0.0371, weight:2.00, lr:0.0006
[03:51:10.299] iteration:7139  t-loss:0.3933, loss-lb:0.1815, loss-ulb:0.1059, weight:2.00, lr:0.0006
[03:51:10.623] iteration:7140  t-loss:0.5607, loss-lb:0.2950, loss-ulb:0.1328, weight:2.00, lr:0.0006
[03:51:10.946] iteration:7141  t-loss:0.4670, loss-lb:0.2264, loss-ulb:0.1203, weight:2.00, lr:0.0006
[03:51:11.260] iteration:7142  t-loss:0.2298, loss-lb:0.1620, loss-ulb:0.0339, weight:2.00, lr:0.0006
[03:51:11.581] iteration:7143  t-loss:0.2338, loss-lb:0.1712, loss-ulb:0.0313, weight:2.00, lr:0.0006
[03:51:11.892] iteration:7144  t-loss:0.2252, loss-lb:0.1620, loss-ulb:0.0316, weight:2.00, lr:0.0006
[03:51:12.212] iteration:7145  t-loss:0.5066, loss-lb:0.3438, loss-ulb:0.0814, weight:2.00, lr:0.0006
[03:51:12.538] iteration:7146  t-loss:0.2753, loss-lb:0.1738, loss-ulb:0.0507, weight:2.00, lr:0.0006
[03:51:12.871] iteration:7147  t-loss:0.3075, loss-lb:0.1496, loss-ulb:0.0789, weight:2.00, lr:0.0006
[03:51:13.221] iteration:7148  t-loss:0.3597, loss-lb:0.2057, loss-ulb:0.0770, weight:2.00, lr:0.0006
[03:51:13.546] iteration:7149  t-loss:0.3654, loss-lb:0.1993, loss-ulb:0.0831, weight:2.00, lr:0.0006
[03:51:13.874] iteration:7150  t-loss:0.2078, loss-lb:0.1434, loss-ulb:0.0322, weight:2.00, lr:0.0006
[03:51:15.111] iteration:7151  t-loss:0.3582, loss-lb:0.1292, loss-ulb:0.1145, weight:2.00, lr:0.0006
[03:51:15.457] iteration:7152  t-loss:0.2300, loss-lb:0.1832, loss-ulb:0.0234, weight:2.00, lr:0.0006
[03:51:15.814] iteration:7153  t-loss:0.3605, loss-lb:0.1820, loss-ulb:0.0893, weight:2.00, lr:0.0006
[03:51:16.162] iteration:7154  t-loss:0.2644, loss-lb:0.1966, loss-ulb:0.0339, weight:2.00, lr:0.0006
[03:51:16.560] iteration:7155  t-loss:0.6274, loss-lb:0.2777, loss-ulb:0.1749, weight:2.00, lr:0.0006
[03:51:16.924] iteration:7156  t-loss:0.6082, loss-lb:0.4275, loss-ulb:0.0903, weight:2.00, lr:0.0006
[03:51:17.276] iteration:7157  t-loss:0.2267, loss-lb:0.1784, loss-ulb:0.0242, weight:2.00, lr:0.0006
[03:51:17.600] iteration:7158  t-loss:0.1997, loss-lb:0.1615, loss-ulb:0.0191, weight:2.00, lr:0.0006
[03:51:17.924] iteration:7159  t-loss:0.3840, loss-lb:0.2420, loss-ulb:0.0710, weight:2.00, lr:0.0006
[03:51:18.246] iteration:7160  t-loss:0.3994, loss-lb:0.1983, loss-ulb:0.1005, weight:2.00, lr:0.0006
[03:51:18.585] iteration:7161  t-loss:0.3277, loss-lb:0.2633, loss-ulb:0.0322, weight:2.00, lr:0.0006
[03:51:18.899] iteration:7162  t-loss:0.3632, loss-lb:0.3029, loss-ulb:0.0302, weight:2.00, lr:0.0006
[03:51:19.215] iteration:7163  t-loss:0.4674, loss-lb:0.2331, loss-ulb:0.1172, weight:2.00, lr:0.0006
[03:51:19.529] iteration:7164  t-loss:0.2572, loss-lb:0.1397, loss-ulb:0.0588, weight:2.00, lr:0.0006
[03:51:19.847] iteration:7165  t-loss:0.5177, loss-lb:0.3499, loss-ulb:0.0839, weight:2.00, lr:0.0006
[03:51:20.162] iteration:7166  t-loss:0.2929, loss-lb:0.2420, loss-ulb:0.0255, weight:2.00, lr:0.0006
[03:51:20.484] iteration:7167  t-loss:0.4883, loss-lb:0.3007, loss-ulb:0.0938, weight:2.00, lr:0.0006
[03:51:20.797] iteration:7168  t-loss:0.3196, loss-lb:0.2078, loss-ulb:0.0559, weight:2.00, lr:0.0006
[03:51:21.115] iteration:7169  t-loss:0.3509, loss-lb:0.2122, loss-ulb:0.0694, weight:2.00, lr:0.0006
[03:51:21.443] iteration:7170  t-loss:0.5344, loss-lb:0.2727, loss-ulb:0.1308, weight:2.00, lr:0.0006
[03:51:21.775] iteration:7171  t-loss:0.5078, loss-lb:0.2277, loss-ulb:0.1401, weight:2.00, lr:0.0006
[03:51:22.105] iteration:7172  t-loss:0.3344, loss-lb:0.1762, loss-ulb:0.0791, weight:2.00, lr:0.0006
[03:51:22.424] iteration:7173  t-loss:0.2163, loss-lb:0.1524, loss-ulb:0.0319, weight:2.00, lr:0.0006
[03:51:22.738] iteration:7174  t-loss:0.3996, loss-lb:0.2632, loss-ulb:0.0682, weight:2.00, lr:0.0006
[03:51:23.063] iteration:7175  t-loss:0.2748, loss-lb:0.2361, loss-ulb:0.0193, weight:2.00, lr:0.0006
[03:51:24.396] iteration:7176  t-loss:0.1923, loss-lb:0.1632, loss-ulb:0.0146, weight:2.00, lr:0.0006
[03:51:24.736] iteration:7177  t-loss:0.8596, loss-lb:0.7874, loss-ulb:0.0361, weight:2.00, lr:0.0006
[03:51:25.074] iteration:7178  t-loss:0.4004, loss-lb:0.2410, loss-ulb:0.0797, weight:2.00, lr:0.0006
[03:51:25.418] iteration:7179  t-loss:0.3953, loss-lb:0.2388, loss-ulb:0.0783, weight:2.00, lr:0.0006
[03:51:25.748] iteration:7180  t-loss:0.3960, loss-lb:0.2150, loss-ulb:0.0905, weight:2.00, lr:0.0006
[03:51:26.077] iteration:7181  t-loss:0.7588, loss-lb:0.2452, loss-ulb:0.2568, weight:2.00, lr:0.0006
[03:51:26.404] iteration:7182  t-loss:0.3322, loss-lb:0.1136, loss-ulb:0.1093, weight:2.00, lr:0.0006
[03:51:26.728] iteration:7183  t-loss:0.2734, loss-lb:0.1260, loss-ulb:0.0737, weight:2.00, lr:0.0006
[03:51:27.061] iteration:7184  t-loss:0.2706, loss-lb:0.1288, loss-ulb:0.0709, weight:2.00, lr:0.0006
[03:51:27.376] iteration:7185  t-loss:0.3035, loss-lb:0.2311, loss-ulb:0.0362, weight:2.00, lr:0.0006
[03:51:27.695] iteration:7186  t-loss:0.4274, loss-lb:0.3137, loss-ulb:0.0569, weight:2.00, lr:0.0006
[03:51:28.008] iteration:7187  t-loss:0.3276, loss-lb:0.2382, loss-ulb:0.0447, weight:2.00, lr:0.0006
[03:51:28.331] iteration:7188  t-loss:0.4984, loss-lb:0.2881, loss-ulb:0.1052, weight:2.00, lr:0.0006
[03:51:28.650] iteration:7189  t-loss:0.4441, loss-lb:0.2394, loss-ulb:0.1023, weight:2.00, lr:0.0006
[03:51:28.974] iteration:7190  t-loss:0.5513, loss-lb:0.3254, loss-ulb:0.1130, weight:2.00, lr:0.0006
[03:51:29.290] iteration:7191  t-loss:0.4500, loss-lb:0.3838, loss-ulb:0.0331, weight:2.00, lr:0.0006
[03:51:29.611] iteration:7192  t-loss:0.7141, loss-lb:0.1752, loss-ulb:0.2694, weight:2.00, lr:0.0006
[03:51:29.928] iteration:7193  t-loss:0.4487, loss-lb:0.2822, loss-ulb:0.0833, weight:2.00, lr:0.0006
[03:51:30.245] iteration:7194  t-loss:0.3691, loss-lb:0.3103, loss-ulb:0.0294, weight:2.00, lr:0.0006
[03:51:30.561] iteration:7195  t-loss:0.4179, loss-lb:0.2306, loss-ulb:0.0936, weight:2.00, lr:0.0006
[03:51:30.875] iteration:7196  t-loss:0.3377, loss-lb:0.1740, loss-ulb:0.0819, weight:2.00, lr:0.0006
[03:51:31.190] iteration:7197  t-loss:0.8615, loss-lb:0.2258, loss-ulb:0.3178, weight:2.00, lr:0.0006
[03:51:31.503] iteration:7198  t-loss:0.3046, loss-lb:0.2703, loss-ulb:0.0171, weight:2.00, lr:0.0006
[03:51:31.819] iteration:7199  t-loss:0.3661, loss-lb:0.2384, loss-ulb:0.0638, weight:2.00, lr:0.0006
[03:51:32.134] iteration:7200  t-loss:0.4155, loss-lb:0.3174, loss-ulb:0.0491, weight:2.00, lr:0.0006
[03:51:33.434] iteration:7201  t-loss:0.5293, loss-lb:0.2136, loss-ulb:0.1579, weight:2.00, lr:0.0006
[03:51:33.760] iteration:7202  t-loss:0.4067, loss-lb:0.1574, loss-ulb:0.1246, weight:2.00, lr:0.0006
[03:51:34.082] iteration:7203  t-loss:0.4500, loss-lb:0.3226, loss-ulb:0.0637, weight:2.00, lr:0.0006
[03:51:34.400] iteration:7204  t-loss:0.3886, loss-lb:0.2996, loss-ulb:0.0445, weight:2.00, lr:0.0006
[03:51:34.722] iteration:7205  t-loss:0.4632, loss-lb:0.2415, loss-ulb:0.1109, weight:2.00, lr:0.0006
[03:51:35.038] iteration:7206  t-loss:0.2652, loss-lb:0.1932, loss-ulb:0.0360, weight:2.00, lr:0.0006
[03:51:35.356] iteration:7207  t-loss:0.3334, loss-lb:0.1928, loss-ulb:0.0703, weight:2.00, lr:0.0006
[03:51:35.673] iteration:7208  t-loss:0.3175, loss-lb:0.2209, loss-ulb:0.0483, weight:2.00, lr:0.0006
[03:51:35.999] iteration:7209  t-loss:0.3375, loss-lb:0.1779, loss-ulb:0.0798, weight:2.00, lr:0.0006
[03:51:36.321] iteration:7210  t-loss:0.3201, loss-lb:0.2779, loss-ulb:0.0211, weight:2.00, lr:0.0006
[03:51:36.639] iteration:7211  t-loss:0.2992, loss-lb:0.1373, loss-ulb:0.0809, weight:2.00, lr:0.0006
[03:51:36.959] iteration:7212  t-loss:0.5208, loss-lb:0.4103, loss-ulb:0.0552, weight:2.00, lr:0.0006
[03:51:37.283] iteration:7213  t-loss:0.4322, loss-lb:0.1892, loss-ulb:0.1215, weight:2.00, lr:0.0006
[03:51:37.600] iteration:7214  t-loss:0.4323, loss-lb:0.1459, loss-ulb:0.1432, weight:2.00, lr:0.0006
[03:51:37.920] iteration:7215  t-loss:0.6357, loss-lb:0.3264, loss-ulb:0.1546, weight:2.00, lr:0.0006
[03:51:38.241] iteration:7216  t-loss:0.2962, loss-lb:0.2468, loss-ulb:0.0247, weight:2.00, lr:0.0006
[03:51:38.561] iteration:7217  t-loss:0.4845, loss-lb:0.1744, loss-ulb:0.1551, weight:2.00, lr:0.0006
[03:51:38.880] iteration:7218  t-loss:0.4006, loss-lb:0.2295, loss-ulb:0.0855, weight:2.00, lr:0.0006
[03:51:39.198] iteration:7219  t-loss:0.4157, loss-lb:0.2374, loss-ulb:0.0892, weight:2.00, lr:0.0006
[03:51:39.515] iteration:7220  t-loss:0.4593, loss-lb:0.2510, loss-ulb:0.1042, weight:2.00, lr:0.0006
[03:51:39.830] iteration:7221  t-loss:0.3305, loss-lb:0.2265, loss-ulb:0.0520, weight:2.00, lr:0.0006
[03:51:40.146] iteration:7222  t-loss:0.6235, loss-lb:0.4308, loss-ulb:0.0964, weight:2.00, lr:0.0006
[03:51:40.461] iteration:7223  t-loss:0.2265, loss-lb:0.1769, loss-ulb:0.0248, weight:2.00, lr:0.0006
[03:51:40.776] iteration:7224  t-loss:0.2035, loss-lb:0.1667, loss-ulb:0.0184, weight:2.00, lr:0.0006
[03:51:41.090] iteration:7225  t-loss:0.2299, loss-lb:0.1814, loss-ulb:0.0242, weight:2.00, lr:0.0006
[03:53:42.302] iteration 7225 : dice_score: 0.844712 best_dice: 0.846000
[03:53:42.303]  <<Test>> - Ep:288  - Dice-S/T:84.32/84.47, Best-S:84.32, Best-T:84.60
[03:53:42.303]           - AvgLoss(lb/ulb/all):0.23/0.07/0.38
[03:53:43.657] iteration:7226  t-loss:0.4278, loss-lb:0.3782, loss-ulb:0.0248, weight:2.00, lr:0.0006
[03:53:44.010] iteration:7227  t-loss:0.4600, loss-lb:0.2279, loss-ulb:0.1161, weight:2.00, lr:0.0006
[03:53:44.354] iteration:7228  t-loss:0.2911, loss-lb:0.1395, loss-ulb:0.0758, weight:2.00, lr:0.0006
[03:53:44.706] iteration:7229  t-loss:0.5106, loss-lb:0.2534, loss-ulb:0.1286, weight:2.00, lr:0.0006
[03:53:45.029] iteration:7230  t-loss:0.6402, loss-lb:0.4513, loss-ulb:0.0944, weight:2.00, lr:0.0006
[03:53:45.351] iteration:7231  t-loss:0.4062, loss-lb:0.3401, loss-ulb:0.0330, weight:2.00, lr:0.0006
[03:53:45.669] iteration:7232  t-loss:0.2423, loss-lb:0.2011, loss-ulb:0.0206, weight:2.00, lr:0.0006
[03:53:45.989] iteration:7233  t-loss:0.3144, loss-lb:0.1974, loss-ulb:0.0585, weight:2.00, lr:0.0006
[03:53:46.310] iteration:7234  t-loss:0.3428, loss-lb:0.2248, loss-ulb:0.0590, weight:2.00, lr:0.0006
[03:53:46.630] iteration:7235  t-loss:0.2134, loss-lb:0.1743, loss-ulb:0.0196, weight:2.00, lr:0.0006
[03:53:46.959] iteration:7236  t-loss:0.4236, loss-lb:0.2449, loss-ulb:0.0894, weight:2.00, lr:0.0006
[03:53:47.272] iteration:7237  t-loss:0.2412, loss-lb:0.1754, loss-ulb:0.0329, weight:2.00, lr:0.0006
[03:53:47.588] iteration:7238  t-loss:0.4684, loss-lb:0.1815, loss-ulb:0.1435, weight:2.00, lr:0.0006
[03:53:47.901] iteration:7239  t-loss:0.3249, loss-lb:0.1741, loss-ulb:0.0754, weight:2.00, lr:0.0006
[03:53:48.212] iteration:7240  t-loss:0.3355, loss-lb:0.1408, loss-ulb:0.0973, weight:2.00, lr:0.0006
[03:53:48.525] iteration:7241  t-loss:0.3233, loss-lb:0.2102, loss-ulb:0.0565, weight:2.00, lr:0.0006
[03:53:48.841] iteration:7242  t-loss:0.1909, loss-lb:0.1502, loss-ulb:0.0204, weight:2.00, lr:0.0006
[03:53:49.158] iteration:7243  t-loss:0.6111, loss-lb:0.2526, loss-ulb:0.1793, weight:2.00, lr:0.0006
[03:53:49.480] iteration:7244  t-loss:0.2935, loss-lb:0.1488, loss-ulb:0.0723, weight:2.00, lr:0.0006
[03:53:49.805] iteration:7245  t-loss:0.2768, loss-lb:0.1405, loss-ulb:0.0681, weight:2.00, lr:0.0006
[03:53:50.127] iteration:7246  t-loss:0.3789, loss-lb:0.3108, loss-ulb:0.0341, weight:2.00, lr:0.0006
[03:53:50.451] iteration:7247  t-loss:0.4542, loss-lb:0.2009, loss-ulb:0.1267, weight:2.00, lr:0.0006
[03:53:50.767] iteration:7248  t-loss:0.2794, loss-lb:0.2332, loss-ulb:0.0231, weight:2.00, lr:0.0006
[03:53:51.081] iteration:7249  t-loss:0.3007, loss-lb:0.2044, loss-ulb:0.0481, weight:2.00, lr:0.0006
[03:53:51.397] iteration:7250  t-loss:0.3209, loss-lb:0.1821, loss-ulb:0.0694, weight:2.00, lr:0.0006
[03:53:52.703] iteration:7251  t-loss:0.2638, loss-lb:0.2021, loss-ulb:0.0308, weight:2.00, lr:0.0006
[03:53:53.053] iteration:7252  t-loss:0.5068, loss-lb:0.2807, loss-ulb:0.1131, weight:2.00, lr:0.0006
[03:53:53.390] iteration:7253  t-loss:0.2796, loss-lb:0.1582, loss-ulb:0.0607, weight:2.00, lr:0.0006
[03:53:53.741] iteration:7254  t-loss:0.5634, loss-lb:0.3847, loss-ulb:0.0893, weight:2.00, lr:0.0006
[03:53:54.075] iteration:7255  t-loss:0.4442, loss-lb:0.1724, loss-ulb:0.1359, weight:2.00, lr:0.0006
[03:53:54.403] iteration:7256  t-loss:0.2366, loss-lb:0.1985, loss-ulb:0.0190, weight:2.00, lr:0.0006
[03:53:54.726] iteration:7257  t-loss:0.3933, loss-lb:0.1509, loss-ulb:0.1212, weight:2.00, lr:0.0006
[03:53:55.048] iteration:7258  t-loss:0.1888, loss-lb:0.1405, loss-ulb:0.0241, weight:2.00, lr:0.0006
[03:53:55.361] iteration:7259  t-loss:0.4626, loss-lb:0.1876, loss-ulb:0.1375, weight:2.00, lr:0.0006
[03:53:55.676] iteration:7260  t-loss:0.2190, loss-lb:0.1526, loss-ulb:0.0332, weight:2.00, lr:0.0006
[03:53:55.993] iteration:7261  t-loss:0.4357, loss-lb:0.1822, loss-ulb:0.1267, weight:2.00, lr:0.0006
[03:53:56.306] iteration:7262  t-loss:0.2335, loss-lb:0.1839, loss-ulb:0.0248, weight:2.00, lr:0.0006
[03:53:56.617] iteration:7263  t-loss:0.2206, loss-lb:0.1579, loss-ulb:0.0314, weight:2.00, lr:0.0006
[03:53:56.932] iteration:7264  t-loss:0.2945, loss-lb:0.1765, loss-ulb:0.0590, weight:2.00, lr:0.0006
[03:53:57.250] iteration:7265  t-loss:0.4453, loss-lb:0.2148, loss-ulb:0.1152, weight:2.00, lr:0.0006
[03:53:57.566] iteration:7266  t-loss:0.3323, loss-lb:0.1465, loss-ulb:0.0929, weight:2.00, lr:0.0006
[03:53:57.885] iteration:7267  t-loss:0.9293, loss-lb:0.1630, loss-ulb:0.3831, weight:2.00, lr:0.0006
[03:53:58.211] iteration:7268  t-loss:0.5359, loss-lb:0.3647, loss-ulb:0.0856, weight:2.00, lr:0.0006
[03:53:58.543] iteration:7269  t-loss:0.3738, loss-lb:0.2547, loss-ulb:0.0596, weight:2.00, lr:0.0006
[03:53:58.863] iteration:7270  t-loss:0.1931, loss-lb:0.1402, loss-ulb:0.0265, weight:2.00, lr:0.0006
[03:53:59.177] iteration:7271  t-loss:0.4012, loss-lb:0.1508, loss-ulb:0.1252, weight:2.00, lr:0.0006
[03:53:59.489] iteration:7272  t-loss:0.2232, loss-lb:0.1860, loss-ulb:0.0186, weight:2.00, lr:0.0006
[03:53:59.806] iteration:7273  t-loss:0.6383, loss-lb:0.4399, loss-ulb:0.0992, weight:2.00, lr:0.0006
[03:54:00.120] iteration:7274  t-loss:0.3187, loss-lb:0.2581, loss-ulb:0.0303, weight:2.00, lr:0.0006
[03:54:00.435] iteration:7275  t-loss:0.3741, loss-lb:0.2489, loss-ulb:0.0626, weight:2.00, lr:0.0006
[03:54:01.631] iteration:7276  t-loss:0.3586, loss-lb:0.2971, loss-ulb:0.0307, weight:2.00, lr:0.0006
[03:54:01.965] iteration:7277  t-loss:0.5124, loss-lb:0.2708, loss-ulb:0.1208, weight:2.00, lr:0.0006
[03:54:02.288] iteration:7278  t-loss:0.8160, loss-lb:0.1950, loss-ulb:0.3105, weight:2.00, lr:0.0006
[03:54:02.617] iteration:7279  t-loss:1.4513, loss-lb:0.2005, loss-ulb:0.6254, weight:2.00, lr:0.0006
[03:54:02.935] iteration:7280  t-loss:0.2445, loss-lb:0.2008, loss-ulb:0.0219, weight:2.00, lr:0.0006
[03:54:03.253] iteration:7281  t-loss:0.1944, loss-lb:0.1458, loss-ulb:0.0243, weight:2.00, lr:0.0006
[03:54:03.570] iteration:7282  t-loss:0.3620, loss-lb:0.1755, loss-ulb:0.0932, weight:2.00, lr:0.0005
[03:54:03.891] iteration:7283  t-loss:0.3442, loss-lb:0.1407, loss-ulb:0.1018, weight:2.00, lr:0.0005
[03:54:04.210] iteration:7284  t-loss:0.4183, loss-lb:0.2286, loss-ulb:0.0948, weight:2.00, lr:0.0005
[03:54:04.529] iteration:7285  t-loss:0.3421, loss-lb:0.1780, loss-ulb:0.0821, weight:2.00, lr:0.0005
[03:54:04.837] iteration:7286  t-loss:0.8529, loss-lb:0.1379, loss-ulb:0.3575, weight:2.00, lr:0.0005
[03:54:05.154] iteration:7287  t-loss:0.3082, loss-lb:0.2345, loss-ulb:0.0369, weight:2.00, lr:0.0005
[03:54:05.470] iteration:7288  t-loss:0.4045, loss-lb:0.1895, loss-ulb:0.1075, weight:2.00, lr:0.0005
[03:54:05.789] iteration:7289  t-loss:0.3327, loss-lb:0.2230, loss-ulb:0.0548, weight:2.00, lr:0.0005
[03:54:06.110] iteration:7290  t-loss:0.4968, loss-lb:0.1794, loss-ulb:0.1587, weight:2.00, lr:0.0005
[03:54:06.433] iteration:7291  t-loss:0.5142, loss-lb:0.2082, loss-ulb:0.1530, weight:2.00, lr:0.0005
[03:54:06.766] iteration:7292  t-loss:0.2524, loss-lb:0.2043, loss-ulb:0.0240, weight:2.00, lr:0.0005
[03:54:07.100] iteration:7293  t-loss:0.3094, loss-lb:0.2391, loss-ulb:0.0351, weight:2.00, lr:0.0005
[03:54:07.422] iteration:7294  t-loss:0.3792, loss-lb:0.2583, loss-ulb:0.0605, weight:2.00, lr:0.0005
[03:54:07.740] iteration:7295  t-loss:0.4121, loss-lb:0.1855, loss-ulb:0.1133, weight:2.00, lr:0.0005
[03:54:08.056] iteration:7296  t-loss:0.3318, loss-lb:0.2730, loss-ulb:0.0294, weight:2.00, lr:0.0005
[03:54:08.373] iteration:7297  t-loss:0.4871, loss-lb:0.2318, loss-ulb:0.1277, weight:2.00, lr:0.0005
[03:54:08.693] iteration:7298  t-loss:0.5796, loss-lb:0.3571, loss-ulb:0.1113, weight:2.00, lr:0.0005
[03:54:09.008] iteration:7299  t-loss:0.4481, loss-lb:0.2336, loss-ulb:0.1073, weight:2.00, lr:0.0005
[03:54:09.322] iteration:7300  t-loss:0.3110, loss-lb:0.2316, loss-ulb:0.0397, weight:2.00, lr:0.0005
[03:54:10.561] iteration:7301  t-loss:0.6446, loss-lb:0.4845, loss-ulb:0.0800, weight:2.00, lr:0.0005
[03:54:10.902] iteration:7302  t-loss:0.7758, loss-lb:0.4198, loss-ulb:0.1780, weight:2.00, lr:0.0005
[03:54:11.249] iteration:7303  t-loss:0.3330, loss-lb:0.2176, loss-ulb:0.0577, weight:2.00, lr:0.0005
[03:54:11.590] iteration:7304  t-loss:0.5966, loss-lb:0.3008, loss-ulb:0.1479, weight:2.00, lr:0.0005
[03:54:11.920] iteration:7305  t-loss:0.4478, loss-lb:0.3514, loss-ulb:0.0482, weight:2.00, lr:0.0005
[03:54:12.253] iteration:7306  t-loss:0.4650, loss-lb:0.3090, loss-ulb:0.0780, weight:2.00, lr:0.0005
[03:54:12.574] iteration:7307  t-loss:0.2714, loss-lb:0.1423, loss-ulb:0.0646, weight:2.00, lr:0.0005
[03:54:12.889] iteration:7308  t-loss:0.4787, loss-lb:0.1454, loss-ulb:0.1667, weight:2.00, lr:0.0005
[03:54:13.207] iteration:7309  t-loss:0.5891, loss-lb:0.2428, loss-ulb:0.1731, weight:2.00, lr:0.0005
[03:54:13.522] iteration:7310  t-loss:0.2056, loss-lb:0.1648, loss-ulb:0.0204, weight:2.00, lr:0.0005
[03:54:13.842] iteration:7311  t-loss:0.6566, loss-lb:0.2428, loss-ulb:0.2069, weight:2.00, lr:0.0005
[03:54:14.158] iteration:7312  t-loss:0.5467, loss-lb:0.2985, loss-ulb:0.1241, weight:2.00, lr:0.0005
[03:54:14.484] iteration:7313  t-loss:0.4737, loss-lb:0.2258, loss-ulb:0.1239, weight:2.00, lr:0.0005
[03:54:14.801] iteration:7314  t-loss:0.2788, loss-lb:0.1687, loss-ulb:0.0551, weight:2.00, lr:0.0005
[03:54:15.121] iteration:7315  t-loss:0.2776, loss-lb:0.1538, loss-ulb:0.0619, weight:2.00, lr:0.0005
[03:54:15.438] iteration:7316  t-loss:0.3923, loss-lb:0.1785, loss-ulb:0.1069, weight:2.00, lr:0.0005
[03:54:15.756] iteration:7317  t-loss:0.3043, loss-lb:0.2549, loss-ulb:0.0247, weight:2.00, lr:0.0005
[03:54:16.074] iteration:7318  t-loss:0.3450, loss-lb:0.1845, loss-ulb:0.0802, weight:2.00, lr:0.0005
[03:54:16.391] iteration:7319  t-loss:0.5085, loss-lb:0.1613, loss-ulb:0.1736, weight:2.00, lr:0.0005
[03:54:16.710] iteration:7320  t-loss:0.3401, loss-lb:0.1578, loss-ulb:0.0911, weight:2.00, lr:0.0005
[03:54:17.032] iteration:7321  t-loss:0.3745, loss-lb:0.1858, loss-ulb:0.0943, weight:2.00, lr:0.0005
[03:54:17.348] iteration:7322  t-loss:0.2860, loss-lb:0.1389, loss-ulb:0.0736, weight:2.00, lr:0.0005
[03:54:17.669] iteration:7323  t-loss:0.3644, loss-lb:0.2718, loss-ulb:0.0463, weight:2.00, lr:0.0005
[03:54:17.984] iteration:7324  t-loss:0.5714, loss-lb:0.3300, loss-ulb:0.1207, weight:2.00, lr:0.0005
[03:54:18.299] iteration:7325  t-loss:0.2584, loss-lb:0.1850, loss-ulb:0.0367, weight:2.00, lr:0.0005
[03:56:24.465] iteration 7325 : dice_score: 0.843849 best_dice: 0.846000
[03:56:24.466]  <<Test>> - Ep:292  - Dice-S/T:84.18/84.38, Best-S:84.32, Best-T:84.60
[03:56:24.466]           - AvgLoss(lb/ulb/all):0.24/0.10/0.40
[03:56:26.330] iteration:7326  t-loss:0.2746, loss-lb:0.2123, loss-ulb:0.0311, weight:2.00, lr:0.0005
[03:56:26.724] iteration:7327  t-loss:0.7528, loss-lb:0.5059, loss-ulb:0.1234, weight:2.00, lr:0.0005
[03:56:27.093] iteration:7328  t-loss:0.7406, loss-lb:0.2980, loss-ulb:0.2213, weight:2.00, lr:0.0005
[03:56:27.433] iteration:7329  t-loss:0.3437, loss-lb:0.2137, loss-ulb:0.0650, weight:2.00, lr:0.0005
[03:56:27.799] iteration:7330  t-loss:0.2666, loss-lb:0.2095, loss-ulb:0.0286, weight:2.00, lr:0.0005
[03:56:28.134] iteration:7331  t-loss:0.2898, loss-lb:0.2415, loss-ulb:0.0241, weight:2.00, lr:0.0005
[03:56:28.460] iteration:7332  t-loss:0.2990, loss-lb:0.1545, loss-ulb:0.0722, weight:2.00, lr:0.0005
[03:56:28.793] iteration:7333  t-loss:0.4052, loss-lb:0.2055, loss-ulb:0.0999, weight:2.00, lr:0.0005
[03:56:29.115] iteration:7334  t-loss:0.3785, loss-lb:0.1781, loss-ulb:0.1002, weight:2.00, lr:0.0005
[03:56:29.450] iteration:7335  t-loss:0.7049, loss-lb:0.2204, loss-ulb:0.2422, weight:2.00, lr:0.0005
[03:56:29.772] iteration:7336  t-loss:0.2207, loss-lb:0.1792, loss-ulb:0.0207, weight:2.00, lr:0.0005
[03:56:30.108] iteration:7337  t-loss:0.3561, loss-lb:0.2049, loss-ulb:0.0756, weight:2.00, lr:0.0005
[03:56:30.427] iteration:7338  t-loss:0.2483, loss-lb:0.1694, loss-ulb:0.0394, weight:2.00, lr:0.0005
[03:56:30.752] iteration:7339  t-loss:0.5308, loss-lb:0.1801, loss-ulb:0.1754, weight:2.00, lr:0.0005
[03:56:31.076] iteration:7340  t-loss:0.6523, loss-lb:0.4270, loss-ulb:0.1126, weight:2.00, lr:0.0005
[03:56:31.394] iteration:7341  t-loss:0.2580, loss-lb:0.1791, loss-ulb:0.0395, weight:2.00, lr:0.0005
[03:56:31.717] iteration:7342  t-loss:0.2755, loss-lb:0.2135, loss-ulb:0.0310, weight:2.00, lr:0.0005
[03:56:32.049] iteration:7343  t-loss:0.5262, loss-lb:0.2269, loss-ulb:0.1497, weight:2.00, lr:0.0005
[03:56:32.371] iteration:7344  t-loss:0.3998, loss-lb:0.2792, loss-ulb:0.0603, weight:2.00, lr:0.0005
[03:56:32.690] iteration:7345  t-loss:0.3836, loss-lb:0.1454, loss-ulb:0.1191, weight:2.00, lr:0.0005
[03:56:33.010] iteration:7346  t-loss:0.4368, loss-lb:0.3714, loss-ulb:0.0327, weight:2.00, lr:0.0005
[03:56:33.331] iteration:7347  t-loss:0.5049, loss-lb:0.2737, loss-ulb:0.1156, weight:2.00, lr:0.0005
[03:56:33.653] iteration:7348  t-loss:0.3523, loss-lb:0.2028, loss-ulb:0.0748, weight:2.00, lr:0.0005
[03:56:33.973] iteration:7349  t-loss:0.3797, loss-lb:0.1651, loss-ulb:0.1073, weight:2.00, lr:0.0005
[03:56:34.303] iteration:7350  t-loss:0.3151, loss-lb:0.1653, loss-ulb:0.0749, weight:2.00, lr:0.0005
[03:56:36.018] iteration:7351  t-loss:0.2797, loss-lb:0.1726, loss-ulb:0.0536, weight:2.00, lr:0.0005
[03:56:36.375] iteration:7352  t-loss:0.2337, loss-lb:0.1953, loss-ulb:0.0192, weight:2.00, lr:0.0005
[03:56:36.723] iteration:7353  t-loss:1.8431, loss-lb:0.1947, loss-ulb:0.8242, weight:2.00, lr:0.0005
[03:56:37.084] iteration:7354  t-loss:0.2305, loss-lb:0.1715, loss-ulb:0.0295, weight:2.00, lr:0.0005
[03:56:37.427] iteration:7355  t-loss:0.6493, loss-lb:0.2194, loss-ulb:0.2149, weight:2.00, lr:0.0005
[03:56:37.754] iteration:7356  t-loss:0.3905, loss-lb:0.1822, loss-ulb:0.1041, weight:2.00, lr:0.0005
[03:56:38.077] iteration:7357  t-loss:0.8403, loss-lb:0.2552, loss-ulb:0.2926, weight:2.00, lr:0.0005
[03:56:38.396] iteration:7358  t-loss:0.3599, loss-lb:0.2199, loss-ulb:0.0700, weight:2.00, lr:0.0005
[03:56:38.716] iteration:7359  t-loss:1.3483, loss-lb:0.5859, loss-ulb:0.3812, weight:2.00, lr:0.0005
[03:56:39.038] iteration:7360  t-loss:0.5488, loss-lb:0.2287, loss-ulb:0.1600, weight:2.00, lr:0.0005
[03:56:39.356] iteration:7361  t-loss:1.0809, loss-lb:0.2773, loss-ulb:0.4018, weight:2.00, lr:0.0005
[03:56:39.675] iteration:7362  t-loss:0.8049, loss-lb:0.2240, loss-ulb:0.2905, weight:2.00, lr:0.0005
[03:56:39.994] iteration:7363  t-loss:0.2577, loss-lb:0.1516, loss-ulb:0.0531, weight:2.00, lr:0.0005
[03:56:40.312] iteration:7364  t-loss:0.4016, loss-lb:0.2444, loss-ulb:0.0786, weight:2.00, lr:0.0005
[03:56:40.629] iteration:7365  t-loss:0.8159, loss-lb:0.4953, loss-ulb:0.1603, weight:2.00, lr:0.0005
[03:56:40.958] iteration:7366  t-loss:0.5910, loss-lb:0.4382, loss-ulb:0.0764, weight:2.00, lr:0.0005
[03:56:41.274] iteration:7367  t-loss:0.6999, loss-lb:0.1457, loss-ulb:0.2771, weight:2.00, lr:0.0005
[03:56:41.587] iteration:7368  t-loss:0.3958, loss-lb:0.1990, loss-ulb:0.0984, weight:2.00, lr:0.0005
[03:56:41.897] iteration:7369  t-loss:0.2714, loss-lb:0.1971, loss-ulb:0.0372, weight:2.00, lr:0.0005
[03:56:42.210] iteration:7370  t-loss:1.2933, loss-lb:0.1326, loss-ulb:0.5804, weight:2.00, lr:0.0005
[03:56:42.530] iteration:7371  t-loss:0.4745, loss-lb:0.1561, loss-ulb:0.1592, weight:2.00, lr:0.0005
[03:56:42.852] iteration:7372  t-loss:0.4997, loss-lb:0.4029, loss-ulb:0.0484, weight:2.00, lr:0.0005
[03:56:43.178] iteration:7373  t-loss:0.6027, loss-lb:0.3130, loss-ulb:0.1448, weight:2.00, lr:0.0005
[03:56:43.509] iteration:7374  t-loss:0.7329, loss-lb:0.3439, loss-ulb:0.1945, weight:2.00, lr:0.0005
[03:56:43.832] iteration:7375  t-loss:0.4011, loss-lb:0.2307, loss-ulb:0.0852, weight:2.00, lr:0.0005
[03:56:45.204] iteration:7376  t-loss:0.3961, loss-lb:0.2005, loss-ulb:0.0978, weight:2.00, lr:0.0005
[03:56:45.537] iteration:7377  t-loss:0.5331, loss-lb:0.1796, loss-ulb:0.1768, weight:2.00, lr:0.0005
[03:56:45.879] iteration:7378  t-loss:0.5054, loss-lb:0.2459, loss-ulb:0.1298, weight:2.00, lr:0.0005
[03:56:46.211] iteration:7379  t-loss:0.4517, loss-lb:0.3625, loss-ulb:0.0446, weight:2.00, lr:0.0005
[03:56:46.547] iteration:7380  t-loss:0.5251, loss-lb:0.2362, loss-ulb:0.1445, weight:2.00, lr:0.0005
[03:56:46.880] iteration:7381  t-loss:0.5055, loss-lb:0.1454, loss-ulb:0.1800, weight:2.00, lr:0.0005
[03:56:47.207] iteration:7382  t-loss:0.3110, loss-lb:0.2047, loss-ulb:0.0531, weight:2.00, lr:0.0005
[03:56:47.527] iteration:7383  t-loss:0.3515, loss-lb:0.2327, loss-ulb:0.0594, weight:2.00, lr:0.0005
[03:56:47.848] iteration:7384  t-loss:0.3684, loss-lb:0.1993, loss-ulb:0.0846, weight:2.00, lr:0.0005
[03:56:48.181] iteration:7385  t-loss:0.9527, loss-lb:0.4553, loss-ulb:0.2487, weight:2.00, lr:0.0005
[03:56:48.499] iteration:7386  t-loss:0.3122, loss-lb:0.2355, loss-ulb:0.0383, weight:2.00, lr:0.0005
[03:56:48.816] iteration:7387  t-loss:0.3267, loss-lb:0.1716, loss-ulb:0.0776, weight:2.00, lr:0.0005
[03:56:49.135] iteration:7388  t-loss:0.5242, loss-lb:0.2317, loss-ulb:0.1462, weight:2.00, lr:0.0005
[03:56:49.454] iteration:7389  t-loss:0.3349, loss-lb:0.1479, loss-ulb:0.0935, weight:2.00, lr:0.0005
[03:56:49.773] iteration:7390  t-loss:0.5450, loss-lb:0.1599, loss-ulb:0.1926, weight:2.00, lr:0.0005
[03:56:50.089] iteration:7391  t-loss:0.5507, loss-lb:0.3548, loss-ulb:0.0980, weight:2.00, lr:0.0005
[03:56:50.407] iteration:7392  t-loss:0.5987, loss-lb:0.2164, loss-ulb:0.1911, weight:2.00, lr:0.0005
[03:56:50.719] iteration:7393  t-loss:0.3616, loss-lb:0.2332, loss-ulb:0.0642, weight:2.00, lr:0.0005
[03:56:51.035] iteration:7394  t-loss:0.3720, loss-lb:0.2860, loss-ulb:0.0430, weight:2.00, lr:0.0005
[03:56:51.358] iteration:7395  t-loss:0.3951, loss-lb:0.2211, loss-ulb:0.0870, weight:2.00, lr:0.0005
[03:56:51.687] iteration:7396  t-loss:0.5193, loss-lb:0.2881, loss-ulb:0.1156, weight:2.00, lr:0.0005
[03:56:52.003] iteration:7397  t-loss:0.3624, loss-lb:0.2104, loss-ulb:0.0760, weight:2.00, lr:0.0005
[03:56:52.318] iteration:7398  t-loss:0.3746, loss-lb:0.1636, loss-ulb:0.1055, weight:2.00, lr:0.0005
[03:56:52.638] iteration:7399  t-loss:0.4969, loss-lb:0.2244, loss-ulb:0.1362, weight:2.00, lr:0.0005
[03:56:52.962] iteration:7400  t-loss:0.5484, loss-lb:0.2114, loss-ulb:0.1685, weight:2.00, lr:0.0005
[03:56:54.782] iteration:7401  t-loss:0.8940, loss-lb:0.1306, loss-ulb:0.3817, weight:2.00, lr:0.0005
[03:56:55.142] iteration:7402  t-loss:0.2257, loss-lb:0.1868, loss-ulb:0.0194, weight:2.00, lr:0.0005
[03:56:55.487] iteration:7403  t-loss:0.3232, loss-lb:0.1567, loss-ulb:0.0832, weight:2.00, lr:0.0005
[03:56:55.834] iteration:7404  t-loss:0.5490, loss-lb:0.3244, loss-ulb:0.1123, weight:2.00, lr:0.0005
[03:56:56.166] iteration:7405  t-loss:0.5458, loss-lb:0.2991, loss-ulb:0.1233, weight:2.00, lr:0.0005
[03:56:56.488] iteration:7406  t-loss:0.3792, loss-lb:0.1906, loss-ulb:0.0943, weight:2.00, lr:0.0005
[03:56:56.811] iteration:7407  t-loss:0.8439, loss-lb:0.3590, loss-ulb:0.2425, weight:2.00, lr:0.0005
[03:56:57.132] iteration:7408  t-loss:0.3003, loss-lb:0.2285, loss-ulb:0.0359, weight:2.00, lr:0.0005
[03:56:57.450] iteration:7409  t-loss:0.3156, loss-lb:0.2034, loss-ulb:0.0561, weight:2.00, lr:0.0005
[03:56:57.764] iteration:7410  t-loss:0.4265, loss-lb:0.1493, loss-ulb:0.1386, weight:2.00, lr:0.0005
[03:56:58.085] iteration:7411  t-loss:0.5754, loss-lb:0.2616, loss-ulb:0.1569, weight:2.00, lr:0.0005
[03:56:58.403] iteration:7412  t-loss:0.5829, loss-lb:0.3447, loss-ulb:0.1191, weight:2.00, lr:0.0005
[03:56:58.717] iteration:7413  t-loss:0.4399, loss-lb:0.1913, loss-ulb:0.1243, weight:2.00, lr:0.0005
[03:56:59.032] iteration:7414  t-loss:0.2475, loss-lb:0.1399, loss-ulb:0.0538, weight:2.00, lr:0.0005
[03:56:59.356] iteration:7415  t-loss:0.2716, loss-lb:0.2069, loss-ulb:0.0323, weight:2.00, lr:0.0005
[03:56:59.675] iteration:7416  t-loss:0.3594, loss-lb:0.2258, loss-ulb:0.0668, weight:2.00, lr:0.0005
[03:56:59.993] iteration:7417  t-loss:0.3942, loss-lb:0.2134, loss-ulb:0.0904, weight:2.00, lr:0.0005
[03:57:00.310] iteration:7418  t-loss:0.3356, loss-lb:0.1319, loss-ulb:0.1018, weight:2.00, lr:0.0005
[03:57:00.626] iteration:7419  t-loss:0.3276, loss-lb:0.1833, loss-ulb:0.0721, weight:2.00, lr:0.0005
[03:57:00.948] iteration:7420  t-loss:0.6396, loss-lb:0.3489, loss-ulb:0.1454, weight:2.00, lr:0.0005
[03:57:01.267] iteration:7421  t-loss:0.4538, loss-lb:0.2261, loss-ulb:0.1138, weight:2.00, lr:0.0005
[03:57:01.580] iteration:7422  t-loss:0.2983, loss-lb:0.1443, loss-ulb:0.0770, weight:2.00, lr:0.0005
[03:57:01.904] iteration:7423  t-loss:0.7407, loss-lb:0.5465, loss-ulb:0.0971, weight:2.00, lr:0.0005
[03:57:02.223] iteration:7424  t-loss:0.3719, loss-lb:0.2487, loss-ulb:0.0616, weight:2.00, lr:0.0005
[03:57:02.541] iteration:7425  t-loss:0.2520, loss-lb:0.2140, loss-ulb:0.0190, weight:2.00, lr:0.0005
[03:59:09.133] iteration 7425 : dice_score: 0.844050 best_dice: 0.846000
[03:59:09.134]  <<Test>> - Ep:296  - Dice-S/T:84.02/84.41, Best-S:84.32, Best-T:84.60
[03:59:09.134]           - AvgLoss(lb/ulb/all):0.23/0.09/0.43
[03:59:10.331] iteration:7426  t-loss:0.3868, loss-lb:0.2097, loss-ulb:0.0885, weight:2.00, lr:0.0005
[03:59:10.667] iteration:7427  t-loss:0.3136, loss-lb:0.1756, loss-ulb:0.0690, weight:2.00, lr:0.0005
[03:59:11.002] iteration:7428  t-loss:0.3566, loss-lb:0.1997, loss-ulb:0.0785, weight:2.00, lr:0.0005
[03:59:11.329] iteration:7429  t-loss:0.4821, loss-lb:0.1635, loss-ulb:0.1593, weight:2.00, lr:0.0005
[03:59:11.658] iteration:7430  t-loss:0.5252, loss-lb:0.3161, loss-ulb:0.1045, weight:2.00, lr:0.0005
[03:59:11.981] iteration:7431  t-loss:0.3847, loss-lb:0.1703, loss-ulb:0.1072, weight:2.00, lr:0.0005
[03:59:12.299] iteration:7432  t-loss:0.3498, loss-lb:0.2071, loss-ulb:0.0714, weight:2.00, lr:0.0005
[03:59:12.611] iteration:7433  t-loss:0.2857, loss-lb:0.2386, loss-ulb:0.0235, weight:2.00, lr:0.0005
[03:59:12.925] iteration:7434  t-loss:0.2580, loss-lb:0.2149, loss-ulb:0.0216, weight:2.00, lr:0.0005
[03:59:13.247] iteration:7435  t-loss:0.2678, loss-lb:0.2314, loss-ulb:0.0182, weight:2.00, lr:0.0005
[03:59:13.564] iteration:7436  t-loss:0.3574, loss-lb:0.2517, loss-ulb:0.0528, weight:2.00, lr:0.0005
[03:59:13.877] iteration:7437  t-loss:0.3482, loss-lb:0.1568, loss-ulb:0.0957, weight:2.00, lr:0.0005
[03:59:14.193] iteration:7438  t-loss:0.6541, loss-lb:0.2200, loss-ulb:0.2171, weight:2.00, lr:0.0005
[03:59:14.517] iteration:7439  t-loss:0.3804, loss-lb:0.2512, loss-ulb:0.0646, weight:2.00, lr:0.0005
[03:59:14.853] iteration:7440  t-loss:0.2971, loss-lb:0.2422, loss-ulb:0.0274, weight:2.00, lr:0.0005
[03:59:15.187] iteration:7441  t-loss:0.3398, loss-lb:0.1493, loss-ulb:0.0953, weight:2.00, lr:0.0005
[03:59:15.518] iteration:7442  t-loss:0.2583, loss-lb:0.2099, loss-ulb:0.0242, weight:2.00, lr:0.0005
[03:59:15.863] iteration:7443  t-loss:0.5712, loss-lb:0.3614, loss-ulb:0.1049, weight:2.00, lr:0.0005
[03:59:16.186] iteration:7444  t-loss:0.5019, loss-lb:0.2946, loss-ulb:0.1036, weight:2.00, lr:0.0005
[03:59:16.500] iteration:7445  t-loss:0.4267, loss-lb:0.2855, loss-ulb:0.0706, weight:2.00, lr:0.0005
[03:59:16.815] iteration:7446  t-loss:0.2577, loss-lb:0.1869, loss-ulb:0.0354, weight:2.00, lr:0.0005
[03:59:17.131] iteration:7447  t-loss:0.6500, loss-lb:0.3553, loss-ulb:0.1473, weight:2.00, lr:0.0005
[03:59:17.451] iteration:7448  t-loss:0.7842, loss-lb:0.2684, loss-ulb:0.2579, weight:2.00, lr:0.0005
[03:59:17.771] iteration:7449  t-loss:0.4284, loss-lb:0.2104, loss-ulb:0.1090, weight:2.00, lr:0.0005
[03:59:18.086] iteration:7450  t-loss:0.3181, loss-lb:0.1890, loss-ulb:0.0646, weight:2.00, lr:0.0005
[03:59:19.377] iteration:7451  t-loss:0.4029, loss-lb:0.1841, loss-ulb:0.1094, weight:2.00, lr:0.0005
[03:59:19.712] iteration:7452  t-loss:0.6307, loss-lb:0.2253, loss-ulb:0.2027, weight:2.00, lr:0.0005
[03:59:20.035] iteration:7453  t-loss:0.3658, loss-lb:0.3205, loss-ulb:0.0226, weight:2.00, lr:0.0005
[03:59:20.357] iteration:7454  t-loss:0.9422, loss-lb:0.3398, loss-ulb:0.3012, weight:2.00, lr:0.0005
[03:59:20.676] iteration:7455  t-loss:0.5361, loss-lb:0.3176, loss-ulb:0.1092, weight:2.00, lr:0.0005
[03:59:20.990] iteration:7456  t-loss:0.4538, loss-lb:0.1662, loss-ulb:0.1438, weight:2.00, lr:0.0005
[03:59:21.302] iteration:7457  t-loss:0.2767, loss-lb:0.1568, loss-ulb:0.0600, weight:2.00, lr:0.0005
[03:59:21.619] iteration:7458  t-loss:0.7064, loss-lb:0.4032, loss-ulb:0.1516, weight:2.00, lr:0.0005
[03:59:21.933] iteration:7459  t-loss:0.4098, loss-lb:0.2895, loss-ulb:0.0601, weight:2.00, lr:0.0005
[03:59:22.242] iteration:7460  t-loss:0.2991, loss-lb:0.1272, loss-ulb:0.0860, weight:2.00, lr:0.0005
[03:59:22.559] iteration:7461  t-loss:0.5593, loss-lb:0.2230, loss-ulb:0.1681, weight:2.00, lr:0.0005
[03:59:22.880] iteration:7462  t-loss:0.2351, loss-lb:0.1680, loss-ulb:0.0335, weight:2.00, lr:0.0005
[03:59:23.211] iteration:7463  t-loss:0.4372, loss-lb:0.2502, loss-ulb:0.0935, weight:2.00, lr:0.0005
[03:59:23.540] iteration:7464  t-loss:0.2577, loss-lb:0.1777, loss-ulb:0.0400, weight:2.00, lr:0.0005
[03:59:23.878] iteration:7465  t-loss:0.5074, loss-lb:0.2513, loss-ulb:0.1280, weight:2.00, lr:0.0005
[03:59:24.205] iteration:7466  t-loss:0.5367, loss-lb:0.2379, loss-ulb:0.1494, weight:2.00, lr:0.0005
[03:59:24.528] iteration:7467  t-loss:0.4665, loss-lb:0.1500, loss-ulb:0.1582, weight:2.00, lr:0.0005
[03:59:24.853] iteration:7468  t-loss:0.3092, loss-lb:0.1902, loss-ulb:0.0595, weight:2.00, lr:0.0005
[03:59:25.171] iteration:7469  t-loss:0.2559, loss-lb:0.2069, loss-ulb:0.0245, weight:2.00, lr:0.0005
[03:59:25.489] iteration:7470  t-loss:0.4193, loss-lb:0.1740, loss-ulb:0.1226, weight:2.00, lr:0.0005
[03:59:25.808] iteration:7471  t-loss:0.3196, loss-lb:0.1141, loss-ulb:0.1028, weight:2.00, lr:0.0005
[03:59:26.125] iteration:7472  t-loss:0.4567, loss-lb:0.2115, loss-ulb:0.1226, weight:2.00, lr:0.0005
[03:59:26.441] iteration:7473  t-loss:0.3323, loss-lb:0.3001, loss-ulb:0.0161, weight:2.00, lr:0.0005
[03:59:26.754] iteration:7474  t-loss:0.3658, loss-lb:0.2728, loss-ulb:0.0465, weight:2.00, lr:0.0005
[03:59:27.069] iteration:7475  t-loss:0.3764, loss-lb:0.2329, loss-ulb:0.0717, weight:2.00, lr:0.0005
[03:59:28.532] iteration:7476  t-loss:0.2677, loss-lb:0.1638, loss-ulb:0.0519, weight:2.00, lr:0.0005
[03:59:28.876] iteration:7477  t-loss:0.1687, loss-lb:0.1362, loss-ulb:0.0163, weight:2.00, lr:0.0005
[03:59:29.216] iteration:7478  t-loss:0.5148, loss-lb:0.3545, loss-ulb:0.0802, weight:2.00, lr:0.0005
[03:59:29.548] iteration:7479  t-loss:0.2275, loss-lb:0.1405, loss-ulb:0.0435, weight:2.00, lr:0.0005
[03:59:29.876] iteration:7480  t-loss:0.4739, loss-lb:0.2118, loss-ulb:0.1310, weight:2.00, lr:0.0005
[03:59:30.199] iteration:7481  t-loss:0.6746, loss-lb:0.4076, loss-ulb:0.1335, weight:2.00, lr:0.0005
[03:59:30.514] iteration:7482  t-loss:0.3494, loss-lb:0.1833, loss-ulb:0.0831, weight:2.00, lr:0.0005
[03:59:30.832] iteration:7483  t-loss:0.4681, loss-lb:0.3216, loss-ulb:0.0733, weight:2.00, lr:0.0005
[03:59:31.155] iteration:7484  t-loss:0.5097, loss-lb:0.2083, loss-ulb:0.1507, weight:2.00, lr:0.0005
[03:59:31.484] iteration:7485  t-loss:0.8584, loss-lb:0.2395, loss-ulb:0.3094, weight:2.00, lr:0.0005
[03:59:31.810] iteration:7486  t-loss:0.1927, loss-lb:0.1630, loss-ulb:0.0148, weight:2.00, lr:0.0005
[03:59:32.159] iteration:7487  t-loss:0.6581, loss-lb:0.4788, loss-ulb:0.0896, weight:2.00, lr:0.0005
[03:59:32.502] iteration:7488  t-loss:0.4020, loss-lb:0.2827, loss-ulb:0.0596, weight:2.00, lr:0.0005
[03:59:32.873] iteration:7489  t-loss:0.3928, loss-lb:0.2253, loss-ulb:0.0838, weight:2.00, lr:0.0005
[03:59:33.200] iteration:7490  t-loss:0.3666, loss-lb:0.2719, loss-ulb:0.0474, weight:2.00, lr:0.0005
[03:59:33.527] iteration:7491  t-loss:0.3347, loss-lb:0.1562, loss-ulb:0.0892, weight:2.00, lr:0.0005
[03:59:33.852] iteration:7492  t-loss:0.6531, loss-lb:0.5894, loss-ulb:0.0318, weight:2.00, lr:0.0005
[03:59:34.168] iteration:7493  t-loss:0.2718, loss-lb:0.1653, loss-ulb:0.0533, weight:2.00, lr:0.0005
[03:59:34.486] iteration:7494  t-loss:0.6346, loss-lb:0.3020, loss-ulb:0.1663, weight:2.00, lr:0.0005
[03:59:34.800] iteration:7495  t-loss:0.2964, loss-lb:0.2620, loss-ulb:0.0172, weight:2.00, lr:0.0005
[03:59:35.115] iteration:7496  t-loss:0.2891, loss-lb:0.2222, loss-ulb:0.0334, weight:2.00, lr:0.0005
[03:59:35.432] iteration:7497  t-loss:0.3018, loss-lb:0.2016, loss-ulb:0.0501, weight:2.00, lr:0.0005
[03:59:35.757] iteration:7498  t-loss:0.3223, loss-lb:0.2320, loss-ulb:0.0452, weight:2.00, lr:0.0005
[03:59:36.072] iteration:7499  t-loss:0.5030, loss-lb:0.4035, loss-ulb:0.0497, weight:2.00, lr:0.0005
[03:59:36.389] iteration:7500  t-loss:0.3755, loss-lb:0.2159, loss-ulb:0.0798, weight:2.00, lr:0.0005
[03:59:37.787] iteration:7501  t-loss:0.4169, loss-lb:0.2526, loss-ulb:0.0821, weight:2.00, lr:0.0005
[03:59:38.127] iteration:7502  t-loss:0.5653, loss-lb:0.3956, loss-ulb:0.0848, weight:2.00, lr:0.0005
[03:59:38.457] iteration:7503  t-loss:0.2991, loss-lb:0.2440, loss-ulb:0.0276, weight:2.00, lr:0.0005
[03:59:38.782] iteration:7504  t-loss:0.6517, loss-lb:0.3840, loss-ulb:0.1338, weight:2.00, lr:0.0005
[03:59:39.102] iteration:7505  t-loss:0.2450, loss-lb:0.1334, loss-ulb:0.0558, weight:2.00, lr:0.0005
[03:59:39.419] iteration:7506  t-loss:0.3391, loss-lb:0.2379, loss-ulb:0.0506, weight:2.00, lr:0.0005
[03:59:39.737] iteration:7507  t-loss:0.3302, loss-lb:0.2821, loss-ulb:0.0240, weight:2.00, lr:0.0005
[03:59:40.068] iteration:7508  t-loss:0.6031, loss-lb:0.1902, loss-ulb:0.2065, weight:2.00, lr:0.0005
[03:59:40.393] iteration:7509  t-loss:0.9669, loss-lb:0.1601, loss-ulb:0.4034, weight:2.00, lr:0.0005
[03:59:40.721] iteration:7510  t-loss:0.4363, loss-lb:0.2021, loss-ulb:0.1171, weight:2.00, lr:0.0005
[03:59:41.045] iteration:7511  t-loss:0.2520, loss-lb:0.1918, loss-ulb:0.0301, weight:2.00, lr:0.0005
[03:59:41.366] iteration:7512  t-loss:0.3073, loss-lb:0.2546, loss-ulb:0.0263, weight:2.00, lr:0.0005
[03:59:41.685] iteration:7513  t-loss:0.4247, loss-lb:0.1137, loss-ulb:0.1555, weight:2.00, lr:0.0005
[03:59:42.004] iteration:7514  t-loss:0.2258, loss-lb:0.1791, loss-ulb:0.0233, weight:2.00, lr:0.0005
[03:59:42.324] iteration:7515  t-loss:0.1968, loss-lb:0.1569, loss-ulb:0.0199, weight:2.00, lr:0.0005
[03:59:42.647] iteration:7516  t-loss:0.4873, loss-lb:0.2642, loss-ulb:0.1116, weight:2.00, lr:0.0005
[03:59:42.966] iteration:7517  t-loss:0.3327, loss-lb:0.2849, loss-ulb:0.0239, weight:2.00, lr:0.0005
[03:59:43.285] iteration:7518  t-loss:0.3107, loss-lb:0.1709, loss-ulb:0.0699, weight:2.00, lr:0.0005
[03:59:43.601] iteration:7519  t-loss:0.4525, loss-lb:0.3329, loss-ulb:0.0598, weight:2.00, lr:0.0005
[03:59:43.920] iteration:7520  t-loss:0.3745, loss-lb:0.2022, loss-ulb:0.0861, weight:2.00, lr:0.0005
[03:59:44.235] iteration:7521  t-loss:0.2514, loss-lb:0.1439, loss-ulb:0.0537, weight:2.00, lr:0.0005
[03:59:44.550] iteration:7522  t-loss:0.2121, loss-lb:0.1859, loss-ulb:0.0131, weight:2.00, lr:0.0005
[03:59:44.870] iteration:7523  t-loss:0.4390, loss-lb:0.1279, loss-ulb:0.1556, weight:2.00, lr:0.0005
[03:59:45.190] iteration:7524  t-loss:0.2720, loss-lb:0.2286, loss-ulb:0.0217, weight:2.00, lr:0.0005
[03:59:45.507] iteration:7525  t-loss:0.4661, loss-lb:0.1935, loss-ulb:0.1363, weight:2.00, lr:0.0005
[04:01:53.537] iteration 7525 : dice_score: 0.841947 best_dice: 0.846000
[04:01:53.538]  <<Test>> - Ep:300  - Dice-S/T:83.59/84.19, Best-S:84.32, Best-T:84.60
[04:01:53.538]           - AvgLoss(lb/ulb/all):0.22/0.09/0.38
[04:01:54.658] iteration:7526  t-loss:0.2473, loss-lb:0.1875, loss-ulb:0.0299, weight:2.00, lr:0.0005
[04:01:54.986] iteration:7527  t-loss:0.3424, loss-lb:0.1695, loss-ulb:0.0865, weight:2.00, lr:0.0005
[04:01:55.310] iteration:7528  t-loss:0.4589, loss-lb:0.1930, loss-ulb:0.1329, weight:2.00, lr:0.0005
[04:01:55.631] iteration:7529  t-loss:0.3988, loss-lb:0.1950, loss-ulb:0.1019, weight:2.00, lr:0.0005
[04:01:55.953] iteration:7530  t-loss:0.4311, loss-lb:0.2754, loss-ulb:0.0778, weight:2.00, lr:0.0005
[04:01:56.268] iteration:7531  t-loss:0.5835, loss-lb:0.1228, loss-ulb:0.2303, weight:2.00, lr:0.0005
[04:01:56.586] iteration:7532  t-loss:0.4114, loss-lb:0.2020, loss-ulb:0.1047, weight:2.00, lr:0.0005
[04:01:56.900] iteration:7533  t-loss:0.3309, loss-lb:0.1473, loss-ulb:0.0918, weight:2.00, lr:0.0005
[04:01:57.222] iteration:7534  t-loss:0.6995, loss-lb:0.2243, loss-ulb:0.2376, weight:2.00, lr:0.0005
[04:01:57.546] iteration:7535  t-loss:0.2480, loss-lb:0.1962, loss-ulb:0.0259, weight:2.00, lr:0.0005
[04:01:57.895] iteration:7536  t-loss:0.4057, loss-lb:0.1764, loss-ulb:0.1147, weight:2.00, lr:0.0005
[04:01:58.238] iteration:7537  t-loss:0.6918, loss-lb:0.4569, loss-ulb:0.1174, weight:2.00, lr:0.0005
[04:01:58.580] iteration:7538  t-loss:0.3519, loss-lb:0.2355, loss-ulb:0.0582, weight:2.00, lr:0.0005
[04:01:58.910] iteration:7539  t-loss:0.2576, loss-lb:0.2170, loss-ulb:0.0203, weight:2.00, lr:0.0005
[04:01:59.233] iteration:7540  t-loss:0.4327, loss-lb:0.2573, loss-ulb:0.0877, weight:2.00, lr:0.0005
[04:01:59.557] iteration:7541  t-loss:0.3384, loss-lb:0.2623, loss-ulb:0.0380, weight:2.00, lr:0.0005
[04:01:59.877] iteration:7542  t-loss:0.5149, loss-lb:0.2701, loss-ulb:0.1224, weight:2.00, lr:0.0005
[04:02:00.197] iteration:7543  t-loss:0.4494, loss-lb:0.3241, loss-ulb:0.0626, weight:2.00, lr:0.0005
[04:02:00.515] iteration:7544  t-loss:0.4194, loss-lb:0.2181, loss-ulb:0.1007, weight:2.00, lr:0.0005
[04:02:00.830] iteration:7545  t-loss:0.2354, loss-lb:0.1899, loss-ulb:0.0228, weight:2.00, lr:0.0005
[04:02:01.147] iteration:7546  t-loss:0.2963, loss-lb:0.2384, loss-ulb:0.0290, weight:2.00, lr:0.0005
[04:02:01.467] iteration:7547  t-loss:0.2647, loss-lb:0.1835, loss-ulb:0.0406, weight:2.00, lr:0.0005
[04:02:01.780] iteration:7548  t-loss:0.5226, loss-lb:0.2098, loss-ulb:0.1564, weight:2.00, lr:0.0005
[04:02:02.099] iteration:7549  t-loss:0.3908, loss-lb:0.2585, loss-ulb:0.0662, weight:2.00, lr:0.0005
[04:02:02.419] iteration:7550  t-loss:0.4985, loss-lb:0.2890, loss-ulb:0.1047, weight:2.00, lr:0.0005
[04:02:03.594] iteration:7551  t-loss:0.3603, loss-lb:0.1925, loss-ulb:0.0839, weight:2.00, lr:0.0005
[04:02:03.919] iteration:7552  t-loss:0.2359, loss-lb:0.1801, loss-ulb:0.0279, weight:2.00, lr:0.0005
[04:02:04.246] iteration:7553  t-loss:0.2644, loss-lb:0.1693, loss-ulb:0.0476, weight:2.00, lr:0.0005
[04:02:04.567] iteration:7554  t-loss:0.5781, loss-lb:0.3097, loss-ulb:0.1342, weight:2.00, lr:0.0005
[04:02:04.882] iteration:7555  t-loss:0.3639, loss-lb:0.3095, loss-ulb:0.0272, weight:2.00, lr:0.0005
[04:02:05.198] iteration:7556  t-loss:0.3346, loss-lb:0.1606, loss-ulb:0.0870, weight:2.00, lr:0.0005
[04:02:05.516] iteration:7557  t-loss:0.3999, loss-lb:0.1379, loss-ulb:0.1310, weight:2.00, lr:0.0005
[04:02:05.849] iteration:7558  t-loss:0.3769, loss-lb:0.2277, loss-ulb:0.0746, weight:2.00, lr:0.0005
[04:02:06.181] iteration:7559  t-loss:0.4460, loss-lb:0.1697, loss-ulb:0.1381, weight:2.00, lr:0.0005
[04:02:06.536] iteration:7560  t-loss:0.5987, loss-lb:0.4076, loss-ulb:0.0956, weight:2.00, lr:0.0005
[04:02:06.893] iteration:7561  t-loss:0.7433, loss-lb:0.3155, loss-ulb:0.2139, weight:2.00, lr:0.0005
[04:02:07.232] iteration:7562  t-loss:0.2113, loss-lb:0.1369, loss-ulb:0.0372, weight:2.00, lr:0.0005
[04:02:07.574] iteration:7563  t-loss:0.2855, loss-lb:0.2255, loss-ulb:0.0300, weight:2.00, lr:0.0005
[04:02:07.905] iteration:7564  t-loss:0.4596, loss-lb:0.1668, loss-ulb:0.1464, weight:2.00, lr:0.0005
[04:02:08.238] iteration:7565  t-loss:0.5518, loss-lb:0.3924, loss-ulb:0.0797, weight:2.00, lr:0.0005
[04:02:08.575] iteration:7566  t-loss:0.4404, loss-lb:0.2783, loss-ulb:0.0810, weight:2.00, lr:0.0005
[04:02:08.896] iteration:7567  t-loss:0.3430, loss-lb:0.2228, loss-ulb:0.0601, weight:2.00, lr:0.0005
[04:02:09.214] iteration:7568  t-loss:0.4122, loss-lb:0.3130, loss-ulb:0.0496, weight:2.00, lr:0.0005
[04:02:09.534] iteration:7569  t-loss:0.4219, loss-lb:0.2390, loss-ulb:0.0915, weight:2.00, lr:0.0005
[04:02:09.845] iteration:7570  t-loss:0.2473, loss-lb:0.1409, loss-ulb:0.0532, weight:2.00, lr:0.0005
[04:02:10.161] iteration:7571  t-loss:0.4071, loss-lb:0.2348, loss-ulb:0.0861, weight:2.00, lr:0.0005
[04:02:10.478] iteration:7572  t-loss:0.3269, loss-lb:0.1661, loss-ulb:0.0804, weight:2.00, lr:0.0005
[04:02:10.794] iteration:7573  t-loss:0.3203, loss-lb:0.1770, loss-ulb:0.0717, weight:2.00, lr:0.0005
[04:02:11.110] iteration:7574  t-loss:0.2319, loss-lb:0.1944, loss-ulb:0.0187, weight:2.00, lr:0.0005
[04:02:11.428] iteration:7575  t-loss:0.4109, loss-lb:0.1867, loss-ulb:0.1121, weight:2.00, lr:0.0005
[04:02:12.518] iteration:7576  t-loss:0.2969, loss-lb:0.2546, loss-ulb:0.0212, weight:2.00, lr:0.0005
[04:02:12.849] iteration:7577  t-loss:0.3971, loss-lb:0.2003, loss-ulb:0.0984, weight:2.00, lr:0.0005
[04:02:13.174] iteration:7578  t-loss:0.2842, loss-lb:0.2009, loss-ulb:0.0416, weight:2.00, lr:0.0005
[04:02:13.487] iteration:7579  t-loss:0.3693, loss-lb:0.3276, loss-ulb:0.0208, weight:2.00, lr:0.0005
[04:02:13.805] iteration:7580  t-loss:0.2975, loss-lb:0.1873, loss-ulb:0.0551, weight:2.00, lr:0.0005
[04:02:14.124] iteration:7581  t-loss:0.3625, loss-lb:0.1559, loss-ulb:0.1033, weight:2.00, lr:0.0005
[04:02:14.442] iteration:7582  t-loss:0.5809, loss-lb:0.3055, loss-ulb:0.1377, weight:2.00, lr:0.0005
[04:02:14.761] iteration:7583  t-loss:0.2229, loss-lb:0.1765, loss-ulb:0.0232, weight:2.00, lr:0.0005
[04:02:15.090] iteration:7584  t-loss:0.2592, loss-lb:0.2334, loss-ulb:0.0129, weight:2.00, lr:0.0005
[04:02:15.421] iteration:7585  t-loss:0.4937, loss-lb:0.2602, loss-ulb:0.1167, weight:2.00, lr:0.0005
[04:02:15.760] iteration:7586  t-loss:0.8205, loss-lb:0.3550, loss-ulb:0.2328, weight:2.00, lr:0.0005
[04:02:16.087] iteration:7587  t-loss:0.2503, loss-lb:0.2077, loss-ulb:0.0213, weight:2.00, lr:0.0005
[04:02:16.403] iteration:7588  t-loss:0.3146, loss-lb:0.2603, loss-ulb:0.0271, weight:2.00, lr:0.0005
[04:02:16.732] iteration:7589  t-loss:0.3330, loss-lb:0.1932, loss-ulb:0.0699, weight:2.00, lr:0.0005
[04:02:17.057] iteration:7590  t-loss:0.4423, loss-lb:0.1761, loss-ulb:0.1331, weight:2.00, lr:0.0005
[04:02:17.381] iteration:7591  t-loss:0.2593, loss-lb:0.2129, loss-ulb:0.0232, weight:2.00, lr:0.0005
[04:02:17.701] iteration:7592  t-loss:0.3082, loss-lb:0.2317, loss-ulb:0.0382, weight:2.00, lr:0.0005
[04:02:18.016] iteration:7593  t-loss:0.2634, loss-lb:0.2024, loss-ulb:0.0305, weight:2.00, lr:0.0005
[04:02:18.334] iteration:7594  t-loss:0.4571, loss-lb:0.1315, loss-ulb:0.1628, weight:2.00, lr:0.0005
[04:02:18.650] iteration:7595  t-loss:0.3643, loss-lb:0.1979, loss-ulb:0.0832, weight:2.00, lr:0.0005
[04:02:18.966] iteration:7596  t-loss:0.3431, loss-lb:0.2791, loss-ulb:0.0320, weight:2.00, lr:0.0005
[04:02:19.280] iteration:7597  t-loss:0.3292, loss-lb:0.2850, loss-ulb:0.0221, weight:2.00, lr:0.0005
[04:02:19.603] iteration:7598  t-loss:0.3130, loss-lb:0.2331, loss-ulb:0.0399, weight:2.00, lr:0.0005
[04:02:19.920] iteration:7599  t-loss:0.4845, loss-lb:0.3300, loss-ulb:0.0773, weight:2.00, lr:0.0005
[04:02:20.241] iteration:7600  t-loss:0.4637, loss-lb:0.2785, loss-ulb:0.0926, weight:2.00, lr:0.0005
[04:02:21.300] iteration:7601  t-loss:0.1992, loss-lb:0.1605, loss-ulb:0.0194, weight:2.00, lr:0.0005
[04:02:21.626] iteration:7602  t-loss:0.3397, loss-lb:0.1893, loss-ulb:0.0752, weight:2.00, lr:0.0005
[04:02:21.953] iteration:7603  t-loss:0.4201, loss-lb:0.1596, loss-ulb:0.1302, weight:2.00, lr:0.0005
[04:02:22.270] iteration:7604  t-loss:0.4505, loss-lb:0.2230, loss-ulb:0.1137, weight:2.00, lr:0.0005
[04:02:22.588] iteration:7605  t-loss:0.6415, loss-lb:0.4740, loss-ulb:0.0838, weight:2.00, lr:0.0005
[04:02:22.902] iteration:7606  t-loss:0.1854, loss-lb:0.1516, loss-ulb:0.0169, weight:2.00, lr:0.0005
[04:02:23.221] iteration:7607  t-loss:0.3391, loss-lb:0.1800, loss-ulb:0.0796, weight:2.00, lr:0.0005
[04:02:23.541] iteration:7608  t-loss:0.3911, loss-lb:0.1492, loss-ulb:0.1209, weight:2.00, lr:0.0005
[04:02:23.863] iteration:7609  t-loss:0.4300, loss-lb:0.3360, loss-ulb:0.0470, weight:2.00, lr:0.0005
[04:02:24.193] iteration:7610  t-loss:0.3042, loss-lb:0.1971, loss-ulb:0.0536, weight:2.00, lr:0.0005
[04:02:24.512] iteration:7611  t-loss:0.5500, loss-lb:0.3488, loss-ulb:0.1006, weight:2.00, lr:0.0005
[04:02:24.833] iteration:7612  t-loss:0.3308, loss-lb:0.2864, loss-ulb:0.0222, weight:2.00, lr:0.0005
[04:02:25.159] iteration:7613  t-loss:0.2976, loss-lb:0.1395, loss-ulb:0.0791, weight:2.00, lr:0.0005
[04:02:25.481] iteration:7614  t-loss:0.2980, loss-lb:0.2147, loss-ulb:0.0416, weight:2.00, lr:0.0005
[04:02:25.803] iteration:7615  t-loss:0.3041, loss-lb:0.1773, loss-ulb:0.0634, weight:2.00, lr:0.0005
[04:02:26.124] iteration:7616  t-loss:0.5577, loss-lb:0.1472, loss-ulb:0.2053, weight:2.00, lr:0.0005
[04:02:26.444] iteration:7617  t-loss:0.3745, loss-lb:0.2665, loss-ulb:0.0540, weight:2.00, lr:0.0005
[04:02:26.763] iteration:7618  t-loss:0.4179, loss-lb:0.2227, loss-ulb:0.0976, weight:2.00, lr:0.0005
[04:02:27.078] iteration:7619  t-loss:0.4693, loss-lb:0.1683, loss-ulb:0.1505, weight:2.00, lr:0.0005
[04:02:27.396] iteration:7620  t-loss:0.3538, loss-lb:0.3113, loss-ulb:0.0212, weight:2.00, lr:0.0005
[04:02:27.712] iteration:7621  t-loss:0.4723, loss-lb:0.1706, loss-ulb:0.1509, weight:2.00, lr:0.0005
[04:02:28.027] iteration:7622  t-loss:0.2967, loss-lb:0.1560, loss-ulb:0.0704, weight:2.00, lr:0.0005
[04:02:28.348] iteration:7623  t-loss:0.2633, loss-lb:0.2428, loss-ulb:0.0102, weight:2.00, lr:0.0005
[04:02:28.667] iteration:7624  t-loss:0.2747, loss-lb:0.2409, loss-ulb:0.0169, weight:2.00, lr:0.0005
[04:02:28.987] iteration:7625  t-loss:0.3524, loss-lb:0.2137, loss-ulb:0.0694, weight:2.00, lr:0.0005
[04:04:30.369] iteration 7625 : dice_score: 0.844303 best_dice: 0.846000
[04:04:30.369]  <<Test>> - Ep:304  - Dice-S/T:84.08/84.43, Best-S:84.32, Best-T:84.60
[04:04:30.369]           - AvgLoss(lb/ulb/all):0.22/0.07/0.36
[04:04:31.443] iteration:7626  t-loss:0.2887, loss-lb:0.2357, loss-ulb:0.0265, weight:2.00, lr:0.0005
[04:04:31.794] iteration:7627  t-loss:0.4072, loss-lb:0.2433, loss-ulb:0.0820, weight:2.00, lr:0.0005
[04:04:32.120] iteration:7628  t-loss:0.3662, loss-lb:0.3132, loss-ulb:0.0265, weight:2.00, lr:0.0005
[04:04:32.436] iteration:7629  t-loss:0.2334, loss-lb:0.1956, loss-ulb:0.0189, weight:2.00, lr:0.0005
[04:04:32.752] iteration:7630  t-loss:0.3853, loss-lb:0.2051, loss-ulb:0.0901, weight:2.00, lr:0.0005
[04:04:33.074] iteration:7631  t-loss:0.3781, loss-lb:0.2307, loss-ulb:0.0737, weight:2.00, lr:0.0005
[04:04:33.400] iteration:7632  t-loss:0.4146, loss-lb:0.2500, loss-ulb:0.0823, weight:2.00, lr:0.0005
[04:04:33.726] iteration:7633  t-loss:0.6486, loss-lb:0.2924, loss-ulb:0.1781, weight:2.00, lr:0.0005
[04:04:34.047] iteration:7634  t-loss:0.3578, loss-lb:0.1860, loss-ulb:0.0859, weight:2.00, lr:0.0005
[04:04:34.378] iteration:7635  t-loss:0.3037, loss-lb:0.1966, loss-ulb:0.0535, weight:2.00, lr:0.0005
[04:04:34.712] iteration:7636  t-loss:0.3886, loss-lb:0.1815, loss-ulb:0.1036, weight:2.00, lr:0.0005
[04:04:35.061] iteration:7637  t-loss:0.2740, loss-lb:0.2337, loss-ulb:0.0201, weight:2.00, lr:0.0005
[04:04:35.429] iteration:7638  t-loss:0.4962, loss-lb:0.2170, loss-ulb:0.1396, weight:2.00, lr:0.0005
[04:04:35.782] iteration:7639  t-loss:0.4480, loss-lb:0.2043, loss-ulb:0.1219, weight:2.00, lr:0.0005
[04:04:36.121] iteration:7640  t-loss:0.4317, loss-lb:0.1578, loss-ulb:0.1369, weight:2.00, lr:0.0005
[04:04:36.461] iteration:7641  t-loss:0.2618, loss-lb:0.2349, loss-ulb:0.0135, weight:2.00, lr:0.0005
[04:04:36.806] iteration:7642  t-loss:0.4051, loss-lb:0.1473, loss-ulb:0.1289, weight:2.00, lr:0.0005
[04:04:37.134] iteration:7643  t-loss:0.2153, loss-lb:0.1772, loss-ulb:0.0191, weight:2.00, lr:0.0005
[04:04:37.450] iteration:7644  t-loss:0.8483, loss-lb:0.2366, loss-ulb:0.3059, weight:2.00, lr:0.0005
[04:04:37.768] iteration:7645  t-loss:0.2882, loss-lb:0.1900, loss-ulb:0.0491, weight:2.00, lr:0.0005
[04:04:38.083] iteration:7646  t-loss:0.4206, loss-lb:0.2074, loss-ulb:0.1066, weight:2.00, lr:0.0005
[04:04:38.401] iteration:7647  t-loss:0.2363, loss-lb:0.2029, loss-ulb:0.0167, weight:2.00, lr:0.0005
[04:04:38.718] iteration:7648  t-loss:0.3858, loss-lb:0.2992, loss-ulb:0.0433, weight:2.00, lr:0.0005
[04:04:39.030] iteration:7649  t-loss:0.3816, loss-lb:0.1542, loss-ulb:0.1137, weight:2.00, lr:0.0005
[04:04:39.348] iteration:7650  t-loss:0.4915, loss-lb:0.2542, loss-ulb:0.1187, weight:2.00, lr:0.0005
[04:04:40.790] iteration:7651  t-loss:0.3153, loss-lb:0.1314, loss-ulb:0.0919, weight:2.00, lr:0.0005
[04:04:41.121] iteration:7652  t-loss:0.2619, loss-lb:0.1294, loss-ulb:0.0663, weight:2.00, lr:0.0005
[04:04:41.437] iteration:7653  t-loss:0.4080, loss-lb:0.2123, loss-ulb:0.0978, weight:2.00, lr:0.0005
[04:04:41.754] iteration:7654  t-loss:0.5535, loss-lb:0.2280, loss-ulb:0.1628, weight:2.00, lr:0.0005
[04:04:42.066] iteration:7655  t-loss:1.3529, loss-lb:0.1593, loss-ulb:0.5968, weight:2.00, lr:0.0005
[04:04:42.388] iteration:7656  t-loss:0.9123, loss-lb:0.3634, loss-ulb:0.2745, weight:2.00, lr:0.0005
[04:04:42.707] iteration:7657  t-loss:0.2684, loss-lb:0.1664, loss-ulb:0.0510, weight:2.00, lr:0.0005
[04:04:43.023] iteration:7658  t-loss:0.3152, loss-lb:0.2679, loss-ulb:0.0236, weight:2.00, lr:0.0005
[04:04:43.342] iteration:7659  t-loss:0.3867, loss-lb:0.3018, loss-ulb:0.0424, weight:2.00, lr:0.0005
[04:04:43.675] iteration:7660  t-loss:0.4491, loss-lb:0.3698, loss-ulb:0.0396, weight:2.00, lr:0.0005
[04:04:44.015] iteration:7661  t-loss:0.5232, loss-lb:0.3312, loss-ulb:0.0960, weight:2.00, lr:0.0005
[04:04:44.371] iteration:7662  t-loss:0.6697, loss-lb:0.2652, loss-ulb:0.2023, weight:2.00, lr:0.0005
[04:04:44.704] iteration:7663  t-loss:0.2748, loss-lb:0.1473, loss-ulb:0.0638, weight:2.00, lr:0.0005
[04:04:45.040] iteration:7664  t-loss:0.4845, loss-lb:0.3430, loss-ulb:0.0707, weight:2.00, lr:0.0005
[04:04:45.377] iteration:7665  t-loss:0.2172, loss-lb:0.1808, loss-ulb:0.0182, weight:2.00, lr:0.0005
[04:04:45.712] iteration:7666  t-loss:0.7361, loss-lb:0.2955, loss-ulb:0.2203, weight:2.00, lr:0.0005
[04:04:46.037] iteration:7667  t-loss:0.4805, loss-lb:0.2427, loss-ulb:0.1189, weight:2.00, lr:0.0005
[04:04:46.359] iteration:7668  t-loss:0.6050, loss-lb:0.4274, loss-ulb:0.0888, weight:2.00, lr:0.0005
[04:04:46.690] iteration:7669  t-loss:0.4605, loss-lb:0.1803, loss-ulb:0.1401, weight:2.00, lr:0.0005
[04:04:47.011] iteration:7670  t-loss:0.4209, loss-lb:0.2621, loss-ulb:0.0794, weight:2.00, lr:0.0005
[04:04:47.331] iteration:7671  t-loss:0.7035, loss-lb:0.3487, loss-ulb:0.1774, weight:2.00, lr:0.0005
[04:04:47.652] iteration:7672  t-loss:0.4338, loss-lb:0.1884, loss-ulb:0.1227, weight:2.00, lr:0.0005
[04:04:47.968] iteration:7673  t-loss:0.3698, loss-lb:0.1890, loss-ulb:0.0904, weight:2.00, lr:0.0005
[04:04:48.284] iteration:7674  t-loss:0.2160, loss-lb:0.1714, loss-ulb:0.0223, weight:2.00, lr:0.0005
[04:04:48.600] iteration:7675  t-loss:0.3538, loss-lb:0.1933, loss-ulb:0.0802, weight:2.00, lr:0.0005
[04:04:49.913] iteration:7676  t-loss:0.2328, loss-lb:0.1363, loss-ulb:0.0482, weight:2.00, lr:0.0005
[04:04:50.240] iteration:7677  t-loss:0.2192, loss-lb:0.1782, loss-ulb:0.0205, weight:2.00, lr:0.0005
[04:04:50.561] iteration:7678  t-loss:0.4441, loss-lb:0.2187, loss-ulb:0.1127, weight:2.00, lr:0.0005
[04:04:50.877] iteration:7679  t-loss:0.4726, loss-lb:0.2734, loss-ulb:0.0996, weight:2.00, lr:0.0005
[04:04:51.193] iteration:7680  t-loss:0.4827, loss-lb:0.3193, loss-ulb:0.0817, weight:2.00, lr:0.0005
[04:04:51.514] iteration:7681  t-loss:0.3009, loss-lb:0.1547, loss-ulb:0.0731, weight:2.00, lr:0.0005
[04:04:51.829] iteration:7682  t-loss:0.3468, loss-lb:0.2834, loss-ulb:0.0317, weight:2.00, lr:0.0005
[04:04:52.145] iteration:7683  t-loss:0.4367, loss-lb:0.3216, loss-ulb:0.0575, weight:2.00, lr:0.0005
[04:04:52.470] iteration:7684  t-loss:0.3660, loss-lb:0.1705, loss-ulb:0.0978, weight:2.00, lr:0.0005
[04:04:52.825] iteration:7685  t-loss:0.3916, loss-lb:0.1809, loss-ulb:0.1053, weight:2.00, lr:0.0005
[04:04:53.159] iteration:7686  t-loss:0.3146, loss-lb:0.1598, loss-ulb:0.0774, weight:2.00, lr:0.0005
[04:04:53.496] iteration:7687  t-loss:0.2005, loss-lb:0.1478, loss-ulb:0.0263, weight:2.00, lr:0.0005
[04:04:53.830] iteration:7688  t-loss:0.3625, loss-lb:0.2046, loss-ulb:0.0789, weight:2.00, lr:0.0005
[04:04:54.153] iteration:7689  t-loss:0.5083, loss-lb:0.2254, loss-ulb:0.1415, weight:2.00, lr:0.0005
[04:04:54.495] iteration:7690  t-loss:0.4634, loss-lb:0.2077, loss-ulb:0.1278, weight:2.00, lr:0.0005
[04:04:54.832] iteration:7691  t-loss:0.2267, loss-lb:0.1830, loss-ulb:0.0218, weight:2.00, lr:0.0005
[04:04:55.149] iteration:7692  t-loss:0.2312, loss-lb:0.1674, loss-ulb:0.0319, weight:2.00, lr:0.0005
[04:04:55.468] iteration:7693  t-loss:0.6391, loss-lb:0.3839, loss-ulb:0.1276, weight:2.00, lr:0.0005
[04:04:55.784] iteration:7694  t-loss:0.7135, loss-lb:0.1983, loss-ulb:0.2576, weight:2.00, lr:0.0005
[04:04:56.102] iteration:7695  t-loss:0.6384, loss-lb:0.5359, loss-ulb:0.0513, weight:2.00, lr:0.0005
[04:04:56.416] iteration:7696  t-loss:0.8729, loss-lb:0.2706, loss-ulb:0.3011, weight:2.00, lr:0.0005
[04:04:56.730] iteration:7697  t-loss:0.5904, loss-lb:0.3229, loss-ulb:0.1337, weight:2.00, lr:0.0005
[04:04:57.047] iteration:7698  t-loss:0.4897, loss-lb:0.2866, loss-ulb:0.1015, weight:2.00, lr:0.0005
[04:04:57.362] iteration:7699  t-loss:0.2571, loss-lb:0.2047, loss-ulb:0.0262, weight:2.00, lr:0.0005
[04:04:57.684] iteration:7700  t-loss:0.2636, loss-lb:0.1739, loss-ulb:0.0448, weight:2.00, lr:0.0005
[04:04:58.905] iteration:7701  t-loss:0.5510, loss-lb:0.4569, loss-ulb:0.0471, weight:2.00, lr:0.0005
[04:04:59.237] iteration:7702  t-loss:0.3638, loss-lb:0.1880, loss-ulb:0.0879, weight:2.00, lr:0.0005
[04:04:59.565] iteration:7703  t-loss:0.5091, loss-lb:0.3050, loss-ulb:0.1021, weight:2.00, lr:0.0005
[04:04:59.891] iteration:7704  t-loss:0.6532, loss-lb:0.2369, loss-ulb:0.2081, weight:2.00, lr:0.0005
[04:05:00.210] iteration:7705  t-loss:0.2766, loss-lb:0.2250, loss-ulb:0.0258, weight:2.00, lr:0.0005
[04:05:00.526] iteration:7706  t-loss:0.3386, loss-lb:0.2879, loss-ulb:0.0253, weight:2.00, lr:0.0005
[04:05:00.843] iteration:7707  t-loss:0.3479, loss-lb:0.1775, loss-ulb:0.0852, weight:2.00, lr:0.0005
[04:05:01.174] iteration:7708  t-loss:1.0268, loss-lb:0.2106, loss-ulb:0.4081, weight:2.00, lr:0.0005
[04:05:01.520] iteration:7709  t-loss:0.5282, loss-lb:0.2739, loss-ulb:0.1271, weight:2.00, lr:0.0005
[04:05:01.848] iteration:7710  t-loss:0.4749, loss-lb:0.2459, loss-ulb:0.1145, weight:2.00, lr:0.0005
[04:05:02.182] iteration:7711  t-loss:0.4467, loss-lb:0.1947, loss-ulb:0.1260, weight:2.00, lr:0.0005
[04:05:02.501] iteration:7712  t-loss:0.3239, loss-lb:0.2724, loss-ulb:0.0258, weight:2.00, lr:0.0005
[04:05:02.823] iteration:7713  t-loss:0.3635, loss-lb:0.2618, loss-ulb:0.0508, weight:2.00, lr:0.0005
[04:05:03.139] iteration:7714  t-loss:0.4289, loss-lb:0.2126, loss-ulb:0.1081, weight:2.00, lr:0.0005
[04:05:03.457] iteration:7715  t-loss:0.4457, loss-lb:0.2788, loss-ulb:0.0834, weight:2.00, lr:0.0005
[04:05:03.776] iteration:7716  t-loss:0.2122, loss-lb:0.1601, loss-ulb:0.0261, weight:2.00, lr:0.0005
[04:05:04.096] iteration:7717  t-loss:0.5290, loss-lb:0.1806, loss-ulb:0.1742, weight:2.00, lr:0.0005
[04:05:04.421] iteration:7718  t-loss:0.4233, loss-lb:0.2176, loss-ulb:0.1029, weight:2.00, lr:0.0005
[04:05:04.736] iteration:7719  t-loss:0.3172, loss-lb:0.1837, loss-ulb:0.0667, weight:2.00, lr:0.0005
[04:05:05.052] iteration:7720  t-loss:0.2359, loss-lb:0.1374, loss-ulb:0.0492, weight:2.00, lr:0.0005
[04:05:05.360] iteration:7721  t-loss:0.6174, loss-lb:0.1938, loss-ulb:0.2118, weight:2.00, lr:0.0005
[04:05:05.676] iteration:7722  t-loss:0.5566, loss-lb:0.2411, loss-ulb:0.1577, weight:2.00, lr:0.0005
[04:05:05.990] iteration:7723  t-loss:0.3415, loss-lb:0.2256, loss-ulb:0.0579, weight:2.00, lr:0.0005
[04:05:06.307] iteration:7724  t-loss:0.2664, loss-lb:0.1646, loss-ulb:0.0509, weight:2.00, lr:0.0005
[04:05:06.624] iteration:7725  t-loss:0.3536, loss-lb:0.1364, loss-ulb:0.1086, weight:2.00, lr:0.0005
[04:07:14.614] iteration 7725 : dice_score: 0.846453 best_dice: 0.846500
[04:07:14.615]  <<Test>> - Ep:308  - Dice-S/T:84.18/84.65, Best-S:84.32, Best-T:84.65
[04:07:14.615]           - AvgLoss(lb/ulb/all):0.23/0.11/0.43
[04:07:15.711] iteration:7726  t-loss:0.3562, loss-lb:0.1577, loss-ulb:0.0993, weight:2.00, lr:0.0005
[04:07:16.049] iteration:7727  t-loss:0.3703, loss-lb:0.1799, loss-ulb:0.0952, weight:2.00, lr:0.0005
[04:07:16.385] iteration:7728  t-loss:0.2893, loss-lb:0.1890, loss-ulb:0.0501, weight:2.00, lr:0.0005
[04:07:16.725] iteration:7729  t-loss:0.3599, loss-lb:0.2477, loss-ulb:0.0561, weight:2.00, lr:0.0005
[04:07:17.045] iteration:7730  t-loss:0.3476, loss-lb:0.2003, loss-ulb:0.0737, weight:2.00, lr:0.0005
[04:07:17.369] iteration:7731  t-loss:0.4739, loss-lb:0.3357, loss-ulb:0.0691, weight:2.00, lr:0.0005
[04:07:17.686] iteration:7732  t-loss:0.4356, loss-lb:0.2162, loss-ulb:0.1097, weight:2.00, lr:0.0005
[04:07:18.004] iteration:7733  t-loss:0.1810, loss-lb:0.1406, loss-ulb:0.0202, weight:2.00, lr:0.0005
[04:07:18.334] iteration:7734  t-loss:0.4058, loss-lb:0.2996, loss-ulb:0.0531, weight:2.00, lr:0.0005
[04:07:18.663] iteration:7735  t-loss:1.7556, loss-lb:0.1884, loss-ulb:0.7836, weight:2.00, lr:0.0005
[04:07:18.981] iteration:7736  t-loss:0.1876, loss-lb:0.1337, loss-ulb:0.0269, weight:2.00, lr:0.0005
[04:07:19.304] iteration:7737  t-loss:0.3253, loss-lb:0.2487, loss-ulb:0.0383, weight:2.00, lr:0.0005
[04:07:19.624] iteration:7738  t-loss:0.4685, loss-lb:0.2071, loss-ulb:0.1307, weight:2.00, lr:0.0005
[04:07:19.950] iteration:7739  t-loss:0.4527, loss-lb:0.2096, loss-ulb:0.1215, weight:2.00, lr:0.0005
[04:07:20.270] iteration:7740  t-loss:0.2422, loss-lb:0.1857, loss-ulb:0.0282, weight:2.00, lr:0.0005
[04:07:20.586] iteration:7741  t-loss:0.3792, loss-lb:0.3496, loss-ulb:0.0148, weight:2.00, lr:0.0005
[04:07:20.903] iteration:7742  t-loss:0.4054, loss-lb:0.2494, loss-ulb:0.0780, weight:2.00, lr:0.0005
[04:07:21.232] iteration:7743  t-loss:0.4540, loss-lb:0.1442, loss-ulb:0.1549, weight:2.00, lr:0.0005
[04:07:21.556] iteration:7744  t-loss:0.5844, loss-lb:0.1402, loss-ulb:0.2221, weight:2.00, lr:0.0005
[04:07:21.891] iteration:7745  t-loss:0.2582, loss-lb:0.2017, loss-ulb:0.0283, weight:2.00, lr:0.0005
[04:07:22.219] iteration:7746  t-loss:0.2323, loss-lb:0.1551, loss-ulb:0.0386, weight:2.00, lr:0.0005
[04:07:22.532] iteration:7747  t-loss:0.1903, loss-lb:0.1508, loss-ulb:0.0197, weight:2.00, lr:0.0005
[04:07:22.845] iteration:7748  t-loss:0.3672, loss-lb:0.1923, loss-ulb:0.0874, weight:2.00, lr:0.0005
[04:07:23.159] iteration:7749  t-loss:0.2506, loss-lb:0.1936, loss-ulb:0.0285, weight:2.00, lr:0.0005
[04:07:23.471] iteration:7750  t-loss:0.2358, loss-lb:0.1395, loss-ulb:0.0482, weight:2.00, lr:0.0005
[04:07:24.833] iteration:7751  t-loss:0.3477, loss-lb:0.1624, loss-ulb:0.0926, weight:2.00, lr:0.0005
[04:07:25.169] iteration:7752  t-loss:0.2594, loss-lb:0.1506, loss-ulb:0.0544, weight:2.00, lr:0.0005
[04:07:25.513] iteration:7753  t-loss:0.4923, loss-lb:0.1359, loss-ulb:0.1782, weight:2.00, lr:0.0005
[04:07:25.860] iteration:7754  t-loss:0.4187, loss-lb:0.2049, loss-ulb:0.1069, weight:2.00, lr:0.0005
[04:07:26.195] iteration:7755  t-loss:0.3463, loss-lb:0.2911, loss-ulb:0.0276, weight:2.00, lr:0.0005
[04:07:26.519] iteration:7756  t-loss:0.4033, loss-lb:0.2105, loss-ulb:0.0964, weight:2.00, lr:0.0005
[04:07:26.848] iteration:7757  t-loss:0.3062, loss-lb:0.1699, loss-ulb:0.0681, weight:2.00, lr:0.0005
[04:07:27.168] iteration:7758  t-loss:0.3437, loss-lb:0.1556, loss-ulb:0.0941, weight:2.00, lr:0.0005
[04:07:27.486] iteration:7759  t-loss:0.3018, loss-lb:0.1909, loss-ulb:0.0555, weight:2.00, lr:0.0005
[04:07:27.804] iteration:7760  t-loss:0.3417, loss-lb:0.2881, loss-ulb:0.0268, weight:2.00, lr:0.0005
[04:07:28.122] iteration:7761  t-loss:0.2035, loss-lb:0.1737, loss-ulb:0.0149, weight:2.00, lr:0.0005
[04:07:28.440] iteration:7762  t-loss:0.5205, loss-lb:0.1410, loss-ulb:0.1897, weight:2.00, lr:0.0005
[04:07:28.754] iteration:7763  t-loss:0.5587, loss-lb:0.1565, loss-ulb:0.2011, weight:2.00, lr:0.0005
[04:07:29.068] iteration:7764  t-loss:0.3961, loss-lb:0.2162, loss-ulb:0.0900, weight:2.00, lr:0.0005
[04:07:29.385] iteration:7765  t-loss:0.2630, loss-lb:0.2338, loss-ulb:0.0146, weight:2.00, lr:0.0005
[04:07:29.708] iteration:7766  t-loss:0.3247, loss-lb:0.1424, loss-ulb:0.0911, weight:2.00, lr:0.0005
[04:07:30.039] iteration:7767  t-loss:0.6514, loss-lb:0.1478, loss-ulb:0.2518, weight:2.00, lr:0.0005
[04:07:30.368] iteration:7768  t-loss:0.2891, loss-lb:0.2144, loss-ulb:0.0374, weight:2.00, lr:0.0005
[04:07:30.694] iteration:7769  t-loss:0.6110, loss-lb:0.4274, loss-ulb:0.0918, weight:2.00, lr:0.0005
[04:07:31.023] iteration:7770  t-loss:0.3597, loss-lb:0.1818, loss-ulb:0.0890, weight:2.00, lr:0.0005
[04:07:31.342] iteration:7771  t-loss:0.3774, loss-lb:0.2093, loss-ulb:0.0841, weight:2.00, lr:0.0005
[04:07:31.657] iteration:7772  t-loss:0.3385, loss-lb:0.1766, loss-ulb:0.0809, weight:2.00, lr:0.0005
[04:07:31.973] iteration:7773  t-loss:0.2901, loss-lb:0.1644, loss-ulb:0.0629, weight:2.00, lr:0.0005
[04:07:32.287] iteration:7774  t-loss:0.3960, loss-lb:0.2409, loss-ulb:0.0776, weight:2.00, lr:0.0005
[04:07:32.601] iteration:7775  t-loss:0.2876, loss-lb:0.2197, loss-ulb:0.0340, weight:2.00, lr:0.0005
[04:07:33.899] iteration:7776  t-loss:0.3811, loss-lb:0.1979, loss-ulb:0.0916, weight:2.00, lr:0.0005
[04:07:34.228] iteration:7777  t-loss:0.2232, loss-lb:0.1588, loss-ulb:0.0322, weight:2.00, lr:0.0005
[04:07:34.551] iteration:7778  t-loss:0.2589, loss-lb:0.1217, loss-ulb:0.0686, weight:2.00, lr:0.0005
[04:07:34.872] iteration:7779  t-loss:0.3473, loss-lb:0.3038, loss-ulb:0.0217, weight:2.00, lr:0.0005
[04:07:35.191] iteration:7780  t-loss:0.6990, loss-lb:0.3920, loss-ulb:0.1535, weight:2.00, lr:0.0005
[04:07:35.511] iteration:7781  t-loss:0.4047, loss-lb:0.2204, loss-ulb:0.0922, weight:2.00, lr:0.0005
[04:07:35.831] iteration:7782  t-loss:0.2684, loss-lb:0.2308, loss-ulb:0.0188, weight:2.00, lr:0.0005
[04:07:36.147] iteration:7783  t-loss:0.4061, loss-lb:0.3616, loss-ulb:0.0223, weight:2.00, lr:0.0005
[04:07:36.461] iteration:7784  t-loss:0.2690, loss-lb:0.1442, loss-ulb:0.0624, weight:2.00, lr:0.0005
[04:07:36.778] iteration:7785  t-loss:0.5311, loss-lb:0.3691, loss-ulb:0.0810, weight:2.00, lr:0.0005
[04:07:37.092] iteration:7786  t-loss:0.2491, loss-lb:0.1985, loss-ulb:0.0253, weight:2.00, lr:0.0005
[04:07:37.407] iteration:7787  t-loss:0.2660, loss-lb:0.1542, loss-ulb:0.0559, weight:2.00, lr:0.0005
[04:07:37.730] iteration:7788  t-loss:0.4183, loss-lb:0.2320, loss-ulb:0.0932, weight:2.00, lr:0.0005
[04:07:38.050] iteration:7789  t-loss:0.2376, loss-lb:0.1904, loss-ulb:0.0236, weight:2.00, lr:0.0005
[04:07:38.387] iteration:7790  t-loss:0.3777, loss-lb:0.2135, loss-ulb:0.0821, weight:2.00, lr:0.0005
[04:07:38.730] iteration:7791  t-loss:0.3424, loss-lb:0.1713, loss-ulb:0.0855, weight:2.00, lr:0.0005
[04:07:39.074] iteration:7792  t-loss:0.2456, loss-lb:0.2008, loss-ulb:0.0224, weight:2.00, lr:0.0005
[04:07:39.410] iteration:7793  t-loss:0.2263, loss-lb:0.1606, loss-ulb:0.0329, weight:2.00, lr:0.0005
[04:07:39.736] iteration:7794  t-loss:0.2325, loss-lb:0.1954, loss-ulb:0.0186, weight:2.00, lr:0.0005
[04:07:40.053] iteration:7795  t-loss:0.5441, loss-lb:0.3149, loss-ulb:0.1146, weight:2.00, lr:0.0005
[04:07:40.378] iteration:7796  t-loss:0.5196, loss-lb:0.2963, loss-ulb:0.1116, weight:2.00, lr:0.0005
[04:07:40.697] iteration:7797  t-loss:0.3303, loss-lb:0.1546, loss-ulb:0.0879, weight:2.00, lr:0.0005
[04:07:41.013] iteration:7798  t-loss:0.3335, loss-lb:0.2886, loss-ulb:0.0225, weight:2.00, lr:0.0005
[04:07:41.331] iteration:7799  t-loss:0.2491, loss-lb:0.1917, loss-ulb:0.0287, weight:2.00, lr:0.0005
[04:07:41.650] iteration:7800  t-loss:0.4272, loss-lb:0.3057, loss-ulb:0.0607, weight:2.00, lr:0.0005
[04:07:43.032] iteration:7801  t-loss:0.6483, loss-lb:0.1782, loss-ulb:0.2351, weight:2.00, lr:0.0005
[04:07:43.400] iteration:7802  t-loss:0.2504, loss-lb:0.2175, loss-ulb:0.0165, weight:2.00, lr:0.0005
[04:07:43.760] iteration:7803  t-loss:0.2426, loss-lb:0.1974, loss-ulb:0.0226, weight:2.00, lr:0.0005
[04:07:44.111] iteration:7804  t-loss:0.2379, loss-lb:0.1581, loss-ulb:0.0399, weight:2.00, lr:0.0005
[04:07:44.476] iteration:7805  t-loss:0.6219, loss-lb:0.4096, loss-ulb:0.1061, weight:2.00, lr:0.0005
[04:07:44.805] iteration:7806  t-loss:0.4986, loss-lb:0.2226, loss-ulb:0.1380, weight:2.00, lr:0.0005
[04:07:45.125] iteration:7807  t-loss:0.5273, loss-lb:0.2449, loss-ulb:0.1412, weight:2.00, lr:0.0005
[04:07:45.445] iteration:7808  t-loss:0.3113, loss-lb:0.1587, loss-ulb:0.0763, weight:2.00, lr:0.0005
[04:07:45.764] iteration:7809  t-loss:0.7327, loss-lb:0.1804, loss-ulb:0.2761, weight:2.00, lr:0.0005
[04:07:46.084] iteration:7810  t-loss:0.4347, loss-lb:0.3640, loss-ulb:0.0353, weight:2.00, lr:0.0005
[04:07:46.399] iteration:7811  t-loss:0.1874, loss-lb:0.1596, loss-ulb:0.0139, weight:2.00, lr:0.0005
[04:07:46.718] iteration:7812  t-loss:0.3758, loss-lb:0.1704, loss-ulb:0.1027, weight:2.00, lr:0.0005
[04:07:47.051] iteration:7813  t-loss:0.4643, loss-lb:0.2870, loss-ulb:0.0887, weight:2.00, lr:0.0005
[04:07:47.384] iteration:7814  t-loss:0.2751, loss-lb:0.1317, loss-ulb:0.0717, weight:2.00, lr:0.0005
[04:07:47.749] iteration:7815  t-loss:0.3135, loss-lb:0.1765, loss-ulb:0.0685, weight:2.00, lr:0.0005
[04:07:48.084] iteration:7816  t-loss:0.4608, loss-lb:0.1792, loss-ulb:0.1408, weight:2.00, lr:0.0005
[04:07:48.434] iteration:7817  t-loss:0.5732, loss-lb:0.2458, loss-ulb:0.1637, weight:2.00, lr:0.0005
[04:07:48.777] iteration:7818  t-loss:0.3374, loss-lb:0.1978, loss-ulb:0.0698, weight:2.00, lr:0.0005
[04:07:49.097] iteration:7819  t-loss:0.2725, loss-lb:0.2297, loss-ulb:0.0214, weight:2.00, lr:0.0005
[04:07:49.421] iteration:7820  t-loss:0.7004, loss-lb:0.4665, loss-ulb:0.1170, weight:2.00, lr:0.0005
[04:07:49.738] iteration:7821  t-loss:0.4114, loss-lb:0.1811, loss-ulb:0.1151, weight:2.00, lr:0.0005
[04:07:50.056] iteration:7822  t-loss:0.5514, loss-lb:0.3081, loss-ulb:0.1217, weight:2.00, lr:0.0005
[04:07:50.372] iteration:7823  t-loss:1.3462, loss-lb:0.2286, loss-ulb:0.5588, weight:2.00, lr:0.0005
[04:07:50.690] iteration:7824  t-loss:0.4354, loss-lb:0.2383, loss-ulb:0.0985, weight:2.00, lr:0.0005
[04:07:51.005] iteration:7825  t-loss:0.2220, loss-lb:0.1824, loss-ulb:0.0198, weight:2.00, lr:0.0005
[04:10:01.065] iteration 7825 : dice_score: 0.847682 best_dice: 0.847700
[04:10:01.065]  <<Test>> - Ep:312  - Dice-S/T:83.28/84.77, Best-S:84.32, Best-T:84.77
[04:10:01.066]           - AvgLoss(lb/ulb/all):0.23/0.12/0.47
[04:10:02.102] iteration:7826  t-loss:0.2440, loss-lb:0.1413, loss-ulb:0.0513, weight:2.00, lr:0.0005
[04:10:02.438] iteration:7827  t-loss:0.3843, loss-lb:0.2023, loss-ulb:0.0910, weight:2.00, lr:0.0005
[04:10:02.780] iteration:7828  t-loss:0.5468, loss-lb:0.3095, loss-ulb:0.1186, weight:2.00, lr:0.0005
[04:10:03.107] iteration:7829  t-loss:0.3590, loss-lb:0.2706, loss-ulb:0.0442, weight:2.00, lr:0.0005
[04:10:03.425] iteration:7830  t-loss:0.4450, loss-lb:0.1736, loss-ulb:0.1357, weight:2.00, lr:0.0005
[04:10:03.749] iteration:7831  t-loss:0.6761, loss-lb:0.2642, loss-ulb:0.2059, weight:2.00, lr:0.0005
[04:10:04.068] iteration:7832  t-loss:0.4123, loss-lb:0.1648, loss-ulb:0.1237, weight:2.00, lr:0.0005
[04:10:04.390] iteration:7833  t-loss:0.3064, loss-lb:0.1871, loss-ulb:0.0596, weight:2.00, lr:0.0005
[04:10:04.708] iteration:7834  t-loss:0.4381, loss-lb:0.3310, loss-ulb:0.0535, weight:2.00, lr:0.0005
[04:10:05.032] iteration:7835  t-loss:0.3586, loss-lb:0.1523, loss-ulb:0.1031, weight:2.00, lr:0.0005
[04:10:05.364] iteration:7836  t-loss:0.1963, loss-lb:0.1459, loss-ulb:0.0252, weight:2.00, lr:0.0005
[04:10:05.679] iteration:7837  t-loss:0.5460, loss-lb:0.1826, loss-ulb:0.1817, weight:2.00, lr:0.0005
[04:10:06.001] iteration:7838  t-loss:0.4549, loss-lb:0.1887, loss-ulb:0.1331, weight:2.00, lr:0.0005
[04:10:06.331] iteration:7839  t-loss:0.3378, loss-lb:0.1685, loss-ulb:0.0847, weight:2.00, lr:0.0005
[04:10:06.669] iteration:7840  t-loss:0.3818, loss-lb:0.1506, loss-ulb:0.1156, weight:2.00, lr:0.0005
[04:10:06.989] iteration:7841  t-loss:0.2168, loss-lb:0.1764, loss-ulb:0.0202, weight:2.00, lr:0.0005
[04:10:07.302] iteration:7842  t-loss:0.3516, loss-lb:0.1405, loss-ulb:0.1055, weight:2.00, lr:0.0005
[04:10:07.616] iteration:7843  t-loss:0.2785, loss-lb:0.2312, loss-ulb:0.0237, weight:2.00, lr:0.0005
[04:10:07.934] iteration:7844  t-loss:0.5955, loss-lb:0.3267, loss-ulb:0.1344, weight:2.00, lr:0.0005
[04:10:08.249] iteration:7845  t-loss:0.6721, loss-lb:0.1616, loss-ulb:0.2553, weight:2.00, lr:0.0005
[04:10:08.575] iteration:7846  t-loss:0.3745, loss-lb:0.2954, loss-ulb:0.0396, weight:2.00, lr:0.0005
[04:10:08.906] iteration:7847  t-loss:0.3570, loss-lb:0.2593, loss-ulb:0.0489, weight:2.00, lr:0.0005
[04:10:09.226] iteration:7848  t-loss:0.2621, loss-lb:0.2232, loss-ulb:0.0195, weight:2.00, lr:0.0005
[04:10:09.548] iteration:7849  t-loss:0.3628, loss-lb:0.1435, loss-ulb:0.1097, weight:2.00, lr:0.0005
[04:10:09.866] iteration:7850  t-loss:0.3657, loss-lb:0.2294, loss-ulb:0.0681, weight:2.00, lr:0.0005
[04:10:11.144] iteration:7851  t-loss:0.2005, loss-lb:0.1733, loss-ulb:0.0136, weight:2.00, lr:0.0005
[04:10:11.470] iteration:7852  t-loss:0.2121, loss-lb:0.1825, loss-ulb:0.0148, weight:2.00, lr:0.0005
[04:10:11.795] iteration:7853  t-loss:0.2590, loss-lb:0.1456, loss-ulb:0.0567, weight:2.00, lr:0.0005
[04:10:12.114] iteration:7854  t-loss:0.2297, loss-lb:0.1404, loss-ulb:0.0447, weight:2.00, lr:0.0005
[04:10:12.440] iteration:7855  t-loss:0.4747, loss-lb:0.2903, loss-ulb:0.0922, weight:2.00, lr:0.0005
[04:10:12.757] iteration:7856  t-loss:0.3298, loss-lb:0.1981, loss-ulb:0.0658, weight:2.00, lr:0.0005
[04:10:13.085] iteration:7857  t-loss:0.3740, loss-lb:0.2750, loss-ulb:0.0495, weight:2.00, lr:0.0005
[04:10:13.404] iteration:7858  t-loss:0.3798, loss-lb:0.1543, loss-ulb:0.1128, weight:2.00, lr:0.0005
[04:10:13.721] iteration:7859  t-loss:0.5228, loss-lb:0.2143, loss-ulb:0.1542, weight:2.00, lr:0.0005
[04:10:14.045] iteration:7860  t-loss:0.4245, loss-lb:0.2070, loss-ulb:0.1087, weight:2.00, lr:0.0005
[04:10:14.364] iteration:7861  t-loss:0.5818, loss-lb:0.1302, loss-ulb:0.2258, weight:2.00, lr:0.0005
[04:10:14.678] iteration:7862  t-loss:0.3757, loss-lb:0.1754, loss-ulb:0.1002, weight:2.00, lr:0.0005
[04:10:14.997] iteration:7863  t-loss:0.5233, loss-lb:0.2674, loss-ulb:0.1280, weight:2.00, lr:0.0005
[04:10:15.316] iteration:7864  t-loss:0.5002, loss-lb:0.3894, loss-ulb:0.0554, weight:2.00, lr:0.0005
[04:10:15.633] iteration:7865  t-loss:0.3906, loss-lb:0.1653, loss-ulb:0.1127, weight:2.00, lr:0.0005
[04:10:15.946] iteration:7866  t-loss:0.2514, loss-lb:0.1148, loss-ulb:0.0683, weight:2.00, lr:0.0005
[04:10:16.264] iteration:7867  t-loss:0.2812, loss-lb:0.2406, loss-ulb:0.0203, weight:2.00, lr:0.0005
[04:10:16.575] iteration:7868  t-loss:0.2400, loss-lb:0.1777, loss-ulb:0.0311, weight:2.00, lr:0.0005
[04:10:16.888] iteration:7869  t-loss:0.2631, loss-lb:0.1227, loss-ulb:0.0702, weight:2.00, lr:0.0005
[04:10:17.207] iteration:7870  t-loss:0.2368, loss-lb:0.1839, loss-ulb:0.0264, weight:2.00, lr:0.0005
[04:10:17.545] iteration:7871  t-loss:0.3697, loss-lb:0.3230, loss-ulb:0.0233, weight:2.00, lr:0.0005
[04:10:17.879] iteration:7872  t-loss:0.2749, loss-lb:0.2095, loss-ulb:0.0327, weight:2.00, lr:0.0005
[04:10:18.211] iteration:7873  t-loss:0.4142, loss-lb:0.1526, loss-ulb:0.1308, weight:2.00, lr:0.0005
[04:10:18.533] iteration:7874  t-loss:0.5636, loss-lb:0.2107, loss-ulb:0.1764, weight:2.00, lr:0.0005
[04:10:18.851] iteration:7875  t-loss:0.2741, loss-lb:0.2297, loss-ulb:0.0222, weight:2.00, lr:0.0005
[04:10:20.357] iteration:7876  t-loss:0.4005, loss-lb:0.1866, loss-ulb:0.1070, weight:2.00, lr:0.0005
[04:10:20.694] iteration:7877  t-loss:0.2599, loss-lb:0.1828, loss-ulb:0.0385, weight:2.00, lr:0.0005
[04:10:21.018] iteration:7878  t-loss:0.3176, loss-lb:0.1601, loss-ulb:0.0787, weight:2.00, lr:0.0005
[04:10:21.346] iteration:7879  t-loss:0.4044, loss-lb:0.1308, loss-ulb:0.1368, weight:2.00, lr:0.0005
[04:10:21.666] iteration:7880  t-loss:0.3352, loss-lb:0.1770, loss-ulb:0.0791, weight:2.00, lr:0.0005
[04:10:21.989] iteration:7881  t-loss:0.6115, loss-lb:0.4839, loss-ulb:0.0638, weight:2.00, lr:0.0005
[04:10:22.318] iteration:7882  t-loss:0.3045, loss-lb:0.1509, loss-ulb:0.0768, weight:2.00, lr:0.0005
[04:10:22.641] iteration:7883  t-loss:0.5673, loss-lb:0.1753, loss-ulb:0.1960, weight:2.00, lr:0.0005
[04:10:22.971] iteration:7884  t-loss:0.2866, loss-lb:0.2415, loss-ulb:0.0225, weight:2.00, lr:0.0005
[04:10:23.295] iteration:7885  t-loss:0.2256, loss-lb:0.1900, loss-ulb:0.0178, weight:2.00, lr:0.0005
[04:10:23.614] iteration:7886  t-loss:0.2595, loss-lb:0.2156, loss-ulb:0.0220, weight:2.00, lr:0.0005
[04:10:23.927] iteration:7887  t-loss:0.1787, loss-lb:0.1302, loss-ulb:0.0242, weight:2.00, lr:0.0005
[04:10:24.246] iteration:7888  t-loss:0.4658, loss-lb:0.1996, loss-ulb:0.1331, weight:2.00, lr:0.0005
[04:10:24.561] iteration:7889  t-loss:0.3376, loss-lb:0.1528, loss-ulb:0.0924, weight:2.00, lr:0.0005
[04:10:24.880] iteration:7890  t-loss:0.2993, loss-lb:0.1551, loss-ulb:0.0721, weight:2.00, lr:0.0005
[04:10:25.194] iteration:7891  t-loss:0.3515, loss-lb:0.1734, loss-ulb:0.0891, weight:2.00, lr:0.0005
[04:10:25.514] iteration:7892  t-loss:0.5060, loss-lb:0.3853, loss-ulb:0.0604, weight:2.00, lr:0.0005
[04:10:25.836] iteration:7893  t-loss:0.2185, loss-lb:0.1849, loss-ulb:0.0168, weight:2.00, lr:0.0005
[04:10:26.164] iteration:7894  t-loss:0.3655, loss-lb:0.1583, loss-ulb:0.1036, weight:2.00, lr:0.0005
[04:10:26.503] iteration:7895  t-loss:0.2162, loss-lb:0.1798, loss-ulb:0.0182, weight:2.00, lr:0.0005
[04:10:26.822] iteration:7896  t-loss:0.2414, loss-lb:0.1672, loss-ulb:0.0371, weight:2.00, lr:0.0005
[04:10:27.141] iteration:7897  t-loss:0.4284, loss-lb:0.3734, loss-ulb:0.0275, weight:2.00, lr:0.0005
[04:10:27.455] iteration:7898  t-loss:0.3587, loss-lb:0.1730, loss-ulb:0.0929, weight:2.00, lr:0.0005
[04:10:27.772] iteration:7899  t-loss:0.3420, loss-lb:0.1804, loss-ulb:0.0808, weight:2.00, lr:0.0005
[04:10:28.089] iteration:7900  t-loss:0.3099, loss-lb:0.2687, loss-ulb:0.0206, weight:2.00, lr:0.0005
[04:10:29.413] iteration:7901  t-loss:0.4344, loss-lb:0.2371, loss-ulb:0.0986, weight:2.00, lr:0.0005
[04:10:29.770] iteration:7902  t-loss:0.2810, loss-lb:0.1288, loss-ulb:0.0761, weight:2.00, lr:0.0005
[04:10:30.100] iteration:7903  t-loss:0.2372, loss-lb:0.1824, loss-ulb:0.0274, weight:2.00, lr:0.0005
[04:10:30.450] iteration:7904  t-loss:0.4047, loss-lb:0.2710, loss-ulb:0.0668, weight:2.00, lr:0.0005
[04:10:30.772] iteration:7905  t-loss:0.1769, loss-lb:0.1179, loss-ulb:0.0295, weight:2.00, lr:0.0005
[04:10:31.095] iteration:7906  t-loss:0.5036, loss-lb:0.2898, loss-ulb:0.1069, weight:2.00, lr:0.0005
[04:10:31.415] iteration:7907  t-loss:0.3674, loss-lb:0.2196, loss-ulb:0.0739, weight:2.00, lr:0.0005
[04:10:31.733] iteration:7908  t-loss:0.7126, loss-lb:0.2266, loss-ulb:0.2430, weight:2.00, lr:0.0005
[04:10:32.059] iteration:7909  t-loss:0.4537, loss-lb:0.2762, loss-ulb:0.0887, weight:2.00, lr:0.0005
[04:10:32.375] iteration:7910  t-loss:0.3407, loss-lb:0.1619, loss-ulb:0.0894, weight:2.00, lr:0.0005
[04:10:32.695] iteration:7911  t-loss:0.3286, loss-lb:0.1354, loss-ulb:0.0966, weight:2.00, lr:0.0005
[04:10:33.010] iteration:7912  t-loss:0.1718, loss-lb:0.1379, loss-ulb:0.0169, weight:2.00, lr:0.0005
[04:10:33.331] iteration:7913  t-loss:0.2495, loss-lb:0.1332, loss-ulb:0.0582, weight:2.00, lr:0.0005
[04:10:33.648] iteration:7914  t-loss:0.2437, loss-lb:0.2109, loss-ulb:0.0164, weight:2.00, lr:0.0005
[04:10:33.966] iteration:7915  t-loss:0.5238, loss-lb:0.2964, loss-ulb:0.1137, weight:2.00, lr:0.0005
[04:10:34.289] iteration:7916  t-loss:0.4513, loss-lb:0.2206, loss-ulb:0.1153, weight:2.00, lr:0.0005
[04:10:34.623] iteration:7917  t-loss:0.5721, loss-lb:0.1812, loss-ulb:0.1955, weight:2.00, lr:0.0005
[04:10:34.957] iteration:7918  t-loss:0.4428, loss-lb:0.2810, loss-ulb:0.0809, weight:2.00, lr:0.0005
[04:10:35.286] iteration:7919  t-loss:0.3765, loss-lb:0.3243, loss-ulb:0.0261, weight:2.00, lr:0.0005
[04:10:35.610] iteration:7920  t-loss:0.5065, loss-lb:0.1513, loss-ulb:0.1776, weight:2.00, lr:0.0005
[04:10:35.935] iteration:7921  t-loss:0.2663, loss-lb:0.1401, loss-ulb:0.0631, weight:2.00, lr:0.0005
[04:10:36.257] iteration:7922  t-loss:0.3655, loss-lb:0.3166, loss-ulb:0.0244, weight:2.00, lr:0.0005
[04:10:36.575] iteration:7923  t-loss:0.2619, loss-lb:0.2025, loss-ulb:0.0297, weight:2.00, lr:0.0005
[04:10:36.893] iteration:7924  t-loss:0.2090, loss-lb:0.1365, loss-ulb:0.0363, weight:2.00, lr:0.0005
[04:10:37.211] iteration:7925  t-loss:0.4683, loss-lb:0.1436, loss-ulb:0.1624, weight:2.00, lr:0.0005
[04:12:52.738] iteration 7925 : dice_score: 0.847027 best_dice: 0.847700
[04:12:52.738]  <<Test>> - Ep:316  - Dice-S/T:83.56/84.70, Best-S:84.32, Best-T:84.77
[04:12:52.738]           - AvgLoss(lb/ulb/all):0.20/0.09/0.39
[04:12:54.016] iteration:7926  t-loss:0.3101, loss-lb:0.1390, loss-ulb:0.0856, weight:2.00, lr:0.0005
[04:12:54.355] iteration:7927  t-loss:0.5108, loss-lb:0.4476, loss-ulb:0.0316, weight:2.00, lr:0.0005
[04:12:54.684] iteration:7928  t-loss:0.2146, loss-lb:0.1729, loss-ulb:0.0209, weight:2.00, lr:0.0005
[04:12:55.015] iteration:7929  t-loss:0.3740, loss-lb:0.1633, loss-ulb:0.1053, weight:2.00, lr:0.0005
[04:12:55.349] iteration:7930  t-loss:0.2997, loss-lb:0.1908, loss-ulb:0.0544, weight:2.00, lr:0.0005
[04:12:55.673] iteration:7931  t-loss:0.1909, loss-lb:0.1564, loss-ulb:0.0172, weight:2.00, lr:0.0005
[04:12:56.003] iteration:7932  t-loss:0.3232, loss-lb:0.1696, loss-ulb:0.0768, weight:2.00, lr:0.0005
[04:12:56.327] iteration:7933  t-loss:0.3521, loss-lb:0.1669, loss-ulb:0.0926, weight:2.00, lr:0.0005
[04:12:56.656] iteration:7934  t-loss:0.4302, loss-lb:0.1435, loss-ulb:0.1434, weight:2.00, lr:0.0005
[04:12:56.995] iteration:7935  t-loss:0.2645, loss-lb:0.2326, loss-ulb:0.0160, weight:2.00, lr:0.0005
[04:12:57.408] iteration:7936  t-loss:0.3191, loss-lb:0.2185, loss-ulb:0.0503, weight:2.00, lr:0.0005
[04:12:57.756] iteration:7937  t-loss:0.2052, loss-lb:0.1639, loss-ulb:0.0206, weight:2.00, lr:0.0005
[04:12:58.107] iteration:7938  t-loss:0.1863, loss-lb:0.1443, loss-ulb:0.0210, weight:2.00, lr:0.0005
[04:12:58.463] iteration:7939  t-loss:0.3519, loss-lb:0.2495, loss-ulb:0.0512, weight:2.00, lr:0.0005
[04:12:58.795] iteration:7940  t-loss:0.1731, loss-lb:0.1450, loss-ulb:0.0141, weight:2.00, lr:0.0005
[04:12:59.125] iteration:7941  t-loss:0.3138, loss-lb:0.1913, loss-ulb:0.0612, weight:2.00, lr:0.0005
[04:12:59.452] iteration:7942  t-loss:0.2155, loss-lb:0.1626, loss-ulb:0.0264, weight:2.00, lr:0.0005
[04:12:59.773] iteration:7943  t-loss:0.1830, loss-lb:0.1378, loss-ulb:0.0226, weight:2.00, lr:0.0005
[04:13:00.091] iteration:7944  t-loss:0.2113, loss-lb:0.1414, loss-ulb:0.0349, weight:2.00, lr:0.0005
[04:13:00.406] iteration:7945  t-loss:0.3101, loss-lb:0.2097, loss-ulb:0.0502, weight:2.00, lr:0.0005
[04:13:00.719] iteration:7946  t-loss:0.2078, loss-lb:0.1376, loss-ulb:0.0351, weight:2.00, lr:0.0005
[04:13:01.037] iteration:7947  t-loss:0.5574, loss-lb:0.2443, loss-ulb:0.1566, weight:2.00, lr:0.0005
[04:13:01.359] iteration:7948  t-loss:0.4946, loss-lb:0.2187, loss-ulb:0.1380, weight:2.00, lr:0.0005
[04:13:01.674] iteration:7949  t-loss:0.5433, loss-lb:0.1900, loss-ulb:0.1767, weight:2.00, lr:0.0005
[04:13:01.992] iteration:7950  t-loss:0.3178, loss-lb:0.1656, loss-ulb:0.0761, weight:2.00, lr:0.0005
[04:13:03.048] iteration:7951  t-loss:0.5473, loss-lb:0.2464, loss-ulb:0.1504, weight:2.00, lr:0.0005
[04:13:03.404] iteration:7952  t-loss:0.7035, loss-lb:0.2618, loss-ulb:0.2208, weight:2.00, lr:0.0005
[04:13:03.743] iteration:7953  t-loss:0.8930, loss-lb:0.2524, loss-ulb:0.3203, weight:2.00, lr:0.0005
[04:13:04.070] iteration:7954  t-loss:0.5483, loss-lb:0.1613, loss-ulb:0.1935, weight:2.00, lr:0.0005
[04:13:04.393] iteration:7955  t-loss:0.3992, loss-lb:0.2941, loss-ulb:0.0525, weight:2.00, lr:0.0005
[04:13:04.715] iteration:7956  t-loss:0.5164, loss-lb:0.2645, loss-ulb:0.1260, weight:2.00, lr:0.0005
[04:13:05.035] iteration:7957  t-loss:0.3738, loss-lb:0.1812, loss-ulb:0.0963, weight:2.00, lr:0.0005
[04:13:05.353] iteration:7958  t-loss:0.5254, loss-lb:0.2597, loss-ulb:0.1328, weight:2.00, lr:0.0005
[04:13:05.671] iteration:7959  t-loss:0.3732, loss-lb:0.2518, loss-ulb:0.0607, weight:2.00, lr:0.0005
[04:13:06.007] iteration:7960  t-loss:0.6510, loss-lb:0.2117, loss-ulb:0.2197, weight:2.00, lr:0.0005
[04:13:06.353] iteration:7961  t-loss:0.3636, loss-lb:0.2571, loss-ulb:0.0533, weight:2.00, lr:0.0005
[04:13:06.709] iteration:7962  t-loss:0.3401, loss-lb:0.2854, loss-ulb:0.0274, weight:2.00, lr:0.0005
[04:13:07.068] iteration:7963  t-loss:0.4993, loss-lb:0.2206, loss-ulb:0.1393, weight:2.00, lr:0.0005
[04:13:07.417] iteration:7964  t-loss:0.4517, loss-lb:0.3262, loss-ulb:0.0628, weight:2.00, lr:0.0005
[04:13:07.758] iteration:7965  t-loss:0.3557, loss-lb:0.1941, loss-ulb:0.0808, weight:2.00, lr:0.0005
[04:13:08.103] iteration:7966  t-loss:0.4060, loss-lb:0.1347, loss-ulb:0.1357, weight:2.00, lr:0.0005
[04:13:08.442] iteration:7967  t-loss:0.2789, loss-lb:0.1916, loss-ulb:0.0436, weight:2.00, lr:0.0005
[04:13:08.771] iteration:7968  t-loss:0.4446, loss-lb:0.1772, loss-ulb:0.1337, weight:2.00, lr:0.0005
[04:13:09.095] iteration:7969  t-loss:0.6267, loss-lb:0.3501, loss-ulb:0.1383, weight:2.00, lr:0.0005
[04:13:09.421] iteration:7970  t-loss:0.3568, loss-lb:0.2032, loss-ulb:0.0768, weight:2.00, lr:0.0005
[04:13:09.739] iteration:7971  t-loss:0.4156, loss-lb:0.2034, loss-ulb:0.1061, weight:2.00, lr:0.0005
[04:13:10.057] iteration:7972  t-loss:0.4414, loss-lb:0.1838, loss-ulb:0.1288, weight:2.00, lr:0.0005
[04:13:10.379] iteration:7973  t-loss:0.4108, loss-lb:0.1959, loss-ulb:0.1075, weight:2.00, lr:0.0005
[04:13:10.693] iteration:7974  t-loss:0.7056, loss-lb:0.1366, loss-ulb:0.2845, weight:2.00, lr:0.0005
[04:13:11.012] iteration:7975  t-loss:0.4117, loss-lb:0.1793, loss-ulb:0.1162, weight:2.00, lr:0.0005
[04:13:12.460] iteration:7976  t-loss:0.5873, loss-lb:0.2469, loss-ulb:0.1702, weight:2.00, lr:0.0005
[04:13:12.796] iteration:7977  t-loss:0.4320, loss-lb:0.2412, loss-ulb:0.0954, weight:2.00, lr:0.0005
[04:13:13.125] iteration:7978  t-loss:0.2656, loss-lb:0.1693, loss-ulb:0.0482, weight:2.00, lr:0.0005
[04:13:13.445] iteration:7979  t-loss:0.3468, loss-lb:0.2022, loss-ulb:0.0723, weight:2.00, lr:0.0005
[04:13:13.758] iteration:7980  t-loss:0.3043, loss-lb:0.2507, loss-ulb:0.0268, weight:2.00, lr:0.0005
[04:13:14.072] iteration:7981  t-loss:0.7219, loss-lb:0.1734, loss-ulb:0.2742, weight:2.00, lr:0.0005
[04:13:14.391] iteration:7982  t-loss:0.5211, loss-lb:0.2963, loss-ulb:0.1124, weight:2.00, lr:0.0005
[04:13:14.707] iteration:7983  t-loss:0.3891, loss-lb:0.1488, loss-ulb:0.1202, weight:2.00, lr:0.0005
[04:13:15.031] iteration:7984  t-loss:0.1883, loss-lb:0.1433, loss-ulb:0.0225, weight:2.00, lr:0.0005
[04:13:15.372] iteration:7985  t-loss:0.5202, loss-lb:0.3342, loss-ulb:0.0930, weight:2.00, lr:0.0005
[04:13:15.711] iteration:7986  t-loss:0.2288, loss-lb:0.1372, loss-ulb:0.0458, weight:2.00, lr:0.0005
[04:13:16.066] iteration:7987  t-loss:0.4181, loss-lb:0.1736, loss-ulb:0.1223, weight:2.00, lr:0.0005
[04:13:16.394] iteration:7988  t-loss:0.3077, loss-lb:0.2680, loss-ulb:0.0199, weight:2.00, lr:0.0005
[04:13:16.725] iteration:7989  t-loss:0.3351, loss-lb:0.1637, loss-ulb:0.0857, weight:2.00, lr:0.0005
[04:13:17.056] iteration:7990  t-loss:0.4307, loss-lb:0.1555, loss-ulb:0.1376, weight:2.00, lr:0.0005
[04:13:17.369] iteration:7991  t-loss:0.1928, loss-lb:0.1438, loss-ulb:0.0245, weight:2.00, lr:0.0005
[04:13:17.701] iteration:7992  t-loss:0.3976, loss-lb:0.2592, loss-ulb:0.0692, weight:2.00, lr:0.0005
[04:13:18.023] iteration:7993  t-loss:0.5567, loss-lb:0.2726, loss-ulb:0.1420, weight:2.00, lr:0.0005
[04:13:18.340] iteration:7994  t-loss:0.4405, loss-lb:0.1546, loss-ulb:0.1429, weight:2.00, lr:0.0005
[04:13:18.659] iteration:7995  t-loss:0.4577, loss-lb:0.1675, loss-ulb:0.1451, weight:2.00, lr:0.0005
[04:13:18.977] iteration:7996  t-loss:0.4970, loss-lb:0.3172, loss-ulb:0.0899, weight:2.00, lr:0.0005
[04:13:19.294] iteration:7997  t-loss:0.2166, loss-lb:0.1694, loss-ulb:0.0236, weight:2.00, lr:0.0005
[04:13:19.610] iteration:7998  t-loss:0.3027, loss-lb:0.1674, loss-ulb:0.0676, weight:2.00, lr:0.0005
[04:13:19.925] iteration:7999  t-loss:0.2680, loss-lb:0.2190, loss-ulb:0.0245, weight:2.00, lr:0.0005
[04:13:20.245] iteration:8000  t-loss:0.2851, loss-lb:0.1975, loss-ulb:0.0438, weight:2.00, lr:0.0005
[04:13:21.493] iteration:8001  t-loss:0.3793, loss-lb:0.2276, loss-ulb:0.0758, weight:2.00, lr:0.0005
[04:13:21.827] iteration:8002  t-loss:0.5729, loss-lb:0.3725, loss-ulb:0.1002, weight:2.00, lr:0.0005
[04:13:22.142] iteration:8003  t-loss:0.3091, loss-lb:0.1658, loss-ulb:0.0717, weight:2.00, lr:0.0005
[04:13:22.460] iteration:8004  t-loss:0.5646, loss-lb:0.2601, loss-ulb:0.1523, weight:2.00, lr:0.0005
[04:13:22.779] iteration:8005  t-loss:0.4428, loss-lb:0.2402, loss-ulb:0.1013, weight:2.00, lr:0.0005
[04:13:23.097] iteration:8006  t-loss:0.2578, loss-lb:0.1345, loss-ulb:0.0617, weight:2.00, lr:0.0005
[04:13:23.432] iteration:8007  t-loss:0.2911, loss-lb:0.2502, loss-ulb:0.0204, weight:2.00, lr:0.0005
[04:13:23.777] iteration:8008  t-loss:0.2587, loss-lb:0.2297, loss-ulb:0.0145, weight:2.00, lr:0.0005
[04:13:24.111] iteration:8009  t-loss:0.3269, loss-lb:0.1908, loss-ulb:0.0680, weight:2.00, lr:0.0005
[04:13:24.447] iteration:8010  t-loss:0.4570, loss-lb:0.2599, loss-ulb:0.0986, weight:2.00, lr:0.0005
[04:13:24.777] iteration:8011  t-loss:0.4390, loss-lb:0.2584, loss-ulb:0.0903, weight:2.00, lr:0.0005
[04:13:25.103] iteration:8012  t-loss:0.3103, loss-lb:0.2059, loss-ulb:0.0522, weight:2.00, lr:0.0005
[04:13:25.433] iteration:8013  t-loss:0.4735, loss-lb:0.3443, loss-ulb:0.0646, weight:2.00, lr:0.0005
[04:13:25.755] iteration:8014  t-loss:0.2809, loss-lb:0.2129, loss-ulb:0.0340, weight:2.00, lr:0.0005
[04:13:26.076] iteration:8015  t-loss:0.2634, loss-lb:0.1833, loss-ulb:0.0401, weight:2.00, lr:0.0005
[04:13:26.398] iteration:8016  t-loss:0.3604, loss-lb:0.2123, loss-ulb:0.0740, weight:2.00, lr:0.0005
[04:13:26.729] iteration:8017  t-loss:0.4396, loss-lb:0.1881, loss-ulb:0.1258, weight:2.00, lr:0.0005
[04:13:27.057] iteration:8018  t-loss:0.2266, loss-lb:0.1245, loss-ulb:0.0510, weight:2.00, lr:0.0005
[04:13:27.381] iteration:8019  t-loss:0.4075, loss-lb:0.3343, loss-ulb:0.0366, weight:2.00, lr:0.0005
[04:13:27.703] iteration:8020  t-loss:0.1659, loss-lb:0.1369, loss-ulb:0.0145, weight:2.00, lr:0.0005
[04:13:28.026] iteration:8021  t-loss:0.4188, loss-lb:0.1584, loss-ulb:0.1302, weight:2.00, lr:0.0005
[04:13:28.347] iteration:8022  t-loss:0.3479, loss-lb:0.2071, loss-ulb:0.0704, weight:2.00, lr:0.0005
[04:13:28.667] iteration:8023  t-loss:0.3000, loss-lb:0.2252, loss-ulb:0.0374, weight:2.00, lr:0.0005
[04:13:28.989] iteration:8024  t-loss:0.3705, loss-lb:0.2282, loss-ulb:0.0711, weight:2.00, lr:0.0005
[04:13:29.311] iteration:8025  t-loss:0.2709, loss-lb:0.1676, loss-ulb:0.0517, weight:2.00, lr:0.0005
[04:15:41.688] iteration 8025 : dice_score: 0.847940 best_dice: 0.847900
[04:15:41.689]  <<Test>> - Ep:320  - Dice-S/T:83.94/84.79, Best-S:84.32, Best-T:84.79
[04:15:41.689]           - AvgLoss(lb/ulb/all):0.22/0.06/0.33
[04:15:43.398] iteration:8026  t-loss:0.6412, loss-lb:0.1878, loss-ulb:0.2267, weight:2.00, lr:0.0005
[04:15:43.749] iteration:8027  t-loss:0.3056, loss-lb:0.1563, loss-ulb:0.0747, weight:2.00, lr:0.0005
[04:15:44.103] iteration:8028  t-loss:0.3207, loss-lb:0.2085, loss-ulb:0.0561, weight:2.00, lr:0.0005
[04:15:44.450] iteration:8029  t-loss:0.3976, loss-lb:0.1818, loss-ulb:0.1079, weight:2.00, lr:0.0005
[04:15:44.818] iteration:8030  t-loss:0.4475, loss-lb:0.2332, loss-ulb:0.1071, weight:2.00, lr:0.0005
[04:15:45.173] iteration:8031  t-loss:0.3273, loss-lb:0.1731, loss-ulb:0.0771, weight:2.00, lr:0.0005
[04:15:45.516] iteration:8032  t-loss:0.2792, loss-lb:0.1669, loss-ulb:0.0562, weight:2.00, lr:0.0005
[04:15:45.849] iteration:8033  t-loss:0.1740, loss-lb:0.1280, loss-ulb:0.0230, weight:2.00, lr:0.0005
[04:15:46.189] iteration:8034  t-loss:0.4021, loss-lb:0.2145, loss-ulb:0.0938, weight:2.00, lr:0.0005
[04:15:46.536] iteration:8035  t-loss:0.3925, loss-lb:0.1425, loss-ulb:0.1250, weight:2.00, lr:0.0005
[04:15:46.867] iteration:8036  t-loss:0.4622, loss-lb:0.2555, loss-ulb:0.1034, weight:2.00, lr:0.0005
[04:15:47.199] iteration:8037  t-loss:0.3889, loss-lb:0.1923, loss-ulb:0.0983, weight:2.00, lr:0.0005
[04:15:47.525] iteration:8038  t-loss:0.2771, loss-lb:0.1520, loss-ulb:0.0626, weight:2.00, lr:0.0005
[04:15:47.859] iteration:8039  t-loss:0.4963, loss-lb:0.1316, loss-ulb:0.1823, weight:2.00, lr:0.0005
[04:15:48.185] iteration:8040  t-loss:0.6148, loss-lb:0.2191, loss-ulb:0.1979, weight:2.00, lr:0.0005
[04:15:48.504] iteration:8041  t-loss:0.3760, loss-lb:0.1326, loss-ulb:0.1217, weight:2.00, lr:0.0005
[04:15:48.829] iteration:8042  t-loss:0.3217, loss-lb:0.2591, loss-ulb:0.0313, weight:2.00, lr:0.0005
[04:15:49.143] iteration:8043  t-loss:0.2224, loss-lb:0.1795, loss-ulb:0.0214, weight:2.00, lr:0.0005
[04:15:49.462] iteration:8044  t-loss:0.3666, loss-lb:0.2627, loss-ulb:0.0520, weight:2.00, lr:0.0005
[04:15:49.774] iteration:8045  t-loss:0.3030, loss-lb:0.2306, loss-ulb:0.0362, weight:2.00, lr:0.0005
[04:15:50.089] iteration:8046  t-loss:0.3105, loss-lb:0.2537, loss-ulb:0.0284, weight:2.00, lr:0.0005
[04:15:50.405] iteration:8047  t-loss:0.4136, loss-lb:0.2977, loss-ulb:0.0580, weight:2.00, lr:0.0005
[04:15:50.728] iteration:8048  t-loss:0.3821, loss-lb:0.1842, loss-ulb:0.0990, weight:2.00, lr:0.0005
[04:15:51.052] iteration:8049  t-loss:0.2425, loss-lb:0.2025, loss-ulb:0.0200, weight:2.00, lr:0.0005
[04:15:51.397] iteration:8050  t-loss:0.3219, loss-lb:0.1546, loss-ulb:0.0837, weight:2.00, lr:0.0005
[04:15:52.845] iteration:8051  t-loss:0.4204, loss-lb:0.1787, loss-ulb:0.1209, weight:2.00, lr:0.0005
[04:15:53.192] iteration:8052  t-loss:0.4912, loss-lb:0.2054, loss-ulb:0.1429, weight:2.00, lr:0.0005
[04:15:53.524] iteration:8053  t-loss:0.3783, loss-lb:0.2839, loss-ulb:0.0472, weight:2.00, lr:0.0005
[04:15:53.847] iteration:8054  t-loss:0.3265, loss-lb:0.1240, loss-ulb:0.1012, weight:2.00, lr:0.0005
[04:15:54.165] iteration:8055  t-loss:0.1673, loss-lb:0.1221, loss-ulb:0.0226, weight:2.00, lr:0.0005
[04:15:54.487] iteration:8056  t-loss:0.7961, loss-lb:0.2361, loss-ulb:0.2800, weight:2.00, lr:0.0005
[04:15:54.803] iteration:8057  t-loss:0.1799, loss-lb:0.1264, loss-ulb:0.0268, weight:2.00, lr:0.0005
[04:15:55.118] iteration:8058  t-loss:0.2260, loss-lb:0.1821, loss-ulb:0.0220, weight:2.00, lr:0.0005
[04:15:55.433] iteration:8059  t-loss:0.2099, loss-lb:0.1570, loss-ulb:0.0265, weight:2.00, lr:0.0005
[04:15:55.751] iteration:8060  t-loss:0.4532, loss-lb:0.2786, loss-ulb:0.0873, weight:2.00, lr:0.0005
[04:15:56.072] iteration:8061  t-loss:0.4127, loss-lb:0.3181, loss-ulb:0.0473, weight:2.00, lr:0.0005
[04:15:56.392] iteration:8062  t-loss:0.4520, loss-lb:0.1803, loss-ulb:0.1359, weight:2.00, lr:0.0005
[04:15:56.709] iteration:8063  t-loss:0.2662, loss-lb:0.2240, loss-ulb:0.0211, weight:2.00, lr:0.0005
[04:15:57.027] iteration:8064  t-loss:0.5584, loss-lb:0.3558, loss-ulb:0.1013, weight:2.00, lr:0.0005
[04:15:57.347] iteration:8065  t-loss:0.2697, loss-lb:0.2072, loss-ulb:0.0313, weight:2.00, lr:0.0005
[04:15:57.675] iteration:8066  t-loss:0.2931, loss-lb:0.1615, loss-ulb:0.0658, weight:2.00, lr:0.0005
[04:15:58.010] iteration:8067  t-loss:0.5753, loss-lb:0.2143, loss-ulb:0.1805, weight:2.00, lr:0.0005
[04:15:58.340] iteration:8068  t-loss:0.3612, loss-lb:0.1918, loss-ulb:0.0847, weight:2.00, lr:0.0005
[04:15:58.658] iteration:8069  t-loss:0.4074, loss-lb:0.3253, loss-ulb:0.0410, weight:2.00, lr:0.0005
[04:15:58.983] iteration:8070  t-loss:0.3973, loss-lb:0.2406, loss-ulb:0.0783, weight:2.00, lr:0.0005
[04:15:59.305] iteration:8071  t-loss:0.2414, loss-lb:0.1551, loss-ulb:0.0431, weight:2.00, lr:0.0005
[04:15:59.632] iteration:8072  t-loss:0.4368, loss-lb:0.1939, loss-ulb:0.1215, weight:2.00, lr:0.0005
[04:15:59.975] iteration:8073  t-loss:0.3005, loss-lb:0.2437, loss-ulb:0.0284, weight:2.00, lr:0.0005
[04:16:00.305] iteration:8074  t-loss:0.5041, loss-lb:0.3769, loss-ulb:0.0636, weight:2.00, lr:0.0005
[04:16:00.627] iteration:8075  t-loss:0.2644, loss-lb:0.1645, loss-ulb:0.0499, weight:2.00, lr:0.0005
[04:16:02.416] iteration:8076  t-loss:0.3524, loss-lb:0.1614, loss-ulb:0.0955, weight:2.00, lr:0.0005
[04:16:02.760] iteration:8077  t-loss:0.2323, loss-lb:0.1656, loss-ulb:0.0334, weight:2.00, lr:0.0005
[04:16:03.085] iteration:8078  t-loss:0.2294, loss-lb:0.1624, loss-ulb:0.0335, weight:2.00, lr:0.0005
[04:16:03.425] iteration:8079  t-loss:0.6577, loss-lb:0.2169, loss-ulb:0.2204, weight:2.00, lr:0.0005
[04:16:03.751] iteration:8080  t-loss:0.4096, loss-lb:0.2079, loss-ulb:0.1009, weight:2.00, lr:0.0005
[04:16:04.074] iteration:8081  t-loss:0.3898, loss-lb:0.1394, loss-ulb:0.1252, weight:2.00, lr:0.0005
[04:16:04.395] iteration:8082  t-loss:0.5251, loss-lb:0.3711, loss-ulb:0.0770, weight:2.00, lr:0.0005
[04:16:04.727] iteration:8083  t-loss:0.4233, loss-lb:0.2817, loss-ulb:0.0708, weight:2.00, lr:0.0005
[04:16:05.054] iteration:8084  t-loss:0.2837, loss-lb:0.2465, loss-ulb:0.0186, weight:2.00, lr:0.0005
[04:16:05.389] iteration:8085  t-loss:0.3577, loss-lb:0.1488, loss-ulb:0.1044, weight:2.00, lr:0.0005
[04:16:05.707] iteration:8086  t-loss:0.2951, loss-lb:0.2175, loss-ulb:0.0388, weight:2.00, lr:0.0005
[04:16:06.023] iteration:8087  t-loss:0.3456, loss-lb:0.1884, loss-ulb:0.0786, weight:2.00, lr:0.0005
[04:16:06.344] iteration:8088  t-loss:0.4165, loss-lb:0.2050, loss-ulb:0.1058, weight:2.00, lr:0.0005
[04:16:06.667] iteration:8089  t-loss:0.4115, loss-lb:0.2256, loss-ulb:0.0930, weight:2.00, lr:0.0005
[04:16:06.985] iteration:8090  t-loss:0.2403, loss-lb:0.1853, loss-ulb:0.0275, weight:2.00, lr:0.0005
[04:16:07.299] iteration:8091  t-loss:0.2147, loss-lb:0.1570, loss-ulb:0.0289, weight:2.00, lr:0.0005
[04:16:07.613] iteration:8092  t-loss:0.2921, loss-lb:0.1694, loss-ulb:0.0613, weight:2.00, lr:0.0005
[04:16:07.931] iteration:8093  t-loss:0.5459, loss-lb:0.3756, loss-ulb:0.0852, weight:2.00, lr:0.0005
[04:16:08.249] iteration:8094  t-loss:0.3438, loss-lb:0.2135, loss-ulb:0.0651, weight:2.00, lr:0.0005
[04:16:08.565] iteration:8095  t-loss:0.3412, loss-lb:0.2069, loss-ulb:0.0672, weight:2.00, lr:0.0005
[04:16:08.880] iteration:8096  t-loss:0.2448, loss-lb:0.1962, loss-ulb:0.0243, weight:2.00, lr:0.0005
[04:16:09.195] iteration:8097  t-loss:0.1644, loss-lb:0.1152, loss-ulb:0.0246, weight:2.00, lr:0.0005
[04:16:09.510] iteration:8098  t-loss:0.4384, loss-lb:0.1220, loss-ulb:0.1582, weight:2.00, lr:0.0005
[04:16:09.825] iteration:8099  t-loss:0.6354, loss-lb:0.1619, loss-ulb:0.2368, weight:2.00, lr:0.0005
[04:16:10.145] iteration:8100  t-loss:0.2551, loss-lb:0.1779, loss-ulb:0.0386, weight:2.00, lr:0.0005
[04:16:11.653] iteration:8101  t-loss:0.3065, loss-lb:0.2267, loss-ulb:0.0399, weight:2.00, lr:0.0005
[04:16:12.010] iteration:8102  t-loss:0.2313, loss-lb:0.1661, loss-ulb:0.0326, weight:2.00, lr:0.0005
[04:16:12.354] iteration:8103  t-loss:0.2706, loss-lb:0.1891, loss-ulb:0.0408, weight:2.00, lr:0.0005
[04:16:12.712] iteration:8104  t-loss:1.2747, loss-lb:0.2636, loss-ulb:0.5055, weight:2.00, lr:0.0005
[04:16:13.058] iteration:8105  t-loss:0.2303, loss-lb:0.1471, loss-ulb:0.0416, weight:2.00, lr:0.0005
[04:16:13.402] iteration:8106  t-loss:0.3204, loss-lb:0.1868, loss-ulb:0.0668, weight:2.00, lr:0.0005
[04:16:13.751] iteration:8107  t-loss:0.5346, loss-lb:0.3939, loss-ulb:0.0703, weight:2.00, lr:0.0005
[04:16:14.084] iteration:8108  t-loss:0.3464, loss-lb:0.2232, loss-ulb:0.0616, weight:2.00, lr:0.0005
[04:16:14.408] iteration:8109  t-loss:0.2981, loss-lb:0.2452, loss-ulb:0.0264, weight:2.00, lr:0.0005
[04:16:14.729] iteration:8110  t-loss:0.3688, loss-lb:0.2582, loss-ulb:0.0553, weight:2.00, lr:0.0005
[04:16:15.054] iteration:8111  t-loss:1.0976, loss-lb:0.2770, loss-ulb:0.4103, weight:2.00, lr:0.0005
[04:16:15.380] iteration:8112  t-loss:0.4287, loss-lb:0.2451, loss-ulb:0.0918, weight:2.00, lr:0.0005
[04:16:15.710] iteration:8113  t-loss:0.4715, loss-lb:0.3998, loss-ulb:0.0358, weight:2.00, lr:0.0005
[04:16:16.035] iteration:8114  t-loss:0.3959, loss-lb:0.1947, loss-ulb:0.1006, weight:2.00, lr:0.0005
[04:16:16.358] iteration:8115  t-loss:0.3746, loss-lb:0.1795, loss-ulb:0.0976, weight:2.00, lr:0.0005
[04:16:16.683] iteration:8116  t-loss:0.3532, loss-lb:0.1524, loss-ulb:0.1004, weight:2.00, lr:0.0005
[04:16:17.007] iteration:8117  t-loss:0.4622, loss-lb:0.1718, loss-ulb:0.1452, weight:2.00, lr:0.0005
[04:16:17.325] iteration:8118  t-loss:0.3698, loss-lb:0.1736, loss-ulb:0.0981, weight:2.00, lr:0.0005
[04:16:17.642] iteration:8119  t-loss:0.2646, loss-lb:0.1743, loss-ulb:0.0451, weight:2.00, lr:0.0005
[04:16:17.966] iteration:8120  t-loss:0.4530, loss-lb:0.2617, loss-ulb:0.0956, weight:2.00, lr:0.0005
[04:16:18.285] iteration:8121  t-loss:0.2316, loss-lb:0.1895, loss-ulb:0.0210, weight:2.00, lr:0.0005
[04:16:18.608] iteration:8122  t-loss:0.3277, loss-lb:0.2293, loss-ulb:0.0492, weight:2.00, lr:0.0005
[04:16:18.926] iteration:8123  t-loss:0.2770, loss-lb:0.2139, loss-ulb:0.0315, weight:2.00, lr:0.0005
[04:16:19.250] iteration:8124  t-loss:0.4216, loss-lb:0.1769, loss-ulb:0.1224, weight:2.00, lr:0.0005
[04:16:19.567] iteration:8125  t-loss:0.2901, loss-lb:0.1596, loss-ulb:0.0653, weight:2.00, lr:0.0005
[04:18:35.160] iteration 8125 : dice_score: 0.845614 best_dice: 0.847900
[04:18:35.160]  <<Test>> - Ep:324  - Dice-S/T:83.98/84.56, Best-S:84.32, Best-T:84.79
[04:18:35.160]           - AvgLoss(lb/ulb/all):0.22/0.09/0.40
[04:18:36.638] iteration:8126  t-loss:0.4224, loss-lb:0.2159, loss-ulb:0.1032, weight:2.00, lr:0.0005
[04:18:36.984] iteration:8127  t-loss:0.3294, loss-lb:0.2753, loss-ulb:0.0271, weight:2.00, lr:0.0005
[04:18:37.323] iteration:8128  t-loss:0.5391, loss-lb:0.4029, loss-ulb:0.0681, weight:2.00, lr:0.0005
[04:18:37.652] iteration:8129  t-loss:0.1888, loss-lb:0.1431, loss-ulb:0.0228, weight:2.00, lr:0.0005
[04:18:37.980] iteration:8130  t-loss:0.5608, loss-lb:0.3576, loss-ulb:0.1016, weight:2.00, lr:0.0005
[04:18:38.300] iteration:8131  t-loss:0.3744, loss-lb:0.2607, loss-ulb:0.0568, weight:2.00, lr:0.0005
[04:18:38.619] iteration:8132  t-loss:0.4209, loss-lb:0.2034, loss-ulb:0.1088, weight:2.00, lr:0.0005
[04:18:38.938] iteration:8133  t-loss:0.5366, loss-lb:0.2681, loss-ulb:0.1342, weight:2.00, lr:0.0005
[04:18:39.260] iteration:8134  t-loss:0.5040, loss-lb:0.2954, loss-ulb:0.1043, weight:2.00, lr:0.0005
[04:18:39.579] iteration:8135  t-loss:0.3585, loss-lb:0.1338, loss-ulb:0.1124, weight:2.00, lr:0.0005
[04:18:39.899] iteration:8136  t-loss:0.4396, loss-lb:0.2401, loss-ulb:0.0997, weight:2.00, lr:0.0005
[04:18:40.220] iteration:8137  t-loss:0.3939, loss-lb:0.1368, loss-ulb:0.1285, weight:2.00, lr:0.0005
[04:18:40.546] iteration:8138  t-loss:0.3413, loss-lb:0.2264, loss-ulb:0.0574, weight:2.00, lr:0.0005
[04:18:40.864] iteration:8139  t-loss:0.2637, loss-lb:0.1449, loss-ulb:0.0594, weight:2.00, lr:0.0005
[04:18:41.191] iteration:8140  t-loss:0.2758, loss-lb:0.2155, loss-ulb:0.0301, weight:2.00, lr:0.0005
[04:18:41.514] iteration:8141  t-loss:0.3795, loss-lb:0.1467, loss-ulb:0.1164, weight:2.00, lr:0.0005
[04:18:41.835] iteration:8142  t-loss:0.3181, loss-lb:0.1464, loss-ulb:0.0858, weight:2.00, lr:0.0005
[04:18:42.155] iteration:8143  t-loss:0.2331, loss-lb:0.1963, loss-ulb:0.0184, weight:2.00, lr:0.0005
[04:18:42.470] iteration:8144  t-loss:0.1824, loss-lb:0.1436, loss-ulb:0.0194, weight:2.00, lr:0.0005
[04:18:42.783] iteration:8145  t-loss:0.1911, loss-lb:0.1238, loss-ulb:0.0336, weight:2.00, lr:0.0005
[04:18:43.098] iteration:8146  t-loss:0.2157, loss-lb:0.1849, loss-ulb:0.0154, weight:2.00, lr:0.0005
[04:18:43.416] iteration:8147  t-loss:0.5340, loss-lb:0.2217, loss-ulb:0.1562, weight:2.00, lr:0.0005
[04:18:43.739] iteration:8148  t-loss:0.3793, loss-lb:0.1718, loss-ulb:0.1038, weight:2.00, lr:0.0005
[04:18:44.057] iteration:8149  t-loss:0.2361, loss-lb:0.1642, loss-ulb:0.0360, weight:2.00, lr:0.0005
[04:18:44.376] iteration:8150  t-loss:0.5254, loss-lb:0.3117, loss-ulb:0.1068, weight:2.00, lr:0.0005
[04:18:45.697] iteration:8151  t-loss:0.4955, loss-lb:0.2177, loss-ulb:0.1389, weight:2.00, lr:0.0005
[04:18:46.039] iteration:8152  t-loss:0.1857, loss-lb:0.1550, loss-ulb:0.0154, weight:2.00, lr:0.0005
[04:18:46.365] iteration:8153  t-loss:0.7434, loss-lb:0.1655, loss-ulb:0.2889, weight:2.00, lr:0.0005
[04:18:46.687] iteration:8154  t-loss:0.2451, loss-lb:0.1904, loss-ulb:0.0273, weight:2.00, lr:0.0005
[04:18:47.009] iteration:8155  t-loss:0.2056, loss-lb:0.1625, loss-ulb:0.0216, weight:2.00, lr:0.0005
[04:18:47.330] iteration:8156  t-loss:0.3830, loss-lb:0.2326, loss-ulb:0.0752, weight:2.00, lr:0.0005
[04:18:47.650] iteration:8157  t-loss:0.3005, loss-lb:0.2278, loss-ulb:0.0363, weight:2.00, lr:0.0005
[04:18:47.968] iteration:8158  t-loss:0.2496, loss-lb:0.2067, loss-ulb:0.0214, weight:2.00, lr:0.0005
[04:18:48.288] iteration:8159  t-loss:0.4346, loss-lb:0.3693, loss-ulb:0.0326, weight:2.00, lr:0.0005
[04:18:48.610] iteration:8160  t-loss:0.4365, loss-lb:0.1627, loss-ulb:0.1369, weight:2.00, lr:0.0005
[04:18:48.939] iteration:8161  t-loss:0.3940, loss-lb:0.2266, loss-ulb:0.0837, weight:2.00, lr:0.0005
[04:18:49.271] iteration:8162  t-loss:0.4622, loss-lb:0.2198, loss-ulb:0.1212, weight:2.00, lr:0.0005
[04:18:49.594] iteration:8163  t-loss:0.3584, loss-lb:0.1978, loss-ulb:0.0803, weight:2.00, lr:0.0005
[04:18:49.916] iteration:8164  t-loss:0.5156, loss-lb:0.2533, loss-ulb:0.1311, weight:2.00, lr:0.0005
[04:18:50.243] iteration:8165  t-loss:0.4239, loss-lb:0.1718, loss-ulb:0.1260, weight:2.00, lr:0.0005
[04:18:50.577] iteration:8166  t-loss:0.3505, loss-lb:0.1877, loss-ulb:0.0814, weight:2.00, lr:0.0005
[04:18:50.894] iteration:8167  t-loss:0.1997, loss-lb:0.1552, loss-ulb:0.0223, weight:2.00, lr:0.0005
[04:18:51.220] iteration:8168  t-loss:0.6962, loss-lb:0.4309, loss-ulb:0.1327, weight:2.00, lr:0.0005
[04:18:51.538] iteration:8169  t-loss:0.3582, loss-lb:0.1938, loss-ulb:0.0822, weight:2.00, lr:0.0005
[04:18:51.857] iteration:8170  t-loss:0.3210, loss-lb:0.1410, loss-ulb:0.0900, weight:2.00, lr:0.0005
[04:18:52.175] iteration:8171  t-loss:0.2060, loss-lb:0.1550, loss-ulb:0.0255, weight:2.00, lr:0.0005
[04:18:52.497] iteration:8172  t-loss:0.6146, loss-lb:0.3412, loss-ulb:0.1367, weight:2.00, lr:0.0005
[04:18:52.813] iteration:8173  t-loss:0.7550, loss-lb:0.1582, loss-ulb:0.2984, weight:2.00, lr:0.0005
[04:18:53.130] iteration:8174  t-loss:0.2154, loss-lb:0.1476, loss-ulb:0.0339, weight:2.00, lr:0.0005
[04:18:53.447] iteration:8175  t-loss:0.4470, loss-lb:0.1492, loss-ulb:0.1489, weight:2.00, lr:0.0005
[04:18:54.694] iteration:8176  t-loss:0.7286, loss-lb:0.5604, loss-ulb:0.0841, weight:2.00, lr:0.0005
[04:18:55.032] iteration:8177  t-loss:0.3625, loss-lb:0.2001, loss-ulb:0.0812, weight:2.00, lr:0.0005
[04:18:55.361] iteration:8178  t-loss:0.4657, loss-lb:0.3480, loss-ulb:0.0588, weight:2.00, lr:0.0005
[04:18:55.708] iteration:8179  t-loss:0.2828, loss-lb:0.1995, loss-ulb:0.0417, weight:2.00, lr:0.0005
[04:18:56.033] iteration:8180  t-loss:0.4556, loss-lb:0.1299, loss-ulb:0.1628, weight:2.00, lr:0.0005
[04:18:56.355] iteration:8181  t-loss:0.3324, loss-lb:0.1442, loss-ulb:0.0941, weight:2.00, lr:0.0005
[04:18:56.688] iteration:8182  t-loss:0.3273, loss-lb:0.2884, loss-ulb:0.0194, weight:2.00, lr:0.0005
[04:18:57.019] iteration:8183  t-loss:0.3167, loss-lb:0.1658, loss-ulb:0.0755, weight:2.00, lr:0.0005
[04:18:57.341] iteration:8184  t-loss:0.4009, loss-lb:0.1785, loss-ulb:0.1112, weight:2.00, lr:0.0005
[04:18:57.667] iteration:8185  t-loss:0.4399, loss-lb:0.2633, loss-ulb:0.0883, weight:2.00, lr:0.0005
[04:18:57.991] iteration:8186  t-loss:0.5032, loss-lb:0.1975, loss-ulb:0.1528, weight:2.00, lr:0.0005
[04:18:58.310] iteration:8187  t-loss:0.9983, loss-lb:0.5064, loss-ulb:0.2460, weight:2.00, lr:0.0005
[04:18:58.634] iteration:8188  t-loss:0.4601, loss-lb:0.3910, loss-ulb:0.0346, weight:2.00, lr:0.0005
[04:18:58.954] iteration:8189  t-loss:0.4003, loss-lb:0.1069, loss-ulb:0.1467, weight:2.00, lr:0.0005
[04:18:59.276] iteration:8190  t-loss:0.2938, loss-lb:0.1731, loss-ulb:0.0603, weight:2.00, lr:0.0005
[04:18:59.604] iteration:8191  t-loss:0.3256, loss-lb:0.1903, loss-ulb:0.0676, weight:2.00, lr:0.0005
[04:18:59.928] iteration:8192  t-loss:0.4627, loss-lb:0.2924, loss-ulb:0.0851, weight:2.00, lr:0.0005
[04:19:00.260] iteration:8193  t-loss:0.5089, loss-lb:0.2443, loss-ulb:0.1323, weight:2.00, lr:0.0005
[04:19:00.581] iteration:8194  t-loss:0.4503, loss-lb:0.1776, loss-ulb:0.1364, weight:2.00, lr:0.0005
[04:19:00.899] iteration:8195  t-loss:0.4985, loss-lb:0.3438, loss-ulb:0.0774, weight:2.00, lr:0.0005
[04:19:01.216] iteration:8196  t-loss:0.4229, loss-lb:0.1625, loss-ulb:0.1302, weight:2.00, lr:0.0005
[04:19:01.533] iteration:8197  t-loss:0.5183, loss-lb:0.4117, loss-ulb:0.0533, weight:2.00, lr:0.0005
[04:19:01.851] iteration:8198  t-loss:0.6375, loss-lb:0.3239, loss-ulb:0.1568, weight:2.00, lr:0.0005
[04:19:02.173] iteration:8199  t-loss:0.4432, loss-lb:0.2387, loss-ulb:0.1023, weight:2.00, lr:0.0005
[04:19:02.488] iteration:8200  t-loss:0.3514, loss-lb:0.1857, loss-ulb:0.0828, weight:2.00, lr:0.0005
[04:19:03.886] iteration:8201  t-loss:0.3998, loss-lb:0.1776, loss-ulb:0.1111, weight:2.00, lr:0.0005
[04:19:04.237] iteration:8202  t-loss:0.6266, loss-lb:0.3201, loss-ulb:0.1533, weight:2.00, lr:0.0005
[04:19:04.567] iteration:8203  t-loss:0.2110, loss-lb:0.1400, loss-ulb:0.0355, weight:2.00, lr:0.0005
[04:19:04.903] iteration:8204  t-loss:0.2264, loss-lb:0.1552, loss-ulb:0.0356, weight:2.00, lr:0.0005
[04:19:05.236] iteration:8205  t-loss:0.4029, loss-lb:0.1483, loss-ulb:0.1273, weight:2.00, lr:0.0005
[04:19:05.553] iteration:8206  t-loss:0.3069, loss-lb:0.2535, loss-ulb:0.0267, weight:2.00, lr:0.0005
[04:19:05.872] iteration:8207  t-loss:0.4559, loss-lb:0.1845, loss-ulb:0.1357, weight:2.00, lr:0.0005
[04:19:06.200] iteration:8208  t-loss:0.2390, loss-lb:0.1303, loss-ulb:0.0544, weight:2.00, lr:0.0005
[04:19:06.522] iteration:8209  t-loss:0.4526, loss-lb:0.2811, loss-ulb:0.0857, weight:2.00, lr:0.0005
[04:19:06.854] iteration:8210  t-loss:0.3737, loss-lb:0.2456, loss-ulb:0.0641, weight:2.00, lr:0.0005
[04:19:07.177] iteration:8211  t-loss:0.2143, loss-lb:0.1494, loss-ulb:0.0325, weight:2.00, lr:0.0005
[04:19:07.503] iteration:8212  t-loss:0.7133, loss-lb:0.1517, loss-ulb:0.2808, weight:2.00, lr:0.0005
[04:19:07.827] iteration:8213  t-loss:0.4070, loss-lb:0.2076, loss-ulb:0.0997, weight:2.00, lr:0.0005
[04:19:08.149] iteration:8214  t-loss:0.1746, loss-lb:0.1290, loss-ulb:0.0228, weight:2.00, lr:0.0005
[04:19:08.477] iteration:8215  t-loss:0.4830, loss-lb:0.2766, loss-ulb:0.1032, weight:2.00, lr:0.0005
[04:19:08.803] iteration:8216  t-loss:0.7582, loss-lb:0.2834, loss-ulb:0.2374, weight:2.00, lr:0.0005
[04:19:09.127] iteration:8217  t-loss:0.4916, loss-lb:0.1598, loss-ulb:0.1659, weight:2.00, lr:0.0005
[04:19:09.451] iteration:8218  t-loss:0.2548, loss-lb:0.1284, loss-ulb:0.0632, weight:2.00, lr:0.0005
[04:19:09.770] iteration:8219  t-loss:0.4422, loss-lb:0.2093, loss-ulb:0.1164, weight:2.00, lr:0.0005
[04:19:10.092] iteration:8220  t-loss:0.6620, loss-lb:0.4176, loss-ulb:0.1222, weight:2.00, lr:0.0005
[04:19:10.415] iteration:8221  t-loss:0.5190, loss-lb:0.3053, loss-ulb:0.1069, weight:2.00, lr:0.0005
[04:19:10.731] iteration:8222  t-loss:0.2844, loss-lb:0.1885, loss-ulb:0.0479, weight:2.00, lr:0.0005
[04:19:11.051] iteration:8223  t-loss:0.3908, loss-lb:0.2216, loss-ulb:0.0846, weight:2.00, lr:0.0005
[04:19:11.372] iteration:8224  t-loss:0.3620, loss-lb:0.1865, loss-ulb:0.0878, weight:2.00, lr:0.0005
[04:19:11.692] iteration:8225  t-loss:0.5194, loss-lb:0.2296, loss-ulb:0.1449, weight:2.00, lr:0.0005
[04:21:26.336] iteration 8225 : dice_score: 0.846598 best_dice: 0.847900
[04:21:26.336]  <<Test>> - Ep:328  - Dice-S/T:83.52/84.66, Best-S:84.32, Best-T:84.79
[04:21:26.336]           - AvgLoss(lb/ulb/all):0.21/0.10/0.43
[04:21:27.829] iteration:8226  t-loss:0.4248, loss-lb:0.1912, loss-ulb:0.1168, weight:2.00, lr:0.0005
[04:21:28.170] iteration:8227  t-loss:0.3294, loss-lb:0.1192, loss-ulb:0.1051, weight:2.00, lr:0.0005
[04:21:28.508] iteration:8228  t-loss:0.3738, loss-lb:0.2356, loss-ulb:0.0691, weight:2.00, lr:0.0005
[04:21:28.840] iteration:8229  t-loss:0.6904, loss-lb:0.2863, loss-ulb:0.2021, weight:2.00, lr:0.0005
[04:21:29.169] iteration:8230  t-loss:0.4059, loss-lb:0.2204, loss-ulb:0.0927, weight:2.00, lr:0.0005
[04:21:29.497] iteration:8231  t-loss:0.4288, loss-lb:0.2153, loss-ulb:0.1067, weight:2.00, lr:0.0005
[04:21:29.822] iteration:8232  t-loss:0.3031, loss-lb:0.2321, loss-ulb:0.0355, weight:2.00, lr:0.0005
[04:21:30.150] iteration:8233  t-loss:0.2817, loss-lb:0.2198, loss-ulb:0.0310, weight:2.00, lr:0.0005
[04:21:30.471] iteration:8234  t-loss:0.3478, loss-lb:0.2519, loss-ulb:0.0479, weight:2.00, lr:0.0005
[04:21:30.792] iteration:8235  t-loss:0.1864, loss-lb:0.1451, loss-ulb:0.0206, weight:2.00, lr:0.0005
[04:21:31.118] iteration:8236  t-loss:0.4172, loss-lb:0.1791, loss-ulb:0.1190, weight:2.00, lr:0.0005
[04:21:31.440] iteration:8237  t-loss:0.3984, loss-lb:0.2920, loss-ulb:0.0532, weight:2.00, lr:0.0005
[04:21:31.758] iteration:8238  t-loss:0.3541, loss-lb:0.2681, loss-ulb:0.0430, weight:2.00, lr:0.0005
[04:21:32.078] iteration:8239  t-loss:0.5457, loss-lb:0.3458, loss-ulb:0.1000, weight:2.00, lr:0.0005
[04:21:32.398] iteration:8240  t-loss:0.5977, loss-lb:0.4005, loss-ulb:0.0986, weight:2.00, lr:0.0005
[04:21:32.717] iteration:8241  t-loss:0.1960, loss-lb:0.1453, loss-ulb:0.0253, weight:2.00, lr:0.0005
[04:21:33.036] iteration:8242  t-loss:0.2488, loss-lb:0.1999, loss-ulb:0.0245, weight:2.00, lr:0.0005
[04:21:33.354] iteration:8243  t-loss:0.2187, loss-lb:0.1699, loss-ulb:0.0244, weight:2.00, lr:0.0005
[04:21:33.670] iteration:8244  t-loss:0.4988, loss-lb:0.3370, loss-ulb:0.0809, weight:2.00, lr:0.0005
[04:21:33.987] iteration:8245  t-loss:0.5139, loss-lb:0.2269, loss-ulb:0.1435, weight:2.00, lr:0.0005
[04:21:34.303] iteration:8246  t-loss:0.4778, loss-lb:0.1593, loss-ulb:0.1592, weight:2.00, lr:0.0005
[04:21:34.619] iteration:8247  t-loss:0.3490, loss-lb:0.1407, loss-ulb:0.1041, weight:2.00, lr:0.0005
[04:21:34.935] iteration:8248  t-loss:0.4341, loss-lb:0.2405, loss-ulb:0.0968, weight:2.00, lr:0.0005
[04:21:35.254] iteration:8249  t-loss:0.6356, loss-lb:0.3019, loss-ulb:0.1668, weight:2.00, lr:0.0005
[04:21:35.569] iteration:8250  t-loss:0.4408, loss-lb:0.1740, loss-ulb:0.1334, weight:2.00, lr:0.0005
[04:21:37.071] iteration:8251  t-loss:0.5608, loss-lb:0.2982, loss-ulb:0.1313, weight:2.00, lr:0.0005
[04:21:37.423] iteration:8252  t-loss:0.5330, loss-lb:0.1997, loss-ulb:0.1666, weight:2.00, lr:0.0005
[04:21:37.768] iteration:8253  t-loss:0.2976, loss-lb:0.1354, loss-ulb:0.0811, weight:2.00, lr:0.0005
[04:21:38.121] iteration:8254  t-loss:0.4413, loss-lb:0.2771, loss-ulb:0.0821, weight:2.00, lr:0.0005
[04:21:38.477] iteration:8255  t-loss:0.3614, loss-lb:0.1904, loss-ulb:0.0855, weight:2.00, lr:0.0005
[04:21:38.822] iteration:8256  t-loss:0.5063, loss-lb:0.3171, loss-ulb:0.0946, weight:2.00, lr:0.0005
[04:21:39.158] iteration:8257  t-loss:0.4307, loss-lb:0.2470, loss-ulb:0.0919, weight:2.00, lr:0.0005
[04:21:39.490] iteration:8258  t-loss:0.3516, loss-lb:0.1651, loss-ulb:0.0932, weight:2.00, lr:0.0005
[04:21:39.817] iteration:8259  t-loss:0.4173, loss-lb:0.3318, loss-ulb:0.0428, weight:2.00, lr:0.0005
[04:21:40.154] iteration:8260  t-loss:0.4550, loss-lb:0.3293, loss-ulb:0.0629, weight:2.00, lr:0.0005
[04:21:40.487] iteration:8261  t-loss:0.6457, loss-lb:0.3378, loss-ulb:0.1539, weight:2.00, lr:0.0005
[04:21:40.820] iteration:8262  t-loss:0.4266, loss-lb:0.2229, loss-ulb:0.1019, weight:2.00, lr:0.0005
[04:21:41.143] iteration:8263  t-loss:0.3326, loss-lb:0.2260, loss-ulb:0.0533, weight:2.00, lr:0.0005
[04:21:41.462] iteration:8264  t-loss:0.2420, loss-lb:0.1815, loss-ulb:0.0302, weight:2.00, lr:0.0005
[04:21:41.785] iteration:8265  t-loss:0.5586, loss-lb:0.2766, loss-ulb:0.1410, weight:2.00, lr:0.0005
[04:21:42.108] iteration:8266  t-loss:0.4574, loss-lb:0.2498, loss-ulb:0.1038, weight:2.00, lr:0.0005
[04:21:42.431] iteration:8267  t-loss:0.5717, loss-lb:0.3885, loss-ulb:0.0916, weight:2.00, lr:0.0005
[04:21:42.748] iteration:8268  t-loss:0.4331, loss-lb:0.2750, loss-ulb:0.0790, weight:2.00, lr:0.0005
[04:21:43.068] iteration:8269  t-loss:0.3678, loss-lb:0.1678, loss-ulb:0.1000, weight:2.00, lr:0.0005
[04:21:43.385] iteration:8270  t-loss:0.3374, loss-lb:0.1753, loss-ulb:0.0810, weight:2.00, lr:0.0005
[04:21:43.702] iteration:8271  t-loss:0.4856, loss-lb:0.2941, loss-ulb:0.0958, weight:2.00, lr:0.0005
[04:21:44.021] iteration:8272  t-loss:0.4103, loss-lb:0.1694, loss-ulb:0.1205, weight:2.00, lr:0.0005
[04:21:44.338] iteration:8273  t-loss:0.2234, loss-lb:0.1699, loss-ulb:0.0267, weight:2.00, lr:0.0005
[04:21:44.653] iteration:8274  t-loss:0.2100, loss-lb:0.1583, loss-ulb:0.0259, weight:2.00, lr:0.0005
[04:21:44.974] iteration:8275  t-loss:0.3985, loss-lb:0.2732, loss-ulb:0.0626, weight:2.00, lr:0.0005
[04:21:46.212] iteration:8276  t-loss:0.2355, loss-lb:0.1823, loss-ulb:0.0266, weight:2.00, lr:0.0005
[04:21:46.553] iteration:8277  t-loss:0.5510, loss-lb:0.1658, loss-ulb:0.1926, weight:2.00, lr:0.0005
[04:21:46.886] iteration:8278  t-loss:0.2871, loss-lb:0.1466, loss-ulb:0.0702, weight:2.00, lr:0.0005
[04:21:47.216] iteration:8279  t-loss:0.4456, loss-lb:0.2913, loss-ulb:0.0771, weight:2.00, lr:0.0005
[04:21:47.540] iteration:8280  t-loss:0.3640, loss-lb:0.2553, loss-ulb:0.0544, weight:2.00, lr:0.0005
[04:21:47.861] iteration:8281  t-loss:0.3103, loss-lb:0.2678, loss-ulb:0.0212, weight:2.00, lr:0.0005
[04:21:48.183] iteration:8282  t-loss:0.6931, loss-lb:0.2992, loss-ulb:0.1969, weight:2.00, lr:0.0005
[04:21:48.504] iteration:8283  t-loss:0.4269, loss-lb:0.2356, loss-ulb:0.0957, weight:2.00, lr:0.0005
[04:21:48.823] iteration:8284  t-loss:0.4679, loss-lb:0.1964, loss-ulb:0.1358, weight:2.00, lr:0.0005
[04:21:49.143] iteration:8285  t-loss:0.5833, loss-lb:0.1199, loss-ulb:0.2317, weight:2.00, lr:0.0005
[04:21:49.463] iteration:8286  t-loss:0.3450, loss-lb:0.1721, loss-ulb:0.0865, weight:2.00, lr:0.0005
[04:21:49.802] iteration:8287  t-loss:0.7098, loss-lb:0.3837, loss-ulb:0.1630, weight:2.00, lr:0.0005
[04:21:50.149] iteration:8288  t-loss:1.0758, loss-lb:0.3899, loss-ulb:0.3430, weight:2.00, lr:0.0005
[04:21:50.500] iteration:8289  t-loss:0.6377, loss-lb:0.4043, loss-ulb:0.1167, weight:2.00, lr:0.0005
[04:21:50.861] iteration:8290  t-loss:0.3551, loss-lb:0.2423, loss-ulb:0.0564, weight:2.00, lr:0.0005
[04:21:51.232] iteration:8291  t-loss:0.3880, loss-lb:0.2216, loss-ulb:0.0832, weight:2.00, lr:0.0005
[04:21:51.617] iteration:8292  t-loss:0.2995, loss-lb:0.2430, loss-ulb:0.0282, weight:2.00, lr:0.0005
[04:21:51.979] iteration:8293  t-loss:0.3950, loss-lb:0.1755, loss-ulb:0.1097, weight:2.00, lr:0.0005
[04:21:52.342] iteration:8294  t-loss:0.3830, loss-lb:0.1971, loss-ulb:0.0930, weight:2.00, lr:0.0005
[04:21:52.693] iteration:8295  t-loss:0.7192, loss-lb:0.1363, loss-ulb:0.2915, weight:2.00, lr:0.0005
[04:21:53.022] iteration:8296  t-loss:0.3358, loss-lb:0.2440, loss-ulb:0.0459, weight:2.00, lr:0.0005
[04:21:53.355] iteration:8297  t-loss:0.2967, loss-lb:0.1751, loss-ulb:0.0608, weight:2.00, lr:0.0005
[04:21:53.694] iteration:8298  t-loss:0.5336, loss-lb:0.1294, loss-ulb:0.2021, weight:2.00, lr:0.0005
[04:21:54.034] iteration:8299  t-loss:0.4100, loss-lb:0.2643, loss-ulb:0.0728, weight:2.00, lr:0.0005
[04:21:54.371] iteration:8300  t-loss:1.1131, loss-lb:0.1576, loss-ulb:0.4778, weight:2.00, lr:0.0005
[04:21:56.152] iteration:8301  t-loss:0.4940, loss-lb:0.1592, loss-ulb:0.1674, weight:2.00, lr:0.0005
[04:21:56.493] iteration:8302  t-loss:0.2386, loss-lb:0.1555, loss-ulb:0.0416, weight:2.00, lr:0.0005
[04:21:56.832] iteration:8303  t-loss:0.2822, loss-lb:0.2289, loss-ulb:0.0267, weight:2.00, lr:0.0005
[04:21:57.152] iteration:8304  t-loss:0.2080, loss-lb:0.1490, loss-ulb:0.0295, weight:2.00, lr:0.0005
[04:21:57.471] iteration:8305  t-loss:0.2277, loss-lb:0.1896, loss-ulb:0.0191, weight:2.00, lr:0.0005
[04:21:57.796] iteration:8306  t-loss:0.5152, loss-lb:0.2442, loss-ulb:0.1355, weight:2.00, lr:0.0005
[04:21:58.116] iteration:8307  t-loss:0.3142, loss-lb:0.1841, loss-ulb:0.0650, weight:2.00, lr:0.0005
[04:21:58.436] iteration:8308  t-loss:1.1978, loss-lb:0.2217, loss-ulb:0.4880, weight:2.00, lr:0.0005
[04:21:58.755] iteration:8309  t-loss:0.5252, loss-lb:0.1775, loss-ulb:0.1738, weight:2.00, lr:0.0005
[04:21:59.074] iteration:8310  t-loss:0.3095, loss-lb:0.2176, loss-ulb:0.0460, weight:2.00, lr:0.0005
[04:21:59.393] iteration:8311  t-loss:0.8012, loss-lb:0.2823, loss-ulb:0.2595, weight:2.00, lr:0.0005
[04:21:59.713] iteration:8312  t-loss:0.6336, loss-lb:0.4001, loss-ulb:0.1168, weight:2.00, lr:0.0005
[04:22:00.040] iteration:8313  t-loss:0.3869, loss-lb:0.1964, loss-ulb:0.0953, weight:2.00, lr:0.0005
[04:22:00.376] iteration:8314  t-loss:0.5510, loss-lb:0.2203, loss-ulb:0.1653, weight:2.00, lr:0.0005
[04:22:00.708] iteration:8315  t-loss:0.3778, loss-lb:0.3069, loss-ulb:0.0354, weight:2.00, lr:0.0005
[04:22:01.048] iteration:8316  t-loss:0.3397, loss-lb:0.2393, loss-ulb:0.0502, weight:2.00, lr:0.0005
[04:22:01.378] iteration:8317  t-loss:0.2256, loss-lb:0.1560, loss-ulb:0.0348, weight:2.00, lr:0.0005
[04:22:01.722] iteration:8318  t-loss:0.4787, loss-lb:0.2598, loss-ulb:0.1095, weight:2.00, lr:0.0005
[04:22:02.051] iteration:8319  t-loss:0.3149, loss-lb:0.1880, loss-ulb:0.0635, weight:2.00, lr:0.0005
[04:22:02.383] iteration:8320  t-loss:0.7555, loss-lb:0.5237, loss-ulb:0.1159, weight:2.00, lr:0.0005
[04:22:02.720] iteration:8321  t-loss:0.4734, loss-lb:0.2765, loss-ulb:0.0985, weight:2.00, lr:0.0005
[04:22:03.048] iteration:8322  t-loss:0.6667, loss-lb:0.3448, loss-ulb:0.1610, weight:2.00, lr:0.0005
[04:22:03.381] iteration:8323  t-loss:0.5576, loss-lb:0.3443, loss-ulb:0.1067, weight:2.00, lr:0.0005
[04:22:03.700] iteration:8324  t-loss:0.3553, loss-lb:0.1304, loss-ulb:0.1124, weight:2.00, lr:0.0005
[04:22:04.019] iteration:8325  t-loss:0.3855, loss-lb:0.1343, loss-ulb:0.1256, weight:2.00, lr:0.0005
[04:24:21.728] iteration 8325 : dice_score: 0.848290 best_dice: 0.848300
[04:24:21.728]  <<Test>> - Ep:332  - Dice-S/T:82.65/84.83, Best-S:84.32, Best-T:84.83
[04:24:21.728]           - AvgLoss(lb/ulb/all):0.24/0.13/0.51
[04:24:23.039] iteration:8326  t-loss:0.7975, loss-lb:0.5766, loss-ulb:0.1105, weight:2.00, lr:0.0005
[04:24:23.374] iteration:8327  t-loss:0.2155, loss-lb:0.1722, loss-ulb:0.0216, weight:2.00, lr:0.0005
[04:24:23.717] iteration:8328  t-loss:0.4295, loss-lb:0.1973, loss-ulb:0.1161, weight:2.00, lr:0.0005
[04:24:24.053] iteration:8329  t-loss:0.3024, loss-lb:0.1870, loss-ulb:0.0577, weight:2.00, lr:0.0005
[04:24:24.381] iteration:8330  t-loss:1.0909, loss-lb:0.3510, loss-ulb:0.3700, weight:2.00, lr:0.0005
[04:24:24.704] iteration:8331  t-loss:0.3655, loss-lb:0.2430, loss-ulb:0.0612, weight:2.00, lr:0.0005
[04:24:25.030] iteration:8332  t-loss:0.7471, loss-lb:0.3835, loss-ulb:0.1818, weight:2.00, lr:0.0005
[04:24:25.370] iteration:8333  t-loss:0.7370, loss-lb:0.1635, loss-ulb:0.2868, weight:2.00, lr:0.0005
[04:24:25.688] iteration:8334  t-loss:0.9942, loss-lb:0.2099, loss-ulb:0.3922, weight:2.00, lr:0.0005
[04:24:26.010] iteration:8335  t-loss:0.3472, loss-lb:0.1555, loss-ulb:0.0958, weight:2.00, lr:0.0005
[04:24:26.335] iteration:8336  t-loss:0.6233, loss-lb:0.3118, loss-ulb:0.1558, weight:2.00, lr:0.0005
[04:24:26.655] iteration:8337  t-loss:1.0548, loss-lb:0.1955, loss-ulb:0.4297, weight:2.00, lr:0.0005
[04:24:26.975] iteration:8338  t-loss:0.4552, loss-lb:0.2343, loss-ulb:0.1105, weight:2.00, lr:0.0005
[04:24:27.308] iteration:8339  t-loss:0.3816, loss-lb:0.2396, loss-ulb:0.0710, weight:2.00, lr:0.0005
[04:24:27.625] iteration:8340  t-loss:0.5242, loss-lb:0.1407, loss-ulb:0.1917, weight:2.00, lr:0.0005
[04:24:27.947] iteration:8341  t-loss:0.2611, loss-lb:0.1943, loss-ulb:0.0334, weight:2.00, lr:0.0005
[04:24:28.269] iteration:8342  t-loss:0.6287, loss-lb:0.3239, loss-ulb:0.1524, weight:2.00, lr:0.0005
[04:24:28.595] iteration:8343  t-loss:0.4346, loss-lb:0.3421, loss-ulb:0.0463, weight:2.00, lr:0.0005
[04:24:28.910] iteration:8344  t-loss:0.3545, loss-lb:0.2400, loss-ulb:0.0572, weight:2.00, lr:0.0005
[04:24:29.229] iteration:8345  t-loss:0.5750, loss-lb:0.3380, loss-ulb:0.1185, weight:2.00, lr:0.0005
[04:24:29.542] iteration:8346  t-loss:0.2910, loss-lb:0.2187, loss-ulb:0.0362, weight:2.00, lr:0.0005
[04:24:29.856] iteration:8347  t-loss:0.2894, loss-lb:0.1354, loss-ulb:0.0770, weight:2.00, lr:0.0005
[04:24:30.170] iteration:8348  t-loss:0.2667, loss-lb:0.1500, loss-ulb:0.0584, weight:2.00, lr:0.0005
[04:24:30.488] iteration:8349  t-loss:0.6326, loss-lb:0.3742, loss-ulb:0.1292, weight:2.00, lr:0.0005
[04:24:30.802] iteration:8350  t-loss:0.2478, loss-lb:0.1772, loss-ulb:0.0353, weight:2.00, lr:0.0005
[04:24:32.202] iteration:8351  t-loss:0.6316, loss-lb:0.2987, loss-ulb:0.1664, weight:2.00, lr:0.0005
[04:24:32.533] iteration:8352  t-loss:0.3719, loss-lb:0.1675, loss-ulb:0.1022, weight:2.00, lr:0.0005
[04:24:32.864] iteration:8353  t-loss:0.6061, loss-lb:0.3434, loss-ulb:0.1314, weight:2.00, lr:0.0005
[04:24:33.186] iteration:8354  t-loss:0.3274, loss-lb:0.1577, loss-ulb:0.0849, weight:2.00, lr:0.0005
[04:24:33.502] iteration:8355  t-loss:0.3543, loss-lb:0.3035, loss-ulb:0.0254, weight:2.00, lr:0.0005
[04:24:33.819] iteration:8356  t-loss:0.3712, loss-lb:0.1870, loss-ulb:0.0921, weight:2.00, lr:0.0005
[04:24:34.140] iteration:8357  t-loss:0.5381, loss-lb:0.2561, loss-ulb:0.1410, weight:2.00, lr:0.0005
[04:24:34.459] iteration:8358  t-loss:0.4060, loss-lb:0.1631, loss-ulb:0.1215, weight:2.00, lr:0.0005
[04:24:34.778] iteration:8359  t-loss:0.3553, loss-lb:0.2793, loss-ulb:0.0380, weight:2.00, lr:0.0005
[04:24:35.097] iteration:8360  t-loss:0.2959, loss-lb:0.2058, loss-ulb:0.0451, weight:2.00, lr:0.0005
[04:24:35.421] iteration:8361  t-loss:0.4649, loss-lb:0.3771, loss-ulb:0.0439, weight:2.00, lr:0.0005
[04:24:35.742] iteration:8362  t-loss:0.3608, loss-lb:0.1876, loss-ulb:0.0866, weight:2.00, lr:0.0005
[04:24:36.062] iteration:8363  t-loss:0.4809, loss-lb:0.2304, loss-ulb:0.1253, weight:2.00, lr:0.0005
[04:24:36.386] iteration:8364  t-loss:0.3334, loss-lb:0.1890, loss-ulb:0.0722, weight:2.00, lr:0.0005
[04:24:36.713] iteration:8365  t-loss:0.5752, loss-lb:0.3050, loss-ulb:0.1351, weight:2.00, lr:0.0005
[04:24:37.036] iteration:8366  t-loss:0.2821, loss-lb:0.2502, loss-ulb:0.0160, weight:2.00, lr:0.0005
[04:24:37.356] iteration:8367  t-loss:0.4077, loss-lb:0.3291, loss-ulb:0.0393, weight:2.00, lr:0.0005
[04:24:37.675] iteration:8368  t-loss:0.3911, loss-lb:0.3359, loss-ulb:0.0276, weight:2.00, lr:0.0005
[04:24:37.993] iteration:8369  t-loss:0.3349, loss-lb:0.2388, loss-ulb:0.0481, weight:2.00, lr:0.0005
[04:24:38.309] iteration:8370  t-loss:0.4589, loss-lb:0.1605, loss-ulb:0.1492, weight:2.00, lr:0.0005
[04:24:38.630] iteration:8371  t-loss:0.7293, loss-lb:0.3291, loss-ulb:0.2001, weight:2.00, lr:0.0005
[04:24:38.947] iteration:8372  t-loss:0.3462, loss-lb:0.1653, loss-ulb:0.0904, weight:2.00, lr:0.0005
[04:24:39.262] iteration:8373  t-loss:0.3518, loss-lb:0.2734, loss-ulb:0.0392, weight:2.00, lr:0.0005
[04:24:39.584] iteration:8374  t-loss:0.5371, loss-lb:0.3609, loss-ulb:0.0881, weight:2.00, lr:0.0005
[04:24:39.904] iteration:8375  t-loss:0.4208, loss-lb:0.1628, loss-ulb:0.1290, weight:2.00, lr:0.0005
[04:24:41.138] iteration:8376  t-loss:0.6101, loss-lb:0.1796, loss-ulb:0.2153, weight:2.00, lr:0.0005
[04:24:41.470] iteration:8377  t-loss:0.1827, loss-lb:0.1229, loss-ulb:0.0299, weight:2.00, lr:0.0005
[04:24:41.801] iteration:8378  t-loss:0.5252, loss-lb:0.2843, loss-ulb:0.1205, weight:2.00, lr:0.0005
[04:24:42.126] iteration:8379  t-loss:0.2463, loss-lb:0.1888, loss-ulb:0.0287, weight:2.00, lr:0.0005
[04:24:42.454] iteration:8380  t-loss:0.2559, loss-lb:0.2050, loss-ulb:0.0254, weight:2.00, lr:0.0005
[04:24:42.779] iteration:8381  t-loss:0.3316, loss-lb:0.2736, loss-ulb:0.0290, weight:2.00, lr:0.0005
[04:24:43.105] iteration:8382  t-loss:0.2918, loss-lb:0.2339, loss-ulb:0.0290, weight:2.00, lr:0.0005
[04:24:43.429] iteration:8383  t-loss:0.4662, loss-lb:0.3923, loss-ulb:0.0370, weight:2.00, lr:0.0005
[04:24:43.754] iteration:8384  t-loss:0.4400, loss-lb:0.1786, loss-ulb:0.1307, weight:2.00, lr:0.0005
[04:24:44.078] iteration:8385  t-loss:0.3933, loss-lb:0.1488, loss-ulb:0.1223, weight:2.00, lr:0.0005
[04:24:44.403] iteration:8386  t-loss:0.4308, loss-lb:0.1756, loss-ulb:0.1276, weight:2.00, lr:0.0005
[04:24:44.725] iteration:8387  t-loss:0.2221, loss-lb:0.1686, loss-ulb:0.0268, weight:2.00, lr:0.0005
[04:24:45.044] iteration:8388  t-loss:0.2729, loss-lb:0.1782, loss-ulb:0.0474, weight:2.00, lr:0.0005
[04:24:45.365] iteration:8389  t-loss:0.2126, loss-lb:0.1478, loss-ulb:0.0324, weight:2.00, lr:0.0005
[04:24:45.685] iteration:8390  t-loss:0.2280, loss-lb:0.1610, loss-ulb:0.0335, weight:2.00, lr:0.0005
[04:24:46.008] iteration:8391  t-loss:0.3531, loss-lb:0.2047, loss-ulb:0.0742, weight:2.00, lr:0.0005
[04:24:46.334] iteration:8392  t-loss:0.2447, loss-lb:0.2019, loss-ulb:0.0214, weight:2.00, lr:0.0005
[04:24:46.660] iteration:8393  t-loss:0.3981, loss-lb:0.1785, loss-ulb:0.1098, weight:2.00, lr:0.0005
[04:24:46.980] iteration:8394  t-loss:0.3674, loss-lb:0.1452, loss-ulb:0.1111, weight:2.00, lr:0.0005
[04:24:47.300] iteration:8395  t-loss:0.3231, loss-lb:0.1362, loss-ulb:0.0935, weight:2.00, lr:0.0005
[04:24:47.620] iteration:8396  t-loss:0.2670, loss-lb:0.2157, loss-ulb:0.0256, weight:2.00, lr:0.0005
[04:24:47.940] iteration:8397  t-loss:0.3359, loss-lb:0.1791, loss-ulb:0.0784, weight:2.00, lr:0.0005
[04:24:48.261] iteration:8398  t-loss:0.5820, loss-lb:0.4160, loss-ulb:0.0830, weight:2.00, lr:0.0005
[04:24:48.576] iteration:8399  t-loss:0.2331, loss-lb:0.1820, loss-ulb:0.0256, weight:2.00, lr:0.0005
[04:24:48.897] iteration:8400  t-loss:0.6076, loss-lb:0.3294, loss-ulb:0.1391, weight:2.00, lr:0.0005
[04:24:50.027] iteration:8401  t-loss:0.4781, loss-lb:0.1893, loss-ulb:0.1444, weight:2.00, lr:0.0005
[04:24:50.359] iteration:8402  t-loss:0.4077, loss-lb:0.1789, loss-ulb:0.1144, weight:2.00, lr:0.0005
[04:24:50.686] iteration:8403  t-loss:0.3837, loss-lb:0.2447, loss-ulb:0.0695, weight:2.00, lr:0.0005
[04:24:51.012] iteration:8404  t-loss:0.8204, loss-lb:0.2052, loss-ulb:0.3076, weight:2.00, lr:0.0005
[04:24:51.333] iteration:8405  t-loss:0.5411, loss-lb:0.4067, loss-ulb:0.0672, weight:2.00, lr:0.0005
[04:24:51.657] iteration:8406  t-loss:0.7842, loss-lb:0.4736, loss-ulb:0.1553, weight:2.00, lr:0.0005
[04:24:51.977] iteration:8407  t-loss:0.3180, loss-lb:0.1814, loss-ulb:0.0683, weight:2.00, lr:0.0005
[04:24:52.302] iteration:8408  t-loss:0.4330, loss-lb:0.2682, loss-ulb:0.0824, weight:2.00, lr:0.0005
[04:24:52.624] iteration:8409  t-loss:0.2883, loss-lb:0.2337, loss-ulb:0.0273, weight:2.00, lr:0.0005
[04:24:52.955] iteration:8410  t-loss:0.3872, loss-lb:0.2412, loss-ulb:0.0730, weight:2.00, lr:0.0005
[04:24:53.281] iteration:8411  t-loss:0.2845, loss-lb:0.1732, loss-ulb:0.0557, weight:2.00, lr:0.0005
[04:24:53.604] iteration:8412  t-loss:0.5028, loss-lb:0.1829, loss-ulb:0.1599, weight:2.00, lr:0.0005
[04:24:53.929] iteration:8413  t-loss:0.5309, loss-lb:0.2734, loss-ulb:0.1288, weight:2.00, lr:0.0005
[04:24:54.261] iteration:8414  t-loss:0.4012, loss-lb:0.1953, loss-ulb:0.1030, weight:2.00, lr:0.0005
[04:24:54.585] iteration:8415  t-loss:0.4630, loss-lb:0.2681, loss-ulb:0.0975, weight:2.00, lr:0.0005
[04:24:54.906] iteration:8416  t-loss:0.2173, loss-lb:0.1822, loss-ulb:0.0176, weight:2.00, lr:0.0005
[04:24:55.229] iteration:8417  t-loss:0.4444, loss-lb:0.1904, loss-ulb:0.1270, weight:2.00, lr:0.0005
[04:24:55.552] iteration:8418  t-loss:0.3103, loss-lb:0.1758, loss-ulb:0.0672, weight:2.00, lr:0.0005
[04:24:55.870] iteration:8419  t-loss:0.4026, loss-lb:0.1495, loss-ulb:0.1265, weight:2.00, lr:0.0005
[04:24:56.190] iteration:8420  t-loss:0.4695, loss-lb:0.4150, loss-ulb:0.0272, weight:2.00, lr:0.0005
[04:24:56.509] iteration:8421  t-loss:0.4031, loss-lb:0.1858, loss-ulb:0.1087, weight:2.00, lr:0.0005
[04:24:56.828] iteration:8422  t-loss:0.5107, loss-lb:0.4349, loss-ulb:0.0379, weight:2.00, lr:0.0005
[04:24:57.150] iteration:8423  t-loss:0.3286, loss-lb:0.2031, loss-ulb:0.0628, weight:2.00, lr:0.0005
[04:24:57.468] iteration:8424  t-loss:0.2464, loss-lb:0.1399, loss-ulb:0.0532, weight:2.00, lr:0.0005
[04:24:57.785] iteration:8425  t-loss:0.3462, loss-lb:0.2950, loss-ulb:0.0256, weight:2.00, lr:0.0005
[04:27:13.009] iteration 8425 : dice_score: 0.847209 best_dice: 0.848300
[04:27:13.010]  <<Test>> - Ep:336  - Dice-S/T:84.18/84.72, Best-S:84.32, Best-T:84.83
[04:27:13.010]           - AvgLoss(lb/ulb/all):0.24/0.08/0.40
[04:27:14.266] iteration:8426  t-loss:0.2609, loss-lb:0.1304, loss-ulb:0.0653, weight:2.00, lr:0.0005
[04:27:14.593] iteration:8427  t-loss:0.4198, loss-lb:0.2706, loss-ulb:0.0746, weight:2.00, lr:0.0005
[04:27:14.924] iteration:8428  t-loss:0.4804, loss-lb:0.3055, loss-ulb:0.0875, weight:2.00, lr:0.0005
[04:27:15.247] iteration:8429  t-loss:0.5031, loss-lb:0.1598, loss-ulb:0.1716, weight:2.00, lr:0.0005
[04:27:15.565] iteration:8430  t-loss:0.5862, loss-lb:0.3451, loss-ulb:0.1206, weight:2.00, lr:0.0005
[04:27:15.892] iteration:8431  t-loss:0.3097, loss-lb:0.1468, loss-ulb:0.0815, weight:2.00, lr:0.0005
[04:27:16.220] iteration:8432  t-loss:0.3772, loss-lb:0.1939, loss-ulb:0.0917, weight:2.00, lr:0.0005
[04:27:16.550] iteration:8433  t-loss:0.4705, loss-lb:0.1688, loss-ulb:0.1509, weight:2.00, lr:0.0005
[04:27:16.884] iteration:8434  t-loss:0.2571, loss-lb:0.1670, loss-ulb:0.0450, weight:2.00, lr:0.0005
[04:27:17.231] iteration:8435  t-loss:0.5670, loss-lb:0.3248, loss-ulb:0.1211, weight:2.00, lr:0.0005
[04:27:17.577] iteration:8436  t-loss:0.2665, loss-lb:0.1777, loss-ulb:0.0444, weight:2.00, lr:0.0005
[04:27:17.914] iteration:8437  t-loss:0.4234, loss-lb:0.2904, loss-ulb:0.0665, weight:2.00, lr:0.0005
[04:27:18.244] iteration:8438  t-loss:0.4002, loss-lb:0.2308, loss-ulb:0.0847, weight:2.00, lr:0.0005
[04:27:18.569] iteration:8439  t-loss:0.4874, loss-lb:0.1445, loss-ulb:0.1715, weight:2.00, lr:0.0005
[04:27:18.913] iteration:8440  t-loss:0.3916, loss-lb:0.3013, loss-ulb:0.0452, weight:2.00, lr:0.0005
[04:27:19.246] iteration:8441  t-loss:0.3609, loss-lb:0.2299, loss-ulb:0.0655, weight:2.00, lr:0.0005
[04:27:19.569] iteration:8442  t-loss:0.2025, loss-lb:0.1440, loss-ulb:0.0293, weight:2.00, lr:0.0005
[04:27:19.893] iteration:8443  t-loss:0.2265, loss-lb:0.1722, loss-ulb:0.0271, weight:2.00, lr:0.0005
[04:27:20.213] iteration:8444  t-loss:0.3158, loss-lb:0.1528, loss-ulb:0.0815, weight:2.00, lr:0.0005
[04:27:20.533] iteration:8445  t-loss:0.5309, loss-lb:0.2716, loss-ulb:0.1296, weight:2.00, lr:0.0005
[04:27:20.849] iteration:8446  t-loss:0.2357, loss-lb:0.1290, loss-ulb:0.0534, weight:2.00, lr:0.0005
[04:27:21.168] iteration:8447  t-loss:0.3042, loss-lb:0.2642, loss-ulb:0.0200, weight:2.00, lr:0.0005
[04:27:21.483] iteration:8448  t-loss:0.4662, loss-lb:0.1855, loss-ulb:0.1404, weight:2.00, lr:0.0005
[04:27:21.803] iteration:8449  t-loss:0.2613, loss-lb:0.2136, loss-ulb:0.0238, weight:2.00, lr:0.0005
[04:27:22.122] iteration:8450  t-loss:0.2915, loss-lb:0.1844, loss-ulb:0.0536, weight:2.00, lr:0.0005
[04:27:23.643] iteration:8451  t-loss:0.1944, loss-lb:0.1434, loss-ulb:0.0255, weight:2.00, lr:0.0005
[04:27:23.981] iteration:8452  t-loss:0.2640, loss-lb:0.2260, loss-ulb:0.0190, weight:2.00, lr:0.0005
[04:27:24.314] iteration:8453  t-loss:0.3609, loss-lb:0.2831, loss-ulb:0.0389, weight:2.00, lr:0.0005
[04:27:24.637] iteration:8454  t-loss:0.2715, loss-lb:0.1825, loss-ulb:0.0445, weight:2.00, lr:0.0005
[04:27:24.960] iteration:8455  t-loss:0.3207, loss-lb:0.1955, loss-ulb:0.0626, weight:2.00, lr:0.0005
[04:27:25.275] iteration:8456  t-loss:0.2470, loss-lb:0.1502, loss-ulb:0.0484, weight:2.00, lr:0.0005
[04:27:25.590] iteration:8457  t-loss:0.1813, loss-lb:0.1449, loss-ulb:0.0182, weight:2.00, lr:0.0005
[04:27:25.906] iteration:8458  t-loss:0.3232, loss-lb:0.2183, loss-ulb:0.0524, weight:2.00, lr:0.0005
[04:27:26.221] iteration:8459  t-loss:0.1980, loss-lb:0.1451, loss-ulb:0.0264, weight:2.00, lr:0.0005
[04:27:26.535] iteration:8460  t-loss:0.6682, loss-lb:0.2462, loss-ulb:0.2110, weight:2.00, lr:0.0005
[04:27:26.851] iteration:8461  t-loss:0.4241, loss-lb:0.3850, loss-ulb:0.0195, weight:2.00, lr:0.0005
[04:27:27.171] iteration:8462  t-loss:0.6188, loss-lb:0.3170, loss-ulb:0.1509, weight:2.00, lr:0.0005
[04:27:27.485] iteration:8463  t-loss:0.3012, loss-lb:0.1774, loss-ulb:0.0619, weight:2.00, lr:0.0005
[04:27:27.805] iteration:8464  t-loss:0.2803, loss-lb:0.1614, loss-ulb:0.0595, weight:2.00, lr:0.0005
[04:27:28.125] iteration:8465  t-loss:0.2324, loss-lb:0.1494, loss-ulb:0.0415, weight:2.00, lr:0.0005
[04:27:28.449] iteration:8466  t-loss:0.5143, loss-lb:0.4796, loss-ulb:0.0173, weight:2.00, lr:0.0005
[04:27:28.773] iteration:8467  t-loss:0.3908, loss-lb:0.2126, loss-ulb:0.0891, weight:2.00, lr:0.0005
[04:27:29.091] iteration:8468  t-loss:0.4017, loss-lb:0.3588, loss-ulb:0.0214, weight:2.00, lr:0.0005
[04:27:29.413] iteration:8469  t-loss:0.5595, loss-lb:0.2402, loss-ulb:0.1596, weight:2.00, lr:0.0005
[04:27:29.732] iteration:8470  t-loss:0.2210, loss-lb:0.1408, loss-ulb:0.0401, weight:2.00, lr:0.0005
[04:27:30.052] iteration:8471  t-loss:0.6885, loss-lb:0.3003, loss-ulb:0.1941, weight:2.00, lr:0.0005
[04:27:30.392] iteration:8472  t-loss:0.5215, loss-lb:0.2739, loss-ulb:0.1238, weight:2.00, lr:0.0005
[04:27:30.719] iteration:8473  t-loss:0.4804, loss-lb:0.2961, loss-ulb:0.0921, weight:2.00, lr:0.0005
[04:27:31.038] iteration:8474  t-loss:0.6453, loss-lb:0.1407, loss-ulb:0.2523, weight:2.00, lr:0.0005
[04:27:31.354] iteration:8475  t-loss:0.3352, loss-lb:0.1679, loss-ulb:0.0837, weight:2.00, lr:0.0005
[04:27:32.917] iteration:8476  t-loss:0.3198, loss-lb:0.1480, loss-ulb:0.0859, weight:2.00, lr:0.0005
[04:27:33.253] iteration:8477  t-loss:0.2336, loss-lb:0.1839, loss-ulb:0.0249, weight:2.00, lr:0.0005
[04:27:33.579] iteration:8478  t-loss:0.2245, loss-lb:0.1789, loss-ulb:0.0228, weight:2.00, lr:0.0005
[04:27:33.906] iteration:8479  t-loss:0.3692, loss-lb:0.3144, loss-ulb:0.0274, weight:2.00, lr:0.0005
[04:27:34.230] iteration:8480  t-loss:0.4028, loss-lb:0.3349, loss-ulb:0.0339, weight:2.00, lr:0.0005
[04:27:34.557] iteration:8481  t-loss:0.2489, loss-lb:0.1695, loss-ulb:0.0397, weight:2.00, lr:0.0005
[04:27:34.880] iteration:8482  t-loss:0.3073, loss-lb:0.2487, loss-ulb:0.0293, weight:2.00, lr:0.0005
[04:27:35.202] iteration:8483  t-loss:0.3946, loss-lb:0.1538, loss-ulb:0.1204, weight:2.00, lr:0.0005
[04:27:35.527] iteration:8484  t-loss:0.6351, loss-lb:0.2478, loss-ulb:0.1937, weight:2.00, lr:0.0005
[04:27:35.854] iteration:8485  t-loss:0.5424, loss-lb:0.2576, loss-ulb:0.1424, weight:2.00, lr:0.0005
[04:27:36.174] iteration:8486  t-loss:0.2315, loss-lb:0.1754, loss-ulb:0.0281, weight:2.00, lr:0.0005
[04:27:36.499] iteration:8487  t-loss:0.4038, loss-lb:0.2006, loss-ulb:0.1016, weight:2.00, lr:0.0005
[04:27:36.818] iteration:8488  t-loss:0.3134, loss-lb:0.2493, loss-ulb:0.0320, weight:2.00, lr:0.0005
[04:27:37.146] iteration:8489  t-loss:0.3535, loss-lb:0.2213, loss-ulb:0.0661, weight:2.00, lr:0.0005
[04:27:37.463] iteration:8490  t-loss:0.7198, loss-lb:0.1790, loss-ulb:0.2704, weight:2.00, lr:0.0005
[04:27:37.784] iteration:8491  t-loss:0.3506, loss-lb:0.3001, loss-ulb:0.0252, weight:2.00, lr:0.0005
[04:27:38.110] iteration:8492  t-loss:0.4562, loss-lb:0.2783, loss-ulb:0.0890, weight:2.00, lr:0.0005
[04:27:38.426] iteration:8493  t-loss:0.4002, loss-lb:0.1816, loss-ulb:0.1093, weight:2.00, lr:0.0005
[04:27:38.742] iteration:8494  t-loss:0.3783, loss-lb:0.1493, loss-ulb:0.1145, weight:2.00, lr:0.0005
[04:27:39.058] iteration:8495  t-loss:0.2902, loss-lb:0.2488, loss-ulb:0.0207, weight:2.00, lr:0.0005
[04:27:39.377] iteration:8496  t-loss:0.2818, loss-lb:0.2369, loss-ulb:0.0224, weight:2.00, lr:0.0005
[04:27:39.693] iteration:8497  t-loss:0.3098, loss-lb:0.1370, loss-ulb:0.0864, weight:2.00, lr:0.0005
[04:27:40.012] iteration:8498  t-loss:0.5178, loss-lb:0.2115, loss-ulb:0.1531, weight:2.00, lr:0.0005
[04:27:40.331] iteration:8499  t-loss:0.3031, loss-lb:0.2401, loss-ulb:0.0315, weight:2.00, lr:0.0005
[04:27:40.653] iteration:8500  t-loss:0.6014, loss-lb:0.3747, loss-ulb:0.1133, weight:2.00, lr:0.0005
[04:27:42.017] iteration:8501  t-loss:0.2712, loss-lb:0.2034, loss-ulb:0.0339, weight:2.00, lr:0.0005
[04:27:42.339] iteration:8502  t-loss:0.5941, loss-lb:0.1202, loss-ulb:0.2370, weight:2.00, lr:0.0005
[04:27:42.669] iteration:8503  t-loss:0.3438, loss-lb:0.3102, loss-ulb:0.0168, weight:2.00, lr:0.0005
[04:27:42.993] iteration:8504  t-loss:0.3865, loss-lb:0.2997, loss-ulb:0.0434, weight:2.00, lr:0.0005
[04:27:43.321] iteration:8505  t-loss:0.2331, loss-lb:0.1549, loss-ulb:0.0391, weight:2.00, lr:0.0005
[04:27:43.651] iteration:8506  t-loss:0.1908, loss-lb:0.1574, loss-ulb:0.0167, weight:2.00, lr:0.0005
[04:27:43.984] iteration:8507  t-loss:0.4538, loss-lb:0.2089, loss-ulb:0.1225, weight:2.00, lr:0.0005
[04:27:44.329] iteration:8508  t-loss:0.2164, loss-lb:0.1327, loss-ulb:0.0419, weight:2.00, lr:0.0005
[04:27:44.654] iteration:8509  t-loss:0.2393, loss-lb:0.1980, loss-ulb:0.0206, weight:2.00, lr:0.0005
[04:27:44.998] iteration:8510  t-loss:0.2340, loss-lb:0.1916, loss-ulb:0.0212, weight:2.00, lr:0.0005
[04:27:45.335] iteration:8511  t-loss:0.2681, loss-lb:0.1796, loss-ulb:0.0443, weight:2.00, lr:0.0005
[04:27:45.666] iteration:8512  t-loss:0.4308, loss-lb:0.2010, loss-ulb:0.1149, weight:2.00, lr:0.0005
[04:27:45.995] iteration:8513  t-loss:0.4702, loss-lb:0.2226, loss-ulb:0.1238, weight:2.00, lr:0.0005
[04:27:46.326] iteration:8514  t-loss:0.2102, loss-lb:0.1625, loss-ulb:0.0239, weight:2.00, lr:0.0005
[04:27:46.652] iteration:8515  t-loss:0.2677, loss-lb:0.2178, loss-ulb:0.0250, weight:2.00, lr:0.0005
[04:27:46.977] iteration:8516  t-loss:0.2810, loss-lb:0.1607, loss-ulb:0.0602, weight:2.00, lr:0.0005
[04:27:47.298] iteration:8517  t-loss:0.4318, loss-lb:0.2893, loss-ulb:0.0712, weight:2.00, lr:0.0005
[04:27:47.625] iteration:8518  t-loss:0.3742, loss-lb:0.2093, loss-ulb:0.0824, weight:2.00, lr:0.0005
[04:27:47.944] iteration:8519  t-loss:0.3051, loss-lb:0.1478, loss-ulb:0.0786, weight:2.00, lr:0.0005
[04:27:48.264] iteration:8520  t-loss:0.3176, loss-lb:0.2290, loss-ulb:0.0443, weight:2.00, lr:0.0005
[04:27:48.584] iteration:8521  t-loss:0.4282, loss-lb:0.2051, loss-ulb:0.1115, weight:2.00, lr:0.0005
[04:27:48.901] iteration:8522  t-loss:0.4766, loss-lb:0.2152, loss-ulb:0.1307, weight:2.00, lr:0.0005
[04:27:49.218] iteration:8523  t-loss:0.3685, loss-lb:0.1729, loss-ulb:0.0978, weight:2.00, lr:0.0005
[04:27:49.535] iteration:8524  t-loss:0.4906, loss-lb:0.2124, loss-ulb:0.1391, weight:2.00, lr:0.0005
[04:27:49.854] iteration:8525  t-loss:0.2642, loss-lb:0.2249, loss-ulb:0.0196, weight:2.00, lr:0.0005
[04:30:07.128] iteration 8525 : dice_score: 0.846540 best_dice: 0.848300
[04:30:07.129]  <<Test>> - Ep:340  - Dice-S/T:84.31/84.65, Best-S:84.32, Best-T:84.83
[04:30:07.129]           - AvgLoss(lb/ulb/all):0.20/0.07/0.34
[04:30:08.609] iteration:8526  t-loss:0.4303, loss-lb:0.3033, loss-ulb:0.0635, weight:2.00, lr:0.0005
[04:30:08.942] iteration:8527  t-loss:0.2330, loss-lb:0.1901, loss-ulb:0.0215, weight:2.00, lr:0.0005
[04:30:09.273] iteration:8528  t-loss:0.2523, loss-lb:0.1850, loss-ulb:0.0336, weight:2.00, lr:0.0005
[04:30:09.597] iteration:8529  t-loss:0.3832, loss-lb:0.1438, loss-ulb:0.1197, weight:2.00, lr:0.0005
[04:30:09.919] iteration:8530  t-loss:0.3126, loss-lb:0.1749, loss-ulb:0.0689, weight:2.00, lr:0.0005
[04:30:10.240] iteration:8531  t-loss:0.2658, loss-lb:0.2313, loss-ulb:0.0173, weight:2.00, lr:0.0005
[04:30:10.562] iteration:8532  t-loss:0.2359, loss-lb:0.2012, loss-ulb:0.0174, weight:2.00, lr:0.0005
[04:30:10.878] iteration:8533  t-loss:0.2046, loss-lb:0.1387, loss-ulb:0.0330, weight:2.00, lr:0.0005
[04:30:11.198] iteration:8534  t-loss:0.3470, loss-lb:0.1638, loss-ulb:0.0916, weight:2.00, lr:0.0005
[04:30:11.518] iteration:8535  t-loss:0.2758, loss-lb:0.2200, loss-ulb:0.0279, weight:2.00, lr:0.0005
[04:30:11.834] iteration:8536  t-loss:0.2250, loss-lb:0.1771, loss-ulb:0.0240, weight:2.00, lr:0.0005
[04:30:12.158] iteration:8537  t-loss:0.2288, loss-lb:0.1630, loss-ulb:0.0329, weight:2.00, lr:0.0005
[04:30:12.480] iteration:8538  t-loss:0.2155, loss-lb:0.1677, loss-ulb:0.0239, weight:2.00, lr:0.0005
[04:30:12.800] iteration:8539  t-loss:0.4337, loss-lb:0.2866, loss-ulb:0.0736, weight:2.00, lr:0.0005
[04:30:13.121] iteration:8540  t-loss:1.1211, loss-lb:0.6620, loss-ulb:0.2296, weight:2.00, lr:0.0005
[04:30:13.441] iteration:8541  t-loss:0.3105, loss-lb:0.1788, loss-ulb:0.0659, weight:2.00, lr:0.0005
[04:30:13.763] iteration:8542  t-loss:0.4339, loss-lb:0.1906, loss-ulb:0.1216, weight:2.00, lr:0.0005
[04:30:14.079] iteration:8543  t-loss:0.3083, loss-lb:0.1300, loss-ulb:0.0891, weight:2.00, lr:0.0005
[04:30:14.396] iteration:8544  t-loss:0.3385, loss-lb:0.3092, loss-ulb:0.0147, weight:2.00, lr:0.0005
[04:30:14.711] iteration:8545  t-loss:0.4605, loss-lb:0.1835, loss-ulb:0.1385, weight:2.00, lr:0.0005
[04:30:15.026] iteration:8546  t-loss:0.4206, loss-lb:0.1720, loss-ulb:0.1243, weight:2.00, lr:0.0005
[04:30:15.343] iteration:8547  t-loss:0.4378, loss-lb:0.1661, loss-ulb:0.1359, weight:2.00, lr:0.0005
[04:30:15.662] iteration:8548  t-loss:0.3903, loss-lb:0.2100, loss-ulb:0.0901, weight:2.00, lr:0.0005
[04:30:15.981] iteration:8549  t-loss:0.3869, loss-lb:0.2290, loss-ulb:0.0790, weight:2.00, lr:0.0005
[04:30:16.298] iteration:8550  t-loss:0.3023, loss-lb:0.2434, loss-ulb:0.0294, weight:2.00, lr:0.0005
[04:30:17.756] iteration:8551  t-loss:0.2070, loss-lb:0.1673, loss-ulb:0.0199, weight:2.00, lr:0.0005
[04:30:18.101] iteration:8552  t-loss:0.2931, loss-lb:0.2240, loss-ulb:0.0345, weight:2.00, lr:0.0005
[04:30:18.435] iteration:8553  t-loss:0.2863, loss-lb:0.1239, loss-ulb:0.0812, weight:2.00, lr:0.0005
[04:30:18.761] iteration:8554  t-loss:0.7217, loss-lb:0.3004, loss-ulb:0.2106, weight:2.00, lr:0.0005
[04:30:19.080] iteration:8555  t-loss:0.1794, loss-lb:0.1443, loss-ulb:0.0176, weight:2.00, lr:0.0005
[04:30:19.405] iteration:8556  t-loss:0.4787, loss-lb:0.2624, loss-ulb:0.1081, weight:2.00, lr:0.0005
[04:30:19.722] iteration:8557  t-loss:0.5810, loss-lb:0.1726, loss-ulb:0.2042, weight:2.00, lr:0.0005
[04:30:20.044] iteration:8558  t-loss:0.3488, loss-lb:0.2235, loss-ulb:0.0627, weight:2.00, lr:0.0005
[04:30:20.363] iteration:8559  t-loss:0.4948, loss-lb:0.1773, loss-ulb:0.1588, weight:2.00, lr:0.0005
[04:30:20.682] iteration:8560  t-loss:0.2294, loss-lb:0.1438, loss-ulb:0.0428, weight:2.00, lr:0.0005
[04:30:21.009] iteration:8561  t-loss:0.5438, loss-lb:0.3663, loss-ulb:0.0887, weight:2.00, lr:0.0005
[04:30:21.332] iteration:8562  t-loss:0.2467, loss-lb:0.1358, loss-ulb:0.0555, weight:2.00, lr:0.0005
[04:30:21.659] iteration:8563  t-loss:0.4092, loss-lb:0.2331, loss-ulb:0.0881, weight:2.00, lr:0.0005
[04:30:21.979] iteration:8564  t-loss:0.1863, loss-lb:0.1526, loss-ulb:0.0169, weight:2.00, lr:0.0005
[04:30:22.302] iteration:8565  t-loss:0.2533, loss-lb:0.2112, loss-ulb:0.0210, weight:2.00, lr:0.0005
[04:30:22.621] iteration:8566  t-loss:0.2835, loss-lb:0.1996, loss-ulb:0.0419, weight:2.00, lr:0.0005
[04:30:22.941] iteration:8567  t-loss:0.2243, loss-lb:0.1614, loss-ulb:0.0314, weight:2.00, lr:0.0005
[04:30:23.264] iteration:8568  t-loss:0.3913, loss-lb:0.2454, loss-ulb:0.0730, weight:2.00, lr:0.0005
[04:30:23.582] iteration:8569  t-loss:0.2967, loss-lb:0.2503, loss-ulb:0.0232, weight:2.00, lr:0.0005
[04:30:23.897] iteration:8570  t-loss:0.4365, loss-lb:0.1278, loss-ulb:0.1544, weight:2.00, lr:0.0005
[04:30:24.216] iteration:8571  t-loss:0.4018, loss-lb:0.1687, loss-ulb:0.1166, weight:2.00, lr:0.0005
[04:30:24.533] iteration:8572  t-loss:0.3449, loss-lb:0.3019, loss-ulb:0.0215, weight:2.00, lr:0.0005
[04:30:24.855] iteration:8573  t-loss:0.4244, loss-lb:0.3139, loss-ulb:0.0552, weight:2.00, lr:0.0005
[04:30:25.174] iteration:8574  t-loss:0.3032, loss-lb:0.1511, loss-ulb:0.0761, weight:2.00, lr:0.0005
[04:30:25.490] iteration:8575  t-loss:0.3909, loss-lb:0.2729, loss-ulb:0.0590, weight:2.00, lr:0.0005
[04:30:26.879] iteration:8576  t-loss:0.1935, loss-lb:0.1445, loss-ulb:0.0245, weight:2.00, lr:0.0005
[04:30:27.210] iteration:8577  t-loss:0.3613, loss-lb:0.1504, loss-ulb:0.1054, weight:2.00, lr:0.0005
[04:30:27.541] iteration:8578  t-loss:0.4850, loss-lb:0.3607, loss-ulb:0.0621, weight:2.00, lr:0.0005
[04:30:27.863] iteration:8579  t-loss:0.2184, loss-lb:0.1705, loss-ulb:0.0240, weight:2.00, lr:0.0005
[04:30:28.184] iteration:8580  t-loss:0.2831, loss-lb:0.2276, loss-ulb:0.0278, weight:2.00, lr:0.0005
[04:30:28.506] iteration:8581  t-loss:0.5122, loss-lb:0.2624, loss-ulb:0.1249, weight:2.00, lr:0.0005
[04:30:28.831] iteration:8582  t-loss:0.5584, loss-lb:0.1906, loss-ulb:0.1839, weight:2.00, lr:0.0005
[04:30:29.152] iteration:8583  t-loss:0.1859, loss-lb:0.1465, loss-ulb:0.0197, weight:2.00, lr:0.0005
[04:30:29.476] iteration:8584  t-loss:0.3335, loss-lb:0.1622, loss-ulb:0.0856, weight:2.00, lr:0.0005
[04:30:29.795] iteration:8585  t-loss:0.6470, loss-lb:0.1826, loss-ulb:0.2322, weight:2.00, lr:0.0005
[04:30:30.114] iteration:8586  t-loss:0.2591, loss-lb:0.2033, loss-ulb:0.0279, weight:2.00, lr:0.0005
[04:30:30.437] iteration:8587  t-loss:0.2742, loss-lb:0.1583, loss-ulb:0.0579, weight:2.00, lr:0.0005
[04:30:30.763] iteration:8588  t-loss:0.3943, loss-lb:0.2816, loss-ulb:0.0563, weight:2.00, lr:0.0005
[04:30:31.086] iteration:8589  t-loss:0.3027, loss-lb:0.2752, loss-ulb:0.0138, weight:2.00, lr:0.0005
[04:30:31.411] iteration:8590  t-loss:0.4998, loss-lb:0.2357, loss-ulb:0.1320, weight:2.00, lr:0.0005
[04:30:31.735] iteration:8591  t-loss:0.3480, loss-lb:0.1498, loss-ulb:0.0991, weight:2.00, lr:0.0005
[04:30:32.058] iteration:8592  t-loss:0.3581, loss-lb:0.1562, loss-ulb:0.1010, weight:2.00, lr:0.0005
[04:30:32.379] iteration:8593  t-loss:0.5799, loss-lb:0.2559, loss-ulb:0.1620, weight:2.00, lr:0.0005
[04:30:32.700] iteration:8594  t-loss:0.3019, loss-lb:0.1947, loss-ulb:0.0536, weight:2.00, lr:0.0005
[04:30:33.024] iteration:8595  t-loss:0.2380, loss-lb:0.1223, loss-ulb:0.0579, weight:2.00, lr:0.0005
[04:30:33.341] iteration:8596  t-loss:0.2919, loss-lb:0.1985, loss-ulb:0.0467, weight:2.00, lr:0.0005
[04:30:33.661] iteration:8597  t-loss:0.3589, loss-lb:0.2017, loss-ulb:0.0786, weight:2.00, lr:0.0005
[04:30:33.979] iteration:8598  t-loss:0.2738, loss-lb:0.2396, loss-ulb:0.0171, weight:2.00, lr:0.0005
[04:30:34.297] iteration:8599  t-loss:0.1861, loss-lb:0.1379, loss-ulb:0.0241, weight:2.00, lr:0.0005
[04:30:34.614] iteration:8600  t-loss:0.3274, loss-lb:0.1479, loss-ulb:0.0897, weight:2.00, lr:0.0005
[04:30:36.199] iteration:8601  t-loss:0.2705, loss-lb:0.1834, loss-ulb:0.0435, weight:2.00, lr:0.0005
[04:30:36.547] iteration:8602  t-loss:0.5092, loss-lb:0.2728, loss-ulb:0.1182, weight:2.00, lr:0.0005
[04:30:36.881] iteration:8603  t-loss:0.5357, loss-lb:0.1932, loss-ulb:0.1713, weight:2.00, lr:0.0005
[04:30:37.209] iteration:8604  t-loss:0.3724, loss-lb:0.1242, loss-ulb:0.1241, weight:2.00, lr:0.0005
[04:30:37.529] iteration:8605  t-loss:0.3632, loss-lb:0.1365, loss-ulb:0.1134, weight:2.00, lr:0.0005
[04:30:37.858] iteration:8606  t-loss:0.6066, loss-lb:0.3003, loss-ulb:0.1532, weight:2.00, lr:0.0005
[04:30:38.185] iteration:8607  t-loss:0.2723, loss-lb:0.1290, loss-ulb:0.0716, weight:2.00, lr:0.0005
[04:30:38.517] iteration:8608  t-loss:0.4648, loss-lb:0.2122, loss-ulb:0.1263, weight:2.00, lr:0.0005
[04:30:38.839] iteration:8609  t-loss:0.3422, loss-lb:0.2364, loss-ulb:0.0529, weight:2.00, lr:0.0005
[04:30:39.160] iteration:8610  t-loss:0.2910, loss-lb:0.1371, loss-ulb:0.0769, weight:2.00, lr:0.0005
[04:30:39.489] iteration:8611  t-loss:0.5021, loss-lb:0.3337, loss-ulb:0.0842, weight:2.00, lr:0.0005
[04:30:39.812] iteration:8612  t-loss:0.3072, loss-lb:0.2361, loss-ulb:0.0355, weight:2.00, lr:0.0005
[04:30:40.131] iteration:8613  t-loss:0.8539, loss-lb:0.2991, loss-ulb:0.2774, weight:2.00, lr:0.0005
[04:30:40.458] iteration:8614  t-loss:0.5159, loss-lb:0.2629, loss-ulb:0.1265, weight:2.00, lr:0.0005
[04:30:40.780] iteration:8615  t-loss:0.3141, loss-lb:0.1859, loss-ulb:0.0641, weight:2.00, lr:0.0005
[04:30:41.104] iteration:8616  t-loss:0.2187, loss-lb:0.1804, loss-ulb:0.0192, weight:2.00, lr:0.0005
[04:30:41.426] iteration:8617  t-loss:0.1874, loss-lb:0.1575, loss-ulb:0.0150, weight:2.00, lr:0.0005
[04:30:41.744] iteration:8618  t-loss:0.3624, loss-lb:0.1565, loss-ulb:0.1030, weight:2.00, lr:0.0005
[04:30:42.061] iteration:8619  t-loss:0.2055, loss-lb:0.1586, loss-ulb:0.0234, weight:2.00, lr:0.0005
[04:30:42.381] iteration:8620  t-loss:0.4465, loss-lb:0.2508, loss-ulb:0.0978, weight:2.00, lr:0.0005
[04:30:42.700] iteration:8621  t-loss:0.3294, loss-lb:0.1667, loss-ulb:0.0814, weight:2.00, lr:0.0005
[04:30:43.015] iteration:8622  t-loss:0.3331, loss-lb:0.2147, loss-ulb:0.0592, weight:2.00, lr:0.0005
[04:30:43.333] iteration:8623  t-loss:0.4045, loss-lb:0.2128, loss-ulb:0.0959, weight:2.00, lr:0.0005
[04:30:43.652] iteration:8624  t-loss:0.3134, loss-lb:0.1481, loss-ulb:0.0827, weight:2.00, lr:0.0005
[04:30:43.958] iteration:8625  t-loss:0.4581, loss-lb:0.1546, loss-ulb:0.1518, weight:2.00, lr:0.0005
[04:32:57.322] iteration 8625 : dice_score: 0.846519 best_dice: 0.848300
[04:32:57.323]  <<Test>> - Ep:344  - Dice-S/T:84.41/84.65, Best-S:84.41, Best-T:84.83
[04:32:57.323]           - AvgLoss(lb/ulb/all):0.20/0.09/0.39
[04:32:58.612] iteration:8626  t-loss:0.2700, loss-lb:0.2300, loss-ulb:0.0200, weight:2.00, lr:0.0005
[04:32:58.944] iteration:8627  t-loss:0.2971, loss-lb:0.2486, loss-ulb:0.0243, weight:2.00, lr:0.0005
[04:32:59.283] iteration:8628  t-loss:0.3278, loss-lb:0.2715, loss-ulb:0.0282, weight:2.00, lr:0.0005
[04:32:59.613] iteration:8629  t-loss:0.2903, loss-lb:0.2561, loss-ulb:0.0171, weight:2.00, lr:0.0005
[04:32:59.941] iteration:8630  t-loss:0.2505, loss-lb:0.2176, loss-ulb:0.0164, weight:2.00, lr:0.0005
[04:33:00.274] iteration:8631  t-loss:0.3469, loss-lb:0.2163, loss-ulb:0.0653, weight:2.00, lr:0.0005
[04:33:00.594] iteration:8632  t-loss:0.5357, loss-lb:0.1625, loss-ulb:0.1866, weight:2.00, lr:0.0005
[04:33:00.917] iteration:8633  t-loss:0.5153, loss-lb:0.2195, loss-ulb:0.1479, weight:2.00, lr:0.0005
[04:33:01.240] iteration:8634  t-loss:0.3447, loss-lb:0.2487, loss-ulb:0.0480, weight:2.00, lr:0.0005
[04:33:01.571] iteration:8635  t-loss:1.0022, loss-lb:0.3243, loss-ulb:0.3389, weight:2.00, lr:0.0005
[04:33:01.890] iteration:8636  t-loss:0.2927, loss-lb:0.2487, loss-ulb:0.0220, weight:2.00, lr:0.0005
[04:33:02.222] iteration:8637  t-loss:0.4600, loss-lb:0.2552, loss-ulb:0.1024, weight:2.00, lr:0.0005
[04:33:02.547] iteration:8638  t-loss:0.7756, loss-lb:0.2808, loss-ulb:0.2474, weight:2.00, lr:0.0005
[04:33:02.867] iteration:8639  t-loss:0.3028, loss-lb:0.2676, loss-ulb:0.0176, weight:2.00, lr:0.0005
[04:33:03.187] iteration:8640  t-loss:0.2314, loss-lb:0.1884, loss-ulb:0.0215, weight:2.00, lr:0.0005
[04:33:03.503] iteration:8641  t-loss:0.2119, loss-lb:0.1737, loss-ulb:0.0191, weight:2.00, lr:0.0005
[04:33:03.823] iteration:8642  t-loss:0.3398, loss-lb:0.2350, loss-ulb:0.0524, weight:2.00, lr:0.0005
[04:33:04.139] iteration:8643  t-loss:0.3668, loss-lb:0.1870, loss-ulb:0.0899, weight:2.00, lr:0.0005
[04:33:04.460] iteration:8644  t-loss:0.4164, loss-lb:0.2860, loss-ulb:0.0652, weight:2.00, lr:0.0005
[04:33:04.775] iteration:8645  t-loss:0.3749, loss-lb:0.2861, loss-ulb:0.0444, weight:2.00, lr:0.0005
[04:33:05.090] iteration:8646  t-loss:0.3320, loss-lb:0.2789, loss-ulb:0.0266, weight:2.00, lr:0.0005
[04:33:05.406] iteration:8647  t-loss:0.2584, loss-lb:0.1572, loss-ulb:0.0506, weight:2.00, lr:0.0005
[04:33:05.722] iteration:8648  t-loss:0.5002, loss-lb:0.1930, loss-ulb:0.1536, weight:2.00, lr:0.0005
[04:33:06.034] iteration:8649  t-loss:0.2570, loss-lb:0.1781, loss-ulb:0.0394, weight:2.00, lr:0.0005
[04:33:06.352] iteration:8650  t-loss:0.4077, loss-lb:0.2254, loss-ulb:0.0912, weight:2.00, lr:0.0005
[04:33:07.639] iteration:8651  t-loss:0.2185, loss-lb:0.1720, loss-ulb:0.0232, weight:2.00, lr:0.0005
[04:33:07.985] iteration:8652  t-loss:0.2510, loss-lb:0.2063, loss-ulb:0.0224, weight:2.00, lr:0.0005
[04:33:08.332] iteration:8653  t-loss:0.2650, loss-lb:0.2281, loss-ulb:0.0185, weight:2.00, lr:0.0005
[04:33:08.689] iteration:8654  t-loss:0.2921, loss-lb:0.1633, loss-ulb:0.0644, weight:2.00, lr:0.0005
[04:33:09.020] iteration:8655  t-loss:0.2264, loss-lb:0.1274, loss-ulb:0.0495, weight:2.00, lr:0.0005
[04:33:09.345] iteration:8656  t-loss:0.2035, loss-lb:0.1709, loss-ulb:0.0163, weight:2.00, lr:0.0005
[04:33:09.686] iteration:8657  t-loss:0.3223, loss-lb:0.1366, loss-ulb:0.0929, weight:2.00, lr:0.0005
[04:33:10.023] iteration:8658  t-loss:0.3525, loss-lb:0.2657, loss-ulb:0.0434, weight:2.00, lr:0.0005
[04:33:10.354] iteration:8659  t-loss:0.4150, loss-lb:0.2603, loss-ulb:0.0774, weight:2.00, lr:0.0005
[04:33:10.675] iteration:8660  t-loss:0.4384, loss-lb:0.1281, loss-ulb:0.1551, weight:2.00, lr:0.0005
[04:33:10.997] iteration:8661  t-loss:0.4230, loss-lb:0.1962, loss-ulb:0.1134, weight:2.00, lr:0.0005
[04:33:11.327] iteration:8662  t-loss:0.4249, loss-lb:0.1214, loss-ulb:0.1517, weight:2.00, lr:0.0005
[04:33:11.652] iteration:8663  t-loss:0.4681, loss-lb:0.2371, loss-ulb:0.1155, weight:2.00, lr:0.0005
[04:33:11.978] iteration:8664  t-loss:0.4165, loss-lb:0.2491, loss-ulb:0.0837, weight:2.00, lr:0.0005
[04:33:12.304] iteration:8665  t-loss:0.3925, loss-lb:0.2941, loss-ulb:0.0492, weight:2.00, lr:0.0005
[04:33:12.635] iteration:8666  t-loss:0.4444, loss-lb:0.2187, loss-ulb:0.1129, weight:2.00, lr:0.0005
[04:33:12.960] iteration:8667  t-loss:0.5022, loss-lb:0.1799, loss-ulb:0.1611, weight:2.00, lr:0.0005
[04:33:13.287] iteration:8668  t-loss:0.2928, loss-lb:0.2221, loss-ulb:0.0354, weight:2.00, lr:0.0005
[04:33:13.630] iteration:8669  t-loss:0.3206, loss-lb:0.1788, loss-ulb:0.0709, weight:2.00, lr:0.0005
[04:33:13.963] iteration:8670  t-loss:0.3896, loss-lb:0.2067, loss-ulb:0.0914, weight:2.00, lr:0.0005
[04:33:14.300] iteration:8671  t-loss:0.3912, loss-lb:0.2155, loss-ulb:0.0879, weight:2.00, lr:0.0005
[04:33:14.634] iteration:8672  t-loss:0.3077, loss-lb:0.1896, loss-ulb:0.0591, weight:2.00, lr:0.0005
[04:33:14.961] iteration:8673  t-loss:0.2265, loss-lb:0.1857, loss-ulb:0.0204, weight:2.00, lr:0.0005
[04:33:15.288] iteration:8674  t-loss:0.5093, loss-lb:0.2013, loss-ulb:0.1540, weight:2.00, lr:0.0005
[04:33:15.618] iteration:8675  t-loss:0.2879, loss-lb:0.2111, loss-ulb:0.0384, weight:2.00, lr:0.0005
[04:33:17.436] iteration:8676  t-loss:0.2922, loss-lb:0.2556, loss-ulb:0.0183, weight:2.00, lr:0.0005
[04:33:17.794] iteration:8677  t-loss:0.3876, loss-lb:0.1675, loss-ulb:0.1100, weight:2.00, lr:0.0005
[04:33:18.125] iteration:8678  t-loss:0.2373, loss-lb:0.1998, loss-ulb:0.0188, weight:2.00, lr:0.0005
[04:33:18.463] iteration:8679  t-loss:0.3817, loss-lb:0.2211, loss-ulb:0.0803, weight:2.00, lr:0.0005
[04:33:18.793] iteration:8680  t-loss:0.2553, loss-lb:0.1483, loss-ulb:0.0535, weight:2.00, lr:0.0005
[04:33:19.116] iteration:8681  t-loss:0.3815, loss-lb:0.2666, loss-ulb:0.0574, weight:2.00, lr:0.0005
[04:33:19.430] iteration:8682  t-loss:0.2028, loss-lb:0.1538, loss-ulb:0.0245, weight:2.00, lr:0.0005
[04:33:19.743] iteration:8683  t-loss:0.3196, loss-lb:0.1694, loss-ulb:0.0751, weight:2.00, lr:0.0005
[04:33:20.061] iteration:8684  t-loss:0.6052, loss-lb:0.3067, loss-ulb:0.1492, weight:2.00, lr:0.0005
[04:33:20.379] iteration:8685  t-loss:0.3726, loss-lb:0.1730, loss-ulb:0.0998, weight:2.00, lr:0.0005
[04:33:20.694] iteration:8686  t-loss:0.2614, loss-lb:0.1695, loss-ulb:0.0460, weight:2.00, lr:0.0005
[04:33:21.012] iteration:8687  t-loss:0.3010, loss-lb:0.2392, loss-ulb:0.0309, weight:2.00, lr:0.0005
[04:33:21.330] iteration:8688  t-loss:0.2617, loss-lb:0.1520, loss-ulb:0.0548, weight:2.00, lr:0.0005
[04:33:21.646] iteration:8689  t-loss:0.2500, loss-lb:0.2031, loss-ulb:0.0234, weight:2.00, lr:0.0005
[04:33:21.966] iteration:8690  t-loss:0.1624, loss-lb:0.1282, loss-ulb:0.0171, weight:2.00, lr:0.0005
[04:33:22.293] iteration:8691  t-loss:0.3190, loss-lb:0.1697, loss-ulb:0.0746, weight:2.00, lr:0.0005
[04:33:22.621] iteration:8692  t-loss:0.4023, loss-lb:0.2285, loss-ulb:0.0869, weight:2.00, lr:0.0005
[04:33:22.968] iteration:8693  t-loss:0.3670, loss-lb:0.2001, loss-ulb:0.0835, weight:2.00, lr:0.0005
[04:33:23.317] iteration:8694  t-loss:0.6291, loss-lb:0.1821, loss-ulb:0.2235, weight:2.00, lr:0.0005
[04:33:23.660] iteration:8695  t-loss:0.5233, loss-lb:0.2487, loss-ulb:0.1373, weight:2.00, lr:0.0005
[04:33:24.000] iteration:8696  t-loss:0.2889, loss-lb:0.2531, loss-ulb:0.0179, weight:2.00, lr:0.0005
[04:33:24.343] iteration:8697  t-loss:0.4663, loss-lb:0.1947, loss-ulb:0.1358, weight:2.00, lr:0.0005
[04:33:24.690] iteration:8698  t-loss:0.4220, loss-lb:0.2697, loss-ulb:0.0761, weight:2.00, lr:0.0005
[04:33:25.026] iteration:8699  t-loss:0.4899, loss-lb:0.2262, loss-ulb:0.1318, weight:2.00, lr:0.0005
[04:33:25.366] iteration:8700  t-loss:0.4937, loss-lb:0.2329, loss-ulb:0.1304, weight:2.00, lr:0.0005
[04:33:27.277] iteration:8701  t-loss:0.2167, loss-lb:0.1393, loss-ulb:0.0387, weight:2.00, lr:0.0005
[04:33:27.634] iteration:8702  t-loss:0.3647, loss-lb:0.1686, loss-ulb:0.0980, weight:2.00, lr:0.0005
[04:33:27.979] iteration:8703  t-loss:0.2667, loss-lb:0.1692, loss-ulb:0.0487, weight:2.00, lr:0.0005
[04:33:28.323] iteration:8704  t-loss:0.2365, loss-lb:0.1240, loss-ulb:0.0562, weight:2.00, lr:0.0005
[04:33:28.675] iteration:8705  t-loss:0.3273, loss-lb:0.2444, loss-ulb:0.0415, weight:2.00, lr:0.0005
[04:33:29.001] iteration:8706  t-loss:0.2638, loss-lb:0.2137, loss-ulb:0.0251, weight:2.00, lr:0.0005
[04:33:29.335] iteration:8707  t-loss:0.3051, loss-lb:0.2013, loss-ulb:0.0519, weight:2.00, lr:0.0005
[04:33:29.660] iteration:8708  t-loss:0.4934, loss-lb:0.3274, loss-ulb:0.0830, weight:2.00, lr:0.0005
[04:33:29.979] iteration:8709  t-loss:0.2382, loss-lb:0.1759, loss-ulb:0.0312, weight:2.00, lr:0.0005
[04:33:30.302] iteration:8710  t-loss:0.2204, loss-lb:0.1309, loss-ulb:0.0448, weight:2.00, lr:0.0005
[04:33:30.620] iteration:8711  t-loss:0.2722, loss-lb:0.2369, loss-ulb:0.0177, weight:2.00, lr:0.0005
[04:33:30.936] iteration:8712  t-loss:0.2435, loss-lb:0.2016, loss-ulb:0.0210, weight:2.00, lr:0.0005
[04:33:31.253] iteration:8713  t-loss:0.3286, loss-lb:0.1426, loss-ulb:0.0930, weight:2.00, lr:0.0005
[04:33:31.571] iteration:8714  t-loss:0.4561, loss-lb:0.2297, loss-ulb:0.1132, weight:2.00, lr:0.0005
[04:33:31.887] iteration:8715  t-loss:0.3844, loss-lb:0.1944, loss-ulb:0.0950, weight:2.00, lr:0.0005
[04:33:32.203] iteration:8716  t-loss:0.2686, loss-lb:0.2199, loss-ulb:0.0243, weight:2.00, lr:0.0005
[04:33:32.523] iteration:8717  t-loss:0.3182, loss-lb:0.1360, loss-ulb:0.0911, weight:2.00, lr:0.0005
[04:33:32.844] iteration:8718  t-loss:0.3024, loss-lb:0.1729, loss-ulb:0.0648, weight:2.00, lr:0.0005
[04:33:33.158] iteration:8719  t-loss:0.2438, loss-lb:0.1555, loss-ulb:0.0442, weight:2.00, lr:0.0005
[04:33:33.474] iteration:8720  t-loss:0.3376, loss-lb:0.3009, loss-ulb:0.0184, weight:2.00, lr:0.0005
[04:33:33.792] iteration:8721  t-loss:0.3925, loss-lb:0.2198, loss-ulb:0.0864, weight:2.00, lr:0.0005
[04:33:34.108] iteration:8722  t-loss:0.5693, loss-lb:0.5071, loss-ulb:0.0311, weight:2.00, lr:0.0005
[04:33:34.427] iteration:8723  t-loss:0.3885, loss-lb:0.2214, loss-ulb:0.0836, weight:2.00, lr:0.0005
[04:33:34.743] iteration:8724  t-loss:0.3390, loss-lb:0.1632, loss-ulb:0.0879, weight:2.00, lr:0.0005
[04:33:35.059] iteration:8725  t-loss:0.5357, loss-lb:0.2195, loss-ulb:0.1581, weight:2.00, lr:0.0005
[04:35:51.614] iteration 8725 : dice_score: 0.847773 best_dice: 0.848300
[04:35:51.615]  <<Test>> - Ep:348  - Dice-S/T:84.60/84.78, Best-S:84.60, Best-T:84.83
[04:35:51.615]           - AvgLoss(lb/ulb/all):0.21/0.06/0.35
[04:35:53.124] iteration:8726  t-loss:0.3530, loss-lb:0.2356, loss-ulb:0.0587, weight:2.00, lr:0.0005
[04:35:53.473] iteration:8727  t-loss:0.3812, loss-lb:0.2407, loss-ulb:0.0703, weight:2.00, lr:0.0005
[04:35:53.809] iteration:8728  t-loss:0.3582, loss-lb:0.1183, loss-ulb:0.1199, weight:2.00, lr:0.0005
[04:35:54.139] iteration:8729  t-loss:0.3741, loss-lb:0.1394, loss-ulb:0.1173, weight:2.00, lr:0.0005
[04:35:54.474] iteration:8730  t-loss:0.2565, loss-lb:0.2019, loss-ulb:0.0273, weight:2.00, lr:0.0005
[04:35:54.801] iteration:8731  t-loss:0.3093, loss-lb:0.2738, loss-ulb:0.0177, weight:2.00, lr:0.0005
[04:35:55.121] iteration:8732  t-loss:0.4373, loss-lb:0.2686, loss-ulb:0.0844, weight:2.00, lr:0.0005
[04:35:55.442] iteration:8733  t-loss:0.4498, loss-lb:0.2391, loss-ulb:0.1054, weight:2.00, lr:0.0005
[04:35:55.761] iteration:8734  t-loss:0.2182, loss-lb:0.1825, loss-ulb:0.0179, weight:2.00, lr:0.0005
[04:35:56.083] iteration:8735  t-loss:0.3930, loss-lb:0.2743, loss-ulb:0.0594, weight:2.00, lr:0.0005
[04:35:56.401] iteration:8736  t-loss:0.5953, loss-lb:0.1981, loss-ulb:0.1986, weight:2.00, lr:0.0005
[04:35:56.720] iteration:8737  t-loss:0.3258, loss-lb:0.1667, loss-ulb:0.0796, weight:2.00, lr:0.0005
[04:35:57.043] iteration:8738  t-loss:0.4995, loss-lb:0.3557, loss-ulb:0.0719, weight:2.00, lr:0.0005
[04:35:57.366] iteration:8739  t-loss:0.2165, loss-lb:0.1318, loss-ulb:0.0423, weight:2.00, lr:0.0005
[04:35:57.684] iteration:8740  t-loss:0.2305, loss-lb:0.1855, loss-ulb:0.0225, weight:2.00, lr:0.0005
[04:35:58.003] iteration:8741  t-loss:0.2724, loss-lb:0.1451, loss-ulb:0.0637, weight:2.00, lr:0.0005
[04:35:58.322] iteration:8742  t-loss:0.2961, loss-lb:0.1622, loss-ulb:0.0670, weight:2.00, lr:0.0005
[04:35:58.641] iteration:8743  t-loss:0.5012, loss-lb:0.3297, loss-ulb:0.0858, weight:2.00, lr:0.0005
[04:35:58.956] iteration:8744  t-loss:0.2510, loss-lb:0.2076, loss-ulb:0.0217, weight:2.00, lr:0.0005
[04:35:59.273] iteration:8745  t-loss:0.1870, loss-lb:0.1540, loss-ulb:0.0165, weight:2.00, lr:0.0005
[04:35:59.593] iteration:8746  t-loss:0.4004, loss-lb:0.2094, loss-ulb:0.0955, weight:2.00, lr:0.0005
[04:35:59.912] iteration:8747  t-loss:0.5397, loss-lb:0.3326, loss-ulb:0.1036, weight:2.00, lr:0.0005
[04:36:00.230] iteration:8748  t-loss:0.4632, loss-lb:0.1830, loss-ulb:0.1401, weight:2.00, lr:0.0005
[04:36:00.547] iteration:8749  t-loss:0.4050, loss-lb:0.2479, loss-ulb:0.0785, weight:2.00, lr:0.0005
[04:36:00.863] iteration:8750  t-loss:0.2850, loss-lb:0.1395, loss-ulb:0.0727, weight:2.00, lr:0.0005
[04:36:02.150] iteration:8751  t-loss:0.3323, loss-lb:0.2064, loss-ulb:0.0630, weight:2.00, lr:0.0005
[04:36:02.480] iteration:8752  t-loss:0.4426, loss-lb:0.1760, loss-ulb:0.1333, weight:2.00, lr:0.0005
[04:36:02.808] iteration:8753  t-loss:0.4385, loss-lb:0.1359, loss-ulb:0.1513, weight:2.00, lr:0.0005
[04:36:03.155] iteration:8754  t-loss:0.3062, loss-lb:0.1859, loss-ulb:0.0602, weight:2.00, lr:0.0005
[04:36:03.480] iteration:8755  t-loss:0.3624, loss-lb:0.1995, loss-ulb:0.0814, weight:2.00, lr:0.0005
[04:36:03.806] iteration:8756  t-loss:0.3658, loss-lb:0.2482, loss-ulb:0.0588, weight:2.00, lr:0.0005
[04:36:04.130] iteration:8757  t-loss:0.4673, loss-lb:0.2894, loss-ulb:0.0889, weight:2.00, lr:0.0005
[04:36:04.452] iteration:8758  t-loss:0.4042, loss-lb:0.1439, loss-ulb:0.1301, weight:2.00, lr:0.0005
[04:36:04.778] iteration:8759  t-loss:0.3356, loss-lb:0.2239, loss-ulb:0.0558, weight:2.00, lr:0.0005
[04:36:05.104] iteration:8760  t-loss:0.2151, loss-lb:0.1690, loss-ulb:0.0230, weight:2.00, lr:0.0005
[04:36:05.429] iteration:8761  t-loss:0.5310, loss-lb:0.1659, loss-ulb:0.1825, weight:2.00, lr:0.0005
[04:36:05.753] iteration:8762  t-loss:0.4932, loss-lb:0.3510, loss-ulb:0.0711, weight:2.00, lr:0.0005
[04:36:06.077] iteration:8763  t-loss:0.2062, loss-lb:0.1720, loss-ulb:0.0171, weight:2.00, lr:0.0005
[04:36:06.401] iteration:8764  t-loss:0.3762, loss-lb:0.2627, loss-ulb:0.0567, weight:2.00, lr:0.0005
[04:36:06.719] iteration:8765  t-loss:0.2171, loss-lb:0.1850, loss-ulb:0.0161, weight:2.00, lr:0.0005
[04:36:07.043] iteration:8766  t-loss:0.3228, loss-lb:0.1439, loss-ulb:0.0895, weight:2.00, lr:0.0005
[04:36:07.367] iteration:8767  t-loss:0.4588, loss-lb:0.1956, loss-ulb:0.1316, weight:2.00, lr:0.0005
[04:36:07.687] iteration:8768  t-loss:0.2441, loss-lb:0.1956, loss-ulb:0.0243, weight:2.00, lr:0.0005
[04:36:08.011] iteration:8769  t-loss:0.4758, loss-lb:0.3326, loss-ulb:0.0716, weight:2.00, lr:0.0005
[04:36:08.329] iteration:8770  t-loss:0.4674, loss-lb:0.1967, loss-ulb:0.1354, weight:2.00, lr:0.0005
[04:36:08.646] iteration:8771  t-loss:0.9122, loss-lb:0.1739, loss-ulb:0.3692, weight:2.00, lr:0.0005
[04:36:08.966] iteration:8772  t-loss:0.4671, loss-lb:0.3288, loss-ulb:0.0692, weight:2.00, lr:0.0005
[04:36:09.289] iteration:8773  t-loss:0.3744, loss-lb:0.3254, loss-ulb:0.0245, weight:2.00, lr:0.0005
[04:36:09.613] iteration:8774  t-loss:0.4864, loss-lb:0.2592, loss-ulb:0.1136, weight:2.00, lr:0.0005
[04:36:09.931] iteration:8775  t-loss:0.4020, loss-lb:0.2741, loss-ulb:0.0640, weight:2.00, lr:0.0005
[04:36:11.336] iteration:8776  t-loss:0.6562, loss-lb:0.2213, loss-ulb:0.2174, weight:2.00, lr:0.0005
[04:36:11.662] iteration:8777  t-loss:0.2500, loss-lb:0.1718, loss-ulb:0.0391, weight:2.00, lr:0.0005
[04:36:11.991] iteration:8778  t-loss:0.3421, loss-lb:0.1927, loss-ulb:0.0747, weight:2.00, lr:0.0005
[04:36:12.318] iteration:8779  t-loss:0.3771, loss-lb:0.2322, loss-ulb:0.0724, weight:2.00, lr:0.0005
[04:36:12.640] iteration:8780  t-loss:0.8750, loss-lb:0.2051, loss-ulb:0.3350, weight:2.00, lr:0.0005
[04:36:12.960] iteration:8781  t-loss:0.2029, loss-lb:0.1498, loss-ulb:0.0265, weight:2.00, lr:0.0005
[04:36:13.282] iteration:8782  t-loss:0.2374, loss-lb:0.1781, loss-ulb:0.0296, weight:2.00, lr:0.0005
[04:36:13.608] iteration:8783  t-loss:0.3490, loss-lb:0.2195, loss-ulb:0.0648, weight:2.00, lr:0.0005
[04:36:13.930] iteration:8784  t-loss:0.3218, loss-lb:0.1491, loss-ulb:0.0863, weight:2.00, lr:0.0005
[04:36:14.261] iteration:8785  t-loss:0.4318, loss-lb:0.3167, loss-ulb:0.0576, weight:2.00, lr:0.0005
[04:36:14.586] iteration:8786  t-loss:1.1295, loss-lb:0.2052, loss-ulb:0.4622, weight:2.00, lr:0.0005
[04:36:14.914] iteration:8787  t-loss:0.7668, loss-lb:0.4998, loss-ulb:0.1335, weight:2.00, lr:0.0005
[04:36:15.241] iteration:8788  t-loss:0.4210, loss-lb:0.1986, loss-ulb:0.1112, weight:2.00, lr:0.0005
[04:36:15.564] iteration:8789  t-loss:0.3418, loss-lb:0.2386, loss-ulb:0.0516, weight:2.00, lr:0.0005
[04:36:15.885] iteration:8790  t-loss:0.2838, loss-lb:0.1878, loss-ulb:0.0480, weight:2.00, lr:0.0005
[04:36:16.211] iteration:8791  t-loss:0.2873, loss-lb:0.2489, loss-ulb:0.0192, weight:2.00, lr:0.0005
[04:36:16.535] iteration:8792  t-loss:0.2715, loss-lb:0.1905, loss-ulb:0.0405, weight:2.00, lr:0.0005
[04:36:16.858] iteration:8793  t-loss:0.5620, loss-lb:0.2832, loss-ulb:0.1394, weight:2.00, lr:0.0005
[04:36:17.182] iteration:8794  t-loss:0.3969, loss-lb:0.2828, loss-ulb:0.0571, weight:2.00, lr:0.0005
[04:36:17.502] iteration:8795  t-loss:0.4221, loss-lb:0.1949, loss-ulb:0.1136, weight:2.00, lr:0.0005
[04:36:17.823] iteration:8796  t-loss:0.3627, loss-lb:0.1705, loss-ulb:0.0961, weight:2.00, lr:0.0005
[04:36:18.145] iteration:8797  t-loss:0.6860, loss-lb:0.3748, loss-ulb:0.1556, weight:2.00, lr:0.0005
[04:36:18.466] iteration:8798  t-loss:0.2978, loss-lb:0.1779, loss-ulb:0.0599, weight:2.00, lr:0.0005
[04:36:18.786] iteration:8799  t-loss:0.3637, loss-lb:0.2777, loss-ulb:0.0430, weight:2.00, lr:0.0005
[04:36:19.103] iteration:8800  t-loss:0.2281, loss-lb:0.1760, loss-ulb:0.0260, weight:2.00, lr:0.0005
[04:36:20.567] iteration:8801  t-loss:0.6852, loss-lb:0.2117, loss-ulb:0.2367, weight:2.00, lr:0.0005
[04:36:20.906] iteration:8802  t-loss:0.3878, loss-lb:0.2191, loss-ulb:0.0843, weight:2.00, lr:0.0005
[04:36:21.244] iteration:8803  t-loss:0.3616, loss-lb:0.2471, loss-ulb:0.0572, weight:2.00, lr:0.0005
[04:36:21.579] iteration:8804  t-loss:0.3111, loss-lb:0.1674, loss-ulb:0.0719, weight:2.00, lr:0.0005
[04:36:21.903] iteration:8805  t-loss:0.3176, loss-lb:0.1602, loss-ulb:0.0787, weight:2.00, lr:0.0005
[04:36:22.228] iteration:8806  t-loss:0.3137, loss-lb:0.2769, loss-ulb:0.0184, weight:2.00, lr:0.0005
[04:36:22.553] iteration:8807  t-loss:0.3553, loss-lb:0.1425, loss-ulb:0.1064, weight:2.00, lr:0.0005
[04:36:22.876] iteration:8808  t-loss:0.2428, loss-lb:0.1258, loss-ulb:0.0585, weight:2.00, lr:0.0005
[04:36:23.199] iteration:8809  t-loss:0.9226, loss-lb:0.2034, loss-ulb:0.3596, weight:2.00, lr:0.0005
[04:36:23.523] iteration:8810  t-loss:0.4649, loss-lb:0.2696, loss-ulb:0.0977, weight:2.00, lr:0.0005
[04:36:23.852] iteration:8811  t-loss:0.2889, loss-lb:0.2260, loss-ulb:0.0315, weight:2.00, lr:0.0005
[04:36:24.179] iteration:8812  t-loss:0.3110, loss-lb:0.1649, loss-ulb:0.0731, weight:2.00, lr:0.0005
[04:36:24.498] iteration:8813  t-loss:0.2181, loss-lb:0.1357, loss-ulb:0.0412, weight:2.00, lr:0.0005
[04:36:24.822] iteration:8814  t-loss:0.3968, loss-lb:0.2316, loss-ulb:0.0826, weight:2.00, lr:0.0005
[04:36:25.146] iteration:8815  t-loss:0.3041, loss-lb:0.2686, loss-ulb:0.0177, weight:2.00, lr:0.0005
[04:36:25.468] iteration:8816  t-loss:0.3139, loss-lb:0.2169, loss-ulb:0.0485, weight:2.00, lr:0.0005
[04:36:25.788] iteration:8817  t-loss:0.2499, loss-lb:0.2046, loss-ulb:0.0226, weight:2.00, lr:0.0005
[04:36:26.110] iteration:8818  t-loss:0.4624, loss-lb:0.2315, loss-ulb:0.1155, weight:2.00, lr:0.0005
[04:36:26.432] iteration:8819  t-loss:0.4637, loss-lb:0.2241, loss-ulb:0.1198, weight:2.00, lr:0.0005
[04:36:26.751] iteration:8820  t-loss:0.3560, loss-lb:0.3020, loss-ulb:0.0270, weight:2.00, lr:0.0005
[04:36:27.071] iteration:8821  t-loss:0.4767, loss-lb:0.2300, loss-ulb:0.1234, weight:2.00, lr:0.0005
[04:36:27.391] iteration:8822  t-loss:0.3764, loss-lb:0.3482, loss-ulb:0.0141, weight:2.00, lr:0.0005
[04:36:27.707] iteration:8823  t-loss:0.4308, loss-lb:0.2118, loss-ulb:0.1095, weight:2.00, lr:0.0005
[04:36:28.027] iteration:8824  t-loss:0.3408, loss-lb:0.2084, loss-ulb:0.0662, weight:2.00, lr:0.0005
[04:36:28.343] iteration:8825  t-loss:0.3580, loss-lb:0.3232, loss-ulb:0.0174, weight:2.00, lr:0.0004
[04:38:43.918] iteration 8825 : dice_score: 0.844665 best_dice: 0.848300
[04:38:43.918]  <<Test>> - Ep:352  - Dice-S/T:83.96/84.47, Best-S:84.60, Best-T:84.83
[04:38:43.918]           - AvgLoss(lb/ulb/all):0.22/0.08/0.38
[04:38:45.143] iteration:8826  t-loss:0.3975, loss-lb:0.2581, loss-ulb:0.0697, weight:2.00, lr:0.0004
[04:38:45.483] iteration:8827  t-loss:0.1343, loss-lb:0.0902, loss-ulb:0.0221, weight:2.00, lr:0.0004
[04:38:45.816] iteration:8828  t-loss:0.5594, loss-lb:0.1975, loss-ulb:0.1809, weight:2.00, lr:0.0004
[04:38:46.154] iteration:8829  t-loss:0.5615, loss-lb:0.2775, loss-ulb:0.1420, weight:2.00, lr:0.0004
[04:38:46.475] iteration:8830  t-loss:0.1962, loss-lb:0.1432, loss-ulb:0.0265, weight:2.00, lr:0.0004
[04:38:46.792] iteration:8831  t-loss:0.3131, loss-lb:0.1690, loss-ulb:0.0720, weight:2.00, lr:0.0004
[04:38:47.110] iteration:8832  t-loss:0.6853, loss-lb:0.5887, loss-ulb:0.0483, weight:2.00, lr:0.0004
[04:38:47.432] iteration:8833  t-loss:0.2729, loss-lb:0.1683, loss-ulb:0.0523, weight:2.00, lr:0.0004
[04:38:47.753] iteration:8834  t-loss:0.3157, loss-lb:0.1467, loss-ulb:0.0845, weight:2.00, lr:0.0004
[04:38:48.072] iteration:8835  t-loss:0.2620, loss-lb:0.1609, loss-ulb:0.0506, weight:2.00, lr:0.0004
[04:38:48.392] iteration:8836  t-loss:0.3735, loss-lb:0.1603, loss-ulb:0.1066, weight:2.00, lr:0.0004
[04:38:48.714] iteration:8837  t-loss:0.2606, loss-lb:0.1593, loss-ulb:0.0507, weight:2.00, lr:0.0004
[04:38:49.039] iteration:8838  t-loss:0.2370, loss-lb:0.1949, loss-ulb:0.0211, weight:2.00, lr:0.0004
[04:38:49.359] iteration:8839  t-loss:0.2793, loss-lb:0.1466, loss-ulb:0.0664, weight:2.00, lr:0.0004
[04:38:49.678] iteration:8840  t-loss:0.4773, loss-lb:0.1630, loss-ulb:0.1571, weight:2.00, lr:0.0004
[04:38:49.999] iteration:8841  t-loss:0.2088, loss-lb:0.1495, loss-ulb:0.0296, weight:2.00, lr:0.0004
[04:38:50.319] iteration:8842  t-loss:0.3907, loss-lb:0.1712, loss-ulb:0.1097, weight:2.00, lr:0.0004
[04:38:50.638] iteration:8843  t-loss:0.4245, loss-lb:0.3067, loss-ulb:0.0589, weight:2.00, lr:0.0004
[04:38:50.956] iteration:8844  t-loss:0.4056, loss-lb:0.1966, loss-ulb:0.1045, weight:2.00, lr:0.0004
[04:38:51.271] iteration:8845  t-loss:0.2955, loss-lb:0.1921, loss-ulb:0.0517, weight:2.00, lr:0.0004
[04:38:51.587] iteration:8846  t-loss:0.2582, loss-lb:0.2108, loss-ulb:0.0237, weight:2.00, lr:0.0004
[04:38:51.902] iteration:8847  t-loss:0.4416, loss-lb:0.3155, loss-ulb:0.0631, weight:2.00, lr:0.0004
[04:38:52.217] iteration:8848  t-loss:0.4818, loss-lb:0.4257, loss-ulb:0.0281, weight:2.00, lr:0.0004
[04:38:52.534] iteration:8849  t-loss:0.4253, loss-lb:0.2805, loss-ulb:0.0724, weight:2.00, lr:0.0004
[04:38:52.848] iteration:8850  t-loss:0.2557, loss-lb:0.2068, loss-ulb:0.0244, weight:2.00, lr:0.0004
[04:38:54.286] iteration:8851  t-loss:0.1692, loss-lb:0.1235, loss-ulb:0.0229, weight:2.00, lr:0.0004
[04:38:54.629] iteration:8852  t-loss:0.2086, loss-lb:0.1428, loss-ulb:0.0329, weight:2.00, lr:0.0004
[04:38:54.986] iteration:8853  t-loss:0.2974, loss-lb:0.2558, loss-ulb:0.0208, weight:2.00, lr:0.0004
[04:38:55.331] iteration:8854  t-loss:0.5249, loss-lb:0.3283, loss-ulb:0.0983, weight:2.00, lr:0.0004
[04:38:55.661] iteration:8855  t-loss:0.1927, loss-lb:0.1541, loss-ulb:0.0193, weight:2.00, lr:0.0004
[04:38:56.001] iteration:8856  t-loss:0.5212, loss-lb:0.2994, loss-ulb:0.1109, weight:2.00, lr:0.0004
[04:38:56.359] iteration:8857  t-loss:0.4526, loss-lb:0.2438, loss-ulb:0.1044, weight:2.00, lr:0.0004
[04:38:56.701] iteration:8858  t-loss:0.4325, loss-lb:0.2847, loss-ulb:0.0739, weight:2.00, lr:0.0004
[04:38:57.031] iteration:8859  t-loss:0.4973, loss-lb:0.2440, loss-ulb:0.1266, weight:2.00, lr:0.0004
[04:38:57.361] iteration:8860  t-loss:0.1943, loss-lb:0.1604, loss-ulb:0.0169, weight:2.00, lr:0.0004
[04:38:57.686] iteration:8861  t-loss:0.2143, loss-lb:0.1776, loss-ulb:0.0183, weight:2.00, lr:0.0004
[04:38:58.009] iteration:8862  t-loss:0.2016, loss-lb:0.1204, loss-ulb:0.0406, weight:2.00, lr:0.0004
[04:38:58.343] iteration:8863  t-loss:0.3793, loss-lb:0.2680, loss-ulb:0.0557, weight:2.00, lr:0.0004
[04:38:58.663] iteration:8864  t-loss:0.2387, loss-lb:0.1863, loss-ulb:0.0262, weight:2.00, lr:0.0004
[04:38:58.987] iteration:8865  t-loss:0.3535, loss-lb:0.1683, loss-ulb:0.0926, weight:2.00, lr:0.0004
[04:38:59.309] iteration:8866  t-loss:0.4068, loss-lb:0.3750, loss-ulb:0.0159, weight:2.00, lr:0.0004
[04:38:59.631] iteration:8867  t-loss:0.4156, loss-lb:0.2811, loss-ulb:0.0673, weight:2.00, lr:0.0004
[04:38:59.952] iteration:8868  t-loss:0.4878, loss-lb:0.1523, loss-ulb:0.1678, weight:2.00, lr:0.0004
[04:39:00.265] iteration:8869  t-loss:0.2265, loss-lb:0.1900, loss-ulb:0.0183, weight:2.00, lr:0.0004
[04:39:00.584] iteration:8870  t-loss:0.3432, loss-lb:0.1647, loss-ulb:0.0893, weight:2.00, lr:0.0004
[04:39:00.899] iteration:8871  t-loss:0.1810, loss-lb:0.1384, loss-ulb:0.0213, weight:2.00, lr:0.0004
[04:39:01.218] iteration:8872  t-loss:0.4448, loss-lb:0.1946, loss-ulb:0.1251, weight:2.00, lr:0.0004
[04:39:01.539] iteration:8873  t-loss:0.4265, loss-lb:0.2889, loss-ulb:0.0688, weight:2.00, lr:0.0004
[04:39:01.859] iteration:8874  t-loss:0.4608, loss-lb:0.2440, loss-ulb:0.1084, weight:2.00, lr:0.0004
[04:39:02.181] iteration:8875  t-loss:0.4437, loss-lb:0.2017, loss-ulb:0.1210, weight:2.00, lr:0.0004
[04:39:03.745] iteration:8876  t-loss:0.4897, loss-lb:0.1860, loss-ulb:0.1519, weight:2.00, lr:0.0004
[04:39:04.085] iteration:8877  t-loss:0.3728, loss-lb:0.2034, loss-ulb:0.0847, weight:2.00, lr:0.0004
[04:39:04.407] iteration:8878  t-loss:0.1854, loss-lb:0.1428, loss-ulb:0.0213, weight:2.00, lr:0.0004
[04:39:04.726] iteration:8879  t-loss:0.1965, loss-lb:0.1474, loss-ulb:0.0246, weight:2.00, lr:0.0004
[04:39:05.047] iteration:8880  t-loss:0.4585, loss-lb:0.2288, loss-ulb:0.1149, weight:2.00, lr:0.0004
[04:39:05.366] iteration:8881  t-loss:0.2928, loss-lb:0.1366, loss-ulb:0.0781, weight:2.00, lr:0.0004
[04:39:05.682] iteration:8882  t-loss:0.1853, loss-lb:0.1457, loss-ulb:0.0198, weight:2.00, lr:0.0004
[04:39:06.005] iteration:8883  t-loss:0.5497, loss-lb:0.2704, loss-ulb:0.1397, weight:2.00, lr:0.0004
[04:39:06.323] iteration:8884  t-loss:0.2396, loss-lb:0.1971, loss-ulb:0.0212, weight:2.00, lr:0.0004
[04:39:06.642] iteration:8885  t-loss:0.4676, loss-lb:0.2350, loss-ulb:0.1163, weight:2.00, lr:0.0004
[04:39:06.957] iteration:8886  t-loss:0.3420, loss-lb:0.1431, loss-ulb:0.0994, weight:2.00, lr:0.0004
[04:39:07.274] iteration:8887  t-loss:0.2463, loss-lb:0.1870, loss-ulb:0.0297, weight:2.00, lr:0.0004
[04:39:07.589] iteration:8888  t-loss:0.2748, loss-lb:0.1237, loss-ulb:0.0755, weight:2.00, lr:0.0004
[04:39:07.909] iteration:8889  t-loss:0.2939, loss-lb:0.2511, loss-ulb:0.0214, weight:2.00, lr:0.0004
[04:39:08.234] iteration:8890  t-loss:0.4346, loss-lb:0.2464, loss-ulb:0.0941, weight:2.00, lr:0.0004
[04:39:08.551] iteration:8891  t-loss:0.2973, loss-lb:0.2196, loss-ulb:0.0389, weight:2.00, lr:0.0004
[04:39:08.872] iteration:8892  t-loss:0.3623, loss-lb:0.2149, loss-ulb:0.0737, weight:2.00, lr:0.0004
[04:39:09.197] iteration:8893  t-loss:0.4172, loss-lb:0.2948, loss-ulb:0.0612, weight:2.00, lr:0.0004
[04:39:09.523] iteration:8894  t-loss:0.3871, loss-lb:0.2078, loss-ulb:0.0896, weight:2.00, lr:0.0004
[04:39:09.852] iteration:8895  t-loss:0.2741, loss-lb:0.1583, loss-ulb:0.0579, weight:2.00, lr:0.0004
[04:39:10.173] iteration:8896  t-loss:0.2327, loss-lb:0.1598, loss-ulb:0.0364, weight:2.00, lr:0.0004
[04:39:10.498] iteration:8897  t-loss:0.1551, loss-lb:0.1200, loss-ulb:0.0175, weight:2.00, lr:0.0004
[04:39:10.819] iteration:8898  t-loss:0.3180, loss-lb:0.2155, loss-ulb:0.0513, weight:2.00, lr:0.0004
[04:39:11.138] iteration:8899  t-loss:0.5490, loss-lb:0.3592, loss-ulb:0.0949, weight:2.00, lr:0.0004
[04:39:11.461] iteration:8900  t-loss:0.2455, loss-lb:0.2167, loss-ulb:0.0144, weight:2.00, lr:0.0004
[04:39:12.780] iteration:8901  t-loss:0.3665, loss-lb:0.2839, loss-ulb:0.0413, weight:2.00, lr:0.0004
[04:39:13.115] iteration:8902  t-loss:0.3268, loss-lb:0.2240, loss-ulb:0.0514, weight:2.00, lr:0.0004
[04:39:13.440] iteration:8903  t-loss:0.2404, loss-lb:0.1795, loss-ulb:0.0304, weight:2.00, lr:0.0004
[04:39:13.788] iteration:8904  t-loss:0.5183, loss-lb:0.2348, loss-ulb:0.1418, weight:2.00, lr:0.0004
[04:39:14.121] iteration:8905  t-loss:1.6021, loss-lb:0.1738, loss-ulb:0.7142, weight:2.00, lr:0.0004
[04:39:14.454] iteration:8906  t-loss:0.2438, loss-lb:0.2148, loss-ulb:0.0145, weight:2.00, lr:0.0004
[04:39:14.791] iteration:8907  t-loss:0.3717, loss-lb:0.1132, loss-ulb:0.1293, weight:2.00, lr:0.0004
[04:39:15.137] iteration:8908  t-loss:0.4858, loss-lb:0.3226, loss-ulb:0.0816, weight:2.00, lr:0.0004
[04:39:15.470] iteration:8909  t-loss:0.3174, loss-lb:0.2705, loss-ulb:0.0235, weight:2.00, lr:0.0004
[04:39:15.797] iteration:8910  t-loss:0.3349, loss-lb:0.1244, loss-ulb:0.1052, weight:2.00, lr:0.0004
[04:39:16.121] iteration:8911  t-loss:0.2736, loss-lb:0.2251, loss-ulb:0.0243, weight:2.00, lr:0.0004
[04:39:16.448] iteration:8912  t-loss:0.2941, loss-lb:0.2064, loss-ulb:0.0439, weight:2.00, lr:0.0004
[04:39:16.775] iteration:8913  t-loss:0.7714, loss-lb:0.1952, loss-ulb:0.2881, weight:2.00, lr:0.0004
[04:39:17.101] iteration:8914  t-loss:0.3241, loss-lb:0.1277, loss-ulb:0.0982, weight:2.00, lr:0.0004
[04:39:17.421] iteration:8915  t-loss:0.5087, loss-lb:0.1760, loss-ulb:0.1663, weight:2.00, lr:0.0004
[04:39:17.751] iteration:8916  t-loss:0.4583, loss-lb:0.3453, loss-ulb:0.0565, weight:2.00, lr:0.0004
[04:39:18.077] iteration:8917  t-loss:0.2921, loss-lb:0.2035, loss-ulb:0.0443, weight:2.00, lr:0.0004
[04:39:18.396] iteration:8918  t-loss:0.4353, loss-lb:0.1598, loss-ulb:0.1378, weight:2.00, lr:0.0004
[04:39:18.711] iteration:8919  t-loss:0.2596, loss-lb:0.2031, loss-ulb:0.0283, weight:2.00, lr:0.0004
[04:39:19.029] iteration:8920  t-loss:0.3359, loss-lb:0.1903, loss-ulb:0.0728, weight:2.00, lr:0.0004
[04:39:19.348] iteration:8921  t-loss:0.1925, loss-lb:0.1369, loss-ulb:0.0278, weight:2.00, lr:0.0004
[04:39:19.667] iteration:8922  t-loss:0.2138, loss-lb:0.1611, loss-ulb:0.0263, weight:2.00, lr:0.0004
[04:39:19.982] iteration:8923  t-loss:0.4750, loss-lb:0.1950, loss-ulb:0.1400, weight:2.00, lr:0.0004
[04:39:20.300] iteration:8924  t-loss:0.3372, loss-lb:0.1429, loss-ulb:0.0971, weight:2.00, lr:0.0004
[04:39:20.614] iteration:8925  t-loss:0.2033, loss-lb:0.1589, loss-ulb:0.0222, weight:2.00, lr:0.0004
[04:41:36.403] iteration 8925 : dice_score: 0.845545 best_dice: 0.848300
[04:41:36.403]  <<Test>> - Ep:356  - Dice-S/T:84.59/84.55, Best-S:84.60, Best-T:84.83
[04:41:36.403]           - AvgLoss(lb/ulb/all):0.20/0.08/0.36
[04:41:37.823] iteration:8926  t-loss:0.3577, loss-lb:0.2597, loss-ulb:0.0490, weight:2.00, lr:0.0004
[04:41:38.150] iteration:8927  t-loss:0.2781, loss-lb:0.2099, loss-ulb:0.0341, weight:2.00, lr:0.0004
[04:41:38.470] iteration:8928  t-loss:0.6709, loss-lb:0.1537, loss-ulb:0.2586, weight:2.00, lr:0.0004
[04:41:38.787] iteration:8929  t-loss:0.2160, loss-lb:0.1693, loss-ulb:0.0234, weight:2.00, lr:0.0004
[04:41:39.106] iteration:8930  t-loss:0.3935, loss-lb:0.1663, loss-ulb:0.1136, weight:2.00, lr:0.0004
[04:41:39.423] iteration:8931  t-loss:0.4527, loss-lb:0.1555, loss-ulb:0.1486, weight:2.00, lr:0.0004
[04:41:39.737] iteration:8932  t-loss:0.1800, loss-lb:0.1331, loss-ulb:0.0234, weight:2.00, lr:0.0004
[04:41:40.059] iteration:8933  t-loss:0.2974, loss-lb:0.2303, loss-ulb:0.0335, weight:2.00, lr:0.0004
[04:41:40.377] iteration:8934  t-loss:0.3535, loss-lb:0.1698, loss-ulb:0.0918, weight:2.00, lr:0.0004
[04:41:40.694] iteration:8935  t-loss:0.2006, loss-lb:0.1323, loss-ulb:0.0341, weight:2.00, lr:0.0004
[04:41:41.012] iteration:8936  t-loss:0.2166, loss-lb:0.1918, loss-ulb:0.0124, weight:2.00, lr:0.0004
[04:41:41.334] iteration:8937  t-loss:0.2686, loss-lb:0.2119, loss-ulb:0.0284, weight:2.00, lr:0.0004
[04:41:41.653] iteration:8938  t-loss:0.3715, loss-lb:0.1786, loss-ulb:0.0965, weight:2.00, lr:0.0004
[04:41:41.968] iteration:8939  t-loss:0.3038, loss-lb:0.1497, loss-ulb:0.0770, weight:2.00, lr:0.0004
[04:41:42.288] iteration:8940  t-loss:0.3166, loss-lb:0.1984, loss-ulb:0.0591, weight:2.00, lr:0.0004
[04:41:42.607] iteration:8941  t-loss:0.3310, loss-lb:0.1555, loss-ulb:0.0877, weight:2.00, lr:0.0004
[04:41:42.930] iteration:8942  t-loss:0.1873, loss-lb:0.1520, loss-ulb:0.0176, weight:2.00, lr:0.0004
[04:41:43.252] iteration:8943  t-loss:0.4342, loss-lb:0.1565, loss-ulb:0.1389, weight:2.00, lr:0.0004
[04:41:43.567] iteration:8944  t-loss:0.2595, loss-lb:0.2283, loss-ulb:0.0156, weight:2.00, lr:0.0004
[04:41:43.882] iteration:8945  t-loss:0.2318, loss-lb:0.1701, loss-ulb:0.0308, weight:2.00, lr:0.0004
[04:41:44.200] iteration:8946  t-loss:0.2948, loss-lb:0.1598, loss-ulb:0.0675, weight:2.00, lr:0.0004
[04:41:44.514] iteration:8947  t-loss:0.2923, loss-lb:0.2096, loss-ulb:0.0413, weight:2.00, lr:0.0004
[04:41:44.833] iteration:8948  t-loss:0.5225, loss-lb:0.2174, loss-ulb:0.1525, weight:2.00, lr:0.0004
[04:41:45.150] iteration:8949  t-loss:0.2684, loss-lb:0.1903, loss-ulb:0.0390, weight:2.00, lr:0.0004
[04:41:45.464] iteration:8950  t-loss:0.1678, loss-lb:0.1345, loss-ulb:0.0166, weight:2.00, lr:0.0004
[04:41:46.892] iteration:8951  t-loss:0.1586, loss-lb:0.1235, loss-ulb:0.0176, weight:2.00, lr:0.0004
[04:41:47.224] iteration:8952  t-loss:0.2521, loss-lb:0.2139, loss-ulb:0.0191, weight:2.00, lr:0.0004
[04:41:47.544] iteration:8953  t-loss:0.2465, loss-lb:0.2198, loss-ulb:0.0134, weight:2.00, lr:0.0004
[04:41:47.866] iteration:8954  t-loss:0.3433, loss-lb:0.2301, loss-ulb:0.0566, weight:2.00, lr:0.0004
[04:41:48.182] iteration:8955  t-loss:0.1785, loss-lb:0.1440, loss-ulb:0.0173, weight:2.00, lr:0.0004
[04:41:48.502] iteration:8956  t-loss:0.3602, loss-lb:0.1503, loss-ulb:0.1049, weight:2.00, lr:0.0004
[04:41:48.825] iteration:8957  t-loss:0.2665, loss-lb:0.1335, loss-ulb:0.0665, weight:2.00, lr:0.0004
[04:41:49.150] iteration:8958  t-loss:0.5851, loss-lb:0.2097, loss-ulb:0.1877, weight:2.00, lr:0.0004
[04:41:49.474] iteration:8959  t-loss:0.1960, loss-lb:0.1587, loss-ulb:0.0187, weight:2.00, lr:0.0004
[04:41:49.794] iteration:8960  t-loss:0.2471, loss-lb:0.2208, loss-ulb:0.0132, weight:2.00, lr:0.0004
[04:41:50.115] iteration:8961  t-loss:0.3943, loss-lb:0.3296, loss-ulb:0.0323, weight:2.00, lr:0.0004
[04:41:50.436] iteration:8962  t-loss:0.2023, loss-lb:0.1586, loss-ulb:0.0219, weight:2.00, lr:0.0004
[04:41:50.767] iteration:8963  t-loss:0.5032, loss-lb:0.2451, loss-ulb:0.1290, weight:2.00, lr:0.0004
[04:41:51.103] iteration:8964  t-loss:0.3460, loss-lb:0.1519, loss-ulb:0.0970, weight:2.00, lr:0.0004
[04:41:51.434] iteration:8965  t-loss:0.2271, loss-lb:0.1511, loss-ulb:0.0380, weight:2.00, lr:0.0004
[04:41:51.763] iteration:8966  t-loss:0.2800, loss-lb:0.2395, loss-ulb:0.0203, weight:2.00, lr:0.0004
[04:41:52.088] iteration:8967  t-loss:0.1928, loss-lb:0.1486, loss-ulb:0.0221, weight:2.00, lr:0.0004
[04:41:52.409] iteration:8968  t-loss:0.4425, loss-lb:0.1878, loss-ulb:0.1273, weight:2.00, lr:0.0004
[04:41:52.727] iteration:8969  t-loss:0.2518, loss-lb:0.1947, loss-ulb:0.0286, weight:2.00, lr:0.0004
[04:41:53.045] iteration:8970  t-loss:0.1989, loss-lb:0.1606, loss-ulb:0.0191, weight:2.00, lr:0.0004
[04:41:53.369] iteration:8971  t-loss:0.3777, loss-lb:0.2579, loss-ulb:0.0599, weight:2.00, lr:0.0004
[04:41:53.685] iteration:8972  t-loss:0.4148, loss-lb:0.3731, loss-ulb:0.0209, weight:2.00, lr:0.0004
[04:41:54.005] iteration:8973  t-loss:0.1989, loss-lb:0.1213, loss-ulb:0.0388, weight:2.00, lr:0.0004
[04:41:54.327] iteration:8974  t-loss:0.4853, loss-lb:0.3523, loss-ulb:0.0665, weight:2.00, lr:0.0004
[04:41:54.646] iteration:8975  t-loss:0.4795, loss-lb:0.1586, loss-ulb:0.1605, weight:2.00, lr:0.0004
[04:41:56.322] iteration:8976  t-loss:0.3912, loss-lb:0.1176, loss-ulb:0.1368, weight:2.00, lr:0.0004
[04:41:56.651] iteration:8977  t-loss:0.3335, loss-lb:0.1757, loss-ulb:0.0789, weight:2.00, lr:0.0004
[04:41:56.974] iteration:8978  t-loss:0.3756, loss-lb:0.2868, loss-ulb:0.0444, weight:2.00, lr:0.0004
[04:41:57.293] iteration:8979  t-loss:0.2995, loss-lb:0.2511, loss-ulb:0.0242, weight:2.00, lr:0.0004
[04:41:57.616] iteration:8980  t-loss:0.5554, loss-lb:0.1539, loss-ulb:0.2008, weight:2.00, lr:0.0004
[04:41:57.939] iteration:8981  t-loss:0.4629, loss-lb:0.1529, loss-ulb:0.1550, weight:2.00, lr:0.0004
[04:41:58.257] iteration:8982  t-loss:0.1953, loss-lb:0.1633, loss-ulb:0.0160, weight:2.00, lr:0.0004
[04:41:58.576] iteration:8983  t-loss:0.3354, loss-lb:0.1521, loss-ulb:0.0916, weight:2.00, lr:0.0004
[04:41:58.895] iteration:8984  t-loss:0.3193, loss-lb:0.1589, loss-ulb:0.0802, weight:2.00, lr:0.0004
[04:41:59.232] iteration:8985  t-loss:0.5004, loss-lb:0.2952, loss-ulb:0.1026, weight:2.00, lr:0.0004
[04:41:59.569] iteration:8986  t-loss:0.2916, loss-lb:0.2343, loss-ulb:0.0287, weight:2.00, lr:0.0004
[04:41:59.896] iteration:8987  t-loss:0.2550, loss-lb:0.1396, loss-ulb:0.0577, weight:2.00, lr:0.0004
[04:42:00.221] iteration:8988  t-loss:0.4145, loss-lb:0.1603, loss-ulb:0.1271, weight:2.00, lr:0.0004
[04:42:00.543] iteration:8989  t-loss:0.2685, loss-lb:0.2352, loss-ulb:0.0166, weight:2.00, lr:0.0004
[04:42:00.865] iteration:8990  t-loss:0.5110, loss-lb:0.1355, loss-ulb:0.1877, weight:2.00, lr:0.0004
[04:42:01.188] iteration:8991  t-loss:0.5225, loss-lb:0.2936, loss-ulb:0.1144, weight:2.00, lr:0.0004
[04:42:01.510] iteration:8992  t-loss:0.2876, loss-lb:0.2053, loss-ulb:0.0411, weight:2.00, lr:0.0004
[04:42:01.833] iteration:8993  t-loss:0.2738, loss-lb:0.2006, loss-ulb:0.0366, weight:2.00, lr:0.0004
[04:42:02.154] iteration:8994  t-loss:0.2788, loss-lb:0.1713, loss-ulb:0.0537, weight:2.00, lr:0.0004
[04:42:02.471] iteration:8995  t-loss:0.1727, loss-lb:0.1243, loss-ulb:0.0242, weight:2.00, lr:0.0004
[04:42:02.791] iteration:8996  t-loss:0.2818, loss-lb:0.1195, loss-ulb:0.0811, weight:2.00, lr:0.0004
[04:42:03.110] iteration:8997  t-loss:0.3305, loss-lb:0.1711, loss-ulb:0.0797, weight:2.00, lr:0.0004
[04:42:03.428] iteration:8998  t-loss:0.3598, loss-lb:0.1741, loss-ulb:0.0928, weight:2.00, lr:0.0004
[04:42:03.750] iteration:8999  t-loss:0.4752, loss-lb:0.2072, loss-ulb:0.1340, weight:2.00, lr:0.0004
[04:42:04.071] iteration:9000  t-loss:0.4172, loss-lb:0.2683, loss-ulb:0.0744, weight:2.00, lr:0.0004
[04:42:05.426] iteration:9001  t-loss:0.5186, loss-lb:0.1650, loss-ulb:0.1768, weight:2.00, lr:0.0004
[04:42:05.761] iteration:9002  t-loss:0.2701, loss-lb:0.1416, loss-ulb:0.0643, weight:2.00, lr:0.0004
[04:42:06.081] iteration:9003  t-loss:0.2840, loss-lb:0.2210, loss-ulb:0.0315, weight:2.00, lr:0.0004
[04:42:06.401] iteration:9004  t-loss:0.3783, loss-lb:0.2106, loss-ulb:0.0838, weight:2.00, lr:0.0004
[04:42:06.730] iteration:9005  t-loss:0.5198, loss-lb:0.1587, loss-ulb:0.1805, weight:2.00, lr:0.0004
[04:42:07.049] iteration:9006  t-loss:0.4241, loss-lb:0.2404, loss-ulb:0.0919, weight:2.00, lr:0.0004
[04:42:07.368] iteration:9007  t-loss:0.3296, loss-lb:0.2102, loss-ulb:0.0597, weight:2.00, lr:0.0004
[04:42:07.695] iteration:9008  t-loss:0.5535, loss-lb:0.1621, loss-ulb:0.1957, weight:2.00, lr:0.0004
[04:42:08.028] iteration:9009  t-loss:0.2737, loss-lb:0.2451, loss-ulb:0.0143, weight:2.00, lr:0.0004
[04:42:08.373] iteration:9010  t-loss:0.6389, loss-lb:0.3678, loss-ulb:0.1355, weight:2.00, lr:0.0004
[04:42:08.712] iteration:9011  t-loss:0.2712, loss-lb:0.1356, loss-ulb:0.0678, weight:2.00, lr:0.0004
[04:42:09.040] iteration:9012  t-loss:0.3003, loss-lb:0.1464, loss-ulb:0.0770, weight:2.00, lr:0.0004
[04:42:09.373] iteration:9013  t-loss:0.3744, loss-lb:0.3111, loss-ulb:0.0317, weight:2.00, lr:0.0004
[04:42:09.705] iteration:9014  t-loss:0.5229, loss-lb:0.3257, loss-ulb:0.0986, weight:2.00, lr:0.0004
[04:42:10.023] iteration:9015  t-loss:0.2381, loss-lb:0.1322, loss-ulb:0.0529, weight:2.00, lr:0.0004
[04:42:10.352] iteration:9016  t-loss:0.5924, loss-lb:0.2361, loss-ulb:0.1781, weight:2.00, lr:0.0004
[04:42:10.676] iteration:9017  t-loss:0.3456, loss-lb:0.1231, loss-ulb:0.1112, weight:2.00, lr:0.0004
[04:42:11.000] iteration:9018  t-loss:0.2867, loss-lb:0.1342, loss-ulb:0.0762, weight:2.00, lr:0.0004
[04:42:11.325] iteration:9019  t-loss:0.5471, loss-lb:0.3701, loss-ulb:0.0885, weight:2.00, lr:0.0004
[04:42:11.643] iteration:9020  t-loss:0.7208, loss-lb:0.1673, loss-ulb:0.2768, weight:2.00, lr:0.0004
[04:42:11.966] iteration:9021  t-loss:0.5831, loss-lb:0.2883, loss-ulb:0.1474, weight:2.00, lr:0.0004
[04:42:12.288] iteration:9022  t-loss:0.4306, loss-lb:0.2453, loss-ulb:0.0926, weight:2.00, lr:0.0004
[04:42:12.606] iteration:9023  t-loss:0.3929, loss-lb:0.2906, loss-ulb:0.0512, weight:2.00, lr:0.0004
[04:42:12.926] iteration:9024  t-loss:0.2433, loss-lb:0.2086, loss-ulb:0.0174, weight:2.00, lr:0.0004
[04:42:13.244] iteration:9025  t-loss:0.1780, loss-lb:0.1451, loss-ulb:0.0165, weight:2.00, lr:0.0004
[04:44:23.596] iteration 9025 : dice_score: 0.844923 best_dice: 0.848300
[04:44:23.596]  <<Test>> - Ep:360  - Dice-S/T:83.52/84.49, Best-S:84.60, Best-T:84.83
[04:44:23.596]           - AvgLoss(lb/ulb/all):0.22/0.09/0.41
[04:44:25.041] iteration:9026  t-loss:0.3939, loss-lb:0.1998, loss-ulb:0.0970, weight:2.00, lr:0.0004
[04:44:25.385] iteration:9027  t-loss:0.3463, loss-lb:0.2701, loss-ulb:0.0381, weight:2.00, lr:0.0004
[04:44:25.715] iteration:9028  t-loss:0.2201, loss-lb:0.1700, loss-ulb:0.0250, weight:2.00, lr:0.0004
[04:44:26.038] iteration:9029  t-loss:0.5095, loss-lb:0.2151, loss-ulb:0.1472, weight:2.00, lr:0.0004
[04:44:26.357] iteration:9030  t-loss:0.2205, loss-lb:0.1655, loss-ulb:0.0275, weight:2.00, lr:0.0004
[04:44:26.672] iteration:9031  t-loss:0.2342, loss-lb:0.1726, loss-ulb:0.0308, weight:2.00, lr:0.0004
[04:44:27.000] iteration:9032  t-loss:0.3610, loss-lb:0.2440, loss-ulb:0.0585, weight:2.00, lr:0.0004
[04:44:27.329] iteration:9033  t-loss:0.2702, loss-lb:0.2299, loss-ulb:0.0201, weight:2.00, lr:0.0004
[04:44:27.653] iteration:9034  t-loss:0.2704, loss-lb:0.2311, loss-ulb:0.0197, weight:2.00, lr:0.0004
[04:44:27.979] iteration:9035  t-loss:0.2529, loss-lb:0.1934, loss-ulb:0.0297, weight:2.00, lr:0.0004
[04:44:28.305] iteration:9036  t-loss:0.3591, loss-lb:0.2224, loss-ulb:0.0684, weight:2.00, lr:0.0004
[04:44:28.625] iteration:9037  t-loss:0.3291, loss-lb:0.2918, loss-ulb:0.0187, weight:2.00, lr:0.0004
[04:44:28.942] iteration:9038  t-loss:0.2115, loss-lb:0.1750, loss-ulb:0.0182, weight:2.00, lr:0.0004
[04:44:29.269] iteration:9039  t-loss:0.4969, loss-lb:0.1661, loss-ulb:0.1654, weight:2.00, lr:0.0004
[04:44:29.594] iteration:9040  t-loss:0.2316, loss-lb:0.1590, loss-ulb:0.0363, weight:2.00, lr:0.0004
[04:44:29.917] iteration:9041  t-loss:0.4865, loss-lb:0.2377, loss-ulb:0.1244, weight:2.00, lr:0.0004
[04:44:30.240] iteration:9042  t-loss:0.4044, loss-lb:0.2539, loss-ulb:0.0752, weight:2.00, lr:0.0004
[04:44:30.553] iteration:9043  t-loss:0.2244, loss-lb:0.1671, loss-ulb:0.0286, weight:2.00, lr:0.0004
[04:44:30.876] iteration:9044  t-loss:0.4060, loss-lb:0.2420, loss-ulb:0.0820, weight:2.00, lr:0.0004
[04:44:31.192] iteration:9045  t-loss:0.5854, loss-lb:0.2056, loss-ulb:0.1899, weight:2.00, lr:0.0004
[04:44:31.510] iteration:9046  t-loss:0.5955, loss-lb:0.2073, loss-ulb:0.1941, weight:2.00, lr:0.0004
[04:44:31.826] iteration:9047  t-loss:0.3611, loss-lb:0.1755, loss-ulb:0.0928, weight:2.00, lr:0.0004
[04:44:32.146] iteration:9048  t-loss:0.4755, loss-lb:0.3288, loss-ulb:0.0733, weight:2.00, lr:0.0004
[04:44:32.474] iteration:9049  t-loss:0.3641, loss-lb:0.1669, loss-ulb:0.0986, weight:2.00, lr:0.0004
[04:44:32.800] iteration:9050  t-loss:0.3162, loss-lb:0.1743, loss-ulb:0.0709, weight:2.00, lr:0.0004
[04:44:34.385] iteration:9051  t-loss:0.3827, loss-lb:0.2745, loss-ulb:0.0541, weight:2.00, lr:0.0004
[04:44:34.717] iteration:9052  t-loss:0.1729, loss-lb:0.1373, loss-ulb:0.0178, weight:2.00, lr:0.0004
[04:44:35.054] iteration:9053  t-loss:0.5238, loss-lb:0.1943, loss-ulb:0.1647, weight:2.00, lr:0.0004
[04:44:35.395] iteration:9054  t-loss:0.2064, loss-lb:0.1567, loss-ulb:0.0248, weight:2.00, lr:0.0004
[04:44:35.739] iteration:9055  t-loss:0.2907, loss-lb:0.2422, loss-ulb:0.0243, weight:2.00, lr:0.0004
[04:44:36.087] iteration:9056  t-loss:0.4426, loss-lb:0.1849, loss-ulb:0.1288, weight:2.00, lr:0.0004
[04:44:36.450] iteration:9057  t-loss:0.3542, loss-lb:0.2639, loss-ulb:0.0451, weight:2.00, lr:0.0004
[04:44:36.811] iteration:9058  t-loss:0.6115, loss-lb:0.2227, loss-ulb:0.1944, weight:2.00, lr:0.0004
[04:44:37.175] iteration:9059  t-loss:0.4707, loss-lb:0.2304, loss-ulb:0.1201, weight:2.00, lr:0.0004
[04:44:37.541] iteration:9060  t-loss:0.4908, loss-lb:0.2340, loss-ulb:0.1284, weight:2.00, lr:0.0004
[04:44:37.899] iteration:9061  t-loss:0.4415, loss-lb:0.1735, loss-ulb:0.1340, weight:2.00, lr:0.0004
[04:44:38.274] iteration:9062  t-loss:0.7216, loss-lb:0.3223, loss-ulb:0.1997, weight:2.00, lr:0.0004
[04:44:38.632] iteration:9063  t-loss:0.2773, loss-lb:0.2353, loss-ulb:0.0210, weight:2.00, lr:0.0004
[04:44:38.962] iteration:9064  t-loss:0.2231, loss-lb:0.1736, loss-ulb:0.0248, weight:2.00, lr:0.0004
[04:44:39.306] iteration:9065  t-loss:0.5180, loss-lb:0.2603, loss-ulb:0.1289, weight:2.00, lr:0.0004
[04:44:39.646] iteration:9066  t-loss:0.5674, loss-lb:0.2224, loss-ulb:0.1725, weight:2.00, lr:0.0004
[04:44:39.980] iteration:9067  t-loss:0.2964, loss-lb:0.1942, loss-ulb:0.0511, weight:2.00, lr:0.0004
[04:44:40.304] iteration:9068  t-loss:0.4589, loss-lb:0.2723, loss-ulb:0.0933, weight:2.00, lr:0.0004
[04:44:40.625] iteration:9069  t-loss:0.3297, loss-lb:0.2021, loss-ulb:0.0638, weight:2.00, lr:0.0004
[04:44:40.945] iteration:9070  t-loss:0.2251, loss-lb:0.1766, loss-ulb:0.0243, weight:2.00, lr:0.0004
[04:44:41.268] iteration:9071  t-loss:0.2786, loss-lb:0.2447, loss-ulb:0.0169, weight:2.00, lr:0.0004
[04:44:41.596] iteration:9072  t-loss:0.3991, loss-lb:0.2289, loss-ulb:0.0851, weight:2.00, lr:0.0004
[04:44:41.930] iteration:9073  t-loss:0.5035, loss-lb:0.2216, loss-ulb:0.1410, weight:2.00, lr:0.0004
[04:44:42.247] iteration:9074  t-loss:0.2432, loss-lb:0.2048, loss-ulb:0.0192, weight:2.00, lr:0.0004
[04:44:42.564] iteration:9075  t-loss:0.5624, loss-lb:0.1865, loss-ulb:0.1880, weight:2.00, lr:0.0004
[04:44:43.800] iteration:9076  t-loss:0.3818, loss-lb:0.2082, loss-ulb:0.0868, weight:2.00, lr:0.0004
[04:44:44.148] iteration:9077  t-loss:0.5054, loss-lb:0.2371, loss-ulb:0.1341, weight:2.00, lr:0.0004
[04:44:44.474] iteration:9078  t-loss:0.1907, loss-lb:0.1387, loss-ulb:0.0260, weight:2.00, lr:0.0004
[04:44:44.802] iteration:9079  t-loss:0.3895, loss-lb:0.1545, loss-ulb:0.1175, weight:2.00, lr:0.0004
[04:44:45.119] iteration:9080  t-loss:0.2042, loss-lb:0.1503, loss-ulb:0.0269, weight:2.00, lr:0.0004
[04:44:45.439] iteration:9081  t-loss:0.5876, loss-lb:0.2260, loss-ulb:0.1808, weight:2.00, lr:0.0004
[04:44:45.766] iteration:9082  t-loss:0.2867, loss-lb:0.1484, loss-ulb:0.0692, weight:2.00, lr:0.0004
[04:44:46.130] iteration:9083  t-loss:0.3464, loss-lb:0.2967, loss-ulb:0.0249, weight:2.00, lr:0.0004
[04:44:46.476] iteration:9084  t-loss:0.7024, loss-lb:0.2259, loss-ulb:0.2383, weight:2.00, lr:0.0004
[04:44:46.826] iteration:9085  t-loss:0.5345, loss-lb:0.2692, loss-ulb:0.1327, weight:2.00, lr:0.0004
[04:44:47.188] iteration:9086  t-loss:0.3571, loss-lb:0.2369, loss-ulb:0.0601, weight:2.00, lr:0.0004
[04:44:47.519] iteration:9087  t-loss:0.2715, loss-lb:0.1575, loss-ulb:0.0570, weight:2.00, lr:0.0004
[04:44:47.860] iteration:9088  t-loss:0.5493, loss-lb:0.2357, loss-ulb:0.1568, weight:2.00, lr:0.0004
[04:44:48.200] iteration:9089  t-loss:0.2980, loss-lb:0.1995, loss-ulb:0.0493, weight:2.00, lr:0.0004
[04:44:48.536] iteration:9090  t-loss:0.3624, loss-lb:0.1614, loss-ulb:0.1005, weight:2.00, lr:0.0004
[04:44:48.874] iteration:9091  t-loss:0.2933, loss-lb:0.1826, loss-ulb:0.0553, weight:2.00, lr:0.0004
[04:44:49.221] iteration:9092  t-loss:0.6176, loss-lb:0.3696, loss-ulb:0.1240, weight:2.00, lr:0.0004
[04:44:49.552] iteration:9093  t-loss:0.3057, loss-lb:0.1417, loss-ulb:0.0820, weight:2.00, lr:0.0004
[04:44:49.884] iteration:9094  t-loss:0.3712, loss-lb:0.2990, loss-ulb:0.0361, weight:2.00, lr:0.0004
[04:44:50.224] iteration:9095  t-loss:0.3674, loss-lb:0.2618, loss-ulb:0.0528, weight:2.00, lr:0.0004
[04:44:50.564] iteration:9096  t-loss:0.2558, loss-lb:0.1343, loss-ulb:0.0608, weight:2.00, lr:0.0004
[04:44:50.952] iteration:9097  t-loss:0.4793, loss-lb:0.1972, loss-ulb:0.1411, weight:2.00, lr:0.0004
[04:44:51.288] iteration:9098  t-loss:0.2032, loss-lb:0.1424, loss-ulb:0.0304, weight:2.00, lr:0.0004
[04:44:51.619] iteration:9099  t-loss:0.2642, loss-lb:0.2080, loss-ulb:0.0281, weight:2.00, lr:0.0004
[04:44:51.950] iteration:9100  t-loss:0.3656, loss-lb:0.2381, loss-ulb:0.0638, weight:2.00, lr:0.0004
[04:44:53.366] iteration:9101  t-loss:0.3306, loss-lb:0.2601, loss-ulb:0.0353, weight:2.00, lr:0.0004
[04:44:53.695] iteration:9102  t-loss:0.2427, loss-lb:0.1940, loss-ulb:0.0244, weight:2.00, lr:0.0004
[04:44:54.022] iteration:9103  t-loss:0.8931, loss-lb:0.1554, loss-ulb:0.3688, weight:2.00, lr:0.0004
[04:44:54.340] iteration:9104  t-loss:0.7530, loss-lb:0.2729, loss-ulb:0.2400, weight:2.00, lr:0.0004
[04:44:54.667] iteration:9105  t-loss:0.3882, loss-lb:0.1296, loss-ulb:0.1293, weight:2.00, lr:0.0004
[04:44:54.985] iteration:9106  t-loss:0.4618, loss-lb:0.1631, loss-ulb:0.1494, weight:2.00, lr:0.0004
[04:44:55.306] iteration:9107  t-loss:0.2134, loss-lb:0.1490, loss-ulb:0.0322, weight:2.00, lr:0.0004
[04:44:55.630] iteration:9108  t-loss:0.5422, loss-lb:0.1949, loss-ulb:0.1736, weight:2.00, lr:0.0004
[04:44:55.960] iteration:9109  t-loss:0.2368, loss-lb:0.1790, loss-ulb:0.0289, weight:2.00, lr:0.0004
[04:44:56.286] iteration:9110  t-loss:0.3895, loss-lb:0.2087, loss-ulb:0.0904, weight:2.00, lr:0.0004
[04:44:56.607] iteration:9111  t-loss:0.3774, loss-lb:0.2108, loss-ulb:0.0833, weight:2.00, lr:0.0004
[04:44:56.926] iteration:9112  t-loss:0.4951, loss-lb:0.4053, loss-ulb:0.0449, weight:2.00, lr:0.0004
[04:44:57.247] iteration:9113  t-loss:0.5270, loss-lb:0.3142, loss-ulb:0.1064, weight:2.00, lr:0.0004
[04:44:57.565] iteration:9114  t-loss:0.3764, loss-lb:0.1712, loss-ulb:0.1026, weight:2.00, lr:0.0004
[04:44:57.884] iteration:9115  t-loss:0.3116, loss-lb:0.2455, loss-ulb:0.0331, weight:2.00, lr:0.0004
[04:44:58.201] iteration:9116  t-loss:0.3804, loss-lb:0.2176, loss-ulb:0.0814, weight:2.00, lr:0.0004
[04:44:58.515] iteration:9117  t-loss:0.2213, loss-lb:0.1361, loss-ulb:0.0426, weight:2.00, lr:0.0004
[04:44:58.830] iteration:9118  t-loss:0.2669, loss-lb:0.2131, loss-ulb:0.0269, weight:2.00, lr:0.0004
[04:44:59.150] iteration:9119  t-loss:0.3781, loss-lb:0.3404, loss-ulb:0.0189, weight:2.00, lr:0.0004
[04:44:59.480] iteration:9120  t-loss:0.5269, loss-lb:0.2611, loss-ulb:0.1329, weight:2.00, lr:0.0004
[04:44:59.798] iteration:9121  t-loss:0.3549, loss-lb:0.1350, loss-ulb:0.1099, weight:2.00, lr:0.0004
[04:45:00.116] iteration:9122  t-loss:0.4184, loss-lb:0.2469, loss-ulb:0.0858, weight:2.00, lr:0.0004
[04:45:00.432] iteration:9123  t-loss:0.1869, loss-lb:0.1409, loss-ulb:0.0230, weight:2.00, lr:0.0004
[04:45:00.751] iteration:9124  t-loss:0.4932, loss-lb:0.2398, loss-ulb:0.1267, weight:2.00, lr:0.0004
[04:45:01.070] iteration:9125  t-loss:0.4839, loss-lb:0.3044, loss-ulb:0.0897, weight:2.00, lr:0.0004
[04:47:04.018] iteration 9125 : dice_score: 0.847181 best_dice: 0.848300
[04:47:04.018]  <<Test>> - Ep:364  - Dice-S/T:82.40/84.72, Best-S:84.60, Best-T:84.83
[04:47:04.018]           - AvgLoss(lb/ulb/all):0.22/0.08/0.38
[04:47:05.270] iteration:9126  t-loss:0.4934, loss-lb:0.1356, loss-ulb:0.1789, weight:2.00, lr:0.0004
[04:47:05.631] iteration:9127  t-loss:0.7588, loss-lb:0.1669, loss-ulb:0.2959, weight:2.00, lr:0.0004
[04:47:05.965] iteration:9128  t-loss:0.3197, loss-lb:0.2212, loss-ulb:0.0493, weight:2.00, lr:0.0004
[04:47:06.285] iteration:9129  t-loss:0.1824, loss-lb:0.1194, loss-ulb:0.0315, weight:2.00, lr:0.0004
[04:47:06.607] iteration:9130  t-loss:0.5307, loss-lb:0.3861, loss-ulb:0.0723, weight:2.00, lr:0.0004
[04:47:06.923] iteration:9131  t-loss:0.3659, loss-lb:0.1680, loss-ulb:0.0989, weight:2.00, lr:0.0004
[04:47:07.246] iteration:9132  t-loss:0.4391, loss-lb:0.2382, loss-ulb:0.1004, weight:2.00, lr:0.0004
[04:47:07.570] iteration:9133  t-loss:0.2458, loss-lb:0.1440, loss-ulb:0.0509, weight:2.00, lr:0.0004
[04:47:07.896] iteration:9134  t-loss:0.3366, loss-lb:0.2824, loss-ulb:0.0271, weight:2.00, lr:0.0004
[04:47:08.226] iteration:9135  t-loss:0.3360, loss-lb:0.1517, loss-ulb:0.0921, weight:2.00, lr:0.0004
[04:47:08.565] iteration:9136  t-loss:0.3242, loss-lb:0.1340, loss-ulb:0.0951, weight:2.00, lr:0.0004
[04:47:08.901] iteration:9137  t-loss:0.4661, loss-lb:0.2528, loss-ulb:0.1066, weight:2.00, lr:0.0004
[04:47:09.233] iteration:9138  t-loss:0.3431, loss-lb:0.1892, loss-ulb:0.0769, weight:2.00, lr:0.0004
[04:47:09.563] iteration:9139  t-loss:0.3911, loss-lb:0.2302, loss-ulb:0.0805, weight:2.00, lr:0.0004
[04:47:09.888] iteration:9140  t-loss:0.3663, loss-lb:0.2606, loss-ulb:0.0528, weight:2.00, lr:0.0004
[04:47:10.222] iteration:9141  t-loss:0.5071, loss-lb:0.3432, loss-ulb:0.0820, weight:2.00, lr:0.0004
[04:47:10.544] iteration:9142  t-loss:0.3836, loss-lb:0.3477, loss-ulb:0.0179, weight:2.00, lr:0.0004
[04:47:10.860] iteration:9143  t-loss:0.2442, loss-lb:0.1140, loss-ulb:0.0651, weight:2.00, lr:0.0004
[04:47:11.180] iteration:9144  t-loss:0.4037, loss-lb:0.2088, loss-ulb:0.0974, weight:2.00, lr:0.0004
[04:47:11.497] iteration:9145  t-loss:0.3164, loss-lb:0.2029, loss-ulb:0.0567, weight:2.00, lr:0.0004
[04:47:11.811] iteration:9146  t-loss:0.2145, loss-lb:0.1675, loss-ulb:0.0235, weight:2.00, lr:0.0004
[04:47:12.126] iteration:9147  t-loss:0.4507, loss-lb:0.1345, loss-ulb:0.1581, weight:2.00, lr:0.0004
[04:47:12.445] iteration:9148  t-loss:0.5134, loss-lb:0.3548, loss-ulb:0.0793, weight:2.00, lr:0.0004
[04:47:12.761] iteration:9149  t-loss:0.3758, loss-lb:0.2507, loss-ulb:0.0625, weight:2.00, lr:0.0004
[04:47:13.074] iteration:9150  t-loss:0.1986, loss-lb:0.1447, loss-ulb:0.0270, weight:2.00, lr:0.0004
[04:47:14.904] iteration:9151  t-loss:0.4296, loss-lb:0.2456, loss-ulb:0.0920, weight:2.00, lr:0.0004
[04:47:15.256] iteration:9152  t-loss:0.3944, loss-lb:0.1925, loss-ulb:0.1010, weight:2.00, lr:0.0004
[04:47:15.599] iteration:9153  t-loss:0.6395, loss-lb:0.2447, loss-ulb:0.1974, weight:2.00, lr:0.0004
[04:47:15.949] iteration:9154  t-loss:0.3680, loss-lb:0.2566, loss-ulb:0.0557, weight:2.00, lr:0.0004
[04:47:16.290] iteration:9155  t-loss:0.4459, loss-lb:0.2333, loss-ulb:0.1063, weight:2.00, lr:0.0004
[04:47:16.618] iteration:9156  t-loss:0.3302, loss-lb:0.1825, loss-ulb:0.0739, weight:2.00, lr:0.0004
[04:47:16.943] iteration:9157  t-loss:0.5373, loss-lb:0.3103, loss-ulb:0.1135, weight:2.00, lr:0.0004
[04:47:17.270] iteration:9158  t-loss:0.4382, loss-lb:0.2075, loss-ulb:0.1153, weight:2.00, lr:0.0004
[04:47:17.589] iteration:9159  t-loss:0.3540, loss-lb:0.1434, loss-ulb:0.1053, weight:2.00, lr:0.0004
[04:47:17.907] iteration:9160  t-loss:0.2300, loss-lb:0.1901, loss-ulb:0.0200, weight:2.00, lr:0.0004
[04:47:18.224] iteration:9161  t-loss:0.3373, loss-lb:0.1672, loss-ulb:0.0851, weight:2.00, lr:0.0004
[04:47:18.544] iteration:9162  t-loss:0.3709, loss-lb:0.3292, loss-ulb:0.0209, weight:2.00, lr:0.0004
[04:47:18.876] iteration:9163  t-loss:0.3827, loss-lb:0.1967, loss-ulb:0.0930, weight:2.00, lr:0.0004
[04:47:19.196] iteration:9164  t-loss:0.2697, loss-lb:0.1747, loss-ulb:0.0475, weight:2.00, lr:0.0004
[04:47:19.513] iteration:9165  t-loss:0.2858, loss-lb:0.2475, loss-ulb:0.0192, weight:2.00, lr:0.0004
[04:47:19.829] iteration:9166  t-loss:0.4780, loss-lb:0.4277, loss-ulb:0.0252, weight:2.00, lr:0.0004
[04:47:20.145] iteration:9167  t-loss:0.3066, loss-lb:0.2386, loss-ulb:0.0340, weight:2.00, lr:0.0004
[04:47:20.461] iteration:9168  t-loss:0.3988, loss-lb:0.1592, loss-ulb:0.1198, weight:2.00, lr:0.0004
[04:47:20.778] iteration:9169  t-loss:0.5338, loss-lb:0.1796, loss-ulb:0.1771, weight:2.00, lr:0.0004
[04:47:21.094] iteration:9170  t-loss:0.4201, loss-lb:0.2196, loss-ulb:0.1003, weight:2.00, lr:0.0004
[04:47:21.415] iteration:9171  t-loss:0.4932, loss-lb:0.2581, loss-ulb:0.1175, weight:2.00, lr:0.0004
[04:47:21.736] iteration:9172  t-loss:0.3273, loss-lb:0.2745, loss-ulb:0.0264, weight:2.00, lr:0.0004
[04:47:22.076] iteration:9173  t-loss:0.3092, loss-lb:0.1397, loss-ulb:0.0848, weight:2.00, lr:0.0004
[04:47:22.409] iteration:9174  t-loss:0.2414, loss-lb:0.1850, loss-ulb:0.0282, weight:2.00, lr:0.0004
[04:47:22.749] iteration:9175  t-loss:0.3673, loss-lb:0.2333, loss-ulb:0.0670, weight:2.00, lr:0.0004
[04:47:24.338] iteration:9176  t-loss:0.3137, loss-lb:0.1435, loss-ulb:0.0851, weight:2.00, lr:0.0004
[04:47:24.687] iteration:9177  t-loss:0.6158, loss-lb:0.4225, loss-ulb:0.0966, weight:2.00, lr:0.0004
[04:47:25.025] iteration:9178  t-loss:0.1747, loss-lb:0.1240, loss-ulb:0.0253, weight:2.00, lr:0.0004
[04:47:25.353] iteration:9179  t-loss:0.2408, loss-lb:0.1915, loss-ulb:0.0247, weight:2.00, lr:0.0004
[04:47:25.676] iteration:9180  t-loss:0.1525, loss-lb:0.1226, loss-ulb:0.0150, weight:2.00, lr:0.0004
[04:47:26.000] iteration:9181  t-loss:0.3527, loss-lb:0.1551, loss-ulb:0.0988, weight:2.00, lr:0.0004
[04:47:26.325] iteration:9182  t-loss:0.2371, loss-lb:0.2026, loss-ulb:0.0173, weight:2.00, lr:0.0004
[04:47:26.646] iteration:9183  t-loss:0.2816, loss-lb:0.1671, loss-ulb:0.0572, weight:2.00, lr:0.0004
[04:47:26.967] iteration:9184  t-loss:0.2038, loss-lb:0.1162, loss-ulb:0.0438, weight:2.00, lr:0.0004
[04:47:27.294] iteration:9185  t-loss:0.3222, loss-lb:0.1735, loss-ulb:0.0743, weight:2.00, lr:0.0004
[04:47:27.623] iteration:9186  t-loss:0.2986, loss-lb:0.2409, loss-ulb:0.0288, weight:2.00, lr:0.0004
[04:47:27.950] iteration:9187  t-loss:0.1925, loss-lb:0.1309, loss-ulb:0.0308, weight:2.00, lr:0.0004
[04:47:28.272] iteration:9188  t-loss:0.4189, loss-lb:0.1621, loss-ulb:0.1284, weight:2.00, lr:0.0004
[04:47:28.595] iteration:9189  t-loss:0.4772, loss-lb:0.2598, loss-ulb:0.1087, weight:2.00, lr:0.0004
[04:47:28.915] iteration:9190  t-loss:0.3994, loss-lb:0.2165, loss-ulb:0.0915, weight:2.00, lr:0.0004
[04:47:29.236] iteration:9191  t-loss:0.4119, loss-lb:0.3569, loss-ulb:0.0275, weight:2.00, lr:0.0004
[04:47:29.552] iteration:9192  t-loss:0.1829, loss-lb:0.1334, loss-ulb:0.0247, weight:2.00, lr:0.0004
[04:47:29.869] iteration:9193  t-loss:0.4509, loss-lb:0.2067, loss-ulb:0.1221, weight:2.00, lr:0.0004
[04:47:30.186] iteration:9194  t-loss:0.4508, loss-lb:0.2229, loss-ulb:0.1139, weight:2.00, lr:0.0004
[04:47:30.504] iteration:9195  t-loss:0.3006, loss-lb:0.1875, loss-ulb:0.0565, weight:2.00, lr:0.0004
[04:47:30.816] iteration:9196  t-loss:0.6268, loss-lb:0.1924, loss-ulb:0.2172, weight:2.00, lr:0.0004
[04:47:31.144] iteration:9197  t-loss:0.4453, loss-lb:0.2405, loss-ulb:0.1024, weight:2.00, lr:0.0004
[04:47:31.466] iteration:9198  t-loss:0.4611, loss-lb:0.3421, loss-ulb:0.0595, weight:2.00, lr:0.0004
[04:47:31.783] iteration:9199  t-loss:0.2523, loss-lb:0.1759, loss-ulb:0.0382, weight:2.00, lr:0.0004
[04:47:32.100] iteration:9200  t-loss:0.2301, loss-lb:0.1800, loss-ulb:0.0250, weight:2.00, lr:0.0004
[04:47:33.500] iteration:9201  t-loss:0.4619, loss-lb:0.3012, loss-ulb:0.0804, weight:2.00, lr:0.0004
[04:47:33.834] iteration:9202  t-loss:0.3227, loss-lb:0.1907, loss-ulb:0.0660, weight:2.00, lr:0.0004
[04:47:34.160] iteration:9203  t-loss:0.2801, loss-lb:0.1574, loss-ulb:0.0614, weight:2.00, lr:0.0004
[04:47:34.482] iteration:9204  t-loss:0.2167, loss-lb:0.1410, loss-ulb:0.0379, weight:2.00, lr:0.0004
[04:47:34.808] iteration:9205  t-loss:0.4222, loss-lb:0.2391, loss-ulb:0.0915, weight:2.00, lr:0.0004
[04:47:35.131] iteration:9206  t-loss:0.4272, loss-lb:0.1974, loss-ulb:0.1149, weight:2.00, lr:0.0004
[04:47:35.460] iteration:9207  t-loss:0.2986, loss-lb:0.2026, loss-ulb:0.0480, weight:2.00, lr:0.0004
[04:47:35.787] iteration:9208  t-loss:0.4971, loss-lb:0.2541, loss-ulb:0.1215, weight:2.00, lr:0.0004
[04:47:36.110] iteration:9209  t-loss:0.2237, loss-lb:0.1899, loss-ulb:0.0169, weight:2.00, lr:0.0004
[04:47:36.432] iteration:9210  t-loss:0.2510, loss-lb:0.2011, loss-ulb:0.0250, weight:2.00, lr:0.0004
[04:47:36.753] iteration:9211  t-loss:0.3376, loss-lb:0.2982, loss-ulb:0.0197, weight:2.00, lr:0.0004
[04:47:37.071] iteration:9212  t-loss:0.3175, loss-lb:0.1641, loss-ulb:0.0767, weight:2.00, lr:0.0004
[04:47:37.393] iteration:9213  t-loss:0.2812, loss-lb:0.2418, loss-ulb:0.0197, weight:2.00, lr:0.0004
[04:47:37.710] iteration:9214  t-loss:0.3532, loss-lb:0.2161, loss-ulb:0.0685, weight:2.00, lr:0.0004
[04:47:38.030] iteration:9215  t-loss:0.2864, loss-lb:0.1662, loss-ulb:0.0601, weight:2.00, lr:0.0004
[04:47:38.348] iteration:9216  t-loss:0.4795, loss-lb:0.3733, loss-ulb:0.0531, weight:2.00, lr:0.0004
[04:47:38.664] iteration:9217  t-loss:0.2473, loss-lb:0.1670, loss-ulb:0.0402, weight:2.00, lr:0.0004
[04:47:38.980] iteration:9218  t-loss:0.1578, loss-lb:0.1268, loss-ulb:0.0155, weight:2.00, lr:0.0004
[04:47:39.301] iteration:9219  t-loss:0.2071, loss-lb:0.1310, loss-ulb:0.0380, weight:2.00, lr:0.0004
[04:47:39.627] iteration:9220  t-loss:0.2903, loss-lb:0.2565, loss-ulb:0.0169, weight:2.00, lr:0.0004
[04:47:39.956] iteration:9221  t-loss:0.2531, loss-lb:0.2130, loss-ulb:0.0201, weight:2.00, lr:0.0004
[04:47:40.289] iteration:9222  t-loss:0.2315, loss-lb:0.1553, loss-ulb:0.0381, weight:2.00, lr:0.0004
[04:47:40.612] iteration:9223  t-loss:0.6042, loss-lb:0.1982, loss-ulb:0.2030, weight:2.00, lr:0.0004
[04:47:40.928] iteration:9224  t-loss:0.5223, loss-lb:0.1435, loss-ulb:0.1894, weight:2.00, lr:0.0004
[04:47:41.249] iteration:9225  t-loss:0.4867, loss-lb:0.2228, loss-ulb:0.1320, weight:2.00, lr:0.0004
[04:49:46.244] iteration 9225 : dice_score: 0.848308 best_dice: 0.848300
[04:49:46.244]  <<Test>> - Ep:368  - Dice-S/T:84.86/84.83, Best-S:84.86, Best-T:84.83
[04:49:46.244]           - AvgLoss(lb/ulb/all):0.21/0.07/0.34
[04:49:47.646] iteration:9226  t-loss:0.1559, loss-lb:0.1218, loss-ulb:0.0171, weight:2.00, lr:0.0004
[04:49:47.980] iteration:9227  t-loss:0.4502, loss-lb:0.3120, loss-ulb:0.0691, weight:2.00, lr:0.0004
[04:49:48.315] iteration:9228  t-loss:0.6720, loss-lb:0.2617, loss-ulb:0.2052, weight:2.00, lr:0.0004
[04:49:48.646] iteration:9229  t-loss:0.5385, loss-lb:0.2569, loss-ulb:0.1408, weight:2.00, lr:0.0004
[04:49:48.980] iteration:9230  t-loss:0.3589, loss-lb:0.1698, loss-ulb:0.0945, weight:2.00, lr:0.0004
[04:49:49.297] iteration:9231  t-loss:0.2110, loss-lb:0.1525, loss-ulb:0.0293, weight:2.00, lr:0.0004
[04:49:49.617] iteration:9232  t-loss:0.4442, loss-lb:0.1622, loss-ulb:0.1410, weight:2.00, lr:0.0004
[04:49:49.941] iteration:9233  t-loss:0.3029, loss-lb:0.2433, loss-ulb:0.0298, weight:2.00, lr:0.0004
[04:49:50.261] iteration:9234  t-loss:0.2995, loss-lb:0.2188, loss-ulb:0.0403, weight:2.00, lr:0.0004
[04:49:50.578] iteration:9235  t-loss:0.2212, loss-lb:0.1595, loss-ulb:0.0308, weight:2.00, lr:0.0004
[04:49:50.900] iteration:9236  t-loss:0.6091, loss-lb:0.3545, loss-ulb:0.1273, weight:2.00, lr:0.0004
[04:49:51.218] iteration:9237  t-loss:0.3780, loss-lb:0.1661, loss-ulb:0.1060, weight:2.00, lr:0.0004
[04:49:51.537] iteration:9238  t-loss:0.4027, loss-lb:0.3623, loss-ulb:0.0202, weight:2.00, lr:0.0004
[04:49:51.855] iteration:9239  t-loss:0.2119, loss-lb:0.1699, loss-ulb:0.0210, weight:2.00, lr:0.0004
[04:49:52.175] iteration:9240  t-loss:0.2498, loss-lb:0.2201, loss-ulb:0.0148, weight:2.00, lr:0.0004
[04:49:52.497] iteration:9241  t-loss:0.6849, loss-lb:0.2496, loss-ulb:0.2177, weight:2.00, lr:0.0004
[04:49:52.816] iteration:9242  t-loss:0.2460, loss-lb:0.1552, loss-ulb:0.0454, weight:2.00, lr:0.0004
[04:49:53.129] iteration:9243  t-loss:0.2184, loss-lb:0.1603, loss-ulb:0.0290, weight:2.00, lr:0.0004
[04:49:53.443] iteration:9244  t-loss:0.2100, loss-lb:0.1639, loss-ulb:0.0231, weight:2.00, lr:0.0004
[04:49:53.761] iteration:9245  t-loss:0.4055, loss-lb:0.2792, loss-ulb:0.0631, weight:2.00, lr:0.0004
[04:49:54.077] iteration:9246  t-loss:0.3044, loss-lb:0.1464, loss-ulb:0.0790, weight:2.00, lr:0.0004
[04:49:54.390] iteration:9247  t-loss:0.3362, loss-lb:0.3059, loss-ulb:0.0151, weight:2.00, lr:0.0004
[04:49:54.709] iteration:9248  t-loss:0.6958, loss-lb:0.2608, loss-ulb:0.2175, weight:2.00, lr:0.0004
[04:49:55.024] iteration:9249  t-loss:0.1765, loss-lb:0.1448, loss-ulb:0.0158, weight:2.00, lr:0.0004
[04:49:55.342] iteration:9250  t-loss:0.2959, loss-lb:0.2541, loss-ulb:0.0209, weight:2.00, lr:0.0004
[04:49:56.730] iteration:9251  t-loss:0.1967, loss-lb:0.1617, loss-ulb:0.0175, weight:2.00, lr:0.0004
[04:49:57.055] iteration:9252  t-loss:0.2837, loss-lb:0.1746, loss-ulb:0.0546, weight:2.00, lr:0.0004
[04:49:57.390] iteration:9253  t-loss:0.4525, loss-lb:0.3273, loss-ulb:0.0626, weight:2.00, lr:0.0004
[04:49:57.711] iteration:9254  t-loss:0.1862, loss-lb:0.1312, loss-ulb:0.0275, weight:2.00, lr:0.0004
[04:49:58.035] iteration:9255  t-loss:0.4548, loss-lb:0.1748, loss-ulb:0.1400, weight:2.00, lr:0.0004
[04:49:58.358] iteration:9256  t-loss:0.4926, loss-lb:0.1553, loss-ulb:0.1686, weight:2.00, lr:0.0004
[04:49:58.681] iteration:9257  t-loss:0.2865, loss-lb:0.2301, loss-ulb:0.0282, weight:2.00, lr:0.0004
[04:49:59.005] iteration:9258  t-loss:0.3595, loss-lb:0.1349, loss-ulb:0.1123, weight:2.00, lr:0.0004
[04:49:59.327] iteration:9259  t-loss:0.4470, loss-lb:0.2380, loss-ulb:0.1045, weight:2.00, lr:0.0004
[04:49:59.646] iteration:9260  t-loss:0.5063, loss-lb:0.2515, loss-ulb:0.1274, weight:2.00, lr:0.0004
[04:49:59.965] iteration:9261  t-loss:0.2042, loss-lb:0.1434, loss-ulb:0.0304, weight:2.00, lr:0.0004
[04:50:00.286] iteration:9262  t-loss:0.2113, loss-lb:0.1541, loss-ulb:0.0286, weight:2.00, lr:0.0004
[04:50:00.603] iteration:9263  t-loss:0.2676, loss-lb:0.2033, loss-ulb:0.0321, weight:2.00, lr:0.0004
[04:50:00.918] iteration:9264  t-loss:0.1815, loss-lb:0.1375, loss-ulb:0.0220, weight:2.00, lr:0.0004
[04:50:01.243] iteration:9265  t-loss:0.3046, loss-lb:0.1702, loss-ulb:0.0672, weight:2.00, lr:0.0004
[04:50:01.568] iteration:9266  t-loss:0.3672, loss-lb:0.2104, loss-ulb:0.0784, weight:2.00, lr:0.0004
[04:50:01.894] iteration:9267  t-loss:0.3171, loss-lb:0.2042, loss-ulb:0.0564, weight:2.00, lr:0.0004
[04:50:02.221] iteration:9268  t-loss:0.6053, loss-lb:0.1643, loss-ulb:0.2205, weight:2.00, lr:0.0004
[04:50:02.549] iteration:9269  t-loss:0.2289, loss-lb:0.1675, loss-ulb:0.0307, weight:2.00, lr:0.0004
[04:50:02.885] iteration:9270  t-loss:0.3488, loss-lb:0.2139, loss-ulb:0.0674, weight:2.00, lr:0.0004
[04:50:03.203] iteration:9271  t-loss:0.3755, loss-lb:0.2092, loss-ulb:0.0832, weight:2.00, lr:0.0004
[04:50:03.524] iteration:9272  t-loss:0.3220, loss-lb:0.1892, loss-ulb:0.0664, weight:2.00, lr:0.0004
[04:50:03.840] iteration:9273  t-loss:0.1998, loss-lb:0.1481, loss-ulb:0.0258, weight:2.00, lr:0.0004
[04:50:04.157] iteration:9274  t-loss:0.3719, loss-lb:0.1598, loss-ulb:0.1060, weight:2.00, lr:0.0004
[04:50:04.475] iteration:9275  t-loss:0.3091, loss-lb:0.1987, loss-ulb:0.0552, weight:2.00, lr:0.0004
[04:50:05.984] iteration:9276  t-loss:0.2680, loss-lb:0.2398, loss-ulb:0.0141, weight:2.00, lr:0.0004
[04:50:06.320] iteration:9277  t-loss:0.2839, loss-lb:0.1839, loss-ulb:0.0500, weight:2.00, lr:0.0004
[04:50:06.656] iteration:9278  t-loss:0.6015, loss-lb:0.3983, loss-ulb:0.1016, weight:2.00, lr:0.0004
[04:50:06.997] iteration:9279  t-loss:0.5890, loss-lb:0.1706, loss-ulb:0.2092, weight:2.00, lr:0.0004
[04:50:07.329] iteration:9280  t-loss:0.3674, loss-lb:0.1713, loss-ulb:0.0980, weight:2.00, lr:0.0004
[04:50:07.659] iteration:9281  t-loss:0.3070, loss-lb:0.2294, loss-ulb:0.0388, weight:2.00, lr:0.0004
[04:50:07.984] iteration:9282  t-loss:0.2765, loss-lb:0.1941, loss-ulb:0.0412, weight:2.00, lr:0.0004
[04:50:08.303] iteration:9283  t-loss:0.5329, loss-lb:0.2485, loss-ulb:0.1422, weight:2.00, lr:0.0004
[04:50:08.624] iteration:9284  t-loss:0.2978, loss-lb:0.2154, loss-ulb:0.0412, weight:2.00, lr:0.0004
[04:50:08.945] iteration:9285  t-loss:0.8205, loss-lb:0.2604, loss-ulb:0.2800, weight:2.00, lr:0.0004
[04:50:09.264] iteration:9286  t-loss:0.3297, loss-lb:0.1543, loss-ulb:0.0877, weight:2.00, lr:0.0004
[04:50:09.580] iteration:9287  t-loss:0.2079, loss-lb:0.1263, loss-ulb:0.0408, weight:2.00, lr:0.0004
[04:50:09.898] iteration:9288  t-loss:0.3292, loss-lb:0.2813, loss-ulb:0.0240, weight:2.00, lr:0.0004
[04:50:10.214] iteration:9289  t-loss:0.2003, loss-lb:0.1518, loss-ulb:0.0243, weight:2.00, lr:0.0004
[04:50:10.538] iteration:9290  t-loss:0.2151, loss-lb:0.1557, loss-ulb:0.0297, weight:2.00, lr:0.0004
[04:50:10.872] iteration:9291  t-loss:0.4582, loss-lb:0.2952, loss-ulb:0.0815, weight:2.00, lr:0.0004
[04:50:11.209] iteration:9292  t-loss:0.3831, loss-lb:0.1203, loss-ulb:0.1314, weight:2.00, lr:0.0004
[04:50:11.542] iteration:9293  t-loss:0.5800, loss-lb:0.4036, loss-ulb:0.0882, weight:2.00, lr:0.0004
[04:50:11.868] iteration:9294  t-loss:0.3695, loss-lb:0.2371, loss-ulb:0.0662, weight:2.00, lr:0.0004
[04:50:12.187] iteration:9295  t-loss:0.2767, loss-lb:0.1626, loss-ulb:0.0570, weight:2.00, lr:0.0004
[04:50:12.506] iteration:9296  t-loss:0.3687, loss-lb:0.2058, loss-ulb:0.0815, weight:2.00, lr:0.0004
[04:50:12.829] iteration:9297  t-loss:0.3816, loss-lb:0.2238, loss-ulb:0.0789, weight:2.00, lr:0.0004
[04:50:13.149] iteration:9298  t-loss:0.8913, loss-lb:0.1633, loss-ulb:0.3640, weight:2.00, lr:0.0004
[04:50:13.480] iteration:9299  t-loss:0.4408, loss-lb:0.3059, loss-ulb:0.0675, weight:2.00, lr:0.0004
[04:50:13.802] iteration:9300  t-loss:0.3977, loss-lb:0.1804, loss-ulb:0.1087, weight:2.00, lr:0.0004
[04:50:15.612] iteration:9301  t-loss:0.3968, loss-lb:0.3305, loss-ulb:0.0331, weight:2.00, lr:0.0004
[04:50:15.955] iteration:9302  t-loss:0.3423, loss-lb:0.1467, loss-ulb:0.0978, weight:2.00, lr:0.0004
[04:50:16.288] iteration:9303  t-loss:0.4759, loss-lb:0.1636, loss-ulb:0.1561, weight:2.00, lr:0.0004
[04:50:16.625] iteration:9304  t-loss:0.5278, loss-lb:0.2212, loss-ulb:0.1533, weight:2.00, lr:0.0004
[04:50:16.951] iteration:9305  t-loss:0.3466, loss-lb:0.2229, loss-ulb:0.0618, weight:2.00, lr:0.0004
[04:50:17.270] iteration:9306  t-loss:0.4094, loss-lb:0.1423, loss-ulb:0.1335, weight:2.00, lr:0.0004
[04:50:17.588] iteration:9307  t-loss:0.5694, loss-lb:0.1899, loss-ulb:0.1897, weight:2.00, lr:0.0004
[04:50:17.909] iteration:9308  t-loss:0.3091, loss-lb:0.2004, loss-ulb:0.0543, weight:2.00, lr:0.0004
[04:50:18.229] iteration:9309  t-loss:0.2231, loss-lb:0.1527, loss-ulb:0.0352, weight:2.00, lr:0.0004
[04:50:18.554] iteration:9310  t-loss:0.4168, loss-lb:0.2218, loss-ulb:0.0975, weight:2.00, lr:0.0004
[04:50:18.870] iteration:9311  t-loss:0.2325, loss-lb:0.1612, loss-ulb:0.0356, weight:2.00, lr:0.0004
[04:50:19.189] iteration:9312  t-loss:0.2154, loss-lb:0.1646, loss-ulb:0.0254, weight:2.00, lr:0.0004
[04:50:19.518] iteration:9313  t-loss:0.2018, loss-lb:0.1748, loss-ulb:0.0135, weight:2.00, lr:0.0004
[04:50:19.850] iteration:9314  t-loss:0.2654, loss-lb:0.1347, loss-ulb:0.0654, weight:2.00, lr:0.0004
[04:50:20.181] iteration:9315  t-loss:0.2536, loss-lb:0.1531, loss-ulb:0.0503, weight:2.00, lr:0.0004
[04:50:20.520] iteration:9316  t-loss:0.4890, loss-lb:0.2051, loss-ulb:0.1419, weight:2.00, lr:0.0004
[04:50:20.849] iteration:9317  t-loss:0.3895, loss-lb:0.2614, loss-ulb:0.0641, weight:2.00, lr:0.0004
[04:50:21.166] iteration:9318  t-loss:0.1942, loss-lb:0.1268, loss-ulb:0.0337, weight:2.00, lr:0.0004
[04:50:21.481] iteration:9319  t-loss:0.3456, loss-lb:0.1299, loss-ulb:0.1078, weight:2.00, lr:0.0004
[04:50:21.797] iteration:9320  t-loss:0.2575, loss-lb:0.1659, loss-ulb:0.0458, weight:2.00, lr:0.0004
[04:50:22.116] iteration:9321  t-loss:0.4824, loss-lb:0.2014, loss-ulb:0.1405, weight:2.00, lr:0.0004
[04:50:22.430] iteration:9322  t-loss:0.1866, loss-lb:0.1502, loss-ulb:0.0182, weight:2.00, lr:0.0004
[04:50:22.748] iteration:9323  t-loss:0.3679, loss-lb:0.1849, loss-ulb:0.0915, weight:2.00, lr:0.0004
[04:50:23.063] iteration:9324  t-loss:0.3453, loss-lb:0.1585, loss-ulb:0.0934, weight:2.00, lr:0.0004
[04:50:23.381] iteration:9325  t-loss:0.5436, loss-lb:0.1659, loss-ulb:0.1888, weight:2.00, lr:0.0004
[04:52:43.241] iteration 9325 : dice_score: 0.850326 best_dice: 0.850300
[04:52:43.242]  <<Test>> - Ep:372  - Dice-S/T:84.40/85.03, Best-S:84.86, Best-T:85.03
[04:52:43.242]           - AvgLoss(lb/ulb/all):0.18/0.08/0.33
[04:52:44.588] iteration:9326  t-loss:0.3316, loss-lb:0.2209, loss-ulb:0.0553, weight:2.00, lr:0.0004
[04:52:44.926] iteration:9327  t-loss:0.2145, loss-lb:0.1596, loss-ulb:0.0274, weight:2.00, lr:0.0004
[04:52:45.249] iteration:9328  t-loss:0.2763, loss-lb:0.1878, loss-ulb:0.0442, weight:2.00, lr:0.0004
[04:52:45.570] iteration:9329  t-loss:0.5620, loss-lb:0.2361, loss-ulb:0.1629, weight:2.00, lr:0.0004
[04:52:45.889] iteration:9330  t-loss:0.4090, loss-lb:0.1840, loss-ulb:0.1125, weight:2.00, lr:0.0004
[04:52:46.214] iteration:9331  t-loss:0.3333, loss-lb:0.2575, loss-ulb:0.0379, weight:2.00, lr:0.0004
[04:52:46.532] iteration:9332  t-loss:0.2170, loss-lb:0.1484, loss-ulb:0.0343, weight:2.00, lr:0.0004
[04:52:46.850] iteration:9333  t-loss:0.1678, loss-lb:0.1246, loss-ulb:0.0216, weight:2.00, lr:0.0004
[04:52:47.168] iteration:9334  t-loss:0.2551, loss-lb:0.2220, loss-ulb:0.0165, weight:2.00, lr:0.0004
[04:52:47.482] iteration:9335  t-loss:0.2123, loss-lb:0.1766, loss-ulb:0.0178, weight:2.00, lr:0.0004
[04:52:47.798] iteration:9336  t-loss:0.2599, loss-lb:0.2256, loss-ulb:0.0172, weight:2.00, lr:0.0004
[04:52:48.120] iteration:9337  t-loss:0.3247, loss-lb:0.2711, loss-ulb:0.0268, weight:2.00, lr:0.0004
[04:52:48.439] iteration:9338  t-loss:0.3434, loss-lb:0.2389, loss-ulb:0.0522, weight:2.00, lr:0.0004
[04:52:48.758] iteration:9339  t-loss:0.2612, loss-lb:0.2129, loss-ulb:0.0242, weight:2.00, lr:0.0004
[04:52:49.078] iteration:9340  t-loss:0.5050, loss-lb:0.3231, loss-ulb:0.0909, weight:2.00, lr:0.0004
[04:52:49.399] iteration:9341  t-loss:0.3678, loss-lb:0.1449, loss-ulb:0.1114, weight:2.00, lr:0.0004
[04:52:49.717] iteration:9342  t-loss:0.2870, loss-lb:0.1620, loss-ulb:0.0625, weight:2.00, lr:0.0004
[04:52:50.041] iteration:9343  t-loss:0.4572, loss-lb:0.2453, loss-ulb:0.1059, weight:2.00, lr:0.0004
[04:52:50.359] iteration:9344  t-loss:0.5800, loss-lb:0.3925, loss-ulb:0.0938, weight:2.00, lr:0.0004
[04:52:50.675] iteration:9345  t-loss:0.2080, loss-lb:0.1385, loss-ulb:0.0347, weight:2.00, lr:0.0004
[04:52:50.992] iteration:9346  t-loss:0.3237, loss-lb:0.2286, loss-ulb:0.0475, weight:2.00, lr:0.0004
[04:52:51.309] iteration:9347  t-loss:0.3892, loss-lb:0.2062, loss-ulb:0.0915, weight:2.00, lr:0.0004
[04:52:51.623] iteration:9348  t-loss:0.2038, loss-lb:0.1527, loss-ulb:0.0256, weight:2.00, lr:0.0004
[04:52:51.939] iteration:9349  t-loss:0.3379, loss-lb:0.2493, loss-ulb:0.0443, weight:2.00, lr:0.0004
[04:52:52.255] iteration:9350  t-loss:0.2900, loss-lb:0.1546, loss-ulb:0.0677, weight:2.00, lr:0.0004
[04:52:53.547] iteration:9351  t-loss:0.4435, loss-lb:0.1369, loss-ulb:0.1533, weight:2.00, lr:0.0004
[04:52:53.883] iteration:9352  t-loss:0.3224, loss-lb:0.2007, loss-ulb:0.0609, weight:2.00, lr:0.0004
[04:52:54.216] iteration:9353  t-loss:0.4623, loss-lb:0.3326, loss-ulb:0.0649, weight:2.00, lr:0.0004
[04:52:54.537] iteration:9354  t-loss:0.2913, loss-lb:0.1549, loss-ulb:0.0682, weight:2.00, lr:0.0004
[04:52:54.855] iteration:9355  t-loss:0.6887, loss-lb:0.2636, loss-ulb:0.2125, weight:2.00, lr:0.0004
[04:52:55.171] iteration:9356  t-loss:0.3056, loss-lb:0.2532, loss-ulb:0.0262, weight:2.00, lr:0.0004
[04:52:55.488] iteration:9357  t-loss:0.2125, loss-lb:0.1754, loss-ulb:0.0185, weight:2.00, lr:0.0004
[04:52:55.804] iteration:9358  t-loss:0.3618, loss-lb:0.3208, loss-ulb:0.0205, weight:2.00, lr:0.0004
[04:52:56.119] iteration:9359  t-loss:0.2133, loss-lb:0.1782, loss-ulb:0.0175, weight:2.00, lr:0.0004
[04:52:56.435] iteration:9360  t-loss:0.2268, loss-lb:0.1361, loss-ulb:0.0453, weight:2.00, lr:0.0004
[04:52:56.754] iteration:9361  t-loss:0.1749, loss-lb:0.1513, loss-ulb:0.0118, weight:2.00, lr:0.0004
[04:52:57.072] iteration:9362  t-loss:0.2442, loss-lb:0.1905, loss-ulb:0.0268, weight:2.00, lr:0.0004
[04:52:57.389] iteration:9363  t-loss:0.2699, loss-lb:0.1881, loss-ulb:0.0409, weight:2.00, lr:0.0004
[04:52:57.710] iteration:9364  t-loss:0.9558, loss-lb:0.1650, loss-ulb:0.3954, weight:2.00, lr:0.0004
[04:52:58.029] iteration:9365  t-loss:0.2707, loss-lb:0.1465, loss-ulb:0.0621, weight:2.00, lr:0.0004
[04:52:58.348] iteration:9366  t-loss:0.4857, loss-lb:0.4499, loss-ulb:0.0179, weight:2.00, lr:0.0004
[04:52:58.674] iteration:9367  t-loss:0.2560, loss-lb:0.2060, loss-ulb:0.0250, weight:2.00, lr:0.0004
[04:52:59.008] iteration:9368  t-loss:0.4588, loss-lb:0.1864, loss-ulb:0.1362, weight:2.00, lr:0.0004
[04:52:59.332] iteration:9369  t-loss:0.2547, loss-lb:0.1954, loss-ulb:0.0296, weight:2.00, lr:0.0004
[04:52:59.654] iteration:9370  t-loss:0.3923, loss-lb:0.2595, loss-ulb:0.0664, weight:2.00, lr:0.0004
[04:52:59.973] iteration:9371  t-loss:0.9601, loss-lb:0.2372, loss-ulb:0.3614, weight:2.00, lr:0.0004
[04:53:00.293] iteration:9372  t-loss:0.4737, loss-lb:0.2383, loss-ulb:0.1177, weight:2.00, lr:0.0004
[04:53:00.619] iteration:9373  t-loss:0.5578, loss-lb:0.3621, loss-ulb:0.0979, weight:2.00, lr:0.0004
[04:53:00.932] iteration:9374  t-loss:0.2370, loss-lb:0.1709, loss-ulb:0.0331, weight:2.00, lr:0.0004
[04:53:01.247] iteration:9375  t-loss:0.2437, loss-lb:0.1248, loss-ulb:0.0594, weight:2.00, lr:0.0004
[04:53:02.853] iteration:9376  t-loss:0.2535, loss-lb:0.1950, loss-ulb:0.0292, weight:2.00, lr:0.0004
[04:53:03.195] iteration:9377  t-loss:0.3501, loss-lb:0.1637, loss-ulb:0.0932, weight:2.00, lr:0.0004
[04:53:03.529] iteration:9378  t-loss:0.2648, loss-lb:0.2278, loss-ulb:0.0185, weight:2.00, lr:0.0004
[04:53:03.866] iteration:9379  t-loss:0.4720, loss-lb:0.3174, loss-ulb:0.0773, weight:2.00, lr:0.0004
[04:53:04.203] iteration:9380  t-loss:0.3275, loss-lb:0.1436, loss-ulb:0.0919, weight:2.00, lr:0.0004
[04:53:04.535] iteration:9381  t-loss:0.4802, loss-lb:0.2416, loss-ulb:0.1193, weight:2.00, lr:0.0004
[04:53:04.857] iteration:9382  t-loss:0.1860, loss-lb:0.1325, loss-ulb:0.0267, weight:2.00, lr:0.0004
[04:53:05.176] iteration:9383  t-loss:0.1900, loss-lb:0.1443, loss-ulb:0.0228, weight:2.00, lr:0.0004
[04:53:05.492] iteration:9384  t-loss:0.2424, loss-lb:0.1427, loss-ulb:0.0498, weight:2.00, lr:0.0004
[04:53:05.814] iteration:9385  t-loss:0.5191, loss-lb:0.2811, loss-ulb:0.1190, weight:2.00, lr:0.0004
[04:53:06.136] iteration:9386  t-loss:0.7165, loss-lb:0.4526, loss-ulb:0.1319, weight:2.00, lr:0.0004
[04:53:06.470] iteration:9387  t-loss:0.2288, loss-lb:0.1886, loss-ulb:0.0201, weight:2.00, lr:0.0004
[04:53:06.789] iteration:9388  t-loss:0.4256, loss-lb:0.2394, loss-ulb:0.0931, weight:2.00, lr:0.0004
[04:53:07.109] iteration:9389  t-loss:0.2557, loss-lb:0.1903, loss-ulb:0.0327, weight:2.00, lr:0.0004
[04:53:07.433] iteration:9390  t-loss:0.3522, loss-lb:0.1604, loss-ulb:0.0959, weight:2.00, lr:0.0004
[04:53:07.760] iteration:9391  t-loss:0.3017, loss-lb:0.1358, loss-ulb:0.0829, weight:2.00, lr:0.0004
[04:53:08.098] iteration:9392  t-loss:0.3611, loss-lb:0.2269, loss-ulb:0.0671, weight:2.00, lr:0.0004
[04:53:08.441] iteration:9393  t-loss:0.2938, loss-lb:0.2327, loss-ulb:0.0305, weight:2.00, lr:0.0004
[04:53:08.767] iteration:9394  t-loss:0.3321, loss-lb:0.1961, loss-ulb:0.0680, weight:2.00, lr:0.0004
[04:53:09.095] iteration:9395  t-loss:0.3754, loss-lb:0.1603, loss-ulb:0.1075, weight:2.00, lr:0.0004
[04:53:09.416] iteration:9396  t-loss:0.1908, loss-lb:0.1142, loss-ulb:0.0383, weight:2.00, lr:0.0004
[04:53:09.733] iteration:9397  t-loss:0.3344, loss-lb:0.1813, loss-ulb:0.0766, weight:2.00, lr:0.0004
[04:53:10.052] iteration:9398  t-loss:0.2802, loss-lb:0.2023, loss-ulb:0.0389, weight:2.00, lr:0.0004
[04:53:10.370] iteration:9399  t-loss:0.3302, loss-lb:0.2088, loss-ulb:0.0607, weight:2.00, lr:0.0004
[04:53:10.689] iteration:9400  t-loss:0.3182, loss-lb:0.2244, loss-ulb:0.0469, weight:2.00, lr:0.0004
[04:53:12.152] iteration:9401  t-loss:0.4663, loss-lb:0.1320, loss-ulb:0.1671, weight:2.00, lr:0.0004
[04:53:12.502] iteration:9402  t-loss:0.4589, loss-lb:0.2446, loss-ulb:0.1071, weight:2.00, lr:0.0004
[04:53:12.843] iteration:9403  t-loss:0.4414, loss-lb:0.2510, loss-ulb:0.0952, weight:2.00, lr:0.0004
[04:53:13.181] iteration:9404  t-loss:0.4391, loss-lb:0.1972, loss-ulb:0.1209, weight:2.00, lr:0.0004
[04:53:13.511] iteration:9405  t-loss:0.2890, loss-lb:0.1567, loss-ulb:0.0661, weight:2.00, lr:0.0004
[04:53:13.841] iteration:9406  t-loss:0.3531, loss-lb:0.1408, loss-ulb:0.1062, weight:2.00, lr:0.0004
[04:53:14.172] iteration:9407  t-loss:0.2748, loss-lb:0.2240, loss-ulb:0.0254, weight:2.00, lr:0.0004
[04:53:14.491] iteration:9408  t-loss:0.6425, loss-lb:0.3091, loss-ulb:0.1667, weight:2.00, lr:0.0004
[04:53:14.809] iteration:9409  t-loss:0.2342, loss-lb:0.1824, loss-ulb:0.0259, weight:2.00, lr:0.0004
[04:53:15.139] iteration:9410  t-loss:0.3025, loss-lb:0.1421, loss-ulb:0.0802, weight:2.00, lr:0.0004
[04:53:15.472] iteration:9411  t-loss:0.3584, loss-lb:0.3078, loss-ulb:0.0253, weight:2.00, lr:0.0004
[04:53:15.816] iteration:9412  t-loss:0.3465, loss-lb:0.2161, loss-ulb:0.0652, weight:2.00, lr:0.0004
[04:53:16.164] iteration:9413  t-loss:0.6082, loss-lb:0.3959, loss-ulb:0.1061, weight:2.00, lr:0.0004
[04:53:16.493] iteration:9414  t-loss:0.1784, loss-lb:0.1317, loss-ulb:0.0234, weight:2.00, lr:0.0004
[04:53:16.846] iteration:9415  t-loss:0.2739, loss-lb:0.2020, loss-ulb:0.0359, weight:2.00, lr:0.0004
[04:53:17.198] iteration:9416  t-loss:0.2949, loss-lb:0.1420, loss-ulb:0.0764, weight:2.00, lr:0.0004
[04:53:17.560] iteration:9417  t-loss:0.4094, loss-lb:0.2371, loss-ulb:0.0862, weight:2.00, lr:0.0004
[04:53:17.892] iteration:9418  t-loss:0.1956, loss-lb:0.1564, loss-ulb:0.0196, weight:2.00, lr:0.0004
[04:53:18.232] iteration:9419  t-loss:0.2716, loss-lb:0.2278, loss-ulb:0.0219, weight:2.00, lr:0.0004
[04:53:18.564] iteration:9420  t-loss:0.5005, loss-lb:0.1421, loss-ulb:0.1792, weight:2.00, lr:0.0004
[04:53:18.893] iteration:9421  t-loss:0.3592, loss-lb:0.1221, loss-ulb:0.1185, weight:2.00, lr:0.0004
[04:53:19.212] iteration:9422  t-loss:0.5825, loss-lb:0.3798, loss-ulb:0.1014, weight:2.00, lr:0.0004
[04:53:19.535] iteration:9423  t-loss:0.2879, loss-lb:0.1206, loss-ulb:0.0836, weight:2.00, lr:0.0004
[04:53:19.854] iteration:9424  t-loss:0.3246, loss-lb:0.2962, loss-ulb:0.0142, weight:2.00, lr:0.0004
[04:53:20.171] iteration:9425  t-loss:0.3926, loss-lb:0.2539, loss-ulb:0.0693, weight:2.00, lr:0.0004
[04:55:36.374] iteration 9425 : dice_score: 0.850207 best_dice: 0.850300
[04:55:36.374]  <<Test>> - Ep:376  - Dice-S/T:84.21/85.02, Best-S:84.86, Best-T:85.03
[04:55:36.374]           - AvgLoss(lb/ulb/all):0.21/0.07/0.36
[04:55:37.681] iteration:9426  t-loss:0.4444, loss-lb:0.2654, loss-ulb:0.0895, weight:2.00, lr:0.0004
[04:55:38.008] iteration:9427  t-loss:0.1903, loss-lb:0.1390, loss-ulb:0.0257, weight:2.00, lr:0.0004
[04:55:38.329] iteration:9428  t-loss:0.2166, loss-lb:0.1763, loss-ulb:0.0202, weight:2.00, lr:0.0004
[04:55:38.650] iteration:9429  t-loss:0.5187, loss-lb:0.1603, loss-ulb:0.1792, weight:2.00, lr:0.0004
[04:55:38.979] iteration:9430  t-loss:0.4043, loss-lb:0.2028, loss-ulb:0.1008, weight:2.00, lr:0.0004
[04:55:39.309] iteration:9431  t-loss:0.2927, loss-lb:0.2434, loss-ulb:0.0247, weight:2.00, lr:0.0004
[04:55:39.630] iteration:9432  t-loss:0.4556, loss-lb:0.1802, loss-ulb:0.1377, weight:2.00, lr:0.0004
[04:55:39.956] iteration:9433  t-loss:0.2752, loss-lb:0.1734, loss-ulb:0.0509, weight:2.00, lr:0.0004
[04:55:40.277] iteration:9434  t-loss:0.2442, loss-lb:0.1361, loss-ulb:0.0540, weight:2.00, lr:0.0004
[04:55:40.597] iteration:9435  t-loss:0.3052, loss-lb:0.2576, loss-ulb:0.0238, weight:2.00, lr:0.0004
[04:55:40.913] iteration:9436  t-loss:0.1568, loss-lb:0.1320, loss-ulb:0.0124, weight:2.00, lr:0.0004
[04:55:41.227] iteration:9437  t-loss:0.2179, loss-lb:0.1676, loss-ulb:0.0251, weight:2.00, lr:0.0004
[04:55:41.545] iteration:9438  t-loss:0.2350, loss-lb:0.1983, loss-ulb:0.0184, weight:2.00, lr:0.0004
[04:55:41.866] iteration:9439  t-loss:0.3632, loss-lb:0.1917, loss-ulb:0.0858, weight:2.00, lr:0.0004
[04:55:42.183] iteration:9440  t-loss:0.2821, loss-lb:0.2083, loss-ulb:0.0369, weight:2.00, lr:0.0004
[04:55:42.499] iteration:9441  t-loss:0.2091, loss-lb:0.1668, loss-ulb:0.0211, weight:2.00, lr:0.0004
[04:55:42.817] iteration:9442  t-loss:0.2977, loss-lb:0.1442, loss-ulb:0.0767, weight:2.00, lr:0.0004
[04:55:43.136] iteration:9443  t-loss:0.3198, loss-lb:0.1705, loss-ulb:0.0747, weight:2.00, lr:0.0004
[04:55:43.456] iteration:9444  t-loss:0.8328, loss-lb:0.2370, loss-ulb:0.2979, weight:2.00, lr:0.0004
[04:55:43.770] iteration:9445  t-loss:0.5065, loss-lb:0.2631, loss-ulb:0.1217, weight:2.00, lr:0.0004
[04:55:44.085] iteration:9446  t-loss:0.2689, loss-lb:0.1903, loss-ulb:0.0393, weight:2.00, lr:0.0004
[04:55:44.401] iteration:9447  t-loss:0.3197, loss-lb:0.2567, loss-ulb:0.0315, weight:2.00, lr:0.0004
[04:55:44.714] iteration:9448  t-loss:0.2244, loss-lb:0.1874, loss-ulb:0.0185, weight:2.00, lr:0.0004
[04:55:45.031] iteration:9449  t-loss:0.2912, loss-lb:0.1417, loss-ulb:0.0747, weight:2.00, lr:0.0004
[04:55:45.349] iteration:9450  t-loss:0.5076, loss-lb:0.3262, loss-ulb:0.0907, weight:2.00, lr:0.0004
[04:55:46.730] iteration:9451  t-loss:0.3696, loss-lb:0.1734, loss-ulb:0.0981, weight:2.00, lr:0.0004
[04:55:47.058] iteration:9452  t-loss:0.2235, loss-lb:0.1245, loss-ulb:0.0495, weight:2.00, lr:0.0004
[04:55:47.384] iteration:9453  t-loss:0.4384, loss-lb:0.2389, loss-ulb:0.0998, weight:2.00, lr:0.0004
[04:55:47.706] iteration:9454  t-loss:0.3374, loss-lb:0.2176, loss-ulb:0.0599, weight:2.00, lr:0.0004
[04:55:48.029] iteration:9455  t-loss:0.4307, loss-lb:0.2003, loss-ulb:0.1152, weight:2.00, lr:0.0004
[04:55:48.346] iteration:9456  t-loss:0.3571, loss-lb:0.3176, loss-ulb:0.0198, weight:2.00, lr:0.0004
[04:55:48.660] iteration:9457  t-loss:0.5105, loss-lb:0.3806, loss-ulb:0.0649, weight:2.00, lr:0.0004
[04:55:48.979] iteration:9458  t-loss:0.2494, loss-lb:0.1170, loss-ulb:0.0662, weight:2.00, lr:0.0004
[04:55:49.302] iteration:9459  t-loss:0.4531, loss-lb:0.2743, loss-ulb:0.0894, weight:2.00, lr:0.0004
[04:55:49.623] iteration:9460  t-loss:0.3134, loss-lb:0.1784, loss-ulb:0.0675, weight:2.00, lr:0.0004
[04:55:49.944] iteration:9461  t-loss:0.4003, loss-lb:0.2641, loss-ulb:0.0681, weight:2.00, lr:0.0004
[04:55:50.261] iteration:9462  t-loss:0.2262, loss-lb:0.1766, loss-ulb:0.0248, weight:2.00, lr:0.0004
[04:55:50.583] iteration:9463  t-loss:0.3334, loss-lb:0.2197, loss-ulb:0.0569, weight:2.00, lr:0.0004
[04:55:50.903] iteration:9464  t-loss:0.2599, loss-lb:0.2167, loss-ulb:0.0216, weight:2.00, lr:0.0004
[04:55:51.230] iteration:9465  t-loss:0.9972, loss-lb:0.1323, loss-ulb:0.4324, weight:2.00, lr:0.0004
[04:55:51.560] iteration:9466  t-loss:0.2488, loss-lb:0.1889, loss-ulb:0.0299, weight:2.00, lr:0.0004
[04:55:51.903] iteration:9467  t-loss:0.3389, loss-lb:0.2110, loss-ulb:0.0639, weight:2.00, lr:0.0004
[04:55:52.251] iteration:9468  t-loss:0.5710, loss-lb:0.2854, loss-ulb:0.1428, weight:2.00, lr:0.0004
[04:55:52.591] iteration:9469  t-loss:0.5037, loss-lb:0.2232, loss-ulb:0.1402, weight:2.00, lr:0.0004
[04:55:52.925] iteration:9470  t-loss:0.2839, loss-lb:0.1658, loss-ulb:0.0591, weight:2.00, lr:0.0004
[04:55:53.254] iteration:9471  t-loss:0.5472, loss-lb:0.1616, loss-ulb:0.1928, weight:2.00, lr:0.0004
[04:55:53.577] iteration:9472  t-loss:0.3034, loss-lb:0.2347, loss-ulb:0.0343, weight:2.00, lr:0.0004
[04:55:53.900] iteration:9473  t-loss:1.6781, loss-lb:0.1762, loss-ulb:0.7509, weight:2.00, lr:0.0004
[04:55:54.216] iteration:9474  t-loss:0.2895, loss-lb:0.1282, loss-ulb:0.0807, weight:2.00, lr:0.0004
[04:55:54.536] iteration:9475  t-loss:0.6628, loss-lb:0.2801, loss-ulb:0.1914, weight:2.00, lr:0.0004
[04:55:55.996] iteration:9476  t-loss:0.3701, loss-lb:0.2721, loss-ulb:0.0490, weight:2.00, lr:0.0004
[04:55:56.331] iteration:9477  t-loss:0.2678, loss-lb:0.1672, loss-ulb:0.0503, weight:2.00, lr:0.0004
[04:55:56.669] iteration:9478  t-loss:0.3942, loss-lb:0.1840, loss-ulb:0.1051, weight:2.00, lr:0.0004
[04:55:57.001] iteration:9479  t-loss:0.3356, loss-lb:0.1943, loss-ulb:0.0707, weight:2.00, lr:0.0004
[04:55:57.318] iteration:9480  t-loss:0.3217, loss-lb:0.1819, loss-ulb:0.0699, weight:2.00, lr:0.0004
[04:55:57.634] iteration:9481  t-loss:0.4044, loss-lb:0.1501, loss-ulb:0.1272, weight:2.00, lr:0.0004
[04:55:57.952] iteration:9482  t-loss:0.4320, loss-lb:0.2491, loss-ulb:0.0914, weight:2.00, lr:0.0004
[04:55:58.279] iteration:9483  t-loss:0.3886, loss-lb:0.2178, loss-ulb:0.0854, weight:2.00, lr:0.0004
[04:55:58.595] iteration:9484  t-loss:0.2211, loss-lb:0.1548, loss-ulb:0.0332, weight:2.00, lr:0.0004
[04:55:58.911] iteration:9485  t-loss:0.2594, loss-lb:0.1948, loss-ulb:0.0323, weight:2.00, lr:0.0004
[04:55:59.230] iteration:9486  t-loss:0.3152, loss-lb:0.1317, loss-ulb:0.0918, weight:2.00, lr:0.0004
[04:55:59.559] iteration:9487  t-loss:0.4733, loss-lb:0.2902, loss-ulb:0.0916, weight:2.00, lr:0.0004
[04:55:59.899] iteration:9488  t-loss:0.7430, loss-lb:0.2664, loss-ulb:0.2383, weight:2.00, lr:0.0004
[04:56:00.228] iteration:9489  t-loss:0.5485, loss-lb:0.2192, loss-ulb:0.1646, weight:2.00, lr:0.0004
[04:56:00.553] iteration:9490  t-loss:0.2200, loss-lb:0.1696, loss-ulb:0.0252, weight:2.00, lr:0.0004
[04:56:00.885] iteration:9491  t-loss:0.4421, loss-lb:0.2801, loss-ulb:0.0810, weight:2.00, lr:0.0004
[04:56:01.206] iteration:9492  t-loss:0.2168, loss-lb:0.1129, loss-ulb:0.0519, weight:2.00, lr:0.0004
[04:56:01.523] iteration:9493  t-loss:0.4291, loss-lb:0.2397, loss-ulb:0.0947, weight:2.00, lr:0.0004
[04:56:01.839] iteration:9494  t-loss:0.4512, loss-lb:0.3945, loss-ulb:0.0283, weight:2.00, lr:0.0004
[04:56:02.156] iteration:9495  t-loss:0.3596, loss-lb:0.2007, loss-ulb:0.0794, weight:2.00, lr:0.0004
[04:56:02.474] iteration:9496  t-loss:0.4160, loss-lb:0.2403, loss-ulb:0.0878, weight:2.00, lr:0.0004
[04:56:02.789] iteration:9497  t-loss:0.7334, loss-lb:0.1270, loss-ulb:0.3032, weight:2.00, lr:0.0004
[04:56:03.103] iteration:9498  t-loss:0.2640, loss-lb:0.1886, loss-ulb:0.0377, weight:2.00, lr:0.0004
[04:56:03.423] iteration:9499  t-loss:0.5895, loss-lb:0.3924, loss-ulb:0.0986, weight:2.00, lr:0.0004
[04:56:03.737] iteration:9500  t-loss:0.2434, loss-lb:0.2142, loss-ulb:0.0146, weight:2.00, lr:0.0004
[04:56:05.034] iteration:9501  t-loss:0.3724, loss-lb:0.3284, loss-ulb:0.0220, weight:2.00, lr:0.0004
[04:56:05.369] iteration:9502  t-loss:0.3657, loss-lb:0.2771, loss-ulb:0.0443, weight:2.00, lr:0.0004
[04:56:05.688] iteration:9503  t-loss:0.2194, loss-lb:0.1299, loss-ulb:0.0448, weight:2.00, lr:0.0004
[04:56:06.008] iteration:9504  t-loss:0.3498, loss-lb:0.1544, loss-ulb:0.0977, weight:2.00, lr:0.0004
[04:56:06.329] iteration:9505  t-loss:0.3063, loss-lb:0.1888, loss-ulb:0.0588, weight:2.00, lr:0.0004
[04:56:06.657] iteration:9506  t-loss:0.5248, loss-lb:0.1824, loss-ulb:0.1712, weight:2.00, lr:0.0004
[04:56:06.997] iteration:9507  t-loss:0.4822, loss-lb:0.3162, loss-ulb:0.0830, weight:2.00, lr:0.0004
[04:56:07.320] iteration:9508  t-loss:0.2551, loss-lb:0.1494, loss-ulb:0.0528, weight:2.00, lr:0.0004
[04:56:07.654] iteration:9509  t-loss:0.6380, loss-lb:0.1971, loss-ulb:0.2204, weight:2.00, lr:0.0004
[04:56:07.983] iteration:9510  t-loss:0.2649, loss-lb:0.2253, loss-ulb:0.0198, weight:2.00, lr:0.0004
[04:56:08.314] iteration:9511  t-loss:0.2685, loss-lb:0.1796, loss-ulb:0.0445, weight:2.00, lr:0.0004
[04:56:08.646] iteration:9512  t-loss:0.3684, loss-lb:0.1520, loss-ulb:0.1082, weight:2.00, lr:0.0004
[04:56:08.980] iteration:9513  t-loss:0.3823, loss-lb:0.1872, loss-ulb:0.0975, weight:2.00, lr:0.0004
[04:56:09.304] iteration:9514  t-loss:0.4880, loss-lb:0.1785, loss-ulb:0.1548, weight:2.00, lr:0.0004
[04:56:09.632] iteration:9515  t-loss:0.2460, loss-lb:0.1959, loss-ulb:0.0251, weight:2.00, lr:0.0004
[04:56:09.962] iteration:9516  t-loss:0.5038, loss-lb:0.3428, loss-ulb:0.0805, weight:2.00, lr:0.0004
[04:56:10.300] iteration:9517  t-loss:0.2775, loss-lb:0.1353, loss-ulb:0.0711, weight:2.00, lr:0.0004
[04:56:10.621] iteration:9518  t-loss:0.2917, loss-lb:0.1685, loss-ulb:0.0616, weight:2.00, lr:0.0004
[04:56:10.942] iteration:9519  t-loss:0.2493, loss-lb:0.1511, loss-ulb:0.0491, weight:2.00, lr:0.0004
[04:56:11.261] iteration:9520  t-loss:0.3280, loss-lb:0.2734, loss-ulb:0.0273, weight:2.00, lr:0.0004
[04:56:11.579] iteration:9521  t-loss:0.3429, loss-lb:0.1926, loss-ulb:0.0751, weight:2.00, lr:0.0004
[04:56:11.894] iteration:9522  t-loss:0.2474, loss-lb:0.1711, loss-ulb:0.0381, weight:2.00, lr:0.0004
[04:56:12.215] iteration:9523  t-loss:0.5037, loss-lb:0.2949, loss-ulb:0.1044, weight:2.00, lr:0.0004
[04:56:12.540] iteration:9524  t-loss:0.5039, loss-lb:0.1501, loss-ulb:0.1769, weight:2.00, lr:0.0004
[04:56:12.861] iteration:9525  t-loss:0.2272, loss-lb:0.1898, loss-ulb:0.0187, weight:2.00, lr:0.0004
[04:58:31.510] iteration 9525 : dice_score: 0.850566 best_dice: 0.850600
[04:58:31.511]  <<Test>> - Ep:380  - Dice-S/T:83.08/85.06, Best-S:84.86, Best-T:85.06
[04:58:31.511]           - AvgLoss(lb/ulb/all):0.20/0.08/0.37
[04:58:32.654] iteration:9526  t-loss:0.2892, loss-lb:0.2616, loss-ulb:0.0138, weight:2.00, lr:0.0004
[04:58:32.983] iteration:9527  t-loss:0.2527, loss-lb:0.2147, loss-ulb:0.0190, weight:2.00, lr:0.0004
[04:58:33.306] iteration:9528  t-loss:0.3188, loss-lb:0.2827, loss-ulb:0.0180, weight:2.00, lr:0.0004
[04:58:33.630] iteration:9529  t-loss:0.5408, loss-lb:0.2485, loss-ulb:0.1462, weight:2.00, lr:0.0004
[04:58:33.948] iteration:9530  t-loss:0.2874, loss-lb:0.1646, loss-ulb:0.0614, weight:2.00, lr:0.0004
[04:58:34.272] iteration:9531  t-loss:0.3374, loss-lb:0.3095, loss-ulb:0.0140, weight:2.00, lr:0.0004
[04:58:34.597] iteration:9532  t-loss:0.3845, loss-lb:0.2235, loss-ulb:0.0805, weight:2.00, lr:0.0004
[04:58:35.000] iteration:9533  t-loss:0.1659, loss-lb:0.1080, loss-ulb:0.0289, weight:2.00, lr:0.0004
[04:58:35.318] iteration:9534  t-loss:0.2159, loss-lb:0.1467, loss-ulb:0.0346, weight:2.00, lr:0.0004
[04:58:35.640] iteration:9535  t-loss:0.3493, loss-lb:0.1651, loss-ulb:0.0921, weight:2.00, lr:0.0004
[04:58:35.958] iteration:9536  t-loss:0.2193, loss-lb:0.1789, loss-ulb:0.0202, weight:2.00, lr:0.0004
[04:58:36.276] iteration:9537  t-loss:0.3540, loss-lb:0.1257, loss-ulb:0.1141, weight:2.00, lr:0.0004
[04:58:36.594] iteration:9538  t-loss:0.2026, loss-lb:0.1644, loss-ulb:0.0191, weight:2.00, lr:0.0004
[04:58:36.913] iteration:9539  t-loss:0.3129, loss-lb:0.1305, loss-ulb:0.0912, weight:2.00, lr:0.0004
[04:58:37.236] iteration:9540  t-loss:0.3037, loss-lb:0.1498, loss-ulb:0.0769, weight:2.00, lr:0.0004
[04:58:37.554] iteration:9541  t-loss:0.2958, loss-lb:0.1854, loss-ulb:0.0552, weight:2.00, lr:0.0004
[04:58:37.885] iteration:9542  t-loss:0.3183, loss-lb:0.1398, loss-ulb:0.0893, weight:2.00, lr:0.0004
[04:58:38.203] iteration:9543  t-loss:0.3403, loss-lb:0.1923, loss-ulb:0.0740, weight:2.00, lr:0.0004
[04:58:38.519] iteration:9544  t-loss:0.2319, loss-lb:0.1831, loss-ulb:0.0244, weight:2.00, lr:0.0004
[04:58:38.840] iteration:9545  t-loss:0.2965, loss-lb:0.2528, loss-ulb:0.0218, weight:2.00, lr:0.0004
[04:58:39.157] iteration:9546  t-loss:0.5134, loss-lb:0.1655, loss-ulb:0.1739, weight:2.00, lr:0.0004
[04:58:39.473] iteration:9547  t-loss:0.3647, loss-lb:0.2848, loss-ulb:0.0399, weight:2.00, lr:0.0004
[04:58:39.795] iteration:9548  t-loss:0.4582, loss-lb:0.2523, loss-ulb:0.1029, weight:2.00, lr:0.0004
[04:58:40.109] iteration:9549  t-loss:0.2322, loss-lb:0.1833, loss-ulb:0.0244, weight:2.00, lr:0.0004
[04:58:40.424] iteration:9550  t-loss:0.3556, loss-lb:0.1780, loss-ulb:0.0888, weight:2.00, lr:0.0004
[04:58:41.639] iteration:9551  t-loss:0.3327, loss-lb:0.1317, loss-ulb:0.1005, weight:2.00, lr:0.0004
[04:58:41.980] iteration:9552  t-loss:0.2328, loss-lb:0.1927, loss-ulb:0.0200, weight:2.00, lr:0.0004
[04:58:42.305] iteration:9553  t-loss:0.3339, loss-lb:0.2091, loss-ulb:0.0624, weight:2.00, lr:0.0004
[04:58:42.638] iteration:9554  t-loss:0.4289, loss-lb:0.2721, loss-ulb:0.0784, weight:2.00, lr:0.0004
[04:58:42.950] iteration:9555  t-loss:0.8329, loss-lb:0.3163, loss-ulb:0.2583, weight:2.00, lr:0.0004
[04:58:43.267] iteration:9556  t-loss:0.2591, loss-lb:0.1598, loss-ulb:0.0496, weight:2.00, lr:0.0004
[04:58:43.587] iteration:9557  t-loss:0.3277, loss-lb:0.1532, loss-ulb:0.0872, weight:2.00, lr:0.0004
[04:58:43.905] iteration:9558  t-loss:0.2000, loss-lb:0.1625, loss-ulb:0.0187, weight:2.00, lr:0.0004
[04:58:44.226] iteration:9559  t-loss:0.5912, loss-lb:0.3322, loss-ulb:0.1295, weight:2.00, lr:0.0004
[04:58:44.545] iteration:9560  t-loss:0.2144, loss-lb:0.1605, loss-ulb:0.0270, weight:2.00, lr:0.0004
[04:58:44.866] iteration:9561  t-loss:0.3736, loss-lb:0.3000, loss-ulb:0.0368, weight:2.00, lr:0.0004
[04:58:45.188] iteration:9562  t-loss:0.3446, loss-lb:0.1423, loss-ulb:0.1011, weight:2.00, lr:0.0004
[04:58:45.508] iteration:9563  t-loss:0.6527, loss-lb:0.2710, loss-ulb:0.1908, weight:2.00, lr:0.0004
[04:58:45.833] iteration:9564  t-loss:0.2712, loss-lb:0.2306, loss-ulb:0.0203, weight:2.00, lr:0.0004
[04:58:46.163] iteration:9565  t-loss:0.2416, loss-lb:0.2005, loss-ulb:0.0205, weight:2.00, lr:0.0004
[04:58:46.498] iteration:9566  t-loss:0.3682, loss-lb:0.2062, loss-ulb:0.0810, weight:2.00, lr:0.0004
[04:58:46.832] iteration:9567  t-loss:0.5136, loss-lb:0.2722, loss-ulb:0.1207, weight:2.00, lr:0.0004
[04:58:47.162] iteration:9568  t-loss:0.3857, loss-lb:0.2074, loss-ulb:0.0891, weight:2.00, lr:0.0004
[04:58:47.481] iteration:9569  t-loss:0.5718, loss-lb:0.1510, loss-ulb:0.2104, weight:2.00, lr:0.0004
[04:58:47.800] iteration:9570  t-loss:0.1758, loss-lb:0.1286, loss-ulb:0.0236, weight:2.00, lr:0.0004
[04:58:48.115] iteration:9571  t-loss:0.3011, loss-lb:0.2524, loss-ulb:0.0243, weight:2.00, lr:0.0004
[04:58:48.434] iteration:9572  t-loss:0.3221, loss-lb:0.2171, loss-ulb:0.0525, weight:2.00, lr:0.0004
[04:58:48.750] iteration:9573  t-loss:0.3707, loss-lb:0.2174, loss-ulb:0.0766, weight:2.00, lr:0.0004
[04:58:49.064] iteration:9574  t-loss:0.3366, loss-lb:0.1539, loss-ulb:0.0914, weight:2.00, lr:0.0004
[04:58:49.382] iteration:9575  t-loss:0.4206, loss-lb:0.3049, loss-ulb:0.0579, weight:2.00, lr:0.0004
[04:58:50.862] iteration:9576  t-loss:0.3372, loss-lb:0.1579, loss-ulb:0.0897, weight:2.00, lr:0.0004
[04:58:51.195] iteration:9577  t-loss:0.4335, loss-lb:0.2081, loss-ulb:0.1127, weight:2.00, lr:0.0004
[04:58:51.527] iteration:9578  t-loss:0.3180, loss-lb:0.1941, loss-ulb:0.0619, weight:2.00, lr:0.0004
[04:58:51.861] iteration:9579  t-loss:0.7829, loss-lb:0.1604, loss-ulb:0.3112, weight:2.00, lr:0.0004
[04:58:52.184] iteration:9580  t-loss:0.3501, loss-lb:0.1342, loss-ulb:0.1079, weight:2.00, lr:0.0004
[04:58:52.501] iteration:9581  t-loss:0.3606, loss-lb:0.1630, loss-ulb:0.0988, weight:2.00, lr:0.0004
[04:58:52.820] iteration:9582  t-loss:0.3794, loss-lb:0.1845, loss-ulb:0.0974, weight:2.00, lr:0.0004
[04:58:53.139] iteration:9583  t-loss:0.3171, loss-lb:0.2727, loss-ulb:0.0222, weight:2.00, lr:0.0004
[04:58:53.457] iteration:9584  t-loss:0.6622, loss-lb:0.2419, loss-ulb:0.2101, weight:2.00, lr:0.0004
[04:58:53.773] iteration:9585  t-loss:0.1746, loss-lb:0.1254, loss-ulb:0.0246, weight:2.00, lr:0.0004
[04:58:54.089] iteration:9586  t-loss:0.2791, loss-lb:0.1654, loss-ulb:0.0569, weight:2.00, lr:0.0004
[04:58:54.407] iteration:9587  t-loss:0.3886, loss-lb:0.2022, loss-ulb:0.0932, weight:2.00, lr:0.0004
[04:58:54.729] iteration:9588  t-loss:0.2223, loss-lb:0.1469, loss-ulb:0.0377, weight:2.00, lr:0.0004
[04:58:55.059] iteration:9589  t-loss:0.2755, loss-lb:0.1649, loss-ulb:0.0553, weight:2.00, lr:0.0004
[04:58:55.395] iteration:9590  t-loss:0.5577, loss-lb:0.2177, loss-ulb:0.1700, weight:2.00, lr:0.0004
[04:58:55.734] iteration:9591  t-loss:0.3450, loss-lb:0.2458, loss-ulb:0.0496, weight:2.00, lr:0.0004
[04:58:56.062] iteration:9592  t-loss:0.1884, loss-lb:0.1434, loss-ulb:0.0225, weight:2.00, lr:0.0004
[04:58:56.391] iteration:9593  t-loss:0.4670, loss-lb:0.4341, loss-ulb:0.0165, weight:2.00, lr:0.0004
[04:58:56.709] iteration:9594  t-loss:0.1875, loss-lb:0.1480, loss-ulb:0.0198, weight:2.00, lr:0.0004
[04:58:57.029] iteration:9595  t-loss:0.2849, loss-lb:0.1328, loss-ulb:0.0760, weight:2.00, lr:0.0004
[04:58:57.351] iteration:9596  t-loss:0.5609, loss-lb:0.2232, loss-ulb:0.1688, weight:2.00, lr:0.0004
[04:58:57.670] iteration:9597  t-loss:0.4803, loss-lb:0.1845, loss-ulb:0.1479, weight:2.00, lr:0.0004
[04:58:57.990] iteration:9598  t-loss:0.3445, loss-lb:0.3064, loss-ulb:0.0190, weight:2.00, lr:0.0004
[04:58:58.312] iteration:9599  t-loss:0.3066, loss-lb:0.1797, loss-ulb:0.0635, weight:2.00, lr:0.0004
[04:58:58.630] iteration:9600  t-loss:0.3492, loss-lb:0.1298, loss-ulb:0.1097, weight:2.00, lr:0.0004
[04:58:59.953] iteration:9601  t-loss:0.4492, loss-lb:0.2108, loss-ulb:0.1192, weight:2.00, lr:0.0004
[04:59:00.289] iteration:9602  t-loss:0.2045, loss-lb:0.1569, loss-ulb:0.0238, weight:2.00, lr:0.0004
[04:59:00.624] iteration:9603  t-loss:0.4147, loss-lb:0.1802, loss-ulb:0.1173, weight:2.00, lr:0.0004
[04:59:00.955] iteration:9604  t-loss:0.4788, loss-lb:0.2342, loss-ulb:0.1223, weight:2.00, lr:0.0004
[04:59:01.279] iteration:9605  t-loss:0.4319, loss-lb:0.2667, loss-ulb:0.0826, weight:2.00, lr:0.0004
[04:59:01.597] iteration:9606  t-loss:0.3933, loss-lb:0.1371, loss-ulb:0.1281, weight:2.00, lr:0.0004
[04:59:01.917] iteration:9607  t-loss:0.3998, loss-lb:0.1718, loss-ulb:0.1140, weight:2.00, lr:0.0004
[04:59:02.240] iteration:9608  t-loss:0.6098, loss-lb:0.1580, loss-ulb:0.2259, weight:2.00, lr:0.0004
[04:59:02.562] iteration:9609  t-loss:0.4569, loss-lb:0.2986, loss-ulb:0.0792, weight:2.00, lr:0.0004
[04:59:02.880] iteration:9610  t-loss:0.2929, loss-lb:0.2013, loss-ulb:0.0458, weight:2.00, lr:0.0004
[04:59:03.198] iteration:9611  t-loss:0.3426, loss-lb:0.1624, loss-ulb:0.0901, weight:2.00, lr:0.0004
[04:59:03.542] iteration:9612  t-loss:0.6076, loss-lb:0.2212, loss-ulb:0.1932, weight:2.00, lr:0.0004
[04:59:03.882] iteration:9613  t-loss:0.5263, loss-lb:0.1359, loss-ulb:0.1952, weight:2.00, lr:0.0004
[04:59:04.220] iteration:9614  t-loss:0.2288, loss-lb:0.1728, loss-ulb:0.0280, weight:2.00, lr:0.0004
[04:59:04.553] iteration:9615  t-loss:0.2293, loss-lb:0.1773, loss-ulb:0.0260, weight:2.00, lr:0.0004
[04:59:04.882] iteration:9616  t-loss:0.2158, loss-lb:0.1504, loss-ulb:0.0327, weight:2.00, lr:0.0004
[04:59:05.217] iteration:9617  t-loss:0.3994, loss-lb:0.2956, loss-ulb:0.0519, weight:2.00, lr:0.0004
[04:59:05.541] iteration:9618  t-loss:0.1816, loss-lb:0.1322, loss-ulb:0.0247, weight:2.00, lr:0.0004
[04:59:05.858] iteration:9619  t-loss:0.2315, loss-lb:0.1852, loss-ulb:0.0232, weight:2.00, lr:0.0004
[04:59:06.176] iteration:9620  t-loss:0.3340, loss-lb:0.1130, loss-ulb:0.1105, weight:2.00, lr:0.0004
[04:59:06.496] iteration:9621  t-loss:0.2495, loss-lb:0.1506, loss-ulb:0.0494, weight:2.00, lr:0.0004
[04:59:06.820] iteration:9622  t-loss:0.3177, loss-lb:0.1561, loss-ulb:0.0808, weight:2.00, lr:0.0004
[04:59:07.140] iteration:9623  t-loss:0.4140, loss-lb:0.2775, loss-ulb:0.0682, weight:2.00, lr:0.0004
[04:59:07.461] iteration:9624  t-loss:0.3074, loss-lb:0.2703, loss-ulb:0.0186, weight:2.00, lr:0.0004
[04:59:07.779] iteration:9625  t-loss:0.1971, loss-lb:0.1457, loss-ulb:0.0257, weight:2.00, lr:0.0004
[05:01:18.583] iteration 9625 : dice_score: 0.850738 best_dice: 0.850700
[05:01:18.583]  <<Test>> - Ep:384  - Dice-S/T:84.90/85.07, Best-S:84.90, Best-T:85.07
[05:01:18.584]           - AvgLoss(lb/ulb/all):0.19/0.08/0.35
[05:01:20.035] iteration:9626  t-loss:0.6842, loss-lb:0.2001, loss-ulb:0.2420, weight:2.00, lr:0.0004
[05:01:20.372] iteration:9627  t-loss:0.2844, loss-lb:0.2433, loss-ulb:0.0205, weight:2.00, lr:0.0004
[05:01:20.694] iteration:9628  t-loss:0.4104, loss-lb:0.1676, loss-ulb:0.1214, weight:2.00, lr:0.0004
[05:01:21.014] iteration:9629  t-loss:0.4064, loss-lb:0.1822, loss-ulb:0.1121, weight:2.00, lr:0.0004
[05:01:21.339] iteration:9630  t-loss:0.4008, loss-lb:0.2063, loss-ulb:0.0972, weight:2.00, lr:0.0004
[05:01:21.664] iteration:9631  t-loss:0.3437, loss-lb:0.2873, loss-ulb:0.0282, weight:2.00, lr:0.0004
[05:01:21.986] iteration:9632  t-loss:0.6310, loss-lb:0.2496, loss-ulb:0.1907, weight:2.00, lr:0.0004
[05:01:22.306] iteration:9633  t-loss:0.3343, loss-lb:0.3030, loss-ulb:0.0156, weight:2.00, lr:0.0004
[05:01:22.626] iteration:9634  t-loss:0.4348, loss-lb:0.2620, loss-ulb:0.0864, weight:2.00, lr:0.0004
[05:01:22.953] iteration:9635  t-loss:0.9955, loss-lb:0.2217, loss-ulb:0.3869, weight:2.00, lr:0.0004
[05:01:23.275] iteration:9636  t-loss:0.5260, loss-lb:0.1388, loss-ulb:0.1936, weight:2.00, lr:0.0004
[05:01:23.599] iteration:9637  t-loss:0.2356, loss-lb:0.2001, loss-ulb:0.0178, weight:2.00, lr:0.0004
[05:01:23.919] iteration:9638  t-loss:0.2585, loss-lb:0.1628, loss-ulb:0.0478, weight:2.00, lr:0.0004
[05:01:24.238] iteration:9639  t-loss:0.5504, loss-lb:0.2018, loss-ulb:0.1743, weight:2.00, lr:0.0004
[05:01:24.552] iteration:9640  t-loss:0.2367, loss-lb:0.2069, loss-ulb:0.0149, weight:2.00, lr:0.0004
[05:01:24.869] iteration:9641  t-loss:0.2847, loss-lb:0.1974, loss-ulb:0.0437, weight:2.00, lr:0.0004
[05:01:25.186] iteration:9642  t-loss:0.2022, loss-lb:0.1612, loss-ulb:0.0205, weight:2.00, lr:0.0004
[05:01:25.500] iteration:9643  t-loss:0.2002, loss-lb:0.1579, loss-ulb:0.0211, weight:2.00, lr:0.0004
[05:01:25.813] iteration:9644  t-loss:0.3552, loss-lb:0.1731, loss-ulb:0.0911, weight:2.00, lr:0.0004
[05:01:26.133] iteration:9645  t-loss:0.4432, loss-lb:0.2560, loss-ulb:0.0936, weight:2.00, lr:0.0004
[05:01:26.450] iteration:9646  t-loss:0.5616, loss-lb:0.2623, loss-ulb:0.1496, weight:2.00, lr:0.0004
[05:01:26.769] iteration:9647  t-loss:0.4892, loss-lb:0.2650, loss-ulb:0.1121, weight:2.00, lr:0.0004
[05:01:27.084] iteration:9648  t-loss:0.3509, loss-lb:0.1994, loss-ulb:0.0757, weight:2.00, lr:0.0004
[05:01:27.400] iteration:9649  t-loss:0.3610, loss-lb:0.1508, loss-ulb:0.1051, weight:2.00, lr:0.0004
[05:01:27.718] iteration:9650  t-loss:0.4455, loss-lb:0.1837, loss-ulb:0.1309, weight:2.00, lr:0.0004
[05:01:29.109] iteration:9651  t-loss:0.6097, loss-lb:0.2797, loss-ulb:0.1650, weight:2.00, lr:0.0004
[05:01:29.442] iteration:9652  t-loss:0.3220, loss-lb:0.1692, loss-ulb:0.0764, weight:2.00, lr:0.0004
[05:01:29.774] iteration:9653  t-loss:0.3815, loss-lb:0.3135, loss-ulb:0.0340, weight:2.00, lr:0.0004
[05:01:30.109] iteration:9654  t-loss:0.2199, loss-lb:0.1217, loss-ulb:0.0491, weight:2.00, lr:0.0004
[05:01:30.450] iteration:9655  t-loss:0.2708, loss-lb:0.1263, loss-ulb:0.0722, weight:2.00, lr:0.0004
[05:01:30.775] iteration:9656  t-loss:0.2149, loss-lb:0.1656, loss-ulb:0.0247, weight:2.00, lr:0.0004
[05:01:31.113] iteration:9657  t-loss:0.5999, loss-lb:0.3018, loss-ulb:0.1490, weight:2.00, lr:0.0004
[05:01:31.443] iteration:9658  t-loss:0.4832, loss-lb:0.3289, loss-ulb:0.0771, weight:2.00, lr:0.0004
[05:01:31.772] iteration:9659  t-loss:0.5465, loss-lb:0.2746, loss-ulb:0.1360, weight:2.00, lr:0.0004
[05:01:32.098] iteration:9660  t-loss:0.2849, loss-lb:0.2233, loss-ulb:0.0308, weight:2.00, lr:0.0004
[05:01:32.421] iteration:9661  t-loss:0.5768, loss-lb:0.2450, loss-ulb:0.1659, weight:2.00, lr:0.0004
[05:01:32.741] iteration:9662  t-loss:0.4513, loss-lb:0.2560, loss-ulb:0.0976, weight:2.00, lr:0.0004
[05:01:33.064] iteration:9663  t-loss:0.6096, loss-lb:0.1677, loss-ulb:0.2210, weight:2.00, lr:0.0004
[05:01:33.384] iteration:9664  t-loss:0.4660, loss-lb:0.2717, loss-ulb:0.0972, weight:2.00, lr:0.0004
[05:01:33.710] iteration:9665  t-loss:0.3986, loss-lb:0.2511, loss-ulb:0.0737, weight:2.00, lr:0.0004
[05:01:34.033] iteration:9666  t-loss:0.4686, loss-lb:0.2041, loss-ulb:0.1322, weight:2.00, lr:0.0004
[05:01:34.361] iteration:9667  t-loss:0.4076, loss-lb:0.1379, loss-ulb:0.1349, weight:2.00, lr:0.0004
[05:01:34.680] iteration:9668  t-loss:0.3362, loss-lb:0.2082, loss-ulb:0.0640, weight:2.00, lr:0.0004
[05:01:34.998] iteration:9669  t-loss:0.4649, loss-lb:0.3017, loss-ulb:0.0816, weight:2.00, lr:0.0004
[05:01:35.321] iteration:9670  t-loss:0.3670, loss-lb:0.1669, loss-ulb:0.1001, weight:2.00, lr:0.0004
[05:01:35.642] iteration:9671  t-loss:0.3700, loss-lb:0.2518, loss-ulb:0.0591, weight:2.00, lr:0.0004
[05:01:35.957] iteration:9672  t-loss:0.2568, loss-lb:0.2059, loss-ulb:0.0254, weight:2.00, lr:0.0004
[05:01:36.339] iteration:9673  t-loss:0.2688, loss-lb:0.1649, loss-ulb:0.0520, weight:2.00, lr:0.0004
[05:01:36.662] iteration:9674  t-loss:0.6447, loss-lb:0.1542, loss-ulb:0.2452, weight:2.00, lr:0.0004
[05:01:37.001] iteration:9675  t-loss:0.4982, loss-lb:0.3024, loss-ulb:0.0979, weight:2.00, lr:0.0004
[05:01:38.731] iteration:9676  t-loss:0.3830, loss-lb:0.2205, loss-ulb:0.0813, weight:2.00, lr:0.0004
[05:01:39.069] iteration:9677  t-loss:0.4459, loss-lb:0.2366, loss-ulb:0.1046, weight:2.00, lr:0.0004
[05:01:39.392] iteration:9678  t-loss:0.1944, loss-lb:0.1480, loss-ulb:0.0232, weight:2.00, lr:0.0004
[05:01:39.718] iteration:9679  t-loss:0.3519, loss-lb:0.1775, loss-ulb:0.0872, weight:2.00, lr:0.0004
[05:01:40.037] iteration:9680  t-loss:0.3386, loss-lb:0.2691, loss-ulb:0.0348, weight:2.00, lr:0.0004
[05:01:40.355] iteration:9681  t-loss:0.2773, loss-lb:0.1957, loss-ulb:0.0408, weight:2.00, lr:0.0004
[05:01:40.676] iteration:9682  t-loss:0.3448, loss-lb:0.1753, loss-ulb:0.0847, weight:2.00, lr:0.0004
[05:01:40.991] iteration:9683  t-loss:0.2010, loss-lb:0.1183, loss-ulb:0.0414, weight:2.00, lr:0.0004
[05:01:41.316] iteration:9684  t-loss:0.4426, loss-lb:0.2642, loss-ulb:0.0892, weight:2.00, lr:0.0004
[05:01:41.639] iteration:9685  t-loss:0.8153, loss-lb:0.2089, loss-ulb:0.3032, weight:2.00, lr:0.0004
[05:01:41.964] iteration:9686  t-loss:0.4470, loss-lb:0.2593, loss-ulb:0.0939, weight:2.00, lr:0.0004
[05:01:42.286] iteration:9687  t-loss:0.5912, loss-lb:0.1698, loss-ulb:0.2107, weight:2.00, lr:0.0004
[05:01:42.610] iteration:9688  t-loss:0.5385, loss-lb:0.2665, loss-ulb:0.1360, weight:2.00, lr:0.0004
[05:01:42.932] iteration:9689  t-loss:0.3651, loss-lb:0.2299, loss-ulb:0.0676, weight:2.00, lr:0.0004
[05:01:43.254] iteration:9690  t-loss:0.4069, loss-lb:0.1316, loss-ulb:0.1376, weight:2.00, lr:0.0004
[05:01:43.584] iteration:9691  t-loss:0.3171, loss-lb:0.1507, loss-ulb:0.0832, weight:2.00, lr:0.0004
[05:01:43.912] iteration:9692  t-loss:0.5875, loss-lb:0.2426, loss-ulb:0.1725, weight:2.00, lr:0.0004
[05:01:44.228] iteration:9693  t-loss:0.1823, loss-lb:0.1114, loss-ulb:0.0354, weight:2.00, lr:0.0004
[05:01:44.551] iteration:9694  t-loss:0.4421, loss-lb:0.2676, loss-ulb:0.0873, weight:2.00, lr:0.0004
[05:01:44.868] iteration:9695  t-loss:0.3944, loss-lb:0.1915, loss-ulb:0.1015, weight:2.00, lr:0.0004
[05:01:45.194] iteration:9696  t-loss:0.2234, loss-lb:0.1711, loss-ulb:0.0261, weight:2.00, lr:0.0004
[05:01:45.524] iteration:9697  t-loss:0.2949, loss-lb:0.2139, loss-ulb:0.0405, weight:2.00, lr:0.0004
[05:01:45.858] iteration:9698  t-loss:0.3560, loss-lb:0.3268, loss-ulb:0.0146, weight:2.00, lr:0.0004
[05:01:46.190] iteration:9699  t-loss:0.3687, loss-lb:0.2221, loss-ulb:0.0733, weight:2.00, lr:0.0004
[05:01:46.521] iteration:9700  t-loss:0.2875, loss-lb:0.1795, loss-ulb:0.0540, weight:2.00, lr:0.0004
[05:01:47.974] iteration:9701  t-loss:0.4892, loss-lb:0.2921, loss-ulb:0.0986, weight:2.00, lr:0.0004
[05:01:48.334] iteration:9702  t-loss:0.3793, loss-lb:0.3007, loss-ulb:0.0393, weight:2.00, lr:0.0004
[05:01:48.684] iteration:9703  t-loss:0.2279, loss-lb:0.1380, loss-ulb:0.0449, weight:2.00, lr:0.0004
[05:01:49.030] iteration:9704  t-loss:0.2325, loss-lb:0.1862, loss-ulb:0.0232, weight:2.00, lr:0.0004
[05:01:49.377] iteration:9705  t-loss:0.3838, loss-lb:0.2407, loss-ulb:0.0716, weight:2.00, lr:0.0004
[05:01:49.709] iteration:9706  t-loss:0.3755, loss-lb:0.2630, loss-ulb:0.0563, weight:2.00, lr:0.0004
[05:01:50.038] iteration:9707  t-loss:0.5187, loss-lb:0.2341, loss-ulb:0.1423, weight:2.00, lr:0.0004
[05:01:50.372] iteration:9708  t-loss:0.3271, loss-lb:0.1752, loss-ulb:0.0759, weight:2.00, lr:0.0004
[05:01:50.698] iteration:9709  t-loss:0.3724, loss-lb:0.2366, loss-ulb:0.0679, weight:2.00, lr:0.0004
[05:01:51.017] iteration:9710  t-loss:0.2086, loss-lb:0.1635, loss-ulb:0.0226, weight:2.00, lr:0.0004
[05:01:51.339] iteration:9711  t-loss:0.2770, loss-lb:0.2200, loss-ulb:0.0285, weight:2.00, lr:0.0004
[05:01:51.656] iteration:9712  t-loss:0.3208, loss-lb:0.1403, loss-ulb:0.0903, weight:2.00, lr:0.0004
[05:01:51.971] iteration:9713  t-loss:0.3137, loss-lb:0.2095, loss-ulb:0.0521, weight:2.00, lr:0.0004
[05:01:52.292] iteration:9714  t-loss:0.4544, loss-lb:0.1880, loss-ulb:0.1332, weight:2.00, lr:0.0004
[05:01:52.611] iteration:9715  t-loss:0.3829, loss-lb:0.1401, loss-ulb:0.1214, weight:2.00, lr:0.0004
[05:01:52.929] iteration:9716  t-loss:0.2552, loss-lb:0.1354, loss-ulb:0.0599, weight:2.00, lr:0.0004
[05:01:53.250] iteration:9717  t-loss:0.5089, loss-lb:0.1690, loss-ulb:0.1699, weight:2.00, lr:0.0004
[05:01:53.566] iteration:9718  t-loss:0.2888, loss-lb:0.1445, loss-ulb:0.0722, weight:2.00, lr:0.0004
[05:01:53.887] iteration:9719  t-loss:0.2106, loss-lb:0.1465, loss-ulb:0.0321, weight:2.00, lr:0.0004
[05:01:54.213] iteration:9720  t-loss:0.1743, loss-lb:0.1263, loss-ulb:0.0240, weight:2.00, lr:0.0004
[05:01:54.547] iteration:9721  t-loss:0.4341, loss-lb:0.2449, loss-ulb:0.0946, weight:2.00, lr:0.0004
[05:01:54.883] iteration:9722  t-loss:0.5362, loss-lb:0.2688, loss-ulb:0.1337, weight:2.00, lr:0.0004
[05:01:55.209] iteration:9723  t-loss:0.1769, loss-lb:0.1383, loss-ulb:0.0193, weight:2.00, lr:0.0004
[05:01:55.533] iteration:9724  t-loss:0.1695, loss-lb:0.1429, loss-ulb:0.0133, weight:2.00, lr:0.0004
[05:01:55.868] iteration:9725  t-loss:0.4985, loss-lb:0.2791, loss-ulb:0.1097, weight:2.00, lr:0.0004
[05:04:09.060] iteration 9725 : dice_score: 0.848376 best_dice: 0.850700
[05:04:09.060]  <<Test>> - Ep:388  - Dice-S/T:84.56/84.84, Best-S:84.90, Best-T:85.07
[05:04:09.060]           - AvgLoss(lb/ulb/all):0.20/0.08/0.34
[05:04:10.242] iteration:9726  t-loss:0.1751, loss-lb:0.1357, loss-ulb:0.0197, weight:2.00, lr:0.0004
[05:04:10.576] iteration:9727  t-loss:0.3551, loss-lb:0.1615, loss-ulb:0.0968, weight:2.00, lr:0.0004
[05:04:10.904] iteration:9728  t-loss:0.3363, loss-lb:0.2553, loss-ulb:0.0405, weight:2.00, lr:0.0004
[05:04:11.222] iteration:9729  t-loss:0.3460, loss-lb:0.2462, loss-ulb:0.0499, weight:2.00, lr:0.0004
[05:04:11.544] iteration:9730  t-loss:0.2562, loss-lb:0.2222, loss-ulb:0.0170, weight:2.00, lr:0.0004
[05:04:11.861] iteration:9731  t-loss:0.5766, loss-lb:0.2385, loss-ulb:0.1691, weight:2.00, lr:0.0004
[05:04:12.179] iteration:9732  t-loss:0.5167, loss-lb:0.1752, loss-ulb:0.1707, weight:2.00, lr:0.0004
[05:04:12.495] iteration:9733  t-loss:0.2275, loss-lb:0.1420, loss-ulb:0.0428, weight:2.00, lr:0.0004
[05:04:12.811] iteration:9734  t-loss:0.2366, loss-lb:0.1784, loss-ulb:0.0291, weight:2.00, lr:0.0004
[05:04:13.127] iteration:9735  t-loss:0.3915, loss-lb:0.1955, loss-ulb:0.0980, weight:2.00, lr:0.0004
[05:04:13.444] iteration:9736  t-loss:0.3058, loss-lb:0.2599, loss-ulb:0.0229, weight:2.00, lr:0.0004
[05:04:13.762] iteration:9737  t-loss:0.2879, loss-lb:0.1501, loss-ulb:0.0689, weight:2.00, lr:0.0004
[05:04:14.078] iteration:9738  t-loss:0.3942, loss-lb:0.2455, loss-ulb:0.0744, weight:2.00, lr:0.0004
[05:04:14.395] iteration:9739  t-loss:0.2043, loss-lb:0.1708, loss-ulb:0.0167, weight:2.00, lr:0.0004
[05:04:14.715] iteration:9740  t-loss:0.3196, loss-lb:0.1295, loss-ulb:0.0951, weight:2.00, lr:0.0004
[05:04:15.036] iteration:9741  t-loss:0.5809, loss-lb:0.1715, loss-ulb:0.2047, weight:2.00, lr:0.0004
[05:04:15.355] iteration:9742  t-loss:0.1790, loss-lb:0.1336, loss-ulb:0.0227, weight:2.00, lr:0.0004
[05:04:15.678] iteration:9743  t-loss:0.5165, loss-lb:0.3289, loss-ulb:0.0938, weight:2.00, lr:0.0004
[05:04:15.996] iteration:9744  t-loss:0.3826, loss-lb:0.1596, loss-ulb:0.1115, weight:2.00, lr:0.0004
[05:04:16.318] iteration:9745  t-loss:0.2545, loss-lb:0.2214, loss-ulb:0.0165, weight:2.00, lr:0.0004
[05:04:16.635] iteration:9746  t-loss:0.3173, loss-lb:0.1630, loss-ulb:0.0771, weight:2.00, lr:0.0004
[05:04:16.950] iteration:9747  t-loss:0.3830, loss-lb:0.1353, loss-ulb:0.1239, weight:2.00, lr:0.0004
[05:04:17.267] iteration:9748  t-loss:0.3960, loss-lb:0.1818, loss-ulb:0.1071, weight:2.00, lr:0.0004
[05:04:17.582] iteration:9749  t-loss:0.5365, loss-lb:0.1334, loss-ulb:0.2016, weight:2.00, lr:0.0004
[05:04:17.899] iteration:9750  t-loss:0.3640, loss-lb:0.1634, loss-ulb:0.1003, weight:2.00, lr:0.0004
[05:04:19.197] iteration:9751  t-loss:0.2929, loss-lb:0.1503, loss-ulb:0.0713, weight:2.00, lr:0.0004
[05:04:19.522] iteration:9752  t-loss:0.4438, loss-lb:0.1180, loss-ulb:0.1629, weight:2.00, lr:0.0004
[05:04:19.845] iteration:9753  t-loss:0.3916, loss-lb:0.3159, loss-ulb:0.0379, weight:2.00, lr:0.0004
[05:04:20.164] iteration:9754  t-loss:0.2437, loss-lb:0.1626, loss-ulb:0.0405, weight:2.00, lr:0.0004
[05:04:20.486] iteration:9755  t-loss:0.3650, loss-lb:0.1793, loss-ulb:0.0928, weight:2.00, lr:0.0004
[05:04:20.809] iteration:9756  t-loss:0.3885, loss-lb:0.1801, loss-ulb:0.1042, weight:2.00, lr:0.0004
[05:04:21.144] iteration:9757  t-loss:0.5497, loss-lb:0.2237, loss-ulb:0.1630, weight:2.00, lr:0.0004
[05:04:21.481] iteration:9758  t-loss:0.6370, loss-lb:0.2035, loss-ulb:0.2167, weight:2.00, lr:0.0004
[05:04:21.818] iteration:9759  t-loss:0.4866, loss-lb:0.3400, loss-ulb:0.0733, weight:2.00, lr:0.0004
[05:04:22.149] iteration:9760  t-loss:0.3661, loss-lb:0.2274, loss-ulb:0.0694, weight:2.00, lr:0.0004
[05:04:22.474] iteration:9761  t-loss:0.3939, loss-lb:0.1483, loss-ulb:0.1228, weight:2.00, lr:0.0004
[05:04:22.795] iteration:9762  t-loss:0.2476, loss-lb:0.1360, loss-ulb:0.0558, weight:2.00, lr:0.0004
[05:04:23.118] iteration:9763  t-loss:0.4026, loss-lb:0.2440, loss-ulb:0.0793, weight:2.00, lr:0.0004
[05:04:23.443] iteration:9764  t-loss:0.3790, loss-lb:0.3222, loss-ulb:0.0284, weight:2.00, lr:0.0004
[05:04:23.771] iteration:9765  t-loss:0.4561, loss-lb:0.2806, loss-ulb:0.0877, weight:2.00, lr:0.0004
[05:04:24.096] iteration:9766  t-loss:0.4267, loss-lb:0.2045, loss-ulb:0.1111, weight:2.00, lr:0.0004
[05:04:24.415] iteration:9767  t-loss:0.3482, loss-lb:0.2553, loss-ulb:0.0464, weight:2.00, lr:0.0004
[05:04:24.731] iteration:9768  t-loss:0.3943, loss-lb:0.2421, loss-ulb:0.0761, weight:2.00, lr:0.0004
[05:04:25.048] iteration:9769  t-loss:0.2539, loss-lb:0.1555, loss-ulb:0.0492, weight:2.00, lr:0.0004
[05:04:25.366] iteration:9770  t-loss:0.2525, loss-lb:0.1850, loss-ulb:0.0338, weight:2.00, lr:0.0004
[05:04:25.683] iteration:9771  t-loss:0.4392, loss-lb:0.1625, loss-ulb:0.1383, weight:2.00, lr:0.0004
[05:04:26.004] iteration:9772  t-loss:0.2905, loss-lb:0.1260, loss-ulb:0.0822, weight:2.00, lr:0.0004
[05:04:26.329] iteration:9773  t-loss:0.2423, loss-lb:0.1218, loss-ulb:0.0602, weight:2.00, lr:0.0004
[05:04:26.647] iteration:9774  t-loss:0.1873, loss-lb:0.1459, loss-ulb:0.0207, weight:2.00, lr:0.0004
[05:04:26.967] iteration:9775  t-loss:0.3050, loss-lb:0.2563, loss-ulb:0.0243, weight:2.00, lr:0.0004
[05:04:28.122] iteration:9776  t-loss:0.3110, loss-lb:0.1550, loss-ulb:0.0780, weight:2.00, lr:0.0004
[05:04:28.459] iteration:9777  t-loss:0.4674, loss-lb:0.2791, loss-ulb:0.0942, weight:2.00, lr:0.0004
[05:04:28.787] iteration:9778  t-loss:0.3527, loss-lb:0.2264, loss-ulb:0.0632, weight:2.00, lr:0.0004
[05:04:29.113] iteration:9779  t-loss:0.4159, loss-lb:0.1609, loss-ulb:0.1275, weight:2.00, lr:0.0004
[05:04:29.437] iteration:9780  t-loss:0.1805, loss-lb:0.1320, loss-ulb:0.0242, weight:2.00, lr:0.0004
[05:04:29.768] iteration:9781  t-loss:0.3432, loss-lb:0.2039, loss-ulb:0.0697, weight:2.00, lr:0.0004
[05:04:30.106] iteration:9782  t-loss:0.3206, loss-lb:0.1835, loss-ulb:0.0686, weight:2.00, lr:0.0004
[05:04:30.434] iteration:9783  t-loss:0.4012, loss-lb:0.1747, loss-ulb:0.1132, weight:2.00, lr:0.0004
[05:04:30.767] iteration:9784  t-loss:0.2791, loss-lb:0.2263, loss-ulb:0.0264, weight:2.00, lr:0.0004
[05:04:31.096] iteration:9785  t-loss:0.2086, loss-lb:0.1715, loss-ulb:0.0186, weight:2.00, lr:0.0004
[05:04:31.418] iteration:9786  t-loss:0.2829, loss-lb:0.2224, loss-ulb:0.0302, weight:2.00, lr:0.0004
[05:04:31.743] iteration:9787  t-loss:0.4129, loss-lb:0.1376, loss-ulb:0.1377, weight:2.00, lr:0.0004
[05:04:32.079] iteration:9788  t-loss:0.2431, loss-lb:0.1906, loss-ulb:0.0262, weight:2.00, lr:0.0004
[05:04:32.401] iteration:9789  t-loss:0.2916, loss-lb:0.2514, loss-ulb:0.0201, weight:2.00, lr:0.0004
[05:04:32.722] iteration:9790  t-loss:0.2015, loss-lb:0.1291, loss-ulb:0.0362, weight:2.00, lr:0.0004
[05:04:33.048] iteration:9791  t-loss:0.9231, loss-lb:0.2611, loss-ulb:0.3310, weight:2.00, lr:0.0004
[05:04:33.365] iteration:9792  t-loss:0.4015, loss-lb:0.1428, loss-ulb:0.1293, weight:2.00, lr:0.0004
[05:04:33.686] iteration:9793  t-loss:0.2653, loss-lb:0.1677, loss-ulb:0.0488, weight:2.00, lr:0.0004
[05:04:34.002] iteration:9794  t-loss:0.2244, loss-lb:0.1752, loss-ulb:0.0246, weight:2.00, lr:0.0004
[05:04:34.319] iteration:9795  t-loss:0.2670, loss-lb:0.1881, loss-ulb:0.0395, weight:2.00, lr:0.0004
[05:04:34.638] iteration:9796  t-loss:0.3945, loss-lb:0.1664, loss-ulb:0.1140, weight:2.00, lr:0.0004
[05:04:34.953] iteration:9797  t-loss:0.3857, loss-lb:0.2227, loss-ulb:0.0815, weight:2.00, lr:0.0004
[05:04:35.271] iteration:9798  t-loss:0.6616, loss-lb:0.2501, loss-ulb:0.2058, weight:2.00, lr:0.0004
[05:04:35.586] iteration:9799  t-loss:0.2109, loss-lb:0.1728, loss-ulb:0.0190, weight:2.00, lr:0.0004
[05:04:35.902] iteration:9800  t-loss:0.3732, loss-lb:0.1969, loss-ulb:0.0882, weight:2.00, lr:0.0004
[05:04:37.288] iteration:9801  t-loss:0.5090, loss-lb:0.1801, loss-ulb:0.1645, weight:2.00, lr:0.0004
[05:04:37.622] iteration:9802  t-loss:0.3242, loss-lb:0.2185, loss-ulb:0.0529, weight:2.00, lr:0.0004
[05:04:37.955] iteration:9803  t-loss:0.5680, loss-lb:0.3341, loss-ulb:0.1169, weight:2.00, lr:0.0004
[05:04:38.294] iteration:9804  t-loss:0.3945, loss-lb:0.2515, loss-ulb:0.0715, weight:2.00, lr:0.0004
[05:04:38.627] iteration:9805  t-loss:0.3119, loss-lb:0.1470, loss-ulb:0.0825, weight:2.00, lr:0.0004
[05:04:38.956] iteration:9806  t-loss:0.2024, loss-lb:0.1667, loss-ulb:0.0178, weight:2.00, lr:0.0004
[05:04:39.287] iteration:9807  t-loss:0.3421, loss-lb:0.1920, loss-ulb:0.0750, weight:2.00, lr:0.0004
[05:04:39.628] iteration:9808  t-loss:0.1934, loss-lb:0.1319, loss-ulb:0.0307, weight:2.00, lr:0.0004
[05:04:39.958] iteration:9809  t-loss:0.4449, loss-lb:0.3018, loss-ulb:0.0716, weight:2.00, lr:0.0004
[05:04:40.288] iteration:9810  t-loss:0.2468, loss-lb:0.2061, loss-ulb:0.0203, weight:2.00, lr:0.0004
[05:04:40.613] iteration:9811  t-loss:0.8440, loss-lb:0.1414, loss-ulb:0.3513, weight:2.00, lr:0.0004
[05:04:40.964] iteration:9812  t-loss:0.2517, loss-lb:0.2106, loss-ulb:0.0205, weight:2.00, lr:0.0004
[05:04:41.291] iteration:9813  t-loss:0.3798, loss-lb:0.2093, loss-ulb:0.0852, weight:2.00, lr:0.0004
[05:04:41.621] iteration:9814  t-loss:0.5867, loss-lb:0.2800, loss-ulb:0.1534, weight:2.00, lr:0.0004
[05:04:41.948] iteration:9815  t-loss:0.3113, loss-lb:0.1420, loss-ulb:0.0846, weight:2.00, lr:0.0004
[05:04:42.271] iteration:9816  t-loss:0.2803, loss-lb:0.2129, loss-ulb:0.0337, weight:2.00, lr:0.0004
[05:04:42.599] iteration:9817  t-loss:0.3417, loss-lb:0.2171, loss-ulb:0.0623, weight:2.00, lr:0.0004
[05:04:42.922] iteration:9818  t-loss:0.2671, loss-lb:0.1806, loss-ulb:0.0433, weight:2.00, lr:0.0004
[05:04:43.246] iteration:9819  t-loss:0.7855, loss-lb:0.2911, loss-ulb:0.2472, weight:2.00, lr:0.0004
[05:04:43.562] iteration:9820  t-loss:0.4982, loss-lb:0.3141, loss-ulb:0.0921, weight:2.00, lr:0.0004
[05:04:43.880] iteration:9821  t-loss:0.3081, loss-lb:0.1292, loss-ulb:0.0895, weight:2.00, lr:0.0004
[05:04:44.205] iteration:9822  t-loss:0.2556, loss-lb:0.1469, loss-ulb:0.0544, weight:2.00, lr:0.0004
[05:04:44.528] iteration:9823  t-loss:0.4345, loss-lb:0.2298, loss-ulb:0.1023, weight:2.00, lr:0.0004
[05:04:44.855] iteration:9824  t-loss:0.3277, loss-lb:0.1529, loss-ulb:0.0874, weight:2.00, lr:0.0004
[05:04:45.182] iteration:9825  t-loss:0.3561, loss-lb:0.1826, loss-ulb:0.0867, weight:2.00, lr:0.0004
[05:06:53.016] iteration 9825 : dice_score: 0.848003 best_dice: 0.850700
[05:06:53.016]  <<Test>> - Ep:392  - Dice-S/T:84.53/84.80, Best-S:84.90, Best-T:85.07
[05:06:53.016]           - AvgLoss(lb/ulb/all):0.21/0.09/0.38
[05:06:54.225] iteration:9826  t-loss:0.3284, loss-lb:0.1558, loss-ulb:0.0863, weight:2.00, lr:0.0004
[05:06:54.561] iteration:9827  t-loss:0.2758, loss-lb:0.1475, loss-ulb:0.0642, weight:2.00, lr:0.0004
[05:06:54.887] iteration:9828  t-loss:0.3524, loss-lb:0.1559, loss-ulb:0.0983, weight:2.00, lr:0.0004
[05:06:55.211] iteration:9829  t-loss:0.3563, loss-lb:0.1998, loss-ulb:0.0783, weight:2.00, lr:0.0004
[05:06:55.529] iteration:9830  t-loss:0.3318, loss-lb:0.1869, loss-ulb:0.0725, weight:2.00, lr:0.0004
[05:06:55.851] iteration:9831  t-loss:0.6150, loss-lb:0.1514, loss-ulb:0.2318, weight:2.00, lr:0.0004
[05:06:56.169] iteration:9832  t-loss:0.3994, loss-lb:0.2336, loss-ulb:0.0829, weight:2.00, lr:0.0004
[05:06:56.487] iteration:9833  t-loss:0.3121, loss-lb:0.1623, loss-ulb:0.0749, weight:2.00, lr:0.0004
[05:06:56.807] iteration:9834  t-loss:0.8837, loss-lb:0.2022, loss-ulb:0.3407, weight:2.00, lr:0.0004
[05:06:57.129] iteration:9835  t-loss:0.1667, loss-lb:0.1284, loss-ulb:0.0191, weight:2.00, lr:0.0004
[05:06:57.447] iteration:9836  t-loss:0.3415, loss-lb:0.1811, loss-ulb:0.0802, weight:2.00, lr:0.0004
[05:06:57.768] iteration:9837  t-loss:0.2812, loss-lb:0.1986, loss-ulb:0.0413, weight:2.00, lr:0.0004
[05:06:58.088] iteration:9838  t-loss:0.2934, loss-lb:0.2586, loss-ulb:0.0174, weight:2.00, lr:0.0004
[05:06:58.405] iteration:9839  t-loss:0.3890, loss-lb:0.1416, loss-ulb:0.1237, weight:2.00, lr:0.0004
[05:06:58.729] iteration:9840  t-loss:0.3927, loss-lb:0.2296, loss-ulb:0.0816, weight:2.00, lr:0.0004
[05:06:59.050] iteration:9841  t-loss:0.5820, loss-lb:0.2445, loss-ulb:0.1688, weight:2.00, lr:0.0004
[05:06:59.368] iteration:9842  t-loss:0.3100, loss-lb:0.1734, loss-ulb:0.0683, weight:2.00, lr:0.0004
[05:06:59.683] iteration:9843  t-loss:0.2193, loss-lb:0.1582, loss-ulb:0.0306, weight:2.00, lr:0.0004
[05:06:59.997] iteration:9844  t-loss:0.4453, loss-lb:0.4041, loss-ulb:0.0206, weight:2.00, lr:0.0004
[05:07:00.311] iteration:9845  t-loss:0.3232, loss-lb:0.2334, loss-ulb:0.0449, weight:2.00, lr:0.0004
[05:07:00.627] iteration:9846  t-loss:0.2095, loss-lb:0.1755, loss-ulb:0.0170, weight:2.00, lr:0.0004
[05:07:00.943] iteration:9847  t-loss:0.2339, loss-lb:0.1419, loss-ulb:0.0460, weight:2.00, lr:0.0004
[05:07:01.261] iteration:9848  t-loss:0.4470, loss-lb:0.2044, loss-ulb:0.1213, weight:2.00, lr:0.0004
[05:07:01.575] iteration:9849  t-loss:0.2598, loss-lb:0.1485, loss-ulb:0.0557, weight:2.00, lr:0.0004
[05:07:01.893] iteration:9850  t-loss:0.3490, loss-lb:0.2154, loss-ulb:0.0668, weight:2.00, lr:0.0004
[05:07:03.100] iteration:9851  t-loss:0.4227, loss-lb:0.2375, loss-ulb:0.0926, weight:2.00, lr:0.0004
[05:07:03.446] iteration:9852  t-loss:0.4336, loss-lb:0.2079, loss-ulb:0.1129, weight:2.00, lr:0.0004
[05:07:03.779] iteration:9853  t-loss:0.3054, loss-lb:0.1344, loss-ulb:0.0855, weight:2.00, lr:0.0004
[05:07:04.112] iteration:9854  t-loss:0.4986, loss-lb:0.2985, loss-ulb:0.1001, weight:2.00, lr:0.0004
[05:07:04.446] iteration:9855  t-loss:0.3165, loss-lb:0.1979, loss-ulb:0.0593, weight:2.00, lr:0.0004
[05:07:04.775] iteration:9856  t-loss:0.3554, loss-lb:0.1812, loss-ulb:0.0871, weight:2.00, lr:0.0004
[05:07:05.093] iteration:9857  t-loss:0.4599, loss-lb:0.2148, loss-ulb:0.1225, weight:2.00, lr:0.0004
[05:07:05.424] iteration:9858  t-loss:0.6989, loss-lb:0.3165, loss-ulb:0.1912, weight:2.00, lr:0.0004
[05:07:05.747] iteration:9859  t-loss:0.4145, loss-lb:0.2602, loss-ulb:0.0771, weight:2.00, lr:0.0004
[05:07:06.066] iteration:9860  t-loss:0.2452, loss-lb:0.1328, loss-ulb:0.0562, weight:2.00, lr:0.0004
[05:07:06.383] iteration:9861  t-loss:0.1846, loss-lb:0.1414, loss-ulb:0.0216, weight:2.00, lr:0.0004
[05:07:06.705] iteration:9862  t-loss:0.6276, loss-lb:0.3717, loss-ulb:0.1279, weight:2.00, lr:0.0004
[05:07:07.026] iteration:9863  t-loss:0.2546, loss-lb:0.1665, loss-ulb:0.0441, weight:2.00, lr:0.0004
[05:07:07.350] iteration:9864  t-loss:0.2286, loss-lb:0.1851, loss-ulb:0.0218, weight:2.00, lr:0.0004
[05:07:07.682] iteration:9865  t-loss:0.3435, loss-lb:0.2214, loss-ulb:0.0610, weight:2.00, lr:0.0004
[05:07:08.016] iteration:9866  t-loss:0.4399, loss-lb:0.2182, loss-ulb:0.1108, weight:2.00, lr:0.0004
[05:07:08.351] iteration:9867  t-loss:0.2652, loss-lb:0.1473, loss-ulb:0.0590, weight:2.00, lr:0.0004
[05:07:08.675] iteration:9868  t-loss:0.3233, loss-lb:0.2499, loss-ulb:0.0367, weight:2.00, lr:0.0004
[05:07:09.020] iteration:9869  t-loss:0.2142, loss-lb:0.1731, loss-ulb:0.0206, weight:2.00, lr:0.0004
[05:07:09.341] iteration:9870  t-loss:0.2595, loss-lb:0.1273, loss-ulb:0.0661, weight:2.00, lr:0.0004
[05:07:09.666] iteration:9871  t-loss:0.1592, loss-lb:0.1223, loss-ulb:0.0185, weight:2.00, lr:0.0004
[05:07:09.982] iteration:9872  t-loss:0.1973, loss-lb:0.1520, loss-ulb:0.0226, weight:2.00, lr:0.0004
[05:07:10.304] iteration:9873  t-loss:0.4632, loss-lb:0.2411, loss-ulb:0.1111, weight:2.00, lr:0.0004
[05:07:10.619] iteration:9874  t-loss:0.2426, loss-lb:0.1540, loss-ulb:0.0443, weight:2.00, lr:0.0004
[05:07:10.937] iteration:9875  t-loss:0.2302, loss-lb:0.1498, loss-ulb:0.0402, weight:2.00, lr:0.0004
[05:07:12.236] iteration:9876  t-loss:0.2172, loss-lb:0.1840, loss-ulb:0.0166, weight:2.00, lr:0.0004
[05:07:12.570] iteration:9877  t-loss:0.3445, loss-lb:0.1594, loss-ulb:0.0926, weight:2.00, lr:0.0004
[05:07:12.898] iteration:9878  t-loss:0.1769, loss-lb:0.1315, loss-ulb:0.0227, weight:2.00, lr:0.0004
[05:07:13.222] iteration:9879  t-loss:0.4432, loss-lb:0.2506, loss-ulb:0.0963, weight:2.00, lr:0.0004
[05:07:13.539] iteration:9880  t-loss:0.3734, loss-lb:0.1679, loss-ulb:0.1028, weight:2.00, lr:0.0004
[05:07:13.855] iteration:9881  t-loss:0.3422, loss-lb:0.3161, loss-ulb:0.0131, weight:2.00, lr:0.0004
[05:07:14.172] iteration:9882  t-loss:0.3864, loss-lb:0.1987, loss-ulb:0.0938, weight:2.00, lr:0.0004
[05:07:14.489] iteration:9883  t-loss:0.2048, loss-lb:0.1424, loss-ulb:0.0312, weight:2.00, lr:0.0004
[05:07:14.806] iteration:9884  t-loss:0.3748, loss-lb:0.2165, loss-ulb:0.0792, weight:2.00, lr:0.0004
[05:07:15.122] iteration:9885  t-loss:0.3498, loss-lb:0.2504, loss-ulb:0.0497, weight:2.00, lr:0.0004
[05:07:15.439] iteration:9886  t-loss:0.3096, loss-lb:0.2592, loss-ulb:0.0252, weight:2.00, lr:0.0004
[05:07:15.759] iteration:9887  t-loss:0.4530, loss-lb:0.2680, loss-ulb:0.0925, weight:2.00, lr:0.0004
[05:07:16.088] iteration:9888  t-loss:0.3685, loss-lb:0.2654, loss-ulb:0.0515, weight:2.00, lr:0.0004
[05:07:16.422] iteration:9889  t-loss:0.5370, loss-lb:0.1899, loss-ulb:0.1735, weight:2.00, lr:0.0004
[05:07:16.762] iteration:9890  t-loss:0.4066, loss-lb:0.2513, loss-ulb:0.0777, weight:2.00, lr:0.0004
[05:07:17.091] iteration:9891  t-loss:0.4095, loss-lb:0.2143, loss-ulb:0.0976, weight:2.00, lr:0.0004
[05:07:17.426] iteration:9892  t-loss:0.2823, loss-lb:0.1415, loss-ulb:0.0704, weight:2.00, lr:0.0004
[05:07:17.753] iteration:9893  t-loss:0.5803, loss-lb:0.2614, loss-ulb:0.1594, weight:2.00, lr:0.0004
[05:07:18.075] iteration:9894  t-loss:0.2293, loss-lb:0.1884, loss-ulb:0.0205, weight:2.00, lr:0.0004
[05:07:18.407] iteration:9895  t-loss:0.5299, loss-lb:0.2095, loss-ulb:0.1602, weight:2.00, lr:0.0004
[05:07:18.744] iteration:9896  t-loss:0.5023, loss-lb:0.1498, loss-ulb:0.1762, weight:2.00, lr:0.0004
[05:07:19.073] iteration:9897  t-loss:0.3641, loss-lb:0.1883, loss-ulb:0.0879, weight:2.00, lr:0.0004
[05:07:19.401] iteration:9898  t-loss:0.3992, loss-lb:0.1851, loss-ulb:0.1071, weight:2.00, lr:0.0004
[05:07:19.728] iteration:9899  t-loss:0.5248, loss-lb:0.3934, loss-ulb:0.0657, weight:2.00, lr:0.0004
[05:07:20.046] iteration:9900  t-loss:0.2418, loss-lb:0.1881, loss-ulb:0.0268, weight:2.00, lr:0.0004
[05:07:21.830] iteration:9901  t-loss:0.2947, loss-lb:0.1546, loss-ulb:0.0701, weight:2.00, lr:0.0004
[05:07:22.166] iteration:9902  t-loss:0.2028, loss-lb:0.1103, loss-ulb:0.0462, weight:2.00, lr:0.0004
[05:07:22.488] iteration:9903  t-loss:0.2982, loss-lb:0.2573, loss-ulb:0.0204, weight:2.00, lr:0.0004
[05:07:22.807] iteration:9904  t-loss:0.2257, loss-lb:0.1719, loss-ulb:0.0269, weight:2.00, lr:0.0004
[05:07:23.125] iteration:9905  t-loss:0.2475, loss-lb:0.2141, loss-ulb:0.0167, weight:2.00, lr:0.0004
[05:07:23.451] iteration:9906  t-loss:0.5170, loss-lb:0.4136, loss-ulb:0.0517, weight:2.00, lr:0.0004
[05:07:23.770] iteration:9907  t-loss:0.7141, loss-lb:0.2886, loss-ulb:0.2127, weight:2.00, lr:0.0004
[05:07:24.091] iteration:9908  t-loss:0.3847, loss-lb:0.1191, loss-ulb:0.1328, weight:2.00, lr:0.0004
[05:07:24.413] iteration:9909  t-loss:0.2748, loss-lb:0.1343, loss-ulb:0.0702, weight:2.00, lr:0.0004
[05:07:24.752] iteration:9910  t-loss:0.3428, loss-lb:0.2226, loss-ulb:0.0601, weight:2.00, lr:0.0004
[05:07:25.082] iteration:9911  t-loss:0.3528, loss-lb:0.1791, loss-ulb:0.0869, weight:2.00, lr:0.0004
[05:07:25.420] iteration:9912  t-loss:0.5755, loss-lb:0.1861, loss-ulb:0.1947, weight:2.00, lr:0.0004
[05:07:25.755] iteration:9913  t-loss:0.2694, loss-lb:0.2307, loss-ulb:0.0193, weight:2.00, lr:0.0004
[05:07:26.090] iteration:9914  t-loss:0.3295, loss-lb:0.1976, loss-ulb:0.0660, weight:2.00, lr:0.0004
[05:07:26.420] iteration:9915  t-loss:0.2051, loss-lb:0.1424, loss-ulb:0.0313, weight:2.00, lr:0.0004
[05:07:26.744] iteration:9916  t-loss:0.3346, loss-lb:0.1748, loss-ulb:0.0799, weight:2.00, lr:0.0004
[05:07:27.067] iteration:9917  t-loss:0.3671, loss-lb:0.2234, loss-ulb:0.0718, weight:2.00, lr:0.0004
[05:07:27.393] iteration:9918  t-loss:0.2068, loss-lb:0.1397, loss-ulb:0.0335, weight:2.00, lr:0.0004
[05:07:27.713] iteration:9919  t-loss:0.3155, loss-lb:0.1594, loss-ulb:0.0780, weight:2.00, lr:0.0004
[05:07:28.036] iteration:9920  t-loss:0.4773, loss-lb:0.2901, loss-ulb:0.0936, weight:2.00, lr:0.0004
[05:07:28.362] iteration:9921  t-loss:0.3334, loss-lb:0.2629, loss-ulb:0.0353, weight:2.00, lr:0.0004
[05:07:28.684] iteration:9922  t-loss:0.2904, loss-lb:0.2507, loss-ulb:0.0199, weight:2.00, lr:0.0004
[05:07:29.004] iteration:9923  t-loss:0.1853, loss-lb:0.1525, loss-ulb:0.0164, weight:2.00, lr:0.0004
[05:07:29.319] iteration:9924  t-loss:0.2027, loss-lb:0.1685, loss-ulb:0.0171, weight:2.00, lr:0.0004
[05:07:29.636] iteration:9925  t-loss:0.4511, loss-lb:0.2848, loss-ulb:0.0831, weight:2.00, lr:0.0004
[05:09:39.673] iteration 9925 : dice_score: 0.850797 best_dice: 0.850800
[05:09:39.673]  <<Test>> - Ep:396  - Dice-S/T:84.71/85.08, Best-S:84.90, Best-T:85.08
[05:09:39.673]           - AvgLoss(lb/ulb/all):0.21/0.07/0.36
[05:09:40.863] iteration:9926  t-loss:0.4678, loss-lb:0.2026, loss-ulb:0.1326, weight:2.00, lr:0.0004
[05:09:41.192] iteration:9927  t-loss:0.2147, loss-lb:0.1641, loss-ulb:0.0253, weight:2.00, lr:0.0004
[05:09:41.521] iteration:9928  t-loss:0.2857, loss-lb:0.2408, loss-ulb:0.0225, weight:2.00, lr:0.0004
[05:09:41.847] iteration:9929  t-loss:0.4645, loss-lb:0.1970, loss-ulb:0.1338, weight:2.00, lr:0.0004
[05:09:42.166] iteration:9930  t-loss:0.2350, loss-lb:0.1300, loss-ulb:0.0525, weight:2.00, lr:0.0004
[05:09:42.488] iteration:9931  t-loss:0.3016, loss-lb:0.2357, loss-ulb:0.0329, weight:2.00, lr:0.0004
[05:09:42.809] iteration:9932  t-loss:0.4314, loss-lb:0.2368, loss-ulb:0.0973, weight:2.00, lr:0.0004
[05:09:43.128] iteration:9933  t-loss:0.2530, loss-lb:0.1568, loss-ulb:0.0481, weight:2.00, lr:0.0004
[05:09:43.454] iteration:9934  t-loss:0.3284, loss-lb:0.1638, loss-ulb:0.0823, weight:2.00, lr:0.0004
[05:09:43.776] iteration:9935  t-loss:0.3407, loss-lb:0.1768, loss-ulb:0.0820, weight:2.00, lr:0.0004
[05:09:44.113] iteration:9936  t-loss:0.3288, loss-lb:0.1872, loss-ulb:0.0708, weight:2.00, lr:0.0004
[05:09:44.445] iteration:9937  t-loss:0.4754, loss-lb:0.2246, loss-ulb:0.1254, weight:2.00, lr:0.0004
[05:09:44.772] iteration:9938  t-loss:0.5651, loss-lb:0.1552, loss-ulb:0.2049, weight:2.00, lr:0.0004
[05:09:45.104] iteration:9939  t-loss:0.3289, loss-lb:0.1336, loss-ulb:0.0977, weight:2.00, lr:0.0004
[05:09:45.430] iteration:9940  t-loss:0.1866, loss-lb:0.1595, loss-ulb:0.0136, weight:2.00, lr:0.0004
[05:09:45.755] iteration:9941  t-loss:0.1625, loss-lb:0.1126, loss-ulb:0.0250, weight:2.00, lr:0.0004
[05:09:46.081] iteration:9942  t-loss:0.4889, loss-lb:0.2461, loss-ulb:0.1214, weight:2.00, lr:0.0004
[05:09:46.408] iteration:9943  t-loss:0.4658, loss-lb:0.2714, loss-ulb:0.0972, weight:2.00, lr:0.0004
[05:09:46.726] iteration:9944  t-loss:0.4086, loss-lb:0.2205, loss-ulb:0.0941, weight:2.00, lr:0.0004
[05:09:47.045] iteration:9945  t-loss:0.2332, loss-lb:0.1449, loss-ulb:0.0441, weight:2.00, lr:0.0004
[05:09:47.365] iteration:9946  t-loss:0.3475, loss-lb:0.2204, loss-ulb:0.0636, weight:2.00, lr:0.0004
[05:09:47.684] iteration:9947  t-loss:0.1693, loss-lb:0.1410, loss-ulb:0.0141, weight:2.00, lr:0.0004
[05:09:48.009] iteration:9948  t-loss:0.4421, loss-lb:0.3011, loss-ulb:0.0705, weight:2.00, lr:0.0004
[05:09:48.336] iteration:9949  t-loss:0.4436, loss-lb:0.2463, loss-ulb:0.0987, weight:2.00, lr:0.0004
[05:09:48.661] iteration:9950  t-loss:0.2970, loss-lb:0.2598, loss-ulb:0.0186, weight:2.00, lr:0.0004
[05:09:50.221] iteration:9951  t-loss:0.4850, loss-lb:0.2996, loss-ulb:0.0927, weight:2.00, lr:0.0004
[05:09:50.549] iteration:9952  t-loss:0.6070, loss-lb:0.3663, loss-ulb:0.1203, weight:2.00, lr:0.0004
[05:09:50.870] iteration:9953  t-loss:0.3345, loss-lb:0.2226, loss-ulb:0.0560, weight:2.00, lr:0.0004
[05:09:51.189] iteration:9954  t-loss:0.2777, loss-lb:0.1420, loss-ulb:0.0679, weight:2.00, lr:0.0004
[05:09:51.508] iteration:9955  t-loss:0.2080, loss-lb:0.1802, loss-ulb:0.0139, weight:2.00, lr:0.0004
[05:09:51.822] iteration:9956  t-loss:0.2289, loss-lb:0.1549, loss-ulb:0.0370, weight:2.00, lr:0.0004
[05:09:52.139] iteration:9957  t-loss:0.4413, loss-lb:0.2702, loss-ulb:0.0856, weight:2.00, lr:0.0004
[05:09:52.460] iteration:9958  t-loss:0.2528, loss-lb:0.1343, loss-ulb:0.0593, weight:2.00, lr:0.0004
[05:09:52.792] iteration:9959  t-loss:0.2952, loss-lb:0.1501, loss-ulb:0.0726, weight:2.00, lr:0.0004
[05:09:53.122] iteration:9960  t-loss:0.6763, loss-lb:0.3115, loss-ulb:0.1824, weight:2.00, lr:0.0004
[05:09:53.454] iteration:9961  t-loss:0.2035, loss-lb:0.1748, loss-ulb:0.0144, weight:2.00, lr:0.0004
[05:09:53.783] iteration:9962  t-loss:0.3342, loss-lb:0.2972, loss-ulb:0.0185, weight:2.00, lr:0.0004
[05:09:54.112] iteration:9963  t-loss:0.3485, loss-lb:0.2748, loss-ulb:0.0369, weight:2.00, lr:0.0004
[05:09:54.433] iteration:9964  t-loss:0.3612, loss-lb:0.3035, loss-ulb:0.0288, weight:2.00, lr:0.0004
[05:09:54.754] iteration:9965  t-loss:0.3102, loss-lb:0.1653, loss-ulb:0.0724, weight:2.00, lr:0.0004
[05:09:55.075] iteration:9966  t-loss:0.1892, loss-lb:0.1572, loss-ulb:0.0160, weight:2.00, lr:0.0004
[05:09:55.400] iteration:9967  t-loss:0.3448, loss-lb:0.2259, loss-ulb:0.0594, weight:2.00, lr:0.0004
[05:09:55.722] iteration:9968  t-loss:0.1577, loss-lb:0.1234, loss-ulb:0.0171, weight:2.00, lr:0.0004
[05:09:56.047] iteration:9969  t-loss:0.3398, loss-lb:0.1734, loss-ulb:0.0832, weight:2.00, lr:0.0004
[05:09:56.367] iteration:9970  t-loss:0.3982, loss-lb:0.1568, loss-ulb:0.1207, weight:2.00, lr:0.0004
[05:09:56.686] iteration:9971  t-loss:0.3208, loss-lb:0.1339, loss-ulb:0.0935, weight:2.00, lr:0.0004
[05:09:57.007] iteration:9972  t-loss:0.3585, loss-lb:0.1499, loss-ulb:0.1043, weight:2.00, lr:0.0004
[05:09:57.326] iteration:9973  t-loss:0.3259, loss-lb:0.1771, loss-ulb:0.0744, weight:2.00, lr:0.0004
[05:09:57.644] iteration:9974  t-loss:0.2028, loss-lb:0.1710, loss-ulb:0.0159, weight:2.00, lr:0.0004
[05:09:57.960] iteration:9975  t-loss:0.1920, loss-lb:0.1344, loss-ulb:0.0288, weight:2.00, lr:0.0004
[05:09:59.320] iteration:9976  t-loss:0.2528, loss-lb:0.2163, loss-ulb:0.0183, weight:2.00, lr:0.0004
[05:09:59.647] iteration:9977  t-loss:0.3321, loss-lb:0.1744, loss-ulb:0.0789, weight:2.00, lr:0.0004
[05:09:59.968] iteration:9978  t-loss:0.2913, loss-lb:0.1661, loss-ulb:0.0626, weight:2.00, lr:0.0004
[05:10:00.291] iteration:9979  t-loss:0.4445, loss-lb:0.2665, loss-ulb:0.0890, weight:2.00, lr:0.0004
[05:10:00.606] iteration:9980  t-loss:0.3495, loss-lb:0.1830, loss-ulb:0.0833, weight:2.00, lr:0.0004
[05:10:00.927] iteration:9981  t-loss:0.3077, loss-lb:0.1388, loss-ulb:0.0845, weight:2.00, lr:0.0004
[05:10:01.255] iteration:9982  t-loss:0.2806, loss-lb:0.1822, loss-ulb:0.0492, weight:2.00, lr:0.0004
[05:10:01.586] iteration:9983  t-loss:0.4555, loss-lb:0.1628, loss-ulb:0.1463, weight:2.00, lr:0.0004
[05:10:01.917] iteration:9984  t-loss:0.4260, loss-lb:0.2619, loss-ulb:0.0820, weight:2.00, lr:0.0004
[05:10:02.239] iteration:9985  t-loss:0.3346, loss-lb:0.1743, loss-ulb:0.0802, weight:2.00, lr:0.0004
[05:10:02.561] iteration:9986  t-loss:0.2699, loss-lb:0.1679, loss-ulb:0.0510, weight:2.00, lr:0.0004
[05:10:02.880] iteration:9987  t-loss:0.1648, loss-lb:0.1381, loss-ulb:0.0134, weight:2.00, lr:0.0004
[05:10:03.208] iteration:9988  t-loss:0.2890, loss-lb:0.1394, loss-ulb:0.0748, weight:2.00, lr:0.0004
[05:10:03.527] iteration:9989  t-loss:0.4142, loss-lb:0.2502, loss-ulb:0.0820, weight:2.00, lr:0.0004
[05:10:03.849] iteration:9990  t-loss:0.3947, loss-lb:0.1600, loss-ulb:0.1174, weight:2.00, lr:0.0004
[05:10:04.165] iteration:9991  t-loss:0.4202, loss-lb:0.1304, loss-ulb:0.1449, weight:2.00, lr:0.0004
[05:10:04.484] iteration:9992  t-loss:0.4671, loss-lb:0.1691, loss-ulb:0.1490, weight:2.00, lr:0.0004
[05:10:04.802] iteration:9993  t-loss:0.3064, loss-lb:0.2562, loss-ulb:0.0251, weight:2.00, lr:0.0004
[05:10:05.123] iteration:9994  t-loss:0.3730, loss-lb:0.2827, loss-ulb:0.0451, weight:2.00, lr:0.0004
[05:10:05.442] iteration:9995  t-loss:0.2400, loss-lb:0.1673, loss-ulb:0.0364, weight:2.00, lr:0.0004
[05:10:05.760] iteration:9996  t-loss:0.2642, loss-lb:0.2312, loss-ulb:0.0165, weight:2.00, lr:0.0004
[05:10:06.074] iteration:9997  t-loss:0.1491, loss-lb:0.1194, loss-ulb:0.0149, weight:2.00, lr:0.0004
[05:10:06.395] iteration:9998  t-loss:0.4195, loss-lb:0.2690, loss-ulb:0.0753, weight:2.00, lr:0.0004
[05:10:06.712] iteration:9999  t-loss:0.3336, loss-lb:0.2464, loss-ulb:0.0436, weight:2.00, lr:0.0004
[05:10:07.032] iteration:10000  t-loss:0.3137, loss-lb:0.1830, loss-ulb:0.0654, weight:2.00, lr:0.0004
[05:10:08.445] iteration:10001  t-loss:0.7906, loss-lb:0.3851, loss-ulb:0.2027, weight:2.00, lr:0.0004
[05:10:08.771] iteration:10002  t-loss:0.5426, loss-lb:0.2329, loss-ulb:0.1549, weight:2.00, lr:0.0004
[05:10:09.092] iteration:10003  t-loss:0.2470, loss-lb:0.2180, loss-ulb:0.0145, weight:2.00, lr:0.0004
[05:10:09.416] iteration:10004  t-loss:0.2755, loss-lb:0.1972, loss-ulb:0.0391, weight:2.00, lr:0.0004
[05:10:09.748] iteration:10005  t-loss:0.3113, loss-lb:0.1564, loss-ulb:0.0775, weight:2.00, lr:0.0004
[05:10:10.086] iteration:10006  t-loss:0.4668, loss-lb:0.3962, loss-ulb:0.0353, weight:2.00, lr:0.0004
[05:10:10.430] iteration:10007  t-loss:0.2411, loss-lb:0.1566, loss-ulb:0.0423, weight:2.00, lr:0.0004
[05:10:10.765] iteration:10008  t-loss:0.2790, loss-lb:0.1863, loss-ulb:0.0463, weight:2.00, lr:0.0004
[05:10:11.107] iteration:10009  t-loss:0.2474, loss-lb:0.1563, loss-ulb:0.0455, weight:2.00, lr:0.0004
[05:10:11.452] iteration:10010  t-loss:0.2138, loss-lb:0.1650, loss-ulb:0.0244, weight:2.00, lr:0.0004
[05:10:11.801] iteration:10011  t-loss:0.1907, loss-lb:0.1531, loss-ulb:0.0188, weight:2.00, lr:0.0004
[05:10:12.148] iteration:10012  t-loss:0.2360, loss-lb:0.1938, loss-ulb:0.0211, weight:2.00, lr:0.0004
[05:10:12.500] iteration:10013  t-loss:0.2372, loss-lb:0.1338, loss-ulb:0.0517, weight:2.00, lr:0.0004
[05:10:12.862] iteration:10014  t-loss:0.2571, loss-lb:0.1198, loss-ulb:0.0686, weight:2.00, lr:0.0004
[05:10:13.231] iteration:10015  t-loss:0.3857, loss-lb:0.2483, loss-ulb:0.0687, weight:2.00, lr:0.0004
[05:10:13.606] iteration:10016  t-loss:0.3904, loss-lb:0.1774, loss-ulb:0.1065, weight:2.00, lr:0.0004
[05:10:13.967] iteration:10017  t-loss:0.2434, loss-lb:0.2070, loss-ulb:0.0182, weight:2.00, lr:0.0004
[05:10:14.304] iteration:10018  t-loss:0.3344, loss-lb:0.2045, loss-ulb:0.0650, weight:2.00, lr:0.0004
[05:10:14.645] iteration:10019  t-loss:0.2667, loss-lb:0.1460, loss-ulb:0.0604, weight:2.00, lr:0.0004
[05:10:14.983] iteration:10020  t-loss:0.2303, loss-lb:0.2012, loss-ulb:0.0145, weight:2.00, lr:0.0004
[05:10:15.315] iteration:10021  t-loss:0.3228, loss-lb:0.1561, loss-ulb:0.0834, weight:2.00, lr:0.0004
[05:10:15.645] iteration:10022  t-loss:0.5063, loss-lb:0.2495, loss-ulb:0.1284, weight:2.00, lr:0.0004
[05:10:15.965] iteration:10023  t-loss:0.3498, loss-lb:0.1612, loss-ulb:0.0943, weight:2.00, lr:0.0004
[05:10:16.286] iteration:10024  t-loss:0.3873, loss-lb:0.2248, loss-ulb:0.0813, weight:2.00, lr:0.0004
[05:10:16.602] iteration:10025  t-loss:0.3483, loss-lb:0.2266, loss-ulb:0.0609, weight:2.00, lr:0.0004
[05:12:20.794] iteration 10025 : dice_score: 0.849664 best_dice: 0.850800
[05:12:20.794]  <<Test>> - Ep:400  - Dice-S/T:84.63/84.97, Best-S:84.90, Best-T:85.08
[05:12:20.794]           - AvgLoss(lb/ulb/all):0.20/0.06/0.31
[05:12:21.873] iteration:10026  t-loss:0.2350, loss-lb:0.1879, loss-ulb:0.0235, weight:2.00, lr:0.0004
[05:12:22.214] iteration:10027  t-loss:0.3869, loss-lb:0.1894, loss-ulb:0.0987, weight:2.00, lr:0.0004
[05:12:22.557] iteration:10028  t-loss:0.3884, loss-lb:0.3597, loss-ulb:0.0144, weight:2.00, lr:0.0004
[05:12:22.892] iteration:10029  t-loss:0.1749, loss-lb:0.1322, loss-ulb:0.0213, weight:2.00, lr:0.0004
[05:12:23.243] iteration:10030  t-loss:0.7116, loss-lb:0.1580, loss-ulb:0.2768, weight:2.00, lr:0.0004
[05:12:23.572] iteration:10031  t-loss:0.2956, loss-lb:0.1707, loss-ulb:0.0625, weight:2.00, lr:0.0004
[05:12:23.903] iteration:10032  t-loss:0.3026, loss-lb:0.2663, loss-ulb:0.0182, weight:2.00, lr:0.0004
[05:12:24.239] iteration:10033  t-loss:0.2547, loss-lb:0.2097, loss-ulb:0.0225, weight:2.00, lr:0.0004
[05:12:24.566] iteration:10034  t-loss:0.4384, loss-lb:0.2003, loss-ulb:0.1191, weight:2.00, lr:0.0004
[05:12:24.897] iteration:10035  t-loss:0.3334, loss-lb:0.2026, loss-ulb:0.0654, weight:2.00, lr:0.0004
[05:12:25.222] iteration:10036  t-loss:0.2234, loss-lb:0.1585, loss-ulb:0.0325, weight:2.00, lr:0.0004
[05:12:25.547] iteration:10037  t-loss:0.6292, loss-lb:0.2394, loss-ulb:0.1949, weight:2.00, lr:0.0004
[05:12:25.879] iteration:10038  t-loss:0.2997, loss-lb:0.2444, loss-ulb:0.0277, weight:2.00, lr:0.0004
[05:12:26.202] iteration:10039  t-loss:0.3641, loss-lb:0.1465, loss-ulb:0.1088, weight:2.00, lr:0.0004
[05:12:26.527] iteration:10040  t-loss:0.4106, loss-lb:0.1312, loss-ulb:0.1397, weight:2.00, lr:0.0004
[05:12:26.852] iteration:10041  t-loss:0.3730, loss-lb:0.1785, loss-ulb:0.0973, weight:2.00, lr:0.0004
[05:12:27.182] iteration:10042  t-loss:0.3514, loss-lb:0.1575, loss-ulb:0.0969, weight:2.00, lr:0.0004
[05:12:27.509] iteration:10043  t-loss:0.1946, loss-lb:0.1655, loss-ulb:0.0145, weight:2.00, lr:0.0004
[05:12:27.831] iteration:10044  t-loss:0.3229, loss-lb:0.1600, loss-ulb:0.0814, weight:2.00, lr:0.0004
[05:12:28.153] iteration:10045  t-loss:0.4362, loss-lb:0.1898, loss-ulb:0.1232, weight:2.00, lr:0.0004
[05:12:28.472] iteration:10046  t-loss:0.2128, loss-lb:0.1753, loss-ulb:0.0188, weight:2.00, lr:0.0004
[05:12:28.791] iteration:10047  t-loss:0.4645, loss-lb:0.1339, loss-ulb:0.1653, weight:2.00, lr:0.0004
[05:12:29.111] iteration:10048  t-loss:0.3041, loss-lb:0.1952, loss-ulb:0.0544, weight:2.00, lr:0.0004
[05:12:29.428] iteration:10049  t-loss:0.4066, loss-lb:0.3303, loss-ulb:0.0381, weight:2.00, lr:0.0004
[05:12:29.745] iteration:10050  t-loss:0.3356, loss-lb:0.1668, loss-ulb:0.0844, weight:2.00, lr:0.0004
[05:12:31.096] iteration:10051  t-loss:0.2292, loss-lb:0.1808, loss-ulb:0.0242, weight:2.00, lr:0.0004
[05:12:31.420] iteration:10052  t-loss:0.2855, loss-lb:0.2510, loss-ulb:0.0173, weight:2.00, lr:0.0004
[05:12:31.739] iteration:10053  t-loss:0.4430, loss-lb:0.1600, loss-ulb:0.1415, weight:2.00, lr:0.0004
[05:12:32.069] iteration:10054  t-loss:0.4734, loss-lb:0.1764, loss-ulb:0.1485, weight:2.00, lr:0.0004
[05:12:32.401] iteration:10055  t-loss:0.2618, loss-lb:0.2287, loss-ulb:0.0166, weight:2.00, lr:0.0004
[05:12:32.729] iteration:10056  t-loss:0.1773, loss-lb:0.1400, loss-ulb:0.0186, weight:2.00, lr:0.0004
[05:12:33.057] iteration:10057  t-loss:0.3391, loss-lb:0.1960, loss-ulb:0.0716, weight:2.00, lr:0.0004
[05:12:33.390] iteration:10058  t-loss:0.2592, loss-lb:0.2131, loss-ulb:0.0230, weight:2.00, lr:0.0004
[05:12:33.724] iteration:10059  t-loss:0.4278, loss-lb:0.2860, loss-ulb:0.0709, weight:2.00, lr:0.0004
[05:12:34.044] iteration:10060  t-loss:0.5583, loss-lb:0.1612, loss-ulb:0.1985, weight:2.00, lr:0.0004
[05:12:34.366] iteration:10061  t-loss:0.2702, loss-lb:0.1377, loss-ulb:0.0662, weight:2.00, lr:0.0004
[05:12:34.687] iteration:10062  t-loss:0.2055, loss-lb:0.1759, loss-ulb:0.0148, weight:2.00, lr:0.0004
[05:12:35.008] iteration:10063  t-loss:0.2621, loss-lb:0.1630, loss-ulb:0.0496, weight:2.00, lr:0.0004
[05:12:35.324] iteration:10064  t-loss:0.2801, loss-lb:0.1246, loss-ulb:0.0777, weight:2.00, lr:0.0004
[05:12:35.649] iteration:10065  t-loss:0.2895, loss-lb:0.2398, loss-ulb:0.0249, weight:2.00, lr:0.0004
[05:12:35.970] iteration:10066  t-loss:0.4567, loss-lb:0.1548, loss-ulb:0.1509, weight:2.00, lr:0.0004
[05:12:36.297] iteration:10067  t-loss:0.5520, loss-lb:0.2501, loss-ulb:0.1509, weight:2.00, lr:0.0004
[05:12:36.619] iteration:10068  t-loss:0.3250, loss-lb:0.1968, loss-ulb:0.0641, weight:2.00, lr:0.0004
[05:12:36.937] iteration:10069  t-loss:0.3793, loss-lb:0.2212, loss-ulb:0.0791, weight:2.00, lr:0.0004
[05:12:37.255] iteration:10070  t-loss:0.2933, loss-lb:0.1405, loss-ulb:0.0764, weight:2.00, lr:0.0004
[05:12:37.573] iteration:10071  t-loss:0.3930, loss-lb:0.2485, loss-ulb:0.0722, weight:2.00, lr:0.0004
[05:12:37.888] iteration:10072  t-loss:0.1936, loss-lb:0.1653, loss-ulb:0.0141, weight:2.00, lr:0.0004
[05:12:38.201] iteration:10073  t-loss:0.3769, loss-lb:0.1249, loss-ulb:0.1260, weight:2.00, lr:0.0004
[05:12:38.515] iteration:10074  t-loss:0.3509, loss-lb:0.1482, loss-ulb:0.1013, weight:2.00, lr:0.0004
[05:12:38.829] iteration:10075  t-loss:0.2367, loss-lb:0.1284, loss-ulb:0.0542, weight:2.00, lr:0.0004
[05:12:40.061] iteration:10076  t-loss:0.1795, loss-lb:0.1348, loss-ulb:0.0223, weight:2.00, lr:0.0004
[05:12:40.394] iteration:10077  t-loss:0.3598, loss-lb:0.1471, loss-ulb:0.1063, weight:2.00, lr:0.0004
[05:12:40.732] iteration:10078  t-loss:0.3410, loss-lb:0.1724, loss-ulb:0.0843, weight:2.00, lr:0.0004
[05:12:41.073] iteration:10079  t-loss:0.3175, loss-lb:0.1625, loss-ulb:0.0775, weight:2.00, lr:0.0004
[05:12:41.412] iteration:10080  t-loss:0.4808, loss-lb:0.1543, loss-ulb:0.1632, weight:2.00, lr:0.0004
[05:12:41.754] iteration:10081  t-loss:0.6229, loss-lb:0.3016, loss-ulb:0.1606, weight:2.00, lr:0.0004
[05:12:42.112] iteration:10082  t-loss:0.1955, loss-lb:0.1669, loss-ulb:0.0143, weight:2.00, lr:0.0004
[05:12:42.459] iteration:10083  t-loss:0.2693, loss-lb:0.1374, loss-ulb:0.0659, weight:2.00, lr:0.0004
[05:12:42.803] iteration:10084  t-loss:0.3930, loss-lb:0.2335, loss-ulb:0.0798, weight:2.00, lr:0.0004
[05:12:43.147] iteration:10085  t-loss:0.4659, loss-lb:0.3615, loss-ulb:0.0522, weight:2.00, lr:0.0004
[05:12:43.475] iteration:10086  t-loss:0.3848, loss-lb:0.2971, loss-ulb:0.0438, weight:2.00, lr:0.0004
[05:12:43.810] iteration:10087  t-loss:0.3154, loss-lb:0.1955, loss-ulb:0.0600, weight:2.00, lr:0.0004
[05:12:44.142] iteration:10088  t-loss:0.3152, loss-lb:0.2111, loss-ulb:0.0521, weight:2.00, lr:0.0004
[05:12:44.462] iteration:10089  t-loss:1.1765, loss-lb:0.1329, loss-ulb:0.5218, weight:2.00, lr:0.0004
[05:12:44.792] iteration:10090  t-loss:0.3217, loss-lb:0.1479, loss-ulb:0.0869, weight:2.00, lr:0.0004
[05:12:45.118] iteration:10091  t-loss:0.3926, loss-lb:0.1716, loss-ulb:0.1105, weight:2.00, lr:0.0004
[05:12:45.441] iteration:10092  t-loss:0.3369, loss-lb:0.1798, loss-ulb:0.0785, weight:2.00, lr:0.0004
[05:12:45.762] iteration:10093  t-loss:0.3270, loss-lb:0.2256, loss-ulb:0.0507, weight:2.00, lr:0.0004
[05:12:46.081] iteration:10094  t-loss:0.4664, loss-lb:0.3125, loss-ulb:0.0770, weight:2.00, lr:0.0004
[05:12:46.405] iteration:10095  t-loss:0.2152, loss-lb:0.1393, loss-ulb:0.0379, weight:2.00, lr:0.0004
[05:12:46.727] iteration:10096  t-loss:0.3054, loss-lb:0.1433, loss-ulb:0.0811, weight:2.00, lr:0.0004
[05:12:47.050] iteration:10097  t-loss:0.3681, loss-lb:0.2166, loss-ulb:0.0757, weight:2.00, lr:0.0004
[05:12:47.366] iteration:10098  t-loss:0.3462, loss-lb:0.1507, loss-ulb:0.0977, weight:2.00, lr:0.0004
[05:12:47.682] iteration:10099  t-loss:0.3174, loss-lb:0.1494, loss-ulb:0.0840, weight:2.00, lr:0.0004
[05:12:47.995] iteration:10100  t-loss:0.2916, loss-lb:0.1338, loss-ulb:0.0789, weight:2.00, lr:0.0004
[05:12:49.335] iteration:10101  t-loss:0.2990, loss-lb:0.2404, loss-ulb:0.0293, weight:2.00, lr:0.0004
[05:12:49.669] iteration:10102  t-loss:0.8322, loss-lb:0.2955, loss-ulb:0.2684, weight:2.00, lr:0.0004
[05:12:50.015] iteration:10103  t-loss:0.2605, loss-lb:0.2285, loss-ulb:0.0160, weight:2.00, lr:0.0004
[05:12:50.362] iteration:10104  t-loss:0.8168, loss-lb:0.3689, loss-ulb:0.2240, weight:2.00, lr:0.0004
[05:12:50.694] iteration:10105  t-loss:0.3729, loss-lb:0.1326, loss-ulb:0.1201, weight:2.00, lr:0.0004
[05:12:51.022] iteration:10106  t-loss:0.2860, loss-lb:0.2177, loss-ulb:0.0341, weight:2.00, lr:0.0004
[05:12:51.347] iteration:10107  t-loss:0.3741, loss-lb:0.1866, loss-ulb:0.0938, weight:2.00, lr:0.0004
[05:12:51.670] iteration:10108  t-loss:0.3054, loss-lb:0.2470, loss-ulb:0.0292, weight:2.00, lr:0.0004
[05:12:51.989] iteration:10109  t-loss:0.2569, loss-lb:0.2057, loss-ulb:0.0256, weight:2.00, lr:0.0004
[05:12:52.311] iteration:10110  t-loss:0.2557, loss-lb:0.1634, loss-ulb:0.0461, weight:2.00, lr:0.0004
[05:12:52.632] iteration:10111  t-loss:0.4564, loss-lb:0.3018, loss-ulb:0.0773, weight:2.00, lr:0.0004
[05:12:52.949] iteration:10112  t-loss:0.3661, loss-lb:0.1668, loss-ulb:0.0996, weight:2.00, lr:0.0004
[05:12:53.270] iteration:10113  t-loss:0.4990, loss-lb:0.2031, loss-ulb:0.1480, weight:2.00, lr:0.0004
[05:12:53.588] iteration:10114  t-loss:0.3792, loss-lb:0.1616, loss-ulb:0.1088, weight:2.00, lr:0.0004
[05:12:53.906] iteration:10115  t-loss:0.3077, loss-lb:0.1733, loss-ulb:0.0672, weight:2.00, lr:0.0004
[05:12:54.226] iteration:10116  t-loss:0.3601, loss-lb:0.2338, loss-ulb:0.0632, weight:2.00, lr:0.0004
[05:12:54.546] iteration:10117  t-loss:0.3252, loss-lb:0.2235, loss-ulb:0.0509, weight:2.00, lr:0.0004
[05:12:54.865] iteration:10118  t-loss:0.3423, loss-lb:0.1404, loss-ulb:0.1009, weight:2.00, lr:0.0004
[05:12:55.179] iteration:10119  t-loss:0.1918, loss-lb:0.1478, loss-ulb:0.0220, weight:2.00, lr:0.0004
[05:12:55.497] iteration:10120  t-loss:0.4517, loss-lb:0.1965, loss-ulb:0.1276, weight:2.00, lr:0.0004
[05:12:55.823] iteration:10121  t-loss:0.2756, loss-lb:0.1470, loss-ulb:0.0643, weight:2.00, lr:0.0004
[05:12:56.155] iteration:10122  t-loss:0.3915, loss-lb:0.2777, loss-ulb:0.0569, weight:2.00, lr:0.0004
[05:12:56.477] iteration:10123  t-loss:0.2590, loss-lb:0.2253, loss-ulb:0.0169, weight:2.00, lr:0.0004
[05:12:56.798] iteration:10124  t-loss:0.4673, loss-lb:0.1780, loss-ulb:0.1446, weight:2.00, lr:0.0004
[05:12:57.116] iteration:10125  t-loss:0.3287, loss-lb:0.1934, loss-ulb:0.0677, weight:2.00, lr:0.0004
[05:15:03.887] iteration 10125 : dice_score: 0.850238 best_dice: 0.850800
[05:15:03.888]  <<Test>> - Ep:404  - Dice-S/T:85.04/85.02, Best-S:85.04, Best-T:85.08
[05:15:03.888]           - AvgLoss(lb/ulb/all):0.21/0.07/0.34
[05:15:04.994] iteration:10126  t-loss:0.2830, loss-lb:0.2375, loss-ulb:0.0227, weight:2.00, lr:0.0004
[05:15:05.327] iteration:10127  t-loss:0.3548, loss-lb:0.1513, loss-ulb:0.1018, weight:2.00, lr:0.0004
[05:15:05.659] iteration:10128  t-loss:0.3983, loss-lb:0.2560, loss-ulb:0.0712, weight:2.00, lr:0.0004
[05:15:05.982] iteration:10129  t-loss:0.1928, loss-lb:0.1407, loss-ulb:0.0261, weight:2.00, lr:0.0004
[05:15:06.305] iteration:10130  t-loss:0.5080, loss-lb:0.2219, loss-ulb:0.1431, weight:2.00, lr:0.0004
[05:15:06.630] iteration:10131  t-loss:0.4951, loss-lb:0.3496, loss-ulb:0.0727, weight:2.00, lr:0.0004
[05:15:06.957] iteration:10132  t-loss:0.5107, loss-lb:0.2731, loss-ulb:0.1188, weight:2.00, lr:0.0004
[05:15:07.275] iteration:10133  t-loss:0.1875, loss-lb:0.1467, loss-ulb:0.0204, weight:2.00, lr:0.0004
[05:15:07.597] iteration:10134  t-loss:0.3515, loss-lb:0.2133, loss-ulb:0.0691, weight:2.00, lr:0.0004
[05:15:07.915] iteration:10135  t-loss:0.3937, loss-lb:0.1838, loss-ulb:0.1049, weight:2.00, lr:0.0004
[05:15:08.239] iteration:10136  t-loss:0.2724, loss-lb:0.2133, loss-ulb:0.0295, weight:2.00, lr:0.0004
[05:15:08.558] iteration:10137  t-loss:0.4134, loss-lb:0.2486, loss-ulb:0.0824, weight:2.00, lr:0.0004
[05:15:08.878] iteration:10138  t-loss:0.2260, loss-lb:0.1210, loss-ulb:0.0525, weight:2.00, lr:0.0004
[05:15:09.199] iteration:10139  t-loss:0.4636, loss-lb:0.2451, loss-ulb:0.1093, weight:2.00, lr:0.0004
[05:15:09.518] iteration:10140  t-loss:0.1876, loss-lb:0.1332, loss-ulb:0.0272, weight:2.00, lr:0.0004
[05:15:09.834] iteration:10141  t-loss:0.2947, loss-lb:0.2475, loss-ulb:0.0236, weight:2.00, lr:0.0004
[05:15:10.156] iteration:10142  t-loss:0.5974, loss-lb:0.2731, loss-ulb:0.1621, weight:2.00, lr:0.0004
[05:15:10.475] iteration:10143  t-loss:0.7168, loss-lb:0.1524, loss-ulb:0.2822, weight:2.00, lr:0.0004
[05:15:10.794] iteration:10144  t-loss:0.2752, loss-lb:0.1575, loss-ulb:0.0588, weight:2.00, lr:0.0004
[05:15:11.107] iteration:10145  t-loss:0.4159, loss-lb:0.1516, loss-ulb:0.1322, weight:2.00, lr:0.0004
[05:15:11.419] iteration:10146  t-loss:0.1823, loss-lb:0.1432, loss-ulb:0.0196, weight:2.00, lr:0.0004
[05:15:11.737] iteration:10147  t-loss:0.3852, loss-lb:0.3018, loss-ulb:0.0417, weight:2.00, lr:0.0004
[05:15:12.054] iteration:10148  t-loss:0.2273, loss-lb:0.1859, loss-ulb:0.0207, weight:2.00, lr:0.0004
[05:15:12.369] iteration:10149  t-loss:0.5337, loss-lb:0.1470, loss-ulb:0.1934, weight:2.00, lr:0.0004
[05:15:12.682] iteration:10150  t-loss:0.3183, loss-lb:0.1840, loss-ulb:0.0671, weight:2.00, lr:0.0004
[05:15:13.826] iteration:10151  t-loss:0.3795, loss-lb:0.1878, loss-ulb:0.0958, weight:2.00, lr:0.0004
[05:15:14.159] iteration:10152  t-loss:0.2516, loss-lb:0.1630, loss-ulb:0.0443, weight:2.00, lr:0.0004
[05:15:14.486] iteration:10153  t-loss:0.2987, loss-lb:0.2585, loss-ulb:0.0201, weight:2.00, lr:0.0004
[05:15:14.810] iteration:10154  t-loss:0.4196, loss-lb:0.1899, loss-ulb:0.1148, weight:2.00, lr:0.0004
[05:15:15.133] iteration:10155  t-loss:0.4565, loss-lb:0.1696, loss-ulb:0.1435, weight:2.00, lr:0.0004
[05:15:15.454] iteration:10156  t-loss:0.5685, loss-lb:0.4165, loss-ulb:0.0760, weight:2.00, lr:0.0004
[05:15:15.779] iteration:10157  t-loss:0.5021, loss-lb:0.1552, loss-ulb:0.1735, weight:2.00, lr:0.0004
[05:15:16.104] iteration:10158  t-loss:0.3239, loss-lb:0.1190, loss-ulb:0.1025, weight:2.00, lr:0.0004
[05:15:16.425] iteration:10159  t-loss:0.2352, loss-lb:0.2019, loss-ulb:0.0167, weight:2.00, lr:0.0004
[05:15:16.746] iteration:10160  t-loss:0.5092, loss-lb:0.2806, loss-ulb:0.1143, weight:2.00, lr:0.0004
[05:15:17.063] iteration:10161  t-loss:0.1826, loss-lb:0.1490, loss-ulb:0.0168, weight:2.00, lr:0.0004
[05:15:17.379] iteration:10162  t-loss:0.2840, loss-lb:0.1452, loss-ulb:0.0694, weight:2.00, lr:0.0004
[05:15:17.704] iteration:10163  t-loss:0.2484, loss-lb:0.2135, loss-ulb:0.0175, weight:2.00, lr:0.0004
[05:15:18.036] iteration:10164  t-loss:0.3750, loss-lb:0.2067, loss-ulb:0.0841, weight:2.00, lr:0.0004
[05:15:18.368] iteration:10165  t-loss:0.3069, loss-lb:0.1899, loss-ulb:0.0585, weight:2.00, lr:0.0004
[05:15:18.693] iteration:10166  t-loss:0.3684, loss-lb:0.2616, loss-ulb:0.0534, weight:2.00, lr:0.0004
[05:15:19.017] iteration:10167  t-loss:0.2695, loss-lb:0.1723, loss-ulb:0.0486, weight:2.00, lr:0.0004
[05:15:19.345] iteration:10168  t-loss:0.3213, loss-lb:0.1540, loss-ulb:0.0836, weight:2.00, lr:0.0004
[05:15:19.667] iteration:10169  t-loss:0.3663, loss-lb:0.2660, loss-ulb:0.0502, weight:2.00, lr:0.0004
[05:15:19.988] iteration:10170  t-loss:0.1994, loss-lb:0.1666, loss-ulb:0.0164, weight:2.00, lr:0.0004
[05:15:20.303] iteration:10171  t-loss:0.2610, loss-lb:0.2163, loss-ulb:0.0223, weight:2.00, lr:0.0004
[05:15:20.622] iteration:10172  t-loss:0.2652, loss-lb:0.1504, loss-ulb:0.0574, weight:2.00, lr:0.0004
[05:15:20.942] iteration:10173  t-loss:0.2479, loss-lb:0.2004, loss-ulb:0.0238, weight:2.00, lr:0.0004
[05:15:21.264] iteration:10174  t-loss:0.4220, loss-lb:0.1695, loss-ulb:0.1262, weight:2.00, lr:0.0004
[05:15:21.581] iteration:10175  t-loss:0.2159, loss-lb:0.1589, loss-ulb:0.0285, weight:2.00, lr:0.0004
[05:15:22.872] iteration:10176  t-loss:0.3373, loss-lb:0.1482, loss-ulb:0.0945, weight:2.00, lr:0.0004
[05:15:23.214] iteration:10177  t-loss:0.4617, loss-lb:0.3249, loss-ulb:0.0684, weight:2.00, lr:0.0004
[05:15:23.543] iteration:10178  t-loss:0.2851, loss-lb:0.1727, loss-ulb:0.0562, weight:2.00, lr:0.0004
[05:15:23.867] iteration:10179  t-loss:0.3379, loss-lb:0.3075, loss-ulb:0.0152, weight:2.00, lr:0.0004
[05:15:24.187] iteration:10180  t-loss:0.4745, loss-lb:0.2704, loss-ulb:0.1021, weight:2.00, lr:0.0004
[05:15:24.505] iteration:10181  t-loss:0.3880, loss-lb:0.2210, loss-ulb:0.0835, weight:2.00, lr:0.0004
[05:15:24.827] iteration:10182  t-loss:0.5563, loss-lb:0.2884, loss-ulb:0.1340, weight:2.00, lr:0.0004
[05:15:25.146] iteration:10183  t-loss:0.6125, loss-lb:0.4938, loss-ulb:0.0594, weight:2.00, lr:0.0004
[05:15:25.471] iteration:10184  t-loss:0.4489, loss-lb:0.2448, loss-ulb:0.1020, weight:2.00, lr:0.0004
[05:15:25.788] iteration:10185  t-loss:0.2492, loss-lb:0.1367, loss-ulb:0.0562, weight:2.00, lr:0.0004
[05:15:26.108] iteration:10186  t-loss:0.2726, loss-lb:0.2422, loss-ulb:0.0152, weight:2.00, lr:0.0004
[05:15:26.435] iteration:10187  t-loss:0.4085, loss-lb:0.1533, loss-ulb:0.1276, weight:2.00, lr:0.0004
[05:15:26.775] iteration:10188  t-loss:0.5346, loss-lb:0.4031, loss-ulb:0.0657, weight:2.00, lr:0.0004
[05:15:27.119] iteration:10189  t-loss:0.3279, loss-lb:0.2536, loss-ulb:0.0372, weight:2.00, lr:0.0004
[05:15:27.447] iteration:10190  t-loss:0.3126, loss-lb:0.1561, loss-ulb:0.0782, weight:2.00, lr:0.0004
[05:15:27.784] iteration:10191  t-loss:0.3145, loss-lb:0.1919, loss-ulb:0.0613, weight:2.00, lr:0.0004
[05:15:28.124] iteration:10192  t-loss:0.4121, loss-lb:0.2269, loss-ulb:0.0926, weight:2.00, lr:0.0004
[05:15:28.451] iteration:10193  t-loss:0.3003, loss-lb:0.1838, loss-ulb:0.0583, weight:2.00, lr:0.0004
[05:15:28.773] iteration:10194  t-loss:0.2725, loss-lb:0.1817, loss-ulb:0.0454, weight:2.00, lr:0.0004
[05:15:29.092] iteration:10195  t-loss:0.1712, loss-lb:0.1296, loss-ulb:0.0208, weight:2.00, lr:0.0004
[05:15:29.413] iteration:10196  t-loss:0.3998, loss-lb:0.2012, loss-ulb:0.0993, weight:2.00, lr:0.0004
[05:15:29.730] iteration:10197  t-loss:0.3880, loss-lb:0.3201, loss-ulb:0.0340, weight:2.00, lr:0.0004
[05:15:30.049] iteration:10198  t-loss:0.1858, loss-lb:0.1477, loss-ulb:0.0191, weight:2.00, lr:0.0004
[05:15:30.372] iteration:10199  t-loss:0.4821, loss-lb:0.2064, loss-ulb:0.1379, weight:2.00, lr:0.0004
[05:15:30.690] iteration:10200  t-loss:0.3259, loss-lb:0.1396, loss-ulb:0.0932, weight:2.00, lr:0.0004
[05:15:32.222] iteration:10201  t-loss:0.2721, loss-lb:0.2265, loss-ulb:0.0228, weight:2.00, lr:0.0004
[05:15:32.553] iteration:10202  t-loss:0.2612, loss-lb:0.1511, loss-ulb:0.0551, weight:2.00, lr:0.0004
[05:15:32.884] iteration:10203  t-loss:0.4611, loss-lb:0.2153, loss-ulb:0.1229, weight:2.00, lr:0.0004
[05:15:33.206] iteration:10204  t-loss:0.3618, loss-lb:0.1273, loss-ulb:0.1173, weight:2.00, lr:0.0004
[05:15:33.523] iteration:10205  t-loss:0.1885, loss-lb:0.1452, loss-ulb:0.0217, weight:2.00, lr:0.0004
[05:15:33.842] iteration:10206  t-loss:0.2448, loss-lb:0.2078, loss-ulb:0.0185, weight:2.00, lr:0.0004
[05:15:34.165] iteration:10207  t-loss:0.4141, loss-lb:0.1925, loss-ulb:0.1108, weight:2.00, lr:0.0004
[05:15:34.482] iteration:10208  t-loss:0.2856, loss-lb:0.2452, loss-ulb:0.0202, weight:2.00, lr:0.0004
[05:15:34.800] iteration:10209  t-loss:0.2679, loss-lb:0.1520, loss-ulb:0.0579, weight:2.00, lr:0.0004
[05:15:35.134] iteration:10210  t-loss:0.4529, loss-lb:0.2403, loss-ulb:0.1063, weight:2.00, lr:0.0004
[05:15:35.487] iteration:10211  t-loss:0.3857, loss-lb:0.1873, loss-ulb:0.0992, weight:2.00, lr:0.0004
[05:15:35.816] iteration:10212  t-loss:0.4578, loss-lb:0.1608, loss-ulb:0.1485, weight:2.00, lr:0.0004
[05:15:36.143] iteration:10213  t-loss:0.2910, loss-lb:0.2320, loss-ulb:0.0295, weight:2.00, lr:0.0004
[05:15:36.469] iteration:10214  t-loss:0.2534, loss-lb:0.2087, loss-ulb:0.0224, weight:2.00, lr:0.0004
[05:15:36.798] iteration:10215  t-loss:0.3364, loss-lb:0.1918, loss-ulb:0.0723, weight:2.00, lr:0.0004
[05:15:37.123] iteration:10216  t-loss:0.4189, loss-lb:0.3266, loss-ulb:0.0461, weight:2.00, lr:0.0004
[05:15:37.447] iteration:10217  t-loss:0.3509, loss-lb:0.1795, loss-ulb:0.0857, weight:2.00, lr:0.0004
[05:15:37.766] iteration:10218  t-loss:0.2136, loss-lb:0.1577, loss-ulb:0.0280, weight:2.00, lr:0.0004
[05:15:38.088] iteration:10219  t-loss:0.3889, loss-lb:0.2444, loss-ulb:0.0722, weight:2.00, lr:0.0004
[05:15:38.410] iteration:10220  t-loss:0.4064, loss-lb:0.2772, loss-ulb:0.0646, weight:2.00, lr:0.0004
[05:15:38.733] iteration:10221  t-loss:0.2967, loss-lb:0.2129, loss-ulb:0.0419, weight:2.00, lr:0.0004
[05:15:39.054] iteration:10222  t-loss:0.2408, loss-lb:0.1460, loss-ulb:0.0474, weight:2.00, lr:0.0004
[05:15:39.373] iteration:10223  t-loss:0.3147, loss-lb:0.1390, loss-ulb:0.0879, weight:2.00, lr:0.0004
[05:15:39.692] iteration:10224  t-loss:0.2895, loss-lb:0.1989, loss-ulb:0.0453, weight:2.00, lr:0.0004
[05:15:40.016] iteration:10225  t-loss:0.4573, loss-lb:0.1905, loss-ulb:0.1334, weight:2.00, lr:0.0004
[05:17:39.564] iteration 10225 : dice_score: 0.848484 best_dice: 0.850800
[05:17:39.564]  <<Test>> - Ep:408  - Dice-S/T:84.68/84.85, Best-S:85.04, Best-T:85.08
[05:17:39.564]           - AvgLoss(lb/ulb/all):0.20/0.07/0.34
[05:17:40.702] iteration:10226  t-loss:0.2792, loss-lb:0.1501, loss-ulb:0.0646, weight:2.00, lr:0.0004
[05:17:41.032] iteration:10227  t-loss:0.3186, loss-lb:0.1384, loss-ulb:0.0901, weight:2.00, lr:0.0004
[05:17:41.359] iteration:10228  t-loss:0.4823, loss-lb:0.1961, loss-ulb:0.1431, weight:2.00, lr:0.0004
[05:17:41.678] iteration:10229  t-loss:0.1819, loss-lb:0.1001, loss-ulb:0.0409, weight:2.00, lr:0.0004
[05:17:41.999] iteration:10230  t-loss:0.5015, loss-lb:0.2367, loss-ulb:0.1324, weight:2.00, lr:0.0004
[05:17:42.320] iteration:10231  t-loss:0.4724, loss-lb:0.2637, loss-ulb:0.1044, weight:2.00, lr:0.0004
[05:17:42.640] iteration:10232  t-loss:0.2781, loss-lb:0.1772, loss-ulb:0.0504, weight:2.00, lr:0.0004
[05:17:42.960] iteration:10233  t-loss:0.2612, loss-lb:0.1958, loss-ulb:0.0327, weight:2.00, lr:0.0004
[05:17:43.278] iteration:10234  t-loss:0.3595, loss-lb:0.2298, loss-ulb:0.0649, weight:2.00, lr:0.0004
[05:17:43.597] iteration:10235  t-loss:0.1724, loss-lb:0.1402, loss-ulb:0.0161, weight:2.00, lr:0.0004
[05:17:43.918] iteration:10236  t-loss:0.2739, loss-lb:0.1421, loss-ulb:0.0659, weight:2.00, lr:0.0004
[05:17:44.246] iteration:10237  t-loss:0.3348, loss-lb:0.1577, loss-ulb:0.0885, weight:2.00, lr:0.0004
[05:17:44.574] iteration:10238  t-loss:0.4390, loss-lb:0.2407, loss-ulb:0.0991, weight:2.00, lr:0.0004
[05:17:44.900] iteration:10239  t-loss:0.3490, loss-lb:0.2180, loss-ulb:0.0655, weight:2.00, lr:0.0004
[05:17:45.221] iteration:10240  t-loss:0.3415, loss-lb:0.2219, loss-ulb:0.0598, weight:2.00, lr:0.0004
[05:17:45.543] iteration:10241  t-loss:0.3203, loss-lb:0.2829, loss-ulb:0.0187, weight:2.00, lr:0.0004
[05:17:45.868] iteration:10242  t-loss:0.3202, loss-lb:0.2175, loss-ulb:0.0514, weight:2.00, lr:0.0004
[05:17:46.195] iteration:10243  t-loss:0.5502, loss-lb:0.2338, loss-ulb:0.1582, weight:2.00, lr:0.0004
[05:17:46.510] iteration:10244  t-loss:0.1728, loss-lb:0.1325, loss-ulb:0.0202, weight:2.00, lr:0.0004
[05:17:46.828] iteration:10245  t-loss:0.2699, loss-lb:0.1366, loss-ulb:0.0666, weight:2.00, lr:0.0004
[05:17:47.146] iteration:10246  t-loss:0.3107, loss-lb:0.2007, loss-ulb:0.0550, weight:2.00, lr:0.0004
[05:17:47.465] iteration:10247  t-loss:0.3301, loss-lb:0.2028, loss-ulb:0.0637, weight:2.00, lr:0.0004
[05:17:47.780] iteration:10248  t-loss:0.1545, loss-lb:0.1216, loss-ulb:0.0164, weight:2.00, lr:0.0004
[05:17:48.100] iteration:10249  t-loss:0.1977, loss-lb:0.1533, loss-ulb:0.0222, weight:2.00, lr:0.0004
[05:17:48.421] iteration:10250  t-loss:0.4150, loss-lb:0.2335, loss-ulb:0.0907, weight:2.00, lr:0.0004
[05:17:49.695] iteration:10251  t-loss:0.1941, loss-lb:0.1554, loss-ulb:0.0193, weight:2.00, lr:0.0004
[05:17:50.038] iteration:10252  t-loss:0.1785, loss-lb:0.1351, loss-ulb:0.0217, weight:2.00, lr:0.0004
[05:17:50.375] iteration:10253  t-loss:0.3717, loss-lb:0.2389, loss-ulb:0.0664, weight:2.00, lr:0.0004
[05:17:50.708] iteration:10254  t-loss:0.3742, loss-lb:0.2623, loss-ulb:0.0560, weight:2.00, lr:0.0004
[05:17:51.045] iteration:10255  t-loss:0.4019, loss-lb:0.1599, loss-ulb:0.1210, weight:2.00, lr:0.0004
[05:17:51.373] iteration:10256  t-loss:0.3007, loss-lb:0.1573, loss-ulb:0.0717, weight:2.00, lr:0.0004
[05:17:51.702] iteration:10257  t-loss:0.5299, loss-lb:0.2715, loss-ulb:0.1292, weight:2.00, lr:0.0004
[05:17:52.026] iteration:10258  t-loss:0.2437, loss-lb:0.2092, loss-ulb:0.0172, weight:2.00, lr:0.0004
[05:17:52.351] iteration:10259  t-loss:0.4057, loss-lb:0.3353, loss-ulb:0.0352, weight:2.00, lr:0.0004
[05:17:52.672] iteration:10260  t-loss:0.2812, loss-lb:0.1884, loss-ulb:0.0464, weight:2.00, lr:0.0004
[05:17:52.994] iteration:10261  t-loss:0.2485, loss-lb:0.1380, loss-ulb:0.0552, weight:2.00, lr:0.0004
[05:17:53.316] iteration:10262  t-loss:0.2588, loss-lb:0.1679, loss-ulb:0.0455, weight:2.00, lr:0.0004
[05:17:53.637] iteration:10263  t-loss:0.2853, loss-lb:0.1188, loss-ulb:0.0833, weight:2.00, lr:0.0004
[05:17:53.959] iteration:10264  t-loss:0.4453, loss-lb:0.2851, loss-ulb:0.0801, weight:2.00, lr:0.0004
[05:17:54.282] iteration:10265  t-loss:0.2417, loss-lb:0.1425, loss-ulb:0.0496, weight:2.00, lr:0.0004
[05:17:54.605] iteration:10266  t-loss:0.4207, loss-lb:0.1798, loss-ulb:0.1204, weight:2.00, lr:0.0004
[05:17:54.928] iteration:10267  t-loss:0.2456, loss-lb:0.1864, loss-ulb:0.0296, weight:2.00, lr:0.0004
[05:17:55.248] iteration:10268  t-loss:0.2824, loss-lb:0.1708, loss-ulb:0.0558, weight:2.00, lr:0.0004
[05:17:55.568] iteration:10269  t-loss:0.3514, loss-lb:0.2285, loss-ulb:0.0614, weight:2.00, lr:0.0004
[05:17:55.882] iteration:10270  t-loss:0.3830, loss-lb:0.1387, loss-ulb:0.1222, weight:2.00, lr:0.0004
[05:17:56.197] iteration:10271  t-loss:0.3231, loss-lb:0.1736, loss-ulb:0.0747, weight:2.00, lr:0.0004
[05:17:56.516] iteration:10272  t-loss:0.3310, loss-lb:0.1912, loss-ulb:0.0699, weight:2.00, lr:0.0004
[05:17:56.835] iteration:10273  t-loss:0.2811, loss-lb:0.1555, loss-ulb:0.0628, weight:2.00, lr:0.0004
[05:17:57.152] iteration:10274  t-loss:0.3515, loss-lb:0.1338, loss-ulb:0.1088, weight:2.00, lr:0.0004
[05:17:57.469] iteration:10275  t-loss:0.4161, loss-lb:0.1608, loss-ulb:0.1277, weight:2.00, lr:0.0004
[05:17:58.829] iteration:10276  t-loss:0.4472, loss-lb:0.2234, loss-ulb:0.1119, weight:2.00, lr:0.0004
[05:17:59.158] iteration:10277  t-loss:0.2637, loss-lb:0.1188, loss-ulb:0.0724, weight:2.00, lr:0.0004
[05:17:59.480] iteration:10278  t-loss:0.3902, loss-lb:0.2777, loss-ulb:0.0562, weight:2.00, lr:0.0004
[05:17:59.799] iteration:10279  t-loss:0.1897, loss-lb:0.1495, loss-ulb:0.0201, weight:2.00, lr:0.0004
[05:18:00.123] iteration:10280  t-loss:0.3700, loss-lb:0.2173, loss-ulb:0.0763, weight:2.00, lr:0.0004
[05:18:00.448] iteration:10281  t-loss:0.6873, loss-lb:0.2911, loss-ulb:0.1981, weight:2.00, lr:0.0004
[05:18:00.768] iteration:10282  t-loss:0.4058, loss-lb:0.1940, loss-ulb:0.1059, weight:2.00, lr:0.0004
[05:18:01.090] iteration:10283  t-loss:0.3932, loss-lb:0.2218, loss-ulb:0.0857, weight:2.00, lr:0.0004
[05:18:01.412] iteration:10284  t-loss:0.3864, loss-lb:0.2003, loss-ulb:0.0930, weight:2.00, lr:0.0004
[05:18:01.732] iteration:10285  t-loss:0.4647, loss-lb:0.1960, loss-ulb:0.1343, weight:2.00, lr:0.0004
[05:18:02.050] iteration:10286  t-loss:0.3857, loss-lb:0.1654, loss-ulb:0.1102, weight:2.00, lr:0.0004
[05:18:02.381] iteration:10287  t-loss:0.3177, loss-lb:0.1687, loss-ulb:0.0745, weight:2.00, lr:0.0004
[05:18:02.715] iteration:10288  t-loss:0.2363, loss-lb:0.1773, loss-ulb:0.0295, weight:2.00, lr:0.0004
[05:18:03.042] iteration:10289  t-loss:0.2340, loss-lb:0.2058, loss-ulb:0.0141, weight:2.00, lr:0.0004
[05:18:03.368] iteration:10290  t-loss:0.3091, loss-lb:0.2149, loss-ulb:0.0471, weight:2.00, lr:0.0004
[05:18:03.686] iteration:10291  t-loss:0.4248, loss-lb:0.1596, loss-ulb:0.1326, weight:2.00, lr:0.0004
[05:18:04.010] iteration:10292  t-loss:0.2930, loss-lb:0.2608, loss-ulb:0.0161, weight:2.00, lr:0.0004
[05:18:04.332] iteration:10293  t-loss:0.3608, loss-lb:0.2008, loss-ulb:0.0800, weight:2.00, lr:0.0004
[05:18:04.659] iteration:10294  t-loss:0.2740, loss-lb:0.2103, loss-ulb:0.0318, weight:2.00, lr:0.0004
[05:18:04.992] iteration:10295  t-loss:0.3867, loss-lb:0.2246, loss-ulb:0.0811, weight:2.00, lr:0.0004
[05:18:05.323] iteration:10296  t-loss:0.3813, loss-lb:0.1647, loss-ulb:0.1083, weight:2.00, lr:0.0004
[05:18:05.646] iteration:10297  t-loss:0.1991, loss-lb:0.1580, loss-ulb:0.0205, weight:2.00, lr:0.0004
[05:18:05.972] iteration:10298  t-loss:0.4904, loss-lb:0.2057, loss-ulb:0.1424, weight:2.00, lr:0.0004
[05:18:06.297] iteration:10299  t-loss:0.2687, loss-lb:0.1372, loss-ulb:0.0657, weight:2.00, lr:0.0004
[05:18:06.623] iteration:10300  t-loss:0.4338, loss-lb:0.1795, loss-ulb:0.1271, weight:2.00, lr:0.0004
[05:18:08.206] iteration:10301  t-loss:0.2271, loss-lb:0.1848, loss-ulb:0.0211, weight:2.00, lr:0.0004
[05:18:08.548] iteration:10302  t-loss:0.3919, loss-lb:0.1696, loss-ulb:0.1112, weight:2.00, lr:0.0004
[05:18:08.882] iteration:10303  t-loss:0.3509, loss-lb:0.2183, loss-ulb:0.0663, weight:2.00, lr:0.0004
[05:18:09.202] iteration:10304  t-loss:0.1522, loss-lb:0.1145, loss-ulb:0.0188, weight:2.00, lr:0.0004
[05:18:09.522] iteration:10305  t-loss:0.4347, loss-lb:0.1737, loss-ulb:0.1305, weight:2.00, lr:0.0004
[05:18:09.838] iteration:10306  t-loss:0.2521, loss-lb:0.1854, loss-ulb:0.0334, weight:2.00, lr:0.0004
[05:18:10.154] iteration:10307  t-loss:0.2613, loss-lb:0.1472, loss-ulb:0.0570, weight:2.00, lr:0.0004
[05:18:10.479] iteration:10308  t-loss:0.3923, loss-lb:0.1991, loss-ulb:0.0966, weight:2.00, lr:0.0004
[05:18:10.816] iteration:10309  t-loss:0.4338, loss-lb:0.2291, loss-ulb:0.1024, weight:2.00, lr:0.0004
[05:18:11.151] iteration:10310  t-loss:0.4924, loss-lb:0.2959, loss-ulb:0.0982, weight:2.00, lr:0.0004
[05:18:11.487] iteration:10311  t-loss:0.2882, loss-lb:0.2072, loss-ulb:0.0405, weight:2.00, lr:0.0004
[05:18:11.826] iteration:10312  t-loss:0.4478, loss-lb:0.3253, loss-ulb:0.0613, weight:2.00, lr:0.0004
[05:18:12.161] iteration:10313  t-loss:0.3433, loss-lb:0.1905, loss-ulb:0.0764, weight:2.00, lr:0.0004
[05:18:12.488] iteration:10314  t-loss:0.2542, loss-lb:0.1204, loss-ulb:0.0669, weight:2.00, lr:0.0004
[05:18:12.809] iteration:10315  t-loss:0.2208, loss-lb:0.1495, loss-ulb:0.0356, weight:2.00, lr:0.0004
[05:18:13.140] iteration:10316  t-loss:0.3453, loss-lb:0.2245, loss-ulb:0.0604, weight:2.00, lr:0.0004
[05:18:13.462] iteration:10317  t-loss:0.2514, loss-lb:0.2214, loss-ulb:0.0150, weight:2.00, lr:0.0004
[05:18:13.792] iteration:10318  t-loss:0.3359, loss-lb:0.1831, loss-ulb:0.0764, weight:2.00, lr:0.0004
[05:18:14.108] iteration:10319  t-loss:0.2480, loss-lb:0.2069, loss-ulb:0.0205, weight:2.00, lr:0.0004
[05:18:14.428] iteration:10320  t-loss:0.4264, loss-lb:0.2359, loss-ulb:0.0952, weight:2.00, lr:0.0004
[05:18:14.747] iteration:10321  t-loss:0.3702, loss-lb:0.2666, loss-ulb:0.0518, weight:2.00, lr:0.0004
[05:18:15.064] iteration:10322  t-loss:0.3186, loss-lb:0.1420, loss-ulb:0.0883, weight:2.00, lr:0.0004
[05:18:15.382] iteration:10323  t-loss:0.3841, loss-lb:0.2409, loss-ulb:0.0716, weight:2.00, lr:0.0004
[05:18:15.696] iteration:10324  t-loss:0.2038, loss-lb:0.1561, loss-ulb:0.0239, weight:2.00, lr:0.0004
[05:18:16.014] iteration:10325  t-loss:0.3148, loss-lb:0.1773, loss-ulb:0.0687, weight:2.00, lr:0.0004
[05:20:22.887] iteration 10325 : dice_score: 0.850032 best_dice: 0.850800
[05:20:22.888]  <<Test>> - Ep:412  - Dice-S/T:85.06/85.00, Best-S:85.06, Best-T:85.08
[05:20:22.888]           - AvgLoss(lb/ulb/all):0.20/0.06/0.33
[05:20:24.224] iteration:10326  t-loss:0.3353, loss-lb:0.2694, loss-ulb:0.0330, weight:2.00, lr:0.0004
[05:20:24.553] iteration:10327  t-loss:0.4320, loss-lb:0.1203, loss-ulb:0.1558, weight:2.00, lr:0.0004
[05:20:24.877] iteration:10328  t-loss:0.1940, loss-lb:0.1472, loss-ulb:0.0234, weight:2.00, lr:0.0004
[05:20:25.207] iteration:10329  t-loss:0.3143, loss-lb:0.1429, loss-ulb:0.0857, weight:2.00, lr:0.0004
[05:20:25.533] iteration:10330  t-loss:0.2606, loss-lb:0.1750, loss-ulb:0.0428, weight:2.00, lr:0.0003
[05:20:25.858] iteration:10331  t-loss:0.3010, loss-lb:0.1482, loss-ulb:0.0764, weight:2.00, lr:0.0003
[05:20:26.174] iteration:10332  t-loss:0.1906, loss-lb:0.1517, loss-ulb:0.0194, weight:2.00, lr:0.0003
[05:20:26.496] iteration:10333  t-loss:0.3555, loss-lb:0.1224, loss-ulb:0.1165, weight:2.00, lr:0.0003
[05:20:26.818] iteration:10334  t-loss:0.2816, loss-lb:0.2499, loss-ulb:0.0158, weight:2.00, lr:0.0003
[05:20:27.138] iteration:10335  t-loss:0.2905, loss-lb:0.1547, loss-ulb:0.0679, weight:2.00, lr:0.0003
[05:20:27.462] iteration:10336  t-loss:0.3556, loss-lb:0.1594, loss-ulb:0.0981, weight:2.00, lr:0.0003
[05:20:27.784] iteration:10337  t-loss:0.2652, loss-lb:0.1799, loss-ulb:0.0427, weight:2.00, lr:0.0003
[05:20:28.110] iteration:10338  t-loss:0.2355, loss-lb:0.1453, loss-ulb:0.0451, weight:2.00, lr:0.0003
[05:20:28.426] iteration:10339  t-loss:0.1946, loss-lb:0.1465, loss-ulb:0.0240, weight:2.00, lr:0.0003
[05:20:28.741] iteration:10340  t-loss:0.3167, loss-lb:0.1450, loss-ulb:0.0858, weight:2.00, lr:0.0003
[05:20:29.061] iteration:10341  t-loss:0.3391, loss-lb:0.1784, loss-ulb:0.0803, weight:2.00, lr:0.0003
[05:20:29.383] iteration:10342  t-loss:0.3964, loss-lb:0.2006, loss-ulb:0.0979, weight:2.00, lr:0.0003
[05:20:29.697] iteration:10343  t-loss:0.3076, loss-lb:0.1707, loss-ulb:0.0685, weight:2.00, lr:0.0003
[05:20:30.013] iteration:10344  t-loss:0.2994, loss-lb:0.2165, loss-ulb:0.0414, weight:2.00, lr:0.0003
[05:20:30.327] iteration:10345  t-loss:0.5481, loss-lb:0.1635, loss-ulb:0.1923, weight:2.00, lr:0.0003
[05:20:30.643] iteration:10346  t-loss:0.4899, loss-lb:0.1464, loss-ulb:0.1718, weight:2.00, lr:0.0003
[05:20:30.959] iteration:10347  t-loss:0.3465, loss-lb:0.1386, loss-ulb:0.1039, weight:2.00, lr:0.0003
[05:20:31.276] iteration:10348  t-loss:0.3350, loss-lb:0.1701, loss-ulb:0.0825, weight:2.00, lr:0.0003
[05:20:31.594] iteration:10349  t-loss:0.3515, loss-lb:0.1211, loss-ulb:0.1152, weight:2.00, lr:0.0003
[05:20:31.911] iteration:10350  t-loss:0.3681, loss-lb:0.1865, loss-ulb:0.0908, weight:2.00, lr:0.0003
[05:20:33.390] iteration:10351  t-loss:0.5358, loss-lb:0.2603, loss-ulb:0.1377, weight:2.00, lr:0.0003
[05:20:33.729] iteration:10352  t-loss:0.2118, loss-lb:0.1679, loss-ulb:0.0219, weight:2.00, lr:0.0003
[05:20:34.062] iteration:10353  t-loss:0.2631, loss-lb:0.1503, loss-ulb:0.0564, weight:2.00, lr:0.0003
[05:20:34.410] iteration:10354  t-loss:0.2697, loss-lb:0.2134, loss-ulb:0.0281, weight:2.00, lr:0.0003
[05:20:34.745] iteration:10355  t-loss:0.2408, loss-lb:0.1126, loss-ulb:0.0641, weight:2.00, lr:0.0003
[05:20:35.075] iteration:10356  t-loss:0.2015, loss-lb:0.1642, loss-ulb:0.0187, weight:2.00, lr:0.0003
[05:20:35.405] iteration:10357  t-loss:0.2603, loss-lb:0.2294, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:20:35.731] iteration:10358  t-loss:0.3854, loss-lb:0.2037, loss-ulb:0.0909, weight:2.00, lr:0.0003
[05:20:36.064] iteration:10359  t-loss:0.3607, loss-lb:0.2108, loss-ulb:0.0749, weight:2.00, lr:0.0003
[05:20:36.388] iteration:10360  t-loss:0.4158, loss-lb:0.2573, loss-ulb:0.0792, weight:2.00, lr:0.0003
[05:20:36.712] iteration:10361  t-loss:0.3576, loss-lb:0.2123, loss-ulb:0.0726, weight:2.00, lr:0.0003
[05:20:37.030] iteration:10362  t-loss:0.3097, loss-lb:0.2086, loss-ulb:0.0506, weight:2.00, lr:0.0003
[05:20:37.353] iteration:10363  t-loss:0.3998, loss-lb:0.2307, loss-ulb:0.0846, weight:2.00, lr:0.0003
[05:20:37.670] iteration:10364  t-loss:0.3715, loss-lb:0.1810, loss-ulb:0.0952, weight:2.00, lr:0.0003
[05:20:37.985] iteration:10365  t-loss:0.3932, loss-lb:0.2391, loss-ulb:0.0771, weight:2.00, lr:0.0003
[05:20:38.304] iteration:10366  t-loss:0.2550, loss-lb:0.2159, loss-ulb:0.0195, weight:2.00, lr:0.0003
[05:20:38.623] iteration:10367  t-loss:0.2734, loss-lb:0.1443, loss-ulb:0.0646, weight:2.00, lr:0.0003
[05:20:38.935] iteration:10368  t-loss:0.2812, loss-lb:0.1226, loss-ulb:0.0793, weight:2.00, lr:0.0003
[05:20:39.250] iteration:10369  t-loss:0.2217, loss-lb:0.1392, loss-ulb:0.0413, weight:2.00, lr:0.0003
[05:20:39.564] iteration:10370  t-loss:0.2287, loss-lb:0.1940, loss-ulb:0.0173, weight:2.00, lr:0.0003
[05:20:39.877] iteration:10371  t-loss:0.4201, loss-lb:0.1217, loss-ulb:0.1492, weight:2.00, lr:0.0003
[05:20:40.191] iteration:10372  t-loss:0.3041, loss-lb:0.2606, loss-ulb:0.0217, weight:2.00, lr:0.0003
[05:20:40.507] iteration:10373  t-loss:0.4377, loss-lb:0.1802, loss-ulb:0.1288, weight:2.00, lr:0.0003
[05:20:40.823] iteration:10374  t-loss:0.3401, loss-lb:0.2607, loss-ulb:0.0397, weight:2.00, lr:0.0003
[05:20:41.137] iteration:10375  t-loss:0.3314, loss-lb:0.2321, loss-ulb:0.0497, weight:2.00, lr:0.0003
[05:20:42.308] iteration:10376  t-loss:0.5032, loss-lb:0.2062, loss-ulb:0.1485, weight:2.00, lr:0.0003
[05:20:42.655] iteration:10377  t-loss:0.3863, loss-lb:0.2430, loss-ulb:0.0717, weight:2.00, lr:0.0003
[05:20:42.993] iteration:10378  t-loss:0.5953, loss-lb:0.1293, loss-ulb:0.2330, weight:2.00, lr:0.0003
[05:20:43.326] iteration:10379  t-loss:0.2586, loss-lb:0.1394, loss-ulb:0.0596, weight:2.00, lr:0.0003
[05:20:43.667] iteration:10380  t-loss:0.3425, loss-lb:0.1598, loss-ulb:0.0913, weight:2.00, lr:0.0003
[05:20:44.008] iteration:10381  t-loss:0.4308, loss-lb:0.2549, loss-ulb:0.0880, weight:2.00, lr:0.0003
[05:20:44.339] iteration:10382  t-loss:0.2350, loss-lb:0.1266, loss-ulb:0.0542, weight:2.00, lr:0.0003
[05:20:44.670] iteration:10383  t-loss:0.1804, loss-lb:0.1461, loss-ulb:0.0172, weight:2.00, lr:0.0003
[05:20:45.010] iteration:10384  t-loss:0.3632, loss-lb:0.2368, loss-ulb:0.0632, weight:2.00, lr:0.0003
[05:20:45.338] iteration:10385  t-loss:0.3384, loss-lb:0.1758, loss-ulb:0.0813, weight:2.00, lr:0.0003
[05:20:45.681] iteration:10386  t-loss:0.3144, loss-lb:0.1769, loss-ulb:0.0688, weight:2.00, lr:0.0003
[05:20:46.021] iteration:10387  t-loss:0.2505, loss-lb:0.2115, loss-ulb:0.0195, weight:2.00, lr:0.0003
[05:20:46.362] iteration:10388  t-loss:0.2931, loss-lb:0.2572, loss-ulb:0.0180, weight:2.00, lr:0.0003
[05:20:46.710] iteration:10389  t-loss:0.3859, loss-lb:0.1857, loss-ulb:0.1001, weight:2.00, lr:0.0003
[05:20:47.059] iteration:10390  t-loss:0.2994, loss-lb:0.1689, loss-ulb:0.0653, weight:2.00, lr:0.0003
[05:20:47.398] iteration:10391  t-loss:0.1991, loss-lb:0.1554, loss-ulb:0.0219, weight:2.00, lr:0.0003
[05:20:47.732] iteration:10392  t-loss:0.3674, loss-lb:0.2109, loss-ulb:0.0782, weight:2.00, lr:0.0003
[05:20:48.049] iteration:10393  t-loss:0.2378, loss-lb:0.1512, loss-ulb:0.0433, weight:2.00, lr:0.0003
[05:20:48.364] iteration:10394  t-loss:0.2174, loss-lb:0.1371, loss-ulb:0.0401, weight:2.00, lr:0.0003
[05:20:48.680] iteration:10395  t-loss:0.3004, loss-lb:0.1197, loss-ulb:0.0904, weight:2.00, lr:0.0003
[05:20:48.998] iteration:10396  t-loss:0.2419, loss-lb:0.1748, loss-ulb:0.0335, weight:2.00, lr:0.0003
[05:20:49.319] iteration:10397  t-loss:0.5034, loss-lb:0.3852, loss-ulb:0.0591, weight:2.00, lr:0.0003
[05:20:49.637] iteration:10398  t-loss:0.2653, loss-lb:0.1716, loss-ulb:0.0468, weight:2.00, lr:0.0003
[05:20:49.950] iteration:10399  t-loss:0.4284, loss-lb:0.1951, loss-ulb:0.1166, weight:2.00, lr:0.0003
[05:20:50.267] iteration:10400  t-loss:0.2579, loss-lb:0.2269, loss-ulb:0.0155, weight:2.00, lr:0.0003
[05:20:51.510] iteration:10401  t-loss:0.3486, loss-lb:0.2036, loss-ulb:0.0725, weight:2.00, lr:0.0003
[05:20:51.848] iteration:10402  t-loss:0.2341, loss-lb:0.1616, loss-ulb:0.0363, weight:2.00, lr:0.0003
[05:20:52.176] iteration:10403  t-loss:0.2080, loss-lb:0.1560, loss-ulb:0.0260, weight:2.00, lr:0.0003
[05:20:52.505] iteration:10404  t-loss:0.2869, loss-lb:0.2401, loss-ulb:0.0234, weight:2.00, lr:0.0003
[05:20:52.825] iteration:10405  t-loss:0.2124, loss-lb:0.1798, loss-ulb:0.0163, weight:2.00, lr:0.0003
[05:20:53.139] iteration:10406  t-loss:0.2120, loss-lb:0.1172, loss-ulb:0.0474, weight:2.00, lr:0.0003
[05:20:53.457] iteration:10407  t-loss:0.8305, loss-lb:0.1343, loss-ulb:0.3481, weight:2.00, lr:0.0003
[05:20:53.777] iteration:10408  t-loss:0.2190, loss-lb:0.1935, loss-ulb:0.0128, weight:2.00, lr:0.0003
[05:20:54.096] iteration:10409  t-loss:0.2155, loss-lb:0.1807, loss-ulb:0.0174, weight:2.00, lr:0.0003
[05:20:54.430] iteration:10410  t-loss:0.3970, loss-lb:0.2869, loss-ulb:0.0551, weight:2.00, lr:0.0003
[05:20:54.762] iteration:10411  t-loss:0.2593, loss-lb:0.2121, loss-ulb:0.0236, weight:2.00, lr:0.0003
[05:20:55.091] iteration:10412  t-loss:0.2086, loss-lb:0.1363, loss-ulb:0.0362, weight:2.00, lr:0.0003
[05:20:55.422] iteration:10413  t-loss:0.3560, loss-lb:0.1685, loss-ulb:0.0937, weight:2.00, lr:0.0003
[05:20:55.755] iteration:10414  t-loss:0.3493, loss-lb:0.2226, loss-ulb:0.0633, weight:2.00, lr:0.0003
[05:20:56.080] iteration:10415  t-loss:0.2978, loss-lb:0.2044, loss-ulb:0.0467, weight:2.00, lr:0.0003
[05:20:56.408] iteration:10416  t-loss:0.3846, loss-lb:0.2254, loss-ulb:0.0796, weight:2.00, lr:0.0003
[05:20:56.732] iteration:10417  t-loss:0.3221, loss-lb:0.2800, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:20:57.052] iteration:10418  t-loss:0.2646, loss-lb:0.2315, loss-ulb:0.0166, weight:2.00, lr:0.0003
[05:20:57.371] iteration:10419  t-loss:0.2649, loss-lb:0.1321, loss-ulb:0.0664, weight:2.00, lr:0.0003
[05:20:57.693] iteration:10420  t-loss:0.3749, loss-lb:0.1944, loss-ulb:0.0903, weight:2.00, lr:0.0003
[05:20:58.009] iteration:10421  t-loss:0.2540, loss-lb:0.2115, loss-ulb:0.0212, weight:2.00, lr:0.0003
[05:20:58.332] iteration:10422  t-loss:0.4048, loss-lb:0.1789, loss-ulb:0.1130, weight:2.00, lr:0.0003
[05:20:58.653] iteration:10423  t-loss:0.3189, loss-lb:0.2187, loss-ulb:0.0501, weight:2.00, lr:0.0003
[05:20:58.975] iteration:10424  t-loss:0.4267, loss-lb:0.1548, loss-ulb:0.1360, weight:2.00, lr:0.0003
[05:20:59.292] iteration:10425  t-loss:0.2799, loss-lb:0.1447, loss-ulb:0.0676, weight:2.00, lr:0.0003
[05:23:01.447] iteration 10425 : dice_score: 0.850009 best_dice: 0.850800
[05:23:01.447]  <<Test>> - Ep:416  - Dice-S/T:84.80/85.00, Best-S:85.06, Best-T:85.08
[05:23:01.447]           - AvgLoss(lb/ulb/all):0.19/0.07/0.33
[05:23:02.552] iteration:10426  t-loss:0.4839, loss-lb:0.2717, loss-ulb:0.1061, weight:2.00, lr:0.0003
[05:23:02.884] iteration:10427  t-loss:0.2793, loss-lb:0.1305, loss-ulb:0.0744, weight:2.00, lr:0.0003
[05:23:03.211] iteration:10428  t-loss:0.4529, loss-lb:0.3775, loss-ulb:0.0377, weight:2.00, lr:0.0003
[05:23:03.534] iteration:10429  t-loss:0.2139, loss-lb:0.1164, loss-ulb:0.0488, weight:2.00, lr:0.0003
[05:23:03.858] iteration:10430  t-loss:0.3688, loss-lb:0.1955, loss-ulb:0.0867, weight:2.00, lr:0.0003
[05:23:04.184] iteration:10431  t-loss:0.5435, loss-lb:0.2207, loss-ulb:0.1614, weight:2.00, lr:0.0003
[05:23:04.505] iteration:10432  t-loss:0.3665, loss-lb:0.2601, loss-ulb:0.0532, weight:2.00, lr:0.0003
[05:23:04.826] iteration:10433  t-loss:0.2252, loss-lb:0.1971, loss-ulb:0.0140, weight:2.00, lr:0.0003
[05:23:05.145] iteration:10434  t-loss:0.6535, loss-lb:0.1642, loss-ulb:0.2446, weight:2.00, lr:0.0003
[05:23:05.465] iteration:10435  t-loss:0.5315, loss-lb:0.1818, loss-ulb:0.1749, weight:2.00, lr:0.0003
[05:23:05.782] iteration:10436  t-loss:0.2067, loss-lb:0.1775, loss-ulb:0.0146, weight:2.00, lr:0.0003
[05:23:06.096] iteration:10437  t-loss:0.1745, loss-lb:0.1298, loss-ulb:0.0224, weight:2.00, lr:0.0003
[05:23:06.418] iteration:10438  t-loss:0.3062, loss-lb:0.2709, loss-ulb:0.0177, weight:2.00, lr:0.0003
[05:23:06.735] iteration:10439  t-loss:0.2727, loss-lb:0.1445, loss-ulb:0.0641, weight:2.00, lr:0.0003
[05:23:07.057] iteration:10440  t-loss:0.3559, loss-lb:0.1687, loss-ulb:0.0936, weight:2.00, lr:0.0003
[05:23:07.377] iteration:10441  t-loss:0.2523, loss-lb:0.1327, loss-ulb:0.0598, weight:2.00, lr:0.0003
[05:23:07.697] iteration:10442  t-loss:0.2825, loss-lb:0.1498, loss-ulb:0.0664, weight:2.00, lr:0.0003
[05:23:08.016] iteration:10443  t-loss:0.6236, loss-lb:0.3071, loss-ulb:0.1582, weight:2.00, lr:0.0003
[05:23:08.330] iteration:10444  t-loss:0.2407, loss-lb:0.1540, loss-ulb:0.0433, weight:2.00, lr:0.0003
[05:23:08.646] iteration:10445  t-loss:0.3326, loss-lb:0.1928, loss-ulb:0.0699, weight:2.00, lr:0.0003
[05:23:08.962] iteration:10446  t-loss:0.3477, loss-lb:0.1913, loss-ulb:0.0782, weight:2.00, lr:0.0003
[05:23:09.281] iteration:10447  t-loss:0.3041, loss-lb:0.1929, loss-ulb:0.0556, weight:2.00, lr:0.0003
[05:23:09.595] iteration:10448  t-loss:0.1919, loss-lb:0.1497, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:23:09.912] iteration:10449  t-loss:0.4306, loss-lb:0.2963, loss-ulb:0.0672, weight:2.00, lr:0.0003
[05:23:10.229] iteration:10450  t-loss:0.3251, loss-lb:0.1580, loss-ulb:0.0835, weight:2.00, lr:0.0003
[05:23:11.625] iteration:10451  t-loss:0.5431, loss-lb:0.2587, loss-ulb:0.1422, weight:2.00, lr:0.0003
[05:23:11.960] iteration:10452  t-loss:0.2449, loss-lb:0.1189, loss-ulb:0.0630, weight:2.00, lr:0.0003
[05:23:12.288] iteration:10453  t-loss:0.2376, loss-lb:0.1290, loss-ulb:0.0543, weight:2.00, lr:0.0003
[05:23:12.614] iteration:10454  t-loss:0.5995, loss-lb:0.3533, loss-ulb:0.1231, weight:2.00, lr:0.0003
[05:23:12.936] iteration:10455  t-loss:0.4306, loss-lb:0.2488, loss-ulb:0.0909, weight:2.00, lr:0.0003
[05:23:13.256] iteration:10456  t-loss:0.1694, loss-lb:0.1261, loss-ulb:0.0217, weight:2.00, lr:0.0003
[05:23:13.573] iteration:10457  t-loss:0.3288, loss-lb:0.1546, loss-ulb:0.0871, weight:2.00, lr:0.0003
[05:23:13.893] iteration:10458  t-loss:0.2096, loss-lb:0.1799, loss-ulb:0.0149, weight:2.00, lr:0.0003
[05:23:14.217] iteration:10459  t-loss:0.4514, loss-lb:0.2548, loss-ulb:0.0983, weight:2.00, lr:0.0003
[05:23:14.532] iteration:10460  t-loss:0.2681, loss-lb:0.1239, loss-ulb:0.0721, weight:2.00, lr:0.0003
[05:23:14.852] iteration:10461  t-loss:0.5715, loss-lb:0.2984, loss-ulb:0.1365, weight:2.00, lr:0.0003
[05:23:15.170] iteration:10462  t-loss:0.3208, loss-lb:0.1623, loss-ulb:0.0793, weight:2.00, lr:0.0003
[05:23:15.491] iteration:10463  t-loss:0.2797, loss-lb:0.1292, loss-ulb:0.0752, weight:2.00, lr:0.0003
[05:23:15.808] iteration:10464  t-loss:0.2121, loss-lb:0.1189, loss-ulb:0.0466, weight:2.00, lr:0.0003
[05:23:16.126] iteration:10465  t-loss:0.2447, loss-lb:0.1956, loss-ulb:0.0245, weight:2.00, lr:0.0003
[05:23:16.447] iteration:10466  t-loss:0.3471, loss-lb:0.2119, loss-ulb:0.0676, weight:2.00, lr:0.0003
[05:23:16.770] iteration:10467  t-loss:0.3217, loss-lb:0.2825, loss-ulb:0.0196, weight:2.00, lr:0.0003
[05:23:17.089] iteration:10468  t-loss:0.2834, loss-lb:0.1656, loss-ulb:0.0589, weight:2.00, lr:0.0003
[05:23:17.406] iteration:10469  t-loss:0.2468, loss-lb:0.1229, loss-ulb:0.0619, weight:2.00, lr:0.0003
[05:23:17.723] iteration:10470  t-loss:0.3690, loss-lb:0.1813, loss-ulb:0.0938, weight:2.00, lr:0.0003
[05:23:18.041] iteration:10471  t-loss:0.2418, loss-lb:0.1320, loss-ulb:0.0549, weight:2.00, lr:0.0003
[05:23:18.358] iteration:10472  t-loss:0.1723, loss-lb:0.1446, loss-ulb:0.0138, weight:2.00, lr:0.0003
[05:23:18.677] iteration:10473  t-loss:0.3186, loss-lb:0.1657, loss-ulb:0.0765, weight:2.00, lr:0.0003
[05:23:18.990] iteration:10474  t-loss:0.2142, loss-lb:0.1763, loss-ulb:0.0189, weight:2.00, lr:0.0003
[05:23:19.309] iteration:10475  t-loss:0.1975, loss-lb:0.1506, loss-ulb:0.0234, weight:2.00, lr:0.0003
[05:23:20.610] iteration:10476  t-loss:0.3634, loss-lb:0.3169, loss-ulb:0.0233, weight:2.00, lr:0.0003
[05:23:20.948] iteration:10477  t-loss:0.2405, loss-lb:0.2050, loss-ulb:0.0177, weight:2.00, lr:0.0003
[05:23:21.271] iteration:10478  t-loss:0.3164, loss-lb:0.2182, loss-ulb:0.0491, weight:2.00, lr:0.0003
[05:23:21.591] iteration:10479  t-loss:0.2028, loss-lb:0.1560, loss-ulb:0.0234, weight:2.00, lr:0.0003
[05:23:21.916] iteration:10480  t-loss:0.3274, loss-lb:0.1770, loss-ulb:0.0752, weight:2.00, lr:0.0003
[05:23:22.240] iteration:10481  t-loss:0.3171, loss-lb:0.1470, loss-ulb:0.0851, weight:2.00, lr:0.0003
[05:23:22.562] iteration:10482  t-loss:0.3168, loss-lb:0.1425, loss-ulb:0.0872, weight:2.00, lr:0.0003
[05:23:22.882] iteration:10483  t-loss:0.3174, loss-lb:0.1523, loss-ulb:0.0825, weight:2.00, lr:0.0003
[05:23:23.207] iteration:10484  t-loss:0.2935, loss-lb:0.1759, loss-ulb:0.0588, weight:2.00, lr:0.0003
[05:23:23.526] iteration:10485  t-loss:0.2442, loss-lb:0.1503, loss-ulb:0.0469, weight:2.00, lr:0.0003
[05:23:23.844] iteration:10486  t-loss:0.3529, loss-lb:0.2632, loss-ulb:0.0449, weight:2.00, lr:0.0003
[05:23:24.166] iteration:10487  t-loss:0.2570, loss-lb:0.2227, loss-ulb:0.0171, weight:2.00, lr:0.0003
[05:23:24.490] iteration:10488  t-loss:0.3456, loss-lb:0.1532, loss-ulb:0.0962, weight:2.00, lr:0.0003
[05:23:24.810] iteration:10489  t-loss:0.3678, loss-lb:0.1698, loss-ulb:0.0990, weight:2.00, lr:0.0003
[05:23:25.139] iteration:10490  t-loss:0.4266, loss-lb:0.2426, loss-ulb:0.0920, weight:2.00, lr:0.0003
[05:23:25.469] iteration:10491  t-loss:0.4032, loss-lb:0.2563, loss-ulb:0.0734, weight:2.00, lr:0.0003
[05:23:25.797] iteration:10492  t-loss:0.3691, loss-lb:0.1410, loss-ulb:0.1140, weight:2.00, lr:0.0003
[05:23:26.126] iteration:10493  t-loss:0.2632, loss-lb:0.1425, loss-ulb:0.0604, weight:2.00, lr:0.0003
[05:23:26.449] iteration:10494  t-loss:0.4348, loss-lb:0.1330, loss-ulb:0.1509, weight:2.00, lr:0.0003
[05:23:26.774] iteration:10495  t-loss:0.4455, loss-lb:0.1451, loss-ulb:0.1502, weight:2.00, lr:0.0003
[05:23:27.096] iteration:10496  t-loss:0.3161, loss-lb:0.1372, loss-ulb:0.0895, weight:2.00, lr:0.0003
[05:23:27.421] iteration:10497  t-loss:0.1570, loss-lb:0.1262, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:23:27.738] iteration:10498  t-loss:0.2138, loss-lb:0.1739, loss-ulb:0.0199, weight:2.00, lr:0.0003
[05:23:28.056] iteration:10499  t-loss:0.2593, loss-lb:0.1426, loss-ulb:0.0584, weight:2.00, lr:0.0003
[05:23:28.377] iteration:10500  t-loss:0.3455, loss-lb:0.2003, loss-ulb:0.0726, weight:2.00, lr:0.0003
[05:23:29.656] iteration:10501  t-loss:0.1780, loss-lb:0.1362, loss-ulb:0.0209, weight:2.00, lr:0.0003
[05:23:29.997] iteration:10502  t-loss:0.3685, loss-lb:0.3093, loss-ulb:0.0296, weight:2.00, lr:0.0003
[05:23:30.320] iteration:10503  t-loss:0.2928, loss-lb:0.2462, loss-ulb:0.0233, weight:2.00, lr:0.0003
[05:23:30.647] iteration:10504  t-loss:0.2237, loss-lb:0.1974, loss-ulb:0.0131, weight:2.00, lr:0.0003
[05:23:30.980] iteration:10505  t-loss:0.5251, loss-lb:0.2613, loss-ulb:0.1319, weight:2.00, lr:0.0003
[05:23:31.318] iteration:10506  t-loss:0.5365, loss-lb:0.1585, loss-ulb:0.1890, weight:2.00, lr:0.0003
[05:23:31.646] iteration:10507  t-loss:0.2801, loss-lb:0.1298, loss-ulb:0.0751, weight:2.00, lr:0.0003
[05:23:31.975] iteration:10508  t-loss:0.2940, loss-lb:0.1323, loss-ulb:0.0808, weight:2.00, lr:0.0003
[05:23:32.306] iteration:10509  t-loss:0.5079, loss-lb:0.2423, loss-ulb:0.1328, weight:2.00, lr:0.0003
[05:23:32.639] iteration:10510  t-loss:0.2076, loss-lb:0.1757, loss-ulb:0.0160, weight:2.00, lr:0.0003
[05:23:32.962] iteration:10511  t-loss:0.3982, loss-lb:0.2283, loss-ulb:0.0850, weight:2.00, lr:0.0003
[05:23:33.290] iteration:10512  t-loss:0.3688, loss-lb:0.2206, loss-ulb:0.0741, weight:2.00, lr:0.0003
[05:23:33.614] iteration:10513  t-loss:0.2746, loss-lb:0.2044, loss-ulb:0.0351, weight:2.00, lr:0.0003
[05:23:33.939] iteration:10514  t-loss:0.2661, loss-lb:0.1805, loss-ulb:0.0428, weight:2.00, lr:0.0003
[05:23:34.261] iteration:10515  t-loss:0.2173, loss-lb:0.1836, loss-ulb:0.0169, weight:2.00, lr:0.0003
[05:23:34.585] iteration:10516  t-loss:0.2851, loss-lb:0.1640, loss-ulb:0.0606, weight:2.00, lr:0.0003
[05:23:34.902] iteration:10517  t-loss:0.3131, loss-lb:0.2848, loss-ulb:0.0141, weight:2.00, lr:0.0003
[05:23:35.219] iteration:10518  t-loss:0.4474, loss-lb:0.2283, loss-ulb:0.1096, weight:2.00, lr:0.0003
[05:23:35.537] iteration:10519  t-loss:0.3009, loss-lb:0.1871, loss-ulb:0.0569, weight:2.00, lr:0.0003
[05:23:35.857] iteration:10520  t-loss:0.2652, loss-lb:0.1467, loss-ulb:0.0592, weight:2.00, lr:0.0003
[05:23:36.175] iteration:10521  t-loss:0.4510, loss-lb:0.2115, loss-ulb:0.1198, weight:2.00, lr:0.0003
[05:23:36.491] iteration:10522  t-loss:0.1753, loss-lb:0.1340, loss-ulb:0.0207, weight:2.00, lr:0.0003
[05:23:36.805] iteration:10523  t-loss:0.3556, loss-lb:0.1515, loss-ulb:0.1020, weight:2.00, lr:0.0003
[05:23:37.122] iteration:10524  t-loss:0.5037, loss-lb:0.3179, loss-ulb:0.0929, weight:2.00, lr:0.0003
[05:23:37.436] iteration:10525  t-loss:0.2402, loss-lb:0.1627, loss-ulb:0.0387, weight:2.00, lr:0.0003
[05:25:46.101] iteration 10525 : dice_score: 0.849203 best_dice: 0.850800
[05:25:46.101]  <<Test>> - Ep:420  - Dice-S/T:84.60/84.92, Best-S:85.06, Best-T:85.08
[05:25:46.101]           - AvgLoss(lb/ulb/all):0.20/0.07/0.33
[05:25:47.435] iteration:10526  t-loss:0.3197, loss-lb:0.1910, loss-ulb:0.0644, weight:2.00, lr:0.0003
[05:25:47.770] iteration:10527  t-loss:0.3681, loss-lb:0.1861, loss-ulb:0.0910, weight:2.00, lr:0.0003
[05:25:48.091] iteration:10528  t-loss:0.2464, loss-lb:0.1928, loss-ulb:0.0268, weight:2.00, lr:0.0003
[05:25:48.414] iteration:10529  t-loss:0.2993, loss-lb:0.1303, loss-ulb:0.0845, weight:2.00, lr:0.0003
[05:25:48.746] iteration:10530  t-loss:0.4054, loss-lb:0.3298, loss-ulb:0.0378, weight:2.00, lr:0.0003
[05:25:49.068] iteration:10531  t-loss:0.2769, loss-lb:0.2229, loss-ulb:0.0270, weight:2.00, lr:0.0003
[05:25:49.388] iteration:10532  t-loss:0.4377, loss-lb:0.1294, loss-ulb:0.1542, weight:2.00, lr:0.0003
[05:25:49.707] iteration:10533  t-loss:0.6128, loss-lb:0.1630, loss-ulb:0.2249, weight:2.00, lr:0.0003
[05:25:50.023] iteration:10534  t-loss:0.7035, loss-lb:0.1295, loss-ulb:0.2870, weight:2.00, lr:0.0003
[05:25:50.341] iteration:10535  t-loss:0.1969, loss-lb:0.1317, loss-ulb:0.0326, weight:2.00, lr:0.0003
[05:25:50.656] iteration:10536  t-loss:0.4093, loss-lb:0.2081, loss-ulb:0.1006, weight:2.00, lr:0.0003
[05:25:50.972] iteration:10537  t-loss:0.3449, loss-lb:0.1323, loss-ulb:0.1063, weight:2.00, lr:0.0003
[05:25:51.292] iteration:10538  t-loss:0.3786, loss-lb:0.1395, loss-ulb:0.1195, weight:2.00, lr:0.0003
[05:25:51.611] iteration:10539  t-loss:0.2595, loss-lb:0.2235, loss-ulb:0.0180, weight:2.00, lr:0.0003
[05:25:51.932] iteration:10540  t-loss:0.3366, loss-lb:0.1751, loss-ulb:0.0808, weight:2.00, lr:0.0003
[05:25:52.252] iteration:10541  t-loss:0.4294, loss-lb:0.2337, loss-ulb:0.0979, weight:2.00, lr:0.0003
[05:25:52.568] iteration:10542  t-loss:0.2961, loss-lb:0.1581, loss-ulb:0.0690, weight:2.00, lr:0.0003
[05:25:52.882] iteration:10543  t-loss:0.1911, loss-lb:0.1501, loss-ulb:0.0205, weight:2.00, lr:0.0003
[05:25:53.197] iteration:10544  t-loss:0.2486, loss-lb:0.2027, loss-ulb:0.0229, weight:2.00, lr:0.0003
[05:25:53.513] iteration:10545  t-loss:0.3015, loss-lb:0.1922, loss-ulb:0.0546, weight:2.00, lr:0.0003
[05:25:53.828] iteration:10546  t-loss:0.4399, loss-lb:0.2582, loss-ulb:0.0909, weight:2.00, lr:0.0003
[05:25:54.144] iteration:10547  t-loss:0.4747, loss-lb:0.1290, loss-ulb:0.1729, weight:2.00, lr:0.0003
[05:25:54.461] iteration:10548  t-loss:0.2494, loss-lb:0.1718, loss-ulb:0.0388, weight:2.00, lr:0.0003
[05:25:54.781] iteration:10549  t-loss:0.4636, loss-lb:0.3222, loss-ulb:0.0707, weight:2.00, lr:0.0003
[05:25:55.101] iteration:10550  t-loss:0.4851, loss-lb:0.1779, loss-ulb:0.1536, weight:2.00, lr:0.0003
[05:25:56.573] iteration:10551  t-loss:0.4148, loss-lb:0.1545, loss-ulb:0.1301, weight:2.00, lr:0.0003
[05:25:56.907] iteration:10552  t-loss:0.3860, loss-lb:0.2732, loss-ulb:0.0564, weight:2.00, lr:0.0003
[05:25:57.236] iteration:10553  t-loss:0.4272, loss-lb:0.1758, loss-ulb:0.1257, weight:2.00, lr:0.0003
[05:25:57.551] iteration:10554  t-loss:0.2294, loss-lb:0.1292, loss-ulb:0.0501, weight:2.00, lr:0.0003
[05:25:57.869] iteration:10555  t-loss:0.4361, loss-lb:0.1304, loss-ulb:0.1528, weight:2.00, lr:0.0003
[05:25:58.187] iteration:10556  t-loss:0.2660, loss-lb:0.2189, loss-ulb:0.0235, weight:2.00, lr:0.0003
[05:25:58.505] iteration:10557  t-loss:0.2865, loss-lb:0.1903, loss-ulb:0.0481, weight:2.00, lr:0.0003
[05:25:58.824] iteration:10558  t-loss:0.3889, loss-lb:0.2063, loss-ulb:0.0913, weight:2.00, lr:0.0003
[05:25:59.140] iteration:10559  t-loss:0.1876, loss-lb:0.1430, loss-ulb:0.0223, weight:2.00, lr:0.0003
[05:25:59.464] iteration:10560  t-loss:0.5042, loss-lb:0.3216, loss-ulb:0.0913, weight:2.00, lr:0.0003
[05:25:59.786] iteration:10561  t-loss:0.5047, loss-lb:0.2242, loss-ulb:0.1402, weight:2.00, lr:0.0003
[05:26:00.104] iteration:10562  t-loss:0.2867, loss-lb:0.1907, loss-ulb:0.0480, weight:2.00, lr:0.0003
[05:26:00.426] iteration:10563  t-loss:0.5478, loss-lb:0.2370, loss-ulb:0.1554, weight:2.00, lr:0.0003
[05:26:00.752] iteration:10564  t-loss:0.3638, loss-lb:0.1782, loss-ulb:0.0928, weight:2.00, lr:0.0003
[05:26:01.073] iteration:10565  t-loss:0.2669, loss-lb:0.2220, loss-ulb:0.0225, weight:2.00, lr:0.0003
[05:26:01.394] iteration:10566  t-loss:0.3466, loss-lb:0.1386, loss-ulb:0.1040, weight:2.00, lr:0.0003
[05:26:01.711] iteration:10567  t-loss:0.1870, loss-lb:0.1354, loss-ulb:0.0258, weight:2.00, lr:0.0003
[05:26:02.025] iteration:10568  t-loss:0.2375, loss-lb:0.1650, loss-ulb:0.0362, weight:2.00, lr:0.0003
[05:26:02.345] iteration:10569  t-loss:0.4034, loss-lb:0.2417, loss-ulb:0.0809, weight:2.00, lr:0.0003
[05:26:02.662] iteration:10570  t-loss:0.4119, loss-lb:0.3329, loss-ulb:0.0395, weight:2.00, lr:0.0003
[05:26:02.978] iteration:10571  t-loss:0.4835, loss-lb:0.1367, loss-ulb:0.1734, weight:2.00, lr:0.0003
[05:26:03.293] iteration:10572  t-loss:0.2334, loss-lb:0.1959, loss-ulb:0.0187, weight:2.00, lr:0.0003
[05:26:03.608] iteration:10573  t-loss:0.1935, loss-lb:0.1466, loss-ulb:0.0234, weight:2.00, lr:0.0003
[05:26:03.927] iteration:10574  t-loss:0.3097, loss-lb:0.1765, loss-ulb:0.0666, weight:2.00, lr:0.0003
[05:26:04.244] iteration:10575  t-loss:0.3227, loss-lb:0.2544, loss-ulb:0.0341, weight:2.00, lr:0.0003
[05:26:05.484] iteration:10576  t-loss:0.6243, loss-lb:0.2398, loss-ulb:0.1923, weight:2.00, lr:0.0003
[05:26:05.816] iteration:10577  t-loss:0.4411, loss-lb:0.1432, loss-ulb:0.1489, weight:2.00, lr:0.0003
[05:26:06.155] iteration:10578  t-loss:0.3325, loss-lb:0.1743, loss-ulb:0.0791, weight:2.00, lr:0.0003
[05:26:06.480] iteration:10579  t-loss:0.1696, loss-lb:0.1303, loss-ulb:0.0197, weight:2.00, lr:0.0003
[05:26:06.801] iteration:10580  t-loss:0.3088, loss-lb:0.1687, loss-ulb:0.0700, weight:2.00, lr:0.0003
[05:26:07.117] iteration:10581  t-loss:0.1914, loss-lb:0.1569, loss-ulb:0.0173, weight:2.00, lr:0.0003
[05:26:07.437] iteration:10582  t-loss:0.4377, loss-lb:0.3232, loss-ulb:0.0573, weight:2.00, lr:0.0003
[05:26:07.761] iteration:10583  t-loss:0.3490, loss-lb:0.1778, loss-ulb:0.0856, weight:2.00, lr:0.0003
[05:26:08.086] iteration:10584  t-loss:0.3953, loss-lb:0.2270, loss-ulb:0.0842, weight:2.00, lr:0.0003
[05:26:08.407] iteration:10585  t-loss:0.3741, loss-lb:0.1758, loss-ulb:0.0992, weight:2.00, lr:0.0003
[05:26:08.734] iteration:10586  t-loss:0.4379, loss-lb:0.2211, loss-ulb:0.1084, weight:2.00, lr:0.0003
[05:26:09.055] iteration:10587  t-loss:0.3272, loss-lb:0.2904, loss-ulb:0.0184, weight:2.00, lr:0.0003
[05:26:09.376] iteration:10588  t-loss:0.1801, loss-lb:0.1487, loss-ulb:0.0157, weight:2.00, lr:0.0003
[05:26:09.705] iteration:10589  t-loss:0.4695, loss-lb:0.2889, loss-ulb:0.0903, weight:2.00, lr:0.0003
[05:26:10.029] iteration:10590  t-loss:0.2910, loss-lb:0.1438, loss-ulb:0.0736, weight:2.00, lr:0.0003
[05:26:10.356] iteration:10591  t-loss:0.2937, loss-lb:0.2591, loss-ulb:0.0173, weight:2.00, lr:0.0003
[05:26:10.682] iteration:10592  t-loss:0.3280, loss-lb:0.2035, loss-ulb:0.0623, weight:2.00, lr:0.0003
[05:26:11.005] iteration:10593  t-loss:0.4478, loss-lb:0.2130, loss-ulb:0.1174, weight:2.00, lr:0.0003
[05:26:11.325] iteration:10594  t-loss:0.4742, loss-lb:0.2998, loss-ulb:0.0872, weight:2.00, lr:0.0003
[05:26:11.649] iteration:10595  t-loss:0.3239, loss-lb:0.2146, loss-ulb:0.0546, weight:2.00, lr:0.0003
[05:26:11.966] iteration:10596  t-loss:0.3186, loss-lb:0.1356, loss-ulb:0.0915, weight:2.00, lr:0.0003
[05:26:12.283] iteration:10597  t-loss:0.3746, loss-lb:0.1421, loss-ulb:0.1163, weight:2.00, lr:0.0003
[05:26:12.604] iteration:10598  t-loss:0.4633, loss-lb:0.2303, loss-ulb:0.1165, weight:2.00, lr:0.0003
[05:26:12.922] iteration:10599  t-loss:0.2295, loss-lb:0.1895, loss-ulb:0.0200, weight:2.00, lr:0.0003
[05:26:13.236] iteration:10600  t-loss:0.2819, loss-lb:0.1482, loss-ulb:0.0669, weight:2.00, lr:0.0003
[05:26:14.706] iteration:10601  t-loss:0.2479, loss-lb:0.1412, loss-ulb:0.0533, weight:2.00, lr:0.0003
[05:26:15.046] iteration:10602  t-loss:0.3863, loss-lb:0.2506, loss-ulb:0.0679, weight:2.00, lr:0.0003
[05:26:15.369] iteration:10603  t-loss:0.3281, loss-lb:0.1982, loss-ulb:0.0649, weight:2.00, lr:0.0003
[05:26:15.693] iteration:10604  t-loss:0.2554, loss-lb:0.1875, loss-ulb:0.0340, weight:2.00, lr:0.0003
[05:26:16.011] iteration:10605  t-loss:0.3753, loss-lb:0.2037, loss-ulb:0.0858, weight:2.00, lr:0.0003
[05:26:16.330] iteration:10606  t-loss:0.2139, loss-lb:0.1587, loss-ulb:0.0276, weight:2.00, lr:0.0003
[05:26:16.658] iteration:10607  t-loss:0.3334, loss-lb:0.2918, loss-ulb:0.0208, weight:2.00, lr:0.0003
[05:26:16.983] iteration:10608  t-loss:0.3472, loss-lb:0.1702, loss-ulb:0.0885, weight:2.00, lr:0.0003
[05:26:17.309] iteration:10609  t-loss:0.3564, loss-lb:0.1808, loss-ulb:0.0878, weight:2.00, lr:0.0003
[05:26:17.631] iteration:10610  t-loss:0.2174, loss-lb:0.1374, loss-ulb:0.0400, weight:2.00, lr:0.0003
[05:26:17.960] iteration:10611  t-loss:0.2739, loss-lb:0.1779, loss-ulb:0.0480, weight:2.00, lr:0.0003
[05:26:18.283] iteration:10612  t-loss:0.3193, loss-lb:0.1741, loss-ulb:0.0726, weight:2.00, lr:0.0003
[05:26:18.608] iteration:10613  t-loss:0.3673, loss-lb:0.1883, loss-ulb:0.0895, weight:2.00, lr:0.0003
[05:26:18.929] iteration:10614  t-loss:0.3658, loss-lb:0.2814, loss-ulb:0.0422, weight:2.00, lr:0.0003
[05:26:19.250] iteration:10615  t-loss:0.2904, loss-lb:0.2391, loss-ulb:0.0256, weight:2.00, lr:0.0003
[05:26:19.566] iteration:10616  t-loss:0.2251, loss-lb:0.1880, loss-ulb:0.0186, weight:2.00, lr:0.0003
[05:26:19.885] iteration:10617  t-loss:0.1559, loss-lb:0.1281, loss-ulb:0.0139, weight:2.00, lr:0.0003
[05:26:20.204] iteration:10618  t-loss:0.4794, loss-lb:0.2140, loss-ulb:0.1327, weight:2.00, lr:0.0003
[05:26:20.523] iteration:10619  t-loss:0.2638, loss-lb:0.2029, loss-ulb:0.0304, weight:2.00, lr:0.0003
[05:26:20.839] iteration:10620  t-loss:0.2223, loss-lb:0.1656, loss-ulb:0.0284, weight:2.00, lr:0.0003
[05:26:21.153] iteration:10621  t-loss:0.2372, loss-lb:0.1949, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:26:21.469] iteration:10622  t-loss:0.2225, loss-lb:0.1304, loss-ulb:0.0460, weight:2.00, lr:0.0003
[05:26:21.790] iteration:10623  t-loss:0.2245, loss-lb:0.1916, loss-ulb:0.0164, weight:2.00, lr:0.0003
[05:26:22.109] iteration:10624  t-loss:0.3833, loss-lb:0.1721, loss-ulb:0.1056, weight:2.00, lr:0.0003
[05:26:22.426] iteration:10625  t-loss:0.2437, loss-lb:0.2082, loss-ulb:0.0178, weight:2.00, lr:0.0003
[05:28:38.456] iteration 10625 : dice_score: 0.850902 best_dice: 0.850900
[05:28:38.456]  <<Test>> - Ep:424  - Dice-S/T:85.02/85.09, Best-S:85.06, Best-T:85.09
[05:28:38.456]           - AvgLoss(lb/ulb/all):0.19/0.05/0.29
[05:28:39.604] iteration:10626  t-loss:0.2282, loss-lb:0.1767, loss-ulb:0.0258, weight:2.00, lr:0.0003
[05:28:39.947] iteration:10627  t-loss:0.4803, loss-lb:0.2831, loss-ulb:0.0986, weight:2.00, lr:0.0003
[05:28:40.273] iteration:10628  t-loss:0.3179, loss-lb:0.2431, loss-ulb:0.0374, weight:2.00, lr:0.0003
[05:28:40.594] iteration:10629  t-loss:0.1991, loss-lb:0.1376, loss-ulb:0.0307, weight:2.00, lr:0.0003
[05:28:40.922] iteration:10630  t-loss:0.2731, loss-lb:0.1591, loss-ulb:0.0570, weight:2.00, lr:0.0003
[05:28:41.242] iteration:10631  t-loss:0.2807, loss-lb:0.2134, loss-ulb:0.0337, weight:2.00, lr:0.0003
[05:28:41.558] iteration:10632  t-loss:0.1797, loss-lb:0.1470, loss-ulb:0.0163, weight:2.00, lr:0.0003
[05:28:41.882] iteration:10633  t-loss:0.3047, loss-lb:0.1709, loss-ulb:0.0669, weight:2.00, lr:0.0003
[05:28:42.202] iteration:10634  t-loss:0.3896, loss-lb:0.1941, loss-ulb:0.0977, weight:2.00, lr:0.0003
[05:28:42.526] iteration:10635  t-loss:0.2757, loss-lb:0.1132, loss-ulb:0.0813, weight:2.00, lr:0.0003
[05:28:42.847] iteration:10636  t-loss:0.3178, loss-lb:0.1593, loss-ulb:0.0792, weight:2.00, lr:0.0003
[05:28:43.166] iteration:10637  t-loss:0.3241, loss-lb:0.1394, loss-ulb:0.0924, weight:2.00, lr:0.0003
[05:28:43.487] iteration:10638  t-loss:0.5545, loss-lb:0.2629, loss-ulb:0.1458, weight:2.00, lr:0.0003
[05:28:43.809] iteration:10639  t-loss:0.2660, loss-lb:0.1486, loss-ulb:0.0587, weight:2.00, lr:0.0003
[05:28:44.130] iteration:10640  t-loss:0.4468, loss-lb:0.2791, loss-ulb:0.0839, weight:2.00, lr:0.0003
[05:28:44.452] iteration:10641  t-loss:0.3704, loss-lb:0.1576, loss-ulb:0.1064, weight:2.00, lr:0.0003
[05:28:44.772] iteration:10642  t-loss:0.3431, loss-lb:0.1675, loss-ulb:0.0878, weight:2.00, lr:0.0003
[05:28:45.087] iteration:10643  t-loss:0.1720, loss-lb:0.1470, loss-ulb:0.0125, weight:2.00, lr:0.0003
[05:28:45.406] iteration:10644  t-loss:0.4413, loss-lb:0.2709, loss-ulb:0.0852, weight:2.00, lr:0.0003
[05:28:45.727] iteration:10645  t-loss:0.4047, loss-lb:0.1116, loss-ulb:0.1466, weight:2.00, lr:0.0003
[05:28:46.050] iteration:10646  t-loss:0.2140, loss-lb:0.1821, loss-ulb:0.0159, weight:2.00, lr:0.0003
[05:28:46.376] iteration:10647  t-loss:0.3086, loss-lb:0.1831, loss-ulb:0.0628, weight:2.00, lr:0.0003
[05:28:46.702] iteration:10648  t-loss:0.4070, loss-lb:0.2050, loss-ulb:0.1010, weight:2.00, lr:0.0003
[05:28:47.023] iteration:10649  t-loss:0.1960, loss-lb:0.1617, loss-ulb:0.0171, weight:2.00, lr:0.0003
[05:28:47.342] iteration:10650  t-loss:0.2166, loss-lb:0.1494, loss-ulb:0.0336, weight:2.00, lr:0.0003
[05:28:48.678] iteration:10651  t-loss:0.1759, loss-lb:0.1435, loss-ulb:0.0162, weight:2.00, lr:0.0003
[05:28:49.015] iteration:10652  t-loss:0.3267, loss-lb:0.2175, loss-ulb:0.0546, weight:2.00, lr:0.0003
[05:28:49.346] iteration:10653  t-loss:0.3536, loss-lb:0.3046, loss-ulb:0.0245, weight:2.00, lr:0.0003
[05:28:49.668] iteration:10654  t-loss:0.1919, loss-lb:0.1589, loss-ulb:0.0165, weight:2.00, lr:0.0003
[05:28:49.989] iteration:10655  t-loss:0.3534, loss-lb:0.2548, loss-ulb:0.0493, weight:2.00, lr:0.0003
[05:28:50.311] iteration:10656  t-loss:0.2371, loss-lb:0.1361, loss-ulb:0.0505, weight:2.00, lr:0.0003
[05:28:50.628] iteration:10657  t-loss:0.5522, loss-lb:0.2824, loss-ulb:0.1349, weight:2.00, lr:0.0003
[05:28:50.947] iteration:10658  t-loss:0.2718, loss-lb:0.1480, loss-ulb:0.0619, weight:2.00, lr:0.0003
[05:28:51.264] iteration:10659  t-loss:0.3504, loss-lb:0.3222, loss-ulb:0.0141, weight:2.00, lr:0.0003
[05:28:51.579] iteration:10660  t-loss:0.3998, loss-lb:0.1328, loss-ulb:0.1335, weight:2.00, lr:0.0003
[05:28:51.900] iteration:10661  t-loss:0.7763, loss-lb:0.3336, loss-ulb:0.2213, weight:2.00, lr:0.0003
[05:28:52.224] iteration:10662  t-loss:0.2480, loss-lb:0.1297, loss-ulb:0.0592, weight:2.00, lr:0.0003
[05:28:52.546] iteration:10663  t-loss:0.3181, loss-lb:0.1570, loss-ulb:0.0805, weight:2.00, lr:0.0003
[05:28:52.867] iteration:10664  t-loss:0.1961, loss-lb:0.1525, loss-ulb:0.0218, weight:2.00, lr:0.0003
[05:28:53.190] iteration:10665  t-loss:0.2255, loss-lb:0.1528, loss-ulb:0.0363, weight:2.00, lr:0.0003
[05:28:53.510] iteration:10666  t-loss:0.2704, loss-lb:0.1676, loss-ulb:0.0514, weight:2.00, lr:0.0003
[05:28:53.831] iteration:10667  t-loss:0.4539, loss-lb:0.2260, loss-ulb:0.1140, weight:2.00, lr:0.0003
[05:28:54.147] iteration:10668  t-loss:0.1985, loss-lb:0.1159, loss-ulb:0.0413, weight:2.00, lr:0.0003
[05:28:54.464] iteration:10669  t-loss:0.2798, loss-lb:0.1381, loss-ulb:0.0709, weight:2.00, lr:0.0003
[05:28:54.778] iteration:10670  t-loss:0.1727, loss-lb:0.1210, loss-ulb:0.0258, weight:2.00, lr:0.0003
[05:28:55.096] iteration:10671  t-loss:0.3233, loss-lb:0.1601, loss-ulb:0.0816, weight:2.00, lr:0.0003
[05:28:55.410] iteration:10672  t-loss:0.2520, loss-lb:0.1985, loss-ulb:0.0267, weight:2.00, lr:0.0003
[05:28:55.726] iteration:10673  t-loss:0.2577, loss-lb:0.1759, loss-ulb:0.0409, weight:2.00, lr:0.0003
[05:28:56.040] iteration:10674  t-loss:0.1963, loss-lb:0.1534, loss-ulb:0.0215, weight:2.00, lr:0.0003
[05:28:56.357] iteration:10675  t-loss:0.1995, loss-lb:0.1495, loss-ulb:0.0250, weight:2.00, lr:0.0003
[05:28:57.643] iteration:10676  t-loss:0.4234, loss-lb:0.1525, loss-ulb:0.1354, weight:2.00, lr:0.0003
[05:28:57.979] iteration:10677  t-loss:0.2723, loss-lb:0.1550, loss-ulb:0.0587, weight:2.00, lr:0.0003
[05:28:58.303] iteration:10678  t-loss:0.4607, loss-lb:0.1948, loss-ulb:0.1329, weight:2.00, lr:0.0003
[05:28:58.627] iteration:10679  t-loss:0.3282, loss-lb:0.2130, loss-ulb:0.0576, weight:2.00, lr:0.0003
[05:28:58.959] iteration:10680  t-loss:0.3732, loss-lb:0.2414, loss-ulb:0.0659, weight:2.00, lr:0.0003
[05:28:59.287] iteration:10681  t-loss:0.3909, loss-lb:0.2700, loss-ulb:0.0605, weight:2.00, lr:0.0003
[05:28:59.619] iteration:10682  t-loss:0.4258, loss-lb:0.1749, loss-ulb:0.1254, weight:2.00, lr:0.0003
[05:28:59.947] iteration:10683  t-loss:0.3830, loss-lb:0.2533, loss-ulb:0.0649, weight:2.00, lr:0.0003
[05:29:00.277] iteration:10684  t-loss:0.5842, loss-lb:0.2017, loss-ulb:0.1913, weight:2.00, lr:0.0003
[05:29:00.606] iteration:10685  t-loss:0.2653, loss-lb:0.2233, loss-ulb:0.0210, weight:2.00, lr:0.0003
[05:29:00.930] iteration:10686  t-loss:0.4233, loss-lb:0.1952, loss-ulb:0.1141, weight:2.00, lr:0.0003
[05:29:01.248] iteration:10687  t-loss:0.2120, loss-lb:0.1731, loss-ulb:0.0195, weight:2.00, lr:0.0003
[05:29:01.567] iteration:10688  t-loss:0.2886, loss-lb:0.1568, loss-ulb:0.0659, weight:2.00, lr:0.0003
[05:29:01.887] iteration:10689  t-loss:0.4340, loss-lb:0.2772, loss-ulb:0.0784, weight:2.00, lr:0.0003
[05:29:02.211] iteration:10690  t-loss:0.3611, loss-lb:0.2211, loss-ulb:0.0700, weight:2.00, lr:0.0003
[05:29:02.530] iteration:10691  t-loss:0.1847, loss-lb:0.1396, loss-ulb:0.0225, weight:2.00, lr:0.0003
[05:29:02.851] iteration:10692  t-loss:0.4086, loss-lb:0.1595, loss-ulb:0.1245, weight:2.00, lr:0.0003
[05:29:03.166] iteration:10693  t-loss:0.1482, loss-lb:0.1077, loss-ulb:0.0202, weight:2.00, lr:0.0003
[05:29:03.484] iteration:10694  t-loss:0.3370, loss-lb:0.1913, loss-ulb:0.0729, weight:2.00, lr:0.0003
[05:29:03.799] iteration:10695  t-loss:0.1826, loss-lb:0.1183, loss-ulb:0.0321, weight:2.00, lr:0.0003
[05:29:04.119] iteration:10696  t-loss:0.3639, loss-lb:0.2183, loss-ulb:0.0728, weight:2.00, lr:0.0003
[05:29:04.436] iteration:10697  t-loss:0.2229, loss-lb:0.1734, loss-ulb:0.0247, weight:2.00, lr:0.0003
[05:29:04.751] iteration:10698  t-loss:0.2194, loss-lb:0.1734, loss-ulb:0.0230, weight:2.00, lr:0.0003
[05:29:05.070] iteration:10699  t-loss:0.3824, loss-lb:0.1858, loss-ulb:0.0983, weight:2.00, lr:0.0003
[05:29:05.385] iteration:10700  t-loss:0.1991, loss-lb:0.1513, loss-ulb:0.0239, weight:2.00, lr:0.0003
[05:29:06.842] iteration:10701  t-loss:0.4373, loss-lb:0.2365, loss-ulb:0.1004, weight:2.00, lr:0.0003
[05:29:07.174] iteration:10702  t-loss:0.2960, loss-lb:0.2651, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:29:07.498] iteration:10703  t-loss:0.3022, loss-lb:0.1086, loss-ulb:0.0968, weight:2.00, lr:0.0003
[05:29:07.814] iteration:10704  t-loss:0.2193, loss-lb:0.1759, loss-ulb:0.0217, weight:2.00, lr:0.0003
[05:29:08.133] iteration:10705  t-loss:0.3644, loss-lb:0.2006, loss-ulb:0.0819, weight:2.00, lr:0.0003
[05:29:08.452] iteration:10706  t-loss:0.2855, loss-lb:0.1341, loss-ulb:0.0757, weight:2.00, lr:0.0003
[05:29:08.769] iteration:10707  t-loss:0.1719, loss-lb:0.1236, loss-ulb:0.0242, weight:2.00, lr:0.0003
[05:29:09.086] iteration:10708  t-loss:0.1863, loss-lb:0.1483, loss-ulb:0.0190, weight:2.00, lr:0.0003
[05:29:09.403] iteration:10709  t-loss:0.1763, loss-lb:0.1436, loss-ulb:0.0164, weight:2.00, lr:0.0003
[05:29:09.724] iteration:10710  t-loss:0.4395, loss-lb:0.3005, loss-ulb:0.0695, weight:2.00, lr:0.0003
[05:29:10.042] iteration:10711  t-loss:0.3296, loss-lb:0.1787, loss-ulb:0.0754, weight:2.00, lr:0.0003
[05:29:10.367] iteration:10712  t-loss:0.3700, loss-lb:0.2150, loss-ulb:0.0775, weight:2.00, lr:0.0003
[05:29:10.718] iteration:10713  t-loss:0.2369, loss-lb:0.1165, loss-ulb:0.0602, weight:2.00, lr:0.0003
[05:29:11.058] iteration:10714  t-loss:0.2721, loss-lb:0.2100, loss-ulb:0.0310, weight:2.00, lr:0.0003
[05:29:11.439] iteration:10715  t-loss:0.4048, loss-lb:0.2651, loss-ulb:0.0698, weight:2.00, lr:0.0003
[05:29:11.786] iteration:10716  t-loss:0.3833, loss-lb:0.2174, loss-ulb:0.0830, weight:2.00, lr:0.0003
[05:29:12.127] iteration:10717  t-loss:0.2502, loss-lb:0.1388, loss-ulb:0.0557, weight:2.00, lr:0.0003
[05:29:12.466] iteration:10718  t-loss:0.7156, loss-lb:0.4864, loss-ulb:0.1146, weight:2.00, lr:0.0003
[05:29:12.803] iteration:10719  t-loss:0.2169, loss-lb:0.1747, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:29:13.128] iteration:10720  t-loss:0.1879, loss-lb:0.1498, loss-ulb:0.0191, weight:2.00, lr:0.0003
[05:29:13.466] iteration:10721  t-loss:0.4306, loss-lb:0.2741, loss-ulb:0.0783, weight:2.00, lr:0.0003
[05:29:13.794] iteration:10722  t-loss:0.2831, loss-lb:0.2390, loss-ulb:0.0220, weight:2.00, lr:0.0003
[05:29:14.134] iteration:10723  t-loss:0.2873, loss-lb:0.2063, loss-ulb:0.0405, weight:2.00, lr:0.0003
[05:29:14.456] iteration:10724  t-loss:0.2244, loss-lb:0.1182, loss-ulb:0.0531, weight:2.00, lr:0.0003
[05:29:14.776] iteration:10725  t-loss:0.2592, loss-lb:0.1619, loss-ulb:0.0486, weight:2.00, lr:0.0003
[05:31:30.145] iteration 10725 : dice_score: 0.849445 best_dice: 0.850900
[05:31:30.145]  <<Test>> - Ep:428  - Dice-S/T:84.93/84.94, Best-S:85.06, Best-T:85.09
[05:31:30.145]           - AvgLoss(lb/ulb/all):0.20/0.05/0.31
[05:31:31.436] iteration:10726  t-loss:0.2239, loss-lb:0.1709, loss-ulb:0.0265, weight:2.00, lr:0.0003
[05:31:31.814] iteration:10727  t-loss:0.3055, loss-lb:0.1744, loss-ulb:0.0656, weight:2.00, lr:0.0003
[05:31:32.173] iteration:10728  t-loss:0.2245, loss-lb:0.1811, loss-ulb:0.0217, weight:2.00, lr:0.0003
[05:31:32.527] iteration:10729  t-loss:0.5318, loss-lb:0.3733, loss-ulb:0.0793, weight:2.00, lr:0.0003
[05:31:32.883] iteration:10730  t-loss:0.3852, loss-lb:0.2190, loss-ulb:0.0831, weight:2.00, lr:0.0003
[05:31:33.233] iteration:10731  t-loss:0.5930, loss-lb:0.2677, loss-ulb:0.1627, weight:2.00, lr:0.0003
[05:31:33.574] iteration:10732  t-loss:0.1912, loss-lb:0.1595, loss-ulb:0.0159, weight:2.00, lr:0.0003
[05:31:33.932] iteration:10733  t-loss:0.2763, loss-lb:0.1321, loss-ulb:0.0721, weight:2.00, lr:0.0003
[05:31:34.276] iteration:10734  t-loss:0.2932, loss-lb:0.1606, loss-ulb:0.0663, weight:2.00, lr:0.0003
[05:31:34.620] iteration:10735  t-loss:0.3200, loss-lb:0.2186, loss-ulb:0.0507, weight:2.00, lr:0.0003
[05:31:34.961] iteration:10736  t-loss:0.2319, loss-lb:0.1481, loss-ulb:0.0419, weight:2.00, lr:0.0003
[05:31:35.293] iteration:10737  t-loss:0.1923, loss-lb:0.1460, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:31:35.628] iteration:10738  t-loss:0.2505, loss-lb:0.1679, loss-ulb:0.0413, weight:2.00, lr:0.0003
[05:31:35.974] iteration:10739  t-loss:0.3507, loss-lb:0.2927, loss-ulb:0.0290, weight:2.00, lr:0.0003
[05:31:36.306] iteration:10740  t-loss:0.3919, loss-lb:0.1914, loss-ulb:0.1003, weight:2.00, lr:0.0003
[05:31:36.628] iteration:10741  t-loss:0.2384, loss-lb:0.1474, loss-ulb:0.0455, weight:2.00, lr:0.0003
[05:31:36.950] iteration:10742  t-loss:0.2412, loss-lb:0.1633, loss-ulb:0.0390, weight:2.00, lr:0.0003
[05:31:37.266] iteration:10743  t-loss:0.2197, loss-lb:0.1839, loss-ulb:0.0179, weight:2.00, lr:0.0003
[05:31:37.579] iteration:10744  t-loss:0.1979, loss-lb:0.1489, loss-ulb:0.0245, weight:2.00, lr:0.0003
[05:31:37.891] iteration:10745  t-loss:0.2635, loss-lb:0.1100, loss-ulb:0.0768, weight:2.00, lr:0.0003
[05:31:38.203] iteration:10746  t-loss:0.1938, loss-lb:0.1509, loss-ulb:0.0214, weight:2.00, lr:0.0003
[05:31:38.515] iteration:10747  t-loss:0.3274, loss-lb:0.1780, loss-ulb:0.0747, weight:2.00, lr:0.0003
[05:31:38.831] iteration:10748  t-loss:0.2532, loss-lb:0.1994, loss-ulb:0.0269, weight:2.00, lr:0.0003
[05:31:39.146] iteration:10749  t-loss:0.3285, loss-lb:0.2574, loss-ulb:0.0356, weight:2.00, lr:0.0003
[05:31:39.460] iteration:10750  t-loss:0.2374, loss-lb:0.1291, loss-ulb:0.0542, weight:2.00, lr:0.0003
[05:31:40.680] iteration:10751  t-loss:0.2095, loss-lb:0.1783, loss-ulb:0.0156, weight:2.00, lr:0.0003
[05:31:41.007] iteration:10752  t-loss:0.3230, loss-lb:0.2975, loss-ulb:0.0128, weight:2.00, lr:0.0003
[05:31:41.334] iteration:10753  t-loss:0.3349, loss-lb:0.1707, loss-ulb:0.0821, weight:2.00, lr:0.0003
[05:31:41.659] iteration:10754  t-loss:0.3783, loss-lb:0.1460, loss-ulb:0.1161, weight:2.00, lr:0.0003
[05:31:41.984] iteration:10755  t-loss:0.2587, loss-lb:0.1691, loss-ulb:0.0448, weight:2.00, lr:0.0003
[05:31:42.301] iteration:10756  t-loss:0.1534, loss-lb:0.1276, loss-ulb:0.0129, weight:2.00, lr:0.0003
[05:31:42.618] iteration:10757  t-loss:0.2842, loss-lb:0.2436, loss-ulb:0.0203, weight:2.00, lr:0.0003
[05:31:42.938] iteration:10758  t-loss:0.3210, loss-lb:0.2056, loss-ulb:0.0577, weight:2.00, lr:0.0003
[05:31:43.260] iteration:10759  t-loss:0.2538, loss-lb:0.2163, loss-ulb:0.0187, weight:2.00, lr:0.0003
[05:31:43.580] iteration:10760  t-loss:0.3481, loss-lb:0.1824, loss-ulb:0.0828, weight:2.00, lr:0.0003
[05:31:43.897] iteration:10761  t-loss:0.2465, loss-lb:0.2002, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:31:44.218] iteration:10762  t-loss:0.2946, loss-lb:0.1372, loss-ulb:0.0787, weight:2.00, lr:0.0003
[05:31:44.541] iteration:10763  t-loss:0.3548, loss-lb:0.3297, loss-ulb:0.0125, weight:2.00, lr:0.0003
[05:31:44.857] iteration:10764  t-loss:0.2119, loss-lb:0.1740, loss-ulb:0.0189, weight:2.00, lr:0.0003
[05:31:45.183] iteration:10765  t-loss:0.2464, loss-lb:0.1344, loss-ulb:0.0560, weight:2.00, lr:0.0003
[05:31:45.506] iteration:10766  t-loss:0.3289, loss-lb:0.2685, loss-ulb:0.0302, weight:2.00, lr:0.0003
[05:31:45.829] iteration:10767  t-loss:0.2967, loss-lb:0.1743, loss-ulb:0.0612, weight:2.00, lr:0.0003
[05:31:46.148] iteration:10768  t-loss:0.2892, loss-lb:0.1998, loss-ulb:0.0447, weight:2.00, lr:0.0003
[05:31:46.463] iteration:10769  t-loss:0.3474, loss-lb:0.2016, loss-ulb:0.0729, weight:2.00, lr:0.0003
[05:31:46.782] iteration:10770  t-loss:0.2909, loss-lb:0.1673, loss-ulb:0.0618, weight:2.00, lr:0.0003
[05:31:47.098] iteration:10771  t-loss:0.3758, loss-lb:0.1183, loss-ulb:0.1288, weight:2.00, lr:0.0003
[05:31:47.414] iteration:10772  t-loss:0.2312, loss-lb:0.1969, loss-ulb:0.0172, weight:2.00, lr:0.0003
[05:31:47.728] iteration:10773  t-loss:0.2805, loss-lb:0.2121, loss-ulb:0.0342, weight:2.00, lr:0.0003
[05:31:48.045] iteration:10774  t-loss:0.1742, loss-lb:0.1437, loss-ulb:0.0152, weight:2.00, lr:0.0003
[05:31:48.364] iteration:10775  t-loss:0.2494, loss-lb:0.1637, loss-ulb:0.0429, weight:2.00, lr:0.0003
[05:31:49.850] iteration:10776  t-loss:0.2083, loss-lb:0.1428, loss-ulb:0.0327, weight:2.00, lr:0.0003
[05:31:50.183] iteration:10777  t-loss:0.2090, loss-lb:0.1442, loss-ulb:0.0324, weight:2.00, lr:0.0003
[05:31:50.524] iteration:10778  t-loss:0.2732, loss-lb:0.2226, loss-ulb:0.0253, weight:2.00, lr:0.0003
[05:31:50.848] iteration:10779  t-loss:0.4190, loss-lb:0.1605, loss-ulb:0.1293, weight:2.00, lr:0.0003
[05:31:51.168] iteration:10780  t-loss:0.1870, loss-lb:0.1540, loss-ulb:0.0165, weight:2.00, lr:0.0003
[05:31:51.486] iteration:10781  t-loss:0.1862, loss-lb:0.1466, loss-ulb:0.0198, weight:2.00, lr:0.0003
[05:31:51.806] iteration:10782  t-loss:0.3853, loss-lb:0.3464, loss-ulb:0.0194, weight:2.00, lr:0.0003
[05:31:52.132] iteration:10783  t-loss:0.3797, loss-lb:0.2078, loss-ulb:0.0860, weight:2.00, lr:0.0003
[05:31:52.455] iteration:10784  t-loss:0.4561, loss-lb:0.2468, loss-ulb:0.1046, weight:2.00, lr:0.0003
[05:31:52.773] iteration:10785  t-loss:0.2240, loss-lb:0.1741, loss-ulb:0.0250, weight:2.00, lr:0.0003
[05:31:53.097] iteration:10786  t-loss:0.3383, loss-lb:0.2185, loss-ulb:0.0599, weight:2.00, lr:0.0003
[05:31:53.416] iteration:10787  t-loss:0.2463, loss-lb:0.1313, loss-ulb:0.0575, weight:2.00, lr:0.0003
[05:31:53.736] iteration:10788  t-loss:0.1908, loss-lb:0.1509, loss-ulb:0.0200, weight:2.00, lr:0.0003
[05:31:54.059] iteration:10789  t-loss:0.2067, loss-lb:0.1459, loss-ulb:0.0304, weight:2.00, lr:0.0003
[05:31:54.384] iteration:10790  t-loss:0.4714, loss-lb:0.3607, loss-ulb:0.0553, weight:2.00, lr:0.0003
[05:31:54.704] iteration:10791  t-loss:0.1980, loss-lb:0.1632, loss-ulb:0.0174, weight:2.00, lr:0.0003
[05:31:55.032] iteration:10792  t-loss:0.4860, loss-lb:0.3126, loss-ulb:0.0867, weight:2.00, lr:0.0003
[05:31:55.350] iteration:10793  t-loss:0.1737, loss-lb:0.1504, loss-ulb:0.0116, weight:2.00, lr:0.0003
[05:31:55.671] iteration:10794  t-loss:0.2405, loss-lb:0.1185, loss-ulb:0.0610, weight:2.00, lr:0.0003
[05:31:55.991] iteration:10795  t-loss:0.3778, loss-lb:0.1948, loss-ulb:0.0915, weight:2.00, lr:0.0003
[05:31:56.306] iteration:10796  t-loss:0.2947, loss-lb:0.2038, loss-ulb:0.0455, weight:2.00, lr:0.0003
[05:31:56.624] iteration:10797  t-loss:0.2415, loss-lb:0.2012, loss-ulb:0.0201, weight:2.00, lr:0.0003
[05:31:56.941] iteration:10798  t-loss:0.3607, loss-lb:0.1345, loss-ulb:0.1131, weight:2.00, lr:0.0003
[05:31:57.257] iteration:10799  t-loss:0.2700, loss-lb:0.2392, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:31:57.573] iteration:10800  t-loss:0.2196, loss-lb:0.1650, loss-ulb:0.0273, weight:2.00, lr:0.0003
[05:31:59.003] iteration:10801  t-loss:0.4254, loss-lb:0.1454, loss-ulb:0.1400, weight:2.00, lr:0.0003
[05:31:59.339] iteration:10802  t-loss:0.3399, loss-lb:0.1935, loss-ulb:0.0732, weight:2.00, lr:0.0003
[05:31:59.663] iteration:10803  t-loss:0.2530, loss-lb:0.1965, loss-ulb:0.0282, weight:2.00, lr:0.0003
[05:31:59.988] iteration:10804  t-loss:0.3318, loss-lb:0.2045, loss-ulb:0.0636, weight:2.00, lr:0.0003
[05:32:00.310] iteration:10805  t-loss:0.3287, loss-lb:0.2543, loss-ulb:0.0372, weight:2.00, lr:0.0003
[05:32:00.632] iteration:10806  t-loss:0.3141, loss-lb:0.1709, loss-ulb:0.0716, weight:2.00, lr:0.0003
[05:32:00.958] iteration:10807  t-loss:0.5101, loss-lb:0.2366, loss-ulb:0.1367, weight:2.00, lr:0.0003
[05:32:01.281] iteration:10808  t-loss:0.5713, loss-lb:0.2985, loss-ulb:0.1364, weight:2.00, lr:0.0003
[05:32:01.606] iteration:10809  t-loss:0.5765, loss-lb:0.5300, loss-ulb:0.0233, weight:2.00, lr:0.0003
[05:32:01.929] iteration:10810  t-loss:0.2743, loss-lb:0.2323, loss-ulb:0.0210, weight:2.00, lr:0.0003
[05:32:02.249] iteration:10811  t-loss:0.5344, loss-lb:0.1950, loss-ulb:0.1697, weight:2.00, lr:0.0003
[05:32:02.571] iteration:10812  t-loss:0.2467, loss-lb:0.2028, loss-ulb:0.0219, weight:2.00, lr:0.0003
[05:32:02.894] iteration:10813  t-loss:0.3852, loss-lb:0.2113, loss-ulb:0.0870, weight:2.00, lr:0.0003
[05:32:03.213] iteration:10814  t-loss:0.2430, loss-lb:0.1667, loss-ulb:0.0382, weight:2.00, lr:0.0003
[05:32:03.528] iteration:10815  t-loss:0.3333, loss-lb:0.1636, loss-ulb:0.0849, weight:2.00, lr:0.0003
[05:32:03.850] iteration:10816  t-loss:0.4861, loss-lb:0.2286, loss-ulb:0.1287, weight:2.00, lr:0.0003
[05:32:04.171] iteration:10817  t-loss:0.3073, loss-lb:0.2585, loss-ulb:0.0244, weight:2.00, lr:0.0003
[05:32:04.487] iteration:10818  t-loss:0.2597, loss-lb:0.1403, loss-ulb:0.0597, weight:2.00, lr:0.0003
[05:32:04.802] iteration:10819  t-loss:0.3992, loss-lb:0.1362, loss-ulb:0.1315, weight:2.00, lr:0.0003
[05:32:05.119] iteration:10820  t-loss:0.6249, loss-lb:0.1539, loss-ulb:0.2355, weight:2.00, lr:0.0003
[05:32:05.438] iteration:10821  t-loss:0.2514, loss-lb:0.2091, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:32:05.758] iteration:10822  t-loss:0.3991, loss-lb:0.2259, loss-ulb:0.0866, weight:2.00, lr:0.0003
[05:32:06.081] iteration:10823  t-loss:0.5152, loss-lb:0.2161, loss-ulb:0.1496, weight:2.00, lr:0.0003
[05:32:06.402] iteration:10824  t-loss:0.5905, loss-lb:0.1446, loss-ulb:0.2229, weight:2.00, lr:0.0003
[05:32:06.722] iteration:10825  t-loss:0.3873, loss-lb:0.2022, loss-ulb:0.0925, weight:2.00, lr:0.0003
[05:34:23.565] iteration 10825 : dice_score: 0.850934 best_dice: 0.850900
[05:34:23.565]  <<Test>> - Ep:432  - Dice-S/T:84.89/85.09, Best-S:85.06, Best-T:85.09
[05:34:23.566]           - AvgLoss(lb/ulb/all):0.21/0.10/0.41
[05:34:25.052] iteration:10826  t-loss:0.4244, loss-lb:0.2787, loss-ulb:0.0728, weight:2.00, lr:0.0003
[05:34:25.386] iteration:10827  t-loss:0.2805, loss-lb:0.2038, loss-ulb:0.0384, weight:2.00, lr:0.0003
[05:34:25.717] iteration:10828  t-loss:0.5787, loss-lb:0.4849, loss-ulb:0.0469, weight:2.00, lr:0.0003
[05:34:26.049] iteration:10829  t-loss:0.2594, loss-lb:0.1655, loss-ulb:0.0470, weight:2.00, lr:0.0003
[05:34:26.374] iteration:10830  t-loss:0.3008, loss-lb:0.1344, loss-ulb:0.0832, weight:2.00, lr:0.0003
[05:34:26.696] iteration:10831  t-loss:0.3553, loss-lb:0.1428, loss-ulb:0.1063, weight:2.00, lr:0.0003
[05:34:27.017] iteration:10832  t-loss:0.3308, loss-lb:0.2912, loss-ulb:0.0198, weight:2.00, lr:0.0003
[05:34:27.338] iteration:10833  t-loss:0.4477, loss-lb:0.2396, loss-ulb:0.1040, weight:2.00, lr:0.0003
[05:34:27.663] iteration:10834  t-loss:0.4312, loss-lb:0.2067, loss-ulb:0.1122, weight:2.00, lr:0.0003
[05:34:27.982] iteration:10835  t-loss:0.6314, loss-lb:0.1882, loss-ulb:0.2216, weight:2.00, lr:0.0003
[05:34:28.304] iteration:10836  t-loss:0.3767, loss-lb:0.1501, loss-ulb:0.1133, weight:2.00, lr:0.0003
[05:34:28.625] iteration:10837  t-loss:0.2679, loss-lb:0.2132, loss-ulb:0.0274, weight:2.00, lr:0.0003
[05:34:28.944] iteration:10838  t-loss:0.2070, loss-lb:0.1521, loss-ulb:0.0275, weight:2.00, lr:0.0003
[05:34:29.265] iteration:10839  t-loss:0.2475, loss-lb:0.2174, loss-ulb:0.0150, weight:2.00, lr:0.0003
[05:34:29.583] iteration:10840  t-loss:0.2029, loss-lb:0.1612, loss-ulb:0.0209, weight:2.00, lr:0.0003
[05:34:29.901] iteration:10841  t-loss:0.3538, loss-lb:0.1515, loss-ulb:0.1011, weight:2.00, lr:0.0003
[05:34:30.223] iteration:10842  t-loss:0.3412, loss-lb:0.1932, loss-ulb:0.0740, weight:2.00, lr:0.0003
[05:34:30.542] iteration:10843  t-loss:0.3479, loss-lb:0.1828, loss-ulb:0.0825, weight:2.00, lr:0.0003
[05:34:30.855] iteration:10844  t-loss:0.1908, loss-lb:0.1497, loss-ulb:0.0205, weight:2.00, lr:0.0003
[05:34:31.172] iteration:10845  t-loss:0.2399, loss-lb:0.1186, loss-ulb:0.0606, weight:2.00, lr:0.0003
[05:34:31.486] iteration:10846  t-loss:0.4577, loss-lb:0.2592, loss-ulb:0.0992, weight:2.00, lr:0.0003
[05:34:31.801] iteration:10847  t-loss:0.4746, loss-lb:0.1606, loss-ulb:0.1570, weight:2.00, lr:0.0003
[05:34:32.117] iteration:10848  t-loss:0.4056, loss-lb:0.2242, loss-ulb:0.0907, weight:2.00, lr:0.0003
[05:34:32.434] iteration:10849  t-loss:0.3082, loss-lb:0.1167, loss-ulb:0.0958, weight:2.00, lr:0.0003
[05:34:32.749] iteration:10850  t-loss:0.2384, loss-lb:0.1491, loss-ulb:0.0446, weight:2.00, lr:0.0003
[05:34:34.243] iteration:10851  t-loss:0.2183, loss-lb:0.1185, loss-ulb:0.0499, weight:2.00, lr:0.0003
[05:34:34.579] iteration:10852  t-loss:0.2771, loss-lb:0.2362, loss-ulb:0.0205, weight:2.00, lr:0.0003
[05:34:34.908] iteration:10853  t-loss:1.6495, loss-lb:0.2109, loss-ulb:0.7193, weight:2.00, lr:0.0003
[05:34:35.229] iteration:10854  t-loss:0.3021, loss-lb:0.2666, loss-ulb:0.0177, weight:2.00, lr:0.0003
[05:34:35.545] iteration:10855  t-loss:0.2934, loss-lb:0.1408, loss-ulb:0.0763, weight:2.00, lr:0.0003
[05:34:35.862] iteration:10856  t-loss:0.3314, loss-lb:0.1736, loss-ulb:0.0789, weight:2.00, lr:0.0003
[05:34:36.179] iteration:10857  t-loss:0.2179, loss-lb:0.1568, loss-ulb:0.0305, weight:2.00, lr:0.0003
[05:34:36.500] iteration:10858  t-loss:0.2631, loss-lb:0.1332, loss-ulb:0.0649, weight:2.00, lr:0.0003
[05:34:36.822] iteration:10859  t-loss:0.2130, loss-lb:0.1652, loss-ulb:0.0239, weight:2.00, lr:0.0003
[05:34:37.145] iteration:10860  t-loss:0.2115, loss-lb:0.1566, loss-ulb:0.0275, weight:2.00, lr:0.0003
[05:34:37.473] iteration:10861  t-loss:0.2807, loss-lb:0.2238, loss-ulb:0.0285, weight:2.00, lr:0.0003
[05:34:37.795] iteration:10862  t-loss:0.3353, loss-lb:0.2219, loss-ulb:0.0567, weight:2.00, lr:0.0003
[05:34:38.125] iteration:10863  t-loss:0.3727, loss-lb:0.3462, loss-ulb:0.0133, weight:2.00, lr:0.0003
[05:34:38.450] iteration:10864  t-loss:0.1978, loss-lb:0.1536, loss-ulb:0.0221, weight:2.00, lr:0.0003
[05:34:38.771] iteration:10865  t-loss:0.2390, loss-lb:0.1858, loss-ulb:0.0266, weight:2.00, lr:0.0003
[05:34:39.094] iteration:10866  t-loss:0.2776, loss-lb:0.2469, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:34:39.420] iteration:10867  t-loss:0.2825, loss-lb:0.2422, loss-ulb:0.0202, weight:2.00, lr:0.0003
[05:34:39.736] iteration:10868  t-loss:0.3872, loss-lb:0.1290, loss-ulb:0.1291, weight:2.00, lr:0.0003
[05:34:40.056] iteration:10869  t-loss:0.3539, loss-lb:0.1524, loss-ulb:0.1007, weight:2.00, lr:0.0003
[05:34:40.373] iteration:10870  t-loss:0.3931, loss-lb:0.1987, loss-ulb:0.0972, weight:2.00, lr:0.0003
[05:34:40.689] iteration:10871  t-loss:0.4307, loss-lb:0.1514, loss-ulb:0.1396, weight:2.00, lr:0.0003
[05:34:41.006] iteration:10872  t-loss:0.3130, loss-lb:0.2605, loss-ulb:0.0263, weight:2.00, lr:0.0003
[05:34:41.323] iteration:10873  t-loss:0.2171, loss-lb:0.1723, loss-ulb:0.0224, weight:2.00, lr:0.0003
[05:34:41.639] iteration:10874  t-loss:0.3759, loss-lb:0.1848, loss-ulb:0.0956, weight:2.00, lr:0.0003
[05:34:41.957] iteration:10875  t-loss:0.3053, loss-lb:0.2396, loss-ulb:0.0328, weight:2.00, lr:0.0003
[05:34:43.367] iteration:10876  t-loss:0.3404, loss-lb:0.1975, loss-ulb:0.0715, weight:2.00, lr:0.0003
[05:34:43.704] iteration:10877  t-loss:0.3381, loss-lb:0.1457, loss-ulb:0.0962, weight:2.00, lr:0.0003
[05:34:44.030] iteration:10878  t-loss:0.4595, loss-lb:0.1309, loss-ulb:0.1643, weight:2.00, lr:0.0003
[05:34:44.359] iteration:10879  t-loss:0.2331, loss-lb:0.1966, loss-ulb:0.0182, weight:2.00, lr:0.0003
[05:34:44.675] iteration:10880  t-loss:0.1599, loss-lb:0.1237, loss-ulb:0.0181, weight:2.00, lr:0.0003
[05:34:44.998] iteration:10881  t-loss:0.3124, loss-lb:0.2497, loss-ulb:0.0313, weight:2.00, lr:0.0003
[05:34:45.319] iteration:10882  t-loss:0.3326, loss-lb:0.2123, loss-ulb:0.0602, weight:2.00, lr:0.0003
[05:34:45.642] iteration:10883  t-loss:0.4242, loss-lb:0.2162, loss-ulb:0.1040, weight:2.00, lr:0.0003
[05:34:45.960] iteration:10884  t-loss:0.3367, loss-lb:0.2022, loss-ulb:0.0673, weight:2.00, lr:0.0003
[05:34:46.278] iteration:10885  t-loss:0.2520, loss-lb:0.1187, loss-ulb:0.0666, weight:2.00, lr:0.0003
[05:34:46.598] iteration:10886  t-loss:0.3640, loss-lb:0.2246, loss-ulb:0.0697, weight:2.00, lr:0.0003
[05:34:46.916] iteration:10887  t-loss:0.2895, loss-lb:0.1537, loss-ulb:0.0679, weight:2.00, lr:0.0003
[05:34:47.234] iteration:10888  t-loss:0.3074, loss-lb:0.1685, loss-ulb:0.0694, weight:2.00, lr:0.0003
[05:34:47.568] iteration:10889  t-loss:0.3291, loss-lb:0.1749, loss-ulb:0.0771, weight:2.00, lr:0.0003
[05:34:47.888] iteration:10890  t-loss:0.4091, loss-lb:0.2575, loss-ulb:0.0758, weight:2.00, lr:0.0003
[05:34:48.207] iteration:10891  t-loss:0.3286, loss-lb:0.1878, loss-ulb:0.0704, weight:2.00, lr:0.0003
[05:34:48.522] iteration:10892  t-loss:0.5676, loss-lb:0.1534, loss-ulb:0.2071, weight:2.00, lr:0.0003
[05:34:48.836] iteration:10893  t-loss:0.1856, loss-lb:0.1264, loss-ulb:0.0296, weight:2.00, lr:0.0003
[05:34:49.153] iteration:10894  t-loss:0.2254, loss-lb:0.1910, loss-ulb:0.0172, weight:2.00, lr:0.0003
[05:34:49.471] iteration:10895  t-loss:0.4024, loss-lb:0.3282, loss-ulb:0.0371, weight:2.00, lr:0.0003
[05:34:49.787] iteration:10896  t-loss:0.1742, loss-lb:0.1075, loss-ulb:0.0334, weight:2.00, lr:0.0003
[05:34:50.105] iteration:10897  t-loss:0.1955, loss-lb:0.1620, loss-ulb:0.0168, weight:2.00, lr:0.0003
[05:34:50.428] iteration:10898  t-loss:0.5990, loss-lb:0.2347, loss-ulb:0.1821, weight:2.00, lr:0.0003
[05:34:50.747] iteration:10899  t-loss:1.2404, loss-lb:0.1331, loss-ulb:0.5537, weight:2.00, lr:0.0003
[05:34:51.064] iteration:10900  t-loss:0.2625, loss-lb:0.2106, loss-ulb:0.0260, weight:2.00, lr:0.0003
[05:34:52.429] iteration:10901  t-loss:0.2682, loss-lb:0.2248, loss-ulb:0.0217, weight:2.00, lr:0.0003
[05:34:52.767] iteration:10902  t-loss:0.2919, loss-lb:0.2009, loss-ulb:0.0455, weight:2.00, lr:0.0003
[05:34:53.096] iteration:10903  t-loss:0.3269, loss-lb:0.2261, loss-ulb:0.0504, weight:2.00, lr:0.0003
[05:34:53.419] iteration:10904  t-loss:0.1720, loss-lb:0.1396, loss-ulb:0.0162, weight:2.00, lr:0.0003
[05:34:53.744] iteration:10905  t-loss:0.4411, loss-lb:0.2277, loss-ulb:0.1067, weight:2.00, lr:0.0003
[05:34:54.066] iteration:10906  t-loss:0.2539, loss-lb:0.2183, loss-ulb:0.0178, weight:2.00, lr:0.0003
[05:34:54.386] iteration:10907  t-loss:0.3561, loss-lb:0.2427, loss-ulb:0.0567, weight:2.00, lr:0.0003
[05:34:54.712] iteration:10908  t-loss:0.3908, loss-lb:0.2584, loss-ulb:0.0662, weight:2.00, lr:0.0003
[05:34:55.028] iteration:10909  t-loss:0.3028, loss-lb:0.1359, loss-ulb:0.0834, weight:2.00, lr:0.0003
[05:34:55.349] iteration:10910  t-loss:0.4380, loss-lb:0.3546, loss-ulb:0.0417, weight:2.00, lr:0.0003
[05:34:55.672] iteration:10911  t-loss:0.2702, loss-lb:0.2186, loss-ulb:0.0258, weight:2.00, lr:0.0003
[05:34:55.992] iteration:10912  t-loss:0.5918, loss-lb:0.1678, loss-ulb:0.2120, weight:2.00, lr:0.0003
[05:34:56.313] iteration:10913  t-loss:0.2084, loss-lb:0.1163, loss-ulb:0.0460, weight:2.00, lr:0.0003
[05:34:56.634] iteration:10914  t-loss:0.2817, loss-lb:0.2237, loss-ulb:0.0290, weight:2.00, lr:0.0003
[05:34:56.953] iteration:10915  t-loss:0.3632, loss-lb:0.1005, loss-ulb:0.1313, weight:2.00, lr:0.0003
[05:34:57.274] iteration:10916  t-loss:0.4887, loss-lb:0.1750, loss-ulb:0.1568, weight:2.00, lr:0.0003
[05:34:57.592] iteration:10917  t-loss:0.2542, loss-lb:0.1483, loss-ulb:0.0529, weight:2.00, lr:0.0003
[05:34:57.910] iteration:10918  t-loss:0.4135, loss-lb:0.2252, loss-ulb:0.0941, weight:2.00, lr:0.0003
[05:34:58.234] iteration:10919  t-loss:0.3972, loss-lb:0.1585, loss-ulb:0.1194, weight:2.00, lr:0.0003
[05:34:58.562] iteration:10920  t-loss:0.2760, loss-lb:0.2364, loss-ulb:0.0198, weight:2.00, lr:0.0003
[05:34:58.886] iteration:10921  t-loss:0.2841, loss-lb:0.2567, loss-ulb:0.0137, weight:2.00, lr:0.0003
[05:34:59.206] iteration:10922  t-loss:0.3050, loss-lb:0.1488, loss-ulb:0.0781, weight:2.00, lr:0.0003
[05:34:59.524] iteration:10923  t-loss:0.2842, loss-lb:0.1325, loss-ulb:0.0758, weight:2.00, lr:0.0003
[05:34:59.846] iteration:10924  t-loss:0.3223, loss-lb:0.2270, loss-ulb:0.0476, weight:2.00, lr:0.0003
[05:35:00.164] iteration:10925  t-loss:0.4374, loss-lb:0.1359, loss-ulb:0.1508, weight:2.00, lr:0.0003
[05:37:02.456] iteration 10925 : dice_score: 0.851574 best_dice: 0.851600
[05:37:02.457]  <<Test>> - Ep:436  - Dice-S/T:84.91/85.16, Best-S:85.06, Best-T:85.16
[05:37:02.457]           - AvgLoss(lb/ulb/all):0.20/0.08/0.35
[05:37:03.725] iteration:10926  t-loss:0.2465, loss-lb:0.2107, loss-ulb:0.0179, weight:2.00, lr:0.0003
[05:37:04.056] iteration:10927  t-loss:0.2882, loss-lb:0.1606, loss-ulb:0.0638, weight:2.00, lr:0.0003
[05:37:04.385] iteration:10928  t-loss:0.4474, loss-lb:0.2430, loss-ulb:0.1022, weight:2.00, lr:0.0003
[05:37:04.710] iteration:10929  t-loss:0.2897, loss-lb:0.1285, loss-ulb:0.0806, weight:2.00, lr:0.0003
[05:37:05.036] iteration:10930  t-loss:0.2628, loss-lb:0.2082, loss-ulb:0.0273, weight:2.00, lr:0.0003
[05:37:05.354] iteration:10931  t-loss:0.3171, loss-lb:0.1542, loss-ulb:0.0815, weight:2.00, lr:0.0003
[05:37:05.673] iteration:10932  t-loss:0.2919, loss-lb:0.1584, loss-ulb:0.0668, weight:2.00, lr:0.0003
[05:37:05.995] iteration:10933  t-loss:0.2384, loss-lb:0.2008, loss-ulb:0.0188, weight:2.00, lr:0.0003
[05:37:06.312] iteration:10934  t-loss:0.2094, loss-lb:0.1825, loss-ulb:0.0135, weight:2.00, lr:0.0003
[05:37:06.632] iteration:10935  t-loss:0.3152, loss-lb:0.2272, loss-ulb:0.0440, weight:2.00, lr:0.0003
[05:37:06.949] iteration:10936  t-loss:0.2081, loss-lb:0.1646, loss-ulb:0.0218, weight:2.00, lr:0.0003
[05:37:07.264] iteration:10937  t-loss:0.2720, loss-lb:0.1158, loss-ulb:0.0781, weight:2.00, lr:0.0003
[05:37:07.587] iteration:10938  t-loss:0.5406, loss-lb:0.1746, loss-ulb:0.1830, weight:2.00, lr:0.0003
[05:37:07.907] iteration:10939  t-loss:0.4179, loss-lb:0.2021, loss-ulb:0.1079, weight:2.00, lr:0.0003
[05:37:08.226] iteration:10940  t-loss:0.3379, loss-lb:0.2528, loss-ulb:0.0426, weight:2.00, lr:0.0003
[05:37:08.545] iteration:10941  t-loss:0.4444, loss-lb:0.2336, loss-ulb:0.1054, weight:2.00, lr:0.0003
[05:37:08.867] iteration:10942  t-loss:0.6859, loss-lb:0.3125, loss-ulb:0.1867, weight:2.00, lr:0.0003
[05:37:09.185] iteration:10943  t-loss:0.4944, loss-lb:0.2850, loss-ulb:0.1047, weight:2.00, lr:0.0003
[05:37:09.503] iteration:10944  t-loss:0.2197, loss-lb:0.1534, loss-ulb:0.0331, weight:2.00, lr:0.0003
[05:37:09.820] iteration:10945  t-loss:0.2446, loss-lb:0.1970, loss-ulb:0.0238, weight:2.00, lr:0.0003
[05:37:10.134] iteration:10946  t-loss:0.2123, loss-lb:0.1823, loss-ulb:0.0150, weight:2.00, lr:0.0003
[05:37:10.452] iteration:10947  t-loss:0.3345, loss-lb:0.2801, loss-ulb:0.0272, weight:2.00, lr:0.0003
[05:37:10.767] iteration:10948  t-loss:0.1901, loss-lb:0.1535, loss-ulb:0.0183, weight:2.00, lr:0.0003
[05:37:11.083] iteration:10949  t-loss:0.2293, loss-lb:0.1753, loss-ulb:0.0270, weight:2.00, lr:0.0003
[05:37:11.399] iteration:10950  t-loss:0.3769, loss-lb:0.1617, loss-ulb:0.1076, weight:2.00, lr:0.0003
[05:37:12.676] iteration:10951  t-loss:0.2505, loss-lb:0.2160, loss-ulb:0.0173, weight:2.00, lr:0.0003
[05:37:13.006] iteration:10952  t-loss:0.2386, loss-lb:0.1410, loss-ulb:0.0488, weight:2.00, lr:0.0003
[05:37:13.324] iteration:10953  t-loss:0.2279, loss-lb:0.1806, loss-ulb:0.0237, weight:2.00, lr:0.0003
[05:37:13.640] iteration:10954  t-loss:0.2209, loss-lb:0.1525, loss-ulb:0.0342, weight:2.00, lr:0.0003
[05:37:13.958] iteration:10955  t-loss:0.1939, loss-lb:0.1542, loss-ulb:0.0198, weight:2.00, lr:0.0003
[05:37:14.274] iteration:10956  t-loss:0.3047, loss-lb:0.1281, loss-ulb:0.0883, weight:2.00, lr:0.0003
[05:37:14.596] iteration:10957  t-loss:0.4509, loss-lb:0.2508, loss-ulb:0.1000, weight:2.00, lr:0.0003
[05:37:14.916] iteration:10958  t-loss:0.5069, loss-lb:0.2426, loss-ulb:0.1322, weight:2.00, lr:0.0003
[05:37:15.239] iteration:10959  t-loss:0.3602, loss-lb:0.1615, loss-ulb:0.0993, weight:2.00, lr:0.0003
[05:37:15.558] iteration:10960  t-loss:0.2875, loss-lb:0.1794, loss-ulb:0.0540, weight:2.00, lr:0.0003
[05:37:15.880] iteration:10961  t-loss:0.3120, loss-lb:0.1766, loss-ulb:0.0677, weight:2.00, lr:0.0003
[05:37:16.200] iteration:10962  t-loss:0.3954, loss-lb:0.2079, loss-ulb:0.0938, weight:2.00, lr:0.0003
[05:37:16.520] iteration:10963  t-loss:0.2958, loss-lb:0.2161, loss-ulb:0.0398, weight:2.00, lr:0.0003
[05:37:16.839] iteration:10964  t-loss:0.2857, loss-lb:0.1383, loss-ulb:0.0737, weight:2.00, lr:0.0003
[05:37:17.163] iteration:10965  t-loss:0.3180, loss-lb:0.1633, loss-ulb:0.0774, weight:2.00, lr:0.0003
[05:37:17.486] iteration:10966  t-loss:0.2909, loss-lb:0.2448, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:37:17.808] iteration:10967  t-loss:0.3612, loss-lb:0.2580, loss-ulb:0.0516, weight:2.00, lr:0.0003
[05:37:18.125] iteration:10968  t-loss:0.3112, loss-lb:0.1296, loss-ulb:0.0908, weight:2.00, lr:0.0003
[05:37:18.433] iteration:10969  t-loss:0.7336, loss-lb:0.1561, loss-ulb:0.2888, weight:2.00, lr:0.0003
[05:37:18.752] iteration:10970  t-loss:0.4397, loss-lb:0.2379, loss-ulb:0.1009, weight:2.00, lr:0.0003
[05:37:19.071] iteration:10971  t-loss:0.3425, loss-lb:0.1598, loss-ulb:0.0913, weight:2.00, lr:0.0003
[05:37:19.387] iteration:10972  t-loss:0.2088, loss-lb:0.1514, loss-ulb:0.0287, weight:2.00, lr:0.0003
[05:37:19.705] iteration:10973  t-loss:0.3281, loss-lb:0.1576, loss-ulb:0.0852, weight:2.00, lr:0.0003
[05:37:20.023] iteration:10974  t-loss:0.3244, loss-lb:0.1972, loss-ulb:0.0636, weight:2.00, lr:0.0003
[05:37:20.330] iteration:10975  t-loss:0.5489, loss-lb:0.1821, loss-ulb:0.1834, weight:2.00, lr:0.0003
[05:37:21.676] iteration:10976  t-loss:0.3582, loss-lb:0.1966, loss-ulb:0.0808, weight:2.00, lr:0.0003
[05:37:22.011] iteration:10977  t-loss:0.2722, loss-lb:0.1922, loss-ulb:0.0400, weight:2.00, lr:0.0003
[05:37:22.331] iteration:10978  t-loss:0.4058, loss-lb:0.2412, loss-ulb:0.0823, weight:2.00, lr:0.0003
[05:37:22.653] iteration:10979  t-loss:0.4473, loss-lb:0.2097, loss-ulb:0.1188, weight:2.00, lr:0.0003
[05:37:22.969] iteration:10980  t-loss:0.2327, loss-lb:0.1724, loss-ulb:0.0302, weight:2.00, lr:0.0003
[05:37:23.288] iteration:10981  t-loss:0.2800, loss-lb:0.2378, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:37:23.610] iteration:10982  t-loss:0.2962, loss-lb:0.2184, loss-ulb:0.0389, weight:2.00, lr:0.0003
[05:37:23.930] iteration:10983  t-loss:0.2806, loss-lb:0.1314, loss-ulb:0.0746, weight:2.00, lr:0.0003
[05:37:24.247] iteration:10984  t-loss:0.2005, loss-lb:0.1634, loss-ulb:0.0185, weight:2.00, lr:0.0003
[05:37:24.570] iteration:10985  t-loss:0.2722, loss-lb:0.1282, loss-ulb:0.0720, weight:2.00, lr:0.0003
[05:37:24.887] iteration:10986  t-loss:0.2593, loss-lb:0.2239, loss-ulb:0.0177, weight:2.00, lr:0.0003
[05:37:25.210] iteration:10987  t-loss:0.5291, loss-lb:0.1782, loss-ulb:0.1754, weight:2.00, lr:0.0003
[05:37:25.531] iteration:10988  t-loss:0.3184, loss-lb:0.2133, loss-ulb:0.0526, weight:2.00, lr:0.0003
[05:37:25.849] iteration:10989  t-loss:0.3168, loss-lb:0.2546, loss-ulb:0.0311, weight:2.00, lr:0.0003
[05:37:26.172] iteration:10990  t-loss:0.3382, loss-lb:0.1962, loss-ulb:0.0710, weight:2.00, lr:0.0003
[05:37:26.490] iteration:10991  t-loss:0.2361, loss-lb:0.2105, loss-ulb:0.0128, weight:2.00, lr:0.0003
[05:37:26.809] iteration:10992  t-loss:0.2850, loss-lb:0.1455, loss-ulb:0.0698, weight:2.00, lr:0.0003
[05:37:27.129] iteration:10993  t-loss:0.3812, loss-lb:0.1984, loss-ulb:0.0914, weight:2.00, lr:0.0003
[05:37:27.447] iteration:10994  t-loss:0.2318, loss-lb:0.1473, loss-ulb:0.0422, weight:2.00, lr:0.0003
[05:37:27.767] iteration:10995  t-loss:0.3581, loss-lb:0.1194, loss-ulb:0.1194, weight:2.00, lr:0.0003
[05:37:28.085] iteration:10996  t-loss:0.2310, loss-lb:0.1256, loss-ulb:0.0527, weight:2.00, lr:0.0003
[05:37:28.404] iteration:10997  t-loss:0.2328, loss-lb:0.1414, loss-ulb:0.0457, weight:2.00, lr:0.0003
[05:37:28.726] iteration:10998  t-loss:0.4079, loss-lb:0.2576, loss-ulb:0.0751, weight:2.00, lr:0.0003
[05:37:29.043] iteration:10999  t-loss:0.3318, loss-lb:0.1619, loss-ulb:0.0849, weight:2.00, lr:0.0003
[05:37:29.363] iteration:11000  t-loss:0.5477, loss-lb:0.2434, loss-ulb:0.1522, weight:2.00, lr:0.0003
[05:37:30.733] iteration:11001  t-loss:0.5866, loss-lb:0.3543, loss-ulb:0.1161, weight:2.00, lr:0.0003
[05:37:31.059] iteration:11002  t-loss:0.1561, loss-lb:0.1258, loss-ulb:0.0151, weight:2.00, lr:0.0003
[05:37:31.381] iteration:11003  t-loss:0.2634, loss-lb:0.1942, loss-ulb:0.0346, weight:2.00, lr:0.0003
[05:37:31.699] iteration:11004  t-loss:0.2206, loss-lb:0.1812, loss-ulb:0.0197, weight:2.00, lr:0.0003
[05:37:32.017] iteration:11005  t-loss:0.3133, loss-lb:0.1706, loss-ulb:0.0713, weight:2.00, lr:0.0003
[05:37:32.338] iteration:11006  t-loss:0.3439, loss-lb:0.1527, loss-ulb:0.0956, weight:2.00, lr:0.0003
[05:37:32.656] iteration:11007  t-loss:0.2697, loss-lb:0.1317, loss-ulb:0.0690, weight:2.00, lr:0.0003
[05:37:32.973] iteration:11008  t-loss:0.2212, loss-lb:0.1699, loss-ulb:0.0257, weight:2.00, lr:0.0003
[05:37:33.295] iteration:11009  t-loss:0.3918, loss-lb:0.1415, loss-ulb:0.1251, weight:2.00, lr:0.0003
[05:37:33.617] iteration:11010  t-loss:0.3201, loss-lb:0.1574, loss-ulb:0.0813, weight:2.00, lr:0.0003
[05:37:33.943] iteration:11011  t-loss:0.2759, loss-lb:0.2026, loss-ulb:0.0366, weight:2.00, lr:0.0003
[05:37:34.273] iteration:11012  t-loss:0.2897, loss-lb:0.1571, loss-ulb:0.0663, weight:2.00, lr:0.0003
[05:37:34.609] iteration:11013  t-loss:0.1836, loss-lb:0.1422, loss-ulb:0.0207, weight:2.00, lr:0.0003
[05:37:34.948] iteration:11014  t-loss:0.3446, loss-lb:0.1625, loss-ulb:0.0910, weight:2.00, lr:0.0003
[05:37:35.281] iteration:11015  t-loss:0.2946, loss-lb:0.1696, loss-ulb:0.0625, weight:2.00, lr:0.0003
[05:37:35.601] iteration:11016  t-loss:0.2136, loss-lb:0.1515, loss-ulb:0.0310, weight:2.00, lr:0.0003
[05:37:35.924] iteration:11017  t-loss:0.5601, loss-lb:0.1804, loss-ulb:0.1898, weight:2.00, lr:0.0003
[05:37:36.245] iteration:11018  t-loss:0.3072, loss-lb:0.1333, loss-ulb:0.0870, weight:2.00, lr:0.0003
[05:37:36.571] iteration:11019  t-loss:0.3977, loss-lb:0.2345, loss-ulb:0.0816, weight:2.00, lr:0.0003
[05:37:36.890] iteration:11020  t-loss:0.3434, loss-lb:0.1775, loss-ulb:0.0830, weight:2.00, lr:0.0003
[05:37:37.214] iteration:11021  t-loss:0.3976, loss-lb:0.1992, loss-ulb:0.0992, weight:2.00, lr:0.0003
[05:37:37.539] iteration:11022  t-loss:0.3518, loss-lb:0.2581, loss-ulb:0.0469, weight:2.00, lr:0.0003
[05:37:37.860] iteration:11023  t-loss:0.3438, loss-lb:0.2945, loss-ulb:0.0247, weight:2.00, lr:0.0003
[05:37:38.198] iteration:11024  t-loss:0.2829, loss-lb:0.1213, loss-ulb:0.0808, weight:2.00, lr:0.0003
[05:37:38.532] iteration:11025  t-loss:0.3961, loss-lb:0.1801, loss-ulb:0.1080, weight:2.00, lr:0.0003
[05:39:40.867] iteration 11025 : dice_score: 0.852738 best_dice: 0.852700
[05:39:40.867]  <<Test>> - Ep:440  - Dice-S/T:85.16/85.27, Best-S:85.16, Best-T:85.27
[05:39:40.868]           - AvgLoss(lb/ulb/all):0.18/0.08/0.33
[05:39:42.042] iteration:11026  t-loss:0.2549, loss-lb:0.2248, loss-ulb:0.0150, weight:2.00, lr:0.0003
[05:39:42.377] iteration:11027  t-loss:0.3580, loss-lb:0.1331, loss-ulb:0.1124, weight:2.00, lr:0.0003
[05:39:42.714] iteration:11028  t-loss:0.4775, loss-lb:0.2700, loss-ulb:0.1038, weight:2.00, lr:0.0003
[05:39:43.052] iteration:11029  t-loss:0.3140, loss-lb:0.2355, loss-ulb:0.0393, weight:2.00, lr:0.0003
[05:39:43.381] iteration:11030  t-loss:0.1922, loss-lb:0.1373, loss-ulb:0.0274, weight:2.00, lr:0.0003
[05:39:43.706] iteration:11031  t-loss:0.3250, loss-lb:0.1623, loss-ulb:0.0814, weight:2.00, lr:0.0003
[05:39:44.043] iteration:11032  t-loss:0.2001, loss-lb:0.1700, loss-ulb:0.0151, weight:2.00, lr:0.0003
[05:39:44.370] iteration:11033  t-loss:0.3260, loss-lb:0.1761, loss-ulb:0.0749, weight:2.00, lr:0.0003
[05:39:44.690] iteration:11034  t-loss:0.2888, loss-lb:0.1387, loss-ulb:0.0750, weight:2.00, lr:0.0003
[05:39:45.013] iteration:11035  t-loss:0.3096, loss-lb:0.1418, loss-ulb:0.0839, weight:2.00, lr:0.0003
[05:39:45.331] iteration:11036  t-loss:0.1624, loss-lb:0.1280, loss-ulb:0.0172, weight:2.00, lr:0.0003
[05:39:45.651] iteration:11037  t-loss:0.2126, loss-lb:0.1246, loss-ulb:0.0440, weight:2.00, lr:0.0003
[05:39:45.971] iteration:11038  t-loss:0.2562, loss-lb:0.1826, loss-ulb:0.0368, weight:2.00, lr:0.0003
[05:39:46.288] iteration:11039  t-loss:0.2944, loss-lb:0.1665, loss-ulb:0.0640, weight:2.00, lr:0.0003
[05:39:46.605] iteration:11040  t-loss:0.3628, loss-lb:0.1745, loss-ulb:0.0941, weight:2.00, lr:0.0003
[05:39:46.923] iteration:11041  t-loss:0.2654, loss-lb:0.1598, loss-ulb:0.0528, weight:2.00, lr:0.0003
[05:39:47.244] iteration:11042  t-loss:0.2495, loss-lb:0.1654, loss-ulb:0.0420, weight:2.00, lr:0.0003
[05:39:47.561] iteration:11043  t-loss:0.3152, loss-lb:0.2112, loss-ulb:0.0520, weight:2.00, lr:0.0003
[05:39:47.875] iteration:11044  t-loss:0.1732, loss-lb:0.1327, loss-ulb:0.0202, weight:2.00, lr:0.0003
[05:39:48.190] iteration:11045  t-loss:0.4727, loss-lb:0.2321, loss-ulb:0.1203, weight:2.00, lr:0.0003
[05:39:48.508] iteration:11046  t-loss:0.2494, loss-lb:0.1327, loss-ulb:0.0583, weight:2.00, lr:0.0003
[05:39:48.823] iteration:11047  t-loss:0.3930, loss-lb:0.3302, loss-ulb:0.0314, weight:2.00, lr:0.0003
[05:39:49.138] iteration:11048  t-loss:0.2655, loss-lb:0.1630, loss-ulb:0.0512, weight:2.00, lr:0.0003
[05:39:49.457] iteration:11049  t-loss:0.2571, loss-lb:0.1396, loss-ulb:0.0588, weight:2.00, lr:0.0003
[05:39:49.775] iteration:11050  t-loss:0.2266, loss-lb:0.1328, loss-ulb:0.0469, weight:2.00, lr:0.0003
[05:39:51.009] iteration:11051  t-loss:0.4820, loss-lb:0.2994, loss-ulb:0.0913, weight:2.00, lr:0.0003
[05:39:51.332] iteration:11052  t-loss:0.2023, loss-lb:0.1698, loss-ulb:0.0162, weight:2.00, lr:0.0003
[05:39:51.654] iteration:11053  t-loss:0.2005, loss-lb:0.1218, loss-ulb:0.0393, weight:2.00, lr:0.0003
[05:39:51.975] iteration:11054  t-loss:0.2692, loss-lb:0.1673, loss-ulb:0.0509, weight:2.00, lr:0.0003
[05:39:52.292] iteration:11055  t-loss:0.2972, loss-lb:0.2199, loss-ulb:0.0386, weight:2.00, lr:0.0003
[05:39:52.620] iteration:11056  t-loss:0.1649, loss-lb:0.1357, loss-ulb:0.0146, weight:2.00, lr:0.0003
[05:39:52.939] iteration:11057  t-loss:0.3345, loss-lb:0.1967, loss-ulb:0.0689, weight:2.00, lr:0.0003
[05:39:53.258] iteration:11058  t-loss:0.2753, loss-lb:0.2350, loss-ulb:0.0202, weight:2.00, lr:0.0003
[05:39:53.576] iteration:11059  t-loss:0.2574, loss-lb:0.1511, loss-ulb:0.0531, weight:2.00, lr:0.0003
[05:39:53.897] iteration:11060  t-loss:0.3265, loss-lb:0.1571, loss-ulb:0.0847, weight:2.00, lr:0.0003
[05:39:54.213] iteration:11061  t-loss:0.3742, loss-lb:0.1374, loss-ulb:0.1184, weight:2.00, lr:0.0003
[05:39:54.532] iteration:11062  t-loss:0.2456, loss-lb:0.1664, loss-ulb:0.0396, weight:2.00, lr:0.0003
[05:39:54.849] iteration:11063  t-loss:0.2877, loss-lb:0.1298, loss-ulb:0.0789, weight:2.00, lr:0.0003
[05:39:55.169] iteration:11064  t-loss:0.6194, loss-lb:0.2154, loss-ulb:0.2020, weight:2.00, lr:0.0003
[05:39:55.487] iteration:11065  t-loss:0.2542, loss-lb:0.1666, loss-ulb:0.0438, weight:2.00, lr:0.0003
[05:39:55.808] iteration:11066  t-loss:0.4935, loss-lb:0.2632, loss-ulb:0.1151, weight:2.00, lr:0.0003
[05:39:56.136] iteration:11067  t-loss:0.4344, loss-lb:0.2072, loss-ulb:0.1136, weight:2.00, lr:0.0003
[05:39:56.459] iteration:11068  t-loss:0.3583, loss-lb:0.2245, loss-ulb:0.0669, weight:2.00, lr:0.0003
[05:39:56.785] iteration:11069  t-loss:0.3684, loss-lb:0.1870, loss-ulb:0.0907, weight:2.00, lr:0.0003
[05:39:57.112] iteration:11070  t-loss:0.4938, loss-lb:0.2508, loss-ulb:0.1215, weight:2.00, lr:0.0003
[05:39:57.433] iteration:11071  t-loss:0.3437, loss-lb:0.2556, loss-ulb:0.0441, weight:2.00, lr:0.0003
[05:39:57.760] iteration:11072  t-loss:0.6649, loss-lb:0.2080, loss-ulb:0.2284, weight:2.00, lr:0.0003
[05:39:58.088] iteration:11073  t-loss:0.4181, loss-lb:0.2000, loss-ulb:0.1090, weight:2.00, lr:0.0003
[05:39:58.410] iteration:11074  t-loss:0.2840, loss-lb:0.1653, loss-ulb:0.0593, weight:2.00, lr:0.0003
[05:39:58.734] iteration:11075  t-loss:0.1680, loss-lb:0.1290, loss-ulb:0.0195, weight:2.00, lr:0.0003
[05:40:00.067] iteration:11076  t-loss:0.4749, loss-lb:0.1371, loss-ulb:0.1689, weight:2.00, lr:0.0003
[05:40:00.396] iteration:11077  t-loss:0.2848, loss-lb:0.1210, loss-ulb:0.0819, weight:2.00, lr:0.0003
[05:40:00.716] iteration:11078  t-loss:0.2002, loss-lb:0.1247, loss-ulb:0.0378, weight:2.00, lr:0.0003
[05:40:01.037] iteration:11079  t-loss:0.2627, loss-lb:0.2033, loss-ulb:0.0297, weight:2.00, lr:0.0003
[05:40:01.358] iteration:11080  t-loss:0.1713, loss-lb:0.1251, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:40:01.679] iteration:11081  t-loss:0.2321, loss-lb:0.1902, loss-ulb:0.0209, weight:2.00, lr:0.0003
[05:40:01.998] iteration:11082  t-loss:0.2844, loss-lb:0.1533, loss-ulb:0.0656, weight:2.00, lr:0.0003
[05:40:02.316] iteration:11083  t-loss:0.6463, loss-lb:0.1580, loss-ulb:0.2441, weight:2.00, lr:0.0003
[05:40:02.637] iteration:11084  t-loss:0.2103, loss-lb:0.1793, loss-ulb:0.0155, weight:2.00, lr:0.0003
[05:40:02.957] iteration:11085  t-loss:0.3421, loss-lb:0.1384, loss-ulb:0.1019, weight:2.00, lr:0.0003
[05:40:03.280] iteration:11086  t-loss:0.3676, loss-lb:0.1812, loss-ulb:0.0932, weight:2.00, lr:0.0003
[05:40:03.605] iteration:11087  t-loss:0.3735, loss-lb:0.2008, loss-ulb:0.0863, weight:2.00, lr:0.0003
[05:40:03.928] iteration:11088  t-loss:0.4347, loss-lb:0.2906, loss-ulb:0.0721, weight:2.00, lr:0.0003
[05:40:04.246] iteration:11089  t-loss:0.2908, loss-lb:0.2513, loss-ulb:0.0198, weight:2.00, lr:0.0003
[05:40:04.564] iteration:11090  t-loss:0.3811, loss-lb:0.2784, loss-ulb:0.0513, weight:2.00, lr:0.0003
[05:40:04.884] iteration:11091  t-loss:0.3212, loss-lb:0.2009, loss-ulb:0.0602, weight:2.00, lr:0.0003
[05:40:05.201] iteration:11092  t-loss:0.8410, loss-lb:0.1914, loss-ulb:0.3248, weight:2.00, lr:0.0003
[05:40:05.519] iteration:11093  t-loss:0.3292, loss-lb:0.1870, loss-ulb:0.0711, weight:2.00, lr:0.0003
[05:40:05.835] iteration:11094  t-loss:0.3170, loss-lb:0.2673, loss-ulb:0.0248, weight:2.00, lr:0.0003
[05:40:06.151] iteration:11095  t-loss:0.1596, loss-lb:0.1298, loss-ulb:0.0149, weight:2.00, lr:0.0003
[05:40:06.471] iteration:11096  t-loss:0.3061, loss-lb:0.1911, loss-ulb:0.0575, weight:2.00, lr:0.0003
[05:40:06.797] iteration:11097  t-loss:0.5081, loss-lb:0.4388, loss-ulb:0.0346, weight:2.00, lr:0.0003
[05:40:07.122] iteration:11098  t-loss:0.2902, loss-lb:0.1388, loss-ulb:0.0757, weight:2.00, lr:0.0003
[05:40:07.454] iteration:11099  t-loss:0.2179, loss-lb:0.1824, loss-ulb:0.0177, weight:2.00, lr:0.0003
[05:40:07.781] iteration:11100  t-loss:0.3405, loss-lb:0.2829, loss-ulb:0.0288, weight:2.00, lr:0.0003
[05:40:09.185] iteration:11101  t-loss:0.3549, loss-lb:0.2356, loss-ulb:0.0597, weight:2.00, lr:0.0003
[05:40:09.516] iteration:11102  t-loss:0.3127, loss-lb:0.2768, loss-ulb:0.0179, weight:2.00, lr:0.0003
[05:40:09.843] iteration:11103  t-loss:0.2831, loss-lb:0.1422, loss-ulb:0.0704, weight:2.00, lr:0.0003
[05:40:10.207] iteration:11104  t-loss:0.4792, loss-lb:0.2665, loss-ulb:0.1064, weight:2.00, lr:0.0003
[05:40:10.538] iteration:11105  t-loss:0.3707, loss-lb:0.2053, loss-ulb:0.0827, weight:2.00, lr:0.0003
[05:40:10.879] iteration:11106  t-loss:0.2255, loss-lb:0.1946, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:40:11.204] iteration:11107  t-loss:0.1676, loss-lb:0.1254, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:40:11.536] iteration:11108  t-loss:0.2275, loss-lb:0.1890, loss-ulb:0.0193, weight:2.00, lr:0.0003
[05:40:11.862] iteration:11109  t-loss:0.3043, loss-lb:0.1732, loss-ulb:0.0655, weight:2.00, lr:0.0003
[05:40:12.182] iteration:11110  t-loss:0.3003, loss-lb:0.2609, loss-ulb:0.0197, weight:2.00, lr:0.0003
[05:40:12.512] iteration:11111  t-loss:0.3940, loss-lb:0.2604, loss-ulb:0.0668, weight:2.00, lr:0.0003
[05:40:12.842] iteration:11112  t-loss:0.2563, loss-lb:0.1248, loss-ulb:0.0658, weight:2.00, lr:0.0003
[05:40:13.171] iteration:11113  t-loss:0.5048, loss-lb:0.1327, loss-ulb:0.1861, weight:2.00, lr:0.0003
[05:40:13.506] iteration:11114  t-loss:0.3932, loss-lb:0.2687, loss-ulb:0.0623, weight:2.00, lr:0.0003
[05:40:13.870] iteration:11115  t-loss:0.3596, loss-lb:0.1985, loss-ulb:0.0806, weight:2.00, lr:0.0003
[05:40:14.215] iteration:11116  t-loss:0.2095, loss-lb:0.1620, loss-ulb:0.0238, weight:2.00, lr:0.0003
[05:40:14.543] iteration:11117  t-loss:0.4045, loss-lb:0.2112, loss-ulb:0.0967, weight:2.00, lr:0.0003
[05:40:14.861] iteration:11118  t-loss:0.1923, loss-lb:0.1446, loss-ulb:0.0239, weight:2.00, lr:0.0003
[05:40:15.179] iteration:11119  t-loss:0.2148, loss-lb:0.1686, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:40:15.504] iteration:11120  t-loss:0.1638, loss-lb:0.1310, loss-ulb:0.0164, weight:2.00, lr:0.0003
[05:40:15.832] iteration:11121  t-loss:0.4050, loss-lb:0.1091, loss-ulb:0.1480, weight:2.00, lr:0.0003
[05:40:16.166] iteration:11122  t-loss:0.5799, loss-lb:0.3411, loss-ulb:0.1194, weight:2.00, lr:0.0003
[05:40:16.498] iteration:11123  t-loss:0.2247, loss-lb:0.1801, loss-ulb:0.0223, weight:2.00, lr:0.0003
[05:40:16.839] iteration:11124  t-loss:0.2837, loss-lb:0.1561, loss-ulb:0.0638, weight:2.00, lr:0.0003
[05:40:17.170] iteration:11125  t-loss:0.3413, loss-lb:0.1832, loss-ulb:0.0791, weight:2.00, lr:0.0003
[05:42:19.039] iteration 11125 : dice_score: 0.850820 best_dice: 0.852700
[05:42:19.040]  <<Test>> - Ep:444  - Dice-S/T:84.02/85.08, Best-S:85.16, Best-T:85.27
[05:42:19.040]           - AvgLoss(lb/ulb/all):0.19/0.06/0.31
[05:42:20.768] iteration:11126  t-loss:0.3137, loss-lb:0.1532, loss-ulb:0.0803, weight:2.00, lr:0.0003
[05:42:21.129] iteration:11127  t-loss:0.3201, loss-lb:0.2175, loss-ulb:0.0513, weight:2.00, lr:0.0003
[05:42:21.476] iteration:11128  t-loss:0.6720, loss-lb:0.2451, loss-ulb:0.2135, weight:2.00, lr:0.0003
[05:42:21.808] iteration:11129  t-loss:0.4231, loss-lb:0.2051, loss-ulb:0.1090, weight:2.00, lr:0.0003
[05:42:22.139] iteration:11130  t-loss:0.1881, loss-lb:0.1546, loss-ulb:0.0168, weight:2.00, lr:0.0003
[05:42:22.472] iteration:11131  t-loss:0.4905, loss-lb:0.2774, loss-ulb:0.1065, weight:2.00, lr:0.0003
[05:42:22.801] iteration:11132  t-loss:0.3729, loss-lb:0.2295, loss-ulb:0.0717, weight:2.00, lr:0.0003
[05:42:23.122] iteration:11133  t-loss:0.2705, loss-lb:0.1526, loss-ulb:0.0589, weight:2.00, lr:0.0003
[05:42:23.438] iteration:11134  t-loss:0.2274, loss-lb:0.1939, loss-ulb:0.0168, weight:2.00, lr:0.0003
[05:42:23.758] iteration:11135  t-loss:0.2832, loss-lb:0.1405, loss-ulb:0.0714, weight:2.00, lr:0.0003
[05:42:24.073] iteration:11136  t-loss:0.2314, loss-lb:0.1603, loss-ulb:0.0356, weight:2.00, lr:0.0003
[05:42:24.392] iteration:11137  t-loss:0.3711, loss-lb:0.2193, loss-ulb:0.0759, weight:2.00, lr:0.0003
[05:42:24.709] iteration:11138  t-loss:0.2475, loss-lb:0.1938, loss-ulb:0.0268, weight:2.00, lr:0.0003
[05:42:25.028] iteration:11139  t-loss:0.5370, loss-lb:0.1652, loss-ulb:0.1859, weight:2.00, lr:0.0003
[05:42:25.349] iteration:11140  t-loss:0.3660, loss-lb:0.1387, loss-ulb:0.1137, weight:2.00, lr:0.0003
[05:42:25.666] iteration:11141  t-loss:0.3980, loss-lb:0.2221, loss-ulb:0.0879, weight:2.00, lr:0.0003
[05:42:25.981] iteration:11142  t-loss:0.4021, loss-lb:0.2492, loss-ulb:0.0765, weight:2.00, lr:0.0003
[05:42:26.298] iteration:11143  t-loss:0.2892, loss-lb:0.2057, loss-ulb:0.0417, weight:2.00, lr:0.0003
[05:42:26.617] iteration:11144  t-loss:0.3969, loss-lb:0.2657, loss-ulb:0.0656, weight:2.00, lr:0.0003
[05:42:26.932] iteration:11145  t-loss:0.3392, loss-lb:0.1828, loss-ulb:0.0782, weight:2.00, lr:0.0003
[05:42:27.250] iteration:11146  t-loss:0.4371, loss-lb:0.2833, loss-ulb:0.0769, weight:2.00, lr:0.0003
[05:42:27.568] iteration:11147  t-loss:0.3725, loss-lb:0.2740, loss-ulb:0.0493, weight:2.00, lr:0.0003
[05:42:27.883] iteration:11148  t-loss:0.1728, loss-lb:0.1270, loss-ulb:0.0229, weight:2.00, lr:0.0003
[05:42:28.197] iteration:11149  t-loss:0.3336, loss-lb:0.1958, loss-ulb:0.0689, weight:2.00, lr:0.0003
[05:42:28.516] iteration:11150  t-loss:0.2095, loss-lb:0.1827, loss-ulb:0.0134, weight:2.00, lr:0.0003
[05:42:29.949] iteration:11151  t-loss:0.3208, loss-lb:0.1137, loss-ulb:0.1036, weight:2.00, lr:0.0003
[05:42:30.278] iteration:11152  t-loss:0.2413, loss-lb:0.2089, loss-ulb:0.0162, weight:2.00, lr:0.0003
[05:42:30.598] iteration:11153  t-loss:0.1949, loss-lb:0.1626, loss-ulb:0.0161, weight:2.00, lr:0.0003
[05:42:30.916] iteration:11154  t-loss:0.2854, loss-lb:0.2477, loss-ulb:0.0189, weight:2.00, lr:0.0003
[05:42:31.235] iteration:11155  t-loss:0.4105, loss-lb:0.2063, loss-ulb:0.1021, weight:2.00, lr:0.0003
[05:42:31.551] iteration:11156  t-loss:0.3325, loss-lb:0.1178, loss-ulb:0.1073, weight:2.00, lr:0.0003
[05:42:31.870] iteration:11157  t-loss:0.1872, loss-lb:0.1435, loss-ulb:0.0219, weight:2.00, lr:0.0003
[05:42:32.189] iteration:11158  t-loss:0.2751, loss-lb:0.1849, loss-ulb:0.0451, weight:2.00, lr:0.0003
[05:42:32.506] iteration:11159  t-loss:0.4538, loss-lb:0.1577, loss-ulb:0.1481, weight:2.00, lr:0.0003
[05:42:32.824] iteration:11160  t-loss:0.3497, loss-lb:0.2959, loss-ulb:0.0269, weight:2.00, lr:0.0003
[05:42:33.139] iteration:11161  t-loss:0.2037, loss-lb:0.1682, loss-ulb:0.0178, weight:2.00, lr:0.0003
[05:42:33.459] iteration:11162  t-loss:0.2705, loss-lb:0.2350, loss-ulb:0.0178, weight:2.00, lr:0.0003
[05:42:33.776] iteration:11163  t-loss:0.2888, loss-lb:0.1489, loss-ulb:0.0699, weight:2.00, lr:0.0003
[05:42:34.093] iteration:11164  t-loss:0.5773, loss-lb:0.1658, loss-ulb:0.2057, weight:2.00, lr:0.0003
[05:42:34.417] iteration:11165  t-loss:0.4303, loss-lb:0.1975, loss-ulb:0.1164, weight:2.00, lr:0.0003
[05:42:34.742] iteration:11166  t-loss:0.3171, loss-lb:0.2102, loss-ulb:0.0535, weight:2.00, lr:0.0003
[05:42:35.061] iteration:11167  t-loss:0.2755, loss-lb:0.1704, loss-ulb:0.0525, weight:2.00, lr:0.0003
[05:42:35.379] iteration:11168  t-loss:0.3218, loss-lb:0.1396, loss-ulb:0.0911, weight:2.00, lr:0.0003
[05:42:35.698] iteration:11169  t-loss:0.4469, loss-lb:0.2651, loss-ulb:0.0909, weight:2.00, lr:0.0003
[05:42:36.015] iteration:11170  t-loss:0.2497, loss-lb:0.1540, loss-ulb:0.0478, weight:2.00, lr:0.0003
[05:42:36.330] iteration:11171  t-loss:0.1944, loss-lb:0.1483, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:42:36.646] iteration:11172  t-loss:0.4520, loss-lb:0.1430, loss-ulb:0.1545, weight:2.00, lr:0.0003
[05:42:36.962] iteration:11173  t-loss:0.3471, loss-lb:0.2073, loss-ulb:0.0699, weight:2.00, lr:0.0003
[05:42:37.283] iteration:11174  t-loss:0.3136, loss-lb:0.1906, loss-ulb:0.0615, weight:2.00, lr:0.0003
[05:42:37.600] iteration:11175  t-loss:0.5108, loss-lb:0.1601, loss-ulb:0.1753, weight:2.00, lr:0.0003
[05:42:38.897] iteration:11176  t-loss:0.4374, loss-lb:0.2647, loss-ulb:0.0864, weight:2.00, lr:0.0003
[05:42:39.233] iteration:11177  t-loss:0.4465, loss-lb:0.2305, loss-ulb:0.1080, weight:2.00, lr:0.0003
[05:42:39.554] iteration:11178  t-loss:0.2143, loss-lb:0.1569, loss-ulb:0.0287, weight:2.00, lr:0.0003
[05:42:39.872] iteration:11179  t-loss:0.3050, loss-lb:0.1616, loss-ulb:0.0717, weight:2.00, lr:0.0003
[05:42:40.196] iteration:11180  t-loss:0.3468, loss-lb:0.1980, loss-ulb:0.0744, weight:2.00, lr:0.0003
[05:42:40.516] iteration:11181  t-loss:0.3261, loss-lb:0.1610, loss-ulb:0.0825, weight:2.00, lr:0.0003
[05:42:40.838] iteration:11182  t-loss:0.7197, loss-lb:0.2869, loss-ulb:0.2164, weight:2.00, lr:0.0003
[05:42:41.156] iteration:11183  t-loss:0.2985, loss-lb:0.1614, loss-ulb:0.0685, weight:2.00, lr:0.0003
[05:42:41.481] iteration:11184  t-loss:0.4679, loss-lb:0.3236, loss-ulb:0.0722, weight:2.00, lr:0.0003
[05:42:41.799] iteration:11185  t-loss:0.3321, loss-lb:0.1317, loss-ulb:0.1002, weight:2.00, lr:0.0003
[05:42:42.123] iteration:11186  t-loss:0.3007, loss-lb:0.2408, loss-ulb:0.0299, weight:2.00, lr:0.0003
[05:42:42.447] iteration:11187  t-loss:0.2990, loss-lb:0.1906, loss-ulb:0.0542, weight:2.00, lr:0.0003
[05:42:42.765] iteration:11188  t-loss:0.2358, loss-lb:0.1961, loss-ulb:0.0198, weight:2.00, lr:0.0003
[05:42:43.085] iteration:11189  t-loss:0.1916, loss-lb:0.1575, loss-ulb:0.0170, weight:2.00, lr:0.0003
[05:42:43.403] iteration:11190  t-loss:0.2312, loss-lb:0.1809, loss-ulb:0.0251, weight:2.00, lr:0.0003
[05:42:43.727] iteration:11191  t-loss:0.3727, loss-lb:0.2388, loss-ulb:0.0670, weight:2.00, lr:0.0003
[05:42:44.052] iteration:11192  t-loss:0.4123, loss-lb:0.3074, loss-ulb:0.0525, weight:2.00, lr:0.0003
[05:42:44.368] iteration:11193  t-loss:0.2893, loss-lb:0.1172, loss-ulb:0.0861, weight:2.00, lr:0.0003
[05:42:44.691] iteration:11194  t-loss:0.4123, loss-lb:0.1909, loss-ulb:0.1107, weight:2.00, lr:0.0003
[05:42:45.011] iteration:11195  t-loss:0.2824, loss-lb:0.1559, loss-ulb:0.0633, weight:2.00, lr:0.0003
[05:42:45.327] iteration:11196  t-loss:0.4334, loss-lb:0.1856, loss-ulb:0.1239, weight:2.00, lr:0.0003
[05:42:45.644] iteration:11197  t-loss:0.2762, loss-lb:0.2332, loss-ulb:0.0215, weight:2.00, lr:0.0003
[05:42:45.961] iteration:11198  t-loss:0.2182, loss-lb:0.1681, loss-ulb:0.0250, weight:2.00, lr:0.0003
[05:42:46.280] iteration:11199  t-loss:0.3151, loss-lb:0.2273, loss-ulb:0.0439, weight:2.00, lr:0.0003
[05:42:46.596] iteration:11200  t-loss:0.1935, loss-lb:0.1398, loss-ulb:0.0269, weight:2.00, lr:0.0003
[05:42:47.885] iteration:11201  t-loss:0.2153, loss-lb:0.1852, loss-ulb:0.0151, weight:2.00, lr:0.0003
[05:42:48.217] iteration:11202  t-loss:0.4780, loss-lb:0.1916, loss-ulb:0.1432, weight:2.00, lr:0.0003
[05:42:48.537] iteration:11203  t-loss:0.5132, loss-lb:0.2251, loss-ulb:0.1441, weight:2.00, lr:0.0003
[05:42:48.852] iteration:11204  t-loss:0.1849, loss-lb:0.1595, loss-ulb:0.0127, weight:2.00, lr:0.0003
[05:42:49.170] iteration:11205  t-loss:0.2055, loss-lb:0.1593, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:42:49.503] iteration:11206  t-loss:0.3306, loss-lb:0.1928, loss-ulb:0.0689, weight:2.00, lr:0.0003
[05:42:49.830] iteration:11207  t-loss:0.2894, loss-lb:0.1609, loss-ulb:0.0643, weight:2.00, lr:0.0003
[05:42:50.165] iteration:11208  t-loss:0.3626, loss-lb:0.2852, loss-ulb:0.0387, weight:2.00, lr:0.0003
[05:42:50.493] iteration:11209  t-loss:0.2003, loss-lb:0.1731, loss-ulb:0.0136, weight:2.00, lr:0.0003
[05:42:50.820] iteration:11210  t-loss:0.4597, loss-lb:0.2090, loss-ulb:0.1254, weight:2.00, lr:0.0003
[05:42:51.152] iteration:11211  t-loss:0.2588, loss-lb:0.1570, loss-ulb:0.0509, weight:2.00, lr:0.0003
[05:42:51.473] iteration:11212  t-loss:0.4156, loss-lb:0.1663, loss-ulb:0.1247, weight:2.00, lr:0.0003
[05:42:51.790] iteration:11213  t-loss:0.2424, loss-lb:0.1953, loss-ulb:0.0235, weight:2.00, lr:0.0003
[05:42:52.111] iteration:11214  t-loss:0.2260, loss-lb:0.1325, loss-ulb:0.0468, weight:2.00, lr:0.0003
[05:42:52.429] iteration:11215  t-loss:0.2421, loss-lb:0.1952, loss-ulb:0.0235, weight:2.00, lr:0.0003
[05:42:52.754] iteration:11216  t-loss:0.3557, loss-lb:0.2238, loss-ulb:0.0659, weight:2.00, lr:0.0003
[05:42:53.072] iteration:11217  t-loss:0.3129, loss-lb:0.1532, loss-ulb:0.0799, weight:2.00, lr:0.0003
[05:42:53.397] iteration:11218  t-loss:0.3034, loss-lb:0.1464, loss-ulb:0.0785, weight:2.00, lr:0.0003
[05:42:53.716] iteration:11219  t-loss:0.3936, loss-lb:0.2630, loss-ulb:0.0653, weight:2.00, lr:0.0003
[05:42:54.038] iteration:11220  t-loss:0.2402, loss-lb:0.1402, loss-ulb:0.0500, weight:2.00, lr:0.0003
[05:42:54.355] iteration:11221  t-loss:0.4534, loss-lb:0.2491, loss-ulb:0.1022, weight:2.00, lr:0.0003
[05:42:54.674] iteration:11222  t-loss:0.3559, loss-lb:0.2718, loss-ulb:0.0421, weight:2.00, lr:0.0003
[05:42:54.999] iteration:11223  t-loss:0.4359, loss-lb:0.1366, loss-ulb:0.1497, weight:2.00, lr:0.0003
[05:42:55.316] iteration:11224  t-loss:0.1897, loss-lb:0.1335, loss-ulb:0.0281, weight:2.00, lr:0.0003
[05:42:55.631] iteration:11225  t-loss:0.3172, loss-lb:0.1720, loss-ulb:0.0726, weight:2.00, lr:0.0003
[05:45:09.619] iteration 11225 : dice_score: 0.851525 best_dice: 0.852700
[05:45:09.619]  <<Test>> - Ep:448  - Dice-S/T:84.50/85.15, Best-S:85.16, Best-T:85.27
[05:45:09.619]           - AvgLoss(lb/ulb/all):0.19/0.07/0.32
[05:45:10.841] iteration:11226  t-loss:0.2403, loss-lb:0.2062, loss-ulb:0.0171, weight:2.00, lr:0.0003
[05:45:11.161] iteration:11227  t-loss:0.1791, loss-lb:0.1451, loss-ulb:0.0170, weight:2.00, lr:0.0003
[05:45:11.488] iteration:11228  t-loss:0.2209, loss-lb:0.1777, loss-ulb:0.0216, weight:2.00, lr:0.0003
[05:45:11.815] iteration:11229  t-loss:0.3113, loss-lb:0.1999, loss-ulb:0.0557, weight:2.00, lr:0.0003
[05:45:12.150] iteration:11230  t-loss:0.2521, loss-lb:0.2214, loss-ulb:0.0153, weight:2.00, lr:0.0003
[05:45:12.487] iteration:11231  t-loss:0.2537, loss-lb:0.2170, loss-ulb:0.0184, weight:2.00, lr:0.0003
[05:45:12.808] iteration:11232  t-loss:0.3618, loss-lb:0.1820, loss-ulb:0.0899, weight:2.00, lr:0.0003
[05:45:13.136] iteration:11233  t-loss:0.2065, loss-lb:0.1711, loss-ulb:0.0177, weight:2.00, lr:0.0003
[05:45:13.463] iteration:11234  t-loss:0.2694, loss-lb:0.2200, loss-ulb:0.0247, weight:2.00, lr:0.0003
[05:45:13.784] iteration:11235  t-loss:0.1699, loss-lb:0.1453, loss-ulb:0.0123, weight:2.00, lr:0.0003
[05:45:14.107] iteration:11236  t-loss:0.4083, loss-lb:0.1417, loss-ulb:0.1333, weight:2.00, lr:0.0003
[05:45:14.426] iteration:11237  t-loss:0.4664, loss-lb:0.1651, loss-ulb:0.1506, weight:2.00, lr:0.0003
[05:45:14.747] iteration:11238  t-loss:0.4665, loss-lb:0.2063, loss-ulb:0.1301, weight:2.00, lr:0.0003
[05:45:15.068] iteration:11239  t-loss:0.2266, loss-lb:0.1946, loss-ulb:0.0160, weight:2.00, lr:0.0003
[05:45:15.387] iteration:11240  t-loss:0.3745, loss-lb:0.2356, loss-ulb:0.0694, weight:2.00, lr:0.0003
[05:45:15.712] iteration:11241  t-loss:0.4151, loss-lb:0.1969, loss-ulb:0.1091, weight:2.00, lr:0.0003
[05:45:16.029] iteration:11242  t-loss:0.2042, loss-lb:0.1500, loss-ulb:0.0271, weight:2.00, lr:0.0003
[05:45:16.343] iteration:11243  t-loss:0.1787, loss-lb:0.1440, loss-ulb:0.0173, weight:2.00, lr:0.0003
[05:45:16.660] iteration:11244  t-loss:0.2943, loss-lb:0.2654, loss-ulb:0.0144, weight:2.00, lr:0.0003
[05:45:16.976] iteration:11245  t-loss:0.4034, loss-lb:0.1973, loss-ulb:0.1030, weight:2.00, lr:0.0003
[05:45:17.293] iteration:11246  t-loss:0.2697, loss-lb:0.1508, loss-ulb:0.0594, weight:2.00, lr:0.0003
[05:45:17.612] iteration:11247  t-loss:0.2692, loss-lb:0.1254, loss-ulb:0.0719, weight:2.00, lr:0.0003
[05:45:17.932] iteration:11248  t-loss:0.3210, loss-lb:0.1673, loss-ulb:0.0768, weight:2.00, lr:0.0003
[05:45:18.251] iteration:11249  t-loss:0.3359, loss-lb:0.2220, loss-ulb:0.0570, weight:2.00, lr:0.0003
[05:45:18.570] iteration:11250  t-loss:0.3750, loss-lb:0.2140, loss-ulb:0.0805, weight:2.00, lr:0.0003
[05:45:20.011] iteration:11251  t-loss:0.4167, loss-lb:0.1823, loss-ulb:0.1172, weight:2.00, lr:0.0003
[05:45:20.340] iteration:11252  t-loss:0.2724, loss-lb:0.1289, loss-ulb:0.0718, weight:2.00, lr:0.0003
[05:45:20.667] iteration:11253  t-loss:0.4541, loss-lb:0.2758, loss-ulb:0.0892, weight:2.00, lr:0.0003
[05:45:20.990] iteration:11254  t-loss:0.3469, loss-lb:0.2029, loss-ulb:0.0720, weight:2.00, lr:0.0003
[05:45:21.309] iteration:11255  t-loss:0.3259, loss-lb:0.1550, loss-ulb:0.0855, weight:2.00, lr:0.0003
[05:45:21.628] iteration:11256  t-loss:0.4702, loss-lb:0.1894, loss-ulb:0.1404, weight:2.00, lr:0.0003
[05:45:21.946] iteration:11257  t-loss:0.2937, loss-lb:0.2125, loss-ulb:0.0406, weight:2.00, lr:0.0003
[05:45:22.266] iteration:11258  t-loss:0.4092, loss-lb:0.2271, loss-ulb:0.0911, weight:2.00, lr:0.0003
[05:45:22.586] iteration:11259  t-loss:0.4880, loss-lb:0.2260, loss-ulb:0.1310, weight:2.00, lr:0.0003
[05:45:22.907] iteration:11260  t-loss:0.2927, loss-lb:0.2543, loss-ulb:0.0192, weight:2.00, lr:0.0003
[05:45:23.228] iteration:11261  t-loss:0.4823, loss-lb:0.2206, loss-ulb:0.1309, weight:2.00, lr:0.0003
[05:45:23.551] iteration:11262  t-loss:0.3848, loss-lb:0.2150, loss-ulb:0.0849, weight:2.00, lr:0.0003
[05:45:23.869] iteration:11263  t-loss:0.2001, loss-lb:0.1578, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:45:24.188] iteration:11264  t-loss:0.6273, loss-lb:0.1567, loss-ulb:0.2353, weight:2.00, lr:0.0003
[05:45:24.510] iteration:11265  t-loss:0.3854, loss-lb:0.2612, loss-ulb:0.0621, weight:2.00, lr:0.0003
[05:45:24.825] iteration:11266  t-loss:0.2444, loss-lb:0.1379, loss-ulb:0.0532, weight:2.00, lr:0.0003
[05:45:25.146] iteration:11267  t-loss:0.2975, loss-lb:0.2030, loss-ulb:0.0473, weight:2.00, lr:0.0003
[05:45:25.468] iteration:11268  t-loss:0.2707, loss-lb:0.2245, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:45:25.792] iteration:11269  t-loss:0.7212, loss-lb:0.2162, loss-ulb:0.2525, weight:2.00, lr:0.0003
[05:45:26.130] iteration:11270  t-loss:0.2423, loss-lb:0.1751, loss-ulb:0.0336, weight:2.00, lr:0.0003
[05:45:26.462] iteration:11271  t-loss:0.2407, loss-lb:0.1445, loss-ulb:0.0481, weight:2.00, lr:0.0003
[05:45:26.793] iteration:11272  t-loss:0.4695, loss-lb:0.1688, loss-ulb:0.1503, weight:2.00, lr:0.0003
[05:45:27.119] iteration:11273  t-loss:0.2665, loss-lb:0.2046, loss-ulb:0.0309, weight:2.00, lr:0.0003
[05:45:27.443] iteration:11274  t-loss:0.4244, loss-lb:0.1786, loss-ulb:0.1229, weight:2.00, lr:0.0003
[05:45:27.763] iteration:11275  t-loss:0.2453, loss-lb:0.1569, loss-ulb:0.0442, weight:2.00, lr:0.0003
[05:45:29.107] iteration:11276  t-loss:0.3021, loss-lb:0.1748, loss-ulb:0.0637, weight:2.00, lr:0.0003
[05:45:29.446] iteration:11277  t-loss:0.2046, loss-lb:0.1733, loss-ulb:0.0157, weight:2.00, lr:0.0003
[05:45:29.795] iteration:11278  t-loss:0.4048, loss-lb:0.2013, loss-ulb:0.1018, weight:2.00, lr:0.0003
[05:45:30.135] iteration:11279  t-loss:0.3114, loss-lb:0.1472, loss-ulb:0.0821, weight:2.00, lr:0.0003
[05:45:30.467] iteration:11280  t-loss:0.2430, loss-lb:0.2116, loss-ulb:0.0157, weight:2.00, lr:0.0003
[05:45:30.799] iteration:11281  t-loss:0.2282, loss-lb:0.1227, loss-ulb:0.0527, weight:2.00, lr:0.0003
[05:45:31.122] iteration:11282  t-loss:0.4645, loss-lb:0.2075, loss-ulb:0.1285, weight:2.00, lr:0.0003
[05:45:31.453] iteration:11283  t-loss:0.2805, loss-lb:0.2370, loss-ulb:0.0217, weight:2.00, lr:0.0003
[05:45:31.792] iteration:11284  t-loss:0.4792, loss-lb:0.2447, loss-ulb:0.1172, weight:2.00, lr:0.0003
[05:45:32.109] iteration:11285  t-loss:0.1770, loss-lb:0.1394, loss-ulb:0.0188, weight:2.00, lr:0.0003
[05:45:32.425] iteration:11286  t-loss:0.3158, loss-lb:0.1693, loss-ulb:0.0732, weight:2.00, lr:0.0003
[05:45:32.739] iteration:11287  t-loss:0.1608, loss-lb:0.1028, loss-ulb:0.0290, weight:2.00, lr:0.0003
[05:45:33.057] iteration:11288  t-loss:0.2775, loss-lb:0.1165, loss-ulb:0.0805, weight:2.00, lr:0.0003
[05:45:33.372] iteration:11289  t-loss:0.3107, loss-lb:0.1821, loss-ulb:0.0643, weight:2.00, lr:0.0003
[05:45:33.687] iteration:11290  t-loss:0.3511, loss-lb:0.1480, loss-ulb:0.1016, weight:2.00, lr:0.0003
[05:45:34.003] iteration:11291  t-loss:0.3054, loss-lb:0.1758, loss-ulb:0.0648, weight:2.00, lr:0.0003
[05:45:34.327] iteration:11292  t-loss:0.3448, loss-lb:0.2160, loss-ulb:0.0644, weight:2.00, lr:0.0003
[05:45:34.650] iteration:11293  t-loss:0.2986, loss-lb:0.1441, loss-ulb:0.0773, weight:2.00, lr:0.0003
[05:45:34.975] iteration:11294  t-loss:0.5585, loss-lb:0.2900, loss-ulb:0.1342, weight:2.00, lr:0.0003
[05:45:35.291] iteration:11295  t-loss:0.1649, loss-lb:0.1134, loss-ulb:0.0257, weight:2.00, lr:0.0003
[05:45:35.609] iteration:11296  t-loss:0.2205, loss-lb:0.1784, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:45:35.924] iteration:11297  t-loss:0.2909, loss-lb:0.1362, loss-ulb:0.0773, weight:2.00, lr:0.0003
[05:45:36.244] iteration:11298  t-loss:0.3847, loss-lb:0.2518, loss-ulb:0.0664, weight:2.00, lr:0.0003
[05:45:36.559] iteration:11299  t-loss:0.2301, loss-lb:0.1708, loss-ulb:0.0297, weight:2.00, lr:0.0003
[05:45:36.875] iteration:11300  t-loss:0.3960, loss-lb:0.2962, loss-ulb:0.0499, weight:2.00, lr:0.0003
[05:45:38.234] iteration:11301  t-loss:0.2947, loss-lb:0.1516, loss-ulb:0.0715, weight:2.00, lr:0.0003
[05:45:38.572] iteration:11302  t-loss:0.3744, loss-lb:0.1669, loss-ulb:0.1038, weight:2.00, lr:0.0003
[05:45:38.926] iteration:11303  t-loss:0.3255, loss-lb:0.1886, loss-ulb:0.0685, weight:2.00, lr:0.0003
[05:45:39.265] iteration:11304  t-loss:0.2431, loss-lb:0.1339, loss-ulb:0.0546, weight:2.00, lr:0.0003
[05:45:39.601] iteration:11305  t-loss:0.3514, loss-lb:0.2684, loss-ulb:0.0415, weight:2.00, lr:0.0003
[05:45:39.941] iteration:11306  t-loss:0.1904, loss-lb:0.1547, loss-ulb:0.0178, weight:2.00, lr:0.0003
[05:45:40.270] iteration:11307  t-loss:0.3310, loss-lb:0.1170, loss-ulb:0.1070, weight:2.00, lr:0.0003
[05:45:40.610] iteration:11308  t-loss:0.4512, loss-lb:0.3281, loss-ulb:0.0616, weight:2.00, lr:0.0003
[05:45:40.945] iteration:11309  t-loss:0.3748, loss-lb:0.2386, loss-ulb:0.0681, weight:2.00, lr:0.0003
[05:45:41.262] iteration:11310  t-loss:0.2325, loss-lb:0.1496, loss-ulb:0.0414, weight:2.00, lr:0.0003
[05:45:41.585] iteration:11311  t-loss:0.1738, loss-lb:0.1414, loss-ulb:0.0162, weight:2.00, lr:0.0003
[05:45:41.895] iteration:11312  t-loss:1.0037, loss-lb:0.3373, loss-ulb:0.3332, weight:2.00, lr:0.0003
[05:45:42.225] iteration:11313  t-loss:0.2923, loss-lb:0.2068, loss-ulb:0.0428, weight:2.00, lr:0.0003
[05:45:42.543] iteration:11314  t-loss:0.1993, loss-lb:0.1406, loss-ulb:0.0293, weight:2.00, lr:0.0003
[05:45:42.869] iteration:11315  t-loss:0.3245, loss-lb:0.2682, loss-ulb:0.0282, weight:2.00, lr:0.0003
[05:45:43.201] iteration:11316  t-loss:0.2447, loss-lb:0.1409, loss-ulb:0.0519, weight:2.00, lr:0.0003
[05:45:43.536] iteration:11317  t-loss:0.4775, loss-lb:0.1622, loss-ulb:0.1577, weight:2.00, lr:0.0003
[05:45:43.863] iteration:11318  t-loss:0.2297, loss-lb:0.1706, loss-ulb:0.0296, weight:2.00, lr:0.0003
[05:45:44.183] iteration:11319  t-loss:0.1887, loss-lb:0.1594, loss-ulb:0.0147, weight:2.00, lr:0.0003
[05:45:44.500] iteration:11320  t-loss:0.2557, loss-lb:0.2191, loss-ulb:0.0183, weight:2.00, lr:0.0003
[05:45:44.820] iteration:11321  t-loss:0.5099, loss-lb:0.1596, loss-ulb:0.1751, weight:2.00, lr:0.0003
[05:45:45.137] iteration:11322  t-loss:0.2035, loss-lb:0.1673, loss-ulb:0.0181, weight:2.00, lr:0.0003
[05:45:45.455] iteration:11323  t-loss:0.3481, loss-lb:0.2105, loss-ulb:0.0688, weight:2.00, lr:0.0003
[05:45:45.771] iteration:11324  t-loss:0.6865, loss-lb:0.1886, loss-ulb:0.2489, weight:2.00, lr:0.0003
[05:45:46.088] iteration:11325  t-loss:0.2644, loss-lb:0.2138, loss-ulb:0.0253, weight:2.00, lr:0.0003
[05:47:59.712] iteration 11325 : dice_score: 0.850670 best_dice: 0.852700
[05:47:59.712]  <<Test>> - Ep:452  - Dice-S/T:84.45/85.07, Best-S:85.16, Best-T:85.27
[05:47:59.712]           - AvgLoss(lb/ulb/all):0.19/0.08/0.35
[05:48:00.794] iteration:11326  t-loss:0.3909, loss-lb:0.1532, loss-ulb:0.1189, weight:2.00, lr:0.0003
[05:48:01.120] iteration:11327  t-loss:0.2276, loss-lb:0.1639, loss-ulb:0.0319, weight:2.00, lr:0.0003
[05:48:01.444] iteration:11328  t-loss:0.2671, loss-lb:0.1673, loss-ulb:0.0499, weight:2.00, lr:0.0003
[05:48:01.772] iteration:11329  t-loss:0.2719, loss-lb:0.2175, loss-ulb:0.0272, weight:2.00, lr:0.0003
[05:48:02.094] iteration:11330  t-loss:0.2580, loss-lb:0.2240, loss-ulb:0.0170, weight:2.00, lr:0.0003
[05:48:02.412] iteration:11331  t-loss:0.2339, loss-lb:0.1363, loss-ulb:0.0488, weight:2.00, lr:0.0003
[05:48:02.737] iteration:11332  t-loss:0.3467, loss-lb:0.1645, loss-ulb:0.0911, weight:2.00, lr:0.0003
[05:48:03.060] iteration:11333  t-loss:0.2372, loss-lb:0.2065, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:48:03.382] iteration:11334  t-loss:0.6295, loss-lb:0.4372, loss-ulb:0.0962, weight:2.00, lr:0.0003
[05:48:03.704] iteration:11335  t-loss:0.3106, loss-lb:0.1592, loss-ulb:0.0757, weight:2.00, lr:0.0003
[05:48:04.020] iteration:11336  t-loss:0.3136, loss-lb:0.2065, loss-ulb:0.0536, weight:2.00, lr:0.0003
[05:48:04.342] iteration:11337  t-loss:0.3331, loss-lb:0.1746, loss-ulb:0.0793, weight:2.00, lr:0.0003
[05:48:04.666] iteration:11338  t-loss:0.4207, loss-lb:0.1547, loss-ulb:0.1330, weight:2.00, lr:0.0003
[05:48:04.987] iteration:11339  t-loss:0.2923, loss-lb:0.1719, loss-ulb:0.0602, weight:2.00, lr:0.0003
[05:48:05.310] iteration:11340  t-loss:0.3004, loss-lb:0.1594, loss-ulb:0.0705, weight:2.00, lr:0.0003
[05:48:05.632] iteration:11341  t-loss:0.2514, loss-lb:0.1497, loss-ulb:0.0508, weight:2.00, lr:0.0003
[05:48:05.955] iteration:11342  t-loss:0.4772, loss-lb:0.2032, loss-ulb:0.1370, weight:2.00, lr:0.0003
[05:48:06.275] iteration:11343  t-loss:0.2929, loss-lb:0.1408, loss-ulb:0.0760, weight:2.00, lr:0.0003
[05:48:06.589] iteration:11344  t-loss:0.2176, loss-lb:0.1895, loss-ulb:0.0141, weight:2.00, lr:0.0003
[05:48:06.905] iteration:11345  t-loss:0.1817, loss-lb:0.1468, loss-ulb:0.0174, weight:2.00, lr:0.0003
[05:48:07.225] iteration:11346  t-loss:0.3612, loss-lb:0.2074, loss-ulb:0.0769, weight:2.00, lr:0.0003
[05:48:07.545] iteration:11347  t-loss:0.4723, loss-lb:0.3001, loss-ulb:0.0861, weight:2.00, lr:0.0003
[05:48:07.863] iteration:11348  t-loss:0.3697, loss-lb:0.2149, loss-ulb:0.0774, weight:2.00, lr:0.0003
[05:48:08.178] iteration:11349  t-loss:0.2290, loss-lb:0.1789, loss-ulb:0.0250, weight:2.00, lr:0.0003
[05:48:08.495] iteration:11350  t-loss:0.3669, loss-lb:0.3136, loss-ulb:0.0266, weight:2.00, lr:0.0003
[05:48:09.674] iteration:11351  t-loss:0.2745, loss-lb:0.2449, loss-ulb:0.0148, weight:2.00, lr:0.0003
[05:48:10.009] iteration:11352  t-loss:0.2707, loss-lb:0.1502, loss-ulb:0.0603, weight:2.00, lr:0.0003
[05:48:10.334] iteration:11353  t-loss:0.3655, loss-lb:0.1638, loss-ulb:0.1008, weight:2.00, lr:0.0003
[05:48:10.650] iteration:11354  t-loss:0.1946, loss-lb:0.1645, loss-ulb:0.0150, weight:2.00, lr:0.0003
[05:48:10.975] iteration:11355  t-loss:0.2245, loss-lb:0.1355, loss-ulb:0.0445, weight:2.00, lr:0.0003
[05:48:11.308] iteration:11356  t-loss:0.2692, loss-lb:0.2175, loss-ulb:0.0259, weight:2.00, lr:0.0003
[05:48:11.644] iteration:11357  t-loss:0.1789, loss-lb:0.1500, loss-ulb:0.0145, weight:2.00, lr:0.0003
[05:48:11.974] iteration:11358  t-loss:0.4643, loss-lb:0.3493, loss-ulb:0.0575, weight:2.00, lr:0.0003
[05:48:12.305] iteration:11359  t-loss:0.2510, loss-lb:0.1925, loss-ulb:0.0293, weight:2.00, lr:0.0003
[05:48:12.635] iteration:11360  t-loss:0.3320, loss-lb:0.1391, loss-ulb:0.0965, weight:2.00, lr:0.0003
[05:48:12.954] iteration:11361  t-loss:0.2357, loss-lb:0.1492, loss-ulb:0.0432, weight:2.00, lr:0.0003
[05:48:13.272] iteration:11362  t-loss:0.2390, loss-lb:0.1346, loss-ulb:0.0522, weight:2.00, lr:0.0003
[05:48:13.605] iteration:11363  t-loss:0.3121, loss-lb:0.1375, loss-ulb:0.0873, weight:2.00, lr:0.0003
[05:48:13.925] iteration:11364  t-loss:0.1942, loss-lb:0.1583, loss-ulb:0.0179, weight:2.00, lr:0.0003
[05:48:14.245] iteration:11365  t-loss:0.1474, loss-lb:0.1217, loss-ulb:0.0129, weight:2.00, lr:0.0003
[05:48:14.574] iteration:11366  t-loss:0.3408, loss-lb:0.2045, loss-ulb:0.0681, weight:2.00, lr:0.0003
[05:48:14.898] iteration:11367  t-loss:1.1378, loss-lb:0.1630, loss-ulb:0.4874, weight:2.00, lr:0.0003
[05:48:15.216] iteration:11368  t-loss:0.5070, loss-lb:0.2053, loss-ulb:0.1509, weight:2.00, lr:0.0003
[05:48:15.536] iteration:11369  t-loss:0.4091, loss-lb:0.2106, loss-ulb:0.0992, weight:2.00, lr:0.0003
[05:48:15.855] iteration:11370  t-loss:0.3410, loss-lb:0.1401, loss-ulb:0.1004, weight:2.00, lr:0.0003
[05:48:16.174] iteration:11371  t-loss:0.3897, loss-lb:0.2721, loss-ulb:0.0588, weight:2.00, lr:0.0003
[05:48:16.493] iteration:11372  t-loss:0.5624, loss-lb:0.3244, loss-ulb:0.1190, weight:2.00, lr:0.0003
[05:48:16.818] iteration:11373  t-loss:0.3867, loss-lb:0.1963, loss-ulb:0.0952, weight:2.00, lr:0.0003
[05:48:17.140] iteration:11374  t-loss:0.4111, loss-lb:0.2142, loss-ulb:0.0984, weight:2.00, lr:0.0003
[05:48:17.455] iteration:11375  t-loss:0.2617, loss-lb:0.1858, loss-ulb:0.0380, weight:2.00, lr:0.0003
[05:48:18.619] iteration:11376  t-loss:0.2166, loss-lb:0.1779, loss-ulb:0.0194, weight:2.00, lr:0.0003
[05:48:18.945] iteration:11377  t-loss:0.3217, loss-lb:0.2022, loss-ulb:0.0597, weight:2.00, lr:0.0003
[05:48:19.267] iteration:11378  t-loss:0.4835, loss-lb:0.1703, loss-ulb:0.1566, weight:2.00, lr:0.0003
[05:48:19.589] iteration:11379  t-loss:0.3474, loss-lb:0.2123, loss-ulb:0.0676, weight:2.00, lr:0.0003
[05:48:19.917] iteration:11380  t-loss:0.3934, loss-lb:0.3263, loss-ulb:0.0335, weight:2.00, lr:0.0003
[05:48:20.248] iteration:11381  t-loss:0.2217, loss-lb:0.1496, loss-ulb:0.0360, weight:2.00, lr:0.0003
[05:48:20.576] iteration:11382  t-loss:0.4435, loss-lb:0.1650, loss-ulb:0.1392, weight:2.00, lr:0.0003
[05:48:20.899] iteration:11383  t-loss:0.1733, loss-lb:0.1226, loss-ulb:0.0254, weight:2.00, lr:0.0003
[05:48:21.240] iteration:11384  t-loss:0.2962, loss-lb:0.1633, loss-ulb:0.0665, weight:2.00, lr:0.0003
[05:48:21.572] iteration:11385  t-loss:0.2998, loss-lb:0.2104, loss-ulb:0.0447, weight:2.00, lr:0.0003
[05:48:21.896] iteration:11386  t-loss:0.3339, loss-lb:0.1705, loss-ulb:0.0817, weight:2.00, lr:0.0003
[05:48:22.217] iteration:11387  t-loss:0.3142, loss-lb:0.1313, loss-ulb:0.0915, weight:2.00, lr:0.0003
[05:48:22.545] iteration:11388  t-loss:0.3476, loss-lb:0.1951, loss-ulb:0.0762, weight:2.00, lr:0.0003
[05:48:22.867] iteration:11389  t-loss:0.5262, loss-lb:0.3043, loss-ulb:0.1110, weight:2.00, lr:0.0003
[05:48:23.186] iteration:11390  t-loss:0.1540, loss-lb:0.1153, loss-ulb:0.0194, weight:2.00, lr:0.0003
[05:48:23.508] iteration:11391  t-loss:0.1495, loss-lb:0.1177, loss-ulb:0.0159, weight:2.00, lr:0.0003
[05:48:23.829] iteration:11392  t-loss:0.1868, loss-lb:0.1481, loss-ulb:0.0193, weight:2.00, lr:0.0003
[05:48:24.151] iteration:11393  t-loss:0.2813, loss-lb:0.2271, loss-ulb:0.0271, weight:2.00, lr:0.0003
[05:48:24.470] iteration:11394  t-loss:0.4428, loss-lb:0.1221, loss-ulb:0.1604, weight:2.00, lr:0.0003
[05:48:24.788] iteration:11395  t-loss:0.3474, loss-lb:0.2395, loss-ulb:0.0540, weight:2.00, lr:0.0003
[05:48:25.104] iteration:11396  t-loss:0.2573, loss-lb:0.1121, loss-ulb:0.0726, weight:2.00, lr:0.0003
[05:48:25.424] iteration:11397  t-loss:0.2945, loss-lb:0.2275, loss-ulb:0.0335, weight:2.00, lr:0.0003
[05:48:25.739] iteration:11398  t-loss:0.2246, loss-lb:0.1698, loss-ulb:0.0274, weight:2.00, lr:0.0003
[05:48:26.054] iteration:11399  t-loss:0.5163, loss-lb:0.2266, loss-ulb:0.1448, weight:2.00, lr:0.0003
[05:48:26.369] iteration:11400  t-loss:0.2035, loss-lb:0.1614, loss-ulb:0.0211, weight:2.00, lr:0.0003
[05:48:27.580] iteration:11401  t-loss:0.2029, loss-lb:0.1594, loss-ulb:0.0218, weight:2.00, lr:0.0003
[05:48:27.906] iteration:11402  t-loss:0.2839, loss-lb:0.1651, loss-ulb:0.0594, weight:2.00, lr:0.0003
[05:48:28.236] iteration:11403  t-loss:0.3373, loss-lb:0.3112, loss-ulb:0.0131, weight:2.00, lr:0.0003
[05:48:28.571] iteration:11404  t-loss:0.2431, loss-lb:0.1903, loss-ulb:0.0264, weight:2.00, lr:0.0003
[05:48:28.911] iteration:11405  t-loss:1.0030, loss-lb:0.4510, loss-ulb:0.2760, weight:2.00, lr:0.0003
[05:48:29.256] iteration:11406  t-loss:0.2559, loss-lb:0.2064, loss-ulb:0.0248, weight:2.00, lr:0.0003
[05:48:29.608] iteration:11407  t-loss:0.3122, loss-lb:0.1435, loss-ulb:0.0844, weight:2.00, lr:0.0003
[05:48:29.961] iteration:11408  t-loss:0.3256, loss-lb:0.2163, loss-ulb:0.0546, weight:2.00, lr:0.0003
[05:48:30.293] iteration:11409  t-loss:0.1833, loss-lb:0.1431, loss-ulb:0.0201, weight:2.00, lr:0.0003
[05:48:30.624] iteration:11410  t-loss:0.4865, loss-lb:0.3021, loss-ulb:0.0922, weight:2.00, lr:0.0003
[05:48:30.947] iteration:11411  t-loss:0.2391, loss-lb:0.1398, loss-ulb:0.0497, weight:2.00, lr:0.0003
[05:48:31.275] iteration:11412  t-loss:0.3689, loss-lb:0.2035, loss-ulb:0.0827, weight:2.00, lr:0.0003
[05:48:31.604] iteration:11413  t-loss:0.8329, loss-lb:0.1648, loss-ulb:0.3340, weight:2.00, lr:0.0003
[05:48:31.929] iteration:11414  t-loss:0.3777, loss-lb:0.2203, loss-ulb:0.0787, weight:2.00, lr:0.0003
[05:48:32.250] iteration:11415  t-loss:0.1800, loss-lb:0.1160, loss-ulb:0.0320, weight:2.00, lr:0.0003
[05:48:32.571] iteration:11416  t-loss:0.3632, loss-lb:0.2241, loss-ulb:0.0696, weight:2.00, lr:0.0003
[05:48:32.896] iteration:11417  t-loss:0.3014, loss-lb:0.1366, loss-ulb:0.0824, weight:2.00, lr:0.0003
[05:48:33.220] iteration:11418  t-loss:0.3193, loss-lb:0.1735, loss-ulb:0.0729, weight:2.00, lr:0.0003
[05:48:33.542] iteration:11419  t-loss:0.2120, loss-lb:0.1522, loss-ulb:0.0299, weight:2.00, lr:0.0003
[05:48:33.862] iteration:11420  t-loss:0.1877, loss-lb:0.1389, loss-ulb:0.0244, weight:2.00, lr:0.0003
[05:48:34.178] iteration:11421  t-loss:0.4539, loss-lb:0.3073, loss-ulb:0.0733, weight:2.00, lr:0.0003
[05:48:34.499] iteration:11422  t-loss:0.7143, loss-lb:0.2998, loss-ulb:0.2073, weight:2.00, lr:0.0003
[05:48:34.822] iteration:11423  t-loss:0.5413, loss-lb:0.2931, loss-ulb:0.1241, weight:2.00, lr:0.0003
[05:48:35.138] iteration:11424  t-loss:0.3156, loss-lb:0.2539, loss-ulb:0.0309, weight:2.00, lr:0.0003
[05:48:35.454] iteration:11425  t-loss:0.2619, loss-lb:0.2256, loss-ulb:0.0181, weight:2.00, lr:0.0003
[05:50:53.348] iteration 11425 : dice_score: 0.849581 best_dice: 0.852700
[05:50:53.348]  <<Test>> - Ep:456  - Dice-S/T:84.83/84.96, Best-S:85.16, Best-T:85.27
[05:50:53.349]           - AvgLoss(lb/ulb/all):0.21/0.08/0.36
[05:50:54.574] iteration:11426  t-loss:0.1919, loss-lb:0.1534, loss-ulb:0.0193, weight:2.00, lr:0.0003
[05:50:54.905] iteration:11427  t-loss:0.2155, loss-lb:0.1685, loss-ulb:0.0235, weight:2.00, lr:0.0003
[05:50:55.227] iteration:11428  t-loss:0.3001, loss-lb:0.1813, loss-ulb:0.0594, weight:2.00, lr:0.0003
[05:50:55.551] iteration:11429  t-loss:0.4484, loss-lb:0.1847, loss-ulb:0.1319, weight:2.00, lr:0.0003
[05:50:55.877] iteration:11430  t-loss:0.3027, loss-lb:0.1750, loss-ulb:0.0639, weight:2.00, lr:0.0003
[05:50:56.200] iteration:11431  t-loss:0.4298, loss-lb:0.2976, loss-ulb:0.0661, weight:2.00, lr:0.0003
[05:50:56.524] iteration:11432  t-loss:0.5306, loss-lb:0.1676, loss-ulb:0.1815, weight:2.00, lr:0.0003
[05:50:56.851] iteration:11433  t-loss:0.4232, loss-lb:0.1737, loss-ulb:0.1247, weight:2.00, lr:0.0003
[05:50:57.170] iteration:11434  t-loss:0.1693, loss-lb:0.1316, loss-ulb:0.0189, weight:2.00, lr:0.0003
[05:50:57.500] iteration:11435  t-loss:0.4218, loss-lb:0.2441, loss-ulb:0.0888, weight:2.00, lr:0.0003
[05:50:57.825] iteration:11436  t-loss:0.1705, loss-lb:0.1348, loss-ulb:0.0178, weight:2.00, lr:0.0003
[05:50:58.148] iteration:11437  t-loss:0.2534, loss-lb:0.2021, loss-ulb:0.0257, weight:2.00, lr:0.0003
[05:50:58.470] iteration:11438  t-loss:0.2631, loss-lb:0.2055, loss-ulb:0.0288, weight:2.00, lr:0.0003
[05:50:58.790] iteration:11439  t-loss:0.2212, loss-lb:0.1788, loss-ulb:0.0212, weight:2.00, lr:0.0003
[05:50:59.107] iteration:11440  t-loss:0.3713, loss-lb:0.1467, loss-ulb:0.1123, weight:2.00, lr:0.0003
[05:50:59.427] iteration:11441  t-loss:0.2926, loss-lb:0.2317, loss-ulb:0.0304, weight:2.00, lr:0.0003
[05:50:59.754] iteration:11442  t-loss:0.4244, loss-lb:0.2271, loss-ulb:0.0987, weight:2.00, lr:0.0003
[05:51:00.070] iteration:11443  t-loss:0.1772, loss-lb:0.1397, loss-ulb:0.0188, weight:2.00, lr:0.0003
[05:51:00.387] iteration:11444  t-loss:0.2617, loss-lb:0.2236, loss-ulb:0.0191, weight:2.00, lr:0.0003
[05:51:00.709] iteration:11445  t-loss:0.2833, loss-lb:0.2100, loss-ulb:0.0366, weight:2.00, lr:0.0003
[05:51:01.023] iteration:11446  t-loss:0.4223, loss-lb:0.1331, loss-ulb:0.1446, weight:2.00, lr:0.0003
[05:51:01.342] iteration:11447  t-loss:0.1832, loss-lb:0.1566, loss-ulb:0.0133, weight:2.00, lr:0.0003
[05:51:01.662] iteration:11448  t-loss:0.3599, loss-lb:0.2161, loss-ulb:0.0719, weight:2.00, lr:0.0003
[05:51:01.984] iteration:11449  t-loss:0.1993, loss-lb:0.1626, loss-ulb:0.0184, weight:2.00, lr:0.0003
[05:51:02.312] iteration:11450  t-loss:0.3754, loss-lb:0.2685, loss-ulb:0.0534, weight:2.00, lr:0.0003
[05:51:04.161] iteration:11451  t-loss:0.3583, loss-lb:0.2322, loss-ulb:0.0630, weight:2.00, lr:0.0003
[05:51:04.504] iteration:11452  t-loss:0.3720, loss-lb:0.2104, loss-ulb:0.0808, weight:2.00, lr:0.0003
[05:51:04.900] iteration:11453  t-loss:0.4967, loss-lb:0.2799, loss-ulb:0.1084, weight:2.00, lr:0.0003
[05:51:05.280] iteration:11454  t-loss:0.2273, loss-lb:0.1270, loss-ulb:0.0502, weight:2.00, lr:0.0003
[05:51:05.618] iteration:11455  t-loss:0.3051, loss-lb:0.1662, loss-ulb:0.0694, weight:2.00, lr:0.0003
[05:51:05.952] iteration:11456  t-loss:0.4070, loss-lb:0.1877, loss-ulb:0.1097, weight:2.00, lr:0.0003
[05:51:06.285] iteration:11457  t-loss:0.1775, loss-lb:0.1408, loss-ulb:0.0184, weight:2.00, lr:0.0003
[05:51:06.617] iteration:11458  t-loss:0.2897, loss-lb:0.2272, loss-ulb:0.0313, weight:2.00, lr:0.0003
[05:51:06.944] iteration:11459  t-loss:0.2578, loss-lb:0.1485, loss-ulb:0.0546, weight:2.00, lr:0.0003
[05:51:07.260] iteration:11460  t-loss:0.1914, loss-lb:0.1502, loss-ulb:0.0206, weight:2.00, lr:0.0003
[05:51:07.574] iteration:11461  t-loss:0.5282, loss-lb:0.1393, loss-ulb:0.1944, weight:2.00, lr:0.0003
[05:51:07.890] iteration:11462  t-loss:0.1835, loss-lb:0.1427, loss-ulb:0.0204, weight:2.00, lr:0.0003
[05:51:08.205] iteration:11463  t-loss:0.2424, loss-lb:0.1945, loss-ulb:0.0239, weight:2.00, lr:0.0003
[05:51:08.521] iteration:11464  t-loss:0.4085, loss-lb:0.1742, loss-ulb:0.1171, weight:2.00, lr:0.0003
[05:51:08.846] iteration:11465  t-loss:0.2527, loss-lb:0.2119, loss-ulb:0.0204, weight:2.00, lr:0.0003
[05:51:09.181] iteration:11466  t-loss:0.3301, loss-lb:0.2961, loss-ulb:0.0170, weight:2.00, lr:0.0003
[05:51:09.522] iteration:11467  t-loss:0.3583, loss-lb:0.2054, loss-ulb:0.0765, weight:2.00, lr:0.0003
[05:51:09.851] iteration:11468  t-loss:0.3572, loss-lb:0.1166, loss-ulb:0.1203, weight:2.00, lr:0.0003
[05:51:10.172] iteration:11469  t-loss:0.3252, loss-lb:0.1798, loss-ulb:0.0727, weight:2.00, lr:0.0003
[05:51:10.491] iteration:11470  t-loss:0.4047, loss-lb:0.2203, loss-ulb:0.0922, weight:2.00, lr:0.0003
[05:51:10.805] iteration:11471  t-loss:0.1645, loss-lb:0.1356, loss-ulb:0.0145, weight:2.00, lr:0.0003
[05:51:11.121] iteration:11472  t-loss:0.3421, loss-lb:0.2039, loss-ulb:0.0691, weight:2.00, lr:0.0003
[05:51:11.440] iteration:11473  t-loss:0.2171, loss-lb:0.1463, loss-ulb:0.0354, weight:2.00, lr:0.0003
[05:51:11.777] iteration:11474  t-loss:0.4690, loss-lb:0.1971, loss-ulb:0.1359, weight:2.00, lr:0.0003
[05:51:12.109] iteration:11475  t-loss:0.5312, loss-lb:0.3428, loss-ulb:0.0942, weight:2.00, lr:0.0003
[05:51:13.956] iteration:11476  t-loss:0.2858, loss-lb:0.2301, loss-ulb:0.0279, weight:2.00, lr:0.0003
[05:51:14.295] iteration:11477  t-loss:0.1747, loss-lb:0.1481, loss-ulb:0.0133, weight:2.00, lr:0.0003
[05:51:14.638] iteration:11478  t-loss:0.1366, loss-lb:0.1075, loss-ulb:0.0146, weight:2.00, lr:0.0003
[05:51:14.998] iteration:11479  t-loss:0.2464, loss-lb:0.2028, loss-ulb:0.0218, weight:2.00, lr:0.0003
[05:51:15.338] iteration:11480  t-loss:0.2957, loss-lb:0.1549, loss-ulb:0.0704, weight:2.00, lr:0.0003
[05:51:15.670] iteration:11481  t-loss:0.2599, loss-lb:0.1486, loss-ulb:0.0556, weight:2.00, lr:0.0003
[05:51:16.005] iteration:11482  t-loss:0.4198, loss-lb:0.1451, loss-ulb:0.1373, weight:2.00, lr:0.0003
[05:51:16.331] iteration:11483  t-loss:0.2455, loss-lb:0.2142, loss-ulb:0.0157, weight:2.00, lr:0.0003
[05:51:16.657] iteration:11484  t-loss:0.3508, loss-lb:0.1656, loss-ulb:0.0926, weight:2.00, lr:0.0003
[05:51:16.976] iteration:11485  t-loss:0.2943, loss-lb:0.1834, loss-ulb:0.0554, weight:2.00, lr:0.0003
[05:51:17.292] iteration:11486  t-loss:0.2219, loss-lb:0.1898, loss-ulb:0.0160, weight:2.00, lr:0.0003
[05:51:17.614] iteration:11487  t-loss:0.1853, loss-lb:0.1355, loss-ulb:0.0249, weight:2.00, lr:0.0003
[05:51:17.947] iteration:11488  t-loss:0.5192, loss-lb:0.1784, loss-ulb:0.1704, weight:2.00, lr:0.0003
[05:51:18.268] iteration:11489  t-loss:0.2264, loss-lb:0.1370, loss-ulb:0.0447, weight:2.00, lr:0.0003
[05:51:18.592] iteration:11490  t-loss:0.1747, loss-lb:0.1475, loss-ulb:0.0136, weight:2.00, lr:0.0003
[05:51:18.915] iteration:11491  t-loss:0.2832, loss-lb:0.2144, loss-ulb:0.0344, weight:2.00, lr:0.0003
[05:51:19.241] iteration:11492  t-loss:0.3991, loss-lb:0.2018, loss-ulb:0.0987, weight:2.00, lr:0.0003
[05:51:19.561] iteration:11493  t-loss:0.2922, loss-lb:0.1352, loss-ulb:0.0785, weight:2.00, lr:0.0003
[05:51:19.875] iteration:11494  t-loss:0.3243, loss-lb:0.1360, loss-ulb:0.0942, weight:2.00, lr:0.0003
[05:51:20.193] iteration:11495  t-loss:0.4064, loss-lb:0.2408, loss-ulb:0.0828, weight:2.00, lr:0.0003
[05:51:20.518] iteration:11496  t-loss:0.3488, loss-lb:0.2763, loss-ulb:0.0362, weight:2.00, lr:0.0003
[05:51:20.832] iteration:11497  t-loss:0.3800, loss-lb:0.1472, loss-ulb:0.1164, weight:2.00, lr:0.0003
[05:51:21.152] iteration:11498  t-loss:0.2061, loss-lb:0.1118, loss-ulb:0.0471, weight:2.00, lr:0.0003
[05:51:21.473] iteration:11499  t-loss:0.3249, loss-lb:0.1726, loss-ulb:0.0762, weight:2.00, lr:0.0003
[05:51:21.792] iteration:11500  t-loss:0.2794, loss-lb:0.1299, loss-ulb:0.0748, weight:2.00, lr:0.0003
[05:51:23.275] iteration:11501  t-loss:0.1758, loss-lb:0.1317, loss-ulb:0.0221, weight:2.00, lr:0.0003
[05:51:23.613] iteration:11502  t-loss:0.4379, loss-lb:0.2108, loss-ulb:0.1136, weight:2.00, lr:0.0003
[05:51:23.934] iteration:11503  t-loss:0.1374, loss-lb:0.1058, loss-ulb:0.0158, weight:2.00, lr:0.0003
[05:51:24.258] iteration:11504  t-loss:0.3321, loss-lb:0.2139, loss-ulb:0.0591, weight:2.00, lr:0.0003
[05:51:24.576] iteration:11505  t-loss:0.5006, loss-lb:0.1603, loss-ulb:0.1701, weight:2.00, lr:0.0003
[05:51:24.891] iteration:11506  t-loss:0.4028, loss-lb:0.1635, loss-ulb:0.1197, weight:2.00, lr:0.0003
[05:51:25.205] iteration:11507  t-loss:0.1972, loss-lb:0.1650, loss-ulb:0.0161, weight:2.00, lr:0.0003
[05:51:25.533] iteration:11508  t-loss:0.1812, loss-lb:0.1520, loss-ulb:0.0146, weight:2.00, lr:0.0003
[05:51:25.859] iteration:11509  t-loss:0.4372, loss-lb:0.1150, loss-ulb:0.1611, weight:2.00, lr:0.0003
[05:51:26.187] iteration:11510  t-loss:0.2130, loss-lb:0.1447, loss-ulb:0.0341, weight:2.00, lr:0.0003
[05:51:26.516] iteration:11511  t-loss:0.2060, loss-lb:0.1381, loss-ulb:0.0339, weight:2.00, lr:0.0003
[05:51:26.862] iteration:11512  t-loss:0.3070, loss-lb:0.2749, loss-ulb:0.0160, weight:2.00, lr:0.0003
[05:51:27.196] iteration:11513  t-loss:0.3248, loss-lb:0.2626, loss-ulb:0.0311, weight:2.00, lr:0.0003
[05:51:27.533] iteration:11514  t-loss:0.2685, loss-lb:0.1504, loss-ulb:0.0591, weight:2.00, lr:0.0003
[05:51:27.872] iteration:11515  t-loss:0.3679, loss-lb:0.2016, loss-ulb:0.0831, weight:2.00, lr:0.0003
[05:51:28.203] iteration:11516  t-loss:0.3020, loss-lb:0.1642, loss-ulb:0.0689, weight:2.00, lr:0.0003
[05:51:28.532] iteration:11517  t-loss:0.4491, loss-lb:0.1763, loss-ulb:0.1364, weight:2.00, lr:0.0003
[05:51:28.857] iteration:11518  t-loss:0.3695, loss-lb:0.1784, loss-ulb:0.0955, weight:2.00, lr:0.0003
[05:51:29.175] iteration:11519  t-loss:0.4074, loss-lb:0.3104, loss-ulb:0.0485, weight:2.00, lr:0.0003
[05:51:29.493] iteration:11520  t-loss:0.2209, loss-lb:0.1940, loss-ulb:0.0134, weight:2.00, lr:0.0003
[05:51:29.812] iteration:11521  t-loss:0.3782, loss-lb:0.1403, loss-ulb:0.1189, weight:2.00, lr:0.0003
[05:51:30.134] iteration:11522  t-loss:0.2557, loss-lb:0.1678, loss-ulb:0.0440, weight:2.00, lr:0.0003
[05:51:30.451] iteration:11523  t-loss:0.2916, loss-lb:0.1888, loss-ulb:0.0514, weight:2.00, lr:0.0003
[05:51:30.770] iteration:11524  t-loss:0.2013, loss-lb:0.1593, loss-ulb:0.0210, weight:2.00, lr:0.0003
[05:51:31.088] iteration:11525  t-loss:0.3067, loss-lb:0.1635, loss-ulb:0.0716, weight:2.00, lr:0.0003
[05:53:47.513] iteration 11525 : dice_score: 0.846993 best_dice: 0.852700
[05:53:47.513]  <<Test>> - Ep:460  - Dice-S/T:84.70/84.70, Best-S:85.16, Best-T:85.27
[05:53:47.513]           - AvgLoss(lb/ulb/all):0.18/0.06/0.30
[05:53:48.663] iteration:11526  t-loss:0.3679, loss-lb:0.2436, loss-ulb:0.0621, weight:2.00, lr:0.0003
[05:53:48.993] iteration:11527  t-loss:0.2646, loss-lb:0.1928, loss-ulb:0.0359, weight:2.00, lr:0.0003
[05:53:49.327] iteration:11528  t-loss:0.3706, loss-lb:0.1338, loss-ulb:0.1184, weight:2.00, lr:0.0003
[05:53:49.649] iteration:11529  t-loss:0.2698, loss-lb:0.2319, loss-ulb:0.0190, weight:2.00, lr:0.0003
[05:53:49.968] iteration:11530  t-loss:0.2529, loss-lb:0.2186, loss-ulb:0.0171, weight:2.00, lr:0.0003
[05:53:50.305] iteration:11531  t-loss:0.3698, loss-lb:0.2629, loss-ulb:0.0535, weight:2.00, lr:0.0003
[05:53:50.621] iteration:11532  t-loss:0.5756, loss-lb:0.1443, loss-ulb:0.2157, weight:2.00, lr:0.0003
[05:53:50.953] iteration:11533  t-loss:0.2987, loss-lb:0.2449, loss-ulb:0.0269, weight:2.00, lr:0.0003
[05:53:51.272] iteration:11534  t-loss:0.5129, loss-lb:0.1973, loss-ulb:0.1578, weight:2.00, lr:0.0003
[05:53:51.588] iteration:11535  t-loss:0.5597, loss-lb:0.1413, loss-ulb:0.2092, weight:2.00, lr:0.0003
[05:53:51.908] iteration:11536  t-loss:0.2294, loss-lb:0.1453, loss-ulb:0.0420, weight:2.00, lr:0.0003
[05:53:52.228] iteration:11537  t-loss:0.2215, loss-lb:0.1842, loss-ulb:0.0186, weight:2.00, lr:0.0003
[05:53:52.548] iteration:11538  t-loss:0.2960, loss-lb:0.1491, loss-ulb:0.0735, weight:2.00, lr:0.0003
[05:53:52.867] iteration:11539  t-loss:0.2885, loss-lb:0.1162, loss-ulb:0.0861, weight:2.00, lr:0.0003
[05:53:53.187] iteration:11540  t-loss:0.2808, loss-lb:0.1493, loss-ulb:0.0658, weight:2.00, lr:0.0003
[05:53:53.502] iteration:11541  t-loss:0.2144, loss-lb:0.1704, loss-ulb:0.0220, weight:2.00, lr:0.0003
[05:53:53.820] iteration:11542  t-loss:0.2599, loss-lb:0.1287, loss-ulb:0.0656, weight:2.00, lr:0.0003
[05:53:54.135] iteration:11543  t-loss:0.1906, loss-lb:0.1315, loss-ulb:0.0296, weight:2.00, lr:0.0003
[05:53:54.454] iteration:11544  t-loss:0.3538, loss-lb:0.1727, loss-ulb:0.0906, weight:2.00, lr:0.0003
[05:53:54.768] iteration:11545  t-loss:0.2761, loss-lb:0.2425, loss-ulb:0.0168, weight:2.00, lr:0.0003
[05:53:55.082] iteration:11546  t-loss:0.1921, loss-lb:0.1506, loss-ulb:0.0207, weight:2.00, lr:0.0003
[05:53:55.398] iteration:11547  t-loss:0.3710, loss-lb:0.1950, loss-ulb:0.0880, weight:2.00, lr:0.0003
[05:53:55.715] iteration:11548  t-loss:0.2759, loss-lb:0.1791, loss-ulb:0.0484, weight:2.00, lr:0.0003
[05:53:56.030] iteration:11549  t-loss:0.3402, loss-lb:0.2960, loss-ulb:0.0221, weight:2.00, lr:0.0003
[05:53:56.346] iteration:11550  t-loss:0.3380, loss-lb:0.1789, loss-ulb:0.0795, weight:2.00, lr:0.0003
[05:53:57.694] iteration:11551  t-loss:0.3261, loss-lb:0.1994, loss-ulb:0.0633, weight:2.00, lr:0.0003
[05:53:58.018] iteration:11552  t-loss:0.1615, loss-lb:0.1283, loss-ulb:0.0166, weight:2.00, lr:0.0003
[05:53:58.341] iteration:11553  t-loss:0.3008, loss-lb:0.1359, loss-ulb:0.0824, weight:2.00, lr:0.0003
[05:53:58.664] iteration:11554  t-loss:0.4970, loss-lb:0.2605, loss-ulb:0.1183, weight:2.00, lr:0.0003
[05:53:58.993] iteration:11555  t-loss:0.2205, loss-lb:0.1966, loss-ulb:0.0119, weight:2.00, lr:0.0003
[05:53:59.324] iteration:11556  t-loss:0.3945, loss-lb:0.2293, loss-ulb:0.0826, weight:2.00, lr:0.0003
[05:53:59.658] iteration:11557  t-loss:0.3990, loss-lb:0.2990, loss-ulb:0.0500, weight:2.00, lr:0.0003
[05:53:59.977] iteration:11558  t-loss:0.1598, loss-lb:0.1294, loss-ulb:0.0152, weight:2.00, lr:0.0003
[05:54:00.300] iteration:11559  t-loss:0.2760, loss-lb:0.1755, loss-ulb:0.0503, weight:2.00, lr:0.0003
[05:54:00.624] iteration:11560  t-loss:0.3879, loss-lb:0.1484, loss-ulb:0.1198, weight:2.00, lr:0.0003
[05:54:00.952] iteration:11561  t-loss:0.3458, loss-lb:0.3079, loss-ulb:0.0189, weight:2.00, lr:0.0003
[05:54:01.290] iteration:11562  t-loss:0.2775, loss-lb:0.1163, loss-ulb:0.0806, weight:2.00, lr:0.0003
[05:54:01.627] iteration:11563  t-loss:0.3143, loss-lb:0.1664, loss-ulb:0.0740, weight:2.00, lr:0.0003
[05:54:01.963] iteration:11564  t-loss:0.2617, loss-lb:0.1890, loss-ulb:0.0363, weight:2.00, lr:0.0003
[05:54:02.297] iteration:11565  t-loss:0.2229, loss-lb:0.1662, loss-ulb:0.0284, weight:2.00, lr:0.0003
[05:54:02.632] iteration:11566  t-loss:0.3035, loss-lb:0.1825, loss-ulb:0.0605, weight:2.00, lr:0.0003
[05:54:02.963] iteration:11567  t-loss:0.3103, loss-lb:0.2655, loss-ulb:0.0224, weight:2.00, lr:0.0003
[05:54:03.286] iteration:11568  t-loss:0.1894, loss-lb:0.1504, loss-ulb:0.0195, weight:2.00, lr:0.0003
[05:54:03.602] iteration:11569  t-loss:0.1905, loss-lb:0.1367, loss-ulb:0.0269, weight:2.00, lr:0.0003
[05:54:03.922] iteration:11570  t-loss:0.3180, loss-lb:0.2658, loss-ulb:0.0261, weight:2.00, lr:0.0003
[05:54:04.238] iteration:11571  t-loss:0.5440, loss-lb:0.2377, loss-ulb:0.1531, weight:2.00, lr:0.0003
[05:54:04.557] iteration:11572  t-loss:0.2986, loss-lb:0.1735, loss-ulb:0.0626, weight:2.00, lr:0.0003
[05:54:04.879] iteration:11573  t-loss:0.4141, loss-lb:0.2330, loss-ulb:0.0905, weight:2.00, lr:0.0003
[05:54:05.194] iteration:11574  t-loss:0.3941, loss-lb:0.2190, loss-ulb:0.0875, weight:2.00, lr:0.0003
[05:54:05.507] iteration:11575  t-loss:0.2786, loss-lb:0.1655, loss-ulb:0.0565, weight:2.00, lr:0.0003
[05:54:06.976] iteration:11576  t-loss:0.2721, loss-lb:0.1501, loss-ulb:0.0610, weight:2.00, lr:0.0003
[05:54:07.311] iteration:11577  t-loss:0.2722, loss-lb:0.2401, loss-ulb:0.0160, weight:2.00, lr:0.0003
[05:54:07.636] iteration:11578  t-loss:0.4331, loss-lb:0.3311, loss-ulb:0.0510, weight:2.00, lr:0.0003
[05:54:07.955] iteration:11579  t-loss:0.5082, loss-lb:0.2599, loss-ulb:0.1241, weight:2.00, lr:0.0003
[05:54:08.271] iteration:11580  t-loss:0.2701, loss-lb:0.1608, loss-ulb:0.0547, weight:2.00, lr:0.0003
[05:54:08.589] iteration:11581  t-loss:0.5360, loss-lb:0.1465, loss-ulb:0.1947, weight:2.00, lr:0.0003
[05:54:08.905] iteration:11582  t-loss:0.2445, loss-lb:0.1519, loss-ulb:0.0463, weight:2.00, lr:0.0003
[05:54:09.221] iteration:11583  t-loss:0.3242, loss-lb:0.1436, loss-ulb:0.0903, weight:2.00, lr:0.0003
[05:54:09.539] iteration:11584  t-loss:0.2355, loss-lb:0.1995, loss-ulb:0.0180, weight:2.00, lr:0.0003
[05:54:09.865] iteration:11585  t-loss:0.2831, loss-lb:0.1566, loss-ulb:0.0632, weight:2.00, lr:0.0003
[05:54:10.196] iteration:11586  t-loss:0.4050, loss-lb:0.1456, loss-ulb:0.1297, weight:2.00, lr:0.0003
[05:54:10.545] iteration:11587  t-loss:0.2880, loss-lb:0.2028, loss-ulb:0.0426, weight:2.00, lr:0.0003
[05:54:10.874] iteration:11588  t-loss:0.2471, loss-lb:0.1225, loss-ulb:0.0623, weight:2.00, lr:0.0003
[05:54:11.209] iteration:11589  t-loss:0.2727, loss-lb:0.2278, loss-ulb:0.0225, weight:2.00, lr:0.0003
[05:54:11.536] iteration:11590  t-loss:0.3179, loss-lb:0.2661, loss-ulb:0.0259, weight:2.00, lr:0.0003
[05:54:11.862] iteration:11591  t-loss:0.3961, loss-lb:0.2141, loss-ulb:0.0910, weight:2.00, lr:0.0003
[05:54:12.183] iteration:11592  t-loss:0.2558, loss-lb:0.1894, loss-ulb:0.0332, weight:2.00, lr:0.0003
[05:54:12.510] iteration:11593  t-loss:0.2590, loss-lb:0.2044, loss-ulb:0.0273, weight:2.00, lr:0.0003
[05:54:12.837] iteration:11594  t-loss:0.4037, loss-lb:0.2069, loss-ulb:0.0984, weight:2.00, lr:0.0003
[05:54:13.171] iteration:11595  t-loss:0.5103, loss-lb:0.2429, loss-ulb:0.1337, weight:2.00, lr:0.0003
[05:54:13.496] iteration:11596  t-loss:0.2939, loss-lb:0.2611, loss-ulb:0.0164, weight:2.00, lr:0.0003
[05:54:13.825] iteration:11597  t-loss:0.2998, loss-lb:0.1375, loss-ulb:0.0812, weight:2.00, lr:0.0003
[05:54:14.162] iteration:11598  t-loss:0.4437, loss-lb:0.2756, loss-ulb:0.0840, weight:2.00, lr:0.0003
[05:54:14.487] iteration:11599  t-loss:0.5054, loss-lb:0.1548, loss-ulb:0.1753, weight:2.00, lr:0.0003
[05:54:14.813] iteration:11600  t-loss:0.2560, loss-lb:0.1352, loss-ulb:0.0604, weight:2.00, lr:0.0003
[05:54:16.292] iteration:11601  t-loss:0.3511, loss-lb:0.1221, loss-ulb:0.1145, weight:2.00, lr:0.0003
[05:54:16.611] iteration:11602  t-loss:0.2788, loss-lb:0.1509, loss-ulb:0.0640, weight:2.00, lr:0.0003
[05:54:16.932] iteration:11603  t-loss:0.2971, loss-lb:0.1801, loss-ulb:0.0585, weight:2.00, lr:0.0003
[05:54:17.254] iteration:11604  t-loss:0.2771, loss-lb:0.1802, loss-ulb:0.0485, weight:2.00, lr:0.0003
[05:54:17.574] iteration:11605  t-loss:0.2769, loss-lb:0.1513, loss-ulb:0.0628, weight:2.00, lr:0.0003
[05:54:17.891] iteration:11606  t-loss:0.2222, loss-lb:0.1252, loss-ulb:0.0485, weight:2.00, lr:0.0003
[05:54:18.217] iteration:11607  t-loss:0.3185, loss-lb:0.1975, loss-ulb:0.0605, weight:2.00, lr:0.0003
[05:54:18.552] iteration:11608  t-loss:0.5445, loss-lb:0.1911, loss-ulb:0.1767, weight:2.00, lr:0.0003
[05:54:18.887] iteration:11609  t-loss:0.1608, loss-lb:0.1353, loss-ulb:0.0127, weight:2.00, lr:0.0003
[05:54:19.230] iteration:11610  t-loss:0.3264, loss-lb:0.2589, loss-ulb:0.0337, weight:2.00, lr:0.0003
[05:54:19.569] iteration:11611  t-loss:0.2130, loss-lb:0.1651, loss-ulb:0.0240, weight:2.00, lr:0.0003
[05:54:19.904] iteration:11612  t-loss:0.2825, loss-lb:0.1253, loss-ulb:0.0786, weight:2.00, lr:0.0003
[05:54:20.232] iteration:11613  t-loss:0.3662, loss-lb:0.2544, loss-ulb:0.0559, weight:2.00, lr:0.0003
[05:54:20.549] iteration:11614  t-loss:0.1767, loss-lb:0.1503, loss-ulb:0.0132, weight:2.00, lr:0.0003
[05:54:20.873] iteration:11615  t-loss:0.2337, loss-lb:0.1954, loss-ulb:0.0192, weight:2.00, lr:0.0003
[05:54:21.194] iteration:11616  t-loss:0.3823, loss-lb:0.2532, loss-ulb:0.0646, weight:2.00, lr:0.0003
[05:54:21.510] iteration:11617  t-loss:0.2106, loss-lb:0.1809, loss-ulb:0.0149, weight:2.00, lr:0.0003
[05:54:21.830] iteration:11618  t-loss:0.4332, loss-lb:0.2809, loss-ulb:0.0761, weight:2.00, lr:0.0003
[05:54:22.142] iteration:11619  t-loss:0.2831, loss-lb:0.1816, loss-ulb:0.0508, weight:2.00, lr:0.0003
[05:54:22.459] iteration:11620  t-loss:0.2776, loss-lb:0.1085, loss-ulb:0.0846, weight:2.00, lr:0.0003
[05:54:22.778] iteration:11621  t-loss:0.2912, loss-lb:0.2088, loss-ulb:0.0412, weight:2.00, lr:0.0003
[05:54:23.096] iteration:11622  t-loss:0.3031, loss-lb:0.1570, loss-ulb:0.0731, weight:2.00, lr:0.0003
[05:54:23.413] iteration:11623  t-loss:0.1960, loss-lb:0.1606, loss-ulb:0.0177, weight:2.00, lr:0.0003
[05:54:23.726] iteration:11624  t-loss:0.2086, loss-lb:0.1710, loss-ulb:0.0188, weight:2.00, lr:0.0003
[05:54:24.045] iteration:11625  t-loss:0.4679, loss-lb:0.2809, loss-ulb:0.0935, weight:2.00, lr:0.0003
[05:56:40.722] iteration 11625 : dice_score: 0.849933 best_dice: 0.852700
[05:56:40.722]  <<Test>> - Ep:464  - Dice-S/T:84.96/84.99, Best-S:85.16, Best-T:85.27
[05:56:40.722]           - AvgLoss(lb/ulb/all):0.18/0.05/0.29
[05:56:41.974] iteration:11626  t-loss:0.4436, loss-lb:0.2129, loss-ulb:0.1154, weight:2.00, lr:0.0003
[05:56:42.307] iteration:11627  t-loss:0.2323, loss-lb:0.1259, loss-ulb:0.0532, weight:2.00, lr:0.0003
[05:56:42.639] iteration:11628  t-loss:0.4341, loss-lb:0.1784, loss-ulb:0.1279, weight:2.00, lr:0.0003
[05:56:42.961] iteration:11629  t-loss:0.1698, loss-lb:0.1309, loss-ulb:0.0194, weight:2.00, lr:0.0003
[05:56:43.286] iteration:11630  t-loss:0.4291, loss-lb:0.1870, loss-ulb:0.1211, weight:2.00, lr:0.0003
[05:56:43.613] iteration:11631  t-loss:0.4186, loss-lb:0.2380, loss-ulb:0.0903, weight:2.00, lr:0.0003
[05:56:43.934] iteration:11632  t-loss:0.3755, loss-lb:0.2390, loss-ulb:0.0682, weight:2.00, lr:0.0003
[05:56:44.251] iteration:11633  t-loss:0.1565, loss-lb:0.1223, loss-ulb:0.0171, weight:2.00, lr:0.0003
[05:56:44.574] iteration:11634  t-loss:0.2599, loss-lb:0.1316, loss-ulb:0.0642, weight:2.00, lr:0.0003
[05:56:44.900] iteration:11635  t-loss:0.3263, loss-lb:0.2067, loss-ulb:0.0598, weight:2.00, lr:0.0003
[05:56:45.226] iteration:11636  t-loss:0.3425, loss-lb:0.2694, loss-ulb:0.0366, weight:2.00, lr:0.0003
[05:56:45.546] iteration:11637  t-loss:0.1809, loss-lb:0.1410, loss-ulb:0.0199, weight:2.00, lr:0.0003
[05:56:45.871] iteration:11638  t-loss:0.3678, loss-lb:0.2856, loss-ulb:0.0411, weight:2.00, lr:0.0003
[05:56:46.190] iteration:11639  t-loss:0.3662, loss-lb:0.1163, loss-ulb:0.1250, weight:2.00, lr:0.0003
[05:56:46.513] iteration:11640  t-loss:0.3613, loss-lb:0.2633, loss-ulb:0.0490, weight:2.00, lr:0.0003
[05:56:46.835] iteration:11641  t-loss:0.2459, loss-lb:0.1362, loss-ulb:0.0549, weight:2.00, lr:0.0003
[05:56:47.157] iteration:11642  t-loss:0.4096, loss-lb:0.2731, loss-ulb:0.0683, weight:2.00, lr:0.0003
[05:56:47.479] iteration:11643  t-loss:0.1765, loss-lb:0.1493, loss-ulb:0.0136, weight:2.00, lr:0.0003
[05:56:47.796] iteration:11644  t-loss:0.5195, loss-lb:0.1593, loss-ulb:0.1801, weight:2.00, lr:0.0003
[05:56:48.113] iteration:11645  t-loss:0.3066, loss-lb:0.2062, loss-ulb:0.0502, weight:2.00, lr:0.0003
[05:56:48.434] iteration:11646  t-loss:0.3687, loss-lb:0.1898, loss-ulb:0.0895, weight:2.00, lr:0.0003
[05:56:48.755] iteration:11647  t-loss:0.5527, loss-lb:0.3153, loss-ulb:0.1187, weight:2.00, lr:0.0003
[05:56:49.074] iteration:11648  t-loss:0.3521, loss-lb:0.2175, loss-ulb:0.0673, weight:2.00, lr:0.0003
[05:56:49.392] iteration:11649  t-loss:0.5002, loss-lb:0.2980, loss-ulb:0.1011, weight:2.00, lr:0.0003
[05:56:49.708] iteration:11650  t-loss:0.1756, loss-lb:0.1441, loss-ulb:0.0157, weight:2.00, lr:0.0003
[05:56:51.217] iteration:11651  t-loss:0.3268, loss-lb:0.2396, loss-ulb:0.0436, weight:2.00, lr:0.0003
[05:56:51.549] iteration:11652  t-loss:0.2513, loss-lb:0.1340, loss-ulb:0.0587, weight:2.00, lr:0.0003
[05:56:51.878] iteration:11653  t-loss:0.4236, loss-lb:0.1431, loss-ulb:0.1402, weight:2.00, lr:0.0003
[05:56:52.206] iteration:11654  t-loss:0.2778, loss-lb:0.1805, loss-ulb:0.0486, weight:2.00, lr:0.0003
[05:56:52.523] iteration:11655  t-loss:0.2570, loss-lb:0.1258, loss-ulb:0.0656, weight:2.00, lr:0.0003
[05:56:52.846] iteration:11656  t-loss:0.2471, loss-lb:0.1876, loss-ulb:0.0298, weight:2.00, lr:0.0003
[05:56:53.162] iteration:11657  t-loss:0.1507, loss-lb:0.1215, loss-ulb:0.0146, weight:2.00, lr:0.0003
[05:56:53.480] iteration:11658  t-loss:0.1723, loss-lb:0.1410, loss-ulb:0.0157, weight:2.00, lr:0.0003
[05:56:53.810] iteration:11659  t-loss:0.2946, loss-lb:0.1929, loss-ulb:0.0509, weight:2.00, lr:0.0003
[05:56:54.138] iteration:11660  t-loss:0.2262, loss-lb:0.1875, loss-ulb:0.0194, weight:2.00, lr:0.0003
[05:56:54.462] iteration:11661  t-loss:0.2954, loss-lb:0.2619, loss-ulb:0.0168, weight:2.00, lr:0.0003
[05:56:54.783] iteration:11662  t-loss:0.2989, loss-lb:0.2130, loss-ulb:0.0430, weight:2.00, lr:0.0003
[05:56:55.111] iteration:11663  t-loss:0.3297, loss-lb:0.1383, loss-ulb:0.0957, weight:2.00, lr:0.0003
[05:56:55.438] iteration:11664  t-loss:0.7553, loss-lb:0.2666, loss-ulb:0.2444, weight:2.00, lr:0.0003
[05:56:55.787] iteration:11665  t-loss:0.3621, loss-lb:0.1561, loss-ulb:0.1030, weight:2.00, lr:0.0003
[05:56:56.127] iteration:11666  t-loss:0.4772, loss-lb:0.2583, loss-ulb:0.1095, weight:2.00, lr:0.0003
[05:56:56.467] iteration:11667  t-loss:0.4843, loss-lb:0.1943, loss-ulb:0.1450, weight:2.00, lr:0.0003
[05:56:56.821] iteration:11668  t-loss:0.4193, loss-lb:0.2235, loss-ulb:0.0979, weight:2.00, lr:0.0003
[05:56:57.143] iteration:11669  t-loss:0.3156, loss-lb:0.1916, loss-ulb:0.0620, weight:2.00, lr:0.0003
[05:56:57.465] iteration:11670  t-loss:0.4049, loss-lb:0.2577, loss-ulb:0.0736, weight:2.00, lr:0.0003
[05:56:57.780] iteration:11671  t-loss:0.3458, loss-lb:0.2844, loss-ulb:0.0307, weight:2.00, lr:0.0003
[05:56:58.098] iteration:11672  t-loss:0.2373, loss-lb:0.1486, loss-ulb:0.0443, weight:2.00, lr:0.0003
[05:56:58.411] iteration:11673  t-loss:0.1411, loss-lb:0.1102, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:56:58.731] iteration:11674  t-loss:0.4285, loss-lb:0.2210, loss-ulb:0.1038, weight:2.00, lr:0.0003
[05:56:59.051] iteration:11675  t-loss:0.6241, loss-lb:0.2428, loss-ulb:0.1906, weight:2.00, lr:0.0003
[05:57:00.465] iteration:11676  t-loss:0.3168, loss-lb:0.1701, loss-ulb:0.0733, weight:2.00, lr:0.0003
[05:57:00.809] iteration:11677  t-loss:0.2908, loss-lb:0.1967, loss-ulb:0.0471, weight:2.00, lr:0.0003
[05:57:01.138] iteration:11678  t-loss:0.2360, loss-lb:0.1669, loss-ulb:0.0345, weight:2.00, lr:0.0003
[05:57:01.460] iteration:11679  t-loss:0.3289, loss-lb:0.2982, loss-ulb:0.0154, weight:2.00, lr:0.0003
[05:57:01.781] iteration:11680  t-loss:0.3169, loss-lb:0.1809, loss-ulb:0.0680, weight:2.00, lr:0.0003
[05:57:02.101] iteration:11681  t-loss:0.2304, loss-lb:0.1926, loss-ulb:0.0189, weight:2.00, lr:0.0003
[05:57:02.420] iteration:11682  t-loss:0.2679, loss-lb:0.2364, loss-ulb:0.0158, weight:2.00, lr:0.0003
[05:57:02.738] iteration:11683  t-loss:0.5347, loss-lb:0.1651, loss-ulb:0.1848, weight:2.00, lr:0.0003
[05:57:03.059] iteration:11684  t-loss:0.2565, loss-lb:0.2069, loss-ulb:0.0248, weight:2.00, lr:0.0003
[05:57:03.376] iteration:11685  t-loss:0.3122, loss-lb:0.1901, loss-ulb:0.0610, weight:2.00, lr:0.0003
[05:57:03.701] iteration:11686  t-loss:0.2665, loss-lb:0.1199, loss-ulb:0.0733, weight:2.00, lr:0.0003
[05:57:04.031] iteration:11687  t-loss:0.3086, loss-lb:0.1483, loss-ulb:0.0801, weight:2.00, lr:0.0003
[05:57:04.372] iteration:11688  t-loss:0.2432, loss-lb:0.1301, loss-ulb:0.0565, weight:2.00, lr:0.0003
[05:57:04.708] iteration:11689  t-loss:0.3289, loss-lb:0.1851, loss-ulb:0.0719, weight:2.00, lr:0.0003
[05:57:05.053] iteration:11690  t-loss:0.3131, loss-lb:0.1556, loss-ulb:0.0788, weight:2.00, lr:0.0003
[05:57:05.387] iteration:11691  t-loss:0.2898, loss-lb:0.1589, loss-ulb:0.0655, weight:2.00, lr:0.0003
[05:57:05.729] iteration:11692  t-loss:0.3513, loss-lb:0.2394, loss-ulb:0.0560, weight:2.00, lr:0.0003
[05:57:06.047] iteration:11693  t-loss:0.1913, loss-lb:0.1503, loss-ulb:0.0205, weight:2.00, lr:0.0003
[05:57:06.368] iteration:11694  t-loss:0.6397, loss-lb:0.4070, loss-ulb:0.1163, weight:2.00, lr:0.0003
[05:57:06.694] iteration:11695  t-loss:0.3563, loss-lb:0.1761, loss-ulb:0.0901, weight:2.00, lr:0.0003
[05:57:07.016] iteration:11696  t-loss:0.2241, loss-lb:0.1246, loss-ulb:0.0498, weight:2.00, lr:0.0003
[05:57:07.334] iteration:11697  t-loss:0.3803, loss-lb:0.1844, loss-ulb:0.0980, weight:2.00, lr:0.0003
[05:57:07.650] iteration:11698  t-loss:0.2477, loss-lb:0.1627, loss-ulb:0.0425, weight:2.00, lr:0.0003
[05:57:07.970] iteration:11699  t-loss:0.3337, loss-lb:0.1348, loss-ulb:0.0994, weight:2.00, lr:0.0003
[05:57:08.294] iteration:11700  t-loss:0.2893, loss-lb:0.1890, loss-ulb:0.0501, weight:2.00, lr:0.0003
[05:57:09.831] iteration:11701  t-loss:0.1892, loss-lb:0.1436, loss-ulb:0.0228, weight:2.00, lr:0.0003
[05:57:10.152] iteration:11702  t-loss:0.1926, loss-lb:0.1560, loss-ulb:0.0183, weight:2.00, lr:0.0003
[05:57:10.480] iteration:11703  t-loss:0.2806, loss-lb:0.1464, loss-ulb:0.0671, weight:2.00, lr:0.0003
[05:57:10.797] iteration:11704  t-loss:0.2073, loss-lb:0.1721, loss-ulb:0.0176, weight:2.00, lr:0.0003
[05:57:11.112] iteration:11705  t-loss:0.1766, loss-lb:0.1414, loss-ulb:0.0176, weight:2.00, lr:0.0003
[05:57:11.432] iteration:11706  t-loss:0.3004, loss-lb:0.2674, loss-ulb:0.0165, weight:2.00, lr:0.0003
[05:57:11.755] iteration:11707  t-loss:0.3431, loss-lb:0.3074, loss-ulb:0.0178, weight:2.00, lr:0.0003
[05:57:12.073] iteration:11708  t-loss:0.1677, loss-lb:0.1216, loss-ulb:0.0231, weight:2.00, lr:0.0003
[05:57:12.415] iteration:11709  t-loss:0.4299, loss-lb:0.2198, loss-ulb:0.1051, weight:2.00, lr:0.0003
[05:57:12.751] iteration:11710  t-loss:0.3518, loss-lb:0.2543, loss-ulb:0.0488, weight:2.00, lr:0.0003
[05:57:13.096] iteration:11711  t-loss:0.2994, loss-lb:0.2660, loss-ulb:0.0167, weight:2.00, lr:0.0003
[05:57:13.437] iteration:11712  t-loss:0.3320, loss-lb:0.1883, loss-ulb:0.0718, weight:2.00, lr:0.0003
[05:57:13.792] iteration:11713  t-loss:0.4421, loss-lb:0.2308, loss-ulb:0.1056, weight:2.00, lr:0.0003
[05:57:14.127] iteration:11714  t-loss:0.3662, loss-lb:0.1517, loss-ulb:0.1073, weight:2.00, lr:0.0003
[05:57:14.461] iteration:11715  t-loss:0.2240, loss-lb:0.1766, loss-ulb:0.0237, weight:2.00, lr:0.0003
[05:57:14.783] iteration:11716  t-loss:0.4143, loss-lb:0.1536, loss-ulb:0.1303, weight:2.00, lr:0.0003
[05:57:15.111] iteration:11717  t-loss:0.2874, loss-lb:0.2468, loss-ulb:0.0203, weight:2.00, lr:0.0003
[05:57:15.446] iteration:11718  t-loss:0.3750, loss-lb:0.1717, loss-ulb:0.1017, weight:2.00, lr:0.0003
[05:57:15.764] iteration:11719  t-loss:0.2076, loss-lb:0.1537, loss-ulb:0.0269, weight:2.00, lr:0.0003
[05:57:16.081] iteration:11720  t-loss:0.1449, loss-lb:0.1160, loss-ulb:0.0145, weight:2.00, lr:0.0003
[05:57:16.406] iteration:11721  t-loss:0.5198, loss-lb:0.2711, loss-ulb:0.1243, weight:2.00, lr:0.0003
[05:57:16.726] iteration:11722  t-loss:0.1823, loss-lb:0.1524, loss-ulb:0.0149, weight:2.00, lr:0.0003
[05:57:17.049] iteration:11723  t-loss:0.3678, loss-lb:0.2449, loss-ulb:0.0615, weight:2.00, lr:0.0003
[05:57:17.372] iteration:11724  t-loss:0.1854, loss-lb:0.1575, loss-ulb:0.0140, weight:2.00, lr:0.0003
[05:57:17.694] iteration:11725  t-loss:0.2855, loss-lb:0.2199, loss-ulb:0.0328, weight:2.00, lr:0.0003
[05:59:29.315] iteration 11725 : dice_score: 0.848768 best_dice: 0.852700
[05:59:29.315]  <<Test>> - Ep:468  - Dice-S/T:84.95/84.88, Best-S:85.16, Best-T:85.27
[05:59:29.315]           - AvgLoss(lb/ulb/all):0.19/0.05/0.31
[05:59:30.556] iteration:11726  t-loss:0.3333, loss-lb:0.1468, loss-ulb:0.0933, weight:2.00, lr:0.0003
[05:59:30.888] iteration:11727  t-loss:0.1782, loss-lb:0.1489, loss-ulb:0.0147, weight:2.00, lr:0.0003
[05:59:31.223] iteration:11728  t-loss:0.3646, loss-lb:0.1884, loss-ulb:0.0881, weight:2.00, lr:0.0003
[05:59:31.558] iteration:11729  t-loss:0.3231, loss-lb:0.2616, loss-ulb:0.0307, weight:2.00, lr:0.0003
[05:59:31.895] iteration:11730  t-loss:0.3011, loss-lb:0.1917, loss-ulb:0.0547, weight:2.00, lr:0.0003
[05:59:32.235] iteration:11731  t-loss:0.3977, loss-lb:0.2263, loss-ulb:0.0857, weight:2.00, lr:0.0003
[05:59:32.565] iteration:11732  t-loss:0.8352, loss-lb:0.5832, loss-ulb:0.1260, weight:2.00, lr:0.0003
[05:59:32.892] iteration:11733  t-loss:0.3583, loss-lb:0.1586, loss-ulb:0.0998, weight:2.00, lr:0.0003
[05:59:33.216] iteration:11734  t-loss:0.4186, loss-lb:0.1987, loss-ulb:0.1100, weight:2.00, lr:0.0003
[05:59:33.541] iteration:11735  t-loss:0.4505, loss-lb:0.2442, loss-ulb:0.1032, weight:2.00, lr:0.0003
[05:59:33.869] iteration:11736  t-loss:0.3310, loss-lb:0.2050, loss-ulb:0.0630, weight:2.00, lr:0.0003
[05:59:34.189] iteration:11737  t-loss:0.1623, loss-lb:0.1211, loss-ulb:0.0206, weight:2.00, lr:0.0003
[05:59:34.506] iteration:11738  t-loss:0.2230, loss-lb:0.1794, loss-ulb:0.0218, weight:2.00, lr:0.0003
[05:59:34.822] iteration:11739  t-loss:0.2578, loss-lb:0.1534, loss-ulb:0.0522, weight:2.00, lr:0.0003
[05:59:35.144] iteration:11740  t-loss:0.3915, loss-lb:0.2364, loss-ulb:0.0775, weight:2.00, lr:0.0003
[05:59:35.463] iteration:11741  t-loss:0.3393, loss-lb:0.1947, loss-ulb:0.0723, weight:2.00, lr:0.0003
[05:59:35.786] iteration:11742  t-loss:0.4184, loss-lb:0.2755, loss-ulb:0.0715, weight:2.00, lr:0.0003
[05:59:36.100] iteration:11743  t-loss:0.2698, loss-lb:0.1545, loss-ulb:0.0577, weight:2.00, lr:0.0003
[05:59:36.419] iteration:11744  t-loss:0.2756, loss-lb:0.2132, loss-ulb:0.0312, weight:2.00, lr:0.0003
[05:59:36.735] iteration:11745  t-loss:0.2748, loss-lb:0.2144, loss-ulb:0.0302, weight:2.00, lr:0.0003
[05:59:37.052] iteration:11746  t-loss:0.3021, loss-lb:0.2416, loss-ulb:0.0302, weight:2.00, lr:0.0003
[05:59:37.368] iteration:11747  t-loss:0.6250, loss-lb:0.1811, loss-ulb:0.2220, weight:2.00, lr:0.0003
[05:59:37.685] iteration:11748  t-loss:0.2396, loss-lb:0.1772, loss-ulb:0.0312, weight:2.00, lr:0.0003
[05:59:38.001] iteration:11749  t-loss:0.2850, loss-lb:0.1232, loss-ulb:0.0809, weight:2.00, lr:0.0003
[05:59:38.318] iteration:11750  t-loss:0.2147, loss-lb:0.1482, loss-ulb:0.0333, weight:2.00, lr:0.0003
[05:59:39.509] iteration:11751  t-loss:0.4394, loss-lb:0.2648, loss-ulb:0.0873, weight:2.00, lr:0.0003
[05:59:39.836] iteration:11752  t-loss:0.1857, loss-lb:0.1469, loss-ulb:0.0194, weight:2.00, lr:0.0003
[05:59:40.175] iteration:11753  t-loss:0.3074, loss-lb:0.2013, loss-ulb:0.0530, weight:2.00, lr:0.0003
[05:59:40.502] iteration:11754  t-loss:0.2613, loss-lb:0.1875, loss-ulb:0.0369, weight:2.00, lr:0.0003
[05:59:40.825] iteration:11755  t-loss:0.3653, loss-lb:0.1712, loss-ulb:0.0970, weight:2.00, lr:0.0003
[05:59:41.139] iteration:11756  t-loss:0.2529, loss-lb:0.1716, loss-ulb:0.0407, weight:2.00, lr:0.0003
[05:59:41.460] iteration:11757  t-loss:0.3085, loss-lb:0.1683, loss-ulb:0.0701, weight:2.00, lr:0.0003
[05:59:41.778] iteration:11758  t-loss:0.9133, loss-lb:0.2566, loss-ulb:0.3284, weight:2.00, lr:0.0003
[05:59:42.097] iteration:11759  t-loss:0.3741, loss-lb:0.2255, loss-ulb:0.0743, weight:2.00, lr:0.0003
[05:59:42.421] iteration:11760  t-loss:0.4456, loss-lb:0.2384, loss-ulb:0.1036, weight:2.00, lr:0.0003
[05:59:42.742] iteration:11761  t-loss:0.2575, loss-lb:0.1634, loss-ulb:0.0471, weight:2.00, lr:0.0003
[05:59:43.064] iteration:11762  t-loss:0.3674, loss-lb:0.2043, loss-ulb:0.0815, weight:2.00, lr:0.0003
[05:59:43.382] iteration:11763  t-loss:0.4035, loss-lb:0.1829, loss-ulb:0.1103, weight:2.00, lr:0.0003
[05:59:43.705] iteration:11764  t-loss:0.4940, loss-lb:0.2175, loss-ulb:0.1383, weight:2.00, lr:0.0003
[05:59:44.022] iteration:11765  t-loss:0.1947, loss-lb:0.1488, loss-ulb:0.0229, weight:2.00, lr:0.0003
[05:59:44.341] iteration:11766  t-loss:0.1788, loss-lb:0.1336, loss-ulb:0.0226, weight:2.00, lr:0.0003
[05:59:44.665] iteration:11767  t-loss:0.2134, loss-lb:0.1374, loss-ulb:0.0380, weight:2.00, lr:0.0003
[05:59:44.992] iteration:11768  t-loss:0.2333, loss-lb:0.1823, loss-ulb:0.0255, weight:2.00, lr:0.0003
[05:59:45.322] iteration:11769  t-loss:0.3983, loss-lb:0.1762, loss-ulb:0.1110, weight:2.00, lr:0.0003
[05:59:45.645] iteration:11770  t-loss:0.2226, loss-lb:0.1681, loss-ulb:0.0272, weight:2.00, lr:0.0003
[05:59:45.966] iteration:11771  t-loss:0.2751, loss-lb:0.1492, loss-ulb:0.0630, weight:2.00, lr:0.0003
[05:59:46.294] iteration:11772  t-loss:0.1845, loss-lb:0.1466, loss-ulb:0.0190, weight:2.00, lr:0.0003
[05:59:46.628] iteration:11773  t-loss:0.2739, loss-lb:0.2463, loss-ulb:0.0138, weight:2.00, lr:0.0003
[05:59:46.950] iteration:11774  t-loss:0.3652, loss-lb:0.2435, loss-ulb:0.0608, weight:2.00, lr:0.0003
[05:59:47.276] iteration:11775  t-loss:0.3021, loss-lb:0.1463, loss-ulb:0.0779, weight:2.00, lr:0.0003
[05:59:49.026] iteration:11776  t-loss:0.2958, loss-lb:0.1417, loss-ulb:0.0770, weight:2.00, lr:0.0003
[05:59:49.378] iteration:11777  t-loss:0.2946, loss-lb:0.1454, loss-ulb:0.0746, weight:2.00, lr:0.0003
[05:59:49.713] iteration:11778  t-loss:0.5704, loss-lb:0.2521, loss-ulb:0.1591, weight:2.00, lr:0.0003
[05:59:50.049] iteration:11779  t-loss:0.1682, loss-lb:0.1277, loss-ulb:0.0203, weight:2.00, lr:0.0003
[05:59:50.378] iteration:11780  t-loss:0.2612, loss-lb:0.1496, loss-ulb:0.0558, weight:2.00, lr:0.0003
[05:59:50.708] iteration:11781  t-loss:0.3794, loss-lb:0.1891, loss-ulb:0.0951, weight:2.00, lr:0.0003
[05:59:51.034] iteration:11782  t-loss:0.2371, loss-lb:0.1955, loss-ulb:0.0208, weight:2.00, lr:0.0003
[05:59:51.366] iteration:11783  t-loss:0.3443, loss-lb:0.3166, loss-ulb:0.0139, weight:2.00, lr:0.0003
[05:59:51.694] iteration:11784  t-loss:0.3866, loss-lb:0.2216, loss-ulb:0.0825, weight:2.00, lr:0.0003
[05:59:52.028] iteration:11785  t-loss:0.3270, loss-lb:0.2152, loss-ulb:0.0559, weight:2.00, lr:0.0003
[05:59:52.351] iteration:11786  t-loss:0.3059, loss-lb:0.1626, loss-ulb:0.0716, weight:2.00, lr:0.0003
[05:59:52.656] iteration:11787  t-loss:0.5660, loss-lb:0.1496, loss-ulb:0.2082, weight:2.00, lr:0.0002
[05:59:52.974] iteration:11788  t-loss:0.4182, loss-lb:0.2836, loss-ulb:0.0673, weight:2.00, lr:0.0002
[05:59:53.292] iteration:11789  t-loss:0.3552, loss-lb:0.1667, loss-ulb:0.0943, weight:2.00, lr:0.0002
[05:59:53.610] iteration:11790  t-loss:0.3220, loss-lb:0.1508, loss-ulb:0.0856, weight:2.00, lr:0.0002
[05:59:53.928] iteration:11791  t-loss:0.3172, loss-lb:0.1991, loss-ulb:0.0590, weight:2.00, lr:0.0002
[05:59:54.242] iteration:11792  t-loss:0.3503, loss-lb:0.1893, loss-ulb:0.0805, weight:2.00, lr:0.0002
[05:59:54.557] iteration:11793  t-loss:0.3825, loss-lb:0.1658, loss-ulb:0.1084, weight:2.00, lr:0.0002
[05:59:54.881] iteration:11794  t-loss:0.3592, loss-lb:0.2525, loss-ulb:0.0533, weight:2.00, lr:0.0002
[05:59:55.213] iteration:11795  t-loss:0.3544, loss-lb:0.2197, loss-ulb:0.0673, weight:2.00, lr:0.0002
[05:59:55.542] iteration:11796  t-loss:0.1612, loss-lb:0.1270, loss-ulb:0.0171, weight:2.00, lr:0.0002
[05:59:55.869] iteration:11797  t-loss:0.4263, loss-lb:0.2340, loss-ulb:0.0961, weight:2.00, lr:0.0002
[05:59:56.183] iteration:11798  t-loss:0.2304, loss-lb:0.1610, loss-ulb:0.0347, weight:2.00, lr:0.0002
[05:59:56.505] iteration:11799  t-loss:0.2654, loss-lb:0.1468, loss-ulb:0.0593, weight:2.00, lr:0.0002
[05:59:56.841] iteration:11800  t-loss:0.3341, loss-lb:0.1319, loss-ulb:0.1011, weight:2.00, lr:0.0002
[05:59:59.118] iteration:11801  t-loss:0.3592, loss-lb:0.2708, loss-ulb:0.0442, weight:2.00, lr:0.0002
[05:59:59.479] iteration:11802  t-loss:0.3436, loss-lb:0.2244, loss-ulb:0.0596, weight:2.00, lr:0.0002
[05:59:59.841] iteration:11803  t-loss:0.3832, loss-lb:0.2763, loss-ulb:0.0535, weight:2.00, lr:0.0002
[06:00:00.200] iteration:11804  t-loss:0.4010, loss-lb:0.1513, loss-ulb:0.1248, weight:2.00, lr:0.0002
[06:00:00.572] iteration:11805  t-loss:0.3577, loss-lb:0.1981, loss-ulb:0.0798, weight:2.00, lr:0.0002
[06:00:00.934] iteration:11806  t-loss:0.5433, loss-lb:0.2567, loss-ulb:0.1433, weight:2.00, lr:0.0002
[06:00:01.278] iteration:11807  t-loss:0.3654, loss-lb:0.1898, loss-ulb:0.0878, weight:2.00, lr:0.0002
[06:00:01.614] iteration:11808  t-loss:0.5202, loss-lb:0.1848, loss-ulb:0.1677, weight:2.00, lr:0.0002
[06:00:01.957] iteration:11809  t-loss:0.3246, loss-lb:0.1809, loss-ulb:0.0718, weight:2.00, lr:0.0002
[06:00:02.292] iteration:11810  t-loss:0.4122, loss-lb:0.2423, loss-ulb:0.0850, weight:2.00, lr:0.0002
[06:00:02.621] iteration:11811  t-loss:0.3373, loss-lb:0.2086, loss-ulb:0.0643, weight:2.00, lr:0.0002
[06:00:02.941] iteration:11812  t-loss:0.2879, loss-lb:0.1342, loss-ulb:0.0768, weight:2.00, lr:0.0002
[06:00:03.263] iteration:11813  t-loss:0.3508, loss-lb:0.2472, loss-ulb:0.0518, weight:2.00, lr:0.0002
[06:00:03.588] iteration:11814  t-loss:0.1707, loss-lb:0.1343, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:00:03.922] iteration:11815  t-loss:0.6780, loss-lb:0.2138, loss-ulb:0.2321, weight:2.00, lr:0.0002
[06:00:04.261] iteration:11816  t-loss:0.5700, loss-lb:0.3102, loss-ulb:0.1299, weight:2.00, lr:0.0002
[06:00:04.592] iteration:11817  t-loss:0.4041, loss-lb:0.2435, loss-ulb:0.0803, weight:2.00, lr:0.0002
[06:00:04.917] iteration:11818  t-loss:0.2961, loss-lb:0.1231, loss-ulb:0.0865, weight:2.00, lr:0.0002
[06:00:05.230] iteration:11819  t-loss:0.2419, loss-lb:0.1775, loss-ulb:0.0322, weight:2.00, lr:0.0002
[06:00:05.545] iteration:11820  t-loss:0.3402, loss-lb:0.2354, loss-ulb:0.0524, weight:2.00, lr:0.0002
[06:00:05.861] iteration:11821  t-loss:0.2547, loss-lb:0.2121, loss-ulb:0.0213, weight:2.00, lr:0.0002
[06:00:06.179] iteration:11822  t-loss:0.3507, loss-lb:0.1925, loss-ulb:0.0791, weight:2.00, lr:0.0002
[06:00:06.496] iteration:11823  t-loss:0.2926, loss-lb:0.2358, loss-ulb:0.0284, weight:2.00, lr:0.0002
[06:00:06.825] iteration:11824  t-loss:0.5102, loss-lb:0.2361, loss-ulb:0.1370, weight:2.00, lr:0.0002
[06:00:07.160] iteration:11825  t-loss:0.4145, loss-lb:0.1534, loss-ulb:0.1305, weight:2.00, lr:0.0002
[06:02:24.638] iteration 11825 : dice_score: 0.849850 best_dice: 0.852700
[06:02:24.638]  <<Test>> - Ep:472  - Dice-S/T:84.76/84.98, Best-S:85.16, Best-T:85.27
[06:02:24.638]           - AvgLoss(lb/ulb/all):0.21/0.09/0.38
[06:02:25.857] iteration:11826  t-loss:0.2348, loss-lb:0.1378, loss-ulb:0.0485, weight:2.00, lr:0.0002
[06:02:26.189] iteration:11827  t-loss:0.1496, loss-lb:0.1240, loss-ulb:0.0128, weight:2.00, lr:0.0002
[06:02:26.511] iteration:11828  t-loss:0.3558, loss-lb:0.1372, loss-ulb:0.1093, weight:2.00, lr:0.0002
[06:02:26.828] iteration:11829  t-loss:0.4122, loss-lb:0.1360, loss-ulb:0.1381, weight:2.00, lr:0.0002
[06:02:27.154] iteration:11830  t-loss:0.4836, loss-lb:0.2738, loss-ulb:0.1049, weight:2.00, lr:0.0002
[06:02:27.471] iteration:11831  t-loss:0.4124, loss-lb:0.1679, loss-ulb:0.1222, weight:2.00, lr:0.0002
[06:02:27.791] iteration:11832  t-loss:0.2656, loss-lb:0.2035, loss-ulb:0.0311, weight:2.00, lr:0.0002
[06:02:28.109] iteration:11833  t-loss:0.1961, loss-lb:0.1548, loss-ulb:0.0206, weight:2.00, lr:0.0002
[06:02:28.427] iteration:11834  t-loss:0.3595, loss-lb:0.2415, loss-ulb:0.0590, weight:2.00, lr:0.0002
[06:02:28.743] iteration:11835  t-loss:0.2459, loss-lb:0.1893, loss-ulb:0.0283, weight:2.00, lr:0.0002
[06:02:29.058] iteration:11836  t-loss:0.2078, loss-lb:0.1644, loss-ulb:0.0217, weight:2.00, lr:0.0002
[06:02:29.379] iteration:11837  t-loss:0.2815, loss-lb:0.2471, loss-ulb:0.0172, weight:2.00, lr:0.0002
[06:02:29.704] iteration:11838  t-loss:0.3566, loss-lb:0.1879, loss-ulb:0.0843, weight:2.00, lr:0.0002
[06:02:30.021] iteration:11839  t-loss:0.4289, loss-lb:0.1886, loss-ulb:0.1202, weight:2.00, lr:0.0002
[06:02:30.341] iteration:11840  t-loss:0.2721, loss-lb:0.2157, loss-ulb:0.0282, weight:2.00, lr:0.0002
[06:02:30.658] iteration:11841  t-loss:0.1963, loss-lb:0.1494, loss-ulb:0.0234, weight:2.00, lr:0.0002
[06:02:30.977] iteration:11842  t-loss:0.3315, loss-lb:0.2778, loss-ulb:0.0268, weight:2.00, lr:0.0002
[06:02:31.293] iteration:11843  t-loss:0.3627, loss-lb:0.1706, loss-ulb:0.0961, weight:2.00, lr:0.0002
[06:02:31.612] iteration:11844  t-loss:0.2745, loss-lb:0.1684, loss-ulb:0.0531, weight:2.00, lr:0.0002
[06:02:31.933] iteration:11845  t-loss:0.3378, loss-lb:0.2187, loss-ulb:0.0596, weight:2.00, lr:0.0002
[06:02:32.251] iteration:11846  t-loss:0.2740, loss-lb:0.2383, loss-ulb:0.0179, weight:2.00, lr:0.0002
[06:02:32.565] iteration:11847  t-loss:0.3372, loss-lb:0.1826, loss-ulb:0.0773, weight:2.00, lr:0.0002
[06:02:32.883] iteration:11848  t-loss:0.3120, loss-lb:0.1963, loss-ulb:0.0579, weight:2.00, lr:0.0002
[06:02:33.203] iteration:11849  t-loss:0.3278, loss-lb:0.1438, loss-ulb:0.0920, weight:2.00, lr:0.0002
[06:02:33.517] iteration:11850  t-loss:0.1757, loss-lb:0.1461, loss-ulb:0.0148, weight:2.00, lr:0.0002
[06:02:34.796] iteration:11851  t-loss:0.2727, loss-lb:0.0963, loss-ulb:0.0882, weight:2.00, lr:0.0002
[06:02:35.140] iteration:11852  t-loss:0.3060, loss-lb:0.2294, loss-ulb:0.0383, weight:2.00, lr:0.0002
[06:02:35.471] iteration:11853  t-loss:0.8269, loss-lb:0.1400, loss-ulb:0.3435, weight:2.00, lr:0.0002
[06:02:35.797] iteration:11854  t-loss:0.5116, loss-lb:0.1957, loss-ulb:0.1579, weight:2.00, lr:0.0002
[06:02:36.120] iteration:11855  t-loss:0.2785, loss-lb:0.2067, loss-ulb:0.0359, weight:2.00, lr:0.0002
[06:02:36.441] iteration:11856  t-loss:0.3303, loss-lb:0.1291, loss-ulb:0.1006, weight:2.00, lr:0.0002
[06:02:36.767] iteration:11857  t-loss:0.3121, loss-lb:0.2006, loss-ulb:0.0557, weight:2.00, lr:0.0002
[06:02:37.086] iteration:11858  t-loss:0.1833, loss-lb:0.1342, loss-ulb:0.0246, weight:2.00, lr:0.0002
[06:02:37.406] iteration:11859  t-loss:0.4303, loss-lb:0.1665, loss-ulb:0.1319, weight:2.00, lr:0.0002
[06:02:37.727] iteration:11860  t-loss:0.2578, loss-lb:0.2098, loss-ulb:0.0240, weight:2.00, lr:0.0002
[06:02:38.050] iteration:11861  t-loss:0.2603, loss-lb:0.1299, loss-ulb:0.0652, weight:2.00, lr:0.0002
[06:02:38.376] iteration:11862  t-loss:0.4847, loss-lb:0.3424, loss-ulb:0.0712, weight:2.00, lr:0.0002
[06:02:38.696] iteration:11863  t-loss:0.2917, loss-lb:0.1292, loss-ulb:0.0812, weight:2.00, lr:0.0002
[06:02:39.020] iteration:11864  t-loss:0.2006, loss-lb:0.1636, loss-ulb:0.0185, weight:2.00, lr:0.0002
[06:02:39.339] iteration:11865  t-loss:0.2474, loss-lb:0.2071, loss-ulb:0.0202, weight:2.00, lr:0.0002
[06:02:39.660] iteration:11866  t-loss:0.2118, loss-lb:0.1692, loss-ulb:0.0213, weight:2.00, lr:0.0002
[06:02:39.980] iteration:11867  t-loss:0.1683, loss-lb:0.1332, loss-ulb:0.0176, weight:2.00, lr:0.0002
[06:02:40.300] iteration:11868  t-loss:0.4081, loss-lb:0.1631, loss-ulb:0.1225, weight:2.00, lr:0.0002
[06:02:40.616] iteration:11869  t-loss:0.3141, loss-lb:0.2680, loss-ulb:0.0231, weight:2.00, lr:0.0002
[06:02:40.933] iteration:11870  t-loss:0.3414, loss-lb:0.2177, loss-ulb:0.0619, weight:2.00, lr:0.0002
[06:02:41.249] iteration:11871  t-loss:0.3342, loss-lb:0.1600, loss-ulb:0.0871, weight:2.00, lr:0.0002
[06:02:41.567] iteration:11872  t-loss:0.2918, loss-lb:0.1477, loss-ulb:0.0720, weight:2.00, lr:0.0002
[06:02:41.882] iteration:11873  t-loss:0.3451, loss-lb:0.1804, loss-ulb:0.0823, weight:2.00, lr:0.0002
[06:02:42.199] iteration:11874  t-loss:0.3430, loss-lb:0.1825, loss-ulb:0.0803, weight:2.00, lr:0.0002
[06:02:42.520] iteration:11875  t-loss:0.2410, loss-lb:0.1618, loss-ulb:0.0396, weight:2.00, lr:0.0002
[06:02:44.139] iteration:11876  t-loss:0.2447, loss-lb:0.2041, loss-ulb:0.0203, weight:2.00, lr:0.0002
[06:02:44.487] iteration:11877  t-loss:0.5418, loss-lb:0.3869, loss-ulb:0.0775, weight:2.00, lr:0.0002
[06:02:44.826] iteration:11878  t-loss:0.2602, loss-lb:0.1644, loss-ulb:0.0479, weight:2.00, lr:0.0002
[06:02:45.156] iteration:11879  t-loss:0.3505, loss-lb:0.1681, loss-ulb:0.0912, weight:2.00, lr:0.0002
[06:02:45.492] iteration:11880  t-loss:0.2579, loss-lb:0.1597, loss-ulb:0.0491, weight:2.00, lr:0.0002
[06:02:45.814] iteration:11881  t-loss:0.2532, loss-lb:0.1599, loss-ulb:0.0467, weight:2.00, lr:0.0002
[06:02:46.174] iteration:11882  t-loss:0.2042, loss-lb:0.1300, loss-ulb:0.0371, weight:2.00, lr:0.0002
[06:02:46.507] iteration:11883  t-loss:0.2310, loss-lb:0.1507, loss-ulb:0.0402, weight:2.00, lr:0.0002
[06:02:46.843] iteration:11884  t-loss:0.6882, loss-lb:0.2746, loss-ulb:0.2068, weight:2.00, lr:0.0002
[06:02:47.163] iteration:11885  t-loss:0.2243, loss-lb:0.1899, loss-ulb:0.0172, weight:2.00, lr:0.0002
[06:02:47.489] iteration:11886  t-loss:0.3946, loss-lb:0.1746, loss-ulb:0.1100, weight:2.00, lr:0.0002
[06:02:47.826] iteration:11887  t-loss:0.3934, loss-lb:0.2210, loss-ulb:0.0862, weight:2.00, lr:0.0002
[06:02:48.171] iteration:11888  t-loss:0.4538, loss-lb:0.2965, loss-ulb:0.0786, weight:2.00, lr:0.0002
[06:02:48.494] iteration:11889  t-loss:0.2314, loss-lb:0.1356, loss-ulb:0.0479, weight:2.00, lr:0.0002
[06:02:48.821] iteration:11890  t-loss:0.2891, loss-lb:0.1721, loss-ulb:0.0585, weight:2.00, lr:0.0002
[06:02:49.142] iteration:11891  t-loss:0.2556, loss-lb:0.1269, loss-ulb:0.0643, weight:2.00, lr:0.0002
[06:02:49.468] iteration:11892  t-loss:0.3578, loss-lb:0.2599, loss-ulb:0.0489, weight:2.00, lr:0.0002
[06:02:49.781] iteration:11893  t-loss:0.2195, loss-lb:0.1564, loss-ulb:0.0316, weight:2.00, lr:0.0002
[06:02:50.099] iteration:11894  t-loss:0.2816, loss-lb:0.1678, loss-ulb:0.0569, weight:2.00, lr:0.0002
[06:02:50.414] iteration:11895  t-loss:0.2072, loss-lb:0.1718, loss-ulb:0.0177, weight:2.00, lr:0.0002
[06:02:50.732] iteration:11896  t-loss:0.4087, loss-lb:0.2338, loss-ulb:0.0875, weight:2.00, lr:0.0002
[06:02:51.054] iteration:11897  t-loss:0.4080, loss-lb:0.2267, loss-ulb:0.0907, weight:2.00, lr:0.0002
[06:02:51.385] iteration:11898  t-loss:0.2246, loss-lb:0.1964, loss-ulb:0.0141, weight:2.00, lr:0.0002
[06:02:51.716] iteration:11899  t-loss:0.1619, loss-lb:0.1339, loss-ulb:0.0140, weight:2.00, lr:0.0002
[06:02:52.051] iteration:11900  t-loss:0.1836, loss-lb:0.1335, loss-ulb:0.0251, weight:2.00, lr:0.0002
[06:02:53.655] iteration:11901  t-loss:0.2246, loss-lb:0.1776, loss-ulb:0.0235, weight:2.00, lr:0.0002
[06:02:53.991] iteration:11902  t-loss:0.1589, loss-lb:0.1131, loss-ulb:0.0229, weight:2.00, lr:0.0002
[06:02:54.324] iteration:11903  t-loss:0.2417, loss-lb:0.1192, loss-ulb:0.0612, weight:2.00, lr:0.0002
[06:02:54.653] iteration:11904  t-loss:0.2840, loss-lb:0.2001, loss-ulb:0.0420, weight:2.00, lr:0.0002
[06:02:54.991] iteration:11905  t-loss:0.6988, loss-lb:0.1471, loss-ulb:0.2759, weight:2.00, lr:0.0002
[06:02:55.324] iteration:11906  t-loss:0.5870, loss-lb:0.3159, loss-ulb:0.1356, weight:2.00, lr:0.0002
[06:02:55.652] iteration:11907  t-loss:0.3169, loss-lb:0.2802, loss-ulb:0.0183, weight:2.00, lr:0.0002
[06:02:55.979] iteration:11908  t-loss:0.2835, loss-lb:0.1473, loss-ulb:0.0681, weight:2.00, lr:0.0002
[06:02:56.295] iteration:11909  t-loss:0.3040, loss-lb:0.1938, loss-ulb:0.0551, weight:2.00, lr:0.0002
[06:02:56.622] iteration:11910  t-loss:0.3735, loss-lb:0.1852, loss-ulb:0.0942, weight:2.00, lr:0.0002
[06:02:56.943] iteration:11911  t-loss:1.0086, loss-lb:0.1327, loss-ulb:0.4380, weight:2.00, lr:0.0002
[06:02:57.265] iteration:11912  t-loss:0.2748, loss-lb:0.2270, loss-ulb:0.0239, weight:2.00, lr:0.0002
[06:02:57.584] iteration:11913  t-loss:0.3332, loss-lb:0.1515, loss-ulb:0.0908, weight:2.00, lr:0.0002
[06:02:57.902] iteration:11914  t-loss:0.3896, loss-lb:0.1488, loss-ulb:0.1204, weight:2.00, lr:0.0002
[06:02:58.221] iteration:11915  t-loss:0.4024, loss-lb:0.1837, loss-ulb:0.1093, weight:2.00, lr:0.0002
[06:02:58.539] iteration:11916  t-loss:0.1633, loss-lb:0.1204, loss-ulb:0.0214, weight:2.00, lr:0.0002
[06:02:58.864] iteration:11917  t-loss:0.2691, loss-lb:0.1855, loss-ulb:0.0418, weight:2.00, lr:0.0002
[06:02:59.180] iteration:11918  t-loss:0.2803, loss-lb:0.2258, loss-ulb:0.0273, weight:2.00, lr:0.0002
[06:02:59.497] iteration:11919  t-loss:0.3567, loss-lb:0.2016, loss-ulb:0.0776, weight:2.00, lr:0.0002
[06:02:59.812] iteration:11920  t-loss:0.2218, loss-lb:0.1424, loss-ulb:0.0397, weight:2.00, lr:0.0002
[06:03:00.130] iteration:11921  t-loss:0.1846, loss-lb:0.1552, loss-ulb:0.0147, weight:2.00, lr:0.0002
[06:03:00.449] iteration:11922  t-loss:0.1710, loss-lb:0.1355, loss-ulb:0.0177, weight:2.00, lr:0.0002
[06:03:00.781] iteration:11923  t-loss:0.4454, loss-lb:0.3079, loss-ulb:0.0687, weight:2.00, lr:0.0002
[06:03:01.108] iteration:11924  t-loss:0.3830, loss-lb:0.1516, loss-ulb:0.1157, weight:2.00, lr:0.0002
[06:03:01.426] iteration:11925  t-loss:0.3582, loss-lb:0.3015, loss-ulb:0.0283, weight:2.00, lr:0.0002
[06:05:13.312] iteration 11925 : dice_score: 0.851920 best_dice: 0.852700
[06:05:13.312]  <<Test>> - Ep:476  - Dice-S/T:85.01/85.19, Best-S:85.16, Best-T:85.27
[06:05:13.312]           - AvgLoss(lb/ulb/all):0.19/0.08/0.36
[06:05:14.632] iteration:11926  t-loss:0.3947, loss-lb:0.2720, loss-ulb:0.0614, weight:2.00, lr:0.0002
[06:05:14.973] iteration:11927  t-loss:0.2936, loss-lb:0.1518, loss-ulb:0.0709, weight:2.00, lr:0.0002
[06:05:15.308] iteration:11928  t-loss:0.3781, loss-lb:0.1827, loss-ulb:0.0977, weight:2.00, lr:0.0002
[06:05:15.633] iteration:11929  t-loss:0.5466, loss-lb:0.1371, loss-ulb:0.2048, weight:2.00, lr:0.0002
[06:05:15.959] iteration:11930  t-loss:0.2001, loss-lb:0.1368, loss-ulb:0.0316, weight:2.00, lr:0.0002
[06:05:16.299] iteration:11931  t-loss:0.2604, loss-lb:0.1494, loss-ulb:0.0555, weight:2.00, lr:0.0002
[06:05:16.625] iteration:11932  t-loss:0.4630, loss-lb:0.2108, loss-ulb:0.1261, weight:2.00, lr:0.0002
[06:05:16.953] iteration:11933  t-loss:0.4014, loss-lb:0.1554, loss-ulb:0.1230, weight:2.00, lr:0.0002
[06:05:17.275] iteration:11934  t-loss:0.4573, loss-lb:0.2700, loss-ulb:0.0937, weight:2.00, lr:0.0002
[06:05:17.594] iteration:11935  t-loss:0.3101, loss-lb:0.1363, loss-ulb:0.0869, weight:2.00, lr:0.0002
[06:05:17.918] iteration:11936  t-loss:0.4329, loss-lb:0.2781, loss-ulb:0.0774, weight:2.00, lr:0.0002
[06:05:18.242] iteration:11937  t-loss:0.3028, loss-lb:0.1966, loss-ulb:0.0531, weight:2.00, lr:0.0002
[06:05:18.561] iteration:11938  t-loss:0.3186, loss-lb:0.1407, loss-ulb:0.0889, weight:2.00, lr:0.0002
[06:05:18.880] iteration:11939  t-loss:0.2329, loss-lb:0.1153, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:05:19.202] iteration:11940  t-loss:0.2690, loss-lb:0.1588, loss-ulb:0.0551, weight:2.00, lr:0.0002
[06:05:19.523] iteration:11941  t-loss:0.3355, loss-lb:0.1676, loss-ulb:0.0840, weight:2.00, lr:0.0002
[06:05:19.843] iteration:11942  t-loss:0.3282, loss-lb:0.1589, loss-ulb:0.0847, weight:2.00, lr:0.0002
[06:05:20.162] iteration:11943  t-loss:0.3914, loss-lb:0.1951, loss-ulb:0.0981, weight:2.00, lr:0.0002
[06:05:20.477] iteration:11944  t-loss:0.2087, loss-lb:0.1786, loss-ulb:0.0151, weight:2.00, lr:0.0002
[06:05:20.794] iteration:11945  t-loss:0.2928, loss-lb:0.2115, loss-ulb:0.0407, weight:2.00, lr:0.0002
[06:05:21.112] iteration:11946  t-loss:0.3103, loss-lb:0.2074, loss-ulb:0.0514, weight:2.00, lr:0.0002
[06:05:21.426] iteration:11947  t-loss:0.2747, loss-lb:0.1145, loss-ulb:0.0801, weight:2.00, lr:0.0002
[06:05:21.743] iteration:11948  t-loss:0.2431, loss-lb:0.1046, loss-ulb:0.0693, weight:2.00, lr:0.0002
[06:05:22.057] iteration:11949  t-loss:0.2730, loss-lb:0.2385, loss-ulb:0.0172, weight:2.00, lr:0.0002
[06:05:22.376] iteration:11950  t-loss:0.2838, loss-lb:0.1724, loss-ulb:0.0557, weight:2.00, lr:0.0002
[06:05:23.779] iteration:11951  t-loss:0.4286, loss-lb:0.1323, loss-ulb:0.1481, weight:2.00, lr:0.0002
[06:05:24.111] iteration:11952  t-loss:0.1940, loss-lb:0.1496, loss-ulb:0.0222, weight:2.00, lr:0.0002
[06:05:24.435] iteration:11953  t-loss:0.2754, loss-lb:0.2393, loss-ulb:0.0181, weight:2.00, lr:0.0002
[06:05:24.756] iteration:11954  t-loss:0.2566, loss-lb:0.1683, loss-ulb:0.0442, weight:2.00, lr:0.0002
[06:05:25.070] iteration:11955  t-loss:0.2922, loss-lb:0.2021, loss-ulb:0.0451, weight:2.00, lr:0.0002
[06:05:25.386] iteration:11956  t-loss:0.3376, loss-lb:0.1452, loss-ulb:0.0962, weight:2.00, lr:0.0002
[06:05:25.703] iteration:11957  t-loss:0.8296, loss-lb:0.3214, loss-ulb:0.2541, weight:2.00, lr:0.0002
[06:05:26.023] iteration:11958  t-loss:0.4036, loss-lb:0.2275, loss-ulb:0.0881, weight:2.00, lr:0.0002
[06:05:26.338] iteration:11959  t-loss:0.3185, loss-lb:0.2030, loss-ulb:0.0578, weight:2.00, lr:0.0002
[06:05:26.660] iteration:11960  t-loss:0.2700, loss-lb:0.1773, loss-ulb:0.0464, weight:2.00, lr:0.0002
[06:05:26.978] iteration:11961  t-loss:0.2800, loss-lb:0.1547, loss-ulb:0.0627, weight:2.00, lr:0.0002
[06:05:27.298] iteration:11962  t-loss:0.3344, loss-lb:0.1887, loss-ulb:0.0728, weight:2.00, lr:0.0002
[06:05:27.617] iteration:11963  t-loss:0.5605, loss-lb:0.2189, loss-ulb:0.1708, weight:2.00, lr:0.0002
[06:05:27.937] iteration:11964  t-loss:0.3046, loss-lb:0.1305, loss-ulb:0.0870, weight:2.00, lr:0.0002
[06:05:28.258] iteration:11965  t-loss:0.5679, loss-lb:0.2075, loss-ulb:0.1802, weight:2.00, lr:0.0002
[06:05:28.575] iteration:11966  t-loss:0.1960, loss-lb:0.1667, loss-ulb:0.0146, weight:2.00, lr:0.0002
[06:05:28.900] iteration:11967  t-loss:0.4090, loss-lb:0.2050, loss-ulb:0.1020, weight:2.00, lr:0.0002
[06:05:29.218] iteration:11968  t-loss:0.3605, loss-lb:0.2594, loss-ulb:0.0506, weight:2.00, lr:0.0002
[06:05:29.539] iteration:11969  t-loss:0.5997, loss-lb:0.2315, loss-ulb:0.1841, weight:2.00, lr:0.0002
[06:05:29.856] iteration:11970  t-loss:0.2676, loss-lb:0.1588, loss-ulb:0.0544, weight:2.00, lr:0.0002
[06:05:30.171] iteration:11971  t-loss:0.2626, loss-lb:0.1957, loss-ulb:0.0335, weight:2.00, lr:0.0002
[06:05:30.486] iteration:11972  t-loss:0.3557, loss-lb:0.1284, loss-ulb:0.1137, weight:2.00, lr:0.0002
[06:05:30.801] iteration:11973  t-loss:0.2066, loss-lb:0.1563, loss-ulb:0.0251, weight:2.00, lr:0.0002
[06:05:31.116] iteration:11974  t-loss:0.2748, loss-lb:0.1737, loss-ulb:0.0505, weight:2.00, lr:0.0002
[06:05:31.433] iteration:11975  t-loss:0.1725, loss-lb:0.1458, loss-ulb:0.0134, weight:2.00, lr:0.0002
[06:05:33.192] iteration:11976  t-loss:0.3114, loss-lb:0.2113, loss-ulb:0.0501, weight:2.00, lr:0.0002
[06:05:33.535] iteration:11977  t-loss:0.2639, loss-lb:0.2364, loss-ulb:0.0137, weight:2.00, lr:0.0002
[06:05:33.877] iteration:11978  t-loss:0.2803, loss-lb:0.1647, loss-ulb:0.0578, weight:2.00, lr:0.0002
[06:05:34.210] iteration:11979  t-loss:0.2087, loss-lb:0.1746, loss-ulb:0.0171, weight:2.00, lr:0.0002
[06:05:34.541] iteration:11980  t-loss:0.4079, loss-lb:0.1151, loss-ulb:0.1464, weight:2.00, lr:0.0002
[06:05:34.878] iteration:11981  t-loss:0.2997, loss-lb:0.1943, loss-ulb:0.0527, weight:2.00, lr:0.0002
[06:05:35.215] iteration:11982  t-loss:0.3892, loss-lb:0.1310, loss-ulb:0.1291, weight:2.00, lr:0.0002
[06:05:35.539] iteration:11983  t-loss:0.1680, loss-lb:0.1120, loss-ulb:0.0280, weight:2.00, lr:0.0002
[06:05:35.864] iteration:11984  t-loss:0.2182, loss-lb:0.1899, loss-ulb:0.0141, weight:2.00, lr:0.0002
[06:05:36.186] iteration:11985  t-loss:0.4263, loss-lb:0.2833, loss-ulb:0.0715, weight:2.00, lr:0.0002
[06:05:36.509] iteration:11986  t-loss:0.2403, loss-lb:0.1914, loss-ulb:0.0244, weight:2.00, lr:0.0002
[06:05:36.839] iteration:11987  t-loss:0.3944, loss-lb:0.2256, loss-ulb:0.0844, weight:2.00, lr:0.0002
[06:05:37.159] iteration:11988  t-loss:0.2169, loss-lb:0.1948, loss-ulb:0.0110, weight:2.00, lr:0.0002
[06:05:37.484] iteration:11989  t-loss:0.3634, loss-lb:0.1357, loss-ulb:0.1138, weight:2.00, lr:0.0002
[06:05:37.808] iteration:11990  t-loss:0.3446, loss-lb:0.1517, loss-ulb:0.0965, weight:2.00, lr:0.0002
[06:05:38.129] iteration:11991  t-loss:0.2573, loss-lb:0.2265, loss-ulb:0.0154, weight:2.00, lr:0.0002
[06:05:38.449] iteration:11992  t-loss:0.3464, loss-lb:0.1711, loss-ulb:0.0876, weight:2.00, lr:0.0002
[06:05:38.767] iteration:11993  t-loss:0.4441, loss-lb:0.2987, loss-ulb:0.0727, weight:2.00, lr:0.0002
[06:05:39.083] iteration:11994  t-loss:0.2681, loss-lb:0.1598, loss-ulb:0.0542, weight:2.00, lr:0.0002
[06:05:39.398] iteration:11995  t-loss:0.3054, loss-lb:0.1047, loss-ulb:0.1004, weight:2.00, lr:0.0002
[06:05:39.714] iteration:11996  t-loss:0.2716, loss-lb:0.1951, loss-ulb:0.0383, weight:2.00, lr:0.0002
[06:05:40.038] iteration:11997  t-loss:0.2542, loss-lb:0.1585, loss-ulb:0.0478, weight:2.00, lr:0.0002
[06:05:40.360] iteration:11998  t-loss:0.2330, loss-lb:0.1747, loss-ulb:0.0292, weight:2.00, lr:0.0002
[06:05:40.685] iteration:11999  t-loss:0.2778, loss-lb:0.1439, loss-ulb:0.0670, weight:2.00, lr:0.0002
[06:05:41.007] iteration:12000  t-loss:0.2055, loss-lb:0.1634, loss-ulb:0.0210, weight:2.00, lr:0.0002
[06:05:42.341] iteration:12001  t-loss:0.3372, loss-lb:0.2628, loss-ulb:0.0372, weight:2.00, lr:0.0002
[06:05:42.691] iteration:12002  t-loss:0.3276, loss-lb:0.2352, loss-ulb:0.0462, weight:2.00, lr:0.0002
[06:05:43.034] iteration:12003  t-loss:0.3295, loss-lb:0.1941, loss-ulb:0.0677, weight:2.00, lr:0.0002
[06:05:43.362] iteration:12004  t-loss:0.2367, loss-lb:0.1750, loss-ulb:0.0309, weight:2.00, lr:0.0002
[06:05:43.706] iteration:12005  t-loss:0.3693, loss-lb:0.1861, loss-ulb:0.0916, weight:2.00, lr:0.0002
[06:05:44.041] iteration:12006  t-loss:0.5754, loss-lb:0.3206, loss-ulb:0.1274, weight:2.00, lr:0.0002
[06:05:44.362] iteration:12007  t-loss:0.1960, loss-lb:0.1509, loss-ulb:0.0225, weight:2.00, lr:0.0002
[06:05:44.691] iteration:12008  t-loss:0.3449, loss-lb:0.2274, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:05:45.016] iteration:12009  t-loss:0.3314, loss-lb:0.2245, loss-ulb:0.0534, weight:2.00, lr:0.0002
[06:05:45.338] iteration:12010  t-loss:0.2802, loss-lb:0.1542, loss-ulb:0.0630, weight:2.00, lr:0.0002
[06:05:45.664] iteration:12011  t-loss:0.2702, loss-lb:0.2139, loss-ulb:0.0282, weight:2.00, lr:0.0002
[06:05:45.986] iteration:12012  t-loss:0.1991, loss-lb:0.1699, loss-ulb:0.0146, weight:2.00, lr:0.0002
[06:05:46.303] iteration:12013  t-loss:0.1636, loss-lb:0.1342, loss-ulb:0.0147, weight:2.00, lr:0.0002
[06:05:46.624] iteration:12014  t-loss:0.4054, loss-lb:0.2235, loss-ulb:0.0909, weight:2.00, lr:0.0002
[06:05:46.943] iteration:12015  t-loss:0.3522, loss-lb:0.2431, loss-ulb:0.0545, weight:2.00, lr:0.0002
[06:05:47.259] iteration:12016  t-loss:0.2636, loss-lb:0.1546, loss-ulb:0.0545, weight:2.00, lr:0.0002
[06:05:47.578] iteration:12017  t-loss:0.3916, loss-lb:0.2560, loss-ulb:0.0678, weight:2.00, lr:0.0002
[06:05:47.894] iteration:12018  t-loss:0.2999, loss-lb:0.1294, loss-ulb:0.0852, weight:2.00, lr:0.0002
[06:05:48.208] iteration:12019  t-loss:0.1791, loss-lb:0.1403, loss-ulb:0.0194, weight:2.00, lr:0.0002
[06:05:48.528] iteration:12020  t-loss:0.2951, loss-lb:0.1637, loss-ulb:0.0657, weight:2.00, lr:0.0002
[06:05:48.852] iteration:12021  t-loss:0.3304, loss-lb:0.1686, loss-ulb:0.0809, weight:2.00, lr:0.0002
[06:05:49.180] iteration:12022  t-loss:0.3590, loss-lb:0.1360, loss-ulb:0.1115, weight:2.00, lr:0.0002
[06:05:49.508] iteration:12023  t-loss:0.3767, loss-lb:0.2032, loss-ulb:0.0868, weight:2.00, lr:0.0002
[06:05:49.828] iteration:12024  t-loss:0.1866, loss-lb:0.1483, loss-ulb:0.0192, weight:2.00, lr:0.0002
[06:05:50.146] iteration:12025  t-loss:0.3538, loss-lb:0.1872, loss-ulb:0.0833, weight:2.00, lr:0.0002
[06:08:02.135] iteration 12025 : dice_score: 0.852488 best_dice: 0.852700
[06:08:02.135]  <<Test>> - Ep:480  - Dice-S/T:85.01/85.25, Best-S:85.16, Best-T:85.27
[06:08:02.135]           - AvgLoss(lb/ulb/all):0.19/0.06/0.31
[06:08:03.475] iteration:12026  t-loss:0.1518, loss-lb:0.1292, loss-ulb:0.0113, weight:2.00, lr:0.0002
[06:08:03.821] iteration:12027  t-loss:0.3770, loss-lb:0.1359, loss-ulb:0.1205, weight:2.00, lr:0.0002
[06:08:04.163] iteration:12028  t-loss:0.4499, loss-lb:0.2129, loss-ulb:0.1185, weight:2.00, lr:0.0002
[06:08:04.485] iteration:12029  t-loss:0.3928, loss-lb:0.3617, loss-ulb:0.0156, weight:2.00, lr:0.0002
[06:08:04.816] iteration:12030  t-loss:0.4755, loss-lb:0.3363, loss-ulb:0.0696, weight:2.00, lr:0.0002
[06:08:05.138] iteration:12031  t-loss:0.3098, loss-lb:0.1686, loss-ulb:0.0706, weight:2.00, lr:0.0002
[06:08:05.460] iteration:12032  t-loss:0.2567, loss-lb:0.1257, loss-ulb:0.0655, weight:2.00, lr:0.0002
[06:08:05.782] iteration:12033  t-loss:0.3936, loss-lb:0.1485, loss-ulb:0.1226, weight:2.00, lr:0.0002
[06:08:06.103] iteration:12034  t-loss:0.2571, loss-lb:0.1690, loss-ulb:0.0441, weight:2.00, lr:0.0002
[06:08:06.423] iteration:12035  t-loss:0.3167, loss-lb:0.1629, loss-ulb:0.0769, weight:2.00, lr:0.0002
[06:08:06.745] iteration:12036  t-loss:0.1867, loss-lb:0.1625, loss-ulb:0.0121, weight:2.00, lr:0.0002
[06:08:07.065] iteration:12037  t-loss:0.2585, loss-lb:0.1596, loss-ulb:0.0494, weight:2.00, lr:0.0002
[06:08:07.386] iteration:12038  t-loss:0.2546, loss-lb:0.1147, loss-ulb:0.0699, weight:2.00, lr:0.0002
[06:08:07.705] iteration:12039  t-loss:0.2624, loss-lb:0.1987, loss-ulb:0.0318, weight:2.00, lr:0.0002
[06:08:08.022] iteration:12040  t-loss:0.1905, loss-lb:0.1563, loss-ulb:0.0171, weight:2.00, lr:0.0002
[06:08:08.338] iteration:12041  t-loss:0.1695, loss-lb:0.1314, loss-ulb:0.0191, weight:2.00, lr:0.0002
[06:08:08.661] iteration:12042  t-loss:0.1841, loss-lb:0.1632, loss-ulb:0.0104, weight:2.00, lr:0.0002
[06:08:08.975] iteration:12043  t-loss:0.3901, loss-lb:0.2539, loss-ulb:0.0681, weight:2.00, lr:0.0002
[06:08:09.290] iteration:12044  t-loss:0.2988, loss-lb:0.2222, loss-ulb:0.0383, weight:2.00, lr:0.0002
[06:08:09.603] iteration:12045  t-loss:0.3170, loss-lb:0.1916, loss-ulb:0.0627, weight:2.00, lr:0.0002
[06:08:09.918] iteration:12046  t-loss:0.2028, loss-lb:0.1526, loss-ulb:0.0251, weight:2.00, lr:0.0002
[06:08:10.234] iteration:12047  t-loss:0.2510, loss-lb:0.2127, loss-ulb:0.0191, weight:2.00, lr:0.0002
[06:08:10.553] iteration:12048  t-loss:0.3758, loss-lb:0.1763, loss-ulb:0.0998, weight:2.00, lr:0.0002
[06:08:10.869] iteration:12049  t-loss:0.1738, loss-lb:0.1432, loss-ulb:0.0153, weight:2.00, lr:0.0002
[06:08:11.185] iteration:12050  t-loss:0.2601, loss-lb:0.1584, loss-ulb:0.0509, weight:2.00, lr:0.0002
[06:08:12.674] iteration:12051  t-loss:0.2627, loss-lb:0.2297, loss-ulb:0.0165, weight:2.00, lr:0.0002
[06:08:13.013] iteration:12052  t-loss:0.2500, loss-lb:0.2238, loss-ulb:0.0131, weight:2.00, lr:0.0002
[06:08:13.348] iteration:12053  t-loss:0.2659, loss-lb:0.2017, loss-ulb:0.0321, weight:2.00, lr:0.0002
[06:08:13.676] iteration:12054  t-loss:0.4817, loss-lb:0.2236, loss-ulb:0.1290, weight:2.00, lr:0.0002
[06:08:13.993] iteration:12055  t-loss:0.3293, loss-lb:0.1405, loss-ulb:0.0944, weight:2.00, lr:0.0002
[06:08:14.313] iteration:12056  t-loss:0.2900, loss-lb:0.2483, loss-ulb:0.0208, weight:2.00, lr:0.0002
[06:08:14.632] iteration:12057  t-loss:0.3563, loss-lb:0.2102, loss-ulb:0.0730, weight:2.00, lr:0.0002
[06:08:14.948] iteration:12058  t-loss:0.2473, loss-lb:0.1296, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:08:15.268] iteration:12059  t-loss:0.2457, loss-lb:0.2076, loss-ulb:0.0190, weight:2.00, lr:0.0002
[06:08:15.591] iteration:12060  t-loss:0.3375, loss-lb:0.1992, loss-ulb:0.0691, weight:2.00, lr:0.0002
[06:08:15.908] iteration:12061  t-loss:0.2251, loss-lb:0.1362, loss-ulb:0.0444, weight:2.00, lr:0.0002
[06:08:16.228] iteration:12062  t-loss:0.3463, loss-lb:0.1790, loss-ulb:0.0836, weight:2.00, lr:0.0002
[06:08:16.547] iteration:12063  t-loss:0.3706, loss-lb:0.1555, loss-ulb:0.1076, weight:2.00, lr:0.0002
[06:08:16.897] iteration:12064  t-loss:0.3213, loss-lb:0.1854, loss-ulb:0.0680, weight:2.00, lr:0.0002
[06:08:17.237] iteration:12065  t-loss:0.3145, loss-lb:0.1624, loss-ulb:0.0761, weight:2.00, lr:0.0002
[06:08:17.600] iteration:12066  t-loss:0.2808, loss-lb:0.1525, loss-ulb:0.0642, weight:2.00, lr:0.0002
[06:08:17.946] iteration:12067  t-loss:0.3114, loss-lb:0.1714, loss-ulb:0.0700, weight:2.00, lr:0.0002
[06:08:18.275] iteration:12068  t-loss:0.3036, loss-lb:0.2600, loss-ulb:0.0218, weight:2.00, lr:0.0002
[06:08:18.597] iteration:12069  t-loss:0.3131, loss-lb:0.1127, loss-ulb:0.1002, weight:2.00, lr:0.0002
[06:08:18.914] iteration:12070  t-loss:0.2907, loss-lb:0.1598, loss-ulb:0.0655, weight:2.00, lr:0.0002
[06:08:19.232] iteration:12071  t-loss:0.2647, loss-lb:0.1482, loss-ulb:0.0582, weight:2.00, lr:0.0002
[06:08:19.551] iteration:12072  t-loss:0.3377, loss-lb:0.2198, loss-ulb:0.0590, weight:2.00, lr:0.0002
[06:08:19.866] iteration:12073  t-loss:0.2937, loss-lb:0.1897, loss-ulb:0.0520, weight:2.00, lr:0.0002
[06:08:20.184] iteration:12074  t-loss:0.2653, loss-lb:0.2274, loss-ulb:0.0190, weight:2.00, lr:0.0002
[06:08:20.501] iteration:12075  t-loss:0.2548, loss-lb:0.1637, loss-ulb:0.0456, weight:2.00, lr:0.0002
[06:08:22.046] iteration:12076  t-loss:0.3914, loss-lb:0.1799, loss-ulb:0.1057, weight:2.00, lr:0.0002
[06:08:22.399] iteration:12077  t-loss:0.3672, loss-lb:0.1770, loss-ulb:0.0951, weight:2.00, lr:0.0002
[06:08:22.742] iteration:12078  t-loss:0.1876, loss-lb:0.1403, loss-ulb:0.0237, weight:2.00, lr:0.0002
[06:08:23.082] iteration:12079  t-loss:0.4566, loss-lb:0.2311, loss-ulb:0.1127, weight:2.00, lr:0.0002
[06:08:23.402] iteration:12080  t-loss:0.1343, loss-lb:0.1015, loss-ulb:0.0164, weight:2.00, lr:0.0002
[06:08:23.720] iteration:12081  t-loss:0.2405, loss-lb:0.1808, loss-ulb:0.0298, weight:2.00, lr:0.0002
[06:08:24.037] iteration:12082  t-loss:0.2805, loss-lb:0.2488, loss-ulb:0.0158, weight:2.00, lr:0.0002
[06:08:24.354] iteration:12083  t-loss:0.3513, loss-lb:0.1566, loss-ulb:0.0974, weight:2.00, lr:0.0002
[06:08:24.671] iteration:12084  t-loss:0.3027, loss-lb:0.1851, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:08:24.991] iteration:12085  t-loss:0.3279, loss-lb:0.2404, loss-ulb:0.0438, weight:2.00, lr:0.0002
[06:08:25.310] iteration:12086  t-loss:0.3941, loss-lb:0.2650, loss-ulb:0.0646, weight:2.00, lr:0.0002
[06:08:25.635] iteration:12087  t-loss:0.3285, loss-lb:0.2306, loss-ulb:0.0489, weight:2.00, lr:0.0002
[06:08:25.967] iteration:12088  t-loss:0.2963, loss-lb:0.1872, loss-ulb:0.0545, weight:2.00, lr:0.0002
[06:08:26.299] iteration:12089  t-loss:0.2580, loss-lb:0.1444, loss-ulb:0.0568, weight:2.00, lr:0.0002
[06:08:26.631] iteration:12090  t-loss:0.2515, loss-lb:0.2180, loss-ulb:0.0167, weight:2.00, lr:0.0002
[06:08:26.961] iteration:12091  t-loss:0.2438, loss-lb:0.2069, loss-ulb:0.0185, weight:2.00, lr:0.0002
[06:08:27.292] iteration:12092  t-loss:0.3797, loss-lb:0.2406, loss-ulb:0.0695, weight:2.00, lr:0.0002
[06:08:27.616] iteration:12093  t-loss:0.3671, loss-lb:0.1965, loss-ulb:0.0853, weight:2.00, lr:0.0002
[06:08:27.937] iteration:12094  t-loss:0.2040, loss-lb:0.1731, loss-ulb:0.0155, weight:2.00, lr:0.0002
[06:08:28.253] iteration:12095  t-loss:0.3384, loss-lb:0.1382, loss-ulb:0.1001, weight:2.00, lr:0.0002
[06:08:28.569] iteration:12096  t-loss:0.3108, loss-lb:0.1824, loss-ulb:0.0642, weight:2.00, lr:0.0002
[06:08:28.888] iteration:12097  t-loss:0.4041, loss-lb:0.2074, loss-ulb:0.0984, weight:2.00, lr:0.0002
[06:08:29.204] iteration:12098  t-loss:0.2953, loss-lb:0.1982, loss-ulb:0.0485, weight:2.00, lr:0.0002
[06:08:29.527] iteration:12099  t-loss:0.3330, loss-lb:0.1550, loss-ulb:0.0890, weight:2.00, lr:0.0002
[06:08:29.843] iteration:12100  t-loss:0.2207, loss-lb:0.1230, loss-ulb:0.0489, weight:2.00, lr:0.0002
[06:08:31.516] iteration:12101  t-loss:0.3994, loss-lb:0.2223, loss-ulb:0.0885, weight:2.00, lr:0.0002
[06:08:31.862] iteration:12102  t-loss:0.2182, loss-lb:0.1848, loss-ulb:0.0167, weight:2.00, lr:0.0002
[06:08:32.195] iteration:12103  t-loss:0.2909, loss-lb:0.1649, loss-ulb:0.0630, weight:2.00, lr:0.0002
[06:08:32.517] iteration:12104  t-loss:0.2385, loss-lb:0.1826, loss-ulb:0.0280, weight:2.00, lr:0.0002
[06:08:32.837] iteration:12105  t-loss:0.3762, loss-lb:0.1936, loss-ulb:0.0913, weight:2.00, lr:0.0002
[06:08:33.153] iteration:12106  t-loss:0.2226, loss-lb:0.1225, loss-ulb:0.0500, weight:2.00, lr:0.0002
[06:08:33.473] iteration:12107  t-loss:0.2241, loss-lb:0.1382, loss-ulb:0.0430, weight:2.00, lr:0.0002
[06:08:33.790] iteration:12108  t-loss:0.3815, loss-lb:0.1579, loss-ulb:0.1118, weight:2.00, lr:0.0002
[06:08:34.113] iteration:12109  t-loss:0.2774, loss-lb:0.1315, loss-ulb:0.0730, weight:2.00, lr:0.0002
[06:08:34.451] iteration:12110  t-loss:0.4270, loss-lb:0.1777, loss-ulb:0.1246, weight:2.00, lr:0.0002
[06:08:34.802] iteration:12111  t-loss:0.2771, loss-lb:0.2498, loss-ulb:0.0137, weight:2.00, lr:0.0002
[06:08:35.135] iteration:12112  t-loss:0.3105, loss-lb:0.1162, loss-ulb:0.0971, weight:2.00, lr:0.0002
[06:08:35.464] iteration:12113  t-loss:0.3356, loss-lb:0.1472, loss-ulb:0.0942, weight:2.00, lr:0.0002
[06:08:35.793] iteration:12114  t-loss:0.1966, loss-lb:0.1584, loss-ulb:0.0191, weight:2.00, lr:0.0002
[06:08:36.118] iteration:12115  t-loss:0.3408, loss-lb:0.2969, loss-ulb:0.0220, weight:2.00, lr:0.0002
[06:08:36.440] iteration:12116  t-loss:0.2152, loss-lb:0.1801, loss-ulb:0.0175, weight:2.00, lr:0.0002
[06:08:36.757] iteration:12117  t-loss:0.1612, loss-lb:0.1310, loss-ulb:0.0151, weight:2.00, lr:0.0002
[06:08:37.073] iteration:12118  t-loss:0.2262, loss-lb:0.1473, loss-ulb:0.0395, weight:2.00, lr:0.0002
[06:08:37.390] iteration:12119  t-loss:0.2588, loss-lb:0.2269, loss-ulb:0.0159, weight:2.00, lr:0.0002
[06:08:37.707] iteration:12120  t-loss:0.3016, loss-lb:0.2691, loss-ulb:0.0162, weight:2.00, lr:0.0002
[06:08:38.028] iteration:12121  t-loss:0.2367, loss-lb:0.1434, loss-ulb:0.0467, weight:2.00, lr:0.0002
[06:08:38.345] iteration:12122  t-loss:0.2169, loss-lb:0.1372, loss-ulb:0.0399, weight:2.00, lr:0.0002
[06:08:38.661] iteration:12123  t-loss:0.1787, loss-lb:0.1483, loss-ulb:0.0152, weight:2.00, lr:0.0002
[06:08:38.979] iteration:12124  t-loss:0.3331, loss-lb:0.1800, loss-ulb:0.0765, weight:2.00, lr:0.0002
[06:08:39.298] iteration:12125  t-loss:0.4125, loss-lb:0.2432, loss-ulb:0.0846, weight:2.00, lr:0.0002
[06:10:53.526] iteration 12125 : dice_score: 0.852579 best_dice: 0.852700
[06:10:53.526]  <<Test>> - Ep:484  - Dice-S/T:85.20/85.26, Best-S:85.20, Best-T:85.27
[06:10:53.526]           - AvgLoss(lb/ulb/all):0.18/0.05/0.28
[06:10:54.817] iteration:12126  t-loss:0.2557, loss-lb:0.1498, loss-ulb:0.0530, weight:2.00, lr:0.0002
[06:10:55.153] iteration:12127  t-loss:0.3382, loss-lb:0.2594, loss-ulb:0.0394, weight:2.00, lr:0.0002
[06:10:55.477] iteration:12128  t-loss:0.2365, loss-lb:0.1487, loss-ulb:0.0439, weight:2.00, lr:0.0002
[06:10:55.815] iteration:12129  t-loss:0.4022, loss-lb:0.2677, loss-ulb:0.0672, weight:2.00, lr:0.0002
[06:10:56.135] iteration:12130  t-loss:0.2799, loss-lb:0.1303, loss-ulb:0.0748, weight:2.00, lr:0.0002
[06:10:56.460] iteration:12131  t-loss:0.2627, loss-lb:0.1409, loss-ulb:0.0609, weight:2.00, lr:0.0002
[06:10:56.778] iteration:12132  t-loss:0.3072, loss-lb:0.1600, loss-ulb:0.0736, weight:2.00, lr:0.0002
[06:10:57.098] iteration:12133  t-loss:0.2254, loss-lb:0.1812, loss-ulb:0.0221, weight:2.00, lr:0.0002
[06:10:57.420] iteration:12134  t-loss:0.2321, loss-lb:0.1880, loss-ulb:0.0220, weight:2.00, lr:0.0002
[06:10:57.741] iteration:12135  t-loss:0.3672, loss-lb:0.2378, loss-ulb:0.0647, weight:2.00, lr:0.0002
[06:10:58.076] iteration:12136  t-loss:0.2769, loss-lb:0.1840, loss-ulb:0.0465, weight:2.00, lr:0.0002
[06:10:58.406] iteration:12137  t-loss:0.4028, loss-lb:0.1328, loss-ulb:0.1350, weight:2.00, lr:0.0002
[06:10:58.744] iteration:12138  t-loss:0.3849, loss-lb:0.1571, loss-ulb:0.1139, weight:2.00, lr:0.0002
[06:10:59.100] iteration:12139  t-loss:0.3167, loss-lb:0.2801, loss-ulb:0.0183, weight:2.00, lr:0.0002
[06:10:59.454] iteration:12140  t-loss:0.2244, loss-lb:0.1421, loss-ulb:0.0411, weight:2.00, lr:0.0002
[06:10:59.799] iteration:12141  t-loss:0.2627, loss-lb:0.1636, loss-ulb:0.0496, weight:2.00, lr:0.0002
[06:11:00.138] iteration:12142  t-loss:0.2966, loss-lb:0.1575, loss-ulb:0.0695, weight:2.00, lr:0.0002
[06:11:00.472] iteration:12143  t-loss:0.2824, loss-lb:0.2022, loss-ulb:0.0401, weight:2.00, lr:0.0002
[06:11:00.797] iteration:12144  t-loss:0.4358, loss-lb:0.2233, loss-ulb:0.1062, weight:2.00, lr:0.0002
[06:11:01.116] iteration:12145  t-loss:0.2727, loss-lb:0.1283, loss-ulb:0.0722, weight:2.00, lr:0.0002
[06:11:01.435] iteration:12146  t-loss:0.3498, loss-lb:0.2890, loss-ulb:0.0304, weight:2.00, lr:0.0002
[06:11:01.755] iteration:12147  t-loss:0.3636, loss-lb:0.2325, loss-ulb:0.0655, weight:2.00, lr:0.0002
[06:11:02.070] iteration:12148  t-loss:0.2651, loss-lb:0.1648, loss-ulb:0.0502, weight:2.00, lr:0.0002
[06:11:02.383] iteration:12149  t-loss:0.2066, loss-lb:0.1749, loss-ulb:0.0158, weight:2.00, lr:0.0002
[06:11:02.699] iteration:12150  t-loss:0.2631, loss-lb:0.1379, loss-ulb:0.0626, weight:2.00, lr:0.0002
[06:11:03.988] iteration:12151  t-loss:0.2589, loss-lb:0.1474, loss-ulb:0.0558, weight:2.00, lr:0.0002
[06:11:04.316] iteration:12152  t-loss:0.2486, loss-lb:0.1439, loss-ulb:0.0523, weight:2.00, lr:0.0002
[06:11:04.636] iteration:12153  t-loss:0.2243, loss-lb:0.1363, loss-ulb:0.0440, weight:2.00, lr:0.0002
[06:11:04.953] iteration:12154  t-loss:0.1672, loss-lb:0.1180, loss-ulb:0.0246, weight:2.00, lr:0.0002
[06:11:05.276] iteration:12155  t-loss:0.2760, loss-lb:0.2526, loss-ulb:0.0117, weight:2.00, lr:0.0002
[06:11:05.594] iteration:12156  t-loss:0.3846, loss-lb:0.1972, loss-ulb:0.0937, weight:2.00, lr:0.0002
[06:11:05.908] iteration:12157  t-loss:0.2638, loss-lb:0.1560, loss-ulb:0.0539, weight:2.00, lr:0.0002
[06:11:06.223] iteration:12158  t-loss:0.2938, loss-lb:0.1364, loss-ulb:0.0787, weight:2.00, lr:0.0002
[06:11:06.543] iteration:12159  t-loss:0.4032, loss-lb:0.2777, loss-ulb:0.0628, weight:2.00, lr:0.0002
[06:11:06.856] iteration:12160  t-loss:0.2113, loss-lb:0.1867, loss-ulb:0.0123, weight:2.00, lr:0.0002
[06:11:07.184] iteration:12161  t-loss:0.3917, loss-lb:0.1779, loss-ulb:0.1069, weight:2.00, lr:0.0002
[06:11:07.513] iteration:12162  t-loss:0.2664, loss-lb:0.1638, loss-ulb:0.0513, weight:2.00, lr:0.0002
[06:11:07.879] iteration:12163  t-loss:0.4742, loss-lb:0.2003, loss-ulb:0.1369, weight:2.00, lr:0.0002
[06:11:08.231] iteration:12164  t-loss:0.1740, loss-lb:0.1437, loss-ulb:0.0151, weight:2.00, lr:0.0002
[06:11:08.590] iteration:12165  t-loss:0.2383, loss-lb:0.1389, loss-ulb:0.0497, weight:2.00, lr:0.0002
[06:11:08.977] iteration:12166  t-loss:0.4022, loss-lb:0.2609, loss-ulb:0.0707, weight:2.00, lr:0.0002
[06:11:09.343] iteration:12167  t-loss:0.2939, loss-lb:0.1613, loss-ulb:0.0663, weight:2.00, lr:0.0002
[06:11:09.700] iteration:12168  t-loss:0.3150, loss-lb:0.1591, loss-ulb:0.0779, weight:2.00, lr:0.0002
[06:11:10.056] iteration:12169  t-loss:0.3537, loss-lb:0.3235, loss-ulb:0.0151, weight:2.00, lr:0.0002
[06:11:10.397] iteration:12170  t-loss:0.3892, loss-lb:0.2243, loss-ulb:0.0824, weight:2.00, lr:0.0002
[06:11:10.735] iteration:12171  t-loss:0.3215, loss-lb:0.2129, loss-ulb:0.0543, weight:2.00, lr:0.0002
[06:11:11.072] iteration:12172  t-loss:0.3539, loss-lb:0.2334, loss-ulb:0.0603, weight:2.00, lr:0.0002
[06:11:11.403] iteration:12173  t-loss:0.3047, loss-lb:0.1186, loss-ulb:0.0931, weight:2.00, lr:0.0002
[06:11:11.731] iteration:12174  t-loss:0.3985, loss-lb:0.1916, loss-ulb:0.1035, weight:2.00, lr:0.0002
[06:11:12.063] iteration:12175  t-loss:0.3081, loss-lb:0.1514, loss-ulb:0.0784, weight:2.00, lr:0.0002
[06:11:13.856] iteration:12176  t-loss:0.2442, loss-lb:0.1323, loss-ulb:0.0559, weight:2.00, lr:0.0002
[06:11:14.188] iteration:12177  t-loss:0.2951, loss-lb:0.1759, loss-ulb:0.0596, weight:2.00, lr:0.0002
[06:11:14.505] iteration:12178  t-loss:0.2760, loss-lb:0.1344, loss-ulb:0.0708, weight:2.00, lr:0.0002
[06:11:14.820] iteration:12179  t-loss:0.2977, loss-lb:0.1757, loss-ulb:0.0610, weight:2.00, lr:0.0002
[06:11:15.140] iteration:12180  t-loss:0.2931, loss-lb:0.1828, loss-ulb:0.0551, weight:2.00, lr:0.0002
[06:11:15.463] iteration:12181  t-loss:0.3595, loss-lb:0.2649, loss-ulb:0.0473, weight:2.00, lr:0.0002
[06:11:15.777] iteration:12182  t-loss:0.2848, loss-lb:0.1735, loss-ulb:0.0557, weight:2.00, lr:0.0002
[06:11:16.101] iteration:12183  t-loss:0.2026, loss-lb:0.1794, loss-ulb:0.0116, weight:2.00, lr:0.0002
[06:11:16.432] iteration:12184  t-loss:0.3383, loss-lb:0.2047, loss-ulb:0.0668, weight:2.00, lr:0.0002
[06:11:16.761] iteration:12185  t-loss:0.1975, loss-lb:0.1406, loss-ulb:0.0284, weight:2.00, lr:0.0002
[06:11:17.093] iteration:12186  t-loss:0.2328, loss-lb:0.1707, loss-ulb:0.0311, weight:2.00, lr:0.0002
[06:11:17.446] iteration:12187  t-loss:0.4183, loss-lb:0.2522, loss-ulb:0.0830, weight:2.00, lr:0.0002
[06:11:17.769] iteration:12188  t-loss:0.3563, loss-lb:0.3198, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:11:18.091] iteration:12189  t-loss:0.1977, loss-lb:0.1471, loss-ulb:0.0253, weight:2.00, lr:0.0002
[06:11:18.419] iteration:12190  t-loss:0.3816, loss-lb:0.2476, loss-ulb:0.0670, weight:2.00, lr:0.0002
[06:11:18.747] iteration:12191  t-loss:0.3913, loss-lb:0.2238, loss-ulb:0.0838, weight:2.00, lr:0.0002
[06:11:19.071] iteration:12192  t-loss:0.2222, loss-lb:0.1800, loss-ulb:0.0211, weight:2.00, lr:0.0002
[06:11:19.389] iteration:12193  t-loss:0.2308, loss-lb:0.1394, loss-ulb:0.0457, weight:2.00, lr:0.0002
[06:11:19.710] iteration:12194  t-loss:0.3576, loss-lb:0.2672, loss-ulb:0.0452, weight:2.00, lr:0.0002
[06:11:20.033] iteration:12195  t-loss:0.3571, loss-lb:0.1969, loss-ulb:0.0801, weight:2.00, lr:0.0002
[06:11:20.352] iteration:12196  t-loss:0.3479, loss-lb:0.1715, loss-ulb:0.0882, weight:2.00, lr:0.0002
[06:11:20.672] iteration:12197  t-loss:0.2745, loss-lb:0.1722, loss-ulb:0.0512, weight:2.00, lr:0.0002
[06:11:20.992] iteration:12198  t-loss:0.1900, loss-lb:0.1648, loss-ulb:0.0126, weight:2.00, lr:0.0002
[06:11:21.312] iteration:12199  t-loss:0.4744, loss-lb:0.2555, loss-ulb:0.1095, weight:2.00, lr:0.0002
[06:11:21.628] iteration:12200  t-loss:0.3713, loss-lb:0.1249, loss-ulb:0.1232, weight:2.00, lr:0.0002
[06:11:22.983] iteration:12201  t-loss:0.3031, loss-lb:0.1330, loss-ulb:0.0851, weight:2.00, lr:0.0002
[06:11:23.308] iteration:12202  t-loss:0.2955, loss-lb:0.1216, loss-ulb:0.0870, weight:2.00, lr:0.0002
[06:11:23.632] iteration:12203  t-loss:0.2650, loss-lb:0.2071, loss-ulb:0.0289, weight:2.00, lr:0.0002
[06:11:23.949] iteration:12204  t-loss:0.1710, loss-lb:0.1393, loss-ulb:0.0159, weight:2.00, lr:0.0002
[06:11:24.270] iteration:12205  t-loss:0.2418, loss-lb:0.2002, loss-ulb:0.0208, weight:2.00, lr:0.0002
[06:11:24.594] iteration:12206  t-loss:0.2500, loss-lb:0.2204, loss-ulb:0.0148, weight:2.00, lr:0.0002
[06:11:24.929] iteration:12207  t-loss:0.3122, loss-lb:0.1926, loss-ulb:0.0598, weight:2.00, lr:0.0002
[06:11:25.274] iteration:12208  t-loss:0.2146, loss-lb:0.1774, loss-ulb:0.0186, weight:2.00, lr:0.0002
[06:11:25.606] iteration:12209  t-loss:0.3737, loss-lb:0.1510, loss-ulb:0.1113, weight:2.00, lr:0.0002
[06:11:25.941] iteration:12210  t-loss:0.1957, loss-lb:0.1645, loss-ulb:0.0156, weight:2.00, lr:0.0002
[06:11:26.289] iteration:12211  t-loss:0.2944, loss-lb:0.2511, loss-ulb:0.0216, weight:2.00, lr:0.0002
[06:11:26.618] iteration:12212  t-loss:0.3406, loss-lb:0.2084, loss-ulb:0.0661, weight:2.00, lr:0.0002
[06:11:26.943] iteration:12213  t-loss:0.4099, loss-lb:0.1647, loss-ulb:0.1226, weight:2.00, lr:0.0002
[06:11:27.266] iteration:12214  t-loss:0.5295, loss-lb:0.2324, loss-ulb:0.1485, weight:2.00, lr:0.0002
[06:11:27.589] iteration:12215  t-loss:0.3230, loss-lb:0.1256, loss-ulb:0.0987, weight:2.00, lr:0.0002
[06:11:27.915] iteration:12216  t-loss:0.3915, loss-lb:0.2384, loss-ulb:0.0765, weight:2.00, lr:0.0002
[06:11:28.236] iteration:12217  t-loss:0.1978, loss-lb:0.1626, loss-ulb:0.0176, weight:2.00, lr:0.0002
[06:11:28.555] iteration:12218  t-loss:0.3957, loss-lb:0.3145, loss-ulb:0.0406, weight:2.00, lr:0.0002
[06:11:28.869] iteration:12219  t-loss:0.2364, loss-lb:0.1832, loss-ulb:0.0266, weight:2.00, lr:0.0002
[06:11:29.193] iteration:12220  t-loss:0.3177, loss-lb:0.2655, loss-ulb:0.0261, weight:2.00, lr:0.0002
[06:11:29.509] iteration:12221  t-loss:0.2053, loss-lb:0.1765, loss-ulb:0.0144, weight:2.00, lr:0.0002
[06:11:29.827] iteration:12222  t-loss:0.3982, loss-lb:0.2568, loss-ulb:0.0707, weight:2.00, lr:0.0002
[06:11:30.141] iteration:12223  t-loss:0.1664, loss-lb:0.1208, loss-ulb:0.0228, weight:2.00, lr:0.0002
[06:11:30.456] iteration:12224  t-loss:0.1908, loss-lb:0.1451, loss-ulb:0.0228, weight:2.00, lr:0.0002
[06:11:30.773] iteration:12225  t-loss:0.2062, loss-lb:0.1827, loss-ulb:0.0117, weight:2.00, lr:0.0002
[06:13:47.802] iteration 12225 : dice_score: 0.850815 best_dice: 0.852700
[06:13:47.802]  <<Test>> - Ep:488  - Dice-S/T:84.86/85.08, Best-S:85.20, Best-T:85.27
[06:13:47.802]           - AvgLoss(lb/ulb/all):0.19/0.05/0.30
[06:13:49.073] iteration:12226  t-loss:0.2862, loss-lb:0.1540, loss-ulb:0.0661, weight:2.00, lr:0.0002
[06:13:49.392] iteration:12227  t-loss:0.2319, loss-lb:0.1435, loss-ulb:0.0442, weight:2.00, lr:0.0002
[06:13:49.721] iteration:12228  t-loss:0.2753, loss-lb:0.1227, loss-ulb:0.0763, weight:2.00, lr:0.0002
[06:13:50.038] iteration:12229  t-loss:0.4413, loss-lb:0.2325, loss-ulb:0.1044, weight:2.00, lr:0.0002
[06:13:50.358] iteration:12230  t-loss:0.5298, loss-lb:0.3446, loss-ulb:0.0926, weight:2.00, lr:0.0002
[06:13:50.676] iteration:12231  t-loss:0.3070, loss-lb:0.2689, loss-ulb:0.0190, weight:2.00, lr:0.0002
[06:13:51.000] iteration:12232  t-loss:0.2533, loss-lb:0.1413, loss-ulb:0.0560, weight:2.00, lr:0.0002
[06:13:51.328] iteration:12233  t-loss:0.4571, loss-lb:0.2814, loss-ulb:0.0878, weight:2.00, lr:0.0002
[06:13:51.661] iteration:12234  t-loss:0.2905, loss-lb:0.1189, loss-ulb:0.0858, weight:2.00, lr:0.0002
[06:13:51.986] iteration:12235  t-loss:0.3073, loss-lb:0.1576, loss-ulb:0.0748, weight:2.00, lr:0.0002
[06:13:52.318] iteration:12236  t-loss:0.2869, loss-lb:0.1327, loss-ulb:0.0771, weight:2.00, lr:0.0002
[06:13:52.652] iteration:12237  t-loss:0.3912, loss-lb:0.2030, loss-ulb:0.0941, weight:2.00, lr:0.0002
[06:13:52.974] iteration:12238  t-loss:0.2140, loss-lb:0.1693, loss-ulb:0.0224, weight:2.00, lr:0.0002
[06:13:53.308] iteration:12239  t-loss:0.3516, loss-lb:0.1861, loss-ulb:0.0828, weight:2.00, lr:0.0002
[06:13:53.628] iteration:12240  t-loss:0.4460, loss-lb:0.2655, loss-ulb:0.0903, weight:2.00, lr:0.0002
[06:13:53.958] iteration:12241  t-loss:0.3762, loss-lb:0.2681, loss-ulb:0.0541, weight:2.00, lr:0.0002
[06:13:54.279] iteration:12242  t-loss:0.1987, loss-lb:0.1564, loss-ulb:0.0212, weight:2.00, lr:0.0002
[06:13:54.599] iteration:12243  t-loss:0.3209, loss-lb:0.1485, loss-ulb:0.0862, weight:2.00, lr:0.0002
[06:13:54.911] iteration:12244  t-loss:0.4842, loss-lb:0.2052, loss-ulb:0.1395, weight:2.00, lr:0.0002
[06:13:55.226] iteration:12245  t-loss:0.3959, loss-lb:0.1236, loss-ulb:0.1361, weight:2.00, lr:0.0002
[06:13:55.543] iteration:12246  t-loss:0.1694, loss-lb:0.1204, loss-ulb:0.0245, weight:2.00, lr:0.0002
[06:13:55.859] iteration:12247  t-loss:0.2507, loss-lb:0.2194, loss-ulb:0.0156, weight:2.00, lr:0.0002
[06:13:56.174] iteration:12248  t-loss:0.6093, loss-lb:0.1488, loss-ulb:0.2302, weight:2.00, lr:0.0002
[06:13:56.487] iteration:12249  t-loss:0.1487, loss-lb:0.1222, loss-ulb:0.0132, weight:2.00, lr:0.0002
[06:13:56.803] iteration:12250  t-loss:0.2343, loss-lb:0.1171, loss-ulb:0.0586, weight:2.00, lr:0.0002
[06:13:58.271] iteration:12251  t-loss:0.1418, loss-lb:0.1134, loss-ulb:0.0142, weight:2.00, lr:0.0002
[06:13:58.601] iteration:12252  t-loss:0.2327, loss-lb:0.1475, loss-ulb:0.0426, weight:2.00, lr:0.0002
[06:13:58.925] iteration:12253  t-loss:0.1849, loss-lb:0.1543, loss-ulb:0.0153, weight:2.00, lr:0.0002
[06:13:59.243] iteration:12254  t-loss:0.1982, loss-lb:0.1596, loss-ulb:0.0193, weight:2.00, lr:0.0002
[06:13:59.563] iteration:12255  t-loss:0.2837, loss-lb:0.2431, loss-ulb:0.0203, weight:2.00, lr:0.0002
[06:13:59.882] iteration:12256  t-loss:0.4293, loss-lb:0.2233, loss-ulb:0.1030, weight:2.00, lr:0.0002
[06:14:00.201] iteration:12257  t-loss:0.1581, loss-lb:0.1296, loss-ulb:0.0142, weight:2.00, lr:0.0002
[06:14:00.518] iteration:12258  t-loss:0.2926, loss-lb:0.2172, loss-ulb:0.0377, weight:2.00, lr:0.0002
[06:14:00.837] iteration:12259  t-loss:0.4975, loss-lb:0.2525, loss-ulb:0.1225, weight:2.00, lr:0.0002
[06:14:01.157] iteration:12260  t-loss:0.3168, loss-lb:0.1630, loss-ulb:0.0769, weight:2.00, lr:0.0002
[06:14:01.478] iteration:12261  t-loss:0.2956, loss-lb:0.2349, loss-ulb:0.0303, weight:2.00, lr:0.0002
[06:14:01.796] iteration:12262  t-loss:0.2527, loss-lb:0.1598, loss-ulb:0.0464, weight:2.00, lr:0.0002
[06:14:02.111] iteration:12263  t-loss:0.3857, loss-lb:0.2124, loss-ulb:0.0866, weight:2.00, lr:0.0002
[06:14:02.437] iteration:12264  t-loss:0.5425, loss-lb:0.2770, loss-ulb:0.1327, weight:2.00, lr:0.0002
[06:14:02.762] iteration:12265  t-loss:0.1841, loss-lb:0.1426, loss-ulb:0.0208, weight:2.00, lr:0.0002
[06:14:03.094] iteration:12266  t-loss:0.1893, loss-lb:0.1559, loss-ulb:0.0167, weight:2.00, lr:0.0002
[06:14:03.426] iteration:12267  t-loss:0.2623, loss-lb:0.2335, loss-ulb:0.0144, weight:2.00, lr:0.0002
[06:14:03.759] iteration:12268  t-loss:0.2638, loss-lb:0.1771, loss-ulb:0.0434, weight:2.00, lr:0.0002
[06:14:04.077] iteration:12269  t-loss:0.3638, loss-lb:0.2610, loss-ulb:0.0514, weight:2.00, lr:0.0002
[06:14:04.394] iteration:12270  t-loss:0.3859, loss-lb:0.2344, loss-ulb:0.0758, weight:2.00, lr:0.0002
[06:14:04.717] iteration:12271  t-loss:0.2910, loss-lb:0.1625, loss-ulb:0.0642, weight:2.00, lr:0.0002
[06:14:05.034] iteration:12272  t-loss:0.3930, loss-lb:0.1732, loss-ulb:0.1099, weight:2.00, lr:0.0002
[06:14:05.360] iteration:12273  t-loss:0.1862, loss-lb:0.1324, loss-ulb:0.0269, weight:2.00, lr:0.0002
[06:14:05.684] iteration:12274  t-loss:0.1618, loss-lb:0.1154, loss-ulb:0.0232, weight:2.00, lr:0.0002
[06:14:06.013] iteration:12275  t-loss:0.2427, loss-lb:0.2069, loss-ulb:0.0179, weight:2.00, lr:0.0002
[06:14:07.815] iteration:12276  t-loss:0.2575, loss-lb:0.1729, loss-ulb:0.0423, weight:2.00, lr:0.0002
[06:14:08.164] iteration:12277  t-loss:0.3202, loss-lb:0.2035, loss-ulb:0.0583, weight:2.00, lr:0.0002
[06:14:08.505] iteration:12278  t-loss:0.3491, loss-lb:0.2085, loss-ulb:0.0703, weight:2.00, lr:0.0002
[06:14:08.838] iteration:12279  t-loss:0.1696, loss-lb:0.1388, loss-ulb:0.0154, weight:2.00, lr:0.0002
[06:14:09.163] iteration:12280  t-loss:0.3553, loss-lb:0.1831, loss-ulb:0.0861, weight:2.00, lr:0.0002
[06:14:09.487] iteration:12281  t-loss:0.5201, loss-lb:0.2703, loss-ulb:0.1249, weight:2.00, lr:0.0002
[06:14:09.808] iteration:12282  t-loss:0.3468, loss-lb:0.2150, loss-ulb:0.0659, weight:2.00, lr:0.0002
[06:14:10.126] iteration:12283  t-loss:0.3971, loss-lb:0.1501, loss-ulb:0.1235, weight:2.00, lr:0.0002
[06:14:10.445] iteration:12284  t-loss:0.4053, loss-lb:0.2429, loss-ulb:0.0812, weight:2.00, lr:0.0002
[06:14:10.759] iteration:12285  t-loss:0.3480, loss-lb:0.1248, loss-ulb:0.1116, weight:2.00, lr:0.0002
[06:14:11.077] iteration:12286  t-loss:0.2144, loss-lb:0.1705, loss-ulb:0.0219, weight:2.00, lr:0.0002
[06:14:11.412] iteration:12287  t-loss:0.4161, loss-lb:0.2329, loss-ulb:0.0916, weight:2.00, lr:0.0002
[06:14:11.748] iteration:12288  t-loss:0.4300, loss-lb:0.2287, loss-ulb:0.1007, weight:2.00, lr:0.0002
[06:14:12.091] iteration:12289  t-loss:0.2154, loss-lb:0.1220, loss-ulb:0.0467, weight:2.00, lr:0.0002
[06:14:12.423] iteration:12290  t-loss:0.1889, loss-lb:0.1417, loss-ulb:0.0236, weight:2.00, lr:0.0002
[06:14:12.753] iteration:12291  t-loss:0.3074, loss-lb:0.1729, loss-ulb:0.0673, weight:2.00, lr:0.0002
[06:14:13.082] iteration:12292  t-loss:0.2078, loss-lb:0.1488, loss-ulb:0.0295, weight:2.00, lr:0.0002
[06:14:13.413] iteration:12293  t-loss:0.3723, loss-lb:0.1521, loss-ulb:0.1101, weight:2.00, lr:0.0002
[06:14:13.733] iteration:12294  t-loss:0.2409, loss-lb:0.2004, loss-ulb:0.0202, weight:2.00, lr:0.0002
[06:14:14.053] iteration:12295  t-loss:0.3164, loss-lb:0.1600, loss-ulb:0.0782, weight:2.00, lr:0.0002
[06:14:14.369] iteration:12296  t-loss:0.6364, loss-lb:0.1608, loss-ulb:0.2378, weight:2.00, lr:0.0002
[06:14:14.684] iteration:12297  t-loss:0.3286, loss-lb:0.2215, loss-ulb:0.0535, weight:2.00, lr:0.0002
[06:14:14.997] iteration:12298  t-loss:0.1975, loss-lb:0.1497, loss-ulb:0.0239, weight:2.00, lr:0.0002
[06:14:15.311] iteration:12299  t-loss:0.1636, loss-lb:0.1274, loss-ulb:0.0181, weight:2.00, lr:0.0002
[06:14:15.627] iteration:12300  t-loss:0.2749, loss-lb:0.1113, loss-ulb:0.0818, weight:2.00, lr:0.0002
[06:14:17.065] iteration:12301  t-loss:0.3915, loss-lb:0.1295, loss-ulb:0.1310, weight:2.00, lr:0.0002
[06:14:17.416] iteration:12302  t-loss:0.2385, loss-lb:0.1951, loss-ulb:0.0217, weight:2.00, lr:0.0002
[06:14:17.755] iteration:12303  t-loss:0.3882, loss-lb:0.1923, loss-ulb:0.0979, weight:2.00, lr:0.0002
[06:14:18.082] iteration:12304  t-loss:0.2403, loss-lb:0.1688, loss-ulb:0.0358, weight:2.00, lr:0.0002
[06:14:18.400] iteration:12305  t-loss:0.4783, loss-lb:0.3068, loss-ulb:0.0857, weight:2.00, lr:0.0002
[06:14:18.717] iteration:12306  t-loss:0.2660, loss-lb:0.1537, loss-ulb:0.0561, weight:2.00, lr:0.0002
[06:14:19.036] iteration:12307  t-loss:0.3508, loss-lb:0.1623, loss-ulb:0.0942, weight:2.00, lr:0.0002
[06:14:19.353] iteration:12308  t-loss:0.3490, loss-lb:0.2214, loss-ulb:0.0638, weight:2.00, lr:0.0002
[06:14:19.670] iteration:12309  t-loss:0.2587, loss-lb:0.2195, loss-ulb:0.0196, weight:2.00, lr:0.0002
[06:14:20.000] iteration:12310  t-loss:0.4170, loss-lb:0.1528, loss-ulb:0.1321, weight:2.00, lr:0.0002
[06:14:20.334] iteration:12311  t-loss:0.3485, loss-lb:0.1478, loss-ulb:0.1003, weight:2.00, lr:0.0002
[06:14:20.660] iteration:12312  t-loss:0.2286, loss-lb:0.1651, loss-ulb:0.0318, weight:2.00, lr:0.0002
[06:14:20.986] iteration:12313  t-loss:0.1607, loss-lb:0.1289, loss-ulb:0.0159, weight:2.00, lr:0.0002
[06:14:21.317] iteration:12314  t-loss:0.2659, loss-lb:0.2160, loss-ulb:0.0249, weight:2.00, lr:0.0002
[06:14:21.647] iteration:12315  t-loss:0.2959, loss-lb:0.1291, loss-ulb:0.0834, weight:2.00, lr:0.0002
[06:14:21.971] iteration:12316  t-loss:0.9245, loss-lb:0.1558, loss-ulb:0.3843, weight:2.00, lr:0.0002
[06:14:22.294] iteration:12317  t-loss:0.3164, loss-lb:0.1567, loss-ulb:0.0798, weight:2.00, lr:0.0002
[06:14:22.622] iteration:12318  t-loss:0.3475, loss-lb:0.2046, loss-ulb:0.0715, weight:2.00, lr:0.0002
[06:14:22.940] iteration:12319  t-loss:0.1745, loss-lb:0.1446, loss-ulb:0.0149, weight:2.00, lr:0.0002
[06:14:23.256] iteration:12320  t-loss:0.2295, loss-lb:0.1461, loss-ulb:0.0417, weight:2.00, lr:0.0002
[06:14:23.577] iteration:12321  t-loss:0.2167, loss-lb:0.1830, loss-ulb:0.0169, weight:2.00, lr:0.0002
[06:14:23.896] iteration:12322  t-loss:0.4532, loss-lb:0.1907, loss-ulb:0.1312, weight:2.00, lr:0.0002
[06:14:24.212] iteration:12323  t-loss:0.1892, loss-lb:0.1380, loss-ulb:0.0256, weight:2.00, lr:0.0002
[06:14:24.527] iteration:12324  t-loss:0.2458, loss-lb:0.1224, loss-ulb:0.0617, weight:2.00, lr:0.0002
[06:14:24.850] iteration:12325  t-loss:0.4717, loss-lb:0.2028, loss-ulb:0.1344, weight:2.00, lr:0.0002
[06:16:38.241] iteration 12325 : dice_score: 0.850882 best_dice: 0.852700
[06:16:38.241]  <<Test>> - Ep:492  - Dice-S/T:84.97/85.09, Best-S:85.20, Best-T:85.27
[06:16:38.241]           - AvgLoss(lb/ulb/all):0.17/0.08/0.33
[06:16:39.392] iteration:12326  t-loss:0.3949, loss-lb:0.2859, loss-ulb:0.0545, weight:2.00, lr:0.0002
[06:16:39.731] iteration:12327  t-loss:0.3563, loss-lb:0.2386, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:16:40.054] iteration:12328  t-loss:0.2023, loss-lb:0.1279, loss-ulb:0.0372, weight:2.00, lr:0.0002
[06:16:40.378] iteration:12329  t-loss:0.3080, loss-lb:0.1986, loss-ulb:0.0547, weight:2.00, lr:0.0002
[06:16:40.699] iteration:12330  t-loss:0.5573, loss-lb:0.2560, loss-ulb:0.1506, weight:2.00, lr:0.0002
[06:16:41.019] iteration:12331  t-loss:0.3696, loss-lb:0.1373, loss-ulb:0.1161, weight:2.00, lr:0.0002
[06:16:41.341] iteration:12332  t-loss:0.3466, loss-lb:0.3017, loss-ulb:0.0224, weight:2.00, lr:0.0002
[06:16:41.664] iteration:12333  t-loss:0.3246, loss-lb:0.1641, loss-ulb:0.0803, weight:2.00, lr:0.0002
[06:16:41.984] iteration:12334  t-loss:0.2911, loss-lb:0.1718, loss-ulb:0.0597, weight:2.00, lr:0.0002
[06:16:42.305] iteration:12335  t-loss:0.3527, loss-lb:0.1855, loss-ulb:0.0836, weight:2.00, lr:0.0002
[06:16:42.627] iteration:12336  t-loss:0.2953, loss-lb:0.2518, loss-ulb:0.0218, weight:2.00, lr:0.0002
[06:16:42.947] iteration:12337  t-loss:0.2763, loss-lb:0.1666, loss-ulb:0.0549, weight:2.00, lr:0.0002
[06:16:43.288] iteration:12338  t-loss:0.3045, loss-lb:0.1401, loss-ulb:0.0822, weight:2.00, lr:0.0002
[06:16:43.612] iteration:12339  t-loss:0.3428, loss-lb:0.2383, loss-ulb:0.0522, weight:2.00, lr:0.0002
[06:16:43.931] iteration:12340  t-loss:0.2574, loss-lb:0.1872, loss-ulb:0.0351, weight:2.00, lr:0.0002
[06:16:44.249] iteration:12341  t-loss:0.1882, loss-lb:0.1553, loss-ulb:0.0164, weight:2.00, lr:0.0002
[06:16:44.569] iteration:12342  t-loss:0.4157, loss-lb:0.1397, loss-ulb:0.1380, weight:2.00, lr:0.0002
[06:16:44.893] iteration:12343  t-loss:0.2814, loss-lb:0.1791, loss-ulb:0.0512, weight:2.00, lr:0.0002
[06:16:45.209] iteration:12344  t-loss:0.1531, loss-lb:0.1016, loss-ulb:0.0258, weight:2.00, lr:0.0002
[06:16:45.524] iteration:12345  t-loss:0.3161, loss-lb:0.2178, loss-ulb:0.0492, weight:2.00, lr:0.0002
[06:16:45.840] iteration:12346  t-loss:0.2646, loss-lb:0.1625, loss-ulb:0.0510, weight:2.00, lr:0.0002
[06:16:46.153] iteration:12347  t-loss:0.2170, loss-lb:0.1315, loss-ulb:0.0428, weight:2.00, lr:0.0002
[06:16:46.470] iteration:12348  t-loss:0.3329, loss-lb:0.3094, loss-ulb:0.0118, weight:2.00, lr:0.0002
[06:16:46.789] iteration:12349  t-loss:0.3160, loss-lb:0.2162, loss-ulb:0.0499, weight:2.00, lr:0.0002
[06:16:47.109] iteration:12350  t-loss:0.6844, loss-lb:0.2625, loss-ulb:0.2110, weight:2.00, lr:0.0002
[06:16:48.272] iteration:12351  t-loss:0.4891, loss-lb:0.1516, loss-ulb:0.1687, weight:2.00, lr:0.0002
[06:16:48.607] iteration:12352  t-loss:0.3393, loss-lb:0.1567, loss-ulb:0.0913, weight:2.00, lr:0.0002
[06:16:48.930] iteration:12353  t-loss:0.4053, loss-lb:0.2880, loss-ulb:0.0587, weight:2.00, lr:0.0002
[06:16:49.251] iteration:12354  t-loss:0.1573, loss-lb:0.1335, loss-ulb:0.0119, weight:2.00, lr:0.0002
[06:16:49.574] iteration:12355  t-loss:0.2743, loss-lb:0.1673, loss-ulb:0.0535, weight:2.00, lr:0.0002
[06:16:49.904] iteration:12356  t-loss:0.3760, loss-lb:0.1497, loss-ulb:0.1131, weight:2.00, lr:0.0002
[06:16:50.241] iteration:12357  t-loss:0.3832, loss-lb:0.2809, loss-ulb:0.0512, weight:2.00, lr:0.0002
[06:16:50.571] iteration:12358  t-loss:0.3944, loss-lb:0.1267, loss-ulb:0.1338, weight:2.00, lr:0.0002
[06:16:50.902] iteration:12359  t-loss:0.2095, loss-lb:0.1320, loss-ulb:0.0388, weight:2.00, lr:0.0002
[06:16:51.230] iteration:12360  t-loss:0.2889, loss-lb:0.1709, loss-ulb:0.0590, weight:2.00, lr:0.0002
[06:16:51.558] iteration:12361  t-loss:0.3438, loss-lb:0.1563, loss-ulb:0.0938, weight:2.00, lr:0.0002
[06:16:51.888] iteration:12362  t-loss:0.3948, loss-lb:0.2028, loss-ulb:0.0960, weight:2.00, lr:0.0002
[06:16:52.209] iteration:12363  t-loss:0.2957, loss-lb:0.1718, loss-ulb:0.0619, weight:2.00, lr:0.0002
[06:16:52.527] iteration:12364  t-loss:0.1739, loss-lb:0.1387, loss-ulb:0.0176, weight:2.00, lr:0.0002
[06:16:52.852] iteration:12365  t-loss:0.3733, loss-lb:0.1900, loss-ulb:0.0916, weight:2.00, lr:0.0002
[06:16:53.177] iteration:12366  t-loss:0.3402, loss-lb:0.2988, loss-ulb:0.0207, weight:2.00, lr:0.0002
[06:16:53.524] iteration:12367  t-loss:0.3235, loss-lb:0.1835, loss-ulb:0.0700, weight:2.00, lr:0.0002
[06:16:53.855] iteration:12368  t-loss:0.2806, loss-lb:0.1680, loss-ulb:0.0563, weight:2.00, lr:0.0002
[06:16:54.181] iteration:12369  t-loss:0.4161, loss-lb:0.2715, loss-ulb:0.0723, weight:2.00, lr:0.0002
[06:16:54.507] iteration:12370  t-loss:0.5731, loss-lb:0.1667, loss-ulb:0.2032, weight:2.00, lr:0.0002
[06:16:54.828] iteration:12371  t-loss:0.2228, loss-lb:0.1286, loss-ulb:0.0471, weight:2.00, lr:0.0002
[06:16:55.150] iteration:12372  t-loss:0.5588, loss-lb:0.3061, loss-ulb:0.1263, weight:2.00, lr:0.0002
[06:16:55.464] iteration:12373  t-loss:0.2991, loss-lb:0.2176, loss-ulb:0.0408, weight:2.00, lr:0.0002
[06:16:55.779] iteration:12374  t-loss:0.2804, loss-lb:0.1526, loss-ulb:0.0639, weight:2.00, lr:0.0002
[06:16:56.098] iteration:12375  t-loss:0.2256, loss-lb:0.1906, loss-ulb:0.0175, weight:2.00, lr:0.0002
[06:16:57.471] iteration:12376  t-loss:0.1646, loss-lb:0.1315, loss-ulb:0.0166, weight:2.00, lr:0.0002
[06:16:57.814] iteration:12377  t-loss:0.2471, loss-lb:0.1286, loss-ulb:0.0592, weight:2.00, lr:0.0002
[06:16:58.165] iteration:12378  t-loss:0.3093, loss-lb:0.1610, loss-ulb:0.0741, weight:2.00, lr:0.0002
[06:16:58.509] iteration:12379  t-loss:0.2906, loss-lb:0.1352, loss-ulb:0.0777, weight:2.00, lr:0.0002
[06:16:58.856] iteration:12380  t-loss:0.4334, loss-lb:0.2950, loss-ulb:0.0692, weight:2.00, lr:0.0002
[06:16:59.193] iteration:12381  t-loss:0.5314, loss-lb:0.2300, loss-ulb:0.1507, weight:2.00, lr:0.0002
[06:16:59.521] iteration:12382  t-loss:1.1106, loss-lb:0.2453, loss-ulb:0.4327, weight:2.00, lr:0.0002
[06:16:59.841] iteration:12383  t-loss:0.3712, loss-lb:0.2159, loss-ulb:0.0777, weight:2.00, lr:0.0002
[06:17:00.161] iteration:12384  t-loss:0.4671, loss-lb:0.1431, loss-ulb:0.1620, weight:2.00, lr:0.0002
[06:17:00.479] iteration:12385  t-loss:0.2967, loss-lb:0.2099, loss-ulb:0.0434, weight:2.00, lr:0.0002
[06:17:00.798] iteration:12386  t-loss:1.5085, loss-lb:0.1663, loss-ulb:0.6711, weight:2.00, lr:0.0002
[06:17:01.112] iteration:12387  t-loss:0.2644, loss-lb:0.2099, loss-ulb:0.0273, weight:2.00, lr:0.0002
[06:17:01.429] iteration:12388  t-loss:0.2779, loss-lb:0.2000, loss-ulb:0.0390, weight:2.00, lr:0.0002
[06:17:01.755] iteration:12389  t-loss:0.3331, loss-lb:0.1498, loss-ulb:0.0916, weight:2.00, lr:0.0002
[06:17:02.081] iteration:12390  t-loss:0.2932, loss-lb:0.1250, loss-ulb:0.0841, weight:2.00, lr:0.0002
[06:17:02.413] iteration:12391  t-loss:0.2128, loss-lb:0.1787, loss-ulb:0.0171, weight:2.00, lr:0.0002
[06:17:02.743] iteration:12392  t-loss:0.1673, loss-lb:0.1313, loss-ulb:0.0180, weight:2.00, lr:0.0002
[06:17:03.076] iteration:12393  t-loss:0.4401, loss-lb:0.2049, loss-ulb:0.1176, weight:2.00, lr:0.0002
[06:17:03.407] iteration:12394  t-loss:0.2553, loss-lb:0.2214, loss-ulb:0.0169, weight:2.00, lr:0.0002
[06:17:03.728] iteration:12395  t-loss:0.2097, loss-lb:0.1733, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:17:04.059] iteration:12396  t-loss:0.3254, loss-lb:0.1493, loss-ulb:0.0880, weight:2.00, lr:0.0002
[06:17:04.385] iteration:12397  t-loss:0.3279, loss-lb:0.2145, loss-ulb:0.0567, weight:2.00, lr:0.0002
[06:17:04.712] iteration:12398  t-loss:0.3001, loss-lb:0.1449, loss-ulb:0.0776, weight:2.00, lr:0.0002
[06:17:05.041] iteration:12399  t-loss:0.4052, loss-lb:0.2661, loss-ulb:0.0695, weight:2.00, lr:0.0002
[06:17:05.362] iteration:12400  t-loss:0.4570, loss-lb:0.1598, loss-ulb:0.1486, weight:2.00, lr:0.0002
[06:17:06.769] iteration:12401  t-loss:0.4232, loss-lb:0.3650, loss-ulb:0.0291, weight:2.00, lr:0.0002
[06:17:07.115] iteration:12402  t-loss:0.3918, loss-lb:0.2371, loss-ulb:0.0773, weight:2.00, lr:0.0002
[06:17:07.477] iteration:12403  t-loss:0.4531, loss-lb:0.1430, loss-ulb:0.1551, weight:2.00, lr:0.0002
[06:17:07.850] iteration:12404  t-loss:0.3200, loss-lb:0.2118, loss-ulb:0.0541, weight:2.00, lr:0.0002
[06:17:08.180] iteration:12405  t-loss:0.2084, loss-lb:0.1741, loss-ulb:0.0171, weight:2.00, lr:0.0002
[06:17:08.500] iteration:12406  t-loss:0.2887, loss-lb:0.2518, loss-ulb:0.0184, weight:2.00, lr:0.0002
[06:17:08.817] iteration:12407  t-loss:0.2814, loss-lb:0.1545, loss-ulb:0.0635, weight:2.00, lr:0.0002
[06:17:09.139] iteration:12408  t-loss:0.3927, loss-lb:0.2630, loss-ulb:0.0649, weight:2.00, lr:0.0002
[06:17:09.457] iteration:12409  t-loss:0.2387, loss-lb:0.1114, loss-ulb:0.0637, weight:2.00, lr:0.0002
[06:17:09.779] iteration:12410  t-loss:0.5191, loss-lb:0.3472, loss-ulb:0.0860, weight:2.00, lr:0.0002
[06:17:10.095] iteration:12411  t-loss:0.2295, loss-lb:0.1525, loss-ulb:0.0385, weight:2.00, lr:0.0002
[06:17:10.415] iteration:12412  t-loss:0.6454, loss-lb:0.3386, loss-ulb:0.1534, weight:2.00, lr:0.0002
[06:17:10.745] iteration:12413  t-loss:0.4406, loss-lb:0.2024, loss-ulb:0.1191, weight:2.00, lr:0.0002
[06:17:11.081] iteration:12414  t-loss:0.3389, loss-lb:0.1500, loss-ulb:0.0945, weight:2.00, lr:0.0002
[06:17:11.410] iteration:12415  t-loss:0.1786, loss-lb:0.1403, loss-ulb:0.0191, weight:2.00, lr:0.0002
[06:17:11.756] iteration:12416  t-loss:0.5014, loss-lb:0.3406, loss-ulb:0.0804, weight:2.00, lr:0.0002
[06:17:12.088] iteration:12417  t-loss:0.3102, loss-lb:0.2373, loss-ulb:0.0364, weight:2.00, lr:0.0002
[06:17:12.414] iteration:12418  t-loss:0.2022, loss-lb:0.1670, loss-ulb:0.0176, weight:2.00, lr:0.0002
[06:17:12.734] iteration:12419  t-loss:0.3245, loss-lb:0.1401, loss-ulb:0.0922, weight:2.00, lr:0.0002
[06:17:13.051] iteration:12420  t-loss:0.2507, loss-lb:0.1394, loss-ulb:0.0557, weight:2.00, lr:0.0002
[06:17:13.366] iteration:12421  t-loss:0.4466, loss-lb:0.2224, loss-ulb:0.1121, weight:2.00, lr:0.0002
[06:17:13.681] iteration:12422  t-loss:0.2685, loss-lb:0.1968, loss-ulb:0.0358, weight:2.00, lr:0.0002
[06:17:13.995] iteration:12423  t-loss:0.2474, loss-lb:0.2086, loss-ulb:0.0194, weight:2.00, lr:0.0002
[06:17:14.313] iteration:12424  t-loss:0.4740, loss-lb:0.1923, loss-ulb:0.1408, weight:2.00, lr:0.0002
[06:17:14.632] iteration:12425  t-loss:0.2599, loss-lb:0.2162, loss-ulb:0.0218, weight:2.00, lr:0.0002
[06:19:31.110] iteration 12425 : dice_score: 0.850938 best_dice: 0.852700
[06:19:31.110]  <<Test>> - Ep:496  - Dice-S/T:84.67/85.09, Best-S:85.20, Best-T:85.27
[06:19:31.110]           - AvgLoss(lb/ulb/all):0.21/0.07/0.34
[06:19:32.456] iteration:12426  t-loss:0.4508, loss-lb:0.1219, loss-ulb:0.1645, weight:2.00, lr:0.0002
[06:19:32.785] iteration:12427  t-loss:0.3774, loss-lb:0.1482, loss-ulb:0.1146, weight:2.00, lr:0.0002
[06:19:33.112] iteration:12428  t-loss:0.2019, loss-lb:0.1172, loss-ulb:0.0424, weight:2.00, lr:0.0002
[06:19:33.434] iteration:12429  t-loss:0.4111, loss-lb:0.1876, loss-ulb:0.1117, weight:2.00, lr:0.0002
[06:19:33.758] iteration:12430  t-loss:0.5118, loss-lb:0.2541, loss-ulb:0.1288, weight:2.00, lr:0.0002
[06:19:34.082] iteration:12431  t-loss:0.3841, loss-lb:0.1810, loss-ulb:0.1015, weight:2.00, lr:0.0002
[06:19:34.406] iteration:12432  t-loss:0.3819, loss-lb:0.2238, loss-ulb:0.0790, weight:2.00, lr:0.0002
[06:19:34.722] iteration:12433  t-loss:0.2318, loss-lb:0.1419, loss-ulb:0.0449, weight:2.00, lr:0.0002
[06:19:35.042] iteration:12434  t-loss:0.4450, loss-lb:0.2691, loss-ulb:0.0879, weight:2.00, lr:0.0002
[06:19:35.358] iteration:12435  t-loss:0.2554, loss-lb:0.1923, loss-ulb:0.0316, weight:2.00, lr:0.0002
[06:19:35.677] iteration:12436  t-loss:0.2643, loss-lb:0.1470, loss-ulb:0.0587, weight:2.00, lr:0.0002
[06:19:35.997] iteration:12437  t-loss:0.2107, loss-lb:0.1269, loss-ulb:0.0419, weight:2.00, lr:0.0002
[06:19:36.319] iteration:12438  t-loss:0.3197, loss-lb:0.1797, loss-ulb:0.0700, weight:2.00, lr:0.0002
[06:19:36.639] iteration:12439  t-loss:0.1895, loss-lb:0.1481, loss-ulb:0.0207, weight:2.00, lr:0.0002
[06:19:36.958] iteration:12440  t-loss:0.3177, loss-lb:0.2288, loss-ulb:0.0444, weight:2.00, lr:0.0002
[06:19:37.277] iteration:12441  t-loss:0.3918, loss-lb:0.2113, loss-ulb:0.0903, weight:2.00, lr:0.0002
[06:19:37.602] iteration:12442  t-loss:0.3166, loss-lb:0.2004, loss-ulb:0.0581, weight:2.00, lr:0.0002
[06:19:37.921] iteration:12443  t-loss:0.2639, loss-lb:0.1653, loss-ulb:0.0493, weight:2.00, lr:0.0002
[06:19:38.234] iteration:12444  t-loss:0.1728, loss-lb:0.1445, loss-ulb:0.0142, weight:2.00, lr:0.0002
[06:19:38.552] iteration:12445  t-loss:0.4669, loss-lb:0.2402, loss-ulb:0.1133, weight:2.00, lr:0.0002
[06:19:38.869] iteration:12446  t-loss:0.3208, loss-lb:0.2070, loss-ulb:0.0569, weight:2.00, lr:0.0002
[06:19:39.185] iteration:12447  t-loss:0.2979, loss-lb:0.1505, loss-ulb:0.0737, weight:2.00, lr:0.0002
[06:19:39.499] iteration:12448  t-loss:0.2213, loss-lb:0.1230, loss-ulb:0.0491, weight:2.00, lr:0.0002
[06:19:39.815] iteration:12449  t-loss:0.6029, loss-lb:0.3248, loss-ulb:0.1390, weight:2.00, lr:0.0002
[06:19:40.130] iteration:12450  t-loss:0.1437, loss-lb:0.1089, loss-ulb:0.0174, weight:2.00, lr:0.0002
[06:19:41.339] iteration:12451  t-loss:0.2821, loss-lb:0.2553, loss-ulb:0.0134, weight:2.00, lr:0.0002
[06:19:41.673] iteration:12452  t-loss:0.3335, loss-lb:0.1329, loss-ulb:0.1003, weight:2.00, lr:0.0002
[06:19:42.008] iteration:12453  t-loss:0.3863, loss-lb:0.1313, loss-ulb:0.1275, weight:2.00, lr:0.0002
[06:19:42.333] iteration:12454  t-loss:0.2328, loss-lb:0.1663, loss-ulb:0.0333, weight:2.00, lr:0.0002
[06:19:42.654] iteration:12455  t-loss:0.2759, loss-lb:0.1209, loss-ulb:0.0775, weight:2.00, lr:0.0002
[06:19:42.974] iteration:12456  t-loss:0.5278, loss-lb:0.3577, loss-ulb:0.0850, weight:2.00, lr:0.0002
[06:19:43.292] iteration:12457  t-loss:0.3031, loss-lb:0.1545, loss-ulb:0.0743, weight:2.00, lr:0.0002
[06:19:43.614] iteration:12458  t-loss:0.3223, loss-lb:0.1838, loss-ulb:0.0692, weight:2.00, lr:0.0002
[06:19:43.938] iteration:12459  t-loss:0.4738, loss-lb:0.3495, loss-ulb:0.0621, weight:2.00, lr:0.0002
[06:19:44.256] iteration:12460  t-loss:0.1967, loss-lb:0.1553, loss-ulb:0.0207, weight:2.00, lr:0.0002
[06:19:44.579] iteration:12461  t-loss:0.4857, loss-lb:0.2203, loss-ulb:0.1327, weight:2.00, lr:0.0002
[06:19:44.897] iteration:12462  t-loss:0.1893, loss-lb:0.1189, loss-ulb:0.0352, weight:2.00, lr:0.0002
[06:19:45.218] iteration:12463  t-loss:0.1722, loss-lb:0.1306, loss-ulb:0.0208, weight:2.00, lr:0.0002
[06:19:45.542] iteration:12464  t-loss:0.4161, loss-lb:0.1721, loss-ulb:0.1220, weight:2.00, lr:0.0002
[06:19:45.860] iteration:12465  t-loss:0.2753, loss-lb:0.2050, loss-ulb:0.0351, weight:2.00, lr:0.0002
[06:19:46.182] iteration:12466  t-loss:0.2905, loss-lb:0.1624, loss-ulb:0.0640, weight:2.00, lr:0.0002
[06:19:46.501] iteration:12467  t-loss:0.3018, loss-lb:0.1891, loss-ulb:0.0564, weight:2.00, lr:0.0002
[06:19:46.820] iteration:12468  t-loss:0.3794, loss-lb:0.1673, loss-ulb:0.1060, weight:2.00, lr:0.0002
[06:19:47.147] iteration:12469  t-loss:0.6623, loss-lb:0.2267, loss-ulb:0.2178, weight:2.00, lr:0.0002
[06:19:47.476] iteration:12470  t-loss:0.3632, loss-lb:0.1522, loss-ulb:0.1055, weight:2.00, lr:0.0002
[06:19:47.799] iteration:12471  t-loss:0.2259, loss-lb:0.1465, loss-ulb:0.0397, weight:2.00, lr:0.0002
[06:19:48.130] iteration:12472  t-loss:0.2118, loss-lb:0.1825, loss-ulb:0.0146, weight:2.00, lr:0.0002
[06:19:48.445] iteration:12473  t-loss:0.3602, loss-lb:0.1961, loss-ulb:0.0821, weight:2.00, lr:0.0002
[06:19:48.761] iteration:12474  t-loss:0.2885, loss-lb:0.1692, loss-ulb:0.0597, weight:2.00, lr:0.0002
[06:19:49.077] iteration:12475  t-loss:0.3388, loss-lb:0.2346, loss-ulb:0.0521, weight:2.00, lr:0.0002
[06:19:50.529] iteration:12476  t-loss:0.5583, loss-lb:0.1851, loss-ulb:0.1866, weight:2.00, lr:0.0002
[06:19:50.869] iteration:12477  t-loss:0.4589, loss-lb:0.1520, loss-ulb:0.1534, weight:2.00, lr:0.0002
[06:19:51.205] iteration:12478  t-loss:0.2446, loss-lb:0.1580, loss-ulb:0.0433, weight:2.00, lr:0.0002
[06:19:51.549] iteration:12479  t-loss:0.3362, loss-lb:0.1762, loss-ulb:0.0800, weight:2.00, lr:0.0002
[06:19:51.878] iteration:12480  t-loss:0.2172, loss-lb:0.1073, loss-ulb:0.0550, weight:2.00, lr:0.0002
[06:19:52.212] iteration:12481  t-loss:0.6333, loss-lb:0.1892, loss-ulb:0.2221, weight:2.00, lr:0.0002
[06:19:52.545] iteration:12482  t-loss:0.3985, loss-lb:0.1825, loss-ulb:0.1080, weight:2.00, lr:0.0002
[06:19:52.868] iteration:12483  t-loss:0.3400, loss-lb:0.2828, loss-ulb:0.0286, weight:2.00, lr:0.0002
[06:19:53.189] iteration:12484  t-loss:0.2493, loss-lb:0.1944, loss-ulb:0.0275, weight:2.00, lr:0.0002
[06:19:53.503] iteration:12485  t-loss:0.2699, loss-lb:0.1500, loss-ulb:0.0599, weight:2.00, lr:0.0002
[06:19:53.826] iteration:12486  t-loss:0.2913, loss-lb:0.1755, loss-ulb:0.0579, weight:2.00, lr:0.0002
[06:19:54.152] iteration:12487  t-loss:0.4084, loss-lb:0.1901, loss-ulb:0.1092, weight:2.00, lr:0.0002
[06:19:54.482] iteration:12488  t-loss:0.2518, loss-lb:0.1535, loss-ulb:0.0492, weight:2.00, lr:0.0002
[06:19:54.813] iteration:12489  t-loss:0.2173, loss-lb:0.1875, loss-ulb:0.0149, weight:2.00, lr:0.0002
[06:19:55.151] iteration:12490  t-loss:0.2846, loss-lb:0.1492, loss-ulb:0.0677, weight:2.00, lr:0.0002
[06:19:55.496] iteration:12491  t-loss:0.3195, loss-lb:0.2074, loss-ulb:0.0560, weight:2.00, lr:0.0002
[06:19:55.847] iteration:12492  t-loss:0.4308, loss-lb:0.1049, loss-ulb:0.1630, weight:2.00, lr:0.0002
[06:19:56.195] iteration:12493  t-loss:0.4577, loss-lb:0.2157, loss-ulb:0.1210, weight:2.00, lr:0.0002
[06:19:56.544] iteration:12494  t-loss:0.2164, loss-lb:0.1888, loss-ulb:0.0138, weight:2.00, lr:0.0002
[06:19:56.888] iteration:12495  t-loss:0.2458, loss-lb:0.1956, loss-ulb:0.0251, weight:2.00, lr:0.0002
[06:19:57.219] iteration:12496  t-loss:0.1941, loss-lb:0.1385, loss-ulb:0.0278, weight:2.00, lr:0.0002
[06:19:57.548] iteration:12497  t-loss:0.3679, loss-lb:0.1805, loss-ulb:0.0937, weight:2.00, lr:0.0002
[06:19:57.885] iteration:12498  t-loss:0.2713, loss-lb:0.2239, loss-ulb:0.0237, weight:2.00, lr:0.0002
[06:19:58.215] iteration:12499  t-loss:0.2057, loss-lb:0.1726, loss-ulb:0.0165, weight:2.00, lr:0.0002
[06:19:58.542] iteration:12500  t-loss:0.2219, loss-lb:0.1570, loss-ulb:0.0325, weight:2.00, lr:0.0002
[06:19:59.851] iteration:12501  t-loss:0.2862, loss-lb:0.1687, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:20:00.182] iteration:12502  t-loss:0.3589, loss-lb:0.1585, loss-ulb:0.1002, weight:2.00, lr:0.0002
[06:20:00.504] iteration:12503  t-loss:0.2929, loss-lb:0.1546, loss-ulb:0.0692, weight:2.00, lr:0.0002
[06:20:00.824] iteration:12504  t-loss:0.4108, loss-lb:0.2423, loss-ulb:0.0842, weight:2.00, lr:0.0002
[06:20:01.142] iteration:12505  t-loss:0.1975, loss-lb:0.1429, loss-ulb:0.0273, weight:2.00, lr:0.0002
[06:20:01.460] iteration:12506  t-loss:0.2698, loss-lb:0.1832, loss-ulb:0.0433, weight:2.00, lr:0.0002
[06:20:01.780] iteration:12507  t-loss:0.4166, loss-lb:0.3114, loss-ulb:0.0526, weight:2.00, lr:0.0002
[06:20:02.096] iteration:12508  t-loss:0.2295, loss-lb:0.1142, loss-ulb:0.0577, weight:2.00, lr:0.0002
[06:20:02.422] iteration:12509  t-loss:0.2410, loss-lb:0.1669, loss-ulb:0.0371, weight:2.00, lr:0.0002
[06:20:02.742] iteration:12510  t-loss:0.3607, loss-lb:0.1931, loss-ulb:0.0838, weight:2.00, lr:0.0002
[06:20:03.059] iteration:12511  t-loss:0.3029, loss-lb:0.1763, loss-ulb:0.0633, weight:2.00, lr:0.0002
[06:20:03.375] iteration:12512  t-loss:0.3885, loss-lb:0.2845, loss-ulb:0.0520, weight:2.00, lr:0.0002
[06:20:03.694] iteration:12513  t-loss:0.2625, loss-lb:0.1484, loss-ulb:0.0571, weight:2.00, lr:0.0002
[06:20:04.020] iteration:12514  t-loss:0.2238, loss-lb:0.1765, loss-ulb:0.0236, weight:2.00, lr:0.0002
[06:20:04.351] iteration:12515  t-loss:0.3457, loss-lb:0.1359, loss-ulb:0.1049, weight:2.00, lr:0.0002
[06:20:04.690] iteration:12516  t-loss:0.5288, loss-lb:0.1334, loss-ulb:0.1977, weight:2.00, lr:0.0002
[06:20:05.032] iteration:12517  t-loss:0.2577, loss-lb:0.2056, loss-ulb:0.0261, weight:2.00, lr:0.0002
[06:20:05.366] iteration:12518  t-loss:0.1777, loss-lb:0.1530, loss-ulb:0.0123, weight:2.00, lr:0.0002
[06:20:05.703] iteration:12519  t-loss:0.1863, loss-lb:0.1454, loss-ulb:0.0205, weight:2.00, lr:0.0002
[06:20:06.031] iteration:12520  t-loss:0.1953, loss-lb:0.1553, loss-ulb:0.0200, weight:2.00, lr:0.0002
[06:20:06.370] iteration:12521  t-loss:0.2930, loss-lb:0.2723, loss-ulb:0.0104, weight:2.00, lr:0.0002
[06:20:06.697] iteration:12522  t-loss:0.2340, loss-lb:0.1985, loss-ulb:0.0178, weight:2.00, lr:0.0002
[06:20:07.035] iteration:12523  t-loss:0.3662, loss-lb:0.1372, loss-ulb:0.1145, weight:2.00, lr:0.0002
[06:20:07.364] iteration:12524  t-loss:0.2128, loss-lb:0.1142, loss-ulb:0.0493, weight:2.00, lr:0.0002
[06:20:07.687] iteration:12525  t-loss:0.1784, loss-lb:0.1424, loss-ulb:0.0180, weight:2.00, lr:0.0002
[06:22:24.977] iteration 12525 : dice_score: 0.850017 best_dice: 0.852700
[06:22:24.977]  <<Test>> - Ep:500  - Dice-S/T:84.93/85.00, Best-S:85.20, Best-T:85.27
[06:22:24.977]           - AvgLoss(lb/ulb/all):0.18/0.05/0.28
[06:22:26.218] iteration:12526  t-loss:0.2096, loss-lb:0.1740, loss-ulb:0.0178, weight:2.00, lr:0.0002
[06:22:26.548] iteration:12527  t-loss:0.2840, loss-lb:0.2467, loss-ulb:0.0187, weight:2.00, lr:0.0002
[06:22:26.869] iteration:12528  t-loss:0.3018, loss-lb:0.1304, loss-ulb:0.0857, weight:2.00, lr:0.0002
[06:22:27.195] iteration:12529  t-loss:0.2440, loss-lb:0.2083, loss-ulb:0.0179, weight:2.00, lr:0.0002
[06:22:27.516] iteration:12530  t-loss:0.2282, loss-lb:0.1673, loss-ulb:0.0304, weight:2.00, lr:0.0002
[06:22:27.840] iteration:12531  t-loss:0.2503, loss-lb:0.1560, loss-ulb:0.0471, weight:2.00, lr:0.0002
[06:22:28.166] iteration:12532  t-loss:0.2036, loss-lb:0.1733, loss-ulb:0.0152, weight:2.00, lr:0.0002
[06:22:28.505] iteration:12533  t-loss:0.2556, loss-lb:0.1740, loss-ulb:0.0408, weight:2.00, lr:0.0002
[06:22:28.837] iteration:12534  t-loss:0.2735, loss-lb:0.1323, loss-ulb:0.0706, weight:2.00, lr:0.0002
[06:22:29.183] iteration:12535  t-loss:0.3775, loss-lb:0.2523, loss-ulb:0.0626, weight:2.00, lr:0.0002
[06:22:29.502] iteration:12536  t-loss:0.4717, loss-lb:0.2570, loss-ulb:0.1074, weight:2.00, lr:0.0002
[06:22:29.823] iteration:12537  t-loss:0.2799, loss-lb:0.1458, loss-ulb:0.0670, weight:2.00, lr:0.0002
[06:22:30.141] iteration:12538  t-loss:0.2417, loss-lb:0.1227, loss-ulb:0.0595, weight:2.00, lr:0.0002
[06:22:30.466] iteration:12539  t-loss:0.2865, loss-lb:0.1885, loss-ulb:0.0490, weight:2.00, lr:0.0002
[06:22:30.795] iteration:12540  t-loss:0.2770, loss-lb:0.1423, loss-ulb:0.0674, weight:2.00, lr:0.0002
[06:22:31.117] iteration:12541  t-loss:0.2706, loss-lb:0.1543, loss-ulb:0.0581, weight:2.00, lr:0.0002
[06:22:31.436] iteration:12542  t-loss:0.1979, loss-lb:0.1764, loss-ulb:0.0108, weight:2.00, lr:0.0002
[06:22:31.758] iteration:12543  t-loss:0.3560, loss-lb:0.1602, loss-ulb:0.0979, weight:2.00, lr:0.0002
[06:22:32.075] iteration:12544  t-loss:0.2099, loss-lb:0.1215, loss-ulb:0.0442, weight:2.00, lr:0.0002
[06:22:32.394] iteration:12545  t-loss:0.2619, loss-lb:0.1502, loss-ulb:0.0559, weight:2.00, lr:0.0002
[06:22:32.710] iteration:12546  t-loss:0.2902, loss-lb:0.2529, loss-ulb:0.0186, weight:2.00, lr:0.0002
[06:22:33.031] iteration:12547  t-loss:0.2734, loss-lb:0.2382, loss-ulb:0.0176, weight:2.00, lr:0.0002
[06:22:33.347] iteration:12548  t-loss:0.2728, loss-lb:0.2349, loss-ulb:0.0189, weight:2.00, lr:0.0002
[06:22:33.662] iteration:12549  t-loss:0.2308, loss-lb:0.1944, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:22:33.978] iteration:12550  t-loss:0.5899, loss-lb:0.3987, loss-ulb:0.0956, weight:2.00, lr:0.0002
[06:22:35.385] iteration:12551  t-loss:0.1973, loss-lb:0.1666, loss-ulb:0.0154, weight:2.00, lr:0.0002
[06:22:35.713] iteration:12552  t-loss:0.4173, loss-lb:0.2522, loss-ulb:0.0825, weight:2.00, lr:0.0002
[06:22:36.032] iteration:12553  t-loss:0.2098, loss-lb:0.1734, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:22:36.353] iteration:12554  t-loss:0.3630, loss-lb:0.1955, loss-ulb:0.0838, weight:2.00, lr:0.0002
[06:22:36.671] iteration:12555  t-loss:0.2428, loss-lb:0.1923, loss-ulb:0.0253, weight:2.00, lr:0.0002
[06:22:36.986] iteration:12556  t-loss:0.1700, loss-lb:0.1377, loss-ulb:0.0162, weight:2.00, lr:0.0002
[06:22:37.303] iteration:12557  t-loss:0.3406, loss-lb:0.1287, loss-ulb:0.1060, weight:2.00, lr:0.0002
[06:22:37.622] iteration:12558  t-loss:0.2252, loss-lb:0.1861, loss-ulb:0.0195, weight:2.00, lr:0.0002
[06:22:37.940] iteration:12559  t-loss:0.2440, loss-lb:0.2146, loss-ulb:0.0147, weight:2.00, lr:0.0002
[06:22:38.256] iteration:12560  t-loss:0.2664, loss-lb:0.1278, loss-ulb:0.0693, weight:2.00, lr:0.0002
[06:22:38.571] iteration:12561  t-loss:0.3775, loss-lb:0.1587, loss-ulb:0.1094, weight:2.00, lr:0.0002
[06:22:38.891] iteration:12562  t-loss:0.3795, loss-lb:0.2722, loss-ulb:0.0536, weight:2.00, lr:0.0002
[06:22:39.211] iteration:12563  t-loss:0.4370, loss-lb:0.2021, loss-ulb:0.1174, weight:2.00, lr:0.0002
[06:22:39.526] iteration:12564  t-loss:0.1860, loss-lb:0.1463, loss-ulb:0.0199, weight:2.00, lr:0.0002
[06:22:39.842] iteration:12565  t-loss:0.2172, loss-lb:0.1762, loss-ulb:0.0205, weight:2.00, lr:0.0002
[06:22:40.160] iteration:12566  t-loss:0.2778, loss-lb:0.1483, loss-ulb:0.0647, weight:2.00, lr:0.0002
[06:22:40.476] iteration:12567  t-loss:0.2792, loss-lb:0.1415, loss-ulb:0.0688, weight:2.00, lr:0.0002
[06:22:40.791] iteration:12568  t-loss:0.1617, loss-lb:0.1125, loss-ulb:0.0246, weight:2.00, lr:0.0002
[06:22:41.111] iteration:12569  t-loss:0.3080, loss-lb:0.2183, loss-ulb:0.0448, weight:2.00, lr:0.0002
[06:22:41.434] iteration:12570  t-loss:0.2827, loss-lb:0.1748, loss-ulb:0.0539, weight:2.00, lr:0.0002
[06:22:41.764] iteration:12571  t-loss:0.4370, loss-lb:0.2516, loss-ulb:0.0927, weight:2.00, lr:0.0002
[06:22:42.093] iteration:12572  t-loss:0.2310, loss-lb:0.1655, loss-ulb:0.0328, weight:2.00, lr:0.0002
[06:22:42.421] iteration:12573  t-loss:0.1790, loss-lb:0.1354, loss-ulb:0.0218, weight:2.00, lr:0.0002
[06:22:42.751] iteration:12574  t-loss:0.3907, loss-lb:0.2725, loss-ulb:0.0591, weight:2.00, lr:0.0002
[06:22:43.076] iteration:12575  t-loss:0.3272, loss-lb:0.1610, loss-ulb:0.0831, weight:2.00, lr:0.0002
[06:22:44.544] iteration:12576  t-loss:0.1575, loss-lb:0.1268, loss-ulb:0.0153, weight:2.00, lr:0.0002
[06:22:44.896] iteration:12577  t-loss:0.2526, loss-lb:0.1472, loss-ulb:0.0527, weight:2.00, lr:0.0002
[06:22:45.228] iteration:12578  t-loss:0.4273, loss-lb:0.1809, loss-ulb:0.1232, weight:2.00, lr:0.0002
[06:22:45.561] iteration:12579  t-loss:0.1858, loss-lb:0.1602, loss-ulb:0.0128, weight:2.00, lr:0.0002
[06:22:45.889] iteration:12580  t-loss:0.1272, loss-lb:0.0993, loss-ulb:0.0139, weight:2.00, lr:0.0002
[06:22:46.226] iteration:12581  t-loss:0.3966, loss-lb:0.1332, loss-ulb:0.1317, weight:2.00, lr:0.0002
[06:22:46.556] iteration:12582  t-loss:0.3541, loss-lb:0.3177, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:22:46.885] iteration:12583  t-loss:0.2606, loss-lb:0.2210, loss-ulb:0.0198, weight:2.00, lr:0.0002
[06:22:47.208] iteration:12584  t-loss:0.2058, loss-lb:0.1123, loss-ulb:0.0467, weight:2.00, lr:0.0002
[06:22:47.531] iteration:12585  t-loss:0.7108, loss-lb:0.1687, loss-ulb:0.2710, weight:2.00, lr:0.0002
[06:22:47.855] iteration:12586  t-loss:0.4095, loss-lb:0.2306, loss-ulb:0.0895, weight:2.00, lr:0.0002
[06:22:48.175] iteration:12587  t-loss:0.2951, loss-lb:0.2590, loss-ulb:0.0181, weight:2.00, lr:0.0002
[06:22:48.491] iteration:12588  t-loss:0.2666, loss-lb:0.1965, loss-ulb:0.0351, weight:2.00, lr:0.0002
[06:22:48.807] iteration:12589  t-loss:0.2082, loss-lb:0.1552, loss-ulb:0.0265, weight:2.00, lr:0.0002
[06:22:49.126] iteration:12590  t-loss:0.2757, loss-lb:0.2418, loss-ulb:0.0169, weight:2.00, lr:0.0002
[06:22:49.447] iteration:12591  t-loss:0.4058, loss-lb:0.1992, loss-ulb:0.1033, weight:2.00, lr:0.0002
[06:22:49.763] iteration:12592  t-loss:0.2994, loss-lb:0.1862, loss-ulb:0.0566, weight:2.00, lr:0.0002
[06:22:50.080] iteration:12593  t-loss:0.3167, loss-lb:0.1986, loss-ulb:0.0591, weight:2.00, lr:0.0002
[06:22:50.395] iteration:12594  t-loss:0.2460, loss-lb:0.2102, loss-ulb:0.0179, weight:2.00, lr:0.0002
[06:22:50.718] iteration:12595  t-loss:0.3579, loss-lb:0.1932, loss-ulb:0.0823, weight:2.00, lr:0.0002
[06:22:51.041] iteration:12596  t-loss:0.2331, loss-lb:0.1495, loss-ulb:0.0418, weight:2.00, lr:0.0002
[06:22:51.360] iteration:12597  t-loss:0.1718, loss-lb:0.1036, loss-ulb:0.0341, weight:2.00, lr:0.0002
[06:22:51.679] iteration:12598  t-loss:0.4276, loss-lb:0.2413, loss-ulb:0.0931, weight:2.00, lr:0.0002
[06:22:51.994] iteration:12599  t-loss:0.3904, loss-lb:0.1310, loss-ulb:0.1297, weight:2.00, lr:0.0002
[06:22:52.317] iteration:12600  t-loss:0.3500, loss-lb:0.1962, loss-ulb:0.0769, weight:2.00, lr:0.0002
[06:22:53.616] iteration:12601  t-loss:0.3857, loss-lb:0.2011, loss-ulb:0.0923, weight:2.00, lr:0.0002
[06:22:53.951] iteration:12602  t-loss:0.3443, loss-lb:0.1526, loss-ulb:0.0958, weight:2.00, lr:0.0002
[06:22:54.283] iteration:12603  t-loss:0.5108, loss-lb:0.2982, loss-ulb:0.1063, weight:2.00, lr:0.0002
[06:22:54.617] iteration:12604  t-loss:0.3779, loss-lb:0.2540, loss-ulb:0.0620, weight:2.00, lr:0.0002
[06:22:54.943] iteration:12605  t-loss:0.2524, loss-lb:0.1611, loss-ulb:0.0457, weight:2.00, lr:0.0002
[06:22:55.273] iteration:12606  t-loss:0.2960, loss-lb:0.1583, loss-ulb:0.0688, weight:2.00, lr:0.0002
[06:22:55.601] iteration:12607  t-loss:0.3443, loss-lb:0.3079, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:22:55.943] iteration:12608  t-loss:0.3059, loss-lb:0.1849, loss-ulb:0.0605, weight:2.00, lr:0.0002
[06:22:56.269] iteration:12609  t-loss:0.2767, loss-lb:0.1692, loss-ulb:0.0538, weight:2.00, lr:0.0002
[06:22:56.599] iteration:12610  t-loss:0.2280, loss-lb:0.1999, loss-ulb:0.0140, weight:2.00, lr:0.0002
[06:22:56.925] iteration:12611  t-loss:0.4020, loss-lb:0.3619, loss-ulb:0.0201, weight:2.00, lr:0.0002
[06:22:57.251] iteration:12612  t-loss:0.3493, loss-lb:0.1881, loss-ulb:0.0806, weight:2.00, lr:0.0002
[06:22:57.574] iteration:12613  t-loss:0.4323, loss-lb:0.1696, loss-ulb:0.1314, weight:2.00, lr:0.0002
[06:22:57.891] iteration:12614  t-loss:0.1728, loss-lb:0.1219, loss-ulb:0.0255, weight:2.00, lr:0.0002
[06:22:58.208] iteration:12615  t-loss:0.3190, loss-lb:0.1551, loss-ulb:0.0819, weight:2.00, lr:0.0002
[06:22:58.523] iteration:12616  t-loss:0.2323, loss-lb:0.1852, loss-ulb:0.0236, weight:2.00, lr:0.0002
[06:22:58.844] iteration:12617  t-loss:0.3755, loss-lb:0.2047, loss-ulb:0.0854, weight:2.00, lr:0.0002
[06:22:59.164] iteration:12618  t-loss:0.1537, loss-lb:0.1164, loss-ulb:0.0186, weight:2.00, lr:0.0002
[06:22:59.491] iteration:12619  t-loss:0.3711, loss-lb:0.1969, loss-ulb:0.0871, weight:2.00, lr:0.0002
[06:22:59.808] iteration:12620  t-loss:0.2477, loss-lb:0.2127, loss-ulb:0.0175, weight:2.00, lr:0.0002
[06:23:00.129] iteration:12621  t-loss:0.2264, loss-lb:0.2008, loss-ulb:0.0128, weight:2.00, lr:0.0002
[06:23:00.448] iteration:12622  t-loss:0.3431, loss-lb:0.1802, loss-ulb:0.0815, weight:2.00, lr:0.0002
[06:23:00.766] iteration:12623  t-loss:0.2845, loss-lb:0.1563, loss-ulb:0.0641, weight:2.00, lr:0.0002
[06:23:01.085] iteration:12624  t-loss:0.2991, loss-lb:0.1816, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:23:01.407] iteration:12625  t-loss:0.3065, loss-lb:0.1983, loss-ulb:0.0541, weight:2.00, lr:0.0002
[06:25:10.863] iteration 12625 : dice_score: 0.849688 best_dice: 0.852700
[06:25:10.863]  <<Test>> - Ep:504  - Dice-S/T:85.18/84.97, Best-S:85.20, Best-T:85.27
[06:25:10.864]           - AvgLoss(lb/ulb/all):0.20/0.05/0.30
[06:25:12.236] iteration:12626  t-loss:0.3450, loss-lb:0.2655, loss-ulb:0.0398, weight:2.00, lr:0.0002
[06:25:12.567] iteration:12627  t-loss:0.1863, loss-lb:0.1203, loss-ulb:0.0330, weight:2.00, lr:0.0002
[06:25:12.909] iteration:12628  t-loss:0.4713, loss-lb:0.3328, loss-ulb:0.0693, weight:2.00, lr:0.0002
[06:25:13.233] iteration:12629  t-loss:0.4413, loss-lb:0.4007, loss-ulb:0.0203, weight:2.00, lr:0.0002
[06:25:13.560] iteration:12630  t-loss:0.4444, loss-lb:0.2168, loss-ulb:0.1138, weight:2.00, lr:0.0002
[06:25:13.881] iteration:12631  t-loss:0.2862, loss-lb:0.1323, loss-ulb:0.0769, weight:2.00, lr:0.0002
[06:25:14.201] iteration:12632  t-loss:0.3341, loss-lb:0.1325, loss-ulb:0.1008, weight:2.00, lr:0.0002
[06:25:14.526] iteration:12633  t-loss:0.3996, loss-lb:0.3306, loss-ulb:0.0345, weight:2.00, lr:0.0002
[06:25:14.847] iteration:12634  t-loss:0.3912, loss-lb:0.1499, loss-ulb:0.1207, weight:2.00, lr:0.0002
[06:25:15.174] iteration:12635  t-loss:0.3161, loss-lb:0.1629, loss-ulb:0.0766, weight:2.00, lr:0.0002
[06:25:15.491] iteration:12636  t-loss:0.2434, loss-lb:0.1228, loss-ulb:0.0603, weight:2.00, lr:0.0002
[06:25:15.814] iteration:12637  t-loss:0.1745, loss-lb:0.1276, loss-ulb:0.0235, weight:2.00, lr:0.0002
[06:25:16.142] iteration:12638  t-loss:0.3327, loss-lb:0.2161, loss-ulb:0.0583, weight:2.00, lr:0.0002
[06:25:16.467] iteration:12639  t-loss:0.3712, loss-lb:0.2379, loss-ulb:0.0667, weight:2.00, lr:0.0002
[06:25:16.795] iteration:12640  t-loss:0.4529, loss-lb:0.2195, loss-ulb:0.1167, weight:2.00, lr:0.0002
[06:25:17.116] iteration:12641  t-loss:0.2451, loss-lb:0.1426, loss-ulb:0.0512, weight:2.00, lr:0.0002
[06:25:17.441] iteration:12642  t-loss:0.2804, loss-lb:0.1191, loss-ulb:0.0807, weight:2.00, lr:0.0002
[06:25:17.762] iteration:12643  t-loss:0.4220, loss-lb:0.2756, loss-ulb:0.0732, weight:2.00, lr:0.0002
[06:25:18.080] iteration:12644  t-loss:0.1797, loss-lb:0.1426, loss-ulb:0.0185, weight:2.00, lr:0.0002
[06:25:18.402] iteration:12645  t-loss:0.2674, loss-lb:0.1326, loss-ulb:0.0674, weight:2.00, lr:0.0002
[06:25:18.720] iteration:12646  t-loss:0.1915, loss-lb:0.1505, loss-ulb:0.0205, weight:2.00, lr:0.0002
[06:25:19.041] iteration:12647  t-loss:0.3244, loss-lb:0.2153, loss-ulb:0.0546, weight:2.00, lr:0.0002
[06:25:19.362] iteration:12648  t-loss:0.5120, loss-lb:0.2308, loss-ulb:0.1406, weight:2.00, lr:0.0002
[06:25:19.683] iteration:12649  t-loss:0.2127, loss-lb:0.1727, loss-ulb:0.0200, weight:2.00, lr:0.0002
[06:25:20.003] iteration:12650  t-loss:0.2580, loss-lb:0.1809, loss-ulb:0.0386, weight:2.00, lr:0.0002
[06:25:21.475] iteration:12651  t-loss:0.2334, loss-lb:0.1428, loss-ulb:0.0453, weight:2.00, lr:0.0002
[06:25:21.803] iteration:12652  t-loss:0.2443, loss-lb:0.2134, loss-ulb:0.0154, weight:2.00, lr:0.0002
[06:25:22.130] iteration:12653  t-loss:0.4949, loss-lb:0.3143, loss-ulb:0.0903, weight:2.00, lr:0.0002
[06:25:22.452] iteration:12654  t-loss:0.2771, loss-lb:0.1502, loss-ulb:0.0635, weight:2.00, lr:0.0002
[06:25:22.775] iteration:12655  t-loss:0.2497, loss-lb:0.1202, loss-ulb:0.0648, weight:2.00, lr:0.0002
[06:25:23.094] iteration:12656  t-loss:0.2284, loss-lb:0.1977, loss-ulb:0.0154, weight:2.00, lr:0.0002
[06:25:23.418] iteration:12657  t-loss:0.2955, loss-lb:0.1758, loss-ulb:0.0599, weight:2.00, lr:0.0002
[06:25:23.740] iteration:12658  t-loss:0.3268, loss-lb:0.1732, loss-ulb:0.0768, weight:2.00, lr:0.0002
[06:25:24.061] iteration:12659  t-loss:0.1651, loss-lb:0.1190, loss-ulb:0.0231, weight:2.00, lr:0.0002
[06:25:24.387] iteration:12660  t-loss:0.3186, loss-lb:0.1765, loss-ulb:0.0710, weight:2.00, lr:0.0002
[06:25:24.710] iteration:12661  t-loss:0.2759, loss-lb:0.1617, loss-ulb:0.0571, weight:2.00, lr:0.0002
[06:25:25.035] iteration:12662  t-loss:0.4989, loss-lb:0.2279, loss-ulb:0.1355, weight:2.00, lr:0.0002
[06:25:25.357] iteration:12663  t-loss:0.2496, loss-lb:0.1584, loss-ulb:0.0456, weight:2.00, lr:0.0002
[06:25:25.683] iteration:12664  t-loss:0.4620, loss-lb:0.3848, loss-ulb:0.0386, weight:2.00, lr:0.0002
[06:25:26.006] iteration:12665  t-loss:0.2372, loss-lb:0.1570, loss-ulb:0.0401, weight:2.00, lr:0.0002
[06:25:26.330] iteration:12666  t-loss:0.1649, loss-lb:0.1390, loss-ulb:0.0129, weight:2.00, lr:0.0002
[06:25:26.656] iteration:12667  t-loss:0.2356, loss-lb:0.1191, loss-ulb:0.0582, weight:2.00, lr:0.0002
[06:25:26.971] iteration:12668  t-loss:0.2818, loss-lb:0.1447, loss-ulb:0.0686, weight:2.00, lr:0.0002
[06:25:27.290] iteration:12669  t-loss:0.3923, loss-lb:0.2384, loss-ulb:0.0769, weight:2.00, lr:0.0002
[06:25:27.607] iteration:12670  t-loss:0.3187, loss-lb:0.1531, loss-ulb:0.0828, weight:2.00, lr:0.0002
[06:25:27.921] iteration:12671  t-loss:0.1781, loss-lb:0.1390, loss-ulb:0.0196, weight:2.00, lr:0.0002
[06:25:28.251] iteration:12672  t-loss:0.3239, loss-lb:0.2378, loss-ulb:0.0430, weight:2.00, lr:0.0002
[06:25:28.575] iteration:12673  t-loss:0.1904, loss-lb:0.1492, loss-ulb:0.0206, weight:2.00, lr:0.0002
[06:25:28.905] iteration:12674  t-loss:0.2027, loss-lb:0.1592, loss-ulb:0.0218, weight:2.00, lr:0.0002
[06:25:29.226] iteration:12675  t-loss:0.1895, loss-lb:0.1365, loss-ulb:0.0265, weight:2.00, lr:0.0002
[06:25:30.986] iteration:12676  t-loss:0.2056, loss-lb:0.1257, loss-ulb:0.0399, weight:2.00, lr:0.0002
[06:25:31.328] iteration:12677  t-loss:0.2540, loss-lb:0.1807, loss-ulb:0.0367, weight:2.00, lr:0.0002
[06:25:31.667] iteration:12678  t-loss:0.3371, loss-lb:0.3059, loss-ulb:0.0156, weight:2.00, lr:0.0002
[06:25:32.000] iteration:12679  t-loss:0.3928, loss-lb:0.2062, loss-ulb:0.0933, weight:2.00, lr:0.0002
[06:25:32.329] iteration:12680  t-loss:0.3191, loss-lb:0.2521, loss-ulb:0.0335, weight:2.00, lr:0.0002
[06:25:32.659] iteration:12681  t-loss:0.2463, loss-lb:0.1280, loss-ulb:0.0591, weight:2.00, lr:0.0002
[06:25:32.983] iteration:12682  t-loss:0.3059, loss-lb:0.1717, loss-ulb:0.0671, weight:2.00, lr:0.0002
[06:25:33.310] iteration:12683  t-loss:0.5328, loss-lb:0.3829, loss-ulb:0.0749, weight:2.00, lr:0.0002
[06:25:33.635] iteration:12684  t-loss:0.3391, loss-lb:0.1678, loss-ulb:0.0856, weight:2.00, lr:0.0002
[06:25:33.967] iteration:12685  t-loss:0.1915, loss-lb:0.1643, loss-ulb:0.0136, weight:2.00, lr:0.0002
[06:25:34.295] iteration:12686  t-loss:0.3676, loss-lb:0.2310, loss-ulb:0.0683, weight:2.00, lr:0.0002
[06:25:34.622] iteration:12687  t-loss:0.2575, loss-lb:0.2300, loss-ulb:0.0138, weight:2.00, lr:0.0002
[06:25:34.939] iteration:12688  t-loss:0.3423, loss-lb:0.2533, loss-ulb:0.0445, weight:2.00, lr:0.0002
[06:25:35.259] iteration:12689  t-loss:0.4178, loss-lb:0.2716, loss-ulb:0.0731, weight:2.00, lr:0.0002
[06:25:35.580] iteration:12690  t-loss:0.3695, loss-lb:0.1846, loss-ulb:0.0925, weight:2.00, lr:0.0002
[06:25:35.899] iteration:12691  t-loss:0.3296, loss-lb:0.1401, loss-ulb:0.0947, weight:2.00, lr:0.0002
[06:25:36.220] iteration:12692  t-loss:0.4365, loss-lb:0.1726, loss-ulb:0.1319, weight:2.00, lr:0.0002
[06:25:36.538] iteration:12693  t-loss:0.2130, loss-lb:0.1315, loss-ulb:0.0408, weight:2.00, lr:0.0002
[06:25:36.851] iteration:12694  t-loss:0.2587, loss-lb:0.1458, loss-ulb:0.0564, weight:2.00, lr:0.0002
[06:25:37.177] iteration:12695  t-loss:0.2234, loss-lb:0.1234, loss-ulb:0.0500, weight:2.00, lr:0.0002
[06:25:37.502] iteration:12696  t-loss:0.2011, loss-lb:0.1628, loss-ulb:0.0191, weight:2.00, lr:0.0002
[06:25:37.834] iteration:12697  t-loss:0.2876, loss-lb:0.2129, loss-ulb:0.0373, weight:2.00, lr:0.0002
[06:25:38.159] iteration:12698  t-loss:0.3355, loss-lb:0.2288, loss-ulb:0.0533, weight:2.00, lr:0.0002
[06:25:38.485] iteration:12699  t-loss:0.3177, loss-lb:0.1448, loss-ulb:0.0865, weight:2.00, lr:0.0002
[06:25:38.802] iteration:12700  t-loss:0.2595, loss-lb:0.1300, loss-ulb:0.0648, weight:2.00, lr:0.0002
[06:25:40.208] iteration:12701  t-loss:0.4515, loss-lb:0.2970, loss-ulb:0.0773, weight:2.00, lr:0.0002
[06:25:40.555] iteration:12702  t-loss:0.4822, loss-lb:0.2532, loss-ulb:0.1145, weight:2.00, lr:0.0002
[06:25:40.889] iteration:12703  t-loss:0.2503, loss-lb:0.1619, loss-ulb:0.0442, weight:2.00, lr:0.0002
[06:25:41.214] iteration:12704  t-loss:0.2746, loss-lb:0.1218, loss-ulb:0.0764, weight:2.00, lr:0.0002
[06:25:41.544] iteration:12705  t-loss:0.2939, loss-lb:0.1786, loss-ulb:0.0576, weight:2.00, lr:0.0002
[06:25:41.872] iteration:12706  t-loss:0.3172, loss-lb:0.1698, loss-ulb:0.0737, weight:2.00, lr:0.0002
[06:25:42.198] iteration:12707  t-loss:0.3370, loss-lb:0.1462, loss-ulb:0.0954, weight:2.00, lr:0.0002
[06:25:42.522] iteration:12708  t-loss:0.3656, loss-lb:0.1211, loss-ulb:0.1223, weight:2.00, lr:0.0002
[06:25:42.851] iteration:12709  t-loss:0.3567, loss-lb:0.2400, loss-ulb:0.0584, weight:2.00, lr:0.0002
[06:25:43.171] iteration:12710  t-loss:0.2511, loss-lb:0.2224, loss-ulb:0.0144, weight:2.00, lr:0.0002
[06:25:43.492] iteration:12711  t-loss:0.3442, loss-lb:0.2177, loss-ulb:0.0633, weight:2.00, lr:0.0002
[06:25:43.808] iteration:12712  t-loss:0.2746, loss-lb:0.1525, loss-ulb:0.0610, weight:2.00, lr:0.0002
[06:25:44.126] iteration:12713  t-loss:0.6224, loss-lb:0.1603, loss-ulb:0.2311, weight:2.00, lr:0.0002
[06:25:44.444] iteration:12714  t-loss:0.2271, loss-lb:0.1186, loss-ulb:0.0542, weight:2.00, lr:0.0002
[06:25:44.760] iteration:12715  t-loss:0.2333, loss-lb:0.1579, loss-ulb:0.0377, weight:2.00, lr:0.0002
[06:25:45.081] iteration:12716  t-loss:0.5688, loss-lb:0.3089, loss-ulb:0.1300, weight:2.00, lr:0.0002
[06:25:45.404] iteration:12717  t-loss:0.3345, loss-lb:0.2341, loss-ulb:0.0502, weight:2.00, lr:0.0002
[06:25:45.736] iteration:12718  t-loss:0.3840, loss-lb:0.2422, loss-ulb:0.0709, weight:2.00, lr:0.0002
[06:25:46.069] iteration:12719  t-loss:0.3497, loss-lb:0.2352, loss-ulb:0.0572, weight:2.00, lr:0.0002
[06:25:46.394] iteration:12720  t-loss:0.3652, loss-lb:0.1784, loss-ulb:0.0934, weight:2.00, lr:0.0002
[06:25:46.720] iteration:12721  t-loss:0.4749, loss-lb:0.1365, loss-ulb:0.1692, weight:2.00, lr:0.0002
[06:25:47.048] iteration:12722  t-loss:0.2025, loss-lb:0.1685, loss-ulb:0.0170, weight:2.00, lr:0.0002
[06:25:47.381] iteration:12723  t-loss:0.3332, loss-lb:0.1763, loss-ulb:0.0785, weight:2.00, lr:0.0002
[06:25:47.708] iteration:12724  t-loss:0.3260, loss-lb:0.2996, loss-ulb:0.0132, weight:2.00, lr:0.0002
[06:25:48.030] iteration:12725  t-loss:0.3561, loss-lb:0.1679, loss-ulb:0.0941, weight:2.00, lr:0.0002
[06:28:01.654] iteration 12725 : dice_score: 0.850576 best_dice: 0.852700
[06:28:01.654]  <<Test>> - Ep:508  - Dice-S/T:85.00/85.06, Best-S:85.20, Best-T:85.27
[06:28:01.654]           - AvgLoss(lb/ulb/all):0.19/0.08/0.35
[06:28:03.092] iteration:12726  t-loss:0.3539, loss-lb:0.1121, loss-ulb:0.1209, weight:2.00, lr:0.0002
[06:28:03.429] iteration:12727  t-loss:0.2254, loss-lb:0.1789, loss-ulb:0.0233, weight:2.00, lr:0.0002
[06:28:03.759] iteration:12728  t-loss:0.4181, loss-lb:0.2096, loss-ulb:0.1042, weight:2.00, lr:0.0002
[06:28:04.077] iteration:12729  t-loss:0.2876, loss-lb:0.1520, loss-ulb:0.0678, weight:2.00, lr:0.0002
[06:28:04.396] iteration:12730  t-loss:0.3010, loss-lb:0.2685, loss-ulb:0.0162, weight:2.00, lr:0.0002
[06:28:04.716] iteration:12731  t-loss:0.4550, loss-lb:0.1876, loss-ulb:0.1337, weight:2.00, lr:0.0002
[06:28:05.033] iteration:12732  t-loss:0.2979, loss-lb:0.1865, loss-ulb:0.0557, weight:2.00, lr:0.0002
[06:28:05.349] iteration:12733  t-loss:0.7510, loss-lb:0.1224, loss-ulb:0.3143, weight:2.00, lr:0.0002
[06:28:05.667] iteration:12734  t-loss:0.3163, loss-lb:0.2694, loss-ulb:0.0235, weight:2.00, lr:0.0002
[06:28:05.986] iteration:12735  t-loss:0.3265, loss-lb:0.1874, loss-ulb:0.0696, weight:2.00, lr:0.0002
[06:28:06.306] iteration:12736  t-loss:0.6458, loss-lb:0.2115, loss-ulb:0.2172, weight:2.00, lr:0.0002
[06:28:06.625] iteration:12737  t-loss:0.4621, loss-lb:0.3057, loss-ulb:0.0782, weight:2.00, lr:0.0002
[06:28:06.940] iteration:12738  t-loss:0.1713, loss-lb:0.1262, loss-ulb:0.0226, weight:2.00, lr:0.0002
[06:28:07.258] iteration:12739  t-loss:0.1869, loss-lb:0.1404, loss-ulb:0.0232, weight:2.00, lr:0.0002
[06:28:07.576] iteration:12740  t-loss:0.2340, loss-lb:0.1470, loss-ulb:0.0435, weight:2.00, lr:0.0002
[06:28:07.897] iteration:12741  t-loss:0.3780, loss-lb:0.2722, loss-ulb:0.0529, weight:2.00, lr:0.0002
[06:28:08.221] iteration:12742  t-loss:0.4719, loss-lb:0.2404, loss-ulb:0.1158, weight:2.00, lr:0.0002
[06:28:08.541] iteration:12743  t-loss:0.2521, loss-lb:0.1436, loss-ulb:0.0542, weight:2.00, lr:0.0002
[06:28:08.865] iteration:12744  t-loss:0.3211, loss-lb:0.1347, loss-ulb:0.0932, weight:2.00, lr:0.0002
[06:28:09.195] iteration:12745  t-loss:0.2728, loss-lb:0.2007, loss-ulb:0.0361, weight:2.00, lr:0.0002
[06:28:09.526] iteration:12746  t-loss:0.3354, loss-lb:0.1830, loss-ulb:0.0762, weight:2.00, lr:0.0002
[06:28:09.848] iteration:12747  t-loss:0.2462, loss-lb:0.1585, loss-ulb:0.0439, weight:2.00, lr:0.0002
[06:28:10.171] iteration:12748  t-loss:0.4485, loss-lb:0.2813, loss-ulb:0.0836, weight:2.00, lr:0.0002
[06:28:10.488] iteration:12749  t-loss:0.4959, loss-lb:0.2395, loss-ulb:0.1282, weight:2.00, lr:0.0002
[06:28:10.807] iteration:12750  t-loss:0.2741, loss-lb:0.2346, loss-ulb:0.0197, weight:2.00, lr:0.0002
[06:28:12.209] iteration:12751  t-loss:0.3366, loss-lb:0.1504, loss-ulb:0.0931, weight:2.00, lr:0.0002
[06:28:12.547] iteration:12752  t-loss:0.2829, loss-lb:0.1427, loss-ulb:0.0701, weight:2.00, lr:0.0002
[06:28:12.879] iteration:12753  t-loss:0.3082, loss-lb:0.2650, loss-ulb:0.0216, weight:2.00, lr:0.0002
[06:28:13.201] iteration:12754  t-loss:0.4574, loss-lb:0.2521, loss-ulb:0.1027, weight:2.00, lr:0.0002
[06:28:13.520] iteration:12755  t-loss:0.1782, loss-lb:0.1220, loss-ulb:0.0281, weight:2.00, lr:0.0002
[06:28:13.842] iteration:12756  t-loss:0.4649, loss-lb:0.2896, loss-ulb:0.0877, weight:2.00, lr:0.0002
[06:28:14.164] iteration:12757  t-loss:0.2838, loss-lb:0.2164, loss-ulb:0.0337, weight:2.00, lr:0.0002
[06:28:14.482] iteration:12758  t-loss:0.2369, loss-lb:0.1870, loss-ulb:0.0249, weight:2.00, lr:0.0002
[06:28:14.799] iteration:12759  t-loss:0.3538, loss-lb:0.3147, loss-ulb:0.0195, weight:2.00, lr:0.0002
[06:28:15.117] iteration:12760  t-loss:0.4103, loss-lb:0.1741, loss-ulb:0.1181, weight:2.00, lr:0.0002
[06:28:15.437] iteration:12761  t-loss:0.3016, loss-lb:0.1304, loss-ulb:0.0856, weight:2.00, lr:0.0002
[06:28:15.756] iteration:12762  t-loss:0.2930, loss-lb:0.1493, loss-ulb:0.0719, weight:2.00, lr:0.0002
[06:28:16.079] iteration:12763  t-loss:0.3300, loss-lb:0.2316, loss-ulb:0.0492, weight:2.00, lr:0.0002
[06:28:16.403] iteration:12764  t-loss:0.2956, loss-lb:0.1459, loss-ulb:0.0749, weight:2.00, lr:0.0002
[06:28:16.720] iteration:12765  t-loss:0.4031, loss-lb:0.2180, loss-ulb:0.0925, weight:2.00, lr:0.0002
[06:28:17.041] iteration:12766  t-loss:0.1826, loss-lb:0.1416, loss-ulb:0.0205, weight:2.00, lr:0.0002
[06:28:17.367] iteration:12767  t-loss:0.3855, loss-lb:0.1494, loss-ulb:0.1180, weight:2.00, lr:0.0002
[06:28:17.699] iteration:12768  t-loss:0.3193, loss-lb:0.2228, loss-ulb:0.0483, weight:2.00, lr:0.0002
[06:28:18.021] iteration:12769  t-loss:0.3129, loss-lb:0.1544, loss-ulb:0.0793, weight:2.00, lr:0.0002
[06:28:18.341] iteration:12770  t-loss:0.2319, loss-lb:0.2000, loss-ulb:0.0160, weight:2.00, lr:0.0002
[06:28:18.661] iteration:12771  t-loss:0.2901, loss-lb:0.1669, loss-ulb:0.0616, weight:2.00, lr:0.0002
[06:28:18.978] iteration:12772  t-loss:0.2528, loss-lb:0.2180, loss-ulb:0.0174, weight:2.00, lr:0.0002
[06:28:19.294] iteration:12773  t-loss:0.3899, loss-lb:0.2442, loss-ulb:0.0729, weight:2.00, lr:0.0002
[06:28:19.612] iteration:12774  t-loss:0.2328, loss-lb:0.1217, loss-ulb:0.0556, weight:2.00, lr:0.0002
[06:28:19.928] iteration:12775  t-loss:0.1963, loss-lb:0.1673, loss-ulb:0.0145, weight:2.00, lr:0.0002
[06:28:21.195] iteration:12776  t-loss:0.3150, loss-lb:0.1704, loss-ulb:0.0723, weight:2.00, lr:0.0002
[06:28:21.538] iteration:12777  t-loss:0.3904, loss-lb:0.2331, loss-ulb:0.0786, weight:2.00, lr:0.0002
[06:28:21.881] iteration:12778  t-loss:0.3414, loss-lb:0.1353, loss-ulb:0.1031, weight:2.00, lr:0.0002
[06:28:22.209] iteration:12779  t-loss:0.1688, loss-lb:0.1345, loss-ulb:0.0172, weight:2.00, lr:0.0002
[06:28:22.544] iteration:12780  t-loss:0.1849, loss-lb:0.1528, loss-ulb:0.0160, weight:2.00, lr:0.0002
[06:28:22.873] iteration:12781  t-loss:0.2160, loss-lb:0.1829, loss-ulb:0.0165, weight:2.00, lr:0.0002
[06:28:23.196] iteration:12782  t-loss:0.3626, loss-lb:0.2655, loss-ulb:0.0486, weight:2.00, lr:0.0002
[06:28:23.511] iteration:12783  t-loss:0.1743, loss-lb:0.1394, loss-ulb:0.0174, weight:2.00, lr:0.0002
[06:28:23.829] iteration:12784  t-loss:0.2469, loss-lb:0.1535, loss-ulb:0.0467, weight:2.00, lr:0.0002
[06:28:24.149] iteration:12785  t-loss:0.3816, loss-lb:0.2642, loss-ulb:0.0587, weight:2.00, lr:0.0002
[06:28:24.479] iteration:12786  t-loss:0.3825, loss-lb:0.2108, loss-ulb:0.0859, weight:2.00, lr:0.0002
[06:28:24.798] iteration:12787  t-loss:0.2797, loss-lb:0.1314, loss-ulb:0.0741, weight:2.00, lr:0.0002
[06:28:25.119] iteration:12788  t-loss:0.3025, loss-lb:0.1581, loss-ulb:0.0722, weight:2.00, lr:0.0002
[06:28:25.437] iteration:12789  t-loss:0.1688, loss-lb:0.1342, loss-ulb:0.0173, weight:2.00, lr:0.0002
[06:28:25.768] iteration:12790  t-loss:0.2189, loss-lb:0.1855, loss-ulb:0.0167, weight:2.00, lr:0.0002
[06:28:26.105] iteration:12791  t-loss:0.2708, loss-lb:0.1630, loss-ulb:0.0539, weight:2.00, lr:0.0002
[06:28:26.434] iteration:12792  t-loss:0.2001, loss-lb:0.1398, loss-ulb:0.0302, weight:2.00, lr:0.0002
[06:28:26.764] iteration:12793  t-loss:0.2726, loss-lb:0.1442, loss-ulb:0.0642, weight:2.00, lr:0.0002
[06:28:27.087] iteration:12794  t-loss:0.1964, loss-lb:0.1660, loss-ulb:0.0152, weight:2.00, lr:0.0002
[06:28:27.413] iteration:12795  t-loss:0.2722, loss-lb:0.2455, loss-ulb:0.0134, weight:2.00, lr:0.0002
[06:28:27.729] iteration:12796  t-loss:0.1931, loss-lb:0.1367, loss-ulb:0.0282, weight:2.00, lr:0.0002
[06:28:28.048] iteration:12797  t-loss:0.4831, loss-lb:0.2364, loss-ulb:0.1233, weight:2.00, lr:0.0002
[06:28:28.366] iteration:12798  t-loss:0.2003, loss-lb:0.1666, loss-ulb:0.0168, weight:2.00, lr:0.0002
[06:28:28.683] iteration:12799  t-loss:0.1743, loss-lb:0.1493, loss-ulb:0.0125, weight:2.00, lr:0.0002
[06:28:29.003] iteration:12800  t-loss:0.3833, loss-lb:0.1868, loss-ulb:0.0982, weight:2.00, lr:0.0002
[06:28:30.539] iteration:12801  t-loss:0.3153, loss-lb:0.1269, loss-ulb:0.0942, weight:2.00, lr:0.0002
[06:28:30.879] iteration:12802  t-loss:0.3475, loss-lb:0.1361, loss-ulb:0.1057, weight:2.00, lr:0.0002
[06:28:31.215] iteration:12803  t-loss:0.4555, loss-lb:0.2064, loss-ulb:0.1246, weight:2.00, lr:0.0002
[06:28:31.559] iteration:12804  t-loss:0.3324, loss-lb:0.2393, loss-ulb:0.0466, weight:2.00, lr:0.0002
[06:28:31.879] iteration:12805  t-loss:0.2039, loss-lb:0.1298, loss-ulb:0.0371, weight:2.00, lr:0.0002
[06:28:32.187] iteration:12806  t-loss:0.5958, loss-lb:0.1478, loss-ulb:0.2240, weight:2.00, lr:0.0002
[06:28:32.504] iteration:12807  t-loss:0.2842, loss-lb:0.1822, loss-ulb:0.0510, weight:2.00, lr:0.0002
[06:28:32.824] iteration:12808  t-loss:0.3870, loss-lb:0.2130, loss-ulb:0.0870, weight:2.00, lr:0.0002
[06:28:33.141] iteration:12809  t-loss:0.2879, loss-lb:0.2519, loss-ulb:0.0180, weight:2.00, lr:0.0002
[06:28:33.461] iteration:12810  t-loss:0.4340, loss-lb:0.2087, loss-ulb:0.1126, weight:2.00, lr:0.0002
[06:28:33.779] iteration:12811  t-loss:0.2521, loss-lb:0.2249, loss-ulb:0.0136, weight:2.00, lr:0.0002
[06:28:34.102] iteration:12812  t-loss:0.2085, loss-lb:0.1697, loss-ulb:0.0194, weight:2.00, lr:0.0002
[06:28:34.447] iteration:12813  t-loss:0.1638, loss-lb:0.1087, loss-ulb:0.0275, weight:2.00, lr:0.0002
[06:28:34.783] iteration:12814  t-loss:0.4073, loss-lb:0.1606, loss-ulb:0.1234, weight:2.00, lr:0.0002
[06:28:35.120] iteration:12815  t-loss:0.3510, loss-lb:0.3050, loss-ulb:0.0230, weight:2.00, lr:0.0002
[06:28:35.454] iteration:12816  t-loss:0.2448, loss-lb:0.2060, loss-ulb:0.0194, weight:2.00, lr:0.0002
[06:28:35.788] iteration:12817  t-loss:0.2589, loss-lb:0.1264, loss-ulb:0.0662, weight:2.00, lr:0.0002
[06:28:36.121] iteration:12818  t-loss:0.3052, loss-lb:0.2697, loss-ulb:0.0178, weight:2.00, lr:0.0002
[06:28:36.447] iteration:12819  t-loss:0.4153, loss-lb:0.2300, loss-ulb:0.0927, weight:2.00, lr:0.0002
[06:28:36.764] iteration:12820  t-loss:0.1905, loss-lb:0.1607, loss-ulb:0.0149, weight:2.00, lr:0.0002
[06:28:37.079] iteration:12821  t-loss:0.1856, loss-lb:0.1456, loss-ulb:0.0200, weight:2.00, lr:0.0002
[06:28:37.399] iteration:12822  t-loss:0.1765, loss-lb:0.1320, loss-ulb:0.0222, weight:2.00, lr:0.0002
[06:28:37.716] iteration:12823  t-loss:0.3024, loss-lb:0.1386, loss-ulb:0.0819, weight:2.00, lr:0.0002
[06:28:38.033] iteration:12824  t-loss:0.3684, loss-lb:0.2845, loss-ulb:0.0419, weight:2.00, lr:0.0002
[06:28:38.356] iteration:12825  t-loss:0.2864, loss-lb:0.1856, loss-ulb:0.0504, weight:2.00, lr:0.0002
[06:30:50.819] iteration 12825 : dice_score: 0.853910 best_dice: 0.853900
[06:30:50.820]  <<Test>> - Ep:512  - Dice-S/T:85.59/85.39, Best-S:85.59, Best-T:85.39
[06:30:50.820]           - AvgLoss(lb/ulb/all):0.19/0.06/0.31
[06:30:52.034] iteration:12826  t-loss:0.3225, loss-lb:0.1474, loss-ulb:0.0876, weight:2.00, lr:0.0002
[06:30:52.371] iteration:12827  t-loss:0.3901, loss-lb:0.3269, loss-ulb:0.0316, weight:2.00, lr:0.0002
[06:30:52.698] iteration:12828  t-loss:0.1655, loss-lb:0.1271, loss-ulb:0.0192, weight:2.00, lr:0.0002
[06:30:53.031] iteration:12829  t-loss:0.2303, loss-lb:0.1371, loss-ulb:0.0466, weight:2.00, lr:0.0002
[06:30:53.352] iteration:12830  t-loss:0.3034, loss-lb:0.1542, loss-ulb:0.0746, weight:2.00, lr:0.0002
[06:30:53.670] iteration:12831  t-loss:0.2584, loss-lb:0.1975, loss-ulb:0.0305, weight:2.00, lr:0.0002
[06:30:53.989] iteration:12832  t-loss:0.1991, loss-lb:0.1723, loss-ulb:0.0134, weight:2.00, lr:0.0002
[06:30:54.309] iteration:12833  t-loss:0.4180, loss-lb:0.1473, loss-ulb:0.1354, weight:2.00, lr:0.0002
[06:30:54.627] iteration:12834  t-loss:0.2185, loss-lb:0.1834, loss-ulb:0.0176, weight:2.00, lr:0.0002
[06:30:54.954] iteration:12835  t-loss:0.3823, loss-lb:0.2560, loss-ulb:0.0632, weight:2.00, lr:0.0002
[06:30:55.275] iteration:12836  t-loss:0.1695, loss-lb:0.1310, loss-ulb:0.0192, weight:2.00, lr:0.0002
[06:30:55.612] iteration:12837  t-loss:0.3452, loss-lb:0.1530, loss-ulb:0.0961, weight:2.00, lr:0.0002
[06:30:55.941] iteration:12838  t-loss:0.1828, loss-lb:0.1434, loss-ulb:0.0197, weight:2.00, lr:0.0002
[06:30:56.265] iteration:12839  t-loss:0.2778, loss-lb:0.1357, loss-ulb:0.0710, weight:2.00, lr:0.0002
[06:30:56.601] iteration:12840  t-loss:0.5294, loss-lb:0.2179, loss-ulb:0.1557, weight:2.00, lr:0.0002
[06:30:56.917] iteration:12841  t-loss:0.1701, loss-lb:0.1326, loss-ulb:0.0188, weight:2.00, lr:0.0002
[06:30:57.241] iteration:12842  t-loss:0.2264, loss-lb:0.1941, loss-ulb:0.0161, weight:2.00, lr:0.0002
[06:30:57.559] iteration:12843  t-loss:0.3383, loss-lb:0.1666, loss-ulb:0.0858, weight:2.00, lr:0.0002
[06:30:57.871] iteration:12844  t-loss:0.2144, loss-lb:0.1720, loss-ulb:0.0212, weight:2.00, lr:0.0002
[06:30:58.187] iteration:12845  t-loss:0.2108, loss-lb:0.1392, loss-ulb:0.0358, weight:2.00, lr:0.0002
[06:30:58.502] iteration:12846  t-loss:0.3317, loss-lb:0.2156, loss-ulb:0.0580, weight:2.00, lr:0.0002
[06:30:58.816] iteration:12847  t-loss:0.2814, loss-lb:0.1783, loss-ulb:0.0515, weight:2.00, lr:0.0002
[06:30:59.134] iteration:12848  t-loss:0.3708, loss-lb:0.2314, loss-ulb:0.0697, weight:2.00, lr:0.0002
[06:30:59.455] iteration:12849  t-loss:0.4484, loss-lb:0.2301, loss-ulb:0.1091, weight:2.00, lr:0.0002
[06:30:59.782] iteration:12850  t-loss:0.2559, loss-lb:0.1222, loss-ulb:0.0669, weight:2.00, lr:0.0002
[06:31:01.620] iteration:12851  t-loss:0.2420, loss-lb:0.1263, loss-ulb:0.0579, weight:2.00, lr:0.0002
[06:31:01.973] iteration:12852  t-loss:0.3344, loss-lb:0.1268, loss-ulb:0.1038, weight:2.00, lr:0.0002
[06:31:02.331] iteration:12853  t-loss:0.3485, loss-lb:0.1644, loss-ulb:0.0920, weight:2.00, lr:0.0002
[06:31:02.671] iteration:12854  t-loss:0.2535, loss-lb:0.1391, loss-ulb:0.0572, weight:2.00, lr:0.0002
[06:31:03.015] iteration:12855  t-loss:0.2824, loss-lb:0.2558, loss-ulb:0.0133, weight:2.00, lr:0.0002
[06:31:03.348] iteration:12856  t-loss:0.2236, loss-lb:0.1490, loss-ulb:0.0373, weight:2.00, lr:0.0002
[06:31:03.685] iteration:12857  t-loss:0.4665, loss-lb:0.3610, loss-ulb:0.0527, weight:2.00, lr:0.0002
[06:31:04.037] iteration:12858  t-loss:0.3818, loss-lb:0.2172, loss-ulb:0.0823, weight:2.00, lr:0.0002
[06:31:04.358] iteration:12859  t-loss:0.1554, loss-lb:0.1223, loss-ulb:0.0165, weight:2.00, lr:0.0002
[06:31:04.682] iteration:12860  t-loss:0.2505, loss-lb:0.1547, loss-ulb:0.0479, weight:2.00, lr:0.0002
[06:31:05.007] iteration:12861  t-loss:0.4921, loss-lb:0.2126, loss-ulb:0.1397, weight:2.00, lr:0.0002
[06:31:05.325] iteration:12862  t-loss:0.2400, loss-lb:0.2140, loss-ulb:0.0130, weight:2.00, lr:0.0002
[06:31:05.639] iteration:12863  t-loss:0.2035, loss-lb:0.1711, loss-ulb:0.0162, weight:2.00, lr:0.0002
[06:31:05.953] iteration:12864  t-loss:0.3007, loss-lb:0.1493, loss-ulb:0.0757, weight:2.00, lr:0.0002
[06:31:06.268] iteration:12865  t-loss:0.2358, loss-lb:0.2132, loss-ulb:0.0113, weight:2.00, lr:0.0002
[06:31:06.582] iteration:12866  t-loss:0.1822, loss-lb:0.1444, loss-ulb:0.0189, weight:2.00, lr:0.0002
[06:31:06.899] iteration:12867  t-loss:0.3918, loss-lb:0.1733, loss-ulb:0.1093, weight:2.00, lr:0.0002
[06:31:07.213] iteration:12868  t-loss:0.2149, loss-lb:0.1266, loss-ulb:0.0442, weight:2.00, lr:0.0002
[06:31:07.526] iteration:12869  t-loss:0.3944, loss-lb:0.1588, loss-ulb:0.1178, weight:2.00, lr:0.0002
[06:31:07.841] iteration:12870  t-loss:0.4146, loss-lb:0.3246, loss-ulb:0.0450, weight:2.00, lr:0.0002
[06:31:08.159] iteration:12871  t-loss:0.5606, loss-lb:0.1462, loss-ulb:0.2072, weight:2.00, lr:0.0002
[06:31:08.483] iteration:12872  t-loss:0.3848, loss-lb:0.1806, loss-ulb:0.1021, weight:2.00, lr:0.0002
[06:31:08.808] iteration:12873  t-loss:0.2392, loss-lb:0.1961, loss-ulb:0.0215, weight:2.00, lr:0.0002
[06:31:09.130] iteration:12874  t-loss:0.3587, loss-lb:0.1974, loss-ulb:0.0807, weight:2.00, lr:0.0002
[06:31:09.457] iteration:12875  t-loss:0.2177, loss-lb:0.1254, loss-ulb:0.0462, weight:2.00, lr:0.0002
[06:31:11.552] iteration:12876  t-loss:0.2964, loss-lb:0.1547, loss-ulb:0.0708, weight:2.00, lr:0.0002
[06:31:11.930] iteration:12877  t-loss:0.2966, loss-lb:0.1616, loss-ulb:0.0675, weight:2.00, lr:0.0002
[06:31:12.291] iteration:12878  t-loss:0.1908, loss-lb:0.1340, loss-ulb:0.0284, weight:2.00, lr:0.0002
[06:31:12.672] iteration:12879  t-loss:0.3499, loss-lb:0.1743, loss-ulb:0.0878, weight:2.00, lr:0.0002
[06:31:13.032] iteration:12880  t-loss:0.4120, loss-lb:0.1741, loss-ulb:0.1189, weight:2.00, lr:0.0002
[06:31:13.411] iteration:12881  t-loss:0.4319, loss-lb:0.2045, loss-ulb:0.1137, weight:2.00, lr:0.0002
[06:31:13.780] iteration:12882  t-loss:0.2550, loss-lb:0.1801, loss-ulb:0.0374, weight:2.00, lr:0.0002
[06:31:14.142] iteration:12883  t-loss:0.3069, loss-lb:0.2094, loss-ulb:0.0488, weight:2.00, lr:0.0002
[06:31:14.501] iteration:12884  t-loss:0.2160, loss-lb:0.1667, loss-ulb:0.0247, weight:2.00, lr:0.0002
[06:31:14.840] iteration:12885  t-loss:0.4619, loss-lb:0.1350, loss-ulb:0.1634, weight:2.00, lr:0.0002
[06:31:15.176] iteration:12886  t-loss:0.2735, loss-lb:0.1758, loss-ulb:0.0488, weight:2.00, lr:0.0002
[06:31:15.505] iteration:12887  t-loss:0.2230, loss-lb:0.1840, loss-ulb:0.0195, weight:2.00, lr:0.0002
[06:31:15.829] iteration:12888  t-loss:0.2089, loss-lb:0.1420, loss-ulb:0.0334, weight:2.00, lr:0.0002
[06:31:16.146] iteration:12889  t-loss:0.4615, loss-lb:0.1398, loss-ulb:0.1609, weight:2.00, lr:0.0002
[06:31:16.462] iteration:12890  t-loss:0.2902, loss-lb:0.2154, loss-ulb:0.0374, weight:2.00, lr:0.0002
[06:31:16.782] iteration:12891  t-loss:0.4632, loss-lb:0.1806, loss-ulb:0.1413, weight:2.00, lr:0.0002
[06:31:17.096] iteration:12892  t-loss:0.3456, loss-lb:0.1714, loss-ulb:0.0871, weight:2.00, lr:0.0002
[06:31:17.421] iteration:12893  t-loss:0.4497, loss-lb:0.2571, loss-ulb:0.0963, weight:2.00, lr:0.0002
[06:31:17.745] iteration:12894  t-loss:0.3530, loss-lb:0.1520, loss-ulb:0.1005, weight:2.00, lr:0.0002
[06:31:18.065] iteration:12895  t-loss:0.3400, loss-lb:0.1241, loss-ulb:0.1079, weight:2.00, lr:0.0002
[06:31:18.385] iteration:12896  t-loss:0.2610, loss-lb:0.2266, loss-ulb:0.0172, weight:2.00, lr:0.0002
[06:31:18.700] iteration:12897  t-loss:0.3629, loss-lb:0.2229, loss-ulb:0.0700, weight:2.00, lr:0.0002
[06:31:19.016] iteration:12898  t-loss:0.3040, loss-lb:0.2010, loss-ulb:0.0515, weight:2.00, lr:0.0002
[06:31:19.329] iteration:12899  t-loss:0.1989, loss-lb:0.1586, loss-ulb:0.0201, weight:2.00, lr:0.0002
[06:31:19.644] iteration:12900  t-loss:0.3786, loss-lb:0.2510, loss-ulb:0.0638, weight:2.00, lr:0.0002
[06:31:20.934] iteration:12901  t-loss:0.4060, loss-lb:0.2765, loss-ulb:0.0647, weight:2.00, lr:0.0002
[06:31:21.279] iteration:12902  t-loss:0.1778, loss-lb:0.1463, loss-ulb:0.0157, weight:2.00, lr:0.0002
[06:31:21.627] iteration:12903  t-loss:0.3239, loss-lb:0.2190, loss-ulb:0.0525, weight:2.00, lr:0.0002
[06:31:21.975] iteration:12904  t-loss:0.3880, loss-lb:0.1744, loss-ulb:0.1068, weight:2.00, lr:0.0002
[06:31:22.313] iteration:12905  t-loss:0.2414, loss-lb:0.1585, loss-ulb:0.0415, weight:2.00, lr:0.0002
[06:31:22.646] iteration:12906  t-loss:0.2613, loss-lb:0.1412, loss-ulb:0.0601, weight:2.00, lr:0.0002
[06:31:22.989] iteration:12907  t-loss:0.3290, loss-lb:0.1357, loss-ulb:0.0967, weight:2.00, lr:0.0002
[06:31:23.319] iteration:12908  t-loss:0.3236, loss-lb:0.1637, loss-ulb:0.0799, weight:2.00, lr:0.0002
[06:31:23.644] iteration:12909  t-loss:0.2829, loss-lb:0.2472, loss-ulb:0.0179, weight:2.00, lr:0.0002
[06:31:23.977] iteration:12910  t-loss:0.3509, loss-lb:0.1553, loss-ulb:0.0978, weight:2.00, lr:0.0002
[06:31:24.315] iteration:12911  t-loss:0.3584, loss-lb:0.1746, loss-ulb:0.0919, weight:2.00, lr:0.0002
[06:31:24.645] iteration:12912  t-loss:0.2820, loss-lb:0.1390, loss-ulb:0.0715, weight:2.00, lr:0.0002
[06:31:24.977] iteration:12913  t-loss:0.3094, loss-lb:0.1844, loss-ulb:0.0625, weight:2.00, lr:0.0002
[06:31:25.296] iteration:12914  t-loss:0.1961, loss-lb:0.1427, loss-ulb:0.0267, weight:2.00, lr:0.0002
[06:31:25.620] iteration:12915  t-loss:0.3738, loss-lb:0.1908, loss-ulb:0.0915, weight:2.00, lr:0.0002
[06:31:25.952] iteration:12916  t-loss:0.2720, loss-lb:0.1741, loss-ulb:0.0489, weight:2.00, lr:0.0002
[06:31:26.287] iteration:12917  t-loss:0.2415, loss-lb:0.1057, loss-ulb:0.0679, weight:2.00, lr:0.0002
[06:31:26.621] iteration:12918  t-loss:0.3559, loss-lb:0.1874, loss-ulb:0.0842, weight:2.00, lr:0.0002
[06:31:26.942] iteration:12919  t-loss:0.1957, loss-lb:0.1614, loss-ulb:0.0171, weight:2.00, lr:0.0002
[06:31:27.264] iteration:12920  t-loss:0.3401, loss-lb:0.2101, loss-ulb:0.0650, weight:2.00, lr:0.0002
[06:31:27.580] iteration:12921  t-loss:0.2821, loss-lb:0.2212, loss-ulb:0.0305, weight:2.00, lr:0.0002
[06:31:27.894] iteration:12922  t-loss:0.2554, loss-lb:0.2206, loss-ulb:0.0174, weight:2.00, lr:0.0002
[06:31:28.210] iteration:12923  t-loss:0.2095, loss-lb:0.1636, loss-ulb:0.0230, weight:2.00, lr:0.0002
[06:31:28.526] iteration:12924  t-loss:0.4032, loss-lb:0.1363, loss-ulb:0.1334, weight:2.00, lr:0.0002
[06:31:28.848] iteration:12925  t-loss:0.2304, loss-lb:0.2014, loss-ulb:0.0145, weight:2.00, lr:0.0002
[06:33:43.861] iteration 12925 : dice_score: 0.853960 best_dice: 0.854000
[06:33:43.861]  <<Test>> - Ep:516  - Dice-S/T:85.19/85.40, Best-S:85.59, Best-T:85.40
[06:33:43.862]           - AvgLoss(lb/ulb/all):0.18/0.06/0.29
[06:33:45.117] iteration:12926  t-loss:0.1930, loss-lb:0.1582, loss-ulb:0.0174, weight:2.00, lr:0.0002
[06:33:45.446] iteration:12927  t-loss:0.2229, loss-lb:0.1915, loss-ulb:0.0157, weight:2.00, lr:0.0002
[06:33:45.776] iteration:12928  t-loss:0.2751, loss-lb:0.1539, loss-ulb:0.0606, weight:2.00, lr:0.0002
[06:33:46.097] iteration:12929  t-loss:0.3890, loss-lb:0.2000, loss-ulb:0.0945, weight:2.00, lr:0.0002
[06:33:46.417] iteration:12930  t-loss:0.1728, loss-lb:0.1499, loss-ulb:0.0115, weight:2.00, lr:0.0002
[06:33:46.742] iteration:12931  t-loss:0.3590, loss-lb:0.1283, loss-ulb:0.1154, weight:2.00, lr:0.0002
[06:33:47.061] iteration:12932  t-loss:0.1648, loss-lb:0.1351, loss-ulb:0.0148, weight:2.00, lr:0.0002
[06:33:47.385] iteration:12933  t-loss:0.2451, loss-lb:0.1443, loss-ulb:0.0504, weight:2.00, lr:0.0002
[06:33:47.711] iteration:12934  t-loss:0.2747, loss-lb:0.1466, loss-ulb:0.0641, weight:2.00, lr:0.0002
[06:33:48.034] iteration:12935  t-loss:0.2906, loss-lb:0.1334, loss-ulb:0.0786, weight:2.00, lr:0.0002
[06:33:48.356] iteration:12936  t-loss:0.2615, loss-lb:0.2285, loss-ulb:0.0165, weight:2.00, lr:0.0002
[06:33:48.676] iteration:12937  t-loss:0.1843, loss-lb:0.1360, loss-ulb:0.0241, weight:2.00, lr:0.0002
[06:33:48.998] iteration:12938  t-loss:0.3062, loss-lb:0.1672, loss-ulb:0.0695, weight:2.00, lr:0.0002
[06:33:49.322] iteration:12939  t-loss:0.3091, loss-lb:0.2168, loss-ulb:0.0461, weight:2.00, lr:0.0002
[06:33:49.641] iteration:12940  t-loss:0.1962, loss-lb:0.1539, loss-ulb:0.0211, weight:2.00, lr:0.0002
[06:33:49.961] iteration:12941  t-loss:0.2744, loss-lb:0.2109, loss-ulb:0.0318, weight:2.00, lr:0.0002
[06:33:50.281] iteration:12942  t-loss:0.3262, loss-lb:0.1484, loss-ulb:0.0889, weight:2.00, lr:0.0002
[06:33:50.602] iteration:12943  t-loss:0.4151, loss-lb:0.2362, loss-ulb:0.0894, weight:2.00, lr:0.0002
[06:33:50.920] iteration:12944  t-loss:0.2904, loss-lb:0.2043, loss-ulb:0.0431, weight:2.00, lr:0.0002
[06:33:51.236] iteration:12945  t-loss:0.1896, loss-lb:0.1531, loss-ulb:0.0182, weight:2.00, lr:0.0002
[06:33:51.555] iteration:12946  t-loss:0.8411, loss-lb:0.3005, loss-ulb:0.2703, weight:2.00, lr:0.0002
[06:33:51.874] iteration:12947  t-loss:0.2874, loss-lb:0.1239, loss-ulb:0.0818, weight:2.00, lr:0.0002
[06:33:52.190] iteration:12948  t-loss:0.3597, loss-lb:0.1258, loss-ulb:0.1170, weight:2.00, lr:0.0002
[06:33:52.509] iteration:12949  t-loss:0.3553, loss-lb:0.2599, loss-ulb:0.0477, weight:2.00, lr:0.0002
[06:33:52.829] iteration:12950  t-loss:0.2230, loss-lb:0.1888, loss-ulb:0.0171, weight:2.00, lr:0.0002
[06:33:54.064] iteration:12951  t-loss:0.4203, loss-lb:0.1396, loss-ulb:0.1404, weight:2.00, lr:0.0002
[06:33:54.407] iteration:12952  t-loss:0.2610, loss-lb:0.2271, loss-ulb:0.0169, weight:2.00, lr:0.0002
[06:33:54.743] iteration:12953  t-loss:0.3455, loss-lb:0.1429, loss-ulb:0.1013, weight:2.00, lr:0.0002
[06:33:55.067] iteration:12954  t-loss:0.2678, loss-lb:0.1892, loss-ulb:0.0393, weight:2.00, lr:0.0002
[06:33:55.392] iteration:12955  t-loss:0.2828, loss-lb:0.1701, loss-ulb:0.0564, weight:2.00, lr:0.0002
[06:33:55.715] iteration:12956  t-loss:0.2362, loss-lb:0.1212, loss-ulb:0.0575, weight:2.00, lr:0.0002
[06:33:56.034] iteration:12957  t-loss:0.4095, loss-lb:0.1573, loss-ulb:0.1261, weight:2.00, lr:0.0002
[06:33:56.356] iteration:12958  t-loss:0.3345, loss-lb:0.2050, loss-ulb:0.0648, weight:2.00, lr:0.0002
[06:33:56.682] iteration:12959  t-loss:0.2593, loss-lb:0.1137, loss-ulb:0.0728, weight:2.00, lr:0.0002
[06:33:57.003] iteration:12960  t-loss:0.2221, loss-lb:0.1512, loss-ulb:0.0354, weight:2.00, lr:0.0002
[06:33:57.331] iteration:12961  t-loss:0.5175, loss-lb:0.2261, loss-ulb:0.1457, weight:2.00, lr:0.0002
[06:33:57.658] iteration:12962  t-loss:0.3069, loss-lb:0.1516, loss-ulb:0.0776, weight:2.00, lr:0.0002
[06:33:57.980] iteration:12963  t-loss:0.2426, loss-lb:0.1447, loss-ulb:0.0489, weight:2.00, lr:0.0002
[06:33:58.303] iteration:12964  t-loss:0.1858, loss-lb:0.1470, loss-ulb:0.0194, weight:2.00, lr:0.0002
[06:33:58.644] iteration:12965  t-loss:0.2668, loss-lb:0.1623, loss-ulb:0.0522, weight:2.00, lr:0.0002
[06:33:58.977] iteration:12966  t-loss:0.2019, loss-lb:0.1681, loss-ulb:0.0169, weight:2.00, lr:0.0002
[06:33:59.317] iteration:12967  t-loss:0.2182, loss-lb:0.1899, loss-ulb:0.0142, weight:2.00, lr:0.0002
[06:33:59.652] iteration:12968  t-loss:0.2831, loss-lb:0.2469, loss-ulb:0.0181, weight:2.00, lr:0.0002
[06:33:59.975] iteration:12969  t-loss:0.2726, loss-lb:0.1876, loss-ulb:0.0425, weight:2.00, lr:0.0002
[06:34:00.297] iteration:12970  t-loss:0.2309, loss-lb:0.1480, loss-ulb:0.0414, weight:2.00, lr:0.0002
[06:34:00.620] iteration:12971  t-loss:0.4023, loss-lb:0.2658, loss-ulb:0.0682, weight:2.00, lr:0.0002
[06:34:00.945] iteration:12972  t-loss:0.2708, loss-lb:0.1615, loss-ulb:0.0546, weight:2.00, lr:0.0002
[06:34:01.262] iteration:12973  t-loss:0.2976, loss-lb:0.1992, loss-ulb:0.0492, weight:2.00, lr:0.0002
[06:34:01.583] iteration:12974  t-loss:0.3646, loss-lb:0.1447, loss-ulb:0.1100, weight:2.00, lr:0.0002
[06:34:01.900] iteration:12975  t-loss:0.2465, loss-lb:0.2180, loss-ulb:0.0143, weight:2.00, lr:0.0002
[06:34:03.298] iteration:12976  t-loss:0.5945, loss-lb:0.1252, loss-ulb:0.2347, weight:2.00, lr:0.0002
[06:34:03.637] iteration:12977  t-loss:0.1402, loss-lb:0.1126, loss-ulb:0.0138, weight:2.00, lr:0.0002
[06:34:03.978] iteration:12978  t-loss:0.2417, loss-lb:0.1845, loss-ulb:0.0286, weight:2.00, lr:0.0002
[06:34:04.312] iteration:12979  t-loss:0.1776, loss-lb:0.1426, loss-ulb:0.0175, weight:2.00, lr:0.0002
[06:34:04.645] iteration:12980  t-loss:0.3353, loss-lb:0.1705, loss-ulb:0.0824, weight:2.00, lr:0.0002
[06:34:04.969] iteration:12981  t-loss:0.2445, loss-lb:0.2135, loss-ulb:0.0155, weight:2.00, lr:0.0002
[06:34:05.293] iteration:12982  t-loss:0.3310, loss-lb:0.1777, loss-ulb:0.0767, weight:2.00, lr:0.0002
[06:34:05.615] iteration:12983  t-loss:0.3320, loss-lb:0.2272, loss-ulb:0.0524, weight:2.00, lr:0.0002
[06:34:05.934] iteration:12984  t-loss:0.1869, loss-lb:0.1129, loss-ulb:0.0370, weight:2.00, lr:0.0002
[06:34:06.253] iteration:12985  t-loss:0.3060, loss-lb:0.2278, loss-ulb:0.0391, weight:2.00, lr:0.0002
[06:34:06.571] iteration:12986  t-loss:0.2594, loss-lb:0.1425, loss-ulb:0.0584, weight:2.00, lr:0.0002
[06:34:06.891] iteration:12987  t-loss:0.1733, loss-lb:0.1388, loss-ulb:0.0172, weight:2.00, lr:0.0002
[06:34:07.229] iteration:12988  t-loss:0.4400, loss-lb:0.2969, loss-ulb:0.0716, weight:2.00, lr:0.0002
[06:34:07.574] iteration:12989  t-loss:0.2648, loss-lb:0.1666, loss-ulb:0.0491, weight:2.00, lr:0.0002
[06:34:07.909] iteration:12990  t-loss:0.2465, loss-lb:0.1439, loss-ulb:0.0513, weight:2.00, lr:0.0002
[06:34:08.249] iteration:12991  t-loss:0.2195, loss-lb:0.1758, loss-ulb:0.0219, weight:2.00, lr:0.0002
[06:34:08.589] iteration:12992  t-loss:0.3955, loss-lb:0.1669, loss-ulb:0.1143, weight:2.00, lr:0.0002
[06:34:08.924] iteration:12993  t-loss:0.4342, loss-lb:0.2367, loss-ulb:0.0987, weight:2.00, lr:0.0002
[06:34:09.246] iteration:12994  t-loss:0.3491, loss-lb:0.1838, loss-ulb:0.0826, weight:2.00, lr:0.0002
[06:34:09.562] iteration:12995  t-loss:0.2336, loss-lb:0.1351, loss-ulb:0.0493, weight:2.00, lr:0.0002
[06:34:09.882] iteration:12996  t-loss:0.1707, loss-lb:0.1433, loss-ulb:0.0137, weight:2.00, lr:0.0002
[06:34:10.201] iteration:12997  t-loss:0.1711, loss-lb:0.1375, loss-ulb:0.0168, weight:2.00, lr:0.0002
[06:34:10.521] iteration:12998  t-loss:0.3445, loss-lb:0.1870, loss-ulb:0.0788, weight:2.00, lr:0.0002
[06:34:10.840] iteration:12999  t-loss:0.4337, loss-lb:0.3217, loss-ulb:0.0560, weight:2.00, lr:0.0002
[06:34:11.158] iteration:13000  t-loss:0.2880, loss-lb:0.1275, loss-ulb:0.0802, weight:2.00, lr:0.0002
[06:34:12.471] iteration:13001  t-loss:0.2810, loss-lb:0.1246, loss-ulb:0.0782, weight:2.00, lr:0.0002
[06:34:12.807] iteration:13002  t-loss:0.5161, loss-lb:0.1587, loss-ulb:0.1787, weight:2.00, lr:0.0002
[06:34:13.147] iteration:13003  t-loss:0.6240, loss-lb:0.2749, loss-ulb:0.1746, weight:2.00, lr:0.0002
[06:34:13.482] iteration:13004  t-loss:0.3028, loss-lb:0.1375, loss-ulb:0.0827, weight:2.00, lr:0.0002
[06:34:13.806] iteration:13005  t-loss:0.3279, loss-lb:0.1675, loss-ulb:0.0802, weight:2.00, lr:0.0002
[06:34:14.123] iteration:13006  t-loss:0.2687, loss-lb:0.1678, loss-ulb:0.0504, weight:2.00, lr:0.0002
[06:34:14.441] iteration:13007  t-loss:0.2634, loss-lb:0.2334, loss-ulb:0.0150, weight:2.00, lr:0.0002
[06:34:14.761] iteration:13008  t-loss:0.2414, loss-lb:0.1775, loss-ulb:0.0319, weight:2.00, lr:0.0002
[06:34:15.077] iteration:13009  t-loss:0.2954, loss-lb:0.1441, loss-ulb:0.0756, weight:2.00, lr:0.0002
[06:34:15.396] iteration:13010  t-loss:0.2133, loss-lb:0.1706, loss-ulb:0.0214, weight:2.00, lr:0.0002
[06:34:15.717] iteration:13011  t-loss:0.1458, loss-lb:0.1215, loss-ulb:0.0121, weight:2.00, lr:0.0002
[06:34:16.049] iteration:13012  t-loss:0.1981, loss-lb:0.1505, loss-ulb:0.0238, weight:2.00, lr:0.0002
[06:34:16.381] iteration:13013  t-loss:0.1890, loss-lb:0.1597, loss-ulb:0.0147, weight:2.00, lr:0.0002
[06:34:16.716] iteration:13014  t-loss:0.4571, loss-lb:0.2335, loss-ulb:0.1118, weight:2.00, lr:0.0002
[06:34:17.041] iteration:13015  t-loss:0.2245, loss-lb:0.1730, loss-ulb:0.0258, weight:2.00, lr:0.0002
[06:34:17.371] iteration:13016  t-loss:0.2415, loss-lb:0.2165, loss-ulb:0.0125, weight:2.00, lr:0.0002
[06:34:17.696] iteration:13017  t-loss:0.2859, loss-lb:0.1791, loss-ulb:0.0534, weight:2.00, lr:0.0002
[06:34:18.019] iteration:13018  t-loss:0.1688, loss-lb:0.1414, loss-ulb:0.0137, weight:2.00, lr:0.0002
[06:34:18.336] iteration:13019  t-loss:0.1716, loss-lb:0.1394, loss-ulb:0.0161, weight:2.00, lr:0.0002
[06:34:18.651] iteration:13020  t-loss:0.2469, loss-lb:0.2050, loss-ulb:0.0210, weight:2.00, lr:0.0002
[06:34:18.971] iteration:13021  t-loss:0.2411, loss-lb:0.1937, loss-ulb:0.0237, weight:2.00, lr:0.0002
[06:34:19.295] iteration:13022  t-loss:0.2974, loss-lb:0.1800, loss-ulb:0.0587, weight:2.00, lr:0.0002
[06:34:19.611] iteration:13023  t-loss:0.3196, loss-lb:0.1896, loss-ulb:0.0650, weight:2.00, lr:0.0002
[06:34:19.930] iteration:13024  t-loss:0.2182, loss-lb:0.1961, loss-ulb:0.0110, weight:2.00, lr:0.0002
[06:34:20.245] iteration:13025  t-loss:0.1635, loss-lb:0.1163, loss-ulb:0.0236, weight:2.00, lr:0.0002
[06:36:33.662] iteration 13025 : dice_score: 0.852597 best_dice: 0.854000
[06:36:33.663]  <<Test>> - Ep:520  - Dice-S/T:85.18/85.26, Best-S:85.59, Best-T:85.40
[06:36:33.663]           - AvgLoss(lb/ulb/all):0.17/0.03/0.24
[06:36:34.826] iteration:13026  t-loss:0.1902, loss-lb:0.1551, loss-ulb:0.0176, weight:2.00, lr:0.0002
[06:36:35.154] iteration:13027  t-loss:0.3174, loss-lb:0.1645, loss-ulb:0.0765, weight:2.00, lr:0.0002
[06:36:35.488] iteration:13028  t-loss:0.4017, loss-lb:0.1829, loss-ulb:0.1094, weight:2.00, lr:0.0002
[06:36:35.821] iteration:13029  t-loss:0.1718, loss-lb:0.1500, loss-ulb:0.0109, weight:2.00, lr:0.0002
[06:36:36.150] iteration:13030  t-loss:0.3396, loss-lb:0.2029, loss-ulb:0.0683, weight:2.00, lr:0.0002
[06:36:36.468] iteration:13031  t-loss:0.2482, loss-lb:0.2094, loss-ulb:0.0194, weight:2.00, lr:0.0002
[06:36:36.799] iteration:13032  t-loss:0.3985, loss-lb:0.1937, loss-ulb:0.1024, weight:2.00, lr:0.0002
[06:36:37.121] iteration:13033  t-loss:0.2607, loss-lb:0.1662, loss-ulb:0.0473, weight:2.00, lr:0.0002
[06:36:37.440] iteration:13034  t-loss:0.1928, loss-lb:0.1547, loss-ulb:0.0191, weight:2.00, lr:0.0002
[06:36:37.756] iteration:13035  t-loss:0.3429, loss-lb:0.2037, loss-ulb:0.0696, weight:2.00, lr:0.0002
[06:36:38.076] iteration:13036  t-loss:0.2824, loss-lb:0.2427, loss-ulb:0.0198, weight:2.00, lr:0.0002
[06:36:38.396] iteration:13037  t-loss:0.2372, loss-lb:0.1670, loss-ulb:0.0351, weight:2.00, lr:0.0002
[06:36:38.716] iteration:13038  t-loss:0.1928, loss-lb:0.1237, loss-ulb:0.0345, weight:2.00, lr:0.0002
[06:36:39.033] iteration:13039  t-loss:0.3168, loss-lb:0.1433, loss-ulb:0.0867, weight:2.00, lr:0.0002
[06:36:39.353] iteration:13040  t-loss:0.1892, loss-lb:0.1695, loss-ulb:0.0099, weight:2.00, lr:0.0002
[06:36:39.673] iteration:13041  t-loss:0.3054, loss-lb:0.1593, loss-ulb:0.0731, weight:2.00, lr:0.0002
[06:36:39.990] iteration:13042  t-loss:0.3153, loss-lb:0.1555, loss-ulb:0.0799, weight:2.00, lr:0.0002
[06:36:40.308] iteration:13043  t-loss:0.5349, loss-lb:0.3058, loss-ulb:0.1145, weight:2.00, lr:0.0002
[06:36:40.622] iteration:13044  t-loss:0.2327, loss-lb:0.2120, loss-ulb:0.0104, weight:2.00, lr:0.0002
[06:36:40.936] iteration:13045  t-loss:0.2418, loss-lb:0.1994, loss-ulb:0.0212, weight:2.00, lr:0.0002
[06:36:41.250] iteration:13046  t-loss:0.1850, loss-lb:0.1593, loss-ulb:0.0128, weight:2.00, lr:0.0002
[06:36:41.565] iteration:13047  t-loss:0.2409, loss-lb:0.1169, loss-ulb:0.0620, weight:2.00, lr:0.0002
[06:36:41.884] iteration:13048  t-loss:0.3921, loss-lb:0.2067, loss-ulb:0.0927, weight:2.00, lr:0.0002
[06:36:42.200] iteration:13049  t-loss:0.2036, loss-lb:0.1312, loss-ulb:0.0362, weight:2.00, lr:0.0002
[06:36:42.516] iteration:13050  t-loss:0.2063, loss-lb:0.1702, loss-ulb:0.0180, weight:2.00, lr:0.0002
[06:36:43.793] iteration:13051  t-loss:0.3126, loss-lb:0.1850, loss-ulb:0.0638, weight:2.00, lr:0.0002
[06:36:44.115] iteration:13052  t-loss:0.2136, loss-lb:0.1324, loss-ulb:0.0406, weight:2.00, lr:0.0002
[06:36:44.444] iteration:13053  t-loss:0.3992, loss-lb:0.2325, loss-ulb:0.0833, weight:2.00, lr:0.0002
[06:36:44.764] iteration:13054  t-loss:0.3533, loss-lb:0.1843, loss-ulb:0.0845, weight:2.00, lr:0.0002
[06:36:45.081] iteration:13055  t-loss:0.2519, loss-lb:0.1223, loss-ulb:0.0648, weight:2.00, lr:0.0002
[06:36:45.403] iteration:13056  t-loss:0.2913, loss-lb:0.2605, loss-ulb:0.0154, weight:2.00, lr:0.0002
[06:36:45.727] iteration:13057  t-loss:0.3566, loss-lb:0.2373, loss-ulb:0.0597, weight:2.00, lr:0.0002
[06:36:46.059] iteration:13058  t-loss:0.3316, loss-lb:0.2227, loss-ulb:0.0544, weight:2.00, lr:0.0002
[06:36:46.394] iteration:13059  t-loss:0.2442, loss-lb:0.1619, loss-ulb:0.0412, weight:2.00, lr:0.0002
[06:36:46.729] iteration:13060  t-loss:0.3308, loss-lb:0.1750, loss-ulb:0.0779, weight:2.00, lr:0.0002
[06:36:47.054] iteration:13061  t-loss:0.2301, loss-lb:0.2037, loss-ulb:0.0132, weight:2.00, lr:0.0002
[06:36:47.381] iteration:13062  t-loss:0.2317, loss-lb:0.1969, loss-ulb:0.0174, weight:2.00, lr:0.0002
[06:36:47.708] iteration:13063  t-loss:0.2155, loss-lb:0.1175, loss-ulb:0.0490, weight:2.00, lr:0.0002
[06:36:48.026] iteration:13064  t-loss:0.1999, loss-lb:0.1662, loss-ulb:0.0168, weight:2.00, lr:0.0002
[06:36:48.346] iteration:13065  t-loss:0.3827, loss-lb:0.3101, loss-ulb:0.0363, weight:2.00, lr:0.0002
[06:36:48.664] iteration:13066  t-loss:0.3019, loss-lb:0.2448, loss-ulb:0.0286, weight:2.00, lr:0.0002
[06:36:49.007] iteration:13067  t-loss:0.3537, loss-lb:0.1727, loss-ulb:0.0905, weight:2.00, lr:0.0002
[06:36:49.337] iteration:13068  t-loss:0.1866, loss-lb:0.1522, loss-ulb:0.0172, weight:2.00, lr:0.0002
[06:36:49.668] iteration:13069  t-loss:0.1917, loss-lb:0.1590, loss-ulb:0.0164, weight:2.00, lr:0.0002
[06:36:49.998] iteration:13070  t-loss:0.3354, loss-lb:0.2001, loss-ulb:0.0677, weight:2.00, lr:0.0002
[06:36:50.323] iteration:13071  t-loss:0.3234, loss-lb:0.1505, loss-ulb:0.0865, weight:2.00, lr:0.0002
[06:36:50.640] iteration:13072  t-loss:0.2265, loss-lb:0.1069, loss-ulb:0.0598, weight:2.00, lr:0.0002
[06:36:50.956] iteration:13073  t-loss:0.2642, loss-lb:0.1566, loss-ulb:0.0538, weight:2.00, lr:0.0002
[06:36:51.272] iteration:13074  t-loss:0.3286, loss-lb:0.1487, loss-ulb:0.0900, weight:2.00, lr:0.0002
[06:36:51.590] iteration:13075  t-loss:0.2045, loss-lb:0.1380, loss-ulb:0.0332, weight:2.00, lr:0.0002
[06:36:53.011] iteration:13076  t-loss:0.2882, loss-lb:0.1456, loss-ulb:0.0713, weight:2.00, lr:0.0002
[06:36:53.353] iteration:13077  t-loss:0.2321, loss-lb:0.1431, loss-ulb:0.0445, weight:2.00, lr:0.0002
[06:36:53.685] iteration:13078  t-loss:0.1908, loss-lb:0.1532, loss-ulb:0.0188, weight:2.00, lr:0.0002
[06:36:54.006] iteration:13079  t-loss:0.3249, loss-lb:0.1405, loss-ulb:0.0922, weight:2.00, lr:0.0002
[06:36:54.330] iteration:13080  t-loss:0.4780, loss-lb:0.1914, loss-ulb:0.1433, weight:2.00, lr:0.0002
[06:36:54.652] iteration:13081  t-loss:0.4400, loss-lb:0.2323, loss-ulb:0.1039, weight:2.00, lr:0.0002
[06:36:54.967] iteration:13082  t-loss:0.1411, loss-lb:0.1115, loss-ulb:0.0148, weight:2.00, lr:0.0002
[06:36:55.284] iteration:13083  t-loss:0.3144, loss-lb:0.2143, loss-ulb:0.0500, weight:2.00, lr:0.0002
[06:36:55.600] iteration:13084  t-loss:0.3965, loss-lb:0.1511, loss-ulb:0.1227, weight:2.00, lr:0.0002
[06:36:55.915] iteration:13085  t-loss:0.1911, loss-lb:0.1637, loss-ulb:0.0137, weight:2.00, lr:0.0002
[06:36:56.233] iteration:13086  t-loss:0.2341, loss-lb:0.1330, loss-ulb:0.0505, weight:2.00, lr:0.0002
[06:36:56.550] iteration:13087  t-loss:0.2390, loss-lb:0.1852, loss-ulb:0.0269, weight:2.00, lr:0.0002
[06:36:56.864] iteration:13088  t-loss:0.1920, loss-lb:0.1489, loss-ulb:0.0215, weight:2.00, lr:0.0002
[06:36:57.185] iteration:13089  t-loss:0.5496, loss-lb:0.2219, loss-ulb:0.1638, weight:2.00, lr:0.0002
[06:36:57.508] iteration:13090  t-loss:0.2700, loss-lb:0.1322, loss-ulb:0.0689, weight:2.00, lr:0.0002
[06:36:57.838] iteration:13091  t-loss:0.3979, loss-lb:0.2668, loss-ulb:0.0655, weight:2.00, lr:0.0002
[06:36:58.176] iteration:13092  t-loss:0.3518, loss-lb:0.1918, loss-ulb:0.0800, weight:2.00, lr:0.0002
[06:36:58.506] iteration:13093  t-loss:0.4695, loss-lb:0.2195, loss-ulb:0.1250, weight:2.00, lr:0.0002
[06:36:58.834] iteration:13094  t-loss:0.3089, loss-lb:0.1756, loss-ulb:0.0666, weight:2.00, lr:0.0002
[06:36:59.151] iteration:13095  t-loss:0.1556, loss-lb:0.1206, loss-ulb:0.0175, weight:2.00, lr:0.0002
[06:36:59.465] iteration:13096  t-loss:0.5147, loss-lb:0.1381, loss-ulb:0.1883, weight:2.00, lr:0.0002
[06:36:59.788] iteration:13097  t-loss:0.4120, loss-lb:0.2350, loss-ulb:0.0885, weight:2.00, lr:0.0002
[06:37:00.106] iteration:13098  t-loss:0.2372, loss-lb:0.1677, loss-ulb:0.0347, weight:2.00, lr:0.0002
[06:37:00.426] iteration:13099  t-loss:0.3631, loss-lb:0.3351, loss-ulb:0.0140, weight:2.00, lr:0.0002
[06:37:00.750] iteration:13100  t-loss:0.2522, loss-lb:0.2075, loss-ulb:0.0223, weight:2.00, lr:0.0002
[06:37:02.183] iteration:13101  t-loss:0.3960, loss-lb:0.3288, loss-ulb:0.0336, weight:2.00, lr:0.0002
[06:37:02.526] iteration:13102  t-loss:0.3163, loss-lb:0.1612, loss-ulb:0.0775, weight:2.00, lr:0.0002
[06:37:02.854] iteration:13103  t-loss:0.1927, loss-lb:0.1585, loss-ulb:0.0171, weight:2.00, lr:0.0002
[06:37:03.187] iteration:13104  t-loss:0.3993, loss-lb:0.2039, loss-ulb:0.0977, weight:2.00, lr:0.0002
[06:37:03.521] iteration:13105  t-loss:0.3984, loss-lb:0.1832, loss-ulb:0.1076, weight:2.00, lr:0.0002
[06:37:03.843] iteration:13106  t-loss:0.3490, loss-lb:0.2159, loss-ulb:0.0666, weight:2.00, lr:0.0002
[06:37:04.161] iteration:13107  t-loss:0.4381, loss-lb:0.2100, loss-ulb:0.1141, weight:2.00, lr:0.0002
[06:37:04.486] iteration:13108  t-loss:0.3325, loss-lb:0.1492, loss-ulb:0.0916, weight:2.00, lr:0.0002
[06:37:04.800] iteration:13109  t-loss:0.2174, loss-lb:0.1879, loss-ulb:0.0148, weight:2.00, lr:0.0002
[06:37:05.123] iteration:13110  t-loss:0.4510, loss-lb:0.3219, loss-ulb:0.0646, weight:2.00, lr:0.0002
[06:37:05.437] iteration:13111  t-loss:0.1787, loss-lb:0.1458, loss-ulb:0.0164, weight:2.00, lr:0.0002
[06:37:05.756] iteration:13112  t-loss:0.3231, loss-lb:0.1531, loss-ulb:0.0850, weight:2.00, lr:0.0002
[06:37:06.088] iteration:13113  t-loss:0.3171, loss-lb:0.1617, loss-ulb:0.0777, weight:2.00, lr:0.0002
[06:37:06.422] iteration:13114  t-loss:0.3782, loss-lb:0.1472, loss-ulb:0.1155, weight:2.00, lr:0.0002
[06:37:06.756] iteration:13115  t-loss:0.2077, loss-lb:0.1724, loss-ulb:0.0177, weight:2.00, lr:0.0002
[06:37:07.080] iteration:13116  t-loss:0.2095, loss-lb:0.1552, loss-ulb:0.0271, weight:2.00, lr:0.0002
[06:37:07.412] iteration:13117  t-loss:0.2755, loss-lb:0.2247, loss-ulb:0.0254, weight:2.00, lr:0.0002
[06:37:07.741] iteration:13118  t-loss:0.3477, loss-lb:0.1377, loss-ulb:0.1050, weight:2.00, lr:0.0002
[06:37:08.064] iteration:13119  t-loss:0.4354, loss-lb:0.2021, loss-ulb:0.1167, weight:2.00, lr:0.0002
[06:37:08.381] iteration:13120  t-loss:0.4046, loss-lb:0.2167, loss-ulb:0.0939, weight:2.00, lr:0.0002
[06:37:08.701] iteration:13121  t-loss:0.4147, loss-lb:0.2181, loss-ulb:0.0983, weight:2.00, lr:0.0002
[06:37:09.020] iteration:13122  t-loss:0.2696, loss-lb:0.1353, loss-ulb:0.0671, weight:2.00, lr:0.0002
[06:37:09.336] iteration:13123  t-loss:0.2202, loss-lb:0.1831, loss-ulb:0.0185, weight:2.00, lr:0.0002
[06:37:09.656] iteration:13124  t-loss:0.3527, loss-lb:0.2618, loss-ulb:0.0455, weight:2.00, lr:0.0002
[06:37:09.974] iteration:13125  t-loss:0.2645, loss-lb:0.2142, loss-ulb:0.0251, weight:2.00, lr:0.0002
[06:39:23.282] iteration 13125 : dice_score: 0.852318 best_dice: 0.854000
[06:39:23.282]  <<Test>> - Ep:524  - Dice-S/T:85.15/85.23, Best-S:85.59, Best-T:85.40
[06:39:23.282]           - AvgLoss(lb/ulb/all):0.19/0.06/0.32
[06:39:24.637] iteration:13126  t-loss:0.3218, loss-lb:0.2041, loss-ulb:0.0588, weight:2.00, lr:0.0002
[06:39:24.966] iteration:13127  t-loss:0.1661, loss-lb:0.1264, loss-ulb:0.0198, weight:2.00, lr:0.0002
[06:39:25.293] iteration:13128  t-loss:0.2222, loss-lb:0.1757, loss-ulb:0.0232, weight:2.00, lr:0.0002
[06:39:25.616] iteration:13129  t-loss:0.4618, loss-lb:0.2410, loss-ulb:0.1104, weight:2.00, lr:0.0002
[06:39:25.939] iteration:13130  t-loss:0.3623, loss-lb:0.2671, loss-ulb:0.0476, weight:2.00, lr:0.0002
[06:39:26.255] iteration:13131  t-loss:0.2672, loss-lb:0.1236, loss-ulb:0.0718, weight:2.00, lr:0.0002
[06:39:26.572] iteration:13132  t-loss:0.1845, loss-lb:0.1492, loss-ulb:0.0177, weight:2.00, lr:0.0002
[06:39:26.892] iteration:13133  t-loss:0.3762, loss-lb:0.2152, loss-ulb:0.0805, weight:2.00, lr:0.0002
[06:39:27.209] iteration:13134  t-loss:0.4021, loss-lb:0.1954, loss-ulb:0.1034, weight:2.00, lr:0.0002
[06:39:27.528] iteration:13135  t-loss:0.1665, loss-lb:0.1283, loss-ulb:0.0191, weight:2.00, lr:0.0002
[06:39:27.850] iteration:13136  t-loss:0.3836, loss-lb:0.1698, loss-ulb:0.1069, weight:2.00, lr:0.0002
[06:39:28.170] iteration:13137  t-loss:0.3410, loss-lb:0.1417, loss-ulb:0.0997, weight:2.00, lr:0.0002
[06:39:28.487] iteration:13138  t-loss:0.1998, loss-lb:0.1278, loss-ulb:0.0360, weight:2.00, lr:0.0002
[06:39:28.810] iteration:13139  t-loss:0.2669, loss-lb:0.1466, loss-ulb:0.0602, weight:2.00, lr:0.0002
[06:39:29.131] iteration:13140  t-loss:0.2996, loss-lb:0.1718, loss-ulb:0.0639, weight:2.00, lr:0.0002
[06:39:29.454] iteration:13141  t-loss:0.2647, loss-lb:0.1826, loss-ulb:0.0410, weight:2.00, lr:0.0002
[06:39:29.771] iteration:13142  t-loss:0.2243, loss-lb:0.1338, loss-ulb:0.0453, weight:2.00, lr:0.0002
[06:39:30.090] iteration:13143  t-loss:0.4630, loss-lb:0.2123, loss-ulb:0.1253, weight:2.00, lr:0.0002
[06:39:30.408] iteration:13144  t-loss:0.2691, loss-lb:0.1743, loss-ulb:0.0474, weight:2.00, lr:0.0002
[06:39:30.729] iteration:13145  t-loss:0.5252, loss-lb:0.3546, loss-ulb:0.0853, weight:2.00, lr:0.0002
[06:39:31.058] iteration:13146  t-loss:0.3891, loss-lb:0.1874, loss-ulb:0.1009, weight:2.00, lr:0.0002
[06:39:31.380] iteration:13147  t-loss:0.3246, loss-lb:0.1445, loss-ulb:0.0900, weight:2.00, lr:0.0002
[06:39:31.707] iteration:13148  t-loss:0.1933, loss-lb:0.1682, loss-ulb:0.0126, weight:2.00, lr:0.0002
[06:39:32.029] iteration:13149  t-loss:0.2494, loss-lb:0.1281, loss-ulb:0.0607, weight:2.00, lr:0.0002
[06:39:32.350] iteration:13150  t-loss:0.2868, loss-lb:0.1863, loss-ulb:0.0503, weight:2.00, lr:0.0002
[06:39:33.810] iteration:13151  t-loss:0.5060, loss-lb:0.1789, loss-ulb:0.1635, weight:2.00, lr:0.0002
[06:39:34.144] iteration:13152  t-loss:0.2544, loss-lb:0.1895, loss-ulb:0.0324, weight:2.00, lr:0.0002
[06:39:34.467] iteration:13153  t-loss:0.7865, loss-lb:0.1692, loss-ulb:0.3086, weight:2.00, lr:0.0002
[06:39:34.788] iteration:13154  t-loss:0.1570, loss-lb:0.1250, loss-ulb:0.0160, weight:2.00, lr:0.0002
[06:39:35.107] iteration:13155  t-loss:0.2882, loss-lb:0.1292, loss-ulb:0.0795, weight:2.00, lr:0.0002
[06:39:35.432] iteration:13156  t-loss:0.3753, loss-lb:0.1480, loss-ulb:0.1137, weight:2.00, lr:0.0002
[06:39:35.751] iteration:13157  t-loss:0.2057, loss-lb:0.1682, loss-ulb:0.0188, weight:2.00, lr:0.0002
[06:39:36.067] iteration:13158  t-loss:0.2401, loss-lb:0.1313, loss-ulb:0.0544, weight:2.00, lr:0.0002
[06:39:36.392] iteration:13159  t-loss:0.3421, loss-lb:0.2179, loss-ulb:0.0621, weight:2.00, lr:0.0002
[06:39:36.709] iteration:13160  t-loss:0.3493, loss-lb:0.1717, loss-ulb:0.0888, weight:2.00, lr:0.0002
[06:39:37.026] iteration:13161  t-loss:0.2630, loss-lb:0.1412, loss-ulb:0.0609, weight:2.00, lr:0.0002
[06:39:37.367] iteration:13162  t-loss:0.4306, loss-lb:0.2844, loss-ulb:0.0731, weight:2.00, lr:0.0002
[06:39:37.686] iteration:13163  t-loss:0.3167, loss-lb:0.1333, loss-ulb:0.0917, weight:2.00, lr:0.0002
[06:39:38.003] iteration:13164  t-loss:0.1971, loss-lb:0.1000, loss-ulb:0.0485, weight:2.00, lr:0.0002
[06:39:38.322] iteration:13165  t-loss:0.2357, loss-lb:0.1913, loss-ulb:0.0222, weight:2.00, lr:0.0002
[06:39:38.636] iteration:13166  t-loss:0.2159, loss-lb:0.1924, loss-ulb:0.0117, weight:2.00, lr:0.0002
[06:39:38.956] iteration:13167  t-loss:0.2650, loss-lb:0.2029, loss-ulb:0.0311, weight:2.00, lr:0.0002
[06:39:39.271] iteration:13168  t-loss:0.2738, loss-lb:0.1282, loss-ulb:0.0728, weight:2.00, lr:0.0002
[06:39:39.592] iteration:13169  t-loss:0.2449, loss-lb:0.1951, loss-ulb:0.0249, weight:2.00, lr:0.0002
[06:39:39.917] iteration:13170  t-loss:0.8595, loss-lb:0.1507, loss-ulb:0.3544, weight:2.00, lr:0.0002
[06:39:40.244] iteration:13171  t-loss:0.3672, loss-lb:0.1868, loss-ulb:0.0902, weight:2.00, lr:0.0002
[06:39:40.571] iteration:13172  t-loss:0.4912, loss-lb:0.2602, loss-ulb:0.1155, weight:2.00, lr:0.0002
[06:39:40.896] iteration:13173  t-loss:0.4111, loss-lb:0.2771, loss-ulb:0.0670, weight:2.00, lr:0.0002
[06:39:41.212] iteration:13174  t-loss:0.3892, loss-lb:0.2597, loss-ulb:0.0648, weight:2.00, lr:0.0002
[06:39:41.526] iteration:13175  t-loss:0.3455, loss-lb:0.1401, loss-ulb:0.1027, weight:2.00, lr:0.0002
[06:39:42.865] iteration:13176  t-loss:0.2755, loss-lb:0.1099, loss-ulb:0.0828, weight:2.00, lr:0.0002
[06:39:43.219] iteration:13177  t-loss:0.3691, loss-lb:0.2418, loss-ulb:0.0637, weight:2.00, lr:0.0002
[06:39:43.559] iteration:13178  t-loss:0.2549, loss-lb:0.1441, loss-ulb:0.0554, weight:2.00, lr:0.0002
[06:39:43.894] iteration:13179  t-loss:0.5231, loss-lb:0.1703, loss-ulb:0.1764, weight:2.00, lr:0.0001
[06:39:44.222] iteration:13180  t-loss:0.3243, loss-lb:0.1554, loss-ulb:0.0844, weight:2.00, lr:0.0001
[06:39:44.553] iteration:13181  t-loss:0.3149, loss-lb:0.2017, loss-ulb:0.0566, weight:2.00, lr:0.0001
[06:39:44.881] iteration:13182  t-loss:0.1799, loss-lb:0.1382, loss-ulb:0.0209, weight:2.00, lr:0.0001
[06:39:45.216] iteration:13183  t-loss:0.5037, loss-lb:0.3677, loss-ulb:0.0680, weight:2.00, lr:0.0001
[06:39:45.549] iteration:13184  t-loss:0.3792, loss-lb:0.1265, loss-ulb:0.1263, weight:2.00, lr:0.0001
[06:39:45.878] iteration:13185  t-loss:0.2780, loss-lb:0.2492, loss-ulb:0.0144, weight:2.00, lr:0.0001
[06:39:46.195] iteration:13186  t-loss:0.2095, loss-lb:0.1478, loss-ulb:0.0309, weight:2.00, lr:0.0001
[06:39:46.525] iteration:13187  t-loss:0.4186, loss-lb:0.2629, loss-ulb:0.0778, weight:2.00, lr:0.0001
[06:39:46.845] iteration:13188  t-loss:0.2367, loss-lb:0.1506, loss-ulb:0.0430, weight:2.00, lr:0.0001
[06:39:47.162] iteration:13189  t-loss:0.2228, loss-lb:0.1340, loss-ulb:0.0444, weight:2.00, lr:0.0001
[06:39:47.479] iteration:13190  t-loss:0.1861, loss-lb:0.1470, loss-ulb:0.0196, weight:2.00, lr:0.0001
[06:39:47.793] iteration:13191  t-loss:0.2326, loss-lb:0.2051, loss-ulb:0.0137, weight:2.00, lr:0.0001
[06:39:48.116] iteration:13192  t-loss:0.1766, loss-lb:0.1202, loss-ulb:0.0282, weight:2.00, lr:0.0001
[06:39:48.450] iteration:13193  t-loss:0.2758, loss-lb:0.1375, loss-ulb:0.0692, weight:2.00, lr:0.0001
[06:39:48.784] iteration:13194  t-loss:0.3138, loss-lb:0.1970, loss-ulb:0.0584, weight:2.00, lr:0.0001
[06:39:49.104] iteration:13195  t-loss:0.1709, loss-lb:0.1358, loss-ulb:0.0175, weight:2.00, lr:0.0001
[06:39:49.425] iteration:13196  t-loss:0.3072, loss-lb:0.2137, loss-ulb:0.0467, weight:2.00, lr:0.0001
[06:39:49.741] iteration:13197  t-loss:0.2878, loss-lb:0.2523, loss-ulb:0.0177, weight:2.00, lr:0.0001
[06:39:50.054] iteration:13198  t-loss:0.1781, loss-lb:0.1515, loss-ulb:0.0133, weight:2.00, lr:0.0001
[06:39:50.373] iteration:13199  t-loss:0.2793, loss-lb:0.2072, loss-ulb:0.0360, weight:2.00, lr:0.0001
[06:39:50.689] iteration:13200  t-loss:0.1941, loss-lb:0.1315, loss-ulb:0.0313, weight:2.00, lr:0.0001
[06:39:52.130] iteration:13201  t-loss:0.4368, loss-lb:0.2054, loss-ulb:0.1157, weight:2.00, lr:0.0001
[06:39:52.475] iteration:13202  t-loss:0.3210, loss-lb:0.1237, loss-ulb:0.0987, weight:2.00, lr:0.0001
[06:39:52.818] iteration:13203  t-loss:0.2390, loss-lb:0.1641, loss-ulb:0.0375, weight:2.00, lr:0.0001
[06:39:53.170] iteration:13204  t-loss:0.3692, loss-lb:0.2009, loss-ulb:0.0842, weight:2.00, lr:0.0001
[06:39:53.523] iteration:13205  t-loss:0.5190, loss-lb:0.2597, loss-ulb:0.1296, weight:2.00, lr:0.0001
[06:39:53.870] iteration:13206  t-loss:0.3722, loss-lb:0.1260, loss-ulb:0.1231, weight:2.00, lr:0.0001
[06:39:54.207] iteration:13207  t-loss:0.2136, loss-lb:0.1694, loss-ulb:0.0221, weight:2.00, lr:0.0001
[06:39:54.534] iteration:13208  t-loss:0.2692, loss-lb:0.1745, loss-ulb:0.0474, weight:2.00, lr:0.0001
[06:39:54.867] iteration:13209  t-loss:0.4222, loss-lb:0.2773, loss-ulb:0.0725, weight:2.00, lr:0.0001
[06:39:55.184] iteration:13210  t-loss:0.1706, loss-lb:0.1447, loss-ulb:0.0130, weight:2.00, lr:0.0001
[06:39:55.499] iteration:13211  t-loss:0.1926, loss-lb:0.1576, loss-ulb:0.0175, weight:2.00, lr:0.0001
[06:39:55.812] iteration:13212  t-loss:0.3093, loss-lb:0.1301, loss-ulb:0.0896, weight:2.00, lr:0.0001
[06:39:56.128] iteration:13213  t-loss:0.2883, loss-lb:0.2360, loss-ulb:0.0262, weight:2.00, lr:0.0001
[06:39:56.453] iteration:13214  t-loss:0.2214, loss-lb:0.1364, loss-ulb:0.0425, weight:2.00, lr:0.0001
[06:39:56.781] iteration:13215  t-loss:0.2492, loss-lb:0.1297, loss-ulb:0.0598, weight:2.00, lr:0.0001
[06:39:57.117] iteration:13216  t-loss:0.2147, loss-lb:0.1746, loss-ulb:0.0200, weight:2.00, lr:0.0001
[06:39:57.463] iteration:13217  t-loss:0.3595, loss-lb:0.2144, loss-ulb:0.0726, weight:2.00, lr:0.0001
[06:39:57.820] iteration:13218  t-loss:0.2413, loss-lb:0.1282, loss-ulb:0.0566, weight:2.00, lr:0.0001
[06:39:58.163] iteration:13219  t-loss:0.6449, loss-lb:0.1488, loss-ulb:0.2481, weight:2.00, lr:0.0001
[06:39:58.517] iteration:13220  t-loss:0.2570, loss-lb:0.2245, loss-ulb:0.0163, weight:2.00, lr:0.0001
[06:39:58.881] iteration:13221  t-loss:0.9373, loss-lb:0.0969, loss-ulb:0.4202, weight:2.00, lr:0.0001
[06:39:59.267] iteration:13222  t-loss:0.3515, loss-lb:0.1782, loss-ulb:0.0867, weight:2.00, lr:0.0001
[06:39:59.619] iteration:13223  t-loss:0.4615, loss-lb:0.1986, loss-ulb:0.1315, weight:2.00, lr:0.0001
[06:39:59.968] iteration:13224  t-loss:0.2237, loss-lb:0.1235, loss-ulb:0.0501, weight:2.00, lr:0.0001
[06:40:00.333] iteration:13225  t-loss:0.1542, loss-lb:0.1220, loss-ulb:0.0161, weight:2.00, lr:0.0001
[06:42:16.121] iteration 13225 : dice_score: 0.851454 best_dice: 0.854000
[06:42:16.121]  <<Test>> - Ep:528  - Dice-S/T:85.01/85.15, Best-S:85.59, Best-T:85.40
[06:42:16.121]           - AvgLoss(lb/ulb/all):0.17/0.08/0.33
[06:42:17.367] iteration:13226  t-loss:0.4004, loss-lb:0.2275, loss-ulb:0.0864, weight:2.00, lr:0.0001
[06:42:17.702] iteration:13227  t-loss:0.2391, loss-lb:0.1908, loss-ulb:0.0242, weight:2.00, lr:0.0001
[06:42:18.020] iteration:13228  t-loss:0.1836, loss-lb:0.1317, loss-ulb:0.0260, weight:2.00, lr:0.0001
[06:42:18.339] iteration:13229  t-loss:0.1816, loss-lb:0.1424, loss-ulb:0.0196, weight:2.00, lr:0.0001
[06:42:18.657] iteration:13230  t-loss:0.3651, loss-lb:0.1760, loss-ulb:0.0946, weight:2.00, lr:0.0001
[06:42:18.976] iteration:13231  t-loss:0.3129, loss-lb:0.2504, loss-ulb:0.0313, weight:2.00, lr:0.0001
[06:42:19.300] iteration:13232  t-loss:0.3719, loss-lb:0.1698, loss-ulb:0.1010, weight:2.00, lr:0.0001
[06:42:19.621] iteration:13233  t-loss:0.1874, loss-lb:0.1218, loss-ulb:0.0328, weight:2.00, lr:0.0001
[06:42:19.945] iteration:13234  t-loss:0.3469, loss-lb:0.1488, loss-ulb:0.0990, weight:2.00, lr:0.0001
[06:42:20.265] iteration:13235  t-loss:0.2297, loss-lb:0.1999, loss-ulb:0.0149, weight:2.00, lr:0.0001
[06:42:20.585] iteration:13236  t-loss:0.4021, loss-lb:0.1516, loss-ulb:0.1253, weight:2.00, lr:0.0001
[06:42:20.905] iteration:13237  t-loss:0.1792, loss-lb:0.1465, loss-ulb:0.0163, weight:2.00, lr:0.0001
[06:42:21.228] iteration:13238  t-loss:0.2571, loss-lb:0.2154, loss-ulb:0.0209, weight:2.00, lr:0.0001
[06:42:21.552] iteration:13239  t-loss:0.3917, loss-lb:0.1930, loss-ulb:0.0993, weight:2.00, lr:0.0001
[06:42:21.874] iteration:13240  t-loss:0.1928, loss-lb:0.1663, loss-ulb:0.0133, weight:2.00, lr:0.0001
[06:42:22.194] iteration:13241  t-loss:0.3632, loss-lb:0.2166, loss-ulb:0.0733, weight:2.00, lr:0.0001
[06:42:22.515] iteration:13242  t-loss:0.1637, loss-lb:0.1283, loss-ulb:0.0177, weight:2.00, lr:0.0001
[06:42:22.835] iteration:13243  t-loss:0.2222, loss-lb:0.2017, loss-ulb:0.0102, weight:2.00, lr:0.0001
[06:42:23.153] iteration:13244  t-loss:0.3431, loss-lb:0.1876, loss-ulb:0.0777, weight:2.00, lr:0.0001
[06:42:23.473] iteration:13245  t-loss:0.4581, loss-lb:0.2556, loss-ulb:0.1012, weight:2.00, lr:0.0001
[06:42:23.793] iteration:13246  t-loss:0.3480, loss-lb:0.3078, loss-ulb:0.0201, weight:2.00, lr:0.0001
[06:42:24.111] iteration:13247  t-loss:0.2446, loss-lb:0.2137, loss-ulb:0.0155, weight:2.00, lr:0.0001
[06:42:24.429] iteration:13248  t-loss:0.1850, loss-lb:0.1522, loss-ulb:0.0164, weight:2.00, lr:0.0001
[06:42:24.748] iteration:13249  t-loss:0.2542, loss-lb:0.1148, loss-ulb:0.0697, weight:2.00, lr:0.0001
[06:42:25.065] iteration:13250  t-loss:0.5159, loss-lb:0.2240, loss-ulb:0.1460, weight:2.00, lr:0.0001
[06:42:26.194] iteration:13251  t-loss:0.2487, loss-lb:0.1175, loss-ulb:0.0656, weight:2.00, lr:0.0001
[06:42:26.543] iteration:13252  t-loss:0.2399, loss-lb:0.1439, loss-ulb:0.0480, weight:2.00, lr:0.0001
[06:42:26.879] iteration:13253  t-loss:0.3510, loss-lb:0.1307, loss-ulb:0.1101, weight:2.00, lr:0.0001
[06:42:27.205] iteration:13254  t-loss:0.1838, loss-lb:0.1500, loss-ulb:0.0169, weight:2.00, lr:0.0001
[06:42:27.525] iteration:13255  t-loss:0.2579, loss-lb:0.2104, loss-ulb:0.0237, weight:2.00, lr:0.0001
[06:42:27.844] iteration:13256  t-loss:0.1889, loss-lb:0.1557, loss-ulb:0.0166, weight:2.00, lr:0.0001
[06:42:28.170] iteration:13257  t-loss:0.2882, loss-lb:0.1747, loss-ulb:0.0568, weight:2.00, lr:0.0001
[06:42:28.495] iteration:13258  t-loss:0.4067, loss-lb:0.2411, loss-ulb:0.0828, weight:2.00, lr:0.0001
[06:42:28.816] iteration:13259  t-loss:0.2168, loss-lb:0.1701, loss-ulb:0.0233, weight:2.00, lr:0.0001
[06:42:29.136] iteration:13260  t-loss:0.1555, loss-lb:0.1286, loss-ulb:0.0134, weight:2.00, lr:0.0001
[06:42:29.460] iteration:13261  t-loss:0.2424, loss-lb:0.2038, loss-ulb:0.0193, weight:2.00, lr:0.0001
[06:42:29.782] iteration:13262  t-loss:0.2232, loss-lb:0.1765, loss-ulb:0.0234, weight:2.00, lr:0.0001
[06:42:30.108] iteration:13263  t-loss:0.3108, loss-lb:0.1743, loss-ulb:0.0683, weight:2.00, lr:0.0001
[06:42:30.428] iteration:13264  t-loss:0.1867, loss-lb:0.1468, loss-ulb:0.0199, weight:2.00, lr:0.0001
[06:42:30.754] iteration:13265  t-loss:0.4391, loss-lb:0.2502, loss-ulb:0.0944, weight:2.00, lr:0.0001
[06:42:31.074] iteration:13266  t-loss:0.1753, loss-lb:0.1550, loss-ulb:0.0102, weight:2.00, lr:0.0001
[06:42:31.405] iteration:13267  t-loss:0.2327, loss-lb:0.1180, loss-ulb:0.0574, weight:2.00, lr:0.0001
[06:42:31.737] iteration:13268  t-loss:0.5673, loss-lb:0.2159, loss-ulb:0.1757, weight:2.00, lr:0.0001
[06:42:32.070] iteration:13269  t-loss:0.1727, loss-lb:0.1398, loss-ulb:0.0164, weight:2.00, lr:0.0001
[06:42:32.400] iteration:13270  t-loss:0.3896, loss-lb:0.2200, loss-ulb:0.0848, weight:2.00, lr:0.0001
[06:42:32.727] iteration:13271  t-loss:0.3051, loss-lb:0.1395, loss-ulb:0.0828, weight:2.00, lr:0.0001
[06:42:33.050] iteration:13272  t-loss:0.2854, loss-lb:0.1984, loss-ulb:0.0435, weight:2.00, lr:0.0001
[06:42:33.365] iteration:13273  t-loss:0.3526, loss-lb:0.1692, loss-ulb:0.0917, weight:2.00, lr:0.0001
[06:42:33.680] iteration:13274  t-loss:0.2822, loss-lb:0.2283, loss-ulb:0.0270, weight:2.00, lr:0.0001
[06:42:33.994] iteration:13275  t-loss:0.2562, loss-lb:0.2077, loss-ulb:0.0243, weight:2.00, lr:0.0001
[06:42:35.643] iteration:13276  t-loss:0.3165, loss-lb:0.2366, loss-ulb:0.0399, weight:2.00, lr:0.0001
[06:42:35.990] iteration:13277  t-loss:0.4943, loss-lb:0.1291, loss-ulb:0.1826, weight:2.00, lr:0.0001
[06:42:36.340] iteration:13278  t-loss:0.3241, loss-lb:0.2031, loss-ulb:0.0605, weight:2.00, lr:0.0001
[06:42:36.697] iteration:13279  t-loss:0.4475, loss-lb:0.1937, loss-ulb:0.1269, weight:2.00, lr:0.0001
[06:42:37.033] iteration:13280  t-loss:0.1911, loss-lb:0.1539, loss-ulb:0.0186, weight:2.00, lr:0.0001
[06:42:37.365] iteration:13281  t-loss:0.2939, loss-lb:0.1522, loss-ulb:0.0708, weight:2.00, lr:0.0001
[06:42:37.686] iteration:13282  t-loss:0.2021, loss-lb:0.1518, loss-ulb:0.0252, weight:2.00, lr:0.0001
[06:42:38.007] iteration:13283  t-loss:0.2823, loss-lb:0.2496, loss-ulb:0.0164, weight:2.00, lr:0.0001
[06:42:38.327] iteration:13284  t-loss:0.3320, loss-lb:0.2260, loss-ulb:0.0530, weight:2.00, lr:0.0001
[06:42:38.645] iteration:13285  t-loss:0.2025, loss-lb:0.1125, loss-ulb:0.0450, weight:2.00, lr:0.0001
[06:42:38.964] iteration:13286  t-loss:0.3402, loss-lb:0.2117, loss-ulb:0.0642, weight:2.00, lr:0.0001
[06:42:39.286] iteration:13287  t-loss:0.3683, loss-lb:0.1823, loss-ulb:0.0930, weight:2.00, lr:0.0001
[06:42:39.608] iteration:13288  t-loss:0.3234, loss-lb:0.1819, loss-ulb:0.0707, weight:2.00, lr:0.0001
[06:42:39.935] iteration:13289  t-loss:0.1751, loss-lb:0.1442, loss-ulb:0.0154, weight:2.00, lr:0.0001
[06:42:40.261] iteration:13290  t-loss:0.1778, loss-lb:0.1312, loss-ulb:0.0233, weight:2.00, lr:0.0001
[06:42:40.603] iteration:13291  t-loss:0.3799, loss-lb:0.2680, loss-ulb:0.0560, weight:2.00, lr:0.0001
[06:42:40.938] iteration:13292  t-loss:0.3296, loss-lb:0.2264, loss-ulb:0.0516, weight:2.00, lr:0.0001
[06:42:41.264] iteration:13293  t-loss:0.3961, loss-lb:0.1887, loss-ulb:0.1037, weight:2.00, lr:0.0001
[06:42:41.584] iteration:13294  t-loss:0.4212, loss-lb:0.1565, loss-ulb:0.1323, weight:2.00, lr:0.0001
[06:42:41.902] iteration:13295  t-loss:0.2916, loss-lb:0.1897, loss-ulb:0.0510, weight:2.00, lr:0.0001
[06:42:42.216] iteration:13296  t-loss:0.2992, loss-lb:0.1339, loss-ulb:0.0826, weight:2.00, lr:0.0001
[06:42:42.534] iteration:13297  t-loss:0.3341, loss-lb:0.2998, loss-ulb:0.0172, weight:2.00, lr:0.0001
[06:42:42.853] iteration:13298  t-loss:0.2403, loss-lb:0.1677, loss-ulb:0.0363, weight:2.00, lr:0.0001
[06:42:43.172] iteration:13299  t-loss:0.3052, loss-lb:0.2740, loss-ulb:0.0156, weight:2.00, lr:0.0001
[06:42:43.489] iteration:13300  t-loss:0.2533, loss-lb:0.2219, loss-ulb:0.0157, weight:2.00, lr:0.0001
[06:42:45.065] iteration:13301  t-loss:0.3212, loss-lb:0.1792, loss-ulb:0.0710, weight:2.00, lr:0.0001
[06:42:45.402] iteration:13302  t-loss:0.2275, loss-lb:0.1342, loss-ulb:0.0466, weight:2.00, lr:0.0001
[06:42:45.741] iteration:13303  t-loss:0.3421, loss-lb:0.2004, loss-ulb:0.0708, weight:2.00, lr:0.0001
[06:42:46.066] iteration:13304  t-loss:0.2677, loss-lb:0.2398, loss-ulb:0.0139, weight:2.00, lr:0.0001
[06:42:46.388] iteration:13305  t-loss:0.3493, loss-lb:0.3181, loss-ulb:0.0156, weight:2.00, lr:0.0001
[06:42:46.706] iteration:13306  t-loss:0.2928, loss-lb:0.1244, loss-ulb:0.0842, weight:2.00, lr:0.0001
[06:42:47.024] iteration:13307  t-loss:0.3549, loss-lb:0.3079, loss-ulb:0.0235, weight:2.00, lr:0.0001
[06:42:47.341] iteration:13308  t-loss:0.2733, loss-lb:0.1452, loss-ulb:0.0641, weight:2.00, lr:0.0001
[06:42:47.656] iteration:13309  t-loss:0.2090, loss-lb:0.1700, loss-ulb:0.0195, weight:2.00, lr:0.0001
[06:42:47.978] iteration:13310  t-loss:0.3460, loss-lb:0.1851, loss-ulb:0.0804, weight:2.00, lr:0.0001
[06:42:48.302] iteration:13311  t-loss:0.3660, loss-lb:0.1518, loss-ulb:0.1071, weight:2.00, lr:0.0001
[06:42:48.631] iteration:13312  t-loss:0.2245, loss-lb:0.1170, loss-ulb:0.0538, weight:2.00, lr:0.0001
[06:42:48.967] iteration:13313  t-loss:0.3500, loss-lb:0.2532, loss-ulb:0.0484, weight:2.00, lr:0.0001
[06:42:49.298] iteration:13314  t-loss:0.1870, loss-lb:0.1450, loss-ulb:0.0210, weight:2.00, lr:0.0001
[06:42:49.636] iteration:13315  t-loss:0.2490, loss-lb:0.2160, loss-ulb:0.0165, weight:2.00, lr:0.0001
[06:42:49.966] iteration:13316  t-loss:0.1822, loss-lb:0.1200, loss-ulb:0.0311, weight:2.00, lr:0.0001
[06:42:50.310] iteration:13317  t-loss:0.2851, loss-lb:0.1707, loss-ulb:0.0572, weight:2.00, lr:0.0001
[06:42:50.634] iteration:13318  t-loss:0.2237, loss-lb:0.1554, loss-ulb:0.0341, weight:2.00, lr:0.0001
[06:42:50.950] iteration:13319  t-loss:0.1630, loss-lb:0.1290, loss-ulb:0.0170, weight:2.00, lr:0.0001
[06:42:51.269] iteration:13320  t-loss:0.2343, loss-lb:0.2028, loss-ulb:0.0157, weight:2.00, lr:0.0001
[06:42:51.585] iteration:13321  t-loss:0.2489, loss-lb:0.1756, loss-ulb:0.0366, weight:2.00, lr:0.0001
[06:42:51.904] iteration:13322  t-loss:0.3143, loss-lb:0.2199, loss-ulb:0.0472, weight:2.00, lr:0.0001
[06:42:52.223] iteration:13323  t-loss:0.2589, loss-lb:0.1797, loss-ulb:0.0396, weight:2.00, lr:0.0001
[06:42:52.539] iteration:13324  t-loss:0.2196, loss-lb:0.1862, loss-ulb:0.0167, weight:2.00, lr:0.0001
[06:42:52.855] iteration:13325  t-loss:0.2020, loss-lb:0.1438, loss-ulb:0.0291, weight:2.00, lr:0.0001
[06:45:04.805] iteration 13325 : dice_score: 0.851412 best_dice: 0.854000
[06:45:04.805]  <<Test>> - Ep:532  - Dice-S/T:85.02/85.14, Best-S:85.59, Best-T:85.40
[06:45:04.805]           - AvgLoss(lb/ulb/all):0.18/0.04/0.26
[06:45:06.144] iteration:13326  t-loss:0.4835, loss-lb:0.2588, loss-ulb:0.1124, weight:2.00, lr:0.0001
[06:45:06.476] iteration:13327  t-loss:0.5332, loss-lb:0.1782, loss-ulb:0.1775, weight:2.00, lr:0.0001
[06:45:06.811] iteration:13328  t-loss:0.2681, loss-lb:0.1677, loss-ulb:0.0502, weight:2.00, lr:0.0001
[06:45:07.137] iteration:13329  t-loss:0.2479, loss-lb:0.2097, loss-ulb:0.0191, weight:2.00, lr:0.0001
[06:45:07.458] iteration:13330  t-loss:0.2809, loss-lb:0.1233, loss-ulb:0.0788, weight:2.00, lr:0.0001
[06:45:07.782] iteration:13331  t-loss:0.3195, loss-lb:0.2961, loss-ulb:0.0117, weight:2.00, lr:0.0001
[06:45:08.101] iteration:13332  t-loss:0.2365, loss-lb:0.1164, loss-ulb:0.0601, weight:2.00, lr:0.0001
[06:45:08.419] iteration:13333  t-loss:0.3307, loss-lb:0.2810, loss-ulb:0.0248, weight:2.00, lr:0.0001
[06:45:08.738] iteration:13334  t-loss:0.1995, loss-lb:0.1644, loss-ulb:0.0175, weight:2.00, lr:0.0001
[06:45:09.059] iteration:13335  t-loss:0.3832, loss-lb:0.2866, loss-ulb:0.0483, weight:2.00, lr:0.0001
[06:45:09.386] iteration:13336  t-loss:0.2413, loss-lb:0.1924, loss-ulb:0.0245, weight:2.00, lr:0.0001
[06:45:09.717] iteration:13337  t-loss:0.1544, loss-lb:0.1254, loss-ulb:0.0145, weight:2.00, lr:0.0001
[06:45:10.051] iteration:13338  t-loss:0.2831, loss-lb:0.1491, loss-ulb:0.0670, weight:2.00, lr:0.0001
[06:45:10.385] iteration:13339  t-loss:0.3752, loss-lb:0.2785, loss-ulb:0.0484, weight:2.00, lr:0.0001
[06:45:10.713] iteration:13340  t-loss:0.2107, loss-lb:0.1213, loss-ulb:0.0447, weight:2.00, lr:0.0001
[06:45:11.041] iteration:13341  t-loss:0.2596, loss-lb:0.1369, loss-ulb:0.0614, weight:2.00, lr:0.0001
[06:45:11.361] iteration:13342  t-loss:0.2124, loss-lb:0.1316, loss-ulb:0.0404, weight:2.00, lr:0.0001
[06:45:11.681] iteration:13343  t-loss:0.2677, loss-lb:0.1459, loss-ulb:0.0609, weight:2.00, lr:0.0001
[06:45:11.999] iteration:13344  t-loss:0.2337, loss-lb:0.1502, loss-ulb:0.0418, weight:2.00, lr:0.0001
[06:45:12.317] iteration:13345  t-loss:0.3116, loss-lb:0.1915, loss-ulb:0.0601, weight:2.00, lr:0.0001
[06:45:12.635] iteration:13346  t-loss:0.2110, loss-lb:0.1855, loss-ulb:0.0127, weight:2.00, lr:0.0001
[06:45:12.950] iteration:13347  t-loss:0.2165, loss-lb:0.1783, loss-ulb:0.0191, weight:2.00, lr:0.0001
[06:45:13.269] iteration:13348  t-loss:0.4211, loss-lb:0.2034, loss-ulb:0.1089, weight:2.00, lr:0.0001
[06:45:13.582] iteration:13349  t-loss:0.1830, loss-lb:0.1500, loss-ulb:0.0165, weight:2.00, lr:0.0001
[06:45:13.898] iteration:13350  t-loss:0.2758, loss-lb:0.2345, loss-ulb:0.0206, weight:2.00, lr:0.0001
[06:45:15.178] iteration:13351  t-loss:0.4966, loss-lb:0.2801, loss-ulb:0.1082, weight:2.00, lr:0.0001
[06:45:15.511] iteration:13352  t-loss:0.2479, loss-lb:0.1632, loss-ulb:0.0424, weight:2.00, lr:0.0001
[06:45:15.836] iteration:13353  t-loss:0.3297, loss-lb:0.1621, loss-ulb:0.0838, weight:2.00, lr:0.0001
[06:45:16.156] iteration:13354  t-loss:0.3374, loss-lb:0.1555, loss-ulb:0.0909, weight:2.00, lr:0.0001
[06:45:16.475] iteration:13355  t-loss:0.2819, loss-lb:0.1209, loss-ulb:0.0805, weight:2.00, lr:0.0001
[06:45:16.794] iteration:13356  t-loss:0.2333, loss-lb:0.2088, loss-ulb:0.0122, weight:2.00, lr:0.0001
[06:45:17.107] iteration:13357  t-loss:0.2565, loss-lb:0.2206, loss-ulb:0.0179, weight:2.00, lr:0.0001
[06:45:17.424] iteration:13358  t-loss:0.3358, loss-lb:0.2073, loss-ulb:0.0643, weight:2.00, lr:0.0001
[06:45:17.742] iteration:13359  t-loss:0.4361, loss-lb:0.3208, loss-ulb:0.0577, weight:2.00, lr:0.0001
[06:45:18.057] iteration:13360  t-loss:0.2428, loss-lb:0.1251, loss-ulb:0.0588, weight:2.00, lr:0.0001
[06:45:18.373] iteration:13361  t-loss:0.6131, loss-lb:0.2564, loss-ulb:0.1783, weight:2.00, lr:0.0001
[06:45:18.687] iteration:13362  t-loss:0.2097, loss-lb:0.1521, loss-ulb:0.0288, weight:2.00, lr:0.0001
[06:45:19.002] iteration:13363  t-loss:0.1948, loss-lb:0.1630, loss-ulb:0.0159, weight:2.00, lr:0.0001
[06:45:19.316] iteration:13364  t-loss:0.1620, loss-lb:0.1363, loss-ulb:0.0129, weight:2.00, lr:0.0001
[06:45:19.631] iteration:13365  t-loss:0.3282, loss-lb:0.1698, loss-ulb:0.0792, weight:2.00, lr:0.0001
[06:45:19.948] iteration:13366  t-loss:0.3211, loss-lb:0.2925, loss-ulb:0.0143, weight:2.00, lr:0.0001
[06:45:20.265] iteration:13367  t-loss:0.3861, loss-lb:0.1497, loss-ulb:0.1182, weight:2.00, lr:0.0001
[06:45:20.579] iteration:13368  t-loss:0.3437, loss-lb:0.1706, loss-ulb:0.0865, weight:2.00, lr:0.0001
[06:45:20.893] iteration:13369  t-loss:0.3609, loss-lb:0.3100, loss-ulb:0.0254, weight:2.00, lr:0.0001
[06:45:21.206] iteration:13370  t-loss:0.2795, loss-lb:0.1394, loss-ulb:0.0700, weight:2.00, lr:0.0001
[06:45:21.520] iteration:13371  t-loss:0.3236, loss-lb:0.1546, loss-ulb:0.0845, weight:2.00, lr:0.0001
[06:45:21.835] iteration:13372  t-loss:0.2699, loss-lb:0.1233, loss-ulb:0.0733, weight:2.00, lr:0.0001
[06:45:22.148] iteration:13373  t-loss:0.2195, loss-lb:0.1828, loss-ulb:0.0184, weight:2.00, lr:0.0001
[06:45:22.461] iteration:13374  t-loss:0.2251, loss-lb:0.1959, loss-ulb:0.0146, weight:2.00, lr:0.0001
[06:45:22.778] iteration:13375  t-loss:0.2542, loss-lb:0.1397, loss-ulb:0.0572, weight:2.00, lr:0.0001
[06:45:24.007] iteration:13376  t-loss:0.2143, loss-lb:0.1730, loss-ulb:0.0207, weight:2.00, lr:0.0001
[06:45:24.343] iteration:13377  t-loss:0.3850, loss-lb:0.1587, loss-ulb:0.1132, weight:2.00, lr:0.0001
[06:45:24.673] iteration:13378  t-loss:0.7359, loss-lb:0.3135, loss-ulb:0.2112, weight:2.00, lr:0.0001
[06:45:24.991] iteration:13379  t-loss:0.2709, loss-lb:0.1390, loss-ulb:0.0660, weight:2.00, lr:0.0001
[06:45:25.310] iteration:13380  t-loss:0.3345, loss-lb:0.2253, loss-ulb:0.0546, weight:2.00, lr:0.0001
[06:45:25.626] iteration:13381  t-loss:0.4867, loss-lb:0.1354, loss-ulb:0.1757, weight:2.00, lr:0.0001
[06:45:25.944] iteration:13382  t-loss:0.3673, loss-lb:0.2172, loss-ulb:0.0751, weight:2.00, lr:0.0001
[06:45:26.260] iteration:13383  t-loss:0.2229, loss-lb:0.1835, loss-ulb:0.0197, weight:2.00, lr:0.0001
[06:45:26.576] iteration:13384  t-loss:0.3296, loss-lb:0.1283, loss-ulb:0.1006, weight:2.00, lr:0.0001
[06:45:26.892] iteration:13385  t-loss:0.3261, loss-lb:0.1533, loss-ulb:0.0864, weight:2.00, lr:0.0001
[06:45:27.209] iteration:13386  t-loss:0.1884, loss-lb:0.1605, loss-ulb:0.0140, weight:2.00, lr:0.0001
[06:45:27.526] iteration:13387  t-loss:0.2614, loss-lb:0.1823, loss-ulb:0.0395, weight:2.00, lr:0.0001
[06:45:27.839] iteration:13388  t-loss:0.2670, loss-lb:0.1905, loss-ulb:0.0383, weight:2.00, lr:0.0001
[06:45:28.154] iteration:13389  t-loss:0.2972, loss-lb:0.1668, loss-ulb:0.0652, weight:2.00, lr:0.0001
[06:45:28.473] iteration:13390  t-loss:0.3453, loss-lb:0.1810, loss-ulb:0.0822, weight:2.00, lr:0.0001
[06:45:28.786] iteration:13391  t-loss:0.1997, loss-lb:0.1341, loss-ulb:0.0328, weight:2.00, lr:0.0001
[06:45:29.103] iteration:13392  t-loss:0.2479, loss-lb:0.1640, loss-ulb:0.0419, weight:2.00, lr:0.0001
[06:45:29.417] iteration:13393  t-loss:0.1903, loss-lb:0.1392, loss-ulb:0.0256, weight:2.00, lr:0.0001
[06:45:29.736] iteration:13394  t-loss:0.4029, loss-lb:0.1775, loss-ulb:0.1127, weight:2.00, lr:0.0001
[06:45:30.059] iteration:13395  t-loss:0.9984, loss-lb:0.1637, loss-ulb:0.4174, weight:2.00, lr:0.0001
[06:45:30.372] iteration:13396  t-loss:0.1842, loss-lb:0.1555, loss-ulb:0.0143, weight:2.00, lr:0.0001
[06:45:30.687] iteration:13397  t-loss:0.2321, loss-lb:0.1562, loss-ulb:0.0380, weight:2.00, lr:0.0001
[06:45:31.000] iteration:13398  t-loss:0.3068, loss-lb:0.2699, loss-ulb:0.0185, weight:2.00, lr:0.0001
[06:45:31.313] iteration:13399  t-loss:0.4394, loss-lb:0.1943, loss-ulb:0.1226, weight:2.00, lr:0.0001
[06:45:31.625] iteration:13400  t-loss:0.2458, loss-lb:0.1746, loss-ulb:0.0356, weight:2.00, lr:0.0001
[06:45:32.927] iteration:13401  t-loss:0.3018, loss-lb:0.2486, loss-ulb:0.0266, weight:2.00, lr:0.0001
[06:45:33.251] iteration:13402  t-loss:0.1967, loss-lb:0.1693, loss-ulb:0.0137, weight:2.00, lr:0.0001
[06:45:33.569] iteration:13403  t-loss:0.2602, loss-lb:0.1256, loss-ulb:0.0673, weight:2.00, lr:0.0001
[06:45:33.884] iteration:13404  t-loss:0.2937, loss-lb:0.1580, loss-ulb:0.0678, weight:2.00, lr:0.0001
[06:45:34.202] iteration:13405  t-loss:0.3379, loss-lb:0.1544, loss-ulb:0.0918, weight:2.00, lr:0.0001
[06:45:34.517] iteration:13406  t-loss:0.2005, loss-lb:0.1725, loss-ulb:0.0140, weight:2.00, lr:0.0001
[06:45:34.832] iteration:13407  t-loss:0.1945, loss-lb:0.1406, loss-ulb:0.0270, weight:2.00, lr:0.0001
[06:45:35.146] iteration:13408  t-loss:0.2063, loss-lb:0.1795, loss-ulb:0.0134, weight:2.00, lr:0.0001
[06:45:35.464] iteration:13409  t-loss:0.4078, loss-lb:0.2315, loss-ulb:0.0882, weight:2.00, lr:0.0001
[06:45:35.780] iteration:13410  t-loss:0.2978, loss-lb:0.2602, loss-ulb:0.0188, weight:2.00, lr:0.0001
[06:45:36.098] iteration:13411  t-loss:0.2306, loss-lb:0.2047, loss-ulb:0.0130, weight:2.00, lr:0.0001
[06:45:36.413] iteration:13412  t-loss:0.1644, loss-lb:0.1238, loss-ulb:0.0203, weight:2.00, lr:0.0001
[06:45:36.732] iteration:13413  t-loss:0.2620, loss-lb:0.1461, loss-ulb:0.0580, weight:2.00, lr:0.0001
[06:45:37.049] iteration:13414  t-loss:0.5502, loss-lb:0.1673, loss-ulb:0.1914, weight:2.00, lr:0.0001
[06:45:37.366] iteration:13415  t-loss:0.3218, loss-lb:0.1544, loss-ulb:0.0837, weight:2.00, lr:0.0001
[06:45:37.683] iteration:13416  t-loss:0.3178, loss-lb:0.1444, loss-ulb:0.0867, weight:2.00, lr:0.0001
[06:45:37.999] iteration:13417  t-loss:0.2747, loss-lb:0.1621, loss-ulb:0.0563, weight:2.00, lr:0.0001
[06:45:38.314] iteration:13418  t-loss:0.2402, loss-lb:0.1231, loss-ulb:0.0585, weight:2.00, lr:0.0001
[06:45:38.631] iteration:13419  t-loss:0.2740, loss-lb:0.1304, loss-ulb:0.0718, weight:2.00, lr:0.0001
[06:45:38.947] iteration:13420  t-loss:0.3431, loss-lb:0.1717, loss-ulb:0.0857, weight:2.00, lr:0.0001
[06:45:39.266] iteration:13421  t-loss:0.4519, loss-lb:0.2075, loss-ulb:0.1222, weight:2.00, lr:0.0001
[06:45:39.581] iteration:13422  t-loss:0.4050, loss-lb:0.1569, loss-ulb:0.1240, weight:2.00, lr:0.0001
[06:45:39.896] iteration:13423  t-loss:0.3917, loss-lb:0.3398, loss-ulb:0.0259, weight:2.00, lr:0.0001
[06:45:40.212] iteration:13424  t-loss:0.1829, loss-lb:0.1536, loss-ulb:0.0146, weight:2.00, lr:0.0001
[06:45:40.530] iteration:13425  t-loss:0.3471, loss-lb:0.1763, loss-ulb:0.0854, weight:2.00, lr:0.0001
[06:47:36.208] iteration 13425 : dice_score: 0.852306 best_dice: 0.854000
[06:47:36.209]  <<Test>> - Ep:536  - Dice-S/T:85.13/85.23, Best-S:85.59, Best-T:85.40
[06:47:36.209]           - AvgLoss(lb/ulb/all):0.18/0.06/0.30
[06:47:37.460] iteration:13426  t-loss:0.3433, loss-lb:0.1363, loss-ulb:0.1035, weight:2.00, lr:0.0001
[06:47:37.788] iteration:13427  t-loss:0.3822, loss-lb:0.2279, loss-ulb:0.0772, weight:2.00, lr:0.0001
[06:47:38.109] iteration:13428  t-loss:0.1864, loss-lb:0.1493, loss-ulb:0.0185, weight:2.00, lr:0.0001
[06:47:38.426] iteration:13429  t-loss:0.1713, loss-lb:0.1369, loss-ulb:0.0172, weight:2.00, lr:0.0001
[06:47:38.744] iteration:13430  t-loss:0.2020, loss-lb:0.1114, loss-ulb:0.0453, weight:2.00, lr:0.0001
[06:47:39.062] iteration:13431  t-loss:0.2294, loss-lb:0.1643, loss-ulb:0.0326, weight:2.00, lr:0.0001
[06:47:39.379] iteration:13432  t-loss:0.1988, loss-lb:0.1667, loss-ulb:0.0161, weight:2.00, lr:0.0001
[06:47:39.696] iteration:13433  t-loss:0.2622, loss-lb:0.1817, loss-ulb:0.0403, weight:2.00, lr:0.0001
[06:47:40.015] iteration:13434  t-loss:0.2414, loss-lb:0.1332, loss-ulb:0.0541, weight:2.00, lr:0.0001
[06:47:40.334] iteration:13435  t-loss:0.3686, loss-lb:0.1566, loss-ulb:0.1060, weight:2.00, lr:0.0001
[06:47:40.652] iteration:13436  t-loss:0.2569, loss-lb:0.2104, loss-ulb:0.0233, weight:2.00, lr:0.0001
[06:47:40.974] iteration:13437  t-loss:0.2854, loss-lb:0.2182, loss-ulb:0.0336, weight:2.00, lr:0.0001
[06:47:41.291] iteration:13438  t-loss:0.3516, loss-lb:0.3160, loss-ulb:0.0178, weight:2.00, lr:0.0001
[06:47:41.610] iteration:13439  t-loss:0.3459, loss-lb:0.1543, loss-ulb:0.0958, weight:2.00, lr:0.0001
[06:47:41.928] iteration:13440  t-loss:0.2229, loss-lb:0.1853, loss-ulb:0.0188, weight:2.00, lr:0.0001
[06:47:42.246] iteration:13441  t-loss:0.1658, loss-lb:0.1172, loss-ulb:0.0243, weight:2.00, lr:0.0001
[06:47:42.566] iteration:13442  t-loss:0.2597, loss-lb:0.1283, loss-ulb:0.0657, weight:2.00, lr:0.0001
[06:47:42.888] iteration:13443  t-loss:0.2911, loss-lb:0.1936, loss-ulb:0.0488, weight:2.00, lr:0.0001
[06:47:43.208] iteration:13444  t-loss:0.4537, loss-lb:0.2308, loss-ulb:0.1115, weight:2.00, lr:0.0001
[06:47:43.526] iteration:13445  t-loss:0.3763, loss-lb:0.2022, loss-ulb:0.0871, weight:2.00, lr:0.0001
[06:47:43.842] iteration:13446  t-loss:0.4394, loss-lb:0.2126, loss-ulb:0.1134, weight:2.00, lr:0.0001
[06:47:44.158] iteration:13447  t-loss:0.2462, loss-lb:0.1840, loss-ulb:0.0311, weight:2.00, lr:0.0001
[06:47:44.473] iteration:13448  t-loss:0.2123, loss-lb:0.1684, loss-ulb:0.0220, weight:2.00, lr:0.0001
[06:47:44.788] iteration:13449  t-loss:0.2285, loss-lb:0.1372, loss-ulb:0.0457, weight:2.00, lr:0.0001
[06:47:45.101] iteration:13450  t-loss:0.2163, loss-lb:0.1346, loss-ulb:0.0409, weight:2.00, lr:0.0001
[06:47:46.289] iteration:13451  t-loss:0.2302, loss-lb:0.2041, loss-ulb:0.0130, weight:2.00, lr:0.0001
[06:47:46.621] iteration:13452  t-loss:0.2602, loss-lb:0.1746, loss-ulb:0.0428, weight:2.00, lr:0.0001
[06:47:46.944] iteration:13453  t-loss:0.2859, loss-lb:0.1353, loss-ulb:0.0753, weight:2.00, lr:0.0001
[06:47:47.263] iteration:13454  t-loss:0.2295, loss-lb:0.1867, loss-ulb:0.0214, weight:2.00, lr:0.0001
[06:47:47.579] iteration:13455  t-loss:0.2953, loss-lb:0.1546, loss-ulb:0.0704, weight:2.00, lr:0.0001
[06:47:47.897] iteration:13456  t-loss:0.3205, loss-lb:0.1579, loss-ulb:0.0813, weight:2.00, lr:0.0001
[06:47:48.211] iteration:13457  t-loss:0.1615, loss-lb:0.1261, loss-ulb:0.0177, weight:2.00, lr:0.0001
[06:47:48.530] iteration:13458  t-loss:0.2664, loss-lb:0.1321, loss-ulb:0.0672, weight:2.00, lr:0.0001
[06:47:48.849] iteration:13459  t-loss:0.3379, loss-lb:0.1740, loss-ulb:0.0819, weight:2.00, lr:0.0001
[06:47:49.168] iteration:13460  t-loss:0.5248, loss-lb:0.2545, loss-ulb:0.1351, weight:2.00, lr:0.0001
[06:47:49.485] iteration:13461  t-loss:0.2267, loss-lb:0.1627, loss-ulb:0.0320, weight:2.00, lr:0.0001
[06:47:49.799] iteration:13462  t-loss:0.1897, loss-lb:0.1423, loss-ulb:0.0237, weight:2.00, lr:0.0001
[06:47:50.117] iteration:13463  t-loss:0.3510, loss-lb:0.2339, loss-ulb:0.0586, weight:2.00, lr:0.0001
[06:47:50.435] iteration:13464  t-loss:0.3197, loss-lb:0.2743, loss-ulb:0.0227, weight:2.00, lr:0.0001
[06:47:50.752] iteration:13465  t-loss:0.2899, loss-lb:0.1332, loss-ulb:0.0784, weight:2.00, lr:0.0001
[06:47:51.070] iteration:13466  t-loss:0.4817, loss-lb:0.2858, loss-ulb:0.0980, weight:2.00, lr:0.0001
[06:47:51.387] iteration:13467  t-loss:0.2497, loss-lb:0.2247, loss-ulb:0.0125, weight:2.00, lr:0.0001
[06:47:51.703] iteration:13468  t-loss:0.3014, loss-lb:0.1404, loss-ulb:0.0805, weight:2.00, lr:0.0001
[06:47:52.018] iteration:13469  t-loss:0.8612, loss-lb:0.1761, loss-ulb:0.3426, weight:2.00, lr:0.0001
[06:47:52.333] iteration:13470  t-loss:0.3379, loss-lb:0.2539, loss-ulb:0.0420, weight:2.00, lr:0.0001
[06:47:52.649] iteration:13471  t-loss:0.2501, loss-lb:0.1503, loss-ulb:0.0499, weight:2.00, lr:0.0001
[06:47:52.964] iteration:13472  t-loss:0.4711, loss-lb:0.1437, loss-ulb:0.1637, weight:2.00, lr:0.0001
[06:47:53.278] iteration:13473  t-loss:0.4023, loss-lb:0.1326, loss-ulb:0.1348, weight:2.00, lr:0.0001
[06:47:53.594] iteration:13474  t-loss:0.3747, loss-lb:0.1849, loss-ulb:0.0949, weight:2.00, lr:0.0001
[06:47:53.909] iteration:13475  t-loss:0.4948, loss-lb:0.2193, loss-ulb:0.1378, weight:2.00, lr:0.0001
[06:47:55.278] iteration:13476  t-loss:0.3588, loss-lb:0.2362, loss-ulb:0.0613, weight:2.00, lr:0.0001
[06:47:55.606] iteration:13477  t-loss:0.1782, loss-lb:0.1538, loss-ulb:0.0122, weight:2.00, lr:0.0001
[06:47:55.922] iteration:13478  t-loss:0.2166, loss-lb:0.1841, loss-ulb:0.0162, weight:2.00, lr:0.0001
[06:47:56.236] iteration:13479  t-loss:0.1700, loss-lb:0.1414, loss-ulb:0.0143, weight:2.00, lr:0.0001
[06:47:56.554] iteration:13480  t-loss:0.2170, loss-lb:0.1760, loss-ulb:0.0205, weight:2.00, lr:0.0001
[06:47:56.869] iteration:13481  t-loss:0.2366, loss-lb:0.1097, loss-ulb:0.0634, weight:2.00, lr:0.0001
[06:47:57.190] iteration:13482  t-loss:0.3686, loss-lb:0.2297, loss-ulb:0.0695, weight:2.00, lr:0.0001
[06:47:57.510] iteration:13483  t-loss:0.3300, loss-lb:0.1038, loss-ulb:0.1131, weight:2.00, lr:0.0001
[06:47:57.823] iteration:13484  t-loss:0.1864, loss-lb:0.1442, loss-ulb:0.0211, weight:2.00, lr:0.0001
[06:47:58.140] iteration:13485  t-loss:0.3378, loss-lb:0.1588, loss-ulb:0.0895, weight:2.00, lr:0.0001
[06:47:58.454] iteration:13486  t-loss:0.1552, loss-lb:0.1299, loss-ulb:0.0127, weight:2.00, lr:0.0001
[06:47:58.771] iteration:13487  t-loss:0.2320, loss-lb:0.2057, loss-ulb:0.0131, weight:2.00, lr:0.0001
[06:47:59.088] iteration:13488  t-loss:0.3086, loss-lb:0.1675, loss-ulb:0.0705, weight:2.00, lr:0.0001
[06:47:59.406] iteration:13489  t-loss:0.3034, loss-lb:0.1917, loss-ulb:0.0559, weight:2.00, lr:0.0001
[06:47:59.723] iteration:13490  t-loss:0.2770, loss-lb:0.1579, loss-ulb:0.0596, weight:2.00, lr:0.0001
[06:48:00.040] iteration:13491  t-loss:0.1557, loss-lb:0.1165, loss-ulb:0.0196, weight:2.00, lr:0.0001
[06:48:00.361] iteration:13492  t-loss:0.2843, loss-lb:0.1585, loss-ulb:0.0629, weight:2.00, lr:0.0001
[06:48:00.676] iteration:13493  t-loss:0.3591, loss-lb:0.2413, loss-ulb:0.0589, weight:2.00, lr:0.0001
[06:48:00.991] iteration:13494  t-loss:0.2055, loss-lb:0.1445, loss-ulb:0.0305, weight:2.00, lr:0.0001
[06:48:01.306] iteration:13495  t-loss:0.3313, loss-lb:0.1877, loss-ulb:0.0718, weight:2.00, lr:0.0001
[06:48:01.622] iteration:13496  t-loss:0.5214, loss-lb:0.2247, loss-ulb:0.1483, weight:2.00, lr:0.0001
[06:48:01.939] iteration:13497  t-loss:0.3895, loss-lb:0.2481, loss-ulb:0.0707, weight:2.00, lr:0.0001
[06:48:02.256] iteration:13498  t-loss:0.4646, loss-lb:0.2405, loss-ulb:0.1121, weight:2.00, lr:0.0001
[06:48:02.572] iteration:13499  t-loss:0.3319, loss-lb:0.1471, loss-ulb:0.0924, weight:2.00, lr:0.0001
[06:48:02.885] iteration:13500  t-loss:0.2753, loss-lb:0.2425, loss-ulb:0.0164, weight:2.00, lr:0.0001
[06:48:04.039] iteration:13501  t-loss:0.3200, loss-lb:0.2011, loss-ulb:0.0594, weight:2.00, lr:0.0001
[06:48:04.370] iteration:13502  t-loss:0.3328, loss-lb:0.1148, loss-ulb:0.1090, weight:2.00, lr:0.0001
[06:48:04.691] iteration:13503  t-loss:0.2174, loss-lb:0.1827, loss-ulb:0.0173, weight:2.00, lr:0.0001
[06:48:05.009] iteration:13504  t-loss:0.1654, loss-lb:0.1387, loss-ulb:0.0134, weight:2.00, lr:0.0001
[06:48:05.327] iteration:13505  t-loss:0.3516, loss-lb:0.2709, loss-ulb:0.0403, weight:2.00, lr:0.0001
[06:48:05.646] iteration:13506  t-loss:0.2034, loss-lb:0.1632, loss-ulb:0.0201, weight:2.00, lr:0.0001
[06:48:05.962] iteration:13507  t-loss:0.1787, loss-lb:0.1507, loss-ulb:0.0140, weight:2.00, lr:0.0001
[06:48:06.281] iteration:13508  t-loss:0.2881, loss-lb:0.1794, loss-ulb:0.0544, weight:2.00, lr:0.0001
[06:48:06.596] iteration:13509  t-loss:0.1878, loss-lb:0.1419, loss-ulb:0.0229, weight:2.00, lr:0.0001
[06:48:06.915] iteration:13510  t-loss:0.3725, loss-lb:0.2482, loss-ulb:0.0622, weight:2.00, lr:0.0001
[06:48:07.233] iteration:13511  t-loss:0.3544, loss-lb:0.1739, loss-ulb:0.0903, weight:2.00, lr:0.0001
[06:48:07.558] iteration:13512  t-loss:0.1949, loss-lb:0.1696, loss-ulb:0.0126, weight:2.00, lr:0.0001
[06:48:07.883] iteration:13513  t-loss:0.2489, loss-lb:0.1784, loss-ulb:0.0352, weight:2.00, lr:0.0001
[06:48:08.205] iteration:13514  t-loss:0.2592, loss-lb:0.1241, loss-ulb:0.0675, weight:2.00, lr:0.0001
[06:48:08.528] iteration:13515  t-loss:0.1793, loss-lb:0.1389, loss-ulb:0.0202, weight:2.00, lr:0.0001
[06:48:08.843] iteration:13516  t-loss:0.2197, loss-lb:0.1930, loss-ulb:0.0133, weight:2.00, lr:0.0001
[06:48:09.171] iteration:13517  t-loss:0.2113, loss-lb:0.1858, loss-ulb:0.0127, weight:2.00, lr:0.0001
[06:48:09.505] iteration:13518  t-loss:0.3695, loss-lb:0.2234, loss-ulb:0.0730, weight:2.00, lr:0.0001
[06:48:09.825] iteration:13519  t-loss:0.1633, loss-lb:0.1359, loss-ulb:0.0137, weight:2.00, lr:0.0001
[06:48:10.153] iteration:13520  t-loss:0.3244, loss-lb:0.1543, loss-ulb:0.0851, weight:2.00, lr:0.0001
[06:48:10.484] iteration:13521  t-loss:0.3061, loss-lb:0.1727, loss-ulb:0.0667, weight:2.00, lr:0.0001
[06:48:10.806] iteration:13522  t-loss:0.2525, loss-lb:0.1299, loss-ulb:0.0613, weight:2.00, lr:0.0001
[06:48:11.128] iteration:13523  t-loss:0.1817, loss-lb:0.1500, loss-ulb:0.0158, weight:2.00, lr:0.0001
[06:48:11.446] iteration:13524  t-loss:0.1656, loss-lb:0.1312, loss-ulb:0.0172, weight:2.00, lr:0.0001
[06:48:11.765] iteration:13525  t-loss:0.2709, loss-lb:0.1710, loss-ulb:0.0499, weight:2.00, lr:0.0001
[06:50:06.907] iteration 13525 : dice_score: 0.850508 best_dice: 0.854000
[06:50:06.907]  <<Test>> - Ep:540  - Dice-S/T:84.93/85.05, Best-S:85.59, Best-T:85.40
[06:50:06.907]           - AvgLoss(lb/ulb/all):0.17/0.04/0.25
[06:50:08.043] iteration:13526  t-loss:0.3773, loss-lb:0.2357, loss-ulb:0.0708, weight:2.00, lr:0.0001
[06:50:08.366] iteration:13527  t-loss:0.2604, loss-lb:0.2112, loss-ulb:0.0246, weight:2.00, lr:0.0001
[06:50:08.684] iteration:13528  t-loss:0.3580, loss-lb:0.1243, loss-ulb:0.1169, weight:2.00, lr:0.0001
[06:50:09.000] iteration:13529  t-loss:0.2079, loss-lb:0.1083, loss-ulb:0.0498, weight:2.00, lr:0.0001
[06:50:09.317] iteration:13530  t-loss:0.3639, loss-lb:0.1914, loss-ulb:0.0863, weight:2.00, lr:0.0001
[06:50:09.632] iteration:13531  t-loss:0.2016, loss-lb:0.1711, loss-ulb:0.0153, weight:2.00, lr:0.0001
[06:50:09.946] iteration:13532  t-loss:0.1823, loss-lb:0.1234, loss-ulb:0.0295, weight:2.00, lr:0.0001
[06:50:10.260] iteration:13533  t-loss:0.2212, loss-lb:0.1804, loss-ulb:0.0204, weight:2.00, lr:0.0001
[06:50:10.575] iteration:13534  t-loss:0.2654, loss-lb:0.2295, loss-ulb:0.0179, weight:2.00, lr:0.0001
[06:50:10.894] iteration:13535  t-loss:0.2174, loss-lb:0.1500, loss-ulb:0.0337, weight:2.00, lr:0.0001
[06:50:11.220] iteration:13536  t-loss:0.2195, loss-lb:0.1746, loss-ulb:0.0225, weight:2.00, lr:0.0001
[06:50:11.555] iteration:13537  t-loss:0.2680, loss-lb:0.1785, loss-ulb:0.0448, weight:2.00, lr:0.0001
[06:50:11.889] iteration:13538  t-loss:0.2734, loss-lb:0.2043, loss-ulb:0.0345, weight:2.00, lr:0.0001
[06:50:12.226] iteration:13539  t-loss:0.4480, loss-lb:0.2162, loss-ulb:0.1159, weight:2.00, lr:0.0001
[06:50:12.564] iteration:13540  t-loss:0.2112, loss-lb:0.1697, loss-ulb:0.0207, weight:2.00, lr:0.0001
[06:50:12.911] iteration:13541  t-loss:0.4401, loss-lb:0.1992, loss-ulb:0.1205, weight:2.00, lr:0.0001
[06:50:13.245] iteration:13542  t-loss:0.2005, loss-lb:0.1625, loss-ulb:0.0190, weight:2.00, lr:0.0001
[06:50:13.571] iteration:13543  t-loss:0.1674, loss-lb:0.1410, loss-ulb:0.0132, weight:2.00, lr:0.0001
[06:50:13.900] iteration:13544  t-loss:0.1983, loss-lb:0.1653, loss-ulb:0.0165, weight:2.00, lr:0.0001
[06:50:14.225] iteration:13545  t-loss:0.1783, loss-lb:0.1509, loss-ulb:0.0137, weight:2.00, lr:0.0001
[06:50:14.546] iteration:13546  t-loss:0.2256, loss-lb:0.1861, loss-ulb:0.0197, weight:2.00, lr:0.0001
[06:50:14.862] iteration:13547  t-loss:0.2861, loss-lb:0.2526, loss-ulb:0.0168, weight:2.00, lr:0.0001
[06:50:15.178] iteration:13548  t-loss:0.2139, loss-lb:0.1259, loss-ulb:0.0440, weight:2.00, lr:0.0001
[06:50:15.492] iteration:13549  t-loss:0.3893, loss-lb:0.2433, loss-ulb:0.0730, weight:2.00, lr:0.0001
[06:50:15.804] iteration:13550  t-loss:0.1735, loss-lb:0.1429, loss-ulb:0.0153, weight:2.00, lr:0.0001
[06:50:16.977] iteration:13551  t-loss:0.3238, loss-lb:0.1965, loss-ulb:0.0636, weight:2.00, lr:0.0001
[06:50:17.309] iteration:13552  t-loss:0.2797, loss-lb:0.2539, loss-ulb:0.0129, weight:2.00, lr:0.0001
[06:50:17.637] iteration:13553  t-loss:0.1958, loss-lb:0.1689, loss-ulb:0.0134, weight:2.00, lr:0.0001
[06:50:17.961] iteration:13554  t-loss:0.1871, loss-lb:0.1414, loss-ulb:0.0228, weight:2.00, lr:0.0001
[06:50:18.279] iteration:13555  t-loss:0.4486, loss-lb:0.1932, loss-ulb:0.1277, weight:2.00, lr:0.0001
[06:50:18.597] iteration:13556  t-loss:0.3363, loss-lb:0.1423, loss-ulb:0.0970, weight:2.00, lr:0.0001
[06:50:18.912] iteration:13557  t-loss:0.2459, loss-lb:0.1369, loss-ulb:0.0545, weight:2.00, lr:0.0001
[06:50:19.225] iteration:13558  t-loss:0.3679, loss-lb:0.1391, loss-ulb:0.1144, weight:2.00, lr:0.0001
[06:50:19.538] iteration:13559  t-loss:0.1330, loss-lb:0.1120, loss-ulb:0.0105, weight:2.00, lr:0.0001
[06:50:19.852] iteration:13560  t-loss:0.3451, loss-lb:0.1509, loss-ulb:0.0971, weight:2.00, lr:0.0001
[06:50:20.166] iteration:13561  t-loss:0.1879, loss-lb:0.1627, loss-ulb:0.0126, weight:2.00, lr:0.0001
[06:50:20.480] iteration:13562  t-loss:0.2412, loss-lb:0.1920, loss-ulb:0.0246, weight:2.00, lr:0.0001
[06:50:20.795] iteration:13563  t-loss:0.1645, loss-lb:0.1391, loss-ulb:0.0127, weight:2.00, lr:0.0001
[06:50:21.109] iteration:13564  t-loss:0.2061, loss-lb:0.1042, loss-ulb:0.0510, weight:2.00, lr:0.0001
[06:50:21.423] iteration:13565  t-loss:0.1894, loss-lb:0.1351, loss-ulb:0.0272, weight:2.00, lr:0.0001
[06:50:21.745] iteration:13566  t-loss:0.7318, loss-lb:0.1959, loss-ulb:0.2679, weight:2.00, lr:0.0001
[06:50:22.065] iteration:13567  t-loss:0.3853, loss-lb:0.2378, loss-ulb:0.0738, weight:2.00, lr:0.0001
[06:50:22.378] iteration:13568  t-loss:0.1739, loss-lb:0.1478, loss-ulb:0.0130, weight:2.00, lr:0.0001
[06:50:22.695] iteration:13569  t-loss:0.3572, loss-lb:0.1754, loss-ulb:0.0909, weight:2.00, lr:0.0001
[06:50:23.008] iteration:13570  t-loss:0.1647, loss-lb:0.1333, loss-ulb:0.0157, weight:2.00, lr:0.0001
[06:50:23.320] iteration:13571  t-loss:0.1908, loss-lb:0.1450, loss-ulb:0.0229, weight:2.00, lr:0.0001
[06:50:23.637] iteration:13572  t-loss:0.3408, loss-lb:0.1291, loss-ulb:0.1059, weight:2.00, lr:0.0001
[06:50:23.953] iteration:13573  t-loss:0.3039, loss-lb:0.2384, loss-ulb:0.0327, weight:2.00, lr:0.0001
[06:50:24.267] iteration:13574  t-loss:0.2210, loss-lb:0.1698, loss-ulb:0.0256, weight:2.00, lr:0.0001
[06:50:24.580] iteration:13575  t-loss:0.7209, loss-lb:0.2812, loss-ulb:0.2198, weight:2.00, lr:0.0001
[06:50:25.837] iteration:13576  t-loss:0.2767, loss-lb:0.1637, loss-ulb:0.0565, weight:2.00, lr:0.0001
[06:50:26.169] iteration:13577  t-loss:0.3419, loss-lb:0.1880, loss-ulb:0.0769, weight:2.00, lr:0.0001
[06:50:26.487] iteration:13578  t-loss:0.1727, loss-lb:0.1456, loss-ulb:0.0136, weight:2.00, lr:0.0001
[06:50:26.804] iteration:13579  t-loss:0.3691, loss-lb:0.1455, loss-ulb:0.1118, weight:2.00, lr:0.0001
[06:50:27.118] iteration:13580  t-loss:0.3427, loss-lb:0.1548, loss-ulb:0.0939, weight:2.00, lr:0.0001
[06:50:27.433] iteration:13581  t-loss:0.3072, loss-lb:0.2004, loss-ulb:0.0534, weight:2.00, lr:0.0001
[06:50:27.748] iteration:13582  t-loss:0.3084, loss-lb:0.1274, loss-ulb:0.0905, weight:2.00, lr:0.0001
[06:50:28.066] iteration:13583  t-loss:0.2971, loss-lb:0.1909, loss-ulb:0.0531, weight:2.00, lr:0.0001
[06:50:28.382] iteration:13584  t-loss:0.2397, loss-lb:0.1851, loss-ulb:0.0273, weight:2.00, lr:0.0001
[06:50:28.698] iteration:13585  t-loss:0.2449, loss-lb:0.2112, loss-ulb:0.0168, weight:2.00, lr:0.0001
[06:50:29.014] iteration:13586  t-loss:0.2304, loss-lb:0.1259, loss-ulb:0.0523, weight:2.00, lr:0.0001
[06:50:29.330] iteration:13587  t-loss:0.3003, loss-lb:0.2701, loss-ulb:0.0151, weight:2.00, lr:0.0001
[06:50:29.646] iteration:13588  t-loss:0.2618, loss-lb:0.2334, loss-ulb:0.0142, weight:2.00, lr:0.0001
[06:50:29.968] iteration:13589  t-loss:0.3090, loss-lb:0.1707, loss-ulb:0.0691, weight:2.00, lr:0.0001
[06:50:30.295] iteration:13590  t-loss:0.2345, loss-lb:0.1485, loss-ulb:0.0430, weight:2.00, lr:0.0001
[06:50:30.613] iteration:13591  t-loss:0.1747, loss-lb:0.1418, loss-ulb:0.0165, weight:2.00, lr:0.0001
[06:50:30.951] iteration:13592  t-loss:0.1579, loss-lb:0.1255, loss-ulb:0.0162, weight:2.00, lr:0.0001
[06:50:31.278] iteration:13593  t-loss:0.3764, loss-lb:0.2454, loss-ulb:0.0655, weight:2.00, lr:0.0001
[06:50:31.595] iteration:13594  t-loss:0.1626, loss-lb:0.1339, loss-ulb:0.0143, weight:2.00, lr:0.0001
[06:50:31.913] iteration:13595  t-loss:0.4437, loss-lb:0.2525, loss-ulb:0.0956, weight:2.00, lr:0.0001
[06:50:32.227] iteration:13596  t-loss:0.1887, loss-lb:0.1258, loss-ulb:0.0315, weight:2.00, lr:0.0001
[06:50:32.545] iteration:13597  t-loss:0.3029, loss-lb:0.1857, loss-ulb:0.0586, weight:2.00, lr:0.0001
[06:50:32.859] iteration:13598  t-loss:0.1598, loss-lb:0.1235, loss-ulb:0.0181, weight:2.00, lr:0.0001
[06:50:33.174] iteration:13599  t-loss:0.2067, loss-lb:0.1697, loss-ulb:0.0185, weight:2.00, lr:0.0001
[06:50:33.488] iteration:13600  t-loss:0.2293, loss-lb:0.1779, loss-ulb:0.0257, weight:2.00, lr:0.0001
[06:50:34.790] iteration:13601  t-loss:0.2867, loss-lb:0.2436, loss-ulb:0.0215, weight:2.00, lr:0.0001
[06:50:35.121] iteration:13602  t-loss:0.3628, loss-lb:0.2425, loss-ulb:0.0602, weight:2.00, lr:0.0001
[06:50:35.437] iteration:13603  t-loss:0.1788, loss-lb:0.1350, loss-ulb:0.0219, weight:2.00, lr:0.0001
[06:50:35.752] iteration:13604  t-loss:0.2151, loss-lb:0.1632, loss-ulb:0.0259, weight:2.00, lr:0.0001
[06:50:36.069] iteration:13605  t-loss:0.4177, loss-lb:0.2941, loss-ulb:0.0618, weight:2.00, lr:0.0001
[06:50:36.387] iteration:13606  t-loss:0.1943, loss-lb:0.1113, loss-ulb:0.0415, weight:2.00, lr:0.0001
[06:50:36.707] iteration:13607  t-loss:0.3032, loss-lb:0.2010, loss-ulb:0.0511, weight:2.00, lr:0.0001
[06:50:37.022] iteration:13608  t-loss:0.3079, loss-lb:0.1051, loss-ulb:0.1014, weight:2.00, lr:0.0001
[06:50:37.346] iteration:13609  t-loss:0.2646, loss-lb:0.1509, loss-ulb:0.0568, weight:2.00, lr:0.0001
[06:50:37.663] iteration:13610  t-loss:0.5095, loss-lb:0.1685, loss-ulb:0.1705, weight:2.00, lr:0.0001
[06:50:37.979] iteration:13611  t-loss:0.1484, loss-lb:0.1149, loss-ulb:0.0168, weight:2.00, lr:0.0001
[06:50:38.292] iteration:13612  t-loss:0.1899, loss-lb:0.1564, loss-ulb:0.0167, weight:2.00, lr:0.0001
[06:50:38.611] iteration:13613  t-loss:0.3948, loss-lb:0.1950, loss-ulb:0.0999, weight:2.00, lr:0.0001
[06:50:38.927] iteration:13614  t-loss:0.2402, loss-lb:0.1316, loss-ulb:0.0543, weight:2.00, lr:0.0001
[06:50:39.244] iteration:13615  t-loss:0.4388, loss-lb:0.2754, loss-ulb:0.0817, weight:2.00, lr:0.0001
[06:50:39.560] iteration:13616  t-loss:0.1783, loss-lb:0.1314, loss-ulb:0.0235, weight:2.00, lr:0.0001
[06:50:39.875] iteration:13617  t-loss:0.2507, loss-lb:0.2261, loss-ulb:0.0123, weight:2.00, lr:0.0001
[06:50:40.188] iteration:13618  t-loss:0.2745, loss-lb:0.1361, loss-ulb:0.0692, weight:2.00, lr:0.0001
[06:50:40.502] iteration:13619  t-loss:0.2335, loss-lb:0.1348, loss-ulb:0.0494, weight:2.00, lr:0.0001
[06:50:40.813] iteration:13620  t-loss:0.2824, loss-lb:0.1906, loss-ulb:0.0459, weight:2.00, lr:0.0001
[06:50:41.129] iteration:13621  t-loss:0.4449, loss-lb:0.2697, loss-ulb:0.0876, weight:2.00, lr:0.0001
[06:50:41.446] iteration:13622  t-loss:0.3002, loss-lb:0.1376, loss-ulb:0.0813, weight:2.00, lr:0.0001
[06:50:41.764] iteration:13623  t-loss:0.3109, loss-lb:0.1042, loss-ulb:0.1034, weight:2.00, lr:0.0001
[06:50:42.080] iteration:13624  t-loss:0.3096, loss-lb:0.1467, loss-ulb:0.0815, weight:2.00, lr:0.0001
[06:50:42.394] iteration:13625  t-loss:0.3436, loss-lb:0.3087, loss-ulb:0.0175, weight:2.00, lr:0.0001
[06:52:41.879] iteration 13625 : dice_score: 0.850860 best_dice: 0.854000
[06:52:41.879]  <<Test>> - Ep:544  - Dice-S/T:84.94/85.09, Best-S:85.59, Best-T:85.40
[06:52:41.879]           - AvgLoss(lb/ulb/all):0.18/0.06/0.30
[06:52:42.995] iteration:13626  t-loss:0.4091, loss-lb:0.1981, loss-ulb:0.1055, weight:2.00, lr:0.0001
[06:52:43.331] iteration:13627  t-loss:0.4987, loss-lb:0.3635, loss-ulb:0.0676, weight:2.00, lr:0.0001
[06:52:43.650] iteration:13628  t-loss:0.2024, loss-lb:0.1658, loss-ulb:0.0183, weight:2.00, lr:0.0001
[06:52:43.969] iteration:13629  t-loss:0.3083, loss-lb:0.1601, loss-ulb:0.0741, weight:2.00, lr:0.0001
[06:52:44.289] iteration:13630  t-loss:0.3038, loss-lb:0.1278, loss-ulb:0.0880, weight:2.00, lr:0.0001
[06:52:44.610] iteration:13631  t-loss:0.3130, loss-lb:0.1568, loss-ulb:0.0781, weight:2.00, lr:0.0001
[06:52:44.932] iteration:13632  t-loss:0.6392, loss-lb:0.2534, loss-ulb:0.1929, weight:2.00, lr:0.0001
[06:52:45.250] iteration:13633  t-loss:0.2428, loss-lb:0.1319, loss-ulb:0.0554, weight:2.00, lr:0.0001
[06:52:45.570] iteration:13634  t-loss:0.1912, loss-lb:0.1470, loss-ulb:0.0221, weight:2.00, lr:0.0001
[06:52:45.889] iteration:13635  t-loss:0.1443, loss-lb:0.1200, loss-ulb:0.0121, weight:2.00, lr:0.0001
[06:52:46.206] iteration:13636  t-loss:0.4521, loss-lb:0.1687, loss-ulb:0.1417, weight:2.00, lr:0.0001
[06:52:46.525] iteration:13637  t-loss:0.1752, loss-lb:0.1189, loss-ulb:0.0281, weight:2.00, lr:0.0001
[06:52:46.848] iteration:13638  t-loss:0.4839, loss-lb:0.2316, loss-ulb:0.1262, weight:2.00, lr:0.0001
[06:52:47.169] iteration:13639  t-loss:0.2750, loss-lb:0.1275, loss-ulb:0.0738, weight:2.00, lr:0.0001
[06:52:47.485] iteration:13640  t-loss:0.1654, loss-lb:0.1283, loss-ulb:0.0186, weight:2.00, lr:0.0001
[06:52:47.808] iteration:13641  t-loss:0.3700, loss-lb:0.1535, loss-ulb:0.1082, weight:2.00, lr:0.0001
[06:52:48.132] iteration:13642  t-loss:0.2303, loss-lb:0.1897, loss-ulb:0.0203, weight:2.00, lr:0.0001
[06:52:48.447] iteration:13643  t-loss:0.2922, loss-lb:0.1431, loss-ulb:0.0745, weight:2.00, lr:0.0001
[06:52:48.764] iteration:13644  t-loss:0.3976, loss-lb:0.2841, loss-ulb:0.0568, weight:2.00, lr:0.0001
[06:52:49.078] iteration:13645  t-loss:0.3004, loss-lb:0.2754, loss-ulb:0.0125, weight:2.00, lr:0.0001
[06:52:49.394] iteration:13646  t-loss:0.2772, loss-lb:0.1217, loss-ulb:0.0778, weight:2.00, lr:0.0001
[06:52:49.707] iteration:13647  t-loss:0.2223, loss-lb:0.1893, loss-ulb:0.0165, weight:2.00, lr:0.0001
[06:52:50.020] iteration:13648  t-loss:0.2048, loss-lb:0.1607, loss-ulb:0.0221, weight:2.00, lr:0.0001
[06:52:50.335] iteration:13649  t-loss:0.1656, loss-lb:0.1313, loss-ulb:0.0171, weight:2.00, lr:0.0001
[06:52:50.652] iteration:13650  t-loss:0.2756, loss-lb:0.1717, loss-ulb:0.0520, weight:2.00, lr:0.0001
[06:52:52.071] iteration:13651  t-loss:0.1565, loss-lb:0.1166, loss-ulb:0.0199, weight:2.00, lr:0.0001
[06:52:52.406] iteration:13652  t-loss:0.1713, loss-lb:0.1475, loss-ulb:0.0119, weight:2.00, lr:0.0001
[06:52:52.729] iteration:13653  t-loss:0.1851, loss-lb:0.1207, loss-ulb:0.0322, weight:2.00, lr:0.0001
[06:52:53.049] iteration:13654  t-loss:0.2692, loss-lb:0.1144, loss-ulb:0.0774, weight:2.00, lr:0.0001
[06:52:53.370] iteration:13655  t-loss:0.3531, loss-lb:0.1910, loss-ulb:0.0811, weight:2.00, lr:0.0001
[06:52:53.686] iteration:13656  t-loss:0.1786, loss-lb:0.1531, loss-ulb:0.0128, weight:2.00, lr:0.0001
[06:52:54.001] iteration:13657  t-loss:0.1466, loss-lb:0.1197, loss-ulb:0.0135, weight:2.00, lr:0.0001
[06:52:54.318] iteration:13658  t-loss:0.2308, loss-lb:0.1384, loss-ulb:0.0462, weight:2.00, lr:0.0001
[06:52:54.632] iteration:13659  t-loss:0.2491, loss-lb:0.1308, loss-ulb:0.0592, weight:2.00, lr:0.0001
[06:52:54.951] iteration:13660  t-loss:0.2540, loss-lb:0.2233, loss-ulb:0.0154, weight:2.00, lr:0.0001
[06:52:55.267] iteration:13661  t-loss:0.2577, loss-lb:0.1573, loss-ulb:0.0502, weight:2.00, lr:0.0001
[06:52:55.584] iteration:13662  t-loss:0.2701, loss-lb:0.1426, loss-ulb:0.0637, weight:2.00, lr:0.0001
[06:52:55.899] iteration:13663  t-loss:0.1996, loss-lb:0.1749, loss-ulb:0.0124, weight:2.00, lr:0.0001
[06:52:56.223] iteration:13664  t-loss:0.2815, loss-lb:0.1659, loss-ulb:0.0578, weight:2.00, lr:0.0001
[06:52:56.535] iteration:13665  t-loss:0.2010, loss-lb:0.1646, loss-ulb:0.0182, weight:2.00, lr:0.0001
[06:52:56.851] iteration:13666  t-loss:0.1852, loss-lb:0.1580, loss-ulb:0.0136, weight:2.00, lr:0.0001
[06:52:57.170] iteration:13667  t-loss:0.4009, loss-lb:0.2292, loss-ulb:0.0858, weight:2.00, lr:0.0001
[06:52:57.484] iteration:13668  t-loss:0.4053, loss-lb:0.1565, loss-ulb:0.1244, weight:2.00, lr:0.0001
[06:52:57.796] iteration:13669  t-loss:0.4055, loss-lb:0.1523, loss-ulb:0.1266, weight:2.00, lr:0.0001
[06:52:58.108] iteration:13670  t-loss:0.2229, loss-lb:0.1866, loss-ulb:0.0182, weight:2.00, lr:0.0001
[06:52:58.421] iteration:13671  t-loss:0.2216, loss-lb:0.1908, loss-ulb:0.0154, weight:2.00, lr:0.0001
[06:52:58.737] iteration:13672  t-loss:0.3857, loss-lb:0.2824, loss-ulb:0.0517, weight:2.00, lr:0.0001
[06:52:59.053] iteration:13673  t-loss:0.2790, loss-lb:0.1521, loss-ulb:0.0634, weight:2.00, lr:0.0001
[06:52:59.368] iteration:13674  t-loss:0.3726, loss-lb:0.1643, loss-ulb:0.1041, weight:2.00, lr:0.0001
[06:52:59.682] iteration:13675  t-loss:0.2728, loss-lb:0.2334, loss-ulb:0.0197, weight:2.00, lr:0.0001
[06:53:00.920] iteration:13676  t-loss:0.4839, loss-lb:0.3188, loss-ulb:0.0826, weight:2.00, lr:0.0001
[06:53:01.258] iteration:13677  t-loss:0.2406, loss-lb:0.1534, loss-ulb:0.0436, weight:2.00, lr:0.0001
[06:53:01.614] iteration:13678  t-loss:0.4873, loss-lb:0.1680, loss-ulb:0.1597, weight:2.00, lr:0.0001
[06:53:01.935] iteration:13679  t-loss:0.2665, loss-lb:0.1520, loss-ulb:0.0573, weight:2.00, lr:0.0001
[06:53:02.260] iteration:13680  t-loss:0.3672, loss-lb:0.2147, loss-ulb:0.0762, weight:2.00, lr:0.0001
[06:53:02.580] iteration:13681  t-loss:0.3803, loss-lb:0.2114, loss-ulb:0.0845, weight:2.00, lr:0.0001
[06:53:02.897] iteration:13682  t-loss:0.2210, loss-lb:0.1350, loss-ulb:0.0430, weight:2.00, lr:0.0001
[06:53:03.215] iteration:13683  t-loss:0.3890, loss-lb:0.2231, loss-ulb:0.0830, weight:2.00, lr:0.0001
[06:53:03.531] iteration:13684  t-loss:0.2994, loss-lb:0.1404, loss-ulb:0.0795, weight:2.00, lr:0.0001
[06:53:03.848] iteration:13685  t-loss:0.5639, loss-lb:0.5204, loss-ulb:0.0217, weight:2.00, lr:0.0001
[06:53:04.167] iteration:13686  t-loss:0.3910, loss-lb:0.1893, loss-ulb:0.1009, weight:2.00, lr:0.0001
[06:53:04.484] iteration:13687  t-loss:0.2330, loss-lb:0.2079, loss-ulb:0.0125, weight:2.00, lr:0.0001
[06:53:04.802] iteration:13688  t-loss:0.2439, loss-lb:0.1535, loss-ulb:0.0452, weight:2.00, lr:0.0001
[06:53:05.116] iteration:13689  t-loss:0.1818, loss-lb:0.1528, loss-ulb:0.0145, weight:2.00, lr:0.0001
[06:53:05.431] iteration:13690  t-loss:0.4030, loss-lb:0.1736, loss-ulb:0.1147, weight:2.00, lr:0.0001
[06:53:05.751] iteration:13691  t-loss:0.4012, loss-lb:0.1590, loss-ulb:0.1211, weight:2.00, lr:0.0001
[06:53:06.066] iteration:13692  t-loss:0.2848, loss-lb:0.1266, loss-ulb:0.0791, weight:2.00, lr:0.0001
[06:53:06.377] iteration:13693  t-loss:0.1533, loss-lb:0.1186, loss-ulb:0.0173, weight:2.00, lr:0.0001
[06:53:06.693] iteration:13694  t-loss:0.1639, loss-lb:0.1342, loss-ulb:0.0149, weight:2.00, lr:0.0001
[06:53:07.006] iteration:13695  t-loss:0.2238, loss-lb:0.1289, loss-ulb:0.0474, weight:2.00, lr:0.0001
[06:53:07.325] iteration:13696  t-loss:0.4538, loss-lb:0.2845, loss-ulb:0.0846, weight:2.00, lr:0.0001
[06:53:07.639] iteration:13697  t-loss:0.1567, loss-lb:0.1260, loss-ulb:0.0154, weight:2.00, lr:0.0001
[06:53:07.952] iteration:13698  t-loss:0.1897, loss-lb:0.1634, loss-ulb:0.0131, weight:2.00, lr:0.0001
[06:53:08.264] iteration:13699  t-loss:0.2368, loss-lb:0.1242, loss-ulb:0.0563, weight:2.00, lr:0.0001
[06:53:08.580] iteration:13700  t-loss:0.3434, loss-lb:0.2078, loss-ulb:0.0678, weight:2.00, lr:0.0001
[06:53:09.804] iteration:13701  t-loss:0.3569, loss-lb:0.1844, loss-ulb:0.0863, weight:2.00, lr:0.0001
[06:53:10.126] iteration:13702  t-loss:0.2395, loss-lb:0.1961, loss-ulb:0.0217, weight:2.00, lr:0.0001
[06:53:10.445] iteration:13703  t-loss:0.3075, loss-lb:0.1923, loss-ulb:0.0576, weight:2.00, lr:0.0001
[06:53:10.761] iteration:13704  t-loss:0.1692, loss-lb:0.1389, loss-ulb:0.0152, weight:2.00, lr:0.0001
[06:53:11.079] iteration:13705  t-loss:0.2583, loss-lb:0.1351, loss-ulb:0.0616, weight:2.00, lr:0.0001
[06:53:11.399] iteration:13706  t-loss:0.2092, loss-lb:0.1846, loss-ulb:0.0123, weight:2.00, lr:0.0001
[06:53:11.720] iteration:13707  t-loss:0.2772, loss-lb:0.2539, loss-ulb:0.0116, weight:2.00, lr:0.0001
[06:53:12.038] iteration:13708  t-loss:0.2255, loss-lb:0.1241, loss-ulb:0.0507, weight:2.00, lr:0.0001
[06:53:12.354] iteration:13709  t-loss:0.2043, loss-lb:0.1476, loss-ulb:0.0284, weight:2.00, lr:0.0001
[06:53:12.670] iteration:13710  t-loss:0.2527, loss-lb:0.2095, loss-ulb:0.0216, weight:2.00, lr:0.0001
[06:53:12.987] iteration:13711  t-loss:0.1541, loss-lb:0.1284, loss-ulb:0.0128, weight:2.00, lr:0.0001
[06:53:13.303] iteration:13712  t-loss:0.2640, loss-lb:0.2350, loss-ulb:0.0145, weight:2.00, lr:0.0001
[06:53:13.621] iteration:13713  t-loss:0.2356, loss-lb:0.1349, loss-ulb:0.0504, weight:2.00, lr:0.0001
[06:53:13.937] iteration:13714  t-loss:0.2722, loss-lb:0.2038, loss-ulb:0.0342, weight:2.00, lr:0.0001
[06:53:14.251] iteration:13715  t-loss:0.1944, loss-lb:0.1277, loss-ulb:0.0334, weight:2.00, lr:0.0001
[06:53:14.567] iteration:13716  t-loss:0.1717, loss-lb:0.1329, loss-ulb:0.0194, weight:2.00, lr:0.0001
[06:53:14.883] iteration:13717  t-loss:0.2982, loss-lb:0.1526, loss-ulb:0.0728, weight:2.00, lr:0.0001
[06:53:15.196] iteration:13718  t-loss:0.2495, loss-lb:0.1127, loss-ulb:0.0684, weight:2.00, lr:0.0001
[06:53:15.508] iteration:13719  t-loss:0.2279, loss-lb:0.1764, loss-ulb:0.0258, weight:2.00, lr:0.0001
[06:53:15.823] iteration:13720  t-loss:0.3681, loss-lb:0.3359, loss-ulb:0.0161, weight:2.00, lr:0.0001
[06:53:16.136] iteration:13721  t-loss:0.3453, loss-lb:0.1910, loss-ulb:0.0772, weight:2.00, lr:0.0001
[06:53:16.449] iteration:13722  t-loss:0.2550, loss-lb:0.1185, loss-ulb:0.0683, weight:2.00, lr:0.0001
[06:53:16.764] iteration:13723  t-loss:0.2619, loss-lb:0.2007, loss-ulb:0.0306, weight:2.00, lr:0.0001
[06:53:17.079] iteration:13724  t-loss:0.3240, loss-lb:0.1616, loss-ulb:0.0812, weight:2.00, lr:0.0001
[06:53:17.392] iteration:13725  t-loss:0.1931, loss-lb:0.1561, loss-ulb:0.0185, weight:2.00, lr:0.0001
[06:55:07.319] iteration 13725 : dice_score: 0.850329 best_dice: 0.854000
[06:55:07.319]  <<Test>> - Ep:548  - Dice-S/T:85.08/85.03, Best-S:85.59, Best-T:85.40
[06:55:07.320]           - AvgLoss(lb/ulb/all):0.17/0.04/0.25
[06:55:08.555] iteration:13726  t-loss:0.3313, loss-lb:0.2350, loss-ulb:0.0481, weight:2.00, lr:0.0001
[06:55:08.890] iteration:13727  t-loss:0.2674, loss-lb:0.2396, loss-ulb:0.0139, weight:2.00, lr:0.0001
[06:55:09.215] iteration:13728  t-loss:0.3690, loss-lb:0.2121, loss-ulb:0.0785, weight:2.00, lr:0.0001
[06:55:09.534] iteration:13729  t-loss:0.3435, loss-lb:0.1151, loss-ulb:0.1142, weight:2.00, lr:0.0001
[06:55:09.853] iteration:13730  t-loss:0.3579, loss-lb:0.2044, loss-ulb:0.0768, weight:2.00, lr:0.0001
[06:55:10.167] iteration:13731  t-loss:0.1950, loss-lb:0.1605, loss-ulb:0.0173, weight:2.00, lr:0.0001
[06:55:10.483] iteration:13732  t-loss:0.2527, loss-lb:0.2197, loss-ulb:0.0165, weight:2.00, lr:0.0001
[06:55:10.796] iteration:13733  t-loss:0.1901, loss-lb:0.1596, loss-ulb:0.0153, weight:2.00, lr:0.0001
[06:55:11.115] iteration:13734  t-loss:0.3309, loss-lb:0.2239, loss-ulb:0.0535, weight:2.00, lr:0.0001
[06:55:11.431] iteration:13735  t-loss:0.1688, loss-lb:0.1357, loss-ulb:0.0166, weight:2.00, lr:0.0001
[06:55:11.747] iteration:13736  t-loss:0.2756, loss-lb:0.1453, loss-ulb:0.0651, weight:2.00, lr:0.0001
[06:55:12.062] iteration:13737  t-loss:0.2042, loss-lb:0.1492, loss-ulb:0.0275, weight:2.00, lr:0.0001
[06:55:12.377] iteration:13738  t-loss:0.2426, loss-lb:0.1705, loss-ulb:0.0361, weight:2.00, lr:0.0001
[06:55:12.693] iteration:13739  t-loss:0.3302, loss-lb:0.1166, loss-ulb:0.1068, weight:2.00, lr:0.0001
[06:55:13.009] iteration:13740  t-loss:0.3783, loss-lb:0.2009, loss-ulb:0.0887, weight:2.00, lr:0.0001
[06:55:13.331] iteration:13741  t-loss:0.3787, loss-lb:0.1841, loss-ulb:0.0973, weight:2.00, lr:0.0001
[06:55:13.650] iteration:13742  t-loss:0.5467, loss-lb:0.3372, loss-ulb:0.1047, weight:2.00, lr:0.0001
[06:55:13.965] iteration:13743  t-loss:0.3681, loss-lb:0.1981, loss-ulb:0.0850, weight:2.00, lr:0.0001
[06:55:14.282] iteration:13744  t-loss:0.2914, loss-lb:0.2265, loss-ulb:0.0325, weight:2.00, lr:0.0001
[06:55:14.594] iteration:13745  t-loss:0.1850, loss-lb:0.1596, loss-ulb:0.0127, weight:2.00, lr:0.0001
[06:55:14.906] iteration:13746  t-loss:0.3292, loss-lb:0.1416, loss-ulb:0.0938, weight:2.00, lr:0.0001
[06:55:15.217] iteration:13747  t-loss:0.3141, loss-lb:0.1566, loss-ulb:0.0788, weight:2.00, lr:0.0001
[06:55:15.532] iteration:13748  t-loss:0.2906, loss-lb:0.1572, loss-ulb:0.0667, weight:2.00, lr:0.0001
[06:55:15.839] iteration:13749  t-loss:0.2172, loss-lb:0.1787, loss-ulb:0.0192, weight:2.00, lr:0.0001
[06:55:16.151] iteration:13750  t-loss:0.2117, loss-lb:0.1449, loss-ulb:0.0334, weight:2.00, lr:0.0001
[06:55:17.506] iteration:13751  t-loss:0.3730, loss-lb:0.1277, loss-ulb:0.1226, weight:2.00, lr:0.0001
[06:55:17.853] iteration:13752  t-loss:0.2984, loss-lb:0.1745, loss-ulb:0.0619, weight:2.00, lr:0.0001
[06:55:18.177] iteration:13753  t-loss:0.4163, loss-lb:0.1230, loss-ulb:0.1467, weight:2.00, lr:0.0001
[06:55:18.493] iteration:13754  t-loss:0.2536, loss-lb:0.1505, loss-ulb:0.0516, weight:2.00, lr:0.0001
[06:55:18.811] iteration:13755  t-loss:0.3479, loss-lb:0.2285, loss-ulb:0.0597, weight:2.00, lr:0.0001
[06:55:19.127] iteration:13756  t-loss:0.2305, loss-lb:0.2068, loss-ulb:0.0118, weight:2.00, lr:0.0001
[06:55:19.441] iteration:13757  t-loss:0.2824, loss-lb:0.1392, loss-ulb:0.0716, weight:2.00, lr:0.0001
[06:55:19.758] iteration:13758  t-loss:0.3021, loss-lb:0.1706, loss-ulb:0.0658, weight:2.00, lr:0.0001
[06:55:20.073] iteration:13759  t-loss:0.2903, loss-lb:0.2324, loss-ulb:0.0290, weight:2.00, lr:0.0001
[06:55:20.390] iteration:13760  t-loss:0.4191, loss-lb:0.2764, loss-ulb:0.0714, weight:2.00, lr:0.0001
[06:55:20.702] iteration:13761  t-loss:0.1923, loss-lb:0.1573, loss-ulb:0.0175, weight:2.00, lr:0.0001
[06:55:21.018] iteration:13762  t-loss:0.2700, loss-lb:0.1170, loss-ulb:0.0765, weight:2.00, lr:0.0001
[06:55:21.334] iteration:13763  t-loss:0.1889, loss-lb:0.1597, loss-ulb:0.0146, weight:2.00, lr:0.0001
[06:55:21.658] iteration:13764  t-loss:0.3435, loss-lb:0.2187, loss-ulb:0.0624, weight:2.00, lr:0.0001
[06:55:21.976] iteration:13765  t-loss:0.2811, loss-lb:0.1975, loss-ulb:0.0418, weight:2.00, lr:0.0001
[06:55:22.308] iteration:13766  t-loss:0.2866, loss-lb:0.1693, loss-ulb:0.0587, weight:2.00, lr:0.0001
[06:55:22.630] iteration:13767  t-loss:0.4513, loss-lb:0.2476, loss-ulb:0.1018, weight:2.00, lr:0.0001
[06:55:22.952] iteration:13768  t-loss:0.4319, loss-lb:0.1493, loss-ulb:0.1413, weight:2.00, lr:0.0001
[06:55:23.268] iteration:13769  t-loss:0.2592, loss-lb:0.1830, loss-ulb:0.0381, weight:2.00, lr:0.0001
[06:55:23.584] iteration:13770  t-loss:0.4119, loss-lb:0.1508, loss-ulb:0.1306, weight:2.00, lr:0.0001
[06:55:23.899] iteration:13771  t-loss:0.3248, loss-lb:0.1690, loss-ulb:0.0779, weight:2.00, lr:0.0001
[06:55:24.213] iteration:13772  t-loss:0.1677, loss-lb:0.1264, loss-ulb:0.0206, weight:2.00, lr:0.0001
[06:55:24.528] iteration:13773  t-loss:0.3096, loss-lb:0.1634, loss-ulb:0.0731, weight:2.00, lr:0.0001
[06:55:24.841] iteration:13774  t-loss:0.2479, loss-lb:0.1926, loss-ulb:0.0277, weight:2.00, lr:0.0001
[06:55:25.154] iteration:13775  t-loss:0.2037, loss-lb:0.1592, loss-ulb:0.0222, weight:2.00, lr:0.0001
[06:55:26.401] iteration:13776  t-loss:0.2940, loss-lb:0.1394, loss-ulb:0.0773, weight:2.00, lr:0.0001
[06:55:26.731] iteration:13777  t-loss:0.3983, loss-lb:0.2147, loss-ulb:0.0918, weight:2.00, lr:0.0001
[06:55:27.048] iteration:13778  t-loss:0.5393, loss-lb:0.5119, loss-ulb:0.0137, weight:2.00, lr:0.0001
[06:55:27.362] iteration:13779  t-loss:0.4246, loss-lb:0.1388, loss-ulb:0.1429, weight:2.00, lr:0.0001
[06:55:27.684] iteration:13780  t-loss:0.3498, loss-lb:0.2000, loss-ulb:0.0749, weight:2.00, lr:0.0001
[06:55:27.998] iteration:13781  t-loss:0.2853, loss-lb:0.1601, loss-ulb:0.0626, weight:2.00, lr:0.0001
[06:55:28.317] iteration:13782  t-loss:0.3112, loss-lb:0.1541, loss-ulb:0.0786, weight:2.00, lr:0.0001
[06:55:28.634] iteration:13783  t-loss:0.3748, loss-lb:0.2582, loss-ulb:0.0583, weight:2.00, lr:0.0001
[06:55:28.952] iteration:13784  t-loss:0.3562, loss-lb:0.1289, loss-ulb:0.1136, weight:2.00, lr:0.0001
[06:55:29.268] iteration:13785  t-loss:0.2867, loss-lb:0.1505, loss-ulb:0.0681, weight:2.00, lr:0.0001
[06:55:29.582] iteration:13786  t-loss:0.1832, loss-lb:0.1441, loss-ulb:0.0195, weight:2.00, lr:0.0001
[06:55:29.897] iteration:13787  t-loss:0.2653, loss-lb:0.2283, loss-ulb:0.0185, weight:2.00, lr:0.0001
[06:55:30.215] iteration:13788  t-loss:0.2157, loss-lb:0.1259, loss-ulb:0.0449, weight:2.00, lr:0.0001
[06:55:30.533] iteration:13789  t-loss:0.2220, loss-lb:0.1934, loss-ulb:0.0143, weight:2.00, lr:0.0001
[06:55:30.848] iteration:13790  t-loss:0.2392, loss-lb:0.2046, loss-ulb:0.0173, weight:2.00, lr:0.0001
[06:55:31.162] iteration:13791  t-loss:0.3088, loss-lb:0.2194, loss-ulb:0.0447, weight:2.00, lr:0.0001
[06:55:31.478] iteration:13792  t-loss:0.3862, loss-lb:0.2583, loss-ulb:0.0640, weight:2.00, lr:0.0001
[06:55:31.788] iteration:13793  t-loss:0.1758, loss-lb:0.1207, loss-ulb:0.0275, weight:2.00, lr:0.0001
[06:55:32.102] iteration:13794  t-loss:0.2661, loss-lb:0.1874, loss-ulb:0.0393, weight:2.00, lr:0.0001
[06:55:32.416] iteration:13795  t-loss:0.2449, loss-lb:0.1435, loss-ulb:0.0507, weight:2.00, lr:0.0001
[06:55:32.730] iteration:13796  t-loss:0.4079, loss-lb:0.1617, loss-ulb:0.1231, weight:2.00, lr:0.0001
[06:55:33.045] iteration:13797  t-loss:0.3935, loss-lb:0.2777, loss-ulb:0.0579, weight:2.00, lr:0.0001
[06:55:33.362] iteration:13798  t-loss:0.2524, loss-lb:0.1516, loss-ulb:0.0504, weight:2.00, lr:0.0001
[06:55:33.678] iteration:13799  t-loss:0.3365, loss-lb:0.2460, loss-ulb:0.0452, weight:2.00, lr:0.0001
[06:55:33.991] iteration:13800  t-loss:0.2035, loss-lb:0.1441, loss-ulb:0.0297, weight:2.00, lr:0.0001
[06:55:35.173] iteration:13801  t-loss:0.2030, loss-lb:0.1635, loss-ulb:0.0198, weight:2.00, lr:0.0001
[06:55:35.503] iteration:13802  t-loss:0.1954, loss-lb:0.1601, loss-ulb:0.0176, weight:2.00, lr:0.0001
[06:55:35.828] iteration:13803  t-loss:0.1740, loss-lb:0.1377, loss-ulb:0.0181, weight:2.00, lr:0.0001
[06:55:36.151] iteration:13804  t-loss:0.1931, loss-lb:0.1237, loss-ulb:0.0347, weight:2.00, lr:0.0001
[06:55:36.470] iteration:13805  t-loss:0.2697, loss-lb:0.1343, loss-ulb:0.0677, weight:2.00, lr:0.0001
[06:55:36.801] iteration:13806  t-loss:0.1858, loss-lb:0.1055, loss-ulb:0.0401, weight:2.00, lr:0.0001
[06:55:37.130] iteration:13807  t-loss:0.2310, loss-lb:0.1673, loss-ulb:0.0318, weight:2.00, lr:0.0001
[06:55:37.450] iteration:13808  t-loss:0.3820, loss-lb:0.1785, loss-ulb:0.1018, weight:2.00, lr:0.0001
[06:55:37.774] iteration:13809  t-loss:0.2997, loss-lb:0.1784, loss-ulb:0.0606, weight:2.00, lr:0.0001
[06:55:38.093] iteration:13810  t-loss:0.2714, loss-lb:0.1585, loss-ulb:0.0565, weight:2.00, lr:0.0001
[06:55:38.412] iteration:13811  t-loss:0.4817, loss-lb:0.2015, loss-ulb:0.1401, weight:2.00, lr:0.0001
[06:55:38.728] iteration:13812  t-loss:0.4249, loss-lb:0.2442, loss-ulb:0.0904, weight:2.00, lr:0.0001
[06:55:39.044] iteration:13813  t-loss:0.1857, loss-lb:0.1459, loss-ulb:0.0199, weight:2.00, lr:0.0001
[06:55:39.359] iteration:13814  t-loss:0.1968, loss-lb:0.1676, loss-ulb:0.0146, weight:2.00, lr:0.0001
[06:55:39.680] iteration:13815  t-loss:0.2494, loss-lb:0.1134, loss-ulb:0.0680, weight:2.00, lr:0.0001
[06:55:39.996] iteration:13816  t-loss:0.1958, loss-lb:0.1527, loss-ulb:0.0215, weight:2.00, lr:0.0001
[06:55:40.322] iteration:13817  t-loss:0.4391, loss-lb:0.2634, loss-ulb:0.0878, weight:2.00, lr:0.0001
[06:55:40.635] iteration:13818  t-loss:0.2071, loss-lb:0.1802, loss-ulb:0.0135, weight:2.00, lr:0.0001
[06:55:40.953] iteration:13819  t-loss:0.2175, loss-lb:0.1863, loss-ulb:0.0156, weight:2.00, lr:0.0001
[06:55:41.270] iteration:13820  t-loss:0.3801, loss-lb:0.2368, loss-ulb:0.0717, weight:2.00, lr:0.0001
[06:55:41.588] iteration:13821  t-loss:0.1999, loss-lb:0.1573, loss-ulb:0.0213, weight:2.00, lr:0.0001
[06:55:41.902] iteration:13822  t-loss:0.2462, loss-lb:0.1539, loss-ulb:0.0462, weight:2.00, lr:0.0001
[06:55:42.215] iteration:13823  t-loss:0.3892, loss-lb:0.1377, loss-ulb:0.1258, weight:2.00, lr:0.0001
[06:55:42.530] iteration:13824  t-loss:0.3255, loss-lb:0.1764, loss-ulb:0.0745, weight:2.00, lr:0.0001
[06:55:42.848] iteration:13825  t-loss:0.3997, loss-lb:0.2072, loss-ulb:0.0962, weight:2.00, lr:0.0001
[06:57:36.251] iteration 13825 : dice_score: 0.852170 best_dice: 0.854000
[06:57:36.251]  <<Test>> - Ep:552  - Dice-S/T:85.19/85.22, Best-S:85.59, Best-T:85.40
[06:57:36.251]           - AvgLoss(lb/ulb/all):0.17/0.06/0.30
[06:57:37.492] iteration:13826  t-loss:0.2794, loss-lb:0.2413, loss-ulb:0.0190, weight:2.00, lr:0.0001
[06:57:37.822] iteration:13827  t-loss:0.2829, loss-lb:0.2426, loss-ulb:0.0202, weight:2.00, lr:0.0001
[06:57:38.140] iteration:13828  t-loss:0.2531, loss-lb:0.1664, loss-ulb:0.0434, weight:2.00, lr:0.0001
[06:57:38.459] iteration:13829  t-loss:0.3465, loss-lb:0.1286, loss-ulb:0.1090, weight:2.00, lr:0.0001
[06:57:38.777] iteration:13830  t-loss:0.1668, loss-lb:0.1359, loss-ulb:0.0155, weight:2.00, lr:0.0001
[06:57:39.094] iteration:13831  t-loss:0.1908, loss-lb:0.1588, loss-ulb:0.0160, weight:2.00, lr:0.0001
[06:57:39.409] iteration:13832  t-loss:0.4089, loss-lb:0.1417, loss-ulb:0.1336, weight:2.00, lr:0.0001
[06:57:39.722] iteration:13833  t-loss:0.2589, loss-lb:0.1368, loss-ulb:0.0610, weight:2.00, lr:0.0001
[06:57:40.038] iteration:13834  t-loss:0.2416, loss-lb:0.2049, loss-ulb:0.0184, weight:2.00, lr:0.0001
[06:57:40.362] iteration:13835  t-loss:0.2962, loss-lb:0.2119, loss-ulb:0.0421, weight:2.00, lr:0.0001
[06:57:40.677] iteration:13836  t-loss:0.1695, loss-lb:0.1290, loss-ulb:0.0203, weight:2.00, lr:0.0001
[06:57:40.991] iteration:13837  t-loss:0.3226, loss-lb:0.1284, loss-ulb:0.0971, weight:2.00, lr:0.0001
[06:57:41.310] iteration:13838  t-loss:0.4518, loss-lb:0.2767, loss-ulb:0.0876, weight:2.00, lr:0.0001
[06:57:41.626] iteration:13839  t-loss:0.4466, loss-lb:0.2148, loss-ulb:0.1159, weight:2.00, lr:0.0001
[06:57:41.944] iteration:13840  t-loss:0.2341, loss-lb:0.2005, loss-ulb:0.0168, weight:2.00, lr:0.0001
[06:57:42.261] iteration:13841  t-loss:0.1571, loss-lb:0.1293, loss-ulb:0.0139, weight:2.00, lr:0.0001
[06:57:42.577] iteration:13842  t-loss:0.2568, loss-lb:0.1833, loss-ulb:0.0367, weight:2.00, lr:0.0001
[06:57:42.892] iteration:13843  t-loss:0.2442, loss-lb:0.1366, loss-ulb:0.0538, weight:2.00, lr:0.0001
[06:57:43.208] iteration:13844  t-loss:0.3556, loss-lb:0.2014, loss-ulb:0.0771, weight:2.00, lr:0.0001
[06:57:43.520] iteration:13845  t-loss:0.4182, loss-lb:0.1269, loss-ulb:0.1457, weight:2.00, lr:0.0001
[06:57:43.835] iteration:13846  t-loss:0.3474, loss-lb:0.1765, loss-ulb:0.0855, weight:2.00, lr:0.0001
[06:57:44.151] iteration:13847  t-loss:0.2781, loss-lb:0.1295, loss-ulb:0.0743, weight:2.00, lr:0.0001
[06:57:44.466] iteration:13848  t-loss:0.3755, loss-lb:0.2500, loss-ulb:0.0628, weight:2.00, lr:0.0001
[06:57:44.778] iteration:13849  t-loss:0.1935, loss-lb:0.1408, loss-ulb:0.0264, weight:2.00, lr:0.0001
[06:57:45.090] iteration:13850  t-loss:0.3325, loss-lb:0.1549, loss-ulb:0.0888, weight:2.00, lr:0.0001
[06:57:46.181] iteration:13851  t-loss:0.3871, loss-lb:0.2031, loss-ulb:0.0920, weight:2.00, lr:0.0001
[06:57:46.519] iteration:13852  t-loss:0.2751, loss-lb:0.1765, loss-ulb:0.0493, weight:2.00, lr:0.0001
[06:57:46.851] iteration:13853  t-loss:0.2300, loss-lb:0.1132, loss-ulb:0.0584, weight:2.00, lr:0.0001
[06:57:47.168] iteration:13854  t-loss:0.2829, loss-lb:0.1548, loss-ulb:0.0641, weight:2.00, lr:0.0001
[06:57:47.483] iteration:13855  t-loss:0.3531, loss-lb:0.1204, loss-ulb:0.1163, weight:2.00, lr:0.0001
[06:57:47.797] iteration:13856  t-loss:0.3133, loss-lb:0.2725, loss-ulb:0.0204, weight:2.00, lr:0.0001
[06:57:48.113] iteration:13857  t-loss:0.2797, loss-lb:0.2532, loss-ulb:0.0132, weight:2.00, lr:0.0001
[06:57:48.427] iteration:13858  t-loss:0.2456, loss-lb:0.1350, loss-ulb:0.0553, weight:2.00, lr:0.0001
[06:57:48.745] iteration:13859  t-loss:0.3531, loss-lb:0.2213, loss-ulb:0.0659, weight:2.00, lr:0.0001
[06:57:49.062] iteration:13860  t-loss:0.1904, loss-lb:0.1629, loss-ulb:0.0137, weight:2.00, lr:0.0001
[06:57:49.379] iteration:13861  t-loss:0.1506, loss-lb:0.1202, loss-ulb:0.0152, weight:2.00, lr:0.0001
[06:57:49.697] iteration:13862  t-loss:0.2372, loss-lb:0.1674, loss-ulb:0.0349, weight:2.00, lr:0.0001
[06:57:50.016] iteration:13863  t-loss:0.4046, loss-lb:0.1895, loss-ulb:0.1076, weight:2.00, lr:0.0001
[06:57:50.337] iteration:13864  t-loss:0.4222, loss-lb:0.2254, loss-ulb:0.0984, weight:2.00, lr:0.0001
[06:57:50.653] iteration:13865  t-loss:0.3249, loss-lb:0.2546, loss-ulb:0.0351, weight:2.00, lr:0.0001
[06:57:50.971] iteration:13866  t-loss:0.4359, loss-lb:0.2050, loss-ulb:0.1155, weight:2.00, lr:0.0001
[06:57:51.290] iteration:13867  t-loss:0.3695, loss-lb:0.2181, loss-ulb:0.0757, weight:2.00, lr:0.0001
[06:57:51.605] iteration:13868  t-loss:0.2785, loss-lb:0.1513, loss-ulb:0.0636, weight:2.00, lr:0.0001
[06:57:51.919] iteration:13869  t-loss:0.1816, loss-lb:0.1431, loss-ulb:0.0192, weight:2.00, lr:0.0001
[06:57:52.235] iteration:13870  t-loss:0.4769, loss-lb:0.1747, loss-ulb:0.1511, weight:2.00, lr:0.0001
[06:57:52.550] iteration:13871  t-loss:0.2240, loss-lb:0.2031, loss-ulb:0.0104, weight:2.00, lr:0.0001
[06:57:52.866] iteration:13872  t-loss:0.3652, loss-lb:0.2273, loss-ulb:0.0690, weight:2.00, lr:0.0001
[06:57:53.180] iteration:13873  t-loss:0.2325, loss-lb:0.1443, loss-ulb:0.0441, weight:2.00, lr:0.0001
[06:57:53.492] iteration:13874  t-loss:0.5771, loss-lb:0.1414, loss-ulb:0.2179, weight:2.00, lr:0.0001
[06:57:53.806] iteration:13875  t-loss:0.2524, loss-lb:0.1805, loss-ulb:0.0359, weight:2.00, lr:0.0001
[06:57:54.874] iteration:13876  t-loss:0.2779, loss-lb:0.1811, loss-ulb:0.0484, weight:2.00, lr:0.0001
[06:57:55.204] iteration:13877  t-loss:0.2741, loss-lb:0.1302, loss-ulb:0.0720, weight:2.00, lr:0.0001
[06:57:55.530] iteration:13878  t-loss:0.4359, loss-lb:0.2926, loss-ulb:0.0717, weight:2.00, lr:0.0001
[06:57:55.849] iteration:13879  t-loss:0.2540, loss-lb:0.2300, loss-ulb:0.0120, weight:2.00, lr:0.0001
[06:57:56.164] iteration:13880  t-loss:0.2763, loss-lb:0.1568, loss-ulb:0.0598, weight:2.00, lr:0.0001
[06:57:56.484] iteration:13881  t-loss:0.2506, loss-lb:0.1416, loss-ulb:0.0545, weight:2.00, lr:0.0001
[06:57:56.799] iteration:13882  t-loss:0.2256, loss-lb:0.1926, loss-ulb:0.0165, weight:2.00, lr:0.0001
[06:57:57.113] iteration:13883  t-loss:0.2976, loss-lb:0.1820, loss-ulb:0.0578, weight:2.00, lr:0.0001
[06:57:57.429] iteration:13884  t-loss:0.3165, loss-lb:0.1407, loss-ulb:0.0879, weight:2.00, lr:0.0001
[06:57:57.745] iteration:13885  t-loss:0.1484, loss-lb:0.1255, loss-ulb:0.0114, weight:2.00, lr:0.0001
[06:57:58.061] iteration:13886  t-loss:0.1747, loss-lb:0.1294, loss-ulb:0.0226, weight:2.00, lr:0.0001
[06:57:58.389] iteration:13887  t-loss:0.3975, loss-lb:0.1837, loss-ulb:0.1069, weight:2.00, lr:0.0001
[06:57:58.718] iteration:13888  t-loss:0.3227, loss-lb:0.1725, loss-ulb:0.0751, weight:2.00, lr:0.0001
[06:57:59.046] iteration:13889  t-loss:0.2109, loss-lb:0.1872, loss-ulb:0.0119, weight:2.00, lr:0.0001
[06:57:59.371] iteration:13890  t-loss:0.3603, loss-lb:0.1661, loss-ulb:0.0971, weight:2.00, lr:0.0001
[06:57:59.694] iteration:13891  t-loss:0.2275, loss-lb:0.1933, loss-ulb:0.0171, weight:2.00, lr:0.0001
[06:58:00.021] iteration:13892  t-loss:0.2429, loss-lb:0.1362, loss-ulb:0.0534, weight:2.00, lr:0.0001
[06:58:00.345] iteration:13893  t-loss:0.1834, loss-lb:0.1611, loss-ulb:0.0111, weight:2.00, lr:0.0001
[06:58:00.667] iteration:13894  t-loss:0.3069, loss-lb:0.1274, loss-ulb:0.0898, weight:2.00, lr:0.0001
[06:58:00.986] iteration:13895  t-loss:0.5856, loss-lb:0.2202, loss-ulb:0.1827, weight:2.00, lr:0.0001
[06:58:01.299] iteration:13896  t-loss:0.1446, loss-lb:0.1160, loss-ulb:0.0143, weight:2.00, lr:0.0001
[06:58:01.617] iteration:13897  t-loss:0.4765, loss-lb:0.1837, loss-ulb:0.1464, weight:2.00, lr:0.0001
[06:58:01.934] iteration:13898  t-loss:0.3100, loss-lb:0.2243, loss-ulb:0.0429, weight:2.00, lr:0.0001
[06:58:02.249] iteration:13899  t-loss:0.2313, loss-lb:0.1408, loss-ulb:0.0453, weight:2.00, lr:0.0001
[06:58:02.565] iteration:13900  t-loss:0.4134, loss-lb:0.2534, loss-ulb:0.0800, weight:2.00, lr:0.0001
[06:58:03.630] iteration:13901  t-loss:0.1771, loss-lb:0.1528, loss-ulb:0.0121, weight:2.00, lr:0.0001
[06:58:03.960] iteration:13902  t-loss:0.3274, loss-lb:0.1341, loss-ulb:0.0966, weight:2.00, lr:0.0001
[06:58:04.278] iteration:13903  t-loss:0.2647, loss-lb:0.2148, loss-ulb:0.0250, weight:2.00, lr:0.0001
[06:58:04.595] iteration:13904  t-loss:0.4679, loss-lb:0.2994, loss-ulb:0.0842, weight:2.00, lr:0.0001
[06:58:04.911] iteration:13905  t-loss:0.3454, loss-lb:0.1926, loss-ulb:0.0764, weight:2.00, lr:0.0001
[06:58:05.225] iteration:13906  t-loss:0.2263, loss-lb:0.1961, loss-ulb:0.0151, weight:2.00, lr:0.0001
[06:58:05.539] iteration:13907  t-loss:0.1925, loss-lb:0.1621, loss-ulb:0.0152, weight:2.00, lr:0.0001
[06:58:05.854] iteration:13908  t-loss:0.4750, loss-lb:0.2010, loss-ulb:0.1370, weight:2.00, lr:0.0001
[06:58:06.170] iteration:13909  t-loss:0.3548, loss-lb:0.1341, loss-ulb:0.1104, weight:2.00, lr:0.0001
[06:58:06.487] iteration:13910  t-loss:0.3274, loss-lb:0.2240, loss-ulb:0.0517, weight:2.00, lr:0.0001
[06:58:06.805] iteration:13911  t-loss:0.2852, loss-lb:0.1549, loss-ulb:0.0652, weight:2.00, lr:0.0001
[06:58:07.123] iteration:13912  t-loss:0.2434, loss-lb:0.2090, loss-ulb:0.0172, weight:2.00, lr:0.0001
[06:58:07.443] iteration:13913  t-loss:0.1996, loss-lb:0.1558, loss-ulb:0.0219, weight:2.00, lr:0.0001
[06:58:07.766] iteration:13914  t-loss:0.1996, loss-lb:0.1246, loss-ulb:0.0375, weight:2.00, lr:0.0001
[06:58:08.093] iteration:13915  t-loss:0.3169, loss-lb:0.1911, loss-ulb:0.0629, weight:2.00, lr:0.0001
[06:58:08.425] iteration:13916  t-loss:0.1816, loss-lb:0.1510, loss-ulb:0.0153, weight:2.00, lr:0.0001
[06:58:08.759] iteration:13917  t-loss:0.4041, loss-lb:0.2167, loss-ulb:0.0937, weight:2.00, lr:0.0001
[06:58:09.087] iteration:13918  t-loss:0.4558, loss-lb:0.3050, loss-ulb:0.0754, weight:2.00, lr:0.0001
[06:58:09.408] iteration:13919  t-loss:0.2521, loss-lb:0.2192, loss-ulb:0.0164, weight:2.00, lr:0.0001
[06:58:09.731] iteration:13920  t-loss:0.2064, loss-lb:0.1887, loss-ulb:0.0089, weight:2.00, lr:0.0001
[06:58:10.053] iteration:13921  t-loss:0.4772, loss-lb:0.2174, loss-ulb:0.1299, weight:2.00, lr:0.0001
[06:58:10.372] iteration:13922  t-loss:0.2606, loss-lb:0.1136, loss-ulb:0.0735, weight:2.00, lr:0.0001
[06:58:10.685] iteration:13923  t-loss:0.3219, loss-lb:0.1459, loss-ulb:0.0880, weight:2.00, lr:0.0001
[06:58:11.002] iteration:13924  t-loss:0.3808, loss-lb:0.2134, loss-ulb:0.0837, weight:2.00, lr:0.0001
[06:58:11.316] iteration:13925  t-loss:0.1912, loss-lb:0.1426, loss-ulb:0.0243, weight:2.00, lr:0.0001
[06:59:59.694] iteration 13925 : dice_score: 0.851640 best_dice: 0.854000
[06:59:59.695]  <<Test>> - Ep:556  - Dice-S/T:84.96/85.16, Best-S:85.59, Best-T:85.40
[06:59:59.695]           - AvgLoss(lb/ulb/all):0.19/0.06/0.30
[07:00:00.862] iteration:13926  t-loss:0.4120, loss-lb:0.2061, loss-ulb:0.1030, weight:2.00, lr:0.0001
[07:00:01.190] iteration:13927  t-loss:0.5228, loss-lb:0.2795, loss-ulb:0.1216, weight:2.00, lr:0.0001
[07:00:01.511] iteration:13928  t-loss:0.2035, loss-lb:0.1523, loss-ulb:0.0256, weight:2.00, lr:0.0001
[07:00:01.826] iteration:13929  t-loss:0.2220, loss-lb:0.1899, loss-ulb:0.0160, weight:2.00, lr:0.0001
[07:00:02.142] iteration:13930  t-loss:0.1637, loss-lb:0.1195, loss-ulb:0.0221, weight:2.00, lr:0.0001
[07:00:02.456] iteration:13931  t-loss:0.3866, loss-lb:0.2203, loss-ulb:0.0832, weight:2.00, lr:0.0001
[07:00:02.773] iteration:13932  t-loss:0.1870, loss-lb:0.1624, loss-ulb:0.0123, weight:2.00, lr:0.0001
[07:00:03.096] iteration:13933  t-loss:0.2971, loss-lb:0.1907, loss-ulb:0.0532, weight:2.00, lr:0.0001
[07:00:03.413] iteration:13934  t-loss:0.3758, loss-lb:0.1803, loss-ulb:0.0977, weight:2.00, lr:0.0001
[07:00:03.728] iteration:13935  t-loss:0.1480, loss-lb:0.1250, loss-ulb:0.0115, weight:2.00, lr:0.0001
[07:00:04.048] iteration:13936  t-loss:0.1534, loss-lb:0.1241, loss-ulb:0.0146, weight:2.00, lr:0.0001
[07:00:04.381] iteration:13937  t-loss:1.4550, loss-lb:0.1392, loss-ulb:0.6579, weight:2.00, lr:0.0001
[07:00:04.715] iteration:13938  t-loss:0.3616, loss-lb:0.2527, loss-ulb:0.0545, weight:2.00, lr:0.0001
[07:00:05.044] iteration:13939  t-loss:0.2916, loss-lb:0.1448, loss-ulb:0.0734, weight:2.00, lr:0.0001
[07:00:05.379] iteration:13940  t-loss:0.3459, loss-lb:0.2469, loss-ulb:0.0495, weight:2.00, lr:0.0001
[07:00:05.714] iteration:13941  t-loss:0.2868, loss-lb:0.1630, loss-ulb:0.0619, weight:2.00, lr:0.0001
[07:00:06.038] iteration:13942  t-loss:0.2248, loss-lb:0.1770, loss-ulb:0.0239, weight:2.00, lr:0.0001
[07:00:06.359] iteration:13943  t-loss:0.3032, loss-lb:0.1420, loss-ulb:0.0806, weight:2.00, lr:0.0001
[07:00:06.686] iteration:13944  t-loss:0.3912, loss-lb:0.1949, loss-ulb:0.0981, weight:2.00, lr:0.0001
[07:00:07.005] iteration:13945  t-loss:0.3018, loss-lb:0.1297, loss-ulb:0.0860, weight:2.00, lr:0.0001
[07:00:07.321] iteration:13946  t-loss:0.3269, loss-lb:0.1478, loss-ulb:0.0895, weight:2.00, lr:0.0001
[07:00:07.635] iteration:13947  t-loss:0.3151, loss-lb:0.1905, loss-ulb:0.0623, weight:2.00, lr:0.0001
[07:00:07.949] iteration:13948  t-loss:0.4438, loss-lb:0.1450, loss-ulb:0.1494, weight:2.00, lr:0.0001
[07:00:08.263] iteration:13949  t-loss:0.2745, loss-lb:0.1947, loss-ulb:0.0399, weight:2.00, lr:0.0001
[07:00:08.575] iteration:13950  t-loss:0.2390, loss-lb:0.1775, loss-ulb:0.0308, weight:2.00, lr:0.0001
[07:00:09.784] iteration:13951  t-loss:0.3726, loss-lb:0.2508, loss-ulb:0.0609, weight:2.00, lr:0.0001
[07:00:10.108] iteration:13952  t-loss:0.1796, loss-lb:0.1443, loss-ulb:0.0177, weight:2.00, lr:0.0001
[07:00:10.426] iteration:13953  t-loss:0.2812, loss-lb:0.2578, loss-ulb:0.0117, weight:2.00, lr:0.0001
[07:00:10.741] iteration:13954  t-loss:0.3063, loss-lb:0.1018, loss-ulb:0.1022, weight:2.00, lr:0.0001
[07:00:11.058] iteration:13955  t-loss:0.4230, loss-lb:0.1713, loss-ulb:0.1258, weight:2.00, lr:0.0001
[07:00:11.376] iteration:13956  t-loss:0.2713, loss-lb:0.2412, loss-ulb:0.0151, weight:2.00, lr:0.0001
[07:00:11.689] iteration:13957  t-loss:0.2145, loss-lb:0.1804, loss-ulb:0.0170, weight:2.00, lr:0.0001
[07:00:12.003] iteration:13958  t-loss:0.2085, loss-lb:0.1399, loss-ulb:0.0343, weight:2.00, lr:0.0001
[07:00:12.318] iteration:13959  t-loss:0.3230, loss-lb:0.2102, loss-ulb:0.0564, weight:2.00, lr:0.0001
[07:00:12.631] iteration:13960  t-loss:0.2827, loss-lb:0.1271, loss-ulb:0.0778, weight:2.00, lr:0.0001
[07:00:12.945] iteration:13961  t-loss:0.1807, loss-lb:0.1307, loss-ulb:0.0250, weight:2.00, lr:0.0001
[07:00:13.261] iteration:13962  t-loss:0.2326, loss-lb:0.2032, loss-ulb:0.0147, weight:2.00, lr:0.0001
[07:00:13.575] iteration:13963  t-loss:0.2984, loss-lb:0.2223, loss-ulb:0.0380, weight:2.00, lr:0.0001
[07:00:13.894] iteration:13964  t-loss:0.2673, loss-lb:0.2028, loss-ulb:0.0322, weight:2.00, lr:0.0001
[07:00:14.213] iteration:13965  t-loss:0.2469, loss-lb:0.1836, loss-ulb:0.0316, weight:2.00, lr:0.0001
[07:00:14.529] iteration:13966  t-loss:0.1497, loss-lb:0.1265, loss-ulb:0.0116, weight:2.00, lr:0.0001
[07:00:14.846] iteration:13967  t-loss:0.3894, loss-lb:0.2192, loss-ulb:0.0851, weight:2.00, lr:0.0001
[07:00:15.161] iteration:13968  t-loss:0.1797, loss-lb:0.1583, loss-ulb:0.0107, weight:2.00, lr:0.0001
[07:00:15.477] iteration:13969  t-loss:0.3046, loss-lb:0.2644, loss-ulb:0.0201, weight:2.00, lr:0.0001
[07:00:15.790] iteration:13970  t-loss:0.2157, loss-lb:0.1665, loss-ulb:0.0246, weight:2.00, lr:0.0001
[07:00:16.104] iteration:13971  t-loss:0.2579, loss-lb:0.1352, loss-ulb:0.0613, weight:2.00, lr:0.0001
[07:00:16.415] iteration:13972  t-loss:0.5107, loss-lb:0.1527, loss-ulb:0.1790, weight:2.00, lr:0.0001
[07:00:16.731] iteration:13973  t-loss:0.3100, loss-lb:0.1761, loss-ulb:0.0669, weight:2.00, lr:0.0001
[07:00:17.043] iteration:13974  t-loss:0.1782, loss-lb:0.1531, loss-ulb:0.0125, weight:2.00, lr:0.0001
[07:00:17.357] iteration:13975  t-loss:0.2252, loss-lb:0.1548, loss-ulb:0.0352, weight:2.00, lr:0.0001
[07:00:18.407] iteration:13976  t-loss:0.2871, loss-lb:0.1515, loss-ulb:0.0678, weight:2.00, lr:0.0001
[07:00:18.748] iteration:13977  t-loss:0.2538, loss-lb:0.2247, loss-ulb:0.0145, weight:2.00, lr:0.0001
[07:00:19.076] iteration:13978  t-loss:0.2739, loss-lb:0.2480, loss-ulb:0.0130, weight:2.00, lr:0.0001
[07:00:19.401] iteration:13979  t-loss:0.3833, loss-lb:0.2372, loss-ulb:0.0730, weight:2.00, lr:0.0001
[07:00:19.721] iteration:13980  t-loss:0.2510, loss-lb:0.1720, loss-ulb:0.0395, weight:2.00, lr:0.0001
[07:00:20.041] iteration:13981  t-loss:0.4131, loss-lb:0.2086, loss-ulb:0.1023, weight:2.00, lr:0.0001
[07:00:20.362] iteration:13982  t-loss:0.3457, loss-lb:0.2123, loss-ulb:0.0667, weight:2.00, lr:0.0001
[07:00:20.676] iteration:13983  t-loss:0.1421, loss-lb:0.1207, loss-ulb:0.0107, weight:2.00, lr:0.0001
[07:00:20.991] iteration:13984  t-loss:0.2246, loss-lb:0.1389, loss-ulb:0.0428, weight:2.00, lr:0.0001
[07:00:21.307] iteration:13985  t-loss:0.1881, loss-lb:0.1625, loss-ulb:0.0128, weight:2.00, lr:0.0001
[07:00:21.621] iteration:13986  t-loss:0.2177, loss-lb:0.1528, loss-ulb:0.0324, weight:2.00, lr:0.0001
[07:00:21.938] iteration:13987  t-loss:0.2676, loss-lb:0.1119, loss-ulb:0.0778, weight:2.00, lr:0.0001
[07:00:22.256] iteration:13988  t-loss:0.4079, loss-lb:0.2104, loss-ulb:0.0988, weight:2.00, lr:0.0001
[07:00:22.572] iteration:13989  t-loss:0.2690, loss-lb:0.1481, loss-ulb:0.0605, weight:2.00, lr:0.0001
[07:00:22.885] iteration:13990  t-loss:0.3648, loss-lb:0.1373, loss-ulb:0.1137, weight:2.00, lr:0.0001
[07:00:23.202] iteration:13991  t-loss:0.3925, loss-lb:0.2181, loss-ulb:0.0872, weight:2.00, lr:0.0001
[07:00:23.517] iteration:13992  t-loss:0.2608, loss-lb:0.1575, loss-ulb:0.0517, weight:2.00, lr:0.0001
[07:00:23.835] iteration:13993  t-loss:0.3365, loss-lb:0.2161, loss-ulb:0.0602, weight:2.00, lr:0.0001
[07:00:24.150] iteration:13994  t-loss:0.3188, loss-lb:0.1474, loss-ulb:0.0857, weight:2.00, lr:0.0001
[07:00:24.463] iteration:13995  t-loss:0.1542, loss-lb:0.1295, loss-ulb:0.0123, weight:2.00, lr:0.0001
[07:00:24.778] iteration:13996  t-loss:0.7202, loss-lb:0.1760, loss-ulb:0.2721, weight:2.00, lr:0.0001
[07:00:25.092] iteration:13997  t-loss:0.1822, loss-lb:0.1527, loss-ulb:0.0147, weight:2.00, lr:0.0001
[07:00:25.406] iteration:13998  t-loss:0.3326, loss-lb:0.1431, loss-ulb:0.0947, weight:2.00, lr:0.0001
[07:00:25.720] iteration:13999  t-loss:0.3374, loss-lb:0.1859, loss-ulb:0.0758, weight:2.00, lr:0.0001
[07:00:26.035] iteration:14000  t-loss:0.1798, loss-lb:0.1437, loss-ulb:0.0181, weight:2.00, lr:0.0001
[07:00:27.222] iteration:14001  t-loss:0.3226, loss-lb:0.1543, loss-ulb:0.0841, weight:2.00, lr:0.0001
[07:00:27.550] iteration:14002  t-loss:0.2309, loss-lb:0.1532, loss-ulb:0.0389, weight:2.00, lr:0.0001
[07:00:27.876] iteration:14003  t-loss:0.1629, loss-lb:0.1027, loss-ulb:0.0301, weight:2.00, lr:0.0001
[07:00:28.194] iteration:14004  t-loss:0.4283, loss-lb:0.2730, loss-ulb:0.0776, weight:2.00, lr:0.0001
[07:00:28.512] iteration:14005  t-loss:0.3874, loss-lb:0.2407, loss-ulb:0.0733, weight:2.00, lr:0.0001
[07:00:28.837] iteration:14006  t-loss:0.6665, loss-lb:0.2343, loss-ulb:0.2161, weight:2.00, lr:0.0001
[07:00:29.159] iteration:14007  t-loss:0.2638, loss-lb:0.2190, loss-ulb:0.0224, weight:2.00, lr:0.0001
[07:00:29.483] iteration:14008  t-loss:0.1723, loss-lb:0.1337, loss-ulb:0.0193, weight:2.00, lr:0.0001
[07:00:29.809] iteration:14009  t-loss:0.3212, loss-lb:0.1840, loss-ulb:0.0686, weight:2.00, lr:0.0001
[07:00:30.134] iteration:14010  t-loss:0.2237, loss-lb:0.1136, loss-ulb:0.0550, weight:2.00, lr:0.0001
[07:00:30.456] iteration:14011  t-loss:0.2368, loss-lb:0.1325, loss-ulb:0.0521, weight:2.00, lr:0.0001
[07:00:30.776] iteration:14012  t-loss:0.1928, loss-lb:0.1485, loss-ulb:0.0221, weight:2.00, lr:0.0001
[07:00:31.096] iteration:14013  t-loss:0.4741, loss-lb:0.1920, loss-ulb:0.1411, weight:2.00, lr:0.0001
[07:00:31.417] iteration:14014  t-loss:0.3275, loss-lb:0.1129, loss-ulb:0.1073, weight:2.00, lr:0.0001
[07:00:31.736] iteration:14015  t-loss:0.2211, loss-lb:0.1227, loss-ulb:0.0492, weight:2.00, lr:0.0001
[07:00:32.050] iteration:14016  t-loss:0.2378, loss-lb:0.1895, loss-ulb:0.0242, weight:2.00, lr:0.0001
[07:00:32.363] iteration:14017  t-loss:0.1702, loss-lb:0.1455, loss-ulb:0.0123, weight:2.00, lr:0.0001
[07:00:32.680] iteration:14018  t-loss:0.3213, loss-lb:0.2248, loss-ulb:0.0482, weight:2.00, lr:0.0001
[07:00:32.993] iteration:14019  t-loss:0.2024, loss-lb:0.1163, loss-ulb:0.0431, weight:2.00, lr:0.0001
[07:00:33.306] iteration:14020  t-loss:0.2831, loss-lb:0.2425, loss-ulb:0.0203, weight:2.00, lr:0.0001
[07:00:33.618] iteration:14021  t-loss:0.3239, loss-lb:0.1565, loss-ulb:0.0837, weight:2.00, lr:0.0001
[07:00:33.932] iteration:14022  t-loss:0.2108, loss-lb:0.1753, loss-ulb:0.0177, weight:2.00, lr:0.0001
[07:00:34.248] iteration:14023  t-loss:0.2704, loss-lb:0.1383, loss-ulb:0.0661, weight:2.00, lr:0.0001
[07:00:34.561] iteration:14024  t-loss:0.1507, loss-lb:0.1047, loss-ulb:0.0230, weight:2.00, lr:0.0001
[07:00:34.876] iteration:14025  t-loss:0.1632, loss-lb:0.1384, loss-ulb:0.0124, weight:2.00, lr:0.0001
[07:02:24.187] iteration 14025 : dice_score: 0.851194 best_dice: 0.854000
[07:02:24.187]  <<Test>> - Ep:560  - Dice-S/T:85.02/85.12, Best-S:85.59, Best-T:85.40
[07:02:24.187]           - AvgLoss(lb/ulb/all):0.17/0.06/0.27
[07:02:25.039] iteration:14026  t-loss:0.2009, loss-lb:0.1775, loss-ulb:0.0117, weight:2.00, lr:0.0001
[07:02:25.373] iteration:14027  t-loss:0.3469, loss-lb:0.2328, loss-ulb:0.0570, weight:2.00, lr:0.0001
[07:02:25.691] iteration:14028  t-loss:0.1756, loss-lb:0.1446, loss-ulb:0.0155, weight:2.00, lr:0.0001
[07:02:26.006] iteration:14029  t-loss:0.1982, loss-lb:0.1649, loss-ulb:0.0167, weight:2.00, lr:0.0001
[07:02:26.324] iteration:14030  t-loss:0.5439, loss-lb:0.2377, loss-ulb:0.1531, weight:2.00, lr:0.0001
[07:02:26.641] iteration:14031  t-loss:0.1955, loss-lb:0.1139, loss-ulb:0.0408, weight:2.00, lr:0.0001
[07:02:26.957] iteration:14032  t-loss:0.2400, loss-lb:0.1458, loss-ulb:0.0471, weight:2.00, lr:0.0001
[07:02:27.276] iteration:14033  t-loss:0.7050, loss-lb:0.2553, loss-ulb:0.2248, weight:2.00, lr:0.0001
[07:02:27.597] iteration:14034  t-loss:0.3917, loss-lb:0.2545, loss-ulb:0.0686, weight:2.00, lr:0.0001
[07:02:27.918] iteration:14035  t-loss:0.3080, loss-lb:0.2687, loss-ulb:0.0196, weight:2.00, lr:0.0001
[07:02:28.240] iteration:14036  t-loss:0.2210, loss-lb:0.1478, loss-ulb:0.0366, weight:2.00, lr:0.0001
[07:02:28.560] iteration:14037  t-loss:0.3547, loss-lb:0.1167, loss-ulb:0.1190, weight:2.00, lr:0.0001
[07:02:28.880] iteration:14038  t-loss:0.4110, loss-lb:0.1298, loss-ulb:0.1406, weight:2.00, lr:0.0001
[07:02:29.207] iteration:14039  t-loss:0.1811, loss-lb:0.1211, loss-ulb:0.0300, weight:2.00, lr:0.0001
[07:02:29.541] iteration:14040  t-loss:0.2188, loss-lb:0.1897, loss-ulb:0.0145, weight:2.00, lr:0.0001
[07:02:29.862] iteration:14041  t-loss:0.2694, loss-lb:0.1319, loss-ulb:0.0688, weight:2.00, lr:0.0001
[07:02:30.184] iteration:14042  t-loss:0.3089, loss-lb:0.1637, loss-ulb:0.0726, weight:2.00, lr:0.0001
[07:02:30.503] iteration:14043  t-loss:0.3969, loss-lb:0.2430, loss-ulb:0.0769, weight:2.00, lr:0.0001
[07:02:30.820] iteration:14044  t-loss:0.1636, loss-lb:0.1311, loss-ulb:0.0163, weight:2.00, lr:0.0001
[07:02:31.134] iteration:14045  t-loss:0.2802, loss-lb:0.1547, loss-ulb:0.0627, weight:2.00, lr:0.0001
[07:02:31.448] iteration:14046  t-loss:0.2682, loss-lb:0.1332, loss-ulb:0.0675, weight:2.00, lr:0.0001
[07:02:31.763] iteration:14047  t-loss:0.2993, loss-lb:0.1936, loss-ulb:0.0529, weight:2.00, lr:0.0001
[07:02:32.078] iteration:14048  t-loss:0.4257, loss-lb:0.1645, loss-ulb:0.1306, weight:2.00, lr:0.0001
[07:02:32.392] iteration:14049  t-loss:0.1396, loss-lb:0.1137, loss-ulb:0.0129, weight:2.00, lr:0.0001
[07:02:32.704] iteration:14050  t-loss:0.1533, loss-lb:0.1223, loss-ulb:0.0155, weight:2.00, lr:0.0001
[07:02:33.814] iteration:14051  t-loss:0.4336, loss-lb:0.1970, loss-ulb:0.1183, weight:2.00, lr:0.0001
[07:02:34.143] iteration:14052  t-loss:0.3365, loss-lb:0.1919, loss-ulb:0.0723, weight:2.00, lr:0.0001
[07:02:34.458] iteration:14053  t-loss:0.3537, loss-lb:0.1586, loss-ulb:0.0976, weight:2.00, lr:0.0001
[07:02:34.778] iteration:14054  t-loss:0.2747, loss-lb:0.1331, loss-ulb:0.0708, weight:2.00, lr:0.0001
[07:02:35.098] iteration:14055  t-loss:0.1727, loss-lb:0.1255, loss-ulb:0.0236, weight:2.00, lr:0.0001
[07:02:35.412] iteration:14056  t-loss:0.2065, loss-lb:0.1266, loss-ulb:0.0400, weight:2.00, lr:0.0001
[07:02:35.730] iteration:14057  t-loss:0.4069, loss-lb:0.2795, loss-ulb:0.0637, weight:2.00, lr:0.0001
[07:02:36.047] iteration:14058  t-loss:0.2213, loss-lb:0.1918, loss-ulb:0.0147, weight:2.00, lr:0.0001
[07:02:36.367] iteration:14059  t-loss:0.2599, loss-lb:0.1647, loss-ulb:0.0476, weight:2.00, lr:0.0001
[07:02:36.684] iteration:14060  t-loss:0.2711, loss-lb:0.1877, loss-ulb:0.0417, weight:2.00, lr:0.0001
[07:02:37.000] iteration:14061  t-loss:0.3393, loss-lb:0.2419, loss-ulb:0.0487, weight:2.00, lr:0.0001
[07:02:37.314] iteration:14062  t-loss:0.4162, loss-lb:0.1362, loss-ulb:0.1400, weight:2.00, lr:0.0001
[07:02:37.629] iteration:14063  t-loss:0.3903, loss-lb:0.1248, loss-ulb:0.1327, weight:2.00, lr:0.0001
[07:02:37.948] iteration:14064  t-loss:0.3746, loss-lb:0.1875, loss-ulb:0.0935, weight:2.00, lr:0.0001
[07:02:38.263] iteration:14065  t-loss:0.2224, loss-lb:0.1849, loss-ulb:0.0187, weight:2.00, lr:0.0001
[07:02:38.582] iteration:14066  t-loss:0.2075, loss-lb:0.1331, loss-ulb:0.0372, weight:2.00, lr:0.0001
[07:02:38.898] iteration:14067  t-loss:0.2988, loss-lb:0.1643, loss-ulb:0.0673, weight:2.00, lr:0.0001
[07:02:39.211] iteration:14068  t-loss:0.2676, loss-lb:0.2299, loss-ulb:0.0189, weight:2.00, lr:0.0001
[07:02:39.525] iteration:14069  t-loss:0.3254, loss-lb:0.2288, loss-ulb:0.0483, weight:2.00, lr:0.0001
[07:02:39.838] iteration:14070  t-loss:0.2381, loss-lb:0.2131, loss-ulb:0.0125, weight:2.00, lr:0.0001
[07:02:40.151] iteration:14071  t-loss:0.2279, loss-lb:0.1118, loss-ulb:0.0581, weight:2.00, lr:0.0001
[07:02:40.462] iteration:14072  t-loss:0.1676, loss-lb:0.1376, loss-ulb:0.0150, weight:2.00, lr:0.0001
[07:02:40.776] iteration:14073  t-loss:0.3924, loss-lb:0.2100, loss-ulb:0.0912, weight:2.00, lr:0.0001
[07:02:41.088] iteration:14074  t-loss:0.2288, loss-lb:0.1585, loss-ulb:0.0352, weight:2.00, lr:0.0001
[07:02:41.400] iteration:14075  t-loss:0.2833, loss-lb:0.2506, loss-ulb:0.0164, weight:2.00, lr:0.0001
[07:02:42.509] iteration:14076  t-loss:0.4247, loss-lb:0.2212, loss-ulb:0.1017, weight:2.00, lr:0.0001
[07:02:42.845] iteration:14077  t-loss:0.1699, loss-lb:0.1482, loss-ulb:0.0108, weight:2.00, lr:0.0001
[07:02:43.169] iteration:14078  t-loss:0.3312, loss-lb:0.2128, loss-ulb:0.0592, weight:2.00, lr:0.0001
[07:02:43.496] iteration:14079  t-loss:0.3687, loss-lb:0.1935, loss-ulb:0.0876, weight:2.00, lr:0.0001
[07:02:43.815] iteration:14080  t-loss:0.3236, loss-lb:0.2600, loss-ulb:0.0318, weight:2.00, lr:0.0001
[07:02:44.135] iteration:14081  t-loss:0.2730, loss-lb:0.2458, loss-ulb:0.0136, weight:2.00, lr:0.0001
[07:02:44.456] iteration:14082  t-loss:0.3589, loss-lb:0.1940, loss-ulb:0.0824, weight:2.00, lr:0.0001
[07:02:44.774] iteration:14083  t-loss:0.2733, loss-lb:0.2210, loss-ulb:0.0262, weight:2.00, lr:0.0001
[07:02:45.090] iteration:14084  t-loss:0.4633, loss-lb:0.3138, loss-ulb:0.0748, weight:2.00, lr:0.0001
[07:02:45.415] iteration:14085  t-loss:0.3153, loss-lb:0.1909, loss-ulb:0.0622, weight:2.00, lr:0.0001
[07:02:45.733] iteration:14086  t-loss:0.1592, loss-lb:0.1385, loss-ulb:0.0103, weight:2.00, lr:0.0001
[07:02:46.053] iteration:14087  t-loss:0.2331, loss-lb:0.1989, loss-ulb:0.0171, weight:2.00, lr:0.0001
[07:02:46.368] iteration:14088  t-loss:0.2452, loss-lb:0.1173, loss-ulb:0.0639, weight:2.00, lr:0.0001
[07:02:46.684] iteration:14089  t-loss:0.3092, loss-lb:0.1774, loss-ulb:0.0659, weight:2.00, lr:0.0001
[07:02:46.999] iteration:14090  t-loss:0.1497, loss-lb:0.1046, loss-ulb:0.0226, weight:2.00, lr:0.0001
[07:02:47.323] iteration:14091  t-loss:0.3972, loss-lb:0.1971, loss-ulb:0.1001, weight:2.00, lr:0.0001
[07:02:47.638] iteration:14092  t-loss:0.2081, loss-lb:0.1692, loss-ulb:0.0195, weight:2.00, lr:0.0001
[07:02:47.953] iteration:14093  t-loss:0.3058, loss-lb:0.2053, loss-ulb:0.0502, weight:2.00, lr:0.0001
[07:02:48.269] iteration:14094  t-loss:0.4619, loss-lb:0.2056, loss-ulb:0.1282, weight:2.00, lr:0.0001
[07:02:48.584] iteration:14095  t-loss:0.1720, loss-lb:0.1358, loss-ulb:0.0181, weight:2.00, lr:0.0001
[07:02:48.898] iteration:14096  t-loss:0.2069, loss-lb:0.1731, loss-ulb:0.0169, weight:2.00, lr:0.0001
[07:02:49.213] iteration:14097  t-loss:0.2798, loss-lb:0.1313, loss-ulb:0.0743, weight:2.00, lr:0.0001
[07:02:49.527] iteration:14098  t-loss:0.2797, loss-lb:0.1542, loss-ulb:0.0628, weight:2.00, lr:0.0001
[07:02:49.842] iteration:14099  t-loss:0.1746, loss-lb:0.1502, loss-ulb:0.0122, weight:2.00, lr:0.0001
[07:02:50.156] iteration:14100  t-loss:0.2547, loss-lb:0.2257, loss-ulb:0.0145, weight:2.00, lr:0.0001
[07:02:51.237] iteration:14101  t-loss:0.3208, loss-lb:0.1363, loss-ulb:0.0922, weight:2.00, lr:0.0001
[07:02:51.563] iteration:14102  t-loss:0.1950, loss-lb:0.1477, loss-ulb:0.0237, weight:2.00, lr:0.0001
[07:02:51.888] iteration:14103  t-loss:0.1992, loss-lb:0.1671, loss-ulb:0.0160, weight:2.00, lr:0.0001
[07:02:52.205] iteration:14104  t-loss:0.3595, loss-lb:0.2411, loss-ulb:0.0592, weight:2.00, lr:0.0001
[07:02:52.519] iteration:14105  t-loss:0.2247, loss-lb:0.1971, loss-ulb:0.0138, weight:2.00, lr:0.0001
[07:02:52.836] iteration:14106  t-loss:0.4763, loss-lb:0.2656, loss-ulb:0.1054, weight:2.00, lr:0.0001
[07:02:53.153] iteration:14107  t-loss:0.3290, loss-lb:0.1092, loss-ulb:0.1099, weight:2.00, lr:0.0001
[07:02:53.466] iteration:14108  t-loss:0.3857, loss-lb:0.1996, loss-ulb:0.0931, weight:2.00, lr:0.0001
[07:02:53.781] iteration:14109  t-loss:0.2365, loss-lb:0.1330, loss-ulb:0.0518, weight:2.00, lr:0.0001
[07:02:54.101] iteration:14110  t-loss:0.3025, loss-lb:0.1850, loss-ulb:0.0588, weight:2.00, lr:0.0001
[07:02:54.416] iteration:14111  t-loss:0.2937, loss-lb:0.2465, loss-ulb:0.0236, weight:2.00, lr:0.0001
[07:02:54.732] iteration:14112  t-loss:0.2473, loss-lb:0.2231, loss-ulb:0.0121, weight:2.00, lr:0.0001
[07:02:55.049] iteration:14113  t-loss:0.3386, loss-lb:0.2434, loss-ulb:0.0476, weight:2.00, lr:0.0001
[07:02:55.371] iteration:14114  t-loss:0.2429, loss-lb:0.1763, loss-ulb:0.0333, weight:2.00, lr:0.0001
[07:02:55.694] iteration:14115  t-loss:0.2767, loss-lb:0.1622, loss-ulb:0.0573, weight:2.00, lr:0.0001
[07:02:56.022] iteration:14116  t-loss:0.2148, loss-lb:0.1118, loss-ulb:0.0515, weight:2.00, lr:0.0001
[07:02:56.349] iteration:14117  t-loss:0.3538, loss-lb:0.1920, loss-ulb:0.0809, weight:2.00, lr:0.0001
[07:02:56.672] iteration:14118  t-loss:0.3315, loss-lb:0.1790, loss-ulb:0.0763, weight:2.00, lr:0.0001
[07:02:56.992] iteration:14119  t-loss:0.2614, loss-lb:0.1663, loss-ulb:0.0475, weight:2.00, lr:0.0001
[07:02:57.306] iteration:14120  t-loss:0.3711, loss-lb:0.1589, loss-ulb:0.1061, weight:2.00, lr:0.0001
[07:02:57.623] iteration:14121  t-loss:0.2589, loss-lb:0.1407, loss-ulb:0.0591, weight:2.00, lr:0.0001
[07:02:57.940] iteration:14122  t-loss:0.3598, loss-lb:0.2711, loss-ulb:0.0444, weight:2.00, lr:0.0001
[07:02:58.254] iteration:14123  t-loss:0.2129, loss-lb:0.1776, loss-ulb:0.0177, weight:2.00, lr:0.0001
[07:02:58.573] iteration:14124  t-loss:0.3127, loss-lb:0.2023, loss-ulb:0.0552, weight:2.00, lr:0.0001
[07:02:58.885] iteration:14125  t-loss:0.2042, loss-lb:0.1371, loss-ulb:0.0335, weight:2.00, lr:0.0001
[07:04:47.508] iteration 14125 : dice_score: 0.850949 best_dice: 0.854000
[07:04:47.508]  <<Test>> - Ep:564  - Dice-S/T:85.00/85.09, Best-S:85.59, Best-T:85.40
[07:04:47.508]           - AvgLoss(lb/ulb/all):0.18/0.06/0.30
[07:04:48.539] iteration:14126  t-loss:0.3130, loss-lb:0.2131, loss-ulb:0.0500, weight:2.00, lr:0.0001
[07:04:48.867] iteration:14127  t-loss:0.5264, loss-lb:0.1562, loss-ulb:0.1851, weight:2.00, lr:0.0001
[07:04:49.188] iteration:14128  t-loss:0.2729, loss-lb:0.1538, loss-ulb:0.0596, weight:2.00, lr:0.0001
[07:04:49.507] iteration:14129  t-loss:0.3014, loss-lb:0.1367, loss-ulb:0.0823, weight:2.00, lr:0.0001
[07:04:49.828] iteration:14130  t-loss:0.2945, loss-lb:0.2197, loss-ulb:0.0374, weight:2.00, lr:0.0001
[07:04:50.152] iteration:14131  t-loss:0.2631, loss-lb:0.2301, loss-ulb:0.0165, weight:2.00, lr:0.0001
[07:04:50.470] iteration:14132  t-loss:0.3910, loss-lb:0.3133, loss-ulb:0.0389, weight:2.00, lr:0.0001
[07:04:50.787] iteration:14133  t-loss:0.2729, loss-lb:0.1147, loss-ulb:0.0791, weight:2.00, lr:0.0001
[07:04:51.103] iteration:14134  t-loss:0.3670, loss-lb:0.1717, loss-ulb:0.0976, weight:2.00, lr:0.0001
[07:04:51.418] iteration:14135  t-loss:0.4812, loss-lb:0.4587, loss-ulb:0.0112, weight:2.00, lr:0.0001
[07:04:51.735] iteration:14136  t-loss:0.3531, loss-lb:0.2502, loss-ulb:0.0515, weight:2.00, lr:0.0001
[07:04:52.049] iteration:14137  t-loss:0.3163, loss-lb:0.1548, loss-ulb:0.0807, weight:2.00, lr:0.0001
[07:04:52.368] iteration:14138  t-loss:0.4771, loss-lb:0.1400, loss-ulb:0.1686, weight:2.00, lr:0.0001
[07:04:52.681] iteration:14139  t-loss:0.2447, loss-lb:0.1395, loss-ulb:0.0526, weight:2.00, lr:0.0001
[07:04:52.999] iteration:14140  t-loss:0.3814, loss-lb:0.2552, loss-ulb:0.0631, weight:2.00, lr:0.0001
[07:04:53.312] iteration:14141  t-loss:0.1609, loss-lb:0.1320, loss-ulb:0.0144, weight:2.00, lr:0.0001
[07:04:53.628] iteration:14142  t-loss:0.3321, loss-lb:0.1329, loss-ulb:0.0996, weight:2.00, lr:0.0001
[07:04:53.942] iteration:14143  t-loss:0.3672, loss-lb:0.1184, loss-ulb:0.1244, weight:2.00, lr:0.0001
[07:04:54.257] iteration:14144  t-loss:0.2813, loss-lb:0.1307, loss-ulb:0.0753, weight:2.00, lr:0.0001
[07:04:54.572] iteration:14145  t-loss:0.3076, loss-lb:0.1125, loss-ulb:0.0975, weight:2.00, lr:0.0001
[07:04:54.884] iteration:14146  t-loss:0.2784, loss-lb:0.1290, loss-ulb:0.0747, weight:2.00, lr:0.0001
[07:04:55.195] iteration:14147  t-loss:0.2524, loss-lb:0.2176, loss-ulb:0.0174, weight:2.00, lr:0.0001
[07:04:55.510] iteration:14148  t-loss:0.2385, loss-lb:0.2084, loss-ulb:0.0151, weight:2.00, lr:0.0001
[07:04:55.823] iteration:14149  t-loss:0.3998, loss-lb:0.1776, loss-ulb:0.1111, weight:2.00, lr:0.0001
[07:04:56.141] iteration:14150  t-loss:0.3696, loss-lb:0.1942, loss-ulb:0.0877, weight:2.00, lr:0.0001
[07:04:57.315] iteration:14151  t-loss:0.1762, loss-lb:0.1444, loss-ulb:0.0159, weight:2.00, lr:0.0001
[07:04:57.653] iteration:14152  t-loss:0.2886, loss-lb:0.1867, loss-ulb:0.0509, weight:2.00, lr:0.0001
[07:04:57.973] iteration:14153  t-loss:0.3298, loss-lb:0.1103, loss-ulb:0.1097, weight:2.00, lr:0.0001
[07:04:58.289] iteration:14154  t-loss:0.2959, loss-lb:0.2696, loss-ulb:0.0131, weight:2.00, lr:0.0001
[07:04:58.609] iteration:14155  t-loss:0.6169, loss-lb:0.2016, loss-ulb:0.2077, weight:2.00, lr:0.0001
[07:04:58.927] iteration:14156  t-loss:0.3315, loss-lb:0.1506, loss-ulb:0.0904, weight:2.00, lr:0.0001
[07:04:59.244] iteration:14157  t-loss:0.2232, loss-lb:0.1806, loss-ulb:0.0213, weight:2.00, lr:0.0001
[07:04:59.560] iteration:14158  t-loss:0.2140, loss-lb:0.1783, loss-ulb:0.0179, weight:2.00, lr:0.0001
[07:04:59.878] iteration:14159  t-loss:0.2908, loss-lb:0.2426, loss-ulb:0.0241, weight:2.00, lr:0.0001
[07:05:00.196] iteration:14160  t-loss:0.3244, loss-lb:0.1919, loss-ulb:0.0662, weight:2.00, lr:0.0001
[07:05:00.512] iteration:14161  t-loss:0.2214, loss-lb:0.1738, loss-ulb:0.0238, weight:2.00, lr:0.0001
[07:05:00.831] iteration:14162  t-loss:0.5404, loss-lb:0.2277, loss-ulb:0.1564, weight:2.00, lr:0.0001
[07:05:01.151] iteration:14163  t-loss:0.3040, loss-lb:0.1799, loss-ulb:0.0620, weight:2.00, lr:0.0001
[07:05:01.472] iteration:14164  t-loss:0.3040, loss-lb:0.2299, loss-ulb:0.0370, weight:2.00, lr:0.0001
[07:05:01.792] iteration:14165  t-loss:0.2283, loss-lb:0.1551, loss-ulb:0.0366, weight:2.00, lr:0.0001
[07:05:02.110] iteration:14166  t-loss:0.3730, loss-lb:0.2203, loss-ulb:0.0763, weight:2.00, lr:0.0001
[07:05:02.426] iteration:14167  t-loss:0.2407, loss-lb:0.2054, loss-ulb:0.0177, weight:2.00, lr:0.0001
[07:05:02.743] iteration:14168  t-loss:0.2736, loss-lb:0.1673, loss-ulb:0.0532, weight:2.00, lr:0.0001
[07:05:03.057] iteration:14169  t-loss:0.1396, loss-lb:0.1175, loss-ulb:0.0110, weight:2.00, lr:0.0001
[07:05:03.374] iteration:14170  t-loss:0.2261, loss-lb:0.1985, loss-ulb:0.0138, weight:2.00, lr:0.0001
[07:05:03.691] iteration:14171  t-loss:0.3018, loss-lb:0.1688, loss-ulb:0.0665, weight:2.00, lr:0.0001
[07:05:04.007] iteration:14172  t-loss:0.2433, loss-lb:0.1897, loss-ulb:0.0268, weight:2.00, lr:0.0001
[07:05:04.326] iteration:14173  t-loss:0.2280, loss-lb:0.1281, loss-ulb:0.0500, weight:2.00, lr:0.0001
[07:05:04.638] iteration:14174  t-loss:0.2160, loss-lb:0.1728, loss-ulb:0.0216, weight:2.00, lr:0.0001
[07:05:04.955] iteration:14175  t-loss:0.3956, loss-lb:0.2843, loss-ulb:0.0557, weight:2.00, lr:0.0001
[07:05:06.123] iteration:14176  t-loss:0.2904, loss-lb:0.1627, loss-ulb:0.0639, weight:2.00, lr:0.0001
[07:05:06.454] iteration:14177  t-loss:0.2517, loss-lb:0.1424, loss-ulb:0.0546, weight:2.00, lr:0.0001
[07:05:06.776] iteration:14178  t-loss:0.4217, loss-lb:0.2237, loss-ulb:0.0990, weight:2.00, lr:0.0001
[07:05:07.094] iteration:14179  t-loss:0.3780, loss-lb:0.1655, loss-ulb:0.1062, weight:2.00, lr:0.0001
[07:05:07.415] iteration:14180  t-loss:0.1725, loss-lb:0.1334, loss-ulb:0.0195, weight:2.00, lr:0.0001
[07:05:07.734] iteration:14181  t-loss:0.3174, loss-lb:0.1931, loss-ulb:0.0621, weight:2.00, lr:0.0001
[07:05:08.052] iteration:14182  t-loss:0.2126, loss-lb:0.1801, loss-ulb:0.0163, weight:2.00, lr:0.0001
[07:05:08.366] iteration:14183  t-loss:0.1604, loss-lb:0.1366, loss-ulb:0.0119, weight:2.00, lr:0.0001
[07:05:08.684] iteration:14184  t-loss:0.2998, loss-lb:0.1660, loss-ulb:0.0669, weight:2.00, lr:0.0001
[07:05:09.002] iteration:14185  t-loss:0.4150, loss-lb:0.1366, loss-ulb:0.1392, weight:2.00, lr:0.0001
[07:05:09.316] iteration:14186  t-loss:0.2156, loss-lb:0.1663, loss-ulb:0.0247, weight:2.00, lr:0.0001
[07:05:09.633] iteration:14187  t-loss:0.3226, loss-lb:0.2534, loss-ulb:0.0346, weight:2.00, lr:0.0001
[07:05:09.950] iteration:14188  t-loss:0.2333, loss-lb:0.2109, loss-ulb:0.0112, weight:2.00, lr:0.0001
[07:05:10.267] iteration:14189  t-loss:0.2221, loss-lb:0.1965, loss-ulb:0.0128, weight:2.00, lr:0.0001
[07:05:10.587] iteration:14190  t-loss:0.4430, loss-lb:0.2274, loss-ulb:0.1078, weight:2.00, lr:0.0001
[07:05:10.906] iteration:14191  t-loss:0.2704, loss-lb:0.2341, loss-ulb:0.0182, weight:2.00, lr:0.0001
[07:05:11.227] iteration:14192  t-loss:0.3065, loss-lb:0.1756, loss-ulb:0.0654, weight:2.00, lr:0.0001
[07:05:11.539] iteration:14193  t-loss:0.1802, loss-lb:0.1532, loss-ulb:0.0135, weight:2.00, lr:0.0001
[07:05:11.854] iteration:14194  t-loss:0.1367, loss-lb:0.1043, loss-ulb:0.0162, weight:2.00, lr:0.0001
[07:05:12.171] iteration:14195  t-loss:0.3060, loss-lb:0.2242, loss-ulb:0.0409, weight:2.00, lr:0.0001
[07:05:12.485] iteration:14196  t-loss:0.2184, loss-lb:0.1475, loss-ulb:0.0355, weight:2.00, lr:0.0001
[07:05:12.800] iteration:14197  t-loss:0.2642, loss-lb:0.1398, loss-ulb:0.0622, weight:2.00, lr:0.0001
[07:05:13.113] iteration:14198  t-loss:0.2548, loss-lb:0.2273, loss-ulb:0.0137, weight:2.00, lr:0.0001
[07:05:13.428] iteration:14199  t-loss:0.2276, loss-lb:0.2030, loss-ulb:0.0123, weight:2.00, lr:0.0001
[07:05:13.744] iteration:14200  t-loss:0.2279, loss-lb:0.1757, loss-ulb:0.0261, weight:2.00, lr:0.0001
[07:05:15.051] iteration:14201  t-loss:0.2732, loss-lb:0.1633, loss-ulb:0.0549, weight:2.00, lr:0.0001
[07:05:15.377] iteration:14202  t-loss:0.2833, loss-lb:0.1295, loss-ulb:0.0769, weight:2.00, lr:0.0001
[07:05:15.695] iteration:14203  t-loss:0.2540, loss-lb:0.1116, loss-ulb:0.0712, weight:2.00, lr:0.0001
[07:05:16.013] iteration:14204  t-loss:0.3255, loss-lb:0.2058, loss-ulb:0.0598, weight:2.00, lr:0.0001
[07:05:16.330] iteration:14205  t-loss:0.1873, loss-lb:0.1488, loss-ulb:0.0192, weight:2.00, lr:0.0001
[07:05:16.646] iteration:14206  t-loss:0.2307, loss-lb:0.2093, loss-ulb:0.0107, weight:2.00, lr:0.0001
[07:05:16.961] iteration:14207  t-loss:0.3104, loss-lb:0.1473, loss-ulb:0.0815, weight:2.00, lr:0.0001
[07:05:17.278] iteration:14208  t-loss:0.4321, loss-lb:0.2805, loss-ulb:0.0758, weight:2.00, lr:0.0001
[07:05:17.592] iteration:14209  t-loss:0.1712, loss-lb:0.1420, loss-ulb:0.0146, weight:2.00, lr:0.0001
[07:05:17.909] iteration:14210  t-loss:0.1962, loss-lb:0.1646, loss-ulb:0.0158, weight:2.00, lr:0.0001
[07:05:18.221] iteration:14211  t-loss:0.2496, loss-lb:0.2157, loss-ulb:0.0169, weight:2.00, lr:0.0001
[07:05:18.537] iteration:14212  t-loss:0.1540, loss-lb:0.1333, loss-ulb:0.0104, weight:2.00, lr:0.0001
[07:05:18.851] iteration:14213  t-loss:0.3791, loss-lb:0.1893, loss-ulb:0.0949, weight:2.00, lr:0.0001
[07:05:19.165] iteration:14214  t-loss:0.2065, loss-lb:0.1346, loss-ulb:0.0359, weight:2.00, lr:0.0001
[07:05:19.482] iteration:14215  t-loss:0.2631, loss-lb:0.1407, loss-ulb:0.0612, weight:2.00, lr:0.0001
[07:05:19.798] iteration:14216  t-loss:0.2365, loss-lb:0.1343, loss-ulb:0.0511, weight:2.00, lr:0.0001
[07:05:20.128] iteration:14217  t-loss:0.3446, loss-lb:0.2161, loss-ulb:0.0643, weight:2.00, lr:0.0001
[07:05:20.443] iteration:14218  t-loss:0.1901, loss-lb:0.1440, loss-ulb:0.0231, weight:2.00, lr:0.0001
[07:05:20.759] iteration:14219  t-loss:0.2738, loss-lb:0.1901, loss-ulb:0.0419, weight:2.00, lr:0.0001
[07:05:21.073] iteration:14220  t-loss:0.2583, loss-lb:0.1498, loss-ulb:0.0543, weight:2.00, lr:0.0001
[07:05:21.388] iteration:14221  t-loss:0.2462, loss-lb:0.1576, loss-ulb:0.0443, weight:2.00, lr:0.0001
[07:05:21.703] iteration:14222  t-loss:0.2895, loss-lb:0.1418, loss-ulb:0.0738, weight:2.00, lr:0.0001
[07:05:22.016] iteration:14223  t-loss:0.1405, loss-lb:0.1136, loss-ulb:0.0135, weight:2.00, lr:0.0001
[07:05:22.331] iteration:14224  t-loss:0.2116, loss-lb:0.1449, loss-ulb:0.0334, weight:2.00, lr:0.0001
[07:05:22.647] iteration:14225  t-loss:0.2945, loss-lb:0.1403, loss-ulb:0.0771, weight:2.00, lr:0.0001
[07:07:12.389] iteration 14225 : dice_score: 0.850823 best_dice: 0.854000
[07:07:12.389]  <<Test>> - Ep:568  - Dice-S/T:85.06/85.08, Best-S:85.59, Best-T:85.40
[07:07:12.389]           - AvgLoss(lb/ulb/all):0.16/0.04/0.25
[07:07:13.564] iteration:14226  t-loss:0.4345, loss-lb:0.1917, loss-ulb:0.1214, weight:2.00, lr:0.0001
[07:07:13.909] iteration:14227  t-loss:0.3140, loss-lb:0.1644, loss-ulb:0.0748, weight:2.00, lr:0.0001
[07:07:14.240] iteration:14228  t-loss:0.2901, loss-lb:0.1636, loss-ulb:0.0633, weight:2.00, lr:0.0001
[07:07:14.562] iteration:14229  t-loss:0.2082, loss-lb:0.1484, loss-ulb:0.0299, weight:2.00, lr:0.0001
[07:07:14.885] iteration:14230  t-loss:0.4694, loss-lb:0.2386, loss-ulb:0.1154, weight:2.00, lr:0.0001
[07:07:15.207] iteration:14231  t-loss:0.3504, loss-lb:0.2469, loss-ulb:0.0517, weight:2.00, lr:0.0001
[07:07:15.524] iteration:14232  t-loss:0.3495, loss-lb:0.1600, loss-ulb:0.0947, weight:2.00, lr:0.0001
[07:07:15.842] iteration:14233  t-loss:0.1913, loss-lb:0.1498, loss-ulb:0.0207, weight:2.00, lr:0.0001
[07:07:16.165] iteration:14234  t-loss:0.3431, loss-lb:0.1917, loss-ulb:0.0757, weight:2.00, lr:0.0001
[07:07:16.483] iteration:14235  t-loss:0.2987, loss-lb:0.1458, loss-ulb:0.0765, weight:2.00, lr:0.0001
[07:07:16.801] iteration:14236  t-loss:0.2704, loss-lb:0.2148, loss-ulb:0.0278, weight:2.00, lr:0.0001
[07:07:17.119] iteration:14237  t-loss:0.3058, loss-lb:0.1470, loss-ulb:0.0794, weight:2.00, lr:0.0001
[07:07:17.442] iteration:14238  t-loss:0.2485, loss-lb:0.1274, loss-ulb:0.0606, weight:2.00, lr:0.0001
[07:07:17.762] iteration:14239  t-loss:0.3296, loss-lb:0.2807, loss-ulb:0.0245, weight:2.00, lr:0.0001
[07:07:18.080] iteration:14240  t-loss:0.2145, loss-lb:0.1595, loss-ulb:0.0275, weight:2.00, lr:0.0001
[07:07:18.404] iteration:14241  t-loss:0.3489, loss-lb:0.2286, loss-ulb:0.0601, weight:2.00, lr:0.0001
[07:07:18.726] iteration:14242  t-loss:0.4326, loss-lb:0.1514, loss-ulb:0.1406, weight:2.00, lr:0.0001
[07:07:19.039] iteration:14243  t-loss:0.1375, loss-lb:0.1111, loss-ulb:0.0132, weight:2.00, lr:0.0001
[07:07:19.355] iteration:14244  t-loss:0.2069, loss-lb:0.1283, loss-ulb:0.0393, weight:2.00, lr:0.0001
[07:07:19.668] iteration:14245  t-loss:0.2623, loss-lb:0.1697, loss-ulb:0.0463, weight:2.00, lr:0.0001
[07:07:19.983] iteration:14246  t-loss:0.2272, loss-lb:0.1697, loss-ulb:0.0287, weight:2.00, lr:0.0001
[07:07:20.298] iteration:14247  t-loss:0.1852, loss-lb:0.1554, loss-ulb:0.0149, weight:2.00, lr:0.0001
[07:07:20.613] iteration:14248  t-loss:0.2134, loss-lb:0.1902, loss-ulb:0.0116, weight:2.00, lr:0.0001
[07:07:20.931] iteration:14249  t-loss:0.2635, loss-lb:0.2028, loss-ulb:0.0304, weight:2.00, lr:0.0001
[07:07:21.244] iteration:14250  t-loss:0.1720, loss-lb:0.1316, loss-ulb:0.0202, weight:2.00, lr:0.0001
[07:07:22.626] iteration:14251  t-loss:0.8934, loss-lb:0.1192, loss-ulb:0.3871, weight:2.00, lr:0.0001
[07:07:22.953] iteration:14252  t-loss:0.2129, loss-lb:0.1679, loss-ulb:0.0225, weight:2.00, lr:0.0001
[07:07:23.269] iteration:14253  t-loss:0.2471, loss-lb:0.1676, loss-ulb:0.0397, weight:2.00, lr:0.0001
[07:07:23.585] iteration:14254  t-loss:0.2397, loss-lb:0.1368, loss-ulb:0.0514, weight:2.00, lr:0.0001
[07:07:23.902] iteration:14255  t-loss:0.2077, loss-lb:0.1786, loss-ulb:0.0145, weight:2.00, lr:0.0001
[07:07:24.222] iteration:14256  t-loss:0.3025, loss-lb:0.1720, loss-ulb:0.0653, weight:2.00, lr:0.0001
[07:07:24.541] iteration:14257  t-loss:0.2903, loss-lb:0.1521, loss-ulb:0.0691, weight:2.00, lr:0.0001
[07:07:24.859] iteration:14258  t-loss:0.1771, loss-lb:0.1366, loss-ulb:0.0203, weight:2.00, lr:0.0001
[07:07:25.176] iteration:14259  t-loss:0.2586, loss-lb:0.1563, loss-ulb:0.0511, weight:2.00, lr:0.0001
[07:07:25.491] iteration:14260  t-loss:0.5140, loss-lb:0.1580, loss-ulb:0.1780, weight:2.00, lr:0.0001
[07:07:25.806] iteration:14261  t-loss:0.3387, loss-lb:0.1246, loss-ulb:0.1070, weight:2.00, lr:0.0001
[07:07:26.119] iteration:14262  t-loss:0.4117, loss-lb:0.2772, loss-ulb:0.0673, weight:2.00, lr:0.0001
[07:07:26.435] iteration:14263  t-loss:0.3134, loss-lb:0.2746, loss-ulb:0.0194, weight:2.00, lr:0.0001
[07:07:26.750] iteration:14264  t-loss:0.3978, loss-lb:0.2456, loss-ulb:0.0761, weight:2.00, lr:0.0001
[07:07:27.064] iteration:14265  t-loss:0.2426, loss-lb:0.1533, loss-ulb:0.0446, weight:2.00, lr:0.0001
[07:07:27.384] iteration:14266  t-loss:0.2730, loss-lb:0.1814, loss-ulb:0.0458, weight:2.00, lr:0.0001
[07:07:27.701] iteration:14267  t-loss:0.7776, loss-lb:0.2038, loss-ulb:0.2869, weight:2.00, lr:0.0001
[07:07:28.017] iteration:14268  t-loss:0.4124, loss-lb:0.1988, loss-ulb:0.1068, weight:2.00, lr:0.0001
[07:07:28.330] iteration:14269  t-loss:0.2210, loss-lb:0.1946, loss-ulb:0.0132, weight:2.00, lr:0.0001
[07:07:28.645] iteration:14270  t-loss:0.3633, loss-lb:0.1694, loss-ulb:0.0970, weight:2.00, lr:0.0001
[07:07:28.959] iteration:14271  t-loss:0.1952, loss-lb:0.1590, loss-ulb:0.0181, weight:2.00, lr:0.0001
[07:07:29.271] iteration:14272  t-loss:0.2135, loss-lb:0.1199, loss-ulb:0.0468, weight:2.00, lr:0.0001
[07:07:29.587] iteration:14273  t-loss:0.2816, loss-lb:0.1593, loss-ulb:0.0611, weight:2.00, lr:0.0001
[07:07:29.899] iteration:14274  t-loss:0.1672, loss-lb:0.1411, loss-ulb:0.0130, weight:2.00, lr:0.0001
[07:07:30.212] iteration:14275  t-loss:0.2195, loss-lb:0.1885, loss-ulb:0.0155, weight:2.00, lr:0.0001
[07:07:31.391] iteration:14276  t-loss:0.3231, loss-lb:0.1764, loss-ulb:0.0733, weight:2.00, lr:0.0001
[07:07:31.724] iteration:14277  t-loss:0.2710, loss-lb:0.1225, loss-ulb:0.0743, weight:2.00, lr:0.0001
[07:07:32.052] iteration:14278  t-loss:0.2775, loss-lb:0.2529, loss-ulb:0.0123, weight:2.00, lr:0.0001
[07:07:32.376] iteration:14279  t-loss:0.3163, loss-lb:0.1698, loss-ulb:0.0732, weight:2.00, lr:0.0001
[07:07:32.696] iteration:14280  t-loss:0.2836, loss-lb:0.1267, loss-ulb:0.0784, weight:2.00, lr:0.0001
[07:07:33.017] iteration:14281  t-loss:0.5089, loss-lb:0.2372, loss-ulb:0.1358, weight:2.00, lr:0.0001
[07:07:33.335] iteration:14282  t-loss:0.2146, loss-lb:0.1322, loss-ulb:0.0412, weight:2.00, lr:0.0001
[07:07:33.651] iteration:14283  t-loss:0.2082, loss-lb:0.1803, loss-ulb:0.0140, weight:2.00, lr:0.0001
[07:07:33.971] iteration:14284  t-loss:0.3918, loss-lb:0.1731, loss-ulb:0.1094, weight:2.00, lr:0.0001
[07:07:34.286] iteration:14285  t-loss:0.1388, loss-lb:0.0936, loss-ulb:0.0226, weight:2.00, lr:0.0001
[07:07:34.609] iteration:14286  t-loss:0.2952, loss-lb:0.1767, loss-ulb:0.0593, weight:2.00, lr:0.0001
[07:07:34.923] iteration:14287  t-loss:0.2653, loss-lb:0.1704, loss-ulb:0.0475, weight:2.00, lr:0.0001
[07:07:35.243] iteration:14288  t-loss:0.3463, loss-lb:0.1050, loss-ulb:0.1207, weight:2.00, lr:0.0001
[07:07:35.563] iteration:14289  t-loss:0.1984, loss-lb:0.1753, loss-ulb:0.0115, weight:2.00, lr:0.0001
[07:07:35.894] iteration:14290  t-loss:0.2469, loss-lb:0.1237, loss-ulb:0.0616, weight:2.00, lr:0.0001
[07:07:36.217] iteration:14291  t-loss:0.2473, loss-lb:0.2053, loss-ulb:0.0210, weight:2.00, lr:0.0001
[07:07:36.537] iteration:14292  t-loss:0.1986, loss-lb:0.1750, loss-ulb:0.0118, weight:2.00, lr:0.0001
[07:07:36.856] iteration:14293  t-loss:0.2095, loss-lb:0.1272, loss-ulb:0.0411, weight:2.00, lr:0.0001
[07:07:37.174] iteration:14294  t-loss:0.4892, loss-lb:0.3232, loss-ulb:0.0830, weight:2.00, lr:0.0001
[07:07:37.492] iteration:14295  t-loss:0.4070, loss-lb:0.1260, loss-ulb:0.1405, weight:2.00, lr:0.0001
[07:07:37.807] iteration:14296  t-loss:0.3558, loss-lb:0.1943, loss-ulb:0.0807, weight:2.00, lr:0.0001
[07:07:38.124] iteration:14297  t-loss:0.2952, loss-lb:0.1427, loss-ulb:0.0763, weight:2.00, lr:0.0001
[07:07:38.438] iteration:14298  t-loss:0.2639, loss-lb:0.1516, loss-ulb:0.0561, weight:2.00, lr:0.0001
[07:07:38.751] iteration:14299  t-loss:0.2085, loss-lb:0.1700, loss-ulb:0.0193, weight:2.00, lr:0.0001
[07:07:39.064] iteration:14300  t-loss:0.2407, loss-lb:0.1388, loss-ulb:0.0510, weight:2.00, lr:0.0001
[07:07:40.215] iteration:14301  t-loss:0.2569, loss-lb:0.1449, loss-ulb:0.0560, weight:2.00, lr:0.0001
[07:07:40.552] iteration:14302  t-loss:0.1834, loss-lb:0.1561, loss-ulb:0.0136, weight:2.00, lr:0.0001
[07:07:40.890] iteration:14303  t-loss:0.3103, loss-lb:0.2794, loss-ulb:0.0154, weight:2.00, lr:0.0001
[07:07:41.242] iteration:14304  t-loss:0.3073, loss-lb:0.2177, loss-ulb:0.0448, weight:2.00, lr:0.0001
[07:07:41.584] iteration:14305  t-loss:0.1713, loss-lb:0.1396, loss-ulb:0.0159, weight:2.00, lr:0.0001
[07:07:41.914] iteration:14306  t-loss:0.3991, loss-lb:0.2588, loss-ulb:0.0702, weight:2.00, lr:0.0001
[07:07:42.234] iteration:14307  t-loss:0.2080, loss-lb:0.1850, loss-ulb:0.0115, weight:2.00, lr:0.0001
[07:07:42.560] iteration:14308  t-loss:0.3547, loss-lb:0.2315, loss-ulb:0.0616, weight:2.00, lr:0.0001
[07:07:42.889] iteration:14309  t-loss:0.2473, loss-lb:0.1462, loss-ulb:0.0506, weight:2.00, lr:0.0001
[07:07:43.208] iteration:14310  t-loss:0.3782, loss-lb:0.1179, loss-ulb:0.1302, weight:2.00, lr:0.0001
[07:07:43.528] iteration:14311  t-loss:0.2394, loss-lb:0.2005, loss-ulb:0.0195, weight:2.00, lr:0.0001
[07:07:43.843] iteration:14312  t-loss:0.2329, loss-lb:0.1905, loss-ulb:0.0212, weight:2.00, lr:0.0001
[07:07:44.158] iteration:14313  t-loss:0.3630, loss-lb:0.1454, loss-ulb:0.1088, weight:2.00, lr:0.0001
[07:07:44.473] iteration:14314  t-loss:0.1400, loss-lb:0.1037, loss-ulb:0.0182, weight:2.00, lr:0.0001
[07:07:44.787] iteration:14315  t-loss:0.3055, loss-lb:0.2623, loss-ulb:0.0216, weight:2.00, lr:0.0001
[07:07:45.101] iteration:14316  t-loss:0.2940, loss-lb:0.1459, loss-ulb:0.0741, weight:2.00, lr:0.0001
[07:07:45.416] iteration:14317  t-loss:0.3278, loss-lb:0.1601, loss-ulb:0.0838, weight:2.00, lr:0.0001
[07:07:45.729] iteration:14318  t-loss:0.3367, loss-lb:0.1047, loss-ulb:0.1160, weight:2.00, lr:0.0001
[07:07:46.042] iteration:14319  t-loss:0.2916, loss-lb:0.1651, loss-ulb:0.0633, weight:2.00, lr:0.0001
[07:07:46.356] iteration:14320  t-loss:0.3708, loss-lb:0.2386, loss-ulb:0.0661, weight:2.00, lr:0.0001
[07:07:46.670] iteration:14321  t-loss:0.5284, loss-lb:0.2293, loss-ulb:0.1496, weight:2.00, lr:0.0001
[07:07:46.983] iteration:14322  t-loss:0.3069, loss-lb:0.1220, loss-ulb:0.0925, weight:2.00, lr:0.0001
[07:07:47.297] iteration:14323  t-loss:0.3012, loss-lb:0.2516, loss-ulb:0.0248, weight:2.00, lr:0.0001
[07:07:47.608] iteration:14324  t-loss:0.1849, loss-lb:0.1574, loss-ulb:0.0138, weight:2.00, lr:0.0001
[07:07:47.923] iteration:14325  t-loss:0.4635, loss-lb:0.2173, loss-ulb:0.1231, weight:2.00, lr:0.0001
[07:09:37.734] iteration 14325 : dice_score: 0.850399 best_dice: 0.854000
[07:09:37.734]  <<Test>> - Ep:572  - Dice-S/T:84.94/85.04, Best-S:85.59, Best-T:85.40
[07:09:37.734]           - AvgLoss(lb/ulb/all):0.18/0.07/0.31
[07:09:39.236] iteration:14326  t-loss:0.3176, loss-lb:0.1178, loss-ulb:0.0999, weight:2.00, lr:0.0001
[07:09:39.565] iteration:14327  t-loss:0.2617, loss-lb:0.1547, loss-ulb:0.0535, weight:2.00, lr:0.0001
[07:09:39.908] iteration:14328  t-loss:0.3771, loss-lb:0.2142, loss-ulb:0.0814, weight:2.00, lr:0.0001
[07:09:40.239] iteration:14329  t-loss:0.2610, loss-lb:0.1317, loss-ulb:0.0647, weight:2.00, lr:0.0001
[07:09:40.558] iteration:14330  t-loss:0.1792, loss-lb:0.1466, loss-ulb:0.0163, weight:2.00, lr:0.0001
[07:09:40.879] iteration:14331  t-loss:0.2854, loss-lb:0.2198, loss-ulb:0.0328, weight:2.00, lr:0.0001
[07:09:41.195] iteration:14332  t-loss:0.3113, loss-lb:0.1804, loss-ulb:0.0654, weight:2.00, lr:0.0001
[07:09:41.507] iteration:14333  t-loss:0.1864, loss-lb:0.1136, loss-ulb:0.0364, weight:2.00, lr:0.0001
[07:09:41.822] iteration:14334  t-loss:0.3777, loss-lb:0.1468, loss-ulb:0.1154, weight:2.00, lr:0.0001
[07:09:42.135] iteration:14335  t-loss:0.1836, loss-lb:0.1547, loss-ulb:0.0145, weight:2.00, lr:0.0001
[07:09:42.450] iteration:14336  t-loss:0.2204, loss-lb:0.1749, loss-ulb:0.0227, weight:2.00, lr:0.0001
[07:09:42.771] iteration:14337  t-loss:0.2528, loss-lb:0.1773, loss-ulb:0.0377, weight:2.00, lr:0.0001
[07:09:43.084] iteration:14338  t-loss:0.3212, loss-lb:0.1532, loss-ulb:0.0840, weight:2.00, lr:0.0001
[07:09:43.398] iteration:14339  t-loss:0.3367, loss-lb:0.1568, loss-ulb:0.0899, weight:2.00, lr:0.0001
[07:09:43.714] iteration:14340  t-loss:0.3974, loss-lb:0.1886, loss-ulb:0.1044, weight:2.00, lr:0.0001
[07:09:44.027] iteration:14341  t-loss:0.2857, loss-lb:0.2283, loss-ulb:0.0287, weight:2.00, lr:0.0001
[07:09:44.350] iteration:14342  t-loss:0.2417, loss-lb:0.1410, loss-ulb:0.0504, weight:2.00, lr:0.0001
[07:09:44.672] iteration:14343  t-loss:0.3041, loss-lb:0.1647, loss-ulb:0.0697, weight:2.00, lr:0.0001
[07:09:44.993] iteration:14344  t-loss:0.2224, loss-lb:0.1169, loss-ulb:0.0527, weight:2.00, lr:0.0001
[07:09:45.318] iteration:14345  t-loss:0.3057, loss-lb:0.2684, loss-ulb:0.0186, weight:2.00, lr:0.0001
[07:09:45.639] iteration:14346  t-loss:0.7360, loss-lb:0.1567, loss-ulb:0.2896, weight:2.00, lr:0.0001
[07:09:45.960] iteration:14347  t-loss:0.2222, loss-lb:0.1637, loss-ulb:0.0293, weight:2.00, lr:0.0001
[07:09:46.277] iteration:14348  t-loss:0.2362, loss-lb:0.1525, loss-ulb:0.0418, weight:2.00, lr:0.0001
[07:09:46.591] iteration:14349  t-loss:0.2614, loss-lb:0.1574, loss-ulb:0.0520, weight:2.00, lr:0.0001
[07:09:46.904] iteration:14350  t-loss:0.1484, loss-lb:0.1254, loss-ulb:0.0115, weight:2.00, lr:0.0001
[07:09:48.070] iteration:14351  t-loss:0.2642, loss-lb:0.1378, loss-ulb:0.0632, weight:2.00, lr:0.0001
[07:09:48.400] iteration:14352  t-loss:0.2231, loss-lb:0.1157, loss-ulb:0.0537, weight:2.00, lr:0.0001
[07:09:48.728] iteration:14353  t-loss:0.2129, loss-lb:0.1760, loss-ulb:0.0185, weight:2.00, lr:0.0001
[07:09:49.050] iteration:14354  t-loss:0.3412, loss-lb:0.1356, loss-ulb:0.1028, weight:2.00, lr:0.0001
[07:09:49.383] iteration:14355  t-loss:0.4855, loss-lb:0.2168, loss-ulb:0.1344, weight:2.00, lr:0.0001
[07:09:49.707] iteration:14356  t-loss:0.3278, loss-lb:0.1545, loss-ulb:0.0867, weight:2.00, lr:0.0001
[07:09:50.027] iteration:14357  t-loss:0.1966, loss-lb:0.1513, loss-ulb:0.0227, weight:2.00, lr:0.0001
[07:09:50.344] iteration:14358  t-loss:0.2585, loss-lb:0.2214, loss-ulb:0.0186, weight:2.00, lr:0.0001
[07:09:50.664] iteration:14359  t-loss:0.3769, loss-lb:0.2550, loss-ulb:0.0609, weight:2.00, lr:0.0001
[07:09:50.981] iteration:14360  t-loss:0.3857, loss-lb:0.1599, loss-ulb:0.1129, weight:2.00, lr:0.0001
[07:09:51.298] iteration:14361  t-loss:0.3879, loss-lb:0.2923, loss-ulb:0.0478, weight:2.00, lr:0.0001
[07:09:51.617] iteration:14362  t-loss:0.3198, loss-lb:0.1529, loss-ulb:0.0834, weight:2.00, lr:0.0001
[07:09:51.930] iteration:14363  t-loss:0.1824, loss-lb:0.1403, loss-ulb:0.0211, weight:2.00, lr:0.0001
[07:09:52.245] iteration:14364  t-loss:0.2484, loss-lb:0.1806, loss-ulb:0.0339, weight:2.00, lr:0.0001
[07:09:52.559] iteration:14365  t-loss:0.2018, loss-lb:0.1515, loss-ulb:0.0252, weight:2.00, lr:0.0001
[07:09:52.874] iteration:14366  t-loss:0.3014, loss-lb:0.1635, loss-ulb:0.0689, weight:2.00, lr:0.0001
[07:09:53.187] iteration:14367  t-loss:0.3095, loss-lb:0.1432, loss-ulb:0.0831, weight:2.00, lr:0.0001
[07:09:53.501] iteration:14368  t-loss:0.4208, loss-lb:0.1707, loss-ulb:0.1250, weight:2.00, lr:0.0001
[07:09:53.815] iteration:14369  t-loss:0.4713, loss-lb:0.2685, loss-ulb:0.1014, weight:2.00, lr:0.0001
[07:09:54.129] iteration:14370  t-loss:0.3349, loss-lb:0.2297, loss-ulb:0.0526, weight:2.00, lr:0.0001
[07:09:54.441] iteration:14371  t-loss:0.3290, loss-lb:0.2076, loss-ulb:0.0607, weight:2.00, lr:0.0001
[07:09:54.757] iteration:14372  t-loss:0.3248, loss-lb:0.1737, loss-ulb:0.0756, weight:2.00, lr:0.0001
[07:09:55.075] iteration:14373  t-loss:0.3025, loss-lb:0.1584, loss-ulb:0.0721, weight:2.00, lr:0.0001
[07:09:55.388] iteration:14374  t-loss:0.1656, loss-lb:0.1405, loss-ulb:0.0126, weight:2.00, lr:0.0001
[07:09:55.701] iteration:14375  t-loss:0.1726, loss-lb:0.1414, loss-ulb:0.0156, weight:2.00, lr:0.0001
[07:09:56.940] iteration:14376  t-loss:0.1911, loss-lb:0.1157, loss-ulb:0.0377, weight:2.00, lr:0.0001
[07:09:57.262] iteration:14377  t-loss:0.3528, loss-lb:0.2448, loss-ulb:0.0540, weight:2.00, lr:0.0001
[07:09:57.582] iteration:14378  t-loss:0.2031, loss-lb:0.1717, loss-ulb:0.0157, weight:2.00, lr:0.0001
[07:09:57.897] iteration:14379  t-loss:0.2523, loss-lb:0.1833, loss-ulb:0.0345, weight:2.00, lr:0.0001
[07:09:58.213] iteration:14380  t-loss:0.3177, loss-lb:0.1561, loss-ulb:0.0808, weight:2.00, lr:0.0001
[07:09:58.528] iteration:14381  t-loss:0.3174, loss-lb:0.1911, loss-ulb:0.0631, weight:2.00, lr:0.0001
[07:09:58.846] iteration:14382  t-loss:0.3828, loss-lb:0.2161, loss-ulb:0.0834, weight:2.00, lr:0.0001
[07:09:59.161] iteration:14383  t-loss:0.3452, loss-lb:0.1836, loss-ulb:0.0808, weight:2.00, lr:0.0001
[07:09:59.480] iteration:14384  t-loss:0.2666, loss-lb:0.1558, loss-ulb:0.0554, weight:2.00, lr:0.0001
[07:09:59.808] iteration:14385  t-loss:0.2996, loss-lb:0.1544, loss-ulb:0.0726, weight:2.00, lr:0.0001
[07:10:00.122] iteration:14386  t-loss:0.2684, loss-lb:0.1281, loss-ulb:0.0701, weight:2.00, lr:0.0001
[07:10:00.437] iteration:14387  t-loss:0.2604, loss-lb:0.2348, loss-ulb:0.0128, weight:2.00, lr:0.0001
[07:10:00.753] iteration:14388  t-loss:0.1889, loss-lb:0.1589, loss-ulb:0.0150, weight:2.00, lr:0.0001
[07:10:01.069] iteration:14389  t-loss:0.2764, loss-lb:0.1752, loss-ulb:0.0506, weight:2.00, lr:0.0001
[07:10:01.384] iteration:14390  t-loss:0.2968, loss-lb:0.2611, loss-ulb:0.0178, weight:2.00, lr:0.0001
[07:10:01.700] iteration:14391  t-loss:0.1634, loss-lb:0.1357, loss-ulb:0.0139, weight:2.00, lr:0.0001
[07:10:02.021] iteration:14392  t-loss:0.2207, loss-lb:0.1118, loss-ulb:0.0544, weight:2.00, lr:0.0001
[07:10:02.339] iteration:14393  t-loss:0.1977, loss-lb:0.1439, loss-ulb:0.0269, weight:2.00, lr:0.0001
[07:10:02.661] iteration:14394  t-loss:0.4288, loss-lb:0.1932, loss-ulb:0.1178, weight:2.00, lr:0.0001
[07:10:02.987] iteration:14395  t-loss:0.7992, loss-lb:0.1867, loss-ulb:0.3062, weight:2.00, lr:0.0001
[07:10:03.304] iteration:14396  t-loss:0.3019, loss-lb:0.1464, loss-ulb:0.0778, weight:2.00, lr:0.0001
[07:10:03.623] iteration:14397  t-loss:0.3340, loss-lb:0.1994, loss-ulb:0.0673, weight:2.00, lr:0.0001
[07:10:03.938] iteration:14398  t-loss:0.3322, loss-lb:0.1558, loss-ulb:0.0882, weight:2.00, lr:0.0001
[07:10:04.258] iteration:14399  t-loss:0.3326, loss-lb:0.1430, loss-ulb:0.0948, weight:2.00, lr:0.0001
[07:10:04.573] iteration:14400  t-loss:0.2442, loss-lb:0.1469, loss-ulb:0.0487, weight:2.00, lr:0.0001
[07:10:05.826] iteration:14401  t-loss:0.3165, loss-lb:0.2356, loss-ulb:0.0404, weight:2.00, lr:0.0001
[07:10:06.163] iteration:14402  t-loss:0.3551, loss-lb:0.2873, loss-ulb:0.0339, weight:2.00, lr:0.0001
[07:10:06.492] iteration:14403  t-loss:0.2289, loss-lb:0.1268, loss-ulb:0.0511, weight:2.00, lr:0.0001
[07:10:06.810] iteration:14404  t-loss:0.3329, loss-lb:0.2019, loss-ulb:0.0655, weight:2.00, lr:0.0001
[07:10:07.127] iteration:14405  t-loss:0.1645, loss-lb:0.1322, loss-ulb:0.0161, weight:2.00, lr:0.0001
[07:10:07.443] iteration:14406  t-loss:0.2416, loss-lb:0.1348, loss-ulb:0.0534, weight:2.00, lr:0.0001
[07:10:07.761] iteration:14407  t-loss:0.3496, loss-lb:0.2012, loss-ulb:0.0742, weight:2.00, lr:0.0001
[07:10:08.080] iteration:14408  t-loss:0.2250, loss-lb:0.1845, loss-ulb:0.0202, weight:2.00, lr:0.0001
[07:10:08.403] iteration:14409  t-loss:0.3540, loss-lb:0.1310, loss-ulb:0.1115, weight:2.00, lr:0.0001
[07:10:08.725] iteration:14410  t-loss:0.2601, loss-lb:0.2318, loss-ulb:0.0142, weight:2.00, lr:0.0001
[07:10:09.042] iteration:14411  t-loss:0.2738, loss-lb:0.1797, loss-ulb:0.0470, weight:2.00, lr:0.0001
[07:10:09.359] iteration:14412  t-loss:0.2066, loss-lb:0.1732, loss-ulb:0.0167, weight:2.00, lr:0.0001
[07:10:09.679] iteration:14413  t-loss:0.3011, loss-lb:0.1741, loss-ulb:0.0635, weight:2.00, lr:0.0001
[07:10:09.993] iteration:14414  t-loss:0.2384, loss-lb:0.2134, loss-ulb:0.0125, weight:2.00, lr:0.0001
[07:10:10.312] iteration:14415  t-loss:0.2534, loss-lb:0.1302, loss-ulb:0.0616, weight:2.00, lr:0.0001
[07:10:10.625] iteration:14416  t-loss:0.2015, loss-lb:0.1623, loss-ulb:0.0196, weight:2.00, lr:0.0001
[07:10:10.943] iteration:14417  t-loss:0.4051, loss-lb:0.2316, loss-ulb:0.0868, weight:2.00, lr:0.0001
[07:10:11.258] iteration:14418  t-loss:0.2345, loss-lb:0.2115, loss-ulb:0.0115, weight:2.00, lr:0.0001
[07:10:11.573] iteration:14419  t-loss:0.2980, loss-lb:0.2542, loss-ulb:0.0219, weight:2.00, lr:0.0001
[07:10:11.886] iteration:14420  t-loss:0.1389, loss-lb:0.1039, loss-ulb:0.0175, weight:2.00, lr:0.0001
[07:10:12.200] iteration:14421  t-loss:0.3111, loss-lb:0.2591, loss-ulb:0.0260, weight:2.00, lr:0.0001
[07:10:12.513] iteration:14422  t-loss:0.2467, loss-lb:0.1574, loss-ulb:0.0447, weight:2.00, lr:0.0001
[07:10:12.826] iteration:14423  t-loss:0.2347, loss-lb:0.1002, loss-ulb:0.0672, weight:2.00, lr:0.0001
[07:10:13.138] iteration:14424  t-loss:0.1849, loss-lb:0.1285, loss-ulb:0.0282, weight:2.00, lr:0.0001
[07:10:13.452] iteration:14425  t-loss:0.2876, loss-lb:0.1575, loss-ulb:0.0650, weight:2.00, lr:0.0001
[07:12:05.478] iteration 14425 : dice_score: 0.849496 best_dice: 0.854000
[07:12:05.478]  <<Test>> - Ep:576  - Dice-S/T:84.93/84.95, Best-S:85.59, Best-T:85.40
[07:12:05.478]           - AvgLoss(lb/ulb/all):0.18/0.04/0.26
[07:12:06.685] iteration:14426  t-loss:0.3710, loss-lb:0.1947, loss-ulb:0.0881, weight:2.00, lr:0.0001
[07:12:07.008] iteration:14427  t-loss:0.2832, loss-lb:0.1455, loss-ulb:0.0689, weight:2.00, lr:0.0001
[07:12:07.329] iteration:14428  t-loss:0.1794, loss-lb:0.1523, loss-ulb:0.0135, weight:2.00, lr:0.0001
[07:12:07.651] iteration:14429  t-loss:0.6863, loss-lb:0.2549, loss-ulb:0.2157, weight:2.00, lr:0.0001
[07:12:07.991] iteration:14430  t-loss:0.4271, loss-lb:0.1845, loss-ulb:0.1213, weight:2.00, lr:0.0001
[07:12:08.312] iteration:14431  t-loss:0.3033, loss-lb:0.1522, loss-ulb:0.0756, weight:2.00, lr:0.0001
[07:12:08.633] iteration:14432  t-loss:0.2814, loss-lb:0.1802, loss-ulb:0.0506, weight:2.00, lr:0.0001
[07:12:08.951] iteration:14433  t-loss:0.3067, loss-lb:0.1703, loss-ulb:0.0682, weight:2.00, lr:0.0001
[07:12:09.271] iteration:14434  t-loss:0.3854, loss-lb:0.3161, loss-ulb:0.0346, weight:2.00, lr:0.0001
[07:12:09.588] iteration:14435  t-loss:0.3584, loss-lb:0.1933, loss-ulb:0.0825, weight:2.00, lr:0.0001
[07:12:09.906] iteration:14436  t-loss:0.2576, loss-lb:0.2275, loss-ulb:0.0150, weight:2.00, lr:0.0001
[07:12:10.220] iteration:14437  t-loss:0.1775, loss-lb:0.1461, loss-ulb:0.0157, weight:2.00, lr:0.0001
[07:12:10.538] iteration:14438  t-loss:0.3612, loss-lb:0.1434, loss-ulb:0.1089, weight:2.00, lr:0.0001
[07:12:10.853] iteration:14439  t-loss:0.2416, loss-lb:0.1588, loss-ulb:0.0414, weight:2.00, lr:0.0001
[07:12:11.171] iteration:14440  t-loss:0.2950, loss-lb:0.1402, loss-ulb:0.0774, weight:2.00, lr:0.0001
[07:12:11.487] iteration:14441  t-loss:0.2981, loss-lb:0.1359, loss-ulb:0.0811, weight:2.00, lr:0.0001
[07:12:11.808] iteration:14442  t-loss:0.3755, loss-lb:0.2269, loss-ulb:0.0743, weight:2.00, lr:0.0001
[07:12:12.121] iteration:14443  t-loss:0.2219, loss-lb:0.2005, loss-ulb:0.0107, weight:2.00, lr:0.0001
[07:12:12.436] iteration:14444  t-loss:0.1612, loss-lb:0.1222, loss-ulb:0.0195, weight:2.00, lr:0.0001
[07:12:12.750] iteration:14445  t-loss:0.1545, loss-lb:0.1147, loss-ulb:0.0199, weight:2.00, lr:0.0001
[07:12:13.067] iteration:14446  t-loss:0.2733, loss-lb:0.1236, loss-ulb:0.0748, weight:2.00, lr:0.0001
[07:12:13.381] iteration:14447  t-loss:0.2293, loss-lb:0.1763, loss-ulb:0.0265, weight:2.00, lr:0.0001
[07:12:13.697] iteration:14448  t-loss:0.3666, loss-lb:0.2300, loss-ulb:0.0683, weight:2.00, lr:0.0001
[07:12:14.011] iteration:14449  t-loss:0.3606, loss-lb:0.1778, loss-ulb:0.0914, weight:2.00, lr:0.0001
[07:12:14.324] iteration:14450  t-loss:0.2383, loss-lb:0.1559, loss-ulb:0.0412, weight:2.00, lr:0.0001
[07:12:15.473] iteration:14451  t-loss:0.2033, loss-lb:0.1790, loss-ulb:0.0121, weight:2.00, lr:0.0001
[07:12:15.802] iteration:14452  t-loss:0.2164, loss-lb:0.1241, loss-ulb:0.0462, weight:2.00, lr:0.0001
[07:12:16.127] iteration:14453  t-loss:0.4463, loss-lb:0.1545, loss-ulb:0.1459, weight:2.00, lr:0.0001
[07:12:16.464] iteration:14454  t-loss:0.3844, loss-lb:0.2529, loss-ulb:0.0658, weight:2.00, lr:0.0001
[07:12:16.783] iteration:14455  t-loss:0.2548, loss-lb:0.2152, loss-ulb:0.0198, weight:2.00, lr:0.0001
[07:12:17.097] iteration:14456  t-loss:0.3045, loss-lb:0.1295, loss-ulb:0.0875, weight:2.00, lr:0.0001
[07:12:17.413] iteration:14457  t-loss:0.2018, loss-lb:0.1728, loss-ulb:0.0145, weight:2.00, lr:0.0001
[07:12:17.732] iteration:14458  t-loss:0.2062, loss-lb:0.1713, loss-ulb:0.0175, weight:2.00, lr:0.0001
[07:12:18.051] iteration:14459  t-loss:0.1922, loss-lb:0.1597, loss-ulb:0.0162, weight:2.00, lr:0.0001
[07:12:18.365] iteration:14460  t-loss:0.2088, loss-lb:0.1587, loss-ulb:0.0251, weight:2.00, lr:0.0001
[07:12:18.681] iteration:14461  t-loss:0.4659, loss-lb:0.1925, loss-ulb:0.1367, weight:2.00, lr:0.0001
[07:12:18.996] iteration:14462  t-loss:0.2000, loss-lb:0.1587, loss-ulb:0.0207, weight:2.00, lr:0.0001
[07:12:19.322] iteration:14463  t-loss:0.2362, loss-lb:0.1946, loss-ulb:0.0208, weight:2.00, lr:0.0001
[07:12:19.650] iteration:14464  t-loss:0.4143, loss-lb:0.1478, loss-ulb:0.1333, weight:2.00, lr:0.0000
[07:12:19.969] iteration:14465  t-loss:0.3250, loss-lb:0.1567, loss-ulb:0.0841, weight:2.00, lr:0.0000
[07:12:20.290] iteration:14466  t-loss:0.1357, loss-lb:0.1083, loss-ulb:0.0137, weight:2.00, lr:0.0000
[07:12:20.608] iteration:14467  t-loss:0.2233, loss-lb:0.1954, loss-ulb:0.0140, weight:2.00, lr:0.0000
[07:12:20.924] iteration:14468  t-loss:0.2333, loss-lb:0.1921, loss-ulb:0.0206, weight:2.00, lr:0.0000
[07:12:21.236] iteration:14469  t-loss:0.1995, loss-lb:0.1565, loss-ulb:0.0215, weight:2.00, lr:0.0000
[07:12:21.551] iteration:14470  t-loss:0.2213, loss-lb:0.1246, loss-ulb:0.0484, weight:2.00, lr:0.0000
[07:12:21.866] iteration:14471  t-loss:0.2833, loss-lb:0.2549, loss-ulb:0.0142, weight:2.00, lr:0.0000
[07:12:22.180] iteration:14472  t-loss:0.1866, loss-lb:0.1454, loss-ulb:0.0206, weight:2.00, lr:0.0000
[07:12:22.499] iteration:14473  t-loss:0.2579, loss-lb:0.1322, loss-ulb:0.0629, weight:2.00, lr:0.0000
[07:12:22.816] iteration:14474  t-loss:0.3012, loss-lb:0.1921, loss-ulb:0.0545, weight:2.00, lr:0.0000
[07:12:23.134] iteration:14475  t-loss:0.2641, loss-lb:0.1805, loss-ulb:0.0418, weight:2.00, lr:0.0000
[07:12:24.450] iteration:14476  t-loss:0.2123, loss-lb:0.1304, loss-ulb:0.0409, weight:2.00, lr:0.0000
[07:12:24.771] iteration:14477  t-loss:0.2588, loss-lb:0.2222, loss-ulb:0.0183, weight:2.00, lr:0.0000
[07:12:25.094] iteration:14478  t-loss:0.2999, loss-lb:0.1380, loss-ulb:0.0810, weight:2.00, lr:0.0000
[07:12:25.410] iteration:14479  t-loss:0.2145, loss-lb:0.1804, loss-ulb:0.0170, weight:2.00, lr:0.0000
[07:12:25.729] iteration:14480  t-loss:0.2661, loss-lb:0.1651, loss-ulb:0.0505, weight:2.00, lr:0.0000
[07:12:26.049] iteration:14481  t-loss:0.2819, loss-lb:0.1630, loss-ulb:0.0594, weight:2.00, lr:0.0000
[07:12:26.368] iteration:14482  t-loss:0.2759, loss-lb:0.1523, loss-ulb:0.0618, weight:2.00, lr:0.0000
[07:12:26.688] iteration:14483  t-loss:0.2742, loss-lb:0.1366, loss-ulb:0.0688, weight:2.00, lr:0.0000
[07:12:27.010] iteration:14484  t-loss:0.3093, loss-lb:0.2417, loss-ulb:0.0338, weight:2.00, lr:0.0000
[07:12:27.326] iteration:14485  t-loss:0.3662, loss-lb:0.2948, loss-ulb:0.0357, weight:2.00, lr:0.0000
[07:12:27.644] iteration:14486  t-loss:0.3081, loss-lb:0.1134, loss-ulb:0.0973, weight:2.00, lr:0.0000
[07:12:27.965] iteration:14487  t-loss:0.3196, loss-lb:0.1961, loss-ulb:0.0617, weight:2.00, lr:0.0000
[07:12:28.284] iteration:14488  t-loss:0.2884, loss-lb:0.2112, loss-ulb:0.0386, weight:2.00, lr:0.0000
[07:12:28.601] iteration:14489  t-loss:0.2526, loss-lb:0.2129, loss-ulb:0.0199, weight:2.00, lr:0.0000
[07:12:28.917] iteration:14490  t-loss:0.2065, loss-lb:0.1763, loss-ulb:0.0151, weight:2.00, lr:0.0000
[07:12:29.238] iteration:14491  t-loss:0.3154, loss-lb:0.1723, loss-ulb:0.0715, weight:2.00, lr:0.0000
[07:12:29.558] iteration:14492  t-loss:0.2744, loss-lb:0.1490, loss-ulb:0.0627, weight:2.00, lr:0.0000
[07:12:29.875] iteration:14493  t-loss:0.3206, loss-lb:0.1470, loss-ulb:0.0868, weight:2.00, lr:0.0000
[07:12:30.191] iteration:14494  t-loss:0.3963, loss-lb:0.1958, loss-ulb:0.1002, weight:2.00, lr:0.0000
[07:12:30.507] iteration:14495  t-loss:0.3729, loss-lb:0.2786, loss-ulb:0.0472, weight:2.00, lr:0.0000
[07:12:30.820] iteration:14496  t-loss:0.2495, loss-lb:0.1670, loss-ulb:0.0413, weight:2.00, lr:0.0000
[07:12:31.137] iteration:14497  t-loss:0.4051, loss-lb:0.2069, loss-ulb:0.0991, weight:2.00, lr:0.0000
[07:12:31.454] iteration:14498  t-loss:0.3573, loss-lb:0.1607, loss-ulb:0.0983, weight:2.00, lr:0.0000
[07:12:31.772] iteration:14499  t-loss:0.4570, loss-lb:0.1877, loss-ulb:0.1346, weight:2.00, lr:0.0000
[07:12:32.088] iteration:14500  t-loss:0.8078, loss-lb:0.2513, loss-ulb:0.2782, weight:2.00, lr:0.0000
[07:12:33.487] iteration:14501  t-loss:0.2740, loss-lb:0.1808, loss-ulb:0.0466, weight:2.00, lr:0.0000
[07:12:33.809] iteration:14502  t-loss:0.2368, loss-lb:0.1720, loss-ulb:0.0324, weight:2.00, lr:0.0000
[07:12:34.126] iteration:14503  t-loss:0.3217, loss-lb:0.1410, loss-ulb:0.0904, weight:2.00, lr:0.0000
[07:12:34.441] iteration:14504  t-loss:0.4832, loss-lb:0.1414, loss-ulb:0.1709, weight:2.00, lr:0.0000
[07:12:34.758] iteration:14505  t-loss:0.1553, loss-lb:0.1238, loss-ulb:0.0157, weight:2.00, lr:0.0000
[07:12:35.080] iteration:14506  t-loss:0.2829, loss-lb:0.2469, loss-ulb:0.0180, weight:2.00, lr:0.0000
[07:12:35.409] iteration:14507  t-loss:0.2495, loss-lb:0.1563, loss-ulb:0.0466, weight:2.00, lr:0.0000
[07:12:35.726] iteration:14508  t-loss:0.1897, loss-lb:0.1342, loss-ulb:0.0278, weight:2.00, lr:0.0000
[07:12:36.044] iteration:14509  t-loss:0.1638, loss-lb:0.1388, loss-ulb:0.0125, weight:2.00, lr:0.0000
[07:12:36.363] iteration:14510  t-loss:0.3543, loss-lb:0.2785, loss-ulb:0.0379, weight:2.00, lr:0.0000
[07:12:36.679] iteration:14511  t-loss:0.3071, loss-lb:0.1899, loss-ulb:0.0586, weight:2.00, lr:0.0000
[07:12:36.993] iteration:14512  t-loss:0.1662, loss-lb:0.1268, loss-ulb:0.0197, weight:2.00, lr:0.0000
[07:12:37.309] iteration:14513  t-loss:0.2407, loss-lb:0.1863, loss-ulb:0.0272, weight:2.00, lr:0.0000
[07:12:37.626] iteration:14514  t-loss:0.1740, loss-lb:0.1228, loss-ulb:0.0256, weight:2.00, lr:0.0000
[07:12:37.945] iteration:14515  t-loss:0.3637, loss-lb:0.1608, loss-ulb:0.1014, weight:2.00, lr:0.0000
[07:12:38.269] iteration:14516  t-loss:0.3626, loss-lb:0.1770, loss-ulb:0.0928, weight:2.00, lr:0.0000
[07:12:38.586] iteration:14517  t-loss:0.2607, loss-lb:0.1812, loss-ulb:0.0397, weight:2.00, lr:0.0000
[07:12:38.899] iteration:14518  t-loss:0.1761, loss-lb:0.1419, loss-ulb:0.0171, weight:2.00, lr:0.0000
[07:12:39.217] iteration:14519  t-loss:0.1579, loss-lb:0.1260, loss-ulb:0.0160, weight:2.00, lr:0.0000
[07:12:39.535] iteration:14520  t-loss:0.3437, loss-lb:0.2075, loss-ulb:0.0681, weight:2.00, lr:0.0000
[07:12:39.849] iteration:14521  t-loss:0.1728, loss-lb:0.1375, loss-ulb:0.0176, weight:2.00, lr:0.0000
[07:12:40.164] iteration:14522  t-loss:0.1654, loss-lb:0.1423, loss-ulb:0.0115, weight:2.00, lr:0.0000
[07:12:40.476] iteration:14523  t-loss:0.1829, loss-lb:0.1444, loss-ulb:0.0192, weight:2.00, lr:0.0000
[07:12:40.793] iteration:14524  t-loss:0.3105, loss-lb:0.1594, loss-ulb:0.0755, weight:2.00, lr:0.0000
[07:12:41.108] iteration:14525  t-loss:0.2255, loss-lb:0.1937, loss-ulb:0.0159, weight:2.00, lr:0.0000
[07:14:34.404] iteration 14525 : dice_score: 0.849236 best_dice: 0.854000
[07:14:34.404]  <<Test>> - Ep:580  - Dice-S/T:84.97/84.92, Best-S:85.59, Best-T:85.40
[07:14:34.404]           - AvgLoss(lb/ulb/all):0.16/0.04/0.24
[07:14:35.503] iteration:14526  t-loss:0.1402, loss-lb:0.1139, loss-ulb:0.0132, weight:2.00, lr:0.0000
[07:14:35.841] iteration:14527  t-loss:0.2911, loss-lb:0.1932, loss-ulb:0.0489, weight:2.00, lr:0.0000
[07:14:36.163] iteration:14528  t-loss:0.2404, loss-lb:0.1682, loss-ulb:0.0361, weight:2.00, lr:0.0000
[07:14:36.500] iteration:14529  t-loss:0.2734, loss-lb:0.1866, loss-ulb:0.0434, weight:2.00, lr:0.0000
[07:14:36.822] iteration:14530  t-loss:0.2868, loss-lb:0.1447, loss-ulb:0.0711, weight:2.00, lr:0.0000
[07:14:37.141] iteration:14531  t-loss:0.2502, loss-lb:0.2248, loss-ulb:0.0127, weight:2.00, lr:0.0000
[07:14:37.460] iteration:14532  t-loss:0.4025, loss-lb:0.2225, loss-ulb:0.0900, weight:2.00, lr:0.0000
[07:14:37.774] iteration:14533  t-loss:0.2433, loss-lb:0.1554, loss-ulb:0.0439, weight:2.00, lr:0.0000
[07:14:38.094] iteration:14534  t-loss:0.3772, loss-lb:0.2205, loss-ulb:0.0783, weight:2.00, lr:0.0000
[07:14:38.407] iteration:14535  t-loss:0.1837, loss-lb:0.1153, loss-ulb:0.0342, weight:2.00, lr:0.0000
[07:14:38.724] iteration:14536  t-loss:0.2813, loss-lb:0.1608, loss-ulb:0.0603, weight:2.00, lr:0.0000
[07:14:39.042] iteration:14537  t-loss:0.2465, loss-lb:0.1492, loss-ulb:0.0487, weight:2.00, lr:0.0000
[07:14:39.359] iteration:14538  t-loss:0.1852, loss-lb:0.1501, loss-ulb:0.0175, weight:2.00, lr:0.0000
[07:14:39.674] iteration:14539  t-loss:0.2810, loss-lb:0.1415, loss-ulb:0.0698, weight:2.00, lr:0.0000
[07:14:39.989] iteration:14540  t-loss:0.3024, loss-lb:0.1425, loss-ulb:0.0800, weight:2.00, lr:0.0000
[07:14:40.301] iteration:14541  t-loss:0.1855, loss-lb:0.1464, loss-ulb:0.0196, weight:2.00, lr:0.0000
[07:14:40.621] iteration:14542  t-loss:0.3115, loss-lb:0.2040, loss-ulb:0.0537, weight:2.00, lr:0.0000
[07:14:40.934] iteration:14543  t-loss:0.2648, loss-lb:0.1686, loss-ulb:0.0481, weight:2.00, lr:0.0000
[07:14:41.247] iteration:14544  t-loss:0.3529, loss-lb:0.2248, loss-ulb:0.0641, weight:2.00, lr:0.0000
[07:14:41.557] iteration:14545  t-loss:0.2902, loss-lb:0.2033, loss-ulb:0.0434, weight:2.00, lr:0.0000
[07:14:41.873] iteration:14546  t-loss:0.3703, loss-lb:0.2079, loss-ulb:0.0812, weight:2.00, lr:0.0000
[07:14:42.187] iteration:14547  t-loss:0.2260, loss-lb:0.1940, loss-ulb:0.0160, weight:2.00, lr:0.0000
[07:14:42.500] iteration:14548  t-loss:0.3295, loss-lb:0.1451, loss-ulb:0.0922, weight:2.00, lr:0.0000
[07:14:42.815] iteration:14549  t-loss:0.3976, loss-lb:0.1255, loss-ulb:0.1361, weight:2.00, lr:0.0000
[07:14:43.127] iteration:14550  t-loss:0.2390, loss-lb:0.1625, loss-ulb:0.0382, weight:2.00, lr:0.0000
[07:14:44.162] iteration:14551  t-loss:0.2348, loss-lb:0.1899, loss-ulb:0.0224, weight:2.00, lr:0.0000
[07:14:44.500] iteration:14552  t-loss:0.3499, loss-lb:0.1375, loss-ulb:0.1062, weight:2.00, lr:0.0000
[07:14:44.837] iteration:14553  t-loss:0.3256, loss-lb:0.1946, loss-ulb:0.0655, weight:2.00, lr:0.0000
[07:14:45.168] iteration:14554  t-loss:0.4043, loss-lb:0.1893, loss-ulb:0.1075, weight:2.00, lr:0.0000
[07:14:45.499] iteration:14555  t-loss:0.2404, loss-lb:0.2089, loss-ulb:0.0158, weight:2.00, lr:0.0000
[07:14:45.826] iteration:14556  t-loss:0.2369, loss-lb:0.2102, loss-ulb:0.0133, weight:2.00, lr:0.0000
[07:14:46.151] iteration:14557  t-loss:0.2137, loss-lb:0.1215, loss-ulb:0.0461, weight:2.00, lr:0.0000
[07:14:46.469] iteration:14558  t-loss:0.1921, loss-lb:0.1410, loss-ulb:0.0256, weight:2.00, lr:0.0000
[07:14:46.786] iteration:14559  t-loss:0.3077, loss-lb:0.2777, loss-ulb:0.0150, weight:2.00, lr:0.0000
[07:14:47.104] iteration:14560  t-loss:0.4002, loss-lb:0.1492, loss-ulb:0.1255, weight:2.00, lr:0.0000
[07:14:47.418] iteration:14561  t-loss:0.1986, loss-lb:0.1502, loss-ulb:0.0242, weight:2.00, lr:0.0000
[07:14:47.738] iteration:14562  t-loss:0.1925, loss-lb:0.1705, loss-ulb:0.0110, weight:2.00, lr:0.0000
[07:14:48.055] iteration:14563  t-loss:0.3535, loss-lb:0.1779, loss-ulb:0.0878, weight:2.00, lr:0.0000
[07:14:48.371] iteration:14564  t-loss:0.1874, loss-lb:0.1316, loss-ulb:0.0279, weight:2.00, lr:0.0000
[07:14:48.688] iteration:14565  t-loss:0.4325, loss-lb:0.1949, loss-ulb:0.1188, weight:2.00, lr:0.0000
[07:14:49.005] iteration:14566  t-loss:0.2898, loss-lb:0.1977, loss-ulb:0.0461, weight:2.00, lr:0.0000
[07:14:49.322] iteration:14567  t-loss:0.3962, loss-lb:0.1170, loss-ulb:0.1396, weight:2.00, lr:0.0000
[07:14:49.635] iteration:14568  t-loss:0.1789, loss-lb:0.1441, loss-ulb:0.0174, weight:2.00, lr:0.0000
[07:14:49.948] iteration:14569  t-loss:0.4600, loss-lb:0.2416, loss-ulb:0.1092, weight:2.00, lr:0.0000
[07:14:50.265] iteration:14570  t-loss:0.3163, loss-lb:0.2129, loss-ulb:0.0517, weight:2.00, lr:0.0000
[07:14:50.581] iteration:14571  t-loss:0.2963, loss-lb:0.1138, loss-ulb:0.0913, weight:2.00, lr:0.0000
[07:14:50.895] iteration:14572  t-loss:0.4786, loss-lb:0.1932, loss-ulb:0.1427, weight:2.00, lr:0.0000
[07:14:51.207] iteration:14573  t-loss:0.1838, loss-lb:0.1491, loss-ulb:0.0173, weight:2.00, lr:0.0000
[07:14:51.523] iteration:14574  t-loss:0.2227, loss-lb:0.1685, loss-ulb:0.0271, weight:2.00, lr:0.0000
[07:14:51.836] iteration:14575  t-loss:0.2744, loss-lb:0.2034, loss-ulb:0.0355, weight:2.00, lr:0.0000
[07:14:53.064] iteration:14576  t-loss:0.3328, loss-lb:0.1642, loss-ulb:0.0843, weight:2.00, lr:0.0000
[07:14:53.393] iteration:14577  t-loss:0.1993, loss-lb:0.1537, loss-ulb:0.0228, weight:2.00, lr:0.0000
[07:14:53.711] iteration:14578  t-loss:0.1904, loss-lb:0.1172, loss-ulb:0.0366, weight:2.00, lr:0.0000
[07:14:54.026] iteration:14579  t-loss:0.2140, loss-lb:0.1238, loss-ulb:0.0451, weight:2.00, lr:0.0000
[07:14:54.351] iteration:14580  t-loss:0.2242, loss-lb:0.1636, loss-ulb:0.0303, weight:2.00, lr:0.0000
[07:14:54.669] iteration:14581  t-loss:0.4988, loss-lb:0.3273, loss-ulb:0.0857, weight:2.00, lr:0.0000
[07:14:54.989] iteration:14582  t-loss:0.4437, loss-lb:0.2144, loss-ulb:0.1147, weight:2.00, lr:0.0000
[07:14:55.301] iteration:14583  t-loss:0.1720, loss-lb:0.1493, loss-ulb:0.0113, weight:2.00, lr:0.0000
[07:14:55.615] iteration:14584  t-loss:0.2546, loss-lb:0.1963, loss-ulb:0.0292, weight:2.00, lr:0.0000
[07:14:55.927] iteration:14585  t-loss:0.1605, loss-lb:0.1238, loss-ulb:0.0183, weight:2.00, lr:0.0000
[07:14:56.244] iteration:14586  t-loss:0.3663, loss-lb:0.1630, loss-ulb:0.1017, weight:2.00, lr:0.0000
[07:14:56.561] iteration:14587  t-loss:0.3125, loss-lb:0.1715, loss-ulb:0.0705, weight:2.00, lr:0.0000
[07:14:56.876] iteration:14588  t-loss:0.1875, loss-lb:0.1590, loss-ulb:0.0143, weight:2.00, lr:0.0000
[07:14:57.188] iteration:14589  t-loss:0.1878, loss-lb:0.1532, loss-ulb:0.0173, weight:2.00, lr:0.0000
[07:14:57.506] iteration:14590  t-loss:0.3371, loss-lb:0.1975, loss-ulb:0.0698, weight:2.00, lr:0.0000
[07:14:57.822] iteration:14591  t-loss:0.2455, loss-lb:0.1240, loss-ulb:0.0608, weight:2.00, lr:0.0000
[07:14:58.139] iteration:14592  t-loss:0.2810, loss-lb:0.2511, loss-ulb:0.0149, weight:2.00, lr:0.0000
[07:14:58.453] iteration:14593  t-loss:0.1435, loss-lb:0.1187, loss-ulb:0.0124, weight:2.00, lr:0.0000
[07:14:58.771] iteration:14594  t-loss:0.3716, loss-lb:0.1689, loss-ulb:0.1014, weight:2.00, lr:0.0000
[07:14:59.091] iteration:14595  t-loss:0.3378, loss-lb:0.1362, loss-ulb:0.1008, weight:2.00, lr:0.0000
[07:14:59.409] iteration:14596  t-loss:0.2765, loss-lb:0.2486, loss-ulb:0.0140, weight:2.00, lr:0.0000
[07:14:59.729] iteration:14597  t-loss:0.2790, loss-lb:0.1450, loss-ulb:0.0670, weight:2.00, lr:0.0000
[07:15:00.044] iteration:14598  t-loss:0.4432, loss-lb:0.1977, loss-ulb:0.1228, weight:2.00, lr:0.0000
[07:15:00.363] iteration:14599  t-loss:0.2430, loss-lb:0.1450, loss-ulb:0.0490, weight:2.00, lr:0.0000
[07:15:00.681] iteration:14600  t-loss:0.4507, loss-lb:0.2643, loss-ulb:0.0932, weight:2.00, lr:0.0000
[07:15:02.037] iteration:14601  t-loss:0.2312, loss-lb:0.1942, loss-ulb:0.0185, weight:2.00, lr:0.0000
[07:15:02.363] iteration:14602  t-loss:0.2754, loss-lb:0.1244, loss-ulb:0.0755, weight:2.00, lr:0.0000
[07:15:02.683] iteration:14603  t-loss:0.1618, loss-lb:0.1255, loss-ulb:0.0181, weight:2.00, lr:0.0000
[07:15:03.003] iteration:14604  t-loss:0.3192, loss-lb:0.2900, loss-ulb:0.0146, weight:2.00, lr:0.0000
[07:15:03.317] iteration:14605  t-loss:0.2108, loss-lb:0.1727, loss-ulb:0.0191, weight:2.00, lr:0.0000
[07:15:03.634] iteration:14606  t-loss:0.2349, loss-lb:0.1658, loss-ulb:0.0346, weight:2.00, lr:0.0000
[07:15:03.956] iteration:14607  t-loss:0.3446, loss-lb:0.2312, loss-ulb:0.0567, weight:2.00, lr:0.0000
[07:15:04.275] iteration:14608  t-loss:0.3581, loss-lb:0.2356, loss-ulb:0.0613, weight:2.00, lr:0.0000
[07:15:04.595] iteration:14609  t-loss:0.3135, loss-lb:0.1646, loss-ulb:0.0745, weight:2.00, lr:0.0000
[07:15:04.909] iteration:14610  t-loss:0.2884, loss-lb:0.1221, loss-ulb:0.0832, weight:2.00, lr:0.0000
[07:15:05.224] iteration:14611  t-loss:0.4208, loss-lb:0.1932, loss-ulb:0.1138, weight:2.00, lr:0.0000
[07:15:05.540] iteration:14612  t-loss:0.2105, loss-lb:0.1835, loss-ulb:0.0135, weight:2.00, lr:0.0000
[07:15:05.852] iteration:14613  t-loss:0.4639, loss-lb:0.1500, loss-ulb:0.1570, weight:2.00, lr:0.0000
[07:15:06.170] iteration:14614  t-loss:0.2458, loss-lb:0.1704, loss-ulb:0.0377, weight:2.00, lr:0.0000
[07:15:06.486] iteration:14615  t-loss:0.3721, loss-lb:0.1719, loss-ulb:0.1001, weight:2.00, lr:0.0000
[07:15:06.802] iteration:14616  t-loss:0.2258, loss-lb:0.1193, loss-ulb:0.0533, weight:2.00, lr:0.0000
[07:15:07.121] iteration:14617  t-loss:0.3353, loss-lb:0.2046, loss-ulb:0.0654, weight:2.00, lr:0.0000
[07:15:07.434] iteration:14618  t-loss:0.3258, loss-lb:0.1285, loss-ulb:0.0986, weight:2.00, lr:0.0000
[07:15:07.747] iteration:14619  t-loss:0.6221, loss-lb:0.1701, loss-ulb:0.2260, weight:2.00, lr:0.0000
[07:15:08.061] iteration:14620  t-loss:0.2407, loss-lb:0.1211, loss-ulb:0.0598, weight:2.00, lr:0.0000
[07:15:08.374] iteration:14621  t-loss:0.3366, loss-lb:0.1791, loss-ulb:0.0788, weight:2.00, lr:0.0000
[07:15:08.687] iteration:14622  t-loss:0.3361, loss-lb:0.1524, loss-ulb:0.0918, weight:2.00, lr:0.0000
[07:15:09.000] iteration:14623  t-loss:0.1886, loss-lb:0.1604, loss-ulb:0.0141, weight:2.00, lr:0.0000
[07:15:09.312] iteration:14624  t-loss:0.3389, loss-lb:0.1813, loss-ulb:0.0788, weight:2.00, lr:0.0000
[07:15:09.628] iteration:14625  t-loss:0.4300, loss-lb:0.2539, loss-ulb:0.0880, weight:2.00, lr:0.0000
[07:17:01.796] iteration 14625 : dice_score: 0.849067 best_dice: 0.854000
[07:17:01.796]  <<Test>> - Ep:584  - Dice-S/T:85.11/84.91, Best-S:85.59, Best-T:85.40
[07:17:01.796]           - AvgLoss(lb/ulb/all):0.17/0.08/0.33
[07:17:03.003] iteration:14626  t-loss:0.2838, loss-lb:0.2480, loss-ulb:0.0179, weight:2.00, lr:0.0000
[07:17:03.326] iteration:14627  t-loss:0.4075, loss-lb:0.1685, loss-ulb:0.1195, weight:2.00, lr:0.0000
[07:17:03.642] iteration:14628  t-loss:0.2765, loss-lb:0.2236, loss-ulb:0.0265, weight:2.00, lr:0.0000
[07:17:03.956] iteration:14629  t-loss:0.2328, loss-lb:0.1513, loss-ulb:0.0408, weight:2.00, lr:0.0000
[07:17:04.272] iteration:14630  t-loss:0.3968, loss-lb:0.2263, loss-ulb:0.0852, weight:2.00, lr:0.0000
[07:17:04.588] iteration:14631  t-loss:0.2600, loss-lb:0.1388, loss-ulb:0.0606, weight:2.00, lr:0.0000
[07:17:04.905] iteration:14632  t-loss:0.2318, loss-lb:0.1640, loss-ulb:0.0339, weight:2.00, lr:0.0000
[07:17:05.222] iteration:14633  t-loss:0.1710, loss-lb:0.1344, loss-ulb:0.0183, weight:2.00, lr:0.0000
[07:17:05.535] iteration:14634  t-loss:0.6201, loss-lb:0.1371, loss-ulb:0.2415, weight:2.00, lr:0.0000
[07:17:05.852] iteration:14635  t-loss:0.3114, loss-lb:0.1832, loss-ulb:0.0641, weight:2.00, lr:0.0000
[07:17:06.171] iteration:14636  t-loss:0.3387, loss-lb:0.2157, loss-ulb:0.0615, weight:2.00, lr:0.0000
[07:17:06.489] iteration:14637  t-loss:0.2763, loss-lb:0.1885, loss-ulb:0.0439, weight:2.00, lr:0.0000
[07:17:06.804] iteration:14638  t-loss:0.2268, loss-lb:0.1860, loss-ulb:0.0204, weight:2.00, lr:0.0000
[07:17:07.118] iteration:14639  t-loss:0.1736, loss-lb:0.1325, loss-ulb:0.0206, weight:2.00, lr:0.0000
[07:17:07.435] iteration:14640  t-loss:0.2384, loss-lb:0.2031, loss-ulb:0.0177, weight:2.00, lr:0.0000
[07:17:07.749] iteration:14641  t-loss:0.2094, loss-lb:0.1636, loss-ulb:0.0229, weight:2.00, lr:0.0000
[07:17:08.068] iteration:14642  t-loss:0.3137, loss-lb:0.1600, loss-ulb:0.0769, weight:2.00, lr:0.0000
[07:17:08.382] iteration:14643  t-loss:0.2572, loss-lb:0.1166, loss-ulb:0.0703, weight:2.00, lr:0.0000
[07:17:08.696] iteration:14644  t-loss:0.2901, loss-lb:0.1411, loss-ulb:0.0745, weight:2.00, lr:0.0000
[07:17:09.010] iteration:14645  t-loss:0.1608, loss-lb:0.1343, loss-ulb:0.0133, weight:2.00, lr:0.0000
[07:17:09.328] iteration:14646  t-loss:0.3572, loss-lb:0.2232, loss-ulb:0.0670, weight:2.00, lr:0.0000
[07:17:09.648] iteration:14647  t-loss:0.1273, loss-lb:0.1036, loss-ulb:0.0118, weight:2.00, lr:0.0000
[07:17:09.969] iteration:14648  t-loss:0.2768, loss-lb:0.1940, loss-ulb:0.0414, weight:2.00, lr:0.0000
[07:17:10.293] iteration:14649  t-loss:0.2337, loss-lb:0.1249, loss-ulb:0.0544, weight:2.00, lr:0.0000
[07:17:10.623] iteration:14650  t-loss:0.2348, loss-lb:0.2052, loss-ulb:0.0148, weight:2.00, lr:0.0000
[07:17:12.411] iteration:14651  t-loss:0.1549, loss-lb:0.1230, loss-ulb:0.0160, weight:2.00, lr:0.0000
[07:17:12.743] iteration:14652  t-loss:0.3850, loss-lb:0.1766, loss-ulb:0.1042, weight:2.00, lr:0.0000
[07:17:13.067] iteration:14653  t-loss:0.3459, loss-lb:0.1525, loss-ulb:0.0967, weight:2.00, lr:0.0000
[07:17:13.390] iteration:14654  t-loss:0.3441, loss-lb:0.1361, loss-ulb:0.1040, weight:2.00, lr:0.0000
[07:17:13.711] iteration:14655  t-loss:0.2682, loss-lb:0.1363, loss-ulb:0.0659, weight:2.00, lr:0.0000
[07:17:14.027] iteration:14656  t-loss:0.3140, loss-lb:0.1428, loss-ulb:0.0856, weight:2.00, lr:0.0000
[07:17:14.341] iteration:14657  t-loss:0.2847, loss-lb:0.1425, loss-ulb:0.0711, weight:2.00, lr:0.0000
[07:17:14.658] iteration:14658  t-loss:0.3810, loss-lb:0.2092, loss-ulb:0.0859, weight:2.00, lr:0.0000
[07:17:14.973] iteration:14659  t-loss:0.2031, loss-lb:0.1304, loss-ulb:0.0364, weight:2.00, lr:0.0000
[07:17:15.293] iteration:14660  t-loss:0.3105, loss-lb:0.1992, loss-ulb:0.0557, weight:2.00, lr:0.0000
[07:17:15.609] iteration:14661  t-loss:0.2207, loss-lb:0.1898, loss-ulb:0.0155, weight:2.00, lr:0.0000
[07:17:15.926] iteration:14662  t-loss:0.3751, loss-lb:0.2695, loss-ulb:0.0528, weight:2.00, lr:0.0000
[07:17:16.243] iteration:14663  t-loss:0.3457, loss-lb:0.3130, loss-ulb:0.0163, weight:2.00, lr:0.0000
[07:17:16.559] iteration:14664  t-loss:0.3692, loss-lb:0.2040, loss-ulb:0.0826, weight:2.00, lr:0.0000
[07:17:16.875] iteration:14665  t-loss:0.2316, loss-lb:0.1122, loss-ulb:0.0597, weight:2.00, lr:0.0000
[07:17:17.194] iteration:14666  t-loss:0.2976, loss-lb:0.1903, loss-ulb:0.0536, weight:2.00, lr:0.0000
[07:17:17.511] iteration:14667  t-loss:0.2613, loss-lb:0.1314, loss-ulb:0.0649, weight:2.00, lr:0.0000
[07:17:17.824] iteration:14668  t-loss:0.2808, loss-lb:0.2079, loss-ulb:0.0365, weight:2.00, lr:0.0000
[07:17:18.140] iteration:14669  t-loss:0.3234, loss-lb:0.2082, loss-ulb:0.0576, weight:2.00, lr:0.0000
[07:17:18.456] iteration:14670  t-loss:0.3039, loss-lb:0.1607, loss-ulb:0.0716, weight:2.00, lr:0.0000
[07:17:18.780] iteration:14671  t-loss:0.3177, loss-lb:0.2067, loss-ulb:0.0555, weight:2.00, lr:0.0000
[07:17:19.104] iteration:14672  t-loss:0.3129, loss-lb:0.1678, loss-ulb:0.0725, weight:2.00, lr:0.0000
[07:17:19.429] iteration:14673  t-loss:0.3429, loss-lb:0.1852, loss-ulb:0.0788, weight:2.00, lr:0.0000
[07:17:19.754] iteration:14674  t-loss:0.1681, loss-lb:0.1263, loss-ulb:0.0209, weight:2.00, lr:0.0000
[07:17:20.081] iteration:14675  t-loss:0.2698, loss-lb:0.2288, loss-ulb:0.0205, weight:2.00, lr:0.0000
[07:17:21.827] iteration:14676  t-loss:0.3386, loss-lb:0.1434, loss-ulb:0.0976, weight:2.00, lr:0.0000
[07:17:22.168] iteration:14677  t-loss:0.1782, loss-lb:0.1410, loss-ulb:0.0186, weight:2.00, lr:0.0000
[07:17:22.507] iteration:14678  t-loss:0.2512, loss-lb:0.2217, loss-ulb:0.0148, weight:2.00, lr:0.0000
[07:17:22.827] iteration:14679  t-loss:0.1701, loss-lb:0.1320, loss-ulb:0.0191, weight:2.00, lr:0.0000
[07:17:23.143] iteration:14680  t-loss:0.3081, loss-lb:0.1703, loss-ulb:0.0689, weight:2.00, lr:0.0000
[07:17:23.461] iteration:14681  t-loss:0.1692, loss-lb:0.1423, loss-ulb:0.0135, weight:2.00, lr:0.0000
[07:17:23.781] iteration:14682  t-loss:0.3489, loss-lb:0.1255, loss-ulb:0.1117, weight:2.00, lr:0.0000
[07:17:24.099] iteration:14683  t-loss:0.5261, loss-lb:0.2053, loss-ulb:0.1604, weight:2.00, lr:0.0000
[07:17:24.429] iteration:14684  t-loss:0.1576, loss-lb:0.1314, loss-ulb:0.0131, weight:2.00, lr:0.0000
[07:17:24.748] iteration:14685  t-loss:0.3164, loss-lb:0.2253, loss-ulb:0.0456, weight:2.00, lr:0.0000
[07:17:25.068] iteration:14686  t-loss:0.3009, loss-lb:0.1844, loss-ulb:0.0582, weight:2.00, lr:0.0000
[07:17:25.392] iteration:14687  t-loss:0.3364, loss-lb:0.1659, loss-ulb:0.0852, weight:2.00, lr:0.0000
[07:17:25.713] iteration:14688  t-loss:0.4087, loss-lb:0.2396, loss-ulb:0.0846, weight:2.00, lr:0.0000
[07:17:26.028] iteration:14689  t-loss:0.3016, loss-lb:0.1400, loss-ulb:0.0808, weight:2.00, lr:0.0000
[07:17:26.347] iteration:14690  t-loss:0.4301, loss-lb:0.2136, loss-ulb:0.1083, weight:2.00, lr:0.0000
[07:17:26.663] iteration:14691  t-loss:0.3300, loss-lb:0.1640, loss-ulb:0.0830, weight:2.00, lr:0.0000
[07:17:26.984] iteration:14692  t-loss:0.2636, loss-lb:0.0981, loss-ulb:0.0828, weight:2.00, lr:0.0000
[07:17:27.297] iteration:14693  t-loss:0.3025, loss-lb:0.2104, loss-ulb:0.0460, weight:2.00, lr:0.0000
[07:17:27.611] iteration:14694  t-loss:0.2297, loss-lb:0.1739, loss-ulb:0.0279, weight:2.00, lr:0.0000
[07:17:27.925] iteration:14695  t-loss:0.2174, loss-lb:0.1829, loss-ulb:0.0173, weight:2.00, lr:0.0000
[07:17:28.239] iteration:14696  t-loss:0.2509, loss-lb:0.1634, loss-ulb:0.0438, weight:2.00, lr:0.0000
[07:17:28.556] iteration:14697  t-loss:0.3427, loss-lb:0.2160, loss-ulb:0.0633, weight:2.00, lr:0.0000
[07:17:28.873] iteration:14698  t-loss:0.2310, loss-lb:0.2085, loss-ulb:0.0113, weight:2.00, lr:0.0000
[07:17:29.186] iteration:14699  t-loss:0.1548, loss-lb:0.1197, loss-ulb:0.0175, weight:2.00, lr:0.0000
[07:17:29.502] iteration:14700  t-loss:0.5815, loss-lb:0.1453, loss-ulb:0.2181, weight:2.00, lr:0.0000
[07:17:30.655] iteration:14701  t-loss:0.2218, loss-lb:0.1333, loss-ulb:0.0442, weight:2.00, lr:0.0000
[07:17:30.988] iteration:14702  t-loss:0.1879, loss-lb:0.1593, loss-ulb:0.0143, weight:2.00, lr:0.0000
[07:17:31.320] iteration:14703  t-loss:0.3837, loss-lb:0.1638, loss-ulb:0.1100, weight:2.00, lr:0.0000
[07:17:31.640] iteration:14704  t-loss:0.3903, loss-lb:0.2702, loss-ulb:0.0601, weight:2.00, lr:0.0000
[07:17:31.958] iteration:14705  t-loss:0.1866, loss-lb:0.1417, loss-ulb:0.0224, weight:2.00, lr:0.0000
[07:17:32.276] iteration:14706  t-loss:0.2343, loss-lb:0.2011, loss-ulb:0.0166, weight:2.00, lr:0.0000
[07:17:32.594] iteration:14707  t-loss:0.4227, loss-lb:0.1523, loss-ulb:0.1352, weight:2.00, lr:0.0000
[07:17:32.917] iteration:14708  t-loss:0.3941, loss-lb:0.1967, loss-ulb:0.0987, weight:2.00, lr:0.0000
[07:17:33.232] iteration:14709  t-loss:0.2516, loss-lb:0.1608, loss-ulb:0.0454, weight:2.00, lr:0.0000
[07:17:33.547] iteration:14710  t-loss:0.1839, loss-lb:0.1510, loss-ulb:0.0164, weight:2.00, lr:0.0000
[07:17:33.861] iteration:14711  t-loss:0.1455, loss-lb:0.1061, loss-ulb:0.0197, weight:2.00, lr:0.0000
[07:17:34.181] iteration:14712  t-loss:0.3191, loss-lb:0.1958, loss-ulb:0.0616, weight:2.00, lr:0.0000
[07:17:34.498] iteration:14713  t-loss:0.3908, loss-lb:0.1710, loss-ulb:0.1099, weight:2.00, lr:0.0000
[07:17:34.816] iteration:14714  t-loss:0.1823, loss-lb:0.1467, loss-ulb:0.0178, weight:2.00, lr:0.0000
[07:17:35.133] iteration:14715  t-loss:0.5340, loss-lb:0.2178, loss-ulb:0.1581, weight:2.00, lr:0.0000
[07:17:35.451] iteration:14716  t-loss:0.2245, loss-lb:0.1899, loss-ulb:0.0173, weight:2.00, lr:0.0000
[07:17:35.772] iteration:14717  t-loss:0.2801, loss-lb:0.1537, loss-ulb:0.0632, weight:2.00, lr:0.0000
[07:17:36.087] iteration:14718  t-loss:0.4321, loss-lb:0.1690, loss-ulb:0.1315, weight:2.00, lr:0.0000
[07:17:36.402] iteration:14719  t-loss:0.1990, loss-lb:0.1191, loss-ulb:0.0399, weight:2.00, lr:0.0000
[07:17:36.717] iteration:14720  t-loss:0.2508, loss-lb:0.1292, loss-ulb:0.0608, weight:2.00, lr:0.0000
[07:17:37.033] iteration:14721  t-loss:0.2604, loss-lb:0.2305, loss-ulb:0.0150, weight:2.00, lr:0.0000
[07:17:37.347] iteration:14722  t-loss:0.3379, loss-lb:0.2030, loss-ulb:0.0675, weight:2.00, lr:0.0000
[07:17:37.666] iteration:14723  t-loss:0.3010, loss-lb:0.1516, loss-ulb:0.0747, weight:2.00, lr:0.0000
[07:17:37.981] iteration:14724  t-loss:0.3808, loss-lb:0.2181, loss-ulb:0.0814, weight:2.00, lr:0.0000
[07:17:38.293] iteration:14725  t-loss:0.1752, loss-lb:0.1408, loss-ulb:0.0172, weight:2.00, lr:0.0000
[07:19:30.379] iteration 14725 : dice_score: 0.850467 best_dice: 0.854000
[07:19:30.379]  <<Test>> - Ep:588  - Dice-S/T:84.96/85.05, Best-S:85.59, Best-T:85.40
[07:19:30.379]           - AvgLoss(lb/ulb/all):0.17/0.06/0.30
[07:19:31.543] iteration:14726  t-loss:0.2894, loss-lb:0.1661, loss-ulb:0.0616, weight:2.00, lr:0.0000
[07:19:31.872] iteration:14727  t-loss:0.2899, loss-lb:0.2069, loss-ulb:0.0415, weight:2.00, lr:0.0000
[07:19:32.192] iteration:14728  t-loss:0.2661, loss-lb:0.1307, loss-ulb:0.0677, weight:2.00, lr:0.0000
[07:19:32.510] iteration:14729  t-loss:0.1970, loss-lb:0.1484, loss-ulb:0.0243, weight:2.00, lr:0.0000
[07:19:32.829] iteration:14730  t-loss:0.3381, loss-lb:0.1588, loss-ulb:0.0896, weight:2.00, lr:0.0000
[07:19:33.149] iteration:14731  t-loss:0.4677, loss-lb:0.2562, loss-ulb:0.1057, weight:2.00, lr:0.0000
[07:19:33.463] iteration:14732  t-loss:0.3215, loss-lb:0.1917, loss-ulb:0.0649, weight:2.00, lr:0.0000
[07:19:33.777] iteration:14733  t-loss:0.1998, loss-lb:0.1651, loss-ulb:0.0174, weight:2.00, lr:0.0000
[07:19:34.098] iteration:14734  t-loss:0.1622, loss-lb:0.1380, loss-ulb:0.0121, weight:2.00, lr:0.0000
[07:19:34.414] iteration:14735  t-loss:0.1746, loss-lb:0.1471, loss-ulb:0.0138, weight:2.00, lr:0.0000
[07:19:34.732] iteration:14736  t-loss:0.2470, loss-lb:0.1300, loss-ulb:0.0585, weight:2.00, lr:0.0000
[07:19:35.051] iteration:14737  t-loss:0.3811, loss-lb:0.2322, loss-ulb:0.0745, weight:2.00, lr:0.0000
[07:19:35.365] iteration:14738  t-loss:0.2109, loss-lb:0.1499, loss-ulb:0.0305, weight:2.00, lr:0.0000
[07:19:35.680] iteration:14739  t-loss:0.1432, loss-lb:0.1166, loss-ulb:0.0133, weight:2.00, lr:0.0000
[07:19:35.996] iteration:14740  t-loss:0.3442, loss-lb:0.1114, loss-ulb:0.1164, weight:2.00, lr:0.0000
[07:19:36.314] iteration:14741  t-loss:0.3741, loss-lb:0.2686, loss-ulb:0.0528, weight:2.00, lr:0.0000
[07:19:36.632] iteration:14742  t-loss:0.4322, loss-lb:0.2337, loss-ulb:0.0992, weight:2.00, lr:0.0000
[07:19:36.951] iteration:14743  t-loss:0.3003, loss-lb:0.1244, loss-ulb:0.0880, weight:2.00, lr:0.0000
[07:19:37.268] iteration:14744  t-loss:0.2639, loss-lb:0.2342, loss-ulb:0.0149, weight:2.00, lr:0.0000
[07:19:37.584] iteration:14745  t-loss:0.2387, loss-lb:0.1723, loss-ulb:0.0332, weight:2.00, lr:0.0000
[07:19:37.900] iteration:14746  t-loss:0.2663, loss-lb:0.1323, loss-ulb:0.0670, weight:2.00, lr:0.0000
[07:19:38.217] iteration:14747  t-loss:0.3961, loss-lb:0.3760, loss-ulb:0.0101, weight:2.00, lr:0.0000
[07:19:38.532] iteration:14748  t-loss:0.2487, loss-lb:0.1293, loss-ulb:0.0597, weight:2.00, lr:0.0000
[07:19:38.849] iteration:14749  t-loss:0.3310, loss-lb:0.1791, loss-ulb:0.0759, weight:2.00, lr:0.0000
[07:19:39.162] iteration:14750  t-loss:0.1226, loss-lb:0.1037, loss-ulb:0.0094, weight:2.00, lr:0.0000
[07:19:40.470] iteration:14751  t-loss:0.4293, loss-lb:0.1503, loss-ulb:0.1395, weight:2.00, lr:0.0000
[07:19:40.807] iteration:14752  t-loss:0.3334, loss-lb:0.2586, loss-ulb:0.0374, weight:2.00, lr:0.0000
[07:19:41.124] iteration:14753  t-loss:0.2787, loss-lb:0.2166, loss-ulb:0.0311, weight:2.00, lr:0.0000
[07:19:41.441] iteration:14754  t-loss:0.2073, loss-lb:0.1356, loss-ulb:0.0358, weight:2.00, lr:0.0000
[07:19:41.755] iteration:14755  t-loss:0.1382, loss-lb:0.1085, loss-ulb:0.0148, weight:2.00, lr:0.0000
[07:19:42.079] iteration:14756  t-loss:0.1671, loss-lb:0.1264, loss-ulb:0.0204, weight:2.00, lr:0.0000
[07:19:42.402] iteration:14757  t-loss:0.2811, loss-lb:0.1525, loss-ulb:0.0643, weight:2.00, lr:0.0000
[07:19:42.725] iteration:14758  t-loss:0.1761, loss-lb:0.1413, loss-ulb:0.0174, weight:2.00, lr:0.0000
[07:19:43.062] iteration:14759  t-loss:0.2422, loss-lb:0.2203, loss-ulb:0.0109, weight:2.00, lr:0.0000
[07:19:43.382] iteration:14760  t-loss:0.2113, loss-lb:0.1879, loss-ulb:0.0117, weight:2.00, lr:0.0000
[07:19:43.712] iteration:14761  t-loss:0.8211, loss-lb:0.1771, loss-ulb:0.3220, weight:2.00, lr:0.0000
[07:19:44.038] iteration:14762  t-loss:0.2393, loss-lb:0.2092, loss-ulb:0.0150, weight:2.00, lr:0.0000
[07:19:44.359] iteration:14763  t-loss:0.2905, loss-lb:0.1529, loss-ulb:0.0688, weight:2.00, lr:0.0000
[07:19:44.675] iteration:14764  t-loss:0.3325, loss-lb:0.2428, loss-ulb:0.0448, weight:2.00, lr:0.0000
[07:19:44.993] iteration:14765  t-loss:0.1541, loss-lb:0.1229, loss-ulb:0.0156, weight:2.00, lr:0.0000
[07:19:45.310] iteration:14766  t-loss:0.2358, loss-lb:0.2057, loss-ulb:0.0151, weight:2.00, lr:0.0000
[07:19:45.625] iteration:14767  t-loss:0.1639, loss-lb:0.1322, loss-ulb:0.0158, weight:2.00, lr:0.0000
[07:19:45.939] iteration:14768  t-loss:0.2262, loss-lb:0.1799, loss-ulb:0.0232, weight:2.00, lr:0.0000
[07:19:46.254] iteration:14769  t-loss:0.2565, loss-lb:0.2107, loss-ulb:0.0229, weight:2.00, lr:0.0000
[07:19:46.566] iteration:14770  t-loss:0.1988, loss-lb:0.1649, loss-ulb:0.0170, weight:2.00, lr:0.0000
[07:19:46.880] iteration:14771  t-loss:0.2550, loss-lb:0.1485, loss-ulb:0.0533, weight:2.00, lr:0.0000
[07:19:47.195] iteration:14772  t-loss:0.3413, loss-lb:0.1561, loss-ulb:0.0926, weight:2.00, lr:0.0000
[07:19:47.507] iteration:14773  t-loss:0.1834, loss-lb:0.1482, loss-ulb:0.0176, weight:2.00, lr:0.0000
[07:19:47.819] iteration:14774  t-loss:0.1676, loss-lb:0.1367, loss-ulb:0.0155, weight:2.00, lr:0.0000
[07:19:48.132] iteration:14775  t-loss:0.2271, loss-lb:0.1830, loss-ulb:0.0221, weight:2.00, lr:0.0000
[07:19:49.368] iteration:14776  t-loss:0.5208, loss-lb:0.2518, loss-ulb:0.1345, weight:2.00, lr:0.0000
[07:19:49.704] iteration:14777  t-loss:0.2397, loss-lb:0.1289, loss-ulb:0.0554, weight:2.00, lr:0.0000
[07:19:50.026] iteration:14778  t-loss:0.2470, loss-lb:0.1169, loss-ulb:0.0651, weight:2.00, lr:0.0000
[07:19:50.346] iteration:14779  t-loss:0.3429, loss-lb:0.2337, loss-ulb:0.0546, weight:2.00, lr:0.0000
[07:19:50.658] iteration:14780  t-loss:0.1606, loss-lb:0.1115, loss-ulb:0.0246, weight:2.00, lr:0.0000
[07:19:50.971] iteration:14781  t-loss:0.3697, loss-lb:0.1582, loss-ulb:0.1058, weight:2.00, lr:0.0000
[07:19:51.286] iteration:14782  t-loss:0.3074, loss-lb:0.1747, loss-ulb:0.0664, weight:2.00, lr:0.0000
[07:19:51.604] iteration:14783  t-loss:0.3462, loss-lb:0.1963, loss-ulb:0.0749, weight:2.00, lr:0.0000
[07:19:51.919] iteration:14784  t-loss:0.2355, loss-lb:0.1084, loss-ulb:0.0636, weight:2.00, lr:0.0000
[07:19:52.232] iteration:14785  t-loss:0.1520, loss-lb:0.1262, loss-ulb:0.0129, weight:2.00, lr:0.0000
[07:19:52.549] iteration:14786  t-loss:0.3521, loss-lb:0.2356, loss-ulb:0.0583, weight:2.00, lr:0.0000
[07:19:52.867] iteration:14787  t-loss:0.3033, loss-lb:0.1976, loss-ulb:0.0529, weight:2.00, lr:0.0000
[07:19:53.184] iteration:14788  t-loss:0.4888, loss-lb:0.1749, loss-ulb:0.1569, weight:2.00, lr:0.0000
[07:19:53.498] iteration:14789  t-loss:0.1568, loss-lb:0.1264, loss-ulb:0.0152, weight:2.00, lr:0.0000
[07:19:53.815] iteration:14790  t-loss:0.2607, loss-lb:0.1594, loss-ulb:0.0506, weight:2.00, lr:0.0000
[07:19:54.129] iteration:14791  t-loss:0.3269, loss-lb:0.1906, loss-ulb:0.0681, weight:2.00, lr:0.0000
[07:19:54.444] iteration:14792  t-loss:0.2727, loss-lb:0.1324, loss-ulb:0.0702, weight:2.00, lr:0.0000
[07:19:54.759] iteration:14793  t-loss:0.4904, loss-lb:0.3727, loss-ulb:0.0588, weight:2.00, lr:0.0000
[07:19:55.073] iteration:14794  t-loss:0.3958, loss-lb:0.2114, loss-ulb:0.0922, weight:2.00, lr:0.0000
[07:19:55.388] iteration:14795  t-loss:0.1374, loss-lb:0.1091, loss-ulb:0.0141, weight:2.00, lr:0.0000
[07:19:55.707] iteration:14796  t-loss:0.2397, loss-lb:0.1255, loss-ulb:0.0571, weight:2.00, lr:0.0000
[07:19:56.027] iteration:14797  t-loss:0.3346, loss-lb:0.2249, loss-ulb:0.0548, weight:2.00, lr:0.0000
[07:19:56.349] iteration:14798  t-loss:0.2921, loss-lb:0.1397, loss-ulb:0.0762, weight:2.00, lr:0.0000
[07:19:56.671] iteration:14799  t-loss:0.3518, loss-lb:0.1850, loss-ulb:0.0834, weight:2.00, lr:0.0000
[07:19:56.988] iteration:14800  t-loss:0.2787, loss-lb:0.1727, loss-ulb:0.0530, weight:2.00, lr:0.0000
[07:19:58.173] iteration:14801  t-loss:0.2411, loss-lb:0.1819, loss-ulb:0.0296, weight:2.00, lr:0.0000
[07:19:58.503] iteration:14802  t-loss:0.2368, loss-lb:0.1923, loss-ulb:0.0222, weight:2.00, lr:0.0000
[07:19:58.826] iteration:14803  t-loss:0.3740, loss-lb:0.2323, loss-ulb:0.0709, weight:2.00, lr:0.0000
[07:19:59.148] iteration:14804  t-loss:0.2554, loss-lb:0.1950, loss-ulb:0.0302, weight:2.00, lr:0.0000
[07:19:59.470] iteration:14805  t-loss:0.3668, loss-lb:0.1934, loss-ulb:0.0867, weight:2.00, lr:0.0000
[07:19:59.788] iteration:14806  t-loss:0.2349, loss-lb:0.1233, loss-ulb:0.0558, weight:2.00, lr:0.0000
[07:20:00.105] iteration:14807  t-loss:0.2032, loss-lb:0.1650, loss-ulb:0.0191, weight:2.00, lr:0.0000
[07:20:00.419] iteration:14808  t-loss:0.2025, loss-lb:0.1799, loss-ulb:0.0113, weight:2.00, lr:0.0000
[07:20:00.740] iteration:14809  t-loss:0.3937, loss-lb:0.2209, loss-ulb:0.0864, weight:2.00, lr:0.0000
[07:20:01.055] iteration:14810  t-loss:0.2786, loss-lb:0.1279, loss-ulb:0.0753, weight:2.00, lr:0.0000
[07:20:01.371] iteration:14811  t-loss:0.2720, loss-lb:0.1329, loss-ulb:0.0696, weight:2.00, lr:0.0000
[07:20:01.680] iteration:14812  t-loss:0.6347, loss-lb:0.2221, loss-ulb:0.2063, weight:2.00, lr:0.0000
[07:20:01.998] iteration:14813  t-loss:0.2146, loss-lb:0.1363, loss-ulb:0.0392, weight:2.00, lr:0.0000
[07:20:02.313] iteration:14814  t-loss:0.2217, loss-lb:0.1979, loss-ulb:0.0119, weight:2.00, lr:0.0000
[07:20:02.631] iteration:14815  t-loss:0.4028, loss-lb:0.2812, loss-ulb:0.0608, weight:2.00, lr:0.0000
[07:20:02.947] iteration:14816  t-loss:0.2742, loss-lb:0.1769, loss-ulb:0.0487, weight:2.00, lr:0.0000
[07:20:03.262] iteration:14817  t-loss:0.2618, loss-lb:0.1502, loss-ulb:0.0558, weight:2.00, lr:0.0000
[07:20:03.574] iteration:14818  t-loss:0.2976, loss-lb:0.1120, loss-ulb:0.0928, weight:2.00, lr:0.0000
[07:20:03.886] iteration:14819  t-loss:0.2464, loss-lb:0.1731, loss-ulb:0.0366, weight:2.00, lr:0.0000
[07:20:04.200] iteration:14820  t-loss:0.3652, loss-lb:0.1950, loss-ulb:0.0851, weight:2.00, lr:0.0000
[07:20:04.512] iteration:14821  t-loss:0.2936, loss-lb:0.1452, loss-ulb:0.0742, weight:2.00, lr:0.0000
[07:20:04.825] iteration:14822  t-loss:0.3578, loss-lb:0.1236, loss-ulb:0.1171, weight:2.00, lr:0.0000
[07:20:05.137] iteration:14823  t-loss:0.3079, loss-lb:0.1926, loss-ulb:0.0577, weight:2.00, lr:0.0000
[07:20:05.450] iteration:14824  t-loss:0.3012, loss-lb:0.1431, loss-ulb:0.0790, weight:2.00, lr:0.0000
[07:20:05.763] iteration:14825  t-loss:0.2446, loss-lb:0.1981, loss-ulb:0.0232, weight:2.00, lr:0.0000
[07:21:59.994] iteration 14825 : dice_score: 0.849899 best_dice: 0.854000
[07:21:59.994]  <<Test>> - Ep:592  - Dice-S/T:85.12/84.99, Best-S:85.59, Best-T:85.40
[07:21:59.994]           - AvgLoss(lb/ulb/all):0.18/0.07/0.30
[07:22:01.188] iteration:14826  t-loss:0.3039, loss-lb:0.1870, loss-ulb:0.0585, weight:2.00, lr:0.0000
[07:22:01.516] iteration:14827  t-loss:0.2441, loss-lb:0.1593, loss-ulb:0.0424, weight:2.00, lr:0.0000
[07:22:01.833] iteration:14828  t-loss:0.2379, loss-lb:0.1587, loss-ulb:0.0396, weight:2.00, lr:0.0000
[07:22:02.147] iteration:14829  t-loss:0.3217, loss-lb:0.1278, loss-ulb:0.0969, weight:2.00, lr:0.0000
[07:22:02.462] iteration:14830  t-loss:0.1360, loss-lb:0.1056, loss-ulb:0.0152, weight:2.00, lr:0.0000
[07:22:02.774] iteration:14831  t-loss:0.4550, loss-lb:0.1638, loss-ulb:0.1456, weight:2.00, lr:0.0000
[07:22:03.087] iteration:14832  t-loss:0.3108, loss-lb:0.1844, loss-ulb:0.0632, weight:2.00, lr:0.0000
[07:22:03.401] iteration:14833  t-loss:0.1917, loss-lb:0.1321, loss-ulb:0.0298, weight:2.00, lr:0.0000
[07:22:03.716] iteration:14834  t-loss:0.2053, loss-lb:0.1538, loss-ulb:0.0257, weight:2.00, lr:0.0000
[07:22:04.031] iteration:14835  t-loss:0.3914, loss-lb:0.1981, loss-ulb:0.0967, weight:2.00, lr:0.0000
[07:22:04.347] iteration:14836  t-loss:0.2335, loss-lb:0.1339, loss-ulb:0.0498, weight:2.00, lr:0.0000
[07:22:04.665] iteration:14837  t-loss:0.3322, loss-lb:0.1276, loss-ulb:0.1023, weight:2.00, lr:0.0000
[07:22:04.985] iteration:14838  t-loss:0.2825, loss-lb:0.1567, loss-ulb:0.0629, weight:2.00, lr:0.0000
[07:22:05.306] iteration:14839  t-loss:0.3318, loss-lb:0.1136, loss-ulb:0.1091, weight:2.00, lr:0.0000
[07:22:05.630] iteration:14840  t-loss:0.1539, loss-lb:0.1262, loss-ulb:0.0139, weight:2.00, lr:0.0000
[07:22:05.956] iteration:14841  t-loss:0.1595, loss-lb:0.1200, loss-ulb:0.0198, weight:2.00, lr:0.0000
[07:22:06.277] iteration:14842  t-loss:0.1713, loss-lb:0.1411, loss-ulb:0.0151, weight:2.00, lr:0.0000
[07:22:06.595] iteration:14843  t-loss:0.4391, loss-lb:0.2018, loss-ulb:0.1187, weight:2.00, lr:0.0000
[07:22:06.910] iteration:14844  t-loss:0.2014, loss-lb:0.1232, loss-ulb:0.0391, weight:2.00, lr:0.0000
[07:22:07.225] iteration:14845  t-loss:0.4728, loss-lb:0.1989, loss-ulb:0.1369, weight:2.00, lr:0.0000
[07:22:07.538] iteration:14846  t-loss:0.5975, loss-lb:0.1576, loss-ulb:0.2200, weight:2.00, lr:0.0000
[07:22:07.849] iteration:14847  t-loss:0.1478, loss-lb:0.1024, loss-ulb:0.0227, weight:2.00, lr:0.0000
[07:22:08.163] iteration:14848  t-loss:0.1938, loss-lb:0.1684, loss-ulb:0.0127, weight:2.00, lr:0.0000
[07:22:08.476] iteration:14849  t-loss:0.2429, loss-lb:0.2182, loss-ulb:0.0124, weight:2.00, lr:0.0000
[07:22:08.790] iteration:14850  t-loss:0.7150, loss-lb:0.1894, loss-ulb:0.2628, weight:2.00, lr:0.0000
[07:22:09.877] iteration:14851  t-loss:0.1636, loss-lb:0.1302, loss-ulb:0.0167, weight:2.00, lr:0.0000
[07:22:10.222] iteration:14852  t-loss:0.3853, loss-lb:0.2882, loss-ulb:0.0486, weight:2.00, lr:0.0000
[07:22:10.547] iteration:14853  t-loss:0.1864, loss-lb:0.1488, loss-ulb:0.0188, weight:2.00, lr:0.0000
[07:22:10.868] iteration:14854  t-loss:0.1436, loss-lb:0.1111, loss-ulb:0.0163, weight:2.00, lr:0.0000
[07:22:11.184] iteration:14855  t-loss:0.2010, loss-lb:0.1766, loss-ulb:0.0122, weight:2.00, lr:0.0000
[07:22:11.503] iteration:14856  t-loss:0.3326, loss-lb:0.1121, loss-ulb:0.1102, weight:2.00, lr:0.0000
[07:22:11.818] iteration:14857  t-loss:0.1585, loss-lb:0.1240, loss-ulb:0.0172, weight:2.00, lr:0.0000
[07:22:12.134] iteration:14858  t-loss:0.2243, loss-lb:0.1034, loss-ulb:0.0604, weight:2.00, lr:0.0000
[07:22:12.450] iteration:14859  t-loss:0.2104, loss-lb:0.1874, loss-ulb:0.0115, weight:2.00, lr:0.0000
[07:22:12.766] iteration:14860  t-loss:0.2471, loss-lb:0.2051, loss-ulb:0.0210, weight:2.00, lr:0.0000
[07:22:13.081] iteration:14861  t-loss:0.1470, loss-lb:0.1129, loss-ulb:0.0171, weight:2.00, lr:0.0000
[07:22:13.397] iteration:14862  t-loss:0.3183, loss-lb:0.2336, loss-ulb:0.0423, weight:2.00, lr:0.0000
[07:22:13.709] iteration:14863  t-loss:0.1441, loss-lb:0.1139, loss-ulb:0.0151, weight:2.00, lr:0.0000
[07:22:14.023] iteration:14864  t-loss:0.2331, loss-lb:0.1328, loss-ulb:0.0502, weight:2.00, lr:0.0000
[07:22:14.339] iteration:14865  t-loss:0.2505, loss-lb:0.1320, loss-ulb:0.0593, weight:2.00, lr:0.0000
[07:22:14.653] iteration:14866  t-loss:0.3058, loss-lb:0.2102, loss-ulb:0.0478, weight:2.00, lr:0.0000
[07:22:14.967] iteration:14867  t-loss:0.2723, loss-lb:0.1308, loss-ulb:0.0707, weight:2.00, lr:0.0000
[07:22:15.279] iteration:14868  t-loss:0.3579, loss-lb:0.1380, loss-ulb:0.1099, weight:2.00, lr:0.0000
[07:22:15.592] iteration:14869  t-loss:0.3042, loss-lb:0.1615, loss-ulb:0.0713, weight:2.00, lr:0.0000
[07:22:15.907] iteration:14870  t-loss:0.2904, loss-lb:0.1864, loss-ulb:0.0520, weight:2.00, lr:0.0000
[07:22:16.221] iteration:14871  t-loss:0.1759, loss-lb:0.1516, loss-ulb:0.0121, weight:2.00, lr:0.0000
[07:22:16.534] iteration:14872  t-loss:0.2271, loss-lb:0.1629, loss-ulb:0.0321, weight:2.00, lr:0.0000
[07:22:16.845] iteration:14873  t-loss:0.1616, loss-lb:0.1319, loss-ulb:0.0148, weight:2.00, lr:0.0000
[07:22:17.159] iteration:14874  t-loss:0.2723, loss-lb:0.1360, loss-ulb:0.0681, weight:2.00, lr:0.0000
[07:22:17.472] iteration:14875  t-loss:0.2959, loss-lb:0.2064, loss-ulb:0.0447, weight:2.00, lr:0.0000
[07:22:18.811] iteration:14876  t-loss:0.3004, loss-lb:0.1495, loss-ulb:0.0755, weight:2.00, lr:0.0000
[07:22:19.137] iteration:14877  t-loss:0.2434, loss-lb:0.1233, loss-ulb:0.0601, weight:2.00, lr:0.0000
[07:22:19.458] iteration:14878  t-loss:0.2820, loss-lb:0.2576, loss-ulb:0.0122, weight:2.00, lr:0.0000
[07:22:19.779] iteration:14879  t-loss:0.2626, loss-lb:0.1931, loss-ulb:0.0347, weight:2.00, lr:0.0000
[07:22:20.104] iteration:14880  t-loss:0.3710, loss-lb:0.1974, loss-ulb:0.0868, weight:2.00, lr:0.0000
[07:22:20.418] iteration:14881  t-loss:0.1573, loss-lb:0.1242, loss-ulb:0.0166, weight:2.00, lr:0.0000
[07:22:20.736] iteration:14882  t-loss:0.2795, loss-lb:0.2436, loss-ulb:0.0179, weight:2.00, lr:0.0000
[07:22:21.052] iteration:14883  t-loss:0.2651, loss-lb:0.2212, loss-ulb:0.0220, weight:2.00, lr:0.0000
[07:22:21.371] iteration:14884  t-loss:0.3813, loss-lb:0.2094, loss-ulb:0.0859, weight:2.00, lr:0.0000
[07:22:21.686] iteration:14885  t-loss:0.2948, loss-lb:0.1272, loss-ulb:0.0838, weight:2.00, lr:0.0000
[07:22:21.998] iteration:14886  t-loss:0.1656, loss-lb:0.1265, loss-ulb:0.0196, weight:2.00, lr:0.0000
[07:22:22.316] iteration:14887  t-loss:0.1895, loss-lb:0.1359, loss-ulb:0.0268, weight:2.00, lr:0.0000
[07:22:22.634] iteration:14888  t-loss:0.3073, loss-lb:0.1816, loss-ulb:0.0629, weight:2.00, lr:0.0000
[07:22:22.947] iteration:14889  t-loss:0.2596, loss-lb:0.2328, loss-ulb:0.0134, weight:2.00, lr:0.0000
[07:22:23.265] iteration:14890  t-loss:0.1695, loss-lb:0.1433, loss-ulb:0.0131, weight:2.00, lr:0.0000
[07:22:23.581] iteration:14891  t-loss:0.2123, loss-lb:0.1778, loss-ulb:0.0172, weight:2.00, lr:0.0000
[07:22:23.901] iteration:14892  t-loss:0.2385, loss-lb:0.1247, loss-ulb:0.0569, weight:2.00, lr:0.0000
[07:22:24.215] iteration:14893  t-loss:0.2170, loss-lb:0.1764, loss-ulb:0.0203, weight:2.00, lr:0.0000
[07:22:24.530] iteration:14894  t-loss:0.2894, loss-lb:0.1432, loss-ulb:0.0731, weight:2.00, lr:0.0000
[07:22:24.845] iteration:14895  t-loss:0.2534, loss-lb:0.1495, loss-ulb:0.0519, weight:2.00, lr:0.0000
[07:22:25.162] iteration:14896  t-loss:0.2877, loss-lb:0.1138, loss-ulb:0.0870, weight:2.00, lr:0.0000
[07:22:25.477] iteration:14897  t-loss:0.2199, loss-lb:0.1985, loss-ulb:0.0107, weight:2.00, lr:0.0000
[07:22:25.791] iteration:14898  t-loss:0.2185, loss-lb:0.1896, loss-ulb:0.0145, weight:2.00, lr:0.0000
[07:22:26.104] iteration:14899  t-loss:0.1961, loss-lb:0.1635, loss-ulb:0.0163, weight:2.00, lr:0.0000
[07:22:26.423] iteration:14900  t-loss:0.3377, loss-lb:0.1593, loss-ulb:0.0892, weight:2.00, lr:0.0000
[07:22:27.783] iteration:14901  t-loss:1.0853, loss-lb:0.1310, loss-ulb:0.4772, weight:2.00, lr:0.0000
[07:22:28.116] iteration:14902  t-loss:0.2919, loss-lb:0.2288, loss-ulb:0.0315, weight:2.00, lr:0.0000
[07:22:28.439] iteration:14903  t-loss:0.3493, loss-lb:0.1979, loss-ulb:0.0757, weight:2.00, lr:0.0000
[07:22:28.759] iteration:14904  t-loss:0.2343, loss-lb:0.2007, loss-ulb:0.0168, weight:2.00, lr:0.0000
[07:22:29.078] iteration:14905  t-loss:0.3114, loss-lb:0.1961, loss-ulb:0.0576, weight:2.00, lr:0.0000
[07:22:29.398] iteration:14906  t-loss:0.3027, loss-lb:0.1524, loss-ulb:0.0751, weight:2.00, lr:0.0000
[07:22:29.714] iteration:14907  t-loss:0.2014, loss-lb:0.1624, loss-ulb:0.0195, weight:2.00, lr:0.0000
[07:22:30.031] iteration:14908  t-loss:0.2396, loss-lb:0.2018, loss-ulb:0.0189, weight:2.00, lr:0.0000
[07:22:30.351] iteration:14909  t-loss:0.3370, loss-lb:0.1639, loss-ulb:0.0865, weight:2.00, lr:0.0000
[07:22:30.665] iteration:14910  t-loss:0.3402, loss-lb:0.1692, loss-ulb:0.0855, weight:2.00, lr:0.0000
[07:22:30.983] iteration:14911  t-loss:0.3539, loss-lb:0.1453, loss-ulb:0.1043, weight:2.00, lr:0.0000
[07:22:31.299] iteration:14912  t-loss:0.1498, loss-lb:0.1156, loss-ulb:0.0171, weight:2.00, lr:0.0000
[07:22:31.616] iteration:14913  t-loss:0.2563, loss-lb:0.1274, loss-ulb:0.0644, weight:2.00, lr:0.0000
[07:22:31.931] iteration:14914  t-loss:0.1911, loss-lb:0.1586, loss-ulb:0.0163, weight:2.00, lr:0.0000
[07:22:32.248] iteration:14915  t-loss:0.3386, loss-lb:0.2669, loss-ulb:0.0358, weight:2.00, lr:0.0000
[07:22:32.569] iteration:14916  t-loss:0.2530, loss-lb:0.1285, loss-ulb:0.0622, weight:2.00, lr:0.0000
[07:22:32.885] iteration:14917  t-loss:0.1842, loss-lb:0.1530, loss-ulb:0.0156, weight:2.00, lr:0.0000
[07:22:33.198] iteration:14918  t-loss:0.3761, loss-lb:0.2704, loss-ulb:0.0528, weight:2.00, lr:0.0000
[07:22:33.514] iteration:14919  t-loss:0.2955, loss-lb:0.1355, loss-ulb:0.0800, weight:2.00, lr:0.0000
[07:22:33.832] iteration:14920  t-loss:0.3715, loss-lb:0.2031, loss-ulb:0.0842, weight:2.00, lr:0.0000
[07:22:34.147] iteration:14921  t-loss:0.2735, loss-lb:0.1135, loss-ulb:0.0800, weight:2.00, lr:0.0000
[07:22:34.461] iteration:14922  t-loss:0.2778, loss-lb:0.1965, loss-ulb:0.0406, weight:2.00, lr:0.0000
[07:22:34.778] iteration:14923  t-loss:0.3616, loss-lb:0.1774, loss-ulb:0.0921, weight:2.00, lr:0.0000
[07:22:35.093] iteration:14924  t-loss:0.2771, loss-lb:0.1480, loss-ulb:0.0645, weight:2.00, lr:0.0000
[07:22:35.410] iteration:14925  t-loss:0.2123, loss-lb:0.1865, loss-ulb:0.0129, weight:2.00, lr:0.0000
[07:24:28.894] iteration 14925 : dice_score: 0.850897 best_dice: 0.854000
[07:24:28.894]  <<Test>> - Ep:596  - Dice-S/T:85.11/85.09, Best-S:85.59, Best-T:85.40
[07:24:28.894]           - AvgLoss(lb/ulb/all):0.17/0.06/0.28
[07:24:29.995] iteration:14926  t-loss:0.1794, loss-lb:0.1531, loss-ulb:0.0131, weight:2.00, lr:0.0000
[07:24:30.326] iteration:14927  t-loss:0.4716, loss-lb:0.2108, loss-ulb:0.1304, weight:2.00, lr:0.0000
[07:24:30.647] iteration:14928  t-loss:0.2882, loss-lb:0.1960, loss-ulb:0.0461, weight:2.00, lr:0.0000
[07:24:30.972] iteration:14929  t-loss:0.2549, loss-lb:0.1937, loss-ulb:0.0306, weight:2.00, lr:0.0000
[07:24:31.286] iteration:14930  t-loss:0.2058, loss-lb:0.1233, loss-ulb:0.0412, weight:2.00, lr:0.0000
[07:24:31.605] iteration:14931  t-loss:0.2906, loss-lb:0.1711, loss-ulb:0.0597, weight:2.00, lr:0.0000
[07:24:31.925] iteration:14932  t-loss:0.3285, loss-lb:0.2919, loss-ulb:0.0183, weight:2.00, lr:0.0000
[07:24:32.243] iteration:14933  t-loss:0.2938, loss-lb:0.1272, loss-ulb:0.0833, weight:2.00, lr:0.0000
[07:24:32.563] iteration:14934  t-loss:0.2655, loss-lb:0.1526, loss-ulb:0.0565, weight:2.00, lr:0.0000
[07:24:32.880] iteration:14935  t-loss:0.4445, loss-lb:0.1754, loss-ulb:0.1345, weight:2.00, lr:0.0000
[07:24:33.200] iteration:14936  t-loss:0.3544, loss-lb:0.2361, loss-ulb:0.0592, weight:2.00, lr:0.0000
[07:24:33.517] iteration:14937  t-loss:0.3473, loss-lb:0.2080, loss-ulb:0.0696, weight:2.00, lr:0.0000
[07:24:33.836] iteration:14938  t-loss:0.2556, loss-lb:0.1655, loss-ulb:0.0451, weight:2.00, lr:0.0000
[07:24:34.155] iteration:14939  t-loss:0.4367, loss-lb:0.2499, loss-ulb:0.0934, weight:2.00, lr:0.0000
[07:24:34.486] iteration:14940  t-loss:0.2544, loss-lb:0.1352, loss-ulb:0.0596, weight:2.00, lr:0.0000
[07:24:34.805] iteration:14941  t-loss:0.4014, loss-lb:0.2810, loss-ulb:0.0602, weight:2.00, lr:0.0000
[07:24:35.124] iteration:14942  t-loss:0.1945, loss-lb:0.1717, loss-ulb:0.0114, weight:2.00, lr:0.0000
[07:24:35.436] iteration:14943  t-loss:0.1732, loss-lb:0.1519, loss-ulb:0.0106, weight:2.00, lr:0.0000
[07:24:35.753] iteration:14944  t-loss:0.3269, loss-lb:0.2258, loss-ulb:0.0506, weight:2.00, lr:0.0000
[07:24:36.068] iteration:14945  t-loss:0.4381, loss-lb:0.2380, loss-ulb:0.1000, weight:2.00, lr:0.0000
[07:24:36.384] iteration:14946  t-loss:0.2159, loss-lb:0.1933, loss-ulb:0.0113, weight:2.00, lr:0.0000
[07:24:36.699] iteration:14947  t-loss:0.2792, loss-lb:0.2476, loss-ulb:0.0158, weight:2.00, lr:0.0000
[07:24:37.014] iteration:14948  t-loss:0.2807, loss-lb:0.1440, loss-ulb:0.0684, weight:2.00, lr:0.0000
[07:24:37.330] iteration:14949  t-loss:0.1778, loss-lb:0.1450, loss-ulb:0.0164, weight:2.00, lr:0.0000
[07:24:37.645] iteration:14950  t-loss:0.2669, loss-lb:0.1289, loss-ulb:0.0690, weight:2.00, lr:0.0000
[07:24:38.849] iteration:14951  t-loss:0.1815, loss-lb:0.1405, loss-ulb:0.0205, weight:2.00, lr:0.0000
[07:24:39.177] iteration:14952  t-loss:0.3455, loss-lb:0.1414, loss-ulb:0.1021, weight:2.00, lr:0.0000
[07:24:39.503] iteration:14953  t-loss:0.4319, loss-lb:0.1732, loss-ulb:0.1294, weight:2.00, lr:0.0000
[07:24:39.822] iteration:14954  t-loss:0.2941, loss-lb:0.1670, loss-ulb:0.0635, weight:2.00, lr:0.0000
[07:24:40.151] iteration:14955  t-loss:0.2163, loss-lb:0.1904, loss-ulb:0.0130, weight:2.00, lr:0.0000
[07:24:40.483] iteration:14956  t-loss:0.2931, loss-lb:0.1970, loss-ulb:0.0481, weight:2.00, lr:0.0000
[07:24:40.812] iteration:14957  t-loss:0.2628, loss-lb:0.1331, loss-ulb:0.0648, weight:2.00, lr:0.0000
[07:24:41.153] iteration:14958  t-loss:0.2146, loss-lb:0.1763, loss-ulb:0.0191, weight:2.00, lr:0.0000
[07:24:41.485] iteration:14959  t-loss:0.2157, loss-lb:0.1319, loss-ulb:0.0419, weight:2.00, lr:0.0000
[07:24:41.821] iteration:14960  t-loss:0.3478, loss-lb:0.2333, loss-ulb:0.0573, weight:2.00, lr:0.0000
[07:24:42.147] iteration:14961  t-loss:0.1754, loss-lb:0.1467, loss-ulb:0.0143, weight:2.00, lr:0.0000
[07:24:42.467] iteration:14962  t-loss:0.3205, loss-lb:0.1854, loss-ulb:0.0676, weight:2.00, lr:0.0000
[07:24:42.787] iteration:14963  t-loss:0.2733, loss-lb:0.1978, loss-ulb:0.0377, weight:2.00, lr:0.0000
[07:24:43.109] iteration:14964  t-loss:0.3071, loss-lb:0.1843, loss-ulb:0.0614, weight:2.00, lr:0.0000
[07:24:43.429] iteration:14965  t-loss:0.3551, loss-lb:0.2596, loss-ulb:0.0477, weight:2.00, lr:0.0000
[07:24:43.748] iteration:14966  t-loss:0.2529, loss-lb:0.1457, loss-ulb:0.0536, weight:2.00, lr:0.0000
[07:24:44.064] iteration:14967  t-loss:0.1828, loss-lb:0.1417, loss-ulb:0.0205, weight:2.00, lr:0.0000
[07:24:44.378] iteration:14968  t-loss:0.1693, loss-lb:0.1357, loss-ulb:0.0168, weight:2.00, lr:0.0000
[07:24:44.692] iteration:14969  t-loss:0.4314, loss-lb:0.1400, loss-ulb:0.1457, weight:2.00, lr:0.0000
[07:24:45.007] iteration:14970  t-loss:0.2556, loss-lb:0.1520, loss-ulb:0.0518, weight:2.00, lr:0.0000
[07:24:45.323] iteration:14971  t-loss:0.2798, loss-lb:0.1819, loss-ulb:0.0490, weight:2.00, lr:0.0000
[07:24:45.638] iteration:14972  t-loss:0.2695, loss-lb:0.1539, loss-ulb:0.0578, weight:2.00, lr:0.0000
[07:24:45.952] iteration:14973  t-loss:0.2605, loss-lb:0.2032, loss-ulb:0.0286, weight:2.00, lr:0.0000
[07:24:46.263] iteration:14974  t-loss:0.1836, loss-lb:0.1557, loss-ulb:0.0139, weight:2.00, lr:0.0000
[07:24:46.576] iteration:14975  t-loss:0.3145, loss-lb:0.1546, loss-ulb:0.0800, weight:2.00, lr:0.0000
[07:24:47.696] iteration:14976  t-loss:0.2091, loss-lb:0.1866, loss-ulb:0.0113, weight:2.00, lr:0.0000
[07:24:48.038] iteration:14977  t-loss:0.3014, loss-lb:0.1759, loss-ulb:0.0627, weight:2.00, lr:0.0000
[07:24:48.362] iteration:14978  t-loss:0.1370, loss-lb:0.1128, loss-ulb:0.0121, weight:2.00, lr:0.0000
[07:24:48.684] iteration:14979  t-loss:0.2700, loss-lb:0.1299, loss-ulb:0.0701, weight:2.00, lr:0.0000
[07:24:49.010] iteration:14980  t-loss:0.2365, loss-lb:0.1366, loss-ulb:0.0500, weight:2.00, lr:0.0000
[07:24:49.336] iteration:14981  t-loss:0.2015, loss-lb:0.1710, loss-ulb:0.0153, weight:2.00, lr:0.0000
[07:24:49.667] iteration:14982  t-loss:0.3735, loss-lb:0.1885, loss-ulb:0.0925, weight:2.00, lr:0.0000
[07:24:50.010] iteration:14983  t-loss:0.2547, loss-lb:0.1546, loss-ulb:0.0501, weight:2.00, lr:0.0000
[07:24:50.338] iteration:14984  t-loss:0.1562, loss-lb:0.1222, loss-ulb:0.0170, weight:2.00, lr:0.0000
[07:24:50.671] iteration:14985  t-loss:0.2457, loss-lb:0.2032, loss-ulb:0.0212, weight:2.00, lr:0.0000
[07:24:50.999] iteration:14986  t-loss:0.3439, loss-lb:0.1787, loss-ulb:0.0826, weight:2.00, lr:0.0000
[07:24:51.321] iteration:14987  t-loss:0.2703, loss-lb:0.1486, loss-ulb:0.0608, weight:2.00, lr:0.0000
[07:24:51.640] iteration:14988  t-loss:0.1585, loss-lb:0.1342, loss-ulb:0.0122, weight:2.00, lr:0.0000
[07:24:51.958] iteration:14989  t-loss:0.1881, loss-lb:0.1027, loss-ulb:0.0427, weight:2.00, lr:0.0000
[07:24:52.276] iteration:14990  t-loss:0.3382, loss-lb:0.2075, loss-ulb:0.0654, weight:2.00, lr:0.0000
[07:24:52.597] iteration:14991  t-loss:0.4037, loss-lb:0.2738, loss-ulb:0.0649, weight:2.00, lr:0.0000
[07:24:52.916] iteration:14992  t-loss:0.1915, loss-lb:0.1430, loss-ulb:0.0243, weight:2.00, lr:0.0000
[07:24:53.232] iteration:14993  t-loss:0.2084, loss-lb:0.1711, loss-ulb:0.0186, weight:2.00, lr:0.0000
[07:24:53.549] iteration:14994  t-loss:0.3382, loss-lb:0.1475, loss-ulb:0.0954, weight:2.00, lr:0.0000
[07:24:53.867] iteration:14995  t-loss:0.3969, loss-lb:0.2920, loss-ulb:0.0525, weight:2.00, lr:0.0000
[07:24:54.195] iteration:14996  t-loss:0.3906, loss-lb:0.1337, loss-ulb:0.1284, weight:2.00, lr:0.0000
[07:24:54.511] iteration:14997  t-loss:0.2888, loss-lb:0.1582, loss-ulb:0.0653, weight:2.00, lr:0.0000
[07:24:54.826] iteration:14998  t-loss:0.1668, loss-lb:0.1431, loss-ulb:0.0119, weight:2.00, lr:0.0000
[07:24:55.143] iteration:14999  t-loss:0.4290, loss-lb:0.2198, loss-ulb:0.1046, weight:2.00, lr:0.0000
[07:24:55.457] iteration:15000  t-loss:0.3436, loss-lb:0.1599, loss-ulb:0.0918, weight:2.00, lr:0.0000
[07:26:46.293] iteration 15000 : dice_score: 0.850097 best_dice: 0.854000
[07:26:46.293]  <<Test>> - Ep:599  - Dice-S/T:84.99/85.01, Best-S:85.59, Best-T:85.40
[07:26:46.293]           - AvgLoss(lb/ulb/all):0.17/0.06/0.28
[07:26:46.337] save model to ./results/Pancreas/Pancrease_base/vbase2_12_labeled/vnet_hsseg/last.pth
