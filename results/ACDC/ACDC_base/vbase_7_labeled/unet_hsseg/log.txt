[10:47:18.515] {'base_lr': 0.001,
 'batch_size': 24,
 'cfg': 'config_2d_aut.yml',
 'consistency': 2.0,
 'consistency_rampup': 50,
 'deterministic': False,
 'ema_decay': 0.99,
 'exp': 'ACDC_base/vbase',
 'flag_pseudo_from_student': False,
 'gpu_id': 0,
 'labeled_bs': 12,
 'labeled_num': 7,
 'max_iterations': 30000,
 'model': 'unet_hsseg',
 'num_classes': 4,
 'patch_size': [256, 256],
 'poly': True,
 'res_path': './results/ACDC',
 'root_path': '/home/chenyu/SSMIS/data/ACDC',
 'save_interval_epoch': 1000000,
 'seed': 2025,
 'test_interval_ep': 2,
 'weight_his': 0.4}
[10:47:18.986] Total silices is: 1312, labeled slices is: 136
[10:47:18.986] 98 iterations per epoch
[10:47:20.621] iteration:1  t-loss:4.6062, loss-lb:4.6062, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:20.726] iteration:2  t-loss:3.8952, loss-lb:3.8952, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:20.825] iteration:3  t-loss:3.3100, loss-lb:3.3100, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:20.924] iteration:4  t-loss:2.9433, loss-lb:2.9433, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.021] iteration:5  t-loss:2.6313, loss-lb:2.6313, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.120] iteration:6  t-loss:2.5062, loss-lb:2.5062, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.219] iteration:7  t-loss:2.3684, loss-lb:2.3684, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.319] iteration:8  t-loss:2.2484, loss-lb:2.2484, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.420] iteration:9  t-loss:2.1456, loss-lb:2.1456, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.522] iteration:10  t-loss:2.0656, loss-lb:2.0656, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.622] iteration:11  t-loss:2.1279, loss-lb:2.1279, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.720] iteration:12  t-loss:1.9861, loss-lb:1.9861, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.820] iteration:13  t-loss:1.9875, loss-lb:1.9875, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:21.923] iteration:14  t-loss:1.9713, loss-lb:1.9713, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.025] iteration:15  t-loss:2.0318, loss-lb:2.0318, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.124] iteration:16  t-loss:1.7980, loss-lb:1.7980, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.223] iteration:17  t-loss:1.7215, loss-lb:1.7215, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.323] iteration:18  t-loss:1.6900, loss-lb:1.6900, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.424] iteration:19  t-loss:1.7932, loss-lb:1.7932, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.522] iteration:20  t-loss:1.5888, loss-lb:1.5888, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.620] iteration:21  t-loss:1.5983, loss-lb:1.5983, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.718] iteration:22  t-loss:1.6156, loss-lb:1.6156, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.818] iteration:23  t-loss:1.5236, loss-lb:1.5236, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:22.916] iteration:24  t-loss:1.6148, loss-lb:1.6148, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.018] iteration:25  t-loss:1.4369, loss-lb:1.4369, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.119] iteration:26  t-loss:1.4667, loss-lb:1.4667, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.221] iteration:27  t-loss:1.3217, loss-lb:1.3217, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.322] iteration:28  t-loss:1.3099, loss-lb:1.3099, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.420] iteration:29  t-loss:1.5005, loss-lb:1.5005, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.519] iteration:30  t-loss:1.2336, loss-lb:1.2336, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.623] iteration:31  t-loss:1.3021, loss-lb:1.3021, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.722] iteration:32  t-loss:1.5215, loss-lb:1.5215, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.820] iteration:33  t-loss:1.3914, loss-lb:1.3914, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:23.921] iteration:34  t-loss:1.4691, loss-lb:1.4691, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.021] iteration:35  t-loss:1.4189, loss-lb:1.4189, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.119] iteration:36  t-loss:1.2712, loss-lb:1.2712, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.220] iteration:37  t-loss:1.1938, loss-lb:1.1938, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.322] iteration:38  t-loss:1.1172, loss-lb:1.1172, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.424] iteration:39  t-loss:1.2236, loss-lb:1.2236, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.524] iteration:40  t-loss:1.2252, loss-lb:1.2252, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.624] iteration:41  t-loss:1.1937, loss-lb:1.1937, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.725] iteration:42  t-loss:1.1166, loss-lb:1.1166, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.826] iteration:43  t-loss:1.2233, loss-lb:1.2233, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:24.927] iteration:44  t-loss:1.1307, loss-lb:1.1307, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.027] iteration:45  t-loss:1.1904, loss-lb:1.1904, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.128] iteration:46  t-loss:1.2893, loss-lb:1.2893, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.231] iteration:47  t-loss:1.1945, loss-lb:1.1945, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.333] iteration:48  t-loss:1.1800, loss-lb:1.1800, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.433] iteration:49  t-loss:1.2064, loss-lb:1.2064, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.539] iteration:50  t-loss:1.1032, loss-lb:1.1032, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.643] iteration:51  t-loss:1.1215, loss-lb:1.1215, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.746] iteration:52  t-loss:1.0033, loss-lb:1.0033, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.847] iteration:53  t-loss:1.1479, loss-lb:1.1479, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:25.951] iteration:54  t-loss:1.1407, loss-lb:1.1407, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.058] iteration:55  t-loss:1.0143, loss-lb:1.0143, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.161] iteration:56  t-loss:1.2291, loss-lb:1.2291, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.264] iteration:57  t-loss:0.9867, loss-lb:0.9867, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.367] iteration:58  t-loss:0.9140, loss-lb:0.9140, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.471] iteration:59  t-loss:0.9931, loss-lb:0.9931, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.574] iteration:60  t-loss:1.0265, loss-lb:1.0265, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.676] iteration:61  t-loss:0.9377, loss-lb:0.9377, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.778] iteration:62  t-loss:1.1225, loss-lb:1.1225, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.881] iteration:63  t-loss:0.8907, loss-lb:0.8907, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:26.982] iteration:64  t-loss:1.1149, loss-lb:1.1149, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.086] iteration:65  t-loss:1.0632, loss-lb:1.0632, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.190] iteration:66  t-loss:1.0328, loss-lb:1.0328, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.294] iteration:67  t-loss:1.0722, loss-lb:1.0722, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.398] iteration:68  t-loss:1.0870, loss-lb:1.0870, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.499] iteration:69  t-loss:0.9678, loss-lb:0.9678, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.602] iteration:70  t-loss:0.9036, loss-lb:0.9036, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.705] iteration:71  t-loss:0.9283, loss-lb:0.9283, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.807] iteration:72  t-loss:0.9742, loss-lb:0.9742, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:27.909] iteration:73  t-loss:1.0802, loss-lb:1.0802, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.012] iteration:74  t-loss:0.9835, loss-lb:0.9835, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.117] iteration:75  t-loss:0.8812, loss-lb:0.8812, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.219] iteration:76  t-loss:1.0930, loss-lb:1.0930, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.322] iteration:77  t-loss:0.9204, loss-lb:0.9204, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.425] iteration:78  t-loss:0.8360, loss-lb:0.8360, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.530] iteration:79  t-loss:1.0792, loss-lb:1.0792, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.632] iteration:80  t-loss:0.9309, loss-lb:0.9309, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.736] iteration:81  t-loss:0.9142, loss-lb:0.9142, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.841] iteration:82  t-loss:1.0780, loss-lb:1.0780, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:28.944] iteration:83  t-loss:0.7854, loss-lb:0.7854, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.048] iteration:84  t-loss:0.9060, loss-lb:0.9060, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.151] iteration:85  t-loss:0.8586, loss-lb:0.8586, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.255] iteration:86  t-loss:1.0999, loss-lb:1.0999, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.360] iteration:87  t-loss:0.9130, loss-lb:0.9130, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.463] iteration:88  t-loss:0.8832, loss-lb:0.8832, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.566] iteration:89  t-loss:0.8508, loss-lb:0.8508, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.671] iteration:90  t-loss:0.9407, loss-lb:0.9407, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.776] iteration:91  t-loss:1.0005, loss-lb:1.0005, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.877] iteration:92  t-loss:0.8314, loss-lb:0.8314, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:29.978] iteration:93  t-loss:0.7616, loss-lb:0.7616, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:30.079] iteration:94  t-loss:0.8947, loss-lb:0.8947, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:30.180] iteration:95  t-loss:0.9066, loss-lb:0.9066, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:30.282] iteration:96  t-loss:0.7968, loss-lb:0.7968, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:30.383] iteration:97  t-loss:0.8249, loss-lb:0.8249, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:30.485] iteration:98  t-loss:0.7703, loss-lb:0.7703, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:41.339]  <<Test>> - Ep:0  - mean_dice/mean_h95 - S:55.42/39.07, Best-S:55.42, T:48.42/20.58, Best-T:48.42
[10:47:41.339]           - AvgLoss(lb/ulb/all):1.3622/0.0000/0.9013
[10:47:41.777] iteration:99  t-loss:0.7970, loss-lb:0.7970, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:41.884] iteration:100  t-loss:0.7681, loss-lb:0.7681, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:41.990] iteration:101  t-loss:0.6722, loss-lb:0.6722, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.093] iteration:102  t-loss:0.6562, loss-lb:0.6562, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.196] iteration:103  t-loss:0.6511, loss-lb:0.6511, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.301] iteration:104  t-loss:0.9556, loss-lb:0.9556, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.405] iteration:105  t-loss:0.6164, loss-lb:0.6164, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.511] iteration:106  t-loss:0.7412, loss-lb:0.7412, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.617] iteration:107  t-loss:0.8936, loss-lb:0.8936, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.722] iteration:108  t-loss:0.8725, loss-lb:0.8725, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.825] iteration:109  t-loss:0.9089, loss-lb:0.9089, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:42.929] iteration:110  t-loss:0.7598, loss-lb:0.7598, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.032] iteration:111  t-loss:0.5521, loss-lb:0.5521, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.138] iteration:112  t-loss:0.7067, loss-lb:0.7067, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.243] iteration:113  t-loss:0.5514, loss-lb:0.5514, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.348] iteration:114  t-loss:0.5975, loss-lb:0.5975, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.452] iteration:115  t-loss:0.6702, loss-lb:0.6702, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.557] iteration:116  t-loss:0.7111, loss-lb:0.7111, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.662] iteration:117  t-loss:0.9315, loss-lb:0.9315, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.767] iteration:118  t-loss:0.5357, loss-lb:0.5357, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.872] iteration:119  t-loss:0.7413, loss-lb:0.7413, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:43.978] iteration:120  t-loss:0.5706, loss-lb:0.5706, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.082] iteration:121  t-loss:0.6531, loss-lb:0.6531, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.187] iteration:122  t-loss:0.5172, loss-lb:0.5172, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.290] iteration:123  t-loss:0.4975, loss-lb:0.4975, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.394] iteration:124  t-loss:0.6395, loss-lb:0.6395, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.500] iteration:125  t-loss:0.7468, loss-lb:0.7468, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.605] iteration:126  t-loss:0.5214, loss-lb:0.5214, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.709] iteration:127  t-loss:0.4834, loss-lb:0.4834, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.814] iteration:128  t-loss:0.6162, loss-lb:0.6162, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:44.921] iteration:129  t-loss:0.6710, loss-lb:0.6710, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.025] iteration:130  t-loss:0.6064, loss-lb:0.6064, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.134] iteration:131  t-loss:0.6429, loss-lb:0.6429, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.241] iteration:132  t-loss:0.7517, loss-lb:0.7517, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.345] iteration:133  t-loss:0.6417, loss-lb:0.6417, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.448] iteration:134  t-loss:0.6227, loss-lb:0.6227, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.554] iteration:135  t-loss:0.4797, loss-lb:0.4797, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.658] iteration:136  t-loss:0.8115, loss-lb:0.8115, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.764] iteration:137  t-loss:0.6384, loss-lb:0.6384, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.868] iteration:138  t-loss:0.4524, loss-lb:0.4524, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:45.974] iteration:139  t-loss:0.6285, loss-lb:0.6285, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.078] iteration:140  t-loss:0.5654, loss-lb:0.5654, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.183] iteration:141  t-loss:0.4682, loss-lb:0.4682, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.289] iteration:142  t-loss:0.5072, loss-lb:0.5072, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.394] iteration:143  t-loss:0.7015, loss-lb:0.7015, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.499] iteration:144  t-loss:0.6231, loss-lb:0.6231, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.604] iteration:145  t-loss:0.5555, loss-lb:0.5555, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.709] iteration:146  t-loss:0.4285, loss-lb:0.4285, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.813] iteration:147  t-loss:0.4150, loss-lb:0.4150, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:46.918] iteration:148  t-loss:0.5791, loss-lb:0.5791, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:47.024] iteration:149  t-loss:0.4918, loss-lb:0.4918, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:47.129] iteration:150  t-loss:0.5701, loss-lb:0.5701, loss-ulb:0.0000, weight:0.01, lr:0.0010
[10:47:47.233] iteration:151  t-loss:0.6796, loss-lb:0.6796, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:47.337] iteration:152  t-loss:0.5518, loss-lb:0.5518, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:47.444] iteration:153  t-loss:0.6125, loss-lb:0.6125, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:47.550] iteration:154  t-loss:0.6122, loss-lb:0.6122, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:47.653] iteration:155  t-loss:0.8074, loss-lb:0.8074, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:47.757] iteration:156  t-loss:0.5865, loss-lb:0.5865, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:47.862] iteration:157  t-loss:0.5186, loss-lb:0.5186, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:47.965] iteration:158  t-loss:0.4625, loss-lb:0.4625, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.071] iteration:159  t-loss:0.4526, loss-lb:0.4526, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.177] iteration:160  t-loss:0.4461, loss-lb:0.4461, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.282] iteration:161  t-loss:0.5124, loss-lb:0.5124, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.388] iteration:162  t-loss:0.5910, loss-lb:0.5910, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.494] iteration:163  t-loss:0.4334, loss-lb:0.4334, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.599] iteration:164  t-loss:0.5399, loss-lb:0.5399, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.705] iteration:165  t-loss:0.6201, loss-lb:0.6201, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.811] iteration:166  t-loss:0.5621, loss-lb:0.5621, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:48.915] iteration:167  t-loss:0.5530, loss-lb:0.5530, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.023] iteration:168  t-loss:0.3734, loss-lb:0.3734, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.129] iteration:169  t-loss:0.5418, loss-lb:0.5418, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.235] iteration:170  t-loss:0.4345, loss-lb:0.4345, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.341] iteration:171  t-loss:0.5811, loss-lb:0.5811, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.446] iteration:172  t-loss:0.5841, loss-lb:0.5841, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.552] iteration:173  t-loss:0.6196, loss-lb:0.6196, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.655] iteration:174  t-loss:0.5838, loss-lb:0.5838, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.761] iteration:175  t-loss:0.5628, loss-lb:0.5628, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.866] iteration:176  t-loss:0.6324, loss-lb:0.6324, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:49.971] iteration:177  t-loss:0.4703, loss-lb:0.4703, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.076] iteration:178  t-loss:0.4285, loss-lb:0.4285, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.182] iteration:179  t-loss:0.3172, loss-lb:0.3172, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.288] iteration:180  t-loss:0.6010, loss-lb:0.6010, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.392] iteration:181  t-loss:0.4326, loss-lb:0.4326, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.496] iteration:182  t-loss:0.6290, loss-lb:0.6290, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.599] iteration:183  t-loss:0.5155, loss-lb:0.5155, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.705] iteration:184  t-loss:0.3123, loss-lb:0.3123, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.811] iteration:185  t-loss:0.4458, loss-lb:0.4458, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:50.916] iteration:186  t-loss:0.6250, loss-lb:0.6250, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.019] iteration:187  t-loss:0.6849, loss-lb:0.6849, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.123] iteration:188  t-loss:0.3194, loss-lb:0.3194, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.229] iteration:189  t-loss:0.5173, loss-lb:0.5173, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.332] iteration:190  t-loss:0.5854, loss-lb:0.5854, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.434] iteration:191  t-loss:0.4807, loss-lb:0.4807, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.537] iteration:192  t-loss:0.3961, loss-lb:0.3961, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.639] iteration:193  t-loss:0.4677, loss-lb:0.4677, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.740] iteration:194  t-loss:0.4910, loss-lb:0.4910, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.841] iteration:195  t-loss:0.3788, loss-lb:0.3788, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:51.942] iteration:196  t-loss:0.5394, loss-lb:0.5394, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:52.431] iteration:197  t-loss:0.3190, loss-lb:0.3190, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:52.540] iteration:198  t-loss:0.4126, loss-lb:0.4126, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:52.647] iteration:199  t-loss:0.4600, loss-lb:0.4600, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:52.751] iteration:200  t-loss:0.3934, loss-lb:0.3934, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:52.856] iteration:201  t-loss:0.3784, loss-lb:0.3784, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:52.962] iteration:202  t-loss:0.4050, loss-lb:0.4050, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.067] iteration:203  t-loss:0.3858, loss-lb:0.3858, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.173] iteration:204  t-loss:0.4073, loss-lb:0.4073, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.279] iteration:205  t-loss:0.4211, loss-lb:0.4211, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.385] iteration:206  t-loss:0.4443, loss-lb:0.4443, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.490] iteration:207  t-loss:0.4223, loss-lb:0.4223, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.594] iteration:208  t-loss:0.4820, loss-lb:0.4820, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.699] iteration:209  t-loss:0.3084, loss-lb:0.3084, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.803] iteration:210  t-loss:0.3133, loss-lb:0.3133, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:53.908] iteration:211  t-loss:0.4841, loss-lb:0.4841, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.012] iteration:212  t-loss:0.3370, loss-lb:0.3370, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.116] iteration:213  t-loss:0.4520, loss-lb:0.4520, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.221] iteration:214  t-loss:0.3958, loss-lb:0.3958, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.328] iteration:215  t-loss:0.3454, loss-lb:0.3454, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.434] iteration:216  t-loss:0.3733, loss-lb:0.3733, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.538] iteration:217  t-loss:0.5522, loss-lb:0.5522, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.644] iteration:218  t-loss:0.4149, loss-lb:0.4149, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.750] iteration:219  t-loss:0.3783, loss-lb:0.3783, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.855] iteration:220  t-loss:0.3454, loss-lb:0.3454, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:54.960] iteration:221  t-loss:0.4297, loss-lb:0.4297, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.064] iteration:222  t-loss:0.6534, loss-lb:0.6534, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.171] iteration:223  t-loss:0.3296, loss-lb:0.3296, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.275] iteration:224  t-loss:0.3946, loss-lb:0.3946, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.379] iteration:225  t-loss:0.4435, loss-lb:0.4435, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.483] iteration:226  t-loss:0.3828, loss-lb:0.3828, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.587] iteration:227  t-loss:0.4453, loss-lb:0.4453, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.693] iteration:228  t-loss:0.4231, loss-lb:0.4231, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.797] iteration:229  t-loss:0.3539, loss-lb:0.3539, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:55.903] iteration:230  t-loss:0.3862, loss-lb:0.3862, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.007] iteration:231  t-loss:0.4324, loss-lb:0.4324, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.113] iteration:232  t-loss:0.3155, loss-lb:0.3155, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.219] iteration:233  t-loss:0.3398, loss-lb:0.3398, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.324] iteration:234  t-loss:0.3291, loss-lb:0.3291, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.429] iteration:235  t-loss:0.4029, loss-lb:0.4029, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.535] iteration:236  t-loss:0.4133, loss-lb:0.4133, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.641] iteration:237  t-loss:0.4336, loss-lb:0.4336, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.746] iteration:238  t-loss:0.4099, loss-lb:0.4099, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.850] iteration:239  t-loss:0.5259, loss-lb:0.5259, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:56.956] iteration:240  t-loss:0.3917, loss-lb:0.3917, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.060] iteration:241  t-loss:0.3624, loss-lb:0.3624, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.165] iteration:242  t-loss:0.4868, loss-lb:0.4868, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.272] iteration:243  t-loss:0.3033, loss-lb:0.3033, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.377] iteration:244  t-loss:0.3268, loss-lb:0.3268, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.484] iteration:245  t-loss:0.6011, loss-lb:0.6011, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.588] iteration:246  t-loss:0.3007, loss-lb:0.3007, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.693] iteration:247  t-loss:0.3706, loss-lb:0.3706, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.798] iteration:248  t-loss:0.3816, loss-lb:0.3816, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:57.902] iteration:249  t-loss:0.3515, loss-lb:0.3515, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.009] iteration:250  t-loss:0.3247, loss-lb:0.3247, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.115] iteration:251  t-loss:0.2743, loss-lb:0.2743, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.218] iteration:252  t-loss:0.2934, loss-lb:0.2934, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.322] iteration:253  t-loss:0.3711, loss-lb:0.3711, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.428] iteration:254  t-loss:0.3258, loss-lb:0.3258, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.534] iteration:255  t-loss:0.3463, loss-lb:0.3463, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.639] iteration:256  t-loss:0.3027, loss-lb:0.3027, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.746] iteration:257  t-loss:0.2985, loss-lb:0.2985, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.849] iteration:258  t-loss:0.2431, loss-lb:0.2431, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:58.955] iteration:259  t-loss:0.3303, loss-lb:0.3303, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.062] iteration:260  t-loss:0.2996, loss-lb:0.2996, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.168] iteration:261  t-loss:0.2238, loss-lb:0.2238, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.273] iteration:262  t-loss:0.2779, loss-lb:0.2779, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.379] iteration:263  t-loss:0.3301, loss-lb:0.3301, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.486] iteration:264  t-loss:0.3670, loss-lb:0.3670, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.589] iteration:265  t-loss:0.3508, loss-lb:0.3508, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.694] iteration:266  t-loss:0.2923, loss-lb:0.2923, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.798] iteration:267  t-loss:0.2881, loss-lb:0.2881, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:47:59.904] iteration:268  t-loss:0.3483, loss-lb:0.3483, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.009] iteration:269  t-loss:0.3330, loss-lb:0.3330, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.114] iteration:270  t-loss:0.2740, loss-lb:0.2740, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.220] iteration:271  t-loss:0.2824, loss-lb:0.2824, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.325] iteration:272  t-loss:0.2664, loss-lb:0.2664, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.430] iteration:273  t-loss:0.4161, loss-lb:0.4161, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.534] iteration:274  t-loss:0.3025, loss-lb:0.3025, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.639] iteration:275  t-loss:0.2913, loss-lb:0.2913, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.744] iteration:276  t-loss:0.2969, loss-lb:0.2969, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.849] iteration:277  t-loss:0.4683, loss-lb:0.4683, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:00.953] iteration:278  t-loss:0.2551, loss-lb:0.2551, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.056] iteration:279  t-loss:0.3651, loss-lb:0.3651, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.163] iteration:280  t-loss:0.2612, loss-lb:0.2612, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.267] iteration:281  t-loss:0.2756, loss-lb:0.2756, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.371] iteration:282  t-loss:0.2374, loss-lb:0.2374, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.475] iteration:283  t-loss:0.2399, loss-lb:0.2399, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.580] iteration:284  t-loss:0.2460, loss-lb:0.2460, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.686] iteration:285  t-loss:0.3229, loss-lb:0.3229, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.790] iteration:286  t-loss:0.3977, loss-lb:0.3977, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.895] iteration:287  t-loss:0.3473, loss-lb:0.3473, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:01.997] iteration:288  t-loss:0.2428, loss-lb:0.2428, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:02.100] iteration:289  t-loss:0.2540, loss-lb:0.2540, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:02.202] iteration:290  t-loss:0.2642, loss-lb:0.2642, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:02.304] iteration:291  t-loss:0.4857, loss-lb:0.4857, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:02.405] iteration:292  t-loss:0.2481, loss-lb:0.2481, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:02.506] iteration:293  t-loss:0.2488, loss-lb:0.2488, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:02.607] iteration:294  t-loss:0.2508, loss-lb:0.2508, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:13.363]  <<Test>> - Ep:2  - mean_dice/mean_h95 - S:74.01/9.75, Best-S:74.01, T:75.11/8.50, Best-T:75.11
[10:48:13.363]           - AvgLoss(lb/ulb/all):0.3583/0.0000/0.3000
[10:48:13.771] iteration:295  t-loss:0.2919, loss-lb:0.2919, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:13.883] iteration:296  t-loss:0.2532, loss-lb:0.2532, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:13.991] iteration:297  t-loss:0.2905, loss-lb:0.2905, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.096] iteration:298  t-loss:0.4356, loss-lb:0.4356, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.204] iteration:299  t-loss:0.2729, loss-lb:0.2729, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.310] iteration:300  t-loss:0.3669, loss-lb:0.3669, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.415] iteration:301  t-loss:0.3104, loss-lb:0.3104, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.521] iteration:302  t-loss:0.2735, loss-lb:0.2735, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.628] iteration:303  t-loss:0.2684, loss-lb:0.2684, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.732] iteration:304  t-loss:0.3680, loss-lb:0.3680, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.838] iteration:305  t-loss:0.2209, loss-lb:0.2209, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:14.942] iteration:306  t-loss:0.2769, loss-lb:0.2769, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.046] iteration:307  t-loss:0.3526, loss-lb:0.3526, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.151] iteration:308  t-loss:0.3357, loss-lb:0.3357, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.258] iteration:309  t-loss:0.3274, loss-lb:0.3274, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.366] iteration:310  t-loss:0.3035, loss-lb:0.3035, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.470] iteration:311  t-loss:0.2697, loss-lb:0.2697, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.575] iteration:312  t-loss:0.2737, loss-lb:0.2737, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.681] iteration:313  t-loss:0.2865, loss-lb:0.2865, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.787] iteration:314  t-loss:0.3176, loss-lb:0.3176, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.892] iteration:315  t-loss:0.2700, loss-lb:0.2700, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:15.998] iteration:316  t-loss:0.2307, loss-lb:0.2307, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.103] iteration:317  t-loss:0.2979, loss-lb:0.2979, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.209] iteration:318  t-loss:0.3295, loss-lb:0.3295, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.315] iteration:319  t-loss:0.2528, loss-lb:0.2528, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.422] iteration:320  t-loss:0.2604, loss-lb:0.2604, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.528] iteration:321  t-loss:0.2458, loss-lb:0.2458, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.632] iteration:322  t-loss:0.3000, loss-lb:0.3000, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.736] iteration:323  t-loss:0.2639, loss-lb:0.2639, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.842] iteration:324  t-loss:0.2952, loss-lb:0.2952, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:16.947] iteration:325  t-loss:0.2734, loss-lb:0.2734, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.051] iteration:326  t-loss:0.2408, loss-lb:0.2408, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.155] iteration:327  t-loss:0.2226, loss-lb:0.2226, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.260] iteration:328  t-loss:0.2940, loss-lb:0.2940, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.363] iteration:329  t-loss:0.2651, loss-lb:0.2651, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.468] iteration:330  t-loss:0.2564, loss-lb:0.2564, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.574] iteration:331  t-loss:0.2421, loss-lb:0.2421, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.679] iteration:332  t-loss:0.2627, loss-lb:0.2627, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.785] iteration:333  t-loss:0.2553, loss-lb:0.2553, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.889] iteration:334  t-loss:0.2342, loss-lb:0.2342, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:17.994] iteration:335  t-loss:0.3458, loss-lb:0.3458, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.098] iteration:336  t-loss:0.2756, loss-lb:0.2756, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.203] iteration:337  t-loss:0.2569, loss-lb:0.2569, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.308] iteration:338  t-loss:0.3239, loss-lb:0.3239, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.411] iteration:339  t-loss:0.3220, loss-lb:0.3220, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.519] iteration:340  t-loss:0.2804, loss-lb:0.2804, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.624] iteration:341  t-loss:0.2157, loss-lb:0.2157, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.729] iteration:342  t-loss:0.2758, loss-lb:0.2758, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.833] iteration:343  t-loss:0.2625, loss-lb:0.2625, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:18.936] iteration:344  t-loss:0.2468, loss-lb:0.2468, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.044] iteration:345  t-loss:0.2517, loss-lb:0.2517, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.150] iteration:346  t-loss:0.2178, loss-lb:0.2178, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.253] iteration:347  t-loss:0.2341, loss-lb:0.2341, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.359] iteration:348  t-loss:0.2983, loss-lb:0.2983, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.465] iteration:349  t-loss:0.3275, loss-lb:0.3275, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.571] iteration:350  t-loss:0.3084, loss-lb:0.3084, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.675] iteration:351  t-loss:0.2968, loss-lb:0.2968, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.780] iteration:352  t-loss:0.2527, loss-lb:0.2527, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.886] iteration:353  t-loss:0.2434, loss-lb:0.2434, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:19.992] iteration:354  t-loss:0.2146, loss-lb:0.2146, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.098] iteration:355  t-loss:0.2606, loss-lb:0.2606, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.202] iteration:356  t-loss:0.2932, loss-lb:0.2932, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.308] iteration:357  t-loss:0.1728, loss-lb:0.1728, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.414] iteration:358  t-loss:0.2814, loss-lb:0.2814, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.521] iteration:359  t-loss:0.2321, loss-lb:0.2321, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.628] iteration:360  t-loss:0.2424, loss-lb:0.2424, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.734] iteration:361  t-loss:0.2854, loss-lb:0.2854, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.840] iteration:362  t-loss:0.2551, loss-lb:0.2551, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:20.944] iteration:363  t-loss:0.2441, loss-lb:0.2441, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.048] iteration:364  t-loss:0.2450, loss-lb:0.2450, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.152] iteration:365  t-loss:0.2539, loss-lb:0.2539, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.259] iteration:366  t-loss:0.2492, loss-lb:0.2492, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.365] iteration:367  t-loss:0.2612, loss-lb:0.2612, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.469] iteration:368  t-loss:0.2217, loss-lb:0.2217, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.575] iteration:369  t-loss:0.2266, loss-lb:0.2266, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.680] iteration:370  t-loss:0.2622, loss-lb:0.2622, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.785] iteration:371  t-loss:0.4194, loss-lb:0.4194, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.889] iteration:372  t-loss:0.2192, loss-lb:0.2192, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:21.994] iteration:373  t-loss:0.3364, loss-lb:0.3364, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.097] iteration:374  t-loss:0.2047, loss-lb:0.2047, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.202] iteration:375  t-loss:0.2167, loss-lb:0.2167, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.306] iteration:376  t-loss:0.2565, loss-lb:0.2565, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.411] iteration:377  t-loss:0.2608, loss-lb:0.2608, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.517] iteration:378  t-loss:0.2495, loss-lb:0.2495, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.621] iteration:379  t-loss:0.2444, loss-lb:0.2444, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.725] iteration:380  t-loss:0.2461, loss-lb:0.2461, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.827] iteration:381  t-loss:0.2482, loss-lb:0.2482, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:22.932] iteration:382  t-loss:0.2493, loss-lb:0.2493, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.036] iteration:383  t-loss:0.2700, loss-lb:0.2700, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.142] iteration:384  t-loss:0.2555, loss-lb:0.2555, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.246] iteration:385  t-loss:0.2395, loss-lb:0.2395, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.349] iteration:386  t-loss:0.3360, loss-lb:0.3360, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.452] iteration:387  t-loss:0.2295, loss-lb:0.2295, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.554] iteration:388  t-loss:0.1870, loss-lb:0.1870, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.656] iteration:389  t-loss:0.2270, loss-lb:0.2270, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.759] iteration:390  t-loss:0.1884, loss-lb:0.1884, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.861] iteration:391  t-loss:0.2861, loss-lb:0.2861, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:23.962] iteration:392  t-loss:0.2916, loss-lb:0.2916, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:24.447] iteration:393  t-loss:0.3180, loss-lb:0.3180, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:24.557] iteration:394  t-loss:0.2910, loss-lb:0.2910, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:24.663] iteration:395  t-loss:0.3914, loss-lb:0.3914, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:24.766] iteration:396  t-loss:0.2284, loss-lb:0.2284, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:24.871] iteration:397  t-loss:0.3324, loss-lb:0.3324, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:24.975] iteration:398  t-loss:0.3528, loss-lb:0.3528, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.082] iteration:399  t-loss:0.2586, loss-lb:0.2586, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.187] iteration:400  t-loss:0.3981, loss-lb:0.3981, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.293] iteration:401  t-loss:0.3056, loss-lb:0.3056, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.399] iteration:402  t-loss:0.2534, loss-lb:0.2534, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.504] iteration:403  t-loss:0.1864, loss-lb:0.1864, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.608] iteration:404  t-loss:0.2783, loss-lb:0.2783, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.712] iteration:405  t-loss:0.2943, loss-lb:0.2943, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.817] iteration:406  t-loss:0.2035, loss-lb:0.2035, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:25.924] iteration:407  t-loss:0.2829, loss-lb:0.2829, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.028] iteration:408  t-loss:0.2170, loss-lb:0.2170, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.132] iteration:409  t-loss:0.2239, loss-lb:0.2239, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.236] iteration:410  t-loss:0.2699, loss-lb:0.2699, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.342] iteration:411  t-loss:0.2027, loss-lb:0.2027, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.447] iteration:412  t-loss:0.2739, loss-lb:0.2739, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.554] iteration:413  t-loss:0.2657, loss-lb:0.2657, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.659] iteration:414  t-loss:0.4091, loss-lb:0.4091, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.764] iteration:415  t-loss:0.2614, loss-lb:0.2614, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.871] iteration:416  t-loss:0.2306, loss-lb:0.2306, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:26.976] iteration:417  t-loss:0.2658, loss-lb:0.2658, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.081] iteration:418  t-loss:0.2236, loss-lb:0.2236, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.186] iteration:419  t-loss:0.2702, loss-lb:0.2702, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.293] iteration:420  t-loss:0.2134, loss-lb:0.2134, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.397] iteration:421  t-loss:0.2476, loss-lb:0.2476, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.501] iteration:422  t-loss:0.1754, loss-lb:0.1754, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.605] iteration:423  t-loss:0.2089, loss-lb:0.2089, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.709] iteration:424  t-loss:0.3091, loss-lb:0.3091, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.812] iteration:425  t-loss:0.2036, loss-lb:0.2036, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:27.919] iteration:426  t-loss:0.1965, loss-lb:0.1965, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.023] iteration:427  t-loss:0.1832, loss-lb:0.1832, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.127] iteration:428  t-loss:0.2166, loss-lb:0.2166, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.232] iteration:429  t-loss:0.2124, loss-lb:0.2124, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.339] iteration:430  t-loss:0.1997, loss-lb:0.1997, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.445] iteration:431  t-loss:0.2525, loss-lb:0.2525, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.551] iteration:432  t-loss:0.2256, loss-lb:0.2256, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.656] iteration:433  t-loss:0.2357, loss-lb:0.2357, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.760] iteration:434  t-loss:0.2844, loss-lb:0.2844, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.865] iteration:435  t-loss:0.3189, loss-lb:0.3189, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:28.972] iteration:436  t-loss:0.2435, loss-lb:0.2435, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.076] iteration:437  t-loss:0.2228, loss-lb:0.2228, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.180] iteration:438  t-loss:0.1959, loss-lb:0.1959, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.283] iteration:439  t-loss:0.2271, loss-lb:0.2271, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.388] iteration:440  t-loss:0.2251, loss-lb:0.2251, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.492] iteration:441  t-loss:0.2052, loss-lb:0.2052, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.597] iteration:442  t-loss:0.1883, loss-lb:0.1883, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.703] iteration:443  t-loss:0.2372, loss-lb:0.2372, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.809] iteration:444  t-loss:0.2583, loss-lb:0.2583, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:29.913] iteration:445  t-loss:0.2122, loss-lb:0.2122, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.019] iteration:446  t-loss:0.2372, loss-lb:0.2372, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.125] iteration:447  t-loss:0.2404, loss-lb:0.2404, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.231] iteration:448  t-loss:0.2749, loss-lb:0.2749, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.336] iteration:449  t-loss:0.2155, loss-lb:0.2155, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.441] iteration:450  t-loss:0.2910, loss-lb:0.2910, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.547] iteration:451  t-loss:0.2560, loss-lb:0.2560, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.651] iteration:452  t-loss:0.2161, loss-lb:0.2161, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.757] iteration:453  t-loss:0.1793, loss-lb:0.1793, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.859] iteration:454  t-loss:0.1907, loss-lb:0.1907, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:30.965] iteration:455  t-loss:0.2267, loss-lb:0.2267, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.071] iteration:456  t-loss:0.2031, loss-lb:0.2031, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.176] iteration:457  t-loss:0.1771, loss-lb:0.1771, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.281] iteration:458  t-loss:0.2190, loss-lb:0.2190, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.386] iteration:459  t-loss:0.2769, loss-lb:0.2769, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.492] iteration:460  t-loss:0.2081, loss-lb:0.2081, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.602] iteration:461  t-loss:0.2164, loss-lb:0.2164, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.708] iteration:462  t-loss:0.2480, loss-lb:0.2480, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.813] iteration:463  t-loss:0.1816, loss-lb:0.1816, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:31.919] iteration:464  t-loss:0.2852, loss-lb:0.2852, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.024] iteration:465  t-loss:0.2465, loss-lb:0.2465, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.130] iteration:466  t-loss:0.2028, loss-lb:0.2028, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.237] iteration:467  t-loss:0.3187, loss-lb:0.3187, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.341] iteration:468  t-loss:0.2668, loss-lb:0.2668, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.445] iteration:469  t-loss:0.1970, loss-lb:0.1970, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.551] iteration:470  t-loss:0.2463, loss-lb:0.2463, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.657] iteration:471  t-loss:0.1958, loss-lb:0.1958, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.762] iteration:472  t-loss:0.1755, loss-lb:0.1755, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.869] iteration:473  t-loss:0.1965, loss-lb:0.1965, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:32.975] iteration:474  t-loss:0.1895, loss-lb:0.1895, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.080] iteration:475  t-loss:0.2139, loss-lb:0.2139, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.185] iteration:476  t-loss:0.1846, loss-lb:0.1846, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.290] iteration:477  t-loss:0.2319, loss-lb:0.2319, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.396] iteration:478  t-loss:0.1967, loss-lb:0.1967, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.500] iteration:479  t-loss:0.1915, loss-lb:0.1915, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.604] iteration:480  t-loss:0.2288, loss-lb:0.2288, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.708] iteration:481  t-loss:0.2477, loss-lb:0.2477, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.814] iteration:482  t-loss:0.1829, loss-lb:0.1829, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:33.919] iteration:483  t-loss:0.1811, loss-lb:0.1811, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:34.021] iteration:484  t-loss:0.2243, loss-lb:0.2243, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:34.123] iteration:485  t-loss:0.2161, loss-lb:0.2161, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:34.225] iteration:486  t-loss:0.2801, loss-lb:0.2801, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:34.327] iteration:487  t-loss:0.1731, loss-lb:0.1731, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:34.429] iteration:488  t-loss:0.1598, loss-lb:0.1598, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:34.531] iteration:489  t-loss:0.1982, loss-lb:0.1982, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:34.632] iteration:490  t-loss:0.1920, loss-lb:0.1920, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:45.304]  <<Test>> - Ep:4  - mean_dice/mean_h95 - S:75.25/8.78, Best-S:75.25, T:79.55/9.53, Best-T:79.55
[10:48:45.304]           - AvgLoss(lb/ulb/all):0.2374/0.0000/0.2030
[10:48:45.735] iteration:491  t-loss:0.1914, loss-lb:0.1914, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:45.846] iteration:492  t-loss:0.1971, loss-lb:0.1971, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:45.954] iteration:493  t-loss:0.1965, loss-lb:0.1965, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.059] iteration:494  t-loss:0.1982, loss-lb:0.1982, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.164] iteration:495  t-loss:0.2245, loss-lb:0.2245, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.270] iteration:496  t-loss:0.1807, loss-lb:0.1807, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.375] iteration:497  t-loss:0.1932, loss-lb:0.1932, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.480] iteration:498  t-loss:0.2096, loss-lb:0.2096, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.588] iteration:499  t-loss:0.2089, loss-lb:0.2089, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.693] iteration:500  t-loss:0.2111, loss-lb:0.2111, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.799] iteration:501  t-loss:0.2052, loss-lb:0.2052, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:46.904] iteration:502  t-loss:0.2292, loss-lb:0.2292, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.009] iteration:503  t-loss:0.2083, loss-lb:0.2083, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.115] iteration:504  t-loss:0.1828, loss-lb:0.1828, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.220] iteration:505  t-loss:0.2419, loss-lb:0.2419, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.324] iteration:506  t-loss:0.2212, loss-lb:0.2212, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.428] iteration:507  t-loss:0.1688, loss-lb:0.1688, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.533] iteration:508  t-loss:0.2316, loss-lb:0.2316, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.639] iteration:509  t-loss:0.1935, loss-lb:0.1935, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.745] iteration:510  t-loss:0.1814, loss-lb:0.1814, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.851] iteration:511  t-loss:0.1696, loss-lb:0.1696, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:47.957] iteration:512  t-loss:0.1795, loss-lb:0.1795, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.062] iteration:513  t-loss:0.1990, loss-lb:0.1990, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.168] iteration:514  t-loss:0.1859, loss-lb:0.1859, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.274] iteration:515  t-loss:0.1747, loss-lb:0.1747, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.380] iteration:516  t-loss:0.1674, loss-lb:0.1674, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.492] iteration:517  t-loss:0.3045, loss-lb:0.3045, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.599] iteration:518  t-loss:0.1684, loss-lb:0.1684, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.704] iteration:519  t-loss:0.2102, loss-lb:0.2102, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.811] iteration:520  t-loss:0.2354, loss-lb:0.2354, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:48.917] iteration:521  t-loss:0.2496, loss-lb:0.2496, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.022] iteration:522  t-loss:0.1977, loss-lb:0.1977, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.127] iteration:523  t-loss:0.1762, loss-lb:0.1762, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.232] iteration:524  t-loss:0.2091, loss-lb:0.2091, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.337] iteration:525  t-loss:0.2861, loss-lb:0.2861, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.441] iteration:526  t-loss:0.2498, loss-lb:0.2498, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.546] iteration:527  t-loss:0.1858, loss-lb:0.1858, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.651] iteration:528  t-loss:0.2065, loss-lb:0.2065, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.755] iteration:529  t-loss:0.1944, loss-lb:0.1944, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.862] iteration:530  t-loss:0.2872, loss-lb:0.2872, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:49.967] iteration:531  t-loss:0.1978, loss-lb:0.1978, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.071] iteration:532  t-loss:0.2231, loss-lb:0.2231, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.175] iteration:533  t-loss:0.2666, loss-lb:0.2666, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.282] iteration:534  t-loss:0.1767, loss-lb:0.1767, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.387] iteration:535  t-loss:0.1680, loss-lb:0.1680, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.510] iteration:536  t-loss:0.2057, loss-lb:0.2057, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.615] iteration:537  t-loss:0.1848, loss-lb:0.1848, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.719] iteration:538  t-loss:0.2461, loss-lb:0.2461, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.824] iteration:539  t-loss:0.2012, loss-lb:0.2012, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:50.926] iteration:540  t-loss:0.2537, loss-lb:0.2537, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.030] iteration:541  t-loss:0.1735, loss-lb:0.1735, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.134] iteration:542  t-loss:0.2082, loss-lb:0.2082, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.238] iteration:543  t-loss:0.2426, loss-lb:0.2426, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.342] iteration:544  t-loss:0.2523, loss-lb:0.2523, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.446] iteration:545  t-loss:0.2237, loss-lb:0.2237, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.549] iteration:546  t-loss:0.2166, loss-lb:0.2166, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.651] iteration:547  t-loss:0.1963, loss-lb:0.1963, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.753] iteration:548  t-loss:0.1684, loss-lb:0.1684, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.856] iteration:549  t-loss:0.2495, loss-lb:0.2495, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:51.960] iteration:550  t-loss:0.3926, loss-lb:0.3926, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.063] iteration:551  t-loss:0.1941, loss-lb:0.1941, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.165] iteration:552  t-loss:0.1734, loss-lb:0.1734, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.269] iteration:553  t-loss:0.1815, loss-lb:0.1815, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.371] iteration:554  t-loss:0.2331, loss-lb:0.2331, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.474] iteration:555  t-loss:0.1718, loss-lb:0.1718, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.577] iteration:556  t-loss:0.2294, loss-lb:0.2294, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.680] iteration:557  t-loss:0.1879, loss-lb:0.1879, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.784] iteration:558  t-loss:0.1879, loss-lb:0.1879, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.888] iteration:559  t-loss:0.1812, loss-lb:0.1812, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:52.989] iteration:560  t-loss:0.1887, loss-lb:0.1887, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.092] iteration:561  t-loss:0.2582, loss-lb:0.2582, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.199] iteration:562  t-loss:0.2665, loss-lb:0.2665, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.303] iteration:563  t-loss:0.1669, loss-lb:0.1669, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.409] iteration:564  t-loss:0.2511, loss-lb:0.2511, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.514] iteration:565  t-loss:0.2594, loss-lb:0.2594, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.617] iteration:566  t-loss:0.2298, loss-lb:0.2298, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.720] iteration:567  t-loss:0.2054, loss-lb:0.2054, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.822] iteration:568  t-loss:0.1877, loss-lb:0.1877, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:53.926] iteration:569  t-loss:0.2069, loss-lb:0.2069, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.029] iteration:570  t-loss:0.3175, loss-lb:0.3175, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.132] iteration:571  t-loss:0.1976, loss-lb:0.1976, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.234] iteration:572  t-loss:0.2069, loss-lb:0.2069, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.336] iteration:573  t-loss:0.2120, loss-lb:0.2120, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.440] iteration:574  t-loss:0.1994, loss-lb:0.1994, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.544] iteration:575  t-loss:0.2334, loss-lb:0.2334, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.647] iteration:576  t-loss:0.2216, loss-lb:0.2216, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.751] iteration:577  t-loss:0.1949, loss-lb:0.1949, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.853] iteration:578  t-loss:0.1985, loss-lb:0.1985, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:54.955] iteration:579  t-loss:0.1930, loss-lb:0.1930, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.057] iteration:580  t-loss:0.2159, loss-lb:0.2159, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.160] iteration:581  t-loss:0.1923, loss-lb:0.1923, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.262] iteration:582  t-loss:0.1908, loss-lb:0.1908, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.364] iteration:583  t-loss:0.1937, loss-lb:0.1937, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.466] iteration:584  t-loss:0.1871, loss-lb:0.1871, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.568] iteration:585  t-loss:0.1892, loss-lb:0.1892, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.670] iteration:586  t-loss:0.2048, loss-lb:0.2048, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.771] iteration:587  t-loss:0.1487, loss-lb:0.1487, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:55.872] iteration:588  t-loss:0.1727, loss-lb:0.1727, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:56.328] iteration:589  t-loss:0.2080, loss-lb:0.2080, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:56.436] iteration:590  t-loss:0.2029, loss-lb:0.2029, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:56.542] iteration:591  t-loss:0.1744, loss-lb:0.1744, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:56.646] iteration:592  t-loss:0.1910, loss-lb:0.1910, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:56.752] iteration:593  t-loss:0.2784, loss-lb:0.2784, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:56.857] iteration:594  t-loss:0.2255, loss-lb:0.2255, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:56.962] iteration:595  t-loss:0.2777, loss-lb:0.2777, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:57.067] iteration:596  t-loss:0.1991, loss-lb:0.1991, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:57.175] iteration:597  t-loss:0.1915, loss-lb:0.1915, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:57.281] iteration:598  t-loss:0.2172, loss-lb:0.2172, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:57.387] iteration:599  t-loss:0.1748, loss-lb:0.1748, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:57.492] iteration:600  t-loss:0.3539, loss-lb:0.3539, loss-ulb:0.0000, weight:0.02, lr:0.0010
[10:48:57.614] iteration:601  t-loss:0.2667, loss-lb:0.2667, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:57.721] iteration:602  t-loss:0.1671, loss-lb:0.1671, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:57.826] iteration:603  t-loss:0.2301, loss-lb:0.2301, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:57.932] iteration:604  t-loss:0.2600, loss-lb:0.2600, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.036] iteration:605  t-loss:0.2890, loss-lb:0.2890, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.143] iteration:606  t-loss:0.1750, loss-lb:0.1750, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.248] iteration:607  t-loss:0.1919, loss-lb:0.1919, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.355] iteration:608  t-loss:0.1718, loss-lb:0.1718, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.460] iteration:609  t-loss:0.2104, loss-lb:0.2104, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.568] iteration:610  t-loss:0.1918, loss-lb:0.1918, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.671] iteration:611  t-loss:0.2171, loss-lb:0.2171, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.775] iteration:612  t-loss:0.2012, loss-lb:0.2012, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.879] iteration:613  t-loss:0.2112, loss-lb:0.2112, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:58.985] iteration:614  t-loss:0.2264, loss-lb:0.2264, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.092] iteration:615  t-loss:0.1838, loss-lb:0.1838, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.198] iteration:616  t-loss:0.1796, loss-lb:0.1796, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.302] iteration:617  t-loss:0.2572, loss-lb:0.2572, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.407] iteration:618  t-loss:0.2779, loss-lb:0.2779, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.512] iteration:619  t-loss:0.1818, loss-lb:0.1818, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.618] iteration:620  t-loss:0.2291, loss-lb:0.2291, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.726] iteration:621  t-loss:0.1652, loss-lb:0.1652, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.833] iteration:622  t-loss:0.1851, loss-lb:0.1851, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:48:59.937] iteration:623  t-loss:0.1540, loss-lb:0.1540, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.040] iteration:624  t-loss:0.1924, loss-lb:0.1924, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.144] iteration:625  t-loss:0.1860, loss-lb:0.1860, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.247] iteration:626  t-loss:0.1546, loss-lb:0.1546, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.347] iteration:627  t-loss:0.1758, loss-lb:0.1758, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.451] iteration:628  t-loss:0.2029, loss-lb:0.2029, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.556] iteration:629  t-loss:0.2853, loss-lb:0.2853, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.660] iteration:630  t-loss:0.1830, loss-lb:0.1830, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.765] iteration:631  t-loss:0.2145, loss-lb:0.2145, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.869] iteration:632  t-loss:0.1868, loss-lb:0.1868, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:00.973] iteration:633  t-loss:0.1689, loss-lb:0.1689, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.079] iteration:634  t-loss:0.2301, loss-lb:0.2301, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.185] iteration:635  t-loss:0.2296, loss-lb:0.2296, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.290] iteration:636  t-loss:0.2247, loss-lb:0.2247, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.394] iteration:637  t-loss:0.1834, loss-lb:0.1834, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.499] iteration:638  t-loss:0.2149, loss-lb:0.2149, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.609] iteration:639  t-loss:0.1802, loss-lb:0.1802, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.716] iteration:640  t-loss:0.1655, loss-lb:0.1655, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.820] iteration:641  t-loss:0.2269, loss-lb:0.2269, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:01.925] iteration:642  t-loss:0.2309, loss-lb:0.2309, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.031] iteration:643  t-loss:0.1785, loss-lb:0.1785, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.138] iteration:644  t-loss:0.1900, loss-lb:0.1900, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.243] iteration:645  t-loss:0.1864, loss-lb:0.1864, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.345] iteration:646  t-loss:0.2327, loss-lb:0.2327, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.448] iteration:647  t-loss:0.2080, loss-lb:0.2080, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.552] iteration:648  t-loss:0.2117, loss-lb:0.2117, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.651] iteration:649  t-loss:0.1919, loss-lb:0.1919, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.754] iteration:650  t-loss:0.1638, loss-lb:0.1638, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.862] iteration:651  t-loss:0.1512, loss-lb:0.1512, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:02.966] iteration:652  t-loss:0.1847, loss-lb:0.1847, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.072] iteration:653  t-loss:0.2102, loss-lb:0.2102, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.174] iteration:654  t-loss:0.2362, loss-lb:0.2362, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.282] iteration:655  t-loss:0.1781, loss-lb:0.1781, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.387] iteration:656  t-loss:0.2105, loss-lb:0.2105, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.491] iteration:657  t-loss:0.1627, loss-lb:0.1627, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.595] iteration:658  t-loss:0.1972, loss-lb:0.1972, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.698] iteration:659  t-loss:0.2533, loss-lb:0.2533, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.803] iteration:660  t-loss:0.2212, loss-lb:0.2212, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:03.912] iteration:661  t-loss:0.1463, loss-lb:0.1463, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.018] iteration:662  t-loss:0.1804, loss-lb:0.1804, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.125] iteration:663  t-loss:0.1941, loss-lb:0.1941, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.240] iteration:664  t-loss:0.1770, loss-lb:0.1770, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.352] iteration:665  t-loss:0.1727, loss-lb:0.1727, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.461] iteration:666  t-loss:0.1743, loss-lb:0.1743, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.570] iteration:667  t-loss:0.2465, loss-lb:0.2465, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.675] iteration:668  t-loss:0.1553, loss-lb:0.1553, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.790] iteration:669  t-loss:0.1600, loss-lb:0.1600, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:04.897] iteration:670  t-loss:0.2293, loss-lb:0.2293, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.002] iteration:671  t-loss:0.1719, loss-lb:0.1719, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.107] iteration:672  t-loss:0.2039, loss-lb:0.2039, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.210] iteration:673  t-loss:0.1901, loss-lb:0.1901, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.329] iteration:674  t-loss:0.1801, loss-lb:0.1801, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.447] iteration:675  t-loss:0.2006, loss-lb:0.2006, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.561] iteration:676  t-loss:0.1567, loss-lb:0.1567, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.660] iteration:677  t-loss:0.1584, loss-lb:0.1584, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.768] iteration:678  t-loss:0.1584, loss-lb:0.1584, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.875] iteration:679  t-loss:0.1773, loss-lb:0.1773, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:05.982] iteration:680  t-loss:0.2255, loss-lb:0.2255, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:06.086] iteration:681  t-loss:0.1629, loss-lb:0.1629, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:06.189] iteration:682  t-loss:0.1457, loss-lb:0.1457, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:06.291] iteration:683  t-loss:0.1462, loss-lb:0.1462, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:06.395] iteration:684  t-loss:0.1517, loss-lb:0.1517, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:06.499] iteration:685  t-loss:0.1719, loss-lb:0.1719, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:06.601] iteration:686  t-loss:0.1444, loss-lb:0.1444, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:17.532]  <<Test>> - Ep:6  - mean_dice/mean_h95 - S:80.70/10.67, Best-S:80.70, T:82.35/9.22, Best-T:82.35
[10:49:17.532]           - AvgLoss(lb/ulb/all):0.1990/0.0000/0.1768
[10:49:17.975] iteration:687  t-loss:0.1644, loss-lb:0.1644, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.090] iteration:688  t-loss:0.1776, loss-lb:0.1776, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.201] iteration:689  t-loss:0.1611, loss-lb:0.1611, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.306] iteration:690  t-loss:0.2081, loss-lb:0.2081, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.412] iteration:691  t-loss:0.1535, loss-lb:0.1535, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.519] iteration:692  t-loss:0.1460, loss-lb:0.1460, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.645] iteration:693  t-loss:0.1767, loss-lb:0.1767, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.751] iteration:694  t-loss:0.1414, loss-lb:0.1414, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.863] iteration:695  t-loss:0.1966, loss-lb:0.1966, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:18.976] iteration:696  t-loss:0.1502, loss-lb:0.1502, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.086] iteration:697  t-loss:0.1811, loss-lb:0.1811, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.190] iteration:698  t-loss:0.1614, loss-lb:0.1614, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.296] iteration:699  t-loss:0.1658, loss-lb:0.1658, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.404] iteration:700  t-loss:0.1989, loss-lb:0.1989, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.511] iteration:701  t-loss:0.1446, loss-lb:0.1446, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.616] iteration:702  t-loss:0.1857, loss-lb:0.1857, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.721] iteration:703  t-loss:0.1699, loss-lb:0.1699, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.826] iteration:704  t-loss:0.2033, loss-lb:0.2033, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:19.931] iteration:705  t-loss:0.1719, loss-lb:0.1719, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.037] iteration:706  t-loss:0.1398, loss-lb:0.1398, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.143] iteration:707  t-loss:0.1628, loss-lb:0.1628, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.250] iteration:708  t-loss:0.1989, loss-lb:0.1989, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.354] iteration:709  t-loss:0.1649, loss-lb:0.1649, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.461] iteration:710  t-loss:0.2107, loss-lb:0.2107, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.568] iteration:711  t-loss:0.2026, loss-lb:0.2026, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.672] iteration:712  t-loss:0.1661, loss-lb:0.1661, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.780] iteration:713  t-loss:0.2282, loss-lb:0.2282, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.888] iteration:714  t-loss:0.1501, loss-lb:0.1501, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:20.992] iteration:715  t-loss:0.1541, loss-lb:0.1541, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.098] iteration:716  t-loss:0.1814, loss-lb:0.1814, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.205] iteration:717  t-loss:0.1802, loss-lb:0.1802, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.310] iteration:718  t-loss:0.1954, loss-lb:0.1954, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.415] iteration:719  t-loss:0.1588, loss-lb:0.1588, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.523] iteration:720  t-loss:0.1748, loss-lb:0.1748, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.629] iteration:721  t-loss:0.1419, loss-lb:0.1419, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.734] iteration:722  t-loss:0.1633, loss-lb:0.1633, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.839] iteration:723  t-loss:0.1521, loss-lb:0.1521, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:21.945] iteration:724  t-loss:0.1600, loss-lb:0.1600, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.051] iteration:725  t-loss:0.2119, loss-lb:0.2119, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.158] iteration:726  t-loss:0.1774, loss-lb:0.1774, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.264] iteration:727  t-loss:0.1790, loss-lb:0.1790, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.369] iteration:728  t-loss:0.2390, loss-lb:0.2390, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.474] iteration:729  t-loss:0.1537, loss-lb:0.1537, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.580] iteration:730  t-loss:0.1978, loss-lb:0.1978, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.686] iteration:731  t-loss:0.1596, loss-lb:0.1596, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.792] iteration:732  t-loss:0.1796, loss-lb:0.1796, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:22.898] iteration:733  t-loss:0.1590, loss-lb:0.1590, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.011] iteration:734  t-loss:0.1646, loss-lb:0.1646, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.119] iteration:735  t-loss:0.1663, loss-lb:0.1663, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.225] iteration:736  t-loss:0.1591, loss-lb:0.1591, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.330] iteration:737  t-loss:0.1259, loss-lb:0.1259, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.435] iteration:738  t-loss:0.2127, loss-lb:0.2127, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.540] iteration:739  t-loss:0.1509, loss-lb:0.1509, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.646] iteration:740  t-loss:0.1797, loss-lb:0.1797, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.754] iteration:741  t-loss:0.1502, loss-lb:0.1502, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.859] iteration:742  t-loss:0.1708, loss-lb:0.1708, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:23.965] iteration:743  t-loss:0.1736, loss-lb:0.1736, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.074] iteration:744  t-loss:0.1702, loss-lb:0.1702, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.181] iteration:745  t-loss:0.1626, loss-lb:0.1626, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.287] iteration:746  t-loss:0.1470, loss-lb:0.1470, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.393] iteration:747  t-loss:0.1535, loss-lb:0.1535, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.499] iteration:748  t-loss:0.1562, loss-lb:0.1562, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.607] iteration:749  t-loss:0.1777, loss-lb:0.1777, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.714] iteration:750  t-loss:0.1670, loss-lb:0.1670, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.821] iteration:751  t-loss:0.1624, loss-lb:0.1624, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:24.927] iteration:752  t-loss:0.1463, loss-lb:0.1463, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.033] iteration:753  t-loss:0.1643, loss-lb:0.1643, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.141] iteration:754  t-loss:0.1610, loss-lb:0.1610, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.247] iteration:755  t-loss:0.1407, loss-lb:0.1407, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.352] iteration:756  t-loss:0.1632, loss-lb:0.1632, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.458] iteration:757  t-loss:0.1658, loss-lb:0.1658, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.565] iteration:758  t-loss:0.1607, loss-lb:0.1607, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.672] iteration:759  t-loss:0.1618, loss-lb:0.1618, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.779] iteration:760  t-loss:0.2769, loss-lb:0.2769, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.883] iteration:761  t-loss:0.1916, loss-lb:0.1916, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:25.989] iteration:762  t-loss:0.1837, loss-lb:0.1837, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.094] iteration:763  t-loss:0.1604, loss-lb:0.1604, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.200] iteration:764  t-loss:0.1656, loss-lb:0.1656, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.305] iteration:765  t-loss:0.1503, loss-lb:0.1503, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.410] iteration:766  t-loss:0.1643, loss-lb:0.1643, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.516] iteration:767  t-loss:0.2392, loss-lb:0.2392, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.623] iteration:768  t-loss:0.1603, loss-lb:0.1603, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.728] iteration:769  t-loss:0.1779, loss-lb:0.1779, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.833] iteration:770  t-loss:0.1757, loss-lb:0.1757, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:26.939] iteration:771  t-loss:0.1819, loss-lb:0.1819, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.044] iteration:772  t-loss:0.1301, loss-lb:0.1301, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.150] iteration:773  t-loss:0.1465, loss-lb:0.1465, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.255] iteration:774  t-loss:0.1605, loss-lb:0.1605, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.359] iteration:775  t-loss:0.1436, loss-lb:0.1436, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.464] iteration:776  t-loss:0.2109, loss-lb:0.2109, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.569] iteration:777  t-loss:0.1858, loss-lb:0.1858, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.671] iteration:778  t-loss:0.1527, loss-lb:0.1527, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.773] iteration:779  t-loss:0.1293, loss-lb:0.1293, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.876] iteration:780  t-loss:0.1527, loss-lb:0.1527, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:27.977] iteration:781  t-loss:0.1513, loss-lb:0.1513, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:28.079] iteration:782  t-loss:0.1619, loss-lb:0.1619, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:28.181] iteration:783  t-loss:0.1617, loss-lb:0.1617, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:28.283] iteration:784  t-loss:0.1375, loss-lb:0.1375, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:28.794] iteration:785  t-loss:0.1530, loss-lb:0.1530, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:28.901] iteration:786  t-loss:0.1434, loss-lb:0.1434, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.009] iteration:787  t-loss:0.1756, loss-lb:0.1756, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.106] iteration:788  t-loss:0.1716, loss-lb:0.1716, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.203] iteration:789  t-loss:0.1666, loss-lb:0.1666, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.322] iteration:790  t-loss:0.1932, loss-lb:0.1932, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.445] iteration:791  t-loss:0.1354, loss-lb:0.1354, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.554] iteration:792  t-loss:0.1627, loss-lb:0.1627, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.657] iteration:793  t-loss:0.1663, loss-lb:0.1663, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.763] iteration:794  t-loss:0.1658, loss-lb:0.1658, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.868] iteration:795  t-loss:0.1739, loss-lb:0.1739, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:29.966] iteration:796  t-loss:0.1402, loss-lb:0.1402, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.065] iteration:797  t-loss:0.1413, loss-lb:0.1413, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.170] iteration:798  t-loss:0.2386, loss-lb:0.2386, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.278] iteration:799  t-loss:0.1744, loss-lb:0.1744, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.376] iteration:800  t-loss:0.1807, loss-lb:0.1807, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.473] iteration:801  t-loss:0.1790, loss-lb:0.1790, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.579] iteration:802  t-loss:0.1726, loss-lb:0.1726, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.686] iteration:803  t-loss:0.1879, loss-lb:0.1879, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.785] iteration:804  t-loss:0.1745, loss-lb:0.1745, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.883] iteration:805  t-loss:0.1717, loss-lb:0.1717, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:30.990] iteration:806  t-loss:0.1654, loss-lb:0.1654, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.096] iteration:807  t-loss:0.1519, loss-lb:0.1519, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.197] iteration:808  t-loss:0.1410, loss-lb:0.1410, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.294] iteration:809  t-loss:0.1699, loss-lb:0.1699, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.399] iteration:810  t-loss:0.1604, loss-lb:0.1604, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.507] iteration:811  t-loss:0.2362, loss-lb:0.2362, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.606] iteration:812  t-loss:0.1688, loss-lb:0.1688, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.703] iteration:813  t-loss:0.1435, loss-lb:0.1435, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.806] iteration:814  t-loss:0.1745, loss-lb:0.1745, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:31.912] iteration:815  t-loss:0.1655, loss-lb:0.1655, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.008] iteration:816  t-loss:0.2048, loss-lb:0.2048, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.107] iteration:817  t-loss:0.1309, loss-lb:0.1309, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.212] iteration:818  t-loss:0.1491, loss-lb:0.1491, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.316] iteration:819  t-loss:0.1521, loss-lb:0.1521, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.414] iteration:820  t-loss:0.1673, loss-lb:0.1673, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.511] iteration:821  t-loss:0.1492, loss-lb:0.1492, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.617] iteration:822  t-loss:0.1418, loss-lb:0.1418, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.723] iteration:823  t-loss:0.1618, loss-lb:0.1618, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.823] iteration:824  t-loss:0.1520, loss-lb:0.1520, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:32.922] iteration:825  t-loss:0.1355, loss-lb:0.1355, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.026] iteration:826  t-loss:0.1492, loss-lb:0.1492, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.131] iteration:827  t-loss:0.1438, loss-lb:0.1438, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.229] iteration:828  t-loss:0.1584, loss-lb:0.1584, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.327] iteration:829  t-loss:0.1431, loss-lb:0.1431, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.432] iteration:830  t-loss:0.1303, loss-lb:0.1303, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.539] iteration:831  t-loss:0.1334, loss-lb:0.1334, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.638] iteration:832  t-loss:0.1290, loss-lb:0.1290, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.736] iteration:833  t-loss:0.1752, loss-lb:0.1752, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.840] iteration:834  t-loss:0.1317, loss-lb:0.1317, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:33.947] iteration:835  t-loss:0.1473, loss-lb:0.1473, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.047] iteration:836  t-loss:0.1278, loss-lb:0.1278, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.145] iteration:837  t-loss:0.1445, loss-lb:0.1445, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.250] iteration:838  t-loss:0.1396, loss-lb:0.1396, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.356] iteration:839  t-loss:0.1507, loss-lb:0.1507, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.454] iteration:840  t-loss:0.1356, loss-lb:0.1356, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.550] iteration:841  t-loss:0.1452, loss-lb:0.1452, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.646] iteration:842  t-loss:0.1863, loss-lb:0.1863, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.742] iteration:843  t-loss:0.1444, loss-lb:0.1444, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.839] iteration:844  t-loss:0.2049, loss-lb:0.2049, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:34.935] iteration:845  t-loss:0.1535, loss-lb:0.1535, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.031] iteration:846  t-loss:0.1463, loss-lb:0.1463, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.129] iteration:847  t-loss:0.1492, loss-lb:0.1492, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.225] iteration:848  t-loss:0.1560, loss-lb:0.1560, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.323] iteration:849  t-loss:0.1257, loss-lb:0.1257, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.418] iteration:850  t-loss:0.1437, loss-lb:0.1437, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.515] iteration:851  t-loss:0.1410, loss-lb:0.1410, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.612] iteration:852  t-loss:0.1583, loss-lb:0.1583, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.708] iteration:853  t-loss:0.1648, loss-lb:0.1648, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.805] iteration:854  t-loss:0.1446, loss-lb:0.1446, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.900] iteration:855  t-loss:0.1898, loss-lb:0.1898, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:35.996] iteration:856  t-loss:0.1522, loss-lb:0.1522, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.093] iteration:857  t-loss:0.1746, loss-lb:0.1746, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.189] iteration:858  t-loss:0.1637, loss-lb:0.1637, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.285] iteration:859  t-loss:0.1261, loss-lb:0.1261, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.381] iteration:860  t-loss:0.1653, loss-lb:0.1653, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.477] iteration:861  t-loss:0.1496, loss-lb:0.1496, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.572] iteration:862  t-loss:0.1346, loss-lb:0.1346, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.670] iteration:863  t-loss:0.1712, loss-lb:0.1712, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.765] iteration:864  t-loss:0.1473, loss-lb:0.1473, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.861] iteration:865  t-loss:0.1627, loss-lb:0.1627, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:36.956] iteration:866  t-loss:0.1329, loss-lb:0.1329, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.052] iteration:867  t-loss:0.1360, loss-lb:0.1360, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.148] iteration:868  t-loss:0.1494, loss-lb:0.1494, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.244] iteration:869  t-loss:0.1382, loss-lb:0.1382, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.357] iteration:870  t-loss:0.1301, loss-lb:0.1301, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.456] iteration:871  t-loss:0.1366, loss-lb:0.1366, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.553] iteration:872  t-loss:0.1594, loss-lb:0.1594, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.652] iteration:873  t-loss:0.1550, loss-lb:0.1550, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.751] iteration:874  t-loss:0.1692, loss-lb:0.1692, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.848] iteration:875  t-loss:0.1752, loss-lb:0.1752, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:37.952] iteration:876  t-loss:0.1401, loss-lb:0.1401, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:38.054] iteration:877  t-loss:0.1386, loss-lb:0.1386, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:38.156] iteration:878  t-loss:0.1437, loss-lb:0.1437, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:38.258] iteration:879  t-loss:0.1418, loss-lb:0.1418, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:38.361] iteration:880  t-loss:0.1550, loss-lb:0.1550, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:38.463] iteration:881  t-loss:0.1431, loss-lb:0.1431, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:38.566] iteration:882  t-loss:0.1552, loss-lb:0.1552, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:49.321]  <<Test>> - Ep:8  - mean_dice/mean_h95 - S:82.71/10.13, Best-S:82.71, T:83.59/8.72, Best-T:83.59
[10:49:49.321]           - AvgLoss(lb/ulb/all):0.1564/0.0000/0.1490
[10:49:49.752] iteration:883  t-loss:0.1433, loss-lb:0.1433, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:49.855] iteration:884  t-loss:0.1310, loss-lb:0.1310, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:49.958] iteration:885  t-loss:0.1583, loss-lb:0.1583, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.055] iteration:886  t-loss:0.1771, loss-lb:0.1771, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.151] iteration:887  t-loss:0.1658, loss-lb:0.1658, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.246] iteration:888  t-loss:0.1713, loss-lb:0.1713, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.342] iteration:889  t-loss:0.1546, loss-lb:0.1546, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.439] iteration:890  t-loss:0.1414, loss-lb:0.1414, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.537] iteration:891  t-loss:0.1479, loss-lb:0.1479, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.633] iteration:892  t-loss:0.1519, loss-lb:0.1519, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.728] iteration:893  t-loss:0.1506, loss-lb:0.1506, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.824] iteration:894  t-loss:0.1671, loss-lb:0.1671, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:50.920] iteration:895  t-loss:0.1302, loss-lb:0.1302, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:51.016] iteration:896  t-loss:0.1349, loss-lb:0.1349, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:51.113] iteration:897  t-loss:0.1669, loss-lb:0.1669, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:51.207] iteration:898  t-loss:0.1519, loss-lb:0.1519, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:51.304] iteration:899  t-loss:0.1617, loss-lb:0.1617, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:51.399] iteration:900  t-loss:0.1597, loss-lb:0.1597, loss-ulb:0.0000, weight:0.03, lr:0.0010
[10:49:51.496] iteration:901  t-loss:0.1479, loss-lb:0.1479, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:51.593] iteration:902  t-loss:0.1281, loss-lb:0.1281, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:51.691] iteration:903  t-loss:0.1746, loss-lb:0.1746, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:51.787] iteration:904  t-loss:0.1544, loss-lb:0.1544, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:51.883] iteration:905  t-loss:0.1235, loss-lb:0.1235, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:51.978] iteration:906  t-loss:0.1237, loss-lb:0.1237, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.074] iteration:907  t-loss:0.1628, loss-lb:0.1628, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.169] iteration:908  t-loss:0.1534, loss-lb:0.1534, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.266] iteration:909  t-loss:0.1385, loss-lb:0.1385, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.362] iteration:910  t-loss:0.1478, loss-lb:0.1478, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.458] iteration:911  t-loss:0.1340, loss-lb:0.1340, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.553] iteration:912  t-loss:0.1359, loss-lb:0.1359, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.651] iteration:913  t-loss:0.1593, loss-lb:0.1593, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.746] iteration:914  t-loss:0.1440, loss-lb:0.1440, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.842] iteration:915  t-loss:0.1449, loss-lb:0.1449, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:52.939] iteration:916  t-loss:0.1307, loss-lb:0.1307, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.034] iteration:917  t-loss:0.1454, loss-lb:0.1454, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.130] iteration:918  t-loss:0.1392, loss-lb:0.1392, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.225] iteration:919  t-loss:0.1601, loss-lb:0.1601, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.321] iteration:920  t-loss:0.1251, loss-lb:0.1251, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.417] iteration:921  t-loss:0.1521, loss-lb:0.1521, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.512] iteration:922  t-loss:0.1195, loss-lb:0.1195, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.607] iteration:923  t-loss:0.1457, loss-lb:0.1457, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.703] iteration:924  t-loss:0.1263, loss-lb:0.1263, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.799] iteration:925  t-loss:0.1467, loss-lb:0.1467, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.898] iteration:926  t-loss:0.1564, loss-lb:0.1564, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:53.993] iteration:927  t-loss:0.1511, loss-lb:0.1511, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.088] iteration:928  t-loss:0.1320, loss-lb:0.1320, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.186] iteration:929  t-loss:0.1515, loss-lb:0.1515, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.284] iteration:930  t-loss:0.1183, loss-lb:0.1183, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.380] iteration:931  t-loss:0.1463, loss-lb:0.1463, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.475] iteration:932  t-loss:0.1486, loss-lb:0.1486, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.573] iteration:933  t-loss:0.1354, loss-lb:0.1354, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.670] iteration:934  t-loss:0.1730, loss-lb:0.1730, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.766] iteration:935  t-loss:0.1226, loss-lb:0.1226, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.862] iteration:936  t-loss:0.1788, loss-lb:0.1788, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:54.960] iteration:937  t-loss:0.1274, loss-lb:0.1274, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.056] iteration:938  t-loss:0.1416, loss-lb:0.1416, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.154] iteration:939  t-loss:0.1804, loss-lb:0.1804, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.249] iteration:940  t-loss:0.1470, loss-lb:0.1470, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.344] iteration:941  t-loss:0.1285, loss-lb:0.1285, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.440] iteration:942  t-loss:0.1570, loss-lb:0.1570, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.537] iteration:943  t-loss:0.1228, loss-lb:0.1228, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.632] iteration:944  t-loss:0.2050, loss-lb:0.2050, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.727] iteration:945  t-loss:0.1292, loss-lb:0.1292, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.823] iteration:946  t-loss:0.1564, loss-lb:0.1564, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:55.922] iteration:947  t-loss:0.1496, loss-lb:0.1496, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.018] iteration:948  t-loss:0.1271, loss-lb:0.1271, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.114] iteration:949  t-loss:0.1421, loss-lb:0.1421, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.211] iteration:950  t-loss:0.1504, loss-lb:0.1504, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.306] iteration:951  t-loss:0.1434, loss-lb:0.1434, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.403] iteration:952  t-loss:0.1487, loss-lb:0.1487, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.500] iteration:953  t-loss:0.1709, loss-lb:0.1709, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.596] iteration:954  t-loss:0.1483, loss-lb:0.1483, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.692] iteration:955  t-loss:0.1337, loss-lb:0.1337, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.788] iteration:956  t-loss:0.1840, loss-lb:0.1840, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.885] iteration:957  t-loss:0.1500, loss-lb:0.1500, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:56.981] iteration:958  t-loss:0.1353, loss-lb:0.1353, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.078] iteration:959  t-loss:0.1552, loss-lb:0.1552, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.173] iteration:960  t-loss:0.1447, loss-lb:0.1447, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.270] iteration:961  t-loss:0.1408, loss-lb:0.1408, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.365] iteration:962  t-loss:0.1401, loss-lb:0.1401, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.463] iteration:963  t-loss:0.1530, loss-lb:0.1530, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.559] iteration:964  t-loss:0.1392, loss-lb:0.1392, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.654] iteration:965  t-loss:0.1384, loss-lb:0.1384, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.750] iteration:966  t-loss:0.1487, loss-lb:0.1487, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.846] iteration:967  t-loss:0.1188, loss-lb:0.1188, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:57.942] iteration:968  t-loss:0.1521, loss-lb:0.1521, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.038] iteration:969  t-loss:0.1315, loss-lb:0.1315, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.133] iteration:970  t-loss:0.1391, loss-lb:0.1391, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.229] iteration:971  t-loss:0.1536, loss-lb:0.1536, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.324] iteration:972  t-loss:0.1324, loss-lb:0.1324, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.420] iteration:973  t-loss:0.1554, loss-lb:0.1554, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.514] iteration:974  t-loss:0.1321, loss-lb:0.1321, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.608] iteration:975  t-loss:0.1290, loss-lb:0.1290, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.701] iteration:976  t-loss:0.1224, loss-lb:0.1224, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.794] iteration:977  t-loss:0.1341, loss-lb:0.1341, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.887] iteration:978  t-loss:0.1444, loss-lb:0.1444, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:58.981] iteration:979  t-loss:0.1303, loss-lb:0.1303, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:59.075] iteration:980  t-loss:0.1516, loss-lb:0.1516, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:59.543] iteration:981  t-loss:0.1627, loss-lb:0.1627, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:59.648] iteration:982  t-loss:0.1384, loss-lb:0.1384, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:59.746] iteration:983  t-loss:0.1806, loss-lb:0.1806, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:59.864] iteration:984  t-loss:0.1459, loss-lb:0.1459, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:49:59.972] iteration:985  t-loss:0.1397, loss-lb:0.1397, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.073] iteration:986  t-loss:0.1577, loss-lb:0.1577, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.176] iteration:987  t-loss:0.1471, loss-lb:0.1471, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.284] iteration:988  t-loss:0.1350, loss-lb:0.1350, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.383] iteration:989  t-loss:0.1225, loss-lb:0.1225, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.483] iteration:990  t-loss:0.1429, loss-lb:0.1429, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.588] iteration:991  t-loss:0.1211, loss-lb:0.1211, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.694] iteration:992  t-loss:0.1448, loss-lb:0.1448, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.792] iteration:993  t-loss:0.1370, loss-lb:0.1370, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.888] iteration:994  t-loss:0.1412, loss-lb:0.1412, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:00.993] iteration:995  t-loss:0.1838, loss-lb:0.1838, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:01.099] iteration:996  t-loss:0.1350, loss-lb:0.1350, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:01.198] iteration:997  t-loss:0.1325, loss-lb:0.1325, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:01.299] iteration:998  t-loss:0.1348, loss-lb:0.1348, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:01.409] iteration:999  t-loss:0.1541, loss-lb:0.1541, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:01.517] iteration:1000  t-loss:0.1364, loss-lb:0.1364, loss-ulb:0.0000, weight:0.04, lr:0.0010
[10:50:01.866] iteration:1001  t-loss:0.1604, loss-lb:0.1481, loss-ulb:0.2947, weight:0.04, lr:0.0010
[10:50:02.059] iteration:1002  t-loss:0.2087, loss-lb:0.2041, loss-ulb:0.1118, weight:0.04, lr:0.0010
[10:50:02.252] iteration:1003  t-loss:0.1383, loss-lb:0.1340, loss-ulb:0.1037, weight:0.04, lr:0.0010
[10:50:02.443] iteration:1004  t-loss:0.1479, loss-lb:0.1455, loss-ulb:0.0568, weight:0.04, lr:0.0010
[10:50:02.635] iteration:1005  t-loss:0.1324, loss-lb:0.1308, loss-ulb:0.0381, weight:0.04, lr:0.0010
[10:50:02.826] iteration:1006  t-loss:0.1448, loss-lb:0.1408, loss-ulb:0.0948, weight:0.04, lr:0.0010
[10:50:03.017] iteration:1007  t-loss:0.1695, loss-lb:0.1637, loss-ulb:0.1382, weight:0.04, lr:0.0010
[10:50:03.207] iteration:1008  t-loss:0.1723, loss-lb:0.1695, loss-ulb:0.0657, weight:0.04, lr:0.0010
[10:50:03.399] iteration:1009  t-loss:0.1633, loss-lb:0.1594, loss-ulb:0.0937, weight:0.04, lr:0.0010
[10:50:03.592] iteration:1010  t-loss:0.1453, loss-lb:0.1411, loss-ulb:0.1017, weight:0.04, lr:0.0010
[10:50:03.784] iteration:1011  t-loss:0.1197, loss-lb:0.1162, loss-ulb:0.0835, weight:0.04, lr:0.0010
[10:50:03.976] iteration:1012  t-loss:0.1577, loss-lb:0.1511, loss-ulb:0.1597, weight:0.04, lr:0.0010
[10:50:04.168] iteration:1013  t-loss:0.1467, loss-lb:0.1397, loss-ulb:0.1683, weight:0.04, lr:0.0010
[10:50:04.357] iteration:1014  t-loss:0.1391, loss-lb:0.1360, loss-ulb:0.0741, weight:0.04, lr:0.0010
[10:50:04.550] iteration:1015  t-loss:0.1403, loss-lb:0.1354, loss-ulb:0.1188, weight:0.04, lr:0.0010
[10:50:04.742] iteration:1016  t-loss:0.1339, loss-lb:0.1309, loss-ulb:0.0742, weight:0.04, lr:0.0010
[10:50:04.935] iteration:1017  t-loss:0.1286, loss-lb:0.1236, loss-ulb:0.1199, weight:0.04, lr:0.0010
[10:50:05.126] iteration:1018  t-loss:0.1637, loss-lb:0.1580, loss-ulb:0.1386, weight:0.04, lr:0.0010
[10:50:05.317] iteration:1019  t-loss:0.2000, loss-lb:0.1980, loss-ulb:0.0479, weight:0.04, lr:0.0010
[10:50:05.508] iteration:1020  t-loss:0.1400, loss-lb:0.1372, loss-ulb:0.0682, weight:0.04, lr:0.0010
[10:50:05.700] iteration:1021  t-loss:0.1573, loss-lb:0.1551, loss-ulb:0.0529, weight:0.04, lr:0.0010
[10:50:05.891] iteration:1022  t-loss:0.1326, loss-lb:0.1305, loss-ulb:0.0502, weight:0.04, lr:0.0010
[10:50:06.083] iteration:1023  t-loss:0.1549, loss-lb:0.1520, loss-ulb:0.0702, weight:0.04, lr:0.0010
[10:50:06.273] iteration:1024  t-loss:0.1244, loss-lb:0.1210, loss-ulb:0.0819, weight:0.04, lr:0.0010
[10:50:06.464] iteration:1025  t-loss:0.1249, loss-lb:0.1217, loss-ulb:0.0787, weight:0.04, lr:0.0010
[10:50:06.653] iteration:1026  t-loss:0.1493, loss-lb:0.1454, loss-ulb:0.0946, weight:0.04, lr:0.0010
[10:50:06.844] iteration:1027  t-loss:0.1514, loss-lb:0.1459, loss-ulb:0.1313, weight:0.04, lr:0.0010
[10:50:07.034] iteration:1028  t-loss:0.1295, loss-lb:0.1270, loss-ulb:0.0603, weight:0.04, lr:0.0010
[10:50:07.225] iteration:1029  t-loss:0.1532, loss-lb:0.1445, loss-ulb:0.2082, weight:0.04, lr:0.0010
[10:50:07.415] iteration:1030  t-loss:0.1470, loss-lb:0.1451, loss-ulb:0.0463, weight:0.04, lr:0.0010
[10:50:07.606] iteration:1031  t-loss:0.1520, loss-lb:0.1495, loss-ulb:0.0605, weight:0.04, lr:0.0010
[10:50:07.798] iteration:1032  t-loss:0.1467, loss-lb:0.1390, loss-ulb:0.1865, weight:0.04, lr:0.0010
[10:50:07.995] iteration:1033  t-loss:0.1905, loss-lb:0.1831, loss-ulb:0.1761, weight:0.04, lr:0.0010
[10:50:08.189] iteration:1034  t-loss:0.1557, loss-lb:0.1488, loss-ulb:0.1665, weight:0.04, lr:0.0010
[10:50:08.384] iteration:1035  t-loss:0.1462, loss-lb:0.1447, loss-ulb:0.0354, weight:0.04, lr:0.0010
[10:50:08.580] iteration:1036  t-loss:0.1398, loss-lb:0.1375, loss-ulb:0.0539, weight:0.04, lr:0.0010
[10:50:08.773] iteration:1037  t-loss:0.1476, loss-lb:0.1446, loss-ulb:0.0733, weight:0.04, lr:0.0010
[10:50:08.966] iteration:1038  t-loss:0.1707, loss-lb:0.1673, loss-ulb:0.0800, weight:0.04, lr:0.0010
[10:50:09.158] iteration:1039  t-loss:0.1798, loss-lb:0.1745, loss-ulb:0.1287, weight:0.04, lr:0.0010
[10:50:09.349] iteration:1040  t-loss:0.1480, loss-lb:0.1447, loss-ulb:0.0788, weight:0.04, lr:0.0010
[10:50:09.540] iteration:1041  t-loss:0.1546, loss-lb:0.1535, loss-ulb:0.0263, weight:0.04, lr:0.0010
[10:50:09.732] iteration:1042  t-loss:0.1476, loss-lb:0.1427, loss-ulb:0.1166, weight:0.04, lr:0.0010
[10:50:09.924] iteration:1043  t-loss:0.1603, loss-lb:0.1583, loss-ulb:0.0476, weight:0.04, lr:0.0010
[10:50:10.117] iteration:1044  t-loss:0.1537, loss-lb:0.1511, loss-ulb:0.0635, weight:0.04, lr:0.0010
[10:50:10.308] iteration:1045  t-loss:0.1553, loss-lb:0.1511, loss-ulb:0.1020, weight:0.04, lr:0.0010
[10:50:10.499] iteration:1046  t-loss:0.1664, loss-lb:0.1643, loss-ulb:0.0496, weight:0.04, lr:0.0010
[10:50:10.690] iteration:1047  t-loss:0.1591, loss-lb:0.1566, loss-ulb:0.0593, weight:0.04, lr:0.0010
[10:50:10.882] iteration:1048  t-loss:0.1617, loss-lb:0.1573, loss-ulb:0.1077, weight:0.04, lr:0.0010
[10:50:11.073] iteration:1049  t-loss:0.1248, loss-lb:0.1214, loss-ulb:0.0830, weight:0.04, lr:0.0010
[10:50:11.264] iteration:1050  t-loss:0.1590, loss-lb:0.1543, loss-ulb:0.1124, weight:0.04, lr:0.0010
[10:50:11.456] iteration:1051  t-loss:0.2046, loss-lb:0.2021, loss-ulb:0.0491, weight:0.05, lr:0.0010
[10:50:11.649] iteration:1052  t-loss:0.2046, loss-lb:0.2011, loss-ulb:0.0708, weight:0.05, lr:0.0010
[10:50:11.840] iteration:1053  t-loss:0.1520, loss-lb:0.1484, loss-ulb:0.0736, weight:0.05, lr:0.0010
[10:50:12.033] iteration:1054  t-loss:0.1547, loss-lb:0.1528, loss-ulb:0.0374, weight:0.05, lr:0.0010
[10:50:12.223] iteration:1055  t-loss:0.1754, loss-lb:0.1727, loss-ulb:0.0549, weight:0.05, lr:0.0010
[10:50:12.416] iteration:1056  t-loss:0.1429, loss-lb:0.1399, loss-ulb:0.0614, weight:0.05, lr:0.0010
[10:50:12.608] iteration:1057  t-loss:0.1420, loss-lb:0.1366, loss-ulb:0.1094, weight:0.05, lr:0.0010
[10:50:12.798] iteration:1058  t-loss:0.1407, loss-lb:0.1316, loss-ulb:0.1840, weight:0.05, lr:0.0010
[10:50:12.989] iteration:1059  t-loss:0.1558, loss-lb:0.1537, loss-ulb:0.0430, weight:0.05, lr:0.0010
[10:50:13.181] iteration:1060  t-loss:0.1426, loss-lb:0.1362, loss-ulb:0.1310, weight:0.05, lr:0.0010
[10:50:13.371] iteration:1061  t-loss:0.1469, loss-lb:0.1416, loss-ulb:0.1070, weight:0.05, lr:0.0010
[10:50:13.562] iteration:1062  t-loss:0.1222, loss-lb:0.1192, loss-ulb:0.0611, weight:0.05, lr:0.0010
[10:50:13.752] iteration:1063  t-loss:0.1509, loss-lb:0.1493, loss-ulb:0.0332, weight:0.05, lr:0.0010
[10:50:13.943] iteration:1064  t-loss:0.1287, loss-lb:0.1264, loss-ulb:0.0478, weight:0.05, lr:0.0010
[10:50:14.134] iteration:1065  t-loss:0.1473, loss-lb:0.1445, loss-ulb:0.0558, weight:0.05, lr:0.0010
[10:50:14.326] iteration:1066  t-loss:0.1198, loss-lb:0.1183, loss-ulb:0.0299, weight:0.05, lr:0.0010
[10:50:14.520] iteration:1067  t-loss:0.1387, loss-lb:0.1348, loss-ulb:0.0800, weight:0.05, lr:0.0010
[10:50:14.714] iteration:1068  t-loss:0.1424, loss-lb:0.1389, loss-ulb:0.0701, weight:0.05, lr:0.0010
[10:50:14.908] iteration:1069  t-loss:0.1651, loss-lb:0.1604, loss-ulb:0.0965, weight:0.05, lr:0.0010
[10:50:15.101] iteration:1070  t-loss:0.1352, loss-lb:0.1333, loss-ulb:0.0388, weight:0.05, lr:0.0010
[10:50:15.295] iteration:1071  t-loss:0.1361, loss-lb:0.1319, loss-ulb:0.0850, weight:0.05, lr:0.0010
[10:50:15.485] iteration:1072  t-loss:0.1484, loss-lb:0.1454, loss-ulb:0.0601, weight:0.05, lr:0.0010
[10:50:15.677] iteration:1073  t-loss:0.1349, loss-lb:0.1323, loss-ulb:0.0536, weight:0.05, lr:0.0010
[10:50:15.867] iteration:1074  t-loss:0.1214, loss-lb:0.1162, loss-ulb:0.1063, weight:0.05, lr:0.0010
[10:50:16.058] iteration:1075  t-loss:0.1597, loss-lb:0.1561, loss-ulb:0.0727, weight:0.05, lr:0.0010
[10:50:16.247] iteration:1076  t-loss:0.1319, loss-lb:0.1293, loss-ulb:0.0534, weight:0.05, lr:0.0010
[10:50:16.438] iteration:1077  t-loss:0.1314, loss-lb:0.1267, loss-ulb:0.0944, weight:0.05, lr:0.0010
[10:50:16.628] iteration:1078  t-loss:0.1419, loss-lb:0.1397, loss-ulb:0.0440, weight:0.05, lr:0.0010
[10:50:28.980]  <<Test>> - Ep:10  - mean_dice/mean_h95 - S:85.03/4.36, Best-S:85.03, T:85.59/3.18, Best-T:85.59
[10:50:28.980]           - AvgLoss(lb/ulb/all):0.1460/0.0682/0.1401
[10:50:29.523] iteration:1079  t-loss:0.1517, loss-lb:0.1478, loss-ulb:0.0791, weight:0.05, lr:0.0010
[10:50:29.720] iteration:1080  t-loss:0.1567, loss-lb:0.1483, loss-ulb:0.1695, weight:0.05, lr:0.0010
[10:50:29.918] iteration:1081  t-loss:0.1260, loss-lb:0.1213, loss-ulb:0.0953, weight:0.05, lr:0.0010
[10:50:30.110] iteration:1082  t-loss:0.1342, loss-lb:0.1327, loss-ulb:0.0307, weight:0.05, lr:0.0010
[10:50:30.301] iteration:1083  t-loss:0.1360, loss-lb:0.1316, loss-ulb:0.0890, weight:0.05, lr:0.0010
[10:50:30.492] iteration:1084  t-loss:0.1451, loss-lb:0.1426, loss-ulb:0.0506, weight:0.05, lr:0.0010
[10:50:30.683] iteration:1085  t-loss:0.1468, loss-lb:0.1445, loss-ulb:0.0474, weight:0.05, lr:0.0010
[10:50:30.874] iteration:1086  t-loss:0.1574, loss-lb:0.1550, loss-ulb:0.0478, weight:0.05, lr:0.0010
[10:50:31.067] iteration:1087  t-loss:0.1369, loss-lb:0.1343, loss-ulb:0.0519, weight:0.05, lr:0.0010
[10:50:31.257] iteration:1088  t-loss:0.1326, loss-lb:0.1232, loss-ulb:0.1905, weight:0.05, lr:0.0010
[10:50:31.449] iteration:1089  t-loss:0.1381, loss-lb:0.1321, loss-ulb:0.1201, weight:0.05, lr:0.0010
[10:50:31.640] iteration:1090  t-loss:0.1342, loss-lb:0.1326, loss-ulb:0.0320, weight:0.05, lr:0.0010
[10:50:31.832] iteration:1091  t-loss:0.1254, loss-lb:0.1226, loss-ulb:0.0558, weight:0.05, lr:0.0010
[10:50:32.023] iteration:1092  t-loss:0.1441, loss-lb:0.1412, loss-ulb:0.0580, weight:0.05, lr:0.0010
[10:50:32.214] iteration:1093  t-loss:0.1367, loss-lb:0.1347, loss-ulb:0.0402, weight:0.05, lr:0.0010
[10:50:32.405] iteration:1094  t-loss:0.1355, loss-lb:0.1306, loss-ulb:0.0990, weight:0.05, lr:0.0010
[10:50:32.609] iteration:1095  t-loss:0.1614, loss-lb:0.1594, loss-ulb:0.0409, weight:0.05, lr:0.0010
[10:50:32.807] iteration:1096  t-loss:0.1454, loss-lb:0.1428, loss-ulb:0.0530, weight:0.05, lr:0.0010
[10:50:33.002] iteration:1097  t-loss:0.1536, loss-lb:0.1512, loss-ulb:0.0473, weight:0.05, lr:0.0010
[10:50:33.193] iteration:1098  t-loss:0.1517, loss-lb:0.1433, loss-ulb:0.1702, weight:0.05, lr:0.0010
[10:50:33.384] iteration:1099  t-loss:0.1464, loss-lb:0.1417, loss-ulb:0.0943, weight:0.05, lr:0.0010
[10:50:33.575] iteration:1100  t-loss:0.1586, loss-lb:0.1561, loss-ulb:0.0510, weight:0.05, lr:0.0010
[10:50:33.767] iteration:1101  t-loss:0.2119, loss-lb:0.2092, loss-ulb:0.0547, weight:0.05, lr:0.0010
[10:50:33.958] iteration:1102  t-loss:0.1318, loss-lb:0.1259, loss-ulb:0.1186, weight:0.05, lr:0.0010
[10:50:34.148] iteration:1103  t-loss:0.1486, loss-lb:0.1414, loss-ulb:0.1466, weight:0.05, lr:0.0010
[10:50:34.341] iteration:1104  t-loss:0.1454, loss-lb:0.1406, loss-ulb:0.0968, weight:0.05, lr:0.0010
[10:50:34.532] iteration:1105  t-loss:0.1548, loss-lb:0.1509, loss-ulb:0.0774, weight:0.05, lr:0.0010
[10:50:34.724] iteration:1106  t-loss:0.1416, loss-lb:0.1371, loss-ulb:0.0907, weight:0.05, lr:0.0010
[10:50:34.915] iteration:1107  t-loss:0.1539, loss-lb:0.1522, loss-ulb:0.0339, weight:0.05, lr:0.0010
[10:50:35.105] iteration:1108  t-loss:0.1445, loss-lb:0.1408, loss-ulb:0.0755, weight:0.05, lr:0.0010
[10:50:35.296] iteration:1109  t-loss:0.1358, loss-lb:0.1337, loss-ulb:0.0416, weight:0.05, lr:0.0010
[10:50:35.486] iteration:1110  t-loss:0.1374, loss-lb:0.1341, loss-ulb:0.0672, weight:0.05, lr:0.0010
[10:50:35.679] iteration:1111  t-loss:0.1307, loss-lb:0.1287, loss-ulb:0.0406, weight:0.05, lr:0.0010
[10:50:35.869] iteration:1112  t-loss:0.1728, loss-lb:0.1693, loss-ulb:0.0707, weight:0.05, lr:0.0010
[10:50:36.061] iteration:1113  t-loss:0.1306, loss-lb:0.1277, loss-ulb:0.0568, weight:0.05, lr:0.0010
[10:50:36.252] iteration:1114  t-loss:0.1362, loss-lb:0.1306, loss-ulb:0.1137, weight:0.05, lr:0.0010
[10:50:36.443] iteration:1115  t-loss:0.1518, loss-lb:0.1471, loss-ulb:0.0949, weight:0.05, lr:0.0010
[10:50:36.635] iteration:1116  t-loss:0.1514, loss-lb:0.1487, loss-ulb:0.0545, weight:0.05, lr:0.0010
[10:50:36.826] iteration:1117  t-loss:0.1308, loss-lb:0.1274, loss-ulb:0.0701, weight:0.05, lr:0.0010
[10:50:37.017] iteration:1118  t-loss:0.1538, loss-lb:0.1483, loss-ulb:0.1127, weight:0.05, lr:0.0010
[10:50:37.208] iteration:1119  t-loss:0.1435, loss-lb:0.1417, loss-ulb:0.0356, weight:0.05, lr:0.0010
[10:50:37.400] iteration:1120  t-loss:0.1287, loss-lb:0.1249, loss-ulb:0.0762, weight:0.05, lr:0.0010
[10:50:37.591] iteration:1121  t-loss:0.1318, loss-lb:0.1252, loss-ulb:0.1331, weight:0.05, lr:0.0010
[10:50:37.782] iteration:1122  t-loss:0.1707, loss-lb:0.1666, loss-ulb:0.0833, weight:0.05, lr:0.0010
[10:50:37.974] iteration:1123  t-loss:0.1586, loss-lb:0.1550, loss-ulb:0.0721, weight:0.05, lr:0.0010
[10:50:38.165] iteration:1124  t-loss:0.1361, loss-lb:0.1337, loss-ulb:0.0475, weight:0.05, lr:0.0010
[10:50:38.358] iteration:1125  t-loss:0.1291, loss-lb:0.1250, loss-ulb:0.0822, weight:0.05, lr:0.0010
[10:50:38.548] iteration:1126  t-loss:0.1256, loss-lb:0.1200, loss-ulb:0.1127, weight:0.05, lr:0.0010
[10:50:38.740] iteration:1127  t-loss:0.1348, loss-lb:0.1311, loss-ulb:0.0732, weight:0.05, lr:0.0010
[10:50:38.933] iteration:1128  t-loss:0.1237, loss-lb:0.1225, loss-ulb:0.0243, weight:0.05, lr:0.0010
[10:50:39.124] iteration:1129  t-loss:0.1214, loss-lb:0.1195, loss-ulb:0.0392, weight:0.05, lr:0.0010
[10:50:39.318] iteration:1130  t-loss:0.1753, loss-lb:0.1713, loss-ulb:0.0804, weight:0.05, lr:0.0010
[10:50:39.512] iteration:1131  t-loss:0.1467, loss-lb:0.1403, loss-ulb:0.1300, weight:0.05, lr:0.0010
[10:50:39.704] iteration:1132  t-loss:0.2178, loss-lb:0.2121, loss-ulb:0.1148, weight:0.05, lr:0.0010
[10:50:39.894] iteration:1133  t-loss:0.1324, loss-lb:0.1277, loss-ulb:0.0962, weight:0.05, lr:0.0010
[10:50:40.085] iteration:1134  t-loss:0.1626, loss-lb:0.1564, loss-ulb:0.1237, weight:0.05, lr:0.0010
[10:50:40.276] iteration:1135  t-loss:0.1264, loss-lb:0.1231, loss-ulb:0.0663, weight:0.05, lr:0.0010
[10:50:40.468] iteration:1136  t-loss:0.1379, loss-lb:0.1350, loss-ulb:0.0582, weight:0.05, lr:0.0010
[10:50:40.658] iteration:1137  t-loss:0.1247, loss-lb:0.1226, loss-ulb:0.0424, weight:0.05, lr:0.0010
[10:50:40.850] iteration:1138  t-loss:0.1327, loss-lb:0.1293, loss-ulb:0.0688, weight:0.05, lr:0.0010
[10:50:41.040] iteration:1139  t-loss:0.1476, loss-lb:0.1443, loss-ulb:0.0649, weight:0.05, lr:0.0010
[10:50:41.232] iteration:1140  t-loss:0.1246, loss-lb:0.1211, loss-ulb:0.0707, weight:0.05, lr:0.0010
[10:50:41.423] iteration:1141  t-loss:0.1646, loss-lb:0.1630, loss-ulb:0.0323, weight:0.05, lr:0.0010
[10:50:41.614] iteration:1142  t-loss:0.1152, loss-lb:0.1122, loss-ulb:0.0611, weight:0.05, lr:0.0010
[10:50:41.805] iteration:1143  t-loss:0.1364, loss-lb:0.1342, loss-ulb:0.0439, weight:0.05, lr:0.0010
[10:50:41.996] iteration:1144  t-loss:0.1617, loss-lb:0.1593, loss-ulb:0.0480, weight:0.05, lr:0.0010
[10:50:42.188] iteration:1145  t-loss:0.1903, loss-lb:0.1873, loss-ulb:0.0605, weight:0.05, lr:0.0010
[10:50:42.381] iteration:1146  t-loss:0.1272, loss-lb:0.1250, loss-ulb:0.0447, weight:0.05, lr:0.0010
[10:50:42.572] iteration:1147  t-loss:0.1456, loss-lb:0.1436, loss-ulb:0.0392, weight:0.05, lr:0.0010
[10:50:42.762] iteration:1148  t-loss:0.1554, loss-lb:0.1519, loss-ulb:0.0716, weight:0.05, lr:0.0010
[10:50:42.952] iteration:1149  t-loss:0.1485, loss-lb:0.1453, loss-ulb:0.0645, weight:0.05, lr:0.0010
[10:50:43.144] iteration:1150  t-loss:0.1274, loss-lb:0.1245, loss-ulb:0.0591, weight:0.05, lr:0.0010
[10:50:43.336] iteration:1151  t-loss:0.1410, loss-lb:0.1369, loss-ulb:0.0828, weight:0.05, lr:0.0010
[10:50:43.526] iteration:1152  t-loss:0.1532, loss-lb:0.1457, loss-ulb:0.1506, weight:0.05, lr:0.0010
[10:50:43.716] iteration:1153  t-loss:0.1410, loss-lb:0.1354, loss-ulb:0.1135, weight:0.05, lr:0.0010
[10:50:43.907] iteration:1154  t-loss:0.1287, loss-lb:0.1237, loss-ulb:0.1005, weight:0.05, lr:0.0010
[10:50:44.098] iteration:1155  t-loss:0.1315, loss-lb:0.1271, loss-ulb:0.0882, weight:0.05, lr:0.0010
[10:50:44.290] iteration:1156  t-loss:0.1692, loss-lb:0.1664, loss-ulb:0.0570, weight:0.05, lr:0.0010
[10:50:44.481] iteration:1157  t-loss:0.1488, loss-lb:0.1460, loss-ulb:0.0558, weight:0.05, lr:0.0010
[10:50:44.673] iteration:1158  t-loss:0.1395, loss-lb:0.1367, loss-ulb:0.0563, weight:0.05, lr:0.0010
[10:50:44.865] iteration:1159  t-loss:0.1306, loss-lb:0.1269, loss-ulb:0.0757, weight:0.05, lr:0.0010
[10:50:45.058] iteration:1160  t-loss:0.1656, loss-lb:0.1611, loss-ulb:0.0899, weight:0.05, lr:0.0010
[10:50:45.248] iteration:1161  t-loss:0.1236, loss-lb:0.1206, loss-ulb:0.0603, weight:0.05, lr:0.0010
[10:50:45.441] iteration:1162  t-loss:0.1458, loss-lb:0.1410, loss-ulb:0.0973, weight:0.05, lr:0.0010
[10:50:45.633] iteration:1163  t-loss:0.1717, loss-lb:0.1661, loss-ulb:0.1136, weight:0.05, lr:0.0010
[10:50:45.825] iteration:1164  t-loss:0.1647, loss-lb:0.1606, loss-ulb:0.0829, weight:0.05, lr:0.0010
[10:50:46.015] iteration:1165  t-loss:0.1400, loss-lb:0.1328, loss-ulb:0.1448, weight:0.05, lr:0.0010
[10:50:46.207] iteration:1166  t-loss:0.1350, loss-lb:0.1316, loss-ulb:0.0687, weight:0.05, lr:0.0010
[10:50:46.399] iteration:1167  t-loss:0.1420, loss-lb:0.1387, loss-ulb:0.0655, weight:0.05, lr:0.0010
[10:50:46.590] iteration:1168  t-loss:0.1260, loss-lb:0.1171, loss-ulb:0.1796, weight:0.05, lr:0.0010
[10:50:46.781] iteration:1169  t-loss:0.1551, loss-lb:0.1492, loss-ulb:0.1203, weight:0.05, lr:0.0010
[10:50:46.971] iteration:1170  t-loss:0.1389, loss-lb:0.1347, loss-ulb:0.0853, weight:0.05, lr:0.0010
[10:50:47.161] iteration:1171  t-loss:0.1276, loss-lb:0.1253, loss-ulb:0.0460, weight:0.05, lr:0.0010
[10:50:47.350] iteration:1172  t-loss:0.1332, loss-lb:0.1301, loss-ulb:0.0627, weight:0.05, lr:0.0010
[10:50:47.540] iteration:1173  t-loss:0.1587, loss-lb:0.1567, loss-ulb:0.0422, weight:0.05, lr:0.0010
[10:50:47.730] iteration:1174  t-loss:0.1395, loss-lb:0.1342, loss-ulb:0.1061, weight:0.05, lr:0.0010
[10:50:47.920] iteration:1175  t-loss:0.1186, loss-lb:0.1135, loss-ulb:0.1016, weight:0.05, lr:0.0010
[10:50:48.109] iteration:1176  t-loss:0.1528, loss-lb:0.1499, loss-ulb:0.0577, weight:0.05, lr:0.0010
[10:50:48.709] iteration:1177  t-loss:0.1446, loss-lb:0.1407, loss-ulb:0.0778, weight:0.05, lr:0.0010
[10:50:48.903] iteration:1178  t-loss:0.1416, loss-lb:0.1380, loss-ulb:0.0726, weight:0.05, lr:0.0010
[10:50:49.096] iteration:1179  t-loss:0.1382, loss-lb:0.1319, loss-ulb:0.1278, weight:0.05, lr:0.0010
[10:50:49.288] iteration:1180  t-loss:0.1500, loss-lb:0.1475, loss-ulb:0.0514, weight:0.05, lr:0.0010
[10:50:49.481] iteration:1181  t-loss:0.1237, loss-lb:0.1204, loss-ulb:0.0666, weight:0.05, lr:0.0010
[10:50:49.673] iteration:1182  t-loss:0.1371, loss-lb:0.1336, loss-ulb:0.0706, weight:0.05, lr:0.0010
[10:50:49.864] iteration:1183  t-loss:0.1464, loss-lb:0.1413, loss-ulb:0.1028, weight:0.05, lr:0.0010
[10:50:50.055] iteration:1184  t-loss:0.1310, loss-lb:0.1287, loss-ulb:0.0455, weight:0.05, lr:0.0010
[10:50:50.247] iteration:1185  t-loss:0.1372, loss-lb:0.1332, loss-ulb:0.0801, weight:0.05, lr:0.0010
[10:50:50.439] iteration:1186  t-loss:0.1149, loss-lb:0.1127, loss-ulb:0.0451, weight:0.05, lr:0.0010
[10:50:50.631] iteration:1187  t-loss:0.1528, loss-lb:0.1470, loss-ulb:0.1157, weight:0.05, lr:0.0010
[10:50:50.823] iteration:1188  t-loss:0.1179, loss-lb:0.1123, loss-ulb:0.1139, weight:0.05, lr:0.0010
[10:50:51.013] iteration:1189  t-loss:0.1202, loss-lb:0.1160, loss-ulb:0.0858, weight:0.05, lr:0.0010
[10:50:51.206] iteration:1190  t-loss:0.1455, loss-lb:0.1430, loss-ulb:0.0502, weight:0.05, lr:0.0010
[10:50:51.397] iteration:1191  t-loss:0.1436, loss-lb:0.1409, loss-ulb:0.0546, weight:0.05, lr:0.0010
[10:50:51.589] iteration:1192  t-loss:0.1273, loss-lb:0.1258, loss-ulb:0.0305, weight:0.05, lr:0.0010
[10:50:51.780] iteration:1193  t-loss:0.1276, loss-lb:0.1250, loss-ulb:0.0535, weight:0.05, lr:0.0010
[10:50:51.971] iteration:1194  t-loss:0.1248, loss-lb:0.1228, loss-ulb:0.0404, weight:0.05, lr:0.0010
[10:50:52.164] iteration:1195  t-loss:0.1353, loss-lb:0.1314, loss-ulb:0.0804, weight:0.05, lr:0.0010
[10:50:52.357] iteration:1196  t-loss:0.1227, loss-lb:0.1207, loss-ulb:0.0396, weight:0.05, lr:0.0010
[10:50:52.548] iteration:1197  t-loss:0.1389, loss-lb:0.1372, loss-ulb:0.0333, weight:0.05, lr:0.0010
[10:50:52.739] iteration:1198  t-loss:0.1497, loss-lb:0.1452, loss-ulb:0.0898, weight:0.05, lr:0.0010
[10:50:52.931] iteration:1199  t-loss:0.1360, loss-lb:0.1341, loss-ulb:0.0392, weight:0.05, lr:0.0010
[10:50:53.122] iteration:1200  t-loss:0.1102, loss-lb:0.1083, loss-ulb:0.0379, weight:0.05, lr:0.0010
[10:50:53.314] iteration:1201  t-loss:0.1405, loss-lb:0.1364, loss-ulb:0.0699, weight:0.06, lr:0.0010
[10:50:53.505] iteration:1202  t-loss:0.1303, loss-lb:0.1268, loss-ulb:0.0592, weight:0.06, lr:0.0010
[10:50:53.697] iteration:1203  t-loss:0.1237, loss-lb:0.1180, loss-ulb:0.0976, weight:0.06, lr:0.0010
[10:50:53.889] iteration:1204  t-loss:0.1365, loss-lb:0.1335, loss-ulb:0.0516, weight:0.06, lr:0.0010
[10:50:54.079] iteration:1205  t-loss:0.1188, loss-lb:0.1170, loss-ulb:0.0315, weight:0.06, lr:0.0010
[10:50:54.271] iteration:1206  t-loss:0.1465, loss-lb:0.1438, loss-ulb:0.0449, weight:0.06, lr:0.0010
[10:50:54.463] iteration:1207  t-loss:0.1317, loss-lb:0.1288, loss-ulb:0.0487, weight:0.06, lr:0.0010
[10:50:54.655] iteration:1208  t-loss:0.1273, loss-lb:0.1234, loss-ulb:0.0660, weight:0.06, lr:0.0010
[10:50:54.846] iteration:1209  t-loss:0.1317, loss-lb:0.1287, loss-ulb:0.0515, weight:0.06, lr:0.0010
[10:50:55.037] iteration:1210  t-loss:0.1504, loss-lb:0.1486, loss-ulb:0.0315, weight:0.06, lr:0.0010
[10:50:55.227] iteration:1211  t-loss:0.1234, loss-lb:0.1148, loss-ulb:0.1466, weight:0.06, lr:0.0010
[10:50:55.419] iteration:1212  t-loss:0.1252, loss-lb:0.1208, loss-ulb:0.0755, weight:0.06, lr:0.0010
[10:50:55.610] iteration:1213  t-loss:0.1310, loss-lb:0.1284, loss-ulb:0.0431, weight:0.06, lr:0.0010
[10:50:55.815] iteration:1214  t-loss:0.1339, loss-lb:0.1298, loss-ulb:0.0699, weight:0.06, lr:0.0010
[10:50:56.007] iteration:1215  t-loss:0.1388, loss-lb:0.1367, loss-ulb:0.0350, weight:0.06, lr:0.0010
[10:50:56.200] iteration:1216  t-loss:0.1532, loss-lb:0.1500, loss-ulb:0.0538, weight:0.06, lr:0.0010
[10:50:56.392] iteration:1217  t-loss:0.1807, loss-lb:0.1771, loss-ulb:0.0612, weight:0.06, lr:0.0010
[10:50:56.596] iteration:1218  t-loss:0.1140, loss-lb:0.1096, loss-ulb:0.0738, weight:0.06, lr:0.0010
[10:50:56.792] iteration:1219  t-loss:0.1387, loss-lb:0.1354, loss-ulb:0.0572, weight:0.06, lr:0.0010
[10:50:56.985] iteration:1220  t-loss:0.1280, loss-lb:0.1255, loss-ulb:0.0431, weight:0.06, lr:0.0010
[10:50:57.177] iteration:1221  t-loss:0.1304, loss-lb:0.1272, loss-ulb:0.0552, weight:0.06, lr:0.0010
[10:50:57.369] iteration:1222  t-loss:0.1459, loss-lb:0.1397, loss-ulb:0.1051, weight:0.06, lr:0.0010
[10:50:57.560] iteration:1223  t-loss:0.1364, loss-lb:0.1327, loss-ulb:0.0634, weight:0.06, lr:0.0010
[10:50:57.751] iteration:1224  t-loss:0.1342, loss-lb:0.1297, loss-ulb:0.0771, weight:0.06, lr:0.0010
[10:50:57.943] iteration:1225  t-loss:0.1250, loss-lb:0.1189, loss-ulb:0.1040, weight:0.06, lr:0.0010
[10:50:58.134] iteration:1226  t-loss:0.1330, loss-lb:0.1311, loss-ulb:0.0329, weight:0.06, lr:0.0010
[10:50:58.325] iteration:1227  t-loss:0.1336, loss-lb:0.1313, loss-ulb:0.0390, weight:0.06, lr:0.0010
[10:50:58.517] iteration:1228  t-loss:0.1238, loss-lb:0.1218, loss-ulb:0.0330, weight:0.06, lr:0.0010
[10:50:58.709] iteration:1229  t-loss:0.1387, loss-lb:0.1347, loss-ulb:0.0679, weight:0.06, lr:0.0010
[10:50:58.900] iteration:1230  t-loss:0.1286, loss-lb:0.1260, loss-ulb:0.0443, weight:0.06, lr:0.0010
[10:50:59.092] iteration:1231  t-loss:0.1216, loss-lb:0.1182, loss-ulb:0.0582, weight:0.06, lr:0.0010
[10:50:59.284] iteration:1232  t-loss:0.1599, loss-lb:0.1535, loss-ulb:0.1086, weight:0.06, lr:0.0010
[10:50:59.477] iteration:1233  t-loss:0.1302, loss-lb:0.1287, loss-ulb:0.0262, weight:0.06, lr:0.0010
[10:50:59.670] iteration:1234  t-loss:0.1410, loss-lb:0.1382, loss-ulb:0.0483, weight:0.06, lr:0.0010
[10:50:59.862] iteration:1235  t-loss:0.1371, loss-lb:0.1316, loss-ulb:0.0942, weight:0.06, lr:0.0010
[10:51:00.054] iteration:1236  t-loss:0.1364, loss-lb:0.1332, loss-ulb:0.0550, weight:0.06, lr:0.0010
[10:51:00.246] iteration:1237  t-loss:0.1369, loss-lb:0.1333, loss-ulb:0.0611, weight:0.06, lr:0.0010
[10:51:00.438] iteration:1238  t-loss:0.1302, loss-lb:0.1281, loss-ulb:0.0361, weight:0.06, lr:0.0010
[10:51:00.630] iteration:1239  t-loss:0.1274, loss-lb:0.1251, loss-ulb:0.0387, weight:0.06, lr:0.0010
[10:51:00.822] iteration:1240  t-loss:0.1379, loss-lb:0.1337, loss-ulb:0.0727, weight:0.06, lr:0.0010
[10:51:01.016] iteration:1241  t-loss:0.1567, loss-lb:0.1546, loss-ulb:0.0365, weight:0.06, lr:0.0010
[10:51:01.207] iteration:1242  t-loss:0.1620, loss-lb:0.1599, loss-ulb:0.0367, weight:0.06, lr:0.0010
[10:51:01.398] iteration:1243  t-loss:0.1460, loss-lb:0.1435, loss-ulb:0.0428, weight:0.06, lr:0.0010
[10:51:01.590] iteration:1244  t-loss:0.1387, loss-lb:0.1353, loss-ulb:0.0581, weight:0.06, lr:0.0010
[10:51:01.782] iteration:1245  t-loss:0.1290, loss-lb:0.1244, loss-ulb:0.0789, weight:0.06, lr:0.0010
[10:51:01.973] iteration:1246  t-loss:0.1231, loss-lb:0.1191, loss-ulb:0.0680, weight:0.06, lr:0.0010
[10:51:02.167] iteration:1247  t-loss:0.1455, loss-lb:0.1432, loss-ulb:0.0400, weight:0.06, lr:0.0010
[10:51:02.358] iteration:1248  t-loss:0.1678, loss-lb:0.1659, loss-ulb:0.0319, weight:0.06, lr:0.0010
[10:51:02.550] iteration:1249  t-loss:0.1379, loss-lb:0.1326, loss-ulb:0.0903, weight:0.06, lr:0.0010
[10:51:02.744] iteration:1250  t-loss:0.1864, loss-lb:0.1823, loss-ulb:0.0684, weight:0.06, lr:0.0010
[10:51:02.937] iteration:1251  t-loss:0.1337, loss-lb:0.1304, loss-ulb:0.0555, weight:0.06, lr:0.0010
[10:51:03.129] iteration:1252  t-loss:0.1273, loss-lb:0.1208, loss-ulb:0.1102, weight:0.06, lr:0.0010
[10:51:03.322] iteration:1253  t-loss:0.1756, loss-lb:0.1702, loss-ulb:0.0918, weight:0.06, lr:0.0010
[10:51:03.514] iteration:1254  t-loss:0.1594, loss-lb:0.1532, loss-ulb:0.1065, weight:0.06, lr:0.0010
[10:51:03.706] iteration:1255  t-loss:0.1433, loss-lb:0.1413, loss-ulb:0.0351, weight:0.06, lr:0.0010
[10:51:03.898] iteration:1256  t-loss:0.1409, loss-lb:0.1385, loss-ulb:0.0394, weight:0.06, lr:0.0010
[10:51:04.090] iteration:1257  t-loss:0.1862, loss-lb:0.1790, loss-ulb:0.1224, weight:0.06, lr:0.0010
[10:51:04.282] iteration:1258  t-loss:0.2319, loss-lb:0.2253, loss-ulb:0.1130, weight:0.06, lr:0.0010
[10:51:04.474] iteration:1259  t-loss:0.1242, loss-lb:0.1213, loss-ulb:0.0492, weight:0.06, lr:0.0010
[10:51:04.666] iteration:1260  t-loss:0.1702, loss-lb:0.1675, loss-ulb:0.0464, weight:0.06, lr:0.0010
[10:51:04.858] iteration:1261  t-loss:0.1595, loss-lb:0.1536, loss-ulb:0.0996, weight:0.06, lr:0.0010
[10:51:05.052] iteration:1262  t-loss:0.1572, loss-lb:0.1540, loss-ulb:0.0539, weight:0.06, lr:0.0010
[10:51:05.243] iteration:1263  t-loss:0.1915, loss-lb:0.1853, loss-ulb:0.1049, weight:0.06, lr:0.0010
[10:51:05.435] iteration:1264  t-loss:0.1388, loss-lb:0.1348, loss-ulb:0.0683, weight:0.06, lr:0.0010
[10:51:05.628] iteration:1265  t-loss:0.1513, loss-lb:0.1472, loss-ulb:0.0704, weight:0.06, lr:0.0010
[10:51:05.823] iteration:1266  t-loss:0.1810, loss-lb:0.1766, loss-ulb:0.0754, weight:0.06, lr:0.0010
[10:51:06.015] iteration:1267  t-loss:0.1541, loss-lb:0.1480, loss-ulb:0.1041, weight:0.06, lr:0.0010
[10:51:06.206] iteration:1268  t-loss:0.2178, loss-lb:0.2126, loss-ulb:0.0886, weight:0.06, lr:0.0010
[10:51:06.396] iteration:1269  t-loss:0.1412, loss-lb:0.1373, loss-ulb:0.0669, weight:0.06, lr:0.0010
[10:51:06.587] iteration:1270  t-loss:0.1738, loss-lb:0.1674, loss-ulb:0.1082, weight:0.06, lr:0.0010
[10:51:06.778] iteration:1271  t-loss:0.1565, loss-lb:0.1524, loss-ulb:0.0697, weight:0.06, lr:0.0010
[10:51:06.968] iteration:1272  t-loss:0.1456, loss-lb:0.1396, loss-ulb:0.1030, weight:0.06, lr:0.0010
[10:51:07.158] iteration:1273  t-loss:0.1264, loss-lb:0.1197, loss-ulb:0.1147, weight:0.06, lr:0.0010
[10:51:07.349] iteration:1274  t-loss:0.1661, loss-lb:0.1610, loss-ulb:0.0870, weight:0.06, lr:0.0010
[10:51:18.466]  <<Test>> - Ep:12  - mean_dice/mean_h95 - S:79.95/21.98, Best-S:85.03, T:86.22/6.75, Best-T:86.22
[10:51:18.466]           - AvgLoss(lb/ulb/all):0.1386/0.0810/0.1629
[10:51:18.991] iteration:1275  t-loss:0.1491, loss-lb:0.1428, loss-ulb:0.1072, weight:0.06, lr:0.0010
[10:51:19.185] iteration:1276  t-loss:0.1908, loss-lb:0.1857, loss-ulb:0.0861, weight:0.06, lr:0.0010
[10:51:19.377] iteration:1277  t-loss:0.1481, loss-lb:0.1429, loss-ulb:0.0879, weight:0.06, lr:0.0010
[10:51:19.569] iteration:1278  t-loss:0.1640, loss-lb:0.1606, loss-ulb:0.0584, weight:0.06, lr:0.0010
[10:51:19.762] iteration:1279  t-loss:0.1302, loss-lb:0.1271, loss-ulb:0.0535, weight:0.06, lr:0.0010
[10:51:19.952] iteration:1280  t-loss:0.1732, loss-lb:0.1663, loss-ulb:0.1177, weight:0.06, lr:0.0010
[10:51:20.148] iteration:1281  t-loss:0.1862, loss-lb:0.1809, loss-ulb:0.0903, weight:0.06, lr:0.0010
[10:51:20.341] iteration:1282  t-loss:0.1513, loss-lb:0.1441, loss-ulb:0.1225, weight:0.06, lr:0.0010
[10:51:20.533] iteration:1283  t-loss:0.1245, loss-lb:0.1203, loss-ulb:0.0722, weight:0.06, lr:0.0010
[10:51:20.727] iteration:1284  t-loss:0.1424, loss-lb:0.1392, loss-ulb:0.0546, weight:0.06, lr:0.0010
[10:51:20.919] iteration:1285  t-loss:0.1481, loss-lb:0.1399, loss-ulb:0.1402, weight:0.06, lr:0.0010
[10:51:21.112] iteration:1286  t-loss:0.1837, loss-lb:0.1750, loss-ulb:0.1472, weight:0.06, lr:0.0010
[10:51:21.304] iteration:1287  t-loss:0.1581, loss-lb:0.1454, loss-ulb:0.2161, weight:0.06, lr:0.0010
[10:51:21.495] iteration:1288  t-loss:0.2117, loss-lb:0.2093, loss-ulb:0.0410, weight:0.06, lr:0.0010
[10:51:21.687] iteration:1289  t-loss:0.1284, loss-lb:0.1218, loss-ulb:0.1132, weight:0.06, lr:0.0010
[10:51:21.880] iteration:1290  t-loss:0.1532, loss-lb:0.1503, loss-ulb:0.0495, weight:0.06, lr:0.0010
[10:51:22.072] iteration:1291  t-loss:0.1523, loss-lb:0.1474, loss-ulb:0.0838, weight:0.06, lr:0.0010
[10:51:22.263] iteration:1292  t-loss:0.2046, loss-lb:0.1972, loss-ulb:0.1271, weight:0.06, lr:0.0010
[10:51:22.454] iteration:1293  t-loss:0.1759, loss-lb:0.1724, loss-ulb:0.0598, weight:0.06, lr:0.0010
[10:51:22.646] iteration:1294  t-loss:0.1683, loss-lb:0.1603, loss-ulb:0.1363, weight:0.06, lr:0.0010
[10:51:22.837] iteration:1295  t-loss:0.1363, loss-lb:0.1317, loss-ulb:0.0788, weight:0.06, lr:0.0010
[10:51:23.028] iteration:1296  t-loss:0.1619, loss-lb:0.1555, loss-ulb:0.1093, weight:0.06, lr:0.0010
[10:51:23.220] iteration:1297  t-loss:0.2956, loss-lb:0.2847, loss-ulb:0.1854, weight:0.06, lr:0.0010
[10:51:23.411] iteration:1298  t-loss:0.1433, loss-lb:0.1390, loss-ulb:0.0722, weight:0.06, lr:0.0010
[10:51:23.601] iteration:1299  t-loss:0.1528, loss-lb:0.1470, loss-ulb:0.0983, weight:0.06, lr:0.0010
[10:51:23.791] iteration:1300  t-loss:0.2748, loss-lb:0.2696, loss-ulb:0.0874, weight:0.06, lr:0.0010
[10:51:23.981] iteration:1301  t-loss:0.1711, loss-lb:0.1663, loss-ulb:0.0825, weight:0.06, lr:0.0010
[10:51:24.170] iteration:1302  t-loss:0.1353, loss-lb:0.1281, loss-ulb:0.1216, weight:0.06, lr:0.0010
[10:51:24.360] iteration:1303  t-loss:0.1665, loss-lb:0.1620, loss-ulb:0.0770, weight:0.06, lr:0.0010
[10:51:24.552] iteration:1304  t-loss:0.1584, loss-lb:0.1525, loss-ulb:0.1008, weight:0.06, lr:0.0010
[10:51:24.744] iteration:1305  t-loss:0.1595, loss-lb:0.1542, loss-ulb:0.0895, weight:0.06, lr:0.0010
[10:51:24.942] iteration:1306  t-loss:0.1705, loss-lb:0.1648, loss-ulb:0.0964, weight:0.06, lr:0.0010
[10:51:25.135] iteration:1307  t-loss:0.1412, loss-lb:0.1347, loss-ulb:0.1109, weight:0.06, lr:0.0010
[10:51:25.330] iteration:1308  t-loss:0.2177, loss-lb:0.2122, loss-ulb:0.0931, weight:0.06, lr:0.0010
[10:51:25.523] iteration:1309  t-loss:0.1950, loss-lb:0.1918, loss-ulb:0.0544, weight:0.06, lr:0.0010
[10:51:25.716] iteration:1310  t-loss:0.1550, loss-lb:0.1494, loss-ulb:0.0962, weight:0.06, lr:0.0010
[10:51:25.908] iteration:1311  t-loss:0.1471, loss-lb:0.1425, loss-ulb:0.0792, weight:0.06, lr:0.0010
[10:51:26.101] iteration:1312  t-loss:0.1928, loss-lb:0.1836, loss-ulb:0.1553, weight:0.06, lr:0.0010
[10:51:26.292] iteration:1313  t-loss:0.1529, loss-lb:0.1460, loss-ulb:0.1178, weight:0.06, lr:0.0010
[10:51:26.483] iteration:1314  t-loss:0.1615, loss-lb:0.1563, loss-ulb:0.0888, weight:0.06, lr:0.0010
[10:51:26.675] iteration:1315  t-loss:0.1543, loss-lb:0.1505, loss-ulb:0.0644, weight:0.06, lr:0.0010
[10:51:26.867] iteration:1316  t-loss:0.1412, loss-lb:0.1355, loss-ulb:0.0983, weight:0.06, lr:0.0010
[10:51:27.060] iteration:1317  t-loss:0.1368, loss-lb:0.1331, loss-ulb:0.0630, weight:0.06, lr:0.0010
[10:51:27.251] iteration:1318  t-loss:0.1434, loss-lb:0.1373, loss-ulb:0.1040, weight:0.06, lr:0.0010
[10:51:27.442] iteration:1319  t-loss:0.1654, loss-lb:0.1588, loss-ulb:0.1116, weight:0.06, lr:0.0010
[10:51:27.635] iteration:1320  t-loss:0.1681, loss-lb:0.1656, loss-ulb:0.0417, weight:0.06, lr:0.0010
[10:51:27.826] iteration:1321  t-loss:0.1419, loss-lb:0.1365, loss-ulb:0.0927, weight:0.06, lr:0.0010
[10:51:28.018] iteration:1322  t-loss:0.1462, loss-lb:0.1439, loss-ulb:0.0393, weight:0.06, lr:0.0010
[10:51:28.209] iteration:1323  t-loss:0.1323, loss-lb:0.1265, loss-ulb:0.0996, weight:0.06, lr:0.0010
[10:51:28.400] iteration:1324  t-loss:0.1488, loss-lb:0.1444, loss-ulb:0.0764, weight:0.06, lr:0.0010
[10:51:28.592] iteration:1325  t-loss:0.1573, loss-lb:0.1555, loss-ulb:0.0308, weight:0.06, lr:0.0010
[10:51:28.783] iteration:1326  t-loss:0.1447, loss-lb:0.1398, loss-ulb:0.0836, weight:0.06, lr:0.0010
[10:51:28.975] iteration:1327  t-loss:0.1263, loss-lb:0.1211, loss-ulb:0.0883, weight:0.06, lr:0.0010
[10:51:29.168] iteration:1328  t-loss:0.1436, loss-lb:0.1419, loss-ulb:0.0295, weight:0.06, lr:0.0010
[10:51:29.374] iteration:1329  t-loss:0.1405, loss-lb:0.1337, loss-ulb:0.1156, weight:0.06, lr:0.0010
[10:51:29.572] iteration:1330  t-loss:0.1502, loss-lb:0.1473, loss-ulb:0.0506, weight:0.06, lr:0.0010
[10:51:29.766] iteration:1331  t-loss:0.1525, loss-lb:0.1501, loss-ulb:0.0408, weight:0.06, lr:0.0010
[10:51:29.956] iteration:1332  t-loss:0.1799, loss-lb:0.1715, loss-ulb:0.1435, weight:0.06, lr:0.0010
[10:51:30.147] iteration:1333  t-loss:0.1306, loss-lb:0.1257, loss-ulb:0.0833, weight:0.06, lr:0.0010
[10:51:30.337] iteration:1334  t-loss:0.1428, loss-lb:0.1357, loss-ulb:0.1203, weight:0.06, lr:0.0010
[10:51:30.541] iteration:1335  t-loss:0.1355, loss-lb:0.1300, loss-ulb:0.0928, weight:0.06, lr:0.0010
[10:51:30.737] iteration:1336  t-loss:0.1951, loss-lb:0.1918, loss-ulb:0.0564, weight:0.06, lr:0.0010
[10:51:30.929] iteration:1337  t-loss:0.1462, loss-lb:0.1415, loss-ulb:0.0793, weight:0.06, lr:0.0010
[10:51:31.120] iteration:1338  t-loss:0.1428, loss-lb:0.1406, loss-ulb:0.0373, weight:0.06, lr:0.0010
[10:51:31.313] iteration:1339  t-loss:0.1446, loss-lb:0.1406, loss-ulb:0.0680, weight:0.06, lr:0.0010
[10:51:31.506] iteration:1340  t-loss:0.1531, loss-lb:0.1498, loss-ulb:0.0559, weight:0.06, lr:0.0010
[10:51:31.702] iteration:1341  t-loss:0.1252, loss-lb:0.1231, loss-ulb:0.0351, weight:0.06, lr:0.0010
[10:51:31.896] iteration:1342  t-loss:0.1405, loss-lb:0.1383, loss-ulb:0.0367, weight:0.06, lr:0.0010
[10:51:32.089] iteration:1343  t-loss:0.1344, loss-lb:0.1316, loss-ulb:0.0480, weight:0.06, lr:0.0010
[10:51:32.285] iteration:1344  t-loss:0.1398, loss-lb:0.1378, loss-ulb:0.0329, weight:0.06, lr:0.0010
[10:51:32.478] iteration:1345  t-loss:0.1379, loss-lb:0.1261, loss-ulb:0.2017, weight:0.06, lr:0.0010
[10:51:32.670] iteration:1346  t-loss:0.1289, loss-lb:0.1256, loss-ulb:0.0572, weight:0.06, lr:0.0010
[10:51:32.861] iteration:1347  t-loss:0.1396, loss-lb:0.1337, loss-ulb:0.0996, weight:0.06, lr:0.0010
[10:51:33.054] iteration:1348  t-loss:0.1248, loss-lb:0.1223, loss-ulb:0.0429, weight:0.06, lr:0.0010
[10:51:33.251] iteration:1349  t-loss:0.1408, loss-lb:0.1375, loss-ulb:0.0563, weight:0.06, lr:0.0010
[10:51:33.443] iteration:1350  t-loss:0.1571, loss-lb:0.1536, loss-ulb:0.0600, weight:0.06, lr:0.0010
[10:51:33.634] iteration:1351  t-loss:0.1560, loss-lb:0.1533, loss-ulb:0.0378, weight:0.07, lr:0.0010
[10:51:33.828] iteration:1352  t-loss:0.1294, loss-lb:0.1252, loss-ulb:0.0604, weight:0.07, lr:0.0010
[10:51:34.032] iteration:1353  t-loss:0.1340, loss-lb:0.1302, loss-ulb:0.0548, weight:0.07, lr:0.0010
[10:51:34.230] iteration:1354  t-loss:0.1356, loss-lb:0.1320, loss-ulb:0.0529, weight:0.07, lr:0.0010
[10:51:34.423] iteration:1355  t-loss:0.1430, loss-lb:0.1396, loss-ulb:0.0500, weight:0.07, lr:0.0010
[10:51:34.616] iteration:1356  t-loss:0.1283, loss-lb:0.1243, loss-ulb:0.0569, weight:0.07, lr:0.0010
[10:51:34.807] iteration:1357  t-loss:0.1216, loss-lb:0.1179, loss-ulb:0.0534, weight:0.07, lr:0.0010
[10:51:34.998] iteration:1358  t-loss:0.1340, loss-lb:0.1302, loss-ulb:0.0556, weight:0.07, lr:0.0010
[10:51:35.191] iteration:1359  t-loss:0.1284, loss-lb:0.1253, loss-ulb:0.0451, weight:0.07, lr:0.0010
[10:51:35.384] iteration:1360  t-loss:0.1186, loss-lb:0.1129, loss-ulb:0.0822, weight:0.07, lr:0.0010
[10:51:35.575] iteration:1361  t-loss:0.1204, loss-lb:0.1160, loss-ulb:0.0638, weight:0.07, lr:0.0010
[10:51:35.767] iteration:1362  t-loss:0.1294, loss-lb:0.1263, loss-ulb:0.0454, weight:0.07, lr:0.0010
[10:51:35.959] iteration:1363  t-loss:0.1723, loss-lb:0.1684, loss-ulb:0.0570, weight:0.07, lr:0.0010
[10:51:36.151] iteration:1364  t-loss:0.1241, loss-lb:0.1202, loss-ulb:0.0556, weight:0.07, lr:0.0010
[10:51:36.342] iteration:1365  t-loss:0.1344, loss-lb:0.1315, loss-ulb:0.0411, weight:0.07, lr:0.0010
[10:51:36.533] iteration:1366  t-loss:0.1354, loss-lb:0.1307, loss-ulb:0.0682, weight:0.07, lr:0.0010
[10:51:36.721] iteration:1367  t-loss:0.1274, loss-lb:0.1189, loss-ulb:0.1234, weight:0.07, lr:0.0010
[10:51:36.910] iteration:1368  t-loss:0.1432, loss-lb:0.1402, loss-ulb:0.0421, weight:0.07, lr:0.0010
[10:51:37.099] iteration:1369  t-loss:0.1154, loss-lb:0.1121, loss-ulb:0.0472, weight:0.07, lr:0.0010
[10:51:37.288] iteration:1370  t-loss:0.1330, loss-lb:0.1310, loss-ulb:0.0290, weight:0.07, lr:0.0010
[10:51:37.477] iteration:1371  t-loss:0.1240, loss-lb:0.1205, loss-ulb:0.0507, weight:0.07, lr:0.0010
[10:51:37.667] iteration:1372  t-loss:0.1298, loss-lb:0.1272, loss-ulb:0.0379, weight:0.07, lr:0.0010
[10:51:38.245] iteration:1373  t-loss:0.1542, loss-lb:0.1448, loss-ulb:0.1350, weight:0.07, lr:0.0010
[10:51:38.442] iteration:1374  t-loss:0.1255, loss-lb:0.1211, loss-ulb:0.0639, weight:0.07, lr:0.0010
[10:51:38.638] iteration:1375  t-loss:0.1361, loss-lb:0.1246, loss-ulb:0.1662, weight:0.07, lr:0.0010
[10:51:38.830] iteration:1376  t-loss:0.1549, loss-lb:0.1524, loss-ulb:0.0364, weight:0.07, lr:0.0010
[10:51:39.021] iteration:1377  t-loss:0.1290, loss-lb:0.1269, loss-ulb:0.0311, weight:0.07, lr:0.0010
[10:51:39.212] iteration:1378  t-loss:0.1282, loss-lb:0.1233, loss-ulb:0.0701, weight:0.07, lr:0.0010
[10:51:39.404] iteration:1379  t-loss:0.1320, loss-lb:0.1289, loss-ulb:0.0453, weight:0.07, lr:0.0010
[10:51:39.596] iteration:1380  t-loss:0.1195, loss-lb:0.1159, loss-ulb:0.0525, weight:0.07, lr:0.0010
[10:51:39.788] iteration:1381  t-loss:0.1104, loss-lb:0.1074, loss-ulb:0.0431, weight:0.07, lr:0.0010
[10:51:39.980] iteration:1382  t-loss:0.1327, loss-lb:0.1267, loss-ulb:0.0878, weight:0.07, lr:0.0010
[10:51:40.173] iteration:1383  t-loss:0.1436, loss-lb:0.1328, loss-ulb:0.1547, weight:0.07, lr:0.0010
[10:51:40.366] iteration:1384  t-loss:0.1392, loss-lb:0.1312, loss-ulb:0.1151, weight:0.07, lr:0.0010
[10:51:40.558] iteration:1385  t-loss:0.1307, loss-lb:0.1247, loss-ulb:0.0867, weight:0.07, lr:0.0010
[10:51:40.750] iteration:1386  t-loss:0.1058, loss-lb:0.1027, loss-ulb:0.0440, weight:0.07, lr:0.0010
[10:51:40.942] iteration:1387  t-loss:0.1389, loss-lb:0.1345, loss-ulb:0.0623, weight:0.07, lr:0.0010
[10:51:41.133] iteration:1388  t-loss:0.1269, loss-lb:0.1237, loss-ulb:0.0462, weight:0.07, lr:0.0010
[10:51:41.325] iteration:1389  t-loss:0.1186, loss-lb:0.1136, loss-ulb:0.0722, weight:0.07, lr:0.0010
[10:51:41.516] iteration:1390  t-loss:0.1643, loss-lb:0.1611, loss-ulb:0.0468, weight:0.07, lr:0.0010
[10:51:41.708] iteration:1391  t-loss:0.1275, loss-lb:0.1224, loss-ulb:0.0731, weight:0.07, lr:0.0010
[10:51:41.898] iteration:1392  t-loss:0.1277, loss-lb:0.1244, loss-ulb:0.0468, weight:0.07, lr:0.0010
[10:51:42.090] iteration:1393  t-loss:0.1387, loss-lb:0.1344, loss-ulb:0.0624, weight:0.07, lr:0.0010
[10:51:42.284] iteration:1394  t-loss:0.1528, loss-lb:0.1476, loss-ulb:0.0751, weight:0.07, lr:0.0010
[10:51:42.476] iteration:1395  t-loss:0.1315, loss-lb:0.1280, loss-ulb:0.0508, weight:0.07, lr:0.0010
[10:51:42.667] iteration:1396  t-loss:0.1310, loss-lb:0.1263, loss-ulb:0.0683, weight:0.07, lr:0.0010
[10:51:42.857] iteration:1397  t-loss:0.1366, loss-lb:0.1325, loss-ulb:0.0592, weight:0.07, lr:0.0010
[10:51:43.049] iteration:1398  t-loss:0.1719, loss-lb:0.1675, loss-ulb:0.0636, weight:0.07, lr:0.0010
[10:51:43.240] iteration:1399  t-loss:0.1204, loss-lb:0.1145, loss-ulb:0.0845, weight:0.07, lr:0.0010
[10:51:43.430] iteration:1400  t-loss:0.1246, loss-lb:0.1223, loss-ulb:0.0333, weight:0.07, lr:0.0010
[10:51:43.622] iteration:1401  t-loss:0.1240, loss-lb:0.1178, loss-ulb:0.0888, weight:0.07, lr:0.0010
[10:51:43.813] iteration:1402  t-loss:0.1411, loss-lb:0.1381, loss-ulb:0.0428, weight:0.07, lr:0.0010
[10:51:44.004] iteration:1403  t-loss:0.1219, loss-lb:0.1184, loss-ulb:0.0509, weight:0.07, lr:0.0010
[10:51:44.195] iteration:1404  t-loss:0.1656, loss-lb:0.1589, loss-ulb:0.0970, weight:0.07, lr:0.0010
[10:51:44.385] iteration:1405  t-loss:0.1314, loss-lb:0.1211, loss-ulb:0.1484, weight:0.07, lr:0.0010
[10:51:44.577] iteration:1406  t-loss:0.1671, loss-lb:0.1644, loss-ulb:0.0387, weight:0.07, lr:0.0010
[10:51:44.769] iteration:1407  t-loss:0.1254, loss-lb:0.1231, loss-ulb:0.0331, weight:0.07, lr:0.0010
[10:51:44.960] iteration:1408  t-loss:0.1455, loss-lb:0.1431, loss-ulb:0.0336, weight:0.07, lr:0.0010
[10:51:45.152] iteration:1409  t-loss:0.1257, loss-lb:0.1215, loss-ulb:0.0604, weight:0.07, lr:0.0010
[10:51:45.344] iteration:1410  t-loss:0.1233, loss-lb:0.1207, loss-ulb:0.0376, weight:0.07, lr:0.0010
[10:51:45.536] iteration:1411  t-loss:0.1451, loss-lb:0.1423, loss-ulb:0.0409, weight:0.07, lr:0.0010
[10:51:45.727] iteration:1412  t-loss:0.1220, loss-lb:0.1160, loss-ulb:0.0868, weight:0.07, lr:0.0010
[10:51:45.919] iteration:1413  t-loss:0.1331, loss-lb:0.1304, loss-ulb:0.0396, weight:0.07, lr:0.0010
[10:51:46.110] iteration:1414  t-loss:0.1182, loss-lb:0.1153, loss-ulb:0.0410, weight:0.07, lr:0.0010
[10:51:46.302] iteration:1415  t-loss:0.1201, loss-lb:0.1153, loss-ulb:0.0690, weight:0.07, lr:0.0010
[10:51:46.493] iteration:1416  t-loss:0.1370, loss-lb:0.1347, loss-ulb:0.0323, weight:0.07, lr:0.0010
[10:51:46.685] iteration:1417  t-loss:0.1262, loss-lb:0.1193, loss-ulb:0.1000, weight:0.07, lr:0.0010
[10:51:46.877] iteration:1418  t-loss:0.1196, loss-lb:0.1157, loss-ulb:0.0564, weight:0.07, lr:0.0010
[10:51:47.069] iteration:1419  t-loss:0.1323, loss-lb:0.1294, loss-ulb:0.0421, weight:0.07, lr:0.0010
[10:51:47.260] iteration:1420  t-loss:0.1196, loss-lb:0.1165, loss-ulb:0.0459, weight:0.07, lr:0.0010
[10:51:47.452] iteration:1421  t-loss:0.1389, loss-lb:0.1337, loss-ulb:0.0741, weight:0.07, lr:0.0010
[10:51:47.644] iteration:1422  t-loss:0.1106, loss-lb:0.1067, loss-ulb:0.0562, weight:0.07, lr:0.0010
[10:51:47.836] iteration:1423  t-loss:0.1179, loss-lb:0.1114, loss-ulb:0.0945, weight:0.07, lr:0.0010
[10:51:48.028] iteration:1424  t-loss:0.1274, loss-lb:0.1248, loss-ulb:0.0382, weight:0.07, lr:0.0010
[10:51:48.219] iteration:1425  t-loss:0.1205, loss-lb:0.1153, loss-ulb:0.0743, weight:0.07, lr:0.0010
[10:51:48.411] iteration:1426  t-loss:0.1226, loss-lb:0.1145, loss-ulb:0.1165, weight:0.07, lr:0.0010
[10:51:48.602] iteration:1427  t-loss:0.1173, loss-lb:0.1148, loss-ulb:0.0353, weight:0.07, lr:0.0010
[10:51:48.795] iteration:1428  t-loss:0.1353, loss-lb:0.1323, loss-ulb:0.0427, weight:0.07, lr:0.0010
[10:51:48.986] iteration:1429  t-loss:0.1302, loss-lb:0.1262, loss-ulb:0.0584, weight:0.07, lr:0.0010
[10:51:49.179] iteration:1430  t-loss:0.1217, loss-lb:0.1190, loss-ulb:0.0388, weight:0.07, lr:0.0010
[10:51:49.370] iteration:1431  t-loss:0.1155, loss-lb:0.1106, loss-ulb:0.0712, weight:0.07, lr:0.0010
[10:51:49.561] iteration:1432  t-loss:0.1216, loss-lb:0.1170, loss-ulb:0.0657, weight:0.07, lr:0.0010
[10:51:49.753] iteration:1433  t-loss:0.1288, loss-lb:0.1255, loss-ulb:0.0483, weight:0.07, lr:0.0010
[10:51:49.945] iteration:1434  t-loss:0.1194, loss-lb:0.1161, loss-ulb:0.0467, weight:0.07, lr:0.0010
[10:51:50.138] iteration:1435  t-loss:0.1122, loss-lb:0.1087, loss-ulb:0.0502, weight:0.07, lr:0.0010
[10:51:50.329] iteration:1436  t-loss:0.1231, loss-lb:0.1201, loss-ulb:0.0433, weight:0.07, lr:0.0010
[10:51:50.520] iteration:1437  t-loss:0.1178, loss-lb:0.1134, loss-ulb:0.0644, weight:0.07, lr:0.0010
[10:51:50.711] iteration:1438  t-loss:0.1384, loss-lb:0.1363, loss-ulb:0.0302, weight:0.07, lr:0.0010
[10:51:50.903] iteration:1439  t-loss:0.1217, loss-lb:0.1172, loss-ulb:0.0656, weight:0.07, lr:0.0010
[10:51:51.093] iteration:1440  t-loss:0.1310, loss-lb:0.1280, loss-ulb:0.0420, weight:0.07, lr:0.0010
[10:51:51.284] iteration:1441  t-loss:0.1195, loss-lb:0.1157, loss-ulb:0.0555, weight:0.07, lr:0.0010
[10:51:51.476] iteration:1442  t-loss:0.1123, loss-lb:0.1102, loss-ulb:0.0314, weight:0.07, lr:0.0010
[10:51:51.667] iteration:1443  t-loss:0.1115, loss-lb:0.1091, loss-ulb:0.0342, weight:0.07, lr:0.0010
[10:51:51.859] iteration:1444  t-loss:0.1262, loss-lb:0.1217, loss-ulb:0.0653, weight:0.07, lr:0.0010
[10:51:52.050] iteration:1445  t-loss:0.1206, loss-lb:0.1156, loss-ulb:0.0723, weight:0.07, lr:0.0010
[10:51:52.242] iteration:1446  t-loss:0.1205, loss-lb:0.1179, loss-ulb:0.0374, weight:0.07, lr:0.0010
[10:51:52.434] iteration:1447  t-loss:0.1361, loss-lb:0.1330, loss-ulb:0.0453, weight:0.07, lr:0.0010
[10:51:52.625] iteration:1448  t-loss:0.1409, loss-lb:0.1357, loss-ulb:0.0754, weight:0.07, lr:0.0010
[10:51:52.816] iteration:1449  t-loss:0.1250, loss-lb:0.1198, loss-ulb:0.0757, weight:0.07, lr:0.0010
[10:51:53.008] iteration:1450  t-loss:0.1139, loss-lb:0.1101, loss-ulb:0.0543, weight:0.07, lr:0.0010
[10:51:53.199] iteration:1451  t-loss:0.1237, loss-lb:0.1207, loss-ulb:0.0430, weight:0.07, lr:0.0010
[10:51:53.391] iteration:1452  t-loss:0.1022, loss-lb:0.0993, loss-ulb:0.0417, weight:0.07, lr:0.0010
[10:51:53.582] iteration:1453  t-loss:0.1115, loss-lb:0.1089, loss-ulb:0.0379, weight:0.07, lr:0.0010
[10:51:53.774] iteration:1454  t-loss:0.1218, loss-lb:0.1171, loss-ulb:0.0680, weight:0.07, lr:0.0010
[10:51:53.966] iteration:1455  t-loss:0.1385, loss-lb:0.1339, loss-ulb:0.0653, weight:0.07, lr:0.0010
[10:51:54.158] iteration:1456  t-loss:0.1102, loss-lb:0.1062, loss-ulb:0.0574, weight:0.07, lr:0.0010
[10:51:54.351] iteration:1457  t-loss:0.1286, loss-lb:0.1261, loss-ulb:0.0362, weight:0.07, lr:0.0010
[10:51:54.542] iteration:1458  t-loss:0.1156, loss-lb:0.1105, loss-ulb:0.0734, weight:0.07, lr:0.0010
[10:51:54.734] iteration:1459  t-loss:0.1295, loss-lb:0.1204, loss-ulb:0.1312, weight:0.07, lr:0.0010
[10:51:54.926] iteration:1460  t-loss:0.1255, loss-lb:0.1232, loss-ulb:0.0319, weight:0.07, lr:0.0010
[10:51:55.117] iteration:1461  t-loss:0.1146, loss-lb:0.1123, loss-ulb:0.0334, weight:0.07, lr:0.0010
[10:51:55.309] iteration:1462  t-loss:0.1098, loss-lb:0.1054, loss-ulb:0.0632, weight:0.07, lr:0.0010
[10:51:55.501] iteration:1463  t-loss:0.1283, loss-lb:0.1258, loss-ulb:0.0352, weight:0.07, lr:0.0010
[10:51:55.691] iteration:1464  t-loss:0.1527, loss-lb:0.1497, loss-ulb:0.0428, weight:0.07, lr:0.0010
[10:51:55.882] iteration:1465  t-loss:0.1199, loss-lb:0.1146, loss-ulb:0.0754, weight:0.07, lr:0.0010
[10:51:56.071] iteration:1466  t-loss:0.1157, loss-lb:0.1120, loss-ulb:0.0529, weight:0.07, lr:0.0010
[10:51:56.262] iteration:1467  t-loss:0.1154, loss-lb:0.1133, loss-ulb:0.0304, weight:0.07, lr:0.0010
[10:51:56.452] iteration:1468  t-loss:0.1169, loss-lb:0.1135, loss-ulb:0.0504, weight:0.07, lr:0.0010
[10:51:56.643] iteration:1469  t-loss:0.1083, loss-lb:0.1032, loss-ulb:0.0730, weight:0.07, lr:0.0010
[10:51:56.834] iteration:1470  t-loss:0.1151, loss-lb:0.1116, loss-ulb:0.0505, weight:0.07, lr:0.0010
[10:52:08.703]  <<Test>> - Ep:14  - mean_dice/mean_h95 - S:86.04/2.60, Best-S:86.04, T:86.54/3.81, Best-T:86.54
[10:52:08.703]           - AvgLoss(lb/ulb/all):0.1233/0.0547/0.1202
[10:52:09.260] iteration:1471  t-loss:0.1358, loss-lb:0.1333, loss-ulb:0.0361, weight:0.07, lr:0.0010
[10:52:09.457] iteration:1472  t-loss:0.1263, loss-lb:0.1208, loss-ulb:0.0796, weight:0.07, lr:0.0010
[10:52:09.649] iteration:1473  t-loss:0.1138, loss-lb:0.1091, loss-ulb:0.0670, weight:0.07, lr:0.0010
[10:52:09.849] iteration:1474  t-loss:0.1231, loss-lb:0.1131, loss-ulb:0.1441, weight:0.07, lr:0.0010
[10:52:10.040] iteration:1475  t-loss:0.1219, loss-lb:0.1193, loss-ulb:0.0371, weight:0.07, lr:0.0010
[10:52:10.232] iteration:1476  t-loss:0.1419, loss-lb:0.1361, loss-ulb:0.0832, weight:0.07, lr:0.0010
[10:52:10.423] iteration:1477  t-loss:0.1086, loss-lb:0.1055, loss-ulb:0.0445, weight:0.07, lr:0.0010
[10:52:10.621] iteration:1478  t-loss:0.1145, loss-lb:0.1101, loss-ulb:0.0630, weight:0.07, lr:0.0010
[10:52:10.812] iteration:1479  t-loss:0.1357, loss-lb:0.1335, loss-ulb:0.0313, weight:0.07, lr:0.0010
[10:52:11.003] iteration:1480  t-loss:0.1163, loss-lb:0.1101, loss-ulb:0.0887, weight:0.07, lr:0.0010
[10:52:11.195] iteration:1481  t-loss:0.1134, loss-lb:0.1099, loss-ulb:0.0508, weight:0.07, lr:0.0010
[10:52:11.387] iteration:1482  t-loss:0.1224, loss-lb:0.1194, loss-ulb:0.0430, weight:0.07, lr:0.0010
[10:52:11.578] iteration:1483  t-loss:0.1216, loss-lb:0.1156, loss-ulb:0.0870, weight:0.07, lr:0.0010
[10:52:11.770] iteration:1484  t-loss:0.1232, loss-lb:0.1158, loss-ulb:0.1069, weight:0.07, lr:0.0010
[10:52:11.962] iteration:1485  t-loss:0.1387, loss-lb:0.1359, loss-ulb:0.0401, weight:0.07, lr:0.0010
[10:52:12.154] iteration:1486  t-loss:0.1114, loss-lb:0.1086, loss-ulb:0.0405, weight:0.07, lr:0.0010
[10:52:12.345] iteration:1487  t-loss:0.1432, loss-lb:0.1403, loss-ulb:0.0421, weight:0.07, lr:0.0010
[10:52:12.536] iteration:1488  t-loss:0.1173, loss-lb:0.1120, loss-ulb:0.0771, weight:0.07, lr:0.0010
[10:52:12.728] iteration:1489  t-loss:0.1221, loss-lb:0.1185, loss-ulb:0.0515, weight:0.07, lr:0.0010
[10:52:12.920] iteration:1490  t-loss:0.1231, loss-lb:0.1160, loss-ulb:0.1022, weight:0.07, lr:0.0010
[10:52:13.111] iteration:1491  t-loss:0.1318, loss-lb:0.1289, loss-ulb:0.0413, weight:0.07, lr:0.0010
[10:52:13.302] iteration:1492  t-loss:0.1304, loss-lb:0.1242, loss-ulb:0.0903, weight:0.07, lr:0.0010
[10:52:13.494] iteration:1493  t-loss:0.1155, loss-lb:0.1108, loss-ulb:0.0677, weight:0.07, lr:0.0010
[10:52:13.685] iteration:1494  t-loss:0.1076, loss-lb:0.1043, loss-ulb:0.0485, weight:0.07, lr:0.0010
[10:52:13.876] iteration:1495  t-loss:0.1280, loss-lb:0.1254, loss-ulb:0.0379, weight:0.07, lr:0.0010
[10:52:14.067] iteration:1496  t-loss:0.1282, loss-lb:0.1200, loss-ulb:0.1195, weight:0.07, lr:0.0010
[10:52:14.259] iteration:1497  t-loss:0.1164, loss-lb:0.1143, loss-ulb:0.0295, weight:0.07, lr:0.0010
[10:52:14.450] iteration:1498  t-loss:0.1265, loss-lb:0.1212, loss-ulb:0.0763, weight:0.07, lr:0.0010
[10:52:14.643] iteration:1499  t-loss:0.1275, loss-lb:0.1217, loss-ulb:0.0844, weight:0.07, lr:0.0010
[10:52:14.836] iteration:1500  t-loss:0.1151, loss-lb:0.1122, loss-ulb:0.0415, weight:0.07, lr:0.0010
[10:52:15.028] iteration:1501  t-loss:0.1263, loss-lb:0.1241, loss-ulb:0.0272, weight:0.08, lr:0.0010
[10:52:15.220] iteration:1502  t-loss:0.1333, loss-lb:0.1309, loss-ulb:0.0296, weight:0.08, lr:0.0010
[10:52:15.412] iteration:1503  t-loss:0.1093, loss-lb:0.1054, loss-ulb:0.0479, weight:0.08, lr:0.0010
[10:52:15.603] iteration:1504  t-loss:0.1187, loss-lb:0.1099, loss-ulb:0.1084, weight:0.08, lr:0.0010
[10:52:15.796] iteration:1505  t-loss:0.1159, loss-lb:0.1111, loss-ulb:0.0585, weight:0.08, lr:0.0010
[10:52:15.987] iteration:1506  t-loss:0.1228, loss-lb:0.1176, loss-ulb:0.0636, weight:0.08, lr:0.0010
[10:52:16.178] iteration:1507  t-loss:0.1121, loss-lb:0.1089, loss-ulb:0.0383, weight:0.08, lr:0.0010
[10:52:16.370] iteration:1508  t-loss:0.1065, loss-lb:0.1021, loss-ulb:0.0541, weight:0.08, lr:0.0010
[10:52:16.562] iteration:1509  t-loss:0.1256, loss-lb:0.1232, loss-ulb:0.0299, weight:0.08, lr:0.0010
[10:52:16.753] iteration:1510  t-loss:0.1284, loss-lb:0.1228, loss-ulb:0.0691, weight:0.08, lr:0.0010
[10:52:16.946] iteration:1511  t-loss:0.1221, loss-lb:0.1174, loss-ulb:0.0575, weight:0.08, lr:0.0010
[10:52:17.138] iteration:1512  t-loss:0.1161, loss-lb:0.1062, loss-ulb:0.1217, weight:0.08, lr:0.0010
[10:52:17.330] iteration:1513  t-loss:0.1502, loss-lb:0.1447, loss-ulb:0.0673, weight:0.08, lr:0.0010
[10:52:17.522] iteration:1514  t-loss:0.1317, loss-lb:0.1293, loss-ulb:0.0291, weight:0.08, lr:0.0010
[10:52:17.713] iteration:1515  t-loss:0.0977, loss-lb:0.0930, loss-ulb:0.0576, weight:0.08, lr:0.0010
[10:52:17.905] iteration:1516  t-loss:0.1207, loss-lb:0.1165, loss-ulb:0.0518, weight:0.08, lr:0.0010
[10:52:18.097] iteration:1517  t-loss:0.1169, loss-lb:0.1101, loss-ulb:0.0836, weight:0.08, lr:0.0010
[10:52:18.289] iteration:1518  t-loss:0.1265, loss-lb:0.1184, loss-ulb:0.0995, weight:0.08, lr:0.0010
[10:52:18.481] iteration:1519  t-loss:0.1423, loss-lb:0.1381, loss-ulb:0.0521, weight:0.08, lr:0.0010
[10:52:18.672] iteration:1520  t-loss:0.1270, loss-lb:0.1150, loss-ulb:0.1475, weight:0.08, lr:0.0010
[10:52:18.864] iteration:1521  t-loss:0.1137, loss-lb:0.1085, loss-ulb:0.0632, weight:0.08, lr:0.0010
[10:52:19.055] iteration:1522  t-loss:0.1285, loss-lb:0.1252, loss-ulb:0.0408, weight:0.08, lr:0.0010
[10:52:19.247] iteration:1523  t-loss:0.1326, loss-lb:0.1273, loss-ulb:0.0655, weight:0.08, lr:0.0010
[10:52:19.438] iteration:1524  t-loss:0.1201, loss-lb:0.1145, loss-ulb:0.0690, weight:0.08, lr:0.0010
[10:52:19.630] iteration:1525  t-loss:0.1831, loss-lb:0.1730, loss-ulb:0.1233, weight:0.08, lr:0.0010
[10:52:19.822] iteration:1526  t-loss:0.1224, loss-lb:0.1180, loss-ulb:0.0542, weight:0.08, lr:0.0010
[10:52:20.015] iteration:1527  t-loss:0.1568, loss-lb:0.1543, loss-ulb:0.0315, weight:0.08, lr:0.0010
[10:52:20.206] iteration:1528  t-loss:0.1261, loss-lb:0.1206, loss-ulb:0.0684, weight:0.08, lr:0.0010
[10:52:20.399] iteration:1529  t-loss:0.1317, loss-lb:0.1253, loss-ulb:0.0790, weight:0.08, lr:0.0010
[10:52:20.590] iteration:1530  t-loss:0.1469, loss-lb:0.1387, loss-ulb:0.1008, weight:0.08, lr:0.0010
[10:52:20.782] iteration:1531  t-loss:0.1320, loss-lb:0.1243, loss-ulb:0.0953, weight:0.08, lr:0.0010
[10:52:20.974] iteration:1532  t-loss:0.1474, loss-lb:0.1407, loss-ulb:0.0824, weight:0.08, lr:0.0010
[10:52:21.165] iteration:1533  t-loss:0.1333, loss-lb:0.1265, loss-ulb:0.0828, weight:0.08, lr:0.0010
[10:52:21.358] iteration:1534  t-loss:0.1535, loss-lb:0.1440, loss-ulb:0.1164, weight:0.08, lr:0.0010
[10:52:21.551] iteration:1535  t-loss:0.1309, loss-lb:0.1271, loss-ulb:0.0465, weight:0.08, lr:0.0010
[10:52:21.742] iteration:1536  t-loss:0.1290, loss-lb:0.1228, loss-ulb:0.0763, weight:0.08, lr:0.0010
[10:52:21.934] iteration:1537  t-loss:0.1590, loss-lb:0.1553, loss-ulb:0.0460, weight:0.08, lr:0.0010
[10:52:22.125] iteration:1538  t-loss:0.1375, loss-lb:0.1334, loss-ulb:0.0505, weight:0.08, lr:0.0010
[10:52:22.317] iteration:1539  t-loss:0.1224, loss-lb:0.1164, loss-ulb:0.0737, weight:0.08, lr:0.0010
[10:52:22.509] iteration:1540  t-loss:0.1418, loss-lb:0.1333, loss-ulb:0.1041, weight:0.08, lr:0.0010
[10:52:22.700] iteration:1541  t-loss:0.1314, loss-lb:0.1263, loss-ulb:0.0627, weight:0.08, lr:0.0010
[10:52:22.892] iteration:1542  t-loss:0.1543, loss-lb:0.1514, loss-ulb:0.0358, weight:0.08, lr:0.0010
[10:52:23.083] iteration:1543  t-loss:0.1349, loss-lb:0.1292, loss-ulb:0.0701, weight:0.08, lr:0.0010
[10:52:23.274] iteration:1544  t-loss:0.1422, loss-lb:0.1395, loss-ulb:0.0335, weight:0.08, lr:0.0010
[10:52:23.466] iteration:1545  t-loss:0.1335, loss-lb:0.1281, loss-ulb:0.0673, weight:0.08, lr:0.0010
[10:52:23.657] iteration:1546  t-loss:0.1285, loss-lb:0.1254, loss-ulb:0.0381, weight:0.08, lr:0.0010
[10:52:23.850] iteration:1547  t-loss:0.1309, loss-lb:0.1246, loss-ulb:0.0778, weight:0.08, lr:0.0010
[10:52:24.041] iteration:1548  t-loss:0.1365, loss-lb:0.1285, loss-ulb:0.0985, weight:0.08, lr:0.0010
[10:52:24.233] iteration:1549  t-loss:0.1360, loss-lb:0.1318, loss-ulb:0.0517, weight:0.08, lr:0.0010
[10:52:24.426] iteration:1550  t-loss:0.1282, loss-lb:0.1170, loss-ulb:0.1373, weight:0.08, lr:0.0010
[10:52:24.617] iteration:1551  t-loss:0.1307, loss-lb:0.1249, loss-ulb:0.0708, weight:0.08, lr:0.0010
[10:52:24.809] iteration:1552  t-loss:0.1381, loss-lb:0.1341, loss-ulb:0.0490, weight:0.08, lr:0.0010
[10:52:25.001] iteration:1553  t-loss:0.1359, loss-lb:0.1332, loss-ulb:0.0333, weight:0.08, lr:0.0010
[10:52:25.192] iteration:1554  t-loss:0.1877, loss-lb:0.1813, loss-ulb:0.0781, weight:0.08, lr:0.0010
[10:52:25.383] iteration:1555  t-loss:0.1292, loss-lb:0.1239, loss-ulb:0.0651, weight:0.08, lr:0.0010
[10:52:25.575] iteration:1556  t-loss:0.1324, loss-lb:0.1282, loss-ulb:0.0520, weight:0.08, lr:0.0010
[10:52:25.767] iteration:1557  t-loss:0.1495, loss-lb:0.1457, loss-ulb:0.0470, weight:0.08, lr:0.0010
[10:52:25.959] iteration:1558  t-loss:0.1550, loss-lb:0.1440, loss-ulb:0.1342, weight:0.08, lr:0.0010
[10:52:26.151] iteration:1559  t-loss:0.1637, loss-lb:0.1567, loss-ulb:0.0866, weight:0.08, lr:0.0010
[10:52:26.343] iteration:1560  t-loss:0.1309, loss-lb:0.1269, loss-ulb:0.0496, weight:0.08, lr:0.0010
[10:52:26.534] iteration:1561  t-loss:0.1743, loss-lb:0.1700, loss-ulb:0.0523, weight:0.08, lr:0.0010
[10:52:26.724] iteration:1562  t-loss:0.1404, loss-lb:0.1367, loss-ulb:0.0449, weight:0.08, lr:0.0010
[10:52:26.913] iteration:1563  t-loss:0.1646, loss-lb:0.1595, loss-ulb:0.0632, weight:0.08, lr:0.0010
[10:52:27.104] iteration:1564  t-loss:0.1435, loss-lb:0.1358, loss-ulb:0.0940, weight:0.08, lr:0.0010
[10:52:27.294] iteration:1565  t-loss:0.1243, loss-lb:0.1203, loss-ulb:0.0499, weight:0.08, lr:0.0010
[10:52:27.484] iteration:1566  t-loss:0.1591, loss-lb:0.1494, loss-ulb:0.1189, weight:0.08, lr:0.0010
[10:52:27.673] iteration:1567  t-loss:0.1379, loss-lb:0.1344, loss-ulb:0.0430, weight:0.08, lr:0.0010
[10:52:27.865] iteration:1568  t-loss:0.1335, loss-lb:0.1231, loss-ulb:0.1279, weight:0.08, lr:0.0010
[10:52:28.478] iteration:1569  t-loss:0.1398, loss-lb:0.1286, loss-ulb:0.1371, weight:0.08, lr:0.0010
[10:52:28.672] iteration:1570  t-loss:0.1604, loss-lb:0.1399, loss-ulb:0.2518, weight:0.08, lr:0.0010
[10:52:28.863] iteration:1571  t-loss:0.1163, loss-lb:0.1117, loss-ulb:0.0556, weight:0.08, lr:0.0010
[10:52:29.055] iteration:1572  t-loss:0.1388, loss-lb:0.1313, loss-ulb:0.0922, weight:0.08, lr:0.0010
[10:52:29.247] iteration:1573  t-loss:0.1356, loss-lb:0.1280, loss-ulb:0.0944, weight:0.08, lr:0.0010
[10:52:29.439] iteration:1574  t-loss:0.1512, loss-lb:0.1462, loss-ulb:0.0616, weight:0.08, lr:0.0010
[10:52:29.633] iteration:1575  t-loss:0.1456, loss-lb:0.1356, loss-ulb:0.1222, weight:0.08, lr:0.0010
[10:52:29.825] iteration:1576  t-loss:0.1281, loss-lb:0.1236, loss-ulb:0.0548, weight:0.08, lr:0.0010
[10:52:30.016] iteration:1577  t-loss:0.1423, loss-lb:0.1357, loss-ulb:0.0811, weight:0.08, lr:0.0010
[10:52:30.208] iteration:1578  t-loss:0.1355, loss-lb:0.1292, loss-ulb:0.0780, weight:0.08, lr:0.0010
[10:52:30.400] iteration:1579  t-loss:0.1154, loss-lb:0.1070, loss-ulb:0.1022, weight:0.08, lr:0.0010
[10:52:30.590] iteration:1580  t-loss:0.1230, loss-lb:0.1181, loss-ulb:0.0603, weight:0.08, lr:0.0010
[10:52:30.783] iteration:1581  t-loss:0.1290, loss-lb:0.1246, loss-ulb:0.0548, weight:0.08, lr:0.0010
[10:52:30.974] iteration:1582  t-loss:0.1418, loss-lb:0.1333, loss-ulb:0.1036, weight:0.08, lr:0.0010
[10:52:31.166] iteration:1583  t-loss:0.1132, loss-lb:0.1095, loss-ulb:0.0448, weight:0.08, lr:0.0010
[10:52:31.358] iteration:1584  t-loss:0.1167, loss-lb:0.1140, loss-ulb:0.0331, weight:0.08, lr:0.0010
[10:52:31.551] iteration:1585  t-loss:0.1661, loss-lb:0.1551, loss-ulb:0.1347, weight:0.08, lr:0.0010
[10:52:31.742] iteration:1586  t-loss:0.1524, loss-lb:0.1404, loss-ulb:0.1473, weight:0.08, lr:0.0010
[10:52:31.934] iteration:1587  t-loss:0.1403, loss-lb:0.1353, loss-ulb:0.0613, weight:0.08, lr:0.0010
[10:52:32.125] iteration:1588  t-loss:0.1203, loss-lb:0.1173, loss-ulb:0.0370, weight:0.08, lr:0.0010
[10:52:32.317] iteration:1589  t-loss:0.1314, loss-lb:0.1276, loss-ulb:0.0464, weight:0.08, lr:0.0010
[10:52:32.508] iteration:1590  t-loss:0.1844, loss-lb:0.1803, loss-ulb:0.0513, weight:0.08, lr:0.0010
[10:52:32.699] iteration:1591  t-loss:0.1403, loss-lb:0.1328, loss-ulb:0.0915, weight:0.08, lr:0.0010
[10:52:32.890] iteration:1592  t-loss:0.1210, loss-lb:0.1167, loss-ulb:0.0517, weight:0.08, lr:0.0010
[10:52:33.082] iteration:1593  t-loss:0.1339, loss-lb:0.1273, loss-ulb:0.0808, weight:0.08, lr:0.0010
[10:52:33.273] iteration:1594  t-loss:0.1457, loss-lb:0.1400, loss-ulb:0.0697, weight:0.08, lr:0.0010
[10:52:33.464] iteration:1595  t-loss:0.1384, loss-lb:0.1350, loss-ulb:0.0419, weight:0.08, lr:0.0010
[10:52:33.655] iteration:1596  t-loss:0.1500, loss-lb:0.1393, loss-ulb:0.1317, weight:0.08, lr:0.0010
[10:52:33.849] iteration:1597  t-loss:0.2001, loss-lb:0.1956, loss-ulb:0.0554, weight:0.08, lr:0.0010
[10:52:34.039] iteration:1598  t-loss:0.1181, loss-lb:0.1113, loss-ulb:0.0839, weight:0.08, lr:0.0010
[10:52:34.233] iteration:1599  t-loss:0.1537, loss-lb:0.1419, loss-ulb:0.1450, weight:0.08, lr:0.0010
[10:52:34.428] iteration:1600  t-loss:0.1471, loss-lb:0.1432, loss-ulb:0.0486, weight:0.08, lr:0.0010
[10:52:34.621] iteration:1601  t-loss:0.1301, loss-lb:0.1260, loss-ulb:0.0504, weight:0.08, lr:0.0010
[10:52:34.814] iteration:1602  t-loss:0.1349, loss-lb:0.1277, loss-ulb:0.0878, weight:0.08, lr:0.0010
[10:52:35.006] iteration:1603  t-loss:0.1219, loss-lb:0.1187, loss-ulb:0.0389, weight:0.08, lr:0.0010
[10:52:35.199] iteration:1604  t-loss:0.1344, loss-lb:0.1285, loss-ulb:0.0734, weight:0.08, lr:0.0010
[10:52:35.390] iteration:1605  t-loss:0.1161, loss-lb:0.1074, loss-ulb:0.1066, weight:0.08, lr:0.0010
[10:52:35.582] iteration:1606  t-loss:0.1384, loss-lb:0.1345, loss-ulb:0.0476, weight:0.08, lr:0.0010
[10:52:35.773] iteration:1607  t-loss:0.1247, loss-lb:0.1202, loss-ulb:0.0561, weight:0.08, lr:0.0010
[10:52:35.966] iteration:1608  t-loss:0.1124, loss-lb:0.1077, loss-ulb:0.0580, weight:0.08, lr:0.0010
[10:52:36.158] iteration:1609  t-loss:0.1258, loss-lb:0.1228, loss-ulb:0.0365, weight:0.08, lr:0.0010
[10:52:36.349] iteration:1610  t-loss:0.1167, loss-lb:0.1122, loss-ulb:0.0560, weight:0.08, lr:0.0010
[10:52:36.541] iteration:1611  t-loss:0.1378, loss-lb:0.1335, loss-ulb:0.0527, weight:0.08, lr:0.0010
[10:52:36.733] iteration:1612  t-loss:0.1512, loss-lb:0.1480, loss-ulb:0.0392, weight:0.08, lr:0.0010
[10:52:36.925] iteration:1613  t-loss:0.1152, loss-lb:0.1119, loss-ulb:0.0409, weight:0.08, lr:0.0010
[10:52:37.117] iteration:1614  t-loss:0.1247, loss-lb:0.1204, loss-ulb:0.0536, weight:0.08, lr:0.0010
[10:52:37.308] iteration:1615  t-loss:0.1335, loss-lb:0.1306, loss-ulb:0.0357, weight:0.08, lr:0.0010
[10:52:37.499] iteration:1616  t-loss:0.1222, loss-lb:0.1191, loss-ulb:0.0385, weight:0.08, lr:0.0010
[10:52:37.691] iteration:1617  t-loss:0.1095, loss-lb:0.1064, loss-ulb:0.0371, weight:0.08, lr:0.0010
[10:52:37.883] iteration:1618  t-loss:0.1300, loss-lb:0.1239, loss-ulb:0.0736, weight:0.08, lr:0.0010
[10:52:38.075] iteration:1619  t-loss:0.1209, loss-lb:0.1184, loss-ulb:0.0305, weight:0.08, lr:0.0010
[10:52:38.267] iteration:1620  t-loss:0.1578, loss-lb:0.1550, loss-ulb:0.0335, weight:0.08, lr:0.0010
[10:52:38.459] iteration:1621  t-loss:0.1151, loss-lb:0.1120, loss-ulb:0.0379, weight:0.08, lr:0.0010
[10:52:38.652] iteration:1622  t-loss:0.1134, loss-lb:0.1051, loss-ulb:0.1011, weight:0.08, lr:0.0010
[10:52:38.844] iteration:1623  t-loss:0.1050, loss-lb:0.1015, loss-ulb:0.0426, weight:0.08, lr:0.0010
[10:52:39.035] iteration:1624  t-loss:0.1113, loss-lb:0.1073, loss-ulb:0.0489, weight:0.08, lr:0.0010
[10:52:39.227] iteration:1625  t-loss:0.1535, loss-lb:0.1513, loss-ulb:0.0263, weight:0.08, lr:0.0010
[10:52:39.418] iteration:1626  t-loss:0.1157, loss-lb:0.1123, loss-ulb:0.0417, weight:0.08, lr:0.0010
[10:52:39.620] iteration:1627  t-loss:0.1106, loss-lb:0.1017, loss-ulb:0.1090, weight:0.08, lr:0.0010
[10:52:39.816] iteration:1628  t-loss:0.1273, loss-lb:0.1213, loss-ulb:0.0735, weight:0.08, lr:0.0010
[10:52:40.008] iteration:1629  t-loss:0.1347, loss-lb:0.1256, loss-ulb:0.1107, weight:0.08, lr:0.0010
[10:52:40.198] iteration:1630  t-loss:0.1144, loss-lb:0.1103, loss-ulb:0.0502, weight:0.08, lr:0.0010
[10:52:40.390] iteration:1631  t-loss:0.1099, loss-lb:0.1027, loss-ulb:0.0882, weight:0.08, lr:0.0010
[10:52:40.580] iteration:1632  t-loss:0.1157, loss-lb:0.1133, loss-ulb:0.0292, weight:0.08, lr:0.0010
[10:52:40.772] iteration:1633  t-loss:0.1419, loss-lb:0.1320, loss-ulb:0.1215, weight:0.08, lr:0.0010
[10:52:40.965] iteration:1634  t-loss:0.1282, loss-lb:0.1195, loss-ulb:0.1067, weight:0.08, lr:0.0010
[10:52:41.157] iteration:1635  t-loss:0.1424, loss-lb:0.1386, loss-ulb:0.0466, weight:0.08, lr:0.0010
[10:52:41.355] iteration:1636  t-loss:0.1207, loss-lb:0.1168, loss-ulb:0.0475, weight:0.08, lr:0.0010
[10:52:41.551] iteration:1637  t-loss:0.1218, loss-lb:0.1180, loss-ulb:0.0467, weight:0.08, lr:0.0010
[10:52:41.746] iteration:1638  t-loss:0.1147, loss-lb:0.1115, loss-ulb:0.0393, weight:0.08, lr:0.0010
[10:52:41.938] iteration:1639  t-loss:0.1244, loss-lb:0.1204, loss-ulb:0.0494, weight:0.08, lr:0.0010
[10:52:42.131] iteration:1640  t-loss:0.1376, loss-lb:0.1326, loss-ulb:0.0611, weight:0.08, lr:0.0010
[10:52:42.323] iteration:1641  t-loss:0.1661, loss-lb:0.1583, loss-ulb:0.0949, weight:0.08, lr:0.0010
[10:52:42.515] iteration:1642  t-loss:0.1350, loss-lb:0.1310, loss-ulb:0.0485, weight:0.08, lr:0.0010
[10:52:42.707] iteration:1643  t-loss:0.1698, loss-lb:0.1670, loss-ulb:0.0345, weight:0.08, lr:0.0010
[10:52:42.900] iteration:1644  t-loss:0.1276, loss-lb:0.1215, loss-ulb:0.0750, weight:0.08, lr:0.0010
[10:52:43.092] iteration:1645  t-loss:0.1508, loss-lb:0.1458, loss-ulb:0.0620, weight:0.08, lr:0.0010
[10:52:43.284] iteration:1646  t-loss:0.1272, loss-lb:0.1227, loss-ulb:0.0553, weight:0.08, lr:0.0010
[10:52:43.475] iteration:1647  t-loss:0.1486, loss-lb:0.1411, loss-ulb:0.0919, weight:0.08, lr:0.0010
[10:52:43.668] iteration:1648  t-loss:0.1335, loss-lb:0.1222, loss-ulb:0.1375, weight:0.08, lr:0.0010
[10:52:43.860] iteration:1649  t-loss:0.1249, loss-lb:0.1147, loss-ulb:0.1250, weight:0.08, lr:0.0010
[10:52:44.053] iteration:1650  t-loss:0.1285, loss-lb:0.1246, loss-ulb:0.0486, weight:0.08, lr:0.0010
[10:52:44.245] iteration:1651  t-loss:0.1487, loss-lb:0.1447, loss-ulb:0.0417, weight:0.10, lr:0.0010
[10:52:44.437] iteration:1652  t-loss:0.1332, loss-lb:0.1241, loss-ulb:0.0960, weight:0.10, lr:0.0010
[10:52:44.629] iteration:1653  t-loss:0.1199, loss-lb:0.1125, loss-ulb:0.0769, weight:0.10, lr:0.0010
[10:52:44.821] iteration:1654  t-loss:0.1150, loss-lb:0.1093, loss-ulb:0.0596, weight:0.10, lr:0.0010
[10:52:45.013] iteration:1655  t-loss:0.1159, loss-lb:0.1128, loss-ulb:0.0325, weight:0.10, lr:0.0010
[10:52:45.204] iteration:1656  t-loss:0.1176, loss-lb:0.1142, loss-ulb:0.0365, weight:0.10, lr:0.0010
[10:52:45.396] iteration:1657  t-loss:0.1180, loss-lb:0.1119, loss-ulb:0.0643, weight:0.10, lr:0.0010
[10:52:45.588] iteration:1658  t-loss:0.1236, loss-lb:0.1184, loss-ulb:0.0542, weight:0.10, lr:0.0010
[10:52:45.782] iteration:1659  t-loss:0.1185, loss-lb:0.1121, loss-ulb:0.0667, weight:0.10, lr:0.0010
[10:52:45.973] iteration:1660  t-loss:0.1238, loss-lb:0.1203, loss-ulb:0.0371, weight:0.10, lr:0.0010
[10:52:46.164] iteration:1661  t-loss:0.1241, loss-lb:0.1165, loss-ulb:0.0795, weight:0.10, lr:0.0010
[10:52:46.353] iteration:1662  t-loss:0.1255, loss-lb:0.1221, loss-ulb:0.0360, weight:0.10, lr:0.0010
[10:52:46.543] iteration:1663  t-loss:0.1265, loss-lb:0.1227, loss-ulb:0.0398, weight:0.10, lr:0.0009
[10:52:46.733] iteration:1664  t-loss:0.1362, loss-lb:0.1296, loss-ulb:0.0686, weight:0.10, lr:0.0009
[10:52:46.924] iteration:1665  t-loss:0.1116, loss-lb:0.1010, loss-ulb:0.1118, weight:0.10, lr:0.0009
[10:52:47.113] iteration:1666  t-loss:0.1289, loss-lb:0.1228, loss-ulb:0.0637, weight:0.10, lr:0.0009
[10:52:58.361]  <<Test>> - Ep:16  - mean_dice/mean_h95 - S:85.85/2.87, Best-S:86.04, T:87.60/2.61, Best-T:87.60
[10:52:58.361]           - AvgLoss(lb/ulb/all):0.1258/0.0684/0.1261
[10:52:58.902] iteration:1667  t-loss:0.1686, loss-lb:0.1647, loss-ulb:0.0413, weight:0.10, lr:0.0009
[10:52:59.098] iteration:1668  t-loss:0.1313, loss-lb:0.1272, loss-ulb:0.0430, weight:0.10, lr:0.0009
[10:52:59.291] iteration:1669  t-loss:0.1065, loss-lb:0.1025, loss-ulb:0.0413, weight:0.10, lr:0.0009
[10:52:59.482] iteration:1670  t-loss:0.1361, loss-lb:0.1280, loss-ulb:0.0846, weight:0.10, lr:0.0009
[10:52:59.674] iteration:1671  t-loss:0.1340, loss-lb:0.1285, loss-ulb:0.0573, weight:0.10, lr:0.0009
[10:52:59.865] iteration:1672  t-loss:0.1487, loss-lb:0.1444, loss-ulb:0.0455, weight:0.10, lr:0.0009
[10:53:00.055] iteration:1673  t-loss:0.1188, loss-lb:0.1159, loss-ulb:0.0306, weight:0.10, lr:0.0009
[10:53:00.246] iteration:1674  t-loss:0.1239, loss-lb:0.1159, loss-ulb:0.0840, weight:0.10, lr:0.0009
[10:53:00.437] iteration:1675  t-loss:0.1203, loss-lb:0.1171, loss-ulb:0.0344, weight:0.10, lr:0.0009
[10:53:00.626] iteration:1676  t-loss:0.1333, loss-lb:0.1273, loss-ulb:0.0632, weight:0.10, lr:0.0009
[10:53:00.818] iteration:1677  t-loss:0.1147, loss-lb:0.1088, loss-ulb:0.0623, weight:0.10, lr:0.0009
[10:53:01.009] iteration:1678  t-loss:0.1426, loss-lb:0.1334, loss-ulb:0.0960, weight:0.10, lr:0.0009
[10:53:01.201] iteration:1679  t-loss:0.1284, loss-lb:0.1254, loss-ulb:0.0310, weight:0.10, lr:0.0009
[10:53:01.392] iteration:1680  t-loss:0.1276, loss-lb:0.1160, loss-ulb:0.1217, weight:0.10, lr:0.0009
[10:53:01.585] iteration:1681  t-loss:0.1564, loss-lb:0.1537, loss-ulb:0.0277, weight:0.10, lr:0.0009
[10:53:01.777] iteration:1682  t-loss:0.1253, loss-lb:0.1205, loss-ulb:0.0496, weight:0.10, lr:0.0009
[10:53:01.969] iteration:1683  t-loss:0.1337, loss-lb:0.1295, loss-ulb:0.0439, weight:0.10, lr:0.0009
[10:53:02.160] iteration:1684  t-loss:0.1270, loss-lb:0.1246, loss-ulb:0.0244, weight:0.10, lr:0.0009
[10:53:02.351] iteration:1685  t-loss:0.1228, loss-lb:0.1195, loss-ulb:0.0346, weight:0.10, lr:0.0009
[10:53:02.543] iteration:1686  t-loss:0.1045, loss-lb:0.0994, loss-ulb:0.0533, weight:0.10, lr:0.0009
[10:53:02.735] iteration:1687  t-loss:0.1344, loss-lb:0.1319, loss-ulb:0.0267, weight:0.10, lr:0.0009
[10:53:02.929] iteration:1688  t-loss:0.1303, loss-lb:0.1248, loss-ulb:0.0580, weight:0.10, lr:0.0009
[10:53:03.121] iteration:1689  t-loss:0.1306, loss-lb:0.1237, loss-ulb:0.0723, weight:0.10, lr:0.0009
[10:53:03.312] iteration:1690  t-loss:0.1213, loss-lb:0.1181, loss-ulb:0.0333, weight:0.10, lr:0.0009
[10:53:03.504] iteration:1691  t-loss:0.1180, loss-lb:0.1141, loss-ulb:0.0408, weight:0.10, lr:0.0009
[10:53:03.695] iteration:1692  t-loss:0.1338, loss-lb:0.1281, loss-ulb:0.0602, weight:0.10, lr:0.0009
[10:53:03.887] iteration:1693  t-loss:0.1289, loss-lb:0.1249, loss-ulb:0.0422, weight:0.10, lr:0.0009
[10:53:04.078] iteration:1694  t-loss:0.1342, loss-lb:0.1238, loss-ulb:0.1095, weight:0.10, lr:0.0009
[10:53:04.269] iteration:1695  t-loss:0.1115, loss-lb:0.1080, loss-ulb:0.0365, weight:0.10, lr:0.0009
[10:53:04.463] iteration:1696  t-loss:0.1138, loss-lb:0.1102, loss-ulb:0.0373, weight:0.10, lr:0.0009
[10:53:04.655] iteration:1697  t-loss:0.1244, loss-lb:0.1209, loss-ulb:0.0365, weight:0.10, lr:0.0009
[10:53:04.847] iteration:1698  t-loss:0.1305, loss-lb:0.1274, loss-ulb:0.0317, weight:0.10, lr:0.0009
[10:53:05.039] iteration:1699  t-loss:0.1118, loss-lb:0.1049, loss-ulb:0.0721, weight:0.10, lr:0.0009
[10:53:05.230] iteration:1700  t-loss:0.1261, loss-lb:0.1155, loss-ulb:0.1114, weight:0.10, lr:0.0009
[10:53:05.422] iteration:1701  t-loss:0.1120, loss-lb:0.1058, loss-ulb:0.0653, weight:0.10, lr:0.0009
[10:53:05.615] iteration:1702  t-loss:0.1125, loss-lb:0.1084, loss-ulb:0.0431, weight:0.10, lr:0.0009
[10:53:05.806] iteration:1703  t-loss:0.1180, loss-lb:0.1135, loss-ulb:0.0476, weight:0.10, lr:0.0009
[10:53:05.997] iteration:1704  t-loss:0.1119, loss-lb:0.1057, loss-ulb:0.0653, weight:0.10, lr:0.0009
[10:53:06.188] iteration:1705  t-loss:0.1005, loss-lb:0.0980, loss-ulb:0.0261, weight:0.10, lr:0.0009
[10:53:06.379] iteration:1706  t-loss:0.1194, loss-lb:0.1142, loss-ulb:0.0543, weight:0.10, lr:0.0009
[10:53:06.570] iteration:1707  t-loss:0.1235, loss-lb:0.1207, loss-ulb:0.0292, weight:0.10, lr:0.0009
[10:53:06.762] iteration:1708  t-loss:0.1188, loss-lb:0.1126, loss-ulb:0.0652, weight:0.10, lr:0.0009
[10:53:06.954] iteration:1709  t-loss:0.1292, loss-lb:0.1250, loss-ulb:0.0438, weight:0.10, lr:0.0009
[10:53:07.146] iteration:1710  t-loss:0.1227, loss-lb:0.1175, loss-ulb:0.0546, weight:0.10, lr:0.0009
[10:53:07.338] iteration:1711  t-loss:0.1176, loss-lb:0.1049, loss-ulb:0.1333, weight:0.10, lr:0.0009
[10:53:07.530] iteration:1712  t-loss:0.1221, loss-lb:0.1140, loss-ulb:0.0847, weight:0.10, lr:0.0009
[10:53:07.724] iteration:1713  t-loss:0.1207, loss-lb:0.1129, loss-ulb:0.0820, weight:0.10, lr:0.0009
[10:53:07.915] iteration:1714  t-loss:0.1053, loss-lb:0.1013, loss-ulb:0.0419, weight:0.10, lr:0.0009
[10:53:08.106] iteration:1715  t-loss:0.1359, loss-lb:0.1319, loss-ulb:0.0414, weight:0.10, lr:0.0009
[10:53:08.298] iteration:1716  t-loss:0.1178, loss-lb:0.1127, loss-ulb:0.0536, weight:0.10, lr:0.0009
[10:53:08.489] iteration:1717  t-loss:0.1163, loss-lb:0.1117, loss-ulb:0.0483, weight:0.10, lr:0.0009
[10:53:08.683] iteration:1718  t-loss:0.1209, loss-lb:0.1174, loss-ulb:0.0364, weight:0.10, lr:0.0009
[10:53:08.874] iteration:1719  t-loss:0.1235, loss-lb:0.1160, loss-ulb:0.0786, weight:0.10, lr:0.0009
[10:53:09.066] iteration:1720  t-loss:0.1164, loss-lb:0.1099, loss-ulb:0.0675, weight:0.10, lr:0.0009
[10:53:09.258] iteration:1721  t-loss:0.1127, loss-lb:0.1093, loss-ulb:0.0360, weight:0.10, lr:0.0009
[10:53:09.449] iteration:1722  t-loss:0.1220, loss-lb:0.1193, loss-ulb:0.0278, weight:0.10, lr:0.0009
[10:53:09.640] iteration:1723  t-loss:0.1072, loss-lb:0.1038, loss-ulb:0.0357, weight:0.10, lr:0.0009
[10:53:09.832] iteration:1724  t-loss:0.1114, loss-lb:0.1079, loss-ulb:0.0364, weight:0.10, lr:0.0009
[10:53:10.025] iteration:1725  t-loss:0.1143, loss-lb:0.1099, loss-ulb:0.0458, weight:0.10, lr:0.0009
[10:53:10.217] iteration:1726  t-loss:0.1092, loss-lb:0.1047, loss-ulb:0.0465, weight:0.10, lr:0.0009
[10:53:10.408] iteration:1727  t-loss:0.1161, loss-lb:0.1134, loss-ulb:0.0283, weight:0.10, lr:0.0009
[10:53:10.601] iteration:1728  t-loss:0.1124, loss-lb:0.1092, loss-ulb:0.0335, weight:0.10, lr:0.0009
[10:53:10.793] iteration:1729  t-loss:0.1016, loss-lb:0.0947, loss-ulb:0.0728, weight:0.10, lr:0.0009
[10:53:10.985] iteration:1730  t-loss:0.1314, loss-lb:0.1268, loss-ulb:0.0474, weight:0.10, lr:0.0009
[10:53:11.176] iteration:1731  t-loss:0.1188, loss-lb:0.1148, loss-ulb:0.0414, weight:0.10, lr:0.0009
[10:53:11.367] iteration:1732  t-loss:0.1146, loss-lb:0.1102, loss-ulb:0.0457, weight:0.10, lr:0.0009
[10:53:11.560] iteration:1733  t-loss:0.1395, loss-lb:0.1359, loss-ulb:0.0376, weight:0.10, lr:0.0009
[10:53:11.750] iteration:1734  t-loss:0.1460, loss-lb:0.1413, loss-ulb:0.0491, weight:0.10, lr:0.0009
[10:53:11.942] iteration:1735  t-loss:0.1170, loss-lb:0.1106, loss-ulb:0.0666, weight:0.10, lr:0.0009
[10:53:12.134] iteration:1736  t-loss:0.1568, loss-lb:0.1536, loss-ulb:0.0339, weight:0.10, lr:0.0009
[10:53:12.341] iteration:1737  t-loss:0.1294, loss-lb:0.1265, loss-ulb:0.0300, weight:0.10, lr:0.0009
[10:53:12.541] iteration:1738  t-loss:0.1384, loss-lb:0.1339, loss-ulb:0.0466, weight:0.10, lr:0.0009
[10:53:12.733] iteration:1739  t-loss:0.1209, loss-lb:0.1173, loss-ulb:0.0380, weight:0.10, lr:0.0009
[10:53:12.924] iteration:1740  t-loss:0.1446, loss-lb:0.1379, loss-ulb:0.0700, weight:0.10, lr:0.0009
[10:53:13.115] iteration:1741  t-loss:0.1160, loss-lb:0.1130, loss-ulb:0.0308, weight:0.10, lr:0.0009
[10:53:13.306] iteration:1742  t-loss:0.1333, loss-lb:0.1305, loss-ulb:0.0299, weight:0.10, lr:0.0009
[10:53:13.498] iteration:1743  t-loss:0.1192, loss-lb:0.1131, loss-ulb:0.0640, weight:0.10, lr:0.0009
[10:53:13.691] iteration:1744  t-loss:0.1284, loss-lb:0.1227, loss-ulb:0.0603, weight:0.10, lr:0.0009
[10:53:13.883] iteration:1745  t-loss:0.1288, loss-lb:0.1235, loss-ulb:0.0557, weight:0.10, lr:0.0009
[10:53:14.074] iteration:1746  t-loss:0.1218, loss-lb:0.1140, loss-ulb:0.0815, weight:0.10, lr:0.0009
[10:53:14.266] iteration:1747  t-loss:0.1104, loss-lb:0.1043, loss-ulb:0.0632, weight:0.10, lr:0.0009
[10:53:14.457] iteration:1748  t-loss:0.1532, loss-lb:0.1389, loss-ulb:0.1495, weight:0.10, lr:0.0009
[10:53:14.650] iteration:1749  t-loss:0.1524, loss-lb:0.1455, loss-ulb:0.0726, weight:0.10, lr:0.0009
[10:53:14.842] iteration:1750  t-loss:0.1214, loss-lb:0.1177, loss-ulb:0.0395, weight:0.10, lr:0.0009
[10:53:15.033] iteration:1751  t-loss:0.1242, loss-lb:0.1204, loss-ulb:0.0398, weight:0.10, lr:0.0009
[10:53:15.225] iteration:1752  t-loss:0.1379, loss-lb:0.1316, loss-ulb:0.0657, weight:0.10, lr:0.0009
[10:53:15.417] iteration:1753  t-loss:0.1784, loss-lb:0.1680, loss-ulb:0.1087, weight:0.10, lr:0.0009
[10:53:15.608] iteration:1754  t-loss:0.1567, loss-lb:0.1509, loss-ulb:0.0617, weight:0.10, lr:0.0009
[10:53:15.800] iteration:1755  t-loss:0.1282, loss-lb:0.1252, loss-ulb:0.0311, weight:0.10, lr:0.0009
[10:53:15.991] iteration:1756  t-loss:0.1391, loss-lb:0.1321, loss-ulb:0.0740, weight:0.10, lr:0.0009
[10:53:16.182] iteration:1757  t-loss:0.1639, loss-lb:0.1593, loss-ulb:0.0476, weight:0.10, lr:0.0009
[10:53:16.372] iteration:1758  t-loss:0.1322, loss-lb:0.1287, loss-ulb:0.0365, weight:0.10, lr:0.0009
[10:53:16.563] iteration:1759  t-loss:0.1393, loss-lb:0.1334, loss-ulb:0.0626, weight:0.10, lr:0.0009
[10:53:16.753] iteration:1760  t-loss:0.1315, loss-lb:0.1268, loss-ulb:0.0497, weight:0.10, lr:0.0009
[10:53:16.943] iteration:1761  t-loss:0.1438, loss-lb:0.1393, loss-ulb:0.0469, weight:0.10, lr:0.0009
[10:53:17.133] iteration:1762  t-loss:0.1642, loss-lb:0.1457, loss-ulb:0.1935, weight:0.10, lr:0.0009
[10:53:17.323] iteration:1763  t-loss:0.1378, loss-lb:0.1332, loss-ulb:0.0485, weight:0.10, lr:0.0009
[10:53:17.513] iteration:1764  t-loss:0.1470, loss-lb:0.1269, loss-ulb:0.2105, weight:0.10, lr:0.0009
[10:53:18.110] iteration:1765  t-loss:0.1647, loss-lb:0.1525, loss-ulb:0.1283, weight:0.10, lr:0.0009
[10:53:18.305] iteration:1766  t-loss:0.1383, loss-lb:0.1346, loss-ulb:0.0383, weight:0.10, lr:0.0009
[10:53:18.497] iteration:1767  t-loss:0.1300, loss-lb:0.1221, loss-ulb:0.0825, weight:0.10, lr:0.0009
[10:53:18.689] iteration:1768  t-loss:0.1341, loss-lb:0.1299, loss-ulb:0.0441, weight:0.10, lr:0.0009
[10:53:18.881] iteration:1769  t-loss:0.1276, loss-lb:0.1230, loss-ulb:0.0481, weight:0.10, lr:0.0009
[10:53:19.073] iteration:1770  t-loss:0.1186, loss-lb:0.1142, loss-ulb:0.0460, weight:0.10, lr:0.0009
[10:53:19.263] iteration:1771  t-loss:0.1344, loss-lb:0.1291, loss-ulb:0.0557, weight:0.10, lr:0.0009
[10:53:19.455] iteration:1772  t-loss:0.1809, loss-lb:0.1653, loss-ulb:0.1633, weight:0.10, lr:0.0009
[10:53:19.647] iteration:1773  t-loss:0.1194, loss-lb:0.1135, loss-ulb:0.0625, weight:0.10, lr:0.0009
[10:53:19.839] iteration:1774  t-loss:0.1347, loss-lb:0.1284, loss-ulb:0.0656, weight:0.10, lr:0.0009
[10:53:20.031] iteration:1775  t-loss:0.1332, loss-lb:0.1246, loss-ulb:0.0904, weight:0.10, lr:0.0009
[10:53:20.224] iteration:1776  t-loss:0.1366, loss-lb:0.1332, loss-ulb:0.0359, weight:0.10, lr:0.0009
[10:53:20.414] iteration:1777  t-loss:0.1277, loss-lb:0.1141, loss-ulb:0.1425, weight:0.10, lr:0.0009
[10:53:20.607] iteration:1778  t-loss:0.1312, loss-lb:0.1264, loss-ulb:0.0500, weight:0.10, lr:0.0009
[10:53:20.798] iteration:1779  t-loss:0.1201, loss-lb:0.1137, loss-ulb:0.0669, weight:0.10, lr:0.0009
[10:53:20.990] iteration:1780  t-loss:0.1282, loss-lb:0.1219, loss-ulb:0.0659, weight:0.10, lr:0.0009
[10:53:21.182] iteration:1781  t-loss:0.1451, loss-lb:0.1358, loss-ulb:0.0969, weight:0.10, lr:0.0009
[10:53:21.373] iteration:1782  t-loss:0.1598, loss-lb:0.1555, loss-ulb:0.0449, weight:0.10, lr:0.0009
[10:53:21.565] iteration:1783  t-loss:0.1215, loss-lb:0.1187, loss-ulb:0.0297, weight:0.10, lr:0.0009
[10:53:21.757] iteration:1784  t-loss:0.1481, loss-lb:0.1404, loss-ulb:0.0806, weight:0.10, lr:0.0009
[10:53:21.948] iteration:1785  t-loss:0.1442, loss-lb:0.1397, loss-ulb:0.0472, weight:0.10, lr:0.0009
[10:53:22.139] iteration:1786  t-loss:0.1513, loss-lb:0.1428, loss-ulb:0.0889, weight:0.10, lr:0.0009
[10:53:22.331] iteration:1787  t-loss:0.1251, loss-lb:0.1214, loss-ulb:0.0387, weight:0.10, lr:0.0009
[10:53:22.523] iteration:1788  t-loss:0.1248, loss-lb:0.1194, loss-ulb:0.0565, weight:0.10, lr:0.0009
[10:53:22.715] iteration:1789  t-loss:0.1782, loss-lb:0.1678, loss-ulb:0.1091, weight:0.10, lr:0.0009
[10:53:22.907] iteration:1790  t-loss:0.1289, loss-lb:0.1221, loss-ulb:0.0715, weight:0.10, lr:0.0009
[10:53:23.099] iteration:1791  t-loss:0.1426, loss-lb:0.1339, loss-ulb:0.0904, weight:0.10, lr:0.0009
[10:53:23.290] iteration:1792  t-loss:0.1186, loss-lb:0.1155, loss-ulb:0.0332, weight:0.10, lr:0.0009
[10:53:23.483] iteration:1793  t-loss:0.1353, loss-lb:0.1305, loss-ulb:0.0506, weight:0.10, lr:0.0009
[10:53:23.675] iteration:1794  t-loss:0.1238, loss-lb:0.1170, loss-ulb:0.0707, weight:0.10, lr:0.0009
[10:53:23.866] iteration:1795  t-loss:0.1537, loss-lb:0.1483, loss-ulb:0.0559, weight:0.10, lr:0.0009
[10:53:24.057] iteration:1796  t-loss:0.1529, loss-lb:0.1472, loss-ulb:0.0593, weight:0.10, lr:0.0009
[10:53:24.248] iteration:1797  t-loss:0.1242, loss-lb:0.1195, loss-ulb:0.0498, weight:0.10, lr:0.0009
[10:53:24.441] iteration:1798  t-loss:0.1219, loss-lb:0.1182, loss-ulb:0.0384, weight:0.10, lr:0.0009
[10:53:24.632] iteration:1799  t-loss:0.1253, loss-lb:0.1199, loss-ulb:0.0565, weight:0.10, lr:0.0009
[10:53:24.824] iteration:1800  t-loss:0.1262, loss-lb:0.1191, loss-ulb:0.0742, weight:0.10, lr:0.0009
[10:53:25.017] iteration:1801  t-loss:0.1360, loss-lb:0.1293, loss-ulb:0.0593, weight:0.11, lr:0.0009
[10:53:25.209] iteration:1802  t-loss:0.1354, loss-lb:0.1304, loss-ulb:0.0451, weight:0.11, lr:0.0009
[10:53:25.400] iteration:1803  t-loss:0.1318, loss-lb:0.1266, loss-ulb:0.0463, weight:0.11, lr:0.0009
[10:53:25.592] iteration:1804  t-loss:0.1314, loss-lb:0.1259, loss-ulb:0.0487, weight:0.11, lr:0.0009
[10:53:25.784] iteration:1805  t-loss:0.1300, loss-lb:0.1224, loss-ulb:0.0686, weight:0.11, lr:0.0009
[10:53:25.977] iteration:1806  t-loss:0.1275, loss-lb:0.1184, loss-ulb:0.0821, weight:0.11, lr:0.0009
[10:53:26.169] iteration:1807  t-loss:0.1367, loss-lb:0.1285, loss-ulb:0.0737, weight:0.11, lr:0.0009
[10:53:26.362] iteration:1808  t-loss:0.1150, loss-lb:0.1112, loss-ulb:0.0340, weight:0.11, lr:0.0009
[10:53:26.553] iteration:1809  t-loss:0.1076, loss-lb:0.1007, loss-ulb:0.0626, weight:0.11, lr:0.0009
[10:53:26.745] iteration:1810  t-loss:0.1199, loss-lb:0.1149, loss-ulb:0.0454, weight:0.11, lr:0.0009
[10:53:26.936] iteration:1811  t-loss:0.1098, loss-lb:0.1039, loss-ulb:0.0538, weight:0.11, lr:0.0009
[10:53:27.128] iteration:1812  t-loss:0.1183, loss-lb:0.1074, loss-ulb:0.0980, weight:0.11, lr:0.0009
[10:53:27.320] iteration:1813  t-loss:0.1599, loss-lb:0.1523, loss-ulb:0.0684, weight:0.11, lr:0.0009
[10:53:27.513] iteration:1814  t-loss:0.1713, loss-lb:0.1623, loss-ulb:0.0808, weight:0.11, lr:0.0009
[10:53:27.705] iteration:1815  t-loss:0.1254, loss-lb:0.1176, loss-ulb:0.0702, weight:0.11, lr:0.0009
[10:53:27.897] iteration:1816  t-loss:0.1394, loss-lb:0.1199, loss-ulb:0.1757, weight:0.11, lr:0.0009
[10:53:28.089] iteration:1817  t-loss:0.1751, loss-lb:0.1622, loss-ulb:0.1159, weight:0.11, lr:0.0009
[10:53:28.281] iteration:1818  t-loss:0.1641, loss-lb:0.1561, loss-ulb:0.0724, weight:0.11, lr:0.0009
[10:53:28.472] iteration:1819  t-loss:0.1216, loss-lb:0.1110, loss-ulb:0.0953, weight:0.11, lr:0.0009
[10:53:28.664] iteration:1820  t-loss:0.1440, loss-lb:0.1359, loss-ulb:0.0728, weight:0.11, lr:0.0009
[10:53:28.856] iteration:1821  t-loss:0.1300, loss-lb:0.1208, loss-ulb:0.0822, weight:0.11, lr:0.0009
[10:53:29.048] iteration:1822  t-loss:0.1637, loss-lb:0.1557, loss-ulb:0.0724, weight:0.11, lr:0.0009
[10:53:29.239] iteration:1823  t-loss:0.3215, loss-lb:0.3152, loss-ulb:0.0565, weight:0.11, lr:0.0009
[10:53:29.431] iteration:1824  t-loss:0.1329, loss-lb:0.1246, loss-ulb:0.0746, weight:0.11, lr:0.0009
[10:53:29.623] iteration:1825  t-loss:0.1606, loss-lb:0.1563, loss-ulb:0.0394, weight:0.11, lr:0.0009
[10:53:29.816] iteration:1826  t-loss:0.1413, loss-lb:0.1323, loss-ulb:0.0807, weight:0.11, lr:0.0009
[10:53:30.008] iteration:1827  t-loss:0.1685, loss-lb:0.1512, loss-ulb:0.1555, weight:0.11, lr:0.0009
[10:53:30.200] iteration:1828  t-loss:0.1241, loss-lb:0.1180, loss-ulb:0.0548, weight:0.11, lr:0.0009
[10:53:30.390] iteration:1829  t-loss:0.1582, loss-lb:0.1532, loss-ulb:0.0446, weight:0.11, lr:0.0009
[10:53:30.582] iteration:1830  t-loss:0.1674, loss-lb:0.1589, loss-ulb:0.0769, weight:0.11, lr:0.0009
[10:53:30.775] iteration:1831  t-loss:0.1362, loss-lb:0.1314, loss-ulb:0.0431, weight:0.11, lr:0.0009
[10:53:30.967] iteration:1832  t-loss:0.1268, loss-lb:0.1224, loss-ulb:0.0395, weight:0.11, lr:0.0009
[10:53:31.159] iteration:1833  t-loss:0.1433, loss-lb:0.1360, loss-ulb:0.0659, weight:0.11, lr:0.0009
[10:53:31.349] iteration:1834  t-loss:0.1397, loss-lb:0.1329, loss-ulb:0.0610, weight:0.11, lr:0.0009
[10:53:31.541] iteration:1835  t-loss:0.1300, loss-lb:0.1235, loss-ulb:0.0579, weight:0.11, lr:0.0009
[10:53:31.732] iteration:1836  t-loss:0.1563, loss-lb:0.1495, loss-ulb:0.0608, weight:0.11, lr:0.0009
[10:53:31.925] iteration:1837  t-loss:0.1857, loss-lb:0.1724, loss-ulb:0.1195, weight:0.11, lr:0.0009
[10:53:32.117] iteration:1838  t-loss:0.1503, loss-lb:0.1458, loss-ulb:0.0403, weight:0.11, lr:0.0009
[10:53:32.309] iteration:1839  t-loss:0.1477, loss-lb:0.1419, loss-ulb:0.0517, weight:0.11, lr:0.0009
[10:53:32.501] iteration:1840  t-loss:0.1343, loss-lb:0.1219, loss-ulb:0.1107, weight:0.11, lr:0.0009
[10:53:32.693] iteration:1841  t-loss:0.1414, loss-lb:0.1353, loss-ulb:0.0548, weight:0.11, lr:0.0009
[10:53:32.886] iteration:1842  t-loss:0.1280, loss-lb:0.1221, loss-ulb:0.0535, weight:0.11, lr:0.0009
[10:53:33.077] iteration:1843  t-loss:0.1236, loss-lb:0.1206, loss-ulb:0.0278, weight:0.11, lr:0.0009
[10:53:33.269] iteration:1844  t-loss:0.1369, loss-lb:0.1281, loss-ulb:0.0793, weight:0.11, lr:0.0009
[10:53:33.460] iteration:1845  t-loss:0.1290, loss-lb:0.1223, loss-ulb:0.0602, weight:0.11, lr:0.0009
[10:53:33.651] iteration:1846  t-loss:0.1374, loss-lb:0.1310, loss-ulb:0.0572, weight:0.11, lr:0.0009
[10:53:33.843] iteration:1847  t-loss:0.1254, loss-lb:0.1156, loss-ulb:0.0883, weight:0.11, lr:0.0009
[10:53:34.035] iteration:1848  t-loss:0.1296, loss-lb:0.1226, loss-ulb:0.0628, weight:0.11, lr:0.0009
[10:53:34.226] iteration:1849  t-loss:0.1343, loss-lb:0.1273, loss-ulb:0.0631, weight:0.11, lr:0.0009
[10:53:34.418] iteration:1850  t-loss:0.1191, loss-lb:0.1155, loss-ulb:0.0325, weight:0.11, lr:0.0009
[10:53:34.612] iteration:1851  t-loss:0.1316, loss-lb:0.1222, loss-ulb:0.0845, weight:0.11, lr:0.0009
[10:53:34.803] iteration:1852  t-loss:0.1313, loss-lb:0.1265, loss-ulb:0.0432, weight:0.11, lr:0.0009
[10:53:34.994] iteration:1853  t-loss:0.1327, loss-lb:0.1278, loss-ulb:0.0438, weight:0.11, lr:0.0009
[10:53:35.186] iteration:1854  t-loss:0.1396, loss-lb:0.1278, loss-ulb:0.1061, weight:0.11, lr:0.0009
[10:53:35.378] iteration:1855  t-loss:0.1432, loss-lb:0.1379, loss-ulb:0.0475, weight:0.11, lr:0.0009
[10:53:35.567] iteration:1856  t-loss:0.1336, loss-lb:0.1236, loss-ulb:0.0896, weight:0.11, lr:0.0009
[10:53:35.757] iteration:1857  t-loss:0.1157, loss-lb:0.1111, loss-ulb:0.0419, weight:0.11, lr:0.0009
[10:53:35.947] iteration:1858  t-loss:0.1341, loss-lb:0.1293, loss-ulb:0.0437, weight:0.11, lr:0.0009
[10:53:36.137] iteration:1859  t-loss:0.1179, loss-lb:0.1139, loss-ulb:0.0358, weight:0.11, lr:0.0009
[10:53:36.326] iteration:1860  t-loss:0.1326, loss-lb:0.1290, loss-ulb:0.0329, weight:0.11, lr:0.0009
[10:53:36.516] iteration:1861  t-loss:0.1131, loss-lb:0.1098, loss-ulb:0.0303, weight:0.11, lr:0.0009
[10:53:36.706] iteration:1862  t-loss:0.1665, loss-lb:0.1608, loss-ulb:0.0514, weight:0.11, lr:0.0009
[10:53:48.808]  <<Test>> - Ep:18  - mean_dice/mean_h95 - S:87.40/4.93, Best-S:87.40, T:88.01/2.41, Best-T:88.01
[10:53:48.808]           - AvgLoss(lb/ulb/all):0.1320/0.0561/0.1314
[10:53:49.320] iteration:1863  t-loss:0.1411, loss-lb:0.1348, loss-ulb:0.0565, weight:0.11, lr:0.0009
[10:53:49.515] iteration:1864  t-loss:0.1514, loss-lb:0.1447, loss-ulb:0.0598, weight:0.11, lr:0.0009
[10:53:49.708] iteration:1865  t-loss:0.1300, loss-lb:0.1247, loss-ulb:0.0475, weight:0.11, lr:0.0009
[10:53:49.901] iteration:1866  t-loss:0.1382, loss-lb:0.1335, loss-ulb:0.0423, weight:0.11, lr:0.0009
[10:53:50.093] iteration:1867  t-loss:0.1270, loss-lb:0.1207, loss-ulb:0.0569, weight:0.11, lr:0.0009
[10:53:50.283] iteration:1868  t-loss:0.1229, loss-lb:0.1183, loss-ulb:0.0408, weight:0.11, lr:0.0009
[10:53:50.477] iteration:1869  t-loss:0.1274, loss-lb:0.1169, loss-ulb:0.0937, weight:0.11, lr:0.0009
[10:53:50.670] iteration:1870  t-loss:0.1427, loss-lb:0.1359, loss-ulb:0.0615, weight:0.11, lr:0.0009
[10:53:50.864] iteration:1871  t-loss:0.1269, loss-lb:0.1241, loss-ulb:0.0247, weight:0.11, lr:0.0009
[10:53:51.055] iteration:1872  t-loss:0.1139, loss-lb:0.1099, loss-ulb:0.0365, weight:0.11, lr:0.0009
[10:53:51.250] iteration:1873  t-loss:0.1123, loss-lb:0.1092, loss-ulb:0.0273, weight:0.11, lr:0.0009
[10:53:51.440] iteration:1874  t-loss:0.1149, loss-lb:0.1083, loss-ulb:0.0591, weight:0.11, lr:0.0009
[10:53:51.633] iteration:1875  t-loss:0.1237, loss-lb:0.1165, loss-ulb:0.0650, weight:0.11, lr:0.0009
[10:53:51.824] iteration:1876  t-loss:0.1296, loss-lb:0.1239, loss-ulb:0.0514, weight:0.11, lr:0.0009
[10:53:52.015] iteration:1877  t-loss:0.1382, loss-lb:0.1345, loss-ulb:0.0335, weight:0.11, lr:0.0009
[10:53:52.207] iteration:1878  t-loss:0.1315, loss-lb:0.1252, loss-ulb:0.0569, weight:0.11, lr:0.0009
[10:53:52.400] iteration:1879  t-loss:0.1227, loss-lb:0.1158, loss-ulb:0.0623, weight:0.11, lr:0.0009
[10:53:52.592] iteration:1880  t-loss:0.1163, loss-lb:0.1098, loss-ulb:0.0583, weight:0.11, lr:0.0009
[10:53:52.783] iteration:1881  t-loss:0.1220, loss-lb:0.1166, loss-ulb:0.0490, weight:0.11, lr:0.0009
[10:53:52.976] iteration:1882  t-loss:0.1044, loss-lb:0.1001, loss-ulb:0.0388, weight:0.11, lr:0.0009
[10:53:53.167] iteration:1883  t-loss:0.1209, loss-lb:0.1133, loss-ulb:0.0685, weight:0.11, lr:0.0009
[10:53:53.357] iteration:1884  t-loss:0.1234, loss-lb:0.1184, loss-ulb:0.0448, weight:0.11, lr:0.0009
[10:53:53.550] iteration:1885  t-loss:0.1249, loss-lb:0.1176, loss-ulb:0.0661, weight:0.11, lr:0.0009
[10:53:53.743] iteration:1886  t-loss:0.1164, loss-lb:0.1024, loss-ulb:0.1255, weight:0.11, lr:0.0009
[10:53:53.935] iteration:1887  t-loss:0.1111, loss-lb:0.1071, loss-ulb:0.0357, weight:0.11, lr:0.0009
[10:53:54.126] iteration:1888  t-loss:0.1365, loss-lb:0.1239, loss-ulb:0.1125, weight:0.11, lr:0.0009
[10:53:54.318] iteration:1889  t-loss:0.1288, loss-lb:0.1216, loss-ulb:0.0644, weight:0.11, lr:0.0009
[10:53:54.509] iteration:1890  t-loss:0.1180, loss-lb:0.1130, loss-ulb:0.0452, weight:0.11, lr:0.0009
[10:53:54.701] iteration:1891  t-loss:0.1328, loss-lb:0.1200, loss-ulb:0.1153, weight:0.11, lr:0.0009
[10:53:54.892] iteration:1892  t-loss:0.1350, loss-lb:0.1258, loss-ulb:0.0829, weight:0.11, lr:0.0009
[10:53:55.084] iteration:1893  t-loss:0.1173, loss-lb:0.1118, loss-ulb:0.0495, weight:0.11, lr:0.0009
[10:53:55.276] iteration:1894  t-loss:0.1305, loss-lb:0.1274, loss-ulb:0.0280, weight:0.11, lr:0.0009
[10:53:55.468] iteration:1895  t-loss:0.1213, loss-lb:0.1085, loss-ulb:0.1143, weight:0.11, lr:0.0009
[10:53:55.658] iteration:1896  t-loss:0.1247, loss-lb:0.1213, loss-ulb:0.0311, weight:0.11, lr:0.0009
[10:53:55.848] iteration:1897  t-loss:0.1275, loss-lb:0.1183, loss-ulb:0.0826, weight:0.11, lr:0.0009
[10:53:56.039] iteration:1898  t-loss:0.1267, loss-lb:0.1236, loss-ulb:0.0274, weight:0.11, lr:0.0009
[10:53:56.231] iteration:1899  t-loss:0.1329, loss-lb:0.1219, loss-ulb:0.0982, weight:0.11, lr:0.0009
[10:53:56.420] iteration:1900  t-loss:0.1110, loss-lb:0.1075, loss-ulb:0.0315, weight:0.11, lr:0.0009
[10:53:56.611] iteration:1901  t-loss:0.1230, loss-lb:0.1164, loss-ulb:0.0600, weight:0.11, lr:0.0009
[10:53:56.801] iteration:1902  t-loss:0.1163, loss-lb:0.1101, loss-ulb:0.0554, weight:0.11, lr:0.0009
[10:53:56.992] iteration:1903  t-loss:0.1179, loss-lb:0.1118, loss-ulb:0.0553, weight:0.11, lr:0.0009
[10:53:57.183] iteration:1904  t-loss:0.1198, loss-lb:0.1149, loss-ulb:0.0440, weight:0.11, lr:0.0009
[10:53:57.376] iteration:1905  t-loss:0.1318, loss-lb:0.1270, loss-ulb:0.0431, weight:0.11, lr:0.0009
[10:53:57.571] iteration:1906  t-loss:0.1198, loss-lb:0.1145, loss-ulb:0.0476, weight:0.11, lr:0.0009
[10:53:57.767] iteration:1907  t-loss:0.1087, loss-lb:0.1053, loss-ulb:0.0306, weight:0.11, lr:0.0009
[10:53:57.960] iteration:1908  t-loss:0.1152, loss-lb:0.1106, loss-ulb:0.0417, weight:0.11, lr:0.0009
[10:53:58.152] iteration:1909  t-loss:0.1156, loss-lb:0.1110, loss-ulb:0.0414, weight:0.11, lr:0.0009
[10:53:58.347] iteration:1910  t-loss:0.1176, loss-lb:0.1055, loss-ulb:0.1085, weight:0.11, lr:0.0009
[10:53:58.539] iteration:1911  t-loss:0.1152, loss-lb:0.1096, loss-ulb:0.0502, weight:0.11, lr:0.0009
[10:53:58.729] iteration:1912  t-loss:0.1119, loss-lb:0.1064, loss-ulb:0.0495, weight:0.11, lr:0.0009
[10:53:58.923] iteration:1913  t-loss:0.1141, loss-lb:0.1102, loss-ulb:0.0351, weight:0.11, lr:0.0009
[10:53:59.113] iteration:1914  t-loss:0.1203, loss-lb:0.1136, loss-ulb:0.0597, weight:0.11, lr:0.0009
[10:53:59.306] iteration:1915  t-loss:0.1194, loss-lb:0.1155, loss-ulb:0.0351, weight:0.11, lr:0.0009
[10:53:59.496] iteration:1916  t-loss:0.1095, loss-lb:0.1027, loss-ulb:0.0616, weight:0.11, lr:0.0009
[10:53:59.688] iteration:1917  t-loss:0.1302, loss-lb:0.1220, loss-ulb:0.0733, weight:0.11, lr:0.0009
[10:53:59.881] iteration:1918  t-loss:0.1452, loss-lb:0.1284, loss-ulb:0.1507, weight:0.11, lr:0.0009
[10:54:00.073] iteration:1919  t-loss:0.1165, loss-lb:0.1110, loss-ulb:0.0492, weight:0.11, lr:0.0009
[10:54:00.264] iteration:1920  t-loss:0.1150, loss-lb:0.1110, loss-ulb:0.0359, weight:0.11, lr:0.0009
[10:54:00.457] iteration:1921  t-loss:0.1160, loss-lb:0.1100, loss-ulb:0.0534, weight:0.11, lr:0.0009
[10:54:00.650] iteration:1922  t-loss:0.1307, loss-lb:0.1248, loss-ulb:0.0528, weight:0.11, lr:0.0009
[10:54:00.841] iteration:1923  t-loss:0.1140, loss-lb:0.1097, loss-ulb:0.0388, weight:0.11, lr:0.0009
[10:54:01.032] iteration:1924  t-loss:0.1150, loss-lb:0.1107, loss-ulb:0.0387, weight:0.11, lr:0.0009
[10:54:01.226] iteration:1925  t-loss:0.1268, loss-lb:0.1218, loss-ulb:0.0453, weight:0.11, lr:0.0009
[10:54:01.419] iteration:1926  t-loss:0.1168, loss-lb:0.1109, loss-ulb:0.0529, weight:0.11, lr:0.0009
[10:54:01.610] iteration:1927  t-loss:0.1155, loss-lb:0.1114, loss-ulb:0.0368, weight:0.11, lr:0.0009
[10:54:01.802] iteration:1928  t-loss:0.1163, loss-lb:0.1058, loss-ulb:0.0935, weight:0.11, lr:0.0009
[10:54:02.001] iteration:1929  t-loss:0.1208, loss-lb:0.1124, loss-ulb:0.0760, weight:0.11, lr:0.0009
[10:54:02.192] iteration:1930  t-loss:0.1230, loss-lb:0.1160, loss-ulb:0.0626, weight:0.11, lr:0.0009
[10:54:02.384] iteration:1931  t-loss:0.1078, loss-lb:0.1039, loss-ulb:0.0351, weight:0.11, lr:0.0009
[10:54:02.574] iteration:1932  t-loss:0.1166, loss-lb:0.1129, loss-ulb:0.0325, weight:0.11, lr:0.0009
[10:54:02.766] iteration:1933  t-loss:0.1458, loss-lb:0.1432, loss-ulb:0.0237, weight:0.11, lr:0.0009
[10:54:02.957] iteration:1934  t-loss:0.1189, loss-lb:0.1157, loss-ulb:0.0286, weight:0.11, lr:0.0009
[10:54:03.147] iteration:1935  t-loss:0.1147, loss-lb:0.1070, loss-ulb:0.0694, weight:0.11, lr:0.0009
[10:54:03.338] iteration:1936  t-loss:0.1165, loss-lb:0.1130, loss-ulb:0.0312, weight:0.11, lr:0.0009
[10:54:03.528] iteration:1937  t-loss:0.1181, loss-lb:0.1114, loss-ulb:0.0598, weight:0.11, lr:0.0009
[10:54:03.719] iteration:1938  t-loss:0.1223, loss-lb:0.1161, loss-ulb:0.0553, weight:0.11, lr:0.0009
[10:54:03.909] iteration:1939  t-loss:0.1106, loss-lb:0.1056, loss-ulb:0.0447, weight:0.11, lr:0.0009
[10:54:04.100] iteration:1940  t-loss:0.1148, loss-lb:0.1108, loss-ulb:0.0361, weight:0.11, lr:0.0009
[10:54:04.292] iteration:1941  t-loss:0.1160, loss-lb:0.1129, loss-ulb:0.0286, weight:0.11, lr:0.0009
[10:54:04.486] iteration:1942  t-loss:0.1124, loss-lb:0.1071, loss-ulb:0.0484, weight:0.11, lr:0.0009
[10:54:04.679] iteration:1943  t-loss:0.1020, loss-lb:0.0980, loss-ulb:0.0364, weight:0.11, lr:0.0009
[10:54:04.874] iteration:1944  t-loss:0.1099, loss-lb:0.1049, loss-ulb:0.0457, weight:0.11, lr:0.0009
[10:54:05.067] iteration:1945  t-loss:0.1174, loss-lb:0.1099, loss-ulb:0.0670, weight:0.11, lr:0.0009
[10:54:05.259] iteration:1946  t-loss:0.1288, loss-lb:0.1186, loss-ulb:0.0915, weight:0.11, lr:0.0009
[10:54:05.452] iteration:1947  t-loss:0.1223, loss-lb:0.1177, loss-ulb:0.0417, weight:0.11, lr:0.0009
[10:54:05.645] iteration:1948  t-loss:0.1056, loss-lb:0.0996, loss-ulb:0.0544, weight:0.11, lr:0.0009
[10:54:05.837] iteration:1949  t-loss:0.1296, loss-lb:0.1258, loss-ulb:0.0340, weight:0.11, lr:0.0009
[10:54:06.029] iteration:1950  t-loss:0.1083, loss-lb:0.1045, loss-ulb:0.0345, weight:0.11, lr:0.0009
[10:54:06.220] iteration:1951  t-loss:0.1512, loss-lb:0.1413, loss-ulb:0.0760, weight:0.13, lr:0.0009
[10:54:06.412] iteration:1952  t-loss:0.1448, loss-lb:0.1414, loss-ulb:0.0260, weight:0.13, lr:0.0009
[10:54:06.603] iteration:1953  t-loss:0.1139, loss-lb:0.1077, loss-ulb:0.0479, weight:0.13, lr:0.0009
[10:54:06.793] iteration:1954  t-loss:0.1156, loss-lb:0.1074, loss-ulb:0.0638, weight:0.13, lr:0.0009
[10:54:06.984] iteration:1955  t-loss:0.1295, loss-lb:0.1248, loss-ulb:0.0362, weight:0.13, lr:0.0009
[10:54:07.175] iteration:1956  t-loss:0.1121, loss-lb:0.1055, loss-ulb:0.0510, weight:0.13, lr:0.0009
[10:54:07.366] iteration:1957  t-loss:0.1265, loss-lb:0.1215, loss-ulb:0.0388, weight:0.13, lr:0.0009
[10:54:07.556] iteration:1958  t-loss:0.1249, loss-lb:0.1118, loss-ulb:0.1013, weight:0.13, lr:0.0009
[10:54:07.747] iteration:1959  t-loss:0.1230, loss-lb:0.1126, loss-ulb:0.0799, weight:0.13, lr:0.0009
[10:54:07.937] iteration:1960  t-loss:0.1083, loss-lb:0.1045, loss-ulb:0.0294, weight:0.13, lr:0.0009
[10:54:08.527] iteration:1961  t-loss:0.1274, loss-lb:0.1171, loss-ulb:0.0797, weight:0.13, lr:0.0009
[10:54:08.720] iteration:1962  t-loss:0.1204, loss-lb:0.1131, loss-ulb:0.0559, weight:0.13, lr:0.0009
[10:54:08.913] iteration:1963  t-loss:0.1230, loss-lb:0.1167, loss-ulb:0.0486, weight:0.13, lr:0.0009
[10:54:09.105] iteration:1964  t-loss:0.1395, loss-lb:0.1296, loss-ulb:0.0768, weight:0.13, lr:0.0009
[10:54:09.296] iteration:1965  t-loss:0.1262, loss-lb:0.1220, loss-ulb:0.0325, weight:0.13, lr:0.0009
[10:54:09.487] iteration:1966  t-loss:0.1318, loss-lb:0.1266, loss-ulb:0.0399, weight:0.13, lr:0.0009
[10:54:09.679] iteration:1967  t-loss:0.1683, loss-lb:0.1619, loss-ulb:0.0495, weight:0.13, lr:0.0009
[10:54:09.871] iteration:1968  t-loss:0.1294, loss-lb:0.1239, loss-ulb:0.0430, weight:0.13, lr:0.0009
[10:54:10.061] iteration:1969  t-loss:0.1269, loss-lb:0.1234, loss-ulb:0.0273, weight:0.13, lr:0.0009
[10:54:10.252] iteration:1970  t-loss:0.1304, loss-lb:0.1258, loss-ulb:0.0354, weight:0.13, lr:0.0009
[10:54:10.443] iteration:1971  t-loss:0.1158, loss-lb:0.1102, loss-ulb:0.0435, weight:0.13, lr:0.0009
[10:54:10.633] iteration:1972  t-loss:0.1104, loss-lb:0.1024, loss-ulb:0.0621, weight:0.13, lr:0.0009
[10:54:10.824] iteration:1973  t-loss:0.1161, loss-lb:0.1110, loss-ulb:0.0393, weight:0.13, lr:0.0009
[10:54:11.016] iteration:1974  t-loss:0.1187, loss-lb:0.1088, loss-ulb:0.0761, weight:0.13, lr:0.0009
[10:54:11.210] iteration:1975  t-loss:0.1191, loss-lb:0.1128, loss-ulb:0.0483, weight:0.13, lr:0.0009
[10:54:11.406] iteration:1976  t-loss:0.1343, loss-lb:0.1221, loss-ulb:0.0939, weight:0.13, lr:0.0009
[10:54:11.603] iteration:1977  t-loss:0.1156, loss-lb:0.1107, loss-ulb:0.0378, weight:0.13, lr:0.0009
[10:54:11.796] iteration:1978  t-loss:0.1341, loss-lb:0.1161, loss-ulb:0.1393, weight:0.13, lr:0.0009
[10:54:11.991] iteration:1979  t-loss:0.1314, loss-lb:0.1263, loss-ulb:0.0397, weight:0.13, lr:0.0009
[10:54:12.182] iteration:1980  t-loss:0.1022, loss-lb:0.0980, loss-ulb:0.0320, weight:0.13, lr:0.0009
[10:54:12.375] iteration:1981  t-loss:0.1204, loss-lb:0.1163, loss-ulb:0.0315, weight:0.13, lr:0.0009
[10:54:12.567] iteration:1982  t-loss:0.1177, loss-lb:0.1113, loss-ulb:0.0493, weight:0.13, lr:0.0009
[10:54:12.760] iteration:1983  t-loss:0.1088, loss-lb:0.0995, loss-ulb:0.0725, weight:0.13, lr:0.0009
[10:54:12.951] iteration:1984  t-loss:0.1117, loss-lb:0.1062, loss-ulb:0.0424, weight:0.13, lr:0.0009
[10:54:13.145] iteration:1985  t-loss:0.1195, loss-lb:0.1110, loss-ulb:0.0657, weight:0.13, lr:0.0009
[10:54:13.338] iteration:1986  t-loss:0.1227, loss-lb:0.1139, loss-ulb:0.0675, weight:0.13, lr:0.0009
[10:54:13.531] iteration:1987  t-loss:0.1340, loss-lb:0.1261, loss-ulb:0.0610, weight:0.13, lr:0.0009
[10:54:13.722] iteration:1988  t-loss:0.1287, loss-lb:0.1207, loss-ulb:0.0617, weight:0.13, lr:0.0009
[10:54:13.911] iteration:1989  t-loss:0.1174, loss-lb:0.1132, loss-ulb:0.0324, weight:0.13, lr:0.0009
[10:54:14.103] iteration:1990  t-loss:0.1299, loss-lb:0.1230, loss-ulb:0.0527, weight:0.13, lr:0.0009
[10:54:14.294] iteration:1991  t-loss:0.1136, loss-lb:0.1103, loss-ulb:0.0260, weight:0.13, lr:0.0009
[10:54:14.485] iteration:1992  t-loss:0.1200, loss-lb:0.1119, loss-ulb:0.0626, weight:0.13, lr:0.0009
[10:54:14.677] iteration:1993  t-loss:0.1109, loss-lb:0.1057, loss-ulb:0.0403, weight:0.13, lr:0.0009
[10:54:14.869] iteration:1994  t-loss:0.1158, loss-lb:0.1121, loss-ulb:0.0282, weight:0.13, lr:0.0009
[10:54:15.061] iteration:1995  t-loss:0.1076, loss-lb:0.1029, loss-ulb:0.0363, weight:0.13, lr:0.0009
[10:54:15.253] iteration:1996  t-loss:0.1130, loss-lb:0.1054, loss-ulb:0.0584, weight:0.13, lr:0.0009
[10:54:15.445] iteration:1997  t-loss:0.1212, loss-lb:0.1163, loss-ulb:0.0373, weight:0.13, lr:0.0009
[10:54:15.638] iteration:1998  t-loss:0.1397, loss-lb:0.1322, loss-ulb:0.0576, weight:0.13, lr:0.0009
[10:54:15.830] iteration:1999  t-loss:0.1309, loss-lb:0.1228, loss-ulb:0.0628, weight:0.13, lr:0.0009
[10:54:16.021] iteration:2000  t-loss:0.1332, loss-lb:0.1224, loss-ulb:0.0835, weight:0.13, lr:0.0009
[10:54:16.213] iteration:2001  t-loss:0.1206, loss-lb:0.1134, loss-ulb:0.0555, weight:0.13, lr:0.0009
[10:54:16.406] iteration:2002  t-loss:0.1308, loss-lb:0.1258, loss-ulb:0.0389, weight:0.13, lr:0.0009
[10:54:16.597] iteration:2003  t-loss:0.1210, loss-lb:0.1123, loss-ulb:0.0674, weight:0.13, lr:0.0009
[10:54:16.789] iteration:2004  t-loss:0.1515, loss-lb:0.1444, loss-ulb:0.0551, weight:0.13, lr:0.0009
[10:54:16.980] iteration:2005  t-loss:0.1038, loss-lb:0.0961, loss-ulb:0.0596, weight:0.13, lr:0.0009
[10:54:17.172] iteration:2006  t-loss:0.1101, loss-lb:0.1038, loss-ulb:0.0486, weight:0.13, lr:0.0009
[10:54:17.362] iteration:2007  t-loss:0.1130, loss-lb:0.1086, loss-ulb:0.0342, weight:0.13, lr:0.0009
[10:54:17.555] iteration:2008  t-loss:0.1103, loss-lb:0.1026, loss-ulb:0.0593, weight:0.13, lr:0.0009
[10:54:17.753] iteration:2009  t-loss:0.1193, loss-lb:0.1132, loss-ulb:0.0471, weight:0.13, lr:0.0009
[10:54:17.957] iteration:2010  t-loss:0.1164, loss-lb:0.1094, loss-ulb:0.0541, weight:0.13, lr:0.0009
[10:54:18.156] iteration:2011  t-loss:0.1110, loss-lb:0.1053, loss-ulb:0.0440, weight:0.13, lr:0.0009
[10:54:18.347] iteration:2012  t-loss:0.1136, loss-lb:0.1096, loss-ulb:0.0307, weight:0.13, lr:0.0009
[10:54:18.538] iteration:2013  t-loss:0.1027, loss-lb:0.0969, loss-ulb:0.0449, weight:0.13, lr:0.0009
[10:54:18.730] iteration:2014  t-loss:0.1202, loss-lb:0.1161, loss-ulb:0.0314, weight:0.13, lr:0.0009
[10:54:18.922] iteration:2015  t-loss:0.1139, loss-lb:0.1071, loss-ulb:0.0529, weight:0.13, lr:0.0009
[10:54:19.113] iteration:2016  t-loss:0.1175, loss-lb:0.1117, loss-ulb:0.0444, weight:0.13, lr:0.0009
[10:54:19.306] iteration:2017  t-loss:0.1168, loss-lb:0.1134, loss-ulb:0.0263, weight:0.13, lr:0.0009
[10:54:19.498] iteration:2018  t-loss:0.1159, loss-lb:0.1117, loss-ulb:0.0321, weight:0.13, lr:0.0009
[10:54:19.690] iteration:2019  t-loss:0.1327, loss-lb:0.1273, loss-ulb:0.0412, weight:0.13, lr:0.0009
[10:54:19.881] iteration:2020  t-loss:0.1254, loss-lb:0.1208, loss-ulb:0.0352, weight:0.13, lr:0.0009
[10:54:20.073] iteration:2021  t-loss:0.1091, loss-lb:0.1050, loss-ulb:0.0321, weight:0.13, lr:0.0009
[10:54:20.266] iteration:2022  t-loss:0.1625, loss-lb:0.1573, loss-ulb:0.0400, weight:0.13, lr:0.0009
[10:54:20.458] iteration:2023  t-loss:0.1141, loss-lb:0.1091, loss-ulb:0.0388, weight:0.13, lr:0.0009
[10:54:20.650] iteration:2024  t-loss:0.1086, loss-lb:0.1013, loss-ulb:0.0564, weight:0.13, lr:0.0009
[10:54:20.842] iteration:2025  t-loss:0.1282, loss-lb:0.1181, loss-ulb:0.0779, weight:0.13, lr:0.0009
[10:54:21.034] iteration:2026  t-loss:0.1101, loss-lb:0.1013, loss-ulb:0.0685, weight:0.13, lr:0.0009
[10:54:21.225] iteration:2027  t-loss:0.1386, loss-lb:0.1295, loss-ulb:0.0699, weight:0.13, lr:0.0009
[10:54:21.419] iteration:2028  t-loss:0.1232, loss-lb:0.1138, loss-ulb:0.0726, weight:0.13, lr:0.0009
[10:54:21.611] iteration:2029  t-loss:0.1079, loss-lb:0.1011, loss-ulb:0.0519, weight:0.13, lr:0.0009
[10:54:21.803] iteration:2030  t-loss:0.1026, loss-lb:0.0995, loss-ulb:0.0237, weight:0.13, lr:0.0009
[10:54:21.996] iteration:2031  t-loss:0.1169, loss-lb:0.1108, loss-ulb:0.0476, weight:0.13, lr:0.0009
[10:54:22.188] iteration:2032  t-loss:0.1330, loss-lb:0.1278, loss-ulb:0.0401, weight:0.13, lr:0.0009
[10:54:22.380] iteration:2033  t-loss:0.1323, loss-lb:0.1248, loss-ulb:0.0583, weight:0.13, lr:0.0009
[10:54:22.572] iteration:2034  t-loss:0.1249, loss-lb:0.1214, loss-ulb:0.0270, weight:0.13, lr:0.0009
[10:54:22.764] iteration:2035  t-loss:0.1131, loss-lb:0.1093, loss-ulb:0.0295, weight:0.13, lr:0.0009
[10:54:22.955] iteration:2036  t-loss:0.1331, loss-lb:0.1192, loss-ulb:0.1068, weight:0.13, lr:0.0009
[10:54:23.147] iteration:2037  t-loss:0.1029, loss-lb:0.0991, loss-ulb:0.0295, weight:0.13, lr:0.0009
[10:54:23.340] iteration:2038  t-loss:0.1163, loss-lb:0.1113, loss-ulb:0.0384, weight:0.13, lr:0.0009
[10:54:23.531] iteration:2039  t-loss:0.1083, loss-lb:0.1053, loss-ulb:0.0238, weight:0.13, lr:0.0009
[10:54:23.724] iteration:2040  t-loss:0.1315, loss-lb:0.1256, loss-ulb:0.0460, weight:0.13, lr:0.0009
[10:54:23.917] iteration:2041  t-loss:0.1193, loss-lb:0.1160, loss-ulb:0.0258, weight:0.13, lr:0.0009
[10:54:24.109] iteration:2042  t-loss:0.1310, loss-lb:0.1205, loss-ulb:0.0814, weight:0.13, lr:0.0009
[10:54:24.300] iteration:2043  t-loss:0.1181, loss-lb:0.1114, loss-ulb:0.0522, weight:0.13, lr:0.0009
[10:54:24.492] iteration:2044  t-loss:0.1071, loss-lb:0.1009, loss-ulb:0.0485, weight:0.13, lr:0.0009
[10:54:24.683] iteration:2045  t-loss:0.1133, loss-lb:0.1092, loss-ulb:0.0316, weight:0.13, lr:0.0009
[10:54:24.875] iteration:2046  t-loss:0.1166, loss-lb:0.1113, loss-ulb:0.0409, weight:0.13, lr:0.0009
[10:54:25.067] iteration:2047  t-loss:0.1447, loss-lb:0.1405, loss-ulb:0.0327, weight:0.13, lr:0.0009
[10:54:25.259] iteration:2048  t-loss:0.1017, loss-lb:0.0946, loss-ulb:0.0547, weight:0.13, lr:0.0009
[10:54:25.451] iteration:2049  t-loss:0.1119, loss-lb:0.1072, loss-ulb:0.0364, weight:0.13, lr:0.0009
[10:54:25.644] iteration:2050  t-loss:0.1151, loss-lb:0.1113, loss-ulb:0.0298, weight:0.13, lr:0.0009
[10:54:25.834] iteration:2051  t-loss:0.1174, loss-lb:0.1096, loss-ulb:0.0609, weight:0.13, lr:0.0009
[10:54:26.025] iteration:2052  t-loss:0.1382, loss-lb:0.1320, loss-ulb:0.0476, weight:0.13, lr:0.0009
[10:54:26.214] iteration:2053  t-loss:0.1270, loss-lb:0.1225, loss-ulb:0.0347, weight:0.13, lr:0.0009
[10:54:26.404] iteration:2054  t-loss:0.1168, loss-lb:0.1088, loss-ulb:0.0619, weight:0.13, lr:0.0009
[10:54:26.594] iteration:2055  t-loss:0.1212, loss-lb:0.1167, loss-ulb:0.0345, weight:0.13, lr:0.0009
[10:54:26.785] iteration:2056  t-loss:0.1190, loss-lb:0.1060, loss-ulb:0.1004, weight:0.13, lr:0.0009
[10:54:26.975] iteration:2057  t-loss:0.1245, loss-lb:0.1200, loss-ulb:0.0347, weight:0.13, lr:0.0009
[10:54:27.166] iteration:2058  t-loss:0.1092, loss-lb:0.1006, loss-ulb:0.0663, weight:0.13, lr:0.0009
[10:54:38.031]  <<Test>> - Ep:20  - mean_dice/mean_h95 - S:85.12/6.45, Best-S:87.40, T:88.62/2.13, Best-T:88.62
[10:54:38.031]           - AvgLoss(lb/ulb/all):0.1147/0.0472/0.1196
[10:54:38.565] iteration:2059  t-loss:0.1292, loss-lb:0.1155, loss-ulb:0.1060, weight:0.13, lr:0.0009
[10:54:38.765] iteration:2060  t-loss:0.1105, loss-lb:0.1054, loss-ulb:0.0390, weight:0.13, lr:0.0009
[10:54:38.958] iteration:2061  t-loss:0.1123, loss-lb:0.1053, loss-ulb:0.0543, weight:0.13, lr:0.0009
[10:54:39.150] iteration:2062  t-loss:0.1323, loss-lb:0.1179, loss-ulb:0.1111, weight:0.13, lr:0.0009
[10:54:39.342] iteration:2063  t-loss:0.1309, loss-lb:0.1246, loss-ulb:0.0493, weight:0.13, lr:0.0009
[10:54:39.533] iteration:2064  t-loss:0.1156, loss-lb:0.1108, loss-ulb:0.0370, weight:0.13, lr:0.0009
[10:54:39.723] iteration:2065  t-loss:0.1146, loss-lb:0.1101, loss-ulb:0.0347, weight:0.13, lr:0.0009
[10:54:39.915] iteration:2066  t-loss:0.2092, loss-lb:0.1981, loss-ulb:0.0852, weight:0.13, lr:0.0009
[10:54:40.108] iteration:2067  t-loss:0.1250, loss-lb:0.1215, loss-ulb:0.0274, weight:0.13, lr:0.0009
[10:54:40.301] iteration:2068  t-loss:0.1140, loss-lb:0.1047, loss-ulb:0.0720, weight:0.13, lr:0.0009
[10:54:40.492] iteration:2069  t-loss:0.1478, loss-lb:0.1395, loss-ulb:0.0638, weight:0.13, lr:0.0009
[10:54:40.684] iteration:2070  t-loss:0.1128, loss-lb:0.1074, loss-ulb:0.0418, weight:0.13, lr:0.0009
[10:54:40.876] iteration:2071  t-loss:0.1277, loss-lb:0.1194, loss-ulb:0.0642, weight:0.13, lr:0.0009
[10:54:41.068] iteration:2072  t-loss:0.1151, loss-lb:0.1103, loss-ulb:0.0377, weight:0.13, lr:0.0009
[10:54:41.259] iteration:2073  t-loss:0.1253, loss-lb:0.1195, loss-ulb:0.0451, weight:0.13, lr:0.0009
[10:54:41.450] iteration:2074  t-loss:0.1232, loss-lb:0.1140, loss-ulb:0.0717, weight:0.13, lr:0.0009
[10:54:41.643] iteration:2075  t-loss:0.1374, loss-lb:0.1325, loss-ulb:0.0382, weight:0.13, lr:0.0009
[10:54:41.836] iteration:2076  t-loss:0.1318, loss-lb:0.1146, loss-ulb:0.1332, weight:0.13, lr:0.0009
[10:54:42.028] iteration:2077  t-loss:0.1303, loss-lb:0.1229, loss-ulb:0.0566, weight:0.13, lr:0.0009
[10:54:42.220] iteration:2078  t-loss:0.1105, loss-lb:0.1058, loss-ulb:0.0361, weight:0.13, lr:0.0009
[10:54:42.413] iteration:2079  t-loss:0.1143, loss-lb:0.1056, loss-ulb:0.0672, weight:0.13, lr:0.0009
[10:54:42.605] iteration:2080  t-loss:0.1470, loss-lb:0.1418, loss-ulb:0.0396, weight:0.13, lr:0.0009
[10:54:42.794] iteration:2081  t-loss:0.1150, loss-lb:0.1102, loss-ulb:0.0365, weight:0.13, lr:0.0009
[10:54:42.986] iteration:2082  t-loss:0.1189, loss-lb:0.1123, loss-ulb:0.0509, weight:0.13, lr:0.0009
[10:54:43.178] iteration:2083  t-loss:0.1546, loss-lb:0.1328, loss-ulb:0.1684, weight:0.13, lr:0.0009
[10:54:43.371] iteration:2084  t-loss:0.1456, loss-lb:0.1270, loss-ulb:0.1439, weight:0.13, lr:0.0009
[10:54:43.564] iteration:2085  t-loss:0.1202, loss-lb:0.1132, loss-ulb:0.0538, weight:0.13, lr:0.0009
[10:54:43.755] iteration:2086  t-loss:0.1604, loss-lb:0.1438, loss-ulb:0.1288, weight:0.13, lr:0.0009
[10:54:43.948] iteration:2087  t-loss:0.1266, loss-lb:0.1057, loss-ulb:0.1617, weight:0.13, lr:0.0009
[10:54:44.140] iteration:2088  t-loss:0.1219, loss-lb:0.1129, loss-ulb:0.0689, weight:0.13, lr:0.0009
[10:54:44.333] iteration:2089  t-loss:0.1119, loss-lb:0.1072, loss-ulb:0.0365, weight:0.13, lr:0.0009
[10:54:44.525] iteration:2090  t-loss:0.1304, loss-lb:0.1246, loss-ulb:0.0452, weight:0.13, lr:0.0009
[10:54:44.717] iteration:2091  t-loss:0.1435, loss-lb:0.1376, loss-ulb:0.0452, weight:0.13, lr:0.0009
[10:54:44.908] iteration:2092  t-loss:0.1144, loss-lb:0.1105, loss-ulb:0.0295, weight:0.13, lr:0.0009
[10:54:45.100] iteration:2093  t-loss:0.1554, loss-lb:0.1496, loss-ulb:0.0451, weight:0.13, lr:0.0009
[10:54:45.292] iteration:2094  t-loss:0.1206, loss-lb:0.1127, loss-ulb:0.0614, weight:0.13, lr:0.0009
[10:54:45.483] iteration:2095  t-loss:0.1188, loss-lb:0.1130, loss-ulb:0.0448, weight:0.13, lr:0.0009
[10:54:45.675] iteration:2096  t-loss:0.1623, loss-lb:0.1441, loss-ulb:0.1407, weight:0.13, lr:0.0009
[10:54:45.867] iteration:2097  t-loss:0.1250, loss-lb:0.1169, loss-ulb:0.0627, weight:0.13, lr:0.0009
[10:54:46.059] iteration:2098  t-loss:0.1242, loss-lb:0.1179, loss-ulb:0.0489, weight:0.13, lr:0.0009
[10:54:46.251] iteration:2099  t-loss:0.1446, loss-lb:0.1401, loss-ulb:0.0346, weight:0.13, lr:0.0009
[10:54:46.443] iteration:2100  t-loss:0.1097, loss-lb:0.1045, loss-ulb:0.0399, weight:0.13, lr:0.0009
[10:54:46.635] iteration:2101  t-loss:0.1410, loss-lb:0.1292, loss-ulb:0.0788, weight:0.15, lr:0.0009
[10:54:46.827] iteration:2102  t-loss:0.1500, loss-lb:0.1390, loss-ulb:0.0731, weight:0.15, lr:0.0009
[10:54:47.019] iteration:2103  t-loss:0.1215, loss-lb:0.1133, loss-ulb:0.0548, weight:0.15, lr:0.0009
[10:54:47.211] iteration:2104  t-loss:0.1256, loss-lb:0.1168, loss-ulb:0.0592, weight:0.15, lr:0.0009
[10:54:47.403] iteration:2105  t-loss:0.1230, loss-lb:0.1096, loss-ulb:0.0894, weight:0.15, lr:0.0009
[10:54:47.596] iteration:2106  t-loss:0.1565, loss-lb:0.1397, loss-ulb:0.1120, weight:0.15, lr:0.0009
[10:54:47.787] iteration:2107  t-loss:0.1273, loss-lb:0.1218, loss-ulb:0.0371, weight:0.15, lr:0.0009
[10:54:47.979] iteration:2108  t-loss:0.1087, loss-lb:0.1017, loss-ulb:0.0470, weight:0.15, lr:0.0009
[10:54:48.170] iteration:2109  t-loss:0.1250, loss-lb:0.1176, loss-ulb:0.0497, weight:0.15, lr:0.0009
[10:54:48.363] iteration:2110  t-loss:0.1350, loss-lb:0.1162, loss-ulb:0.1253, weight:0.15, lr:0.0009
[10:54:48.557] iteration:2111  t-loss:0.1100, loss-lb:0.1043, loss-ulb:0.0380, weight:0.15, lr:0.0009
[10:54:48.748] iteration:2112  t-loss:0.1553, loss-lb:0.1427, loss-ulb:0.0841, weight:0.15, lr:0.0009
[10:54:48.939] iteration:2113  t-loss:0.1250, loss-lb:0.1190, loss-ulb:0.0399, weight:0.15, lr:0.0009
[10:54:49.132] iteration:2114  t-loss:0.1377, loss-lb:0.1237, loss-ulb:0.0935, weight:0.15, lr:0.0009
[10:54:49.323] iteration:2115  t-loss:0.1376, loss-lb:0.1304, loss-ulb:0.0482, weight:0.15, lr:0.0009
[10:54:49.515] iteration:2116  t-loss:0.1247, loss-lb:0.1145, loss-ulb:0.0676, weight:0.15, lr:0.0009
[10:54:49.708] iteration:2117  t-loss:0.1212, loss-lb:0.1139, loss-ulb:0.0487, weight:0.15, lr:0.0009
[10:54:49.899] iteration:2118  t-loss:0.1499, loss-lb:0.1316, loss-ulb:0.1223, weight:0.15, lr:0.0009
[10:54:50.091] iteration:2119  t-loss:0.1271, loss-lb:0.1203, loss-ulb:0.0451, weight:0.15, lr:0.0009
[10:54:50.284] iteration:2120  t-loss:0.1627, loss-lb:0.1469, loss-ulb:0.1051, weight:0.15, lr:0.0009
[10:54:50.476] iteration:2121  t-loss:0.1441, loss-lb:0.1348, loss-ulb:0.0617, weight:0.15, lr:0.0009
[10:54:50.681] iteration:2122  t-loss:0.1310, loss-lb:0.1223, loss-ulb:0.0582, weight:0.15, lr:0.0009
[10:54:50.877] iteration:2123  t-loss:0.1399, loss-lb:0.1278, loss-ulb:0.0804, weight:0.15, lr:0.0009
[10:54:51.071] iteration:2124  t-loss:0.1117, loss-lb:0.1036, loss-ulb:0.0539, weight:0.15, lr:0.0009
[10:54:51.264] iteration:2125  t-loss:0.1474, loss-lb:0.1348, loss-ulb:0.0841, weight:0.15, lr:0.0009
[10:54:51.455] iteration:2126  t-loss:0.1525, loss-lb:0.1439, loss-ulb:0.0574, weight:0.15, lr:0.0009
[10:54:51.648] iteration:2127  t-loss:0.1179, loss-lb:0.1122, loss-ulb:0.0382, weight:0.15, lr:0.0009
[10:54:51.841] iteration:2128  t-loss:0.1215, loss-lb:0.1164, loss-ulb:0.0342, weight:0.15, lr:0.0009
[10:54:52.033] iteration:2129  t-loss:0.1327, loss-lb:0.1276, loss-ulb:0.0342, weight:0.15, lr:0.0009
[10:54:52.225] iteration:2130  t-loss:0.1501, loss-lb:0.1434, loss-ulb:0.0449, weight:0.15, lr:0.0009
[10:54:52.417] iteration:2131  t-loss:0.1449, loss-lb:0.1387, loss-ulb:0.0417, weight:0.15, lr:0.0009
[10:54:52.609] iteration:2132  t-loss:0.1436, loss-lb:0.1376, loss-ulb:0.0405, weight:0.15, lr:0.0009
[10:54:52.802] iteration:2133  t-loss:0.1272, loss-lb:0.1230, loss-ulb:0.0278, weight:0.15, lr:0.0009
[10:54:52.995] iteration:2134  t-loss:0.1384, loss-lb:0.1321, loss-ulb:0.0417, weight:0.15, lr:0.0009
[10:54:53.186] iteration:2135  t-loss:0.1232, loss-lb:0.1184, loss-ulb:0.0325, weight:0.15, lr:0.0009
[10:54:53.378] iteration:2136  t-loss:0.1195, loss-lb:0.1097, loss-ulb:0.0657, weight:0.15, lr:0.0009
[10:54:53.570] iteration:2137  t-loss:0.1273, loss-lb:0.1184, loss-ulb:0.0596, weight:0.15, lr:0.0009
[10:54:53.761] iteration:2138  t-loss:0.1476, loss-lb:0.1433, loss-ulb:0.0284, weight:0.15, lr:0.0009
[10:54:53.953] iteration:2139  t-loss:0.1185, loss-lb:0.1112, loss-ulb:0.0492, weight:0.15, lr:0.0009
[10:54:54.145] iteration:2140  t-loss:0.1283, loss-lb:0.1177, loss-ulb:0.0712, weight:0.15, lr:0.0009
[10:54:54.336] iteration:2141  t-loss:0.1423, loss-lb:0.1310, loss-ulb:0.0754, weight:0.15, lr:0.0009
[10:54:54.529] iteration:2142  t-loss:0.1116, loss-lb:0.1048, loss-ulb:0.0460, weight:0.15, lr:0.0009
[10:54:54.723] iteration:2143  t-loss:0.1491, loss-lb:0.1329, loss-ulb:0.1079, weight:0.15, lr:0.0009
[10:54:54.914] iteration:2144  t-loss:0.1195, loss-lb:0.1147, loss-ulb:0.0317, weight:0.15, lr:0.0009
[10:54:55.108] iteration:2145  t-loss:0.1296, loss-lb:0.1255, loss-ulb:0.0275, weight:0.15, lr:0.0009
[10:54:55.300] iteration:2146  t-loss:0.1284, loss-lb:0.1141, loss-ulb:0.0956, weight:0.15, lr:0.0009
[10:54:55.492] iteration:2147  t-loss:0.1345, loss-lb:0.1172, loss-ulb:0.1154, weight:0.15, lr:0.0009
[10:54:55.684] iteration:2148  t-loss:0.1252, loss-lb:0.1123, loss-ulb:0.0859, weight:0.15, lr:0.0009
[10:54:55.876] iteration:2149  t-loss:0.1328, loss-lb:0.1241, loss-ulb:0.0580, weight:0.15, lr:0.0009
[10:54:56.066] iteration:2150  t-loss:0.1133, loss-lb:0.1047, loss-ulb:0.0572, weight:0.15, lr:0.0009
[10:54:56.258] iteration:2151  t-loss:0.1526, loss-lb:0.1405, loss-ulb:0.0805, weight:0.15, lr:0.0009
[10:54:56.448] iteration:2152  t-loss:0.1307, loss-lb:0.1192, loss-ulb:0.0769, weight:0.15, lr:0.0009
[10:54:56.639] iteration:2153  t-loss:0.1282, loss-lb:0.1222, loss-ulb:0.0404, weight:0.15, lr:0.0009
[10:54:56.830] iteration:2154  t-loss:0.1403, loss-lb:0.1166, loss-ulb:0.1584, weight:0.15, lr:0.0009
[10:54:57.020] iteration:2155  t-loss:0.1217, loss-lb:0.1147, loss-ulb:0.0470, weight:0.15, lr:0.0009
[10:54:57.212] iteration:2156  t-loss:0.1100, loss-lb:0.1061, loss-ulb:0.0259, weight:0.15, lr:0.0009
[10:54:57.808] iteration:2157  t-loss:0.1238, loss-lb:0.1167, loss-ulb:0.0475, weight:0.15, lr:0.0009
[10:54:58.004] iteration:2158  t-loss:0.1238, loss-lb:0.1179, loss-ulb:0.0393, weight:0.15, lr:0.0009
[10:54:58.195] iteration:2159  t-loss:0.1264, loss-lb:0.1170, loss-ulb:0.0630, weight:0.15, lr:0.0009
[10:54:58.390] iteration:2160  t-loss:0.1195, loss-lb:0.1151, loss-ulb:0.0295, weight:0.15, lr:0.0009
[10:54:58.582] iteration:2161  t-loss:0.1319, loss-lb:0.1278, loss-ulb:0.0269, weight:0.15, lr:0.0009
[10:54:58.774] iteration:2162  t-loss:0.1390, loss-lb:0.1330, loss-ulb:0.0396, weight:0.15, lr:0.0009
[10:54:58.966] iteration:2163  t-loss:0.1052, loss-lb:0.0981, loss-ulb:0.0478, weight:0.15, lr:0.0009
[10:54:59.158] iteration:2164  t-loss:0.1263, loss-lb:0.1183, loss-ulb:0.0533, weight:0.15, lr:0.0009
[10:54:59.350] iteration:2165  t-loss:0.1288, loss-lb:0.1176, loss-ulb:0.0745, weight:0.15, lr:0.0009
[10:54:59.541] iteration:2166  t-loss:0.1134, loss-lb:0.1049, loss-ulb:0.0572, weight:0.15, lr:0.0009
[10:54:59.733] iteration:2167  t-loss:0.1239, loss-lb:0.1129, loss-ulb:0.0733, weight:0.15, lr:0.0009
[10:54:59.925] iteration:2168  t-loss:0.1223, loss-lb:0.1171, loss-ulb:0.0347, weight:0.15, lr:0.0009
[10:55:00.117] iteration:2169  t-loss:0.1267, loss-lb:0.1161, loss-ulb:0.0710, weight:0.15, lr:0.0009
[10:55:00.309] iteration:2170  t-loss:0.1083, loss-lb:0.1010, loss-ulb:0.0485, weight:0.15, lr:0.0009
[10:55:00.500] iteration:2171  t-loss:0.1166, loss-lb:0.1041, loss-ulb:0.0837, weight:0.15, lr:0.0009
[10:55:00.692] iteration:2172  t-loss:0.1216, loss-lb:0.1175, loss-ulb:0.0278, weight:0.15, lr:0.0009
[10:55:00.884] iteration:2173  t-loss:0.1347, loss-lb:0.1210, loss-ulb:0.0918, weight:0.15, lr:0.0009
[10:55:01.076] iteration:2174  t-loss:0.1248, loss-lb:0.1185, loss-ulb:0.0415, weight:0.15, lr:0.0009
[10:55:01.268] iteration:2175  t-loss:0.1345, loss-lb:0.1306, loss-ulb:0.0257, weight:0.15, lr:0.0009
[10:55:01.459] iteration:2176  t-loss:0.1119, loss-lb:0.1065, loss-ulb:0.0363, weight:0.15, lr:0.0009
[10:55:01.651] iteration:2177  t-loss:0.1397, loss-lb:0.1286, loss-ulb:0.0743, weight:0.15, lr:0.0009
[10:55:01.842] iteration:2178  t-loss:0.1199, loss-lb:0.1060, loss-ulb:0.0925, weight:0.15, lr:0.0009
[10:55:02.035] iteration:2179  t-loss:0.1183, loss-lb:0.1038, loss-ulb:0.0964, weight:0.15, lr:0.0009
[10:55:02.227] iteration:2180  t-loss:0.1036, loss-lb:0.0968, loss-ulb:0.0450, weight:0.15, lr:0.0009
[10:55:02.418] iteration:2181  t-loss:0.1157, loss-lb:0.1106, loss-ulb:0.0340, weight:0.15, lr:0.0009
[10:55:02.611] iteration:2182  t-loss:0.1374, loss-lb:0.1315, loss-ulb:0.0394, weight:0.15, lr:0.0009
[10:55:02.802] iteration:2183  t-loss:0.1328, loss-lb:0.1288, loss-ulb:0.0262, weight:0.15, lr:0.0009
[10:55:02.993] iteration:2184  t-loss:0.1206, loss-lb:0.1119, loss-ulb:0.0575, weight:0.15, lr:0.0009
[10:55:03.187] iteration:2185  t-loss:0.1290, loss-lb:0.1147, loss-ulb:0.0952, weight:0.15, lr:0.0009
[10:55:03.378] iteration:2186  t-loss:0.1369, loss-lb:0.1306, loss-ulb:0.0421, weight:0.15, lr:0.0009
[10:55:03.569] iteration:2187  t-loss:0.1108, loss-lb:0.1056, loss-ulb:0.0343, weight:0.15, lr:0.0009
[10:55:03.762] iteration:2188  t-loss:0.1277, loss-lb:0.1224, loss-ulb:0.0348, weight:0.15, lr:0.0009
[10:55:03.955] iteration:2189  t-loss:0.1072, loss-lb:0.0990, loss-ulb:0.0549, weight:0.15, lr:0.0009
[10:55:04.147] iteration:2190  t-loss:0.1240, loss-lb:0.1181, loss-ulb:0.0395, weight:0.15, lr:0.0009
[10:55:04.340] iteration:2191  t-loss:0.1396, loss-lb:0.1247, loss-ulb:0.0996, weight:0.15, lr:0.0009
[10:55:04.531] iteration:2192  t-loss:0.1195, loss-lb:0.1162, loss-ulb:0.0224, weight:0.15, lr:0.0009
[10:55:04.723] iteration:2193  t-loss:0.1215, loss-lb:0.1157, loss-ulb:0.0392, weight:0.15, lr:0.0009
[10:55:04.915] iteration:2194  t-loss:0.1221, loss-lb:0.1166, loss-ulb:0.0363, weight:0.15, lr:0.0009
[10:55:05.108] iteration:2195  t-loss:0.1292, loss-lb:0.1231, loss-ulb:0.0407, weight:0.15, lr:0.0009
[10:55:05.299] iteration:2196  t-loss:0.1067, loss-lb:0.0996, loss-ulb:0.0479, weight:0.15, lr:0.0009
[10:55:05.490] iteration:2197  t-loss:0.1155, loss-lb:0.1104, loss-ulb:0.0338, weight:0.15, lr:0.0009
[10:55:05.682] iteration:2198  t-loss:0.1140, loss-lb:0.1043, loss-ulb:0.0645, weight:0.15, lr:0.0009
[10:55:05.874] iteration:2199  t-loss:0.1220, loss-lb:0.1150, loss-ulb:0.0464, weight:0.15, lr:0.0009
[10:55:06.066] iteration:2200  t-loss:0.1149, loss-lb:0.1108, loss-ulb:0.0278, weight:0.15, lr:0.0009
[10:55:06.257] iteration:2201  t-loss:0.1158, loss-lb:0.1110, loss-ulb:0.0323, weight:0.15, lr:0.0009
[10:55:06.449] iteration:2202  t-loss:0.1132, loss-lb:0.1088, loss-ulb:0.0295, weight:0.15, lr:0.0009
[10:55:06.641] iteration:2203  t-loss:0.1008, loss-lb:0.0948, loss-ulb:0.0396, weight:0.15, lr:0.0009
[10:55:06.833] iteration:2204  t-loss:0.1137, loss-lb:0.1035, loss-ulb:0.0686, weight:0.15, lr:0.0009
[10:55:07.025] iteration:2205  t-loss:0.1300, loss-lb:0.1229, loss-ulb:0.0479, weight:0.15, lr:0.0009
[10:55:07.216] iteration:2206  t-loss:0.1241, loss-lb:0.1202, loss-ulb:0.0262, weight:0.15, lr:0.0009
[10:55:07.408] iteration:2207  t-loss:0.1232, loss-lb:0.1109, loss-ulb:0.0823, weight:0.15, lr:0.0009
[10:55:07.599] iteration:2208  t-loss:0.1072, loss-lb:0.1041, loss-ulb:0.0204, weight:0.15, lr:0.0009
[10:55:07.791] iteration:2209  t-loss:0.1154, loss-lb:0.1076, loss-ulb:0.0523, weight:0.15, lr:0.0009
[10:55:07.983] iteration:2210  t-loss:0.1109, loss-lb:0.1028, loss-ulb:0.0543, weight:0.15, lr:0.0009
[10:55:08.175] iteration:2211  t-loss:0.1165, loss-lb:0.1110, loss-ulb:0.0369, weight:0.15, lr:0.0009
[10:55:08.367] iteration:2212  t-loss:0.1148, loss-lb:0.1011, loss-ulb:0.0917, weight:0.15, lr:0.0009
[10:55:08.558] iteration:2213  t-loss:0.1129, loss-lb:0.1053, loss-ulb:0.0508, weight:0.15, lr:0.0009
[10:55:08.750] iteration:2214  t-loss:0.1268, loss-lb:0.1187, loss-ulb:0.0535, weight:0.15, lr:0.0009
[10:55:08.944] iteration:2215  t-loss:0.1253, loss-lb:0.1150, loss-ulb:0.0693, weight:0.15, lr:0.0009
[10:55:09.138] iteration:2216  t-loss:0.1428, loss-lb:0.1278, loss-ulb:0.1001, weight:0.15, lr:0.0009
[10:55:09.334] iteration:2217  t-loss:0.1117, loss-lb:0.1057, loss-ulb:0.0404, weight:0.15, lr:0.0009
[10:55:09.532] iteration:2218  t-loss:0.1359, loss-lb:0.1173, loss-ulb:0.1244, weight:0.15, lr:0.0009
[10:55:09.726] iteration:2219  t-loss:0.1113, loss-lb:0.1056, loss-ulb:0.0385, weight:0.15, lr:0.0009
[10:55:09.920] iteration:2220  t-loss:0.1248, loss-lb:0.1167, loss-ulb:0.0542, weight:0.15, lr:0.0009
[10:55:10.111] iteration:2221  t-loss:0.1114, loss-lb:0.1038, loss-ulb:0.0505, weight:0.15, lr:0.0009
[10:55:10.303] iteration:2222  t-loss:0.1119, loss-lb:0.1048, loss-ulb:0.0477, weight:0.15, lr:0.0009
[10:55:10.497] iteration:2223  t-loss:0.1295, loss-lb:0.1186, loss-ulb:0.0725, weight:0.15, lr:0.0009
[10:55:10.689] iteration:2224  t-loss:0.1284, loss-lb:0.1185, loss-ulb:0.0662, weight:0.15, lr:0.0009
[10:55:10.883] iteration:2225  t-loss:0.1200, loss-lb:0.1136, loss-ulb:0.0428, weight:0.15, lr:0.0009
[10:55:11.077] iteration:2226  t-loss:0.1037, loss-lb:0.0994, loss-ulb:0.0289, weight:0.15, lr:0.0009
[10:55:11.269] iteration:2227  t-loss:0.1065, loss-lb:0.0995, loss-ulb:0.0464, weight:0.15, lr:0.0009
[10:55:11.461] iteration:2228  t-loss:0.1251, loss-lb:0.1207, loss-ulb:0.0296, weight:0.15, lr:0.0009
[10:55:11.653] iteration:2229  t-loss:0.1219, loss-lb:0.1143, loss-ulb:0.0507, weight:0.15, lr:0.0009
[10:55:11.845] iteration:2230  t-loss:0.1125, loss-lb:0.1085, loss-ulb:0.0265, weight:0.15, lr:0.0009
[10:55:12.041] iteration:2231  t-loss:0.1086, loss-lb:0.1047, loss-ulb:0.0265, weight:0.15, lr:0.0009
[10:55:12.233] iteration:2232  t-loss:0.1294, loss-lb:0.1207, loss-ulb:0.0581, weight:0.15, lr:0.0009
[10:55:12.426] iteration:2233  t-loss:0.1176, loss-lb:0.1090, loss-ulb:0.0572, weight:0.15, lr:0.0009
[10:55:12.621] iteration:2234  t-loss:0.1294, loss-lb:0.1237, loss-ulb:0.0379, weight:0.15, lr:0.0009
[10:55:12.814] iteration:2235  t-loss:0.1163, loss-lb:0.1085, loss-ulb:0.0522, weight:0.15, lr:0.0009
[10:55:13.006] iteration:2236  t-loss:0.1104, loss-lb:0.1018, loss-ulb:0.0575, weight:0.15, lr:0.0009
[10:55:13.197] iteration:2237  t-loss:0.1084, loss-lb:0.1052, loss-ulb:0.0217, weight:0.15, lr:0.0009
[10:55:13.390] iteration:2238  t-loss:0.1179, loss-lb:0.1100, loss-ulb:0.0526, weight:0.15, lr:0.0009
[10:55:13.585] iteration:2239  t-loss:0.1202, loss-lb:0.1118, loss-ulb:0.0558, weight:0.15, lr:0.0009
[10:55:13.778] iteration:2240  t-loss:0.1106, loss-lb:0.1020, loss-ulb:0.0575, weight:0.15, lr:0.0009
[10:55:13.970] iteration:2241  t-loss:0.1112, loss-lb:0.1071, loss-ulb:0.0270, weight:0.15, lr:0.0009
[10:55:14.161] iteration:2242  t-loss:0.1103, loss-lb:0.1063, loss-ulb:0.0269, weight:0.15, lr:0.0009
[10:55:14.354] iteration:2243  t-loss:0.1252, loss-lb:0.1185, loss-ulb:0.0443, weight:0.15, lr:0.0009
[10:55:14.547] iteration:2244  t-loss:0.1578, loss-lb:0.1433, loss-ulb:0.0971, weight:0.15, lr:0.0009
[10:55:14.740] iteration:2245  t-loss:0.1275, loss-lb:0.1233, loss-ulb:0.0279, weight:0.15, lr:0.0009
[10:55:14.932] iteration:2246  t-loss:0.1193, loss-lb:0.1084, loss-ulb:0.0728, weight:0.15, lr:0.0009
[10:55:15.123] iteration:2247  t-loss:0.1162, loss-lb:0.1114, loss-ulb:0.0322, weight:0.15, lr:0.0009
[10:55:15.313] iteration:2248  t-loss:0.1110, loss-lb:0.1044, loss-ulb:0.0443, weight:0.15, lr:0.0009
[10:55:15.504] iteration:2249  t-loss:0.1308, loss-lb:0.1148, loss-ulb:0.1063, weight:0.15, lr:0.0009
[10:55:15.695] iteration:2250  t-loss:0.1147, loss-lb:0.1103, loss-ulb:0.0293, weight:0.15, lr:0.0009
[10:55:15.890] iteration:2251  t-loss:0.1212, loss-lb:0.1140, loss-ulb:0.0417, weight:0.17, lr:0.0009
[10:55:16.086] iteration:2252  t-loss:0.1458, loss-lb:0.1337, loss-ulb:0.0697, weight:0.17, lr:0.0009
[10:55:16.284] iteration:2253  t-loss:0.1052, loss-lb:0.0985, loss-ulb:0.0385, weight:0.17, lr:0.0009
[10:55:16.479] iteration:2254  t-loss:0.1178, loss-lb:0.1130, loss-ulb:0.0276, weight:0.17, lr:0.0009
[10:55:29.040]  <<Test>> - Ep:22  - mean_dice/mean_h95 - S:86.95/8.86, Best-S:87.40, T:88.93/1.98, Best-T:88.93
[10:55:29.040]           - AvgLoss(lb/ulb/all):0.1130/0.0491/0.1199
[10:55:29.557] iteration:2255  t-loss:0.1185, loss-lb:0.1134, loss-ulb:0.0295, weight:0.17, lr:0.0009
[10:55:29.762] iteration:2256  t-loss:0.1089, loss-lb:0.1020, loss-ulb:0.0396, weight:0.17, lr:0.0009
[10:55:29.956] iteration:2257  t-loss:0.1254, loss-lb:0.1192, loss-ulb:0.0356, weight:0.17, lr:0.0009
[10:55:30.149] iteration:2258  t-loss:0.1317, loss-lb:0.1172, loss-ulb:0.0841, weight:0.17, lr:0.0009
[10:55:30.343] iteration:2259  t-loss:0.1223, loss-lb:0.1167, loss-ulb:0.0322, weight:0.17, lr:0.0009
[10:55:30.534] iteration:2260  t-loss:0.1084, loss-lb:0.0986, loss-ulb:0.0568, weight:0.17, lr:0.0009
[10:55:30.726] iteration:2261  t-loss:0.1567, loss-lb:0.1450, loss-ulb:0.0682, weight:0.17, lr:0.0009
[10:55:30.917] iteration:2262  t-loss:0.1228, loss-lb:0.1179, loss-ulb:0.0281, weight:0.17, lr:0.0009
[10:55:31.109] iteration:2263  t-loss:0.1289, loss-lb:0.1230, loss-ulb:0.0346, weight:0.17, lr:0.0009
[10:55:31.300] iteration:2264  t-loss:0.1386, loss-lb:0.1259, loss-ulb:0.0734, weight:0.17, lr:0.0009
[10:55:31.492] iteration:2265  t-loss:0.1293, loss-lb:0.1112, loss-ulb:0.1052, weight:0.17, lr:0.0009
[10:55:31.683] iteration:2266  t-loss:0.1103, loss-lb:0.1021, loss-ulb:0.0474, weight:0.17, lr:0.0009
[10:55:31.875] iteration:2267  t-loss:0.1235, loss-lb:0.1158, loss-ulb:0.0445, weight:0.17, lr:0.0009
[10:55:32.067] iteration:2268  t-loss:0.1043, loss-lb:0.0990, loss-ulb:0.0303, weight:0.17, lr:0.0009
[10:55:32.260] iteration:2269  t-loss:0.1098, loss-lb:0.1019, loss-ulb:0.0459, weight:0.17, lr:0.0009
[10:55:32.451] iteration:2270  t-loss:0.1302, loss-lb:0.1176, loss-ulb:0.0727, weight:0.17, lr:0.0009
[10:55:32.642] iteration:2271  t-loss:0.1423, loss-lb:0.1352, loss-ulb:0.0412, weight:0.17, lr:0.0009
[10:55:32.834] iteration:2272  t-loss:0.1198, loss-lb:0.1097, loss-ulb:0.0583, weight:0.17, lr:0.0009
[10:55:33.027] iteration:2273  t-loss:0.1159, loss-lb:0.1094, loss-ulb:0.0378, weight:0.17, lr:0.0009
[10:55:33.219] iteration:2274  t-loss:0.1606, loss-lb:0.1441, loss-ulb:0.0958, weight:0.17, lr:0.0009
[10:55:33.410] iteration:2275  t-loss:0.1124, loss-lb:0.1059, loss-ulb:0.0375, weight:0.17, lr:0.0009
[10:55:33.603] iteration:2276  t-loss:0.1228, loss-lb:0.1178, loss-ulb:0.0288, weight:0.17, lr:0.0009
[10:55:33.794] iteration:2277  t-loss:0.1172, loss-lb:0.1115, loss-ulb:0.0328, weight:0.17, lr:0.0009
[10:55:33.985] iteration:2278  t-loss:0.1155, loss-lb:0.1106, loss-ulb:0.0285, weight:0.17, lr:0.0009
[10:55:34.177] iteration:2279  t-loss:0.1220, loss-lb:0.1150, loss-ulb:0.0406, weight:0.17, lr:0.0009
[10:55:34.368] iteration:2280  t-loss:0.1156, loss-lb:0.1070, loss-ulb:0.0499, weight:0.17, lr:0.0009
[10:55:34.560] iteration:2281  t-loss:0.1373, loss-lb:0.1211, loss-ulb:0.0940, weight:0.17, lr:0.0009
[10:55:34.751] iteration:2282  t-loss:0.1374, loss-lb:0.1290, loss-ulb:0.0487, weight:0.17, lr:0.0009
[10:55:34.943] iteration:2283  t-loss:0.1213, loss-lb:0.1040, loss-ulb:0.1005, weight:0.17, lr:0.0009
[10:55:35.135] iteration:2284  t-loss:0.1171, loss-lb:0.1027, loss-ulb:0.0832, weight:0.17, lr:0.0009
[10:55:35.327] iteration:2285  t-loss:0.1186, loss-lb:0.1129, loss-ulb:0.0330, weight:0.17, lr:0.0009
[10:55:35.517] iteration:2286  t-loss:0.1257, loss-lb:0.1146, loss-ulb:0.0646, weight:0.17, lr:0.0009
[10:55:35.708] iteration:2287  t-loss:0.1081, loss-lb:0.0980, loss-ulb:0.0586, weight:0.17, lr:0.0009
[10:55:35.899] iteration:2288  t-loss:0.1045, loss-lb:0.0952, loss-ulb:0.0542, weight:0.17, lr:0.0009
[10:55:36.092] iteration:2289  t-loss:0.1201, loss-lb:0.1135, loss-ulb:0.0385, weight:0.17, lr:0.0009
[10:55:36.283] iteration:2290  t-loss:0.1285, loss-lb:0.1227, loss-ulb:0.0332, weight:0.17, lr:0.0009
[10:55:36.476] iteration:2291  t-loss:0.1263, loss-lb:0.1182, loss-ulb:0.0468, weight:0.17, lr:0.0009
[10:55:36.668] iteration:2292  t-loss:0.1203, loss-lb:0.1146, loss-ulb:0.0327, weight:0.17, lr:0.0009
[10:55:36.861] iteration:2293  t-loss:0.1254, loss-lb:0.1138, loss-ulb:0.0673, weight:0.17, lr:0.0009
[10:55:37.051] iteration:2294  t-loss:0.1071, loss-lb:0.1013, loss-ulb:0.0336, weight:0.17, lr:0.0009
[10:55:37.243] iteration:2295  t-loss:0.1143, loss-lb:0.1046, loss-ulb:0.0559, weight:0.17, lr:0.0009
[10:55:37.437] iteration:2296  t-loss:0.1238, loss-lb:0.0999, loss-ulb:0.1384, weight:0.17, lr:0.0009
[10:55:37.629] iteration:2297  t-loss:0.1444, loss-lb:0.1364, loss-ulb:0.0466, weight:0.17, lr:0.0009
[10:55:37.820] iteration:2298  t-loss:0.1074, loss-lb:0.0998, loss-ulb:0.0438, weight:0.17, lr:0.0009
[10:55:38.011] iteration:2299  t-loss:0.1216, loss-lb:0.1104, loss-ulb:0.0647, weight:0.17, lr:0.0009
[10:55:38.203] iteration:2300  t-loss:0.1110, loss-lb:0.1026, loss-ulb:0.0485, weight:0.17, lr:0.0009
[10:55:38.395] iteration:2301  t-loss:0.1063, loss-lb:0.0974, loss-ulb:0.0515, weight:0.17, lr:0.0009
[10:55:38.586] iteration:2302  t-loss:0.1213, loss-lb:0.1167, loss-ulb:0.0264, weight:0.17, lr:0.0009
[10:55:38.779] iteration:2303  t-loss:0.1166, loss-lb:0.1110, loss-ulb:0.0326, weight:0.17, lr:0.0009
[10:55:38.971] iteration:2304  t-loss:0.1164, loss-lb:0.1113, loss-ulb:0.0297, weight:0.17, lr:0.0009
[10:55:39.162] iteration:2305  t-loss:0.1172, loss-lb:0.1109, loss-ulb:0.0367, weight:0.17, lr:0.0009
[10:55:39.354] iteration:2306  t-loss:0.1346, loss-lb:0.1244, loss-ulb:0.0589, weight:0.17, lr:0.0009
[10:55:39.545] iteration:2307  t-loss:0.1132, loss-lb:0.1052, loss-ulb:0.0466, weight:0.17, lr:0.0009
[10:55:39.737] iteration:2308  t-loss:0.1136, loss-lb:0.1064, loss-ulb:0.0421, weight:0.17, lr:0.0009
[10:55:39.930] iteration:2309  t-loss:0.1063, loss-lb:0.0996, loss-ulb:0.0386, weight:0.17, lr:0.0009
[10:55:40.122] iteration:2310  t-loss:0.1159, loss-lb:0.1098, loss-ulb:0.0350, weight:0.17, lr:0.0009
[10:55:40.315] iteration:2311  t-loss:0.1264, loss-lb:0.1205, loss-ulb:0.0338, weight:0.17, lr:0.0009
[10:55:40.507] iteration:2312  t-loss:0.1159, loss-lb:0.1083, loss-ulb:0.0446, weight:0.17, lr:0.0009
[10:55:40.697] iteration:2313  t-loss:0.1032, loss-lb:0.0980, loss-ulb:0.0301, weight:0.17, lr:0.0009
[10:55:40.890] iteration:2314  t-loss:0.1150, loss-lb:0.1093, loss-ulb:0.0330, weight:0.17, lr:0.0009
[10:55:41.081] iteration:2315  t-loss:0.1191, loss-lb:0.1108, loss-ulb:0.0485, weight:0.17, lr:0.0009
[10:55:41.273] iteration:2316  t-loss:0.1266, loss-lb:0.1142, loss-ulb:0.0722, weight:0.17, lr:0.0009
[10:55:41.465] iteration:2317  t-loss:0.1224, loss-lb:0.1177, loss-ulb:0.0273, weight:0.17, lr:0.0009
[10:55:41.658] iteration:2318  t-loss:0.1142, loss-lb:0.1067, loss-ulb:0.0431, weight:0.17, lr:0.0009
[10:55:41.849] iteration:2319  t-loss:0.1172, loss-lb:0.1095, loss-ulb:0.0447, weight:0.17, lr:0.0009
[10:55:42.040] iteration:2320  t-loss:0.1284, loss-lb:0.1205, loss-ulb:0.0460, weight:0.17, lr:0.0009
[10:55:42.232] iteration:2321  t-loss:0.1329, loss-lb:0.1269, loss-ulb:0.0348, weight:0.17, lr:0.0009
[10:55:42.424] iteration:2322  t-loss:0.1112, loss-lb:0.0983, loss-ulb:0.0748, weight:0.17, lr:0.0009
[10:55:42.617] iteration:2323  t-loss:0.1272, loss-lb:0.1222, loss-ulb:0.0290, weight:0.17, lr:0.0009
[10:55:42.807] iteration:2324  t-loss:0.0984, loss-lb:0.0941, loss-ulb:0.0248, weight:0.17, lr:0.0009
[10:55:43.000] iteration:2325  t-loss:0.1197, loss-lb:0.1143, loss-ulb:0.0316, weight:0.17, lr:0.0009
[10:55:43.192] iteration:2326  t-loss:0.1185, loss-lb:0.1131, loss-ulb:0.0310, weight:0.17, lr:0.0009
[10:55:43.384] iteration:2327  t-loss:0.1291, loss-lb:0.1194, loss-ulb:0.0565, weight:0.17, lr:0.0009
[10:55:43.576] iteration:2328  t-loss:0.1138, loss-lb:0.1086, loss-ulb:0.0303, weight:0.17, lr:0.0009
[10:55:43.768] iteration:2329  t-loss:0.1181, loss-lb:0.1070, loss-ulb:0.0640, weight:0.17, lr:0.0009
[10:55:43.959] iteration:2330  t-loss:0.1171, loss-lb:0.1037, loss-ulb:0.0780, weight:0.17, lr:0.0009
[10:55:44.152] iteration:2331  t-loss:0.1175, loss-lb:0.1021, loss-ulb:0.0891, weight:0.17, lr:0.0009
[10:55:44.343] iteration:2332  t-loss:0.1414, loss-lb:0.1353, loss-ulb:0.0354, weight:0.17, lr:0.0009
[10:55:44.535] iteration:2333  t-loss:0.1355, loss-lb:0.1237, loss-ulb:0.0685, weight:0.17, lr:0.0009
[10:55:44.726] iteration:2334  t-loss:0.1108, loss-lb:0.1022, loss-ulb:0.0495, weight:0.17, lr:0.0009
[10:55:44.918] iteration:2335  t-loss:0.1117, loss-lb:0.1025, loss-ulb:0.0530, weight:0.17, lr:0.0009
[10:55:45.110] iteration:2336  t-loss:0.1210, loss-lb:0.1172, loss-ulb:0.0221, weight:0.17, lr:0.0009
[10:55:45.302] iteration:2337  t-loss:0.1132, loss-lb:0.1041, loss-ulb:0.0523, weight:0.17, lr:0.0009
[10:55:45.494] iteration:2338  t-loss:0.1298, loss-lb:0.1220, loss-ulb:0.0453, weight:0.17, lr:0.0009
[10:55:45.688] iteration:2339  t-loss:0.1125, loss-lb:0.1018, loss-ulb:0.0619, weight:0.17, lr:0.0009
[10:55:45.882] iteration:2340  t-loss:0.1095, loss-lb:0.0990, loss-ulb:0.0607, weight:0.17, lr:0.0009
[10:55:46.073] iteration:2341  t-loss:0.1425, loss-lb:0.1367, loss-ulb:0.0335, weight:0.17, lr:0.0009
[10:55:46.264] iteration:2342  t-loss:0.1574, loss-lb:0.1494, loss-ulb:0.0464, weight:0.17, lr:0.0009
[10:55:46.457] iteration:2343  t-loss:0.1325, loss-lb:0.1265, loss-ulb:0.0346, weight:0.17, lr:0.0009
[10:55:46.648] iteration:2344  t-loss:0.1321, loss-lb:0.1245, loss-ulb:0.0439, weight:0.17, lr:0.0009
[10:55:46.840] iteration:2345  t-loss:0.1143, loss-lb:0.1058, loss-ulb:0.0493, weight:0.17, lr:0.0009
[10:55:47.030] iteration:2346  t-loss:0.1504, loss-lb:0.1326, loss-ulb:0.1033, weight:0.17, lr:0.0009
[10:55:47.220] iteration:2347  t-loss:0.1597, loss-lb:0.1477, loss-ulb:0.0693, weight:0.17, lr:0.0009
[10:55:47.410] iteration:2348  t-loss:0.1426, loss-lb:0.1246, loss-ulb:0.1047, weight:0.17, lr:0.0009
[10:55:47.600] iteration:2349  t-loss:0.1325, loss-lb:0.1228, loss-ulb:0.0566, weight:0.17, lr:0.0009
[10:55:47.791] iteration:2350  t-loss:0.1196, loss-lb:0.1077, loss-ulb:0.0691, weight:0.17, lr:0.0009
[10:55:47.981] iteration:2351  t-loss:0.1316, loss-lb:0.1095, loss-ulb:0.1283, weight:0.17, lr:0.0009
[10:55:48.172] iteration:2352  t-loss:0.1289, loss-lb:0.1166, loss-ulb:0.0714, weight:0.17, lr:0.0009
[10:55:48.772] iteration:2353  t-loss:0.1422, loss-lb:0.1357, loss-ulb:0.0373, weight:0.17, lr:0.0009
[10:55:48.967] iteration:2354  t-loss:0.1314, loss-lb:0.1083, loss-ulb:0.1337, weight:0.17, lr:0.0009
[10:55:49.159] iteration:2355  t-loss:0.1423, loss-lb:0.1319, loss-ulb:0.0602, weight:0.17, lr:0.0009
[10:55:49.350] iteration:2356  t-loss:0.1425, loss-lb:0.1355, loss-ulb:0.0409, weight:0.17, lr:0.0009
[10:55:49.542] iteration:2357  t-loss:0.1250, loss-lb:0.1176, loss-ulb:0.0427, weight:0.17, lr:0.0009
[10:55:49.734] iteration:2358  t-loss:0.1192, loss-lb:0.1072, loss-ulb:0.0694, weight:0.17, lr:0.0009
[10:55:49.928] iteration:2359  t-loss:0.1270, loss-lb:0.1207, loss-ulb:0.0366, weight:0.17, lr:0.0009
[10:55:50.119] iteration:2360  t-loss:0.1489, loss-lb:0.1302, loss-ulb:0.1083, weight:0.17, lr:0.0009
[10:55:50.311] iteration:2361  t-loss:0.1184, loss-lb:0.1067, loss-ulb:0.0676, weight:0.17, lr:0.0009
[10:55:50.506] iteration:2362  t-loss:0.1356, loss-lb:0.1174, loss-ulb:0.1057, weight:0.17, lr:0.0009
[10:55:50.698] iteration:2363  t-loss:0.1095, loss-lb:0.1023, loss-ulb:0.0412, weight:0.17, lr:0.0009
[10:55:50.891] iteration:2364  t-loss:0.1359, loss-lb:0.1271, loss-ulb:0.0510, weight:0.17, lr:0.0009
[10:55:51.083] iteration:2365  t-loss:0.1209, loss-lb:0.1140, loss-ulb:0.0402, weight:0.17, lr:0.0009
[10:55:51.275] iteration:2366  t-loss:0.1445, loss-lb:0.1297, loss-ulb:0.0856, weight:0.17, lr:0.0009
[10:55:51.467] iteration:2367  t-loss:0.1152, loss-lb:0.1053, loss-ulb:0.0573, weight:0.17, lr:0.0009
[10:55:51.660] iteration:2368  t-loss:0.1182, loss-lb:0.1125, loss-ulb:0.0331, weight:0.17, lr:0.0009
[10:55:51.852] iteration:2369  t-loss:0.1373, loss-lb:0.1260, loss-ulb:0.0658, weight:0.17, lr:0.0009
[10:55:52.043] iteration:2370  t-loss:0.1391, loss-lb:0.1263, loss-ulb:0.0739, weight:0.17, lr:0.0009
[10:55:52.236] iteration:2371  t-loss:0.1396, loss-lb:0.1340, loss-ulb:0.0324, weight:0.17, lr:0.0009
[10:55:52.427] iteration:2372  t-loss:0.1205, loss-lb:0.1062, loss-ulb:0.0827, weight:0.17, lr:0.0009
[10:55:52.619] iteration:2373  t-loss:0.1332, loss-lb:0.1210, loss-ulb:0.0710, weight:0.17, lr:0.0009
[10:55:52.810] iteration:2374  t-loss:0.1314, loss-lb:0.1232, loss-ulb:0.0479, weight:0.17, lr:0.0009
[10:55:53.002] iteration:2375  t-loss:0.1098, loss-lb:0.1016, loss-ulb:0.0479, weight:0.17, lr:0.0009
[10:55:53.194] iteration:2376  t-loss:0.1146, loss-lb:0.1067, loss-ulb:0.0456, weight:0.17, lr:0.0009
[10:55:53.385] iteration:2377  t-loss:0.1365, loss-lb:0.1232, loss-ulb:0.0771, weight:0.17, lr:0.0009
[10:55:53.577] iteration:2378  t-loss:0.1334, loss-lb:0.1204, loss-ulb:0.0755, weight:0.17, lr:0.0009
[10:55:53.770] iteration:2379  t-loss:0.1420, loss-lb:0.1344, loss-ulb:0.0442, weight:0.17, lr:0.0009
[10:55:53.961] iteration:2380  t-loss:0.1481, loss-lb:0.1304, loss-ulb:0.1030, weight:0.17, lr:0.0009
[10:55:54.154] iteration:2381  t-loss:0.1375, loss-lb:0.1305, loss-ulb:0.0405, weight:0.17, lr:0.0009
[10:55:54.346] iteration:2382  t-loss:0.1236, loss-lb:0.1128, loss-ulb:0.0622, weight:0.17, lr:0.0009
[10:55:54.538] iteration:2383  t-loss:0.1237, loss-lb:0.1121, loss-ulb:0.0670, weight:0.17, lr:0.0009
[10:55:54.729] iteration:2384  t-loss:0.1296, loss-lb:0.1204, loss-ulb:0.0533, weight:0.17, lr:0.0009
[10:55:54.921] iteration:2385  t-loss:0.1100, loss-lb:0.0980, loss-ulb:0.0692, weight:0.17, lr:0.0009
[10:55:55.113] iteration:2386  t-loss:0.1334, loss-lb:0.1146, loss-ulb:0.1086, weight:0.17, lr:0.0009
[10:55:55.306] iteration:2387  t-loss:0.1261, loss-lb:0.1058, loss-ulb:0.1179, weight:0.17, lr:0.0009
[10:55:55.499] iteration:2388  t-loss:0.1147, loss-lb:0.1077, loss-ulb:0.0409, weight:0.17, lr:0.0009
[10:55:55.689] iteration:2389  t-loss:0.1240, loss-lb:0.1188, loss-ulb:0.0298, weight:0.17, lr:0.0009
[10:55:55.882] iteration:2390  t-loss:0.1746, loss-lb:0.1683, loss-ulb:0.0363, weight:0.17, lr:0.0009
[10:55:56.083] iteration:2391  t-loss:0.1194, loss-lb:0.1113, loss-ulb:0.0469, weight:0.17, lr:0.0009
[10:55:56.284] iteration:2392  t-loss:0.1289, loss-lb:0.1155, loss-ulb:0.0780, weight:0.17, lr:0.0009
[10:55:56.480] iteration:2393  t-loss:0.1275, loss-lb:0.1195, loss-ulb:0.0465, weight:0.17, lr:0.0009
[10:55:56.672] iteration:2394  t-loss:0.1281, loss-lb:0.1182, loss-ulb:0.0570, weight:0.17, lr:0.0009
[10:55:56.863] iteration:2395  t-loss:0.1253, loss-lb:0.1150, loss-ulb:0.0597, weight:0.17, lr:0.0009
[10:55:57.054] iteration:2396  t-loss:0.1412, loss-lb:0.1319, loss-ulb:0.0541, weight:0.17, lr:0.0009
[10:55:57.247] iteration:2397  t-loss:0.1307, loss-lb:0.1219, loss-ulb:0.0511, weight:0.17, lr:0.0009
[10:55:57.439] iteration:2398  t-loss:0.1214, loss-lb:0.1105, loss-ulb:0.0630, weight:0.17, lr:0.0009
[10:55:57.631] iteration:2399  t-loss:0.1179, loss-lb:0.1114, loss-ulb:0.0379, weight:0.17, lr:0.0009
[10:55:57.824] iteration:2400  t-loss:0.1313, loss-lb:0.1238, loss-ulb:0.0439, weight:0.17, lr:0.0009
[10:55:58.016] iteration:2401  t-loss:0.1343, loss-lb:0.1273, loss-ulb:0.0352, weight:0.20, lr:0.0009
[10:55:58.209] iteration:2402  t-loss:0.1262, loss-lb:0.1213, loss-ulb:0.0244, weight:0.20, lr:0.0009
[10:55:58.401] iteration:2403  t-loss:0.1149, loss-lb:0.1047, loss-ulb:0.0515, weight:0.20, lr:0.0009
[10:55:58.593] iteration:2404  t-loss:0.1170, loss-lb:0.1109, loss-ulb:0.0306, weight:0.20, lr:0.0009
[10:55:58.786] iteration:2405  t-loss:0.1330, loss-lb:0.1264, loss-ulb:0.0332, weight:0.20, lr:0.0009
[10:55:58.978] iteration:2406  t-loss:0.1301, loss-lb:0.1225, loss-ulb:0.0384, weight:0.20, lr:0.0009
[10:55:59.169] iteration:2407  t-loss:0.1179, loss-lb:0.1014, loss-ulb:0.0835, weight:0.20, lr:0.0009
[10:55:59.362] iteration:2408  t-loss:0.1371, loss-lb:0.1168, loss-ulb:0.1027, weight:0.20, lr:0.0009
[10:55:59.554] iteration:2409  t-loss:0.1261, loss-lb:0.1209, loss-ulb:0.0262, weight:0.20, lr:0.0009
[10:55:59.746] iteration:2410  t-loss:0.1285, loss-lb:0.1175, loss-ulb:0.0559, weight:0.20, lr:0.0009
[10:55:59.938] iteration:2411  t-loss:0.1215, loss-lb:0.1111, loss-ulb:0.0521, weight:0.20, lr:0.0009
[10:56:00.129] iteration:2412  t-loss:0.1134, loss-lb:0.1082, loss-ulb:0.0264, weight:0.20, lr:0.0009
[10:56:00.321] iteration:2413  t-loss:0.1165, loss-lb:0.1106, loss-ulb:0.0295, weight:0.20, lr:0.0009
[10:56:00.513] iteration:2414  t-loss:0.1134, loss-lb:0.1065, loss-ulb:0.0348, weight:0.20, lr:0.0009
[10:56:00.705] iteration:2415  t-loss:0.1174, loss-lb:0.1126, loss-ulb:0.0238, weight:0.20, lr:0.0009
[10:56:00.899] iteration:2416  t-loss:0.1125, loss-lb:0.0995, loss-ulb:0.0655, weight:0.20, lr:0.0009
[10:56:01.091] iteration:2417  t-loss:0.1165, loss-lb:0.1071, loss-ulb:0.0472, weight:0.20, lr:0.0009
[10:56:01.282] iteration:2418  t-loss:0.1220, loss-lb:0.1153, loss-ulb:0.0341, weight:0.20, lr:0.0009
[10:56:01.475] iteration:2419  t-loss:0.1403, loss-lb:0.1326, loss-ulb:0.0386, weight:0.20, lr:0.0009
[10:56:01.667] iteration:2420  t-loss:0.1143, loss-lb:0.1018, loss-ulb:0.0630, weight:0.20, lr:0.0009
[10:56:01.858] iteration:2421  t-loss:0.1043, loss-lb:0.0957, loss-ulb:0.0434, weight:0.20, lr:0.0009
[10:56:02.051] iteration:2422  t-loss:0.1154, loss-lb:0.1104, loss-ulb:0.0254, weight:0.20, lr:0.0009
[10:56:02.245] iteration:2423  t-loss:0.1160, loss-lb:0.1112, loss-ulb:0.0245, weight:0.20, lr:0.0009
[10:56:02.436] iteration:2424  t-loss:0.1246, loss-lb:0.1040, loss-ulb:0.1036, weight:0.20, lr:0.0009
[10:56:02.628] iteration:2425  t-loss:0.1172, loss-lb:0.1062, loss-ulb:0.0551, weight:0.20, lr:0.0009
[10:56:02.821] iteration:2426  t-loss:0.1182, loss-lb:0.1073, loss-ulb:0.0550, weight:0.20, lr:0.0009
[10:56:03.013] iteration:2427  t-loss:0.1079, loss-lb:0.1029, loss-ulb:0.0252, weight:0.20, lr:0.0009
[10:56:03.205] iteration:2428  t-loss:0.1209, loss-lb:0.1125, loss-ulb:0.0424, weight:0.20, lr:0.0009
[10:56:03.397] iteration:2429  t-loss:0.1170, loss-lb:0.1089, loss-ulb:0.0410, weight:0.20, lr:0.0009
[10:56:03.589] iteration:2430  t-loss:0.1158, loss-lb:0.1062, loss-ulb:0.0486, weight:0.20, lr:0.0009
[10:56:03.780] iteration:2431  t-loss:0.1225, loss-lb:0.1164, loss-ulb:0.0306, weight:0.20, lr:0.0009
[10:56:03.973] iteration:2432  t-loss:0.1145, loss-lb:0.1060, loss-ulb:0.0427, weight:0.20, lr:0.0009
[10:56:04.165] iteration:2433  t-loss:0.1049, loss-lb:0.0976, loss-ulb:0.0368, weight:0.20, lr:0.0009
[10:56:04.359] iteration:2434  t-loss:0.1122, loss-lb:0.1060, loss-ulb:0.0316, weight:0.20, lr:0.0009
[10:56:04.551] iteration:2435  t-loss:0.1169, loss-lb:0.1047, loss-ulb:0.0619, weight:0.20, lr:0.0009
[10:56:04.741] iteration:2436  t-loss:0.1141, loss-lb:0.1094, loss-ulb:0.0236, weight:0.20, lr:0.0009
[10:56:04.934] iteration:2437  t-loss:0.1239, loss-lb:0.1150, loss-ulb:0.0447, weight:0.20, lr:0.0009
[10:56:05.126] iteration:2438  t-loss:0.1067, loss-lb:0.0987, loss-ulb:0.0408, weight:0.20, lr:0.0009
[10:56:05.318] iteration:2439  t-loss:0.1117, loss-lb:0.1061, loss-ulb:0.0283, weight:0.20, lr:0.0009
[10:56:05.510] iteration:2440  t-loss:0.1367, loss-lb:0.1312, loss-ulb:0.0277, weight:0.20, lr:0.0009
[10:56:05.701] iteration:2441  t-loss:0.1169, loss-lb:0.1095, loss-ulb:0.0375, weight:0.20, lr:0.0009
[10:56:05.892] iteration:2442  t-loss:0.1021, loss-lb:0.0951, loss-ulb:0.0349, weight:0.20, lr:0.0009
[10:56:06.085] iteration:2443  t-loss:0.1157, loss-lb:0.1071, loss-ulb:0.0436, weight:0.20, lr:0.0009
[10:56:06.275] iteration:2444  t-loss:0.1385, loss-lb:0.1190, loss-ulb:0.0987, weight:0.20, lr:0.0009
[10:56:06.466] iteration:2445  t-loss:0.1150, loss-lb:0.1085, loss-ulb:0.0329, weight:0.20, lr:0.0009
[10:56:06.656] iteration:2446  t-loss:0.1049, loss-lb:0.0946, loss-ulb:0.0521, weight:0.20, lr:0.0009
[10:56:06.847] iteration:2447  t-loss:0.1008, loss-lb:0.0960, loss-ulb:0.0242, weight:0.20, lr:0.0009
[10:56:07.036] iteration:2448  t-loss:0.1089, loss-lb:0.1024, loss-ulb:0.0329, weight:0.20, lr:0.0009
[10:56:07.227] iteration:2449  t-loss:0.1117, loss-lb:0.1025, loss-ulb:0.0464, weight:0.20, lr:0.0009
[10:56:07.417] iteration:2450  t-loss:0.1218, loss-lb:0.1105, loss-ulb:0.0569, weight:0.20, lr:0.0009
[10:56:18.115]  <<Test>> - Ep:24  - mean_dice/mean_h95 - S:88.59/1.67, Best-S:88.59, T:89.32/1.40, Best-T:89.32
[10:56:18.115]           - AvgLoss(lb/ulb/all):0.1143/0.0414/0.1150
[10:56:18.634] iteration:2451  t-loss:0.1132, loss-lb:0.1068, loss-ulb:0.0322, weight:0.20, lr:0.0009
[10:56:18.831] iteration:2452  t-loss:0.1117, loss-lb:0.1057, loss-ulb:0.0306, weight:0.20, lr:0.0009
[10:56:19.024] iteration:2453  t-loss:0.1237, loss-lb:0.1169, loss-ulb:0.0345, weight:0.20, lr:0.0009
[10:56:19.217] iteration:2454  t-loss:0.1044, loss-lb:0.0958, loss-ulb:0.0435, weight:0.20, lr:0.0009
[10:56:19.409] iteration:2455  t-loss:0.1183, loss-lb:0.1037, loss-ulb:0.0736, weight:0.20, lr:0.0009
[10:56:19.601] iteration:2456  t-loss:0.1069, loss-lb:0.1013, loss-ulb:0.0282, weight:0.20, lr:0.0009
[10:56:19.793] iteration:2457  t-loss:0.1088, loss-lb:0.1005, loss-ulb:0.0420, weight:0.20, lr:0.0009
[10:56:19.985] iteration:2458  t-loss:0.1590, loss-lb:0.1186, loss-ulb:0.2038, weight:0.20, lr:0.0009
[10:56:20.176] iteration:2459  t-loss:0.0996, loss-lb:0.0939, loss-ulb:0.0286, weight:0.20, lr:0.0009
[10:56:20.368] iteration:2460  t-loss:0.1010, loss-lb:0.0944, loss-ulb:0.0330, weight:0.20, lr:0.0009
[10:56:20.560] iteration:2461  t-loss:0.1508, loss-lb:0.1403, loss-ulb:0.0532, weight:0.20, lr:0.0009
[10:56:20.752] iteration:2462  t-loss:0.1213, loss-lb:0.1035, loss-ulb:0.0898, weight:0.20, lr:0.0009
[10:56:20.943] iteration:2463  t-loss:0.1169, loss-lb:0.1089, loss-ulb:0.0400, weight:0.20, lr:0.0009
[10:56:21.134] iteration:2464  t-loss:0.0998, loss-lb:0.0937, loss-ulb:0.0309, weight:0.20, lr:0.0009
[10:56:21.325] iteration:2465  t-loss:0.1168, loss-lb:0.1017, loss-ulb:0.0764, weight:0.20, lr:0.0009
[10:56:21.517] iteration:2466  t-loss:0.1424, loss-lb:0.1365, loss-ulb:0.0298, weight:0.20, lr:0.0009
[10:56:21.711] iteration:2467  t-loss:0.1211, loss-lb:0.1067, loss-ulb:0.0723, weight:0.20, lr:0.0009
[10:56:21.902] iteration:2468  t-loss:0.1102, loss-lb:0.0993, loss-ulb:0.0550, weight:0.20, lr:0.0009
[10:56:22.094] iteration:2469  t-loss:0.1234, loss-lb:0.1169, loss-ulb:0.0328, weight:0.20, lr:0.0009
[10:56:22.289] iteration:2470  t-loss:0.1181, loss-lb:0.1105, loss-ulb:0.0381, weight:0.20, lr:0.0009
[10:56:22.482] iteration:2471  t-loss:0.1115, loss-lb:0.1060, loss-ulb:0.0273, weight:0.20, lr:0.0009
[10:56:22.674] iteration:2472  t-loss:0.1197, loss-lb:0.1151, loss-ulb:0.0228, weight:0.20, lr:0.0009
[10:56:22.866] iteration:2473  t-loss:0.1073, loss-lb:0.1012, loss-ulb:0.0309, weight:0.20, lr:0.0009
[10:56:23.059] iteration:2474  t-loss:0.1144, loss-lb:0.1018, loss-ulb:0.0636, weight:0.20, lr:0.0009
[10:56:23.250] iteration:2475  t-loss:0.1122, loss-lb:0.1051, loss-ulb:0.0356, weight:0.20, lr:0.0009
[10:56:23.442] iteration:2476  t-loss:0.1141, loss-lb:0.1087, loss-ulb:0.0273, weight:0.20, lr:0.0009
[10:56:23.635] iteration:2477  t-loss:0.1155, loss-lb:0.1077, loss-ulb:0.0395, weight:0.20, lr:0.0009
[10:56:23.828] iteration:2478  t-loss:0.1220, loss-lb:0.1157, loss-ulb:0.0321, weight:0.20, lr:0.0009
[10:56:24.020] iteration:2479  t-loss:0.1213, loss-lb:0.1035, loss-ulb:0.0897, weight:0.20, lr:0.0009
[10:56:24.212] iteration:2480  t-loss:0.1060, loss-lb:0.1007, loss-ulb:0.0268, weight:0.20, lr:0.0009
[10:56:24.404] iteration:2481  t-loss:0.1197, loss-lb:0.1102, loss-ulb:0.0479, weight:0.20, lr:0.0009
[10:56:24.595] iteration:2482  t-loss:0.1088, loss-lb:0.1047, loss-ulb:0.0207, weight:0.20, lr:0.0009
[10:56:24.788] iteration:2483  t-loss:0.1120, loss-lb:0.1050, loss-ulb:0.0353, weight:0.20, lr:0.0009
[10:56:24.980] iteration:2484  t-loss:0.0975, loss-lb:0.0903, loss-ulb:0.0363, weight:0.20, lr:0.0009
[10:56:25.172] iteration:2485  t-loss:0.1186, loss-lb:0.1139, loss-ulb:0.0237, weight:0.20, lr:0.0009
[10:56:25.365] iteration:2486  t-loss:0.1116, loss-lb:0.1061, loss-ulb:0.0277, weight:0.20, lr:0.0009
[10:56:25.555] iteration:2487  t-loss:0.1077, loss-lb:0.1008, loss-ulb:0.0350, weight:0.20, lr:0.0009
[10:56:25.747] iteration:2488  t-loss:0.1153, loss-lb:0.1094, loss-ulb:0.0296, weight:0.20, lr:0.0009
[10:56:25.939] iteration:2489  t-loss:0.1197, loss-lb:0.1091, loss-ulb:0.0535, weight:0.20, lr:0.0009
[10:56:26.130] iteration:2490  t-loss:0.1018, loss-lb:0.0959, loss-ulb:0.0297, weight:0.20, lr:0.0009
[10:56:26.322] iteration:2491  t-loss:0.1244, loss-lb:0.1142, loss-ulb:0.0515, weight:0.20, lr:0.0009
[10:56:26.513] iteration:2492  t-loss:0.1186, loss-lb:0.1049, loss-ulb:0.0692, weight:0.20, lr:0.0009
[10:56:26.707] iteration:2493  t-loss:0.1247, loss-lb:0.1103, loss-ulb:0.0727, weight:0.20, lr:0.0009
[10:56:26.901] iteration:2494  t-loss:0.1041, loss-lb:0.0982, loss-ulb:0.0298, weight:0.20, lr:0.0009
[10:56:27.096] iteration:2495  t-loss:0.1063, loss-lb:0.0941, loss-ulb:0.0616, weight:0.20, lr:0.0009
[10:56:27.290] iteration:2496  t-loss:0.1293, loss-lb:0.1040, loss-ulb:0.1277, weight:0.20, lr:0.0009
[10:56:27.483] iteration:2497  t-loss:0.1119, loss-lb:0.1064, loss-ulb:0.0277, weight:0.20, lr:0.0009
[10:56:27.675] iteration:2498  t-loss:0.1025, loss-lb:0.0954, loss-ulb:0.0359, weight:0.20, lr:0.0009
[10:56:27.867] iteration:2499  t-loss:0.1193, loss-lb:0.1096, loss-ulb:0.0489, weight:0.20, lr:0.0009
[10:56:28.059] iteration:2500  t-loss:0.1170, loss-lb:0.1091, loss-ulb:0.0395, weight:0.20, lr:0.0009
[10:56:28.251] iteration:2501  t-loss:0.1101, loss-lb:0.1019, loss-ulb:0.0412, weight:0.20, lr:0.0009
[10:56:28.443] iteration:2502  t-loss:0.0983, loss-lb:0.0933, loss-ulb:0.0253, weight:0.20, lr:0.0009
[10:56:28.633] iteration:2503  t-loss:0.1217, loss-lb:0.1076, loss-ulb:0.0710, weight:0.20, lr:0.0009
[10:56:28.830] iteration:2504  t-loss:0.1102, loss-lb:0.1018, loss-ulb:0.0421, weight:0.20, lr:0.0009
[10:56:29.033] iteration:2505  t-loss:0.1343, loss-lb:0.1190, loss-ulb:0.0769, weight:0.20, lr:0.0009
[10:56:29.231] iteration:2506  t-loss:0.1175, loss-lb:0.1093, loss-ulb:0.0418, weight:0.20, lr:0.0009
[10:56:29.423] iteration:2507  t-loss:0.1150, loss-lb:0.1070, loss-ulb:0.0406, weight:0.20, lr:0.0009
[10:56:29.616] iteration:2508  t-loss:0.1106, loss-lb:0.1027, loss-ulb:0.0399, weight:0.20, lr:0.0009
[10:56:29.808] iteration:2509  t-loss:0.1235, loss-lb:0.1133, loss-ulb:0.0515, weight:0.20, lr:0.0009
[10:56:30.000] iteration:2510  t-loss:0.1216, loss-lb:0.1086, loss-ulb:0.0659, weight:0.20, lr:0.0009
[10:56:30.193] iteration:2511  t-loss:0.1193, loss-lb:0.1023, loss-ulb:0.0857, weight:0.20, lr:0.0009
[10:56:30.385] iteration:2512  t-loss:0.1411, loss-lb:0.1340, loss-ulb:0.0358, weight:0.20, lr:0.0009
[10:56:30.577] iteration:2513  t-loss:0.1129, loss-lb:0.1064, loss-ulb:0.0327, weight:0.20, lr:0.0009
[10:56:30.770] iteration:2514  t-loss:0.1179, loss-lb:0.1106, loss-ulb:0.0367, weight:0.20, lr:0.0009
[10:56:30.962] iteration:2515  t-loss:0.1412, loss-lb:0.1272, loss-ulb:0.0707, weight:0.20, lr:0.0009
[10:56:31.154] iteration:2516  t-loss:0.1255, loss-lb:0.1156, loss-ulb:0.0500, weight:0.20, lr:0.0009
[10:56:31.346] iteration:2517  t-loss:0.1187, loss-lb:0.1068, loss-ulb:0.0599, weight:0.20, lr:0.0009
[10:56:31.539] iteration:2518  t-loss:0.1585, loss-lb:0.1368, loss-ulb:0.1096, weight:0.20, lr:0.0009
[10:56:31.730] iteration:2519  t-loss:0.1465, loss-lb:0.1390, loss-ulb:0.0379, weight:0.20, lr:0.0009
[10:56:31.922] iteration:2520  t-loss:0.1145, loss-lb:0.1077, loss-ulb:0.0342, weight:0.20, lr:0.0009
[10:56:32.113] iteration:2521  t-loss:0.1247, loss-lb:0.1148, loss-ulb:0.0503, weight:0.20, lr:0.0009
[10:56:32.304] iteration:2522  t-loss:0.1310, loss-lb:0.1228, loss-ulb:0.0415, weight:0.20, lr:0.0009
[10:56:32.495] iteration:2523  t-loss:0.1127, loss-lb:0.1024, loss-ulb:0.0523, weight:0.20, lr:0.0009
[10:56:32.687] iteration:2524  t-loss:0.1236, loss-lb:0.1178, loss-ulb:0.0294, weight:0.20, lr:0.0009
[10:56:32.878] iteration:2525  t-loss:0.1188, loss-lb:0.1128, loss-ulb:0.0307, weight:0.20, lr:0.0009
[10:56:33.069] iteration:2526  t-loss:0.1366, loss-lb:0.1255, loss-ulb:0.0561, weight:0.20, lr:0.0009
[10:56:33.260] iteration:2527  t-loss:0.1220, loss-lb:0.1118, loss-ulb:0.0515, weight:0.20, lr:0.0009
[10:56:33.451] iteration:2528  t-loss:0.1408, loss-lb:0.1346, loss-ulb:0.0311, weight:0.20, lr:0.0009
[10:56:33.645] iteration:2529  t-loss:0.1261, loss-lb:0.1140, loss-ulb:0.0610, weight:0.20, lr:0.0009
[10:56:33.841] iteration:2530  t-loss:0.1267, loss-lb:0.1184, loss-ulb:0.0420, weight:0.20, lr:0.0009
[10:56:34.034] iteration:2531  t-loss:0.1220, loss-lb:0.1165, loss-ulb:0.0279, weight:0.20, lr:0.0009
[10:56:34.227] iteration:2532  t-loss:0.1489, loss-lb:0.1259, loss-ulb:0.1159, weight:0.20, lr:0.0009
[10:56:34.420] iteration:2533  t-loss:0.1070, loss-lb:0.0991, loss-ulb:0.0399, weight:0.20, lr:0.0009
[10:56:34.613] iteration:2534  t-loss:0.1300, loss-lb:0.1212, loss-ulb:0.0444, weight:0.20, lr:0.0009
[10:56:34.804] iteration:2535  t-loss:0.1298, loss-lb:0.1219, loss-ulb:0.0399, weight:0.20, lr:0.0009
[10:56:34.998] iteration:2536  t-loss:0.1139, loss-lb:0.1000, loss-ulb:0.0697, weight:0.20, lr:0.0009
[10:56:35.191] iteration:2537  t-loss:0.1206, loss-lb:0.1121, loss-ulb:0.0428, weight:0.20, lr:0.0009
[10:56:35.383] iteration:2538  t-loss:0.1419, loss-lb:0.1308, loss-ulb:0.0557, weight:0.20, lr:0.0009
[10:56:35.575] iteration:2539  t-loss:0.1292, loss-lb:0.1198, loss-ulb:0.0476, weight:0.20, lr:0.0009
[10:56:35.767] iteration:2540  t-loss:0.1113, loss-lb:0.1030, loss-ulb:0.0420, weight:0.20, lr:0.0009
[10:56:35.959] iteration:2541  t-loss:0.1170, loss-lb:0.1111, loss-ulb:0.0298, weight:0.20, lr:0.0009
[10:56:36.150] iteration:2542  t-loss:0.1175, loss-lb:0.1083, loss-ulb:0.0463, weight:0.20, lr:0.0009
[10:56:36.343] iteration:2543  t-loss:0.1214, loss-lb:0.1128, loss-ulb:0.0434, weight:0.20, lr:0.0009
[10:56:36.534] iteration:2544  t-loss:0.1140, loss-lb:0.1067, loss-ulb:0.0369, weight:0.20, lr:0.0009
[10:56:36.728] iteration:2545  t-loss:0.1108, loss-lb:0.1019, loss-ulb:0.0452, weight:0.20, lr:0.0009
[10:56:36.928] iteration:2546  t-loss:0.1186, loss-lb:0.1094, loss-ulb:0.0466, weight:0.20, lr:0.0009
[10:56:37.118] iteration:2547  t-loss:0.1139, loss-lb:0.1042, loss-ulb:0.0491, weight:0.20, lr:0.0009
[10:56:37.318] iteration:2548  t-loss:0.1271, loss-lb:0.1025, loss-ulb:0.1241, weight:0.20, lr:0.0009
[10:56:37.902] iteration:2549  t-loss:0.1047, loss-lb:0.0985, loss-ulb:0.0313, weight:0.20, lr:0.0009
[10:56:38.094] iteration:2550  t-loss:0.1376, loss-lb:0.1293, loss-ulb:0.0420, weight:0.20, lr:0.0009
[10:56:38.288] iteration:2551  t-loss:0.1248, loss-lb:0.1155, loss-ulb:0.0412, weight:0.23, lr:0.0009
[10:56:38.489] iteration:2552  t-loss:0.1304, loss-lb:0.1150, loss-ulb:0.0680, weight:0.23, lr:0.0009
[10:56:38.681] iteration:2553  t-loss:0.1177, loss-lb:0.1117, loss-ulb:0.0265, weight:0.23, lr:0.0009
[10:56:38.872] iteration:2554  t-loss:0.1169, loss-lb:0.1088, loss-ulb:0.0355, weight:0.23, lr:0.0009
[10:56:39.063] iteration:2555  t-loss:0.1104, loss-lb:0.1038, loss-ulb:0.0291, weight:0.23, lr:0.0009
[10:56:39.254] iteration:2556  t-loss:0.1175, loss-lb:0.1107, loss-ulb:0.0300, weight:0.23, lr:0.0009
[10:56:39.444] iteration:2557  t-loss:0.1162, loss-lb:0.1064, loss-ulb:0.0431, weight:0.23, lr:0.0009
[10:56:39.636] iteration:2558  t-loss:0.1146, loss-lb:0.1005, loss-ulb:0.0621, weight:0.23, lr:0.0009
[10:56:39.826] iteration:2559  t-loss:0.1285, loss-lb:0.1090, loss-ulb:0.0863, weight:0.23, lr:0.0009
[10:56:40.018] iteration:2560  t-loss:0.1570, loss-lb:0.1416, loss-ulb:0.0682, weight:0.23, lr:0.0009
[10:56:40.209] iteration:2561  t-loss:0.1177, loss-lb:0.1085, loss-ulb:0.0409, weight:0.23, lr:0.0009
[10:56:40.402] iteration:2562  t-loss:0.1774, loss-lb:0.1685, loss-ulb:0.0393, weight:0.23, lr:0.0009
[10:56:40.598] iteration:2563  t-loss:0.1231, loss-lb:0.1102, loss-ulb:0.0569, weight:0.23, lr:0.0009
[10:56:40.793] iteration:2564  t-loss:0.1486, loss-lb:0.1311, loss-ulb:0.0773, weight:0.23, lr:0.0009
[10:56:40.988] iteration:2565  t-loss:0.1223, loss-lb:0.1125, loss-ulb:0.0430, weight:0.23, lr:0.0009
[10:56:41.180] iteration:2566  t-loss:0.1622, loss-lb:0.1445, loss-ulb:0.0782, weight:0.23, lr:0.0009
[10:56:41.373] iteration:2567  t-loss:0.1216, loss-lb:0.1124, loss-ulb:0.0407, weight:0.23, lr:0.0009
[10:56:41.565] iteration:2568  t-loss:0.1115, loss-lb:0.1012, loss-ulb:0.0451, weight:0.23, lr:0.0009
[10:56:41.758] iteration:2569  t-loss:0.1113, loss-lb:0.1024, loss-ulb:0.0394, weight:0.23, lr:0.0009
[10:56:41.949] iteration:2570  t-loss:0.1192, loss-lb:0.1117, loss-ulb:0.0331, weight:0.23, lr:0.0009
[10:56:42.141] iteration:2571  t-loss:0.1166, loss-lb:0.1069, loss-ulb:0.0429, weight:0.23, lr:0.0009
[10:56:42.334] iteration:2572  t-loss:0.1075, loss-lb:0.0989, loss-ulb:0.0375, weight:0.23, lr:0.0009
[10:56:42.526] iteration:2573  t-loss:0.1133, loss-lb:0.1065, loss-ulb:0.0303, weight:0.23, lr:0.0009
[10:56:42.719] iteration:2574  t-loss:0.1107, loss-lb:0.1038, loss-ulb:0.0304, weight:0.23, lr:0.0009
[10:56:42.911] iteration:2575  t-loss:0.1154, loss-lb:0.1064, loss-ulb:0.0398, weight:0.23, lr:0.0009
[10:56:43.103] iteration:2576  t-loss:0.1201, loss-lb:0.1097, loss-ulb:0.0458, weight:0.23, lr:0.0009
[10:56:43.296] iteration:2577  t-loss:0.1040, loss-lb:0.0968, loss-ulb:0.0318, weight:0.23, lr:0.0009
[10:56:43.488] iteration:2578  t-loss:0.1349, loss-lb:0.1046, loss-ulb:0.1337, weight:0.23, lr:0.0009
[10:56:43.681] iteration:2579  t-loss:0.1191, loss-lb:0.1119, loss-ulb:0.0318, weight:0.23, lr:0.0009
[10:56:43.873] iteration:2580  t-loss:0.1242, loss-lb:0.1133, loss-ulb:0.0484, weight:0.23, lr:0.0009
[10:56:44.064] iteration:2581  t-loss:0.1194, loss-lb:0.1064, loss-ulb:0.0572, weight:0.23, lr:0.0009
[10:56:44.256] iteration:2582  t-loss:0.1160, loss-lb:0.1086, loss-ulb:0.0326, weight:0.23, lr:0.0009
[10:56:44.449] iteration:2583  t-loss:0.0994, loss-lb:0.0912, loss-ulb:0.0364, weight:0.23, lr:0.0009
[10:56:44.641] iteration:2584  t-loss:0.1027, loss-lb:0.0975, loss-ulb:0.0227, weight:0.23, lr:0.0009
[10:56:44.834] iteration:2585  t-loss:0.1157, loss-lb:0.1038, loss-ulb:0.0523, weight:0.23, lr:0.0009
[10:56:45.026] iteration:2586  t-loss:0.1218, loss-lb:0.1111, loss-ulb:0.0472, weight:0.23, lr:0.0009
[10:56:45.218] iteration:2587  t-loss:0.1090, loss-lb:0.0977, loss-ulb:0.0502, weight:0.23, lr:0.0009
[10:56:45.408] iteration:2588  t-loss:0.1092, loss-lb:0.0999, loss-ulb:0.0410, weight:0.23, lr:0.0009
[10:56:45.599] iteration:2589  t-loss:0.1106, loss-lb:0.1022, loss-ulb:0.0372, weight:0.23, lr:0.0009
[10:56:45.792] iteration:2590  t-loss:0.1095, loss-lb:0.1018, loss-ulb:0.0341, weight:0.23, lr:0.0009
[10:56:45.982] iteration:2591  t-loss:0.1420, loss-lb:0.1219, loss-ulb:0.0887, weight:0.23, lr:0.0009
[10:56:46.174] iteration:2592  t-loss:0.1041, loss-lb:0.0983, loss-ulb:0.0257, weight:0.23, lr:0.0009
[10:56:46.365] iteration:2593  t-loss:0.1170, loss-lb:0.1048, loss-ulb:0.0537, weight:0.23, lr:0.0009
[10:56:46.556] iteration:2594  t-loss:0.1233, loss-lb:0.0945, loss-ulb:0.1271, weight:0.23, lr:0.0009
[10:56:46.746] iteration:2595  t-loss:0.1088, loss-lb:0.0987, loss-ulb:0.0444, weight:0.23, lr:0.0009
[10:56:46.938] iteration:2596  t-loss:0.1099, loss-lb:0.0982, loss-ulb:0.0516, weight:0.23, lr:0.0009
[10:56:47.132] iteration:2597  t-loss:0.1450, loss-lb:0.1005, loss-ulb:0.1963, weight:0.23, lr:0.0009
[10:56:47.325] iteration:2598  t-loss:0.1082, loss-lb:0.1020, loss-ulb:0.0274, weight:0.23, lr:0.0009
[10:56:47.522] iteration:2599  t-loss:0.1172, loss-lb:0.1059, loss-ulb:0.0499, weight:0.23, lr:0.0009
[10:56:47.717] iteration:2600  t-loss:0.1184, loss-lb:0.1045, loss-ulb:0.0615, weight:0.23, lr:0.0009
[10:56:47.910] iteration:2601  t-loss:0.1110, loss-lb:0.1024, loss-ulb:0.0382, weight:0.23, lr:0.0009
[10:56:48.104] iteration:2602  t-loss:0.1255, loss-lb:0.1130, loss-ulb:0.0553, weight:0.23, lr:0.0009
[10:56:48.298] iteration:2603  t-loss:0.0970, loss-lb:0.0888, loss-ulb:0.0358, weight:0.23, lr:0.0009
[10:56:48.491] iteration:2604  t-loss:0.1168, loss-lb:0.1054, loss-ulb:0.0503, weight:0.23, lr:0.0009
[10:56:48.684] iteration:2605  t-loss:0.1106, loss-lb:0.1010, loss-ulb:0.0422, weight:0.23, lr:0.0009
[10:56:48.876] iteration:2606  t-loss:0.1059, loss-lb:0.0983, loss-ulb:0.0337, weight:0.23, lr:0.0009
[10:56:49.069] iteration:2607  t-loss:0.1207, loss-lb:0.1117, loss-ulb:0.0397, weight:0.23, lr:0.0009
[10:56:49.261] iteration:2608  t-loss:0.1086, loss-lb:0.0972, loss-ulb:0.0505, weight:0.23, lr:0.0009
[10:56:49.454] iteration:2609  t-loss:0.1209, loss-lb:0.1132, loss-ulb:0.0338, weight:0.23, lr:0.0009
[10:56:49.647] iteration:2610  t-loss:0.1106, loss-lb:0.0996, loss-ulb:0.0487, weight:0.23, lr:0.0009
[10:56:49.839] iteration:2611  t-loss:0.1067, loss-lb:0.1004, loss-ulb:0.0279, weight:0.23, lr:0.0009
[10:56:50.032] iteration:2612  t-loss:0.1101, loss-lb:0.1004, loss-ulb:0.0428, weight:0.23, lr:0.0009
[10:56:50.226] iteration:2613  t-loss:0.1079, loss-lb:0.1024, loss-ulb:0.0240, weight:0.23, lr:0.0009
[10:56:50.418] iteration:2614  t-loss:0.1097, loss-lb:0.1031, loss-ulb:0.0294, weight:0.23, lr:0.0009
[10:56:50.610] iteration:2615  t-loss:0.1155, loss-lb:0.1096, loss-ulb:0.0261, weight:0.23, lr:0.0009
[10:56:50.802] iteration:2616  t-loss:0.1181, loss-lb:0.1106, loss-ulb:0.0332, weight:0.23, lr:0.0009
[10:56:50.993] iteration:2617  t-loss:0.1170, loss-lb:0.1117, loss-ulb:0.0235, weight:0.23, lr:0.0009
[10:56:51.186] iteration:2618  t-loss:0.1065, loss-lb:0.0939, loss-ulb:0.0559, weight:0.23, lr:0.0009
[10:56:51.378] iteration:2619  t-loss:0.1217, loss-lb:0.1060, loss-ulb:0.0696, weight:0.23, lr:0.0009
[10:56:51.570] iteration:2620  t-loss:0.1115, loss-lb:0.1056, loss-ulb:0.0259, weight:0.23, lr:0.0009
[10:56:51.762] iteration:2621  t-loss:0.1039, loss-lb:0.0980, loss-ulb:0.0260, weight:0.23, lr:0.0009
[10:56:51.955] iteration:2622  t-loss:0.1083, loss-lb:0.1001, loss-ulb:0.0361, weight:0.23, lr:0.0009
[10:56:52.148] iteration:2623  t-loss:0.1145, loss-lb:0.1092, loss-ulb:0.0234, weight:0.23, lr:0.0009
[10:56:52.341] iteration:2624  t-loss:0.1123, loss-lb:0.1037, loss-ulb:0.0380, weight:0.23, lr:0.0009
[10:56:52.533] iteration:2625  t-loss:0.1099, loss-lb:0.1015, loss-ulb:0.0368, weight:0.23, lr:0.0009
[10:56:52.725] iteration:2626  t-loss:0.1191, loss-lb:0.1114, loss-ulb:0.0338, weight:0.23, lr:0.0009
[10:56:52.916] iteration:2627  t-loss:0.1049, loss-lb:0.0981, loss-ulb:0.0300, weight:0.23, lr:0.0009
[10:56:53.109] iteration:2628  t-loss:0.1049, loss-lb:0.0993, loss-ulb:0.0248, weight:0.23, lr:0.0009
[10:56:53.301] iteration:2629  t-loss:0.1131, loss-lb:0.1000, loss-ulb:0.0580, weight:0.23, lr:0.0009
[10:56:53.493] iteration:2630  t-loss:0.1117, loss-lb:0.1007, loss-ulb:0.0486, weight:0.23, lr:0.0009
[10:56:53.685] iteration:2631  t-loss:0.1209, loss-lb:0.1052, loss-ulb:0.0693, weight:0.23, lr:0.0009
[10:56:53.876] iteration:2632  t-loss:0.1122, loss-lb:0.1032, loss-ulb:0.0397, weight:0.23, lr:0.0009
[10:56:54.068] iteration:2633  t-loss:0.0981, loss-lb:0.0926, loss-ulb:0.0245, weight:0.23, lr:0.0009
[10:56:54.260] iteration:2634  t-loss:0.1052, loss-lb:0.0979, loss-ulb:0.0323, weight:0.23, lr:0.0009
[10:56:54.452] iteration:2635  t-loss:0.1475, loss-lb:0.1414, loss-ulb:0.0270, weight:0.23, lr:0.0009
[10:56:54.644] iteration:2636  t-loss:0.1022, loss-lb:0.0947, loss-ulb:0.0331, weight:0.23, lr:0.0009
[10:56:54.837] iteration:2637  t-loss:0.1238, loss-lb:0.1161, loss-ulb:0.0341, weight:0.23, lr:0.0009
[10:56:55.029] iteration:2638  t-loss:0.1168, loss-lb:0.1094, loss-ulb:0.0325, weight:0.23, lr:0.0009
[10:56:55.221] iteration:2639  t-loss:0.1289, loss-lb:0.1208, loss-ulb:0.0356, weight:0.23, lr:0.0009
[10:56:55.412] iteration:2640  t-loss:0.1080, loss-lb:0.1002, loss-ulb:0.0348, weight:0.23, lr:0.0009
[10:56:55.603] iteration:2641  t-loss:0.1169, loss-lb:0.1033, loss-ulb:0.0601, weight:0.23, lr:0.0009
[10:56:55.793] iteration:2642  t-loss:0.1124, loss-lb:0.1073, loss-ulb:0.0227, weight:0.23, lr:0.0009
[10:56:55.984] iteration:2643  t-loss:0.1120, loss-lb:0.1044, loss-ulb:0.0335, weight:0.23, lr:0.0009
[10:56:56.174] iteration:2644  t-loss:0.1149, loss-lb:0.1014, loss-ulb:0.0594, weight:0.23, lr:0.0009
[10:56:56.364] iteration:2645  t-loss:0.1333, loss-lb:0.1264, loss-ulb:0.0304, weight:0.23, lr:0.0009
[10:56:56.555] iteration:2646  t-loss:0.1262, loss-lb:0.1180, loss-ulb:0.0362, weight:0.23, lr:0.0009
[10:57:08.549]  <<Test>> - Ep:26  - mean_dice/mean_h95 - S:88.81/2.22, Best-S:88.81, T:89.52/1.79, Best-T:89.52
[10:57:08.550]           - AvgLoss(lb/ulb/all):0.1072/0.0383/0.1157
[10:57:09.063] iteration:2647  t-loss:0.1269, loss-lb:0.1205, loss-ulb:0.0285, weight:0.23, lr:0.0009
[10:57:09.261] iteration:2648  t-loss:0.1203, loss-lb:0.1014, loss-ulb:0.0836, weight:0.23, lr:0.0009
[10:57:09.453] iteration:2649  t-loss:0.1109, loss-lb:0.1042, loss-ulb:0.0295, weight:0.23, lr:0.0009
[10:57:09.647] iteration:2650  t-loss:0.1242, loss-lb:0.1158, loss-ulb:0.0373, weight:0.23, lr:0.0009
[10:57:09.840] iteration:2651  t-loss:0.1393, loss-lb:0.1296, loss-ulb:0.0426, weight:0.23, lr:0.0009
[10:57:10.032] iteration:2652  t-loss:0.1214, loss-lb:0.1154, loss-ulb:0.0264, weight:0.23, lr:0.0009
[10:57:10.225] iteration:2653  t-loss:0.1202, loss-lb:0.1093, loss-ulb:0.0480, weight:0.23, lr:0.0009
[10:57:10.417] iteration:2654  t-loss:0.1145, loss-lb:0.1046, loss-ulb:0.0436, weight:0.23, lr:0.0009
[10:57:10.608] iteration:2655  t-loss:0.1198, loss-lb:0.1060, loss-ulb:0.0611, weight:0.23, lr:0.0009
[10:57:10.800] iteration:2656  t-loss:0.1064, loss-lb:0.0971, loss-ulb:0.0409, weight:0.23, lr:0.0009
[10:57:10.991] iteration:2657  t-loss:0.1134, loss-lb:0.1032, loss-ulb:0.0451, weight:0.23, lr:0.0009
[10:57:11.183] iteration:2658  t-loss:0.1198, loss-lb:0.1106, loss-ulb:0.0406, weight:0.23, lr:0.0009
[10:57:11.375] iteration:2659  t-loss:0.1125, loss-lb:0.1025, loss-ulb:0.0444, weight:0.23, lr:0.0009
[10:57:11.566] iteration:2660  t-loss:0.1205, loss-lb:0.1125, loss-ulb:0.0355, weight:0.23, lr:0.0009
[10:57:11.757] iteration:2661  t-loss:0.1401, loss-lb:0.1161, loss-ulb:0.1061, weight:0.23, lr:0.0009
[10:57:11.950] iteration:2662  t-loss:0.1250, loss-lb:0.1001, loss-ulb:0.1099, weight:0.23, lr:0.0009
[10:57:12.141] iteration:2663  t-loss:0.1004, loss-lb:0.0943, loss-ulb:0.0268, weight:0.23, lr:0.0009
[10:57:12.334] iteration:2664  t-loss:0.1253, loss-lb:0.1160, loss-ulb:0.0408, weight:0.23, lr:0.0009
[10:57:12.526] iteration:2665  t-loss:0.1228, loss-lb:0.1074, loss-ulb:0.0682, weight:0.23, lr:0.0009
[10:57:12.718] iteration:2666  t-loss:0.1191, loss-lb:0.1059, loss-ulb:0.0583, weight:0.23, lr:0.0009
[10:57:12.909] iteration:2667  t-loss:0.1487, loss-lb:0.1179, loss-ulb:0.1360, weight:0.23, lr:0.0009
[10:57:13.102] iteration:2668  t-loss:0.1689, loss-lb:0.1411, loss-ulb:0.1228, weight:0.23, lr:0.0009
[10:57:13.295] iteration:2669  t-loss:0.1146, loss-lb:0.1053, loss-ulb:0.0412, weight:0.23, lr:0.0009
[10:57:13.487] iteration:2670  t-loss:0.1055, loss-lb:0.0967, loss-ulb:0.0388, weight:0.23, lr:0.0009
[10:57:13.679] iteration:2671  t-loss:0.1127, loss-lb:0.1054, loss-ulb:0.0322, weight:0.23, lr:0.0009
[10:57:13.870] iteration:2672  t-loss:0.1220, loss-lb:0.1141, loss-ulb:0.0348, weight:0.23, lr:0.0009
[10:57:14.061] iteration:2673  t-loss:0.1032, loss-lb:0.0981, loss-ulb:0.0227, weight:0.23, lr:0.0009
[10:57:14.253] iteration:2674  t-loss:0.1112, loss-lb:0.1033, loss-ulb:0.0349, weight:0.23, lr:0.0009
[10:57:14.445] iteration:2675  t-loss:0.1106, loss-lb:0.1009, loss-ulb:0.0428, weight:0.23, lr:0.0009
[10:57:14.636] iteration:2676  t-loss:0.1109, loss-lb:0.1035, loss-ulb:0.0326, weight:0.23, lr:0.0009
[10:57:14.829] iteration:2677  t-loss:0.1214, loss-lb:0.1009, loss-ulb:0.0904, weight:0.23, lr:0.0009
[10:57:15.020] iteration:2678  t-loss:0.1272, loss-lb:0.1198, loss-ulb:0.0326, weight:0.23, lr:0.0009
[10:57:15.212] iteration:2679  t-loss:0.1225, loss-lb:0.1139, loss-ulb:0.0379, weight:0.23, lr:0.0009
[10:57:15.405] iteration:2680  t-loss:0.1086, loss-lb:0.1032, loss-ulb:0.0239, weight:0.23, lr:0.0009
[10:57:15.597] iteration:2681  t-loss:0.1121, loss-lb:0.1048, loss-ulb:0.0322, weight:0.23, lr:0.0009
[10:57:15.789] iteration:2682  t-loss:0.0991, loss-lb:0.0916, loss-ulb:0.0333, weight:0.23, lr:0.0009
[10:57:15.980] iteration:2683  t-loss:0.1130, loss-lb:0.1012, loss-ulb:0.0522, weight:0.23, lr:0.0009
[10:57:16.172] iteration:2684  t-loss:0.1106, loss-lb:0.1019, loss-ulb:0.0384, weight:0.23, lr:0.0009
[10:57:16.365] iteration:2685  t-loss:0.1199, loss-lb:0.1124, loss-ulb:0.0331, weight:0.23, lr:0.0009
[10:57:16.556] iteration:2686  t-loss:0.1112, loss-lb:0.1018, loss-ulb:0.0416, weight:0.23, lr:0.0009
[10:57:16.747] iteration:2687  t-loss:0.1207, loss-lb:0.1089, loss-ulb:0.0519, weight:0.23, lr:0.0009
[10:57:16.939] iteration:2688  t-loss:0.1139, loss-lb:0.1068, loss-ulb:0.0315, weight:0.23, lr:0.0009
[10:57:17.132] iteration:2689  t-loss:0.1163, loss-lb:0.1035, loss-ulb:0.0562, weight:0.23, lr:0.0009
[10:57:17.324] iteration:2690  t-loss:0.1140, loss-lb:0.1038, loss-ulb:0.0451, weight:0.23, lr:0.0009
[10:57:17.517] iteration:2691  t-loss:0.1119, loss-lb:0.1049, loss-ulb:0.0310, weight:0.23, lr:0.0009
[10:57:17.709] iteration:2692  t-loss:0.1209, loss-lb:0.1091, loss-ulb:0.0520, weight:0.23, lr:0.0009
[10:57:17.903] iteration:2693  t-loss:0.1146, loss-lb:0.1004, loss-ulb:0.0624, weight:0.23, lr:0.0009
[10:57:18.094] iteration:2694  t-loss:0.1207, loss-lb:0.1004, loss-ulb:0.0898, weight:0.23, lr:0.0009
[10:57:18.286] iteration:2695  t-loss:0.1032, loss-lb:0.0949, loss-ulb:0.0369, weight:0.23, lr:0.0009
[10:57:18.478] iteration:2696  t-loss:0.1007, loss-lb:0.0935, loss-ulb:0.0317, weight:0.23, lr:0.0009
[10:57:18.670] iteration:2697  t-loss:0.1095, loss-lb:0.0980, loss-ulb:0.0506, weight:0.23, lr:0.0009
[10:57:18.863] iteration:2698  t-loss:0.1245, loss-lb:0.1146, loss-ulb:0.0438, weight:0.23, lr:0.0009
[10:57:19.056] iteration:2699  t-loss:0.1176, loss-lb:0.1025, loss-ulb:0.0670, weight:0.23, lr:0.0009
[10:57:19.247] iteration:2700  t-loss:0.1128, loss-lb:0.1037, loss-ulb:0.0401, weight:0.23, lr:0.0009
[10:57:19.440] iteration:2701  t-loss:0.1087, loss-lb:0.0983, loss-ulb:0.0401, weight:0.26, lr:0.0009
[10:57:19.633] iteration:2702  t-loss:0.1150, loss-lb:0.1022, loss-ulb:0.0496, weight:0.26, lr:0.0009
[10:57:19.830] iteration:2703  t-loss:0.1102, loss-lb:0.1022, loss-ulb:0.0310, weight:0.26, lr:0.0009
[10:57:20.022] iteration:2704  t-loss:0.1058, loss-lb:0.0953, loss-ulb:0.0408, weight:0.26, lr:0.0009
[10:57:20.213] iteration:2705  t-loss:0.1110, loss-lb:0.1014, loss-ulb:0.0374, weight:0.26, lr:0.0009
[10:57:20.406] iteration:2706  t-loss:0.1200, loss-lb:0.1096, loss-ulb:0.0404, weight:0.26, lr:0.0009
[10:57:20.599] iteration:2707  t-loss:0.1036, loss-lb:0.0938, loss-ulb:0.0379, weight:0.26, lr:0.0009
[10:57:20.791] iteration:2708  t-loss:0.1131, loss-lb:0.0961, loss-ulb:0.0659, weight:0.26, lr:0.0009
[10:57:20.984] iteration:2709  t-loss:0.1132, loss-lb:0.0999, loss-ulb:0.0517, weight:0.26, lr:0.0009
[10:57:21.175] iteration:2710  t-loss:0.1166, loss-lb:0.0997, loss-ulb:0.0655, weight:0.26, lr:0.0009
[10:57:21.366] iteration:2711  t-loss:0.1106, loss-lb:0.1044, loss-ulb:0.0241, weight:0.26, lr:0.0009
[10:57:21.559] iteration:2712  t-loss:0.1104, loss-lb:0.0972, loss-ulb:0.0511, weight:0.26, lr:0.0009
[10:57:21.750] iteration:2713  t-loss:0.1078, loss-lb:0.1021, loss-ulb:0.0221, weight:0.26, lr:0.0009
[10:57:21.941] iteration:2714  t-loss:0.1179, loss-lb:0.1091, loss-ulb:0.0339, weight:0.26, lr:0.0009
[10:57:22.133] iteration:2715  t-loss:0.1179, loss-lb:0.1046, loss-ulb:0.0517, weight:0.26, lr:0.0009
[10:57:22.326] iteration:2716  t-loss:0.1122, loss-lb:0.0992, loss-ulb:0.0506, weight:0.26, lr:0.0009
[10:57:22.518] iteration:2717  t-loss:0.0996, loss-lb:0.0923, loss-ulb:0.0284, weight:0.26, lr:0.0009
[10:57:22.710] iteration:2718  t-loss:0.1079, loss-lb:0.1011, loss-ulb:0.0265, weight:0.26, lr:0.0009
[10:57:22.902] iteration:2719  t-loss:0.1105, loss-lb:0.1042, loss-ulb:0.0247, weight:0.26, lr:0.0009
[10:57:23.094] iteration:2720  t-loss:0.1162, loss-lb:0.1075, loss-ulb:0.0338, weight:0.26, lr:0.0009
[10:57:23.286] iteration:2721  t-loss:0.1024, loss-lb:0.0941, loss-ulb:0.0321, weight:0.26, lr:0.0009
[10:57:23.478] iteration:2722  t-loss:0.1150, loss-lb:0.1057, loss-ulb:0.0358, weight:0.26, lr:0.0009
[10:57:23.670] iteration:2723  t-loss:0.1118, loss-lb:0.1042, loss-ulb:0.0292, weight:0.26, lr:0.0009
[10:57:23.862] iteration:2724  t-loss:0.1235, loss-lb:0.1105, loss-ulb:0.0503, weight:0.26, lr:0.0009
[10:57:24.055] iteration:2725  t-loss:0.1150, loss-lb:0.1048, loss-ulb:0.0394, weight:0.26, lr:0.0009
[10:57:24.247] iteration:2726  t-loss:0.1123, loss-lb:0.1050, loss-ulb:0.0280, weight:0.26, lr:0.0009
[10:57:24.439] iteration:2727  t-loss:0.1103, loss-lb:0.1030, loss-ulb:0.0285, weight:0.26, lr:0.0009
[10:57:24.632] iteration:2728  t-loss:0.1148, loss-lb:0.1018, loss-ulb:0.0505, weight:0.26, lr:0.0009
[10:57:24.825] iteration:2729  t-loss:0.1068, loss-lb:0.0951, loss-ulb:0.0456, weight:0.26, lr:0.0009
[10:57:25.016] iteration:2730  t-loss:0.1009, loss-lb:0.0939, loss-ulb:0.0270, weight:0.26, lr:0.0009
[10:57:25.209] iteration:2731  t-loss:0.1116, loss-lb:0.1001, loss-ulb:0.0446, weight:0.26, lr:0.0009
[10:57:25.401] iteration:2732  t-loss:0.1104, loss-lb:0.1028, loss-ulb:0.0294, weight:0.26, lr:0.0009
[10:57:25.593] iteration:2733  t-loss:0.1182, loss-lb:0.1069, loss-ulb:0.0438, weight:0.26, lr:0.0009
[10:57:25.785] iteration:2734  t-loss:0.0973, loss-lb:0.0905, loss-ulb:0.0261, weight:0.26, lr:0.0009
[10:57:25.978] iteration:2735  t-loss:0.1157, loss-lb:0.1087, loss-ulb:0.0268, weight:0.26, lr:0.0009
[10:57:26.169] iteration:2736  t-loss:0.1161, loss-lb:0.1056, loss-ulb:0.0406, weight:0.26, lr:0.0009
[10:57:26.361] iteration:2737  t-loss:0.1086, loss-lb:0.0987, loss-ulb:0.0382, weight:0.26, lr:0.0009
[10:57:26.550] iteration:2738  t-loss:0.1035, loss-lb:0.0945, loss-ulb:0.0350, weight:0.26, lr:0.0009
[10:57:26.740] iteration:2739  t-loss:0.1119, loss-lb:0.1027, loss-ulb:0.0357, weight:0.26, lr:0.0009
[10:57:26.930] iteration:2740  t-loss:0.1110, loss-lb:0.1045, loss-ulb:0.0250, weight:0.26, lr:0.0009
[10:57:27.121] iteration:2741  t-loss:0.1130, loss-lb:0.1005, loss-ulb:0.0484, weight:0.26, lr:0.0009
[10:57:27.311] iteration:2742  t-loss:0.1226, loss-lb:0.1117, loss-ulb:0.0423, weight:0.26, lr:0.0009
[10:57:27.501] iteration:2743  t-loss:0.1061, loss-lb:0.0981, loss-ulb:0.0308, weight:0.26, lr:0.0009
[10:57:27.691] iteration:2744  t-loss:0.1120, loss-lb:0.1024, loss-ulb:0.0370, weight:0.26, lr:0.0009
[10:57:28.262] iteration:2745  t-loss:0.1061, loss-lb:0.1003, loss-ulb:0.0228, weight:0.26, lr:0.0009
[10:57:28.456] iteration:2746  t-loss:0.0985, loss-lb:0.0910, loss-ulb:0.0291, weight:0.26, lr:0.0009
[10:57:28.649] iteration:2747  t-loss:0.1018, loss-lb:0.0928, loss-ulb:0.0351, weight:0.26, lr:0.0009
[10:57:28.841] iteration:2748  t-loss:0.1299, loss-lb:0.1194, loss-ulb:0.0407, weight:0.26, lr:0.0009
[10:57:29.033] iteration:2749  t-loss:0.1288, loss-lb:0.1217, loss-ulb:0.0276, weight:0.26, lr:0.0009
[10:57:29.225] iteration:2750  t-loss:0.1015, loss-lb:0.0939, loss-ulb:0.0292, weight:0.26, lr:0.0009
[10:57:29.417] iteration:2751  t-loss:0.1063, loss-lb:0.0992, loss-ulb:0.0275, weight:0.26, lr:0.0009
[10:57:29.608] iteration:2752  t-loss:0.1085, loss-lb:0.1013, loss-ulb:0.0278, weight:0.26, lr:0.0009
[10:57:29.800] iteration:2753  t-loss:0.1088, loss-lb:0.1008, loss-ulb:0.0313, weight:0.26, lr:0.0009
[10:57:29.992] iteration:2754  t-loss:0.1152, loss-lb:0.1026, loss-ulb:0.0489, weight:0.26, lr:0.0009
[10:57:30.183] iteration:2755  t-loss:0.1013, loss-lb:0.0929, loss-ulb:0.0327, weight:0.26, lr:0.0009
[10:57:30.375] iteration:2756  t-loss:0.1034, loss-lb:0.0965, loss-ulb:0.0269, weight:0.26, lr:0.0009
[10:57:30.568] iteration:2757  t-loss:0.1179, loss-lb:0.1037, loss-ulb:0.0550, weight:0.26, lr:0.0009
[10:57:30.759] iteration:2758  t-loss:0.1061, loss-lb:0.0978, loss-ulb:0.0319, weight:0.26, lr:0.0009
[10:57:30.951] iteration:2759  t-loss:0.1044, loss-lb:0.0974, loss-ulb:0.0272, weight:0.26, lr:0.0009
[10:57:31.144] iteration:2760  t-loss:0.1142, loss-lb:0.0990, loss-ulb:0.0589, weight:0.26, lr:0.0009
[10:57:31.336] iteration:2761  t-loss:0.1087, loss-lb:0.0997, loss-ulb:0.0347, weight:0.26, lr:0.0009
[10:57:31.528] iteration:2762  t-loss:0.1226, loss-lb:0.1085, loss-ulb:0.0543, weight:0.26, lr:0.0009
[10:57:31.722] iteration:2763  t-loss:0.1312, loss-lb:0.0973, loss-ulb:0.1316, weight:0.26, lr:0.0009
[10:57:31.913] iteration:2764  t-loss:0.1156, loss-lb:0.0964, loss-ulb:0.0747, weight:0.26, lr:0.0009
[10:57:32.104] iteration:2765  t-loss:0.1127, loss-lb:0.1042, loss-ulb:0.0328, weight:0.26, lr:0.0009
[10:57:32.296] iteration:2766  t-loss:0.1037, loss-lb:0.0946, loss-ulb:0.0355, weight:0.26, lr:0.0009
[10:57:32.488] iteration:2767  t-loss:0.1112, loss-lb:0.1025, loss-ulb:0.0338, weight:0.26, lr:0.0009
[10:57:32.680] iteration:2768  t-loss:0.1062, loss-lb:0.0990, loss-ulb:0.0281, weight:0.26, lr:0.0009
[10:57:32.873] iteration:2769  t-loss:0.1122, loss-lb:0.0904, loss-ulb:0.0844, weight:0.26, lr:0.0009
[10:57:33.065] iteration:2770  t-loss:0.1208, loss-lb:0.1057, loss-ulb:0.0585, weight:0.26, lr:0.0009
[10:57:33.257] iteration:2771  t-loss:0.0974, loss-lb:0.0899, loss-ulb:0.0292, weight:0.26, lr:0.0009
[10:57:33.449] iteration:2772  t-loss:0.1137, loss-lb:0.0930, loss-ulb:0.0802, weight:0.26, lr:0.0009
[10:57:33.642] iteration:2773  t-loss:0.1140, loss-lb:0.1056, loss-ulb:0.0329, weight:0.26, lr:0.0009
[10:57:33.834] iteration:2774  t-loss:0.1093, loss-lb:0.1032, loss-ulb:0.0236, weight:0.26, lr:0.0009
[10:57:34.026] iteration:2775  t-loss:0.1086, loss-lb:0.1021, loss-ulb:0.0253, weight:0.26, lr:0.0009
[10:57:34.218] iteration:2776  t-loss:0.1285, loss-lb:0.1055, loss-ulb:0.0893, weight:0.26, lr:0.0009
[10:57:34.423] iteration:2777  t-loss:0.1054, loss-lb:0.0960, loss-ulb:0.0366, weight:0.26, lr:0.0009
[10:57:34.622] iteration:2778  t-loss:0.1068, loss-lb:0.1009, loss-ulb:0.0230, weight:0.26, lr:0.0009
[10:57:34.819] iteration:2779  t-loss:0.1116, loss-lb:0.1046, loss-ulb:0.0271, weight:0.26, lr:0.0009
[10:57:35.010] iteration:2780  t-loss:0.0999, loss-lb:0.0921, loss-ulb:0.0301, weight:0.26, lr:0.0009
[10:57:35.203] iteration:2781  t-loss:0.1069, loss-lb:0.0988, loss-ulb:0.0312, weight:0.26, lr:0.0009
[10:57:35.395] iteration:2782  t-loss:0.1049, loss-lb:0.0984, loss-ulb:0.0249, weight:0.26, lr:0.0009
[10:57:35.587] iteration:2783  t-loss:0.1114, loss-lb:0.1033, loss-ulb:0.0314, weight:0.26, lr:0.0009
[10:57:35.779] iteration:2784  t-loss:0.1159, loss-lb:0.0971, loss-ulb:0.0729, weight:0.26, lr:0.0009
[10:57:35.970] iteration:2785  t-loss:0.1131, loss-lb:0.1058, loss-ulb:0.0283, weight:0.26, lr:0.0009
[10:57:36.162] iteration:2786  t-loss:0.1151, loss-lb:0.1068, loss-ulb:0.0322, weight:0.26, lr:0.0009
[10:57:36.355] iteration:2787  t-loss:0.1126, loss-lb:0.1013, loss-ulb:0.0439, weight:0.26, lr:0.0009
[10:57:36.546] iteration:2788  t-loss:0.1111, loss-lb:0.1046, loss-ulb:0.0253, weight:0.26, lr:0.0009
[10:57:36.740] iteration:2789  t-loss:0.1170, loss-lb:0.1061, loss-ulb:0.0424, weight:0.26, lr:0.0009
[10:57:36.931] iteration:2790  t-loss:0.1033, loss-lb:0.0965, loss-ulb:0.0265, weight:0.26, lr:0.0009
[10:57:37.123] iteration:2791  t-loss:0.1027, loss-lb:0.0951, loss-ulb:0.0292, weight:0.26, lr:0.0009
[10:57:37.315] iteration:2792  t-loss:0.1016, loss-lb:0.0875, loss-ulb:0.0548, weight:0.26, lr:0.0009
[10:57:37.508] iteration:2793  t-loss:0.1190, loss-lb:0.1078, loss-ulb:0.0434, weight:0.26, lr:0.0009
[10:57:37.699] iteration:2794  t-loss:0.1155, loss-lb:0.1028, loss-ulb:0.0493, weight:0.26, lr:0.0009
[10:57:37.890] iteration:2795  t-loss:0.0969, loss-lb:0.0891, loss-ulb:0.0303, weight:0.26, lr:0.0009
[10:57:38.083] iteration:2796  t-loss:0.1096, loss-lb:0.0994, loss-ulb:0.0396, weight:0.26, lr:0.0009
[10:57:38.275] iteration:2797  t-loss:0.1154, loss-lb:0.1059, loss-ulb:0.0370, weight:0.26, lr:0.0009
[10:57:38.467] iteration:2798  t-loss:0.1101, loss-lb:0.1002, loss-ulb:0.0382, weight:0.26, lr:0.0009
[10:57:38.659] iteration:2799  t-loss:0.1393, loss-lb:0.0987, loss-ulb:0.1575, weight:0.26, lr:0.0009
[10:57:38.851] iteration:2800  t-loss:0.1132, loss-lb:0.1067, loss-ulb:0.0254, weight:0.26, lr:0.0009
[10:57:39.043] iteration:2801  t-loss:0.0990, loss-lb:0.0910, loss-ulb:0.0313, weight:0.26, lr:0.0009
[10:57:39.235] iteration:2802  t-loss:0.0987, loss-lb:0.0892, loss-ulb:0.0368, weight:0.26, lr:0.0009
[10:57:39.427] iteration:2803  t-loss:0.1296, loss-lb:0.1156, loss-ulb:0.0541, weight:0.26, lr:0.0009
[10:57:39.618] iteration:2804  t-loss:0.1261, loss-lb:0.1024, loss-ulb:0.0918, weight:0.26, lr:0.0009
[10:57:39.810] iteration:2805  t-loss:0.1114, loss-lb:0.0940, loss-ulb:0.0674, weight:0.26, lr:0.0009
[10:57:40.002] iteration:2806  t-loss:0.1201, loss-lb:0.1125, loss-ulb:0.0295, weight:0.26, lr:0.0009
[10:57:40.194] iteration:2807  t-loss:0.1133, loss-lb:0.1059, loss-ulb:0.0290, weight:0.26, lr:0.0009
[10:57:40.385] iteration:2808  t-loss:0.1256, loss-lb:0.1174, loss-ulb:0.0319, weight:0.26, lr:0.0009
[10:57:40.577] iteration:2809  t-loss:0.1082, loss-lb:0.0983, loss-ulb:0.0381, weight:0.26, lr:0.0009
[10:57:40.768] iteration:2810  t-loss:0.1089, loss-lb:0.1019, loss-ulb:0.0273, weight:0.26, lr:0.0009
[10:57:40.960] iteration:2811  t-loss:0.1458, loss-lb:0.0983, loss-ulb:0.1842, weight:0.26, lr:0.0009
[10:57:41.154] iteration:2812  t-loss:0.1267, loss-lb:0.1113, loss-ulb:0.0599, weight:0.26, lr:0.0009
[10:57:41.345] iteration:2813  t-loss:0.1134, loss-lb:0.0968, loss-ulb:0.0641, weight:0.26, lr:0.0009
[10:57:41.537] iteration:2814  t-loss:0.1142, loss-lb:0.1079, loss-ulb:0.0242, weight:0.26, lr:0.0009
[10:57:41.729] iteration:2815  t-loss:0.1248, loss-lb:0.1111, loss-ulb:0.0530, weight:0.26, lr:0.0009
[10:57:41.921] iteration:2816  t-loss:0.1014, loss-lb:0.0935, loss-ulb:0.0305, weight:0.26, lr:0.0009
[10:57:42.115] iteration:2817  t-loss:0.1316, loss-lb:0.1063, loss-ulb:0.0981, weight:0.26, lr:0.0009
[10:57:42.306] iteration:2818  t-loss:0.0999, loss-lb:0.0944, loss-ulb:0.0210, weight:0.26, lr:0.0009
[10:57:42.498] iteration:2819  t-loss:0.1139, loss-lb:0.1065, loss-ulb:0.0289, weight:0.26, lr:0.0009
[10:57:42.689] iteration:2820  t-loss:0.1206, loss-lb:0.1103, loss-ulb:0.0400, weight:0.26, lr:0.0009
[10:57:42.881] iteration:2821  t-loss:0.1137, loss-lb:0.1028, loss-ulb:0.0426, weight:0.26, lr:0.0009
[10:57:43.075] iteration:2822  t-loss:0.1098, loss-lb:0.1014, loss-ulb:0.0325, weight:0.26, lr:0.0009
[10:57:43.270] iteration:2823  t-loss:0.1217, loss-lb:0.1012, loss-ulb:0.0794, weight:0.26, lr:0.0009
[10:57:43.464] iteration:2824  t-loss:0.1269, loss-lb:0.1114, loss-ulb:0.0600, weight:0.26, lr:0.0009
[10:57:43.657] iteration:2825  t-loss:0.0995, loss-lb:0.0902, loss-ulb:0.0361, weight:0.26, lr:0.0009
[10:57:43.850] iteration:2826  t-loss:0.1180, loss-lb:0.1078, loss-ulb:0.0395, weight:0.26, lr:0.0009
[10:57:44.041] iteration:2827  t-loss:0.1061, loss-lb:0.0997, loss-ulb:0.0247, weight:0.26, lr:0.0009
[10:57:44.233] iteration:2828  t-loss:0.1140, loss-lb:0.1020, loss-ulb:0.0465, weight:0.26, lr:0.0009
[10:57:44.426] iteration:2829  t-loss:0.1188, loss-lb:0.0990, loss-ulb:0.0767, weight:0.26, lr:0.0009
[10:57:44.618] iteration:2830  t-loss:0.1122, loss-lb:0.1062, loss-ulb:0.0232, weight:0.26, lr:0.0009
[10:57:44.811] iteration:2831  t-loss:0.1204, loss-lb:0.1088, loss-ulb:0.0450, weight:0.26, lr:0.0009
[10:57:45.005] iteration:2832  t-loss:0.1396, loss-lb:0.1198, loss-ulb:0.0766, weight:0.26, lr:0.0009
[10:57:45.197] iteration:2833  t-loss:0.1265, loss-lb:0.1192, loss-ulb:0.0282, weight:0.26, lr:0.0009
[10:57:45.390] iteration:2834  t-loss:0.1297, loss-lb:0.1024, loss-ulb:0.1062, weight:0.26, lr:0.0009
[10:57:45.580] iteration:2835  t-loss:0.1152, loss-lb:0.1049, loss-ulb:0.0398, weight:0.26, lr:0.0009
[10:57:45.771] iteration:2836  t-loss:0.1201, loss-lb:0.1112, loss-ulb:0.0345, weight:0.26, lr:0.0009
[10:57:45.963] iteration:2837  t-loss:0.1119, loss-lb:0.1011, loss-ulb:0.0421, weight:0.26, lr:0.0009
[10:57:46.153] iteration:2838  t-loss:0.1188, loss-lb:0.1118, loss-ulb:0.0269, weight:0.26, lr:0.0009
[10:57:46.344] iteration:2839  t-loss:0.1205, loss-lb:0.1044, loss-ulb:0.0627, weight:0.26, lr:0.0009
[10:57:46.536] iteration:2840  t-loss:0.1294, loss-lb:0.1069, loss-ulb:0.0873, weight:0.26, lr:0.0009
[10:57:46.728] iteration:2841  t-loss:0.1100, loss-lb:0.0987, loss-ulb:0.0441, weight:0.26, lr:0.0009
[10:57:46.918] iteration:2842  t-loss:0.1160, loss-lb:0.1090, loss-ulb:0.0271, weight:0.26, lr:0.0009
[10:57:58.002]  <<Test>> - Ep:28  - mean_dice/mean_h95 - S:88.90/1.91, Best-S:88.90, T:89.46/1.47, Best-T:89.52
[10:57:58.002]           - AvgLoss(lb/ulb/all):0.1020/0.0503/0.1188
[10:57:58.533] iteration:2843  t-loss:0.1147, loss-lb:0.0986, loss-ulb:0.0626, weight:0.26, lr:0.0009
[10:57:58.731] iteration:2844  t-loss:0.1065, loss-lb:0.0988, loss-ulb:0.0302, weight:0.26, lr:0.0009
[10:57:58.923] iteration:2845  t-loss:0.1425, loss-lb:0.0999, loss-ulb:0.1652, weight:0.26, lr:0.0009
[10:57:59.125] iteration:2846  t-loss:0.1236, loss-lb:0.1145, loss-ulb:0.0354, weight:0.26, lr:0.0009
[10:57:59.316] iteration:2847  t-loss:0.1116, loss-lb:0.1016, loss-ulb:0.0389, weight:0.26, lr:0.0009
[10:57:59.508] iteration:2848  t-loss:0.1097, loss-lb:0.1027, loss-ulb:0.0273, weight:0.26, lr:0.0009
[10:57:59.700] iteration:2849  t-loss:0.1110, loss-lb:0.0991, loss-ulb:0.0461, weight:0.26, lr:0.0009
[10:57:59.899] iteration:2850  t-loss:0.1132, loss-lb:0.1022, loss-ulb:0.0427, weight:0.26, lr:0.0009
[10:58:00.090] iteration:2851  t-loss:0.1054, loss-lb:0.0980, loss-ulb:0.0252, weight:0.29, lr:0.0009
[10:58:00.284] iteration:2852  t-loss:0.1135, loss-lb:0.1027, loss-ulb:0.0372, weight:0.29, lr:0.0009
[10:58:00.476] iteration:2853  t-loss:0.1368, loss-lb:0.1099, loss-ulb:0.0919, weight:0.29, lr:0.0009
[10:58:00.675] iteration:2854  t-loss:0.1223, loss-lb:0.1132, loss-ulb:0.0312, weight:0.29, lr:0.0009
[10:58:00.867] iteration:2855  t-loss:0.1077, loss-lb:0.0984, loss-ulb:0.0318, weight:0.29, lr:0.0009
[10:58:01.059] iteration:2856  t-loss:0.1157, loss-lb:0.1047, loss-ulb:0.0377, weight:0.29, lr:0.0009
[10:58:01.252] iteration:2857  t-loss:0.1124, loss-lb:0.1009, loss-ulb:0.0393, weight:0.29, lr:0.0009
[10:58:01.451] iteration:2858  t-loss:0.1090, loss-lb:0.1001, loss-ulb:0.0306, weight:0.29, lr:0.0009
[10:58:01.644] iteration:2859  t-loss:0.1391, loss-lb:0.1044, loss-ulb:0.1185, weight:0.29, lr:0.0009
[10:58:01.835] iteration:2860  t-loss:0.1262, loss-lb:0.1175, loss-ulb:0.0297, weight:0.29, lr:0.0009
[10:58:02.028] iteration:2861  t-loss:0.1048, loss-lb:0.0972, loss-ulb:0.0260, weight:0.29, lr:0.0009
[10:58:02.218] iteration:2862  t-loss:0.1133, loss-lb:0.1031, loss-ulb:0.0349, weight:0.29, lr:0.0009
[10:58:02.410] iteration:2863  t-loss:0.1127, loss-lb:0.0998, loss-ulb:0.0440, weight:0.29, lr:0.0009
[10:58:02.601] iteration:2864  t-loss:0.1262, loss-lb:0.1090, loss-ulb:0.0590, weight:0.29, lr:0.0009
[10:58:02.792] iteration:2865  t-loss:0.1093, loss-lb:0.1025, loss-ulb:0.0234, weight:0.29, lr:0.0009
[10:58:02.983] iteration:2866  t-loss:0.1098, loss-lb:0.0916, loss-ulb:0.0620, weight:0.29, lr:0.0009
[10:58:03.176] iteration:2867  t-loss:0.1083, loss-lb:0.1009, loss-ulb:0.0254, weight:0.29, lr:0.0009
[10:58:03.369] iteration:2868  t-loss:0.1306, loss-lb:0.1068, loss-ulb:0.0813, weight:0.29, lr:0.0009
[10:58:03.564] iteration:2869  t-loss:0.1049, loss-lb:0.0934, loss-ulb:0.0395, weight:0.29, lr:0.0009
[10:58:03.758] iteration:2870  t-loss:0.1086, loss-lb:0.1006, loss-ulb:0.0273, weight:0.29, lr:0.0009
[10:58:03.952] iteration:2871  t-loss:0.1053, loss-lb:0.0957, loss-ulb:0.0329, weight:0.29, lr:0.0009
[10:58:04.146] iteration:2872  t-loss:0.1380, loss-lb:0.1042, loss-ulb:0.1155, weight:0.29, lr:0.0009
[10:58:04.339] iteration:2873  t-loss:0.1227, loss-lb:0.1069, loss-ulb:0.0538, weight:0.29, lr:0.0009
[10:58:04.531] iteration:2874  t-loss:0.1082, loss-lb:0.1003, loss-ulb:0.0270, weight:0.29, lr:0.0009
[10:58:04.723] iteration:2875  t-loss:0.1025, loss-lb:0.0911, loss-ulb:0.0388, weight:0.29, lr:0.0009
[10:58:04.915] iteration:2876  t-loss:0.0975, loss-lb:0.0895, loss-ulb:0.0273, weight:0.29, lr:0.0009
[10:58:05.106] iteration:2877  t-loss:0.1113, loss-lb:0.0949, loss-ulb:0.0561, weight:0.29, lr:0.0009
[10:58:05.299] iteration:2878  t-loss:0.1131, loss-lb:0.1021, loss-ulb:0.0376, weight:0.29, lr:0.0009
[10:58:05.491] iteration:2879  t-loss:0.1139, loss-lb:0.0999, loss-ulb:0.0478, weight:0.29, lr:0.0009
[10:58:05.685] iteration:2880  t-loss:0.1082, loss-lb:0.0986, loss-ulb:0.0329, weight:0.29, lr:0.0009
[10:58:05.877] iteration:2881  t-loss:0.1150, loss-lb:0.1060, loss-ulb:0.0306, weight:0.29, lr:0.0009
[10:58:06.070] iteration:2882  t-loss:0.1074, loss-lb:0.0972, loss-ulb:0.0347, weight:0.29, lr:0.0009
[10:58:06.262] iteration:2883  t-loss:0.1097, loss-lb:0.0971, loss-ulb:0.0429, weight:0.29, lr:0.0009
[10:58:06.454] iteration:2884  t-loss:0.1085, loss-lb:0.0994, loss-ulb:0.0311, weight:0.29, lr:0.0009
[10:58:06.647] iteration:2885  t-loss:0.1095, loss-lb:0.0974, loss-ulb:0.0412, weight:0.29, lr:0.0009
[10:58:06.840] iteration:2886  t-loss:0.1056, loss-lb:0.0932, loss-ulb:0.0424, weight:0.29, lr:0.0009
[10:58:07.033] iteration:2887  t-loss:0.1181, loss-lb:0.0987, loss-ulb:0.0663, weight:0.29, lr:0.0009
[10:58:07.234] iteration:2888  t-loss:0.0997, loss-lb:0.0897, loss-ulb:0.0342, weight:0.29, lr:0.0009
[10:58:07.435] iteration:2889  t-loss:0.1107, loss-lb:0.0960, loss-ulb:0.0505, weight:0.29, lr:0.0009
[10:58:07.632] iteration:2890  t-loss:0.1091, loss-lb:0.0956, loss-ulb:0.0462, weight:0.29, lr:0.0009
[10:58:07.824] iteration:2891  t-loss:0.1172, loss-lb:0.1058, loss-ulb:0.0390, weight:0.29, lr:0.0009
[10:58:08.016] iteration:2892  t-loss:0.1059, loss-lb:0.0970, loss-ulb:0.0305, weight:0.29, lr:0.0009
[10:58:08.208] iteration:2893  t-loss:0.1113, loss-lb:0.0935, loss-ulb:0.0607, weight:0.29, lr:0.0009
[10:58:08.400] iteration:2894  t-loss:0.1200, loss-lb:0.0952, loss-ulb:0.0849, weight:0.29, lr:0.0009
[10:58:08.592] iteration:2895  t-loss:0.1123, loss-lb:0.1055, loss-ulb:0.0234, weight:0.29, lr:0.0009
[10:58:08.782] iteration:2896  t-loss:0.1062, loss-lb:0.0964, loss-ulb:0.0334, weight:0.29, lr:0.0009
[10:58:08.973] iteration:2897  t-loss:0.1037, loss-lb:0.0951, loss-ulb:0.0292, weight:0.29, lr:0.0009
[10:58:09.164] iteration:2898  t-loss:0.1040, loss-lb:0.0963, loss-ulb:0.0264, weight:0.29, lr:0.0009
[10:58:09.355] iteration:2899  t-loss:0.1100, loss-lb:0.1008, loss-ulb:0.0313, weight:0.29, lr:0.0009
[10:58:09.546] iteration:2900  t-loss:0.1121, loss-lb:0.1020, loss-ulb:0.0344, weight:0.29, lr:0.0009
[10:58:09.737] iteration:2901  t-loss:0.1140, loss-lb:0.0996, loss-ulb:0.0490, weight:0.29, lr:0.0009
[10:58:09.929] iteration:2902  t-loss:0.1152, loss-lb:0.1042, loss-ulb:0.0378, weight:0.29, lr:0.0009
[10:58:10.121] iteration:2903  t-loss:0.1088, loss-lb:0.0980, loss-ulb:0.0371, weight:0.29, lr:0.0009
[10:58:10.312] iteration:2904  t-loss:0.1039, loss-lb:0.0885, loss-ulb:0.0526, weight:0.29, lr:0.0009
[10:58:10.504] iteration:2905  t-loss:0.1047, loss-lb:0.0955, loss-ulb:0.0316, weight:0.29, lr:0.0009
[10:58:10.696] iteration:2906  t-loss:0.1076, loss-lb:0.0981, loss-ulb:0.0323, weight:0.29, lr:0.0009
[10:58:10.887] iteration:2907  t-loss:0.1387, loss-lb:0.1310, loss-ulb:0.0261, weight:0.29, lr:0.0009
[10:58:11.078] iteration:2908  t-loss:0.1202, loss-lb:0.1019, loss-ulb:0.0627, weight:0.29, lr:0.0009
[10:58:11.271] iteration:2909  t-loss:0.1196, loss-lb:0.1058, loss-ulb:0.0469, weight:0.29, lr:0.0009
[10:58:11.462] iteration:2910  t-loss:0.1162, loss-lb:0.1025, loss-ulb:0.0466, weight:0.29, lr:0.0009
[10:58:11.654] iteration:2911  t-loss:0.1366, loss-lb:0.1185, loss-ulb:0.0619, weight:0.29, lr:0.0009
[10:58:11.847] iteration:2912  t-loss:0.1292, loss-lb:0.1064, loss-ulb:0.0780, weight:0.29, lr:0.0009
[10:58:12.038] iteration:2913  t-loss:0.1502, loss-lb:0.1259, loss-ulb:0.0832, weight:0.29, lr:0.0009
[10:58:12.230] iteration:2914  t-loss:0.1255, loss-lb:0.1130, loss-ulb:0.0426, weight:0.29, lr:0.0009
[10:58:12.422] iteration:2915  t-loss:0.2221, loss-lb:0.2062, loss-ulb:0.0545, weight:0.29, lr:0.0009
[10:58:12.614] iteration:2916  t-loss:0.2103, loss-lb:0.1763, loss-ulb:0.1163, weight:0.29, lr:0.0009
[10:58:12.806] iteration:2917  t-loss:0.1535, loss-lb:0.1410, loss-ulb:0.0429, weight:0.29, lr:0.0009
[10:58:12.998] iteration:2918  t-loss:0.1152, loss-lb:0.1053, loss-ulb:0.0338, weight:0.29, lr:0.0009
[10:58:13.190] iteration:2919  t-loss:0.1298, loss-lb:0.1160, loss-ulb:0.0473, weight:0.29, lr:0.0009
[10:58:13.381] iteration:2920  t-loss:0.1287, loss-lb:0.1109, loss-ulb:0.0607, weight:0.29, lr:0.0009
[10:58:13.574] iteration:2921  t-loss:0.1557, loss-lb:0.1255, loss-ulb:0.1034, weight:0.29, lr:0.0009
[10:58:13.765] iteration:2922  t-loss:0.1410, loss-lb:0.1313, loss-ulb:0.0329, weight:0.29, lr:0.0009
[10:58:13.957] iteration:2923  t-loss:0.1404, loss-lb:0.1199, loss-ulb:0.0702, weight:0.29, lr:0.0009
[10:58:14.149] iteration:2924  t-loss:0.1549, loss-lb:0.1301, loss-ulb:0.0848, weight:0.29, lr:0.0009
[10:58:14.340] iteration:2925  t-loss:0.1573, loss-lb:0.1374, loss-ulb:0.0679, weight:0.29, lr:0.0009
[10:58:14.532] iteration:2926  t-loss:0.1188, loss-lb:0.1029, loss-ulb:0.0544, weight:0.29, lr:0.0009
[10:58:14.725] iteration:2927  t-loss:0.1243, loss-lb:0.1095, loss-ulb:0.0506, weight:0.29, lr:0.0009
[10:58:14.916] iteration:2928  t-loss:0.1422, loss-lb:0.1190, loss-ulb:0.0793, weight:0.29, lr:0.0009
[10:58:15.108] iteration:2929  t-loss:0.1465, loss-lb:0.1213, loss-ulb:0.0858, weight:0.29, lr:0.0009
[10:58:15.300] iteration:2930  t-loss:0.1346, loss-lb:0.1140, loss-ulb:0.0702, weight:0.29, lr:0.0009
[10:58:15.492] iteration:2931  t-loss:0.1302, loss-lb:0.1171, loss-ulb:0.0447, weight:0.29, lr:0.0009
[10:58:15.684] iteration:2932  t-loss:0.1498, loss-lb:0.1376, loss-ulb:0.0419, weight:0.29, lr:0.0009
[10:58:15.875] iteration:2933  t-loss:0.1404, loss-lb:0.1258, loss-ulb:0.0499, weight:0.29, lr:0.0009
[10:58:16.066] iteration:2934  t-loss:0.1375, loss-lb:0.1247, loss-ulb:0.0439, weight:0.29, lr:0.0009
[10:58:16.256] iteration:2935  t-loss:0.1165, loss-lb:0.1035, loss-ulb:0.0447, weight:0.29, lr:0.0009
[10:58:16.446] iteration:2936  t-loss:0.1374, loss-lb:0.1196, loss-ulb:0.0607, weight:0.29, lr:0.0009
[10:58:16.636] iteration:2937  t-loss:0.1411, loss-lb:0.1173, loss-ulb:0.0813, weight:0.29, lr:0.0009
[10:58:16.827] iteration:2938  t-loss:0.1207, loss-lb:0.1073, loss-ulb:0.0460, weight:0.29, lr:0.0009
[10:58:17.017] iteration:2939  t-loss:0.2295, loss-lb:0.2228, loss-ulb:0.0232, weight:0.29, lr:0.0009
[10:58:17.209] iteration:2940  t-loss:0.1255, loss-lb:0.1149, loss-ulb:0.0361, weight:0.29, lr:0.0009
[10:58:17.768] iteration:2941  t-loss:0.1291, loss-lb:0.1128, loss-ulb:0.0556, weight:0.29, lr:0.0009
[10:58:17.962] iteration:2942  t-loss:0.1411, loss-lb:0.1270, loss-ulb:0.0480, weight:0.29, lr:0.0009
[10:58:18.154] iteration:2943  t-loss:0.1380, loss-lb:0.1119, loss-ulb:0.0890, weight:0.29, lr:0.0009
[10:58:18.345] iteration:2944  t-loss:0.1437, loss-lb:0.1158, loss-ulb:0.0952, weight:0.29, lr:0.0009
[10:58:18.536] iteration:2945  t-loss:0.1371, loss-lb:0.1191, loss-ulb:0.0617, weight:0.29, lr:0.0009
[10:58:18.729] iteration:2946  t-loss:0.1513, loss-lb:0.1297, loss-ulb:0.0739, weight:0.29, lr:0.0009
[10:58:18.921] iteration:2947  t-loss:0.1172, loss-lb:0.1083, loss-ulb:0.0302, weight:0.29, lr:0.0009
[10:58:19.112] iteration:2948  t-loss:0.1292, loss-lb:0.1179, loss-ulb:0.0388, weight:0.29, lr:0.0009
[10:58:19.305] iteration:2949  t-loss:0.1456, loss-lb:0.1307, loss-ulb:0.0508, weight:0.29, lr:0.0009
[10:58:19.496] iteration:2950  t-loss:0.1267, loss-lb:0.1131, loss-ulb:0.0467, weight:0.29, lr:0.0009
[10:58:19.688] iteration:2951  t-loss:0.1142, loss-lb:0.0979, loss-ulb:0.0558, weight:0.29, lr:0.0009
[10:58:19.881] iteration:2952  t-loss:0.1444, loss-lb:0.1191, loss-ulb:0.0865, weight:0.29, lr:0.0009
[10:58:20.074] iteration:2953  t-loss:0.1408, loss-lb:0.1242, loss-ulb:0.0568, weight:0.29, lr:0.0009
[10:58:20.266] iteration:2954  t-loss:0.1121, loss-lb:0.0996, loss-ulb:0.0426, weight:0.29, lr:0.0009
[10:58:20.458] iteration:2955  t-loss:0.1207, loss-lb:0.1117, loss-ulb:0.0308, weight:0.29, lr:0.0009
[10:58:20.649] iteration:2956  t-loss:0.1214, loss-lb:0.1059, loss-ulb:0.0529, weight:0.29, lr:0.0009
[10:58:20.841] iteration:2957  t-loss:0.1376, loss-lb:0.1265, loss-ulb:0.0379, weight:0.29, lr:0.0009
[10:58:21.034] iteration:2958  t-loss:0.1257, loss-lb:0.1116, loss-ulb:0.0479, weight:0.29, lr:0.0009
[10:58:21.225] iteration:2959  t-loss:0.1344, loss-lb:0.1109, loss-ulb:0.0803, weight:0.29, lr:0.0009
[10:58:21.417] iteration:2960  t-loss:0.1259, loss-lb:0.1140, loss-ulb:0.0408, weight:0.29, lr:0.0009
[10:58:21.610] iteration:2961  t-loss:0.1310, loss-lb:0.1077, loss-ulb:0.0796, weight:0.29, lr:0.0009
[10:58:21.802] iteration:2962  t-loss:0.1163, loss-lb:0.0949, loss-ulb:0.0733, weight:0.29, lr:0.0009
[10:58:21.994] iteration:2963  t-loss:0.1217, loss-lb:0.1146, loss-ulb:0.0244, weight:0.29, lr:0.0009
[10:58:22.186] iteration:2964  t-loss:0.1268, loss-lb:0.1122, loss-ulb:0.0501, weight:0.29, lr:0.0009
[10:58:22.379] iteration:2965  t-loss:0.1617, loss-lb:0.1148, loss-ulb:0.1603, weight:0.29, lr:0.0009
[10:58:22.571] iteration:2966  t-loss:0.2178, loss-lb:0.2022, loss-ulb:0.0533, weight:0.29, lr:0.0009
[10:58:22.762] iteration:2967  t-loss:0.1206, loss-lb:0.1098, loss-ulb:0.0370, weight:0.29, lr:0.0009
[10:58:22.953] iteration:2968  t-loss:0.1412, loss-lb:0.1126, loss-ulb:0.0978, weight:0.29, lr:0.0009
[10:58:23.146] iteration:2969  t-loss:0.1264, loss-lb:0.1144, loss-ulb:0.0408, weight:0.29, lr:0.0009
[10:58:23.337] iteration:2970  t-loss:0.1512, loss-lb:0.1343, loss-ulb:0.0577, weight:0.29, lr:0.0009
[10:58:23.529] iteration:2971  t-loss:0.1528, loss-lb:0.1311, loss-ulb:0.0740, weight:0.29, lr:0.0009
[10:58:23.721] iteration:2972  t-loss:0.1904, loss-lb:0.1796, loss-ulb:0.0370, weight:0.29, lr:0.0009
[10:58:23.913] iteration:2973  t-loss:0.1448, loss-lb:0.1117, loss-ulb:0.1132, weight:0.29, lr:0.0009
[10:58:24.106] iteration:2974  t-loss:0.1469, loss-lb:0.1101, loss-ulb:0.1259, weight:0.29, lr:0.0009
[10:58:24.299] iteration:2975  t-loss:0.1902, loss-lb:0.1638, loss-ulb:0.0901, weight:0.29, lr:0.0009
[10:58:24.490] iteration:2976  t-loss:0.1203, loss-lb:0.1070, loss-ulb:0.0456, weight:0.29, lr:0.0009
[10:58:24.683] iteration:2977  t-loss:0.1593, loss-lb:0.1471, loss-ulb:0.0417, weight:0.29, lr:0.0009
[10:58:24.876] iteration:2978  t-loss:0.1676, loss-lb:0.1537, loss-ulb:0.0475, weight:0.29, lr:0.0009
[10:58:25.067] iteration:2979  t-loss:0.1568, loss-lb:0.1371, loss-ulb:0.0673, weight:0.29, lr:0.0009
[10:58:25.259] iteration:2980  t-loss:0.1698, loss-lb:0.1424, loss-ulb:0.0935, weight:0.29, lr:0.0009
[10:58:25.450] iteration:2981  t-loss:0.1627, loss-lb:0.1347, loss-ulb:0.0957, weight:0.29, lr:0.0009
[10:58:25.642] iteration:2982  t-loss:0.1609, loss-lb:0.1303, loss-ulb:0.1047, weight:0.29, lr:0.0009
[10:58:25.834] iteration:2983  t-loss:0.1397, loss-lb:0.1093, loss-ulb:0.1039, weight:0.29, lr:0.0009
[10:58:26.026] iteration:2984  t-loss:0.1294, loss-lb:0.1156, loss-ulb:0.0472, weight:0.29, lr:0.0009
[10:58:26.218] iteration:2985  t-loss:0.1585, loss-lb:0.1243, loss-ulb:0.1167, weight:0.29, lr:0.0009
[10:58:26.410] iteration:2986  t-loss:0.1342, loss-lb:0.1181, loss-ulb:0.0550, weight:0.29, lr:0.0009
[10:58:26.601] iteration:2987  t-loss:0.1083, loss-lb:0.0990, loss-ulb:0.0318, weight:0.29, lr:0.0009
[10:58:26.793] iteration:2988  t-loss:0.1201, loss-lb:0.1098, loss-ulb:0.0353, weight:0.29, lr:0.0009
[10:58:26.985] iteration:2989  t-loss:0.1591, loss-lb:0.1446, loss-ulb:0.0497, weight:0.29, lr:0.0009
[10:58:27.177] iteration:2990  t-loss:0.1490, loss-lb:0.1333, loss-ulb:0.0536, weight:0.29, lr:0.0009
[10:58:27.370] iteration:2991  t-loss:0.1806, loss-lb:0.1465, loss-ulb:0.1164, weight:0.29, lr:0.0009
[10:58:27.564] iteration:2992  t-loss:0.1395, loss-lb:0.1313, loss-ulb:0.0280, weight:0.29, lr:0.0009
[10:58:27.756] iteration:2993  t-loss:0.1271, loss-lb:0.1135, loss-ulb:0.0465, weight:0.29, lr:0.0009
[10:58:27.948] iteration:2994  t-loss:0.1344, loss-lb:0.1192, loss-ulb:0.0519, weight:0.29, lr:0.0009
[10:58:28.155] iteration:2995  t-loss:0.1303, loss-lb:0.1150, loss-ulb:0.0524, weight:0.29, lr:0.0009
[10:58:28.347] iteration:2996  t-loss:0.1486, loss-lb:0.1362, loss-ulb:0.0426, weight:0.29, lr:0.0009
[10:58:28.540] iteration:2997  t-loss:0.1654, loss-lb:0.1283, loss-ulb:0.1268, weight:0.29, lr:0.0009
[10:58:28.732] iteration:2998  t-loss:0.1319, loss-lb:0.1111, loss-ulb:0.0713, weight:0.29, lr:0.0009
[10:58:28.925] iteration:2999  t-loss:0.1274, loss-lb:0.1152, loss-ulb:0.0418, weight:0.29, lr:0.0009
[10:58:29.116] iteration:3000  t-loss:0.1295, loss-lb:0.1102, loss-ulb:0.0659, weight:0.29, lr:0.0009
[10:58:29.308] iteration:3001  t-loss:0.1469, loss-lb:0.1271, loss-ulb:0.0601, weight:0.33, lr:0.0009
[10:58:29.502] iteration:3002  t-loss:0.1329, loss-lb:0.1138, loss-ulb:0.0578, weight:0.33, lr:0.0009
[10:58:29.693] iteration:3003  t-loss:0.1204, loss-lb:0.1099, loss-ulb:0.0317, weight:0.33, lr:0.0009
[10:58:29.884] iteration:3004  t-loss:0.1180, loss-lb:0.1057, loss-ulb:0.0374, weight:0.33, lr:0.0009
[10:58:30.076] iteration:3005  t-loss:0.1205, loss-lb:0.1032, loss-ulb:0.0525, weight:0.33, lr:0.0009
[10:58:30.268] iteration:3006  t-loss:0.1424, loss-lb:0.1250, loss-ulb:0.0527, weight:0.33, lr:0.0009
[10:58:30.460] iteration:3007  t-loss:0.1332, loss-lb:0.1096, loss-ulb:0.0715, weight:0.33, lr:0.0009
[10:58:30.651] iteration:3008  t-loss:0.1098, loss-lb:0.0967, loss-ulb:0.0397, weight:0.33, lr:0.0009
[10:58:30.843] iteration:3009  t-loss:0.1198, loss-lb:0.1080, loss-ulb:0.0358, weight:0.33, lr:0.0009
[10:58:31.037] iteration:3010  t-loss:0.1198, loss-lb:0.1101, loss-ulb:0.0292, weight:0.33, lr:0.0009
[10:58:31.230] iteration:3011  t-loss:0.1295, loss-lb:0.1158, loss-ulb:0.0416, weight:0.33, lr:0.0009
[10:58:31.422] iteration:3012  t-loss:0.1160, loss-lb:0.1051, loss-ulb:0.0330, weight:0.33, lr:0.0009
[10:58:31.614] iteration:3013  t-loss:0.1282, loss-lb:0.1058, loss-ulb:0.0678, weight:0.33, lr:0.0009
[10:58:31.807] iteration:3014  t-loss:0.1291, loss-lb:0.1121, loss-ulb:0.0513, weight:0.33, lr:0.0009
[10:58:32.000] iteration:3015  t-loss:0.1244, loss-lb:0.1100, loss-ulb:0.0435, weight:0.33, lr:0.0009
[10:58:32.193] iteration:3016  t-loss:0.1477, loss-lb:0.1307, loss-ulb:0.0513, weight:0.33, lr:0.0009
[10:58:32.384] iteration:3017  t-loss:0.1154, loss-lb:0.1029, loss-ulb:0.0377, weight:0.33, lr:0.0009
[10:58:32.577] iteration:3018  t-loss:0.1441, loss-lb:0.1209, loss-ulb:0.0702, weight:0.33, lr:0.0009
[10:58:32.769] iteration:3019  t-loss:0.1344, loss-lb:0.1240, loss-ulb:0.0314, weight:0.33, lr:0.0009
[10:58:32.963] iteration:3020  t-loss:0.1251, loss-lb:0.1071, loss-ulb:0.0544, weight:0.33, lr:0.0009
[10:58:33.155] iteration:3021  t-loss:0.1498, loss-lb:0.0902, loss-ulb:0.1801, weight:0.33, lr:0.0009
[10:58:33.349] iteration:3022  t-loss:0.1335, loss-lb:0.1210, loss-ulb:0.0378, weight:0.33, lr:0.0009
[10:58:33.542] iteration:3023  t-loss:0.1133, loss-lb:0.0969, loss-ulb:0.0496, weight:0.33, lr:0.0009
[10:58:33.733] iteration:3024  t-loss:0.1281, loss-lb:0.1160, loss-ulb:0.0366, weight:0.33, lr:0.0009
[10:58:33.925] iteration:3025  t-loss:0.1346, loss-lb:0.1133, loss-ulb:0.0645, weight:0.33, lr:0.0009
[10:58:34.118] iteration:3026  t-loss:0.1318, loss-lb:0.1099, loss-ulb:0.0662, weight:0.33, lr:0.0009
[10:58:34.310] iteration:3027  t-loss:0.1316, loss-lb:0.1119, loss-ulb:0.0595, weight:0.33, lr:0.0009
[10:58:34.503] iteration:3028  t-loss:0.1410, loss-lb:0.1163, loss-ulb:0.0748, weight:0.33, lr:0.0009
[10:58:34.696] iteration:3029  t-loss:0.1401, loss-lb:0.1256, loss-ulb:0.0438, weight:0.33, lr:0.0009
[10:58:34.887] iteration:3030  t-loss:0.1432, loss-lb:0.1265, loss-ulb:0.0505, weight:0.33, lr:0.0009
[10:58:35.079] iteration:3031  t-loss:0.1109, loss-lb:0.0952, loss-ulb:0.0473, weight:0.33, lr:0.0009
[10:58:35.271] iteration:3032  t-loss:0.1246, loss-lb:0.1068, loss-ulb:0.0537, weight:0.33, lr:0.0009
[10:58:35.462] iteration:3033  t-loss:0.1326, loss-lb:0.1082, loss-ulb:0.0737, weight:0.33, lr:0.0009
[10:58:35.652] iteration:3034  t-loss:0.1235, loss-lb:0.1106, loss-ulb:0.0390, weight:0.33, lr:0.0009
[10:58:35.842] iteration:3035  t-loss:0.1203, loss-lb:0.1039, loss-ulb:0.0496, weight:0.33, lr:0.0009
[10:58:36.032] iteration:3036  t-loss:0.1217, loss-lb:0.1114, loss-ulb:0.0312, weight:0.33, lr:0.0009
[10:58:36.223] iteration:3037  t-loss:0.1126, loss-lb:0.1022, loss-ulb:0.0313, weight:0.33, lr:0.0009
[10:58:36.415] iteration:3038  t-loss:0.1122, loss-lb:0.1019, loss-ulb:0.0312, weight:0.33, lr:0.0009
[10:58:48.199]  <<Test>> - Ep:30  - mean_dice/mean_h95 - S:88.43/3.40, Best-S:88.90, T:89.41/1.91, Best-T:89.52
[10:58:48.199]           - AvgLoss(lb/ulb/all):0.1180/0.0553/0.1282
[10:58:48.729] iteration:3039  t-loss:0.1193, loss-lb:0.1042, loss-ulb:0.0460, weight:0.33, lr:0.0009
[10:58:48.925] iteration:3040  t-loss:0.1089, loss-lb:0.0981, loss-ulb:0.0327, weight:0.33, lr:0.0009
[10:58:49.118] iteration:3041  t-loss:0.1229, loss-lb:0.1133, loss-ulb:0.0293, weight:0.33, lr:0.0009
[10:58:49.310] iteration:3042  t-loss:0.1175, loss-lb:0.1049, loss-ulb:0.0381, weight:0.33, lr:0.0009
[10:58:49.502] iteration:3043  t-loss:0.1310, loss-lb:0.1072, loss-ulb:0.0718, weight:0.33, lr:0.0009
[10:58:49.695] iteration:3044  t-loss:0.1281, loss-lb:0.1170, loss-ulb:0.0336, weight:0.33, lr:0.0009
[10:58:49.889] iteration:3045  t-loss:0.1547, loss-lb:0.1104, loss-ulb:0.1340, weight:0.33, lr:0.0009
[10:58:50.081] iteration:3046  t-loss:0.1107, loss-lb:0.0972, loss-ulb:0.0409, weight:0.33, lr:0.0009
[10:58:50.273] iteration:3047  t-loss:0.1119, loss-lb:0.1044, loss-ulb:0.0225, weight:0.33, lr:0.0009
[10:58:50.466] iteration:3048  t-loss:0.1306, loss-lb:0.1071, loss-ulb:0.0711, weight:0.33, lr:0.0009
[10:58:50.659] iteration:3049  t-loss:0.1252, loss-lb:0.1107, loss-ulb:0.0441, weight:0.33, lr:0.0009
[10:58:50.851] iteration:3050  t-loss:0.1109, loss-lb:0.0999, loss-ulb:0.0331, weight:0.33, lr:0.0009
[10:58:51.043] iteration:3051  t-loss:0.1132, loss-lb:0.1049, loss-ulb:0.0252, weight:0.33, lr:0.0009
[10:58:51.234] iteration:3052  t-loss:0.1104, loss-lb:0.1028, loss-ulb:0.0228, weight:0.33, lr:0.0009
[10:58:51.427] iteration:3053  t-loss:0.1207, loss-lb:0.1012, loss-ulb:0.0587, weight:0.33, lr:0.0009
[10:58:51.620] iteration:3054  t-loss:0.1246, loss-lb:0.1070, loss-ulb:0.0531, weight:0.33, lr:0.0009
[10:58:51.812] iteration:3055  t-loss:0.1103, loss-lb:0.1011, loss-ulb:0.0277, weight:0.33, lr:0.0009
[10:58:52.003] iteration:3056  t-loss:0.1204, loss-lb:0.1098, loss-ulb:0.0322, weight:0.33, lr:0.0009
[10:58:52.195] iteration:3057  t-loss:0.1243, loss-lb:0.1113, loss-ulb:0.0393, weight:0.33, lr:0.0009
[10:58:52.387] iteration:3058  t-loss:0.1002, loss-lb:0.0910, loss-ulb:0.0278, weight:0.33, lr:0.0009
[10:58:52.579] iteration:3059  t-loss:0.1197, loss-lb:0.1050, loss-ulb:0.0444, weight:0.33, lr:0.0009
[10:58:52.770] iteration:3060  t-loss:0.1302, loss-lb:0.1213, loss-ulb:0.0271, weight:0.33, lr:0.0009
[10:58:52.963] iteration:3061  t-loss:0.1066, loss-lb:0.0943, loss-ulb:0.0375, weight:0.33, lr:0.0009
[10:58:53.155] iteration:3062  t-loss:0.1135, loss-lb:0.1060, loss-ulb:0.0228, weight:0.33, lr:0.0009
[10:58:53.347] iteration:3063  t-loss:0.1251, loss-lb:0.1059, loss-ulb:0.0580, weight:0.33, lr:0.0009
[10:58:53.541] iteration:3064  t-loss:0.1083, loss-lb:0.0975, loss-ulb:0.0327, weight:0.33, lr:0.0009
[10:58:53.735] iteration:3065  t-loss:0.1296, loss-lb:0.1037, loss-ulb:0.0784, weight:0.33, lr:0.0009
[10:58:53.926] iteration:3066  t-loss:0.1117, loss-lb:0.0900, loss-ulb:0.0658, weight:0.33, lr:0.0009
[10:58:54.118] iteration:3067  t-loss:0.1192, loss-lb:0.1102, loss-ulb:0.0272, weight:0.33, lr:0.0009
[10:58:54.311] iteration:3068  t-loss:0.1162, loss-lb:0.1024, loss-ulb:0.0418, weight:0.33, lr:0.0009
[10:58:54.502] iteration:3069  t-loss:0.1002, loss-lb:0.0919, loss-ulb:0.0250, weight:0.33, lr:0.0009
[10:58:54.694] iteration:3070  t-loss:0.1285, loss-lb:0.1112, loss-ulb:0.0523, weight:0.33, lr:0.0009
[10:58:54.888] iteration:3071  t-loss:0.1085, loss-lb:0.0903, loss-ulb:0.0548, weight:0.33, lr:0.0009
[10:58:55.081] iteration:3072  t-loss:0.0980, loss-lb:0.0902, loss-ulb:0.0235, weight:0.33, lr:0.0009
[10:58:55.273] iteration:3073  t-loss:0.1263, loss-lb:0.1153, loss-ulb:0.0335, weight:0.33, lr:0.0009
[10:58:55.466] iteration:3074  t-loss:0.1361, loss-lb:0.1059, loss-ulb:0.0913, weight:0.33, lr:0.0009
[10:58:55.658] iteration:3075  t-loss:0.1009, loss-lb:0.0906, loss-ulb:0.0311, weight:0.33, lr:0.0009
[10:58:55.850] iteration:3076  t-loss:0.1081, loss-lb:0.0986, loss-ulb:0.0287, weight:0.33, lr:0.0009
[10:58:56.042] iteration:3077  t-loss:0.1174, loss-lb:0.1061, loss-ulb:0.0343, weight:0.33, lr:0.0009
[10:58:56.235] iteration:3078  t-loss:0.1137, loss-lb:0.1053, loss-ulb:0.0253, weight:0.33, lr:0.0009
[10:58:56.429] iteration:3079  t-loss:0.1307, loss-lb:0.1055, loss-ulb:0.0765, weight:0.33, lr:0.0009
[10:58:56.621] iteration:3080  t-loss:0.1125, loss-lb:0.0990, loss-ulb:0.0407, weight:0.33, lr:0.0009
[10:58:56.813] iteration:3081  t-loss:0.1104, loss-lb:0.1018, loss-ulb:0.0260, weight:0.33, lr:0.0009
[10:58:57.006] iteration:3082  t-loss:0.1037, loss-lb:0.0957, loss-ulb:0.0242, weight:0.33, lr:0.0009
[10:58:57.197] iteration:3083  t-loss:0.1030, loss-lb:0.0933, loss-ulb:0.0293, weight:0.33, lr:0.0009
[10:58:57.389] iteration:3084  t-loss:0.1149, loss-lb:0.1039, loss-ulb:0.0332, weight:0.33, lr:0.0009
[10:58:57.581] iteration:3085  t-loss:0.1090, loss-lb:0.0921, loss-ulb:0.0512, weight:0.33, lr:0.0009
[10:58:57.773] iteration:3086  t-loss:0.0993, loss-lb:0.0881, loss-ulb:0.0340, weight:0.33, lr:0.0009
[10:58:57.965] iteration:3087  t-loss:0.1210, loss-lb:0.1043, loss-ulb:0.0506, weight:0.33, lr:0.0009
[10:58:58.157] iteration:3088  t-loss:0.0995, loss-lb:0.0905, loss-ulb:0.0273, weight:0.33, lr:0.0009
[10:58:58.349] iteration:3089  t-loss:0.0994, loss-lb:0.0888, loss-ulb:0.0319, weight:0.33, lr:0.0009
[10:58:58.541] iteration:3090  t-loss:0.1200, loss-lb:0.1129, loss-ulb:0.0213, weight:0.33, lr:0.0009
[10:58:58.734] iteration:3091  t-loss:0.1121, loss-lb:0.1022, loss-ulb:0.0299, weight:0.33, lr:0.0009
[10:58:58.927] iteration:3092  t-loss:0.1071, loss-lb:0.0923, loss-ulb:0.0448, weight:0.33, lr:0.0009
[10:58:59.125] iteration:3093  t-loss:0.1019, loss-lb:0.0923, loss-ulb:0.0289, weight:0.33, lr:0.0009
[10:58:59.319] iteration:3094  t-loss:0.1249, loss-lb:0.1110, loss-ulb:0.0422, weight:0.33, lr:0.0009
[10:58:59.512] iteration:3095  t-loss:0.1232, loss-lb:0.1142, loss-ulb:0.0275, weight:0.33, lr:0.0009
[10:58:59.706] iteration:3096  t-loss:0.1097, loss-lb:0.0989, loss-ulb:0.0325, weight:0.33, lr:0.0009
[10:58:59.897] iteration:3097  t-loss:0.1192, loss-lb:0.1100, loss-ulb:0.0278, weight:0.33, lr:0.0009
[10:59:00.090] iteration:3098  t-loss:0.1005, loss-lb:0.0929, loss-ulb:0.0232, weight:0.33, lr:0.0009
[10:59:00.282] iteration:3099  t-loss:0.1266, loss-lb:0.0988, loss-ulb:0.0839, weight:0.33, lr:0.0009
[10:59:00.473] iteration:3100  t-loss:0.1013, loss-lb:0.0895, loss-ulb:0.0359, weight:0.33, lr:0.0009
[10:59:00.665] iteration:3101  t-loss:0.1105, loss-lb:0.0981, loss-ulb:0.0376, weight:0.33, lr:0.0009
[10:59:00.856] iteration:3102  t-loss:0.1129, loss-lb:0.1022, loss-ulb:0.0322, weight:0.33, lr:0.0009
[10:59:01.048] iteration:3103  t-loss:0.1306, loss-lb:0.1159, loss-ulb:0.0443, weight:0.33, lr:0.0009
[10:59:01.240] iteration:3104  t-loss:0.1022, loss-lb:0.0942, loss-ulb:0.0240, weight:0.33, lr:0.0009
[10:59:01.433] iteration:3105  t-loss:0.1356, loss-lb:0.1207, loss-ulb:0.0452, weight:0.33, lr:0.0009
[10:59:01.624] iteration:3106  t-loss:0.1209, loss-lb:0.1027, loss-ulb:0.0550, weight:0.33, lr:0.0009
[10:59:01.816] iteration:3107  t-loss:0.1195, loss-lb:0.1045, loss-ulb:0.0455, weight:0.33, lr:0.0009
[10:59:02.009] iteration:3108  t-loss:0.1094, loss-lb:0.0936, loss-ulb:0.0478, weight:0.33, lr:0.0009
[10:59:02.200] iteration:3109  t-loss:0.1418, loss-lb:0.1243, loss-ulb:0.0529, weight:0.33, lr:0.0009
[10:59:02.392] iteration:3110  t-loss:0.1153, loss-lb:0.1060, loss-ulb:0.0282, weight:0.33, lr:0.0009
[10:59:02.582] iteration:3111  t-loss:0.1059, loss-lb:0.0967, loss-ulb:0.0277, weight:0.33, lr:0.0009
[10:59:02.774] iteration:3112  t-loss:0.1338, loss-lb:0.1213, loss-ulb:0.0378, weight:0.33, lr:0.0009
[10:59:02.966] iteration:3113  t-loss:0.1102, loss-lb:0.0984, loss-ulb:0.0357, weight:0.33, lr:0.0009
[10:59:03.158] iteration:3114  t-loss:0.1107, loss-lb:0.0999, loss-ulb:0.0325, weight:0.33, lr:0.0009
[10:59:03.351] iteration:3115  t-loss:0.1028, loss-lb:0.0889, loss-ulb:0.0420, weight:0.33, lr:0.0009
[10:59:03.542] iteration:3116  t-loss:0.1144, loss-lb:0.1041, loss-ulb:0.0312, weight:0.33, lr:0.0009
[10:59:03.735] iteration:3117  t-loss:0.1228, loss-lb:0.1118, loss-ulb:0.0331, weight:0.33, lr:0.0009
[10:59:03.928] iteration:3118  t-loss:0.1196, loss-lb:0.1012, loss-ulb:0.0558, weight:0.33, lr:0.0009
[10:59:04.119] iteration:3119  t-loss:0.1039, loss-lb:0.0957, loss-ulb:0.0247, weight:0.33, lr:0.0009
[10:59:04.311] iteration:3120  t-loss:0.1287, loss-lb:0.1036, loss-ulb:0.0760, weight:0.33, lr:0.0009
[10:59:04.503] iteration:3121  t-loss:0.1322, loss-lb:0.1137, loss-ulb:0.0559, weight:0.33, lr:0.0009
[10:59:04.693] iteration:3122  t-loss:0.1184, loss-lb:0.1056, loss-ulb:0.0389, weight:0.33, lr:0.0009
[10:59:04.885] iteration:3123  t-loss:0.1209, loss-lb:0.0964, loss-ulb:0.0744, weight:0.33, lr:0.0009
[10:59:05.075] iteration:3124  t-loss:0.1121, loss-lb:0.0979, loss-ulb:0.0430, weight:0.33, lr:0.0009
[10:59:05.266] iteration:3125  t-loss:0.1565, loss-lb:0.1082, loss-ulb:0.1461, weight:0.33, lr:0.0009
[10:59:05.458] iteration:3126  t-loss:0.1155, loss-lb:0.0999, loss-ulb:0.0470, weight:0.33, lr:0.0009
[10:59:05.652] iteration:3127  t-loss:0.1239, loss-lb:0.1064, loss-ulb:0.0529, weight:0.33, lr:0.0009
[10:59:05.846] iteration:3128  t-loss:0.1267, loss-lb:0.1099, loss-ulb:0.0508, weight:0.33, lr:0.0009
[10:59:06.041] iteration:3129  t-loss:0.1227, loss-lb:0.1083, loss-ulb:0.0435, weight:0.33, lr:0.0009
[10:59:06.235] iteration:3130  t-loss:0.1185, loss-lb:0.1054, loss-ulb:0.0397, weight:0.33, lr:0.0009
[10:59:06.427] iteration:3131  t-loss:0.1102, loss-lb:0.0984, loss-ulb:0.0356, weight:0.33, lr:0.0009
[10:59:06.616] iteration:3132  t-loss:0.1359, loss-lb:0.1078, loss-ulb:0.0848, weight:0.33, lr:0.0009
[10:59:06.806] iteration:3133  t-loss:0.1065, loss-lb:0.0978, loss-ulb:0.0265, weight:0.33, lr:0.0009
[10:59:07.000] iteration:3134  t-loss:0.1284, loss-lb:0.1050, loss-ulb:0.0710, weight:0.33, lr:0.0009
[10:59:07.190] iteration:3135  t-loss:0.1452, loss-lb:0.1325, loss-ulb:0.0384, weight:0.33, lr:0.0009
[10:59:07.380] iteration:3136  t-loss:0.1236, loss-lb:0.1085, loss-ulb:0.0456, weight:0.33, lr:0.0009
[10:59:07.990] iteration:3137  t-loss:0.1223, loss-lb:0.1121, loss-ulb:0.0309, weight:0.33, lr:0.0009
[10:59:08.184] iteration:3138  t-loss:0.1192, loss-lb:0.1119, loss-ulb:0.0219, weight:0.33, lr:0.0009
[10:59:08.377] iteration:3139  t-loss:0.1098, loss-lb:0.0995, loss-ulb:0.0311, weight:0.33, lr:0.0009
[10:59:08.569] iteration:3140  t-loss:0.1131, loss-lb:0.0941, loss-ulb:0.0574, weight:0.33, lr:0.0009
[10:59:08.762] iteration:3141  t-loss:0.1430, loss-lb:0.1101, loss-ulb:0.0997, weight:0.33, lr:0.0009
[10:59:08.954] iteration:3142  t-loss:0.1258, loss-lb:0.1075, loss-ulb:0.0555, weight:0.33, lr:0.0009
[10:59:09.146] iteration:3143  t-loss:0.1459, loss-lb:0.1216, loss-ulb:0.0736, weight:0.33, lr:0.0009
[10:59:09.339] iteration:3144  t-loss:0.1072, loss-lb:0.0924, loss-ulb:0.0449, weight:0.33, lr:0.0009
[10:59:09.531] iteration:3145  t-loss:0.1020, loss-lb:0.0930, loss-ulb:0.0271, weight:0.33, lr:0.0009
[10:59:09.723] iteration:3146  t-loss:0.1178, loss-lb:0.0963, loss-ulb:0.0649, weight:0.33, lr:0.0009
[10:59:09.916] iteration:3147  t-loss:0.1257, loss-lb:0.1098, loss-ulb:0.0479, weight:0.33, lr:0.0009
[10:59:10.107] iteration:3148  t-loss:0.1213, loss-lb:0.1132, loss-ulb:0.0246, weight:0.33, lr:0.0009
[10:59:10.301] iteration:3149  t-loss:0.1176, loss-lb:0.1030, loss-ulb:0.0441, weight:0.33, lr:0.0009
[10:59:10.494] iteration:3150  t-loss:0.1299, loss-lb:0.1034, loss-ulb:0.0801, weight:0.33, lr:0.0009
[10:59:10.685] iteration:3151  t-loss:0.1418, loss-lb:0.1177, loss-ulb:0.0647, weight:0.37, lr:0.0009
[10:59:10.876] iteration:3152  t-loss:0.1136, loss-lb:0.0962, loss-ulb:0.0469, weight:0.37, lr:0.0009
[10:59:11.066] iteration:3153  t-loss:0.1160, loss-lb:0.1038, loss-ulb:0.0328, weight:0.37, lr:0.0009
[10:59:11.257] iteration:3154  t-loss:0.1200, loss-lb:0.1025, loss-ulb:0.0469, weight:0.37, lr:0.0009
[10:59:11.450] iteration:3155  t-loss:0.1180, loss-lb:0.0998, loss-ulb:0.0491, weight:0.37, lr:0.0009
[10:59:11.640] iteration:3156  t-loss:0.1047, loss-lb:0.0951, loss-ulb:0.0260, weight:0.37, lr:0.0009
[10:59:11.833] iteration:3157  t-loss:0.1163, loss-lb:0.0962, loss-ulb:0.0540, weight:0.37, lr:0.0009
[10:59:12.023] iteration:3158  t-loss:0.1165, loss-lb:0.1030, loss-ulb:0.0361, weight:0.37, lr:0.0009
[10:59:12.214] iteration:3159  t-loss:0.1165, loss-lb:0.1036, loss-ulb:0.0348, weight:0.37, lr:0.0009
[10:59:12.408] iteration:3160  t-loss:0.1035, loss-lb:0.0912, loss-ulb:0.0331, weight:0.37, lr:0.0009
[10:59:12.603] iteration:3161  t-loss:0.1246, loss-lb:0.0970, loss-ulb:0.0742, weight:0.37, lr:0.0009
[10:59:12.800] iteration:3162  t-loss:0.1184, loss-lb:0.0997, loss-ulb:0.0503, weight:0.37, lr:0.0009
[10:59:12.995] iteration:3163  t-loss:0.1260, loss-lb:0.1070, loss-ulb:0.0512, weight:0.37, lr:0.0009
[10:59:13.187] iteration:3164  t-loss:0.1245, loss-lb:0.1080, loss-ulb:0.0445, weight:0.37, lr:0.0009
[10:59:13.381] iteration:3165  t-loss:0.1075, loss-lb:0.0971, loss-ulb:0.0282, weight:0.37, lr:0.0009
[10:59:13.575] iteration:3166  t-loss:0.1218, loss-lb:0.0949, loss-ulb:0.0724, weight:0.37, lr:0.0009
[10:59:13.776] iteration:3167  t-loss:0.1239, loss-lb:0.1046, loss-ulb:0.0518, weight:0.37, lr:0.0009
[10:59:13.978] iteration:3168  t-loss:0.1417, loss-lb:0.1337, loss-ulb:0.0214, weight:0.37, lr:0.0009
[10:59:14.175] iteration:3169  t-loss:0.0962, loss-lb:0.0855, loss-ulb:0.0288, weight:0.37, lr:0.0009
[10:59:14.368] iteration:3170  t-loss:0.0970, loss-lb:0.0866, loss-ulb:0.0278, weight:0.37, lr:0.0009
[10:59:14.562] iteration:3171  t-loss:0.1204, loss-lb:0.0934, loss-ulb:0.0728, weight:0.37, lr:0.0009
[10:59:14.754] iteration:3172  t-loss:0.1082, loss-lb:0.0990, loss-ulb:0.0247, weight:0.37, lr:0.0009
[10:59:14.946] iteration:3173  t-loss:0.1079, loss-lb:0.0945, loss-ulb:0.0361, weight:0.37, lr:0.0009
[10:59:15.138] iteration:3174  t-loss:0.1327, loss-lb:0.0967, loss-ulb:0.0968, weight:0.37, lr:0.0009
[10:59:15.329] iteration:3175  t-loss:0.1092, loss-lb:0.0945, loss-ulb:0.0396, weight:0.37, lr:0.0009
[10:59:15.521] iteration:3176  t-loss:0.1176, loss-lb:0.1022, loss-ulb:0.0413, weight:0.37, lr:0.0009
[10:59:15.713] iteration:3177  t-loss:0.1083, loss-lb:0.0955, loss-ulb:0.0344, weight:0.37, lr:0.0009
[10:59:15.904] iteration:3178  t-loss:0.1444, loss-lb:0.1001, loss-ulb:0.1192, weight:0.37, lr:0.0009
[10:59:16.097] iteration:3179  t-loss:0.1340, loss-lb:0.1129, loss-ulb:0.0566, weight:0.37, lr:0.0009
[10:59:16.288] iteration:3180  t-loss:0.1308, loss-lb:0.1062, loss-ulb:0.0660, weight:0.37, lr:0.0009
[10:59:16.480] iteration:3181  t-loss:0.1199, loss-lb:0.0958, loss-ulb:0.0647, weight:0.37, lr:0.0009
[10:59:16.671] iteration:3182  t-loss:0.1022, loss-lb:0.0867, loss-ulb:0.0417, weight:0.37, lr:0.0009
[10:59:16.863] iteration:3183  t-loss:0.1169, loss-lb:0.1061, loss-ulb:0.0290, weight:0.37, lr:0.0009
[10:59:17.055] iteration:3184  t-loss:0.1095, loss-lb:0.0988, loss-ulb:0.0288, weight:0.37, lr:0.0009
[10:59:17.246] iteration:3185  t-loss:0.1300, loss-lb:0.1140, loss-ulb:0.0430, weight:0.37, lr:0.0009
[10:59:17.438] iteration:3186  t-loss:0.1166, loss-lb:0.1005, loss-ulb:0.0433, weight:0.37, lr:0.0009
[10:59:17.630] iteration:3187  t-loss:0.1455, loss-lb:0.1121, loss-ulb:0.0897, weight:0.37, lr:0.0009
[10:59:17.820] iteration:3188  t-loss:0.1168, loss-lb:0.1018, loss-ulb:0.0402, weight:0.37, lr:0.0009
[10:59:18.012] iteration:3189  t-loss:0.1553, loss-lb:0.1466, loss-ulb:0.0234, weight:0.37, lr:0.0009
[10:59:18.203] iteration:3190  t-loss:0.1251, loss-lb:0.1046, loss-ulb:0.0550, weight:0.37, lr:0.0009
[10:59:18.395] iteration:3191  t-loss:0.1098, loss-lb:0.0995, loss-ulb:0.0276, weight:0.37, lr:0.0009
[10:59:18.589] iteration:3192  t-loss:0.1169, loss-lb:0.1010, loss-ulb:0.0427, weight:0.37, lr:0.0009
[10:59:18.780] iteration:3193  t-loss:0.1399, loss-lb:0.1298, loss-ulb:0.0272, weight:0.37, lr:0.0009
[10:59:18.972] iteration:3194  t-loss:0.1397, loss-lb:0.1277, loss-ulb:0.0323, weight:0.37, lr:0.0009
[10:59:19.163] iteration:3195  t-loss:0.1492, loss-lb:0.1357, loss-ulb:0.0362, weight:0.37, lr:0.0009
[10:59:19.356] iteration:3196  t-loss:0.1224, loss-lb:0.1022, loss-ulb:0.0542, weight:0.37, lr:0.0009
[10:59:19.548] iteration:3197  t-loss:0.1229, loss-lb:0.1097, loss-ulb:0.0355, weight:0.37, lr:0.0009
[10:59:19.739] iteration:3198  t-loss:0.1118, loss-lb:0.0905, loss-ulb:0.0571, weight:0.37, lr:0.0009
[10:59:19.930] iteration:3199  t-loss:0.1486, loss-lb:0.1395, loss-ulb:0.0243, weight:0.37, lr:0.0009
[10:59:20.122] iteration:3200  t-loss:0.1285, loss-lb:0.1080, loss-ulb:0.0552, weight:0.37, lr:0.0009
[10:59:20.312] iteration:3201  t-loss:0.1366, loss-lb:0.1116, loss-ulb:0.0674, weight:0.37, lr:0.0009
[10:59:20.504] iteration:3202  t-loss:0.1153, loss-lb:0.1026, loss-ulb:0.0339, weight:0.37, lr:0.0009
[10:59:20.695] iteration:3203  t-loss:0.1225, loss-lb:0.0993, loss-ulb:0.0622, weight:0.37, lr:0.0009
[10:59:20.887] iteration:3204  t-loss:0.1165, loss-lb:0.1009, loss-ulb:0.0419, weight:0.37, lr:0.0009
[10:59:21.077] iteration:3205  t-loss:0.1230, loss-lb:0.1003, loss-ulb:0.0611, weight:0.37, lr:0.0009
[10:59:21.268] iteration:3206  t-loss:0.1151, loss-lb:0.1071, loss-ulb:0.0215, weight:0.37, lr:0.0009
[10:59:21.459] iteration:3207  t-loss:0.1349, loss-lb:0.1147, loss-ulb:0.0544, weight:0.37, lr:0.0009
[10:59:21.650] iteration:3208  t-loss:0.1284, loss-lb:0.1199, loss-ulb:0.0229, weight:0.37, lr:0.0009
[10:59:21.840] iteration:3209  t-loss:0.1205, loss-lb:0.1034, loss-ulb:0.0461, weight:0.37, lr:0.0009
[10:59:22.032] iteration:3210  t-loss:0.1373, loss-lb:0.1262, loss-ulb:0.0299, weight:0.37, lr:0.0009
[10:59:22.223] iteration:3211  t-loss:0.1180, loss-lb:0.0957, loss-ulb:0.0602, weight:0.37, lr:0.0009
[10:59:22.415] iteration:3212  t-loss:0.1207, loss-lb:0.1067, loss-ulb:0.0376, weight:0.37, lr:0.0009
[10:59:22.609] iteration:3213  t-loss:0.1307, loss-lb:0.1203, loss-ulb:0.0278, weight:0.37, lr:0.0009
[10:59:22.805] iteration:3214  t-loss:0.1293, loss-lb:0.1119, loss-ulb:0.0468, weight:0.37, lr:0.0009
[10:59:23.000] iteration:3215  t-loss:0.1311, loss-lb:0.1132, loss-ulb:0.0481, weight:0.37, lr:0.0009
[10:59:23.192] iteration:3216  t-loss:0.1274, loss-lb:0.1030, loss-ulb:0.0656, weight:0.37, lr:0.0009
[10:59:23.385] iteration:3217  t-loss:0.1198, loss-lb:0.1079, loss-ulb:0.0319, weight:0.37, lr:0.0009
[10:59:23.577] iteration:3218  t-loss:0.1255, loss-lb:0.1117, loss-ulb:0.0370, weight:0.37, lr:0.0009
[10:59:23.769] iteration:3219  t-loss:0.1276, loss-lb:0.1045, loss-ulb:0.0621, weight:0.37, lr:0.0009
[10:59:23.960] iteration:3220  t-loss:0.1073, loss-lb:0.0896, loss-ulb:0.0475, weight:0.37, lr:0.0009
[10:59:24.153] iteration:3221  t-loss:0.1125, loss-lb:0.1000, loss-ulb:0.0336, weight:0.37, lr:0.0009
[10:59:24.346] iteration:3222  t-loss:0.1098, loss-lb:0.0953, loss-ulb:0.0390, weight:0.37, lr:0.0009
[10:59:24.536] iteration:3223  t-loss:0.1331, loss-lb:0.1054, loss-ulb:0.0743, weight:0.37, lr:0.0009
[10:59:24.728] iteration:3224  t-loss:0.1086, loss-lb:0.0975, loss-ulb:0.0301, weight:0.37, lr:0.0009
[10:59:24.921] iteration:3225  t-loss:0.1679, loss-lb:0.1453, loss-ulb:0.0609, weight:0.37, lr:0.0009
[10:59:25.113] iteration:3226  t-loss:0.1212, loss-lb:0.0963, loss-ulb:0.0670, weight:0.37, lr:0.0009
[10:59:25.306] iteration:3227  t-loss:0.1422, loss-lb:0.1108, loss-ulb:0.0842, weight:0.37, lr:0.0009
[10:59:25.497] iteration:3228  t-loss:0.1169, loss-lb:0.1045, loss-ulb:0.0333, weight:0.37, lr:0.0009
[10:59:25.688] iteration:3229  t-loss:0.1439, loss-lb:0.1111, loss-ulb:0.0882, weight:0.37, lr:0.0009
[10:59:25.878] iteration:3230  t-loss:0.1164, loss-lb:0.0963, loss-ulb:0.0541, weight:0.37, lr:0.0009
[10:59:26.068] iteration:3231  t-loss:0.1149, loss-lb:0.1022, loss-ulb:0.0343, weight:0.37, lr:0.0009
[10:59:26.259] iteration:3232  t-loss:0.1150, loss-lb:0.0988, loss-ulb:0.0438, weight:0.37, lr:0.0009
[10:59:26.450] iteration:3233  t-loss:0.1444, loss-lb:0.1014, loss-ulb:0.1154, weight:0.37, lr:0.0009
[10:59:26.641] iteration:3234  t-loss:0.1157, loss-lb:0.1062, loss-ulb:0.0255, weight:0.37, lr:0.0009
[10:59:37.376]  <<Test>> - Ep:32  - mean_dice/mean_h95 - S:85.82/15.40, Best-S:88.90, T:89.38/2.63, Best-T:89.52
[10:59:37.376]           - AvgLoss(lb/ulb/all):0.1053/0.0538/0.1251
[10:59:37.919] iteration:3235  t-loss:0.1461, loss-lb:0.1230, loss-ulb:0.0621, weight:0.37, lr:0.0009
[10:59:38.116] iteration:3236  t-loss:0.1322, loss-lb:0.1144, loss-ulb:0.0481, weight:0.37, lr:0.0009
[10:59:38.308] iteration:3237  t-loss:0.1077, loss-lb:0.0963, loss-ulb:0.0306, weight:0.37, lr:0.0009
[10:59:38.501] iteration:3238  t-loss:0.1261, loss-lb:0.1153, loss-ulb:0.0289, weight:0.37, lr:0.0009
[10:59:38.695] iteration:3239  t-loss:0.1141, loss-lb:0.1051, loss-ulb:0.0244, weight:0.37, lr:0.0009
[10:59:38.887] iteration:3240  t-loss:0.1135, loss-lb:0.0986, loss-ulb:0.0398, weight:0.37, lr:0.0009
[10:59:39.078] iteration:3241  t-loss:0.1410, loss-lb:0.1252, loss-ulb:0.0425, weight:0.37, lr:0.0009
[10:59:39.270] iteration:3242  t-loss:0.1341, loss-lb:0.1091, loss-ulb:0.0673, weight:0.37, lr:0.0009
[10:59:39.463] iteration:3243  t-loss:0.1105, loss-lb:0.0997, loss-ulb:0.0290, weight:0.37, lr:0.0009
[10:59:39.655] iteration:3244  t-loss:0.1123, loss-lb:0.0982, loss-ulb:0.0379, weight:0.37, lr:0.0009
[10:59:39.847] iteration:3245  t-loss:0.1210, loss-lb:0.1058, loss-ulb:0.0408, weight:0.37, lr:0.0009
[10:59:40.039] iteration:3246  t-loss:0.1236, loss-lb:0.1114, loss-ulb:0.0328, weight:0.37, lr:0.0009
[10:59:40.230] iteration:3247  t-loss:0.1144, loss-lb:0.1045, loss-ulb:0.0267, weight:0.37, lr:0.0009
[10:59:40.423] iteration:3248  t-loss:0.1396, loss-lb:0.1278, loss-ulb:0.0318, weight:0.37, lr:0.0009
[10:59:40.615] iteration:3249  t-loss:0.1188, loss-lb:0.1092, loss-ulb:0.0258, weight:0.37, lr:0.0009
[10:59:40.806] iteration:3250  t-loss:0.1270, loss-lb:0.1124, loss-ulb:0.0394, weight:0.37, lr:0.0009
[10:59:40.999] iteration:3251  t-loss:0.1289, loss-lb:0.1119, loss-ulb:0.0457, weight:0.37, lr:0.0009
[10:59:41.191] iteration:3252  t-loss:0.1510, loss-lb:0.1222, loss-ulb:0.0774, weight:0.37, lr:0.0009
[10:59:41.383] iteration:3253  t-loss:0.1710, loss-lb:0.1404, loss-ulb:0.0822, weight:0.37, lr:0.0009
[10:59:41.576] iteration:3254  t-loss:0.1483, loss-lb:0.1300, loss-ulb:0.0492, weight:0.37, lr:0.0009
[10:59:41.768] iteration:3255  t-loss:0.1291, loss-lb:0.1032, loss-ulb:0.0698, weight:0.37, lr:0.0009
[10:59:41.961] iteration:3256  t-loss:0.1421, loss-lb:0.1313, loss-ulb:0.0290, weight:0.37, lr:0.0009
[10:59:42.152] iteration:3257  t-loss:0.1335, loss-lb:0.1219, loss-ulb:0.0312, weight:0.37, lr:0.0009
[10:59:42.343] iteration:3258  t-loss:0.1435, loss-lb:0.1160, loss-ulb:0.0738, weight:0.37, lr:0.0009
[10:59:42.535] iteration:3259  t-loss:0.1294, loss-lb:0.1110, loss-ulb:0.0495, weight:0.37, lr:0.0009
[10:59:42.728] iteration:3260  t-loss:0.1374, loss-lb:0.1219, loss-ulb:0.0416, weight:0.37, lr:0.0009
[10:59:42.920] iteration:3261  t-loss:0.1538, loss-lb:0.1183, loss-ulb:0.0954, weight:0.37, lr:0.0009
[10:59:43.113] iteration:3262  t-loss:0.1798, loss-lb:0.1502, loss-ulb:0.0794, weight:0.37, lr:0.0009
[10:59:43.306] iteration:3263  t-loss:0.1399, loss-lb:0.1164, loss-ulb:0.0632, weight:0.37, lr:0.0009
[10:59:43.499] iteration:3264  t-loss:0.1283, loss-lb:0.1119, loss-ulb:0.0439, weight:0.37, lr:0.0009
[10:59:43.690] iteration:3265  t-loss:0.1172, loss-lb:0.1002, loss-ulb:0.0457, weight:0.37, lr:0.0009
[10:59:43.883] iteration:3266  t-loss:0.1648, loss-lb:0.1256, loss-ulb:0.1054, weight:0.37, lr:0.0009
[10:59:44.076] iteration:3267  t-loss:0.1361, loss-lb:0.1142, loss-ulb:0.0588, weight:0.37, lr:0.0009
[10:59:44.267] iteration:3268  t-loss:0.1264, loss-lb:0.1013, loss-ulb:0.0674, weight:0.37, lr:0.0009
[10:59:44.459] iteration:3269  t-loss:0.1162, loss-lb:0.1036, loss-ulb:0.0339, weight:0.37, lr:0.0009
[10:59:44.652] iteration:3270  t-loss:0.1276, loss-lb:0.1154, loss-ulb:0.0326, weight:0.37, lr:0.0009
[10:59:44.843] iteration:3271  t-loss:0.1331, loss-lb:0.1210, loss-ulb:0.0325, weight:0.37, lr:0.0009
[10:59:45.035] iteration:3272  t-loss:0.1287, loss-lb:0.1025, loss-ulb:0.0702, weight:0.37, lr:0.0009
[10:59:45.227] iteration:3273  t-loss:0.1235, loss-lb:0.1089, loss-ulb:0.0393, weight:0.37, lr:0.0009
[10:59:45.418] iteration:3274  t-loss:0.1291, loss-lb:0.1115, loss-ulb:0.0472, weight:0.37, lr:0.0009
[10:59:45.610] iteration:3275  t-loss:0.1261, loss-lb:0.1147, loss-ulb:0.0305, weight:0.37, lr:0.0009
[10:59:45.802] iteration:3276  t-loss:0.1306, loss-lb:0.1124, loss-ulb:0.0489, weight:0.37, lr:0.0009
[10:59:45.995] iteration:3277  t-loss:0.1577, loss-lb:0.1329, loss-ulb:0.0667, weight:0.37, lr:0.0009
[10:59:46.187] iteration:3278  t-loss:0.1067, loss-lb:0.0939, loss-ulb:0.0343, weight:0.37, lr:0.0009
[10:59:46.379] iteration:3279  t-loss:0.1267, loss-lb:0.1131, loss-ulb:0.0365, weight:0.37, lr:0.0009
[10:59:46.580] iteration:3280  t-loss:0.1119, loss-lb:0.1002, loss-ulb:0.0313, weight:0.37, lr:0.0009
[10:59:46.778] iteration:3281  t-loss:0.1204, loss-lb:0.1058, loss-ulb:0.0391, weight:0.37, lr:0.0009
[10:59:46.970] iteration:3282  t-loss:0.1208, loss-lb:0.0984, loss-ulb:0.0602, weight:0.37, lr:0.0009
[10:59:47.162] iteration:3283  t-loss:0.1258, loss-lb:0.1132, loss-ulb:0.0340, weight:0.37, lr:0.0009
[10:59:47.355] iteration:3284  t-loss:0.1455, loss-lb:0.1139, loss-ulb:0.0847, weight:0.37, lr:0.0009
[10:59:47.547] iteration:3285  t-loss:0.1174, loss-lb:0.0986, loss-ulb:0.0506, weight:0.37, lr:0.0009
[10:59:47.739] iteration:3286  t-loss:0.1190, loss-lb:0.1084, loss-ulb:0.0285, weight:0.37, lr:0.0009
[10:59:47.931] iteration:3287  t-loss:0.1474, loss-lb:0.1341, loss-ulb:0.0356, weight:0.37, lr:0.0009
[10:59:48.122] iteration:3288  t-loss:0.1171, loss-lb:0.0962, loss-ulb:0.0561, weight:0.37, lr:0.0009
[10:59:48.314] iteration:3289  t-loss:0.1232, loss-lb:0.1019, loss-ulb:0.0574, weight:0.37, lr:0.0009
[10:59:48.508] iteration:3290  t-loss:0.1478, loss-lb:0.1269, loss-ulb:0.0562, weight:0.37, lr:0.0009
[10:59:48.700] iteration:3291  t-loss:0.1231, loss-lb:0.1070, loss-ulb:0.0431, weight:0.37, lr:0.0009
[10:59:48.892] iteration:3292  t-loss:0.1212, loss-lb:0.1046, loss-ulb:0.0448, weight:0.37, lr:0.0009
[10:59:49.085] iteration:3293  t-loss:0.1285, loss-lb:0.1164, loss-ulb:0.0325, weight:0.37, lr:0.0009
[10:59:49.278] iteration:3294  t-loss:0.1261, loss-lb:0.1121, loss-ulb:0.0376, weight:0.37, lr:0.0009
[10:59:49.469] iteration:3295  t-loss:0.1179, loss-lb:0.0977, loss-ulb:0.0542, weight:0.37, lr:0.0009
[10:59:49.662] iteration:3296  t-loss:0.1129, loss-lb:0.0933, loss-ulb:0.0526, weight:0.37, lr:0.0009
[10:59:49.854] iteration:3297  t-loss:0.1219, loss-lb:0.1041, loss-ulb:0.0477, weight:0.37, lr:0.0009
[10:59:50.045] iteration:3298  t-loss:0.1346, loss-lb:0.1253, loss-ulb:0.0251, weight:0.37, lr:0.0009
[10:59:50.238] iteration:3299  t-loss:0.1297, loss-lb:0.1202, loss-ulb:0.0256, weight:0.37, lr:0.0009
[10:59:50.430] iteration:3300  t-loss:0.1323, loss-lb:0.1068, loss-ulb:0.0686, weight:0.37, lr:0.0009
[10:59:50.622] iteration:3301  t-loss:0.1218, loss-lb:0.1071, loss-ulb:0.0352, weight:0.42, lr:0.0009
[10:59:50.815] iteration:3302  t-loss:0.1351, loss-lb:0.1202, loss-ulb:0.0359, weight:0.42, lr:0.0009
[10:59:51.006] iteration:3303  t-loss:0.1088, loss-lb:0.0946, loss-ulb:0.0341, weight:0.42, lr:0.0009
[10:59:51.198] iteration:3304  t-loss:0.1175, loss-lb:0.1027, loss-ulb:0.0355, weight:0.42, lr:0.0009
[10:59:51.390] iteration:3305  t-loss:0.1187, loss-lb:0.0991, loss-ulb:0.0470, weight:0.42, lr:0.0009
[10:59:51.582] iteration:3306  t-loss:0.1127, loss-lb:0.0985, loss-ulb:0.0339, weight:0.42, lr:0.0009
[10:59:51.774] iteration:3307  t-loss:0.1202, loss-lb:0.1063, loss-ulb:0.0334, weight:0.42, lr:0.0009
[10:59:51.966] iteration:3308  t-loss:0.1407, loss-lb:0.1160, loss-ulb:0.0592, weight:0.42, lr:0.0009
[10:59:52.157] iteration:3309  t-loss:0.1150, loss-lb:0.1035, loss-ulb:0.0275, weight:0.42, lr:0.0009
[10:59:52.350] iteration:3310  t-loss:0.1352, loss-lb:0.1157, loss-ulb:0.0467, weight:0.42, lr:0.0009
[10:59:52.542] iteration:3311  t-loss:0.1226, loss-lb:0.1088, loss-ulb:0.0330, weight:0.42, lr:0.0009
[10:59:52.734] iteration:3312  t-loss:0.1201, loss-lb:0.1039, loss-ulb:0.0388, weight:0.42, lr:0.0009
[10:59:52.927] iteration:3313  t-loss:0.1161, loss-lb:0.1036, loss-ulb:0.0300, weight:0.42, lr:0.0009
[10:59:53.119] iteration:3314  t-loss:0.1230, loss-lb:0.1109, loss-ulb:0.0290, weight:0.42, lr:0.0009
[10:59:53.311] iteration:3315  t-loss:0.1148, loss-lb:0.0902, loss-ulb:0.0590, weight:0.42, lr:0.0009
[10:59:53.503] iteration:3316  t-loss:0.1256, loss-lb:0.1136, loss-ulb:0.0289, weight:0.42, lr:0.0009
[10:59:53.696] iteration:3317  t-loss:0.1252, loss-lb:0.1113, loss-ulb:0.0335, weight:0.42, lr:0.0009
[10:59:53.889] iteration:3318  t-loss:0.1099, loss-lb:0.0963, loss-ulb:0.0327, weight:0.42, lr:0.0009
[10:59:54.080] iteration:3319  t-loss:0.1198, loss-lb:0.1006, loss-ulb:0.0462, weight:0.42, lr:0.0009
[10:59:54.273] iteration:3320  t-loss:0.1051, loss-lb:0.0890, loss-ulb:0.0386, weight:0.42, lr:0.0009
[10:59:54.466] iteration:3321  t-loss:0.1104, loss-lb:0.0989, loss-ulb:0.0277, weight:0.42, lr:0.0009
[10:59:54.658] iteration:3322  t-loss:0.1308, loss-lb:0.0961, loss-ulb:0.0831, weight:0.42, lr:0.0009
[10:59:54.850] iteration:3323  t-loss:0.1104, loss-lb:0.1011, loss-ulb:0.0224, weight:0.42, lr:0.0009
[10:59:55.042] iteration:3324  t-loss:0.1317, loss-lb:0.1070, loss-ulb:0.0591, weight:0.42, lr:0.0009
[10:59:55.233] iteration:3325  t-loss:0.1223, loss-lb:0.1084, loss-ulb:0.0332, weight:0.42, lr:0.0009
[10:59:55.424] iteration:3326  t-loss:0.1225, loss-lb:0.1003, loss-ulb:0.0533, weight:0.42, lr:0.0009
[10:59:55.614] iteration:3327  t-loss:0.1217, loss-lb:0.1065, loss-ulb:0.0364, weight:0.42, lr:0.0009
[10:59:55.806] iteration:3328  t-loss:0.1167, loss-lb:0.1028, loss-ulb:0.0335, weight:0.42, lr:0.0009
[10:59:55.996] iteration:3329  t-loss:0.1404, loss-lb:0.0932, loss-ulb:0.1132, weight:0.42, lr:0.0009
[10:59:56.188] iteration:3330  t-loss:0.1248, loss-lb:0.0960, loss-ulb:0.0692, weight:0.42, lr:0.0009
[10:59:56.377] iteration:3331  t-loss:0.1181, loss-lb:0.1044, loss-ulb:0.0330, weight:0.42, lr:0.0009
[10:59:56.567] iteration:3332  t-loss:0.1095, loss-lb:0.0960, loss-ulb:0.0323, weight:0.42, lr:0.0009
[10:59:57.143] iteration:3333  t-loss:0.1034, loss-lb:0.0906, loss-ulb:0.0306, weight:0.42, lr:0.0009
[10:59:57.338] iteration:3334  t-loss:0.1510, loss-lb:0.1146, loss-ulb:0.0873, weight:0.42, lr:0.0009
[10:59:57.530] iteration:3335  t-loss:0.1157, loss-lb:0.0967, loss-ulb:0.0457, weight:0.42, lr:0.0009
[10:59:57.722] iteration:3336  t-loss:0.1149, loss-lb:0.1040, loss-ulb:0.0261, weight:0.42, lr:0.0009
[10:59:57.914] iteration:3337  t-loss:0.1097, loss-lb:0.1005, loss-ulb:0.0221, weight:0.42, lr:0.0009
[10:59:58.106] iteration:3338  t-loss:0.1250, loss-lb:0.0983, loss-ulb:0.0639, weight:0.42, lr:0.0009
[10:59:58.298] iteration:3339  t-loss:0.1190, loss-lb:0.1083, loss-ulb:0.0255, weight:0.42, lr:0.0009
[10:59:58.489] iteration:3340  t-loss:0.1221, loss-lb:0.1058, loss-ulb:0.0393, weight:0.42, lr:0.0009
[10:59:58.681] iteration:3341  t-loss:0.1144, loss-lb:0.1011, loss-ulb:0.0320, weight:0.42, lr:0.0009
[10:59:58.873] iteration:3342  t-loss:0.1120, loss-lb:0.0980, loss-ulb:0.0336, weight:0.42, lr:0.0009
[10:59:59.065] iteration:3343  t-loss:0.1009, loss-lb:0.0905, loss-ulb:0.0249, weight:0.42, lr:0.0009
[10:59:59.256] iteration:3344  t-loss:0.1210, loss-lb:0.0970, loss-ulb:0.0575, weight:0.42, lr:0.0009
[10:59:59.449] iteration:3345  t-loss:0.1660, loss-lb:0.1060, loss-ulb:0.1438, weight:0.42, lr:0.0009
[10:59:59.641] iteration:3346  t-loss:0.1374, loss-lb:0.1124, loss-ulb:0.0599, weight:0.42, lr:0.0009
[10:59:59.832] iteration:3347  t-loss:0.1131, loss-lb:0.0967, loss-ulb:0.0392, weight:0.42, lr:0.0009
[11:00:00.025] iteration:3348  t-loss:0.1119, loss-lb:0.0957, loss-ulb:0.0389, weight:0.42, lr:0.0009
[11:00:00.216] iteration:3349  t-loss:0.1279, loss-lb:0.1077, loss-ulb:0.0485, weight:0.42, lr:0.0009
[11:00:00.408] iteration:3350  t-loss:0.1179, loss-lb:0.1030, loss-ulb:0.0356, weight:0.42, lr:0.0009
[11:00:00.601] iteration:3351  t-loss:0.1250, loss-lb:0.1006, loss-ulb:0.0585, weight:0.42, lr:0.0009
[11:00:00.793] iteration:3352  t-loss:0.1121, loss-lb:0.0938, loss-ulb:0.0438, weight:0.42, lr:0.0009
[11:00:00.984] iteration:3353  t-loss:0.1204, loss-lb:0.0985, loss-ulb:0.0525, weight:0.42, lr:0.0009
[11:00:01.176] iteration:3354  t-loss:0.1175, loss-lb:0.1028, loss-ulb:0.0352, weight:0.42, lr:0.0009
[11:00:01.369] iteration:3355  t-loss:0.1066, loss-lb:0.0949, loss-ulb:0.0281, weight:0.42, lr:0.0009
[11:00:01.560] iteration:3356  t-loss:0.1075, loss-lb:0.0922, loss-ulb:0.0368, weight:0.42, lr:0.0009
[11:00:01.752] iteration:3357  t-loss:0.1170, loss-lb:0.1022, loss-ulb:0.0354, weight:0.42, lr:0.0009
[11:00:01.944] iteration:3358  t-loss:0.1199, loss-lb:0.1088, loss-ulb:0.0268, weight:0.42, lr:0.0009
[11:00:02.136] iteration:3359  t-loss:0.1221, loss-lb:0.1046, loss-ulb:0.0420, weight:0.42, lr:0.0009
[11:00:02.327] iteration:3360  t-loss:0.1299, loss-lb:0.1002, loss-ulb:0.0711, weight:0.42, lr:0.0009
[11:00:02.520] iteration:3361  t-loss:0.1185, loss-lb:0.1023, loss-ulb:0.0389, weight:0.42, lr:0.0009
[11:00:02.712] iteration:3362  t-loss:0.1376, loss-lb:0.1220, loss-ulb:0.0374, weight:0.42, lr:0.0009
[11:00:02.904] iteration:3363  t-loss:0.1077, loss-lb:0.0945, loss-ulb:0.0315, weight:0.42, lr:0.0009
[11:00:03.096] iteration:3364  t-loss:0.1335, loss-lb:0.1200, loss-ulb:0.0323, weight:0.42, lr:0.0009
[11:00:03.289] iteration:3365  t-loss:0.1275, loss-lb:0.1094, loss-ulb:0.0433, weight:0.42, lr:0.0009
[11:00:03.480] iteration:3366  t-loss:0.1208, loss-lb:0.1081, loss-ulb:0.0304, weight:0.42, lr:0.0009
[11:00:03.673] iteration:3367  t-loss:0.1082, loss-lb:0.0973, loss-ulb:0.0260, weight:0.42, lr:0.0009
[11:00:03.865] iteration:3368  t-loss:0.1144, loss-lb:0.0942, loss-ulb:0.0486, weight:0.42, lr:0.0009
[11:00:04.056] iteration:3369  t-loss:0.1343, loss-lb:0.1173, loss-ulb:0.0409, weight:0.42, lr:0.0009
[11:00:04.248] iteration:3370  t-loss:0.1170, loss-lb:0.1054, loss-ulb:0.0277, weight:0.42, lr:0.0009
[11:00:04.442] iteration:3371  t-loss:0.1209, loss-lb:0.1031, loss-ulb:0.0427, weight:0.42, lr:0.0009
[11:00:04.634] iteration:3372  t-loss:0.1607, loss-lb:0.1122, loss-ulb:0.1162, weight:0.42, lr:0.0009
[11:00:04.826] iteration:3373  t-loss:0.1312, loss-lb:0.1030, loss-ulb:0.0678, weight:0.42, lr:0.0009
[11:00:05.019] iteration:3374  t-loss:0.1216, loss-lb:0.1015, loss-ulb:0.0482, weight:0.42, lr:0.0009
[11:00:05.212] iteration:3375  t-loss:0.1259, loss-lb:0.1025, loss-ulb:0.0563, weight:0.42, lr:0.0009
[11:00:05.403] iteration:3376  t-loss:0.1446, loss-lb:0.1314, loss-ulb:0.0315, weight:0.42, lr:0.0009
[11:00:05.595] iteration:3377  t-loss:0.1194, loss-lb:0.0982, loss-ulb:0.0508, weight:0.42, lr:0.0009
[11:00:05.787] iteration:3378  t-loss:0.1258, loss-lb:0.1043, loss-ulb:0.0515, weight:0.42, lr:0.0009
[11:00:05.980] iteration:3379  t-loss:0.1184, loss-lb:0.1061, loss-ulb:0.0296, weight:0.42, lr:0.0009
[11:00:06.172] iteration:3380  t-loss:0.1577, loss-lb:0.1066, loss-ulb:0.1225, weight:0.42, lr:0.0009
[11:00:06.363] iteration:3381  t-loss:0.1179, loss-lb:0.1060, loss-ulb:0.0286, weight:0.42, lr:0.0009
[11:00:06.556] iteration:3382  t-loss:0.1156, loss-lb:0.1009, loss-ulb:0.0352, weight:0.42, lr:0.0009
[11:00:06.747] iteration:3383  t-loss:0.1191, loss-lb:0.1033, loss-ulb:0.0380, weight:0.42, lr:0.0009
[11:00:06.938] iteration:3384  t-loss:0.1340, loss-lb:0.1104, loss-ulb:0.0567, weight:0.42, lr:0.0009
[11:00:07.131] iteration:3385  t-loss:0.1432, loss-lb:0.1135, loss-ulb:0.0712, weight:0.42, lr:0.0009
[11:00:07.322] iteration:3386  t-loss:0.1117, loss-lb:0.0968, loss-ulb:0.0357, weight:0.42, lr:0.0009
[11:00:07.514] iteration:3387  t-loss:0.1465, loss-lb:0.1316, loss-ulb:0.0358, weight:0.42, lr:0.0009
[11:00:07.706] iteration:3388  t-loss:0.1271, loss-lb:0.1161, loss-ulb:0.0264, weight:0.42, lr:0.0009
[11:00:07.898] iteration:3389  t-loss:0.1114, loss-lb:0.0983, loss-ulb:0.0314, weight:0.42, lr:0.0009
[11:00:08.090] iteration:3390  t-loss:0.1114, loss-lb:0.1009, loss-ulb:0.0253, weight:0.42, lr:0.0009
[11:00:08.282] iteration:3391  t-loss:0.1253, loss-lb:0.1072, loss-ulb:0.0434, weight:0.42, lr:0.0009
[11:00:08.473] iteration:3392  t-loss:0.1062, loss-lb:0.0936, loss-ulb:0.0303, weight:0.42, lr:0.0009
[11:00:08.665] iteration:3393  t-loss:0.1253, loss-lb:0.1143, loss-ulb:0.0264, weight:0.42, lr:0.0009
[11:00:08.858] iteration:3394  t-loss:0.1110, loss-lb:0.1001, loss-ulb:0.0264, weight:0.42, lr:0.0009
[11:00:09.049] iteration:3395  t-loss:0.1371, loss-lb:0.1149, loss-ulb:0.0534, weight:0.42, lr:0.0009
[11:00:09.242] iteration:3396  t-loss:0.1083, loss-lb:0.0966, loss-ulb:0.0280, weight:0.42, lr:0.0009
[11:00:09.433] iteration:3397  t-loss:0.1126, loss-lb:0.1005, loss-ulb:0.0290, weight:0.42, lr:0.0009
[11:00:09.626] iteration:3398  t-loss:0.1259, loss-lb:0.1153, loss-ulb:0.0253, weight:0.42, lr:0.0009
[11:00:09.818] iteration:3399  t-loss:0.1416, loss-lb:0.1270, loss-ulb:0.0350, weight:0.42, lr:0.0009
[11:00:10.011] iteration:3400  t-loss:0.1435, loss-lb:0.1287, loss-ulb:0.0356, weight:0.42, lr:0.0009
[11:00:10.203] iteration:3401  t-loss:0.1087, loss-lb:0.0982, loss-ulb:0.0252, weight:0.42, lr:0.0009
[11:00:10.396] iteration:3402  t-loss:0.1399, loss-lb:0.1021, loss-ulb:0.0906, weight:0.42, lr:0.0009
[11:00:10.588] iteration:3403  t-loss:0.1059, loss-lb:0.0937, loss-ulb:0.0292, weight:0.42, lr:0.0009
[11:00:10.780] iteration:3404  t-loss:0.1526, loss-lb:0.1408, loss-ulb:0.0283, weight:0.42, lr:0.0009
[11:00:10.973] iteration:3405  t-loss:0.1422, loss-lb:0.1017, loss-ulb:0.0971, weight:0.42, lr:0.0009
[11:00:11.165] iteration:3406  t-loss:0.1265, loss-lb:0.1100, loss-ulb:0.0397, weight:0.42, lr:0.0009
[11:00:11.357] iteration:3407  t-loss:0.1118, loss-lb:0.0919, loss-ulb:0.0478, weight:0.42, lr:0.0009
[11:00:11.548] iteration:3408  t-loss:0.1670, loss-lb:0.1531, loss-ulb:0.0333, weight:0.42, lr:0.0009
[11:00:11.741] iteration:3409  t-loss:0.1241, loss-lb:0.1076, loss-ulb:0.0395, weight:0.42, lr:0.0009
[11:00:11.934] iteration:3410  t-loss:0.1119, loss-lb:0.0947, loss-ulb:0.0413, weight:0.42, lr:0.0009
[11:00:12.125] iteration:3411  t-loss:0.1298, loss-lb:0.1133, loss-ulb:0.0395, weight:0.42, lr:0.0009
[11:00:12.317] iteration:3412  t-loss:0.1448, loss-lb:0.1014, loss-ulb:0.1040, weight:0.42, lr:0.0009
[11:00:12.510] iteration:3413  t-loss:0.1583, loss-lb:0.1083, loss-ulb:0.1199, weight:0.42, lr:0.0009
[11:00:12.701] iteration:3414  t-loss:0.1232, loss-lb:0.1072, loss-ulb:0.0384, weight:0.42, lr:0.0009
[11:00:12.894] iteration:3415  t-loss:0.1214, loss-lb:0.1120, loss-ulb:0.0227, weight:0.42, lr:0.0009
[11:00:13.086] iteration:3416  t-loss:0.1433, loss-lb:0.1124, loss-ulb:0.0741, weight:0.42, lr:0.0009
[11:00:13.279] iteration:3417  t-loss:0.1218, loss-lb:0.1088, loss-ulb:0.0311, weight:0.42, lr:0.0009
[11:00:13.471] iteration:3418  t-loss:0.1193, loss-lb:0.1019, loss-ulb:0.0418, weight:0.42, lr:0.0009
[11:00:13.664] iteration:3419  t-loss:0.1320, loss-lb:0.1173, loss-ulb:0.0354, weight:0.42, lr:0.0009
[11:00:13.856] iteration:3420  t-loss:0.1184, loss-lb:0.1033, loss-ulb:0.0361, weight:0.42, lr:0.0009
[11:00:14.048] iteration:3421  t-loss:0.1272, loss-lb:0.1132, loss-ulb:0.0336, weight:0.42, lr:0.0009
[11:00:14.240] iteration:3422  t-loss:0.1068, loss-lb:0.0945, loss-ulb:0.0296, weight:0.42, lr:0.0009
[11:00:14.430] iteration:3423  t-loss:0.1259, loss-lb:0.1081, loss-ulb:0.0427, weight:0.42, lr:0.0009
[11:00:14.621] iteration:3424  t-loss:0.1218, loss-lb:0.1089, loss-ulb:0.0310, weight:0.42, lr:0.0009
[11:00:14.811] iteration:3425  t-loss:0.1119, loss-lb:0.0969, loss-ulb:0.0359, weight:0.42, lr:0.0009
[11:00:15.001] iteration:3426  t-loss:0.1185, loss-lb:0.1035, loss-ulb:0.0358, weight:0.42, lr:0.0009
[11:00:15.191] iteration:3427  t-loss:0.1324, loss-lb:0.1109, loss-ulb:0.0515, weight:0.42, lr:0.0009
[11:00:15.382] iteration:3428  t-loss:0.1091, loss-lb:0.0977, loss-ulb:0.0272, weight:0.42, lr:0.0009
[11:00:15.572] iteration:3429  t-loss:0.1143, loss-lb:0.0976, loss-ulb:0.0401, weight:0.42, lr:0.0009
[11:00:15.763] iteration:3430  t-loss:0.1307, loss-lb:0.1163, loss-ulb:0.0344, weight:0.42, lr:0.0009
[11:00:27.930]  <<Test>> - Ep:34  - mean_dice/mean_h95 - S:89.21/1.59, Best-S:89.21, T:89.54/2.08, Best-T:89.54
[11:00:27.930]           - AvgLoss(lb/ulb/all):0.1058/0.0452/0.1255
[11:00:28.464] iteration:3431  t-loss:0.1079, loss-lb:0.0949, loss-ulb:0.0312, weight:0.42, lr:0.0009
[11:00:28.662] iteration:3432  t-loss:0.1158, loss-lb:0.0949, loss-ulb:0.0501, weight:0.42, lr:0.0009
[11:00:28.855] iteration:3433  t-loss:0.1175, loss-lb:0.1018, loss-ulb:0.0377, weight:0.42, lr:0.0009
[11:00:29.054] iteration:3434  t-loss:0.1160, loss-lb:0.1048, loss-ulb:0.0268, weight:0.42, lr:0.0009
[11:00:29.248] iteration:3435  t-loss:0.1155, loss-lb:0.0996, loss-ulb:0.0381, weight:0.42, lr:0.0009
[11:00:29.439] iteration:3436  t-loss:0.1124, loss-lb:0.0983, loss-ulb:0.0339, weight:0.42, lr:0.0009
[11:00:29.631] iteration:3437  t-loss:0.1245, loss-lb:0.1096, loss-ulb:0.0358, weight:0.42, lr:0.0009
[11:00:29.823] iteration:3438  t-loss:0.1275, loss-lb:0.1043, loss-ulb:0.0557, weight:0.42, lr:0.0009
[11:00:30.015] iteration:3439  t-loss:0.1158, loss-lb:0.0976, loss-ulb:0.0436, weight:0.42, lr:0.0009
[11:00:30.206] iteration:3440  t-loss:0.1324, loss-lb:0.1175, loss-ulb:0.0356, weight:0.42, lr:0.0009
[11:00:30.399] iteration:3441  t-loss:0.1433, loss-lb:0.0984, loss-ulb:0.1078, weight:0.42, lr:0.0009
[11:00:30.592] iteration:3442  t-loss:0.1225, loss-lb:0.1123, loss-ulb:0.0244, weight:0.42, lr:0.0009
[11:00:30.785] iteration:3443  t-loss:0.0987, loss-lb:0.0892, loss-ulb:0.0229, weight:0.42, lr:0.0009
[11:00:30.975] iteration:3444  t-loss:0.1178, loss-lb:0.1080, loss-ulb:0.0235, weight:0.42, lr:0.0009
[11:00:31.169] iteration:3445  t-loss:0.1162, loss-lb:0.1026, loss-ulb:0.0328, weight:0.42, lr:0.0009
[11:00:31.362] iteration:3446  t-loss:0.1154, loss-lb:0.0984, loss-ulb:0.0407, weight:0.42, lr:0.0009
[11:00:31.553] iteration:3447  t-loss:0.1162, loss-lb:0.1034, loss-ulb:0.0306, weight:0.42, lr:0.0009
[11:00:31.746] iteration:3448  t-loss:0.1259, loss-lb:0.1075, loss-ulb:0.0443, weight:0.42, lr:0.0009
[11:00:31.937] iteration:3449  t-loss:0.1113, loss-lb:0.1004, loss-ulb:0.0261, weight:0.42, lr:0.0009
[11:00:32.128] iteration:3450  t-loss:0.1109, loss-lb:0.0967, loss-ulb:0.0340, weight:0.42, lr:0.0009
[11:00:32.320] iteration:3451  t-loss:0.1178, loss-lb:0.0993, loss-ulb:0.0397, weight:0.47, lr:0.0009
[11:00:32.512] iteration:3452  t-loss:0.1340, loss-lb:0.1072, loss-ulb:0.0577, weight:0.47, lr:0.0009
[11:00:32.703] iteration:3453  t-loss:0.1081, loss-lb:0.0979, loss-ulb:0.0221, weight:0.47, lr:0.0009
[11:00:32.895] iteration:3454  t-loss:0.1034, loss-lb:0.0923, loss-ulb:0.0239, weight:0.47, lr:0.0009
[11:00:33.085] iteration:3455  t-loss:0.1198, loss-lb:0.1053, loss-ulb:0.0311, weight:0.47, lr:0.0009
[11:00:33.278] iteration:3456  t-loss:0.1931, loss-lb:0.1030, loss-ulb:0.1935, weight:0.47, lr:0.0009
[11:00:33.469] iteration:3457  t-loss:0.1394, loss-lb:0.1037, loss-ulb:0.0766, weight:0.47, lr:0.0009
[11:00:33.660] iteration:3458  t-loss:0.1067, loss-lb:0.0894, loss-ulb:0.0371, weight:0.47, lr:0.0009
[11:00:33.852] iteration:3459  t-loss:0.1148, loss-lb:0.0949, loss-ulb:0.0427, weight:0.47, lr:0.0009
[11:00:34.043] iteration:3460  t-loss:0.1170, loss-lb:0.0997, loss-ulb:0.0372, weight:0.47, lr:0.0009
[11:00:34.237] iteration:3461  t-loss:0.1226, loss-lb:0.1050, loss-ulb:0.0378, weight:0.47, lr:0.0009
[11:00:34.432] iteration:3462  t-loss:0.1170, loss-lb:0.1010, loss-ulb:0.0343, weight:0.47, lr:0.0009
[11:00:34.629] iteration:3463  t-loss:0.1230, loss-lb:0.1015, loss-ulb:0.0462, weight:0.47, lr:0.0009
[11:00:34.825] iteration:3464  t-loss:0.1271, loss-lb:0.1024, loss-ulb:0.0531, weight:0.47, lr:0.0009
[11:00:35.020] iteration:3465  t-loss:0.1183, loss-lb:0.0910, loss-ulb:0.0586, weight:0.47, lr:0.0009
[11:00:35.213] iteration:3466  t-loss:0.1414, loss-lb:0.0896, loss-ulb:0.1112, weight:0.47, lr:0.0009
[11:00:35.404] iteration:3467  t-loss:0.1217, loss-lb:0.0980, loss-ulb:0.0508, weight:0.47, lr:0.0009
[11:00:35.598] iteration:3468  t-loss:0.1252, loss-lb:0.1108, loss-ulb:0.0310, weight:0.47, lr:0.0009
[11:00:35.789] iteration:3469  t-loss:0.1272, loss-lb:0.1119, loss-ulb:0.0329, weight:0.47, lr:0.0009
[11:00:35.981] iteration:3470  t-loss:0.1158, loss-lb:0.0961, loss-ulb:0.0423, weight:0.47, lr:0.0009
[11:00:36.173] iteration:3471  t-loss:0.1249, loss-lb:0.1033, loss-ulb:0.0463, weight:0.47, lr:0.0009
[11:00:36.365] iteration:3472  t-loss:0.1407, loss-lb:0.1201, loss-ulb:0.0442, weight:0.47, lr:0.0009
[11:00:36.556] iteration:3473  t-loss:0.1419, loss-lb:0.1285, loss-ulb:0.0288, weight:0.47, lr:0.0009
[11:00:36.749] iteration:3474  t-loss:0.1173, loss-lb:0.1047, loss-ulb:0.0269, weight:0.47, lr:0.0009
[11:00:36.941] iteration:3475  t-loss:0.1081, loss-lb:0.0902, loss-ulb:0.0385, weight:0.47, lr:0.0009
[11:00:37.132] iteration:3476  t-loss:0.1342, loss-lb:0.1055, loss-ulb:0.0617, weight:0.47, lr:0.0009
[11:00:37.325] iteration:3477  t-loss:0.1282, loss-lb:0.0968, loss-ulb:0.0674, weight:0.47, lr:0.0009
[11:00:37.517] iteration:3478  t-loss:0.1087, loss-lb:0.0955, loss-ulb:0.0283, weight:0.47, lr:0.0009
[11:00:37.708] iteration:3479  t-loss:0.1499, loss-lb:0.1296, loss-ulb:0.0437, weight:0.47, lr:0.0009
[11:00:37.901] iteration:3480  t-loss:0.1119, loss-lb:0.0996, loss-ulb:0.0265, weight:0.47, lr:0.0009
[11:00:38.092] iteration:3481  t-loss:0.1370, loss-lb:0.1161, loss-ulb:0.0450, weight:0.47, lr:0.0009
[11:00:38.284] iteration:3482  t-loss:0.1454, loss-lb:0.1012, loss-ulb:0.0948, weight:0.47, lr:0.0009
[11:00:38.474] iteration:3483  t-loss:0.1367, loss-lb:0.1024, loss-ulb:0.0738, weight:0.47, lr:0.0009
[11:00:38.665] iteration:3484  t-loss:0.1223, loss-lb:0.1062, loss-ulb:0.0348, weight:0.47, lr:0.0009
[11:00:38.857] iteration:3485  t-loss:0.1317, loss-lb:0.1083, loss-ulb:0.0503, weight:0.47, lr:0.0009
[11:00:39.046] iteration:3486  t-loss:0.1147, loss-lb:0.1032, loss-ulb:0.0247, weight:0.47, lr:0.0009
[11:00:39.238] iteration:3487  t-loss:0.1113, loss-lb:0.0998, loss-ulb:0.0249, weight:0.47, lr:0.0009
[11:00:39.431] iteration:3488  t-loss:0.1118, loss-lb:0.0880, loss-ulb:0.0511, weight:0.47, lr:0.0009
[11:00:39.624] iteration:3489  t-loss:0.1267, loss-lb:0.0990, loss-ulb:0.0593, weight:0.47, lr:0.0009
[11:00:39.816] iteration:3490  t-loss:0.1137, loss-lb:0.0967, loss-ulb:0.0365, weight:0.47, lr:0.0009
[11:00:40.008] iteration:3491  t-loss:0.1228, loss-lb:0.1039, loss-ulb:0.0405, weight:0.47, lr:0.0009
[11:00:40.200] iteration:3492  t-loss:0.1410, loss-lb:0.1196, loss-ulb:0.0460, weight:0.47, lr:0.0009
[11:00:40.391] iteration:3493  t-loss:0.1100, loss-lb:0.0983, loss-ulb:0.0252, weight:0.47, lr:0.0009
[11:00:40.584] iteration:3494  t-loss:0.1317, loss-lb:0.1115, loss-ulb:0.0434, weight:0.47, lr:0.0009
[11:00:40.775] iteration:3495  t-loss:0.1464, loss-lb:0.1175, loss-ulb:0.0621, weight:0.47, lr:0.0009
[11:00:40.966] iteration:3496  t-loss:0.1207, loss-lb:0.0956, loss-ulb:0.0538, weight:0.47, lr:0.0009
[11:00:41.158] iteration:3497  t-loss:0.1218, loss-lb:0.1046, loss-ulb:0.0369, weight:0.47, lr:0.0009
[11:00:41.348] iteration:3498  t-loss:0.1390, loss-lb:0.1239, loss-ulb:0.0325, weight:0.47, lr:0.0009
[11:00:41.547] iteration:3499  t-loss:0.1316, loss-lb:0.1137, loss-ulb:0.0383, weight:0.47, lr:0.0009
[11:00:41.737] iteration:3500  t-loss:0.1276, loss-lb:0.1112, loss-ulb:0.0354, weight:0.47, lr:0.0009
[11:00:41.926] iteration:3501  t-loss:0.1267, loss-lb:0.1134, loss-ulb:0.0287, weight:0.47, lr:0.0009
[11:00:42.118] iteration:3502  t-loss:0.1230, loss-lb:0.1061, loss-ulb:0.0362, weight:0.47, lr:0.0009
[11:00:42.311] iteration:3503  t-loss:0.1759, loss-lb:0.1013, loss-ulb:0.1604, weight:0.47, lr:0.0009
[11:00:42.502] iteration:3504  t-loss:0.1237, loss-lb:0.1074, loss-ulb:0.0350, weight:0.47, lr:0.0009
[11:00:42.692] iteration:3505  t-loss:0.2033, loss-lb:0.1838, loss-ulb:0.0419, weight:0.47, lr:0.0009
[11:00:42.884] iteration:3506  t-loss:0.1428, loss-lb:0.1139, loss-ulb:0.0620, weight:0.47, lr:0.0009
[11:00:43.075] iteration:3507  t-loss:0.1534, loss-lb:0.1394, loss-ulb:0.0302, weight:0.47, lr:0.0009
[11:00:43.267] iteration:3508  t-loss:0.1221, loss-lb:0.1050, loss-ulb:0.0369, weight:0.47, lr:0.0009
[11:00:43.458] iteration:3509  t-loss:0.1382, loss-lb:0.1120, loss-ulb:0.0564, weight:0.47, lr:0.0009
[11:00:43.649] iteration:3510  t-loss:0.1345, loss-lb:0.1196, loss-ulb:0.0321, weight:0.47, lr:0.0009
[11:00:43.840] iteration:3511  t-loss:0.1406, loss-lb:0.1049, loss-ulb:0.0767, weight:0.47, lr:0.0009
[11:00:44.031] iteration:3512  t-loss:0.1593, loss-lb:0.1307, loss-ulb:0.0616, weight:0.47, lr:0.0009
[11:00:44.222] iteration:3513  t-loss:0.1353, loss-lb:0.1050, loss-ulb:0.0650, weight:0.47, lr:0.0009
[11:00:44.415] iteration:3514  t-loss:0.1822, loss-lb:0.1452, loss-ulb:0.0796, weight:0.47, lr:0.0009
[11:00:44.606] iteration:3515  t-loss:0.1510, loss-lb:0.1116, loss-ulb:0.0847, weight:0.47, lr:0.0009
[11:00:44.797] iteration:3516  t-loss:0.1322, loss-lb:0.1047, loss-ulb:0.0590, weight:0.47, lr:0.0009
[11:00:44.989] iteration:3517  t-loss:0.1383, loss-lb:0.1108, loss-ulb:0.0591, weight:0.47, lr:0.0009
[11:00:45.182] iteration:3518  t-loss:0.1291, loss-lb:0.1175, loss-ulb:0.0248, weight:0.47, lr:0.0009
[11:00:45.381] iteration:3519  t-loss:0.1460, loss-lb:0.1333, loss-ulb:0.0273, weight:0.47, lr:0.0009
[11:00:45.575] iteration:3520  t-loss:0.1680, loss-lb:0.1165, loss-ulb:0.1108, weight:0.47, lr:0.0009
[11:00:45.769] iteration:3521  t-loss:0.1346, loss-lb:0.1151, loss-ulb:0.0419, weight:0.47, lr:0.0009
[11:00:45.962] iteration:3522  t-loss:0.1301, loss-lb:0.1038, loss-ulb:0.0566, weight:0.47, lr:0.0009
[11:00:46.153] iteration:3523  t-loss:0.1240, loss-lb:0.1079, loss-ulb:0.0347, weight:0.47, lr:0.0009
[11:00:46.345] iteration:3524  t-loss:0.1235, loss-lb:0.1071, loss-ulb:0.0353, weight:0.47, lr:0.0009
[11:00:46.534] iteration:3525  t-loss:0.1114, loss-lb:0.0995, loss-ulb:0.0255, weight:0.47, lr:0.0009
[11:00:46.725] iteration:3526  t-loss:0.1536, loss-lb:0.1158, loss-ulb:0.0813, weight:0.47, lr:0.0009
[11:00:46.915] iteration:3527  t-loss:0.1207, loss-lb:0.1050, loss-ulb:0.0338, weight:0.47, lr:0.0009
[11:00:47.105] iteration:3528  t-loss:0.1510, loss-lb:0.1244, loss-ulb:0.0573, weight:0.47, lr:0.0009
[11:00:47.679] iteration:3529  t-loss:0.1171, loss-lb:0.1019, loss-ulb:0.0325, weight:0.47, lr:0.0009
[11:00:47.872] iteration:3530  t-loss:0.1269, loss-lb:0.1073, loss-ulb:0.0422, weight:0.47, lr:0.0009
[11:00:48.063] iteration:3531  t-loss:0.1248, loss-lb:0.1040, loss-ulb:0.0448, weight:0.47, lr:0.0009
[11:00:48.255] iteration:3532  t-loss:0.1238, loss-lb:0.1122, loss-ulb:0.0250, weight:0.47, lr:0.0009
[11:00:48.447] iteration:3533  t-loss:0.1264, loss-lb:0.1094, loss-ulb:0.0365, weight:0.47, lr:0.0009
[11:00:48.638] iteration:3534  t-loss:0.1177, loss-lb:0.1014, loss-ulb:0.0352, weight:0.47, lr:0.0009
[11:00:48.830] iteration:3535  t-loss:0.1505, loss-lb:0.1383, loss-ulb:0.0263, weight:0.47, lr:0.0009
[11:00:49.021] iteration:3536  t-loss:0.1330, loss-lb:0.0969, loss-ulb:0.0775, weight:0.47, lr:0.0009
[11:00:49.212] iteration:3537  t-loss:0.1285, loss-lb:0.0996, loss-ulb:0.0620, weight:0.47, lr:0.0009
[11:00:49.404] iteration:3538  t-loss:0.1658, loss-lb:0.1333, loss-ulb:0.0697, weight:0.47, lr:0.0009
[11:00:49.595] iteration:3539  t-loss:0.1319, loss-lb:0.1053, loss-ulb:0.0571, weight:0.47, lr:0.0009
[11:00:49.788] iteration:3540  t-loss:0.1245, loss-lb:0.1112, loss-ulb:0.0287, weight:0.47, lr:0.0009
[11:00:49.980] iteration:3541  t-loss:0.1511, loss-lb:0.1215, loss-ulb:0.0636, weight:0.47, lr:0.0009
[11:00:50.171] iteration:3542  t-loss:0.1510, loss-lb:0.1213, loss-ulb:0.0638, weight:0.47, lr:0.0009
[11:00:50.364] iteration:3543  t-loss:0.1403, loss-lb:0.0982, loss-ulb:0.0904, weight:0.47, lr:0.0009
[11:00:50.556] iteration:3544  t-loss:0.1089, loss-lb:0.0948, loss-ulb:0.0304, weight:0.47, lr:0.0009
[11:00:50.748] iteration:3545  t-loss:0.1300, loss-lb:0.1088, loss-ulb:0.0457, weight:0.47, lr:0.0009
[11:00:50.940] iteration:3546  t-loss:0.1309, loss-lb:0.1171, loss-ulb:0.0296, weight:0.47, lr:0.0009
[11:00:51.132] iteration:3547  t-loss:0.1551, loss-lb:0.1385, loss-ulb:0.0356, weight:0.47, lr:0.0009
[11:00:51.323] iteration:3548  t-loss:0.1336, loss-lb:0.1124, loss-ulb:0.0456, weight:0.47, lr:0.0009
[11:00:51.515] iteration:3549  t-loss:0.1188, loss-lb:0.1024, loss-ulb:0.0354, weight:0.47, lr:0.0009
[11:00:51.708] iteration:3550  t-loss:0.1236, loss-lb:0.1051, loss-ulb:0.0396, weight:0.47, lr:0.0009
[11:00:51.898] iteration:3551  t-loss:0.1311, loss-lb:0.0993, loss-ulb:0.0685, weight:0.47, lr:0.0009
[11:00:52.090] iteration:3552  t-loss:0.1222, loss-lb:0.0996, loss-ulb:0.0484, weight:0.47, lr:0.0009
[11:00:52.281] iteration:3553  t-loss:0.1255, loss-lb:0.1133, loss-ulb:0.0262, weight:0.47, lr:0.0009
[11:00:52.473] iteration:3554  t-loss:0.1299, loss-lb:0.1105, loss-ulb:0.0416, weight:0.47, lr:0.0009
[11:00:52.665] iteration:3555  t-loss:0.1119, loss-lb:0.0970, loss-ulb:0.0321, weight:0.47, lr:0.0009
[11:00:52.857] iteration:3556  t-loss:0.1222, loss-lb:0.1060, loss-ulb:0.0348, weight:0.47, lr:0.0009
[11:00:53.049] iteration:3557  t-loss:0.1331, loss-lb:0.1195, loss-ulb:0.0292, weight:0.47, lr:0.0009
[11:00:53.241] iteration:3558  t-loss:0.1471, loss-lb:0.1258, loss-ulb:0.0458, weight:0.47, lr:0.0009
[11:00:53.432] iteration:3559  t-loss:0.1236, loss-lb:0.1053, loss-ulb:0.0394, weight:0.47, lr:0.0009
[11:00:53.623] iteration:3560  t-loss:0.1281, loss-lb:0.1149, loss-ulb:0.0284, weight:0.47, lr:0.0009
[11:00:53.815] iteration:3561  t-loss:0.1381, loss-lb:0.0994, loss-ulb:0.0833, weight:0.47, lr:0.0009
[11:00:54.007] iteration:3562  t-loss:0.1212, loss-lb:0.0942, loss-ulb:0.0580, weight:0.47, lr:0.0009
[11:00:54.212] iteration:3563  t-loss:0.1179, loss-lb:0.1031, loss-ulb:0.0318, weight:0.47, lr:0.0009
[11:00:54.410] iteration:3564  t-loss:0.1083, loss-lb:0.0962, loss-ulb:0.0259, weight:0.47, lr:0.0009
[11:00:54.603] iteration:3565  t-loss:0.1274, loss-lb:0.1003, loss-ulb:0.0581, weight:0.47, lr:0.0009
[11:00:54.794] iteration:3566  t-loss:0.1217, loss-lb:0.0951, loss-ulb:0.0571, weight:0.47, lr:0.0009
[11:00:54.985] iteration:3567  t-loss:0.1205, loss-lb:0.1022, loss-ulb:0.0394, weight:0.47, lr:0.0009
[11:00:55.176] iteration:3568  t-loss:0.1175, loss-lb:0.0948, loss-ulb:0.0488, weight:0.47, lr:0.0009
[11:00:55.368] iteration:3569  t-loss:0.1179, loss-lb:0.1045, loss-ulb:0.0290, weight:0.47, lr:0.0009
[11:00:55.560] iteration:3570  t-loss:0.1510, loss-lb:0.1325, loss-ulb:0.0397, weight:0.47, lr:0.0009
[11:00:55.752] iteration:3571  t-loss:0.1172, loss-lb:0.1006, loss-ulb:0.0357, weight:0.47, lr:0.0009
[11:00:55.946] iteration:3572  t-loss:0.1131, loss-lb:0.1014, loss-ulb:0.0252, weight:0.47, lr:0.0009
[11:00:56.143] iteration:3573  t-loss:0.1159, loss-lb:0.0968, loss-ulb:0.0411, weight:0.47, lr:0.0009
[11:00:56.340] iteration:3574  t-loss:0.1207, loss-lb:0.1075, loss-ulb:0.0284, weight:0.47, lr:0.0009
[11:00:56.533] iteration:3575  t-loss:0.1092, loss-lb:0.0956, loss-ulb:0.0290, weight:0.47, lr:0.0009
[11:00:56.725] iteration:3576  t-loss:0.1121, loss-lb:0.1002, loss-ulb:0.0255, weight:0.47, lr:0.0009
[11:00:56.917] iteration:3577  t-loss:0.1220, loss-lb:0.1025, loss-ulb:0.0419, weight:0.47, lr:0.0009
[11:00:57.108] iteration:3578  t-loss:0.1268, loss-lb:0.1159, loss-ulb:0.0235, weight:0.47, lr:0.0009
[11:00:57.308] iteration:3579  t-loss:0.1268, loss-lb:0.1083, loss-ulb:0.0398, weight:0.47, lr:0.0009
[11:00:57.500] iteration:3580  t-loss:0.1219, loss-lb:0.0939, loss-ulb:0.0601, weight:0.47, lr:0.0009
[11:00:57.692] iteration:3581  t-loss:0.1213, loss-lb:0.1077, loss-ulb:0.0293, weight:0.47, lr:0.0009
[11:00:57.882] iteration:3582  t-loss:0.1220, loss-lb:0.1043, loss-ulb:0.0380, weight:0.47, lr:0.0009
[11:00:58.075] iteration:3583  t-loss:0.1148, loss-lb:0.0920, loss-ulb:0.0488, weight:0.47, lr:0.0009
[11:00:58.264] iteration:3584  t-loss:0.1230, loss-lb:0.1098, loss-ulb:0.0282, weight:0.47, lr:0.0009
[11:00:58.456] iteration:3585  t-loss:0.1175, loss-lb:0.1011, loss-ulb:0.0352, weight:0.47, lr:0.0009
[11:00:58.647] iteration:3586  t-loss:0.1066, loss-lb:0.0940, loss-ulb:0.0271, weight:0.47, lr:0.0009
[11:00:58.838] iteration:3587  t-loss:0.1145, loss-lb:0.1005, loss-ulb:0.0302, weight:0.47, lr:0.0009
[11:00:59.030] iteration:3588  t-loss:0.1207, loss-lb:0.1047, loss-ulb:0.0344, weight:0.47, lr:0.0009
[11:00:59.221] iteration:3589  t-loss:0.1281, loss-lb:0.1066, loss-ulb:0.0462, weight:0.47, lr:0.0009
[11:00:59.411] iteration:3590  t-loss:0.1152, loss-lb:0.1028, loss-ulb:0.0266, weight:0.47, lr:0.0009
[11:00:59.604] iteration:3591  t-loss:0.1112, loss-lb:0.0982, loss-ulb:0.0279, weight:0.47, lr:0.0009
[11:00:59.801] iteration:3592  t-loss:0.1176, loss-lb:0.0989, loss-ulb:0.0402, weight:0.47, lr:0.0009
[11:00:59.993] iteration:3593  t-loss:0.1155, loss-lb:0.0981, loss-ulb:0.0374, weight:0.47, lr:0.0009
[11:01:00.183] iteration:3594  t-loss:0.1017, loss-lb:0.0892, loss-ulb:0.0268, weight:0.47, lr:0.0009
[11:01:00.375] iteration:3595  t-loss:0.1245, loss-lb:0.1114, loss-ulb:0.0282, weight:0.47, lr:0.0009
[11:01:00.567] iteration:3596  t-loss:0.1157, loss-lb:0.1051, loss-ulb:0.0229, weight:0.47, lr:0.0009
[11:01:00.759] iteration:3597  t-loss:0.1239, loss-lb:0.1084, loss-ulb:0.0335, weight:0.47, lr:0.0009
[11:01:00.951] iteration:3598  t-loss:0.1052, loss-lb:0.0927, loss-ulb:0.0267, weight:0.47, lr:0.0009
[11:01:01.140] iteration:3599  t-loss:0.1180, loss-lb:0.1053, loss-ulb:0.0273, weight:0.47, lr:0.0009
[11:01:01.332] iteration:3600  t-loss:0.1430, loss-lb:0.1143, loss-ulb:0.0619, weight:0.47, lr:0.0009
[11:01:01.524] iteration:3601  t-loss:0.1270, loss-lb:0.1072, loss-ulb:0.0382, weight:0.52, lr:0.0009
[11:01:01.721] iteration:3602  t-loss:0.1242, loss-lb:0.1053, loss-ulb:0.0363, weight:0.52, lr:0.0009
[11:01:01.914] iteration:3603  t-loss:0.1091, loss-lb:0.0967, loss-ulb:0.0240, weight:0.52, lr:0.0009
[11:01:02.104] iteration:3604  t-loss:0.1374, loss-lb:0.1077, loss-ulb:0.0574, weight:0.52, lr:0.0009
[11:01:02.297] iteration:3605  t-loss:0.1037, loss-lb:0.0893, loss-ulb:0.0277, weight:0.52, lr:0.0009
[11:01:02.488] iteration:3606  t-loss:0.1245, loss-lb:0.1061, loss-ulb:0.0356, weight:0.52, lr:0.0009
[11:01:02.679] iteration:3607  t-loss:0.1187, loss-lb:0.1028, loss-ulb:0.0308, weight:0.52, lr:0.0009
[11:01:02.871] iteration:3608  t-loss:0.1569, loss-lb:0.1159, loss-ulb:0.0791, weight:0.52, lr:0.0009
[11:01:03.063] iteration:3609  t-loss:0.1165, loss-lb:0.1030, loss-ulb:0.0261, weight:0.52, lr:0.0009
[11:01:03.257] iteration:3610  t-loss:0.1597, loss-lb:0.0976, loss-ulb:0.1199, weight:0.52, lr:0.0009
[11:01:03.449] iteration:3611  t-loss:0.1112, loss-lb:0.0971, loss-ulb:0.0272, weight:0.52, lr:0.0009
[11:01:03.639] iteration:3612  t-loss:0.1185, loss-lb:0.0976, loss-ulb:0.0404, weight:0.52, lr:0.0009
[11:01:03.831] iteration:3613  t-loss:0.1167, loss-lb:0.0984, loss-ulb:0.0353, weight:0.52, lr:0.0009
[11:01:04.022] iteration:3614  t-loss:0.1125, loss-lb:0.0994, loss-ulb:0.0252, weight:0.52, lr:0.0009
[11:01:04.213] iteration:3615  t-loss:0.1082, loss-lb:0.0961, loss-ulb:0.0235, weight:0.52, lr:0.0009
[11:01:04.404] iteration:3616  t-loss:0.1458, loss-lb:0.1018, loss-ulb:0.0850, weight:0.52, lr:0.0009
[11:01:04.594] iteration:3617  t-loss:0.1263, loss-lb:0.1106, loss-ulb:0.0305, weight:0.52, lr:0.0009
[11:01:04.784] iteration:3618  t-loss:0.1322, loss-lb:0.1012, loss-ulb:0.0598, weight:0.52, lr:0.0009
[11:01:04.974] iteration:3619  t-loss:0.1305, loss-lb:0.1076, loss-ulb:0.0442, weight:0.52, lr:0.0009
[11:01:05.166] iteration:3620  t-loss:0.1953, loss-lb:0.1083, loss-ulb:0.1682, weight:0.52, lr:0.0009
[11:01:05.356] iteration:3621  t-loss:0.1259, loss-lb:0.1040, loss-ulb:0.0424, weight:0.52, lr:0.0009
[11:01:05.545] iteration:3622  t-loss:0.1218, loss-lb:0.0981, loss-ulb:0.0458, weight:0.52, lr:0.0009
[11:01:05.735] iteration:3623  t-loss:0.1060, loss-lb:0.0850, loss-ulb:0.0405, weight:0.52, lr:0.0009
[11:01:05.925] iteration:3624  t-loss:0.1369, loss-lb:0.0987, loss-ulb:0.0736, weight:0.52, lr:0.0009
[11:01:06.114] iteration:3625  t-loss:0.1051, loss-lb:0.0922, loss-ulb:0.0248, weight:0.52, lr:0.0009
[11:01:06.306] iteration:3626  t-loss:0.1283, loss-lb:0.1175, loss-ulb:0.0209, weight:0.52, lr:0.0009
[11:01:17.015]  <<Test>> - Ep:36  - mean_dice/mean_h95 - S:88.49/3.74, Best-S:89.21, T:89.94/2.01, Best-T:89.94
[11:01:17.015]           - AvgLoss(lb/ulb/all):0.1048/0.0522/0.1286
[11:01:17.507] iteration:3627  t-loss:0.1344, loss-lb:0.1148, loss-ulb:0.0378, weight:0.52, lr:0.0009
[11:01:17.706] iteration:3628  t-loss:0.1261, loss-lb:0.1039, loss-ulb:0.0431, weight:0.52, lr:0.0009
[11:01:17.898] iteration:3629  t-loss:0.1205, loss-lb:0.1027, loss-ulb:0.0345, weight:0.52, lr:0.0009
[11:01:18.091] iteration:3630  t-loss:0.1258, loss-lb:0.1056, loss-ulb:0.0390, weight:0.52, lr:0.0009
[11:01:18.285] iteration:3631  t-loss:0.1291, loss-lb:0.1121, loss-ulb:0.0328, weight:0.52, lr:0.0009
[11:01:18.478] iteration:3632  t-loss:0.1204, loss-lb:0.1019, loss-ulb:0.0358, weight:0.52, lr:0.0009
[11:01:18.669] iteration:3633  t-loss:0.1158, loss-lb:0.1055, loss-ulb:0.0198, weight:0.52, lr:0.0009
[11:01:18.861] iteration:3634  t-loss:0.1116, loss-lb:0.0917, loss-ulb:0.0384, weight:0.52, lr:0.0009
[11:01:19.053] iteration:3635  t-loss:0.1098, loss-lb:0.0934, loss-ulb:0.0316, weight:0.52, lr:0.0009
[11:01:19.245] iteration:3636  t-loss:0.1336, loss-lb:0.1047, loss-ulb:0.0557, weight:0.52, lr:0.0009
[11:01:19.437] iteration:3637  t-loss:0.1042, loss-lb:0.0912, loss-ulb:0.0251, weight:0.52, lr:0.0009
[11:01:19.631] iteration:3638  t-loss:0.1159, loss-lb:0.0961, loss-ulb:0.0382, weight:0.52, lr:0.0009
[11:01:19.823] iteration:3639  t-loss:0.1107, loss-lb:0.0922, loss-ulb:0.0356, weight:0.52, lr:0.0009
[11:01:20.016] iteration:3640  t-loss:0.1183, loss-lb:0.1051, loss-ulb:0.0255, weight:0.52, lr:0.0009
[11:01:20.208] iteration:3641  t-loss:0.1306, loss-lb:0.0997, loss-ulb:0.0597, weight:0.52, lr:0.0009
[11:01:20.402] iteration:3642  t-loss:0.1064, loss-lb:0.0949, loss-ulb:0.0222, weight:0.52, lr:0.0009
[11:01:20.594] iteration:3643  t-loss:0.1217, loss-lb:0.1066, loss-ulb:0.0292, weight:0.52, lr:0.0009
[11:01:20.787] iteration:3644  t-loss:0.1144, loss-lb:0.0988, loss-ulb:0.0301, weight:0.52, lr:0.0009
[11:01:20.979] iteration:3645  t-loss:0.1454, loss-lb:0.1237, loss-ulb:0.0419, weight:0.52, lr:0.0009
[11:01:21.171] iteration:3646  t-loss:0.1108, loss-lb:0.0953, loss-ulb:0.0300, weight:0.52, lr:0.0009
[11:01:21.364] iteration:3647  t-loss:0.1243, loss-lb:0.1022, loss-ulb:0.0428, weight:0.52, lr:0.0009
[11:01:21.557] iteration:3648  t-loss:0.1242, loss-lb:0.1060, loss-ulb:0.0351, weight:0.52, lr:0.0009
[11:01:21.749] iteration:3649  t-loss:0.1234, loss-lb:0.1041, loss-ulb:0.0372, weight:0.52, lr:0.0009
[11:01:21.941] iteration:3650  t-loss:0.1277, loss-lb:0.1034, loss-ulb:0.0468, weight:0.52, lr:0.0009
[11:01:22.134] iteration:3651  t-loss:0.1112, loss-lb:0.0955, loss-ulb:0.0302, weight:0.52, lr:0.0009
[11:01:22.325] iteration:3652  t-loss:0.1307, loss-lb:0.1082, loss-ulb:0.0433, weight:0.52, lr:0.0009
[11:01:22.517] iteration:3653  t-loss:0.1248, loss-lb:0.1087, loss-ulb:0.0311, weight:0.52, lr:0.0009
[11:01:22.711] iteration:3654  t-loss:0.1608, loss-lb:0.1056, loss-ulb:0.1067, weight:0.52, lr:0.0009
[11:01:22.904] iteration:3655  t-loss:0.1202, loss-lb:0.1063, loss-ulb:0.0268, weight:0.52, lr:0.0009
[11:01:23.096] iteration:3656  t-loss:0.1187, loss-lb:0.1011, loss-ulb:0.0340, weight:0.52, lr:0.0009
[11:01:23.289] iteration:3657  t-loss:0.1121, loss-lb:0.0924, loss-ulb:0.0379, weight:0.52, lr:0.0009
[11:01:23.482] iteration:3658  t-loss:0.1337, loss-lb:0.1177, loss-ulb:0.0309, weight:0.52, lr:0.0009
[11:01:23.674] iteration:3659  t-loss:0.1265, loss-lb:0.0984, loss-ulb:0.0542, weight:0.52, lr:0.0009
[11:01:23.867] iteration:3660  t-loss:0.1193, loss-lb:0.0987, loss-ulb:0.0399, weight:0.52, lr:0.0009
[11:01:24.059] iteration:3661  t-loss:0.1175, loss-lb:0.0984, loss-ulb:0.0370, weight:0.52, lr:0.0009
[11:01:24.251] iteration:3662  t-loss:0.1211, loss-lb:0.1047, loss-ulb:0.0316, weight:0.52, lr:0.0009
[11:01:24.444] iteration:3663  t-loss:0.1236, loss-lb:0.1022, loss-ulb:0.0413, weight:0.52, lr:0.0009
[11:01:24.637] iteration:3664  t-loss:0.1232, loss-lb:0.0949, loss-ulb:0.0547, weight:0.52, lr:0.0009
[11:01:24.829] iteration:3665  t-loss:0.1354, loss-lb:0.1144, loss-ulb:0.0406, weight:0.52, lr:0.0009
[11:01:25.021] iteration:3666  t-loss:0.1590, loss-lb:0.1074, loss-ulb:0.0998, weight:0.52, lr:0.0009
[11:01:25.214] iteration:3667  t-loss:0.1548, loss-lb:0.1194, loss-ulb:0.0685, weight:0.52, lr:0.0009
[11:01:25.406] iteration:3668  t-loss:0.1092, loss-lb:0.0955, loss-ulb:0.0264, weight:0.52, lr:0.0009
[11:01:25.598] iteration:3669  t-loss:0.1380, loss-lb:0.1060, loss-ulb:0.0620, weight:0.52, lr:0.0009
[11:01:25.792] iteration:3670  t-loss:0.1471, loss-lb:0.1182, loss-ulb:0.0558, weight:0.52, lr:0.0009
[11:01:25.986] iteration:3671  t-loss:0.1163, loss-lb:0.0887, loss-ulb:0.0533, weight:0.52, lr:0.0009
[11:01:26.179] iteration:3672  t-loss:0.1076, loss-lb:0.0944, loss-ulb:0.0255, weight:0.52, lr:0.0009
[11:01:26.371] iteration:3673  t-loss:0.1073, loss-lb:0.0912, loss-ulb:0.0312, weight:0.52, lr:0.0009
[11:01:26.563] iteration:3674  t-loss:0.1561, loss-lb:0.0964, loss-ulb:0.1154, weight:0.52, lr:0.0009
[11:01:26.755] iteration:3675  t-loss:0.1247, loss-lb:0.1109, loss-ulb:0.0266, weight:0.52, lr:0.0009
[11:01:26.958] iteration:3676  t-loss:0.1031, loss-lb:0.0904, loss-ulb:0.0245, weight:0.52, lr:0.0009
[11:01:27.156] iteration:3677  t-loss:0.1350, loss-lb:0.1128, loss-ulb:0.0430, weight:0.52, lr:0.0009
[11:01:27.348] iteration:3678  t-loss:0.1192, loss-lb:0.1047, loss-ulb:0.0280, weight:0.52, lr:0.0009
[11:01:27.540] iteration:3679  t-loss:0.1128, loss-lb:0.0973, loss-ulb:0.0299, weight:0.52, lr:0.0009
[11:01:27.732] iteration:3680  t-loss:0.1642, loss-lb:0.1103, loss-ulb:0.1042, weight:0.52, lr:0.0009
[11:01:27.925] iteration:3681  t-loss:0.1232, loss-lb:0.1075, loss-ulb:0.0304, weight:0.52, lr:0.0009
[11:01:28.118] iteration:3682  t-loss:0.1569, loss-lb:0.1260, loss-ulb:0.0598, weight:0.52, lr:0.0009
[11:01:28.310] iteration:3683  t-loss:0.1131, loss-lb:0.0984, loss-ulb:0.0284, weight:0.52, lr:0.0009
[11:01:28.503] iteration:3684  t-loss:0.1466, loss-lb:0.1156, loss-ulb:0.0599, weight:0.52, lr:0.0009
[11:01:28.695] iteration:3685  t-loss:0.1848, loss-lb:0.1059, loss-ulb:0.1524, weight:0.52, lr:0.0009
[11:01:28.887] iteration:3686  t-loss:0.1377, loss-lb:0.1187, loss-ulb:0.0367, weight:0.52, lr:0.0009
[11:01:29.079] iteration:3687  t-loss:0.1311, loss-lb:0.1034, loss-ulb:0.0536, weight:0.52, lr:0.0009
[11:01:29.272] iteration:3688  t-loss:0.1158, loss-lb:0.1011, loss-ulb:0.0285, weight:0.52, lr:0.0009
[11:01:29.464] iteration:3689  t-loss:0.1232, loss-lb:0.0965, loss-ulb:0.0516, weight:0.52, lr:0.0009
[11:01:29.657] iteration:3690  t-loss:0.1176, loss-lb:0.0954, loss-ulb:0.0428, weight:0.52, lr:0.0009
[11:01:29.850] iteration:3691  t-loss:0.1282, loss-lb:0.1068, loss-ulb:0.0414, weight:0.52, lr:0.0009
[11:01:30.042] iteration:3692  t-loss:0.1357, loss-lb:0.1218, loss-ulb:0.0270, weight:0.52, lr:0.0009
[11:01:30.234] iteration:3693  t-loss:0.1230, loss-lb:0.1094, loss-ulb:0.0264, weight:0.52, lr:0.0009
[11:01:30.426] iteration:3694  t-loss:0.1661, loss-lb:0.1327, loss-ulb:0.0646, weight:0.52, lr:0.0009
[11:01:30.617] iteration:3695  t-loss:0.1174, loss-lb:0.0954, loss-ulb:0.0427, weight:0.52, lr:0.0009
[11:01:30.809] iteration:3696  t-loss:0.1096, loss-lb:0.0984, loss-ulb:0.0217, weight:0.52, lr:0.0009
[11:01:31.002] iteration:3697  t-loss:0.1315, loss-lb:0.1149, loss-ulb:0.0321, weight:0.52, lr:0.0009
[11:01:31.193] iteration:3698  t-loss:0.2140, loss-lb:0.1863, loss-ulb:0.0534, weight:0.52, lr:0.0009
[11:01:31.385] iteration:3699  t-loss:0.1286, loss-lb:0.1093, loss-ulb:0.0374, weight:0.52, lr:0.0009
[11:01:31.578] iteration:3700  t-loss:0.1229, loss-lb:0.1105, loss-ulb:0.0241, weight:0.52, lr:0.0009
[11:01:31.771] iteration:3701  t-loss:0.1194, loss-lb:0.1025, loss-ulb:0.0327, weight:0.52, lr:0.0009
[11:01:31.964] iteration:3702  t-loss:0.1343, loss-lb:0.1162, loss-ulb:0.0350, weight:0.52, lr:0.0009
[11:01:32.156] iteration:3703  t-loss:0.1704, loss-lb:0.1378, loss-ulb:0.0631, weight:0.52, lr:0.0009
[11:01:32.348] iteration:3704  t-loss:0.1480, loss-lb:0.1213, loss-ulb:0.0515, weight:0.52, lr:0.0009
[11:01:32.540] iteration:3705  t-loss:0.1401, loss-lb:0.1046, loss-ulb:0.0686, weight:0.52, lr:0.0009
[11:01:32.732] iteration:3706  t-loss:0.1455, loss-lb:0.1162, loss-ulb:0.0566, weight:0.52, lr:0.0009
[11:01:32.924] iteration:3707  t-loss:0.1191, loss-lb:0.1072, loss-ulb:0.0230, weight:0.52, lr:0.0009
[11:01:33.117] iteration:3708  t-loss:0.1407, loss-lb:0.1155, loss-ulb:0.0486, weight:0.52, lr:0.0009
[11:01:33.309] iteration:3709  t-loss:0.1584, loss-lb:0.0995, loss-ulb:0.1138, weight:0.52, lr:0.0009
[11:01:33.501] iteration:3710  t-loss:0.1181, loss-lb:0.1045, loss-ulb:0.0263, weight:0.52, lr:0.0009
[11:01:33.694] iteration:3711  t-loss:0.1177, loss-lb:0.0990, loss-ulb:0.0361, weight:0.52, lr:0.0009
[11:01:33.886] iteration:3712  t-loss:0.1103, loss-lb:0.0944, loss-ulb:0.0308, weight:0.52, lr:0.0009
[11:01:34.078] iteration:3713  t-loss:0.1233, loss-lb:0.1005, loss-ulb:0.0441, weight:0.52, lr:0.0009
[11:01:34.271] iteration:3714  t-loss:0.1470, loss-lb:0.1274, loss-ulb:0.0378, weight:0.52, lr:0.0009
[11:01:34.464] iteration:3715  t-loss:0.1182, loss-lb:0.1037, loss-ulb:0.0279, weight:0.52, lr:0.0009
[11:01:34.657] iteration:3716  t-loss:0.1684, loss-lb:0.1073, loss-ulb:0.1181, weight:0.52, lr:0.0009
[11:01:34.849] iteration:3717  t-loss:0.1336, loss-lb:0.1131, loss-ulb:0.0396, weight:0.52, lr:0.0009
[11:01:35.039] iteration:3718  t-loss:0.1349, loss-lb:0.1053, loss-ulb:0.0573, weight:0.52, lr:0.0009
[11:01:35.230] iteration:3719  t-loss:0.1525, loss-lb:0.1012, loss-ulb:0.0992, weight:0.52, lr:0.0009
[11:01:35.421] iteration:3720  t-loss:0.1496, loss-lb:0.1289, loss-ulb:0.0399, weight:0.52, lr:0.0009
[11:01:35.611] iteration:3721  t-loss:0.1233, loss-lb:0.0947, loss-ulb:0.0553, weight:0.52, lr:0.0009
[11:01:35.802] iteration:3722  t-loss:0.1224, loss-lb:0.0989, loss-ulb:0.0455, weight:0.52, lr:0.0009
[11:01:35.992] iteration:3723  t-loss:0.1356, loss-lb:0.0969, loss-ulb:0.0749, weight:0.52, lr:0.0009
[11:01:36.183] iteration:3724  t-loss:0.1160, loss-lb:0.0990, loss-ulb:0.0329, weight:0.52, lr:0.0009
[11:01:36.775] iteration:3725  t-loss:0.1332, loss-lb:0.1102, loss-ulb:0.0444, weight:0.52, lr:0.0009
[11:01:36.972] iteration:3726  t-loss:0.1582, loss-lb:0.1122, loss-ulb:0.0889, weight:0.52, lr:0.0009
[11:01:37.165] iteration:3727  t-loss:0.1274, loss-lb:0.0963, loss-ulb:0.0601, weight:0.52, lr:0.0009
[11:01:37.358] iteration:3728  t-loss:0.1136, loss-lb:0.0965, loss-ulb:0.0331, weight:0.52, lr:0.0009
[11:01:37.549] iteration:3729  t-loss:0.1316, loss-lb:0.1168, loss-ulb:0.0287, weight:0.52, lr:0.0009
[11:01:37.741] iteration:3730  t-loss:0.1397, loss-lb:0.1266, loss-ulb:0.0254, weight:0.52, lr:0.0009
[11:01:37.933] iteration:3731  t-loss:0.1189, loss-lb:0.1055, loss-ulb:0.0259, weight:0.52, lr:0.0009
[11:01:38.125] iteration:3732  t-loss:0.1268, loss-lb:0.1047, loss-ulb:0.0427, weight:0.52, lr:0.0009
[11:01:38.317] iteration:3733  t-loss:0.1252, loss-lb:0.1098, loss-ulb:0.0297, weight:0.52, lr:0.0009
[11:01:38.509] iteration:3734  t-loss:0.1270, loss-lb:0.1052, loss-ulb:0.0420, weight:0.52, lr:0.0009
[11:01:38.702] iteration:3735  t-loss:0.1359, loss-lb:0.0949, loss-ulb:0.0793, weight:0.52, lr:0.0009
[11:01:38.893] iteration:3736  t-loss:0.1193, loss-lb:0.1075, loss-ulb:0.0228, weight:0.52, lr:0.0009
[11:01:39.085] iteration:3737  t-loss:0.1290, loss-lb:0.1005, loss-ulb:0.0552, weight:0.52, lr:0.0009
[11:01:39.276] iteration:3738  t-loss:0.1334, loss-lb:0.1138, loss-ulb:0.0378, weight:0.52, lr:0.0009
[11:01:39.468] iteration:3739  t-loss:0.1185, loss-lb:0.1009, loss-ulb:0.0340, weight:0.52, lr:0.0009
[11:01:39.660] iteration:3740  t-loss:0.1231, loss-lb:0.1012, loss-ulb:0.0423, weight:0.52, lr:0.0009
[11:01:39.852] iteration:3741  t-loss:0.1381, loss-lb:0.1189, loss-ulb:0.0372, weight:0.52, lr:0.0009
[11:01:40.044] iteration:3742  t-loss:0.1323, loss-lb:0.1173, loss-ulb:0.0290, weight:0.52, lr:0.0009
[11:01:40.235] iteration:3743  t-loss:0.1090, loss-lb:0.0971, loss-ulb:0.0231, weight:0.52, lr:0.0009
[11:01:40.427] iteration:3744  t-loss:0.1135, loss-lb:0.0987, loss-ulb:0.0285, weight:0.52, lr:0.0009
[11:01:40.620] iteration:3745  t-loss:0.1445, loss-lb:0.1086, loss-ulb:0.0695, weight:0.52, lr:0.0009
[11:01:40.811] iteration:3746  t-loss:0.1319, loss-lb:0.0927, loss-ulb:0.0756, weight:0.52, lr:0.0009
[11:01:41.003] iteration:3747  t-loss:0.1419, loss-lb:0.0948, loss-ulb:0.0911, weight:0.52, lr:0.0009
[11:01:41.196] iteration:3748  t-loss:0.1098, loss-lb:0.0968, loss-ulb:0.0250, weight:0.52, lr:0.0009
[11:01:41.388] iteration:3749  t-loss:0.1218, loss-lb:0.1010, loss-ulb:0.0401, weight:0.52, lr:0.0009
[11:01:41.581] iteration:3750  t-loss:0.1396, loss-lb:0.1089, loss-ulb:0.0594, weight:0.52, lr:0.0009
[11:01:41.772] iteration:3751  t-loss:0.1288, loss-lb:0.1149, loss-ulb:0.0243, weight:0.57, lr:0.0009
[11:01:41.964] iteration:3752  t-loss:0.1414, loss-lb:0.1076, loss-ulb:0.0590, weight:0.57, lr:0.0009
[11:01:42.156] iteration:3753  t-loss:0.1414, loss-lb:0.1199, loss-ulb:0.0376, weight:0.57, lr:0.0009
[11:01:42.348] iteration:3754  t-loss:0.1364, loss-lb:0.1032, loss-ulb:0.0580, weight:0.57, lr:0.0009
[11:01:42.541] iteration:3755  t-loss:0.1313, loss-lb:0.1105, loss-ulb:0.0364, weight:0.57, lr:0.0009
[11:01:42.733] iteration:3756  t-loss:0.1232, loss-lb:0.1009, loss-ulb:0.0389, weight:0.57, lr:0.0009
[11:01:42.925] iteration:3757  t-loss:0.1257, loss-lb:0.0945, loss-ulb:0.0545, weight:0.57, lr:0.0009
[11:01:43.117] iteration:3758  t-loss:0.1278, loss-lb:0.0999, loss-ulb:0.0487, weight:0.57, lr:0.0009
[11:01:43.310] iteration:3759  t-loss:0.1506, loss-lb:0.1190, loss-ulb:0.0551, weight:0.57, lr:0.0009
[11:01:43.501] iteration:3760  t-loss:0.1306, loss-lb:0.1047, loss-ulb:0.0451, weight:0.57, lr:0.0009
[11:01:43.693] iteration:3761  t-loss:0.1278, loss-lb:0.1065, loss-ulb:0.0372, weight:0.57, lr:0.0009
[11:01:43.884] iteration:3762  t-loss:0.1328, loss-lb:0.1111, loss-ulb:0.0379, weight:0.57, lr:0.0009
[11:01:44.076] iteration:3763  t-loss:0.1322, loss-lb:0.1118, loss-ulb:0.0356, weight:0.57, lr:0.0009
[11:01:44.267] iteration:3764  t-loss:0.1320, loss-lb:0.1136, loss-ulb:0.0321, weight:0.57, lr:0.0009
[11:01:44.459] iteration:3765  t-loss:0.1674, loss-lb:0.1436, loss-ulb:0.0416, weight:0.57, lr:0.0009
[11:01:44.651] iteration:3766  t-loss:0.1492, loss-lb:0.1170, loss-ulb:0.0561, weight:0.57, lr:0.0009
[11:01:44.843] iteration:3767  t-loss:0.1287, loss-lb:0.1044, loss-ulb:0.0424, weight:0.57, lr:0.0009
[11:01:45.035] iteration:3768  t-loss:0.1236, loss-lb:0.0968, loss-ulb:0.0468, weight:0.57, lr:0.0009
[11:01:45.228] iteration:3769  t-loss:0.2128, loss-lb:0.1293, loss-ulb:0.1458, weight:0.57, lr:0.0009
[11:01:45.419] iteration:3770  t-loss:0.1329, loss-lb:0.1064, loss-ulb:0.0464, weight:0.57, lr:0.0009
[11:01:45.612] iteration:3771  t-loss:0.1323, loss-lb:0.1070, loss-ulb:0.0442, weight:0.57, lr:0.0009
[11:01:45.805] iteration:3772  t-loss:0.2440, loss-lb:0.1562, loss-ulb:0.1532, weight:0.57, lr:0.0009
[11:01:45.997] iteration:3773  t-loss:0.1668, loss-lb:0.1373, loss-ulb:0.0513, weight:0.57, lr:0.0009
[11:01:46.189] iteration:3774  t-loss:0.1191, loss-lb:0.1020, loss-ulb:0.0299, weight:0.57, lr:0.0009
[11:01:46.380] iteration:3775  t-loss:0.1261, loss-lb:0.1059, loss-ulb:0.0353, weight:0.57, lr:0.0009
[11:01:46.573] iteration:3776  t-loss:0.1270, loss-lb:0.1007, loss-ulb:0.0459, weight:0.57, lr:0.0009
[11:01:46.768] iteration:3777  t-loss:0.1465, loss-lb:0.1159, loss-ulb:0.0533, weight:0.57, lr:0.0009
[11:01:46.961] iteration:3778  t-loss:0.1340, loss-lb:0.0998, loss-ulb:0.0597, weight:0.57, lr:0.0009
[11:01:47.152] iteration:3779  t-loss:0.1424, loss-lb:0.1035, loss-ulb:0.0679, weight:0.57, lr:0.0009
[11:01:47.345] iteration:3780  t-loss:0.1512, loss-lb:0.1175, loss-ulb:0.0589, weight:0.57, lr:0.0009
[11:01:47.537] iteration:3781  t-loss:0.1823, loss-lb:0.1399, loss-ulb:0.0740, weight:0.57, lr:0.0009
[11:01:47.730] iteration:3782  t-loss:0.1243, loss-lb:0.1027, loss-ulb:0.0377, weight:0.57, lr:0.0009
[11:01:47.922] iteration:3783  t-loss:0.1204, loss-lb:0.1067, loss-ulb:0.0240, weight:0.57, lr:0.0009
[11:01:48.114] iteration:3784  t-loss:0.1381, loss-lb:0.1222, loss-ulb:0.0277, weight:0.57, lr:0.0009
[11:01:48.305] iteration:3785  t-loss:0.1173, loss-lb:0.0978, loss-ulb:0.0342, weight:0.57, lr:0.0009
[11:01:48.497] iteration:3786  t-loss:0.1268, loss-lb:0.1063, loss-ulb:0.0359, weight:0.57, lr:0.0009
[11:01:48.689] iteration:3787  t-loss:0.1288, loss-lb:0.1085, loss-ulb:0.0354, weight:0.57, lr:0.0009
[11:01:48.882] iteration:3788  t-loss:0.1602, loss-lb:0.1160, loss-ulb:0.0771, weight:0.57, lr:0.0009
[11:01:49.075] iteration:3789  t-loss:0.1156, loss-lb:0.0933, loss-ulb:0.0389, weight:0.57, lr:0.0009
[11:01:49.268] iteration:3790  t-loss:0.1588, loss-lb:0.1196, loss-ulb:0.0683, weight:0.57, lr:0.0009
[11:01:49.461] iteration:3791  t-loss:0.1616, loss-lb:0.1153, loss-ulb:0.0808, weight:0.57, lr:0.0009
[11:01:49.653] iteration:3792  t-loss:0.1213, loss-lb:0.1005, loss-ulb:0.0363, weight:0.57, lr:0.0009
[11:01:49.845] iteration:3793  t-loss:0.1221, loss-lb:0.0970, loss-ulb:0.0437, weight:0.57, lr:0.0009
[11:01:50.039] iteration:3794  t-loss:0.1257, loss-lb:0.1057, loss-ulb:0.0349, weight:0.57, lr:0.0009
[11:01:50.247] iteration:3795  t-loss:0.1270, loss-lb:0.1075, loss-ulb:0.0340, weight:0.57, lr:0.0009
[11:01:50.439] iteration:3796  t-loss:0.1284, loss-lb:0.1107, loss-ulb:0.0308, weight:0.57, lr:0.0009
[11:01:50.633] iteration:3797  t-loss:0.1550, loss-lb:0.1289, loss-ulb:0.0455, weight:0.57, lr:0.0009
[11:01:50.825] iteration:3798  t-loss:0.1304, loss-lb:0.1175, loss-ulb:0.0225, weight:0.57, lr:0.0009
[11:01:51.017] iteration:3799  t-loss:0.1299, loss-lb:0.1076, loss-ulb:0.0389, weight:0.57, lr:0.0009
[11:01:51.211] iteration:3800  t-loss:0.1327, loss-lb:0.0956, loss-ulb:0.0648, weight:0.57, lr:0.0009
[11:01:51.403] iteration:3801  t-loss:0.1407, loss-lb:0.1103, loss-ulb:0.0531, weight:0.57, lr:0.0009
[11:01:51.596] iteration:3802  t-loss:0.1251, loss-lb:0.1014, loss-ulb:0.0414, weight:0.57, lr:0.0009
[11:01:51.790] iteration:3803  t-loss:0.1174, loss-lb:0.1018, loss-ulb:0.0272, weight:0.57, lr:0.0009
[11:01:51.985] iteration:3804  t-loss:0.1507, loss-lb:0.1236, loss-ulb:0.0473, weight:0.57, lr:0.0009
[11:01:52.176] iteration:3805  t-loss:0.1101, loss-lb:0.0947, loss-ulb:0.0269, weight:0.57, lr:0.0009
[11:01:52.369] iteration:3806  t-loss:0.1622, loss-lb:0.1138, loss-ulb:0.0846, weight:0.57, lr:0.0009
[11:01:52.562] iteration:3807  t-loss:0.1262, loss-lb:0.0953, loss-ulb:0.0538, weight:0.57, lr:0.0009
[11:01:52.754] iteration:3808  t-loss:0.1242, loss-lb:0.0969, loss-ulb:0.0478, weight:0.57, lr:0.0009
[11:01:52.947] iteration:3809  t-loss:0.1239, loss-lb:0.1008, loss-ulb:0.0404, weight:0.57, lr:0.0009
[11:01:53.140] iteration:3810  t-loss:0.1275, loss-lb:0.1001, loss-ulb:0.0478, weight:0.57, lr:0.0009
[11:01:53.334] iteration:3811  t-loss:0.1238, loss-lb:0.1048, loss-ulb:0.0333, weight:0.57, lr:0.0009
[11:01:53.528] iteration:3812  t-loss:0.1258, loss-lb:0.1040, loss-ulb:0.0380, weight:0.57, lr:0.0009
[11:01:53.720] iteration:3813  t-loss:0.1178, loss-lb:0.1020, loss-ulb:0.0276, weight:0.57, lr:0.0009
[11:01:53.912] iteration:3814  t-loss:0.1190, loss-lb:0.0979, loss-ulb:0.0368, weight:0.57, lr:0.0009
[11:01:54.105] iteration:3815  t-loss:0.1106, loss-lb:0.0942, loss-ulb:0.0286, weight:0.57, lr:0.0009
[11:01:54.297] iteration:3816  t-loss:0.1091, loss-lb:0.0924, loss-ulb:0.0291, weight:0.57, lr:0.0009
[11:01:54.489] iteration:3817  t-loss:0.1034, loss-lb:0.0904, loss-ulb:0.0228, weight:0.57, lr:0.0009
[11:01:54.682] iteration:3818  t-loss:0.1198, loss-lb:0.1071, loss-ulb:0.0223, weight:0.57, lr:0.0009
[11:01:54.873] iteration:3819  t-loss:0.1275, loss-lb:0.1054, loss-ulb:0.0386, weight:0.57, lr:0.0009
[11:01:55.065] iteration:3820  t-loss:0.1306, loss-lb:0.1063, loss-ulb:0.0423, weight:0.57, lr:0.0009
[11:01:55.258] iteration:3821  t-loss:0.1234, loss-lb:0.1063, loss-ulb:0.0298, weight:0.57, lr:0.0009
[11:01:55.448] iteration:3822  t-loss:0.1094, loss-lb:0.0932, loss-ulb:0.0282, weight:0.57, lr:0.0009
[11:02:08.032]  <<Test>> - Ep:38  - mean_dice/mean_h95 - S:88.83/1.93, Best-S:89.21, T:89.77/1.58, Best-T:89.94
[11:02:08.032]           - AvgLoss(lb/ulb/all):0.1076/0.0377/0.1231
[11:02:08.582] iteration:3823  t-loss:0.1062, loss-lb:0.0919, loss-ulb:0.0250, weight:0.57, lr:0.0009
[11:02:08.778] iteration:3824  t-loss:0.1456, loss-lb:0.1290, loss-ulb:0.0291, weight:0.57, lr:0.0009
[11:02:08.970] iteration:3825  t-loss:0.1068, loss-lb:0.0940, loss-ulb:0.0224, weight:0.57, lr:0.0009
[11:02:09.163] iteration:3826  t-loss:0.1229, loss-lb:0.1009, loss-ulb:0.0384, weight:0.57, lr:0.0009
[11:02:09.355] iteration:3827  t-loss:0.1137, loss-lb:0.0946, loss-ulb:0.0334, weight:0.57, lr:0.0009
[11:02:09.547] iteration:3828  t-loss:0.1262, loss-lb:0.1080, loss-ulb:0.0318, weight:0.57, lr:0.0009
[11:02:09.740] iteration:3829  t-loss:0.1093, loss-lb:0.0967, loss-ulb:0.0221, weight:0.57, lr:0.0009
[11:02:09.933] iteration:3830  t-loss:0.1158, loss-lb:0.1029, loss-ulb:0.0226, weight:0.57, lr:0.0009
[11:02:10.126] iteration:3831  t-loss:0.1337, loss-lb:0.1176, loss-ulb:0.0280, weight:0.57, lr:0.0009
[11:02:10.318] iteration:3832  t-loss:0.1331, loss-lb:0.1021, loss-ulb:0.0542, weight:0.57, lr:0.0009
[11:02:10.511] iteration:3833  t-loss:0.1290, loss-lb:0.1110, loss-ulb:0.0314, weight:0.57, lr:0.0009
[11:02:10.703] iteration:3834  t-loss:0.1485, loss-lb:0.1153, loss-ulb:0.0580, weight:0.57, lr:0.0009
[11:02:10.895] iteration:3835  t-loss:0.1134, loss-lb:0.0946, loss-ulb:0.0328, weight:0.57, lr:0.0009
[11:02:11.094] iteration:3836  t-loss:0.1551, loss-lb:0.1263, loss-ulb:0.0503, weight:0.57, lr:0.0009
[11:02:11.286] iteration:3837  t-loss:0.1214, loss-lb:0.0986, loss-ulb:0.0397, weight:0.57, lr:0.0009
[11:02:11.480] iteration:3838  t-loss:0.1542, loss-lb:0.1051, loss-ulb:0.0858, weight:0.57, lr:0.0009
[11:02:11.672] iteration:3839  t-loss:0.1147, loss-lb:0.0984, loss-ulb:0.0284, weight:0.57, lr:0.0009
[11:02:11.863] iteration:3840  t-loss:0.1565, loss-lb:0.1411, loss-ulb:0.0269, weight:0.57, lr:0.0009
[11:02:12.058] iteration:3841  t-loss:0.1902, loss-lb:0.1247, loss-ulb:0.1143, weight:0.57, lr:0.0009
[11:02:12.250] iteration:3842  t-loss:0.1319, loss-lb:0.0942, loss-ulb:0.0657, weight:0.57, lr:0.0009
[11:02:12.441] iteration:3843  t-loss:0.1260, loss-lb:0.1065, loss-ulb:0.0340, weight:0.57, lr:0.0009
[11:02:12.633] iteration:3844  t-loss:0.1424, loss-lb:0.1098, loss-ulb:0.0568, weight:0.57, lr:0.0009
[11:02:12.826] iteration:3845  t-loss:0.1451, loss-lb:0.1257, loss-ulb:0.0339, weight:0.57, lr:0.0009
[11:02:13.018] iteration:3846  t-loss:0.1317, loss-lb:0.1016, loss-ulb:0.0524, weight:0.57, lr:0.0009
[11:02:13.210] iteration:3847  t-loss:0.1354, loss-lb:0.1174, loss-ulb:0.0315, weight:0.57, lr:0.0009
[11:02:13.402] iteration:3848  t-loss:0.1998, loss-lb:0.1628, loss-ulb:0.0646, weight:0.57, lr:0.0009
[11:02:13.593] iteration:3849  t-loss:0.1417, loss-lb:0.1163, loss-ulb:0.0443, weight:0.57, lr:0.0009
[11:02:13.785] iteration:3850  t-loss:0.1237, loss-lb:0.1019, loss-ulb:0.0381, weight:0.57, lr:0.0009
[11:02:13.979] iteration:3851  t-loss:0.1482, loss-lb:0.1029, loss-ulb:0.0790, weight:0.57, lr:0.0009
[11:02:14.171] iteration:3852  t-loss:0.1221, loss-lb:0.0954, loss-ulb:0.0465, weight:0.57, lr:0.0009
[11:02:14.362] iteration:3853  t-loss:0.1270, loss-lb:0.1118, loss-ulb:0.0266, weight:0.57, lr:0.0009
[11:02:14.554] iteration:3854  t-loss:0.1279, loss-lb:0.1087, loss-ulb:0.0335, weight:0.57, lr:0.0009
[11:02:14.745] iteration:3855  t-loss:0.1348, loss-lb:0.0998, loss-ulb:0.0610, weight:0.57, lr:0.0009
[11:02:14.937] iteration:3856  t-loss:0.1832, loss-lb:0.1113, loss-ulb:0.1253, weight:0.57, lr:0.0009
[11:02:15.128] iteration:3857  t-loss:0.1295, loss-lb:0.1103, loss-ulb:0.0335, weight:0.57, lr:0.0009
[11:02:15.320] iteration:3858  t-loss:0.1351, loss-lb:0.1095, loss-ulb:0.0446, weight:0.57, lr:0.0009
[11:02:15.511] iteration:3859  t-loss:0.1114, loss-lb:0.0965, loss-ulb:0.0259, weight:0.57, lr:0.0009
[11:02:15.702] iteration:3860  t-loss:0.1190, loss-lb:0.1014, loss-ulb:0.0307, weight:0.57, lr:0.0009
[11:02:15.893] iteration:3861  t-loss:0.1171, loss-lb:0.0981, loss-ulb:0.0331, weight:0.57, lr:0.0009
[11:02:16.084] iteration:3862  t-loss:0.1385, loss-lb:0.1089, loss-ulb:0.0516, weight:0.57, lr:0.0009
[11:02:16.276] iteration:3863  t-loss:0.1370, loss-lb:0.1027, loss-ulb:0.0600, weight:0.57, lr:0.0009
[11:02:16.467] iteration:3864  t-loss:0.1296, loss-lb:0.1053, loss-ulb:0.0425, weight:0.57, lr:0.0009
[11:02:16.659] iteration:3865  t-loss:0.1264, loss-lb:0.1082, loss-ulb:0.0317, weight:0.57, lr:0.0009
[11:02:16.849] iteration:3866  t-loss:0.1147, loss-lb:0.0960, loss-ulb:0.0326, weight:0.57, lr:0.0009
[11:02:17.041] iteration:3867  t-loss:0.1217, loss-lb:0.1051, loss-ulb:0.0288, weight:0.57, lr:0.0009
[11:02:17.233] iteration:3868  t-loss:0.1248, loss-lb:0.0984, loss-ulb:0.0461, weight:0.57, lr:0.0009
[11:02:17.426] iteration:3869  t-loss:0.1222, loss-lb:0.0893, loss-ulb:0.0575, weight:0.57, lr:0.0009
[11:02:17.621] iteration:3870  t-loss:0.1217, loss-lb:0.1040, loss-ulb:0.0309, weight:0.57, lr:0.0009
[11:02:17.820] iteration:3871  t-loss:0.1415, loss-lb:0.1196, loss-ulb:0.0382, weight:0.57, lr:0.0009
[11:02:18.016] iteration:3872  t-loss:0.1320, loss-lb:0.1181, loss-ulb:0.0242, weight:0.57, lr:0.0009
[11:02:18.208] iteration:3873  t-loss:0.1122, loss-lb:0.0959, loss-ulb:0.0283, weight:0.57, lr:0.0009
[11:02:18.400] iteration:3874  t-loss:0.1165, loss-lb:0.1009, loss-ulb:0.0273, weight:0.57, lr:0.0009
[11:02:18.592] iteration:3875  t-loss:0.1584, loss-lb:0.1363, loss-ulb:0.0385, weight:0.57, lr:0.0009
[11:02:18.785] iteration:3876  t-loss:0.1325, loss-lb:0.1008, loss-ulb:0.0552, weight:0.57, lr:0.0009
[11:02:18.976] iteration:3877  t-loss:0.1358, loss-lb:0.1162, loss-ulb:0.0341, weight:0.57, lr:0.0009
[11:02:19.168] iteration:3878  t-loss:0.1218, loss-lb:0.1061, loss-ulb:0.0273, weight:0.57, lr:0.0009
[11:02:19.359] iteration:3879  t-loss:0.1579, loss-lb:0.1100, loss-ulb:0.0835, weight:0.57, lr:0.0009
[11:02:19.551] iteration:3880  t-loss:0.1149, loss-lb:0.0952, loss-ulb:0.0345, weight:0.57, lr:0.0009
[11:02:19.743] iteration:3881  t-loss:0.1357, loss-lb:0.1045, loss-ulb:0.0543, weight:0.57, lr:0.0009
[11:02:19.935] iteration:3882  t-loss:0.1283, loss-lb:0.1152, loss-ulb:0.0229, weight:0.57, lr:0.0009
[11:02:20.126] iteration:3883  t-loss:0.1296, loss-lb:0.1130, loss-ulb:0.0289, weight:0.57, lr:0.0009
[11:02:20.319] iteration:3884  t-loss:0.1392, loss-lb:0.1014, loss-ulb:0.0660, weight:0.57, lr:0.0009
[11:02:20.511] iteration:3885  t-loss:0.1247, loss-lb:0.1063, loss-ulb:0.0321, weight:0.57, lr:0.0009
[11:02:20.702] iteration:3886  t-loss:0.1230, loss-lb:0.0917, loss-ulb:0.0546, weight:0.57, lr:0.0009
[11:02:20.893] iteration:3887  t-loss:0.1261, loss-lb:0.1011, loss-ulb:0.0437, weight:0.57, lr:0.0009
[11:02:21.085] iteration:3888  t-loss:0.1310, loss-lb:0.1021, loss-ulb:0.0503, weight:0.57, lr:0.0009
[11:02:21.276] iteration:3889  t-loss:0.1257, loss-lb:0.1036, loss-ulb:0.0386, weight:0.57, lr:0.0009
[11:02:21.467] iteration:3890  t-loss:0.1129, loss-lb:0.0941, loss-ulb:0.0328, weight:0.57, lr:0.0009
[11:02:21.659] iteration:3891  t-loss:0.1528, loss-lb:0.1108, loss-ulb:0.0734, weight:0.57, lr:0.0009
[11:02:21.851] iteration:3892  t-loss:0.1101, loss-lb:0.0958, loss-ulb:0.0250, weight:0.57, lr:0.0009
[11:02:22.043] iteration:3893  t-loss:0.1393, loss-lb:0.1133, loss-ulb:0.0452, weight:0.57, lr:0.0009
[11:02:22.235] iteration:3894  t-loss:0.1291, loss-lb:0.1116, loss-ulb:0.0305, weight:0.57, lr:0.0009
[11:02:22.426] iteration:3895  t-loss:0.1283, loss-lb:0.1031, loss-ulb:0.0439, weight:0.57, lr:0.0009
[11:02:22.617] iteration:3896  t-loss:0.1176, loss-lb:0.0998, loss-ulb:0.0312, weight:0.57, lr:0.0009
[11:02:22.809] iteration:3897  t-loss:0.1249, loss-lb:0.1090, loss-ulb:0.0278, weight:0.57, lr:0.0009
[11:02:23.000] iteration:3898  t-loss:0.1261, loss-lb:0.0979, loss-ulb:0.0493, weight:0.57, lr:0.0009
[11:02:23.191] iteration:3899  t-loss:0.1321, loss-lb:0.1133, loss-ulb:0.0328, weight:0.57, lr:0.0009
[11:02:23.384] iteration:3900  t-loss:0.1080, loss-lb:0.0838, loss-ulb:0.0422, weight:0.57, lr:0.0009
[11:02:23.575] iteration:3901  t-loss:0.2140, loss-lb:0.1948, loss-ulb:0.0305, weight:0.63, lr:0.0009
[11:02:23.767] iteration:3902  t-loss:0.1170, loss-lb:0.1004, loss-ulb:0.0262, weight:0.63, lr:0.0009
[11:02:23.958] iteration:3903  t-loss:0.1199, loss-lb:0.1002, loss-ulb:0.0310, weight:0.63, lr:0.0009
[11:02:24.150] iteration:3904  t-loss:0.1596, loss-lb:0.1030, loss-ulb:0.0894, weight:0.63, lr:0.0009
[11:02:24.342] iteration:3905  t-loss:0.1214, loss-lb:0.0851, loss-ulb:0.0575, weight:0.63, lr:0.0009
[11:02:24.533] iteration:3906  t-loss:0.1237, loss-lb:0.0994, loss-ulb:0.0384, weight:0.63, lr:0.0009
[11:02:24.725] iteration:3907  t-loss:0.1267, loss-lb:0.1013, loss-ulb:0.0402, weight:0.63, lr:0.0009
[11:02:24.916] iteration:3908  t-loss:0.1279, loss-lb:0.1053, loss-ulb:0.0358, weight:0.63, lr:0.0009
[11:02:25.108] iteration:3909  t-loss:0.1143, loss-lb:0.0994, loss-ulb:0.0236, weight:0.63, lr:0.0009
[11:02:25.299] iteration:3910  t-loss:0.1212, loss-lb:0.1015, loss-ulb:0.0312, weight:0.63, lr:0.0009
[11:02:25.491] iteration:3911  t-loss:0.1377, loss-lb:0.1083, loss-ulb:0.0465, weight:0.63, lr:0.0009
[11:02:25.683] iteration:3912  t-loss:0.1099, loss-lb:0.0936, loss-ulb:0.0258, weight:0.63, lr:0.0009
[11:02:25.873] iteration:3913  t-loss:0.1070, loss-lb:0.0883, loss-ulb:0.0296, weight:0.63, lr:0.0009
[11:02:26.063] iteration:3914  t-loss:0.1137, loss-lb:0.0916, loss-ulb:0.0350, weight:0.63, lr:0.0009
[11:02:26.252] iteration:3915  t-loss:0.1242, loss-lb:0.1033, loss-ulb:0.0330, weight:0.63, lr:0.0009
[11:02:26.442] iteration:3916  t-loss:0.1282, loss-lb:0.1104, loss-ulb:0.0282, weight:0.63, lr:0.0009
[11:02:26.631] iteration:3917  t-loss:0.1321, loss-lb:0.1095, loss-ulb:0.0357, weight:0.63, lr:0.0009
[11:02:26.820] iteration:3918  t-loss:0.1313, loss-lb:0.1143, loss-ulb:0.0269, weight:0.63, lr:0.0009
[11:02:27.009] iteration:3919  t-loss:0.1124, loss-lb:0.0965, loss-ulb:0.0251, weight:0.63, lr:0.0009
[11:02:27.200] iteration:3920  t-loss:0.1501, loss-lb:0.0939, loss-ulb:0.0889, weight:0.63, lr:0.0009
[11:02:27.798] iteration:3921  t-loss:0.1337, loss-lb:0.1103, loss-ulb:0.0370, weight:0.63, lr:0.0009
[11:02:27.993] iteration:3922  t-loss:0.1282, loss-lb:0.1032, loss-ulb:0.0396, weight:0.63, lr:0.0009
[11:02:28.186] iteration:3923  t-loss:0.1117, loss-lb:0.0941, loss-ulb:0.0279, weight:0.63, lr:0.0009
[11:02:28.381] iteration:3924  t-loss:0.1150, loss-lb:0.0982, loss-ulb:0.0266, weight:0.63, lr:0.0009
[11:02:28.576] iteration:3925  t-loss:0.1159, loss-lb:0.1002, loss-ulb:0.0249, weight:0.63, lr:0.0009
[11:02:28.769] iteration:3926  t-loss:0.1153, loss-lb:0.0942, loss-ulb:0.0334, weight:0.63, lr:0.0009
[11:02:28.963] iteration:3927  t-loss:0.1139, loss-lb:0.0959, loss-ulb:0.0284, weight:0.63, lr:0.0009
[11:02:29.155] iteration:3928  t-loss:0.1183, loss-lb:0.0936, loss-ulb:0.0390, weight:0.63, lr:0.0009
[11:02:29.346] iteration:3929  t-loss:0.1209, loss-lb:0.1045, loss-ulb:0.0260, weight:0.63, lr:0.0009
[11:02:29.540] iteration:3930  t-loss:0.1264, loss-lb:0.0953, loss-ulb:0.0492, weight:0.63, lr:0.0009
[11:02:29.731] iteration:3931  t-loss:0.1468, loss-lb:0.0969, loss-ulb:0.0790, weight:0.63, lr:0.0009
[11:02:29.923] iteration:3932  t-loss:0.1285, loss-lb:0.1091, loss-ulb:0.0307, weight:0.63, lr:0.0009
[11:02:30.116] iteration:3933  t-loss:0.1177, loss-lb:0.0973, loss-ulb:0.0323, weight:0.63, lr:0.0009
[11:02:30.307] iteration:3934  t-loss:0.1208, loss-lb:0.0918, loss-ulb:0.0458, weight:0.63, lr:0.0009
[11:02:30.503] iteration:3935  t-loss:0.1109, loss-lb:0.0926, loss-ulb:0.0290, weight:0.63, lr:0.0009
[11:02:30.697] iteration:3936  t-loss:0.1091, loss-lb:0.0953, loss-ulb:0.0218, weight:0.63, lr:0.0009
[11:02:30.888] iteration:3937  t-loss:0.1245, loss-lb:0.1089, loss-ulb:0.0246, weight:0.63, lr:0.0009
[11:02:31.082] iteration:3938  t-loss:0.1293, loss-lb:0.0964, loss-ulb:0.0522, weight:0.63, lr:0.0009
[11:02:31.273] iteration:3939  t-loss:0.1380, loss-lb:0.1146, loss-ulb:0.0370, weight:0.63, lr:0.0009
[11:02:31.466] iteration:3940  t-loss:0.1193, loss-lb:0.1003, loss-ulb:0.0300, weight:0.63, lr:0.0009
[11:02:31.657] iteration:3941  t-loss:0.1195, loss-lb:0.1016, loss-ulb:0.0283, weight:0.63, lr:0.0009
[11:02:31.848] iteration:3942  t-loss:0.1397, loss-lb:0.1152, loss-ulb:0.0388, weight:0.63, lr:0.0009
[11:02:32.041] iteration:3943  t-loss:0.1209, loss-lb:0.1019, loss-ulb:0.0301, weight:0.63, lr:0.0009
[11:02:32.232] iteration:3944  t-loss:0.1222, loss-lb:0.1007, loss-ulb:0.0341, weight:0.63, lr:0.0009
[11:02:32.424] iteration:3945  t-loss:0.1309, loss-lb:0.1041, loss-ulb:0.0423, weight:0.63, lr:0.0009
[11:02:32.616] iteration:3946  t-loss:0.1187, loss-lb:0.0972, loss-ulb:0.0339, weight:0.63, lr:0.0009
[11:02:32.807] iteration:3947  t-loss:0.1256, loss-lb:0.1113, loss-ulb:0.0226, weight:0.63, lr:0.0009
[11:02:33.001] iteration:3948  t-loss:0.1204, loss-lb:0.0966, loss-ulb:0.0376, weight:0.63, lr:0.0009
[11:02:33.192] iteration:3949  t-loss:0.1144, loss-lb:0.0995, loss-ulb:0.0236, weight:0.63, lr:0.0009
[11:02:33.392] iteration:3950  t-loss:0.1219, loss-lb:0.1067, loss-ulb:0.0240, weight:0.63, lr:0.0009
[11:02:33.594] iteration:3951  t-loss:0.1153, loss-lb:0.1011, loss-ulb:0.0225, weight:0.63, lr:0.0009
[11:02:33.790] iteration:3952  t-loss:0.1257, loss-lb:0.1030, loss-ulb:0.0360, weight:0.63, lr:0.0009
[11:02:33.983] iteration:3953  t-loss:0.1091, loss-lb:0.0933, loss-ulb:0.0250, weight:0.63, lr:0.0009
[11:02:34.176] iteration:3954  t-loss:0.1560, loss-lb:0.0836, loss-ulb:0.1145, weight:0.63, lr:0.0009
[11:02:34.369] iteration:3955  t-loss:0.1738, loss-lb:0.1496, loss-ulb:0.0383, weight:0.63, lr:0.0009
[11:02:34.560] iteration:3956  t-loss:0.1227, loss-lb:0.1055, loss-ulb:0.0272, weight:0.63, lr:0.0009
[11:02:34.752] iteration:3957  t-loss:0.1156, loss-lb:0.0979, loss-ulb:0.0281, weight:0.63, lr:0.0009
[11:02:34.944] iteration:3958  t-loss:0.1208, loss-lb:0.0961, loss-ulb:0.0391, weight:0.63, lr:0.0009
[11:02:35.135] iteration:3959  t-loss:0.1434, loss-lb:0.1119, loss-ulb:0.0499, weight:0.63, lr:0.0009
[11:02:35.326] iteration:3960  t-loss:0.1270, loss-lb:0.0962, loss-ulb:0.0488, weight:0.63, lr:0.0009
[11:02:35.521] iteration:3961  t-loss:0.1162, loss-lb:0.0984, loss-ulb:0.0281, weight:0.63, lr:0.0009
[11:02:35.715] iteration:3962  t-loss:0.1354, loss-lb:0.1069, loss-ulb:0.0451, weight:0.63, lr:0.0009
[11:02:35.909] iteration:3963  t-loss:0.1245, loss-lb:0.0997, loss-ulb:0.0393, weight:0.63, lr:0.0009
[11:02:36.103] iteration:3964  t-loss:0.1134, loss-lb:0.0963, loss-ulb:0.0269, weight:0.63, lr:0.0009
[11:02:36.297] iteration:3965  t-loss:0.1133, loss-lb:0.0954, loss-ulb:0.0283, weight:0.63, lr:0.0009
[11:02:36.488] iteration:3966  t-loss:0.1132, loss-lb:0.0960, loss-ulb:0.0271, weight:0.63, lr:0.0009
[11:02:36.679] iteration:3967  t-loss:0.1210, loss-lb:0.1025, loss-ulb:0.0293, weight:0.63, lr:0.0009
[11:02:36.872] iteration:3968  t-loss:0.1297, loss-lb:0.1088, loss-ulb:0.0331, weight:0.63, lr:0.0009
[11:02:37.064] iteration:3969  t-loss:0.1260, loss-lb:0.0977, loss-ulb:0.0448, weight:0.63, lr:0.0009
[11:02:37.255] iteration:3970  t-loss:0.1204, loss-lb:0.1025, loss-ulb:0.0282, weight:0.63, lr:0.0009
[11:02:37.445] iteration:3971  t-loss:0.1134, loss-lb:0.0982, loss-ulb:0.0240, weight:0.63, lr:0.0009
[11:02:37.637] iteration:3972  t-loss:0.1272, loss-lb:0.1123, loss-ulb:0.0236, weight:0.63, lr:0.0009
[11:02:37.828] iteration:3973  t-loss:0.1401, loss-lb:0.1143, loss-ulb:0.0408, weight:0.63, lr:0.0009
[11:02:38.021] iteration:3974  t-loss:0.1256, loss-lb:0.0945, loss-ulb:0.0493, weight:0.63, lr:0.0009
[11:02:38.214] iteration:3975  t-loss:0.1321, loss-lb:0.0983, loss-ulb:0.0536, weight:0.63, lr:0.0009
[11:02:38.405] iteration:3976  t-loss:0.1171, loss-lb:0.0959, loss-ulb:0.0336, weight:0.63, lr:0.0009
[11:02:38.596] iteration:3977  t-loss:0.1611, loss-lb:0.1321, loss-ulb:0.0459, weight:0.63, lr:0.0009
[11:02:38.789] iteration:3978  t-loss:0.1167, loss-lb:0.0934, loss-ulb:0.0368, weight:0.63, lr:0.0009
[11:02:38.981] iteration:3979  t-loss:0.1261, loss-lb:0.1032, loss-ulb:0.0363, weight:0.63, lr:0.0009
[11:02:39.172] iteration:3980  t-loss:0.1183, loss-lb:0.0915, loss-ulb:0.0424, weight:0.63, lr:0.0009
[11:02:39.364] iteration:3981  t-loss:0.1448, loss-lb:0.1063, loss-ulb:0.0609, weight:0.63, lr:0.0009
[11:02:39.559] iteration:3982  t-loss:0.1223, loss-lb:0.1053, loss-ulb:0.0269, weight:0.63, lr:0.0009
[11:02:39.750] iteration:3983  t-loss:0.1081, loss-lb:0.0902, loss-ulb:0.0283, weight:0.63, lr:0.0009
[11:02:39.943] iteration:3984  t-loss:0.1225, loss-lb:0.1045, loss-ulb:0.0283, weight:0.63, lr:0.0009
[11:02:40.135] iteration:3985  t-loss:0.1394, loss-lb:0.1095, loss-ulb:0.0473, weight:0.63, lr:0.0009
[11:02:40.327] iteration:3986  t-loss:0.1216, loss-lb:0.1023, loss-ulb:0.0305, weight:0.63, lr:0.0009
[11:02:40.519] iteration:3987  t-loss:0.1406, loss-lb:0.1013, loss-ulb:0.0623, weight:0.63, lr:0.0009
[11:02:40.711] iteration:3988  t-loss:0.1126, loss-lb:0.0966, loss-ulb:0.0253, weight:0.63, lr:0.0009
[11:02:40.903] iteration:3989  t-loss:0.1366, loss-lb:0.1013, loss-ulb:0.0558, weight:0.63, lr:0.0009
[11:02:41.095] iteration:3990  t-loss:0.1431, loss-lb:0.1161, loss-ulb:0.0428, weight:0.63, lr:0.0009
[11:02:41.287] iteration:3991  t-loss:0.1515, loss-lb:0.1114, loss-ulb:0.0635, weight:0.63, lr:0.0009
[11:02:41.481] iteration:3992  t-loss:0.1217, loss-lb:0.1032, loss-ulb:0.0293, weight:0.63, lr:0.0009
[11:02:41.672] iteration:3993  t-loss:0.1501, loss-lb:0.1207, loss-ulb:0.0465, weight:0.63, lr:0.0009
[11:02:41.866] iteration:3994  t-loss:0.1801, loss-lb:0.1048, loss-ulb:0.1191, weight:0.63, lr:0.0009
[11:02:42.059] iteration:3995  t-loss:0.1224, loss-lb:0.0951, loss-ulb:0.0432, weight:0.63, lr:0.0009
[11:02:42.250] iteration:3996  t-loss:0.1347, loss-lb:0.0962, loss-ulb:0.0609, weight:0.63, lr:0.0009
[11:02:42.443] iteration:3997  t-loss:0.1184, loss-lb:0.0984, loss-ulb:0.0318, weight:0.63, lr:0.0009
[11:02:42.636] iteration:3998  t-loss:0.1900, loss-lb:0.1248, loss-ulb:0.1032, weight:0.63, lr:0.0009
[11:02:42.827] iteration:3999  t-loss:0.1213, loss-lb:0.1069, loss-ulb:0.0229, weight:0.63, lr:0.0009
[11:02:43.020] iteration:4000  t-loss:0.1194, loss-lb:0.1049, loss-ulb:0.0229, weight:0.63, lr:0.0009
[11:02:43.212] iteration:4001  t-loss:0.1389, loss-lb:0.1170, loss-ulb:0.0347, weight:0.63, lr:0.0009
[11:02:43.405] iteration:4002  t-loss:0.1454, loss-lb:0.1118, loss-ulb:0.0533, weight:0.63, lr:0.0009
[11:02:43.596] iteration:4003  t-loss:0.1342, loss-lb:0.1004, loss-ulb:0.0535, weight:0.63, lr:0.0009
[11:02:43.790] iteration:4004  t-loss:0.1149, loss-lb:0.1006, loss-ulb:0.0226, weight:0.63, lr:0.0009
[11:02:43.981] iteration:4005  t-loss:0.1531, loss-lb:0.1035, loss-ulb:0.0784, weight:0.63, lr:0.0009
[11:02:44.174] iteration:4006  t-loss:0.1241, loss-lb:0.1011, loss-ulb:0.0364, weight:0.63, lr:0.0009
[11:02:44.367] iteration:4007  t-loss:0.1502, loss-lb:0.1008, loss-ulb:0.0781, weight:0.63, lr:0.0009
[11:02:44.559] iteration:4008  t-loss:0.1171, loss-lb:0.1028, loss-ulb:0.0227, weight:0.63, lr:0.0009
[11:02:44.751] iteration:4009  t-loss:0.1241, loss-lb:0.1016, loss-ulb:0.0357, weight:0.63, lr:0.0009
[11:02:44.943] iteration:4010  t-loss:0.1451, loss-lb:0.1178, loss-ulb:0.0432, weight:0.63, lr:0.0009
[11:02:45.134] iteration:4011  t-loss:0.1271, loss-lb:0.1039, loss-ulb:0.0368, weight:0.63, lr:0.0009
[11:02:45.325] iteration:4012  t-loss:0.1341, loss-lb:0.1099, loss-ulb:0.0383, weight:0.63, lr:0.0009
[11:02:45.515] iteration:4013  t-loss:0.1165, loss-lb:0.0998, loss-ulb:0.0264, weight:0.63, lr:0.0009
[11:02:45.706] iteration:4014  t-loss:0.1068, loss-lb:0.0891, loss-ulb:0.0279, weight:0.63, lr:0.0009
[11:02:45.896] iteration:4015  t-loss:0.1181, loss-lb:0.1000, loss-ulb:0.0287, weight:0.63, lr:0.0009
[11:02:46.087] iteration:4016  t-loss:0.1210, loss-lb:0.0985, loss-ulb:0.0356, weight:0.63, lr:0.0009
[11:02:46.277] iteration:4017  t-loss:0.1346, loss-lb:0.1057, loss-ulb:0.0457, weight:0.63, lr:0.0009
[11:02:46.467] iteration:4018  t-loss:0.1165, loss-lb:0.1004, loss-ulb:0.0255, weight:0.63, lr:0.0009
[11:02:57.205]  <<Test>> - Ep:40  - mean_dice/mean_h95 - S:89.27/1.38, Best-S:89.27, T:89.81/1.40, Best-T:89.94
[11:02:57.205]           - AvgLoss(lb/ulb/all):0.1027/0.0385/0.1281
[11:02:57.740] iteration:4019  t-loss:0.1481, loss-lb:0.0891, loss-ulb:0.0934, weight:0.63, lr:0.0009
[11:02:57.934] iteration:4020  t-loss:0.1290, loss-lb:0.1068, loss-ulb:0.0352, weight:0.63, lr:0.0009
[11:02:58.126] iteration:4021  t-loss:0.1174, loss-lb:0.1020, loss-ulb:0.0243, weight:0.63, lr:0.0009
[11:02:58.319] iteration:4022  t-loss:0.1332, loss-lb:0.1085, loss-ulb:0.0390, weight:0.63, lr:0.0009
[11:02:58.511] iteration:4023  t-loss:0.1076, loss-lb:0.0915, loss-ulb:0.0255, weight:0.63, lr:0.0009
[11:02:58.704] iteration:4024  t-loss:0.1310, loss-lb:0.1031, loss-ulb:0.0441, weight:0.63, lr:0.0009
[11:02:58.897] iteration:4025  t-loss:0.1135, loss-lb:0.0991, loss-ulb:0.0227, weight:0.63, lr:0.0009
[11:02:59.089] iteration:4026  t-loss:0.1178, loss-lb:0.0937, loss-ulb:0.0380, weight:0.63, lr:0.0009
[11:02:59.281] iteration:4027  t-loss:0.1416, loss-lb:0.0949, loss-ulb:0.0738, weight:0.63, lr:0.0009
[11:02:59.476] iteration:4028  t-loss:0.1251, loss-lb:0.1036, loss-ulb:0.0340, weight:0.63, lr:0.0009
[11:02:59.669] iteration:4029  t-loss:0.1297, loss-lb:0.1109, loss-ulb:0.0297, weight:0.63, lr:0.0009
[11:02:59.862] iteration:4030  t-loss:0.1426, loss-lb:0.1231, loss-ulb:0.0309, weight:0.63, lr:0.0009
[11:03:00.054] iteration:4031  t-loss:0.1393, loss-lb:0.0927, loss-ulb:0.0737, weight:0.63, lr:0.0009
[11:03:00.246] iteration:4032  t-loss:0.1184, loss-lb:0.0969, loss-ulb:0.0341, weight:0.63, lr:0.0009
[11:03:00.439] iteration:4033  t-loss:0.1449, loss-lb:0.1049, loss-ulb:0.0632, weight:0.63, lr:0.0009
[11:03:00.631] iteration:4034  t-loss:0.1315, loss-lb:0.0935, loss-ulb:0.0600, weight:0.63, lr:0.0009
[11:03:00.824] iteration:4035  t-loss:0.1719, loss-lb:0.1171, loss-ulb:0.0868, weight:0.63, lr:0.0009
[11:03:01.016] iteration:4036  t-loss:0.1344, loss-lb:0.1100, loss-ulb:0.0386, weight:0.63, lr:0.0009
[11:03:01.208] iteration:4037  t-loss:0.1177, loss-lb:0.0945, loss-ulb:0.0367, weight:0.63, lr:0.0009
[11:03:01.399] iteration:4038  t-loss:0.1149, loss-lb:0.0974, loss-ulb:0.0277, weight:0.63, lr:0.0009
[11:03:01.591] iteration:4039  t-loss:0.1268, loss-lb:0.0936, loss-ulb:0.0525, weight:0.63, lr:0.0009
[11:03:01.783] iteration:4040  t-loss:0.1526, loss-lb:0.1115, loss-ulb:0.0652, weight:0.63, lr:0.0009
[11:03:01.975] iteration:4041  t-loss:0.1211, loss-lb:0.1044, loss-ulb:0.0264, weight:0.63, lr:0.0009
[11:03:02.167] iteration:4042  t-loss:0.1341, loss-lb:0.1138, loss-ulb:0.0321, weight:0.63, lr:0.0009
[11:03:02.359] iteration:4043  t-loss:0.1237, loss-lb:0.1052, loss-ulb:0.0292, weight:0.63, lr:0.0009
[11:03:02.550] iteration:4044  t-loss:0.1433, loss-lb:0.1123, loss-ulb:0.0490, weight:0.63, lr:0.0009
[11:03:02.742] iteration:4045  t-loss:0.1284, loss-lb:0.1063, loss-ulb:0.0350, weight:0.63, lr:0.0009
[11:03:02.934] iteration:4046  t-loss:0.1289, loss-lb:0.0986, loss-ulb:0.0479, weight:0.63, lr:0.0009
[11:03:03.127] iteration:4047  t-loss:0.1268, loss-lb:0.1070, loss-ulb:0.0313, weight:0.63, lr:0.0009
[11:03:03.318] iteration:4048  t-loss:0.1190, loss-lb:0.1027, loss-ulb:0.0258, weight:0.63, lr:0.0009
[11:03:03.510] iteration:4049  t-loss:0.1075, loss-lb:0.0919, loss-ulb:0.0247, weight:0.63, lr:0.0009
[11:03:03.702] iteration:4050  t-loss:0.1223, loss-lb:0.1031, loss-ulb:0.0304, weight:0.63, lr:0.0009
[11:03:03.894] iteration:4051  t-loss:0.1087, loss-lb:0.0922, loss-ulb:0.0238, weight:0.69, lr:0.0009
[11:03:04.087] iteration:4052  t-loss:0.1514, loss-lb:0.1311, loss-ulb:0.0292, weight:0.69, lr:0.0009
[11:03:04.279] iteration:4053  t-loss:0.1588, loss-lb:0.1046, loss-ulb:0.0780, weight:0.69, lr:0.0009
[11:03:04.471] iteration:4054  t-loss:0.1727, loss-lb:0.1260, loss-ulb:0.0673, weight:0.69, lr:0.0009
[11:03:04.663] iteration:4055  t-loss:0.1374, loss-lb:0.1084, loss-ulb:0.0418, weight:0.69, lr:0.0009
[11:03:04.855] iteration:4056  t-loss:0.1391, loss-lb:0.1157, loss-ulb:0.0337, weight:0.69, lr:0.0009
[11:03:05.046] iteration:4057  t-loss:0.1396, loss-lb:0.1151, loss-ulb:0.0353, weight:0.69, lr:0.0009
[11:03:05.240] iteration:4058  t-loss:0.1287, loss-lb:0.1040, loss-ulb:0.0356, weight:0.69, lr:0.0009
[11:03:05.431] iteration:4059  t-loss:0.1211, loss-lb:0.0942, loss-ulb:0.0387, weight:0.69, lr:0.0009
[11:03:05.624] iteration:4060  t-loss:0.1248, loss-lb:0.1036, loss-ulb:0.0306, weight:0.69, lr:0.0009
[11:03:05.815] iteration:4061  t-loss:0.1697, loss-lb:0.1290, loss-ulb:0.0587, weight:0.69, lr:0.0009
[11:03:06.008] iteration:4062  t-loss:0.2107, loss-lb:0.1327, loss-ulb:0.1124, weight:0.69, lr:0.0009
[11:03:06.214] iteration:4063  t-loss:0.1150, loss-lb:0.0944, loss-ulb:0.0297, weight:0.69, lr:0.0009
[11:03:06.412] iteration:4064  t-loss:0.1628, loss-lb:0.1298, loss-ulb:0.0475, weight:0.69, lr:0.0009
[11:03:06.607] iteration:4065  t-loss:0.1161, loss-lb:0.0995, loss-ulb:0.0239, weight:0.69, lr:0.0009
[11:03:06.799] iteration:4066  t-loss:0.1389, loss-lb:0.1124, loss-ulb:0.0381, weight:0.69, lr:0.0009
[11:03:06.991] iteration:4067  t-loss:0.1487, loss-lb:0.1256, loss-ulb:0.0331, weight:0.69, lr:0.0009
[11:03:07.183] iteration:4068  t-loss:0.2060, loss-lb:0.1052, loss-ulb:0.1451, weight:0.69, lr:0.0009
[11:03:07.374] iteration:4069  t-loss:0.1462, loss-lb:0.1148, loss-ulb:0.0452, weight:0.69, lr:0.0009
[11:03:07.567] iteration:4070  t-loss:0.1582, loss-lb:0.0984, loss-ulb:0.0862, weight:0.69, lr:0.0009
[11:03:07.760] iteration:4071  t-loss:0.1218, loss-lb:0.1007, loss-ulb:0.0304, weight:0.69, lr:0.0009
[11:03:07.952] iteration:4072  t-loss:0.1371, loss-lb:0.1169, loss-ulb:0.0291, weight:0.69, lr:0.0009
[11:03:08.144] iteration:4073  t-loss:0.1221, loss-lb:0.1035, loss-ulb:0.0267, weight:0.69, lr:0.0009
[11:03:08.335] iteration:4074  t-loss:0.1886, loss-lb:0.1453, loss-ulb:0.0624, weight:0.69, lr:0.0009
[11:03:08.527] iteration:4075  t-loss:0.1205, loss-lb:0.1045, loss-ulb:0.0230, weight:0.69, lr:0.0009
[11:03:08.719] iteration:4076  t-loss:0.1507, loss-lb:0.1263, loss-ulb:0.0351, weight:0.69, lr:0.0009
[11:03:08.911] iteration:4077  t-loss:0.1557, loss-lb:0.1253, loss-ulb:0.0439, weight:0.69, lr:0.0009
[11:03:09.103] iteration:4078  t-loss:0.1233, loss-lb:0.0978, loss-ulb:0.0367, weight:0.69, lr:0.0009
[11:03:09.296] iteration:4079  t-loss:0.1432, loss-lb:0.1202, loss-ulb:0.0330, weight:0.69, lr:0.0009
[11:03:09.488] iteration:4080  t-loss:0.1337, loss-lb:0.1088, loss-ulb:0.0359, weight:0.69, lr:0.0009
[11:03:09.679] iteration:4081  t-loss:0.1678, loss-lb:0.1164, loss-ulb:0.0740, weight:0.69, lr:0.0009
[11:03:09.872] iteration:4082  t-loss:0.1695, loss-lb:0.1360, loss-ulb:0.0483, weight:0.69, lr:0.0009
[11:03:10.063] iteration:4083  t-loss:0.1292, loss-lb:0.1065, loss-ulb:0.0327, weight:0.69, lr:0.0009
[11:03:10.255] iteration:4084  t-loss:0.2338, loss-lb:0.1989, loss-ulb:0.0502, weight:0.69, lr:0.0009
[11:03:10.447] iteration:4085  t-loss:0.1460, loss-lb:0.1127, loss-ulb:0.0480, weight:0.69, lr:0.0009
[11:03:10.639] iteration:4086  t-loss:0.1518, loss-lb:0.1150, loss-ulb:0.0530, weight:0.69, lr:0.0009
[11:03:10.831] iteration:4087  t-loss:0.1284, loss-lb:0.1099, loss-ulb:0.0267, weight:0.69, lr:0.0009
[11:03:11.023] iteration:4088  t-loss:0.1912, loss-lb:0.1044, loss-ulb:0.1250, weight:0.69, lr:0.0009
[11:03:11.215] iteration:4089  t-loss:0.2187, loss-lb:0.1557, loss-ulb:0.0907, weight:0.69, lr:0.0009
[11:03:11.407] iteration:4090  t-loss:0.2659, loss-lb:0.2274, loss-ulb:0.0555, weight:0.69, lr:0.0009
[11:03:11.599] iteration:4091  t-loss:0.1385, loss-lb:0.1072, loss-ulb:0.0450, weight:0.69, lr:0.0009
[11:03:11.791] iteration:4092  t-loss:0.1323, loss-lb:0.1091, loss-ulb:0.0333, weight:0.69, lr:0.0009
[11:03:11.983] iteration:4093  t-loss:0.1651, loss-lb:0.1149, loss-ulb:0.0723, weight:0.69, lr:0.0009
[11:03:12.176] iteration:4094  t-loss:0.2449, loss-lb:0.1599, loss-ulb:0.1224, weight:0.69, lr:0.0009
[11:03:12.368] iteration:4095  t-loss:0.1600, loss-lb:0.1335, loss-ulb:0.0381, weight:0.69, lr:0.0009
[11:03:12.561] iteration:4096  t-loss:0.1738, loss-lb:0.1377, loss-ulb:0.0521, weight:0.69, lr:0.0009
[11:03:12.752] iteration:4097  t-loss:0.1554, loss-lb:0.1213, loss-ulb:0.0490, weight:0.69, lr:0.0009
[11:03:12.944] iteration:4098  t-loss:0.1755, loss-lb:0.1295, loss-ulb:0.0663, weight:0.69, lr:0.0009
[11:03:13.136] iteration:4099  t-loss:0.2128, loss-lb:0.1593, loss-ulb:0.0770, weight:0.69, lr:0.0009
[11:03:13.328] iteration:4100  t-loss:0.2236, loss-lb:0.1541, loss-ulb:0.1002, weight:0.69, lr:0.0009
[11:03:13.520] iteration:4101  t-loss:0.1261, loss-lb:0.1036, loss-ulb:0.0324, weight:0.69, lr:0.0009
[11:03:13.712] iteration:4102  t-loss:0.1629, loss-lb:0.1184, loss-ulb:0.0641, weight:0.69, lr:0.0009
[11:03:13.904] iteration:4103  t-loss:0.1635, loss-lb:0.1370, loss-ulb:0.0381, weight:0.69, lr:0.0009
[11:03:14.097] iteration:4104  t-loss:0.1450, loss-lb:0.1213, loss-ulb:0.0342, weight:0.69, lr:0.0009
[11:03:14.289] iteration:4105  t-loss:0.1447, loss-lb:0.1146, loss-ulb:0.0434, weight:0.69, lr:0.0009
[11:03:14.481] iteration:4106  t-loss:0.1580, loss-lb:0.1241, loss-ulb:0.0489, weight:0.69, lr:0.0009
[11:03:14.673] iteration:4107  t-loss:0.1606, loss-lb:0.1202, loss-ulb:0.0582, weight:0.69, lr:0.0009
[11:03:14.865] iteration:4108  t-loss:0.1793, loss-lb:0.1168, loss-ulb:0.0900, weight:0.69, lr:0.0009
[11:03:15.057] iteration:4109  t-loss:0.1726, loss-lb:0.1229, loss-ulb:0.0715, weight:0.69, lr:0.0009
[11:03:15.247] iteration:4110  t-loss:0.1398, loss-lb:0.1125, loss-ulb:0.0392, weight:0.69, lr:0.0009
[11:03:15.437] iteration:4111  t-loss:0.1499, loss-lb:0.1251, loss-ulb:0.0358, weight:0.69, lr:0.0009
[11:03:15.628] iteration:4112  t-loss:0.1385, loss-lb:0.1218, loss-ulb:0.0241, weight:0.69, lr:0.0009
[11:03:15.820] iteration:4113  t-loss:0.1734, loss-lb:0.1466, loss-ulb:0.0386, weight:0.69, lr:0.0009
[11:03:16.010] iteration:4114  t-loss:0.1538, loss-lb:0.1146, loss-ulb:0.0565, weight:0.69, lr:0.0009
[11:03:16.201] iteration:4115  t-loss:0.1709, loss-lb:0.1160, loss-ulb:0.0791, weight:0.69, lr:0.0009
[11:03:16.391] iteration:4116  t-loss:0.1642, loss-lb:0.1370, loss-ulb:0.0392, weight:0.69, lr:0.0009
[11:03:16.981] iteration:4117  t-loss:0.1372, loss-lb:0.1126, loss-ulb:0.0354, weight:0.69, lr:0.0009
[11:03:17.178] iteration:4118  t-loss:0.1370, loss-lb:0.1105, loss-ulb:0.0381, weight:0.69, lr:0.0009
[11:03:17.371] iteration:4119  t-loss:0.2365, loss-lb:0.1152, loss-ulb:0.1747, weight:0.69, lr:0.0009
[11:03:17.563] iteration:4120  t-loss:0.1503, loss-lb:0.1269, loss-ulb:0.0337, weight:0.69, lr:0.0009
[11:03:17.755] iteration:4121  t-loss:0.1270, loss-lb:0.1052, loss-ulb:0.0314, weight:0.69, lr:0.0009
[11:03:17.947] iteration:4122  t-loss:0.1761, loss-lb:0.1380, loss-ulb:0.0549, weight:0.69, lr:0.0009
[11:03:18.140] iteration:4123  t-loss:0.1295, loss-lb:0.1053, loss-ulb:0.0349, weight:0.69, lr:0.0009
[11:03:18.331] iteration:4124  t-loss:0.1977, loss-lb:0.1402, loss-ulb:0.0828, weight:0.69, lr:0.0009
[11:03:18.523] iteration:4125  t-loss:0.1380, loss-lb:0.1099, loss-ulb:0.0405, weight:0.69, lr:0.0009
[11:03:18.715] iteration:4126  t-loss:0.1535, loss-lb:0.1224, loss-ulb:0.0447, weight:0.69, lr:0.0009
[11:03:18.908] iteration:4127  t-loss:0.1358, loss-lb:0.1067, loss-ulb:0.0419, weight:0.69, lr:0.0009
[11:03:19.100] iteration:4128  t-loss:0.1461, loss-lb:0.1269, loss-ulb:0.0277, weight:0.69, lr:0.0009
[11:03:19.292] iteration:4129  t-loss:0.1361, loss-lb:0.1132, loss-ulb:0.0329, weight:0.69, lr:0.0009
[11:03:19.484] iteration:4130  t-loss:0.1435, loss-lb:0.1113, loss-ulb:0.0463, weight:0.69, lr:0.0009
[11:03:19.676] iteration:4131  t-loss:0.1576, loss-lb:0.1152, loss-ulb:0.0611, weight:0.69, lr:0.0009
[11:03:19.869] iteration:4132  t-loss:0.1727, loss-lb:0.1012, loss-ulb:0.1030, weight:0.69, lr:0.0009
[11:03:20.061] iteration:4133  t-loss:0.1487, loss-lb:0.1228, loss-ulb:0.0373, weight:0.69, lr:0.0009
[11:03:20.253] iteration:4134  t-loss:0.1456, loss-lb:0.1097, loss-ulb:0.0518, weight:0.69, lr:0.0009
[11:03:20.445] iteration:4135  t-loss:0.1388, loss-lb:0.1083, loss-ulb:0.0439, weight:0.69, lr:0.0009
[11:03:20.637] iteration:4136  t-loss:0.1177, loss-lb:0.0982, loss-ulb:0.0281, weight:0.69, lr:0.0009
[11:03:20.830] iteration:4137  t-loss:0.1319, loss-lb:0.1061, loss-ulb:0.0371, weight:0.69, lr:0.0009
[11:03:21.023] iteration:4138  t-loss:0.1874, loss-lb:0.1212, loss-ulb:0.0954, weight:0.69, lr:0.0009
[11:03:21.215] iteration:4139  t-loss:0.1468, loss-lb:0.1217, loss-ulb:0.0361, weight:0.69, lr:0.0009
[11:03:21.408] iteration:4140  t-loss:0.1266, loss-lb:0.1078, loss-ulb:0.0270, weight:0.69, lr:0.0009
[11:03:21.600] iteration:4141  t-loss:0.1327, loss-lb:0.1046, loss-ulb:0.0405, weight:0.69, lr:0.0009
[11:03:21.792] iteration:4142  t-loss:0.1337, loss-lb:0.1157, loss-ulb:0.0259, weight:0.69, lr:0.0009
[11:03:21.984] iteration:4143  t-loss:0.1314, loss-lb:0.1058, loss-ulb:0.0368, weight:0.69, lr:0.0009
[11:03:22.176] iteration:4144  t-loss:0.1497, loss-lb:0.1262, loss-ulb:0.0338, weight:0.69, lr:0.0009
[11:03:22.369] iteration:4145  t-loss:0.1203, loss-lb:0.1001, loss-ulb:0.0291, weight:0.69, lr:0.0009
[11:03:22.560] iteration:4146  t-loss:0.1479, loss-lb:0.1219, loss-ulb:0.0375, weight:0.69, lr:0.0009
[11:03:22.753] iteration:4147  t-loss:0.1221, loss-lb:0.0952, loss-ulb:0.0387, weight:0.69, lr:0.0009
[11:03:22.945] iteration:4148  t-loss:0.1420, loss-lb:0.1087, loss-ulb:0.0479, weight:0.69, lr:0.0009
[11:03:23.139] iteration:4149  t-loss:0.1043, loss-lb:0.0884, loss-ulb:0.0230, weight:0.69, lr:0.0009
[11:03:23.330] iteration:4150  t-loss:0.1134, loss-lb:0.0957, loss-ulb:0.0255, weight:0.69, lr:0.0009
[11:03:23.522] iteration:4151  t-loss:0.1082, loss-lb:0.0915, loss-ulb:0.0240, weight:0.69, lr:0.0009
[11:03:23.716] iteration:4152  t-loss:0.1161, loss-lb:0.0924, loss-ulb:0.0341, weight:0.69, lr:0.0009
[11:03:23.909] iteration:4153  t-loss:0.1262, loss-lb:0.1080, loss-ulb:0.0263, weight:0.69, lr:0.0009
[11:03:24.100] iteration:4154  t-loss:0.1510, loss-lb:0.0995, loss-ulb:0.0742, weight:0.69, lr:0.0009
[11:03:24.292] iteration:4155  t-loss:0.1168, loss-lb:0.0988, loss-ulb:0.0260, weight:0.69, lr:0.0009
[11:03:24.484] iteration:4156  t-loss:0.1335, loss-lb:0.1095, loss-ulb:0.0345, weight:0.69, lr:0.0009
[11:03:24.677] iteration:4157  t-loss:0.1554, loss-lb:0.1087, loss-ulb:0.0674, weight:0.69, lr:0.0009
[11:03:24.869] iteration:4158  t-loss:0.1339, loss-lb:0.1066, loss-ulb:0.0392, weight:0.69, lr:0.0009
[11:03:25.061] iteration:4159  t-loss:0.1594, loss-lb:0.1109, loss-ulb:0.0699, weight:0.69, lr:0.0009
[11:03:25.253] iteration:4160  t-loss:0.1122, loss-lb:0.0922, loss-ulb:0.0289, weight:0.69, lr:0.0009
[11:03:25.445] iteration:4161  t-loss:0.1202, loss-lb:0.0995, loss-ulb:0.0297, weight:0.69, lr:0.0009
[11:03:25.637] iteration:4162  t-loss:0.1167, loss-lb:0.0977, loss-ulb:0.0274, weight:0.69, lr:0.0009
[11:03:25.830] iteration:4163  t-loss:0.1254, loss-lb:0.1081, loss-ulb:0.0249, weight:0.69, lr:0.0009
[11:03:26.024] iteration:4164  t-loss:0.1288, loss-lb:0.1071, loss-ulb:0.0312, weight:0.69, lr:0.0009
[11:03:26.215] iteration:4165  t-loss:0.1420, loss-lb:0.1026, loss-ulb:0.0567, weight:0.69, lr:0.0009
[11:03:26.408] iteration:4166  t-loss:0.1409, loss-lb:0.1236, loss-ulb:0.0249, weight:0.69, lr:0.0009
[11:03:26.599] iteration:4167  t-loss:0.1212, loss-lb:0.0970, loss-ulb:0.0349, weight:0.69, lr:0.0009
[11:03:26.791] iteration:4168  t-loss:0.1274, loss-lb:0.1070, loss-ulb:0.0294, weight:0.69, lr:0.0009
[11:03:26.984] iteration:4169  t-loss:0.1354, loss-lb:0.1023, loss-ulb:0.0476, weight:0.69, lr:0.0009
[11:03:27.174] iteration:4170  t-loss:0.1347, loss-lb:0.0952, loss-ulb:0.0570, weight:0.69, lr:0.0009
[11:03:27.367] iteration:4171  t-loss:0.1505, loss-lb:0.1062, loss-ulb:0.0638, weight:0.69, lr:0.0009
[11:03:27.559] iteration:4172  t-loss:0.1438, loss-lb:0.1064, loss-ulb:0.0539, weight:0.69, lr:0.0009
[11:03:27.752] iteration:4173  t-loss:0.1369, loss-lb:0.0967, loss-ulb:0.0580, weight:0.69, lr:0.0009
[11:03:27.945] iteration:4174  t-loss:0.1185, loss-lb:0.1004, loss-ulb:0.0261, weight:0.69, lr:0.0009
[11:03:28.136] iteration:4175  t-loss:0.1202, loss-lb:0.1061, loss-ulb:0.0203, weight:0.69, lr:0.0009
[11:03:28.328] iteration:4176  t-loss:0.1388, loss-lb:0.0978, loss-ulb:0.0589, weight:0.69, lr:0.0009
[11:03:28.520] iteration:4177  t-loss:0.1244, loss-lb:0.0970, loss-ulb:0.0395, weight:0.69, lr:0.0009
[11:03:28.712] iteration:4178  t-loss:0.1209, loss-lb:0.0945, loss-ulb:0.0380, weight:0.69, lr:0.0009
[11:03:28.903] iteration:4179  t-loss:0.1224, loss-lb:0.1014, loss-ulb:0.0304, weight:0.69, lr:0.0009
[11:03:29.095] iteration:4180  t-loss:0.1356, loss-lb:0.1094, loss-ulb:0.0377, weight:0.69, lr:0.0009
[11:03:29.287] iteration:4181  t-loss:0.1549, loss-lb:0.1086, loss-ulb:0.0667, weight:0.69, lr:0.0009
[11:03:29.484] iteration:4182  t-loss:0.1219, loss-lb:0.1022, loss-ulb:0.0285, weight:0.69, lr:0.0009
[11:03:29.675] iteration:4183  t-loss:0.1318, loss-lb:0.1031, loss-ulb:0.0414, weight:0.69, lr:0.0009
[11:03:29.869] iteration:4184  t-loss:0.1872, loss-lb:0.1125, loss-ulb:0.1076, weight:0.69, lr:0.0009
[11:03:30.060] iteration:4185  t-loss:0.1225, loss-lb:0.1036, loss-ulb:0.0273, weight:0.69, lr:0.0009
[11:03:30.252] iteration:4186  t-loss:0.1117, loss-lb:0.0953, loss-ulb:0.0235, weight:0.69, lr:0.0009
[11:03:30.444] iteration:4187  t-loss:0.1198, loss-lb:0.1003, loss-ulb:0.0281, weight:0.69, lr:0.0009
[11:03:30.635] iteration:4188  t-loss:0.1621, loss-lb:0.1329, loss-ulb:0.0421, weight:0.69, lr:0.0009
[11:03:30.827] iteration:4189  t-loss:0.1310, loss-lb:0.1078, loss-ulb:0.0333, weight:0.69, lr:0.0009
[11:03:31.019] iteration:4190  t-loss:0.1414, loss-lb:0.1100, loss-ulb:0.0452, weight:0.69, lr:0.0009
[11:03:31.211] iteration:4191  t-loss:0.1403, loss-lb:0.0954, loss-ulb:0.0647, weight:0.69, lr:0.0009
[11:03:31.403] iteration:4192  t-loss:0.1419, loss-lb:0.1086, loss-ulb:0.0480, weight:0.69, lr:0.0009
[11:03:31.596] iteration:4193  t-loss:0.1241, loss-lb:0.1007, loss-ulb:0.0338, weight:0.69, lr:0.0009
[11:03:31.788] iteration:4194  t-loss:0.1424, loss-lb:0.1042, loss-ulb:0.0549, weight:0.69, lr:0.0009
[11:03:31.981] iteration:4195  t-loss:0.1392, loss-lb:0.1046, loss-ulb:0.0499, weight:0.69, lr:0.0009
[11:03:32.174] iteration:4196  t-loss:0.1454, loss-lb:0.1252, loss-ulb:0.0290, weight:0.69, lr:0.0009
[11:03:32.365] iteration:4197  t-loss:0.1132, loss-lb:0.0932, loss-ulb:0.0289, weight:0.69, lr:0.0009
[11:03:32.557] iteration:4198  t-loss:0.1614, loss-lb:0.1040, loss-ulb:0.0826, weight:0.69, lr:0.0009
[11:03:32.750] iteration:4199  t-loss:0.1494, loss-lb:0.1264, loss-ulb:0.0330, weight:0.69, lr:0.0009
[11:03:32.941] iteration:4200  t-loss:0.1418, loss-lb:0.1095, loss-ulb:0.0465, weight:0.69, lr:0.0009
[11:03:33.134] iteration:4201  t-loss:0.2143, loss-lb:0.1071, loss-ulb:0.1410, weight:0.76, lr:0.0009
[11:03:33.325] iteration:4202  t-loss:0.1142, loss-lb:0.0901, loss-ulb:0.0316, weight:0.76, lr:0.0009
[11:03:33.517] iteration:4203  t-loss:0.1333, loss-lb:0.0982, loss-ulb:0.0462, weight:0.76, lr:0.0009
[11:03:33.709] iteration:4204  t-loss:0.1228, loss-lb:0.1013, loss-ulb:0.0284, weight:0.76, lr:0.0009
[11:03:33.899] iteration:4205  t-loss:0.1651, loss-lb:0.1320, loss-ulb:0.0435, weight:0.76, lr:0.0009
[11:03:34.092] iteration:4206  t-loss:0.1474, loss-lb:0.1119, loss-ulb:0.0467, weight:0.76, lr:0.0009
[11:03:34.284] iteration:4207  t-loss:0.1499, loss-lb:0.1154, loss-ulb:0.0455, weight:0.76, lr:0.0009
[11:03:34.475] iteration:4208  t-loss:0.1628, loss-lb:0.1394, loss-ulb:0.0308, weight:0.76, lr:0.0009
[11:03:34.665] iteration:4209  t-loss:0.2089, loss-lb:0.1768, loss-ulb:0.0423, weight:0.76, lr:0.0009
[11:03:34.855] iteration:4210  t-loss:0.1379, loss-lb:0.1059, loss-ulb:0.0422, weight:0.76, lr:0.0009
[11:03:35.047] iteration:4211  t-loss:0.1346, loss-lb:0.1142, loss-ulb:0.0268, weight:0.76, lr:0.0009
[11:03:35.237] iteration:4212  t-loss:0.1413, loss-lb:0.1126, loss-ulb:0.0378, weight:0.76, lr:0.0009
[11:03:35.428] iteration:4213  t-loss:0.1835, loss-lb:0.1266, loss-ulb:0.0749, weight:0.76, lr:0.0009
[11:03:35.618] iteration:4214  t-loss:0.1934, loss-lb:0.1190, loss-ulb:0.0979, weight:0.76, lr:0.0009
[11:03:47.906]  <<Test>> - Ep:42  - mean_dice/mean_h95 - S:89.28/1.50, Best-S:89.28, T:89.87/1.40, Best-T:89.94
[11:03:47.907]           - AvgLoss(lb/ulb/all):0.1091/0.0503/0.1530
[11:03:48.424] iteration:4215  t-loss:0.1693, loss-lb:0.1062, loss-ulb:0.0831, weight:0.76, lr:0.0009
[11:03:48.621] iteration:4216  t-loss:0.1449, loss-lb:0.1123, loss-ulb:0.0428, weight:0.76, lr:0.0009
[11:03:48.813] iteration:4217  t-loss:0.2548, loss-lb:0.1197, loss-ulb:0.1778, weight:0.76, lr:0.0009
[11:03:49.005] iteration:4218  t-loss:0.1676, loss-lb:0.1247, loss-ulb:0.0565, weight:0.76, lr:0.0009
[11:03:49.198] iteration:4219  t-loss:0.1609, loss-lb:0.1350, loss-ulb:0.0340, weight:0.76, lr:0.0009
[11:03:49.390] iteration:4220  t-loss:0.2250, loss-lb:0.1277, loss-ulb:0.1282, weight:0.76, lr:0.0009
[11:03:49.581] iteration:4221  t-loss:0.1367, loss-lb:0.1169, loss-ulb:0.0260, weight:0.76, lr:0.0009
[11:03:49.773] iteration:4222  t-loss:0.1419, loss-lb:0.1191, loss-ulb:0.0300, weight:0.76, lr:0.0009
[11:03:49.964] iteration:4223  t-loss:0.1271, loss-lb:0.1049, loss-ulb:0.0292, weight:0.76, lr:0.0009
[11:03:50.156] iteration:4224  t-loss:0.1239, loss-lb:0.1051, loss-ulb:0.0247, weight:0.76, lr:0.0009
[11:03:50.347] iteration:4225  t-loss:0.1351, loss-lb:0.1105, loss-ulb:0.0324, weight:0.76, lr:0.0009
[11:03:50.541] iteration:4226  t-loss:0.1821, loss-lb:0.1096, loss-ulb:0.0954, weight:0.76, lr:0.0009
[11:03:50.730] iteration:4227  t-loss:0.1593, loss-lb:0.1171, loss-ulb:0.0555, weight:0.76, lr:0.0009
[11:03:50.923] iteration:4228  t-loss:0.1367, loss-lb:0.1165, loss-ulb:0.0266, weight:0.76, lr:0.0009
[11:03:51.117] iteration:4229  t-loss:0.2035, loss-lb:0.1375, loss-ulb:0.0869, weight:0.76, lr:0.0009
[11:03:51.314] iteration:4230  t-loss:0.1309, loss-lb:0.1088, loss-ulb:0.0290, weight:0.76, lr:0.0009
[11:03:51.508] iteration:4231  t-loss:0.1604, loss-lb:0.1352, loss-ulb:0.0332, weight:0.76, lr:0.0009
[11:03:51.704] iteration:4232  t-loss:0.1523, loss-lb:0.1226, loss-ulb:0.0391, weight:0.76, lr:0.0009
[11:03:51.898] iteration:4233  t-loss:0.1335, loss-lb:0.1095, loss-ulb:0.0316, weight:0.76, lr:0.0009
[11:03:52.089] iteration:4234  t-loss:0.1524, loss-lb:0.1181, loss-ulb:0.0452, weight:0.76, lr:0.0009
[11:03:52.281] iteration:4235  t-loss:0.1344, loss-lb:0.1148, loss-ulb:0.0259, weight:0.76, lr:0.0009
[11:03:52.473] iteration:4236  t-loss:0.1484, loss-lb:0.1135, loss-ulb:0.0460, weight:0.76, lr:0.0009
[11:03:52.666] iteration:4237  t-loss:0.1528, loss-lb:0.1269, loss-ulb:0.0341, weight:0.76, lr:0.0009
[11:03:52.858] iteration:4238  t-loss:0.1439, loss-lb:0.1093, loss-ulb:0.0455, weight:0.76, lr:0.0009
[11:03:53.050] iteration:4239  t-loss:0.1520, loss-lb:0.1204, loss-ulb:0.0417, weight:0.76, lr:0.0009
[11:03:53.241] iteration:4240  t-loss:0.1348, loss-lb:0.1068, loss-ulb:0.0368, weight:0.76, lr:0.0009
[11:03:53.433] iteration:4241  t-loss:0.1435, loss-lb:0.1098, loss-ulb:0.0442, weight:0.76, lr:0.0009
[11:03:53.623] iteration:4242  t-loss:0.1703, loss-lb:0.1373, loss-ulb:0.0434, weight:0.76, lr:0.0009
[11:03:53.816] iteration:4243  t-loss:0.1379, loss-lb:0.1111, loss-ulb:0.0353, weight:0.76, lr:0.0009
[11:03:54.009] iteration:4244  t-loss:0.2100, loss-lb:0.1807, loss-ulb:0.0386, weight:0.76, lr:0.0009
[11:03:54.200] iteration:4245  t-loss:0.1158, loss-lb:0.0930, loss-ulb:0.0300, weight:0.76, lr:0.0009
[11:03:54.391] iteration:4246  t-loss:0.1902, loss-lb:0.1358, loss-ulb:0.0716, weight:0.76, lr:0.0009
[11:03:54.583] iteration:4247  t-loss:0.1517, loss-lb:0.1037, loss-ulb:0.0632, weight:0.76, lr:0.0009
[11:03:54.773] iteration:4248  t-loss:0.1268, loss-lb:0.1000, loss-ulb:0.0354, weight:0.76, lr:0.0009
[11:03:54.966] iteration:4249  t-loss:0.1392, loss-lb:0.1161, loss-ulb:0.0304, weight:0.76, lr:0.0009
[11:03:55.158] iteration:4250  t-loss:0.1393, loss-lb:0.1074, loss-ulb:0.0420, weight:0.76, lr:0.0009
[11:03:55.349] iteration:4251  t-loss:0.1339, loss-lb:0.1001, loss-ulb:0.0444, weight:0.76, lr:0.0009
[11:03:55.540] iteration:4252  t-loss:0.1295, loss-lb:0.1088, loss-ulb:0.0274, weight:0.76, lr:0.0009
[11:03:55.731] iteration:4253  t-loss:0.1518, loss-lb:0.1222, loss-ulb:0.0390, weight:0.76, lr:0.0009
[11:03:55.923] iteration:4254  t-loss:0.1443, loss-lb:0.1035, loss-ulb:0.0537, weight:0.76, lr:0.0009
[11:03:56.113] iteration:4255  t-loss:0.1449, loss-lb:0.1125, loss-ulb:0.0427, weight:0.76, lr:0.0009
[11:03:56.305] iteration:4256  t-loss:0.1155, loss-lb:0.0939, loss-ulb:0.0284, weight:0.76, lr:0.0009
[11:03:56.499] iteration:4257  t-loss:0.1349, loss-lb:0.1091, loss-ulb:0.0340, weight:0.76, lr:0.0009
[11:03:56.689] iteration:4258  t-loss:0.1237, loss-lb:0.0992, loss-ulb:0.0322, weight:0.76, lr:0.0009
[11:03:56.881] iteration:4259  t-loss:0.1173, loss-lb:0.0901, loss-ulb:0.0358, weight:0.76, lr:0.0009
[11:03:57.073] iteration:4260  t-loss:0.1303, loss-lb:0.0982, loss-ulb:0.0423, weight:0.76, lr:0.0009
[11:03:57.264] iteration:4261  t-loss:0.1182, loss-lb:0.0918, loss-ulb:0.0348, weight:0.76, lr:0.0009
[11:03:57.456] iteration:4262  t-loss:0.1272, loss-lb:0.1038, loss-ulb:0.0309, weight:0.76, lr:0.0009
[11:03:57.651] iteration:4263  t-loss:0.1323, loss-lb:0.1078, loss-ulb:0.0323, weight:0.76, lr:0.0009
[11:03:57.843] iteration:4264  t-loss:0.1128, loss-lb:0.0925, loss-ulb:0.0268, weight:0.76, lr:0.0009
[11:03:58.036] iteration:4265  t-loss:0.1203, loss-lb:0.0976, loss-ulb:0.0299, weight:0.76, lr:0.0009
[11:03:58.227] iteration:4266  t-loss:0.1404, loss-lb:0.1181, loss-ulb:0.0294, weight:0.76, lr:0.0009
[11:03:58.418] iteration:4267  t-loss:0.1310, loss-lb:0.1118, loss-ulb:0.0252, weight:0.76, lr:0.0009
[11:03:58.609] iteration:4268  t-loss:0.1146, loss-lb:0.0953, loss-ulb:0.0254, weight:0.76, lr:0.0009
[11:03:58.800] iteration:4269  t-loss:0.1241, loss-lb:0.1002, loss-ulb:0.0315, weight:0.76, lr:0.0009
[11:03:58.993] iteration:4270  t-loss:0.1413, loss-lb:0.1002, loss-ulb:0.0541, weight:0.76, lr:0.0009
[11:03:59.184] iteration:4271  t-loss:0.1245, loss-lb:0.1045, loss-ulb:0.0263, weight:0.76, lr:0.0009
[11:03:59.375] iteration:4272  t-loss:0.1149, loss-lb:0.0949, loss-ulb:0.0264, weight:0.76, lr:0.0009
[11:03:59.566] iteration:4273  t-loss:0.1334, loss-lb:0.1042, loss-ulb:0.0384, weight:0.76, lr:0.0009
[11:03:59.757] iteration:4274  t-loss:0.1247, loss-lb:0.0928, loss-ulb:0.0420, weight:0.76, lr:0.0009
[11:03:59.949] iteration:4275  t-loss:0.1376, loss-lb:0.1023, loss-ulb:0.0464, weight:0.76, lr:0.0009
[11:04:00.139] iteration:4276  t-loss:0.1247, loss-lb:0.0859, loss-ulb:0.0511, weight:0.76, lr:0.0009
[11:04:00.331] iteration:4277  t-loss:0.1307, loss-lb:0.0975, loss-ulb:0.0438, weight:0.76, lr:0.0009
[11:04:00.522] iteration:4278  t-loss:0.1253, loss-lb:0.1032, loss-ulb:0.0291, weight:0.76, lr:0.0009
[11:04:00.714] iteration:4279  t-loss:0.1596, loss-lb:0.1136, loss-ulb:0.0606, weight:0.76, lr:0.0009
[11:04:00.905] iteration:4280  t-loss:0.1262, loss-lb:0.0974, loss-ulb:0.0380, weight:0.76, lr:0.0009
[11:04:01.096] iteration:4281  t-loss:0.1198, loss-lb:0.0974, loss-ulb:0.0295, weight:0.76, lr:0.0009
[11:04:01.287] iteration:4282  t-loss:0.1158, loss-lb:0.0914, loss-ulb:0.0321, weight:0.76, lr:0.0009
[11:04:01.477] iteration:4283  t-loss:0.1292, loss-lb:0.1052, loss-ulb:0.0316, weight:0.76, lr:0.0009
[11:04:01.670] iteration:4284  t-loss:0.1083, loss-lb:0.0869, loss-ulb:0.0282, weight:0.76, lr:0.0009
[11:04:01.863] iteration:4285  t-loss:0.1097, loss-lb:0.0941, loss-ulb:0.0205, weight:0.76, lr:0.0009
[11:04:02.057] iteration:4286  t-loss:0.1181, loss-lb:0.0993, loss-ulb:0.0248, weight:0.76, lr:0.0009
[11:04:02.251] iteration:4287  t-loss:0.1233, loss-lb:0.1037, loss-ulb:0.0258, weight:0.76, lr:0.0009
[11:04:02.445] iteration:4288  t-loss:0.1179, loss-lb:0.0987, loss-ulb:0.0253, weight:0.76, lr:0.0009
[11:04:02.638] iteration:4289  t-loss:0.1281, loss-lb:0.0951, loss-ulb:0.0433, weight:0.76, lr:0.0009
[11:04:02.830] iteration:4290  t-loss:0.1407, loss-lb:0.1034, loss-ulb:0.0492, weight:0.76, lr:0.0009
[11:04:03.022] iteration:4291  t-loss:0.1344, loss-lb:0.1151, loss-ulb:0.0254, weight:0.76, lr:0.0009
[11:04:03.214] iteration:4292  t-loss:0.1314, loss-lb:0.1087, loss-ulb:0.0300, weight:0.76, lr:0.0009
[11:04:03.406] iteration:4293  t-loss:0.1272, loss-lb:0.0936, loss-ulb:0.0443, weight:0.76, lr:0.0009
[11:04:03.598] iteration:4294  t-loss:0.1622, loss-lb:0.0971, loss-ulb:0.0857, weight:0.76, lr:0.0009
[11:04:03.789] iteration:4295  t-loss:0.1341, loss-lb:0.0961, loss-ulb:0.0501, weight:0.76, lr:0.0009
[11:04:03.981] iteration:4296  t-loss:0.1176, loss-lb:0.1007, loss-ulb:0.0222, weight:0.76, lr:0.0009
[11:04:04.173] iteration:4297  t-loss:0.1408, loss-lb:0.1192, loss-ulb:0.0284, weight:0.76, lr:0.0009
[11:04:04.364] iteration:4298  t-loss:0.1198, loss-lb:0.0897, loss-ulb:0.0396, weight:0.76, lr:0.0009
[11:04:04.555] iteration:4299  t-loss:0.1258, loss-lb:0.1050, loss-ulb:0.0274, weight:0.76, lr:0.0009
[11:04:04.746] iteration:4300  t-loss:0.1274, loss-lb:0.0995, loss-ulb:0.0367, weight:0.76, lr:0.0009
[11:04:04.940] iteration:4301  t-loss:0.1706, loss-lb:0.1021, loss-ulb:0.0903, weight:0.76, lr:0.0009
[11:04:05.131] iteration:4302  t-loss:0.1531, loss-lb:0.1095, loss-ulb:0.0574, weight:0.76, lr:0.0009
[11:04:05.323] iteration:4303  t-loss:0.1329, loss-lb:0.1047, loss-ulb:0.0371, weight:0.76, lr:0.0009
[11:04:05.515] iteration:4304  t-loss:0.1191, loss-lb:0.0993, loss-ulb:0.0260, weight:0.76, lr:0.0009
[11:04:05.707] iteration:4305  t-loss:0.1608, loss-lb:0.0997, loss-ulb:0.0805, weight:0.76, lr:0.0009
[11:04:05.898] iteration:4306  t-loss:0.1327, loss-lb:0.1020, loss-ulb:0.0404, weight:0.76, lr:0.0009
[11:04:06.089] iteration:4307  t-loss:0.1369, loss-lb:0.1114, loss-ulb:0.0336, weight:0.76, lr:0.0009
[11:04:06.279] iteration:4308  t-loss:0.1269, loss-lb:0.1033, loss-ulb:0.0310, weight:0.76, lr:0.0009
[11:04:06.469] iteration:4309  t-loss:0.1158, loss-lb:0.0953, loss-ulb:0.0269, weight:0.76, lr:0.0009
[11:04:06.660] iteration:4310  t-loss:0.1812, loss-lb:0.1079, loss-ulb:0.0965, weight:0.76, lr:0.0009
[11:04:06.852] iteration:4311  t-loss:0.1113, loss-lb:0.0893, loss-ulb:0.0290, weight:0.76, lr:0.0009
[11:04:07.043] iteration:4312  t-loss:0.1530, loss-lb:0.1024, loss-ulb:0.0666, weight:0.76, lr:0.0009
[11:04:07.622] iteration:4313  t-loss:0.1646, loss-lb:0.1276, loss-ulb:0.0487, weight:0.76, lr:0.0009
[11:04:07.816] iteration:4314  t-loss:0.1205, loss-lb:0.0970, loss-ulb:0.0309, weight:0.76, lr:0.0009
[11:04:08.008] iteration:4315  t-loss:0.1073, loss-lb:0.0880, loss-ulb:0.0254, weight:0.76, lr:0.0009
[11:04:08.200] iteration:4316  t-loss:0.1372, loss-lb:0.1093, loss-ulb:0.0367, weight:0.76, lr:0.0009
[11:04:08.392] iteration:4317  t-loss:0.1383, loss-lb:0.1150, loss-ulb:0.0307, weight:0.76, lr:0.0009
[11:04:08.584] iteration:4318  t-loss:0.1164, loss-lb:0.0971, loss-ulb:0.0254, weight:0.76, lr:0.0009
[11:04:08.776] iteration:4319  t-loss:0.1537, loss-lb:0.1125, loss-ulb:0.0542, weight:0.76, lr:0.0009
[11:04:08.968] iteration:4320  t-loss:0.1247, loss-lb:0.1048, loss-ulb:0.0263, weight:0.76, lr:0.0009
[11:04:09.160] iteration:4321  t-loss:0.1174, loss-lb:0.0964, loss-ulb:0.0276, weight:0.76, lr:0.0009
[11:04:09.352] iteration:4322  t-loss:0.1297, loss-lb:0.0918, loss-ulb:0.0498, weight:0.76, lr:0.0009
[11:04:09.545] iteration:4323  t-loss:0.1240, loss-lb:0.1030, loss-ulb:0.0276, weight:0.76, lr:0.0009
[11:04:09.736] iteration:4324  t-loss:0.1593, loss-lb:0.0932, loss-ulb:0.0870, weight:0.76, lr:0.0009
[11:04:09.927] iteration:4325  t-loss:0.1302, loss-lb:0.1087, loss-ulb:0.0283, weight:0.76, lr:0.0009
[11:04:10.120] iteration:4326  t-loss:0.1180, loss-lb:0.0991, loss-ulb:0.0248, weight:0.76, lr:0.0009
[11:04:10.310] iteration:4327  t-loss:0.1146, loss-lb:0.0966, loss-ulb:0.0237, weight:0.76, lr:0.0009
[11:04:10.502] iteration:4328  t-loss:0.1116, loss-lb:0.0870, loss-ulb:0.0324, weight:0.76, lr:0.0009
[11:04:10.693] iteration:4329  t-loss:0.1423, loss-lb:0.1158, loss-ulb:0.0348, weight:0.76, lr:0.0009
[11:04:10.886] iteration:4330  t-loss:0.1338, loss-lb:0.1016, loss-ulb:0.0423, weight:0.76, lr:0.0009
[11:04:11.078] iteration:4331  t-loss:0.1158, loss-lb:0.0963, loss-ulb:0.0257, weight:0.76, lr:0.0009
[11:04:11.269] iteration:4332  t-loss:0.1180, loss-lb:0.0947, loss-ulb:0.0307, weight:0.76, lr:0.0009
[11:04:11.461] iteration:4333  t-loss:0.1412, loss-lb:0.0904, loss-ulb:0.0670, weight:0.76, lr:0.0009
[11:04:11.653] iteration:4334  t-loss:0.1441, loss-lb:0.1070, loss-ulb:0.0488, weight:0.76, lr:0.0009
[11:04:11.843] iteration:4335  t-loss:0.1283, loss-lb:0.0994, loss-ulb:0.0381, weight:0.76, lr:0.0009
[11:04:12.035] iteration:4336  t-loss:0.1737, loss-lb:0.1324, loss-ulb:0.0544, weight:0.76, lr:0.0009
[11:04:12.226] iteration:4337  t-loss:0.1239, loss-lb:0.1067, loss-ulb:0.0226, weight:0.76, lr:0.0009
[11:04:12.417] iteration:4338  t-loss:0.1571, loss-lb:0.0960, loss-ulb:0.0804, weight:0.76, lr:0.0009
[11:04:12.610] iteration:4339  t-loss:0.1424, loss-lb:0.0976, loss-ulb:0.0590, weight:0.76, lr:0.0009
[11:04:12.802] iteration:4340  t-loss:0.1909, loss-lb:0.1198, loss-ulb:0.0936, weight:0.76, lr:0.0009
[11:04:12.994] iteration:4341  t-loss:0.1362, loss-lb:0.1085, loss-ulb:0.0365, weight:0.76, lr:0.0009
[11:04:13.186] iteration:4342  t-loss:0.1317, loss-lb:0.1107, loss-ulb:0.0277, weight:0.76, lr:0.0009
[11:04:13.380] iteration:4343  t-loss:0.1495, loss-lb:0.0979, loss-ulb:0.0679, weight:0.76, lr:0.0009
[11:04:13.573] iteration:4344  t-loss:0.1717, loss-lb:0.1117, loss-ulb:0.0789, weight:0.76, lr:0.0009
[11:04:13.778] iteration:4345  t-loss:0.1148, loss-lb:0.0952, loss-ulb:0.0258, weight:0.76, lr:0.0009
[11:04:13.977] iteration:4346  t-loss:0.1209, loss-lb:0.0925, loss-ulb:0.0374, weight:0.76, lr:0.0009
[11:04:14.174] iteration:4347  t-loss:0.1193, loss-lb:0.0986, loss-ulb:0.0273, weight:0.76, lr:0.0009
[11:04:14.366] iteration:4348  t-loss:0.1528, loss-lb:0.1238, loss-ulb:0.0382, weight:0.76, lr:0.0009
[11:04:14.560] iteration:4349  t-loss:0.1334, loss-lb:0.1045, loss-ulb:0.0380, weight:0.76, lr:0.0009
[11:04:14.754] iteration:4350  t-loss:0.1334, loss-lb:0.1094, loss-ulb:0.0316, weight:0.76, lr:0.0009
[11:04:14.947] iteration:4351  t-loss:0.1522, loss-lb:0.1022, loss-ulb:0.0603, weight:0.83, lr:0.0009
[11:04:15.140] iteration:4352  t-loss:0.1283, loss-lb:0.1046, loss-ulb:0.0286, weight:0.83, lr:0.0009
[11:04:15.334] iteration:4353  t-loss:0.1366, loss-lb:0.1194, loss-ulb:0.0207, weight:0.83, lr:0.0009
[11:04:15.528] iteration:4354  t-loss:0.1506, loss-lb:0.1024, loss-ulb:0.0582, weight:0.83, lr:0.0009
[11:04:15.740] iteration:4355  t-loss:0.1777, loss-lb:0.1068, loss-ulb:0.0857, weight:0.83, lr:0.0009
[11:04:15.932] iteration:4356  t-loss:0.1229, loss-lb:0.1013, loss-ulb:0.0261, weight:0.83, lr:0.0009
[11:04:16.123] iteration:4357  t-loss:0.1203, loss-lb:0.1008, loss-ulb:0.0236, weight:0.83, lr:0.0009
[11:04:16.316] iteration:4358  t-loss:0.1510, loss-lb:0.1020, loss-ulb:0.0592, weight:0.83, lr:0.0009
[11:04:16.508] iteration:4359  t-loss:0.1268, loss-lb:0.0973, loss-ulb:0.0357, weight:0.83, lr:0.0009
[11:04:16.700] iteration:4360  t-loss:0.1666, loss-lb:0.1107, loss-ulb:0.0675, weight:0.83, lr:0.0009
[11:04:16.894] iteration:4361  t-loss:0.1541, loss-lb:0.1075, loss-ulb:0.0563, weight:0.83, lr:0.0009
[11:04:17.086] iteration:4362  t-loss:0.1166, loss-lb:0.0944, loss-ulb:0.0268, weight:0.83, lr:0.0009
[11:04:17.278] iteration:4363  t-loss:0.1326, loss-lb:0.1007, loss-ulb:0.0385, weight:0.83, lr:0.0009
[11:04:17.471] iteration:4364  t-loss:0.1281, loss-lb:0.1025, loss-ulb:0.0309, weight:0.83, lr:0.0009
[11:04:17.665] iteration:4365  t-loss:0.1358, loss-lb:0.1104, loss-ulb:0.0307, weight:0.83, lr:0.0009
[11:04:17.860] iteration:4366  t-loss:0.1447, loss-lb:0.1164, loss-ulb:0.0342, weight:0.83, lr:0.0009
[11:04:18.052] iteration:4367  t-loss:0.1433, loss-lb:0.0988, loss-ulb:0.0538, weight:0.83, lr:0.0009
[11:04:18.245] iteration:4368  t-loss:0.1849, loss-lb:0.1202, loss-ulb:0.0782, weight:0.83, lr:0.0009
[11:04:18.437] iteration:4369  t-loss:0.1311, loss-lb:0.1018, loss-ulb:0.0354, weight:0.83, lr:0.0009
[11:04:18.630] iteration:4370  t-loss:0.1211, loss-lb:0.0932, loss-ulb:0.0337, weight:0.83, lr:0.0009
[11:04:18.822] iteration:4371  t-loss:0.1350, loss-lb:0.1069, loss-ulb:0.0339, weight:0.83, lr:0.0009
[11:04:19.015] iteration:4372  t-loss:0.1279, loss-lb:0.1007, loss-ulb:0.0328, weight:0.83, lr:0.0009
[11:04:19.207] iteration:4373  t-loss:0.1443, loss-lb:0.1184, loss-ulb:0.0313, weight:0.83, lr:0.0009
[11:04:19.401] iteration:4374  t-loss:0.1387, loss-lb:0.1048, loss-ulb:0.0410, weight:0.83, lr:0.0009
[11:04:19.594] iteration:4375  t-loss:0.1307, loss-lb:0.1071, loss-ulb:0.0285, weight:0.83, lr:0.0009
[11:04:19.787] iteration:4376  t-loss:0.1554, loss-lb:0.1092, loss-ulb:0.0557, weight:0.83, lr:0.0009
[11:04:19.979] iteration:4377  t-loss:0.1180, loss-lb:0.0976, loss-ulb:0.0246, weight:0.83, lr:0.0009
[11:04:20.171] iteration:4378  t-loss:0.1335, loss-lb:0.1138, loss-ulb:0.0238, weight:0.83, lr:0.0009
[11:04:20.364] iteration:4379  t-loss:0.1322, loss-lb:0.1018, loss-ulb:0.0368, weight:0.83, lr:0.0009
[11:04:20.561] iteration:4380  t-loss:0.1203, loss-lb:0.0933, loss-ulb:0.0326, weight:0.83, lr:0.0009
[11:04:20.755] iteration:4381  t-loss:0.1060, loss-lb:0.0864, loss-ulb:0.0237, weight:0.83, lr:0.0009
[11:04:20.947] iteration:4382  t-loss:0.1150, loss-lb:0.0936, loss-ulb:0.0259, weight:0.83, lr:0.0009
[11:04:21.141] iteration:4383  t-loss:0.1343, loss-lb:0.1101, loss-ulb:0.0292, weight:0.83, lr:0.0009
[11:04:21.335] iteration:4384  t-loss:0.2038, loss-lb:0.1083, loss-ulb:0.1153, weight:0.83, lr:0.0009
[11:04:21.527] iteration:4385  t-loss:0.1219, loss-lb:0.1014, loss-ulb:0.0248, weight:0.83, lr:0.0009
[11:04:21.723] iteration:4386  t-loss:0.1349, loss-lb:0.1068, loss-ulb:0.0339, weight:0.83, lr:0.0009
[11:04:21.916] iteration:4387  t-loss:0.1337, loss-lb:0.1014, loss-ulb:0.0390, weight:0.83, lr:0.0009
[11:04:22.109] iteration:4388  t-loss:0.1134, loss-lb:0.0944, loss-ulb:0.0229, weight:0.83, lr:0.0009
[11:04:22.302] iteration:4389  t-loss:0.1276, loss-lb:0.1080, loss-ulb:0.0237, weight:0.83, lr:0.0009
[11:04:22.494] iteration:4390  t-loss:0.1337, loss-lb:0.0992, loss-ulb:0.0416, weight:0.83, lr:0.0009
[11:04:22.687] iteration:4391  t-loss:0.1155, loss-lb:0.0970, loss-ulb:0.0224, weight:0.83, lr:0.0009
[11:04:22.879] iteration:4392  t-loss:0.1371, loss-lb:0.1179, loss-ulb:0.0232, weight:0.83, lr:0.0009
[11:04:23.071] iteration:4393  t-loss:0.1311, loss-lb:0.1096, loss-ulb:0.0259, weight:0.83, lr:0.0009
[11:04:23.263] iteration:4394  t-loss:0.1227, loss-lb:0.0965, loss-ulb:0.0317, weight:0.83, lr:0.0009
[11:04:23.456] iteration:4395  t-loss:0.1207, loss-lb:0.1005, loss-ulb:0.0244, weight:0.83, lr:0.0009
[11:04:23.653] iteration:4396  t-loss:0.1247, loss-lb:0.0938, loss-ulb:0.0373, weight:0.83, lr:0.0009
[11:04:23.846] iteration:4397  t-loss:0.1270, loss-lb:0.1011, loss-ulb:0.0313, weight:0.83, lr:0.0009
[11:04:24.043] iteration:4398  t-loss:0.1173, loss-lb:0.0934, loss-ulb:0.0289, weight:0.83, lr:0.0009
[11:04:24.235] iteration:4399  t-loss:0.1168, loss-lb:0.0948, loss-ulb:0.0266, weight:0.83, lr:0.0009
[11:04:24.427] iteration:4400  t-loss:0.1205, loss-lb:0.1005, loss-ulb:0.0242, weight:0.83, lr:0.0009
[11:04:24.621] iteration:4401  t-loss:0.1342, loss-lb:0.1052, loss-ulb:0.0350, weight:0.83, lr:0.0009
[11:04:24.816] iteration:4402  t-loss:0.1425, loss-lb:0.0921, loss-ulb:0.0609, weight:0.83, lr:0.0009
[11:04:25.007] iteration:4403  t-loss:0.1208, loss-lb:0.0994, loss-ulb:0.0258, weight:0.83, lr:0.0009
[11:04:25.199] iteration:4404  t-loss:0.1651, loss-lb:0.1021, loss-ulb:0.0761, weight:0.83, lr:0.0009
[11:04:25.390] iteration:4405  t-loss:0.1803, loss-lb:0.1061, loss-ulb:0.0896, weight:0.83, lr:0.0009
[11:04:25.583] iteration:4406  t-loss:0.1415, loss-lb:0.1121, loss-ulb:0.0355, weight:0.83, lr:0.0009
[11:04:25.775] iteration:4407  t-loss:0.1540, loss-lb:0.0923, loss-ulb:0.0745, weight:0.83, lr:0.0009
[11:04:25.966] iteration:4408  t-loss:0.1499, loss-lb:0.1150, loss-ulb:0.0422, weight:0.83, lr:0.0009
[11:04:26.157] iteration:4409  t-loss:0.1175, loss-lb:0.0964, loss-ulb:0.0255, weight:0.83, lr:0.0009
[11:04:26.348] iteration:4410  t-loss:0.1198, loss-lb:0.0980, loss-ulb:0.0262, weight:0.83, lr:0.0009
[11:04:37.310]  <<Test>> - Ep:44  - mean_dice/mean_h95 - S:88.67/2.66, Best-S:89.28, T:90.13/1.39, Best-T:90.13
[11:04:37.310]           - AvgLoss(lb/ulb/all):0.1032/0.0384/0.1330
[11:04:37.827] iteration:4411  t-loss:0.1565, loss-lb:0.1305, loss-ulb:0.0314, weight:0.83, lr:0.0009
[11:04:38.025] iteration:4412  t-loss:0.1207, loss-lb:0.1011, loss-ulb:0.0237, weight:0.83, lr:0.0009
[11:04:38.218] iteration:4413  t-loss:0.1131, loss-lb:0.0941, loss-ulb:0.0230, weight:0.83, lr:0.0009
[11:04:38.412] iteration:4414  t-loss:0.1278, loss-lb:0.1043, loss-ulb:0.0284, weight:0.83, lr:0.0009
[11:04:38.605] iteration:4415  t-loss:0.1222, loss-lb:0.1019, loss-ulb:0.0244, weight:0.83, lr:0.0009
[11:04:38.798] iteration:4416  t-loss:0.1257, loss-lb:0.1027, loss-ulb:0.0277, weight:0.83, lr:0.0009
[11:04:38.991] iteration:4417  t-loss:0.1176, loss-lb:0.0970, loss-ulb:0.0249, weight:0.83, lr:0.0009
[11:04:39.185] iteration:4418  t-loss:0.1260, loss-lb:0.0872, loss-ulb:0.0469, weight:0.83, lr:0.0009
[11:04:39.377] iteration:4419  t-loss:0.1240, loss-lb:0.0976, loss-ulb:0.0320, weight:0.83, lr:0.0009
[11:04:39.569] iteration:4420  t-loss:0.1087, loss-lb:0.0895, loss-ulb:0.0233, weight:0.83, lr:0.0009
[11:04:39.762] iteration:4421  t-loss:0.1249, loss-lb:0.1004, loss-ulb:0.0295, weight:0.83, lr:0.0009
[11:04:39.954] iteration:4422  t-loss:0.1241, loss-lb:0.1031, loss-ulb:0.0254, weight:0.83, lr:0.0009
[11:04:40.146] iteration:4423  t-loss:0.1331, loss-lb:0.0943, loss-ulb:0.0469, weight:0.83, lr:0.0009
[11:04:40.339] iteration:4424  t-loss:0.1377, loss-lb:0.1138, loss-ulb:0.0289, weight:0.83, lr:0.0009
[11:04:40.532] iteration:4425  t-loss:0.1222, loss-lb:0.0960, loss-ulb:0.0316, weight:0.83, lr:0.0009
[11:04:40.724] iteration:4426  t-loss:0.1233, loss-lb:0.0982, loss-ulb:0.0303, weight:0.83, lr:0.0009
[11:04:40.918] iteration:4427  t-loss:0.1440, loss-lb:0.1119, loss-ulb:0.0387, weight:0.83, lr:0.0009
[11:04:41.110] iteration:4428  t-loss:0.1215, loss-lb:0.0980, loss-ulb:0.0284, weight:0.83, lr:0.0009
[11:04:41.303] iteration:4429  t-loss:0.1382, loss-lb:0.1028, loss-ulb:0.0427, weight:0.83, lr:0.0009
[11:04:41.496] iteration:4430  t-loss:0.1419, loss-lb:0.1048, loss-ulb:0.0448, weight:0.83, lr:0.0009
[11:04:41.690] iteration:4431  t-loss:0.1689, loss-lb:0.1166, loss-ulb:0.0632, weight:0.83, lr:0.0009
[11:04:41.884] iteration:4432  t-loss:0.1529, loss-lb:0.1137, loss-ulb:0.0473, weight:0.83, lr:0.0009
[11:04:42.077] iteration:4433  t-loss:0.1091, loss-lb:0.0907, loss-ulb:0.0222, weight:0.83, lr:0.0009
[11:04:42.269] iteration:4434  t-loss:0.1436, loss-lb:0.1200, loss-ulb:0.0285, weight:0.83, lr:0.0009
[11:04:42.461] iteration:4435  t-loss:0.1368, loss-lb:0.1024, loss-ulb:0.0415, weight:0.83, lr:0.0009
[11:04:42.654] iteration:4436  t-loss:0.1842, loss-lb:0.1141, loss-ulb:0.0847, weight:0.83, lr:0.0009
[11:04:42.845] iteration:4437  t-loss:0.1259, loss-lb:0.1023, loss-ulb:0.0286, weight:0.83, lr:0.0009
[11:04:43.039] iteration:4438  t-loss:0.1398, loss-lb:0.1117, loss-ulb:0.0340, weight:0.83, lr:0.0009
[11:04:43.231] iteration:4439  t-loss:0.1475, loss-lb:0.1172, loss-ulb:0.0366, weight:0.83, lr:0.0009
[11:04:43.423] iteration:4440  t-loss:0.1353, loss-lb:0.0975, loss-ulb:0.0457, weight:0.83, lr:0.0009
[11:04:43.615] iteration:4441  t-loss:0.1388, loss-lb:0.1015, loss-ulb:0.0452, weight:0.83, lr:0.0009
[11:04:43.809] iteration:4442  t-loss:0.1728, loss-lb:0.0942, loss-ulb:0.0949, weight:0.83, lr:0.0009
[11:04:44.001] iteration:4443  t-loss:0.1212, loss-lb:0.0988, loss-ulb:0.0271, weight:0.83, lr:0.0009
[11:04:44.193] iteration:4444  t-loss:0.1385, loss-lb:0.1107, loss-ulb:0.0336, weight:0.83, lr:0.0009
[11:04:44.388] iteration:4445  t-loss:0.1306, loss-lb:0.1052, loss-ulb:0.0308, weight:0.83, lr:0.0009
[11:04:44.580] iteration:4446  t-loss:0.1632, loss-lb:0.1411, loss-ulb:0.0268, weight:0.83, lr:0.0009
[11:04:44.771] iteration:4447  t-loss:0.1418, loss-lb:0.1092, loss-ulb:0.0393, weight:0.83, lr:0.0009
[11:04:44.963] iteration:4448  t-loss:0.1204, loss-lb:0.0959, loss-ulb:0.0297, weight:0.83, lr:0.0009
[11:04:45.155] iteration:4449  t-loss:0.1533, loss-lb:0.1244, loss-ulb:0.0349, weight:0.83, lr:0.0009
[11:04:45.348] iteration:4450  t-loss:0.1642, loss-lb:0.1301, loss-ulb:0.0412, weight:0.83, lr:0.0009
[11:04:45.541] iteration:4451  t-loss:0.1458, loss-lb:0.1086, loss-ulb:0.0450, weight:0.83, lr:0.0009
[11:04:45.734] iteration:4452  t-loss:0.2015, loss-lb:0.1133, loss-ulb:0.1065, weight:0.83, lr:0.0009
[11:04:45.925] iteration:4453  t-loss:0.1584, loss-lb:0.1337, loss-ulb:0.0299, weight:0.83, lr:0.0009
[11:04:46.117] iteration:4454  t-loss:0.1155, loss-lb:0.0934, loss-ulb:0.0267, weight:0.83, lr:0.0009
[11:04:46.310] iteration:4455  t-loss:0.1397, loss-lb:0.0984, loss-ulb:0.0498, weight:0.83, lr:0.0009
[11:04:46.510] iteration:4456  t-loss:0.1614, loss-lb:0.1409, loss-ulb:0.0248, weight:0.83, lr:0.0009
[11:04:46.713] iteration:4457  t-loss:0.1776, loss-lb:0.1524, loss-ulb:0.0304, weight:0.83, lr:0.0009
[11:04:46.910] iteration:4458  t-loss:0.1632, loss-lb:0.1024, loss-ulb:0.0735, weight:0.83, lr:0.0009
[11:04:47.103] iteration:4459  t-loss:0.1817, loss-lb:0.1318, loss-ulb:0.0602, weight:0.83, lr:0.0009
[11:04:47.296] iteration:4460  t-loss:0.1344, loss-lb:0.1068, loss-ulb:0.0333, weight:0.83, lr:0.0009
[11:04:47.488] iteration:4461  t-loss:0.1341, loss-lb:0.1079, loss-ulb:0.0317, weight:0.83, lr:0.0009
[11:04:47.681] iteration:4462  t-loss:0.1376, loss-lb:0.1033, loss-ulb:0.0414, weight:0.83, lr:0.0009
[11:04:47.874] iteration:4463  t-loss:0.1459, loss-lb:0.1070, loss-ulb:0.0470, weight:0.83, lr:0.0009
[11:04:48.065] iteration:4464  t-loss:0.1484, loss-lb:0.1033, loss-ulb:0.0545, weight:0.83, lr:0.0009
[11:04:48.257] iteration:4465  t-loss:0.1169, loss-lb:0.0939, loss-ulb:0.0278, weight:0.83, lr:0.0009
[11:04:48.450] iteration:4466  t-loss:0.1910, loss-lb:0.1174, loss-ulb:0.0889, weight:0.83, lr:0.0009
[11:04:48.643] iteration:4467  t-loss:0.1341, loss-lb:0.1041, loss-ulb:0.0361, weight:0.83, lr:0.0009
[11:04:48.834] iteration:4468  t-loss:0.1287, loss-lb:0.1025, loss-ulb:0.0316, weight:0.83, lr:0.0009
[11:04:49.026] iteration:4469  t-loss:0.1649, loss-lb:0.1353, loss-ulb:0.0358, weight:0.83, lr:0.0009
[11:04:49.220] iteration:4470  t-loss:0.1567, loss-lb:0.1136, loss-ulb:0.0520, weight:0.83, lr:0.0009
[11:04:49.412] iteration:4471  t-loss:0.1326, loss-lb:0.1093, loss-ulb:0.0281, weight:0.83, lr:0.0009
[11:04:49.604] iteration:4472  t-loss:0.1366, loss-lb:0.1045, loss-ulb:0.0388, weight:0.83, lr:0.0009
[11:04:49.799] iteration:4473  t-loss:0.2028, loss-lb:0.1512, loss-ulb:0.0623, weight:0.83, lr:0.0009
[11:04:49.994] iteration:4474  t-loss:0.1411, loss-lb:0.1120, loss-ulb:0.0352, weight:0.83, lr:0.0009
[11:04:50.186] iteration:4475  t-loss:0.1420, loss-lb:0.1158, loss-ulb:0.0316, weight:0.83, lr:0.0009
[11:04:50.379] iteration:4476  t-loss:0.1917, loss-lb:0.1005, loss-ulb:0.1102, weight:0.83, lr:0.0009
[11:04:50.570] iteration:4477  t-loss:0.1224, loss-lb:0.0991, loss-ulb:0.0281, weight:0.83, lr:0.0009
[11:04:50.763] iteration:4478  t-loss:0.1460, loss-lb:0.0998, loss-ulb:0.0559, weight:0.83, lr:0.0009
[11:04:50.955] iteration:4479  t-loss:0.1548, loss-lb:0.1022, loss-ulb:0.0635, weight:0.83, lr:0.0009
[11:04:51.148] iteration:4480  t-loss:0.1654, loss-lb:0.1355, loss-ulb:0.0361, weight:0.83, lr:0.0009
[11:04:51.340] iteration:4481  t-loss:0.1505, loss-lb:0.1051, loss-ulb:0.0549, weight:0.83, lr:0.0009
[11:04:51.532] iteration:4482  t-loss:0.1461, loss-lb:0.0939, loss-ulb:0.0630, weight:0.83, lr:0.0009
[11:04:51.725] iteration:4483  t-loss:0.1244, loss-lb:0.1019, loss-ulb:0.0272, weight:0.83, lr:0.0009
[11:04:51.918] iteration:4484  t-loss:0.1537, loss-lb:0.1059, loss-ulb:0.0577, weight:0.83, lr:0.0009
[11:04:52.110] iteration:4485  t-loss:0.1365, loss-lb:0.1100, loss-ulb:0.0321, weight:0.83, lr:0.0009
[11:04:52.302] iteration:4486  t-loss:0.1508, loss-lb:0.1156, loss-ulb:0.0425, weight:0.83, lr:0.0009
[11:04:52.495] iteration:4487  t-loss:0.1592, loss-lb:0.1100, loss-ulb:0.0595, weight:0.83, lr:0.0009
[11:04:52.686] iteration:4488  t-loss:0.1459, loss-lb:0.1102, loss-ulb:0.0432, weight:0.83, lr:0.0009
[11:04:52.880] iteration:4489  t-loss:0.1311, loss-lb:0.1098, loss-ulb:0.0258, weight:0.83, lr:0.0009
[11:04:53.073] iteration:4490  t-loss:0.1295, loss-lb:0.0912, loss-ulb:0.0462, weight:0.83, lr:0.0009
[11:04:53.270] iteration:4491  t-loss:0.1419, loss-lb:0.1080, loss-ulb:0.0409, weight:0.83, lr:0.0009
[11:04:53.461] iteration:4492  t-loss:0.1469, loss-lb:0.1194, loss-ulb:0.0332, weight:0.83, lr:0.0009
[11:04:53.654] iteration:4493  t-loss:0.1388, loss-lb:0.1085, loss-ulb:0.0366, weight:0.83, lr:0.0009
[11:04:53.847] iteration:4494  t-loss:0.1165, loss-lb:0.0990, loss-ulb:0.0212, weight:0.83, lr:0.0009
[11:04:54.040] iteration:4495  t-loss:0.1322, loss-lb:0.0933, loss-ulb:0.0469, weight:0.83, lr:0.0009
[11:04:54.232] iteration:4496  t-loss:0.1931, loss-lb:0.0974, loss-ulb:0.1155, weight:0.83, lr:0.0009
[11:04:54.425] iteration:4497  t-loss:0.2069, loss-lb:0.0998, loss-ulb:0.1294, weight:0.83, lr:0.0009
[11:04:54.617] iteration:4498  t-loss:0.1211, loss-lb:0.0939, loss-ulb:0.0328, weight:0.83, lr:0.0009
[11:04:54.811] iteration:4499  t-loss:0.1656, loss-lb:0.1149, loss-ulb:0.0613, weight:0.83, lr:0.0009
[11:04:55.003] iteration:4500  t-loss:0.1512, loss-lb:0.1164, loss-ulb:0.0421, weight:0.83, lr:0.0009
[11:04:55.195] iteration:4501  t-loss:0.1406, loss-lb:0.1128, loss-ulb:0.0310, weight:0.90, lr:0.0009
[11:04:55.387] iteration:4502  t-loss:0.1780, loss-lb:0.1263, loss-ulb:0.0575, weight:0.90, lr:0.0009
[11:04:55.578] iteration:4503  t-loss:0.1808, loss-lb:0.1089, loss-ulb:0.0800, weight:0.90, lr:0.0009
[11:04:55.769] iteration:4504  t-loss:0.1537, loss-lb:0.1243, loss-ulb:0.0327, weight:0.90, lr:0.0009
[11:04:55.960] iteration:4505  t-loss:0.1846, loss-lb:0.1127, loss-ulb:0.0800, weight:0.90, lr:0.0009
[11:04:56.151] iteration:4506  t-loss:0.1650, loss-lb:0.1161, loss-ulb:0.0544, weight:0.90, lr:0.0009
[11:04:56.343] iteration:4507  t-loss:0.1631, loss-lb:0.0941, loss-ulb:0.0768, weight:0.90, lr:0.0009
[11:04:56.535] iteration:4508  t-loss:0.1247, loss-lb:0.0989, loss-ulb:0.0288, weight:0.90, lr:0.0009
[11:04:57.140] iteration:4509  t-loss:0.1516, loss-lb:0.0995, loss-ulb:0.0580, weight:0.90, lr:0.0009
[11:04:57.336] iteration:4510  t-loss:0.1387, loss-lb:0.1088, loss-ulb:0.0333, weight:0.90, lr:0.0009
[11:04:57.528] iteration:4511  t-loss:0.1492, loss-lb:0.1092, loss-ulb:0.0445, weight:0.90, lr:0.0009
[11:04:57.721] iteration:4512  t-loss:0.1797, loss-lb:0.1070, loss-ulb:0.0808, weight:0.90, lr:0.0009
[11:04:57.914] iteration:4513  t-loss:0.1455, loss-lb:0.1026, loss-ulb:0.0478, weight:0.90, lr:0.0009
[11:04:58.126] iteration:4514  t-loss:0.1578, loss-lb:0.1117, loss-ulb:0.0513, weight:0.90, lr:0.0009
[11:04:58.318] iteration:4515  t-loss:0.1545, loss-lb:0.1072, loss-ulb:0.0527, weight:0.90, lr:0.0009
[11:04:58.510] iteration:4516  t-loss:0.1610, loss-lb:0.1333, loss-ulb:0.0308, weight:0.90, lr:0.0009
[11:04:58.704] iteration:4517  t-loss:0.1700, loss-lb:0.0981, loss-ulb:0.0800, weight:0.90, lr:0.0009
[11:04:58.896] iteration:4518  t-loss:0.1327, loss-lb:0.0982, loss-ulb:0.0384, weight:0.90, lr:0.0009
[11:04:59.090] iteration:4519  t-loss:0.1667, loss-lb:0.1073, loss-ulb:0.0661, weight:0.90, lr:0.0009
[11:04:59.284] iteration:4520  t-loss:0.1496, loss-lb:0.1028, loss-ulb:0.0521, weight:0.90, lr:0.0009
[11:04:59.476] iteration:4521  t-loss:0.1341, loss-lb:0.1026, loss-ulb:0.0350, weight:0.90, lr:0.0009
[11:04:59.669] iteration:4522  t-loss:0.1294, loss-lb:0.1002, loss-ulb:0.0325, weight:0.90, lr:0.0009
[11:04:59.863] iteration:4523  t-loss:0.1808, loss-lb:0.1465, loss-ulb:0.0382, weight:0.90, lr:0.0009
[11:05:00.055] iteration:4524  t-loss:0.1304, loss-lb:0.0920, loss-ulb:0.0427, weight:0.90, lr:0.0009
[11:05:00.247] iteration:4525  t-loss:0.1576, loss-lb:0.1053, loss-ulb:0.0582, weight:0.90, lr:0.0009
[11:05:00.440] iteration:4526  t-loss:0.1591, loss-lb:0.1196, loss-ulb:0.0439, weight:0.90, lr:0.0009
[11:05:00.634] iteration:4527  t-loss:0.1666, loss-lb:0.1045, loss-ulb:0.0691, weight:0.90, lr:0.0009
[11:05:00.826] iteration:4528  t-loss:0.1754, loss-lb:0.1217, loss-ulb:0.0598, weight:0.90, lr:0.0009
[11:05:01.018] iteration:4529  t-loss:0.1437, loss-lb:0.1105, loss-ulb:0.0370, weight:0.90, lr:0.0009
[11:05:01.216] iteration:4530  t-loss:0.1498, loss-lb:0.0973, loss-ulb:0.0584, weight:0.90, lr:0.0009
[11:05:01.426] iteration:4531  t-loss:0.1171, loss-lb:0.0969, loss-ulb:0.0225, weight:0.90, lr:0.0009
[11:05:01.619] iteration:4532  t-loss:0.1359, loss-lb:0.1095, loss-ulb:0.0293, weight:0.90, lr:0.0009
[11:05:01.811] iteration:4533  t-loss:0.1273, loss-lb:0.0954, loss-ulb:0.0355, weight:0.90, lr:0.0009
[11:05:02.008] iteration:4534  t-loss:0.1512, loss-lb:0.1086, loss-ulb:0.0474, weight:0.90, lr:0.0009
[11:05:02.200] iteration:4535  t-loss:0.1292, loss-lb:0.1001, loss-ulb:0.0324, weight:0.90, lr:0.0009
[11:05:02.397] iteration:4536  t-loss:0.1172, loss-lb:0.0946, loss-ulb:0.0252, weight:0.90, lr:0.0009
[11:05:02.590] iteration:4537  t-loss:0.1177, loss-lb:0.0974, loss-ulb:0.0226, weight:0.90, lr:0.0009
[11:05:02.791] iteration:4538  t-loss:0.1357, loss-lb:0.0957, loss-ulb:0.0445, weight:0.90, lr:0.0009
[11:05:02.984] iteration:4539  t-loss:0.1382, loss-lb:0.0995, loss-ulb:0.0431, weight:0.90, lr:0.0009
[11:05:03.178] iteration:4540  t-loss:0.1216, loss-lb:0.1009, loss-ulb:0.0230, weight:0.90, lr:0.0009
[11:05:03.371] iteration:4541  t-loss:0.1288, loss-lb:0.0939, loss-ulb:0.0388, weight:0.90, lr:0.0009
[11:05:03.562] iteration:4542  t-loss:0.1475, loss-lb:0.0967, loss-ulb:0.0566, weight:0.90, lr:0.0009
[11:05:03.755] iteration:4543  t-loss:0.1270, loss-lb:0.1058, loss-ulb:0.0236, weight:0.90, lr:0.0009
[11:05:03.948] iteration:4544  t-loss:0.1321, loss-lb:0.1045, loss-ulb:0.0307, weight:0.90, lr:0.0009
[11:05:04.141] iteration:4545  t-loss:0.1222, loss-lb:0.0891, loss-ulb:0.0368, weight:0.90, lr:0.0009
[11:05:04.336] iteration:4546  t-loss:0.1225, loss-lb:0.0963, loss-ulb:0.0292, weight:0.90, lr:0.0009
[11:05:04.530] iteration:4547  t-loss:0.1162, loss-lb:0.0891, loss-ulb:0.0303, weight:0.90, lr:0.0009
[11:05:04.726] iteration:4548  t-loss:0.1272, loss-lb:0.1071, loss-ulb:0.0224, weight:0.90, lr:0.0009
[11:05:04.918] iteration:4549  t-loss:0.1344, loss-lb:0.0986, loss-ulb:0.0398, weight:0.90, lr:0.0009
[11:05:05.110] iteration:4550  t-loss:0.1387, loss-lb:0.1054, loss-ulb:0.0370, weight:0.90, lr:0.0009
[11:05:05.302] iteration:4551  t-loss:0.1340, loss-lb:0.1108, loss-ulb:0.0259, weight:0.90, lr:0.0009
[11:05:05.493] iteration:4552  t-loss:0.1243, loss-lb:0.1008, loss-ulb:0.0261, weight:0.90, lr:0.0009
[11:05:05.686] iteration:4553  t-loss:0.1143, loss-lb:0.0890, loss-ulb:0.0282, weight:0.90, lr:0.0009
[11:05:05.878] iteration:4554  t-loss:0.1430, loss-lb:0.0990, loss-ulb:0.0489, weight:0.90, lr:0.0009
[11:05:06.070] iteration:4555  t-loss:0.1264, loss-lb:0.0976, loss-ulb:0.0320, weight:0.90, lr:0.0009
[11:05:06.262] iteration:4556  t-loss:0.1169, loss-lb:0.0975, loss-ulb:0.0216, weight:0.90, lr:0.0009
[11:05:06.455] iteration:4557  t-loss:0.1716, loss-lb:0.1149, loss-ulb:0.0631, weight:0.90, lr:0.0009
[11:05:06.647] iteration:4558  t-loss:0.1212, loss-lb:0.0962, loss-ulb:0.0278, weight:0.90, lr:0.0009
[11:05:06.840] iteration:4559  t-loss:0.1121, loss-lb:0.0903, loss-ulb:0.0243, weight:0.90, lr:0.0009
[11:05:07.032] iteration:4560  t-loss:0.1901, loss-lb:0.1464, loss-ulb:0.0486, weight:0.90, lr:0.0009
[11:05:07.225] iteration:4561  t-loss:0.1888, loss-lb:0.1287, loss-ulb:0.0669, weight:0.90, lr:0.0009
[11:05:07.416] iteration:4562  t-loss:0.1468, loss-lb:0.0885, loss-ulb:0.0649, weight:0.90, lr:0.0009
[11:05:07.608] iteration:4563  t-loss:0.1541, loss-lb:0.1120, loss-ulb:0.0468, weight:0.90, lr:0.0009
[11:05:07.800] iteration:4564  t-loss:0.1437, loss-lb:0.0906, loss-ulb:0.0591, weight:0.90, lr:0.0009
[11:05:07.992] iteration:4565  t-loss:0.1856, loss-lb:0.1073, loss-ulb:0.0872, weight:0.90, lr:0.0009
[11:05:08.186] iteration:4566  t-loss:0.1610, loss-lb:0.1057, loss-ulb:0.0615, weight:0.90, lr:0.0009
[11:05:08.377] iteration:4567  t-loss:0.1830, loss-lb:0.1345, loss-ulb:0.0540, weight:0.90, lr:0.0009
[11:05:08.570] iteration:4568  t-loss:0.1478, loss-lb:0.0978, loss-ulb:0.0556, weight:0.90, lr:0.0009
[11:05:08.762] iteration:4569  t-loss:0.2282, loss-lb:0.1088, loss-ulb:0.1328, weight:0.90, lr:0.0009
[11:05:08.954] iteration:4570  t-loss:0.1349, loss-lb:0.0980, loss-ulb:0.0410, weight:0.90, lr:0.0009
[11:05:09.145] iteration:4571  t-loss:0.1479, loss-lb:0.1113, loss-ulb:0.0408, weight:0.90, lr:0.0009
[11:05:09.336] iteration:4572  t-loss:0.1785, loss-lb:0.1090, loss-ulb:0.0773, weight:0.90, lr:0.0009
[11:05:09.528] iteration:4573  t-loss:0.1497, loss-lb:0.0963, loss-ulb:0.0594, weight:0.90, lr:0.0009
[11:05:09.721] iteration:4574  t-loss:0.1400, loss-lb:0.1200, loss-ulb:0.0223, weight:0.90, lr:0.0009
[11:05:09.913] iteration:4575  t-loss:0.1393, loss-lb:0.1036, loss-ulb:0.0397, weight:0.90, lr:0.0009
[11:05:10.104] iteration:4576  t-loss:0.1532, loss-lb:0.1164, loss-ulb:0.0409, weight:0.90, lr:0.0009
[11:05:10.296] iteration:4577  t-loss:0.1495, loss-lb:0.1095, loss-ulb:0.0445, weight:0.90, lr:0.0009
[11:05:10.487] iteration:4578  t-loss:0.1194, loss-lb:0.0985, loss-ulb:0.0232, weight:0.90, lr:0.0009
[11:05:10.678] iteration:4579  t-loss:0.1929, loss-lb:0.1059, loss-ulb:0.0968, weight:0.90, lr:0.0009
[11:05:10.869] iteration:4580  t-loss:0.1331, loss-lb:0.1076, loss-ulb:0.0284, weight:0.90, lr:0.0009
[11:05:11.062] iteration:4581  t-loss:0.1306, loss-lb:0.0960, loss-ulb:0.0385, weight:0.90, lr:0.0009
[11:05:11.254] iteration:4582  t-loss:0.1310, loss-lb:0.1010, loss-ulb:0.0335, weight:0.90, lr:0.0009
[11:05:11.444] iteration:4583  t-loss:0.1497, loss-lb:0.1172, loss-ulb:0.0362, weight:0.90, lr:0.0009
[11:05:11.636] iteration:4584  t-loss:0.1378, loss-lb:0.1168, loss-ulb:0.0234, weight:0.90, lr:0.0009
[11:05:11.828] iteration:4585  t-loss:0.1427, loss-lb:0.0917, loss-ulb:0.0567, weight:0.90, lr:0.0009
[11:05:12.019] iteration:4586  t-loss:0.1467, loss-lb:0.1129, loss-ulb:0.0376, weight:0.90, lr:0.0009
[11:05:12.210] iteration:4587  t-loss:0.1613, loss-lb:0.1385, loss-ulb:0.0254, weight:0.90, lr:0.0009
[11:05:12.402] iteration:4588  t-loss:0.1659, loss-lb:0.1001, loss-ulb:0.0732, weight:0.90, lr:0.0009
[11:05:12.594] iteration:4589  t-loss:0.1185, loss-lb:0.0931, loss-ulb:0.0283, weight:0.90, lr:0.0009
[11:05:12.784] iteration:4590  t-loss:0.1376, loss-lb:0.1062, loss-ulb:0.0349, weight:0.90, lr:0.0009
[11:05:12.976] iteration:4591  t-loss:0.1272, loss-lb:0.0904, loss-ulb:0.0410, weight:0.90, lr:0.0009
[11:05:13.168] iteration:4592  t-loss:0.1338, loss-lb:0.0980, loss-ulb:0.0398, weight:0.90, lr:0.0009
[11:05:13.359] iteration:4593  t-loss:0.1512, loss-lb:0.1034, loss-ulb:0.0533, weight:0.90, lr:0.0009
[11:05:13.551] iteration:4594  t-loss:0.1347, loss-lb:0.1011, loss-ulb:0.0374, weight:0.90, lr:0.0009
[11:05:13.741] iteration:4595  t-loss:0.1233, loss-lb:0.0985, loss-ulb:0.0276, weight:0.90, lr:0.0009
[11:05:13.933] iteration:4596  t-loss:0.1207, loss-lb:0.0923, loss-ulb:0.0317, weight:0.90, lr:0.0009
[11:05:14.124] iteration:4597  t-loss:0.1652, loss-lb:0.1229, loss-ulb:0.0471, weight:0.90, lr:0.0009
[11:05:14.315] iteration:4598  t-loss:0.1384, loss-lb:0.1124, loss-ulb:0.0290, weight:0.90, lr:0.0009
[11:05:14.504] iteration:4599  t-loss:0.1380, loss-lb:0.1109, loss-ulb:0.0301, weight:0.90, lr:0.0009
[11:05:14.695] iteration:4600  t-loss:0.1293, loss-lb:0.1090, loss-ulb:0.0226, weight:0.90, lr:0.0009
[11:05:14.885] iteration:4601  t-loss:0.1449, loss-lb:0.1155, loss-ulb:0.0327, weight:0.90, lr:0.0009
[11:05:15.078] iteration:4602  t-loss:0.1336, loss-lb:0.1056, loss-ulb:0.0312, weight:0.90, lr:0.0009
[11:05:15.273] iteration:4603  t-loss:0.1059, loss-lb:0.0883, loss-ulb:0.0196, weight:0.90, lr:0.0009
[11:05:15.468] iteration:4604  t-loss:0.1201, loss-lb:0.0970, loss-ulb:0.0257, weight:0.90, lr:0.0009
[11:05:15.660] iteration:4605  t-loss:0.1172, loss-lb:0.0919, loss-ulb:0.0282, weight:0.90, lr:0.0009
[11:05:15.850] iteration:4606  t-loss:0.1308, loss-lb:0.1009, loss-ulb:0.0333, weight:0.90, lr:0.0009
[11:05:28.773]  <<Test>> - Ep:46  - mean_dice/mean_h95 - S:89.22/3.47, Best-S:89.28, T:90.08/1.37, Best-T:90.13
[11:05:28.773]           - AvgLoss(lb/ulb/all):0.1048/0.0346/0.1349
[11:05:29.315] iteration:4607  t-loss:0.1481, loss-lb:0.0928, loss-ulb:0.0615, weight:0.90, lr:0.0009
[11:05:29.510] iteration:4608  t-loss:0.1408, loss-lb:0.1012, loss-ulb:0.0441, weight:0.90, lr:0.0009
[11:05:29.702] iteration:4609  t-loss:0.1246, loss-lb:0.0994, loss-ulb:0.0280, weight:0.90, lr:0.0009
[11:05:29.895] iteration:4610  t-loss:0.1193, loss-lb:0.0977, loss-ulb:0.0241, weight:0.90, lr:0.0009
[11:05:30.087] iteration:4611  t-loss:0.1344, loss-lb:0.1042, loss-ulb:0.0337, weight:0.90, lr:0.0009
[11:05:30.280] iteration:4612  t-loss:0.1460, loss-lb:0.1197, loss-ulb:0.0292, weight:0.90, lr:0.0009
[11:05:30.473] iteration:4613  t-loss:0.1238, loss-lb:0.1003, loss-ulb:0.0261, weight:0.90, lr:0.0009
[11:05:30.664] iteration:4614  t-loss:0.1460, loss-lb:0.1222, loss-ulb:0.0265, weight:0.90, lr:0.0009
[11:05:30.856] iteration:4615  t-loss:0.1248, loss-lb:0.1009, loss-ulb:0.0266, weight:0.90, lr:0.0009
[11:05:31.049] iteration:4616  t-loss:0.1754, loss-lb:0.0973, loss-ulb:0.0868, weight:0.90, lr:0.0009
[11:05:31.241] iteration:4617  t-loss:0.1145, loss-lb:0.0932, loss-ulb:0.0237, weight:0.90, lr:0.0009
[11:05:31.436] iteration:4618  t-loss:0.1797, loss-lb:0.1301, loss-ulb:0.0552, weight:0.90, lr:0.0009
[11:05:31.629] iteration:4619  t-loss:0.1504, loss-lb:0.1155, loss-ulb:0.0388, weight:0.90, lr:0.0009
[11:05:31.821] iteration:4620  t-loss:0.1425, loss-lb:0.1094, loss-ulb:0.0369, weight:0.90, lr:0.0009
[11:05:32.013] iteration:4621  t-loss:0.1177, loss-lb:0.0924, loss-ulb:0.0281, weight:0.90, lr:0.0009
[11:05:32.205] iteration:4622  t-loss:0.1502, loss-lb:0.1042, loss-ulb:0.0512, weight:0.90, lr:0.0009
[11:05:32.398] iteration:4623  t-loss:0.1617, loss-lb:0.1405, loss-ulb:0.0236, weight:0.90, lr:0.0009
[11:05:32.590] iteration:4624  t-loss:0.1302, loss-lb:0.1035, loss-ulb:0.0297, weight:0.90, lr:0.0009
[11:05:32.783] iteration:4625  t-loss:0.1484, loss-lb:0.0988, loss-ulb:0.0552, weight:0.90, lr:0.0009
[11:05:32.976] iteration:4626  t-loss:0.1428, loss-lb:0.1025, loss-ulb:0.0449, weight:0.90, lr:0.0009
[11:05:33.169] iteration:4627  t-loss:0.1170, loss-lb:0.0941, loss-ulb:0.0255, weight:0.90, lr:0.0009
[11:05:33.361] iteration:4628  t-loss:0.1446, loss-lb:0.1045, loss-ulb:0.0447, weight:0.90, lr:0.0009
[11:05:33.554] iteration:4629  t-loss:0.1258, loss-lb:0.1013, loss-ulb:0.0273, weight:0.90, lr:0.0009
[11:05:33.747] iteration:4630  t-loss:0.1274, loss-lb:0.0948, loss-ulb:0.0363, weight:0.90, lr:0.0009
[11:05:33.938] iteration:4631  t-loss:0.1510, loss-lb:0.1070, loss-ulb:0.0489, weight:0.90, lr:0.0009
[11:05:34.129] iteration:4632  t-loss:0.1350, loss-lb:0.1044, loss-ulb:0.0341, weight:0.90, lr:0.0009
[11:05:34.320] iteration:4633  t-loss:0.1354, loss-lb:0.1050, loss-ulb:0.0338, weight:0.90, lr:0.0009
[11:05:34.511] iteration:4634  t-loss:0.1960, loss-lb:0.1169, loss-ulb:0.0880, weight:0.90, lr:0.0009
[11:05:34.704] iteration:4635  t-loss:0.1304, loss-lb:0.1047, loss-ulb:0.0286, weight:0.90, lr:0.0009
[11:05:34.895] iteration:4636  t-loss:0.1343, loss-lb:0.1017, loss-ulb:0.0363, weight:0.90, lr:0.0009
[11:05:35.086] iteration:4637  t-loss:0.1379, loss-lb:0.1039, loss-ulb:0.0379, weight:0.90, lr:0.0009
[11:05:35.278] iteration:4638  t-loss:0.1436, loss-lb:0.1104, loss-ulb:0.0370, weight:0.90, lr:0.0009
[11:05:35.469] iteration:4639  t-loss:0.1323, loss-lb:0.1062, loss-ulb:0.0290, weight:0.90, lr:0.0009
[11:05:35.662] iteration:4640  t-loss:0.1573, loss-lb:0.1081, loss-ulb:0.0547, weight:0.90, lr:0.0009
[11:05:35.852] iteration:4641  t-loss:0.1283, loss-lb:0.0989, loss-ulb:0.0327, weight:0.90, lr:0.0009
[11:05:36.044] iteration:4642  t-loss:0.1295, loss-lb:0.1080, loss-ulb:0.0239, weight:0.90, lr:0.0009
[11:05:36.234] iteration:4643  t-loss:0.1289, loss-lb:0.1020, loss-ulb:0.0299, weight:0.90, lr:0.0009
[11:05:36.426] iteration:4644  t-loss:0.1411, loss-lb:0.1062, loss-ulb:0.0388, weight:0.90, lr:0.0009
[11:05:36.620] iteration:4645  t-loss:0.1495, loss-lb:0.1167, loss-ulb:0.0366, weight:0.90, lr:0.0009
[11:05:36.817] iteration:4646  t-loss:0.1312, loss-lb:0.1015, loss-ulb:0.0331, weight:0.90, lr:0.0009
[11:05:37.011] iteration:4647  t-loss:0.1394, loss-lb:0.1170, loss-ulb:0.0249, weight:0.90, lr:0.0009
[11:05:37.207] iteration:4648  t-loss:0.1542, loss-lb:0.1142, loss-ulb:0.0445, weight:0.90, lr:0.0009
[11:05:37.399] iteration:4649  t-loss:0.1381, loss-lb:0.0985, loss-ulb:0.0440, weight:0.90, lr:0.0009
[11:05:37.591] iteration:4650  t-loss:0.1444, loss-lb:0.1033, loss-ulb:0.0457, weight:0.90, lr:0.0009
[11:05:37.783] iteration:4651  t-loss:0.1604, loss-lb:0.1150, loss-ulb:0.0467, weight:0.97, lr:0.0009
[11:05:37.975] iteration:4652  t-loss:0.2976, loss-lb:0.1240, loss-ulb:0.1787, weight:0.97, lr:0.0009
[11:05:38.167] iteration:4653  t-loss:0.1487, loss-lb:0.1060, loss-ulb:0.0440, weight:0.97, lr:0.0009
[11:05:38.359] iteration:4654  t-loss:0.1591, loss-lb:0.0993, loss-ulb:0.0615, weight:0.97, lr:0.0009
[11:05:38.550] iteration:4655  t-loss:0.1421, loss-lb:0.1103, loss-ulb:0.0328, weight:0.97, lr:0.0009
[11:05:38.743] iteration:4656  t-loss:0.1453, loss-lb:0.1028, loss-ulb:0.0437, weight:0.97, lr:0.0009
[11:05:38.934] iteration:4657  t-loss:0.1346, loss-lb:0.1023, loss-ulb:0.0332, weight:0.97, lr:0.0009
[11:05:39.126] iteration:4658  t-loss:0.1499, loss-lb:0.1217, loss-ulb:0.0291, weight:0.97, lr:0.0009
[11:05:39.318] iteration:4659  t-loss:0.1326, loss-lb:0.1014, loss-ulb:0.0321, weight:0.97, lr:0.0009
[11:05:39.509] iteration:4660  t-loss:0.1439, loss-lb:0.0990, loss-ulb:0.0463, weight:0.97, lr:0.0009
[11:05:39.702] iteration:4661  t-loss:0.1288, loss-lb:0.0959, loss-ulb:0.0338, weight:0.97, lr:0.0009
[11:05:39.892] iteration:4662  t-loss:0.1821, loss-lb:0.1241, loss-ulb:0.0596, weight:0.97, lr:0.0009
[11:05:40.084] iteration:4663  t-loss:0.1835, loss-lb:0.1348, loss-ulb:0.0501, weight:0.97, lr:0.0009
[11:05:40.275] iteration:4664  t-loss:0.1346, loss-lb:0.1028, loss-ulb:0.0328, weight:0.97, lr:0.0009
[11:05:40.466] iteration:4665  t-loss:0.1267, loss-lb:0.0977, loss-ulb:0.0299, weight:0.97, lr:0.0009
[11:05:40.659] iteration:4666  t-loss:0.1373, loss-lb:0.0992, loss-ulb:0.0392, weight:0.97, lr:0.0009
[11:05:40.852] iteration:4667  t-loss:0.1411, loss-lb:0.0979, loss-ulb:0.0445, weight:0.97, lr:0.0009
[11:05:41.044] iteration:4668  t-loss:0.1273, loss-lb:0.1025, loss-ulb:0.0256, weight:0.97, lr:0.0009
[11:05:41.235] iteration:4669  t-loss:0.1157, loss-lb:0.0886, loss-ulb:0.0278, weight:0.97, lr:0.0009
[11:05:41.426] iteration:4670  t-loss:0.1307, loss-lb:0.1089, loss-ulb:0.0224, weight:0.97, lr:0.0009
[11:05:41.619] iteration:4671  t-loss:0.1652, loss-lb:0.1426, loss-ulb:0.0232, weight:0.97, lr:0.0009
[11:05:41.810] iteration:4672  t-loss:0.1284, loss-lb:0.0963, loss-ulb:0.0330, weight:0.97, lr:0.0009
[11:05:42.004] iteration:4673  t-loss:0.1560, loss-lb:0.1001, loss-ulb:0.0576, weight:0.97, lr:0.0009
[11:05:42.195] iteration:4674  t-loss:0.1390, loss-lb:0.1068, loss-ulb:0.0331, weight:0.97, lr:0.0009
[11:05:42.387] iteration:4675  t-loss:0.1083, loss-lb:0.0877, loss-ulb:0.0212, weight:0.97, lr:0.0009
[11:05:42.580] iteration:4676  t-loss:0.1398, loss-lb:0.1160, loss-ulb:0.0244, weight:0.97, lr:0.0009
[11:05:42.772] iteration:4677  t-loss:0.1493, loss-lb:0.1119, loss-ulb:0.0385, weight:0.97, lr:0.0009
[11:05:42.965] iteration:4678  t-loss:0.1467, loss-lb:0.1160, loss-ulb:0.0317, weight:0.97, lr:0.0009
[11:05:43.157] iteration:4679  t-loss:0.1302, loss-lb:0.1077, loss-ulb:0.0231, weight:0.97, lr:0.0009
[11:05:43.350] iteration:4680  t-loss:0.1283, loss-lb:0.0941, loss-ulb:0.0352, weight:0.97, lr:0.0009
[11:05:43.542] iteration:4681  t-loss:0.1400, loss-lb:0.1100, loss-ulb:0.0308, weight:0.97, lr:0.0009
[11:05:43.735] iteration:4682  t-loss:0.1205, loss-lb:0.0921, loss-ulb:0.0292, weight:0.97, lr:0.0009
[11:05:43.926] iteration:4683  t-loss:0.1522, loss-lb:0.0987, loss-ulb:0.0551, weight:0.97, lr:0.0009
[11:05:44.118] iteration:4684  t-loss:0.1318, loss-lb:0.1033, loss-ulb:0.0293, weight:0.97, lr:0.0009
[11:05:44.309] iteration:4685  t-loss:0.1414, loss-lb:0.1007, loss-ulb:0.0419, weight:0.97, lr:0.0009
[11:05:44.501] iteration:4686  t-loss:0.1166, loss-lb:0.0928, loss-ulb:0.0244, weight:0.97, lr:0.0009
[11:05:44.692] iteration:4687  t-loss:0.1196, loss-lb:0.0933, loss-ulb:0.0271, weight:0.97, lr:0.0009
[11:05:44.883] iteration:4688  t-loss:0.1452, loss-lb:0.0994, loss-ulb:0.0472, weight:0.97, lr:0.0009
[11:05:45.075] iteration:4689  t-loss:0.1240, loss-lb:0.1010, loss-ulb:0.0237, weight:0.97, lr:0.0009
[11:05:45.265] iteration:4690  t-loss:0.1631, loss-lb:0.1066, loss-ulb:0.0582, weight:0.97, lr:0.0009
[11:05:45.457] iteration:4691  t-loss:0.1175, loss-lb:0.0954, loss-ulb:0.0228, weight:0.97, lr:0.0009
[11:05:45.649] iteration:4692  t-loss:0.1398, loss-lb:0.0848, loss-ulb:0.0566, weight:0.97, lr:0.0009
[11:05:45.840] iteration:4693  t-loss:0.2338, loss-lb:0.0999, loss-ulb:0.1378, weight:0.97, lr:0.0009
[11:05:46.032] iteration:4694  t-loss:0.1372, loss-lb:0.1081, loss-ulb:0.0300, weight:0.97, lr:0.0009
[11:05:46.222] iteration:4695  t-loss:0.1554, loss-lb:0.1092, loss-ulb:0.0476, weight:0.97, lr:0.0009
[11:05:46.413] iteration:4696  t-loss:0.1365, loss-lb:0.1071, loss-ulb:0.0302, weight:0.97, lr:0.0009
[11:05:46.604] iteration:4697  t-loss:0.1889, loss-lb:0.0978, loss-ulb:0.0937, weight:0.97, lr:0.0009
[11:05:46.794] iteration:4698  t-loss:0.1459, loss-lb:0.1007, loss-ulb:0.0465, weight:0.97, lr:0.0009
[11:05:46.984] iteration:4699  t-loss:0.1613, loss-lb:0.1010, loss-ulb:0.0620, weight:0.97, lr:0.0009
[11:05:47.176] iteration:4700  t-loss:0.1332, loss-lb:0.1014, loss-ulb:0.0327, weight:0.97, lr:0.0009
[11:05:47.366] iteration:4701  t-loss:0.1507, loss-lb:0.1011, loss-ulb:0.0511, weight:0.97, lr:0.0009
[11:05:47.556] iteration:4702  t-loss:0.1651, loss-lb:0.0971, loss-ulb:0.0700, weight:0.97, lr:0.0009
[11:05:47.748] iteration:4703  t-loss:0.1473, loss-lb:0.1045, loss-ulb:0.0440, weight:0.97, lr:0.0009
[11:05:47.939] iteration:4704  t-loss:0.1564, loss-lb:0.1066, loss-ulb:0.0512, weight:0.97, lr:0.0009
[11:05:48.538] iteration:4705  t-loss:0.1529, loss-lb:0.1045, loss-ulb:0.0499, weight:0.97, lr:0.0009
[11:05:48.734] iteration:4706  t-loss:0.1620, loss-lb:0.0990, loss-ulb:0.0648, weight:0.97, lr:0.0009
[11:05:48.927] iteration:4707  t-loss:0.2221, loss-lb:0.0996, loss-ulb:0.1261, weight:0.97, lr:0.0009
[11:05:49.127] iteration:4708  t-loss:0.1397, loss-lb:0.1053, loss-ulb:0.0353, weight:0.97, lr:0.0009
[11:05:49.319] iteration:4709  t-loss:0.1536, loss-lb:0.1070, loss-ulb:0.0480, weight:0.97, lr:0.0009
[11:05:49.512] iteration:4710  t-loss:0.1616, loss-lb:0.1068, loss-ulb:0.0564, weight:0.97, lr:0.0009
[11:05:49.705] iteration:4711  t-loss:0.1571, loss-lb:0.1032, loss-ulb:0.0555, weight:0.97, lr:0.0009
[11:05:49.904] iteration:4712  t-loss:0.1544, loss-lb:0.1114, loss-ulb:0.0442, weight:0.97, lr:0.0009
[11:05:50.097] iteration:4713  t-loss:0.1378, loss-lb:0.1029, loss-ulb:0.0359, weight:0.97, lr:0.0009
[11:05:50.290] iteration:4714  t-loss:0.1679, loss-lb:0.1203, loss-ulb:0.0490, weight:0.97, lr:0.0009
[11:05:50.482] iteration:4715  t-loss:0.1295, loss-lb:0.1018, loss-ulb:0.0286, weight:0.97, lr:0.0009
[11:05:50.682] iteration:4716  t-loss:0.1610, loss-lb:0.1105, loss-ulb:0.0520, weight:0.97, lr:0.0009
[11:05:50.874] iteration:4717  t-loss:0.1467, loss-lb:0.1028, loss-ulb:0.0452, weight:0.97, lr:0.0009
[11:05:51.068] iteration:4718  t-loss:0.1389, loss-lb:0.1107, loss-ulb:0.0290, weight:0.97, lr:0.0009
[11:05:51.260] iteration:4719  t-loss:0.1339, loss-lb:0.1065, loss-ulb:0.0281, weight:0.97, lr:0.0009
[11:05:51.459] iteration:4720  t-loss:0.2675, loss-lb:0.1023, loss-ulb:0.1700, weight:0.97, lr:0.0009
[11:05:51.654] iteration:4721  t-loss:0.1552, loss-lb:0.1118, loss-ulb:0.0447, weight:0.97, lr:0.0009
[11:05:51.848] iteration:4722  t-loss:0.1395, loss-lb:0.1055, loss-ulb:0.0350, weight:0.97, lr:0.0009
[11:05:52.048] iteration:4723  t-loss:0.1346, loss-lb:0.1018, loss-ulb:0.0337, weight:0.97, lr:0.0009
[11:05:52.249] iteration:4724  t-loss:0.2022, loss-lb:0.1090, loss-ulb:0.0959, weight:0.97, lr:0.0009
[11:05:52.447] iteration:4725  t-loss:0.2266, loss-lb:0.1495, loss-ulb:0.0793, weight:0.97, lr:0.0009
[11:05:52.640] iteration:4726  t-loss:0.2153, loss-lb:0.1149, loss-ulb:0.1034, weight:0.97, lr:0.0009
[11:05:52.831] iteration:4727  t-loss:0.1170, loss-lb:0.0969, loss-ulb:0.0208, weight:0.97, lr:0.0009
[11:05:53.025] iteration:4728  t-loss:0.1770, loss-lb:0.1117, loss-ulb:0.0672, weight:0.97, lr:0.0009
[11:05:53.217] iteration:4729  t-loss:0.1542, loss-lb:0.0970, loss-ulb:0.0589, weight:0.97, lr:0.0009
[11:05:53.409] iteration:4730  t-loss:0.1752, loss-lb:0.1204, loss-ulb:0.0564, weight:0.97, lr:0.0009
[11:05:53.601] iteration:4731  t-loss:0.1646, loss-lb:0.1348, loss-ulb:0.0306, weight:0.97, lr:0.0009
[11:05:53.794] iteration:4732  t-loss:0.1428, loss-lb:0.0991, loss-ulb:0.0450, weight:0.97, lr:0.0009
[11:05:53.986] iteration:4733  t-loss:0.1245, loss-lb:0.1043, loss-ulb:0.0208, weight:0.97, lr:0.0009
[11:05:54.178] iteration:4734  t-loss:0.1420, loss-lb:0.1053, loss-ulb:0.0377, weight:0.97, lr:0.0009
[11:05:54.371] iteration:4735  t-loss:0.1538, loss-lb:0.1129, loss-ulb:0.0420, weight:0.97, lr:0.0009
[11:05:54.563] iteration:4736  t-loss:0.1401, loss-lb:0.1068, loss-ulb:0.0343, weight:0.97, lr:0.0009
[11:05:54.756] iteration:4737  t-loss:0.1448, loss-lb:0.1049, loss-ulb:0.0411, weight:0.97, lr:0.0009
[11:05:54.949] iteration:4738  t-loss:0.1227, loss-lb:0.0950, loss-ulb:0.0285, weight:0.97, lr:0.0009
[11:05:55.142] iteration:4739  t-loss:0.1441, loss-lb:0.0967, loss-ulb:0.0488, weight:0.97, lr:0.0009
[11:05:55.335] iteration:4740  t-loss:0.1335, loss-lb:0.1016, loss-ulb:0.0329, weight:0.97, lr:0.0009
[11:05:55.527] iteration:4741  t-loss:0.1611, loss-lb:0.0988, loss-ulb:0.0641, weight:0.97, lr:0.0009
[11:05:55.719] iteration:4742  t-loss:0.1294, loss-lb:0.1009, loss-ulb:0.0293, weight:0.97, lr:0.0009
[11:05:55.910] iteration:4743  t-loss:0.1387, loss-lb:0.1116, loss-ulb:0.0280, weight:0.97, lr:0.0009
[11:05:56.101] iteration:4744  t-loss:0.1205, loss-lb:0.0972, loss-ulb:0.0240, weight:0.97, lr:0.0009
[11:05:56.295] iteration:4745  t-loss:0.1602, loss-lb:0.1054, loss-ulb:0.0564, weight:0.97, lr:0.0009
[11:05:56.487] iteration:4746  t-loss:0.1428, loss-lb:0.1105, loss-ulb:0.0332, weight:0.97, lr:0.0009
[11:05:56.680] iteration:4747  t-loss:0.1404, loss-lb:0.0997, loss-ulb:0.0419, weight:0.97, lr:0.0009
[11:05:56.873] iteration:4748  t-loss:0.1439, loss-lb:0.1108, loss-ulb:0.0340, weight:0.97, lr:0.0009
[11:05:57.067] iteration:4749  t-loss:0.1362, loss-lb:0.1037, loss-ulb:0.0335, weight:0.97, lr:0.0009
[11:05:57.258] iteration:4750  t-loss:0.1392, loss-lb:0.1101, loss-ulb:0.0299, weight:0.97, lr:0.0009
[11:05:57.451] iteration:4751  t-loss:0.1387, loss-lb:0.1108, loss-ulb:0.0288, weight:0.97, lr:0.0009
[11:05:57.643] iteration:4752  t-loss:0.1251, loss-lb:0.0976, loss-ulb:0.0283, weight:0.97, lr:0.0009
[11:05:57.835] iteration:4753  t-loss:0.1394, loss-lb:0.1014, loss-ulb:0.0391, weight:0.97, lr:0.0009
[11:05:58.028] iteration:4754  t-loss:0.1320, loss-lb:0.0953, loss-ulb:0.0378, weight:0.97, lr:0.0009
[11:05:58.219] iteration:4755  t-loss:0.1517, loss-lb:0.1098, loss-ulb:0.0431, weight:0.97, lr:0.0009
[11:05:58.411] iteration:4756  t-loss:0.1173, loss-lb:0.0931, loss-ulb:0.0248, weight:0.97, lr:0.0009
[11:05:58.604] iteration:4757  t-loss:0.1215, loss-lb:0.0947, loss-ulb:0.0276, weight:0.97, lr:0.0009
[11:05:58.796] iteration:4758  t-loss:0.1205, loss-lb:0.0856, loss-ulb:0.0359, weight:0.97, lr:0.0009
[11:05:58.987] iteration:4759  t-loss:0.1203, loss-lb:0.0926, loss-ulb:0.0285, weight:0.97, lr:0.0009
[11:05:59.180] iteration:4760  t-loss:0.1224, loss-lb:0.1015, loss-ulb:0.0214, weight:0.97, lr:0.0009
[11:05:59.371] iteration:4761  t-loss:0.1228, loss-lb:0.0985, loss-ulb:0.0251, weight:0.97, lr:0.0009
[11:05:59.563] iteration:4762  t-loss:0.1611, loss-lb:0.0958, loss-ulb:0.0672, weight:0.97, lr:0.0009
[11:05:59.754] iteration:4763  t-loss:0.1282, loss-lb:0.0848, loss-ulb:0.0447, weight:0.97, lr:0.0009
[11:05:59.946] iteration:4764  t-loss:0.1365, loss-lb:0.0985, loss-ulb:0.0391, weight:0.97, lr:0.0009
[11:06:00.138] iteration:4765  t-loss:0.1326, loss-lb:0.1027, loss-ulb:0.0308, weight:0.97, lr:0.0009
[11:06:00.329] iteration:4766  t-loss:0.1426, loss-lb:0.1166, loss-ulb:0.0268, weight:0.97, lr:0.0009
[11:06:00.522] iteration:4767  t-loss:0.1305, loss-lb:0.0906, loss-ulb:0.0411, weight:0.97, lr:0.0009
[11:06:00.715] iteration:4768  t-loss:0.1363, loss-lb:0.1036, loss-ulb:0.0336, weight:0.97, lr:0.0009
[11:06:00.907] iteration:4769  t-loss:0.1348, loss-lb:0.1078, loss-ulb:0.0277, weight:0.97, lr:0.0009
[11:06:01.099] iteration:4770  t-loss:0.1424, loss-lb:0.1034, loss-ulb:0.0401, weight:0.97, lr:0.0009
[11:06:01.290] iteration:4771  t-loss:0.1345, loss-lb:0.0941, loss-ulb:0.0416, weight:0.97, lr:0.0009
[11:06:01.482] iteration:4772  t-loss:0.1727, loss-lb:0.1082, loss-ulb:0.0663, weight:0.97, lr:0.0009
[11:06:01.674] iteration:4773  t-loss:0.1293, loss-lb:0.1061, loss-ulb:0.0238, weight:0.97, lr:0.0009
[11:06:01.866] iteration:4774  t-loss:0.1321, loss-lb:0.1036, loss-ulb:0.0293, weight:0.97, lr:0.0009
[11:06:02.058] iteration:4775  t-loss:0.1719, loss-lb:0.1068, loss-ulb:0.0671, weight:0.97, lr:0.0009
[11:06:02.250] iteration:4776  t-loss:0.1456, loss-lb:0.1024, loss-ulb:0.0444, weight:0.97, lr:0.0009
[11:06:02.443] iteration:4777  t-loss:0.1388, loss-lb:0.0993, loss-ulb:0.0406, weight:0.97, lr:0.0009
[11:06:02.634] iteration:4778  t-loss:0.2196, loss-lb:0.1919, loss-ulb:0.0285, weight:0.97, lr:0.0009
[11:06:02.826] iteration:4779  t-loss:0.1723, loss-lb:0.1051, loss-ulb:0.0691, weight:0.97, lr:0.0009
[11:06:03.018] iteration:4780  t-loss:0.1543, loss-lb:0.1104, loss-ulb:0.0451, weight:0.97, lr:0.0009
[11:06:03.210] iteration:4781  t-loss:0.1546, loss-lb:0.1088, loss-ulb:0.0471, weight:0.97, lr:0.0009
[11:06:03.403] iteration:4782  t-loss:0.1418, loss-lb:0.1122, loss-ulb:0.0305, weight:0.97, lr:0.0009
[11:06:03.594] iteration:4783  t-loss:0.1317, loss-lb:0.0984, loss-ulb:0.0342, weight:0.97, lr:0.0009
[11:06:03.788] iteration:4784  t-loss:0.1620, loss-lb:0.1065, loss-ulb:0.0571, weight:0.97, lr:0.0009
[11:06:03.981] iteration:4785  t-loss:0.1366, loss-lb:0.1053, loss-ulb:0.0323, weight:0.97, lr:0.0009
[11:06:04.173] iteration:4786  t-loss:0.1324, loss-lb:0.1067, loss-ulb:0.0265, weight:0.97, lr:0.0009
[11:06:04.365] iteration:4787  t-loss:0.1451, loss-lb:0.1180, loss-ulb:0.0279, weight:0.97, lr:0.0009
[11:06:04.557] iteration:4788  t-loss:0.1594, loss-lb:0.1197, loss-ulb:0.0408, weight:0.97, lr:0.0009
[11:06:04.751] iteration:4789  t-loss:0.1619, loss-lb:0.1179, loss-ulb:0.0453, weight:0.97, lr:0.0009
[11:06:04.942] iteration:4790  t-loss:0.1653, loss-lb:0.0961, loss-ulb:0.0712, weight:0.97, lr:0.0009
[11:06:05.135] iteration:4791  t-loss:0.1460, loss-lb:0.1171, loss-ulb:0.0297, weight:0.97, lr:0.0009
[11:06:05.328] iteration:4792  t-loss:0.1676, loss-lb:0.0925, loss-ulb:0.0773, weight:0.97, lr:0.0009
[11:06:05.519] iteration:4793  t-loss:0.1415, loss-lb:0.1071, loss-ulb:0.0354, weight:0.97, lr:0.0009
[11:06:05.711] iteration:4794  t-loss:0.1463, loss-lb:0.1040, loss-ulb:0.0435, weight:0.97, lr:0.0009
[11:06:05.903] iteration:4795  t-loss:0.1705, loss-lb:0.1009, loss-ulb:0.0716, weight:0.97, lr:0.0009
[11:06:06.094] iteration:4796  t-loss:0.1414, loss-lb:0.0978, loss-ulb:0.0449, weight:0.97, lr:0.0009
[11:06:06.285] iteration:4797  t-loss:0.1343, loss-lb:0.1002, loss-ulb:0.0351, weight:0.97, lr:0.0009
[11:06:06.476] iteration:4798  t-loss:0.1932, loss-lb:0.1064, loss-ulb:0.0894, weight:0.97, lr:0.0009
[11:06:06.667] iteration:4799  t-loss:0.2123, loss-lb:0.1026, loss-ulb:0.1129, weight:0.97, lr:0.0009
[11:06:06.857] iteration:4800  t-loss:0.1222, loss-lb:0.0998, loss-ulb:0.0230, weight:0.97, lr:0.0009
[11:06:07.049] iteration:4801  t-loss:0.2001, loss-lb:0.0999, loss-ulb:0.0958, weight:1.05, lr:0.0009
[11:06:07.239] iteration:4802  t-loss:0.1425, loss-lb:0.1037, loss-ulb:0.0371, weight:1.05, lr:0.0009
[11:06:18.397]  <<Test>> - Ep:48  - mean_dice/mean_h95 - S:87.55/9.92, Best-S:89.28, T:90.00/1.39, Best-T:90.13
[11:06:18.397]           - AvgLoss(lb/ulb/all):0.1057/0.0516/0.1556
[11:06:18.937] iteration:4803  t-loss:0.1384, loss-lb:0.1020, loss-ulb:0.0348, weight:1.05, lr:0.0009
[11:06:19.135] iteration:4804  t-loss:0.1514, loss-lb:0.1141, loss-ulb:0.0357, weight:1.05, lr:0.0009
[11:06:19.327] iteration:4805  t-loss:0.1656, loss-lb:0.0902, loss-ulb:0.0721, weight:1.05, lr:0.0009
[11:06:19.520] iteration:4806  t-loss:0.1485, loss-lb:0.1191, loss-ulb:0.0282, weight:1.05, lr:0.0009
[11:06:19.714] iteration:4807  t-loss:0.1367, loss-lb:0.0979, loss-ulb:0.0371, weight:1.05, lr:0.0009
[11:06:19.907] iteration:4808  t-loss:0.1505, loss-lb:0.1093, loss-ulb:0.0394, weight:1.05, lr:0.0009
[11:06:20.099] iteration:4809  t-loss:0.2216, loss-lb:0.1017, loss-ulb:0.1146, weight:1.05, lr:0.0009
[11:06:20.294] iteration:4810  t-loss:0.1415, loss-lb:0.1058, loss-ulb:0.0341, weight:1.05, lr:0.0009
[11:06:20.486] iteration:4811  t-loss:0.1311, loss-lb:0.0984, loss-ulb:0.0312, weight:1.05, lr:0.0009
[11:06:20.678] iteration:4812  t-loss:0.1297, loss-lb:0.0980, loss-ulb:0.0303, weight:1.05, lr:0.0009
[11:06:20.871] iteration:4813  t-loss:0.1708, loss-lb:0.0968, loss-ulb:0.0707, weight:1.05, lr:0.0009
[11:06:21.065] iteration:4814  t-loss:0.1479, loss-lb:0.1015, loss-ulb:0.0444, weight:1.05, lr:0.0009
[11:06:21.257] iteration:4815  t-loss:0.1360, loss-lb:0.0932, loss-ulb:0.0410, weight:1.05, lr:0.0009
[11:06:21.450] iteration:4816  t-loss:0.1540, loss-lb:0.1123, loss-ulb:0.0399, weight:1.05, lr:0.0009
[11:06:21.642] iteration:4817  t-loss:0.1454, loss-lb:0.1039, loss-ulb:0.0396, weight:1.05, lr:0.0009
[11:06:21.834] iteration:4818  t-loss:0.1440, loss-lb:0.0968, loss-ulb:0.0451, weight:1.05, lr:0.0009
[11:06:22.028] iteration:4819  t-loss:0.1230, loss-lb:0.0974, loss-ulb:0.0244, weight:1.05, lr:0.0009
[11:06:22.221] iteration:4820  t-loss:0.1332, loss-lb:0.1072, loss-ulb:0.0248, weight:1.05, lr:0.0009
[11:06:22.414] iteration:4821  t-loss:0.2496, loss-lb:0.1055, loss-ulb:0.1378, weight:1.05, lr:0.0009
[11:06:22.608] iteration:4822  t-loss:0.1238, loss-lb:0.0978, loss-ulb:0.0248, weight:1.05, lr:0.0009
[11:06:22.806] iteration:4823  t-loss:0.1625, loss-lb:0.1299, loss-ulb:0.0311, weight:1.05, lr:0.0009
[11:06:22.998] iteration:4824  t-loss:0.1314, loss-lb:0.1023, loss-ulb:0.0278, weight:1.05, lr:0.0009
[11:06:23.189] iteration:4825  t-loss:0.2032, loss-lb:0.1479, loss-ulb:0.0528, weight:1.05, lr:0.0009
[11:06:23.382] iteration:4826  t-loss:0.1117, loss-lb:0.0903, loss-ulb:0.0205, weight:1.05, lr:0.0009
[11:06:23.574] iteration:4827  t-loss:0.1363, loss-lb:0.1018, loss-ulb:0.0330, weight:1.05, lr:0.0009
[11:06:23.767] iteration:4828  t-loss:0.1977, loss-lb:0.1054, loss-ulb:0.0881, weight:1.05, lr:0.0009
[11:06:23.958] iteration:4829  t-loss:0.2171, loss-lb:0.1401, loss-ulb:0.0736, weight:1.05, lr:0.0009
[11:06:24.151] iteration:4830  t-loss:0.1322, loss-lb:0.0998, loss-ulb:0.0309, weight:1.05, lr:0.0009
[11:06:24.343] iteration:4831  t-loss:0.1374, loss-lb:0.1003, loss-ulb:0.0355, weight:1.05, lr:0.0009
[11:06:24.535] iteration:4832  t-loss:0.1294, loss-lb:0.1059, loss-ulb:0.0225, weight:1.05, lr:0.0009
[11:06:24.728] iteration:4833  t-loss:0.1316, loss-lb:0.0979, loss-ulb:0.0322, weight:1.05, lr:0.0009
[11:06:24.932] iteration:4834  t-loss:0.1399, loss-lb:0.1007, loss-ulb:0.0375, weight:1.05, lr:0.0009
[11:06:25.131] iteration:4835  t-loss:0.1764, loss-lb:0.1336, loss-ulb:0.0409, weight:1.05, lr:0.0009
[11:06:25.324] iteration:4836  t-loss:0.1412, loss-lb:0.0997, loss-ulb:0.0396, weight:1.05, lr:0.0009
[11:06:25.515] iteration:4837  t-loss:0.1422, loss-lb:0.0933, loss-ulb:0.0468, weight:1.05, lr:0.0009
[11:06:25.707] iteration:4838  t-loss:0.2216, loss-lb:0.1140, loss-ulb:0.1029, weight:1.05, lr:0.0009
[11:06:25.899] iteration:4839  t-loss:0.1362, loss-lb:0.1013, loss-ulb:0.0333, weight:1.05, lr:0.0009
[11:06:26.092] iteration:4840  t-loss:0.1827, loss-lb:0.1287, loss-ulb:0.0516, weight:1.05, lr:0.0009
[11:06:26.283] iteration:4841  t-loss:0.1331, loss-lb:0.1082, loss-ulb:0.0237, weight:1.05, lr:0.0009
[11:06:26.476] iteration:4842  t-loss:0.1483, loss-lb:0.1121, loss-ulb:0.0346, weight:1.05, lr:0.0009
[11:06:26.667] iteration:4843  t-loss:0.1410, loss-lb:0.1081, loss-ulb:0.0315, weight:1.05, lr:0.0009
[11:06:26.858] iteration:4844  t-loss:0.1457, loss-lb:0.1085, loss-ulb:0.0356, weight:1.05, lr:0.0009
[11:06:27.050] iteration:4845  t-loss:0.2060, loss-lb:0.1290, loss-ulb:0.0736, weight:1.05, lr:0.0009
[11:06:27.244] iteration:4846  t-loss:0.1322, loss-lb:0.1025, loss-ulb:0.0284, weight:1.05, lr:0.0009
[11:06:27.436] iteration:4847  t-loss:0.1610, loss-lb:0.1089, loss-ulb:0.0498, weight:1.05, lr:0.0009
[11:06:27.628] iteration:4848  t-loss:0.1272, loss-lb:0.0995, loss-ulb:0.0265, weight:1.05, lr:0.0009
[11:06:27.820] iteration:4849  t-loss:0.2040, loss-lb:0.1101, loss-ulb:0.0898, weight:1.05, lr:0.0009
[11:06:28.012] iteration:4850  t-loss:0.1279, loss-lb:0.1027, loss-ulb:0.0242, weight:1.05, lr:0.0009
[11:06:28.205] iteration:4851  t-loss:0.1377, loss-lb:0.0980, loss-ulb:0.0379, weight:1.05, lr:0.0009
[11:06:28.396] iteration:4852  t-loss:0.1594, loss-lb:0.1134, loss-ulb:0.0440, weight:1.05, lr:0.0009
[11:06:28.589] iteration:4853  t-loss:0.1590, loss-lb:0.1031, loss-ulb:0.0534, weight:1.05, lr:0.0009
[11:06:28.781] iteration:4854  t-loss:0.2033, loss-lb:0.0987, loss-ulb:0.1000, weight:1.05, lr:0.0009
[11:06:28.974] iteration:4855  t-loss:0.1345, loss-lb:0.1015, loss-ulb:0.0315, weight:1.05, lr:0.0009
[11:06:29.167] iteration:4856  t-loss:0.1392, loss-lb:0.1056, loss-ulb:0.0321, weight:1.05, lr:0.0009
[11:06:29.358] iteration:4857  t-loss:0.1663, loss-lb:0.1107, loss-ulb:0.0531, weight:1.05, lr:0.0009
[11:06:29.551] iteration:4858  t-loss:0.1872, loss-lb:0.1212, loss-ulb:0.0631, weight:1.05, lr:0.0009
[11:06:29.743] iteration:4859  t-loss:0.1465, loss-lb:0.1091, loss-ulb:0.0357, weight:1.05, lr:0.0009
[11:06:29.935] iteration:4860  t-loss:0.1763, loss-lb:0.1129, loss-ulb:0.0606, weight:1.05, lr:0.0009
[11:06:30.127] iteration:4861  t-loss:0.1598, loss-lb:0.1302, loss-ulb:0.0283, weight:1.05, lr:0.0009
[11:06:30.319] iteration:4862  t-loss:0.1537, loss-lb:0.1170, loss-ulb:0.0350, weight:1.05, lr:0.0009
[11:06:30.510] iteration:4863  t-loss:0.1328, loss-lb:0.0956, loss-ulb:0.0355, weight:1.05, lr:0.0009
[11:06:30.702] iteration:4864  t-loss:0.1461, loss-lb:0.0996, loss-ulb:0.0445, weight:1.05, lr:0.0009
[11:06:30.895] iteration:4865  t-loss:0.1298, loss-lb:0.1010, loss-ulb:0.0276, weight:1.05, lr:0.0009
[11:06:31.086] iteration:4866  t-loss:0.1613, loss-lb:0.0942, loss-ulb:0.0641, weight:1.05, lr:0.0009
[11:06:31.278] iteration:4867  t-loss:0.1507, loss-lb:0.0996, loss-ulb:0.0489, weight:1.05, lr:0.0009
[11:06:31.470] iteration:4868  t-loss:0.1579, loss-lb:0.1190, loss-ulb:0.0372, weight:1.05, lr:0.0009
[11:06:31.663] iteration:4869  t-loss:0.1742, loss-lb:0.1028, loss-ulb:0.0682, weight:1.05, lr:0.0009
[11:06:31.854] iteration:4870  t-loss:0.1470, loss-lb:0.1066, loss-ulb:0.0386, weight:1.05, lr:0.0009
[11:06:32.048] iteration:4871  t-loss:0.1655, loss-lb:0.0987, loss-ulb:0.0638, weight:1.05, lr:0.0009
[11:06:32.239] iteration:4872  t-loss:0.1409, loss-lb:0.1165, loss-ulb:0.0233, weight:1.05, lr:0.0009
[11:06:32.432] iteration:4873  t-loss:0.1459, loss-lb:0.0985, loss-ulb:0.0453, weight:1.05, lr:0.0009
[11:06:32.624] iteration:4874  t-loss:0.1499, loss-lb:0.1169, loss-ulb:0.0315, weight:1.05, lr:0.0009
[11:06:32.815] iteration:4875  t-loss:0.1557, loss-lb:0.1136, loss-ulb:0.0402, weight:1.05, lr:0.0009
[11:06:33.007] iteration:4876  t-loss:0.1579, loss-lb:0.1309, loss-ulb:0.0258, weight:1.05, lr:0.0009
[11:06:33.200] iteration:4877  t-loss:0.1392, loss-lb:0.1032, loss-ulb:0.0344, weight:1.05, lr:0.0009
[11:06:33.392] iteration:4878  t-loss:0.1783, loss-lb:0.1040, loss-ulb:0.0710, weight:1.05, lr:0.0009
[11:06:33.584] iteration:4879  t-loss:0.1387, loss-lb:0.1133, loss-ulb:0.0243, weight:1.05, lr:0.0009
[11:06:33.776] iteration:4880  t-loss:0.2096, loss-lb:0.1153, loss-ulb:0.0902, weight:1.05, lr:0.0009
[11:06:33.967] iteration:4881  t-loss:0.1329, loss-lb:0.1094, loss-ulb:0.0225, weight:1.05, lr:0.0009
[11:06:34.159] iteration:4882  t-loss:0.1465, loss-lb:0.0965, loss-ulb:0.0478, weight:1.05, lr:0.0009
[11:06:34.351] iteration:4883  t-loss:0.1377, loss-lb:0.0946, loss-ulb:0.0412, weight:1.05, lr:0.0009
[11:06:34.543] iteration:4884  t-loss:0.1406, loss-lb:0.1047, loss-ulb:0.0344, weight:1.05, lr:0.0009
[11:06:34.734] iteration:4885  t-loss:0.1461, loss-lb:0.1057, loss-ulb:0.0386, weight:1.05, lr:0.0009
[11:06:34.926] iteration:4886  t-loss:0.1599, loss-lb:0.0932, loss-ulb:0.0638, weight:1.05, lr:0.0009
[11:06:35.118] iteration:4887  t-loss:0.2040, loss-lb:0.1345, loss-ulb:0.0665, weight:1.05, lr:0.0009
[11:06:35.310] iteration:4888  t-loss:0.1207, loss-lb:0.0974, loss-ulb:0.0223, weight:1.05, lr:0.0009
[11:06:35.504] iteration:4889  t-loss:0.1503, loss-lb:0.1209, loss-ulb:0.0281, weight:1.05, lr:0.0009
[11:06:35.695] iteration:4890  t-loss:0.1230, loss-lb:0.0970, loss-ulb:0.0248, weight:1.05, lr:0.0009
[11:06:35.889] iteration:4891  t-loss:0.2058, loss-lb:0.1047, loss-ulb:0.0967, weight:1.05, lr:0.0009
[11:06:36.081] iteration:4892  t-loss:0.1354, loss-lb:0.1049, loss-ulb:0.0291, weight:1.05, lr:0.0009
[11:06:36.272] iteration:4893  t-loss:0.1518, loss-lb:0.1137, loss-ulb:0.0365, weight:1.05, lr:0.0009
[11:06:36.464] iteration:4894  t-loss:0.1548, loss-lb:0.1091, loss-ulb:0.0437, weight:1.05, lr:0.0009
[11:06:36.654] iteration:4895  t-loss:0.1392, loss-lb:0.1003, loss-ulb:0.0372, weight:1.05, lr:0.0009
[11:06:36.846] iteration:4896  t-loss:0.1300, loss-lb:0.1060, loss-ulb:0.0230, weight:1.05, lr:0.0009
[11:06:37.035] iteration:4897  t-loss:0.1270, loss-lb:0.0969, loss-ulb:0.0288, weight:1.05, lr:0.0009
[11:06:37.227] iteration:4898  t-loss:0.1604, loss-lb:0.0975, loss-ulb:0.0602, weight:1.05, lr:0.0009
[11:06:37.418] iteration:4899  t-loss:0.1347, loss-lb:0.1029, loss-ulb:0.0304, weight:1.05, lr:0.0009
[11:06:37.612] iteration:4900  t-loss:0.1369, loss-lb:0.1035, loss-ulb:0.0319, weight:1.05, lr:0.0009
[11:06:38.238] iteration:4901  t-loss:0.1336, loss-lb:0.1060, loss-ulb:0.0264, weight:1.05, lr:0.0009
[11:06:38.432] iteration:4902  t-loss:0.1387, loss-lb:0.1067, loss-ulb:0.0306, weight:1.05, lr:0.0009
[11:06:38.625] iteration:4903  t-loss:0.1396, loss-lb:0.1094, loss-ulb:0.0288, weight:1.05, lr:0.0009
[11:06:38.816] iteration:4904  t-loss:0.1319, loss-lb:0.1000, loss-ulb:0.0305, weight:1.05, lr:0.0009
[11:06:39.008] iteration:4905  t-loss:0.1287, loss-lb:0.0974, loss-ulb:0.0299, weight:1.05, lr:0.0009
[11:06:39.200] iteration:4906  t-loss:0.1563, loss-lb:0.1024, loss-ulb:0.0515, weight:1.05, lr:0.0009
[11:06:39.392] iteration:4907  t-loss:0.1328, loss-lb:0.1021, loss-ulb:0.0293, weight:1.05, lr:0.0009
[11:06:39.583] iteration:4908  t-loss:0.1352, loss-lb:0.1080, loss-ulb:0.0261, weight:1.05, lr:0.0009
[11:06:39.775] iteration:4909  t-loss:0.1236, loss-lb:0.0942, loss-ulb:0.0281, weight:1.05, lr:0.0009
[11:06:39.966] iteration:4910  t-loss:0.1198, loss-lb:0.0846, loss-ulb:0.0337, weight:1.05, lr:0.0009
[11:06:40.159] iteration:4911  t-loss:0.1358, loss-lb:0.1092, loss-ulb:0.0255, weight:1.05, lr:0.0009
[11:06:40.351] iteration:4912  t-loss:0.1482, loss-lb:0.1105, loss-ulb:0.0361, weight:1.05, lr:0.0009
[11:06:40.544] iteration:4913  t-loss:0.1550, loss-lb:0.1115, loss-ulb:0.0416, weight:1.05, lr:0.0009
[11:06:40.736] iteration:4914  t-loss:0.1457, loss-lb:0.0979, loss-ulb:0.0457, weight:1.05, lr:0.0009
[11:06:40.927] iteration:4915  t-loss:0.1079, loss-lb:0.0861, loss-ulb:0.0208, weight:1.05, lr:0.0009
[11:06:41.119] iteration:4916  t-loss:0.1211, loss-lb:0.0976, loss-ulb:0.0225, weight:1.05, lr:0.0009
[11:06:41.311] iteration:4917  t-loss:0.1304, loss-lb:0.1045, loss-ulb:0.0248, weight:1.05, lr:0.0009
[11:06:41.502] iteration:4918  t-loss:0.1531, loss-lb:0.1288, loss-ulb:0.0232, weight:1.05, lr:0.0009
[11:06:41.693] iteration:4919  t-loss:0.1465, loss-lb:0.1142, loss-ulb:0.0309, weight:1.05, lr:0.0009
[11:06:41.885] iteration:4920  t-loss:0.1195, loss-lb:0.0901, loss-ulb:0.0280, weight:1.05, lr:0.0009
[11:06:42.078] iteration:4921  t-loss:0.1646, loss-lb:0.1175, loss-ulb:0.0450, weight:1.05, lr:0.0009
[11:06:42.271] iteration:4922  t-loss:0.1281, loss-lb:0.0966, loss-ulb:0.0301, weight:1.05, lr:0.0009
[11:06:42.464] iteration:4923  t-loss:0.1188, loss-lb:0.0942, loss-ulb:0.0235, weight:1.05, lr:0.0009
[11:06:42.655] iteration:4924  t-loss:0.1245, loss-lb:0.0811, loss-ulb:0.0416, weight:1.05, lr:0.0009
[11:06:42.844] iteration:4925  t-loss:0.1278, loss-lb:0.0945, loss-ulb:0.0318, weight:1.05, lr:0.0009
[11:06:43.041] iteration:4926  t-loss:0.1534, loss-lb:0.1159, loss-ulb:0.0358, weight:1.05, lr:0.0009
[11:06:43.233] iteration:4927  t-loss:0.1432, loss-lb:0.0924, loss-ulb:0.0485, weight:1.05, lr:0.0009
[11:06:43.428] iteration:4928  t-loss:0.1704, loss-lb:0.1020, loss-ulb:0.0654, weight:1.05, lr:0.0009
[11:06:43.619] iteration:4929  t-loss:0.1433, loss-lb:0.1063, loss-ulb:0.0354, weight:1.05, lr:0.0009
[11:06:43.810] iteration:4930  t-loss:0.2709, loss-lb:0.0937, loss-ulb:0.1694, weight:1.05, lr:0.0009
[11:06:44.003] iteration:4931  t-loss:0.1518, loss-lb:0.0987, loss-ulb:0.0507, weight:1.05, lr:0.0009
[11:06:44.194] iteration:4932  t-loss:0.1422, loss-lb:0.1043, loss-ulb:0.0362, weight:1.05, lr:0.0009
[11:06:44.387] iteration:4933  t-loss:0.1508, loss-lb:0.1096, loss-ulb:0.0394, weight:1.05, lr:0.0009
[11:06:44.580] iteration:4934  t-loss:0.1608, loss-lb:0.1023, loss-ulb:0.0559, weight:1.05, lr:0.0009
[11:06:44.776] iteration:4935  t-loss:0.1238, loss-lb:0.0984, loss-ulb:0.0243, weight:1.05, lr:0.0009
[11:06:44.969] iteration:4936  t-loss:0.1242, loss-lb:0.0959, loss-ulb:0.0271, weight:1.05, lr:0.0009
[11:06:45.162] iteration:4937  t-loss:0.1335, loss-lb:0.0957, loss-ulb:0.0361, weight:1.05, lr:0.0009
[11:06:45.353] iteration:4938  t-loss:0.1284, loss-lb:0.0946, loss-ulb:0.0324, weight:1.05, lr:0.0009
[11:06:45.545] iteration:4939  t-loss:0.1640, loss-lb:0.1224, loss-ulb:0.0397, weight:1.05, lr:0.0009
[11:06:45.736] iteration:4940  t-loss:0.1746, loss-lb:0.1276, loss-ulb:0.0449, weight:1.05, lr:0.0009
[11:06:45.928] iteration:4941  t-loss:0.1877, loss-lb:0.1121, loss-ulb:0.0722, weight:1.05, lr:0.0009
[11:06:46.120] iteration:4942  t-loss:0.1521, loss-lb:0.1213, loss-ulb:0.0294, weight:1.05, lr:0.0009
[11:06:46.312] iteration:4943  t-loss:0.1488, loss-lb:0.1200, loss-ulb:0.0276, weight:1.05, lr:0.0009
[11:06:46.504] iteration:4944  t-loss:0.1317, loss-lb:0.0996, loss-ulb:0.0307, weight:1.05, lr:0.0009
[11:06:46.696] iteration:4945  t-loss:0.1515, loss-lb:0.1178, loss-ulb:0.0322, weight:1.05, lr:0.0009
[11:06:46.888] iteration:4946  t-loss:0.1751, loss-lb:0.1053, loss-ulb:0.0668, weight:1.05, lr:0.0009
[11:06:47.079] iteration:4947  t-loss:0.1278, loss-lb:0.0968, loss-ulb:0.0296, weight:1.05, lr:0.0009
[11:06:47.270] iteration:4948  t-loss:0.1316, loss-lb:0.0992, loss-ulb:0.0310, weight:1.05, lr:0.0009
[11:06:47.462] iteration:4949  t-loss:0.1214, loss-lb:0.0950, loss-ulb:0.0252, weight:1.05, lr:0.0009
[11:06:47.653] iteration:4950  t-loss:0.1283, loss-lb:0.0934, loss-ulb:0.0334, weight:1.05, lr:0.0009
[11:06:47.847] iteration:4951  t-loss:0.1638, loss-lb:0.0963, loss-ulb:0.0602, weight:1.12, lr:0.0009
[11:06:48.040] iteration:4952  t-loss:0.1236, loss-lb:0.0987, loss-ulb:0.0222, weight:1.12, lr:0.0009
[11:06:48.235] iteration:4953  t-loss:0.1473, loss-lb:0.1094, loss-ulb:0.0338, weight:1.12, lr:0.0009
[11:06:48.430] iteration:4954  t-loss:0.1281, loss-lb:0.0951, loss-ulb:0.0294, weight:1.12, lr:0.0009
[11:06:48.623] iteration:4955  t-loss:0.1593, loss-lb:0.1119, loss-ulb:0.0423, weight:1.12, lr:0.0009
[11:06:48.817] iteration:4956  t-loss:0.1684, loss-lb:0.1203, loss-ulb:0.0429, weight:1.12, lr:0.0009
[11:06:49.011] iteration:4957  t-loss:0.1357, loss-lb:0.1032, loss-ulb:0.0289, weight:1.12, lr:0.0009
[11:06:49.203] iteration:4958  t-loss:0.1489, loss-lb:0.1149, loss-ulb:0.0303, weight:1.12, lr:0.0008
[11:06:49.394] iteration:4959  t-loss:0.1407, loss-lb:0.1079, loss-ulb:0.0292, weight:1.12, lr:0.0008
[11:06:49.586] iteration:4960  t-loss:0.1400, loss-lb:0.1032, loss-ulb:0.0328, weight:1.12, lr:0.0008
[11:06:49.778] iteration:4961  t-loss:0.1507, loss-lb:0.1142, loss-ulb:0.0325, weight:1.12, lr:0.0008
[11:06:49.970] iteration:4962  t-loss:0.1166, loss-lb:0.0896, loss-ulb:0.0241, weight:1.12, lr:0.0008
[11:06:50.162] iteration:4963  t-loss:0.1362, loss-lb:0.0993, loss-ulb:0.0328, weight:1.12, lr:0.0008
[11:06:50.355] iteration:4964  t-loss:0.1770, loss-lb:0.0967, loss-ulb:0.0716, weight:1.12, lr:0.0008
[11:06:50.546] iteration:4965  t-loss:0.1528, loss-lb:0.1143, loss-ulb:0.0343, weight:1.12, lr:0.0008
[11:06:50.738] iteration:4966  t-loss:0.1313, loss-lb:0.1030, loss-ulb:0.0252, weight:1.12, lr:0.0008
[11:06:50.929] iteration:4967  t-loss:0.1302, loss-lb:0.0997, loss-ulb:0.0272, weight:1.12, lr:0.0008
[11:06:51.121] iteration:4968  t-loss:0.1711, loss-lb:0.1392, loss-ulb:0.0284, weight:1.12, lr:0.0008
[11:06:51.313] iteration:4969  t-loss:0.1227, loss-lb:0.0926, loss-ulb:0.0268, weight:1.12, lr:0.0008
[11:06:51.504] iteration:4970  t-loss:0.1804, loss-lb:0.0937, loss-ulb:0.0773, weight:1.12, lr:0.0008
[11:06:51.697] iteration:4971  t-loss:0.1256, loss-lb:0.0965, loss-ulb:0.0259, weight:1.12, lr:0.0008
[11:06:51.890] iteration:4972  t-loss:0.1313, loss-lb:0.0944, loss-ulb:0.0329, weight:1.12, lr:0.0008
[11:06:52.081] iteration:4973  t-loss:0.1378, loss-lb:0.1074, loss-ulb:0.0271, weight:1.12, lr:0.0008
[11:06:52.274] iteration:4974  t-loss:0.1801, loss-lb:0.1192, loss-ulb:0.0543, weight:1.12, lr:0.0008
[11:06:52.466] iteration:4975  t-loss:0.1198, loss-lb:0.0933, loss-ulb:0.0236, weight:1.12, lr:0.0008
[11:06:52.657] iteration:4976  t-loss:0.1526, loss-lb:0.0985, loss-ulb:0.0483, weight:1.12, lr:0.0008
[11:06:52.849] iteration:4977  t-loss:0.1223, loss-lb:0.0913, loss-ulb:0.0276, weight:1.12, lr:0.0008
[11:06:53.041] iteration:4978  t-loss:0.1313, loss-lb:0.1052, loss-ulb:0.0233, weight:1.12, lr:0.0008
[11:06:53.233] iteration:4979  t-loss:0.1362, loss-lb:0.1127, loss-ulb:0.0209, weight:1.12, lr:0.0008
[11:06:53.425] iteration:4980  t-loss:0.1890, loss-lb:0.1313, loss-ulb:0.0514, weight:1.12, lr:0.0008
[11:06:53.617] iteration:4981  t-loss:0.1312, loss-lb:0.0953, loss-ulb:0.0320, weight:1.12, lr:0.0008
[11:06:53.807] iteration:4982  t-loss:0.1396, loss-lb:0.1133, loss-ulb:0.0234, weight:1.12, lr:0.0008
[11:06:53.999] iteration:4983  t-loss:0.1402, loss-lb:0.1031, loss-ulb:0.0331, weight:1.12, lr:0.0008
[11:06:54.191] iteration:4984  t-loss:0.1246, loss-lb:0.0964, loss-ulb:0.0252, weight:1.12, lr:0.0008
[11:06:54.383] iteration:4985  t-loss:0.1214, loss-lb:0.0968, loss-ulb:0.0219, weight:1.12, lr:0.0008
[11:06:54.575] iteration:4986  t-loss:0.1209, loss-lb:0.0917, loss-ulb:0.0260, weight:1.12, lr:0.0008
[11:06:54.766] iteration:4987  t-loss:0.1388, loss-lb:0.0959, loss-ulb:0.0382, weight:1.12, lr:0.0008
[11:06:54.956] iteration:4988  t-loss:0.1215, loss-lb:0.0939, loss-ulb:0.0245, weight:1.12, lr:0.0008
[11:06:55.149] iteration:4989  t-loss:0.1325, loss-lb:0.0936, loss-ulb:0.0347, weight:1.12, lr:0.0008
[11:06:55.340] iteration:4990  t-loss:0.1378, loss-lb:0.1001, loss-ulb:0.0335, weight:1.12, lr:0.0008
[11:06:55.531] iteration:4991  t-loss:0.1594, loss-lb:0.0961, loss-ulb:0.0565, weight:1.12, lr:0.0008
[11:06:55.721] iteration:4992  t-loss:0.1251, loss-lb:0.0970, loss-ulb:0.0251, weight:1.12, lr:0.0008
[11:06:55.910] iteration:4993  t-loss:0.1364, loss-lb:0.1070, loss-ulb:0.0263, weight:1.12, lr:0.0008
[11:06:56.101] iteration:4994  t-loss:0.1887, loss-lb:0.0936, loss-ulb:0.0848, weight:1.12, lr:0.0008
[11:06:56.290] iteration:4995  t-loss:0.1190, loss-lb:0.0871, loss-ulb:0.0284, weight:1.12, lr:0.0008
[11:06:56.479] iteration:4996  t-loss:0.1484, loss-lb:0.1099, loss-ulb:0.0343, weight:1.12, lr:0.0008
[11:06:56.669] iteration:4997  t-loss:0.1441, loss-lb:0.1033, loss-ulb:0.0363, weight:1.12, lr:0.0008
[11:06:56.858] iteration:4998  t-loss:0.1284, loss-lb:0.0988, loss-ulb:0.0264, weight:1.12, lr:0.0008
[11:07:09.443]  <<Test>> - Ep:50  - mean_dice/mean_h95 - S:89.92/1.41, Best-S:89.92, T:89.93/2.00, Best-T:90.13
[11:07:09.443]           - AvgLoss(lb/ulb/all):0.1030/0.0341/0.1392
[11:07:09.993] iteration:4999  t-loss:0.1314, loss-lb:0.0924, loss-ulb:0.0347, weight:1.12, lr:0.0008
[11:07:10.192] iteration:5000  t-loss:0.1194, loss-lb:0.0930, loss-ulb:0.0235, weight:1.12, lr:0.0008
[11:07:10.385] iteration:5001  t-loss:0.1596, loss-lb:0.0992, loss-ulb:0.0538, weight:1.12, lr:0.0008
[11:07:10.577] iteration:5002  t-loss:0.1205, loss-lb:0.0948, loss-ulb:0.0229, weight:1.12, lr:0.0008
[11:07:10.769] iteration:5003  t-loss:0.1896, loss-lb:0.1026, loss-ulb:0.0775, weight:1.12, lr:0.0008
[11:07:10.962] iteration:5004  t-loss:0.1423, loss-lb:0.1021, loss-ulb:0.0358, weight:1.12, lr:0.0008
[11:07:11.153] iteration:5005  t-loss:0.1312, loss-lb:0.1064, loss-ulb:0.0221, weight:1.12, lr:0.0008
[11:07:11.345] iteration:5006  t-loss:0.1385, loss-lb:0.1034, loss-ulb:0.0313, weight:1.12, lr:0.0008
[11:07:11.537] iteration:5007  t-loss:0.1281, loss-lb:0.1014, loss-ulb:0.0238, weight:1.12, lr:0.0008
[11:07:11.729] iteration:5008  t-loss:0.1217, loss-lb:0.0984, loss-ulb:0.0208, weight:1.12, lr:0.0008
[11:07:11.921] iteration:5009  t-loss:0.1341, loss-lb:0.0961, loss-ulb:0.0338, weight:1.12, lr:0.0008
[11:07:12.115] iteration:5010  t-loss:0.1268, loss-lb:0.0995, loss-ulb:0.0243, weight:1.12, lr:0.0008
[11:07:12.306] iteration:5011  t-loss:0.1241, loss-lb:0.0961, loss-ulb:0.0250, weight:1.12, lr:0.0008
[11:07:12.498] iteration:5012  t-loss:0.1262, loss-lb:0.0866, loss-ulb:0.0353, weight:1.12, lr:0.0008
[11:07:12.690] iteration:5013  t-loss:0.1346, loss-lb:0.1038, loss-ulb:0.0275, weight:1.12, lr:0.0008
[11:07:12.882] iteration:5014  t-loss:0.1524, loss-lb:0.0981, loss-ulb:0.0484, weight:1.12, lr:0.0008
[11:07:13.075] iteration:5015  t-loss:0.1445, loss-lb:0.0937, loss-ulb:0.0453, weight:1.12, lr:0.0008
[11:07:13.268] iteration:5016  t-loss:0.1600, loss-lb:0.1086, loss-ulb:0.0459, weight:1.12, lr:0.0008
[11:07:13.461] iteration:5017  t-loss:0.1250, loss-lb:0.1001, loss-ulb:0.0222, weight:1.12, lr:0.0008
[11:07:13.653] iteration:5018  t-loss:0.1305, loss-lb:0.0902, loss-ulb:0.0360, weight:1.12, lr:0.0008
[11:07:13.846] iteration:5019  t-loss:0.1285, loss-lb:0.0941, loss-ulb:0.0307, weight:1.12, lr:0.0008
[11:07:14.037] iteration:5020  t-loss:0.1482, loss-lb:0.1175, loss-ulb:0.0273, weight:1.12, lr:0.0008
[11:07:14.229] iteration:5021  t-loss:0.1253, loss-lb:0.0956, loss-ulb:0.0265, weight:1.12, lr:0.0008
[11:07:14.422] iteration:5022  t-loss:0.1283, loss-lb:0.0955, loss-ulb:0.0293, weight:1.12, lr:0.0008
[11:07:14.613] iteration:5023  t-loss:0.1244, loss-lb:0.0944, loss-ulb:0.0267, weight:1.12, lr:0.0008
[11:07:14.805] iteration:5024  t-loss:0.1273, loss-lb:0.1009, loss-ulb:0.0235, weight:1.12, lr:0.0008
[11:07:14.997] iteration:5025  t-loss:0.1314, loss-lb:0.0989, loss-ulb:0.0290, weight:1.12, lr:0.0008
[11:07:15.188] iteration:5026  t-loss:0.1338, loss-lb:0.1000, loss-ulb:0.0301, weight:1.12, lr:0.0008
[11:07:15.381] iteration:5027  t-loss:0.2396, loss-lb:0.1130, loss-ulb:0.1128, weight:1.12, lr:0.0008
[11:07:15.573] iteration:5028  t-loss:0.1274, loss-lb:0.0979, loss-ulb:0.0263, weight:1.12, lr:0.0008
[11:07:15.764] iteration:5029  t-loss:0.1273, loss-lb:0.0896, loss-ulb:0.0336, weight:1.12, lr:0.0008
[11:07:15.956] iteration:5030  t-loss:0.1451, loss-lb:0.1001, loss-ulb:0.0401, weight:1.12, lr:0.0008
[11:07:16.149] iteration:5031  t-loss:0.1144, loss-lb:0.0821, loss-ulb:0.0288, weight:1.12, lr:0.0008
[11:07:16.340] iteration:5032  t-loss:0.1176, loss-lb:0.0865, loss-ulb:0.0277, weight:1.12, lr:0.0008
[11:07:16.532] iteration:5033  t-loss:0.1246, loss-lb:0.1010, loss-ulb:0.0210, weight:1.12, lr:0.0008
[11:07:16.724] iteration:5034  t-loss:0.1376, loss-lb:0.1086, loss-ulb:0.0259, weight:1.12, lr:0.0008
[11:07:16.915] iteration:5035  t-loss:0.1273, loss-lb:0.0931, loss-ulb:0.0305, weight:1.12, lr:0.0008
[11:07:17.107] iteration:5036  t-loss:0.1246, loss-lb:0.0937, loss-ulb:0.0276, weight:1.12, lr:0.0008
[11:07:17.298] iteration:5037  t-loss:0.1355, loss-lb:0.1019, loss-ulb:0.0299, weight:1.12, lr:0.0008
[11:07:17.489] iteration:5038  t-loss:0.1080, loss-lb:0.0824, loss-ulb:0.0228, weight:1.12, lr:0.0008
[11:07:17.681] iteration:5039  t-loss:0.1562, loss-lb:0.1271, loss-ulb:0.0259, weight:1.12, lr:0.0008
[11:07:17.872] iteration:5040  t-loss:0.1149, loss-lb:0.0875, loss-ulb:0.0244, weight:1.12, lr:0.0008
[11:07:18.064] iteration:5041  t-loss:0.2511, loss-lb:0.1474, loss-ulb:0.0924, weight:1.12, lr:0.0008
[11:07:18.253] iteration:5042  t-loss:0.1189, loss-lb:0.0907, loss-ulb:0.0251, weight:1.12, lr:0.0008
[11:07:18.445] iteration:5043  t-loss:0.1463, loss-lb:0.0977, loss-ulb:0.0434, weight:1.12, lr:0.0008
[11:07:18.636] iteration:5044  t-loss:0.1300, loss-lb:0.0969, loss-ulb:0.0296, weight:1.12, lr:0.0008
[11:07:18.827] iteration:5045  t-loss:0.1290, loss-lb:0.0972, loss-ulb:0.0284, weight:1.12, lr:0.0008
[11:07:19.018] iteration:5046  t-loss:0.1785, loss-lb:0.1029, loss-ulb:0.0674, weight:1.12, lr:0.0008
[11:07:19.210] iteration:5047  t-loss:0.1305, loss-lb:0.0976, loss-ulb:0.0293, weight:1.12, lr:0.0008
[11:07:19.400] iteration:5048  t-loss:0.1362, loss-lb:0.1074, loss-ulb:0.0256, weight:1.12, lr:0.0008
[11:07:19.592] iteration:5049  t-loss:0.1392, loss-lb:0.1062, loss-ulb:0.0294, weight:1.12, lr:0.0008
[11:07:19.784] iteration:5050  t-loss:0.1416, loss-lb:0.1134, loss-ulb:0.0252, weight:1.12, lr:0.0008
[11:07:19.975] iteration:5051  t-loss:0.1510, loss-lb:0.1096, loss-ulb:0.0369, weight:1.12, lr:0.0008
[11:07:20.166] iteration:5052  t-loss:0.1480, loss-lb:0.0988, loss-ulb:0.0439, weight:1.12, lr:0.0008
[11:07:20.359] iteration:5053  t-loss:0.1284, loss-lb:0.1009, loss-ulb:0.0245, weight:1.12, lr:0.0008
[11:07:20.550] iteration:5054  t-loss:0.1624, loss-lb:0.1008, loss-ulb:0.0549, weight:1.12, lr:0.0008
[11:07:20.743] iteration:5055  t-loss:0.1413, loss-lb:0.1042, loss-ulb:0.0331, weight:1.12, lr:0.0008
[11:07:20.935] iteration:5056  t-loss:0.1517, loss-lb:0.1177, loss-ulb:0.0303, weight:1.12, lr:0.0008
[11:07:21.127] iteration:5057  t-loss:0.1297, loss-lb:0.0992, loss-ulb:0.0272, weight:1.12, lr:0.0008
[11:07:21.320] iteration:5058  t-loss:0.1329, loss-lb:0.0994, loss-ulb:0.0299, weight:1.12, lr:0.0008
[11:07:21.512] iteration:5059  t-loss:0.2023, loss-lb:0.0947, loss-ulb:0.0959, weight:1.12, lr:0.0008
[11:07:21.704] iteration:5060  t-loss:0.1893, loss-lb:0.0953, loss-ulb:0.0838, weight:1.12, lr:0.0008
[11:07:21.898] iteration:5061  t-loss:0.1312, loss-lb:0.1014, loss-ulb:0.0266, weight:1.12, lr:0.0008
[11:07:22.089] iteration:5062  t-loss:0.1397, loss-lb:0.1012, loss-ulb:0.0343, weight:1.12, lr:0.0008
[11:07:22.281] iteration:5063  t-loss:0.1698, loss-lb:0.1029, loss-ulb:0.0596, weight:1.12, lr:0.0008
[11:07:22.473] iteration:5064  t-loss:0.1293, loss-lb:0.0942, loss-ulb:0.0313, weight:1.12, lr:0.0008
[11:07:22.665] iteration:5065  t-loss:0.1235, loss-lb:0.0916, loss-ulb:0.0285, weight:1.12, lr:0.0008
[11:07:22.857] iteration:5066  t-loss:0.1468, loss-lb:0.0982, loss-ulb:0.0433, weight:1.12, lr:0.0008
[11:07:23.050] iteration:5067  t-loss:0.1504, loss-lb:0.1017, loss-ulb:0.0434, weight:1.12, lr:0.0008
[11:07:23.241] iteration:5068  t-loss:0.1545, loss-lb:0.1312, loss-ulb:0.0208, weight:1.12, lr:0.0008
[11:07:23.434] iteration:5069  t-loss:0.1341, loss-lb:0.1049, loss-ulb:0.0260, weight:1.12, lr:0.0008
[11:07:23.627] iteration:5070  t-loss:0.1602, loss-lb:0.0936, loss-ulb:0.0594, weight:1.12, lr:0.0008
[11:07:23.819] iteration:5071  t-loss:0.1323, loss-lb:0.0933, loss-ulb:0.0348, weight:1.12, lr:0.0008
[11:07:24.011] iteration:5072  t-loss:0.1394, loss-lb:0.1020, loss-ulb:0.0334, weight:1.12, lr:0.0008
[11:07:24.203] iteration:5073  t-loss:0.1455, loss-lb:0.1084, loss-ulb:0.0331, weight:1.12, lr:0.0008
[11:07:24.396] iteration:5074  t-loss:0.1544, loss-lb:0.1138, loss-ulb:0.0363, weight:1.12, lr:0.0008
[11:07:24.588] iteration:5075  t-loss:0.1577, loss-lb:0.1062, loss-ulb:0.0459, weight:1.12, lr:0.0008
[11:07:24.781] iteration:5076  t-loss:0.1272, loss-lb:0.0942, loss-ulb:0.0294, weight:1.12, lr:0.0008
[11:07:24.973] iteration:5077  t-loss:0.1339, loss-lb:0.0956, loss-ulb:0.0341, weight:1.12, lr:0.0008
[11:07:25.166] iteration:5078  t-loss:0.1370, loss-lb:0.0836, loss-ulb:0.0476, weight:1.12, lr:0.0008
[11:07:25.357] iteration:5079  t-loss:0.1206, loss-lb:0.0924, loss-ulb:0.0251, weight:1.12, lr:0.0008
[11:07:25.549] iteration:5080  t-loss:0.1334, loss-lb:0.0977, loss-ulb:0.0318, weight:1.12, lr:0.0008
[11:07:25.742] iteration:5081  t-loss:0.1281, loss-lb:0.0945, loss-ulb:0.0299, weight:1.12, lr:0.0008
[11:07:25.934] iteration:5082  t-loss:0.1304, loss-lb:0.0893, loss-ulb:0.0366, weight:1.12, lr:0.0008
[11:07:26.127] iteration:5083  t-loss:0.2158, loss-lb:0.0931, loss-ulb:0.1094, weight:1.12, lr:0.0008
[11:07:26.320] iteration:5084  t-loss:0.1500, loss-lb:0.1009, loss-ulb:0.0437, weight:1.12, lr:0.0008
[11:07:26.512] iteration:5085  t-loss:0.1718, loss-lb:0.1288, loss-ulb:0.0383, weight:1.12, lr:0.0008
[11:07:26.705] iteration:5086  t-loss:0.1447, loss-lb:0.0995, loss-ulb:0.0403, weight:1.12, lr:0.0008
[11:07:26.896] iteration:5087  t-loss:0.1698, loss-lb:0.1254, loss-ulb:0.0396, weight:1.12, lr:0.0008
[11:07:27.089] iteration:5088  t-loss:0.1412, loss-lb:0.1062, loss-ulb:0.0312, weight:1.12, lr:0.0008
[11:07:27.280] iteration:5089  t-loss:0.1530, loss-lb:0.1151, loss-ulb:0.0337, weight:1.12, lr:0.0008
[11:07:27.471] iteration:5090  t-loss:0.1907, loss-lb:0.1573, loss-ulb:0.0298, weight:1.12, lr:0.0008
[11:07:27.660] iteration:5091  t-loss:0.1452, loss-lb:0.1069, loss-ulb:0.0341, weight:1.12, lr:0.0008
[11:07:27.850] iteration:5092  t-loss:0.1384, loss-lb:0.0970, loss-ulb:0.0369, weight:1.12, lr:0.0008
[11:07:28.040] iteration:5093  t-loss:0.1265, loss-lb:0.1005, loss-ulb:0.0232, weight:1.12, lr:0.0008
[11:07:28.230] iteration:5094  t-loss:0.1463, loss-lb:0.1148, loss-ulb:0.0281, weight:1.12, lr:0.0008
[11:07:28.421] iteration:5095  t-loss:0.1191, loss-lb:0.0899, loss-ulb:0.0260, weight:1.12, lr:0.0008
[11:07:28.611] iteration:5096  t-loss:0.1391, loss-lb:0.1073, loss-ulb:0.0284, weight:1.12, lr:0.0008
[11:07:29.183] iteration:5097  t-loss:0.1444, loss-lb:0.1092, loss-ulb:0.0314, weight:1.12, lr:0.0008
[11:07:29.381] iteration:5098  t-loss:0.2187, loss-lb:0.0922, loss-ulb:0.1127, weight:1.12, lr:0.0008
[11:07:29.573] iteration:5099  t-loss:0.1225, loss-lb:0.0940, loss-ulb:0.0254, weight:1.12, lr:0.0008
[11:07:29.765] iteration:5100  t-loss:0.1735, loss-lb:0.1485, loss-ulb:0.0222, weight:1.12, lr:0.0008
[11:07:29.957] iteration:5101  t-loss:0.1314, loss-lb:0.0947, loss-ulb:0.0306, weight:1.20, lr:0.0008
[11:07:30.149] iteration:5102  t-loss:0.1875, loss-lb:0.1075, loss-ulb:0.0668, weight:1.20, lr:0.0008
[11:07:30.349] iteration:5103  t-loss:0.1252, loss-lb:0.0986, loss-ulb:0.0222, weight:1.20, lr:0.0008
[11:07:30.553] iteration:5104  t-loss:0.1930, loss-lb:0.1038, loss-ulb:0.0744, weight:1.20, lr:0.0008
[11:07:30.751] iteration:5105  t-loss:0.1564, loss-lb:0.1112, loss-ulb:0.0377, weight:1.20, lr:0.0008
[11:07:30.942] iteration:5106  t-loss:0.1346, loss-lb:0.0944, loss-ulb:0.0335, weight:1.20, lr:0.0008
[11:07:31.136] iteration:5107  t-loss:0.1449, loss-lb:0.1015, loss-ulb:0.0362, weight:1.20, lr:0.0008
[11:07:31.329] iteration:5108  t-loss:0.1478, loss-lb:0.0958, loss-ulb:0.0434, weight:1.20, lr:0.0008
[11:07:31.521] iteration:5109  t-loss:0.1555, loss-lb:0.0940, loss-ulb:0.0513, weight:1.20, lr:0.0008
[11:07:31.714] iteration:5110  t-loss:0.1508, loss-lb:0.1128, loss-ulb:0.0317, weight:1.20, lr:0.0008
[11:07:31.905] iteration:5111  t-loss:0.1629, loss-lb:0.1237, loss-ulb:0.0326, weight:1.20, lr:0.0008
[11:07:32.097] iteration:5112  t-loss:0.1219, loss-lb:0.0952, loss-ulb:0.0222, weight:1.20, lr:0.0008
[11:07:32.291] iteration:5113  t-loss:0.1738, loss-lb:0.1100, loss-ulb:0.0532, weight:1.20, lr:0.0008
[11:07:32.484] iteration:5114  t-loss:0.1749, loss-lb:0.1042, loss-ulb:0.0590, weight:1.20, lr:0.0008
[11:07:32.676] iteration:5115  t-loss:0.1409, loss-lb:0.1004, loss-ulb:0.0338, weight:1.20, lr:0.0008
[11:07:32.869] iteration:5116  t-loss:0.1340, loss-lb:0.0932, loss-ulb:0.0340, weight:1.20, lr:0.0008
[11:07:33.064] iteration:5117  t-loss:0.1371, loss-lb:0.1058, loss-ulb:0.0261, weight:1.20, lr:0.0008
[11:07:33.255] iteration:5118  t-loss:0.1503, loss-lb:0.1067, loss-ulb:0.0364, weight:1.20, lr:0.0008
[11:07:33.448] iteration:5119  t-loss:0.1320, loss-lb:0.0962, loss-ulb:0.0299, weight:1.20, lr:0.0008
[11:07:33.642] iteration:5120  t-loss:0.1274, loss-lb:0.0972, loss-ulb:0.0252, weight:1.20, lr:0.0008
[11:07:33.835] iteration:5121  t-loss:0.1308, loss-lb:0.0968, loss-ulb:0.0284, weight:1.20, lr:0.0008
[11:07:34.027] iteration:5122  t-loss:0.1572, loss-lb:0.1031, loss-ulb:0.0451, weight:1.20, lr:0.0008
[11:07:34.220] iteration:5123  t-loss:0.2036, loss-lb:0.1025, loss-ulb:0.0844, weight:1.20, lr:0.0008
[11:07:34.412] iteration:5124  t-loss:0.1656, loss-lb:0.1336, loss-ulb:0.0267, weight:1.20, lr:0.0008
[11:07:34.605] iteration:5125  t-loss:0.1938, loss-lb:0.0982, loss-ulb:0.0797, weight:1.20, lr:0.0008
[11:07:34.797] iteration:5126  t-loss:0.1504, loss-lb:0.1016, loss-ulb:0.0407, weight:1.20, lr:0.0008
[11:07:34.989] iteration:5127  t-loss:0.1384, loss-lb:0.0916, loss-ulb:0.0390, weight:1.20, lr:0.0008
[11:07:35.181] iteration:5128  t-loss:0.1354, loss-lb:0.1048, loss-ulb:0.0256, weight:1.20, lr:0.0008
[11:07:35.373] iteration:5129  t-loss:0.1524, loss-lb:0.0976, loss-ulb:0.0457, weight:1.20, lr:0.0008
[11:07:35.565] iteration:5130  t-loss:0.1377, loss-lb:0.1091, loss-ulb:0.0239, weight:1.20, lr:0.0008
[11:07:35.757] iteration:5131  t-loss:0.1612, loss-lb:0.1113, loss-ulb:0.0416, weight:1.20, lr:0.0008
[11:07:35.951] iteration:5132  t-loss:0.1235, loss-lb:0.0918, loss-ulb:0.0265, weight:1.20, lr:0.0008
[11:07:36.145] iteration:5133  t-loss:0.1494, loss-lb:0.1067, loss-ulb:0.0356, weight:1.20, lr:0.0008
[11:07:36.337] iteration:5134  t-loss:0.1439, loss-lb:0.1011, loss-ulb:0.0357, weight:1.20, lr:0.0008
[11:07:36.529] iteration:5135  t-loss:0.1246, loss-lb:0.0974, loss-ulb:0.0226, weight:1.20, lr:0.0008
[11:07:36.724] iteration:5136  t-loss:0.1304, loss-lb:0.0954, loss-ulb:0.0293, weight:1.20, lr:0.0008
[11:07:36.916] iteration:5137  t-loss:0.1365, loss-lb:0.1073, loss-ulb:0.0243, weight:1.20, lr:0.0008
[11:07:37.110] iteration:5138  t-loss:0.1535, loss-lb:0.1083, loss-ulb:0.0377, weight:1.20, lr:0.0008
[11:07:37.301] iteration:5139  t-loss:0.1432, loss-lb:0.1020, loss-ulb:0.0343, weight:1.20, lr:0.0008
[11:07:37.494] iteration:5140  t-loss:0.1291, loss-lb:0.0954, loss-ulb:0.0282, weight:1.20, lr:0.0008
[11:07:37.687] iteration:5141  t-loss:0.1190, loss-lb:0.0846, loss-ulb:0.0287, weight:1.20, lr:0.0008
[11:07:37.879] iteration:5142  t-loss:0.1293, loss-lb:0.0969, loss-ulb:0.0270, weight:1.20, lr:0.0008
[11:07:38.070] iteration:5143  t-loss:0.1171, loss-lb:0.0892, loss-ulb:0.0233, weight:1.20, lr:0.0008
[11:07:38.263] iteration:5144  t-loss:0.1347, loss-lb:0.0963, loss-ulb:0.0321, weight:1.20, lr:0.0008
[11:07:38.455] iteration:5145  t-loss:0.1499, loss-lb:0.1090, loss-ulb:0.0341, weight:1.20, lr:0.0008
[11:07:38.647] iteration:5146  t-loss:0.1243, loss-lb:0.0923, loss-ulb:0.0266, weight:1.20, lr:0.0008
[11:07:38.838] iteration:5147  t-loss:0.1526, loss-lb:0.1012, loss-ulb:0.0429, weight:1.20, lr:0.0008
[11:07:39.029] iteration:5148  t-loss:0.1394, loss-lb:0.0986, loss-ulb:0.0340, weight:1.20, lr:0.0008
[11:07:39.222] iteration:5149  t-loss:0.1230, loss-lb:0.0871, loss-ulb:0.0300, weight:1.20, lr:0.0008
[11:07:39.414] iteration:5150  t-loss:0.1711, loss-lb:0.1267, loss-ulb:0.0370, weight:1.20, lr:0.0008
[11:07:39.606] iteration:5151  t-loss:0.1397, loss-lb:0.1004, loss-ulb:0.0328, weight:1.20, lr:0.0008
[11:07:39.797] iteration:5152  t-loss:0.1278, loss-lb:0.0913, loss-ulb:0.0304, weight:1.20, lr:0.0008
[11:07:39.991] iteration:5153  t-loss:0.1526, loss-lb:0.0998, loss-ulb:0.0441, weight:1.20, lr:0.0008
[11:07:40.183] iteration:5154  t-loss:0.1343, loss-lb:0.1021, loss-ulb:0.0269, weight:1.20, lr:0.0008
[11:07:40.376] iteration:5155  t-loss:0.1510, loss-lb:0.1010, loss-ulb:0.0417, weight:1.20, lr:0.0008
[11:07:40.568] iteration:5156  t-loss:0.1277, loss-lb:0.0955, loss-ulb:0.0269, weight:1.20, lr:0.0008
[11:07:40.760] iteration:5157  t-loss:0.1217, loss-lb:0.0860, loss-ulb:0.0298, weight:1.20, lr:0.0008
[11:07:40.952] iteration:5158  t-loss:0.1273, loss-lb:0.0913, loss-ulb:0.0300, weight:1.20, lr:0.0008
[11:07:41.145] iteration:5159  t-loss:0.1306, loss-lb:0.0936, loss-ulb:0.0309, weight:1.20, lr:0.0008
[11:07:41.336] iteration:5160  t-loss:0.1316, loss-lb:0.1051, loss-ulb:0.0221, weight:1.20, lr:0.0008
[11:07:41.528] iteration:5161  t-loss:0.1260, loss-lb:0.1010, loss-ulb:0.0209, weight:1.20, lr:0.0008
[11:07:41.721] iteration:5162  t-loss:0.1567, loss-lb:0.0940, loss-ulb:0.0523, weight:1.20, lr:0.0008
[11:07:41.912] iteration:5163  t-loss:0.1395, loss-lb:0.0936, loss-ulb:0.0383, weight:1.20, lr:0.0008
[11:07:42.105] iteration:5164  t-loss:0.1658, loss-lb:0.1083, loss-ulb:0.0480, weight:1.20, lr:0.0008
[11:07:42.298] iteration:5165  t-loss:0.1857, loss-lb:0.0898, loss-ulb:0.0800, weight:1.20, lr:0.0008
[11:07:42.492] iteration:5166  t-loss:0.1241, loss-lb:0.0956, loss-ulb:0.0238, weight:1.20, lr:0.0008
[11:07:42.685] iteration:5167  t-loss:0.1510, loss-lb:0.1159, loss-ulb:0.0293, weight:1.20, lr:0.0008
[11:07:42.876] iteration:5168  t-loss:0.1544, loss-lb:0.1161, loss-ulb:0.0319, weight:1.20, lr:0.0008
[11:07:43.068] iteration:5169  t-loss:0.1441, loss-lb:0.1157, loss-ulb:0.0237, weight:1.20, lr:0.0008
[11:07:43.261] iteration:5170  t-loss:0.1398, loss-lb:0.1039, loss-ulb:0.0300, weight:1.20, lr:0.0008
[11:07:43.454] iteration:5171  t-loss:0.1260, loss-lb:0.0880, loss-ulb:0.0317, weight:1.20, lr:0.0008
[11:07:43.646] iteration:5172  t-loss:0.1786, loss-lb:0.1012, loss-ulb:0.0646, weight:1.20, lr:0.0008
[11:07:43.838] iteration:5173  t-loss:0.1350, loss-lb:0.1017, loss-ulb:0.0278, weight:1.20, lr:0.0008
[11:07:44.030] iteration:5174  t-loss:0.1621, loss-lb:0.1348, loss-ulb:0.0228, weight:1.20, lr:0.0008
[11:07:44.222] iteration:5175  t-loss:0.1229, loss-lb:0.0974, loss-ulb:0.0213, weight:1.20, lr:0.0008
[11:07:44.414] iteration:5176  t-loss:0.1189, loss-lb:0.0851, loss-ulb:0.0282, weight:1.20, lr:0.0008
[11:07:44.606] iteration:5177  t-loss:0.2738, loss-lb:0.0966, loss-ulb:0.1478, weight:1.20, lr:0.0008
[11:07:44.799] iteration:5178  t-loss:0.1287, loss-lb:0.0939, loss-ulb:0.0290, weight:1.20, lr:0.0008
[11:07:44.990] iteration:5179  t-loss:0.1641, loss-lb:0.0952, loss-ulb:0.0574, weight:1.20, lr:0.0008
[11:07:45.183] iteration:5180  t-loss:0.1303, loss-lb:0.1030, loss-ulb:0.0227, weight:1.20, lr:0.0008
[11:07:45.374] iteration:5181  t-loss:0.1518, loss-lb:0.1017, loss-ulb:0.0418, weight:1.20, lr:0.0008
[11:07:45.565] iteration:5182  t-loss:0.1177, loss-lb:0.0858, loss-ulb:0.0266, weight:1.20, lr:0.0008
[11:07:45.759] iteration:5183  t-loss:0.1396, loss-lb:0.1060, loss-ulb:0.0280, weight:1.20, lr:0.0008
[11:07:45.952] iteration:5184  t-loss:0.1673, loss-lb:0.0986, loss-ulb:0.0573, weight:1.20, lr:0.0008
[11:07:46.145] iteration:5185  t-loss:0.1861, loss-lb:0.1068, loss-ulb:0.0661, weight:1.20, lr:0.0008
[11:07:46.337] iteration:5186  t-loss:0.1356, loss-lb:0.1040, loss-ulb:0.0263, weight:1.20, lr:0.0008
[11:07:46.529] iteration:5187  t-loss:0.1319, loss-lb:0.1034, loss-ulb:0.0238, weight:1.20, lr:0.0008
[11:07:46.721] iteration:5188  t-loss:0.1514, loss-lb:0.0920, loss-ulb:0.0496, weight:1.20, lr:0.0008
[11:07:46.911] iteration:5189  t-loss:0.1332, loss-lb:0.0948, loss-ulb:0.0321, weight:1.20, lr:0.0008
[11:07:47.101] iteration:5190  t-loss:0.1382, loss-lb:0.1067, loss-ulb:0.0263, weight:1.20, lr:0.0008
[11:07:47.291] iteration:5191  t-loss:0.1248, loss-lb:0.0911, loss-ulb:0.0281, weight:1.20, lr:0.0008
[11:07:47.481] iteration:5192  t-loss:0.1732, loss-lb:0.1015, loss-ulb:0.0599, weight:1.20, lr:0.0008
[11:07:47.671] iteration:5193  t-loss:0.1636, loss-lb:0.0912, loss-ulb:0.0604, weight:1.20, lr:0.0008
[11:07:47.861] iteration:5194  t-loss:0.1319, loss-lb:0.0994, loss-ulb:0.0271, weight:1.20, lr:0.0008
[11:07:58.755]  <<Test>> - Ep:52  - mean_dice/mean_h95 - S:89.53/2.44, Best-S:89.92, T:90.11/1.35, Best-T:90.13
[11:07:58.755]           - AvgLoss(lb/ulb/all):0.1011/0.0430/0.1492
[11:07:59.319] iteration:5195  t-loss:0.1554, loss-lb:0.1223, loss-ulb:0.0277, weight:1.20, lr:0.0008
[11:07:59.517] iteration:5196  t-loss:0.1550, loss-lb:0.0864, loss-ulb:0.0573, weight:1.20, lr:0.0008
[11:07:59.710] iteration:5197  t-loss:0.1390, loss-lb:0.1065, loss-ulb:0.0271, weight:1.20, lr:0.0008
[11:07:59.901] iteration:5198  t-loss:0.1307, loss-lb:0.1014, loss-ulb:0.0245, weight:1.20, lr:0.0008
[11:08:00.095] iteration:5199  t-loss:0.1281, loss-lb:0.0905, loss-ulb:0.0313, weight:1.20, lr:0.0008
[11:08:00.288] iteration:5200  t-loss:0.1488, loss-lb:0.1187, loss-ulb:0.0251, weight:1.20, lr:0.0008
[11:08:00.482] iteration:5201  t-loss:0.1306, loss-lb:0.1043, loss-ulb:0.0220, weight:1.20, lr:0.0008
[11:08:00.675] iteration:5202  t-loss:0.1629, loss-lb:0.0997, loss-ulb:0.0527, weight:1.20, lr:0.0008
[11:08:00.868] iteration:5203  t-loss:0.1313, loss-lb:0.0967, loss-ulb:0.0288, weight:1.20, lr:0.0008
[11:08:01.060] iteration:5204  t-loss:0.1360, loss-lb:0.1015, loss-ulb:0.0287, weight:1.20, lr:0.0008
[11:08:01.253] iteration:5205  t-loss:0.1284, loss-lb:0.0966, loss-ulb:0.0265, weight:1.20, lr:0.0008
[11:08:01.445] iteration:5206  t-loss:0.2719, loss-lb:0.0988, loss-ulb:0.1444, weight:1.20, lr:0.0008
[11:08:01.639] iteration:5207  t-loss:0.1352, loss-lb:0.0998, loss-ulb:0.0296, weight:1.20, lr:0.0008
[11:08:01.832] iteration:5208  t-loss:0.1290, loss-lb:0.0963, loss-ulb:0.0272, weight:1.20, lr:0.0008
[11:08:02.024] iteration:5209  t-loss:0.1928, loss-lb:0.0942, loss-ulb:0.0823, weight:1.20, lr:0.0008
[11:08:02.215] iteration:5210  t-loss:0.1781, loss-lb:0.0986, loss-ulb:0.0663, weight:1.20, lr:0.0008
[11:08:02.407] iteration:5211  t-loss:0.1631, loss-lb:0.0998, loss-ulb:0.0528, weight:1.20, lr:0.0008
[11:08:02.607] iteration:5212  t-loss:0.1294, loss-lb:0.0978, loss-ulb:0.0264, weight:1.20, lr:0.0008
[11:08:02.800] iteration:5213  t-loss:0.1507, loss-lb:0.1141, loss-ulb:0.0306, weight:1.20, lr:0.0008
[11:08:02.991] iteration:5214  t-loss:0.1222, loss-lb:0.0905, loss-ulb:0.0265, weight:1.20, lr:0.0008
[11:08:03.195] iteration:5215  t-loss:0.1293, loss-lb:0.1010, loss-ulb:0.0236, weight:1.20, lr:0.0008
[11:08:03.403] iteration:5216  t-loss:0.1390, loss-lb:0.1026, loss-ulb:0.0304, weight:1.20, lr:0.0008
[11:08:03.596] iteration:5217  t-loss:0.1262, loss-lb:0.0994, loss-ulb:0.0223, weight:1.20, lr:0.0008
[11:08:03.787] iteration:5218  t-loss:0.1471, loss-lb:0.0971, loss-ulb:0.0417, weight:1.20, lr:0.0008
[11:08:03.978] iteration:5219  t-loss:0.1404, loss-lb:0.0955, loss-ulb:0.0374, weight:1.20, lr:0.0008
[11:08:04.178] iteration:5220  t-loss:0.1448, loss-lb:0.1084, loss-ulb:0.0304, weight:1.20, lr:0.0008
[11:08:04.369] iteration:5221  t-loss:0.1585, loss-lb:0.1181, loss-ulb:0.0337, weight:1.20, lr:0.0008
[11:08:04.560] iteration:5222  t-loss:0.1476, loss-lb:0.0935, loss-ulb:0.0451, weight:1.20, lr:0.0008
[11:08:04.752] iteration:5223  t-loss:0.1613, loss-lb:0.0999, loss-ulb:0.0513, weight:1.20, lr:0.0008
[11:08:04.952] iteration:5224  t-loss:0.1538, loss-lb:0.1005, loss-ulb:0.0444, weight:1.20, lr:0.0008
[11:08:05.144] iteration:5225  t-loss:0.1292, loss-lb:0.0964, loss-ulb:0.0273, weight:1.20, lr:0.0008
[11:08:05.335] iteration:5226  t-loss:0.1226, loss-lb:0.0960, loss-ulb:0.0222, weight:1.20, lr:0.0008
[11:08:05.529] iteration:5227  t-loss:0.1223, loss-lb:0.0844, loss-ulb:0.0316, weight:1.20, lr:0.0008
[11:08:05.729] iteration:5228  t-loss:0.1461, loss-lb:0.0946, loss-ulb:0.0430, weight:1.20, lr:0.0008
[11:08:05.920] iteration:5229  t-loss:0.1316, loss-lb:0.0951, loss-ulb:0.0304, weight:1.20, lr:0.0008
[11:08:06.111] iteration:5230  t-loss:0.2018, loss-lb:0.1049, loss-ulb:0.0809, weight:1.20, lr:0.0008
[11:08:06.303] iteration:5231  t-loss:0.1502, loss-lb:0.1149, loss-ulb:0.0295, weight:1.20, lr:0.0008
[11:08:06.502] iteration:5232  t-loss:0.1450, loss-lb:0.0978, loss-ulb:0.0394, weight:1.20, lr:0.0008
[11:08:06.694] iteration:5233  t-loss:0.1353, loss-lb:0.1000, loss-ulb:0.0295, weight:1.20, lr:0.0008
[11:08:06.885] iteration:5234  t-loss:0.1254, loss-lb:0.0938, loss-ulb:0.0263, weight:1.20, lr:0.0008
[11:08:07.079] iteration:5235  t-loss:0.2010, loss-lb:0.0962, loss-ulb:0.0874, weight:1.20, lr:0.0008
[11:08:07.280] iteration:5236  t-loss:0.1333, loss-lb:0.0971, loss-ulb:0.0302, weight:1.20, lr:0.0008
[11:08:07.472] iteration:5237  t-loss:0.1452, loss-lb:0.1013, loss-ulb:0.0367, weight:1.20, lr:0.0008
[11:08:07.662] iteration:5238  t-loss:0.1735, loss-lb:0.1055, loss-ulb:0.0567, weight:1.20, lr:0.0008
[11:08:07.854] iteration:5239  t-loss:0.1580, loss-lb:0.1015, loss-ulb:0.0472, weight:1.20, lr:0.0008
[11:08:08.055] iteration:5240  t-loss:0.1311, loss-lb:0.1057, loss-ulb:0.0212, weight:1.20, lr:0.0008
[11:08:08.246] iteration:5241  t-loss:0.1172, loss-lb:0.0905, loss-ulb:0.0223, weight:1.20, lr:0.0008
[11:08:08.437] iteration:5242  t-loss:0.1346, loss-lb:0.1011, loss-ulb:0.0280, weight:1.20, lr:0.0008
[11:08:08.629] iteration:5243  t-loss:0.1311, loss-lb:0.1030, loss-ulb:0.0235, weight:1.20, lr:0.0008
[11:08:08.829] iteration:5244  t-loss:0.1361, loss-lb:0.1005, loss-ulb:0.0297, weight:1.20, lr:0.0008
[11:08:09.022] iteration:5245  t-loss:0.1251, loss-lb:0.0947, loss-ulb:0.0254, weight:1.20, lr:0.0008
[11:08:09.213] iteration:5246  t-loss:0.1388, loss-lb:0.1055, loss-ulb:0.0278, weight:1.20, lr:0.0008
[11:08:09.406] iteration:5247  t-loss:0.1293, loss-lb:0.0979, loss-ulb:0.0262, weight:1.20, lr:0.0008
[11:08:09.605] iteration:5248  t-loss:0.1547, loss-lb:0.1049, loss-ulb:0.0415, weight:1.20, lr:0.0008
[11:08:09.796] iteration:5249  t-loss:0.1378, loss-lb:0.1034, loss-ulb:0.0288, weight:1.20, lr:0.0008
[11:08:09.987] iteration:5250  t-loss:0.1468, loss-lb:0.1138, loss-ulb:0.0275, weight:1.20, lr:0.0008
[11:08:10.179] iteration:5251  t-loss:0.1334, loss-lb:0.0941, loss-ulb:0.0308, weight:1.28, lr:0.0008
[11:08:10.381] iteration:5252  t-loss:0.1476, loss-lb:0.1136, loss-ulb:0.0267, weight:1.28, lr:0.0008
[11:08:10.573] iteration:5253  t-loss:0.1533, loss-lb:0.0997, loss-ulb:0.0421, weight:1.28, lr:0.0008
[11:08:10.768] iteration:5254  t-loss:0.1390, loss-lb:0.0923, loss-ulb:0.0366, weight:1.28, lr:0.0008
[11:08:10.962] iteration:5255  t-loss:0.1292, loss-lb:0.0935, loss-ulb:0.0279, weight:1.28, lr:0.0008
[11:08:11.164] iteration:5256  t-loss:0.1627, loss-lb:0.1073, loss-ulb:0.0434, weight:1.28, lr:0.0008
[11:08:11.355] iteration:5257  t-loss:0.1289, loss-lb:0.0951, loss-ulb:0.0266, weight:1.28, lr:0.0008
[11:08:11.547] iteration:5258  t-loss:0.1321, loss-lb:0.0936, loss-ulb:0.0301, weight:1.28, lr:0.0008
[11:08:11.738] iteration:5259  t-loss:0.1665, loss-lb:0.1038, loss-ulb:0.0492, weight:1.28, lr:0.0008
[11:08:11.938] iteration:5260  t-loss:0.1527, loss-lb:0.1105, loss-ulb:0.0331, weight:1.28, lr:0.0008
[11:08:12.130] iteration:5261  t-loss:0.1385, loss-lb:0.0943, loss-ulb:0.0347, weight:1.28, lr:0.0008
[11:08:12.321] iteration:5262  t-loss:0.1521, loss-lb:0.1091, loss-ulb:0.0337, weight:1.28, lr:0.0008
[11:08:12.513] iteration:5263  t-loss:0.1398, loss-lb:0.0955, loss-ulb:0.0348, weight:1.28, lr:0.0008
[11:08:12.712] iteration:5264  t-loss:0.1347, loss-lb:0.0898, loss-ulb:0.0352, weight:1.28, lr:0.0008
[11:08:12.904] iteration:5265  t-loss:0.1741, loss-lb:0.0999, loss-ulb:0.0582, weight:1.28, lr:0.0008
[11:08:13.094] iteration:5266  t-loss:0.1451, loss-lb:0.1058, loss-ulb:0.0308, weight:1.28, lr:0.0008
[11:08:13.286] iteration:5267  t-loss:0.1679, loss-lb:0.0974, loss-ulb:0.0554, weight:1.28, lr:0.0008
[11:08:13.485] iteration:5268  t-loss:0.1408, loss-lb:0.1000, loss-ulb:0.0320, weight:1.28, lr:0.0008
[11:08:13.676] iteration:5269  t-loss:0.1671, loss-lb:0.1228, loss-ulb:0.0347, weight:1.28, lr:0.0008
[11:08:13.867] iteration:5270  t-loss:0.1434, loss-lb:0.1004, loss-ulb:0.0337, weight:1.28, lr:0.0008
[11:08:14.059] iteration:5271  t-loss:0.1727, loss-lb:0.1030, loss-ulb:0.0547, weight:1.28, lr:0.0008
[11:08:14.259] iteration:5272  t-loss:0.1384, loss-lb:0.1004, loss-ulb:0.0297, weight:1.28, lr:0.0008
[11:08:14.450] iteration:5273  t-loss:0.1395, loss-lb:0.0971, loss-ulb:0.0332, weight:1.28, lr:0.0008
[11:08:14.643] iteration:5274  t-loss:0.1295, loss-lb:0.0931, loss-ulb:0.0286, weight:1.28, lr:0.0008
[11:08:14.835] iteration:5275  t-loss:0.1487, loss-lb:0.1011, loss-ulb:0.0374, weight:1.28, lr:0.0008
[11:08:15.033] iteration:5276  t-loss:0.1639, loss-lb:0.1281, loss-ulb:0.0281, weight:1.28, lr:0.0008
[11:08:15.225] iteration:5277  t-loss:0.1372, loss-lb:0.1000, loss-ulb:0.0292, weight:1.28, lr:0.0008
[11:08:15.416] iteration:5278  t-loss:0.1414, loss-lb:0.0985, loss-ulb:0.0336, weight:1.28, lr:0.0008
[11:08:15.608] iteration:5279  t-loss:0.1501, loss-lb:0.1041, loss-ulb:0.0361, weight:1.28, lr:0.0008
[11:08:15.807] iteration:5280  t-loss:0.1296, loss-lb:0.0925, loss-ulb:0.0291, weight:1.28, lr:0.0008
[11:08:15.998] iteration:5281  t-loss:0.2389, loss-lb:0.1427, loss-ulb:0.0755, weight:1.28, lr:0.0008
[11:08:16.191] iteration:5282  t-loss:0.1619, loss-lb:0.0998, loss-ulb:0.0487, weight:1.28, lr:0.0008
[11:08:16.383] iteration:5283  t-loss:0.2158, loss-lb:0.1032, loss-ulb:0.0883, weight:1.28, lr:0.0008
[11:08:16.582] iteration:5284  t-loss:0.1746, loss-lb:0.1118, loss-ulb:0.0492, weight:1.28, lr:0.0008
[11:08:16.773] iteration:5285  t-loss:0.1494, loss-lb:0.1023, loss-ulb:0.0369, weight:1.28, lr:0.0008
[11:08:16.964] iteration:5286  t-loss:0.1523, loss-lb:0.1070, loss-ulb:0.0355, weight:1.28, lr:0.0008
[11:08:17.154] iteration:5287  t-loss:0.1814, loss-lb:0.1188, loss-ulb:0.0491, weight:1.28, lr:0.0008
[11:08:17.344] iteration:5288  t-loss:0.1747, loss-lb:0.1036, loss-ulb:0.0558, weight:1.28, lr:0.0008
[11:08:17.535] iteration:5289  t-loss:0.1603, loss-lb:0.1082, loss-ulb:0.0409, weight:1.28, lr:0.0008
[11:08:17.726] iteration:5290  t-loss:0.2060, loss-lb:0.1101, loss-ulb:0.0752, weight:1.28, lr:0.0008
[11:08:17.915] iteration:5291  t-loss:0.1588, loss-lb:0.1051, loss-ulb:0.0421, weight:1.28, lr:0.0008
[11:08:18.106] iteration:5292  t-loss:0.1539, loss-lb:0.1056, loss-ulb:0.0379, weight:1.28, lr:0.0008
[11:08:18.715] iteration:5293  t-loss:0.1388, loss-lb:0.1022, loss-ulb:0.0287, weight:1.28, lr:0.0008
[11:08:18.909] iteration:5294  t-loss:0.1380, loss-lb:0.1077, loss-ulb:0.0238, weight:1.28, lr:0.0008
[11:08:19.101] iteration:5295  t-loss:0.1868, loss-lb:0.1034, loss-ulb:0.0654, weight:1.28, lr:0.0008
[11:08:19.291] iteration:5296  t-loss:0.1899, loss-lb:0.1481, loss-ulb:0.0328, weight:1.28, lr:0.0008
[11:08:19.483] iteration:5297  t-loss:0.1454, loss-lb:0.1076, loss-ulb:0.0296, weight:1.28, lr:0.0008
[11:08:19.675] iteration:5298  t-loss:0.2132, loss-lb:0.0963, loss-ulb:0.0917, weight:1.28, lr:0.0008
[11:08:19.866] iteration:5299  t-loss:0.1674, loss-lb:0.1091, loss-ulb:0.0457, weight:1.28, lr:0.0008
[11:08:20.057] iteration:5300  t-loss:0.1843, loss-lb:0.1253, loss-ulb:0.0463, weight:1.28, lr:0.0008
[11:08:20.249] iteration:5301  t-loss:0.1875, loss-lb:0.0991, loss-ulb:0.0693, weight:1.28, lr:0.0008
[11:08:20.440] iteration:5302  t-loss:0.1576, loss-lb:0.1108, loss-ulb:0.0366, weight:1.28, lr:0.0008
[11:08:20.631] iteration:5303  t-loss:0.1623, loss-lb:0.1027, loss-ulb:0.0467, weight:1.28, lr:0.0008
[11:08:20.823] iteration:5304  t-loss:0.1671, loss-lb:0.1155, loss-ulb:0.0405, weight:1.28, lr:0.0008
[11:08:21.015] iteration:5305  t-loss:0.2093, loss-lb:0.1201, loss-ulb:0.0699, weight:1.28, lr:0.0008
[11:08:21.207] iteration:5306  t-loss:0.1519, loss-lb:0.1186, loss-ulb:0.0261, weight:1.28, lr:0.0008
[11:08:21.401] iteration:5307  t-loss:0.1516, loss-lb:0.1057, loss-ulb:0.0360, weight:1.28, lr:0.0008
[11:08:21.597] iteration:5308  t-loss:0.1505, loss-lb:0.1098, loss-ulb:0.0319, weight:1.28, lr:0.0008
[11:08:21.793] iteration:5309  t-loss:0.1640, loss-lb:0.1246, loss-ulb:0.0310, weight:1.28, lr:0.0008
[11:08:21.986] iteration:5310  t-loss:0.2148, loss-lb:0.1052, loss-ulb:0.0859, weight:1.28, lr:0.0008
[11:08:22.180] iteration:5311  t-loss:0.1612, loss-lb:0.1127, loss-ulb:0.0380, weight:1.28, lr:0.0008
[11:08:22.371] iteration:5312  t-loss:0.1400, loss-lb:0.1000, loss-ulb:0.0314, weight:1.28, lr:0.0008
[11:08:22.562] iteration:5313  t-loss:0.1303, loss-lb:0.0968, loss-ulb:0.0263, weight:1.28, lr:0.0008
[11:08:22.753] iteration:5314  t-loss:0.1565, loss-lb:0.1206, loss-ulb:0.0282, weight:1.28, lr:0.0008
[11:08:22.944] iteration:5315  t-loss:0.1665, loss-lb:0.1060, loss-ulb:0.0474, weight:1.28, lr:0.0008
[11:08:23.137] iteration:5316  t-loss:0.1321, loss-lb:0.0980, loss-ulb:0.0268, weight:1.28, lr:0.0008
[11:08:23.328] iteration:5317  t-loss:0.2002, loss-lb:0.1066, loss-ulb:0.0734, weight:1.28, lr:0.0008
[11:08:23.521] iteration:5318  t-loss:0.1623, loss-lb:0.1128, loss-ulb:0.0388, weight:1.28, lr:0.0008
[11:08:23.713] iteration:5319  t-loss:0.1648, loss-lb:0.0990, loss-ulb:0.0516, weight:1.28, lr:0.0008
[11:08:23.905] iteration:5320  t-loss:0.1505, loss-lb:0.1009, loss-ulb:0.0389, weight:1.28, lr:0.0008
[11:08:24.097] iteration:5321  t-loss:0.1297, loss-lb:0.0935, loss-ulb:0.0284, weight:1.28, lr:0.0008
[11:08:24.289] iteration:5322  t-loss:0.1379, loss-lb:0.1065, loss-ulb:0.0246, weight:1.28, lr:0.0008
[11:08:24.482] iteration:5323  t-loss:0.1839, loss-lb:0.0980, loss-ulb:0.0673, weight:1.28, lr:0.0008
[11:08:24.676] iteration:5324  t-loss:0.1726, loss-lb:0.1080, loss-ulb:0.0506, weight:1.28, lr:0.0008
[11:08:24.868] iteration:5325  t-loss:0.1525, loss-lb:0.0982, loss-ulb:0.0426, weight:1.28, lr:0.0008
[11:08:25.059] iteration:5326  t-loss:0.1963, loss-lb:0.1097, loss-ulb:0.0679, weight:1.28, lr:0.0008
[11:08:25.253] iteration:5327  t-loss:0.1523, loss-lb:0.1063, loss-ulb:0.0361, weight:1.28, lr:0.0008
[11:08:25.445] iteration:5328  t-loss:0.1555, loss-lb:0.1123, loss-ulb:0.0338, weight:1.28, lr:0.0008
[11:08:25.638] iteration:5329  t-loss:0.1503, loss-lb:0.1111, loss-ulb:0.0307, weight:1.28, lr:0.0008
[11:08:25.831] iteration:5330  t-loss:0.1567, loss-lb:0.1127, loss-ulb:0.0345, weight:1.28, lr:0.0008
[11:08:26.023] iteration:5331  t-loss:0.1835, loss-lb:0.1240, loss-ulb:0.0466, weight:1.28, lr:0.0008
[11:08:26.214] iteration:5332  t-loss:0.1472, loss-lb:0.1125, loss-ulb:0.0271, weight:1.28, lr:0.0008
[11:08:26.407] iteration:5333  t-loss:0.1667, loss-lb:0.1313, loss-ulb:0.0277, weight:1.28, lr:0.0008
[11:08:26.598] iteration:5334  t-loss:0.2509, loss-lb:0.0997, loss-ulb:0.1186, weight:1.28, lr:0.0008
[11:08:26.790] iteration:5335  t-loss:0.1421, loss-lb:0.0992, loss-ulb:0.0336, weight:1.28, lr:0.0008
[11:08:26.984] iteration:5336  t-loss:0.1320, loss-lb:0.1038, loss-ulb:0.0221, weight:1.28, lr:0.0008
[11:08:27.175] iteration:5337  t-loss:0.1436, loss-lb:0.0906, loss-ulb:0.0415, weight:1.28, lr:0.0008
[11:08:27.367] iteration:5338  t-loss:0.1454, loss-lb:0.1073, loss-ulb:0.0299, weight:1.28, lr:0.0008
[11:08:27.558] iteration:5339  t-loss:0.1378, loss-lb:0.0946, loss-ulb:0.0339, weight:1.28, lr:0.0008
[11:08:27.750] iteration:5340  t-loss:0.1318, loss-lb:0.0931, loss-ulb:0.0304, weight:1.28, lr:0.0008
[11:08:27.942] iteration:5341  t-loss:0.1483, loss-lb:0.1098, loss-ulb:0.0302, weight:1.28, lr:0.0008
[11:08:28.135] iteration:5342  t-loss:0.1404, loss-lb:0.0906, loss-ulb:0.0391, weight:1.28, lr:0.0008
[11:08:28.326] iteration:5343  t-loss:0.1409, loss-lb:0.0845, loss-ulb:0.0442, weight:1.28, lr:0.0008
[11:08:28.519] iteration:5344  t-loss:0.1452, loss-lb:0.0975, loss-ulb:0.0375, weight:1.28, lr:0.0008
[11:08:28.711] iteration:5345  t-loss:0.1510, loss-lb:0.1088, loss-ulb:0.0331, weight:1.28, lr:0.0008
[11:08:28.904] iteration:5346  t-loss:0.1428, loss-lb:0.1109, loss-ulb:0.0250, weight:1.28, lr:0.0008
[11:08:29.095] iteration:5347  t-loss:0.1288, loss-lb:0.0925, loss-ulb:0.0284, weight:1.28, lr:0.0008
[11:08:29.287] iteration:5348  t-loss:0.1682, loss-lb:0.1191, loss-ulb:0.0385, weight:1.28, lr:0.0008
[11:08:29.480] iteration:5349  t-loss:0.1340, loss-lb:0.0995, loss-ulb:0.0271, weight:1.28, lr:0.0008
[11:08:29.670] iteration:5350  t-loss:0.1588, loss-lb:0.1035, loss-ulb:0.0434, weight:1.28, lr:0.0008
[11:08:29.862] iteration:5351  t-loss:0.1374, loss-lb:0.0954, loss-ulb:0.0330, weight:1.28, lr:0.0008
[11:08:30.055] iteration:5352  t-loss:0.1364, loss-lb:0.1057, loss-ulb:0.0241, weight:1.28, lr:0.0008
[11:08:30.246] iteration:5353  t-loss:0.1305, loss-lb:0.1015, loss-ulb:0.0227, weight:1.28, lr:0.0008
[11:08:30.437] iteration:5354  t-loss:0.1248, loss-lb:0.0967, loss-ulb:0.0220, weight:1.28, lr:0.0008
[11:08:30.631] iteration:5355  t-loss:0.1576, loss-lb:0.0979, loss-ulb:0.0468, weight:1.28, lr:0.0008
[11:08:30.823] iteration:5356  t-loss:0.2023, loss-lb:0.0921, loss-ulb:0.0864, weight:1.28, lr:0.0008
[11:08:31.014] iteration:5357  t-loss:0.1374, loss-lb:0.0908, loss-ulb:0.0366, weight:1.28, lr:0.0008
[11:08:31.205] iteration:5358  t-loss:0.2166, loss-lb:0.1138, loss-ulb:0.0806, weight:1.28, lr:0.0008
[11:08:31.396] iteration:5359  t-loss:0.1272, loss-lb:0.0983, loss-ulb:0.0226, weight:1.28, lr:0.0008
[11:08:31.588] iteration:5360  t-loss:0.1362, loss-lb:0.1019, loss-ulb:0.0268, weight:1.28, lr:0.0008
[11:08:31.780] iteration:5361  t-loss:0.1453, loss-lb:0.0984, loss-ulb:0.0368, weight:1.28, lr:0.0008
[11:08:31.973] iteration:5362  t-loss:0.1309, loss-lb:0.0964, loss-ulb:0.0271, weight:1.28, lr:0.0008
[11:08:32.166] iteration:5363  t-loss:0.1543, loss-lb:0.1123, loss-ulb:0.0329, weight:1.28, lr:0.0008
[11:08:32.363] iteration:5364  t-loss:0.1483, loss-lb:0.1153, loss-ulb:0.0259, weight:1.28, lr:0.0008
[11:08:32.558] iteration:5365  t-loss:0.1199, loss-lb:0.0914, loss-ulb:0.0223, weight:1.28, lr:0.0008
[11:08:32.751] iteration:5366  t-loss:0.1633, loss-lb:0.1086, loss-ulb:0.0429, weight:1.28, lr:0.0008
[11:08:32.944] iteration:5367  t-loss:0.1946, loss-lb:0.0972, loss-ulb:0.0764, weight:1.28, lr:0.0008
[11:08:33.136] iteration:5368  t-loss:0.1437, loss-lb:0.1094, loss-ulb:0.0269, weight:1.28, lr:0.0008
[11:08:33.329] iteration:5369  t-loss:0.1407, loss-lb:0.0968, loss-ulb:0.0344, weight:1.28, lr:0.0008
[11:08:33.520] iteration:5370  t-loss:0.1303, loss-lb:0.1023, loss-ulb:0.0219, weight:1.28, lr:0.0008
[11:08:33.712] iteration:5371  t-loss:0.1386, loss-lb:0.1030, loss-ulb:0.0279, weight:1.28, lr:0.0008
[11:08:33.903] iteration:5372  t-loss:0.1335, loss-lb:0.0961, loss-ulb:0.0293, weight:1.28, lr:0.0008
[11:08:34.094] iteration:5373  t-loss:0.1449, loss-lb:0.0923, loss-ulb:0.0412, weight:1.28, lr:0.0008
[11:08:34.286] iteration:5374  t-loss:0.1768, loss-lb:0.1046, loss-ulb:0.0566, weight:1.28, lr:0.0008
[11:08:34.477] iteration:5375  t-loss:0.1168, loss-lb:0.0865, loss-ulb:0.0237, weight:1.28, lr:0.0008
[11:08:34.668] iteration:5376  t-loss:0.1883, loss-lb:0.1064, loss-ulb:0.0642, weight:1.28, lr:0.0008
[11:08:34.859] iteration:5377  t-loss:0.1515, loss-lb:0.0952, loss-ulb:0.0441, weight:1.28, lr:0.0008
[11:08:35.051] iteration:5378  t-loss:0.1207, loss-lb:0.0907, loss-ulb:0.0235, weight:1.28, lr:0.0008
[11:08:35.242] iteration:5379  t-loss:0.1301, loss-lb:0.0920, loss-ulb:0.0298, weight:1.28, lr:0.0008
[11:08:35.434] iteration:5380  t-loss:0.1873, loss-lb:0.0961, loss-ulb:0.0715, weight:1.28, lr:0.0008
[11:08:35.627] iteration:5381  t-loss:0.1273, loss-lb:0.0975, loss-ulb:0.0234, weight:1.28, lr:0.0008
[11:08:35.819] iteration:5382  t-loss:0.1295, loss-lb:0.0999, loss-ulb:0.0233, weight:1.28, lr:0.0008
[11:08:36.022] iteration:5383  t-loss:0.1553, loss-lb:0.1243, loss-ulb:0.0243, weight:1.28, lr:0.0008
[11:08:36.218] iteration:5384  t-loss:0.1231, loss-lb:0.0895, loss-ulb:0.0263, weight:1.28, lr:0.0008
[11:08:36.411] iteration:5385  t-loss:0.1340, loss-lb:0.1017, loss-ulb:0.0254, weight:1.28, lr:0.0008
[11:08:36.600] iteration:5386  t-loss:0.1283, loss-lb:0.0962, loss-ulb:0.0252, weight:1.28, lr:0.0008
[11:08:36.791] iteration:5387  t-loss:0.1360, loss-lb:0.1022, loss-ulb:0.0265, weight:1.28, lr:0.0008
[11:08:36.982] iteration:5388  t-loss:0.2000, loss-lb:0.0995, loss-ulb:0.0788, weight:1.28, lr:0.0008
[11:08:37.173] iteration:5389  t-loss:0.1435, loss-lb:0.0848, loss-ulb:0.0461, weight:1.28, lr:0.0008
[11:08:37.365] iteration:5390  t-loss:0.1300, loss-lb:0.0943, loss-ulb:0.0281, weight:1.28, lr:0.0008
[11:08:49.893]  <<Test>> - Ep:54  - mean_dice/mean_h95 - S:89.47/1.43, Best-S:89.92, T:90.22/1.33, Best-T:90.22
[11:08:49.893]           - AvgLoss(lb/ulb/all):0.1038/0.0370/0.1448
[11:08:50.410] iteration:5391  t-loss:0.1495, loss-lb:0.1123, loss-ulb:0.0292, weight:1.28, lr:0.0008
[11:08:50.604] iteration:5392  t-loss:0.1211, loss-lb:0.0936, loss-ulb:0.0215, weight:1.28, lr:0.0008
[11:08:50.797] iteration:5393  t-loss:0.1529, loss-lb:0.0916, loss-ulb:0.0481, weight:1.28, lr:0.0008
[11:08:50.989] iteration:5394  t-loss:0.1826, loss-lb:0.1209, loss-ulb:0.0483, weight:1.28, lr:0.0008
[11:08:51.180] iteration:5395  t-loss:0.1341, loss-lb:0.1035, loss-ulb:0.0240, weight:1.28, lr:0.0008
[11:08:51.373] iteration:5396  t-loss:0.1617, loss-lb:0.1048, loss-ulb:0.0446, weight:1.28, lr:0.0008
[11:08:51.564] iteration:5397  t-loss:0.1329, loss-lb:0.0989, loss-ulb:0.0267, weight:1.28, lr:0.0008
[11:08:51.757] iteration:5398  t-loss:0.2135, loss-lb:0.1085, loss-ulb:0.0823, weight:1.28, lr:0.0008
[11:08:51.949] iteration:5399  t-loss:0.1323, loss-lb:0.0984, loss-ulb:0.0265, weight:1.28, lr:0.0008
[11:08:52.140] iteration:5400  t-loss:0.1355, loss-lb:0.1028, loss-ulb:0.0256, weight:1.28, lr:0.0008
[11:08:52.331] iteration:5401  t-loss:0.1434, loss-lb:0.1022, loss-ulb:0.0304, weight:1.35, lr:0.0008
[11:08:52.524] iteration:5402  t-loss:0.1894, loss-lb:0.1161, loss-ulb:0.0542, weight:1.35, lr:0.0008
[11:08:52.716] iteration:5403  t-loss:0.1622, loss-lb:0.1225, loss-ulb:0.0294, weight:1.35, lr:0.0008
[11:08:52.909] iteration:5404  t-loss:0.1618, loss-lb:0.1171, loss-ulb:0.0331, weight:1.35, lr:0.0008
[11:08:53.101] iteration:5405  t-loss:0.1372, loss-lb:0.0955, loss-ulb:0.0308, weight:1.35, lr:0.0008
[11:08:53.294] iteration:5406  t-loss:0.1620, loss-lb:0.1053, loss-ulb:0.0420, weight:1.35, lr:0.0008
[11:08:53.487] iteration:5407  t-loss:0.1379, loss-lb:0.1056, loss-ulb:0.0239, weight:1.35, lr:0.0008
[11:08:53.680] iteration:5408  t-loss:0.2020, loss-lb:0.1026, loss-ulb:0.0736, weight:1.35, lr:0.0008
[11:08:53.872] iteration:5409  t-loss:0.1720, loss-lb:0.1186, loss-ulb:0.0396, weight:1.35, lr:0.0008
[11:08:54.064] iteration:5410  t-loss:0.1708, loss-lb:0.0976, loss-ulb:0.0541, weight:1.35, lr:0.0008
[11:08:54.256] iteration:5411  t-loss:0.1365, loss-lb:0.0974, loss-ulb:0.0289, weight:1.35, lr:0.0008
[11:08:54.449] iteration:5412  t-loss:0.1722, loss-lb:0.1102, loss-ulb:0.0459, weight:1.35, lr:0.0008
[11:08:54.642] iteration:5413  t-loss:0.1245, loss-lb:0.0886, loss-ulb:0.0266, weight:1.35, lr:0.0008
[11:08:54.834] iteration:5414  t-loss:0.1397, loss-lb:0.0978, loss-ulb:0.0310, weight:1.35, lr:0.0008
[11:08:55.028] iteration:5415  t-loss:0.3148, loss-lb:0.1074, loss-ulb:0.1535, weight:1.35, lr:0.0008
[11:08:55.222] iteration:5416  t-loss:0.1707, loss-lb:0.1319, loss-ulb:0.0288, weight:1.35, lr:0.0008
[11:08:55.414] iteration:5417  t-loss:0.1770, loss-lb:0.1186, loss-ulb:0.0432, weight:1.35, lr:0.0008
[11:08:55.608] iteration:5418  t-loss:0.1730, loss-lb:0.1105, loss-ulb:0.0463, weight:1.35, lr:0.0008
[11:08:55.800] iteration:5419  t-loss:0.1856, loss-lb:0.1313, loss-ulb:0.0402, weight:1.35, lr:0.0008
[11:08:55.994] iteration:5420  t-loss:0.1632, loss-lb:0.1122, loss-ulb:0.0377, weight:1.35, lr:0.0008
[11:08:56.186] iteration:5421  t-loss:0.1841, loss-lb:0.1055, loss-ulb:0.0582, weight:1.35, lr:0.0008
[11:08:56.379] iteration:5422  t-loss:0.2169, loss-lb:0.1352, loss-ulb:0.0605, weight:1.35, lr:0.0008
[11:08:56.572] iteration:5423  t-loss:0.1720, loss-lb:0.1037, loss-ulb:0.0505, weight:1.35, lr:0.0008
[11:08:56.764] iteration:5424  t-loss:0.1752, loss-lb:0.1107, loss-ulb:0.0477, weight:1.35, lr:0.0008
[11:08:56.957] iteration:5425  t-loss:0.2284, loss-lb:0.1230, loss-ulb:0.0781, weight:1.35, lr:0.0008
[11:08:57.150] iteration:5426  t-loss:0.1835, loss-lb:0.1152, loss-ulb:0.0505, weight:1.35, lr:0.0008
[11:08:57.342] iteration:5427  t-loss:0.2078, loss-lb:0.1119, loss-ulb:0.0709, weight:1.35, lr:0.0008
[11:08:57.533] iteration:5428  t-loss:0.1752, loss-lb:0.1349, loss-ulb:0.0298, weight:1.35, lr:0.0008
[11:08:57.726] iteration:5429  t-loss:0.1652, loss-lb:0.1139, loss-ulb:0.0380, weight:1.35, lr:0.0008
[11:08:57.917] iteration:5430  t-loss:0.1713, loss-lb:0.1080, loss-ulb:0.0468, weight:1.35, lr:0.0008
[11:08:58.109] iteration:5431  t-loss:0.1721, loss-lb:0.1105, loss-ulb:0.0456, weight:1.35, lr:0.0008
[11:08:58.302] iteration:5432  t-loss:0.1550, loss-lb:0.1095, loss-ulb:0.0337, weight:1.35, lr:0.0008
[11:08:58.495] iteration:5433  t-loss:0.1610, loss-lb:0.1023, loss-ulb:0.0434, weight:1.35, lr:0.0008
[11:08:58.686] iteration:5434  t-loss:0.1576, loss-lb:0.1207, loss-ulb:0.0272, weight:1.35, lr:0.0008
[11:08:58.879] iteration:5435  t-loss:0.1414, loss-lb:0.0975, loss-ulb:0.0325, weight:1.35, lr:0.0008
[11:08:59.071] iteration:5436  t-loss:0.1710, loss-lb:0.1109, loss-ulb:0.0445, weight:1.35, lr:0.0008
[11:08:59.263] iteration:5437  t-loss:0.1469, loss-lb:0.1021, loss-ulb:0.0331, weight:1.35, lr:0.0008
[11:08:59.455] iteration:5438  t-loss:0.1521, loss-lb:0.0929, loss-ulb:0.0438, weight:1.35, lr:0.0008
[11:08:59.646] iteration:5439  t-loss:0.1701, loss-lb:0.1090, loss-ulb:0.0452, weight:1.35, lr:0.0008
[11:08:59.838] iteration:5440  t-loss:0.1437, loss-lb:0.1021, loss-ulb:0.0308, weight:1.35, lr:0.0008
[11:09:00.032] iteration:5441  t-loss:0.2216, loss-lb:0.1056, loss-ulb:0.0858, weight:1.35, lr:0.0008
[11:09:00.223] iteration:5442  t-loss:0.1419, loss-lb:0.0990, loss-ulb:0.0317, weight:1.35, lr:0.0008
[11:09:00.414] iteration:5443  t-loss:0.1660, loss-lb:0.0954, loss-ulb:0.0522, weight:1.35, lr:0.0008
[11:09:00.607] iteration:5444  t-loss:0.1442, loss-lb:0.1029, loss-ulb:0.0305, weight:1.35, lr:0.0008
[11:09:00.800] iteration:5445  t-loss:0.1410, loss-lb:0.1021, loss-ulb:0.0288, weight:1.35, lr:0.0008
[11:09:00.991] iteration:5446  t-loss:0.1412, loss-lb:0.1069, loss-ulb:0.0254, weight:1.35, lr:0.0008
[11:09:01.183] iteration:5447  t-loss:0.1506, loss-lb:0.1116, loss-ulb:0.0289, weight:1.35, lr:0.0008
[11:09:01.376] iteration:5448  t-loss:0.1612, loss-lb:0.0971, loss-ulb:0.0474, weight:1.35, lr:0.0008
[11:09:01.569] iteration:5449  t-loss:0.1618, loss-lb:0.1161, loss-ulb:0.0338, weight:1.35, lr:0.0008
[11:09:01.760] iteration:5450  t-loss:0.1687, loss-lb:0.1047, loss-ulb:0.0473, weight:1.35, lr:0.0008
[11:09:01.953] iteration:5451  t-loss:0.1587, loss-lb:0.1048, loss-ulb:0.0399, weight:1.35, lr:0.0008
[11:09:02.145] iteration:5452  t-loss:0.1453, loss-lb:0.1068, loss-ulb:0.0284, weight:1.35, lr:0.0008
[11:09:02.336] iteration:5453  t-loss:0.1799, loss-lb:0.1085, loss-ulb:0.0529, weight:1.35, lr:0.0008
[11:09:02.529] iteration:5454  t-loss:0.1333, loss-lb:0.0993, loss-ulb:0.0252, weight:1.35, lr:0.0008
[11:09:02.721] iteration:5455  t-loss:0.1534, loss-lb:0.0972, loss-ulb:0.0416, weight:1.35, lr:0.0008
[11:09:02.914] iteration:5456  t-loss:0.1434, loss-lb:0.1085, loss-ulb:0.0258, weight:1.35, lr:0.0008
[11:09:03.106] iteration:5457  t-loss:0.1593, loss-lb:0.1212, loss-ulb:0.0281, weight:1.35, lr:0.0008
[11:09:03.298] iteration:5458  t-loss:0.1405, loss-lb:0.0986, loss-ulb:0.0310, weight:1.35, lr:0.0008
[11:09:03.489] iteration:5459  t-loss:0.1796, loss-lb:0.1418, loss-ulb:0.0280, weight:1.35, lr:0.0008
[11:09:03.681] iteration:5460  t-loss:0.1469, loss-lb:0.1028, loss-ulb:0.0326, weight:1.35, lr:0.0008
[11:09:03.873] iteration:5461  t-loss:0.1408, loss-lb:0.0971, loss-ulb:0.0324, weight:1.35, lr:0.0008
[11:09:04.065] iteration:5462  t-loss:0.1580, loss-lb:0.1269, loss-ulb:0.0230, weight:1.35, lr:0.0008
[11:09:04.257] iteration:5463  t-loss:0.1641, loss-lb:0.1020, loss-ulb:0.0459, weight:1.35, lr:0.0008
[11:09:04.449] iteration:5464  t-loss:0.1464, loss-lb:0.1106, loss-ulb:0.0264, weight:1.35, lr:0.0008
[11:09:04.641] iteration:5465  t-loss:0.1912, loss-lb:0.1016, loss-ulb:0.0663, weight:1.35, lr:0.0008
[11:09:04.834] iteration:5466  t-loss:0.1418, loss-lb:0.1084, loss-ulb:0.0247, weight:1.35, lr:0.0008
[11:09:05.025] iteration:5467  t-loss:0.1683, loss-lb:0.1223, loss-ulb:0.0340, weight:1.35, lr:0.0008
[11:09:05.217] iteration:5468  t-loss:0.1788, loss-lb:0.1160, loss-ulb:0.0465, weight:1.35, lr:0.0008
[11:09:05.409] iteration:5469  t-loss:0.1568, loss-lb:0.1082, loss-ulb:0.0360, weight:1.35, lr:0.0008
[11:09:05.602] iteration:5470  t-loss:0.1402, loss-lb:0.1071, loss-ulb:0.0245, weight:1.35, lr:0.0008
[11:09:05.795] iteration:5471  t-loss:0.1411, loss-lb:0.1107, loss-ulb:0.0225, weight:1.35, lr:0.0008
[11:09:05.988] iteration:5472  t-loss:0.1707, loss-lb:0.1105, loss-ulb:0.0445, weight:1.35, lr:0.0008
[11:09:06.181] iteration:5473  t-loss:0.1379, loss-lb:0.0958, loss-ulb:0.0312, weight:1.35, lr:0.0008
[11:09:06.373] iteration:5474  t-loss:0.1556, loss-lb:0.1033, loss-ulb:0.0387, weight:1.35, lr:0.0008
[11:09:06.565] iteration:5475  t-loss:0.1371, loss-lb:0.0959, loss-ulb:0.0305, weight:1.35, lr:0.0008
[11:09:06.758] iteration:5476  t-loss:0.1762, loss-lb:0.1316, loss-ulb:0.0330, weight:1.35, lr:0.0008
[11:09:06.949] iteration:5477  t-loss:0.1419, loss-lb:0.1080, loss-ulb:0.0251, weight:1.35, lr:0.0008
[11:09:07.141] iteration:5478  t-loss:0.1458, loss-lb:0.1103, loss-ulb:0.0262, weight:1.35, lr:0.0008
[11:09:07.333] iteration:5479  t-loss:0.1490, loss-lb:0.1097, loss-ulb:0.0291, weight:1.35, lr:0.0008
[11:09:07.525] iteration:5480  t-loss:0.1821, loss-lb:0.1088, loss-ulb:0.0543, weight:1.35, lr:0.0008
[11:09:07.717] iteration:5481  t-loss:0.1996, loss-lb:0.1115, loss-ulb:0.0652, weight:1.35, lr:0.0008
[11:09:07.909] iteration:5482  t-loss:0.1516, loss-lb:0.1021, loss-ulb:0.0366, weight:1.35, lr:0.0008
[11:09:08.099] iteration:5483  t-loss:0.1492, loss-lb:0.1003, loss-ulb:0.0361, weight:1.35, lr:0.0008
[11:09:08.289] iteration:5484  t-loss:0.1831, loss-lb:0.1070, loss-ulb:0.0563, weight:1.35, lr:0.0008
[11:09:08.480] iteration:5485  t-loss:0.1881, loss-lb:0.0908, loss-ulb:0.0720, weight:1.35, lr:0.0008
[11:09:08.685] iteration:5486  t-loss:0.2027, loss-lb:0.0959, loss-ulb:0.0790, weight:1.35, lr:0.0008
[11:09:08.883] iteration:5487  t-loss:0.1737, loss-lb:0.1122, loss-ulb:0.0455, weight:1.35, lr:0.0008
[11:09:09.079] iteration:5488  t-loss:0.1670, loss-lb:0.1041, loss-ulb:0.0465, weight:1.35, lr:0.0008
[11:09:09.654] iteration:5489  t-loss:0.1618, loss-lb:0.1137, loss-ulb:0.0356, weight:1.35, lr:0.0008
[11:09:09.851] iteration:5490  t-loss:0.1611, loss-lb:0.1152, loss-ulb:0.0340, weight:1.35, lr:0.0008
[11:09:10.044] iteration:5491  t-loss:0.1488, loss-lb:0.1099, loss-ulb:0.0288, weight:1.35, lr:0.0008
[11:09:10.237] iteration:5492  t-loss:0.2016, loss-lb:0.1107, loss-ulb:0.0673, weight:1.35, lr:0.0008
[11:09:10.429] iteration:5493  t-loss:0.1568, loss-lb:0.1001, loss-ulb:0.0420, weight:1.35, lr:0.0008
[11:09:10.622] iteration:5494  t-loss:0.1443, loss-lb:0.1023, loss-ulb:0.0311, weight:1.35, lr:0.0008
[11:09:10.814] iteration:5495  t-loss:0.1253, loss-lb:0.0905, loss-ulb:0.0258, weight:1.35, lr:0.0008
[11:09:11.005] iteration:5496  t-loss:0.1751, loss-lb:0.1092, loss-ulb:0.0488, weight:1.35, lr:0.0008
[11:09:11.198] iteration:5497  t-loss:0.1406, loss-lb:0.0964, loss-ulb:0.0327, weight:1.35, lr:0.0008
[11:09:11.390] iteration:5498  t-loss:0.1404, loss-lb:0.1045, loss-ulb:0.0266, weight:1.35, lr:0.0008
[11:09:11.583] iteration:5499  t-loss:0.1309, loss-lb:0.0973, loss-ulb:0.0249, weight:1.35, lr:0.0008
[11:09:11.776] iteration:5500  t-loss:0.1407, loss-lb:0.1032, loss-ulb:0.0278, weight:1.35, lr:0.0008
[11:09:11.968] iteration:5501  t-loss:0.1536, loss-lb:0.1144, loss-ulb:0.0290, weight:1.35, lr:0.0008
[11:09:12.159] iteration:5502  t-loss:0.1500, loss-lb:0.1140, loss-ulb:0.0266, weight:1.35, lr:0.0008
[11:09:12.352] iteration:5503  t-loss:0.1598, loss-lb:0.1202, loss-ulb:0.0293, weight:1.35, lr:0.0008
[11:09:12.545] iteration:5504  t-loss:0.1662, loss-lb:0.1139, loss-ulb:0.0387, weight:1.35, lr:0.0008
[11:09:12.739] iteration:5505  t-loss:0.1483, loss-lb:0.1001, loss-ulb:0.0357, weight:1.35, lr:0.0008
[11:09:12.931] iteration:5506  t-loss:0.1386, loss-lb:0.1029, loss-ulb:0.0264, weight:1.35, lr:0.0008
[11:09:13.123] iteration:5507  t-loss:0.1734, loss-lb:0.1199, loss-ulb:0.0396, weight:1.35, lr:0.0008
[11:09:13.315] iteration:5508  t-loss:0.1662, loss-lb:0.0898, loss-ulb:0.0565, weight:1.35, lr:0.0008
[11:09:13.506] iteration:5509  t-loss:0.1321, loss-lb:0.1010, loss-ulb:0.0230, weight:1.35, lr:0.0008
[11:09:13.699] iteration:5510  t-loss:0.1425, loss-lb:0.1108, loss-ulb:0.0235, weight:1.35, lr:0.0008
[11:09:13.892] iteration:5511  t-loss:0.1824, loss-lb:0.1123, loss-ulb:0.0519, weight:1.35, lr:0.0008
[11:09:14.084] iteration:5512  t-loss:0.1293, loss-lb:0.0933, loss-ulb:0.0267, weight:1.35, lr:0.0008
[11:09:14.276] iteration:5513  t-loss:0.1713, loss-lb:0.1062, loss-ulb:0.0482, weight:1.35, lr:0.0008
[11:09:14.468] iteration:5514  t-loss:0.1396, loss-lb:0.1032, loss-ulb:0.0269, weight:1.35, lr:0.0008
[11:09:14.660] iteration:5515  t-loss:0.1229, loss-lb:0.0897, loss-ulb:0.0245, weight:1.35, lr:0.0008
[11:09:14.852] iteration:5516  t-loss:0.1418, loss-lb:0.1056, loss-ulb:0.0267, weight:1.35, lr:0.0008
[11:09:15.047] iteration:5517  t-loss:0.2600, loss-lb:0.0998, loss-ulb:0.1185, weight:1.35, lr:0.0008
[11:09:15.239] iteration:5518  t-loss:0.1987, loss-lb:0.0973, loss-ulb:0.0750, weight:1.35, lr:0.0008
[11:09:15.431] iteration:5519  t-loss:0.1536, loss-lb:0.0931, loss-ulb:0.0448, weight:1.35, lr:0.0008
[11:09:15.624] iteration:5520  t-loss:0.1487, loss-lb:0.1031, loss-ulb:0.0337, weight:1.35, lr:0.0008
[11:09:15.817] iteration:5521  t-loss:0.1302, loss-lb:0.0972, loss-ulb:0.0244, weight:1.35, lr:0.0008
[11:09:16.010] iteration:5522  t-loss:0.1464, loss-lb:0.0892, loss-ulb:0.0423, weight:1.35, lr:0.0008
[11:09:16.202] iteration:5523  t-loss:0.1511, loss-lb:0.0984, loss-ulb:0.0390, weight:1.35, lr:0.0008
[11:09:16.395] iteration:5524  t-loss:0.1421, loss-lb:0.1025, loss-ulb:0.0293, weight:1.35, lr:0.0008
[11:09:16.588] iteration:5525  t-loss:0.1220, loss-lb:0.0881, loss-ulb:0.0252, weight:1.35, lr:0.0008
[11:09:16.780] iteration:5526  t-loss:0.1306, loss-lb:0.0975, loss-ulb:0.0245, weight:1.35, lr:0.0008
[11:09:16.972] iteration:5527  t-loss:0.2027, loss-lb:0.1109, loss-ulb:0.0679, weight:1.35, lr:0.0008
[11:09:17.165] iteration:5528  t-loss:0.1416, loss-lb:0.1083, loss-ulb:0.0247, weight:1.35, lr:0.0008
[11:09:17.356] iteration:5529  t-loss:0.1376, loss-lb:0.1010, loss-ulb:0.0271, weight:1.35, lr:0.0008
[11:09:17.550] iteration:5530  t-loss:0.1322, loss-lb:0.0987, loss-ulb:0.0248, weight:1.35, lr:0.0008
[11:09:17.742] iteration:5531  t-loss:0.1317, loss-lb:0.0995, loss-ulb:0.0238, weight:1.35, lr:0.0008
[11:09:17.935] iteration:5532  t-loss:0.1321, loss-lb:0.1029, loss-ulb:0.0217, weight:1.35, lr:0.0008
[11:09:18.128] iteration:5533  t-loss:0.1349, loss-lb:0.0892, loss-ulb:0.0339, weight:1.35, lr:0.0008
[11:09:18.321] iteration:5534  t-loss:0.1426, loss-lb:0.0975, loss-ulb:0.0334, weight:1.35, lr:0.0008
[11:09:18.515] iteration:5535  t-loss:0.1494, loss-lb:0.0871, loss-ulb:0.0461, weight:1.35, lr:0.0008
[11:09:18.708] iteration:5536  t-loss:0.1275, loss-lb:0.0932, loss-ulb:0.0254, weight:1.35, lr:0.0008
[11:09:18.901] iteration:5537  t-loss:0.2071, loss-lb:0.1052, loss-ulb:0.0754, weight:1.35, lr:0.0008
[11:09:19.094] iteration:5538  t-loss:0.1550, loss-lb:0.1105, loss-ulb:0.0329, weight:1.35, lr:0.0008
[11:09:19.286] iteration:5539  t-loss:0.1192, loss-lb:0.0911, loss-ulb:0.0208, weight:1.35, lr:0.0008
[11:09:19.478] iteration:5540  t-loss:0.1337, loss-lb:0.0945, loss-ulb:0.0290, weight:1.35, lr:0.0008
[11:09:19.670] iteration:5541  t-loss:0.1283, loss-lb:0.0961, loss-ulb:0.0238, weight:1.35, lr:0.0008
[11:09:19.862] iteration:5542  t-loss:0.1321, loss-lb:0.0934, loss-ulb:0.0287, weight:1.35, lr:0.0008
[11:09:20.054] iteration:5543  t-loss:0.1311, loss-lb:0.0981, loss-ulb:0.0244, weight:1.35, lr:0.0008
[11:09:20.246] iteration:5544  t-loss:0.1390, loss-lb:0.0938, loss-ulb:0.0335, weight:1.35, lr:0.0008
[11:09:20.437] iteration:5545  t-loss:0.1299, loss-lb:0.0992, loss-ulb:0.0227, weight:1.35, lr:0.0008
[11:09:20.629] iteration:5546  t-loss:0.1480, loss-lb:0.0947, loss-ulb:0.0395, weight:1.35, lr:0.0008
[11:09:20.821] iteration:5547  t-loss:0.1811, loss-lb:0.1030, loss-ulb:0.0578, weight:1.35, lr:0.0008
[11:09:21.014] iteration:5548  t-loss:0.1624, loss-lb:0.0944, loss-ulb:0.0503, weight:1.35, lr:0.0008
[11:09:21.206] iteration:5549  t-loss:0.1467, loss-lb:0.0966, loss-ulb:0.0370, weight:1.35, lr:0.0008
[11:09:21.398] iteration:5550  t-loss:0.1702, loss-lb:0.0892, loss-ulb:0.0600, weight:1.35, lr:0.0008
[11:09:21.591] iteration:5551  t-loss:0.1375, loss-lb:0.0997, loss-ulb:0.0265, weight:1.43, lr:0.0008
[11:09:21.782] iteration:5552  t-loss:0.1423, loss-lb:0.0926, loss-ulb:0.0349, weight:1.43, lr:0.0008
[11:09:21.974] iteration:5553  t-loss:0.1446, loss-lb:0.1087, loss-ulb:0.0252, weight:1.43, lr:0.0008
[11:09:22.167] iteration:5554  t-loss:0.1603, loss-lb:0.1142, loss-ulb:0.0323, weight:1.43, lr:0.0008
[11:09:22.359] iteration:5555  t-loss:0.1398, loss-lb:0.1037, loss-ulb:0.0254, weight:1.43, lr:0.0008
[11:09:22.551] iteration:5556  t-loss:0.1301, loss-lb:0.0994, loss-ulb:0.0215, weight:1.43, lr:0.0008
[11:09:22.743] iteration:5557  t-loss:0.1445, loss-lb:0.0952, loss-ulb:0.0346, weight:1.43, lr:0.0008
[11:09:22.935] iteration:5558  t-loss:0.1639, loss-lb:0.1021, loss-ulb:0.0434, weight:1.43, lr:0.0008
[11:09:23.128] iteration:5559  t-loss:0.1602, loss-lb:0.1117, loss-ulb:0.0340, weight:1.43, lr:0.0008
[11:09:23.320] iteration:5560  t-loss:0.1614, loss-lb:0.1056, loss-ulb:0.0391, weight:1.43, lr:0.0008
[11:09:23.513] iteration:5561  t-loss:0.2346, loss-lb:0.0983, loss-ulb:0.0956, weight:1.43, lr:0.0008
[11:09:23.706] iteration:5562  t-loss:0.2329, loss-lb:0.0961, loss-ulb:0.0959, weight:1.43, lr:0.0008
[11:09:23.897] iteration:5563  t-loss:0.1252, loss-lb:0.0911, loss-ulb:0.0239, weight:1.43, lr:0.0008
[11:09:24.089] iteration:5564  t-loss:0.1697, loss-lb:0.1316, loss-ulb:0.0268, weight:1.43, lr:0.0008
[11:09:24.282] iteration:5565  t-loss:0.1380, loss-lb:0.0940, loss-ulb:0.0309, weight:1.43, lr:0.0008
[11:09:24.474] iteration:5566  t-loss:0.1686, loss-lb:0.1228, loss-ulb:0.0321, weight:1.43, lr:0.0008
[11:09:24.666] iteration:5567  t-loss:0.1701, loss-lb:0.1253, loss-ulb:0.0314, weight:1.43, lr:0.0008
[11:09:24.860] iteration:5568  t-loss:0.2235, loss-lb:0.1057, loss-ulb:0.0826, weight:1.43, lr:0.0008
[11:09:25.052] iteration:5569  t-loss:0.1396, loss-lb:0.0932, loss-ulb:0.0326, weight:1.43, lr:0.0008
[11:09:25.243] iteration:5570  t-loss:0.1504, loss-lb:0.1137, loss-ulb:0.0257, weight:1.43, lr:0.0008
[11:09:25.436] iteration:5571  t-loss:0.1611, loss-lb:0.0896, loss-ulb:0.0502, weight:1.43, lr:0.0008
[11:09:25.630] iteration:5572  t-loss:0.2048, loss-lb:0.0998, loss-ulb:0.0736, weight:1.43, lr:0.0008
[11:09:25.823] iteration:5573  t-loss:0.1408, loss-lb:0.1028, loss-ulb:0.0267, weight:1.43, lr:0.0008
[11:09:26.016] iteration:5574  t-loss:0.2045, loss-lb:0.1114, loss-ulb:0.0653, weight:1.43, lr:0.0008
[11:09:26.209] iteration:5575  t-loss:0.1525, loss-lb:0.1043, loss-ulb:0.0338, weight:1.43, lr:0.0008
[11:09:26.400] iteration:5576  t-loss:0.1316, loss-lb:0.0948, loss-ulb:0.0258, weight:1.43, lr:0.0008
[11:09:26.592] iteration:5577  t-loss:0.1462, loss-lb:0.1034, loss-ulb:0.0300, weight:1.43, lr:0.0008
[11:09:26.785] iteration:5578  t-loss:0.1848, loss-lb:0.1116, loss-ulb:0.0513, weight:1.43, lr:0.0008
[11:09:26.977] iteration:5579  t-loss:0.1437, loss-lb:0.1105, loss-ulb:0.0232, weight:1.43, lr:0.0008
[11:09:27.168] iteration:5580  t-loss:0.1871, loss-lb:0.1076, loss-ulb:0.0557, weight:1.43, lr:0.0008
[11:09:27.358] iteration:5581  t-loss:0.1765, loss-lb:0.1256, loss-ulb:0.0357, weight:1.43, lr:0.0008
[11:09:27.548] iteration:5582  t-loss:0.1600, loss-lb:0.1062, loss-ulb:0.0377, weight:1.43, lr:0.0008
[11:09:27.739] iteration:5583  t-loss:0.1308, loss-lb:0.0963, loss-ulb:0.0242, weight:1.43, lr:0.0008
[11:09:27.929] iteration:5584  t-loss:0.1710, loss-lb:0.1259, loss-ulb:0.0316, weight:1.43, lr:0.0008
[11:09:28.120] iteration:5585  t-loss:0.1269, loss-lb:0.0930, loss-ulb:0.0237, weight:1.43, lr:0.0008
[11:09:28.310] iteration:5586  t-loss:0.1725, loss-lb:0.1061, loss-ulb:0.0466, weight:1.43, lr:0.0008
[11:09:39.362]  <<Test>> - Ep:56  - mean_dice/mean_h95 - S:89.39/1.45, Best-S:89.92, T:90.16/1.38, Best-T:90.22
[11:09:39.363]           - AvgLoss(lb/ulb/all):0.1026/0.0404/0.1639
[11:09:39.889] iteration:5587  t-loss:0.1619, loss-lb:0.1051, loss-ulb:0.0398, weight:1.43, lr:0.0008
[11:09:40.090] iteration:5588  t-loss:0.1852, loss-lb:0.0923, loss-ulb:0.0651, weight:1.43, lr:0.0008
[11:09:40.283] iteration:5589  t-loss:0.1379, loss-lb:0.1002, loss-ulb:0.0265, weight:1.43, lr:0.0008
[11:09:40.476] iteration:5590  t-loss:0.1740, loss-lb:0.1224, loss-ulb:0.0362, weight:1.43, lr:0.0008
[11:09:40.669] iteration:5591  t-loss:0.1388, loss-lb:0.0973, loss-ulb:0.0291, weight:1.43, lr:0.0008
[11:09:40.862] iteration:5592  t-loss:0.1678, loss-lb:0.1311, loss-ulb:0.0258, weight:1.43, lr:0.0008
[11:09:41.055] iteration:5593  t-loss:0.1594, loss-lb:0.1178, loss-ulb:0.0292, weight:1.43, lr:0.0008
[11:09:41.247] iteration:5594  t-loss:0.1558, loss-lb:0.0985, loss-ulb:0.0402, weight:1.43, lr:0.0008
[11:09:41.454] iteration:5595  t-loss:0.1599, loss-lb:0.0944, loss-ulb:0.0460, weight:1.43, lr:0.0008
[11:09:41.653] iteration:5596  t-loss:0.1498, loss-lb:0.1069, loss-ulb:0.0301, weight:1.43, lr:0.0008
[11:09:41.852] iteration:5597  t-loss:0.1883, loss-lb:0.0991, loss-ulb:0.0625, weight:1.43, lr:0.0008
[11:09:42.046] iteration:5598  t-loss:0.1362, loss-lb:0.1008, loss-ulb:0.0249, weight:1.43, lr:0.0008
[11:09:42.238] iteration:5599  t-loss:0.1836, loss-lb:0.1099, loss-ulb:0.0516, weight:1.43, lr:0.0008
[11:09:42.432] iteration:5600  t-loss:0.1699, loss-lb:0.0918, loss-ulb:0.0548, weight:1.43, lr:0.0008
[11:09:42.625] iteration:5601  t-loss:0.1495, loss-lb:0.1083, loss-ulb:0.0289, weight:1.43, lr:0.0008
[11:09:42.818] iteration:5602  t-loss:0.1439, loss-lb:0.1009, loss-ulb:0.0301, weight:1.43, lr:0.0008
[11:09:43.012] iteration:5603  t-loss:0.1721, loss-lb:0.1083, loss-ulb:0.0447, weight:1.43, lr:0.0008
[11:09:43.205] iteration:5604  t-loss:0.2803, loss-lb:0.1935, loss-ulb:0.0608, weight:1.43, lr:0.0008
[11:09:43.396] iteration:5605  t-loss:0.1574, loss-lb:0.1155, loss-ulb:0.0294, weight:1.43, lr:0.0008
[11:09:43.589] iteration:5606  t-loss:0.1415, loss-lb:0.1054, loss-ulb:0.0253, weight:1.43, lr:0.0008
[11:09:43.784] iteration:5607  t-loss:0.1806, loss-lb:0.1051, loss-ulb:0.0530, weight:1.43, lr:0.0008
[11:09:43.978] iteration:5608  t-loss:0.1464, loss-lb:0.1022, loss-ulb:0.0310, weight:1.43, lr:0.0008
[11:09:44.172] iteration:5609  t-loss:0.1538, loss-lb:0.0982, loss-ulb:0.0390, weight:1.43, lr:0.0008
[11:09:44.364] iteration:5610  t-loss:0.1941, loss-lb:0.1322, loss-ulb:0.0434, weight:1.43, lr:0.0008
[11:09:44.557] iteration:5611  t-loss:0.2171, loss-lb:0.1161, loss-ulb:0.0708, weight:1.43, lr:0.0008
[11:09:44.749] iteration:5612  t-loss:0.1749, loss-lb:0.1250, loss-ulb:0.0350, weight:1.43, lr:0.0008
[11:09:44.943] iteration:5613  t-loss:0.1462, loss-lb:0.1049, loss-ulb:0.0289, weight:1.43, lr:0.0008
[11:09:45.135] iteration:5614  t-loss:0.1922, loss-lb:0.1164, loss-ulb:0.0532, weight:1.43, lr:0.0008
[11:09:45.327] iteration:5615  t-loss:0.1398, loss-lb:0.0928, loss-ulb:0.0329, weight:1.43, lr:0.0008
[11:09:45.519] iteration:5616  t-loss:0.1905, loss-lb:0.1115, loss-ulb:0.0554, weight:1.43, lr:0.0008
[11:09:45.710] iteration:5617  t-loss:0.2100, loss-lb:0.1013, loss-ulb:0.0762, weight:1.43, lr:0.0008
[11:09:45.903] iteration:5618  t-loss:0.2063, loss-lb:0.1063, loss-ulb:0.0701, weight:1.43, lr:0.0008
[11:09:46.095] iteration:5619  t-loss:0.1397, loss-lb:0.0942, loss-ulb:0.0319, weight:1.43, lr:0.0008
[11:09:46.286] iteration:5620  t-loss:0.1325, loss-lb:0.0991, loss-ulb:0.0234, weight:1.43, lr:0.0008
[11:09:46.479] iteration:5621  t-loss:0.1495, loss-lb:0.0947, loss-ulb:0.0384, weight:1.43, lr:0.0008
[11:09:46.671] iteration:5622  t-loss:0.1508, loss-lb:0.1118, loss-ulb:0.0274, weight:1.43, lr:0.0008
[11:09:46.862] iteration:5623  t-loss:0.1455, loss-lb:0.1037, loss-ulb:0.0293, weight:1.43, lr:0.0008
[11:09:47.055] iteration:5624  t-loss:0.1903, loss-lb:0.1152, loss-ulb:0.0527, weight:1.43, lr:0.0008
[11:09:47.247] iteration:5625  t-loss:0.1456, loss-lb:0.0974, loss-ulb:0.0338, weight:1.43, lr:0.0008
[11:09:47.439] iteration:5626  t-loss:0.1493, loss-lb:0.1067, loss-ulb:0.0299, weight:1.43, lr:0.0008
[11:09:47.631] iteration:5627  t-loss:0.1550, loss-lb:0.1080, loss-ulb:0.0330, weight:1.43, lr:0.0008
[11:09:47.823] iteration:5628  t-loss:0.1482, loss-lb:0.1157, loss-ulb:0.0228, weight:1.43, lr:0.0008
[11:09:48.015] iteration:5629  t-loss:0.1403, loss-lb:0.1051, loss-ulb:0.0247, weight:1.43, lr:0.0008
[11:09:48.208] iteration:5630  t-loss:0.1329, loss-lb:0.0979, loss-ulb:0.0246, weight:1.43, lr:0.0008
[11:09:48.402] iteration:5631  t-loss:0.1509, loss-lb:0.1045, loss-ulb:0.0325, weight:1.43, lr:0.0008
[11:09:48.597] iteration:5632  t-loss:0.1377, loss-lb:0.0975, loss-ulb:0.0281, weight:1.43, lr:0.0008
[11:09:48.788] iteration:5633  t-loss:0.1487, loss-lb:0.0930, loss-ulb:0.0391, weight:1.43, lr:0.0008
[11:09:48.980] iteration:5634  t-loss:0.1390, loss-lb:0.0956, loss-ulb:0.0304, weight:1.43, lr:0.0008
[11:09:49.172] iteration:5635  t-loss:0.1974, loss-lb:0.1409, loss-ulb:0.0396, weight:1.43, lr:0.0008
[11:09:49.363] iteration:5636  t-loss:0.1797, loss-lb:0.1345, loss-ulb:0.0317, weight:1.43, lr:0.0008
[11:09:49.554] iteration:5637  t-loss:0.1418, loss-lb:0.0982, loss-ulb:0.0305, weight:1.43, lr:0.0008
[11:09:49.745] iteration:5638  t-loss:0.1490, loss-lb:0.1108, loss-ulb:0.0267, weight:1.43, lr:0.0008
[11:09:49.938] iteration:5639  t-loss:0.1557, loss-lb:0.1127, loss-ulb:0.0301, weight:1.43, lr:0.0008
[11:09:50.129] iteration:5640  t-loss:0.1777, loss-lb:0.1218, loss-ulb:0.0392, weight:1.43, lr:0.0008
[11:09:50.322] iteration:5641  t-loss:0.1988, loss-lb:0.1000, loss-ulb:0.0693, weight:1.43, lr:0.0008
[11:09:50.513] iteration:5642  t-loss:0.1379, loss-lb:0.1059, loss-ulb:0.0224, weight:1.43, lr:0.0008
[11:09:50.705] iteration:5643  t-loss:0.1397, loss-lb:0.0985, loss-ulb:0.0289, weight:1.43, lr:0.0008
[11:09:50.899] iteration:5644  t-loss:0.1693, loss-lb:0.1144, loss-ulb:0.0385, weight:1.43, lr:0.0008
[11:09:51.091] iteration:5645  t-loss:0.1573, loss-lb:0.1069, loss-ulb:0.0353, weight:1.43, lr:0.0008
[11:09:51.285] iteration:5646  t-loss:0.1943, loss-lb:0.0941, loss-ulb:0.0703, weight:1.43, lr:0.0008
[11:09:51.477] iteration:5647  t-loss:0.1738, loss-lb:0.1010, loss-ulb:0.0511, weight:1.43, lr:0.0008
[11:09:51.668] iteration:5648  t-loss:0.1472, loss-lb:0.0945, loss-ulb:0.0369, weight:1.43, lr:0.0008
[11:09:51.860] iteration:5649  t-loss:0.1693, loss-lb:0.1093, loss-ulb:0.0421, weight:1.43, lr:0.0008
[11:09:52.051] iteration:5650  t-loss:0.1478, loss-lb:0.1091, loss-ulb:0.0272, weight:1.43, lr:0.0008
[11:09:52.243] iteration:5651  t-loss:0.1734, loss-lb:0.1040, loss-ulb:0.0486, weight:1.43, lr:0.0008
[11:09:52.433] iteration:5652  t-loss:0.1938, loss-lb:0.1075, loss-ulb:0.0605, weight:1.43, lr:0.0008
[11:09:52.624] iteration:5653  t-loss:0.1739, loss-lb:0.1105, loss-ulb:0.0445, weight:1.43, lr:0.0008
[11:09:52.816] iteration:5654  t-loss:0.1563, loss-lb:0.1117, loss-ulb:0.0312, weight:1.43, lr:0.0008
[11:09:53.008] iteration:5655  t-loss:0.1562, loss-lb:0.0954, loss-ulb:0.0427, weight:1.43, lr:0.0008
[11:09:53.201] iteration:5656  t-loss:0.1393, loss-lb:0.0935, loss-ulb:0.0321, weight:1.43, lr:0.0008
[11:09:53.391] iteration:5657  t-loss:0.1525, loss-lb:0.1152, loss-ulb:0.0261, weight:1.43, lr:0.0008
[11:09:53.583] iteration:5658  t-loss:0.1971, loss-lb:0.1089, loss-ulb:0.0618, weight:1.43, lr:0.0008
[11:09:53.775] iteration:5659  t-loss:0.1528, loss-lb:0.0987, loss-ulb:0.0379, weight:1.43, lr:0.0008
[11:09:53.967] iteration:5660  t-loss:0.1386, loss-lb:0.1052, loss-ulb:0.0234, weight:1.43, lr:0.0008
[11:09:54.159] iteration:5661  t-loss:0.1374, loss-lb:0.0959, loss-ulb:0.0290, weight:1.43, lr:0.0008
[11:09:54.351] iteration:5662  t-loss:0.1562, loss-lb:0.1066, loss-ulb:0.0348, weight:1.43, lr:0.0008
[11:09:54.544] iteration:5663  t-loss:0.1611, loss-lb:0.1198, loss-ulb:0.0289, weight:1.43, lr:0.0008
[11:09:54.740] iteration:5664  t-loss:0.1706, loss-lb:0.1071, loss-ulb:0.0445, weight:1.43, lr:0.0008
[11:09:54.934] iteration:5665  t-loss:0.1364, loss-lb:0.0998, loss-ulb:0.0256, weight:1.43, lr:0.0008
[11:09:55.128] iteration:5666  t-loss:0.1753, loss-lb:0.1279, loss-ulb:0.0332, weight:1.43, lr:0.0008
[11:09:55.320] iteration:5667  t-loss:0.1374, loss-lb:0.0985, loss-ulb:0.0272, weight:1.43, lr:0.0008
[11:09:55.511] iteration:5668  t-loss:0.1524, loss-lb:0.1089, loss-ulb:0.0305, weight:1.43, lr:0.0008
[11:09:55.702] iteration:5669  t-loss:0.1892, loss-lb:0.1133, loss-ulb:0.0532, weight:1.43, lr:0.0008
[11:09:55.894] iteration:5670  t-loss:0.1268, loss-lb:0.0936, loss-ulb:0.0232, weight:1.43, lr:0.0008
[11:09:56.085] iteration:5671  t-loss:0.1441, loss-lb:0.1011, loss-ulb:0.0302, weight:1.43, lr:0.0008
[11:09:56.278] iteration:5672  t-loss:0.1953, loss-lb:0.0928, loss-ulb:0.0719, weight:1.43, lr:0.0008
[11:09:56.470] iteration:5673  t-loss:0.1464, loss-lb:0.1093, loss-ulb:0.0260, weight:1.43, lr:0.0008
[11:09:56.661] iteration:5674  t-loss:0.1271, loss-lb:0.0902, loss-ulb:0.0259, weight:1.43, lr:0.0008
[11:09:56.853] iteration:5675  t-loss:0.1657, loss-lb:0.1269, loss-ulb:0.0272, weight:1.43, lr:0.0008
[11:09:57.045] iteration:5676  t-loss:0.1480, loss-lb:0.0938, loss-ulb:0.0380, weight:1.43, lr:0.0008
[11:09:57.236] iteration:5677  t-loss:0.1764, loss-lb:0.1079, loss-ulb:0.0480, weight:1.43, lr:0.0008
[11:09:57.428] iteration:5678  t-loss:0.1490, loss-lb:0.1012, loss-ulb:0.0335, weight:1.43, lr:0.0008
[11:09:57.621] iteration:5679  t-loss:0.1461, loss-lb:0.0963, loss-ulb:0.0349, weight:1.43, lr:0.0008
[11:09:57.812] iteration:5680  t-loss:0.1582, loss-lb:0.0998, loss-ulb:0.0410, weight:1.43, lr:0.0008
[11:09:58.003] iteration:5681  t-loss:0.1499, loss-lb:0.1152, loss-ulb:0.0243, weight:1.43, lr:0.0008
[11:09:58.194] iteration:5682  t-loss:0.2667, loss-lb:0.1448, loss-ulb:0.0855, weight:1.43, lr:0.0008
[11:09:58.386] iteration:5683  t-loss:0.1650, loss-lb:0.1340, loss-ulb:0.0218, weight:1.43, lr:0.0008
[11:09:58.577] iteration:5684  t-loss:0.2801, loss-lb:0.1452, loss-ulb:0.0946, weight:1.43, lr:0.0008
[11:09:59.168] iteration:5685  t-loss:0.1634, loss-lb:0.1092, loss-ulb:0.0380, weight:1.43, lr:0.0008
[11:09:59.365] iteration:5686  t-loss:0.2021, loss-lb:0.1013, loss-ulb:0.0707, weight:1.43, lr:0.0008
[11:09:59.556] iteration:5687  t-loss:0.1811, loss-lb:0.1048, loss-ulb:0.0535, weight:1.43, lr:0.0008
[11:09:59.748] iteration:5688  t-loss:0.1584, loss-lb:0.1084, loss-ulb:0.0351, weight:1.43, lr:0.0008
[11:09:59.940] iteration:5689  t-loss:0.2234, loss-lb:0.1081, loss-ulb:0.0808, weight:1.43, lr:0.0008
[11:10:00.132] iteration:5690  t-loss:0.1608, loss-lb:0.1167, loss-ulb:0.0309, weight:1.43, lr:0.0008
[11:10:00.324] iteration:5691  t-loss:0.3023, loss-lb:0.1155, loss-ulb:0.1309, weight:1.43, lr:0.0008
[11:10:00.516] iteration:5692  t-loss:0.3027, loss-lb:0.1170, loss-ulb:0.1302, weight:1.43, lr:0.0008
[11:10:00.708] iteration:5693  t-loss:0.1871, loss-lb:0.1047, loss-ulb:0.0578, weight:1.43, lr:0.0008
[11:10:00.900] iteration:5694  t-loss:0.1909, loss-lb:0.1076, loss-ulb:0.0584, weight:1.43, lr:0.0008
[11:10:01.091] iteration:5695  t-loss:0.1805, loss-lb:0.1047, loss-ulb:0.0531, weight:1.43, lr:0.0008
[11:10:01.284] iteration:5696  t-loss:0.1641, loss-lb:0.1123, loss-ulb:0.0363, weight:1.43, lr:0.0008
[11:10:01.477] iteration:5697  t-loss:0.1860, loss-lb:0.1281, loss-ulb:0.0406, weight:1.43, lr:0.0008
[11:10:01.670] iteration:5698  t-loss:0.1606, loss-lb:0.1028, loss-ulb:0.0406, weight:1.43, lr:0.0008
[11:10:01.862] iteration:5699  t-loss:0.2414, loss-lb:0.1276, loss-ulb:0.0798, weight:1.43, lr:0.0008
[11:10:02.053] iteration:5700  t-loss:0.1562, loss-lb:0.1156, loss-ulb:0.0284, weight:1.43, lr:0.0008
[11:10:02.244] iteration:5701  t-loss:0.2030, loss-lb:0.1484, loss-ulb:0.0364, weight:1.50, lr:0.0008
[11:10:02.435] iteration:5702  t-loss:0.1826, loss-lb:0.1317, loss-ulb:0.0339, weight:1.50, lr:0.0008
[11:10:02.626] iteration:5703  t-loss:0.1543, loss-lb:0.1127, loss-ulb:0.0277, weight:1.50, lr:0.0008
[11:10:02.817] iteration:5704  t-loss:0.1543, loss-lb:0.1004, loss-ulb:0.0359, weight:1.50, lr:0.0008
[11:10:03.009] iteration:5705  t-loss:0.1526, loss-lb:0.1070, loss-ulb:0.0304, weight:1.50, lr:0.0008
[11:10:03.200] iteration:5706  t-loss:0.1718, loss-lb:0.1236, loss-ulb:0.0321, weight:1.50, lr:0.0008
[11:10:03.391] iteration:5707  t-loss:0.1832, loss-lb:0.1079, loss-ulb:0.0502, weight:1.50, lr:0.0008
[11:10:03.582] iteration:5708  t-loss:0.2495, loss-lb:0.0998, loss-ulb:0.0999, weight:1.50, lr:0.0008
[11:10:03.773] iteration:5709  t-loss:0.1387, loss-lb:0.1056, loss-ulb:0.0221, weight:1.50, lr:0.0008
[11:10:03.964] iteration:5710  t-loss:0.1898, loss-lb:0.1052, loss-ulb:0.0564, weight:1.50, lr:0.0008
[11:10:04.157] iteration:5711  t-loss:0.1703, loss-lb:0.1078, loss-ulb:0.0417, weight:1.50, lr:0.0008
[11:10:04.347] iteration:5712  t-loss:0.1837, loss-lb:0.1439, loss-ulb:0.0265, weight:1.50, lr:0.0008
[11:10:04.539] iteration:5713  t-loss:0.1984, loss-lb:0.1079, loss-ulb:0.0604, weight:1.50, lr:0.0008
[11:10:04.729] iteration:5714  t-loss:0.1756, loss-lb:0.1306, loss-ulb:0.0300, weight:1.50, lr:0.0008
[11:10:04.921] iteration:5715  t-loss:0.1618, loss-lb:0.1022, loss-ulb:0.0398, weight:1.50, lr:0.0008
[11:10:05.114] iteration:5716  t-loss:0.1898, loss-lb:0.1367, loss-ulb:0.0354, weight:1.50, lr:0.0008
[11:10:05.307] iteration:5717  t-loss:0.1407, loss-lb:0.0977, loss-ulb:0.0287, weight:1.50, lr:0.0008
[11:10:05.502] iteration:5718  t-loss:0.3345, loss-lb:0.1076, loss-ulb:0.1513, weight:1.50, lr:0.0008
[11:10:05.696] iteration:5719  t-loss:0.1595, loss-lb:0.1087, loss-ulb:0.0339, weight:1.50, lr:0.0008
[11:10:05.891] iteration:5720  t-loss:0.1580, loss-lb:0.1182, loss-ulb:0.0265, weight:1.50, lr:0.0008
[11:10:06.084] iteration:5721  t-loss:0.1430, loss-lb:0.1034, loss-ulb:0.0264, weight:1.50, lr:0.0008
[11:10:06.277] iteration:5722  t-loss:0.1755, loss-lb:0.1270, loss-ulb:0.0324, weight:1.50, lr:0.0008
[11:10:06.469] iteration:5723  t-loss:0.1847, loss-lb:0.1050, loss-ulb:0.0532, weight:1.50, lr:0.0008
[11:10:06.660] iteration:5724  t-loss:0.1554, loss-lb:0.0980, loss-ulb:0.0383, weight:1.50, lr:0.0008
[11:10:06.854] iteration:5725  t-loss:0.2139, loss-lb:0.1041, loss-ulb:0.0732, weight:1.50, lr:0.0008
[11:10:07.047] iteration:5726  t-loss:0.1752, loss-lb:0.1003, loss-ulb:0.0499, weight:1.50, lr:0.0008
[11:10:07.243] iteration:5727  t-loss:0.2030, loss-lb:0.1130, loss-ulb:0.0600, weight:1.50, lr:0.0008
[11:10:07.434] iteration:5728  t-loss:0.1620, loss-lb:0.0992, loss-ulb:0.0419, weight:1.50, lr:0.0008
[11:10:07.626] iteration:5729  t-loss:0.1578, loss-lb:0.1120, loss-ulb:0.0306, weight:1.50, lr:0.0008
[11:10:07.819] iteration:5730  t-loss:0.1570, loss-lb:0.1049, loss-ulb:0.0348, weight:1.50, lr:0.0008
[11:10:08.010] iteration:5731  t-loss:0.1652, loss-lb:0.0975, loss-ulb:0.0452, weight:1.50, lr:0.0008
[11:10:08.202] iteration:5732  t-loss:0.1623, loss-lb:0.1002, loss-ulb:0.0414, weight:1.50, lr:0.0008
[11:10:08.393] iteration:5733  t-loss:0.1932, loss-lb:0.1316, loss-ulb:0.0411, weight:1.50, lr:0.0008
[11:10:08.585] iteration:5734  t-loss:0.1652, loss-lb:0.1151, loss-ulb:0.0334, weight:1.50, lr:0.0008
[11:10:08.777] iteration:5735  t-loss:0.1626, loss-lb:0.1025, loss-ulb:0.0401, weight:1.50, lr:0.0008
[11:10:08.968] iteration:5736  t-loss:0.1453, loss-lb:0.1029, loss-ulb:0.0283, weight:1.50, lr:0.0008
[11:10:09.160] iteration:5737  t-loss:0.1767, loss-lb:0.1016, loss-ulb:0.0501, weight:1.50, lr:0.0008
[11:10:09.353] iteration:5738  t-loss:0.1391, loss-lb:0.1012, loss-ulb:0.0253, weight:1.50, lr:0.0008
[11:10:09.545] iteration:5739  t-loss:0.1463, loss-lb:0.1014, loss-ulb:0.0300, weight:1.50, lr:0.0008
[11:10:09.737] iteration:5740  t-loss:0.1753, loss-lb:0.1309, loss-ulb:0.0296, weight:1.50, lr:0.0008
[11:10:09.929] iteration:5741  t-loss:0.1438, loss-lb:0.1063, loss-ulb:0.0250, weight:1.50, lr:0.0008
[11:10:10.120] iteration:5742  t-loss:0.1575, loss-lb:0.1048, loss-ulb:0.0351, weight:1.50, lr:0.0008
[11:10:10.312] iteration:5743  t-loss:0.1412, loss-lb:0.1028, loss-ulb:0.0256, weight:1.50, lr:0.0008
[11:10:10.504] iteration:5744  t-loss:0.1660, loss-lb:0.1040, loss-ulb:0.0414, weight:1.50, lr:0.0008
[11:10:10.696] iteration:5745  t-loss:0.1401, loss-lb:0.0980, loss-ulb:0.0280, weight:1.50, lr:0.0008
[11:10:10.889] iteration:5746  t-loss:0.1371, loss-lb:0.0997, loss-ulb:0.0249, weight:1.50, lr:0.0008
[11:10:11.081] iteration:5747  t-loss:0.1679, loss-lb:0.0928, loss-ulb:0.0501, weight:1.50, lr:0.0008
[11:10:11.273] iteration:5748  t-loss:0.1547, loss-lb:0.1005, loss-ulb:0.0361, weight:1.50, lr:0.0008
[11:10:11.465] iteration:5749  t-loss:0.1557, loss-lb:0.0994, loss-ulb:0.0375, weight:1.50, lr:0.0008
[11:10:11.658] iteration:5750  t-loss:0.1624, loss-lb:0.0991, loss-ulb:0.0422, weight:1.50, lr:0.0008
[11:10:11.850] iteration:5751  t-loss:0.1424, loss-lb:0.1018, loss-ulb:0.0271, weight:1.50, lr:0.0008
[11:10:12.042] iteration:5752  t-loss:0.1509, loss-lb:0.1005, loss-ulb:0.0336, weight:1.50, lr:0.0008
[11:10:12.234] iteration:5753  t-loss:0.1527, loss-lb:0.1006, loss-ulb:0.0347, weight:1.50, lr:0.0008
[11:10:12.426] iteration:5754  t-loss:0.1728, loss-lb:0.0981, loss-ulb:0.0498, weight:1.50, lr:0.0008
[11:10:12.620] iteration:5755  t-loss:0.1513, loss-lb:0.0954, loss-ulb:0.0373, weight:1.50, lr:0.0008
[11:10:12.811] iteration:5756  t-loss:0.1356, loss-lb:0.1033, loss-ulb:0.0215, weight:1.50, lr:0.0008
[11:10:13.004] iteration:5757  t-loss:0.1469, loss-lb:0.1022, loss-ulb:0.0298, weight:1.50, lr:0.0008
[11:10:13.195] iteration:5758  t-loss:0.1487, loss-lb:0.1014, loss-ulb:0.0315, weight:1.50, lr:0.0008
[11:10:13.387] iteration:5759  t-loss:0.1402, loss-lb:0.1010, loss-ulb:0.0262, weight:1.50, lr:0.0008
[11:10:13.579] iteration:5760  t-loss:0.1874, loss-lb:0.1082, loss-ulb:0.0528, weight:1.50, lr:0.0008
[11:10:13.771] iteration:5761  t-loss:0.1818, loss-lb:0.1057, loss-ulb:0.0508, weight:1.50, lr:0.0008
[11:10:13.962] iteration:5762  t-loss:0.1494, loss-lb:0.1045, loss-ulb:0.0299, weight:1.50, lr:0.0008
[11:10:14.156] iteration:5763  t-loss:0.1557, loss-lb:0.1090, loss-ulb:0.0312, weight:1.50, lr:0.0008
[11:10:14.359] iteration:5764  t-loss:0.1238, loss-lb:0.0844, loss-ulb:0.0263, weight:1.50, lr:0.0008
[11:10:14.555] iteration:5765  t-loss:0.1444, loss-lb:0.1030, loss-ulb:0.0276, weight:1.50, lr:0.0008
[11:10:14.746] iteration:5766  t-loss:0.1462, loss-lb:0.1042, loss-ulb:0.0280, weight:1.50, lr:0.0008
[11:10:14.937] iteration:5767  t-loss:0.1408, loss-lb:0.0959, loss-ulb:0.0299, weight:1.50, lr:0.0008
[11:10:15.129] iteration:5768  t-loss:0.1653, loss-lb:0.0940, loss-ulb:0.0475, weight:1.50, lr:0.0008
[11:10:15.322] iteration:5769  t-loss:0.1235, loss-lb:0.0894, loss-ulb:0.0227, weight:1.50, lr:0.0008
[11:10:15.513] iteration:5770  t-loss:0.1398, loss-lb:0.0926, loss-ulb:0.0315, weight:1.50, lr:0.0008
[11:10:15.706] iteration:5771  t-loss:0.1425, loss-lb:0.1037, loss-ulb:0.0258, weight:1.50, lr:0.0008
[11:10:15.899] iteration:5772  t-loss:0.1326, loss-lb:0.0950, loss-ulb:0.0251, weight:1.50, lr:0.0008
[11:10:16.092] iteration:5773  t-loss:0.1522, loss-lb:0.1061, loss-ulb:0.0307, weight:1.50, lr:0.0008
[11:10:16.285] iteration:5774  t-loss:0.2007, loss-lb:0.1302, loss-ulb:0.0470, weight:1.50, lr:0.0008
[11:10:16.481] iteration:5775  t-loss:0.2381, loss-lb:0.0937, loss-ulb:0.0963, weight:1.50, lr:0.0008
[11:10:16.674] iteration:5776  t-loss:0.1377, loss-lb:0.0927, loss-ulb:0.0300, weight:1.50, lr:0.0008
[11:10:16.866] iteration:5777  t-loss:0.1473, loss-lb:0.1006, loss-ulb:0.0311, weight:1.50, lr:0.0008
[11:10:17.057] iteration:5778  t-loss:0.1439, loss-lb:0.1019, loss-ulb:0.0280, weight:1.50, lr:0.0008
[11:10:17.248] iteration:5779  t-loss:0.2145, loss-lb:0.1089, loss-ulb:0.0704, weight:1.50, lr:0.0008
[11:10:17.439] iteration:5780  t-loss:0.1643, loss-lb:0.0968, loss-ulb:0.0450, weight:1.50, lr:0.0008
[11:10:17.629] iteration:5781  t-loss:0.1430, loss-lb:0.1024, loss-ulb:0.0271, weight:1.50, lr:0.0008
[11:10:17.820] iteration:5782  t-loss:0.1939, loss-lb:0.1375, loss-ulb:0.0376, weight:1.50, lr:0.0008
[11:10:30.194]  <<Test>> - Ep:58  - mean_dice/mean_h95 - S:87.93/2.16, Best-S:89.92, T:89.71/1.64, Best-T:90.22
[11:10:30.194]           - AvgLoss(lb/ulb/all):0.1073/0.0369/0.1575
[11:10:30.739] iteration:5783  t-loss:0.1773, loss-lb:0.1262, loss-ulb:0.0341, weight:1.50, lr:0.0008
[11:10:30.936] iteration:5784  t-loss:0.1787, loss-lb:0.1267, loss-ulb:0.0347, weight:1.50, lr:0.0008
[11:10:31.129] iteration:5785  t-loss:0.1681, loss-lb:0.1108, loss-ulb:0.0383, weight:1.50, lr:0.0008
[11:10:31.323] iteration:5786  t-loss:0.1700, loss-lb:0.1268, loss-ulb:0.0288, weight:1.50, lr:0.0008
[11:10:31.517] iteration:5787  t-loss:0.2171, loss-lb:0.1020, loss-ulb:0.0768, weight:1.50, lr:0.0008
[11:10:31.710] iteration:5788  t-loss:0.1876, loss-lb:0.0973, loss-ulb:0.0603, weight:1.50, lr:0.0008
[11:10:31.903] iteration:5789  t-loss:0.2144, loss-lb:0.1139, loss-ulb:0.0670, weight:1.50, lr:0.0008
[11:10:32.095] iteration:5790  t-loss:0.1528, loss-lb:0.1102, loss-ulb:0.0284, weight:1.50, lr:0.0008
[11:10:32.290] iteration:5791  t-loss:0.1587, loss-lb:0.1009, loss-ulb:0.0385, weight:1.50, lr:0.0008
[11:10:32.483] iteration:5792  t-loss:0.1648, loss-lb:0.1289, loss-ulb:0.0239, weight:1.50, lr:0.0008
[11:10:32.676] iteration:5793  t-loss:0.1766, loss-lb:0.1010, loss-ulb:0.0504, weight:1.50, lr:0.0008
[11:10:32.869] iteration:5794  t-loss:0.1535, loss-lb:0.0967, loss-ulb:0.0379, weight:1.50, lr:0.0008
[11:10:33.063] iteration:5795  t-loss:0.1524, loss-lb:0.1142, loss-ulb:0.0255, weight:1.50, lr:0.0008
[11:10:33.257] iteration:5796  t-loss:0.2447, loss-lb:0.1112, loss-ulb:0.0890, weight:1.50, lr:0.0008
[11:10:33.451] iteration:5797  t-loss:0.1721, loss-lb:0.1046, loss-ulb:0.0450, weight:1.50, lr:0.0008
[11:10:33.646] iteration:5798  t-loss:0.2018, loss-lb:0.1296, loss-ulb:0.0481, weight:1.50, lr:0.0008
[11:10:33.838] iteration:5799  t-loss:0.1693, loss-lb:0.1163, loss-ulb:0.0353, weight:1.50, lr:0.0008
[11:10:34.031] iteration:5800  t-loss:0.1764, loss-lb:0.1236, loss-ulb:0.0352, weight:1.50, lr:0.0008
[11:10:34.224] iteration:5801  t-loss:0.2869, loss-lb:0.1712, loss-ulb:0.0772, weight:1.50, lr:0.0008
[11:10:34.417] iteration:5802  t-loss:0.2172, loss-lb:0.1249, loss-ulb:0.0615, weight:1.50, lr:0.0008
[11:10:34.610] iteration:5803  t-loss:0.1978, loss-lb:0.1294, loss-ulb:0.0456, weight:1.50, lr:0.0008
[11:10:34.802] iteration:5804  t-loss:0.2042, loss-lb:0.1318, loss-ulb:0.0483, weight:1.50, lr:0.0008
[11:10:34.995] iteration:5805  t-loss:0.1557, loss-lb:0.1066, loss-ulb:0.0327, weight:1.50, lr:0.0008
[11:10:35.189] iteration:5806  t-loss:0.1989, loss-lb:0.1083, loss-ulb:0.0604, weight:1.50, lr:0.0008
[11:10:35.380] iteration:5807  t-loss:0.1796, loss-lb:0.1225, loss-ulb:0.0381, weight:1.50, lr:0.0008
[11:10:35.572] iteration:5808  t-loss:0.1891, loss-lb:0.1165, loss-ulb:0.0484, weight:1.50, lr:0.0008
[11:10:35.764] iteration:5809  t-loss:0.2047, loss-lb:0.1227, loss-ulb:0.0547, weight:1.50, lr:0.0008
[11:10:35.956] iteration:5810  t-loss:0.1980, loss-lb:0.1345, loss-ulb:0.0423, weight:1.50, lr:0.0008
[11:10:36.149] iteration:5811  t-loss:0.1487, loss-lb:0.1084, loss-ulb:0.0269, weight:1.50, lr:0.0008
[11:10:36.342] iteration:5812  t-loss:0.2146, loss-lb:0.1082, loss-ulb:0.0710, weight:1.50, lr:0.0008
[11:10:36.534] iteration:5813  t-loss:0.1465, loss-lb:0.1051, loss-ulb:0.0276, weight:1.50, lr:0.0008
[11:10:36.726] iteration:5814  t-loss:0.1690, loss-lb:0.1073, loss-ulb:0.0411, weight:1.50, lr:0.0008
[11:10:36.919] iteration:5815  t-loss:0.2046, loss-lb:0.1216, loss-ulb:0.0554, weight:1.50, lr:0.0008
[11:10:37.112] iteration:5816  t-loss:0.1450, loss-lb:0.0985, loss-ulb:0.0310, weight:1.50, lr:0.0008
[11:10:37.304] iteration:5817  t-loss:0.2117, loss-lb:0.1044, loss-ulb:0.0715, weight:1.50, lr:0.0008
[11:10:37.496] iteration:5818  t-loss:0.1815, loss-lb:0.1109, loss-ulb:0.0471, weight:1.50, lr:0.0008
[11:10:37.688] iteration:5819  t-loss:0.1589, loss-lb:0.1137, loss-ulb:0.0302, weight:1.50, lr:0.0008
[11:10:37.879] iteration:5820  t-loss:0.1477, loss-lb:0.1145, loss-ulb:0.0221, weight:1.50, lr:0.0008
[11:10:38.071] iteration:5821  t-loss:0.1373, loss-lb:0.0970, loss-ulb:0.0269, weight:1.50, lr:0.0008
[11:10:38.263] iteration:5822  t-loss:0.1472, loss-lb:0.1075, loss-ulb:0.0264, weight:1.50, lr:0.0008
[11:10:38.454] iteration:5823  t-loss:0.1654, loss-lb:0.1106, loss-ulb:0.0366, weight:1.50, lr:0.0008
[11:10:38.647] iteration:5824  t-loss:0.1832, loss-lb:0.1253, loss-ulb:0.0386, weight:1.50, lr:0.0008
[11:10:38.841] iteration:5825  t-loss:0.1459, loss-lb:0.1037, loss-ulb:0.0281, weight:1.50, lr:0.0008
[11:10:39.033] iteration:5826  t-loss:0.1678, loss-lb:0.1129, loss-ulb:0.0366, weight:1.50, lr:0.0008
[11:10:39.226] iteration:5827  t-loss:0.1464, loss-lb:0.1014, loss-ulb:0.0300, weight:1.50, lr:0.0008
[11:10:39.418] iteration:5828  t-loss:0.1856, loss-lb:0.1129, loss-ulb:0.0484, weight:1.50, lr:0.0008
[11:10:39.610] iteration:5829  t-loss:0.1825, loss-lb:0.1453, loss-ulb:0.0248, weight:1.50, lr:0.0008
[11:10:39.803] iteration:5830  t-loss:0.2093, loss-lb:0.0848, loss-ulb:0.0830, weight:1.50, lr:0.0008
[11:10:39.996] iteration:5831  t-loss:0.1899, loss-lb:0.1073, loss-ulb:0.0551, weight:1.50, lr:0.0008
[11:10:40.188] iteration:5832  t-loss:0.1812, loss-lb:0.1427, loss-ulb:0.0257, weight:1.50, lr:0.0008
[11:10:40.381] iteration:5833  t-loss:0.1399, loss-lb:0.1040, loss-ulb:0.0240, weight:1.50, lr:0.0008
[11:10:40.574] iteration:5834  t-loss:0.1477, loss-lb:0.1000, loss-ulb:0.0318, weight:1.50, lr:0.0008
[11:10:40.766] iteration:5835  t-loss:0.1404, loss-lb:0.1024, loss-ulb:0.0253, weight:1.50, lr:0.0008
[11:10:40.958] iteration:5836  t-loss:0.1456, loss-lb:0.0960, loss-ulb:0.0330, weight:1.50, lr:0.0008
[11:10:41.151] iteration:5837  t-loss:0.1493, loss-lb:0.1100, loss-ulb:0.0262, weight:1.50, lr:0.0008
[11:10:41.343] iteration:5838  t-loss:0.1762, loss-lb:0.1368, loss-ulb:0.0262, weight:1.50, lr:0.0008
[11:10:41.535] iteration:5839  t-loss:0.1643, loss-lb:0.1200, loss-ulb:0.0295, weight:1.50, lr:0.0008
[11:10:41.727] iteration:5840  t-loss:0.1588, loss-lb:0.0996, loss-ulb:0.0395, weight:1.50, lr:0.0008
[11:10:41.919] iteration:5841  t-loss:0.1470, loss-lb:0.1127, loss-ulb:0.0229, weight:1.50, lr:0.0008
[11:10:42.111] iteration:5842  t-loss:0.1435, loss-lb:0.1035, loss-ulb:0.0267, weight:1.50, lr:0.0008
[11:10:42.304] iteration:5843  t-loss:0.1774, loss-lb:0.1101, loss-ulb:0.0448, weight:1.50, lr:0.0008
[11:10:42.497] iteration:5844  t-loss:0.1446, loss-lb:0.0995, loss-ulb:0.0301, weight:1.50, lr:0.0008
[11:10:42.688] iteration:5845  t-loss:0.1595, loss-lb:0.0941, loss-ulb:0.0436, weight:1.50, lr:0.0008
[11:10:42.881] iteration:5846  t-loss:0.1334, loss-lb:0.0998, loss-ulb:0.0224, weight:1.50, lr:0.0008
[11:10:43.073] iteration:5847  t-loss:0.1397, loss-lb:0.0956, loss-ulb:0.0295, weight:1.50, lr:0.0008
[11:10:43.265] iteration:5848  t-loss:0.1939, loss-lb:0.1168, loss-ulb:0.0515, weight:1.50, lr:0.0008
[11:10:43.457] iteration:5849  t-loss:0.1456, loss-lb:0.1100, loss-ulb:0.0238, weight:1.50, lr:0.0008
[11:10:43.649] iteration:5850  t-loss:0.1405, loss-lb:0.1028, loss-ulb:0.0251, weight:1.50, lr:0.0008
[11:10:43.841] iteration:5851  t-loss:0.2007, loss-lb:0.1123, loss-ulb:0.0563, weight:1.57, lr:0.0008
[11:10:44.034] iteration:5852  t-loss:0.1580, loss-lb:0.0904, loss-ulb:0.0431, weight:1.57, lr:0.0008
[11:10:44.226] iteration:5853  t-loss:0.2956, loss-lb:0.1902, loss-ulb:0.0671, weight:1.57, lr:0.0008
[11:10:44.418] iteration:5854  t-loss:0.1649, loss-lb:0.1054, loss-ulb:0.0379, weight:1.57, lr:0.0008
[11:10:44.611] iteration:5855  t-loss:0.2187, loss-lb:0.1035, loss-ulb:0.0733, weight:1.57, lr:0.0008
[11:10:44.803] iteration:5856  t-loss:0.1586, loss-lb:0.1172, loss-ulb:0.0264, weight:1.57, lr:0.0008
[11:10:44.995] iteration:5857  t-loss:0.1663, loss-lb:0.1130, loss-ulb:0.0339, weight:1.57, lr:0.0008
[11:10:45.187] iteration:5858  t-loss:0.1709, loss-lb:0.1056, loss-ulb:0.0416, weight:1.57, lr:0.0008
[11:10:45.381] iteration:5859  t-loss:0.1543, loss-lb:0.1147, loss-ulb:0.0252, weight:1.57, lr:0.0008
[11:10:45.573] iteration:5860  t-loss:0.1685, loss-lb:0.1086, loss-ulb:0.0381, weight:1.57, lr:0.0008
[11:10:45.766] iteration:5861  t-loss:0.3357, loss-lb:0.1254, loss-ulb:0.1339, weight:1.57, lr:0.0008
[11:10:45.958] iteration:5862  t-loss:0.1464, loss-lb:0.1092, loss-ulb:0.0237, weight:1.57, lr:0.0008
[11:10:46.150] iteration:5863  t-loss:0.2022, loss-lb:0.1528, loss-ulb:0.0314, weight:1.57, lr:0.0008
[11:10:46.343] iteration:5864  t-loss:0.2171, loss-lb:0.1133, loss-ulb:0.0661, weight:1.57, lr:0.0008
[11:10:46.535] iteration:5865  t-loss:0.1485, loss-lb:0.1011, loss-ulb:0.0301, weight:1.57, lr:0.0008
[11:10:46.728] iteration:5866  t-loss:0.2599, loss-lb:0.0990, loss-ulb:0.1025, weight:1.57, lr:0.0008
[11:10:46.922] iteration:5867  t-loss:0.1541, loss-lb:0.0958, loss-ulb:0.0371, weight:1.57, lr:0.0008
[11:10:47.127] iteration:5868  t-loss:0.1965, loss-lb:0.1083, loss-ulb:0.0562, weight:1.57, lr:0.0008
[11:10:47.326] iteration:5869  t-loss:0.1395, loss-lb:0.0964, loss-ulb:0.0274, weight:1.57, lr:0.0008
[11:10:47.519] iteration:5870  t-loss:0.1696, loss-lb:0.0980, loss-ulb:0.0456, weight:1.57, lr:0.0008
[11:10:47.711] iteration:5871  t-loss:0.1601, loss-lb:0.1199, loss-ulb:0.0256, weight:1.57, lr:0.0008
[11:10:47.904] iteration:5872  t-loss:0.1974, loss-lb:0.1024, loss-ulb:0.0605, weight:1.57, lr:0.0008
[11:10:48.097] iteration:5873  t-loss:0.2638, loss-lb:0.1012, loss-ulb:0.1036, weight:1.57, lr:0.0008
[11:10:48.287] iteration:5874  t-loss:0.1850, loss-lb:0.1053, loss-ulb:0.0508, weight:1.57, lr:0.0008
[11:10:48.479] iteration:5875  t-loss:0.1878, loss-lb:0.1034, loss-ulb:0.0538, weight:1.57, lr:0.0008
[11:10:48.669] iteration:5876  t-loss:0.2042, loss-lb:0.1124, loss-ulb:0.0584, weight:1.57, lr:0.0008
[11:10:48.861] iteration:5877  t-loss:0.1703, loss-lb:0.1105, loss-ulb:0.0381, weight:1.57, lr:0.0008
[11:10:49.050] iteration:5878  t-loss:0.1789, loss-lb:0.0939, loss-ulb:0.0541, weight:1.57, lr:0.0008
[11:10:49.241] iteration:5879  t-loss:0.1594, loss-lb:0.1056, loss-ulb:0.0343, weight:1.57, lr:0.0008
[11:10:49.432] iteration:5880  t-loss:0.2025, loss-lb:0.1082, loss-ulb:0.0600, weight:1.57, lr:0.0008
[11:10:50.020] iteration:5881  t-loss:0.1486, loss-lb:0.1067, loss-ulb:0.0267, weight:1.57, lr:0.0008
[11:10:50.215] iteration:5882  t-loss:0.2302, loss-lb:0.1302, loss-ulb:0.0637, weight:1.57, lr:0.0008
[11:10:50.408] iteration:5883  t-loss:0.1565, loss-lb:0.1084, loss-ulb:0.0306, weight:1.57, lr:0.0008
[11:10:50.600] iteration:5884  t-loss:0.1684, loss-lb:0.1191, loss-ulb:0.0314, weight:1.57, lr:0.0008
[11:10:50.793] iteration:5885  t-loss:0.1568, loss-lb:0.1203, loss-ulb:0.0232, weight:1.57, lr:0.0008
[11:10:50.986] iteration:5886  t-loss:0.1770, loss-lb:0.1058, loss-ulb:0.0454, weight:1.57, lr:0.0008
[11:10:51.178] iteration:5887  t-loss:0.1691, loss-lb:0.1110, loss-ulb:0.0371, weight:1.57, lr:0.0008
[11:10:51.370] iteration:5888  t-loss:0.1600, loss-lb:0.1019, loss-ulb:0.0370, weight:1.57, lr:0.0008
[11:10:51.562] iteration:5889  t-loss:0.1525, loss-lb:0.1059, loss-ulb:0.0297, weight:1.57, lr:0.0008
[11:10:51.754] iteration:5890  t-loss:0.1446, loss-lb:0.0918, loss-ulb:0.0336, weight:1.57, lr:0.0008
[11:10:51.946] iteration:5891  t-loss:0.1514, loss-lb:0.1113, loss-ulb:0.0256, weight:1.57, lr:0.0008
[11:10:52.138] iteration:5892  t-loss:0.1459, loss-lb:0.0913, loss-ulb:0.0348, weight:1.57, lr:0.0008
[11:10:52.331] iteration:5893  t-loss:0.1493, loss-lb:0.0990, loss-ulb:0.0320, weight:1.57, lr:0.0008
[11:10:52.524] iteration:5894  t-loss:0.1505, loss-lb:0.1040, loss-ulb:0.0296, weight:1.57, lr:0.0008
[11:10:52.718] iteration:5895  t-loss:0.1457, loss-lb:0.0949, loss-ulb:0.0324, weight:1.57, lr:0.0008
[11:10:52.911] iteration:5896  t-loss:0.1912, loss-lb:0.1097, loss-ulb:0.0519, weight:1.57, lr:0.0008
[11:10:53.104] iteration:5897  t-loss:0.1973, loss-lb:0.1091, loss-ulb:0.0562, weight:1.57, lr:0.0008
[11:10:53.296] iteration:5898  t-loss:0.1745, loss-lb:0.0928, loss-ulb:0.0521, weight:1.57, lr:0.0008
[11:10:53.488] iteration:5899  t-loss:0.1376, loss-lb:0.1006, loss-ulb:0.0235, weight:1.57, lr:0.0008
[11:10:53.681] iteration:5900  t-loss:0.1659, loss-lb:0.0929, loss-ulb:0.0464, weight:1.57, lr:0.0008
[11:10:53.874] iteration:5901  t-loss:0.1335, loss-lb:0.0967, loss-ulb:0.0235, weight:1.57, lr:0.0008
[11:10:54.065] iteration:5902  t-loss:0.1418, loss-lb:0.1045, loss-ulb:0.0237, weight:1.57, lr:0.0008
[11:10:54.259] iteration:5903  t-loss:0.1338, loss-lb:0.0933, loss-ulb:0.0258, weight:1.57, lr:0.0008
[11:10:54.453] iteration:5904  t-loss:0.1351, loss-lb:0.0911, loss-ulb:0.0281, weight:1.57, lr:0.0008
[11:10:54.646] iteration:5905  t-loss:0.1519, loss-lb:0.1005, loss-ulb:0.0327, weight:1.57, lr:0.0008
[11:10:54.839] iteration:5906  t-loss:0.1931, loss-lb:0.1199, loss-ulb:0.0466, weight:1.57, lr:0.0008
[11:10:55.032] iteration:5907  t-loss:0.1485, loss-lb:0.1078, loss-ulb:0.0259, weight:1.57, lr:0.0008
[11:10:55.225] iteration:5908  t-loss:0.1481, loss-lb:0.0949, loss-ulb:0.0339, weight:1.57, lr:0.0008
[11:10:55.417] iteration:5909  t-loss:0.1757, loss-lb:0.1122, loss-ulb:0.0404, weight:1.57, lr:0.0008
[11:10:55.609] iteration:5910  t-loss:0.1491, loss-lb:0.1096, loss-ulb:0.0252, weight:1.57, lr:0.0008
[11:10:55.801] iteration:5911  t-loss:0.1595, loss-lb:0.1074, loss-ulb:0.0332, weight:1.57, lr:0.0008
[11:10:55.994] iteration:5912  t-loss:0.1388, loss-lb:0.1010, loss-ulb:0.0241, weight:1.57, lr:0.0008
[11:10:56.186] iteration:5913  t-loss:0.1381, loss-lb:0.0985, loss-ulb:0.0252, weight:1.57, lr:0.0008
[11:10:56.380] iteration:5914  t-loss:0.1511, loss-lb:0.1077, loss-ulb:0.0277, weight:1.57, lr:0.0008
[11:10:56.572] iteration:5915  t-loss:0.1372, loss-lb:0.0974, loss-ulb:0.0254, weight:1.57, lr:0.0008
[11:10:56.765] iteration:5916  t-loss:0.1596, loss-lb:0.1057, loss-ulb:0.0343, weight:1.57, lr:0.0008
[11:10:56.956] iteration:5917  t-loss:0.1371, loss-lb:0.0984, loss-ulb:0.0247, weight:1.57, lr:0.0008
[11:10:57.149] iteration:5918  t-loss:0.1465, loss-lb:0.1091, loss-ulb:0.0238, weight:1.57, lr:0.0008
[11:10:57.342] iteration:5919  t-loss:0.2312, loss-lb:0.1025, loss-ulb:0.0820, weight:1.57, lr:0.0008
[11:10:57.534] iteration:5920  t-loss:0.1362, loss-lb:0.1016, loss-ulb:0.0220, weight:1.57, lr:0.0008
[11:10:57.726] iteration:5921  t-loss:0.2732, loss-lb:0.0952, loss-ulb:0.1133, weight:1.57, lr:0.0008
[11:10:57.918] iteration:5922  t-loss:0.1717, loss-lb:0.1025, loss-ulb:0.0441, weight:1.57, lr:0.0008
[11:10:58.110] iteration:5923  t-loss:0.1657, loss-lb:0.1249, loss-ulb:0.0260, weight:1.57, lr:0.0008
[11:10:58.302] iteration:5924  t-loss:0.1633, loss-lb:0.1104, loss-ulb:0.0337, weight:1.57, lr:0.0008
[11:10:58.495] iteration:5925  t-loss:0.1544, loss-lb:0.1054, loss-ulb:0.0312, weight:1.57, lr:0.0008
[11:10:58.687] iteration:5926  t-loss:0.1793, loss-lb:0.1034, loss-ulb:0.0484, weight:1.57, lr:0.0008
[11:10:58.880] iteration:5927  t-loss:0.1449, loss-lb:0.0969, loss-ulb:0.0306, weight:1.57, lr:0.0008
[11:10:59.073] iteration:5928  t-loss:0.1849, loss-lb:0.1070, loss-ulb:0.0496, weight:1.57, lr:0.0008
[11:10:59.265] iteration:5929  t-loss:0.1647, loss-lb:0.1224, loss-ulb:0.0270, weight:1.57, lr:0.0008
[11:10:59.457] iteration:5930  t-loss:0.1934, loss-lb:0.1055, loss-ulb:0.0560, weight:1.57, lr:0.0008
[11:10:59.649] iteration:5931  t-loss:0.1651, loss-lb:0.1038, loss-ulb:0.0390, weight:1.57, lr:0.0008
[11:10:59.842] iteration:5932  t-loss:0.1539, loss-lb:0.1069, loss-ulb:0.0299, weight:1.57, lr:0.0008
[11:11:00.035] iteration:5933  t-loss:0.2650, loss-lb:0.1121, loss-ulb:0.0974, weight:1.57, lr:0.0008
[11:11:00.227] iteration:5934  t-loss:0.1743, loss-lb:0.1231, loss-ulb:0.0326, weight:1.57, lr:0.0008
[11:11:00.420] iteration:5935  t-loss:0.1609, loss-lb:0.1053, loss-ulb:0.0354, weight:1.57, lr:0.0008
[11:11:00.615] iteration:5936  t-loss:0.1889, loss-lb:0.1135, loss-ulb:0.0480, weight:1.57, lr:0.0008
[11:11:00.809] iteration:5937  t-loss:0.1719, loss-lb:0.1071, loss-ulb:0.0413, weight:1.57, lr:0.0008
[11:11:01.001] iteration:5938  t-loss:0.1600, loss-lb:0.1128, loss-ulb:0.0301, weight:1.57, lr:0.0008
[11:11:01.192] iteration:5939  t-loss:0.1731, loss-lb:0.1129, loss-ulb:0.0383, weight:1.57, lr:0.0008
[11:11:01.385] iteration:5940  t-loss:0.1671, loss-lb:0.1058, loss-ulb:0.0390, weight:1.57, lr:0.0008
[11:11:01.577] iteration:5941  t-loss:0.1664, loss-lb:0.1058, loss-ulb:0.0386, weight:1.57, lr:0.0008
[11:11:01.769] iteration:5942  t-loss:0.1445, loss-lb:0.1031, loss-ulb:0.0263, weight:1.57, lr:0.0008
[11:11:01.963] iteration:5943  t-loss:0.1992, loss-lb:0.0970, loss-ulb:0.0651, weight:1.57, lr:0.0008
[11:11:02.154] iteration:5944  t-loss:0.1512, loss-lb:0.1019, loss-ulb:0.0314, weight:1.57, lr:0.0008
[11:11:02.346] iteration:5945  t-loss:0.1784, loss-lb:0.1107, loss-ulb:0.0431, weight:1.57, lr:0.0008
[11:11:02.538] iteration:5946  t-loss:0.1506, loss-lb:0.1052, loss-ulb:0.0289, weight:1.57, lr:0.0008
[11:11:02.732] iteration:5947  t-loss:0.1969, loss-lb:0.1221, loss-ulb:0.0476, weight:1.57, lr:0.0008
[11:11:02.923] iteration:5948  t-loss:0.1886, loss-lb:0.1447, loss-ulb:0.0280, weight:1.57, lr:0.0008
[11:11:03.116] iteration:5949  t-loss:0.1598, loss-lb:0.1149, loss-ulb:0.0286, weight:1.57, lr:0.0008
[11:11:03.308] iteration:5950  t-loss:0.1469, loss-lb:0.0992, loss-ulb:0.0303, weight:1.57, lr:0.0008
[11:11:03.500] iteration:5951  t-loss:0.1503, loss-lb:0.1058, loss-ulb:0.0284, weight:1.57, lr:0.0008
[11:11:03.692] iteration:5952  t-loss:0.1410, loss-lb:0.1017, loss-ulb:0.0250, weight:1.57, lr:0.0008
[11:11:03.883] iteration:5953  t-loss:0.2016, loss-lb:0.1362, loss-ulb:0.0417, weight:1.57, lr:0.0008
[11:11:04.077] iteration:5954  t-loss:0.2198, loss-lb:0.1039, loss-ulb:0.0739, weight:1.57, lr:0.0008
[11:11:04.269] iteration:5955  t-loss:0.1595, loss-lb:0.1074, loss-ulb:0.0331, weight:1.57, lr:0.0008
[11:11:04.460] iteration:5956  t-loss:0.1696, loss-lb:0.1093, loss-ulb:0.0384, weight:1.57, lr:0.0008
[11:11:04.653] iteration:5957  t-loss:0.1852, loss-lb:0.1054, loss-ulb:0.0508, weight:1.57, lr:0.0008
[11:11:04.845] iteration:5958  t-loss:0.1373, loss-lb:0.0960, loss-ulb:0.0263, weight:1.57, lr:0.0008
[11:11:05.037] iteration:5959  t-loss:0.1485, loss-lb:0.1069, loss-ulb:0.0265, weight:1.57, lr:0.0008
[11:11:05.229] iteration:5960  t-loss:0.1546, loss-lb:0.1065, loss-ulb:0.0306, weight:1.57, lr:0.0008
[11:11:05.422] iteration:5961  t-loss:0.1396, loss-lb:0.1011, loss-ulb:0.0245, weight:1.57, lr:0.0008
[11:11:05.613] iteration:5962  t-loss:0.1400, loss-lb:0.1009, loss-ulb:0.0249, weight:1.57, lr:0.0008
[11:11:05.806] iteration:5963  t-loss:0.1533, loss-lb:0.1053, loss-ulb:0.0306, weight:1.57, lr:0.0008
[11:11:05.997] iteration:5964  t-loss:0.1325, loss-lb:0.0861, loss-ulb:0.0296, weight:1.57, lr:0.0008
[11:11:06.190] iteration:5965  t-loss:0.1531, loss-lb:0.1085, loss-ulb:0.0284, weight:1.57, lr:0.0008
[11:11:06.383] iteration:5966  t-loss:0.1603, loss-lb:0.0979, loss-ulb:0.0397, weight:1.57, lr:0.0008
[11:11:06.576] iteration:5967  t-loss:0.1514, loss-lb:0.0966, loss-ulb:0.0348, weight:1.57, lr:0.0008
[11:11:06.768] iteration:5968  t-loss:0.1481, loss-lb:0.1005, loss-ulb:0.0303, weight:1.57, lr:0.0008
[11:11:06.960] iteration:5969  t-loss:0.1409, loss-lb:0.0999, loss-ulb:0.0261, weight:1.57, lr:0.0008
[11:11:07.152] iteration:5970  t-loss:0.1270, loss-lb:0.0897, loss-ulb:0.0237, weight:1.57, lr:0.0008
[11:11:07.343] iteration:5971  t-loss:0.1361, loss-lb:0.0937, loss-ulb:0.0270, weight:1.57, lr:0.0008
[11:11:07.534] iteration:5972  t-loss:0.1421, loss-lb:0.0961, loss-ulb:0.0293, weight:1.57, lr:0.0008
[11:11:07.726] iteration:5973  t-loss:0.2133, loss-lb:0.0973, loss-ulb:0.0738, weight:1.57, lr:0.0008
[11:11:07.916] iteration:5974  t-loss:0.1350, loss-lb:0.0995, loss-ulb:0.0226, weight:1.57, lr:0.0008
[11:11:08.106] iteration:5975  t-loss:0.1307, loss-lb:0.0940, loss-ulb:0.0234, weight:1.57, lr:0.0008
[11:11:08.296] iteration:5976  t-loss:0.2071, loss-lb:0.1503, loss-ulb:0.0362, weight:1.57, lr:0.0008
[11:11:08.486] iteration:5977  t-loss:0.1486, loss-lb:0.1026, loss-ulb:0.0293, weight:1.57, lr:0.0008
[11:11:08.677] iteration:5978  t-loss:0.1441, loss-lb:0.1084, loss-ulb:0.0227, weight:1.57, lr:0.0008
[11:11:19.862]  <<Test>> - Ep:60  - mean_dice/mean_h95 - S:89.58/1.44, Best-S:89.92, T:89.96/1.38, Best-T:90.22
[11:11:19.862]           - AvgLoss(lb/ulb/all):0.1057/0.0307/0.1503
[11:11:20.390] iteration:5979  t-loss:0.1390, loss-lb:0.0949, loss-ulb:0.0280, weight:1.57, lr:0.0008
[11:11:20.591] iteration:5980  t-loss:0.1504, loss-lb:0.1037, loss-ulb:0.0297, weight:1.57, lr:0.0008
[11:11:20.784] iteration:5981  t-loss:0.1385, loss-lb:0.1044, loss-ulb:0.0217, weight:1.57, lr:0.0008
[11:11:20.977] iteration:5982  t-loss:0.1618, loss-lb:0.1027, loss-ulb:0.0377, weight:1.57, lr:0.0008
[11:11:21.170] iteration:5983  t-loss:0.1358, loss-lb:0.1023, loss-ulb:0.0213, weight:1.57, lr:0.0008
[11:11:21.363] iteration:5984  t-loss:0.1324, loss-lb:0.0999, loss-ulb:0.0207, weight:1.57, lr:0.0008
[11:11:21.555] iteration:5985  t-loss:0.1552, loss-lb:0.0989, loss-ulb:0.0358, weight:1.57, lr:0.0008
[11:11:21.747] iteration:5986  t-loss:0.1660, loss-lb:0.1254, loss-ulb:0.0259, weight:1.57, lr:0.0008
[11:11:21.942] iteration:5987  t-loss:0.1378, loss-lb:0.0904, loss-ulb:0.0301, weight:1.57, lr:0.0008
[11:11:22.134] iteration:5988  t-loss:0.1411, loss-lb:0.1039, loss-ulb:0.0236, weight:1.57, lr:0.0008
[11:11:22.327] iteration:5989  t-loss:0.1376, loss-lb:0.0924, loss-ulb:0.0288, weight:1.57, lr:0.0008
[11:11:22.521] iteration:5990  t-loss:0.1756, loss-lb:0.1009, loss-ulb:0.0476, weight:1.57, lr:0.0008
[11:11:22.713] iteration:5991  t-loss:0.1375, loss-lb:0.0949, loss-ulb:0.0272, weight:1.57, lr:0.0008
[11:11:22.905] iteration:5992  t-loss:0.1461, loss-lb:0.1023, loss-ulb:0.0279, weight:1.57, lr:0.0008
[11:11:23.096] iteration:5993  t-loss:0.1383, loss-lb:0.0955, loss-ulb:0.0272, weight:1.57, lr:0.0008
[11:11:23.287] iteration:5994  t-loss:0.1288, loss-lb:0.0913, loss-ulb:0.0239, weight:1.57, lr:0.0008
[11:11:23.479] iteration:5995  t-loss:0.1955, loss-lb:0.1320, loss-ulb:0.0405, weight:1.57, lr:0.0008
[11:11:23.670] iteration:5996  t-loss:0.1419, loss-lb:0.0892, loss-ulb:0.0336, weight:1.57, lr:0.0008
[11:11:23.863] iteration:5997  t-loss:0.1263, loss-lb:0.0890, loss-ulb:0.0238, weight:1.57, lr:0.0008
[11:11:24.054] iteration:5998  t-loss:0.1312, loss-lb:0.0935, loss-ulb:0.0240, weight:1.57, lr:0.0008
[11:11:24.245] iteration:5999  t-loss:0.1462, loss-lb:0.1023, loss-ulb:0.0279, weight:1.57, lr:0.0008
[11:11:24.437] iteration:6000  t-loss:0.1307, loss-lb:0.0978, loss-ulb:0.0210, weight:1.57, lr:0.0008
[11:11:24.630] iteration:6001  t-loss:0.1308, loss-lb:0.0964, loss-ulb:0.0210, weight:1.64, lr:0.0008
[11:11:24.821] iteration:6002  t-loss:0.1412, loss-lb:0.0836, loss-ulb:0.0352, weight:1.64, lr:0.0008
[11:11:25.014] iteration:6003  t-loss:0.1504, loss-lb:0.0975, loss-ulb:0.0323, weight:1.64, lr:0.0008
[11:11:25.205] iteration:6004  t-loss:0.1506, loss-lb:0.1061, loss-ulb:0.0272, weight:1.64, lr:0.0008
[11:11:25.396] iteration:6005  t-loss:0.1418, loss-lb:0.1016, loss-ulb:0.0245, weight:1.64, lr:0.0008
[11:11:25.588] iteration:6006  t-loss:0.1384, loss-lb:0.0980, loss-ulb:0.0247, weight:1.64, lr:0.0008
[11:11:25.779] iteration:6007  t-loss:0.1359, loss-lb:0.0869, loss-ulb:0.0300, weight:1.64, lr:0.0008
[11:11:25.971] iteration:6008  t-loss:0.1467, loss-lb:0.0998, loss-ulb:0.0286, weight:1.64, lr:0.0008
[11:11:26.162] iteration:6009  t-loss:0.1565, loss-lb:0.0955, loss-ulb:0.0373, weight:1.64, lr:0.0008
[11:11:26.355] iteration:6010  t-loss:0.1440, loss-lb:0.0992, loss-ulb:0.0273, weight:1.64, lr:0.0008
[11:11:26.546] iteration:6011  t-loss:0.1398, loss-lb:0.0955, loss-ulb:0.0271, weight:1.64, lr:0.0008
[11:11:26.737] iteration:6012  t-loss:0.1385, loss-lb:0.0968, loss-ulb:0.0255, weight:1.64, lr:0.0008
[11:11:26.930] iteration:6013  t-loss:0.1422, loss-lb:0.1045, loss-ulb:0.0230, weight:1.64, lr:0.0008
[11:11:27.120] iteration:6014  t-loss:0.1411, loss-lb:0.0990, loss-ulb:0.0257, weight:1.64, lr:0.0008
[11:11:27.312] iteration:6015  t-loss:0.1404, loss-lb:0.0979, loss-ulb:0.0260, weight:1.64, lr:0.0008
[11:11:27.502] iteration:6016  t-loss:0.1360, loss-lb:0.0976, loss-ulb:0.0234, weight:1.64, lr:0.0008
[11:11:27.693] iteration:6017  t-loss:0.1580, loss-lb:0.0924, loss-ulb:0.0401, weight:1.64, lr:0.0008
[11:11:27.883] iteration:6018  t-loss:0.1319, loss-lb:0.0958, loss-ulb:0.0220, weight:1.64, lr:0.0008
[11:11:28.075] iteration:6019  t-loss:0.1409, loss-lb:0.0963, loss-ulb:0.0272, weight:1.64, lr:0.0008
[11:11:28.268] iteration:6020  t-loss:0.1452, loss-lb:0.1028, loss-ulb:0.0259, weight:1.64, lr:0.0008
[11:11:28.463] iteration:6021  t-loss:0.1633, loss-lb:0.1077, loss-ulb:0.0340, weight:1.64, lr:0.0008
[11:11:28.661] iteration:6022  t-loss:0.1313, loss-lb:0.0873, loss-ulb:0.0269, weight:1.64, lr:0.0008
[11:11:28.858] iteration:6023  t-loss:0.1398, loss-lb:0.0938, loss-ulb:0.0281, weight:1.64, lr:0.0008
[11:11:29.051] iteration:6024  t-loss:0.1426, loss-lb:0.1045, loss-ulb:0.0233, weight:1.64, lr:0.0008
[11:11:29.243] iteration:6025  t-loss:0.1370, loss-lb:0.0977, loss-ulb:0.0240, weight:1.64, lr:0.0008
[11:11:29.434] iteration:6026  t-loss:0.1798, loss-lb:0.0861, loss-ulb:0.0572, weight:1.64, lr:0.0008
[11:11:29.626] iteration:6027  t-loss:0.1621, loss-lb:0.0970, loss-ulb:0.0398, weight:1.64, lr:0.0008
[11:11:29.818] iteration:6028  t-loss:0.1297, loss-lb:0.0908, loss-ulb:0.0238, weight:1.64, lr:0.0008
[11:11:30.010] iteration:6029  t-loss:0.1344, loss-lb:0.0906, loss-ulb:0.0268, weight:1.64, lr:0.0008
[11:11:30.201] iteration:6030  t-loss:0.1322, loss-lb:0.0907, loss-ulb:0.0254, weight:1.64, lr:0.0008
[11:11:30.393] iteration:6031  t-loss:0.1829, loss-lb:0.1324, loss-ulb:0.0309, weight:1.64, lr:0.0008
[11:11:30.584] iteration:6032  t-loss:0.1749, loss-lb:0.0945, loss-ulb:0.0491, weight:1.64, lr:0.0008
[11:11:30.777] iteration:6033  t-loss:0.1643, loss-lb:0.0989, loss-ulb:0.0400, weight:1.64, lr:0.0008
[11:11:30.969] iteration:6034  t-loss:0.1401, loss-lb:0.0989, loss-ulb:0.0252, weight:1.64, lr:0.0008
[11:11:31.161] iteration:6035  t-loss:0.1407, loss-lb:0.1028, loss-ulb:0.0231, weight:1.64, lr:0.0008
[11:11:31.353] iteration:6036  t-loss:0.1854, loss-lb:0.1051, loss-ulb:0.0490, weight:1.64, lr:0.0008
[11:11:31.545] iteration:6037  t-loss:0.1855, loss-lb:0.1142, loss-ulb:0.0435, weight:1.64, lr:0.0008
[11:11:31.737] iteration:6038  t-loss:0.1484, loss-lb:0.0967, loss-ulb:0.0316, weight:1.64, lr:0.0008
[11:11:31.930] iteration:6039  t-loss:0.1345, loss-lb:0.0927, loss-ulb:0.0255, weight:1.64, lr:0.0008
[11:11:32.121] iteration:6040  t-loss:0.1516, loss-lb:0.1054, loss-ulb:0.0283, weight:1.64, lr:0.0008
[11:11:32.313] iteration:6041  t-loss:0.1847, loss-lb:0.1007, loss-ulb:0.0513, weight:1.64, lr:0.0008
[11:11:32.506] iteration:6042  t-loss:0.1229, loss-lb:0.0857, loss-ulb:0.0228, weight:1.64, lr:0.0008
[11:11:32.697] iteration:6043  t-loss:0.2311, loss-lb:0.0880, loss-ulb:0.0874, weight:1.64, lr:0.0008
[11:11:32.890] iteration:6044  t-loss:0.1574, loss-lb:0.1030, loss-ulb:0.0332, weight:1.64, lr:0.0008
[11:11:33.081] iteration:6045  t-loss:0.1659, loss-lb:0.1011, loss-ulb:0.0395, weight:1.64, lr:0.0008
[11:11:33.272] iteration:6046  t-loss:0.2682, loss-lb:0.0966, loss-ulb:0.1048, weight:1.64, lr:0.0008
[11:11:33.465] iteration:6047  t-loss:0.1542, loss-lb:0.0999, loss-ulb:0.0332, weight:1.64, lr:0.0008
[11:11:33.656] iteration:6048  t-loss:0.1251, loss-lb:0.0871, loss-ulb:0.0232, weight:1.64, lr:0.0008
[11:11:33.848] iteration:6049  t-loss:0.1483, loss-lb:0.1037, loss-ulb:0.0272, weight:1.64, lr:0.0008
[11:11:34.040] iteration:6050  t-loss:0.1470, loss-lb:0.1007, loss-ulb:0.0283, weight:1.64, lr:0.0008
[11:11:34.238] iteration:6051  t-loss:0.1953, loss-lb:0.1360, loss-ulb:0.0362, weight:1.64, lr:0.0008
[11:11:34.429] iteration:6052  t-loss:0.1441, loss-lb:0.1054, loss-ulb:0.0236, weight:1.64, lr:0.0008
[11:11:34.619] iteration:6053  t-loss:0.1901, loss-lb:0.1351, loss-ulb:0.0336, weight:1.64, lr:0.0008
[11:11:34.812] iteration:6054  t-loss:0.1584, loss-lb:0.1074, loss-ulb:0.0311, weight:1.64, lr:0.0008
[11:11:35.003] iteration:6055  t-loss:0.2326, loss-lb:0.1019, loss-ulb:0.0798, weight:1.64, lr:0.0008
[11:11:35.197] iteration:6056  t-loss:0.1677, loss-lb:0.0959, loss-ulb:0.0439, weight:1.64, lr:0.0008
[11:11:35.389] iteration:6057  t-loss:0.1495, loss-lb:0.1099, loss-ulb:0.0242, weight:1.64, lr:0.0008
[11:11:35.581] iteration:6058  t-loss:0.1708, loss-lb:0.1032, loss-ulb:0.0413, weight:1.64, lr:0.0008
[11:11:35.772] iteration:6059  t-loss:0.1636, loss-lb:0.1130, loss-ulb:0.0309, weight:1.64, lr:0.0008
[11:11:35.964] iteration:6060  t-loss:0.1757, loss-lb:0.1324, loss-ulb:0.0264, weight:1.64, lr:0.0008
[11:11:36.155] iteration:6061  t-loss:0.1658, loss-lb:0.0949, loss-ulb:0.0433, weight:1.64, lr:0.0008
[11:11:36.347] iteration:6062  t-loss:0.1615, loss-lb:0.1069, loss-ulb:0.0333, weight:1.64, lr:0.0008
[11:11:36.538] iteration:6063  t-loss:0.1916, loss-lb:0.1081, loss-ulb:0.0510, weight:1.64, lr:0.0008
[11:11:36.730] iteration:6064  t-loss:0.1433, loss-lb:0.0979, loss-ulb:0.0277, weight:1.64, lr:0.0008
[11:11:36.922] iteration:6065  t-loss:0.1591, loss-lb:0.1076, loss-ulb:0.0315, weight:1.64, lr:0.0008
[11:11:37.113] iteration:6066  t-loss:0.1595, loss-lb:0.0974, loss-ulb:0.0379, weight:1.64, lr:0.0008
[11:11:37.304] iteration:6067  t-loss:0.1550, loss-lb:0.1091, loss-ulb:0.0281, weight:1.64, lr:0.0008
[11:11:37.495] iteration:6068  t-loss:0.1662, loss-lb:0.1154, loss-ulb:0.0310, weight:1.64, lr:0.0008
[11:11:37.686] iteration:6069  t-loss:0.1764, loss-lb:0.1207, loss-ulb:0.0340, weight:1.64, lr:0.0008
[11:11:37.876] iteration:6070  t-loss:0.1645, loss-lb:0.1088, loss-ulb:0.0340, weight:1.64, lr:0.0008
[11:11:38.067] iteration:6071  t-loss:0.1585, loss-lb:0.1016, loss-ulb:0.0348, weight:1.64, lr:0.0008
[11:11:38.258] iteration:6072  t-loss:0.1422, loss-lb:0.1022, loss-ulb:0.0244, weight:1.64, lr:0.0008
[11:11:38.448] iteration:6073  t-loss:0.1555, loss-lb:0.1055, loss-ulb:0.0305, weight:1.64, lr:0.0008
[11:11:38.637] iteration:6074  t-loss:0.2427, loss-lb:0.1087, loss-ulb:0.0818, weight:1.64, lr:0.0008
[11:11:38.828] iteration:6075  t-loss:0.1482, loss-lb:0.0992, loss-ulb:0.0299, weight:1.64, lr:0.0008
[11:11:39.020] iteration:6076  t-loss:0.1395, loss-lb:0.0956, loss-ulb:0.0268, weight:1.64, lr:0.0008
[11:11:39.662] iteration:6077  t-loss:0.1659, loss-lb:0.1103, loss-ulb:0.0340, weight:1.64, lr:0.0008
[11:11:39.862] iteration:6078  t-loss:0.1710, loss-lb:0.1006, loss-ulb:0.0430, weight:1.64, lr:0.0008
[11:11:40.054] iteration:6079  t-loss:0.1329, loss-lb:0.0912, loss-ulb:0.0255, weight:1.64, lr:0.0008
[11:11:40.247] iteration:6080  t-loss:0.1449, loss-lb:0.1049, loss-ulb:0.0245, weight:1.64, lr:0.0008
[11:11:40.439] iteration:6081  t-loss:0.1470, loss-lb:0.0921, loss-ulb:0.0335, weight:1.64, lr:0.0008
[11:11:40.632] iteration:6082  t-loss:0.1687, loss-lb:0.1185, loss-ulb:0.0306, weight:1.64, lr:0.0008
[11:11:40.824] iteration:6083  t-loss:0.1852, loss-lb:0.1353, loss-ulb:0.0305, weight:1.64, lr:0.0008
[11:11:41.017] iteration:6084  t-loss:0.1420, loss-lb:0.0963, loss-ulb:0.0279, weight:1.64, lr:0.0008
[11:11:41.208] iteration:6085  t-loss:0.1433, loss-lb:0.0979, loss-ulb:0.0277, weight:1.64, lr:0.0008
[11:11:41.399] iteration:6086  t-loss:0.1489, loss-lb:0.0891, loss-ulb:0.0365, weight:1.64, lr:0.0008
[11:11:41.591] iteration:6087  t-loss:0.1432, loss-lb:0.0990, loss-ulb:0.0270, weight:1.64, lr:0.0008
[11:11:41.783] iteration:6088  t-loss:0.1658, loss-lb:0.1207, loss-ulb:0.0275, weight:1.64, lr:0.0008
[11:11:41.975] iteration:6089  t-loss:0.1475, loss-lb:0.0914, loss-ulb:0.0343, weight:1.64, lr:0.0008
[11:11:42.168] iteration:6090  t-loss:0.1477, loss-lb:0.0995, loss-ulb:0.0294, weight:1.64, lr:0.0008
[11:11:42.358] iteration:6091  t-loss:0.1420, loss-lb:0.1056, loss-ulb:0.0222, weight:1.64, lr:0.0008
[11:11:42.551] iteration:6092  t-loss:0.1436, loss-lb:0.0960, loss-ulb:0.0291, weight:1.64, lr:0.0008
[11:11:42.743] iteration:6093  t-loss:0.1677, loss-lb:0.0950, loss-ulb:0.0444, weight:1.64, lr:0.0008
[11:11:42.934] iteration:6094  t-loss:0.1984, loss-lb:0.0941, loss-ulb:0.0637, weight:1.64, lr:0.0008
[11:11:43.127] iteration:6095  t-loss:0.1656, loss-lb:0.0979, loss-ulb:0.0414, weight:1.64, lr:0.0008
[11:11:43.320] iteration:6096  t-loss:0.1689, loss-lb:0.1050, loss-ulb:0.0390, weight:1.64, lr:0.0008
[11:11:43.512] iteration:6097  t-loss:0.1389, loss-lb:0.1002, loss-ulb:0.0237, weight:1.64, lr:0.0008
[11:11:43.704] iteration:6098  t-loss:0.1459, loss-lb:0.1028, loss-ulb:0.0263, weight:1.64, lr:0.0008
[11:11:43.897] iteration:6099  t-loss:0.1284, loss-lb:0.0917, loss-ulb:0.0224, weight:1.64, lr:0.0008
[11:11:44.089] iteration:6100  t-loss:0.1534, loss-lb:0.0938, loss-ulb:0.0364, weight:1.64, lr:0.0008
[11:11:44.282] iteration:6101  t-loss:0.1892, loss-lb:0.1033, loss-ulb:0.0525, weight:1.64, lr:0.0008
[11:11:44.474] iteration:6102  t-loss:0.1422, loss-lb:0.1031, loss-ulb:0.0239, weight:1.64, lr:0.0008
[11:11:44.666] iteration:6103  t-loss:0.1327, loss-lb:0.0852, loss-ulb:0.0290, weight:1.64, lr:0.0008
[11:11:44.858] iteration:6104  t-loss:0.2456, loss-lb:0.0999, loss-ulb:0.0890, weight:1.64, lr:0.0008
[11:11:45.050] iteration:6105  t-loss:0.1385, loss-lb:0.0950, loss-ulb:0.0266, weight:1.64, lr:0.0008
[11:11:45.241] iteration:6106  t-loss:0.1628, loss-lb:0.0963, loss-ulb:0.0406, weight:1.64, lr:0.0008
[11:11:45.434] iteration:6107  t-loss:0.1945, loss-lb:0.0996, loss-ulb:0.0580, weight:1.64, lr:0.0008
[11:11:45.627] iteration:6108  t-loss:0.1544, loss-lb:0.1041, loss-ulb:0.0307, weight:1.64, lr:0.0008
[11:11:45.818] iteration:6109  t-loss:0.2006, loss-lb:0.0919, loss-ulb:0.0664, weight:1.64, lr:0.0008
[11:11:46.011] iteration:6110  t-loss:0.1769, loss-lb:0.1385, loss-ulb:0.0234, weight:1.64, lr:0.0008
[11:11:46.203] iteration:6111  t-loss:0.1433, loss-lb:0.1000, loss-ulb:0.0265, weight:1.64, lr:0.0008
[11:11:46.395] iteration:6112  t-loss:0.1428, loss-lb:0.0945, loss-ulb:0.0295, weight:1.64, lr:0.0008
[11:11:46.587] iteration:6113  t-loss:0.1840, loss-lb:0.0934, loss-ulb:0.0553, weight:1.64, lr:0.0008
[11:11:46.779] iteration:6114  t-loss:0.2485, loss-lb:0.0993, loss-ulb:0.0911, weight:1.64, lr:0.0008
[11:11:46.972] iteration:6115  t-loss:0.1529, loss-lb:0.0961, loss-ulb:0.0347, weight:1.64, lr:0.0008
[11:11:47.163] iteration:6116  t-loss:0.1512, loss-lb:0.1092, loss-ulb:0.0257, weight:1.64, lr:0.0008
[11:11:47.354] iteration:6117  t-loss:0.1614, loss-lb:0.1167, loss-ulb:0.0273, weight:1.64, lr:0.0008
[11:11:47.545] iteration:6118  t-loss:0.2418, loss-lb:0.1232, loss-ulb:0.0724, weight:1.64, lr:0.0008
[11:11:47.736] iteration:6119  t-loss:0.1625, loss-lb:0.1042, loss-ulb:0.0356, weight:1.64, lr:0.0008
[11:11:47.928] iteration:6120  t-loss:0.1892, loss-lb:0.1421, loss-ulb:0.0288, weight:1.64, lr:0.0008
[11:11:48.119] iteration:6121  t-loss:0.1501, loss-lb:0.1006, loss-ulb:0.0303, weight:1.64, lr:0.0008
[11:11:48.310] iteration:6122  t-loss:0.1596, loss-lb:0.1110, loss-ulb:0.0297, weight:1.64, lr:0.0008
[11:11:48.502] iteration:6123  t-loss:0.1975, loss-lb:0.0991, loss-ulb:0.0601, weight:1.64, lr:0.0008
[11:11:48.694] iteration:6124  t-loss:0.1635, loss-lb:0.1257, loss-ulb:0.0231, weight:1.64, lr:0.0008
[11:11:48.885] iteration:6125  t-loss:0.1431, loss-lb:0.1091, loss-ulb:0.0208, weight:1.64, lr:0.0008
[11:11:49.077] iteration:6126  t-loss:0.1460, loss-lb:0.1010, loss-ulb:0.0275, weight:1.64, lr:0.0008
[11:11:49.267] iteration:6127  t-loss:0.1728, loss-lb:0.1175, loss-ulb:0.0337, weight:1.64, lr:0.0008
[11:11:49.459] iteration:6128  t-loss:0.2538, loss-lb:0.1230, loss-ulb:0.0799, weight:1.64, lr:0.0008
[11:11:49.651] iteration:6129  t-loss:0.1931, loss-lb:0.1060, loss-ulb:0.0532, weight:1.64, lr:0.0008
[11:11:49.844] iteration:6130  t-loss:0.1489, loss-lb:0.0974, loss-ulb:0.0314, weight:1.64, lr:0.0008
[11:11:50.039] iteration:6131  t-loss:0.1553, loss-lb:0.0936, loss-ulb:0.0376, weight:1.64, lr:0.0008
[11:11:50.233] iteration:6132  t-loss:0.1669, loss-lb:0.1144, loss-ulb:0.0321, weight:1.64, lr:0.0008
[11:11:50.426] iteration:6133  t-loss:0.1767, loss-lb:0.1184, loss-ulb:0.0356, weight:1.64, lr:0.0008
[11:11:50.618] iteration:6134  t-loss:0.1577, loss-lb:0.1022, loss-ulb:0.0339, weight:1.64, lr:0.0008
[11:11:50.811] iteration:6135  t-loss:0.1827, loss-lb:0.1260, loss-ulb:0.0346, weight:1.64, lr:0.0008
[11:11:51.003] iteration:6136  t-loss:0.1785, loss-lb:0.1073, loss-ulb:0.0435, weight:1.64, lr:0.0008
[11:11:51.196] iteration:6137  t-loss:0.1870, loss-lb:0.1088, loss-ulb:0.0478, weight:1.64, lr:0.0008
[11:11:51.387] iteration:6138  t-loss:0.2546, loss-lb:0.1093, loss-ulb:0.0887, weight:1.64, lr:0.0008
[11:11:51.579] iteration:6139  t-loss:0.1469, loss-lb:0.1025, loss-ulb:0.0271, weight:1.64, lr:0.0008
[11:11:51.772] iteration:6140  t-loss:0.1673, loss-lb:0.1025, loss-ulb:0.0396, weight:1.64, lr:0.0008
[11:11:51.963] iteration:6141  t-loss:0.1909, loss-lb:0.1350, loss-ulb:0.0341, weight:1.64, lr:0.0008
[11:11:52.155] iteration:6142  t-loss:0.1889, loss-lb:0.1030, loss-ulb:0.0524, weight:1.64, lr:0.0008
[11:11:52.346] iteration:6143  t-loss:0.1843, loss-lb:0.1139, loss-ulb:0.0430, weight:1.64, lr:0.0008
[11:11:52.550] iteration:6144  t-loss:0.1545, loss-lb:0.1128, loss-ulb:0.0255, weight:1.64, lr:0.0008
[11:11:52.747] iteration:6145  t-loss:0.1568, loss-lb:0.0973, loss-ulb:0.0363, weight:1.64, lr:0.0008
[11:11:52.943] iteration:6146  t-loss:0.1565, loss-lb:0.0929, loss-ulb:0.0389, weight:1.64, lr:0.0008
[11:11:53.134] iteration:6147  t-loss:0.1738, loss-lb:0.1175, loss-ulb:0.0344, weight:1.64, lr:0.0008
[11:11:53.326] iteration:6148  t-loss:0.2412, loss-lb:0.1402, loss-ulb:0.0617, weight:1.64, lr:0.0008
[11:11:53.517] iteration:6149  t-loss:0.1564, loss-lb:0.0972, loss-ulb:0.0361, weight:1.64, lr:0.0008
[11:11:53.708] iteration:6150  t-loss:0.1585, loss-lb:0.1106, loss-ulb:0.0293, weight:1.64, lr:0.0008
[11:11:53.901] iteration:6151  t-loss:0.1423, loss-lb:0.0955, loss-ulb:0.0275, weight:1.70, lr:0.0008
[11:11:54.092] iteration:6152  t-loss:0.1821, loss-lb:0.1135, loss-ulb:0.0403, weight:1.70, lr:0.0008
[11:11:54.284] iteration:6153  t-loss:0.1664, loss-lb:0.1030, loss-ulb:0.0373, weight:1.70, lr:0.0008
[11:11:54.480] iteration:6154  t-loss:0.1639, loss-lb:0.1012, loss-ulb:0.0369, weight:1.70, lr:0.0008
[11:11:54.671] iteration:6155  t-loss:0.1641, loss-lb:0.1067, loss-ulb:0.0337, weight:1.70, lr:0.0008
[11:11:54.862] iteration:6156  t-loss:0.1653, loss-lb:0.1020, loss-ulb:0.0373, weight:1.70, lr:0.0008
[11:11:55.053] iteration:6157  t-loss:0.1818, loss-lb:0.1240, loss-ulb:0.0340, weight:1.70, lr:0.0008
[11:11:55.246] iteration:6158  t-loss:0.1513, loss-lb:0.1048, loss-ulb:0.0274, weight:1.70, lr:0.0008
[11:11:55.438] iteration:6159  t-loss:0.1607, loss-lb:0.1130, loss-ulb:0.0280, weight:1.70, lr:0.0008
[11:11:55.631] iteration:6160  t-loss:0.1960, loss-lb:0.0932, loss-ulb:0.0605, weight:1.70, lr:0.0008
[11:11:55.824] iteration:6161  t-loss:0.1383, loss-lb:0.1025, loss-ulb:0.0211, weight:1.70, lr:0.0008
[11:11:56.017] iteration:6162  t-loss:0.1286, loss-lb:0.0942, loss-ulb:0.0203, weight:1.70, lr:0.0008
[11:11:56.209] iteration:6163  t-loss:0.1628, loss-lb:0.1023, loss-ulb:0.0356, weight:1.70, lr:0.0008
[11:11:56.400] iteration:6164  t-loss:0.1416, loss-lb:0.1006, loss-ulb:0.0241, weight:1.70, lr:0.0008
[11:11:56.593] iteration:6165  t-loss:0.1698, loss-lb:0.1086, loss-ulb:0.0360, weight:1.70, lr:0.0008
[11:11:56.785] iteration:6166  t-loss:0.1617, loss-lb:0.0994, loss-ulb:0.0367, weight:1.70, lr:0.0008
[11:11:56.976] iteration:6167  t-loss:0.1589, loss-lb:0.1188, loss-ulb:0.0236, weight:1.70, lr:0.0008
[11:11:57.167] iteration:6168  t-loss:0.1434, loss-lb:0.0951, loss-ulb:0.0284, weight:1.70, lr:0.0008
[11:11:57.356] iteration:6169  t-loss:0.1635, loss-lb:0.0955, loss-ulb:0.0399, weight:1.70, lr:0.0008
[11:11:57.548] iteration:6170  t-loss:0.1483, loss-lb:0.1053, loss-ulb:0.0253, weight:1.70, lr:0.0008
[11:11:57.738] iteration:6171  t-loss:0.1457, loss-lb:0.0933, loss-ulb:0.0308, weight:1.70, lr:0.0008
[11:11:57.928] iteration:6172  t-loss:0.1478, loss-lb:0.0984, loss-ulb:0.0290, weight:1.70, lr:0.0008
[11:11:58.117] iteration:6173  t-loss:0.1369, loss-lb:0.0919, loss-ulb:0.0264, weight:1.70, lr:0.0008
[11:11:58.306] iteration:6174  t-loss:0.1808, loss-lb:0.0979, loss-ulb:0.0487, weight:1.70, lr:0.0008
[11:12:10.480]  <<Test>> - Ep:62  - mean_dice/mean_h95 - S:89.63/1.41, Best-S:89.92, T:89.84/1.38, Best-T:90.22
[11:12:10.481]           - AvgLoss(lb/ulb/all):0.1049/0.0323/0.1574
[11:12:11.031] iteration:6175  t-loss:0.1455, loss-lb:0.1066, loss-ulb:0.0229, weight:1.70, lr:0.0008
[11:12:11.232] iteration:6176  t-loss:0.1861, loss-lb:0.0955, loss-ulb:0.0532, weight:1.70, lr:0.0008
[11:12:11.426] iteration:6177  t-loss:0.1368, loss-lb:0.0925, loss-ulb:0.0260, weight:1.70, lr:0.0008
[11:12:11.619] iteration:6178  t-loss:0.1363, loss-lb:0.0973, loss-ulb:0.0229, weight:1.70, lr:0.0008
[11:12:11.811] iteration:6179  t-loss:0.1552, loss-lb:0.0910, loss-ulb:0.0377, weight:1.70, lr:0.0008
[11:12:12.004] iteration:6180  t-loss:0.1582, loss-lb:0.1072, loss-ulb:0.0300, weight:1.70, lr:0.0008
[11:12:12.197] iteration:6181  t-loss:0.1437, loss-lb:0.1000, loss-ulb:0.0257, weight:1.70, lr:0.0008
[11:12:12.390] iteration:6182  t-loss:0.1515, loss-lb:0.0913, loss-ulb:0.0354, weight:1.70, lr:0.0008
[11:12:12.582] iteration:6183  t-loss:0.1426, loss-lb:0.0975, loss-ulb:0.0265, weight:1.70, lr:0.0008
[11:12:12.775] iteration:6184  t-loss:0.1556, loss-lb:0.0907, loss-ulb:0.0382, weight:1.70, lr:0.0008
[11:12:12.968] iteration:6185  t-loss:0.1387, loss-lb:0.0987, loss-ulb:0.0235, weight:1.70, lr:0.0008
[11:12:13.161] iteration:6186  t-loss:0.1299, loss-lb:0.0870, loss-ulb:0.0252, weight:1.70, lr:0.0008
[11:12:13.353] iteration:6187  t-loss:0.1486, loss-lb:0.0918, loss-ulb:0.0334, weight:1.70, lr:0.0008
[11:12:13.546] iteration:6188  t-loss:0.2375, loss-lb:0.1083, loss-ulb:0.0760, weight:1.70, lr:0.0008
[11:12:13.739] iteration:6189  t-loss:0.1506, loss-lb:0.1055, loss-ulb:0.0265, weight:1.70, lr:0.0008
[11:12:13.933] iteration:6190  t-loss:0.1430, loss-lb:0.0891, loss-ulb:0.0317, weight:1.70, lr:0.0008
[11:12:14.127] iteration:6191  t-loss:0.1423, loss-lb:0.1016, loss-ulb:0.0239, weight:1.70, lr:0.0008
[11:12:14.320] iteration:6192  t-loss:0.1484, loss-lb:0.0997, loss-ulb:0.0287, weight:1.70, lr:0.0008
[11:12:14.514] iteration:6193  t-loss:0.2161, loss-lb:0.0985, loss-ulb:0.0692, weight:1.70, lr:0.0008
[11:12:14.706] iteration:6194  t-loss:0.1289, loss-lb:0.0884, loss-ulb:0.0238, weight:1.70, lr:0.0008
[11:12:14.899] iteration:6195  t-loss:0.1459, loss-lb:0.0987, loss-ulb:0.0278, weight:1.70, lr:0.0008
[11:12:15.091] iteration:6196  t-loss:0.1372, loss-lb:0.0895, loss-ulb:0.0280, weight:1.70, lr:0.0008
[11:12:15.284] iteration:6197  t-loss:0.1648, loss-lb:0.0992, loss-ulb:0.0386, weight:1.70, lr:0.0008
[11:12:15.476] iteration:6198  t-loss:0.1330, loss-lb:0.0938, loss-ulb:0.0230, weight:1.70, lr:0.0008
[11:12:15.668] iteration:6199  t-loss:0.1282, loss-lb:0.0891, loss-ulb:0.0230, weight:1.70, lr:0.0008
[11:12:15.860] iteration:6200  t-loss:0.1781, loss-lb:0.1357, loss-ulb:0.0249, weight:1.70, lr:0.0008
[11:12:16.052] iteration:6201  t-loss:0.1485, loss-lb:0.1057, loss-ulb:0.0252, weight:1.70, lr:0.0008
[11:12:16.244] iteration:6202  t-loss:0.1342, loss-lb:0.0950, loss-ulb:0.0230, weight:1.70, lr:0.0008
[11:12:16.437] iteration:6203  t-loss:0.2278, loss-lb:0.1359, loss-ulb:0.0541, weight:1.70, lr:0.0008
[11:12:16.630] iteration:6204  t-loss:0.1940, loss-lb:0.0921, loss-ulb:0.0599, weight:1.70, lr:0.0008
[11:12:16.822] iteration:6205  t-loss:0.1407, loss-lb:0.1002, loss-ulb:0.0238, weight:1.70, lr:0.0008
[11:12:17.014] iteration:6206  t-loss:0.1612, loss-lb:0.1156, loss-ulb:0.0268, weight:1.70, lr:0.0008
[11:12:17.205] iteration:6207  t-loss:0.1668, loss-lb:0.1189, loss-ulb:0.0281, weight:1.70, lr:0.0008
[11:12:17.397] iteration:6208  t-loss:0.1253, loss-lb:0.0846, loss-ulb:0.0239, weight:1.70, lr:0.0008
[11:12:17.589] iteration:6209  t-loss:0.1568, loss-lb:0.1015, loss-ulb:0.0325, weight:1.70, lr:0.0008
[11:12:17.782] iteration:6210  t-loss:0.1454, loss-lb:0.1100, loss-ulb:0.0208, weight:1.70, lr:0.0008
[11:12:17.974] iteration:6211  t-loss:0.1670, loss-lb:0.1051, loss-ulb:0.0364, weight:1.70, lr:0.0008
[11:12:18.165] iteration:6212  t-loss:0.1526, loss-lb:0.0956, loss-ulb:0.0335, weight:1.70, lr:0.0008
[11:12:18.357] iteration:6213  t-loss:0.1471, loss-lb:0.0917, loss-ulb:0.0326, weight:1.70, lr:0.0008
[11:12:18.549] iteration:6214  t-loss:0.1358, loss-lb:0.0895, loss-ulb:0.0272, weight:1.70, lr:0.0008
[11:12:18.741] iteration:6215  t-loss:0.1388, loss-lb:0.0931, loss-ulb:0.0269, weight:1.70, lr:0.0008
[11:12:18.934] iteration:6216  t-loss:0.1717, loss-lb:0.1043, loss-ulb:0.0396, weight:1.70, lr:0.0008
[11:12:19.126] iteration:6217  t-loss:0.1567, loss-lb:0.0974, loss-ulb:0.0349, weight:1.70, lr:0.0008
[11:12:19.319] iteration:6218  t-loss:0.1280, loss-lb:0.0844, loss-ulb:0.0256, weight:1.70, lr:0.0008
[11:12:19.511] iteration:6219  t-loss:0.1824, loss-lb:0.1069, loss-ulb:0.0444, weight:1.70, lr:0.0008
[11:12:19.702] iteration:6220  t-loss:0.1556, loss-lb:0.0998, loss-ulb:0.0328, weight:1.70, lr:0.0008
[11:12:19.895] iteration:6221  t-loss:0.1566, loss-lb:0.0963, loss-ulb:0.0355, weight:1.70, lr:0.0008
[11:12:20.088] iteration:6222  t-loss:0.1518, loss-lb:0.0820, loss-ulb:0.0410, weight:1.70, lr:0.0008
[11:12:20.278] iteration:6223  t-loss:0.1492, loss-lb:0.0986, loss-ulb:0.0298, weight:1.70, lr:0.0008
[11:12:20.471] iteration:6224  t-loss:0.1385, loss-lb:0.0902, loss-ulb:0.0284, weight:1.70, lr:0.0008
[11:12:20.664] iteration:6225  t-loss:0.1577, loss-lb:0.1144, loss-ulb:0.0254, weight:1.70, lr:0.0008
[11:12:20.855] iteration:6226  t-loss:0.1415, loss-lb:0.0978, loss-ulb:0.0257, weight:1.70, lr:0.0008
[11:12:21.047] iteration:6227  t-loss:0.1448, loss-lb:0.0908, loss-ulb:0.0317, weight:1.70, lr:0.0008
[11:12:21.239] iteration:6228  t-loss:0.1460, loss-lb:0.1001, loss-ulb:0.0270, weight:1.70, lr:0.0008
[11:12:21.432] iteration:6229  t-loss:0.1382, loss-lb:0.0955, loss-ulb:0.0251, weight:1.70, lr:0.0008
[11:12:21.625] iteration:6230  t-loss:0.1725, loss-lb:0.1034, loss-ulb:0.0406, weight:1.70, lr:0.0008
[11:12:21.819] iteration:6231  t-loss:0.1698, loss-lb:0.1025, loss-ulb:0.0396, weight:1.70, lr:0.0008
[11:12:22.011] iteration:6232  t-loss:0.1285, loss-lb:0.0905, loss-ulb:0.0223, weight:1.70, lr:0.0008
[11:12:22.203] iteration:6233  t-loss:0.1644, loss-lb:0.1130, loss-ulb:0.0302, weight:1.70, lr:0.0008
[11:12:22.395] iteration:6234  t-loss:0.1545, loss-lb:0.0986, loss-ulb:0.0329, weight:1.70, lr:0.0008
[11:12:22.588] iteration:6235  t-loss:0.1404, loss-lb:0.0861, loss-ulb:0.0319, weight:1.70, lr:0.0008
[11:12:22.780] iteration:6236  t-loss:0.1379, loss-lb:0.0895, loss-ulb:0.0285, weight:1.70, lr:0.0008
[11:12:22.973] iteration:6237  t-loss:0.1406, loss-lb:0.1049, loss-ulb:0.0210, weight:1.70, lr:0.0008
[11:12:23.165] iteration:6238  t-loss:0.1485, loss-lb:0.1133, loss-ulb:0.0207, weight:1.70, lr:0.0008
[11:12:23.358] iteration:6239  t-loss:0.1470, loss-lb:0.1022, loss-ulb:0.0264, weight:1.70, lr:0.0008
[11:12:23.551] iteration:6240  t-loss:0.1694, loss-lb:0.0931, loss-ulb:0.0448, weight:1.70, lr:0.0008
[11:12:23.744] iteration:6241  t-loss:0.1704, loss-lb:0.0985, loss-ulb:0.0423, weight:1.70, lr:0.0008
[11:12:23.936] iteration:6242  t-loss:0.2188, loss-lb:0.0953, loss-ulb:0.0726, weight:1.70, lr:0.0008
[11:12:24.128] iteration:6243  t-loss:0.1409, loss-lb:0.0902, loss-ulb:0.0298, weight:1.70, lr:0.0008
[11:12:24.320] iteration:6244  t-loss:0.1308, loss-lb:0.0918, loss-ulb:0.0229, weight:1.70, lr:0.0008
[11:12:24.511] iteration:6245  t-loss:0.1451, loss-lb:0.0964, loss-ulb:0.0286, weight:1.70, lr:0.0008
[11:12:24.703] iteration:6246  t-loss:0.1835, loss-lb:0.1061, loss-ulb:0.0455, weight:1.70, lr:0.0008
[11:12:24.895] iteration:6247  t-loss:0.1421, loss-lb:0.1029, loss-ulb:0.0231, weight:1.70, lr:0.0008
[11:12:25.088] iteration:6248  t-loss:0.1809, loss-lb:0.1060, loss-ulb:0.0440, weight:1.70, lr:0.0008
[11:12:25.292] iteration:6249  t-loss:0.1459, loss-lb:0.1018, loss-ulb:0.0259, weight:1.70, lr:0.0008
[11:12:25.491] iteration:6250  t-loss:0.1379, loss-lb:0.0982, loss-ulb:0.0233, weight:1.70, lr:0.0008
[11:12:25.687] iteration:6251  t-loss:0.1649, loss-lb:0.0956, loss-ulb:0.0408, weight:1.70, lr:0.0008
[11:12:25.879] iteration:6252  t-loss:0.1523, loss-lb:0.0927, loss-ulb:0.0350, weight:1.70, lr:0.0008
[11:12:26.072] iteration:6253  t-loss:0.1628, loss-lb:0.1138, loss-ulb:0.0288, weight:1.70, lr:0.0008
[11:12:26.265] iteration:6254  t-loss:0.1611, loss-lb:0.0933, loss-ulb:0.0399, weight:1.70, lr:0.0008
[11:12:26.457] iteration:6255  t-loss:0.1462, loss-lb:0.0953, loss-ulb:0.0299, weight:1.70, lr:0.0008
[11:12:26.650] iteration:6256  t-loss:0.1394, loss-lb:0.0998, loss-ulb:0.0233, weight:1.70, lr:0.0008
[11:12:26.842] iteration:6257  t-loss:0.1537, loss-lb:0.0917, loss-ulb:0.0364, weight:1.70, lr:0.0008
[11:12:27.034] iteration:6258  t-loss:0.1391, loss-lb:0.0910, loss-ulb:0.0283, weight:1.70, lr:0.0008
[11:12:27.226] iteration:6259  t-loss:0.1462, loss-lb:0.0962, loss-ulb:0.0294, weight:1.70, lr:0.0008
[11:12:27.427] iteration:6260  t-loss:0.1313, loss-lb:0.0901, loss-ulb:0.0242, weight:1.70, lr:0.0008
[11:12:27.619] iteration:6261  t-loss:0.1760, loss-lb:0.0934, loss-ulb:0.0486, weight:1.70, lr:0.0008
[11:12:27.811] iteration:6262  t-loss:0.1593, loss-lb:0.1014, loss-ulb:0.0340, weight:1.70, lr:0.0008
[11:12:28.003] iteration:6263  t-loss:0.1645, loss-lb:0.1078, loss-ulb:0.0334, weight:1.70, lr:0.0008
[11:12:28.204] iteration:6264  t-loss:0.1908, loss-lb:0.0906, loss-ulb:0.0589, weight:1.70, lr:0.0008
[11:12:28.397] iteration:6265  t-loss:0.1576, loss-lb:0.0959, loss-ulb:0.0362, weight:1.70, lr:0.0008
[11:12:28.588] iteration:6266  t-loss:0.2438, loss-lb:0.1003, loss-ulb:0.0843, weight:1.70, lr:0.0008
[11:12:28.779] iteration:6267  t-loss:0.1519, loss-lb:0.0966, loss-ulb:0.0326, weight:1.70, lr:0.0008
[11:12:28.969] iteration:6268  t-loss:0.1706, loss-lb:0.0948, loss-ulb:0.0446, weight:1.70, lr:0.0008
[11:12:29.160] iteration:6269  t-loss:0.1331, loss-lb:0.0886, loss-ulb:0.0261, weight:1.70, lr:0.0008
[11:12:29.351] iteration:6270  t-loss:0.1768, loss-lb:0.0954, loss-ulb:0.0478, weight:1.70, lr:0.0008
[11:12:29.542] iteration:6271  t-loss:0.1500, loss-lb:0.0984, loss-ulb:0.0304, weight:1.70, lr:0.0008
[11:12:29.732] iteration:6272  t-loss:0.1486, loss-lb:0.1055, loss-ulb:0.0253, weight:1.70, lr:0.0008
[11:12:30.318] iteration:6273  t-loss:0.1707, loss-lb:0.1084, loss-ulb:0.0366, weight:1.70, lr:0.0008
[11:12:30.514] iteration:6274  t-loss:0.1785, loss-lb:0.1115, loss-ulb:0.0394, weight:1.70, lr:0.0008
[11:12:30.706] iteration:6275  t-loss:0.1473, loss-lb:0.0939, loss-ulb:0.0314, weight:1.70, lr:0.0008
[11:12:30.897] iteration:6276  t-loss:0.1366, loss-lb:0.0942, loss-ulb:0.0249, weight:1.70, lr:0.0008
[11:12:31.090] iteration:6277  t-loss:0.1350, loss-lb:0.0980, loss-ulb:0.0217, weight:1.70, lr:0.0008
[11:12:31.281] iteration:6278  t-loss:0.1717, loss-lb:0.0953, loss-ulb:0.0449, weight:1.70, lr:0.0008
[11:12:31.474] iteration:6279  t-loss:0.1555, loss-lb:0.1083, loss-ulb:0.0277, weight:1.70, lr:0.0008
[11:12:31.666] iteration:6280  t-loss:0.1767, loss-lb:0.0989, loss-ulb:0.0457, weight:1.70, lr:0.0008
[11:12:31.858] iteration:6281  t-loss:0.1652, loss-lb:0.1171, loss-ulb:0.0283, weight:1.70, lr:0.0008
[11:12:32.050] iteration:6282  t-loss:0.1789, loss-lb:0.1250, loss-ulb:0.0316, weight:1.70, lr:0.0008
[11:12:32.242] iteration:6283  t-loss:0.1498, loss-lb:0.0947, loss-ulb:0.0324, weight:1.70, lr:0.0008
[11:12:32.436] iteration:6284  t-loss:0.1466, loss-lb:0.0989, loss-ulb:0.0281, weight:1.70, lr:0.0008
[11:12:32.628] iteration:6285  t-loss:0.1506, loss-lb:0.0959, loss-ulb:0.0322, weight:1.70, lr:0.0008
[11:12:32.819] iteration:6286  t-loss:0.2351, loss-lb:0.1354, loss-ulb:0.0586, weight:1.70, lr:0.0008
[11:12:33.012] iteration:6287  t-loss:0.1254, loss-lb:0.0905, loss-ulb:0.0205, weight:1.70, lr:0.0008
[11:12:33.204] iteration:6288  t-loss:0.1522, loss-lb:0.0920, loss-ulb:0.0354, weight:1.70, lr:0.0008
[11:12:33.397] iteration:6289  t-loss:0.1490, loss-lb:0.0964, loss-ulb:0.0309, weight:1.70, lr:0.0008
[11:12:33.589] iteration:6290  t-loss:0.1567, loss-lb:0.1095, loss-ulb:0.0278, weight:1.70, lr:0.0008
[11:12:33.782] iteration:6291  t-loss:0.1473, loss-lb:0.1029, loss-ulb:0.0260, weight:1.70, lr:0.0008
[11:12:33.973] iteration:6292  t-loss:0.1612, loss-lb:0.1079, loss-ulb:0.0314, weight:1.70, lr:0.0008
[11:12:34.166] iteration:6293  t-loss:0.1435, loss-lb:0.1033, loss-ulb:0.0236, weight:1.70, lr:0.0008
[11:12:34.360] iteration:6294  t-loss:0.1850, loss-lb:0.1103, loss-ulb:0.0439, weight:1.70, lr:0.0008
[11:12:34.551] iteration:6295  t-loss:0.1386, loss-lb:0.0994, loss-ulb:0.0230, weight:1.70, lr:0.0008
[11:12:34.743] iteration:6296  t-loss:0.2225, loss-lb:0.1021, loss-ulb:0.0708, weight:1.70, lr:0.0008
[11:12:34.937] iteration:6297  t-loss:0.1517, loss-lb:0.0939, loss-ulb:0.0340, weight:1.70, lr:0.0008
[11:12:35.130] iteration:6298  t-loss:0.1454, loss-lb:0.1018, loss-ulb:0.0256, weight:1.70, lr:0.0008
[11:12:35.321] iteration:6299  t-loss:0.1454, loss-lb:0.0974, loss-ulb:0.0282, weight:1.70, lr:0.0008
[11:12:35.514] iteration:6300  t-loss:0.1493, loss-lb:0.1066, loss-ulb:0.0251, weight:1.70, lr:0.0008
[11:12:35.706] iteration:6301  t-loss:0.1463, loss-lb:0.1020, loss-ulb:0.0252, weight:1.76, lr:0.0008
[11:12:35.898] iteration:6302  t-loss:0.1650, loss-lb:0.0965, loss-ulb:0.0390, weight:1.76, lr:0.0008
[11:12:36.091] iteration:6303  t-loss:0.1366, loss-lb:0.0912, loss-ulb:0.0258, weight:1.76, lr:0.0008
[11:12:36.284] iteration:6304  t-loss:0.1491, loss-lb:0.1004, loss-ulb:0.0276, weight:1.76, lr:0.0008
[11:12:36.476] iteration:6305  t-loss:0.1394, loss-lb:0.0833, loss-ulb:0.0319, weight:1.76, lr:0.0008
[11:12:36.669] iteration:6306  t-loss:0.2578, loss-lb:0.0946, loss-ulb:0.0928, weight:1.76, lr:0.0008
[11:12:36.861] iteration:6307  t-loss:0.1222, loss-lb:0.0863, loss-ulb:0.0204, weight:1.76, lr:0.0008
[11:12:37.054] iteration:6308  t-loss:0.1521, loss-lb:0.1017, loss-ulb:0.0286, weight:1.76, lr:0.0008
[11:12:37.246] iteration:6309  t-loss:0.1752, loss-lb:0.0937, loss-ulb:0.0463, weight:1.76, lr:0.0008
[11:12:37.438] iteration:6310  t-loss:0.1743, loss-lb:0.0970, loss-ulb:0.0439, weight:1.76, lr:0.0008
[11:12:37.631] iteration:6311  t-loss:0.1789, loss-lb:0.0895, loss-ulb:0.0508, weight:1.76, lr:0.0008
[11:12:37.822] iteration:6312  t-loss:0.1438, loss-lb:0.0988, loss-ulb:0.0256, weight:1.76, lr:0.0008
[11:12:38.014] iteration:6313  t-loss:0.1527, loss-lb:0.0969, loss-ulb:0.0317, weight:1.76, lr:0.0008
[11:12:38.207] iteration:6314  t-loss:0.1441, loss-lb:0.0948, loss-ulb:0.0280, weight:1.76, lr:0.0008
[11:12:38.398] iteration:6315  t-loss:0.1873, loss-lb:0.1238, loss-ulb:0.0361, weight:1.76, lr:0.0008
[11:12:38.589] iteration:6316  t-loss:0.1639, loss-lb:0.0968, loss-ulb:0.0381, weight:1.76, lr:0.0008
[11:12:38.783] iteration:6317  t-loss:0.1407, loss-lb:0.0999, loss-ulb:0.0231, weight:1.76, lr:0.0008
[11:12:38.977] iteration:6318  t-loss:0.1466, loss-lb:0.1010, loss-ulb:0.0259, weight:1.76, lr:0.0008
[11:12:39.168] iteration:6319  t-loss:0.1444, loss-lb:0.1065, loss-ulb:0.0216, weight:1.76, lr:0.0008
[11:12:39.360] iteration:6320  t-loss:0.1438, loss-lb:0.0921, loss-ulb:0.0294, weight:1.76, lr:0.0008
[11:12:39.552] iteration:6321  t-loss:0.1595, loss-lb:0.1092, loss-ulb:0.0286, weight:1.76, lr:0.0008
[11:12:39.743] iteration:6322  t-loss:0.1556, loss-lb:0.0905, loss-ulb:0.0370, weight:1.76, lr:0.0008
[11:12:39.936] iteration:6323  t-loss:0.1397, loss-lb:0.0942, loss-ulb:0.0259, weight:1.76, lr:0.0008
[11:12:40.128] iteration:6324  t-loss:0.1657, loss-lb:0.1099, loss-ulb:0.0317, weight:1.76, lr:0.0008
[11:12:40.319] iteration:6325  t-loss:0.1551, loss-lb:0.1067, loss-ulb:0.0275, weight:1.76, lr:0.0008
[11:12:40.512] iteration:6326  t-loss:0.1431, loss-lb:0.0976, loss-ulb:0.0259, weight:1.76, lr:0.0008
[11:12:40.704] iteration:6327  t-loss:0.1302, loss-lb:0.0940, loss-ulb:0.0206, weight:1.76, lr:0.0008
[11:12:40.895] iteration:6328  t-loss:0.1708, loss-lb:0.1229, loss-ulb:0.0273, weight:1.76, lr:0.0008
[11:12:41.088] iteration:6329  t-loss:0.1522, loss-lb:0.1050, loss-ulb:0.0268, weight:1.76, lr:0.0008
[11:12:41.281] iteration:6330  t-loss:0.1435, loss-lb:0.0978, loss-ulb:0.0259, weight:1.76, lr:0.0008
[11:12:41.472] iteration:6331  t-loss:0.1587, loss-lb:0.1062, loss-ulb:0.0299, weight:1.76, lr:0.0008
[11:12:41.664] iteration:6332  t-loss:0.1738, loss-lb:0.1135, loss-ulb:0.0343, weight:1.76, lr:0.0008
[11:12:41.857] iteration:6333  t-loss:0.1388, loss-lb:0.0978, loss-ulb:0.0233, weight:1.76, lr:0.0008
[11:12:42.048] iteration:6334  t-loss:0.1316, loss-lb:0.0917, loss-ulb:0.0226, weight:1.76, lr:0.0008
[11:12:42.240] iteration:6335  t-loss:0.1668, loss-lb:0.1040, loss-ulb:0.0357, weight:1.76, lr:0.0008
[11:12:42.434] iteration:6336  t-loss:0.1579, loss-lb:0.0943, loss-ulb:0.0361, weight:1.76, lr:0.0008
[11:12:42.627] iteration:6337  t-loss:0.1464, loss-lb:0.0950, loss-ulb:0.0292, weight:1.76, lr:0.0008
[11:12:42.818] iteration:6338  t-loss:0.1472, loss-lb:0.0977, loss-ulb:0.0281, weight:1.76, lr:0.0008
[11:12:43.010] iteration:6339  t-loss:0.1460, loss-lb:0.0946, loss-ulb:0.0292, weight:1.76, lr:0.0008
[11:12:43.203] iteration:6340  t-loss:0.1379, loss-lb:0.0953, loss-ulb:0.0242, weight:1.76, lr:0.0008
[11:12:43.394] iteration:6341  t-loss:0.1528, loss-lb:0.1031, loss-ulb:0.0282, weight:1.76, lr:0.0008
[11:12:43.587] iteration:6342  t-loss:0.1344, loss-lb:0.0889, loss-ulb:0.0259, weight:1.76, lr:0.0008
[11:12:43.780] iteration:6343  t-loss:0.1964, loss-lb:0.1038, loss-ulb:0.0526, weight:1.76, lr:0.0008
[11:12:43.974] iteration:6344  t-loss:0.1523, loss-lb:0.0962, loss-ulb:0.0319, weight:1.76, lr:0.0008
[11:12:44.166] iteration:6345  t-loss:0.1681, loss-lb:0.1018, loss-ulb:0.0377, weight:1.76, lr:0.0008
[11:12:44.359] iteration:6346  t-loss:0.1662, loss-lb:0.1111, loss-ulb:0.0313, weight:1.76, lr:0.0008
[11:12:44.552] iteration:6347  t-loss:0.1545, loss-lb:0.1035, loss-ulb:0.0290, weight:1.76, lr:0.0008
[11:12:44.744] iteration:6348  t-loss:0.1468, loss-lb:0.1008, loss-ulb:0.0261, weight:1.76, lr:0.0008
[11:12:44.937] iteration:6349  t-loss:0.1318, loss-lb:0.0912, loss-ulb:0.0230, weight:1.76, lr:0.0008
[11:12:45.130] iteration:6350  t-loss:0.1501, loss-lb:0.1086, loss-ulb:0.0236, weight:1.76, lr:0.0008
[11:12:45.322] iteration:6351  t-loss:0.1873, loss-lb:0.0952, loss-ulb:0.0523, weight:1.76, lr:0.0008
[11:12:45.515] iteration:6352  t-loss:0.1697, loss-lb:0.0958, loss-ulb:0.0420, weight:1.76, lr:0.0008
[11:12:45.708] iteration:6353  t-loss:0.1424, loss-lb:0.0955, loss-ulb:0.0266, weight:1.76, lr:0.0008
[11:12:45.899] iteration:6354  t-loss:0.1437, loss-lb:0.0930, loss-ulb:0.0288, weight:1.76, lr:0.0008
[11:12:46.092] iteration:6355  t-loss:0.1504, loss-lb:0.1016, loss-ulb:0.0277, weight:1.76, lr:0.0008
[11:12:46.285] iteration:6356  t-loss:0.1586, loss-lb:0.1003, loss-ulb:0.0331, weight:1.76, lr:0.0008
[11:12:46.477] iteration:6357  t-loss:0.1394, loss-lb:0.0907, loss-ulb:0.0277, weight:1.76, lr:0.0008
[11:12:46.669] iteration:6358  t-loss:0.1324, loss-lb:0.0872, loss-ulb:0.0257, weight:1.76, lr:0.0008
[11:12:46.862] iteration:6359  t-loss:0.1540, loss-lb:0.1011, loss-ulb:0.0301, weight:1.76, lr:0.0008
[11:12:47.054] iteration:6360  t-loss:0.1437, loss-lb:0.0966, loss-ulb:0.0268, weight:1.76, lr:0.0008
[11:12:47.246] iteration:6361  t-loss:0.1330, loss-lb:0.0959, loss-ulb:0.0211, weight:1.76, lr:0.0008
[11:12:47.439] iteration:6362  t-loss:0.1451, loss-lb:0.0980, loss-ulb:0.0268, weight:1.76, lr:0.0008
[11:12:47.631] iteration:6363  t-loss:0.1438, loss-lb:0.0898, loss-ulb:0.0307, weight:1.76, lr:0.0008
[11:12:47.822] iteration:6364  t-loss:0.1315, loss-lb:0.0907, loss-ulb:0.0232, weight:1.76, lr:0.0008
[11:12:48.012] iteration:6365  t-loss:0.1901, loss-lb:0.0935, loss-ulb:0.0549, weight:1.76, lr:0.0008
[11:12:48.203] iteration:6366  t-loss:0.1626, loss-lb:0.0996, loss-ulb:0.0358, weight:1.76, lr:0.0008
[11:12:48.394] iteration:6367  t-loss:0.1400, loss-lb:0.0956, loss-ulb:0.0252, weight:1.76, lr:0.0008
[11:12:48.584] iteration:6368  t-loss:0.1503, loss-lb:0.0914, loss-ulb:0.0334, weight:1.76, lr:0.0008
[11:12:48.775] iteration:6369  t-loss:0.1383, loss-lb:0.0906, loss-ulb:0.0271, weight:1.76, lr:0.0008
[11:12:48.965] iteration:6370  t-loss:0.2064, loss-lb:0.1347, loss-ulb:0.0408, weight:1.76, lr:0.0008
[11:13:00.786]  <<Test>> - Ep:64  - mean_dice/mean_h95 - S:90.13/1.35, Best-S:90.13, T:90.22/1.32, Best-T:90.22
[11:13:00.786]           - AvgLoss(lb/ulb/all):0.1000/0.0320/0.1531
[11:13:01.306] iteration:6371  t-loss:0.1364, loss-lb:0.0957, loss-ulb:0.0231, weight:1.76, lr:0.0008
[11:13:01.503] iteration:6372  t-loss:0.1576, loss-lb:0.1016, loss-ulb:0.0318, weight:1.76, lr:0.0008
[11:13:01.695] iteration:6373  t-loss:0.1530, loss-lb:0.0938, loss-ulb:0.0336, weight:1.76, lr:0.0008
[11:13:01.889] iteration:6374  t-loss:0.1483, loss-lb:0.0917, loss-ulb:0.0322, weight:1.76, lr:0.0008
[11:13:02.085] iteration:6375  t-loss:0.1333, loss-lb:0.0913, loss-ulb:0.0239, weight:1.76, lr:0.0008
[11:13:02.280] iteration:6376  t-loss:0.1599, loss-lb:0.1077, loss-ulb:0.0296, weight:1.76, lr:0.0008
[11:13:02.475] iteration:6377  t-loss:0.1738, loss-lb:0.1161, loss-ulb:0.0328, weight:1.76, lr:0.0008
[11:13:02.668] iteration:6378  t-loss:0.1557, loss-lb:0.1040, loss-ulb:0.0294, weight:1.76, lr:0.0008
[11:13:02.862] iteration:6379  t-loss:0.1833, loss-lb:0.1018, loss-ulb:0.0463, weight:1.76, lr:0.0008
[11:13:03.053] iteration:6380  t-loss:0.1768, loss-lb:0.0940, loss-ulb:0.0471, weight:1.76, lr:0.0008
[11:13:03.246] iteration:6381  t-loss:0.1319, loss-lb:0.0903, loss-ulb:0.0236, weight:1.76, lr:0.0008
[11:13:03.440] iteration:6382  t-loss:0.1747, loss-lb:0.1067, loss-ulb:0.0387, weight:1.76, lr:0.0008
[11:13:03.633] iteration:6383  t-loss:0.1743, loss-lb:0.1127, loss-ulb:0.0350, weight:1.76, lr:0.0008
[11:13:03.826] iteration:6384  t-loss:0.1484, loss-lb:0.1084, loss-ulb:0.0227, weight:1.76, lr:0.0008
[11:13:04.019] iteration:6385  t-loss:0.2194, loss-lb:0.0932, loss-ulb:0.0717, weight:1.76, lr:0.0008
[11:13:04.211] iteration:6386  t-loss:0.1741, loss-lb:0.1072, loss-ulb:0.0380, weight:1.76, lr:0.0008
[11:13:04.404] iteration:6387  t-loss:0.1800, loss-lb:0.1115, loss-ulb:0.0389, weight:1.76, lr:0.0008
[11:13:04.596] iteration:6388  t-loss:0.1578, loss-lb:0.1025, loss-ulb:0.0314, weight:1.76, lr:0.0008
[11:13:04.788] iteration:6389  t-loss:0.1464, loss-lb:0.1007, loss-ulb:0.0260, weight:1.76, lr:0.0008
[11:13:04.981] iteration:6390  t-loss:0.1945, loss-lb:0.0911, loss-ulb:0.0587, weight:1.76, lr:0.0008
[11:13:05.172] iteration:6391  t-loss:0.1506, loss-lb:0.1024, loss-ulb:0.0274, weight:1.76, lr:0.0008
[11:13:05.365] iteration:6392  t-loss:0.1506, loss-lb:0.0998, loss-ulb:0.0289, weight:1.76, lr:0.0008
[11:13:05.557] iteration:6393  t-loss:0.1370, loss-lb:0.0907, loss-ulb:0.0263, weight:1.76, lr:0.0008
[11:13:05.748] iteration:6394  t-loss:0.1500, loss-lb:0.0998, loss-ulb:0.0285, weight:1.76, lr:0.0008
[11:13:05.940] iteration:6395  t-loss:0.1638, loss-lb:0.1143, loss-ulb:0.0281, weight:1.76, lr:0.0008
[11:13:06.130] iteration:6396  t-loss:0.1633, loss-lb:0.1054, loss-ulb:0.0329, weight:1.76, lr:0.0008
[11:13:06.323] iteration:6397  t-loss:0.1801, loss-lb:0.1214, loss-ulb:0.0333, weight:1.76, lr:0.0008
[11:13:06.514] iteration:6398  t-loss:0.2005, loss-lb:0.0970, loss-ulb:0.0588, weight:1.76, lr:0.0008
[11:13:06.707] iteration:6399  t-loss:0.1590, loss-lb:0.0981, loss-ulb:0.0346, weight:1.76, lr:0.0008
[11:13:06.899] iteration:6400  t-loss:0.1457, loss-lb:0.0949, loss-ulb:0.0289, weight:1.76, lr:0.0008
[11:13:07.090] iteration:6401  t-loss:0.2640, loss-lb:0.1113, loss-ulb:0.0868, weight:1.76, lr:0.0008
[11:13:07.282] iteration:6402  t-loss:0.1458, loss-lb:0.1003, loss-ulb:0.0258, weight:1.76, lr:0.0008
[11:13:07.475] iteration:6403  t-loss:0.1640, loss-lb:0.0987, loss-ulb:0.0371, weight:1.76, lr:0.0008
[11:13:07.667] iteration:6404  t-loss:0.1838, loss-lb:0.1175, loss-ulb:0.0377, weight:1.76, lr:0.0008
[11:13:07.859] iteration:6405  t-loss:0.1614, loss-lb:0.1037, loss-ulb:0.0328, weight:1.76, lr:0.0008
[11:13:08.051] iteration:6406  t-loss:0.1786, loss-lb:0.1253, loss-ulb:0.0303, weight:1.76, lr:0.0008
[11:13:08.242] iteration:6407  t-loss:0.1912, loss-lb:0.1003, loss-ulb:0.0516, weight:1.76, lr:0.0008
[11:13:08.433] iteration:6408  t-loss:0.1591, loss-lb:0.0960, loss-ulb:0.0358, weight:1.76, lr:0.0008
[11:13:08.625] iteration:6409  t-loss:0.1573, loss-lb:0.0981, loss-ulb:0.0336, weight:1.76, lr:0.0008
[11:13:08.817] iteration:6410  t-loss:0.1395, loss-lb:0.0958, loss-ulb:0.0248, weight:1.76, lr:0.0008
[11:13:09.009] iteration:6411  t-loss:0.1734, loss-lb:0.1237, loss-ulb:0.0282, weight:1.76, lr:0.0008
[11:13:09.201] iteration:6412  t-loss:0.1445, loss-lb:0.0935, loss-ulb:0.0290, weight:1.76, lr:0.0008
[11:13:09.392] iteration:6413  t-loss:0.1554, loss-lb:0.1017, loss-ulb:0.0305, weight:1.76, lr:0.0008
[11:13:09.585] iteration:6414  t-loss:0.1576, loss-lb:0.1154, loss-ulb:0.0240, weight:1.76, lr:0.0008
[11:13:09.778] iteration:6415  t-loss:0.1337, loss-lb:0.0898, loss-ulb:0.0250, weight:1.76, lr:0.0008
[11:13:09.970] iteration:6416  t-loss:0.1568, loss-lb:0.1048, loss-ulb:0.0295, weight:1.76, lr:0.0008
[11:13:10.161] iteration:6417  t-loss:0.1418, loss-lb:0.0968, loss-ulb:0.0256, weight:1.76, lr:0.0008
[11:13:10.352] iteration:6418  t-loss:0.1537, loss-lb:0.0946, loss-ulb:0.0336, weight:1.76, lr:0.0008
[11:13:10.544] iteration:6419  t-loss:0.1684, loss-lb:0.1011, loss-ulb:0.0383, weight:1.76, lr:0.0008
[11:13:10.734] iteration:6420  t-loss:0.1890, loss-lb:0.1366, loss-ulb:0.0298, weight:1.76, lr:0.0008
[11:13:10.926] iteration:6421  t-loss:0.1625, loss-lb:0.0947, loss-ulb:0.0385, weight:1.76, lr:0.0008
[11:13:11.119] iteration:6422  t-loss:0.2114, loss-lb:0.0958, loss-ulb:0.0657, weight:1.76, lr:0.0008
[11:13:11.310] iteration:6423  t-loss:0.1488, loss-lb:0.1068, loss-ulb:0.0239, weight:1.76, lr:0.0008
[11:13:11.502] iteration:6424  t-loss:0.1557, loss-lb:0.0960, loss-ulb:0.0339, weight:1.76, lr:0.0008
[11:13:11.692] iteration:6425  t-loss:0.1470, loss-lb:0.1004, loss-ulb:0.0265, weight:1.76, lr:0.0008
[11:13:11.883] iteration:6426  t-loss:0.1718, loss-lb:0.1021, loss-ulb:0.0396, weight:1.76, lr:0.0008
[11:13:12.074] iteration:6427  t-loss:0.1553, loss-lb:0.1106, loss-ulb:0.0254, weight:1.76, lr:0.0008
[11:13:12.266] iteration:6428  t-loss:0.1410, loss-lb:0.0950, loss-ulb:0.0261, weight:1.76, lr:0.0008
[11:13:12.459] iteration:6429  t-loss:0.1455, loss-lb:0.0933, loss-ulb:0.0297, weight:1.76, lr:0.0008
[11:13:12.653] iteration:6430  t-loss:0.1428, loss-lb:0.0913, loss-ulb:0.0292, weight:1.76, lr:0.0008
[11:13:12.846] iteration:6431  t-loss:0.1351, loss-lb:0.0832, loss-ulb:0.0295, weight:1.76, lr:0.0008
[11:13:13.042] iteration:6432  t-loss:0.1584, loss-lb:0.0950, loss-ulb:0.0360, weight:1.76, lr:0.0008
[11:13:13.240] iteration:6433  t-loss:0.1464, loss-lb:0.1017, loss-ulb:0.0254, weight:1.76, lr:0.0008
[11:13:13.433] iteration:6434  t-loss:0.1738, loss-lb:0.0886, loss-ulb:0.0484, weight:1.76, lr:0.0008
[11:13:13.635] iteration:6435  t-loss:0.1939, loss-lb:0.1198, loss-ulb:0.0421, weight:1.76, lr:0.0008
[11:13:13.828] iteration:6436  t-loss:0.1638, loss-lb:0.0966, loss-ulb:0.0382, weight:1.76, lr:0.0008
[11:13:14.019] iteration:6437  t-loss:0.1483, loss-lb:0.0967, loss-ulb:0.0293, weight:1.76, lr:0.0008
[11:13:14.211] iteration:6438  t-loss:0.1574, loss-lb:0.0951, loss-ulb:0.0354, weight:1.76, lr:0.0008
[11:13:14.409] iteration:6439  t-loss:0.1574, loss-lb:0.1046, loss-ulb:0.0300, weight:1.76, lr:0.0008
[11:13:14.601] iteration:6440  t-loss:0.1330, loss-lb:0.0888, loss-ulb:0.0251, weight:1.76, lr:0.0008
[11:13:14.792] iteration:6441  t-loss:0.1365, loss-lb:0.0917, loss-ulb:0.0255, weight:1.76, lr:0.0008
[11:13:14.985] iteration:6442  t-loss:0.1812, loss-lb:0.1365, loss-ulb:0.0254, weight:1.76, lr:0.0008
[11:13:15.183] iteration:6443  t-loss:0.1438, loss-lb:0.0973, loss-ulb:0.0264, weight:1.76, lr:0.0008
[11:13:15.375] iteration:6444  t-loss:0.1645, loss-lb:0.1133, loss-ulb:0.0291, weight:1.76, lr:0.0008
[11:13:15.567] iteration:6445  t-loss:0.1492, loss-lb:0.1037, loss-ulb:0.0259, weight:1.76, lr:0.0008
[11:13:15.758] iteration:6446  t-loss:0.1591, loss-lb:0.0971, loss-ulb:0.0352, weight:1.76, lr:0.0008
[11:13:15.958] iteration:6447  t-loss:0.1548, loss-lb:0.0882, loss-ulb:0.0378, weight:1.76, lr:0.0008
[11:13:16.151] iteration:6448  t-loss:0.1478, loss-lb:0.0949, loss-ulb:0.0301, weight:1.76, lr:0.0008
[11:13:16.342] iteration:6449  t-loss:0.1694, loss-lb:0.1039, loss-ulb:0.0372, weight:1.76, lr:0.0008
[11:13:16.537] iteration:6450  t-loss:0.1466, loss-lb:0.0989, loss-ulb:0.0271, weight:1.76, lr:0.0008
[11:13:16.735] iteration:6451  t-loss:0.1495, loss-lb:0.0962, loss-ulb:0.0294, weight:1.81, lr:0.0008
[11:13:16.927] iteration:6452  t-loss:0.1500, loss-lb:0.0948, loss-ulb:0.0305, weight:1.81, lr:0.0008
[11:13:17.118] iteration:6453  t-loss:0.1881, loss-lb:0.1249, loss-ulb:0.0349, weight:1.81, lr:0.0008
[11:13:17.310] iteration:6454  t-loss:0.1366, loss-lb:0.0912, loss-ulb:0.0251, weight:1.81, lr:0.0008
[11:13:17.511] iteration:6455  t-loss:0.1396, loss-lb:0.0975, loss-ulb:0.0232, weight:1.81, lr:0.0008
[11:13:17.703] iteration:6456  t-loss:0.1561, loss-lb:0.1009, loss-ulb:0.0305, weight:1.81, lr:0.0008
[11:13:17.896] iteration:6457  t-loss:0.2303, loss-lb:0.0946, loss-ulb:0.0748, weight:1.81, lr:0.0008
[11:13:18.087] iteration:6458  t-loss:0.1324, loss-lb:0.0933, loss-ulb:0.0216, weight:1.81, lr:0.0008
[11:13:18.287] iteration:6459  t-loss:0.1450, loss-lb:0.0954, loss-ulb:0.0274, weight:1.81, lr:0.0008
[11:13:18.479] iteration:6460  t-loss:0.1497, loss-lb:0.0945, loss-ulb:0.0305, weight:1.81, lr:0.0008
[11:13:18.672] iteration:6461  t-loss:0.1695, loss-lb:0.1091, loss-ulb:0.0333, weight:1.81, lr:0.0008
[11:13:18.863] iteration:6462  t-loss:0.1569, loss-lb:0.0928, loss-ulb:0.0354, weight:1.81, lr:0.0008
[11:13:19.053] iteration:6463  t-loss:0.1396, loss-lb:0.0976, loss-ulb:0.0231, weight:1.81, lr:0.0008
[11:13:19.244] iteration:6464  t-loss:0.1693, loss-lb:0.0953, loss-ulb:0.0408, weight:1.81, lr:0.0008
[11:13:19.435] iteration:6465  t-loss:0.2394, loss-lb:0.0928, loss-ulb:0.0809, weight:1.81, lr:0.0008
[11:13:19.625] iteration:6466  t-loss:0.1432, loss-lb:0.0976, loss-ulb:0.0251, weight:1.81, lr:0.0008
[11:13:19.816] iteration:6467  t-loss:0.1364, loss-lb:0.0865, loss-ulb:0.0275, weight:1.81, lr:0.0008
[11:13:20.006] iteration:6468  t-loss:0.1361, loss-lb:0.0930, loss-ulb:0.0238, weight:1.81, lr:0.0008
[11:13:20.630] iteration:6469  t-loss:0.1591, loss-lb:0.0943, loss-ulb:0.0357, weight:1.81, lr:0.0008
[11:13:20.826] iteration:6470  t-loss:0.1633, loss-lb:0.0955, loss-ulb:0.0374, weight:1.81, lr:0.0008
[11:13:21.018] iteration:6471  t-loss:0.1558, loss-lb:0.1068, loss-ulb:0.0270, weight:1.81, lr:0.0008
[11:13:21.209] iteration:6472  t-loss:0.1310, loss-lb:0.0920, loss-ulb:0.0215, weight:1.81, lr:0.0008
[11:13:21.402] iteration:6473  t-loss:0.1654, loss-lb:0.0955, loss-ulb:0.0386, weight:1.81, lr:0.0008
[11:13:21.593] iteration:6474  t-loss:0.1598, loss-lb:0.1000, loss-ulb:0.0330, weight:1.81, lr:0.0008
[11:13:21.786] iteration:6475  t-loss:0.1521, loss-lb:0.1040, loss-ulb:0.0266, weight:1.81, lr:0.0008
[11:13:21.977] iteration:6476  t-loss:0.1777, loss-lb:0.1115, loss-ulb:0.0365, weight:1.81, lr:0.0008
[11:13:22.168] iteration:6477  t-loss:0.2329, loss-lb:0.1012, loss-ulb:0.0727, weight:1.81, lr:0.0008
[11:13:22.359] iteration:6478  t-loss:0.1414, loss-lb:0.0911, loss-ulb:0.0277, weight:1.81, lr:0.0008
[11:13:22.551] iteration:6479  t-loss:0.1341, loss-lb:0.0872, loss-ulb:0.0259, weight:1.81, lr:0.0008
[11:13:22.743] iteration:6480  t-loss:0.1619, loss-lb:0.0974, loss-ulb:0.0355, weight:1.81, lr:0.0008
[11:13:22.936] iteration:6481  t-loss:0.1462, loss-lb:0.0964, loss-ulb:0.0274, weight:1.81, lr:0.0008
[11:13:23.128] iteration:6482  t-loss:0.1470, loss-lb:0.0926, loss-ulb:0.0300, weight:1.81, lr:0.0008
[11:13:23.320] iteration:6483  t-loss:0.1420, loss-lb:0.1020, loss-ulb:0.0221, weight:1.81, lr:0.0008
[11:13:23.514] iteration:6484  t-loss:0.1387, loss-lb:0.0911, loss-ulb:0.0263, weight:1.81, lr:0.0008
[11:13:23.708] iteration:6485  t-loss:0.1808, loss-lb:0.1049, loss-ulb:0.0419, weight:1.81, lr:0.0008
[11:13:23.914] iteration:6486  t-loss:0.2894, loss-lb:0.0903, loss-ulb:0.1098, weight:1.81, lr:0.0008
[11:13:24.124] iteration:6487  t-loss:0.1527, loss-lb:0.1112, loss-ulb:0.0229, weight:1.81, lr:0.0008
[11:13:24.318] iteration:6488  t-loss:0.1443, loss-lb:0.0925, loss-ulb:0.0286, weight:1.81, lr:0.0008
[11:13:24.511] iteration:6489  t-loss:0.1328, loss-lb:0.0958, loss-ulb:0.0204, weight:1.81, lr:0.0008
[11:13:24.702] iteration:6490  t-loss:0.1573, loss-lb:0.1017, loss-ulb:0.0307, weight:1.81, lr:0.0008
[11:13:24.894] iteration:6491  t-loss:0.1567, loss-lb:0.0977, loss-ulb:0.0326, weight:1.81, lr:0.0008
[11:13:25.086] iteration:6492  t-loss:0.1562, loss-lb:0.1023, loss-ulb:0.0297, weight:1.81, lr:0.0008
[11:13:25.280] iteration:6493  t-loss:0.1317, loss-lb:0.0868, loss-ulb:0.0247, weight:1.81, lr:0.0008
[11:13:25.473] iteration:6494  t-loss:0.1785, loss-lb:0.1050, loss-ulb:0.0405, weight:1.81, lr:0.0008
[11:13:25.666] iteration:6495  t-loss:0.1860, loss-lb:0.0923, loss-ulb:0.0516, weight:1.81, lr:0.0008
[11:13:25.858] iteration:6496  t-loss:0.1411, loss-lb:0.0961, loss-ulb:0.0248, weight:1.81, lr:0.0008
[11:13:26.051] iteration:6497  t-loss:0.1384, loss-lb:0.0968, loss-ulb:0.0230, weight:1.81, lr:0.0008
[11:13:26.243] iteration:6498  t-loss:0.1916, loss-lb:0.0863, loss-ulb:0.0581, weight:1.81, lr:0.0008
[11:13:26.435] iteration:6499  t-loss:0.1548, loss-lb:0.0836, loss-ulb:0.0392, weight:1.81, lr:0.0008
[11:13:26.627] iteration:6500  t-loss:0.1464, loss-lb:0.0948, loss-ulb:0.0284, weight:1.81, lr:0.0008
[11:13:26.819] iteration:6501  t-loss:0.1323, loss-lb:0.0826, loss-ulb:0.0274, weight:1.81, lr:0.0008
[11:13:27.014] iteration:6502  t-loss:0.2263, loss-lb:0.0893, loss-ulb:0.0756, weight:1.81, lr:0.0008
[11:13:27.205] iteration:6503  t-loss:0.1390, loss-lb:0.0970, loss-ulb:0.0232, weight:1.81, lr:0.0008
[11:13:27.397] iteration:6504  t-loss:0.1438, loss-lb:0.0933, loss-ulb:0.0278, weight:1.81, lr:0.0008
[11:13:27.589] iteration:6505  t-loss:0.1501, loss-lb:0.0991, loss-ulb:0.0281, weight:1.81, lr:0.0008
[11:13:27.781] iteration:6506  t-loss:0.1403, loss-lb:0.0963, loss-ulb:0.0243, weight:1.81, lr:0.0008
[11:13:27.974] iteration:6507  t-loss:0.1522, loss-lb:0.0965, loss-ulb:0.0307, weight:1.81, lr:0.0008
[11:13:28.166] iteration:6508  t-loss:0.1596, loss-lb:0.0975, loss-ulb:0.0343, weight:1.81, lr:0.0008
[11:13:28.359] iteration:6509  t-loss:0.2181, loss-lb:0.0925, loss-ulb:0.0693, weight:1.81, lr:0.0008
[11:13:28.552] iteration:6510  t-loss:0.1488, loss-lb:0.1020, loss-ulb:0.0258, weight:1.81, lr:0.0008
[11:13:28.743] iteration:6511  t-loss:0.1568, loss-lb:0.1022, loss-ulb:0.0301, weight:1.81, lr:0.0008
[11:13:28.935] iteration:6512  t-loss:0.1404, loss-lb:0.0926, loss-ulb:0.0264, weight:1.81, lr:0.0008
[11:13:29.127] iteration:6513  t-loss:0.1357, loss-lb:0.0909, loss-ulb:0.0247, weight:1.81, lr:0.0008
[11:13:29.318] iteration:6514  t-loss:0.1493, loss-lb:0.0969, loss-ulb:0.0289, weight:1.81, lr:0.0008
[11:13:29.511] iteration:6515  t-loss:0.1564, loss-lb:0.0953, loss-ulb:0.0337, weight:1.81, lr:0.0008
[11:13:29.702] iteration:6516  t-loss:0.1323, loss-lb:0.0859, loss-ulb:0.0256, weight:1.81, lr:0.0008
[11:13:29.895] iteration:6517  t-loss:0.1610, loss-lb:0.1083, loss-ulb:0.0291, weight:1.81, lr:0.0008
[11:13:30.088] iteration:6518  t-loss:0.2127, loss-lb:0.0926, loss-ulb:0.0663, weight:1.81, lr:0.0008
[11:13:30.280] iteration:6519  t-loss:0.1457, loss-lb:0.0890, loss-ulb:0.0313, weight:1.81, lr:0.0008
[11:13:30.472] iteration:6520  t-loss:0.1589, loss-lb:0.0898, loss-ulb:0.0381, weight:1.81, lr:0.0008
[11:13:30.664] iteration:6521  t-loss:0.1826, loss-lb:0.1000, loss-ulb:0.0455, weight:1.81, lr:0.0008
[11:13:30.860] iteration:6522  t-loss:0.1575, loss-lb:0.0954, loss-ulb:0.0343, weight:1.81, lr:0.0008
[11:13:31.054] iteration:6523  t-loss:0.1458, loss-lb:0.0881, loss-ulb:0.0318, weight:1.81, lr:0.0008
[11:13:31.247] iteration:6524  t-loss:0.1612, loss-lb:0.1036, loss-ulb:0.0317, weight:1.81, lr:0.0008
[11:13:31.441] iteration:6525  t-loss:0.1468, loss-lb:0.0924, loss-ulb:0.0300, weight:1.81, lr:0.0008
[11:13:31.633] iteration:6526  t-loss:0.1568, loss-lb:0.0933, loss-ulb:0.0350, weight:1.81, lr:0.0008
[11:13:31.824] iteration:6527  t-loss:0.1418, loss-lb:0.0997, loss-ulb:0.0232, weight:1.81, lr:0.0008
[11:13:32.016] iteration:6528  t-loss:0.1322, loss-lb:0.0921, loss-ulb:0.0222, weight:1.81, lr:0.0008
[11:13:32.207] iteration:6529  t-loss:0.1376, loss-lb:0.0912, loss-ulb:0.0256, weight:1.81, lr:0.0008
[11:13:32.399] iteration:6530  t-loss:0.1418, loss-lb:0.0964, loss-ulb:0.0250, weight:1.81, lr:0.0008
[11:13:32.590] iteration:6531  t-loss:0.1776, loss-lb:0.0908, loss-ulb:0.0479, weight:1.81, lr:0.0008
[11:13:32.782] iteration:6532  t-loss:0.1833, loss-lb:0.1056, loss-ulb:0.0428, weight:1.81, lr:0.0008
[11:13:32.974] iteration:6533  t-loss:0.1593, loss-lb:0.0975, loss-ulb:0.0341, weight:1.81, lr:0.0008
[11:13:33.165] iteration:6534  t-loss:0.2728, loss-lb:0.1328, loss-ulb:0.0772, weight:1.81, lr:0.0008
[11:13:33.357] iteration:6535  t-loss:0.2116, loss-lb:0.0930, loss-ulb:0.0654, weight:1.81, lr:0.0008
[11:13:33.548] iteration:6536  t-loss:0.1493, loss-lb:0.1026, loss-ulb:0.0258, weight:1.81, lr:0.0008
[11:13:33.740] iteration:6537  t-loss:0.1480, loss-lb:0.0883, loss-ulb:0.0329, weight:1.81, lr:0.0008
[11:13:33.932] iteration:6538  t-loss:0.1880, loss-lb:0.1003, loss-ulb:0.0484, weight:1.81, lr:0.0008
[11:13:34.123] iteration:6539  t-loss:0.1538, loss-lb:0.1046, loss-ulb:0.0272, weight:1.81, lr:0.0008
[11:13:34.316] iteration:6540  t-loss:0.1564, loss-lb:0.1014, loss-ulb:0.0303, weight:1.81, lr:0.0008
[11:13:34.509] iteration:6541  t-loss:0.2485, loss-lb:0.1065, loss-ulb:0.0783, weight:1.81, lr:0.0008
[11:13:34.702] iteration:6542  t-loss:0.2104, loss-lb:0.1020, loss-ulb:0.0598, weight:1.81, lr:0.0008
[11:13:34.894] iteration:6543  t-loss:0.1781, loss-lb:0.1171, loss-ulb:0.0336, weight:1.81, lr:0.0008
[11:13:35.086] iteration:6544  t-loss:0.1504, loss-lb:0.1047, loss-ulb:0.0252, weight:1.81, lr:0.0008
[11:13:35.278] iteration:6545  t-loss:0.1795, loss-lb:0.1051, loss-ulb:0.0411, weight:1.81, lr:0.0008
[11:13:35.470] iteration:6546  t-loss:0.1965, loss-lb:0.1428, loss-ulb:0.0296, weight:1.81, lr:0.0008
[11:13:35.663] iteration:6547  t-loss:0.1720, loss-lb:0.1091, loss-ulb:0.0347, weight:1.81, lr:0.0008
[11:13:35.856] iteration:6548  t-loss:0.2550, loss-lb:0.0992, loss-ulb:0.0859, weight:1.81, lr:0.0008
[11:13:36.048] iteration:6549  t-loss:0.1446, loss-lb:0.0984, loss-ulb:0.0255, weight:1.81, lr:0.0008
[11:13:36.240] iteration:6550  t-loss:0.1683, loss-lb:0.1291, loss-ulb:0.0217, weight:1.81, lr:0.0008
[11:13:36.433] iteration:6551  t-loss:0.2501, loss-lb:0.1308, loss-ulb:0.0658, weight:1.81, lr:0.0008
[11:13:36.625] iteration:6552  t-loss:0.1622, loss-lb:0.1007, loss-ulb:0.0339, weight:1.81, lr:0.0008
[11:13:36.817] iteration:6553  t-loss:0.1611, loss-lb:0.0976, loss-ulb:0.0350, weight:1.81, lr:0.0008
[11:13:37.010] iteration:6554  t-loss:0.1464, loss-lb:0.0936, loss-ulb:0.0291, weight:1.81, lr:0.0008
[11:13:37.203] iteration:6555  t-loss:0.1595, loss-lb:0.0940, loss-ulb:0.0361, weight:1.81, lr:0.0008
[11:13:37.394] iteration:6556  t-loss:0.1973, loss-lb:0.1476, loss-ulb:0.0274, weight:1.81, lr:0.0008
[11:13:37.587] iteration:6557  t-loss:0.1721, loss-lb:0.0953, loss-ulb:0.0423, weight:1.81, lr:0.0008
[11:13:37.780] iteration:6558  t-loss:0.1599, loss-lb:0.0984, loss-ulb:0.0340, weight:1.81, lr:0.0008
[11:13:37.971] iteration:6559  t-loss:0.1516, loss-lb:0.1022, loss-ulb:0.0273, weight:1.81, lr:0.0008
[11:13:38.161] iteration:6560  t-loss:0.1862, loss-lb:0.1112, loss-ulb:0.0414, weight:1.81, lr:0.0008
[11:13:38.352] iteration:6561  t-loss:0.1522, loss-lb:0.0992, loss-ulb:0.0292, weight:1.81, lr:0.0008
[11:13:38.543] iteration:6562  t-loss:0.2218, loss-lb:0.1255, loss-ulb:0.0531, weight:1.81, lr:0.0008
[11:13:38.734] iteration:6563  t-loss:0.1457, loss-lb:0.0906, loss-ulb:0.0304, weight:1.81, lr:0.0008
[11:13:38.924] iteration:6564  t-loss:0.1934, loss-lb:0.1024, loss-ulb:0.0502, weight:1.81, lr:0.0008
[11:13:39.116] iteration:6565  t-loss:0.1839, loss-lb:0.1119, loss-ulb:0.0397, weight:1.81, lr:0.0008
[11:13:39.306] iteration:6566  t-loss:0.1739, loss-lb:0.1043, loss-ulb:0.0384, weight:1.81, lr:0.0008
[11:13:51.462]  <<Test>> - Ep:66  - mean_dice/mean_h95 - S:89.62/1.47, Best-S:90.13, T:90.18/1.34, Best-T:90.22
[11:13:51.463]           - AvgLoss(lb/ulb/all):0.0997/0.0391/0.1779
[11:13:51.992] iteration:6567  t-loss:0.1729, loss-lb:0.1091, loss-ulb:0.0352, weight:1.81, lr:0.0008
[11:13:52.190] iteration:6568  t-loss:0.1576, loss-lb:0.1042, loss-ulb:0.0295, weight:1.81, lr:0.0008
[11:13:52.384] iteration:6569  t-loss:0.1429, loss-lb:0.0953, loss-ulb:0.0262, weight:1.81, lr:0.0008
[11:13:52.577] iteration:6570  t-loss:0.1509, loss-lb:0.1049, loss-ulb:0.0254, weight:1.81, lr:0.0008
[11:13:52.769] iteration:6571  t-loss:0.1397, loss-lb:0.0955, loss-ulb:0.0244, weight:1.81, lr:0.0008
[11:13:52.962] iteration:6572  t-loss:0.1907, loss-lb:0.1479, loss-ulb:0.0236, weight:1.81, lr:0.0008
[11:13:53.155] iteration:6573  t-loss:0.1726, loss-lb:0.1079, loss-ulb:0.0357, weight:1.81, lr:0.0008
[11:13:53.347] iteration:6574  t-loss:0.1751, loss-lb:0.0927, loss-ulb:0.0455, weight:1.81, lr:0.0008
[11:13:53.540] iteration:6575  t-loss:0.1744, loss-lb:0.1179, loss-ulb:0.0312, weight:1.81, lr:0.0008
[11:13:53.733] iteration:6576  t-loss:0.1781, loss-lb:0.1119, loss-ulb:0.0365, weight:1.81, lr:0.0008
[11:13:53.926] iteration:6577  t-loss:0.1870, loss-lb:0.0992, loss-ulb:0.0484, weight:1.81, lr:0.0008
[11:13:54.118] iteration:6578  t-loss:0.1779, loss-lb:0.0982, loss-ulb:0.0439, weight:1.81, lr:0.0008
[11:13:54.311] iteration:6579  t-loss:0.1537, loss-lb:0.0901, loss-ulb:0.0350, weight:1.81, lr:0.0008
[11:13:54.504] iteration:6580  t-loss:0.1457, loss-lb:0.1011, loss-ulb:0.0246, weight:1.81, lr:0.0008
[11:13:54.697] iteration:6581  t-loss:0.1606, loss-lb:0.0999, loss-ulb:0.0335, weight:1.81, lr:0.0008
[11:13:54.890] iteration:6582  t-loss:0.1541, loss-lb:0.1023, loss-ulb:0.0285, weight:1.81, lr:0.0008
[11:13:55.083] iteration:6583  t-loss:0.1860, loss-lb:0.1048, loss-ulb:0.0447, weight:1.81, lr:0.0008
[11:13:55.276] iteration:6584  t-loss:0.2341, loss-lb:0.1392, loss-ulb:0.0523, weight:1.81, lr:0.0008
[11:13:55.469] iteration:6585  t-loss:0.1544, loss-lb:0.1100, loss-ulb:0.0245, weight:1.81, lr:0.0008
[11:13:55.661] iteration:6586  t-loss:0.1680, loss-lb:0.0909, loss-ulb:0.0425, weight:1.81, lr:0.0008
[11:13:55.854] iteration:6587  t-loss:0.1596, loss-lb:0.0961, loss-ulb:0.0350, weight:1.81, lr:0.0008
[11:13:56.047] iteration:6588  t-loss:0.1867, loss-lb:0.1155, loss-ulb:0.0393, weight:1.81, lr:0.0008
[11:13:56.240] iteration:6589  t-loss:0.1427, loss-lb:0.0962, loss-ulb:0.0256, weight:1.81, lr:0.0008
[11:13:56.432] iteration:6590  t-loss:0.1852, loss-lb:0.0922, loss-ulb:0.0513, weight:1.81, lr:0.0008
[11:13:56.624] iteration:6591  t-loss:0.1444, loss-lb:0.1040, loss-ulb:0.0223, weight:1.81, lr:0.0008
[11:13:56.817] iteration:6592  t-loss:0.1568, loss-lb:0.1076, loss-ulb:0.0271, weight:1.81, lr:0.0008
[11:13:57.010] iteration:6593  t-loss:0.2660, loss-lb:0.2025, loss-ulb:0.0350, weight:1.81, lr:0.0008
[11:13:57.203] iteration:6594  t-loss:0.1828, loss-lb:0.1274, loss-ulb:0.0305, weight:1.81, lr:0.0008
[11:13:57.397] iteration:6595  t-loss:0.1843, loss-lb:0.1049, loss-ulb:0.0438, weight:1.81, lr:0.0008
[11:13:57.589] iteration:6596  t-loss:0.1713, loss-lb:0.1095, loss-ulb:0.0341, weight:1.81, lr:0.0008
[11:13:57.781] iteration:6597  t-loss:0.1800, loss-lb:0.1240, loss-ulb:0.0308, weight:1.81, lr:0.0008
[11:13:57.974] iteration:6598  t-loss:0.1503, loss-lb:0.1029, loss-ulb:0.0261, weight:1.81, lr:0.0008
[11:13:58.167] iteration:6599  t-loss:0.1937, loss-lb:0.1071, loss-ulb:0.0477, weight:1.81, lr:0.0008
[11:13:58.360] iteration:6600  t-loss:0.1529, loss-lb:0.0957, loss-ulb:0.0316, weight:1.81, lr:0.0008
[11:13:58.552] iteration:6601  t-loss:0.1687, loss-lb:0.1052, loss-ulb:0.0341, weight:1.86, lr:0.0008
[11:13:58.745] iteration:6602  t-loss:0.1699, loss-lb:0.1035, loss-ulb:0.0357, weight:1.86, lr:0.0008
[11:13:58.938] iteration:6603  t-loss:0.1804, loss-lb:0.1182, loss-ulb:0.0334, weight:1.86, lr:0.0008
[11:13:59.130] iteration:6604  t-loss:0.1588, loss-lb:0.0931, loss-ulb:0.0353, weight:1.86, lr:0.0008
[11:13:59.322] iteration:6605  t-loss:0.1694, loss-lb:0.1170, loss-ulb:0.0281, weight:1.86, lr:0.0008
[11:13:59.515] iteration:6606  t-loss:0.1611, loss-lb:0.1086, loss-ulb:0.0282, weight:1.86, lr:0.0008
[11:13:59.707] iteration:6607  t-loss:0.1602, loss-lb:0.1036, loss-ulb:0.0304, weight:1.86, lr:0.0008
[11:13:59.900] iteration:6608  t-loss:0.2456, loss-lb:0.1130, loss-ulb:0.0713, weight:1.86, lr:0.0008
[11:14:00.092] iteration:6609  t-loss:0.1694, loss-lb:0.1093, loss-ulb:0.0323, weight:1.86, lr:0.0008
[11:14:00.285] iteration:6610  t-loss:0.1544, loss-lb:0.0986, loss-ulb:0.0300, weight:1.86, lr:0.0008
[11:14:00.476] iteration:6611  t-loss:0.1570, loss-lb:0.1050, loss-ulb:0.0279, weight:1.86, lr:0.0008
[11:14:00.668] iteration:6612  t-loss:0.1656, loss-lb:0.0996, loss-ulb:0.0355, weight:1.86, lr:0.0008
[11:14:00.860] iteration:6613  t-loss:0.1957, loss-lb:0.1055, loss-ulb:0.0484, weight:1.86, lr:0.0008
[11:14:01.054] iteration:6614  t-loss:0.1799, loss-lb:0.0978, loss-ulb:0.0441, weight:1.86, lr:0.0008
[11:14:01.246] iteration:6615  t-loss:0.1725, loss-lb:0.1184, loss-ulb:0.0290, weight:1.86, lr:0.0008
[11:14:01.440] iteration:6616  t-loss:0.1669, loss-lb:0.1030, loss-ulb:0.0343, weight:1.86, lr:0.0008
[11:14:01.633] iteration:6617  t-loss:0.1599, loss-lb:0.0973, loss-ulb:0.0336, weight:1.86, lr:0.0008
[11:14:01.825] iteration:6618  t-loss:0.1510, loss-lb:0.1061, loss-ulb:0.0241, weight:1.86, lr:0.0008
[11:14:02.017] iteration:6619  t-loss:0.1811, loss-lb:0.1095, loss-ulb:0.0385, weight:1.86, lr:0.0008
[11:14:02.210] iteration:6620  t-loss:0.1831, loss-lb:0.1107, loss-ulb:0.0389, weight:1.86, lr:0.0008
[11:14:02.403] iteration:6621  t-loss:0.1413, loss-lb:0.0959, loss-ulb:0.0244, weight:1.86, lr:0.0008
[11:14:02.595] iteration:6622  t-loss:0.1711, loss-lb:0.1044, loss-ulb:0.0358, weight:1.86, lr:0.0008
[11:14:02.787] iteration:6623  t-loss:0.1971, loss-lb:0.1380, loss-ulb:0.0317, weight:1.86, lr:0.0008
[11:14:02.979] iteration:6624  t-loss:0.2136, loss-lb:0.0960, loss-ulb:0.0632, weight:1.86, lr:0.0008
[11:14:03.171] iteration:6625  t-loss:0.2925, loss-lb:0.1004, loss-ulb:0.1032, weight:1.86, lr:0.0008
[11:14:03.363] iteration:6626  t-loss:0.1809, loss-lb:0.1148, loss-ulb:0.0355, weight:1.86, lr:0.0008
[11:14:03.563] iteration:6627  t-loss:0.1823, loss-lb:0.1029, loss-ulb:0.0427, weight:1.86, lr:0.0008
[11:14:03.765] iteration:6628  t-loss:0.2169, loss-lb:0.0975, loss-ulb:0.0642, weight:1.86, lr:0.0008
[11:14:03.961] iteration:6629  t-loss:0.1687, loss-lb:0.1192, loss-ulb:0.0266, weight:1.86, lr:0.0008
[11:14:04.153] iteration:6630  t-loss:0.1776, loss-lb:0.1112, loss-ulb:0.0357, weight:1.86, lr:0.0008
[11:14:04.345] iteration:6631  t-loss:0.2676, loss-lb:0.1216, loss-ulb:0.0785, weight:1.86, lr:0.0008
[11:14:04.537] iteration:6632  t-loss:0.1792, loss-lb:0.1152, loss-ulb:0.0344, weight:1.86, lr:0.0008
[11:14:04.730] iteration:6633  t-loss:0.1747, loss-lb:0.1115, loss-ulb:0.0340, weight:1.86, lr:0.0008
[11:14:04.921] iteration:6634  t-loss:0.2721, loss-lb:0.1093, loss-ulb:0.0874, weight:1.86, lr:0.0008
[11:14:05.114] iteration:6635  t-loss:0.2198, loss-lb:0.1079, loss-ulb:0.0601, weight:1.86, lr:0.0008
[11:14:05.306] iteration:6636  t-loss:0.1723, loss-lb:0.1077, loss-ulb:0.0347, weight:1.86, lr:0.0008
[11:14:05.498] iteration:6637  t-loss:0.1864, loss-lb:0.1135, loss-ulb:0.0392, weight:1.86, lr:0.0008
[11:14:05.692] iteration:6638  t-loss:0.1759, loss-lb:0.1028, loss-ulb:0.0393, weight:1.86, lr:0.0008
[11:14:05.883] iteration:6639  t-loss:0.1726, loss-lb:0.1007, loss-ulb:0.0386, weight:1.86, lr:0.0008
[11:14:06.075] iteration:6640  t-loss:0.1555, loss-lb:0.1024, loss-ulb:0.0285, weight:1.86, lr:0.0008
[11:14:06.269] iteration:6641  t-loss:0.2459, loss-lb:0.1022, loss-ulb:0.0772, weight:1.86, lr:0.0008
[11:14:06.461] iteration:6642  t-loss:0.1488, loss-lb:0.1066, loss-ulb:0.0227, weight:1.86, lr:0.0008
[11:14:06.654] iteration:6643  t-loss:0.1721, loss-lb:0.1137, loss-ulb:0.0314, weight:1.86, lr:0.0008
[11:14:06.847] iteration:6644  t-loss:0.1923, loss-lb:0.1395, loss-ulb:0.0283, weight:1.86, lr:0.0008
[11:14:07.039] iteration:6645  t-loss:0.1506, loss-lb:0.1052, loss-ulb:0.0244, weight:1.86, lr:0.0008
[11:14:07.230] iteration:6646  t-loss:0.1511, loss-lb:0.1008, loss-ulb:0.0270, weight:1.86, lr:0.0008
[11:14:07.423] iteration:6647  t-loss:0.1502, loss-lb:0.0955, loss-ulb:0.0294, weight:1.86, lr:0.0008
[11:14:07.615] iteration:6648  t-loss:0.2001, loss-lb:0.1130, loss-ulb:0.0468, weight:1.86, lr:0.0008
[11:14:07.807] iteration:6649  t-loss:0.1435, loss-lb:0.0980, loss-ulb:0.0245, weight:1.86, lr:0.0008
[11:14:08.000] iteration:6650  t-loss:0.1823, loss-lb:0.1121, loss-ulb:0.0377, weight:1.86, lr:0.0008
[11:14:08.192] iteration:6651  t-loss:0.1434, loss-lb:0.0933, loss-ulb:0.0269, weight:1.86, lr:0.0008
[11:14:08.384] iteration:6652  t-loss:0.1660, loss-lb:0.1041, loss-ulb:0.0332, weight:1.86, lr:0.0008
[11:14:08.577] iteration:6653  t-loss:0.1776, loss-lb:0.1120, loss-ulb:0.0353, weight:1.86, lr:0.0008
[11:14:08.769] iteration:6654  t-loss:0.1500, loss-lb:0.1054, loss-ulb:0.0240, weight:1.86, lr:0.0008
[11:14:08.962] iteration:6655  t-loss:0.1699, loss-lb:0.1056, loss-ulb:0.0346, weight:1.86, lr:0.0008
[11:14:09.154] iteration:6656  t-loss:0.2141, loss-lb:0.1061, loss-ulb:0.0580, weight:1.86, lr:0.0008
[11:14:09.345] iteration:6657  t-loss:0.1552, loss-lb:0.1039, loss-ulb:0.0276, weight:1.86, lr:0.0008
[11:14:09.536] iteration:6658  t-loss:0.2179, loss-lb:0.1469, loss-ulb:0.0381, weight:1.86, lr:0.0008
[11:14:09.727] iteration:6659  t-loss:0.2176, loss-lb:0.1284, loss-ulb:0.0479, weight:1.86, lr:0.0008
[11:14:09.917] iteration:6660  t-loss:0.1812, loss-lb:0.1153, loss-ulb:0.0354, weight:1.86, lr:0.0008
[11:14:10.109] iteration:6661  t-loss:0.1646, loss-lb:0.1042, loss-ulb:0.0325, weight:1.86, lr:0.0008
[11:14:10.299] iteration:6662  t-loss:0.2130, loss-lb:0.1187, loss-ulb:0.0506, weight:1.86, lr:0.0008
[11:14:10.490] iteration:6663  t-loss:0.1983, loss-lb:0.1163, loss-ulb:0.0441, weight:1.86, lr:0.0008
[11:14:10.680] iteration:6664  t-loss:0.2258, loss-lb:0.1265, loss-ulb:0.0533, weight:1.86, lr:0.0008
[11:14:11.254] iteration:6665  t-loss:0.1982, loss-lb:0.1154, loss-ulb:0.0444, weight:1.86, lr:0.0008
[11:14:11.450] iteration:6666  t-loss:0.1700, loss-lb:0.1169, loss-ulb:0.0285, weight:1.86, lr:0.0008
[11:14:11.642] iteration:6667  t-loss:0.1850, loss-lb:0.1124, loss-ulb:0.0390, weight:1.86, lr:0.0008
[11:14:11.835] iteration:6668  t-loss:0.1767, loss-lb:0.1170, loss-ulb:0.0321, weight:1.86, lr:0.0008
[11:14:12.027] iteration:6669  t-loss:0.1724, loss-lb:0.1165, loss-ulb:0.0300, weight:1.86, lr:0.0008
[11:14:12.220] iteration:6670  t-loss:0.2789, loss-lb:0.1409, loss-ulb:0.0742, weight:1.86, lr:0.0008
[11:14:12.412] iteration:6671  t-loss:0.1672, loss-lb:0.1073, loss-ulb:0.0322, weight:1.86, lr:0.0008
[11:14:12.606] iteration:6672  t-loss:0.3144, loss-lb:0.1138, loss-ulb:0.1078, weight:1.86, lr:0.0008
[11:14:12.798] iteration:6673  t-loss:0.2027, loss-lb:0.1186, loss-ulb:0.0452, weight:1.86, lr:0.0008
[11:14:12.990] iteration:6674  t-loss:0.2769, loss-lb:0.1002, loss-ulb:0.0950, weight:1.86, lr:0.0008
[11:14:13.182] iteration:6675  t-loss:0.1671, loss-lb:0.1059, loss-ulb:0.0329, weight:1.86, lr:0.0008
[11:14:13.373] iteration:6676  t-loss:0.1713, loss-lb:0.1123, loss-ulb:0.0317, weight:1.86, lr:0.0008
[11:14:13.565] iteration:6677  t-loss:0.1674, loss-lb:0.1101, loss-ulb:0.0308, weight:1.86, lr:0.0008
[11:14:13.758] iteration:6678  t-loss:0.1736, loss-lb:0.1129, loss-ulb:0.0326, weight:1.86, lr:0.0008
[11:14:13.950] iteration:6679  t-loss:0.2185, loss-lb:0.1101, loss-ulb:0.0582, weight:1.86, lr:0.0008
[11:14:14.144] iteration:6680  t-loss:0.2231, loss-lb:0.0976, loss-ulb:0.0675, weight:1.86, lr:0.0008
[11:14:14.337] iteration:6681  t-loss:0.1586, loss-lb:0.1047, loss-ulb:0.0290, weight:1.86, lr:0.0008
[11:14:14.530] iteration:6682  t-loss:0.1874, loss-lb:0.1132, loss-ulb:0.0399, weight:1.86, lr:0.0008
[11:14:14.722] iteration:6683  t-loss:0.2833, loss-lb:0.1166, loss-ulb:0.0896, weight:1.86, lr:0.0008
[11:14:14.915] iteration:6684  t-loss:0.1873, loss-lb:0.0985, loss-ulb:0.0477, weight:1.86, lr:0.0008
[11:14:15.108] iteration:6685  t-loss:0.3036, loss-lb:0.1019, loss-ulb:0.1084, weight:1.86, lr:0.0008
[11:14:15.301] iteration:6686  t-loss:0.1741, loss-lb:0.1123, loss-ulb:0.0332, weight:1.86, lr:0.0008
[11:14:15.494] iteration:6687  t-loss:0.1728, loss-lb:0.1216, loss-ulb:0.0275, weight:1.86, lr:0.0008
[11:14:15.691] iteration:6688  t-loss:0.1725, loss-lb:0.0897, loss-ulb:0.0445, weight:1.86, lr:0.0008
[11:14:15.884] iteration:6689  t-loss:0.1795, loss-lb:0.1207, loss-ulb:0.0316, weight:1.86, lr:0.0008
[11:14:16.085] iteration:6690  t-loss:0.1575, loss-lb:0.1021, loss-ulb:0.0298, weight:1.86, lr:0.0008
[11:14:16.278] iteration:6691  t-loss:0.2005, loss-lb:0.1396, loss-ulb:0.0328, weight:1.86, lr:0.0008
[11:14:16.469] iteration:6692  t-loss:0.1983, loss-lb:0.1163, loss-ulb:0.0441, weight:1.86, lr:0.0008
[11:14:16.662] iteration:6693  t-loss:0.1592, loss-lb:0.0997, loss-ulb:0.0320, weight:1.86, lr:0.0008
[11:14:16.862] iteration:6694  t-loss:0.1692, loss-lb:0.0988, loss-ulb:0.0378, weight:1.86, lr:0.0008
[11:14:17.054] iteration:6695  t-loss:0.1768, loss-lb:0.0976, loss-ulb:0.0425, weight:1.86, lr:0.0008
[11:14:17.247] iteration:6696  t-loss:0.1563, loss-lb:0.1092, loss-ulb:0.0253, weight:1.86, lr:0.0008
[11:14:17.439] iteration:6697  t-loss:0.1445, loss-lb:0.1009, loss-ulb:0.0234, weight:1.86, lr:0.0008
[11:14:17.638] iteration:6698  t-loss:0.1364, loss-lb:0.0904, loss-ulb:0.0247, weight:1.86, lr:0.0008
[11:14:17.833] iteration:6699  t-loss:0.1623, loss-lb:0.1002, loss-ulb:0.0334, weight:1.86, lr:0.0008
[11:14:18.026] iteration:6700  t-loss:0.1737, loss-lb:0.1358, loss-ulb:0.0203, weight:1.86, lr:0.0008
[11:14:18.219] iteration:6701  t-loss:0.1994, loss-lb:0.1012, loss-ulb:0.0527, weight:1.86, lr:0.0008
[11:14:18.412] iteration:6702  t-loss:0.2146, loss-lb:0.0977, loss-ulb:0.0628, weight:1.86, lr:0.0008
[11:14:18.604] iteration:6703  t-loss:0.1786, loss-lb:0.1006, loss-ulb:0.0419, weight:1.86, lr:0.0008
[11:14:18.798] iteration:6704  t-loss:0.1630, loss-lb:0.1101, loss-ulb:0.0284, weight:1.86, lr:0.0008
[11:14:18.990] iteration:6705  t-loss:0.1440, loss-lb:0.1022, loss-ulb:0.0225, weight:1.86, lr:0.0008
[11:14:19.183] iteration:6706  t-loss:0.1566, loss-lb:0.1072, loss-ulb:0.0265, weight:1.86, lr:0.0008
[11:14:19.375] iteration:6707  t-loss:0.1861, loss-lb:0.1035, loss-ulb:0.0444, weight:1.86, lr:0.0008
[11:14:19.567] iteration:6708  t-loss:0.1533, loss-lb:0.1002, loss-ulb:0.0285, weight:1.86, lr:0.0008
[11:14:19.759] iteration:6709  t-loss:0.1596, loss-lb:0.0978, loss-ulb:0.0332, weight:1.86, lr:0.0008
[11:14:19.952] iteration:6710  t-loss:0.1602, loss-lb:0.0989, loss-ulb:0.0329, weight:1.86, lr:0.0008
[11:14:20.144] iteration:6711  t-loss:0.2082, loss-lb:0.1134, loss-ulb:0.0509, weight:1.86, lr:0.0008
[11:14:20.336] iteration:6712  t-loss:0.1535, loss-lb:0.1064, loss-ulb:0.0253, weight:1.86, lr:0.0008
[11:14:20.528] iteration:6713  t-loss:0.1626, loss-lb:0.1000, loss-ulb:0.0336, weight:1.86, lr:0.0008
[11:14:20.721] iteration:6714  t-loss:0.2487, loss-lb:0.1026, loss-ulb:0.0785, weight:1.86, lr:0.0008
[11:14:20.914] iteration:6715  t-loss:0.1641, loss-lb:0.1008, loss-ulb:0.0340, weight:1.86, lr:0.0008
[11:14:21.107] iteration:6716  t-loss:0.1484, loss-lb:0.1015, loss-ulb:0.0252, weight:1.86, lr:0.0008
[11:14:21.300] iteration:6717  t-loss:0.1427, loss-lb:0.0895, loss-ulb:0.0286, weight:1.86, lr:0.0008
[11:14:21.491] iteration:6718  t-loss:0.1501, loss-lb:0.0960, loss-ulb:0.0291, weight:1.86, lr:0.0008
[11:14:21.684] iteration:6719  t-loss:0.1536, loss-lb:0.1021, loss-ulb:0.0276, weight:1.86, lr:0.0008
[11:14:21.876] iteration:6720  t-loss:0.1720, loss-lb:0.1068, loss-ulb:0.0350, weight:1.86, lr:0.0008
[11:14:22.068] iteration:6721  t-loss:0.1816, loss-lb:0.1194, loss-ulb:0.0334, weight:1.86, lr:0.0008
[11:14:22.261] iteration:6722  t-loss:0.1562, loss-lb:0.1022, loss-ulb:0.0290, weight:1.86, lr:0.0008
[11:14:22.454] iteration:6723  t-loss:0.1958, loss-lb:0.1468, loss-ulb:0.0264, weight:1.86, lr:0.0008
[11:14:22.646] iteration:6724  t-loss:0.1778, loss-lb:0.0924, loss-ulb:0.0459, weight:1.86, lr:0.0008
[11:14:22.838] iteration:6725  t-loss:0.1684, loss-lb:0.0937, loss-ulb:0.0401, weight:1.86, lr:0.0008
[11:14:23.031] iteration:6726  t-loss:0.1467, loss-lb:0.0933, loss-ulb:0.0287, weight:1.86, lr:0.0008
[11:14:23.225] iteration:6727  t-loss:0.1490, loss-lb:0.0998, loss-ulb:0.0265, weight:1.86, lr:0.0008
[11:14:23.418] iteration:6728  t-loss:0.1520, loss-lb:0.0975, loss-ulb:0.0293, weight:1.86, lr:0.0008
[11:14:23.611] iteration:6729  t-loss:0.1562, loss-lb:0.0974, loss-ulb:0.0316, weight:1.86, lr:0.0008
[11:14:23.803] iteration:6730  t-loss:0.1524, loss-lb:0.0984, loss-ulb:0.0290, weight:1.86, lr:0.0008
[11:14:23.995] iteration:6731  t-loss:0.1408, loss-lb:0.0937, loss-ulb:0.0253, weight:1.86, lr:0.0008
[11:14:24.187] iteration:6732  t-loss:0.1612, loss-lb:0.1172, loss-ulb:0.0237, weight:1.86, lr:0.0008
[11:14:24.379] iteration:6733  t-loss:0.1439, loss-lb:0.0968, loss-ulb:0.0253, weight:1.86, lr:0.0008
[11:14:24.571] iteration:6734  t-loss:0.1884, loss-lb:0.1328, loss-ulb:0.0299, weight:1.86, lr:0.0008
[11:14:24.765] iteration:6735  t-loss:0.1506, loss-lb:0.0990, loss-ulb:0.0277, weight:1.86, lr:0.0008
[11:14:24.957] iteration:6736  t-loss:0.1517, loss-lb:0.1044, loss-ulb:0.0254, weight:1.86, lr:0.0008
[11:14:25.156] iteration:6737  t-loss:0.1371, loss-lb:0.0878, loss-ulb:0.0265, weight:1.86, lr:0.0008
[11:14:25.352] iteration:6738  t-loss:0.1542, loss-lb:0.1004, loss-ulb:0.0289, weight:1.86, lr:0.0008
[11:14:25.545] iteration:6739  t-loss:0.1718, loss-lb:0.1146, loss-ulb:0.0308, weight:1.86, lr:0.0008
[11:14:25.736] iteration:6740  t-loss:0.1640, loss-lb:0.1101, loss-ulb:0.0290, weight:1.86, lr:0.0008
[11:14:25.928] iteration:6741  t-loss:0.2232, loss-lb:0.0975, loss-ulb:0.0676, weight:1.86, lr:0.0008
[11:14:26.121] iteration:6742  t-loss:0.1561, loss-lb:0.0910, loss-ulb:0.0350, weight:1.86, lr:0.0008
[11:14:26.312] iteration:6743  t-loss:0.1611, loss-lb:0.1040, loss-ulb:0.0307, weight:1.86, lr:0.0008
[11:14:26.505] iteration:6744  t-loss:0.1395, loss-lb:0.0908, loss-ulb:0.0261, weight:1.86, lr:0.0008
[11:14:26.697] iteration:6745  t-loss:0.1441, loss-lb:0.0931, loss-ulb:0.0274, weight:1.86, lr:0.0008
[11:14:26.889] iteration:6746  t-loss:0.1502, loss-lb:0.1011, loss-ulb:0.0264, weight:1.86, lr:0.0008
[11:14:27.082] iteration:6747  t-loss:0.1694, loss-lb:0.0920, loss-ulb:0.0416, weight:1.86, lr:0.0008
[11:14:27.274] iteration:6748  t-loss:0.1544, loss-lb:0.0978, loss-ulb:0.0304, weight:1.86, lr:0.0008
[11:14:27.465] iteration:6749  t-loss:0.2897, loss-lb:0.1037, loss-ulb:0.1000, weight:1.86, lr:0.0008
[11:14:27.655] iteration:6750  t-loss:0.1850, loss-lb:0.1029, loss-ulb:0.0441, weight:1.86, lr:0.0008
[11:14:27.847] iteration:6751  t-loss:0.1420, loss-lb:0.0992, loss-ulb:0.0225, weight:1.90, lr:0.0008
[11:14:28.039] iteration:6752  t-loss:0.1517, loss-lb:0.0957, loss-ulb:0.0294, weight:1.90, lr:0.0008
[11:14:28.234] iteration:6753  t-loss:0.1468, loss-lb:0.0971, loss-ulb:0.0261, weight:1.90, lr:0.0008
[11:14:28.426] iteration:6754  t-loss:0.1715, loss-lb:0.1142, loss-ulb:0.0301, weight:1.90, lr:0.0008
[11:14:28.617] iteration:6755  t-loss:0.1469, loss-lb:0.0928, loss-ulb:0.0284, weight:1.90, lr:0.0008
[11:14:28.809] iteration:6756  t-loss:0.1534, loss-lb:0.0955, loss-ulb:0.0304, weight:1.90, lr:0.0008
[11:14:29.001] iteration:6757  t-loss:0.1601, loss-lb:0.1082, loss-ulb:0.0273, weight:1.90, lr:0.0008
[11:14:29.194] iteration:6758  t-loss:0.2557, loss-lb:0.1136, loss-ulb:0.0747, weight:1.90, lr:0.0008
[11:14:29.384] iteration:6759  t-loss:0.1377, loss-lb:0.0874, loss-ulb:0.0265, weight:1.90, lr:0.0008
[11:14:29.574] iteration:6760  t-loss:0.1620, loss-lb:0.1061, loss-ulb:0.0294, weight:1.90, lr:0.0008
[11:14:29.766] iteration:6761  t-loss:0.2020, loss-lb:0.1410, loss-ulb:0.0321, weight:1.90, lr:0.0008
[11:14:29.955] iteration:6762  t-loss:0.1869, loss-lb:0.1343, loss-ulb:0.0277, weight:1.90, lr:0.0008
[11:14:41.488]  <<Test>> - Ep:68  - mean_dice/mean_h95 - S:88.91/3.49, Best-S:90.13, T:89.99/1.37, Best-T:90.22
[11:14:41.488]           - AvgLoss(lb/ulb/all):0.1058/0.0356/0.1705
[11:14:42.020] iteration:6763  t-loss:0.1562, loss-lb:0.1080, loss-ulb:0.0254, weight:1.90, lr:0.0008
[11:14:42.216] iteration:6764  t-loss:0.1804, loss-lb:0.1135, loss-ulb:0.0352, weight:1.90, lr:0.0008
[11:14:42.410] iteration:6765  t-loss:0.1585, loss-lb:0.1007, loss-ulb:0.0304, weight:1.90, lr:0.0008
[11:14:42.600] iteration:6766  t-loss:0.1657, loss-lb:0.1088, loss-ulb:0.0299, weight:1.90, lr:0.0008
[11:14:42.792] iteration:6767  t-loss:0.1896, loss-lb:0.1202, loss-ulb:0.0365, weight:1.90, lr:0.0008
[11:14:42.986] iteration:6768  t-loss:0.1766, loss-lb:0.1231, loss-ulb:0.0282, weight:1.90, lr:0.0008
[11:14:43.178] iteration:6769  t-loss:0.1884, loss-lb:0.1028, loss-ulb:0.0450, weight:1.90, lr:0.0008
[11:14:43.371] iteration:6770  t-loss:0.1966, loss-lb:0.1110, loss-ulb:0.0450, weight:1.90, lr:0.0008
[11:14:43.563] iteration:6771  t-loss:0.1361, loss-lb:0.0888, loss-ulb:0.0249, weight:1.90, lr:0.0008
[11:14:43.754] iteration:6772  t-loss:0.1428, loss-lb:0.0940, loss-ulb:0.0257, weight:1.90, lr:0.0008
[11:14:43.946] iteration:6773  t-loss:0.1455, loss-lb:0.0876, loss-ulb:0.0304, weight:1.90, lr:0.0008
[11:14:44.138] iteration:6774  t-loss:0.1676, loss-lb:0.0959, loss-ulb:0.0377, weight:1.90, lr:0.0008
[11:14:44.330] iteration:6775  t-loss:0.1597, loss-lb:0.1021, loss-ulb:0.0302, weight:1.90, lr:0.0008
[11:14:44.521] iteration:6776  t-loss:0.1986, loss-lb:0.0944, loss-ulb:0.0548, weight:1.90, lr:0.0008
[11:14:44.714] iteration:6777  t-loss:0.1649, loss-lb:0.1017, loss-ulb:0.0332, weight:1.90, lr:0.0008
[11:14:44.905] iteration:6778  t-loss:0.1538, loss-lb:0.1017, loss-ulb:0.0274, weight:1.90, lr:0.0008
[11:14:45.096] iteration:6779  t-loss:0.1617, loss-lb:0.1077, loss-ulb:0.0284, weight:1.90, lr:0.0008
[11:14:45.287] iteration:6780  t-loss:0.2042, loss-lb:0.0979, loss-ulb:0.0558, weight:1.90, lr:0.0008
[11:14:45.478] iteration:6781  t-loss:0.1522, loss-lb:0.1042, loss-ulb:0.0252, weight:1.90, lr:0.0008
[11:14:45.670] iteration:6782  t-loss:0.2029, loss-lb:0.0991, loss-ulb:0.0546, weight:1.90, lr:0.0008
[11:14:45.860] iteration:6783  t-loss:0.1582, loss-lb:0.1114, loss-ulb:0.0246, weight:1.90, lr:0.0008
[11:14:46.052] iteration:6784  t-loss:0.1643, loss-lb:0.1035, loss-ulb:0.0319, weight:1.90, lr:0.0008
[11:14:46.244] iteration:6785  t-loss:0.1516, loss-lb:0.1042, loss-ulb:0.0249, weight:1.90, lr:0.0008
[11:14:46.436] iteration:6786  t-loss:0.1505, loss-lb:0.0941, loss-ulb:0.0297, weight:1.90, lr:0.0008
[11:14:46.629] iteration:6787  t-loss:0.1518, loss-lb:0.0931, loss-ulb:0.0309, weight:1.90, lr:0.0008
[11:14:46.827] iteration:6788  t-loss:0.1764, loss-lb:0.0983, loss-ulb:0.0410, weight:1.90, lr:0.0008
[11:14:47.022] iteration:6789  t-loss:0.2285, loss-lb:0.1482, loss-ulb:0.0422, weight:1.90, lr:0.0008
[11:14:47.216] iteration:6790  t-loss:0.1557, loss-lb:0.0956, loss-ulb:0.0316, weight:1.90, lr:0.0008
[11:14:47.411] iteration:6791  t-loss:0.2190, loss-lb:0.0927, loss-ulb:0.0664, weight:1.90, lr:0.0008
[11:14:47.601] iteration:6792  t-loss:0.2051, loss-lb:0.1128, loss-ulb:0.0485, weight:1.90, lr:0.0008
[11:14:47.793] iteration:6793  t-loss:0.1451, loss-lb:0.1047, loss-ulb:0.0213, weight:1.90, lr:0.0008
[11:14:47.985] iteration:6794  t-loss:0.1703, loss-lb:0.1155, loss-ulb:0.0288, weight:1.90, lr:0.0008
[11:14:48.178] iteration:6795  t-loss:0.1732, loss-lb:0.0859, loss-ulb:0.0459, weight:1.90, lr:0.0008
[11:14:48.370] iteration:6796  t-loss:0.2086, loss-lb:0.1013, loss-ulb:0.0564, weight:1.90, lr:0.0008
[11:14:48.563] iteration:6797  t-loss:0.1525, loss-lb:0.1036, loss-ulb:0.0257, weight:1.90, lr:0.0008
[11:14:48.755] iteration:6798  t-loss:0.1714, loss-lb:0.1003, loss-ulb:0.0374, weight:1.90, lr:0.0008
[11:14:48.946] iteration:6799  t-loss:0.1506, loss-lb:0.1028, loss-ulb:0.0251, weight:1.90, lr:0.0008
[11:14:49.139] iteration:6800  t-loss:0.1958, loss-lb:0.0970, loss-ulb:0.0520, weight:1.90, lr:0.0008
[11:14:49.330] iteration:6801  t-loss:0.1539, loss-lb:0.0955, loss-ulb:0.0307, weight:1.90, lr:0.0008
[11:14:49.524] iteration:6802  t-loss:0.1731, loss-lb:0.0935, loss-ulb:0.0418, weight:1.90, lr:0.0008
[11:14:49.716] iteration:6803  t-loss:0.1578, loss-lb:0.0940, loss-ulb:0.0335, weight:1.90, lr:0.0008
[11:14:49.907] iteration:6804  t-loss:0.2158, loss-lb:0.0870, loss-ulb:0.0677, weight:1.90, lr:0.0008
[11:14:50.099] iteration:6805  t-loss:0.1598, loss-lb:0.1073, loss-ulb:0.0276, weight:1.90, lr:0.0008
[11:14:50.291] iteration:6806  t-loss:0.1374, loss-lb:0.0897, loss-ulb:0.0251, weight:1.90, lr:0.0008
[11:14:50.482] iteration:6807  t-loss:0.1824, loss-lb:0.0948, loss-ulb:0.0461, weight:1.90, lr:0.0008
[11:14:50.674] iteration:6808  t-loss:0.1606, loss-lb:0.1059, loss-ulb:0.0288, weight:1.90, lr:0.0008
[11:14:50.866] iteration:6809  t-loss:0.1527, loss-lb:0.0972, loss-ulb:0.0291, weight:1.90, lr:0.0008
[11:14:51.056] iteration:6810  t-loss:0.1400, loss-lb:0.0903, loss-ulb:0.0261, weight:1.90, lr:0.0008
[11:14:51.250] iteration:6811  t-loss:0.1560, loss-lb:0.1005, loss-ulb:0.0291, weight:1.90, lr:0.0008
[11:14:51.442] iteration:6812  t-loss:0.1653, loss-lb:0.1099, loss-ulb:0.0291, weight:1.90, lr:0.0008
[11:14:51.636] iteration:6813  t-loss:0.1920, loss-lb:0.0980, loss-ulb:0.0494, weight:1.90, lr:0.0008
[11:14:51.828] iteration:6814  t-loss:0.1829, loss-lb:0.1051, loss-ulb:0.0409, weight:1.90, lr:0.0008
[11:14:52.021] iteration:6815  t-loss:0.1379, loss-lb:0.0924, loss-ulb:0.0239, weight:1.90, lr:0.0008
[11:14:52.214] iteration:6816  t-loss:0.1414, loss-lb:0.0924, loss-ulb:0.0258, weight:1.90, lr:0.0008
[11:14:52.405] iteration:6817  t-loss:0.1789, loss-lb:0.1348, loss-ulb:0.0232, weight:1.90, lr:0.0008
[11:14:52.597] iteration:6818  t-loss:0.2313, loss-lb:0.0890, loss-ulb:0.0748, weight:1.90, lr:0.0008
[11:14:52.790] iteration:6819  t-loss:0.1446, loss-lb:0.0840, loss-ulb:0.0318, weight:1.90, lr:0.0008
[11:14:52.982] iteration:6820  t-loss:0.1448, loss-lb:0.0930, loss-ulb:0.0272, weight:1.90, lr:0.0008
[11:14:53.175] iteration:6821  t-loss:0.1570, loss-lb:0.1083, loss-ulb:0.0256, weight:1.90, lr:0.0008
[11:14:53.366] iteration:6822  t-loss:0.1664, loss-lb:0.1096, loss-ulb:0.0298, weight:1.90, lr:0.0008
[11:14:53.557] iteration:6823  t-loss:0.1419, loss-lb:0.0943, loss-ulb:0.0250, weight:1.90, lr:0.0008
[11:14:53.750] iteration:6824  t-loss:0.1432, loss-lb:0.0963, loss-ulb:0.0246, weight:1.90, lr:0.0008
[11:14:53.943] iteration:6825  t-loss:0.2449, loss-lb:0.0976, loss-ulb:0.0774, weight:1.90, lr:0.0008
[11:14:54.135] iteration:6826  t-loss:0.1394, loss-lb:0.0973, loss-ulb:0.0221, weight:1.90, lr:0.0008
[11:14:54.326] iteration:6827  t-loss:0.1688, loss-lb:0.0967, loss-ulb:0.0379, weight:1.90, lr:0.0008
[11:14:54.519] iteration:6828  t-loss:0.1592, loss-lb:0.0933, loss-ulb:0.0347, weight:1.90, lr:0.0008
[11:14:54.710] iteration:6829  t-loss:0.1462, loss-lb:0.0985, loss-ulb:0.0251, weight:1.90, lr:0.0008
[11:14:54.901] iteration:6830  t-loss:0.1687, loss-lb:0.0922, loss-ulb:0.0402, weight:1.90, lr:0.0008
[11:14:55.093] iteration:6831  t-loss:0.1409, loss-lb:0.0854, loss-ulb:0.0291, weight:1.90, lr:0.0008
[11:14:55.284] iteration:6832  t-loss:0.1342, loss-lb:0.0898, loss-ulb:0.0233, weight:1.90, lr:0.0008
[11:14:55.475] iteration:6833  t-loss:0.1940, loss-lb:0.0940, loss-ulb:0.0526, weight:1.90, lr:0.0008
[11:14:55.666] iteration:6834  t-loss:0.1488, loss-lb:0.1074, loss-ulb:0.0218, weight:1.90, lr:0.0008
[11:14:55.858] iteration:6835  t-loss:0.1814, loss-lb:0.1020, loss-ulb:0.0417, weight:1.90, lr:0.0008
[11:14:56.049] iteration:6836  t-loss:0.1477, loss-lb:0.1091, loss-ulb:0.0202, weight:1.90, lr:0.0008
[11:14:56.241] iteration:6837  t-loss:0.1487, loss-lb:0.0981, loss-ulb:0.0266, weight:1.90, lr:0.0008
[11:14:56.432] iteration:6838  t-loss:0.1695, loss-lb:0.1025, loss-ulb:0.0352, weight:1.90, lr:0.0008
[11:14:56.624] iteration:6839  t-loss:0.1455, loss-lb:0.0920, loss-ulb:0.0281, weight:1.90, lr:0.0008
[11:14:56.816] iteration:6840  t-loss:0.1500, loss-lb:0.0992, loss-ulb:0.0267, weight:1.90, lr:0.0008
[11:14:57.008] iteration:6841  t-loss:0.1489, loss-lb:0.0925, loss-ulb:0.0297, weight:1.90, lr:0.0008
[11:14:57.201] iteration:6842  t-loss:0.1593, loss-lb:0.0924, loss-ulb:0.0352, weight:1.90, lr:0.0008
[11:14:57.395] iteration:6843  t-loss:0.2868, loss-lb:0.0906, loss-ulb:0.1031, weight:1.90, lr:0.0008
[11:14:57.590] iteration:6844  t-loss:0.1676, loss-lb:0.1078, loss-ulb:0.0314, weight:1.90, lr:0.0008
[11:14:57.786] iteration:6845  t-loss:0.1950, loss-lb:0.0900, loss-ulb:0.0552, weight:1.90, lr:0.0008
[11:14:57.978] iteration:6846  t-loss:0.1726, loss-lb:0.0898, loss-ulb:0.0435, weight:1.90, lr:0.0008
[11:14:58.170] iteration:6847  t-loss:0.1344, loss-lb:0.0904, loss-ulb:0.0231, weight:1.90, lr:0.0008
[11:14:58.363] iteration:6848  t-loss:0.1422, loss-lb:0.0949, loss-ulb:0.0249, weight:1.90, lr:0.0008
[11:14:58.554] iteration:6849  t-loss:0.1649, loss-lb:0.0979, loss-ulb:0.0352, weight:1.90, lr:0.0008
[11:14:58.745] iteration:6850  t-loss:0.1622, loss-lb:0.1153, loss-ulb:0.0247, weight:1.90, lr:0.0008
[11:14:58.936] iteration:6851  t-loss:0.1685, loss-lb:0.0952, loss-ulb:0.0385, weight:1.90, lr:0.0008
[11:14:59.127] iteration:6852  t-loss:0.1442, loss-lb:0.0959, loss-ulb:0.0254, weight:1.90, lr:0.0008
[11:14:59.319] iteration:6853  t-loss:0.1540, loss-lb:0.0926, loss-ulb:0.0323, weight:1.90, lr:0.0008
[11:14:59.509] iteration:6854  t-loss:0.1464, loss-lb:0.0913, loss-ulb:0.0290, weight:1.90, lr:0.0008
[11:14:59.700] iteration:6855  t-loss:0.1878, loss-lb:0.1313, loss-ulb:0.0297, weight:1.90, lr:0.0008
[11:14:59.890] iteration:6856  t-loss:0.1456, loss-lb:0.0991, loss-ulb:0.0244, weight:1.90, lr:0.0008
[11:15:00.080] iteration:6857  t-loss:0.1952, loss-lb:0.1038, loss-ulb:0.0480, weight:1.90, lr:0.0008
[11:15:00.271] iteration:6858  t-loss:0.2744, loss-lb:0.1088, loss-ulb:0.0870, weight:1.90, lr:0.0008
[11:15:00.462] iteration:6859  t-loss:0.1316, loss-lb:0.0841, loss-ulb:0.0249, weight:1.90, lr:0.0008
[11:15:00.652] iteration:6860  t-loss:0.1689, loss-lb:0.0887, loss-ulb:0.0422, weight:1.90, lr:0.0008
[11:15:01.237] iteration:6861  t-loss:0.1514, loss-lb:0.0967, loss-ulb:0.0288, weight:1.90, lr:0.0008
[11:15:01.430] iteration:6862  t-loss:0.1387, loss-lb:0.0932, loss-ulb:0.0239, weight:1.90, lr:0.0008
[11:15:01.623] iteration:6863  t-loss:0.1538, loss-lb:0.0950, loss-ulb:0.0309, weight:1.90, lr:0.0008
[11:15:01.814] iteration:6864  t-loss:0.1798, loss-lb:0.1288, loss-ulb:0.0268, weight:1.90, lr:0.0008
[11:15:02.005] iteration:6865  t-loss:0.1384, loss-lb:0.0933, loss-ulb:0.0237, weight:1.90, lr:0.0008
[11:15:02.196] iteration:6866  t-loss:0.1913, loss-lb:0.1104, loss-ulb:0.0426, weight:1.90, lr:0.0008
[11:15:02.388] iteration:6867  t-loss:0.1462, loss-lb:0.0948, loss-ulb:0.0270, weight:1.90, lr:0.0008
[11:15:02.579] iteration:6868  t-loss:0.1632, loss-lb:0.0947, loss-ulb:0.0360, weight:1.90, lr:0.0008
[11:15:02.771] iteration:6869  t-loss:0.1490, loss-lb:0.0872, loss-ulb:0.0325, weight:1.90, lr:0.0008
[11:15:02.963] iteration:6870  t-loss:0.1617, loss-lb:0.0981, loss-ulb:0.0334, weight:1.90, lr:0.0008
[11:15:03.154] iteration:6871  t-loss:0.1587, loss-lb:0.0927, loss-ulb:0.0347, weight:1.90, lr:0.0008
[11:15:03.346] iteration:6872  t-loss:0.2178, loss-lb:0.1022, loss-ulb:0.0608, weight:1.90, lr:0.0008
[11:15:03.537] iteration:6873  t-loss:0.1426, loss-lb:0.0923, loss-ulb:0.0264, weight:1.90, lr:0.0008
[11:15:03.729] iteration:6874  t-loss:0.1585, loss-lb:0.1059, loss-ulb:0.0276, weight:1.90, lr:0.0008
[11:15:03.922] iteration:6875  t-loss:0.1799, loss-lb:0.0949, loss-ulb:0.0447, weight:1.90, lr:0.0008
[11:15:04.115] iteration:6876  t-loss:0.1400, loss-lb:0.0944, loss-ulb:0.0240, weight:1.90, lr:0.0008
[11:15:04.306] iteration:6877  t-loss:0.1693, loss-lb:0.1077, loss-ulb:0.0323, weight:1.90, lr:0.0008
[11:15:04.498] iteration:6878  t-loss:0.1684, loss-lb:0.1019, loss-ulb:0.0350, weight:1.90, lr:0.0008
[11:15:04.690] iteration:6879  t-loss:0.1469, loss-lb:0.0914, loss-ulb:0.0292, weight:1.90, lr:0.0008
[11:15:04.882] iteration:6880  t-loss:0.1739, loss-lb:0.0943, loss-ulb:0.0418, weight:1.90, lr:0.0008
[11:15:05.073] iteration:6881  t-loss:0.1639, loss-lb:0.0954, loss-ulb:0.0361, weight:1.90, lr:0.0008
[11:15:05.264] iteration:6882  t-loss:0.1939, loss-lb:0.0997, loss-ulb:0.0495, weight:1.90, lr:0.0008
[11:15:05.456] iteration:6883  t-loss:0.1583, loss-lb:0.1078, loss-ulb:0.0265, weight:1.90, lr:0.0008
[11:15:05.647] iteration:6884  t-loss:0.1430, loss-lb:0.0952, loss-ulb:0.0251, weight:1.90, lr:0.0008
[11:15:05.840] iteration:6885  t-loss:0.2034, loss-lb:0.1029, loss-ulb:0.0528, weight:1.90, lr:0.0008
[11:15:06.032] iteration:6886  t-loss:0.1903, loss-lb:0.0956, loss-ulb:0.0498, weight:1.90, lr:0.0008
[11:15:06.223] iteration:6887  t-loss:0.1654, loss-lb:0.1096, loss-ulb:0.0293, weight:1.90, lr:0.0008
[11:15:06.414] iteration:6888  t-loss:0.2229, loss-lb:0.0987, loss-ulb:0.0653, weight:1.90, lr:0.0008
[11:15:06.607] iteration:6889  t-loss:0.1524, loss-lb:0.0910, loss-ulb:0.0323, weight:1.90, lr:0.0008
[11:15:06.799] iteration:6890  t-loss:0.1684, loss-lb:0.1127, loss-ulb:0.0293, weight:1.90, lr:0.0008
[11:15:06.990] iteration:6891  t-loss:0.1800, loss-lb:0.1087, loss-ulb:0.0375, weight:1.90, lr:0.0008
[11:15:07.181] iteration:6892  t-loss:0.1605, loss-lb:0.0964, loss-ulb:0.0337, weight:1.90, lr:0.0008
[11:15:07.372] iteration:6893  t-loss:0.2049, loss-lb:0.0923, loss-ulb:0.0592, weight:1.90, lr:0.0008
[11:15:07.564] iteration:6894  t-loss:0.1397, loss-lb:0.0863, loss-ulb:0.0280, weight:1.90, lr:0.0008
[11:15:07.756] iteration:6895  t-loss:0.1483, loss-lb:0.0970, loss-ulb:0.0270, weight:1.90, lr:0.0008
[11:15:07.947] iteration:6896  t-loss:0.1480, loss-lb:0.0936, loss-ulb:0.0286, weight:1.90, lr:0.0008
[11:15:08.140] iteration:6897  t-loss:0.1658, loss-lb:0.1076, loss-ulb:0.0306, weight:1.90, lr:0.0008
[11:15:08.332] iteration:6898  t-loss:0.1532, loss-lb:0.1014, loss-ulb:0.0272, weight:1.90, lr:0.0008
[11:15:08.524] iteration:6899  t-loss:0.1667, loss-lb:0.1157, loss-ulb:0.0268, weight:1.90, lr:0.0008
[11:15:08.717] iteration:6900  t-loss:0.1428, loss-lb:0.1021, loss-ulb:0.0214, weight:1.90, lr:0.0008
[11:15:08.908] iteration:6901  t-loss:0.2316, loss-lb:0.1054, loss-ulb:0.0652, weight:1.94, lr:0.0008
[11:15:09.111] iteration:6902  t-loss:0.1653, loss-lb:0.0947, loss-ulb:0.0364, weight:1.94, lr:0.0008
[11:15:09.312] iteration:6903  t-loss:0.1608, loss-lb:0.1118, loss-ulb:0.0253, weight:1.94, lr:0.0008
[11:15:09.509] iteration:6904  t-loss:0.1537, loss-lb:0.1039, loss-ulb:0.0257, weight:1.94, lr:0.0008
[11:15:09.702] iteration:6905  t-loss:0.1437, loss-lb:0.0887, loss-ulb:0.0284, weight:1.94, lr:0.0008
[11:15:09.894] iteration:6906  t-loss:0.2108, loss-lb:0.0992, loss-ulb:0.0576, weight:1.94, lr:0.0008
[11:15:10.086] iteration:6907  t-loss:0.1538, loss-lb:0.1170, loss-ulb:0.0190, weight:1.94, lr:0.0008
[11:15:10.279] iteration:6908  t-loss:0.1554, loss-lb:0.0888, loss-ulb:0.0344, weight:1.94, lr:0.0008
[11:15:10.470] iteration:6909  t-loss:0.1780, loss-lb:0.1005, loss-ulb:0.0400, weight:1.94, lr:0.0008
[11:15:10.664] iteration:6910  t-loss:0.1418, loss-lb:0.0979, loss-ulb:0.0226, weight:1.94, lr:0.0008
[11:15:10.856] iteration:6911  t-loss:0.1409, loss-lb:0.0959, loss-ulb:0.0232, weight:1.94, lr:0.0008
[11:15:11.047] iteration:6912  t-loss:0.1538, loss-lb:0.0989, loss-ulb:0.0284, weight:1.94, lr:0.0008
[11:15:11.239] iteration:6913  t-loss:0.1652, loss-lb:0.1065, loss-ulb:0.0303, weight:1.94, lr:0.0008
[11:15:11.431] iteration:6914  t-loss:0.1713, loss-lb:0.1050, loss-ulb:0.0343, weight:1.94, lr:0.0008
[11:15:11.623] iteration:6915  t-loss:0.1477, loss-lb:0.0867, loss-ulb:0.0315, weight:1.94, lr:0.0008
[11:15:11.816] iteration:6916  t-loss:0.1536, loss-lb:0.1074, loss-ulb:0.0238, weight:1.94, lr:0.0008
[11:15:12.010] iteration:6917  t-loss:0.1579, loss-lb:0.0995, loss-ulb:0.0302, weight:1.94, lr:0.0008
[11:15:12.203] iteration:6918  t-loss:0.1506, loss-lb:0.0984, loss-ulb:0.0270, weight:1.94, lr:0.0008
[11:15:12.395] iteration:6919  t-loss:0.1643, loss-lb:0.1086, loss-ulb:0.0287, weight:1.94, lr:0.0008
[11:15:12.587] iteration:6920  t-loss:0.1572, loss-lb:0.0928, loss-ulb:0.0333, weight:1.94, lr:0.0008
[11:15:12.780] iteration:6921  t-loss:0.1479, loss-lb:0.0825, loss-ulb:0.0338, weight:1.94, lr:0.0008
[11:15:12.972] iteration:6922  t-loss:0.1676, loss-lb:0.0934, loss-ulb:0.0383, weight:1.94, lr:0.0008
[11:15:13.165] iteration:6923  t-loss:0.1888, loss-lb:0.0992, loss-ulb:0.0463, weight:1.94, lr:0.0008
[11:15:13.358] iteration:6924  t-loss:0.1638, loss-lb:0.1081, loss-ulb:0.0288, weight:1.94, lr:0.0008
[11:15:13.549] iteration:6925  t-loss:0.1617, loss-lb:0.1044, loss-ulb:0.0296, weight:1.94, lr:0.0008
[11:15:13.742] iteration:6926  t-loss:0.1932, loss-lb:0.0999, loss-ulb:0.0481, weight:1.94, lr:0.0008
[11:15:13.934] iteration:6927  t-loss:0.1410, loss-lb:0.0955, loss-ulb:0.0235, weight:1.94, lr:0.0008
[11:15:14.128] iteration:6928  t-loss:0.2004, loss-lb:0.0983, loss-ulb:0.0527, weight:1.94, lr:0.0008
[11:15:14.320] iteration:6929  t-loss:0.1407, loss-lb:0.0930, loss-ulb:0.0246, weight:1.94, lr:0.0008
[11:15:14.512] iteration:6930  t-loss:0.1443, loss-lb:0.0946, loss-ulb:0.0256, weight:1.94, lr:0.0008
[11:15:14.704] iteration:6931  t-loss:0.2651, loss-lb:0.1057, loss-ulb:0.0823, weight:1.94, lr:0.0008
[11:15:14.897] iteration:6932  t-loss:0.1415, loss-lb:0.1017, loss-ulb:0.0205, weight:1.94, lr:0.0008
[11:15:15.088] iteration:6933  t-loss:0.1697, loss-lb:0.1039, loss-ulb:0.0340, weight:1.94, lr:0.0008
[11:15:15.281] iteration:6934  t-loss:0.1523, loss-lb:0.1003, loss-ulb:0.0268, weight:1.94, lr:0.0008
[11:15:15.473] iteration:6935  t-loss:0.1586, loss-lb:0.1027, loss-ulb:0.0288, weight:1.94, lr:0.0008
[11:15:15.666] iteration:6936  t-loss:0.1457, loss-lb:0.0991, loss-ulb:0.0241, weight:1.94, lr:0.0008
[11:15:15.859] iteration:6937  t-loss:0.1569, loss-lb:0.1002, loss-ulb:0.0293, weight:1.94, lr:0.0008
[11:15:16.052] iteration:6938  t-loss:0.2524, loss-lb:0.1935, loss-ulb:0.0304, weight:1.94, lr:0.0008
[11:15:16.244] iteration:6939  t-loss:0.1760, loss-lb:0.0928, loss-ulb:0.0430, weight:1.94, lr:0.0008
[11:15:16.436] iteration:6940  t-loss:0.1927, loss-lb:0.0934, loss-ulb:0.0512, weight:1.94, lr:0.0008
[11:15:16.629] iteration:6941  t-loss:0.2821, loss-lb:0.0954, loss-ulb:0.0964, weight:1.94, lr:0.0008
[11:15:16.821] iteration:6942  t-loss:0.1497, loss-lb:0.1038, loss-ulb:0.0237, weight:1.94, lr:0.0008
[11:15:17.013] iteration:6943  t-loss:0.1854, loss-lb:0.1030, loss-ulb:0.0425, weight:1.94, lr:0.0008
[11:15:17.206] iteration:6944  t-loss:0.1586, loss-lb:0.1005, loss-ulb:0.0300, weight:1.94, lr:0.0008
[11:15:17.398] iteration:6945  t-loss:0.1470, loss-lb:0.0910, loss-ulb:0.0290, weight:1.94, lr:0.0008
[11:15:17.590] iteration:6946  t-loss:0.1476, loss-lb:0.0912, loss-ulb:0.0291, weight:1.94, lr:0.0008
[11:15:17.784] iteration:6947  t-loss:0.3173, loss-lb:0.1111, loss-ulb:0.1065, weight:1.94, lr:0.0008
[11:15:17.976] iteration:6948  t-loss:0.1434, loss-lb:0.0900, loss-ulb:0.0276, weight:1.94, lr:0.0008
[11:15:18.169] iteration:6949  t-loss:0.1661, loss-lb:0.0958, loss-ulb:0.0363, weight:1.94, lr:0.0008
[11:15:18.362] iteration:6950  t-loss:0.3241, loss-lb:0.1027, loss-ulb:0.1143, weight:1.94, lr:0.0008
[11:15:18.554] iteration:6951  t-loss:0.1547, loss-lb:0.0966, loss-ulb:0.0300, weight:1.94, lr:0.0008
[11:15:18.744] iteration:6952  t-loss:0.1514, loss-lb:0.1048, loss-ulb:0.0241, weight:1.94, lr:0.0008
[11:15:18.935] iteration:6953  t-loss:0.1811, loss-lb:0.0870, loss-ulb:0.0486, weight:1.94, lr:0.0008
[11:15:19.125] iteration:6954  t-loss:0.1485, loss-lb:0.1008, loss-ulb:0.0246, weight:1.94, lr:0.0008
[11:15:19.316] iteration:6955  t-loss:0.1419, loss-lb:0.0941, loss-ulb:0.0247, weight:1.94, lr:0.0008
[11:15:19.506] iteration:6956  t-loss:0.1510, loss-lb:0.0993, loss-ulb:0.0267, weight:1.94, lr:0.0008
[11:15:19.696] iteration:6957  t-loss:0.1731, loss-lb:0.1174, loss-ulb:0.0288, weight:1.94, lr:0.0008
[11:15:19.885] iteration:6958  t-loss:0.2075, loss-lb:0.0981, loss-ulb:0.0565, weight:1.94, lr:0.0008
[11:15:31.829]  <<Test>> - Ep:70  - mean_dice/mean_h95 - S:89.48/3.08, Best-S:90.13, T:90.10/1.39, Best-T:90.22
[11:15:31.829]           - AvgLoss(lb/ulb/all):0.1003/0.0447/0.1850
[11:15:32.354] iteration:6959  t-loss:0.1685, loss-lb:0.0932, loss-ulb:0.0389, weight:1.94, lr:0.0008
[11:15:32.554] iteration:6960  t-loss:0.2186, loss-lb:0.0917, loss-ulb:0.0655, weight:1.94, lr:0.0008
[11:15:32.747] iteration:6961  t-loss:0.1447, loss-lb:0.0971, loss-ulb:0.0246, weight:1.94, lr:0.0008
[11:15:32.941] iteration:6962  t-loss:0.2769, loss-lb:0.1043, loss-ulb:0.0891, weight:1.94, lr:0.0008
[11:15:33.133] iteration:6963  t-loss:0.1823, loss-lb:0.1057, loss-ulb:0.0396, weight:1.94, lr:0.0008
[11:15:33.327] iteration:6964  t-loss:0.1741, loss-lb:0.0943, loss-ulb:0.0412, weight:1.94, lr:0.0008
[11:15:33.520] iteration:6965  t-loss:0.1722, loss-lb:0.1026, loss-ulb:0.0359, weight:1.94, lr:0.0008
[11:15:33.712] iteration:6966  t-loss:0.1727, loss-lb:0.0984, loss-ulb:0.0383, weight:1.94, lr:0.0008
[11:15:33.905] iteration:6967  t-loss:0.1667, loss-lb:0.1068, loss-ulb:0.0309, weight:1.94, lr:0.0008
[11:15:34.097] iteration:6968  t-loss:0.1538, loss-lb:0.0979, loss-ulb:0.0289, weight:1.94, lr:0.0008
[11:15:34.291] iteration:6969  t-loss:0.2243, loss-lb:0.1239, loss-ulb:0.0518, weight:1.94, lr:0.0008
[11:15:34.483] iteration:6970  t-loss:0.1650, loss-lb:0.1150, loss-ulb:0.0258, weight:1.94, lr:0.0008
[11:15:34.676] iteration:6971  t-loss:0.2010, loss-lb:0.0954, loss-ulb:0.0545, weight:1.94, lr:0.0008
[11:15:34.869] iteration:6972  t-loss:0.1347, loss-lb:0.0903, loss-ulb:0.0229, weight:1.94, lr:0.0008
[11:15:35.061] iteration:6973  t-loss:0.1510, loss-lb:0.0981, loss-ulb:0.0273, weight:1.94, lr:0.0008
[11:15:35.255] iteration:6974  t-loss:0.1528, loss-lb:0.0988, loss-ulb:0.0279, weight:1.94, lr:0.0008
[11:15:35.448] iteration:6975  t-loss:0.1434, loss-lb:0.0943, loss-ulb:0.0253, weight:1.94, lr:0.0008
[11:15:35.641] iteration:6976  t-loss:0.1557, loss-lb:0.0882, loss-ulb:0.0349, weight:1.94, lr:0.0008
[11:15:35.834] iteration:6977  t-loss:0.1519, loss-lb:0.1028, loss-ulb:0.0254, weight:1.94, lr:0.0008
[11:15:36.026] iteration:6978  t-loss:0.1727, loss-lb:0.0942, loss-ulb:0.0405, weight:1.94, lr:0.0008
[11:15:36.218] iteration:6979  t-loss:0.1819, loss-lb:0.0940, loss-ulb:0.0454, weight:1.94, lr:0.0008
[11:15:36.410] iteration:6980  t-loss:0.1509, loss-lb:0.1035, loss-ulb:0.0245, weight:1.94, lr:0.0008
[11:15:36.602] iteration:6981  t-loss:0.1779, loss-lb:0.1196, loss-ulb:0.0301, weight:1.94, lr:0.0008
[11:15:36.794] iteration:6982  t-loss:0.1590, loss-lb:0.0936, loss-ulb:0.0337, weight:1.94, lr:0.0008
[11:15:36.986] iteration:6983  t-loss:0.1446, loss-lb:0.0977, loss-ulb:0.0242, weight:1.94, lr:0.0008
[11:15:37.178] iteration:6984  t-loss:0.2462, loss-lb:0.1899, loss-ulb:0.0291, weight:1.94, lr:0.0008
[11:15:37.370] iteration:6985  t-loss:0.3096, loss-lb:0.1146, loss-ulb:0.1007, weight:1.94, lr:0.0008
[11:15:37.562] iteration:6986  t-loss:0.1476, loss-lb:0.0963, loss-ulb:0.0265, weight:1.94, lr:0.0008
[11:15:37.756] iteration:6987  t-loss:0.1465, loss-lb:0.0949, loss-ulb:0.0266, weight:1.94, lr:0.0008
[11:15:37.949] iteration:6988  t-loss:0.2222, loss-lb:0.0952, loss-ulb:0.0655, weight:1.94, lr:0.0008
[11:15:38.142] iteration:6989  t-loss:0.1964, loss-lb:0.1004, loss-ulb:0.0496, weight:1.94, lr:0.0008
[11:15:38.334] iteration:6990  t-loss:0.1902, loss-lb:0.1016, loss-ulb:0.0458, weight:1.94, lr:0.0008
[11:15:38.527] iteration:6991  t-loss:0.1376, loss-lb:0.0844, loss-ulb:0.0275, weight:1.94, lr:0.0008
[11:15:38.720] iteration:6992  t-loss:0.1341, loss-lb:0.0917, loss-ulb:0.0219, weight:1.94, lr:0.0008
[11:15:38.913] iteration:6993  t-loss:0.1563, loss-lb:0.1007, loss-ulb:0.0287, weight:1.94, lr:0.0008
[11:15:39.105] iteration:6994  t-loss:0.1591, loss-lb:0.1162, loss-ulb:0.0221, weight:1.94, lr:0.0008
[11:15:39.297] iteration:6995  t-loss:0.1626, loss-lb:0.0930, loss-ulb:0.0359, weight:1.94, lr:0.0008
[11:15:39.489] iteration:6996  t-loss:0.1315, loss-lb:0.0853, loss-ulb:0.0238, weight:1.94, lr:0.0008
[11:15:39.681] iteration:6997  t-loss:0.1532, loss-lb:0.1003, loss-ulb:0.0273, weight:1.94, lr:0.0008
[11:15:39.874] iteration:6998  t-loss:0.1656, loss-lb:0.1154, loss-ulb:0.0259, weight:1.94, lr:0.0008
[11:15:40.065] iteration:6999  t-loss:0.1458, loss-lb:0.0962, loss-ulb:0.0256, weight:1.94, lr:0.0008
[11:15:40.257] iteration:7000  t-loss:0.1486, loss-lb:0.0995, loss-ulb:0.0253, weight:1.94, lr:0.0008
[11:15:40.449] iteration:7001  t-loss:0.1789, loss-lb:0.0943, loss-ulb:0.0437, weight:1.94, lr:0.0008
[11:15:40.641] iteration:7002  t-loss:0.1772, loss-lb:0.0936, loss-ulb:0.0431, weight:1.94, lr:0.0008
[11:15:40.833] iteration:7003  t-loss:0.1540, loss-lb:0.0964, loss-ulb:0.0297, weight:1.94, lr:0.0008
[11:15:41.026] iteration:7004  t-loss:0.1743, loss-lb:0.1291, loss-ulb:0.0233, weight:1.94, lr:0.0008
[11:15:41.219] iteration:7005  t-loss:0.1764, loss-lb:0.1033, loss-ulb:0.0378, weight:1.94, lr:0.0008
[11:15:41.411] iteration:7006  t-loss:0.2123, loss-lb:0.0924, loss-ulb:0.0619, weight:1.94, lr:0.0008
[11:15:41.602] iteration:7007  t-loss:0.1442, loss-lb:0.0941, loss-ulb:0.0259, weight:1.94, lr:0.0008
[11:15:41.794] iteration:7008  t-loss:0.1427, loss-lb:0.0907, loss-ulb:0.0268, weight:1.94, lr:0.0008
[11:15:42.014] iteration:7009  t-loss:0.1939, loss-lb:0.0982, loss-ulb:0.0494, weight:1.94, lr:0.0008
[11:15:42.214] iteration:7010  t-loss:0.1998, loss-lb:0.0907, loss-ulb:0.0563, weight:1.94, lr:0.0008
[11:15:42.406] iteration:7011  t-loss:0.1591, loss-lb:0.1073, loss-ulb:0.0267, weight:1.94, lr:0.0008
[11:15:42.598] iteration:7012  t-loss:0.1602, loss-lb:0.1034, loss-ulb:0.0293, weight:1.94, lr:0.0008
[11:15:42.797] iteration:7013  t-loss:0.2078, loss-lb:0.0955, loss-ulb:0.0580, weight:1.94, lr:0.0008
[11:15:42.989] iteration:7014  t-loss:0.1650, loss-lb:0.1087, loss-ulb:0.0291, weight:1.94, lr:0.0008
[11:15:43.182] iteration:7015  t-loss:0.2451, loss-lb:0.1350, loss-ulb:0.0569, weight:1.94, lr:0.0008
[11:15:43.374] iteration:7016  t-loss:0.1431, loss-lb:0.0941, loss-ulb:0.0253, weight:1.94, lr:0.0008
[11:15:43.574] iteration:7017  t-loss:0.1730, loss-lb:0.1077, loss-ulb:0.0337, weight:1.94, lr:0.0008
[11:15:43.766] iteration:7018  t-loss:0.1585, loss-lb:0.0966, loss-ulb:0.0320, weight:1.94, lr:0.0008
[11:15:43.958] iteration:7019  t-loss:0.1876, loss-lb:0.0949, loss-ulb:0.0478, weight:1.94, lr:0.0008
[11:15:44.149] iteration:7020  t-loss:0.1666, loss-lb:0.1112, loss-ulb:0.0286, weight:1.94, lr:0.0008
[11:15:44.349] iteration:7021  t-loss:0.1912, loss-lb:0.1153, loss-ulb:0.0392, weight:1.94, lr:0.0008
[11:15:44.543] iteration:7022  t-loss:0.1658, loss-lb:0.1061, loss-ulb:0.0308, weight:1.94, lr:0.0008
[11:15:44.736] iteration:7023  t-loss:0.3095, loss-lb:0.0944, loss-ulb:0.1110, weight:1.94, lr:0.0008
[11:15:44.928] iteration:7024  t-loss:0.1723, loss-lb:0.1015, loss-ulb:0.0366, weight:1.94, lr:0.0008
[11:15:45.127] iteration:7025  t-loss:0.1861, loss-lb:0.1265, loss-ulb:0.0308, weight:1.94, lr:0.0008
[11:15:45.319] iteration:7026  t-loss:0.1490, loss-lb:0.0985, loss-ulb:0.0261, weight:1.94, lr:0.0008
[11:15:45.512] iteration:7027  t-loss:0.1674, loss-lb:0.1000, loss-ulb:0.0348, weight:1.94, lr:0.0008
[11:15:45.704] iteration:7028  t-loss:0.1510, loss-lb:0.0932, loss-ulb:0.0299, weight:1.94, lr:0.0008
[11:15:45.904] iteration:7029  t-loss:0.1666, loss-lb:0.1031, loss-ulb:0.0328, weight:1.94, lr:0.0008
[11:15:46.096] iteration:7030  t-loss:0.1517, loss-lb:0.1052, loss-ulb:0.0240, weight:1.94, lr:0.0008
[11:15:46.288] iteration:7031  t-loss:0.1471, loss-lb:0.0983, loss-ulb:0.0252, weight:1.94, lr:0.0008
[11:15:46.480] iteration:7032  t-loss:0.1612, loss-lb:0.1048, loss-ulb:0.0291, weight:1.94, lr:0.0008
[11:15:46.680] iteration:7033  t-loss:0.2041, loss-lb:0.0952, loss-ulb:0.0562, weight:1.94, lr:0.0008
[11:15:46.872] iteration:7034  t-loss:0.1574, loss-lb:0.1126, loss-ulb:0.0231, weight:1.94, lr:0.0008
[11:15:47.065] iteration:7035  t-loss:0.1754, loss-lb:0.1009, loss-ulb:0.0384, weight:1.94, lr:0.0008
[11:15:47.257] iteration:7036  t-loss:0.1509, loss-lb:0.1040, loss-ulb:0.0242, weight:1.94, lr:0.0008
[11:15:47.456] iteration:7037  t-loss:0.1433, loss-lb:0.0940, loss-ulb:0.0254, weight:1.94, lr:0.0008
[11:15:47.648] iteration:7038  t-loss:0.1537, loss-lb:0.0950, loss-ulb:0.0303, weight:1.94, lr:0.0008
[11:15:47.841] iteration:7039  t-loss:0.1911, loss-lb:0.1023, loss-ulb:0.0459, weight:1.94, lr:0.0008
[11:15:48.033] iteration:7040  t-loss:0.2570, loss-lb:0.1097, loss-ulb:0.0760, weight:1.94, lr:0.0008
[11:15:48.233] iteration:7041  t-loss:0.1584, loss-lb:0.1019, loss-ulb:0.0292, weight:1.94, lr:0.0008
[11:15:48.425] iteration:7042  t-loss:0.1622, loss-lb:0.0916, loss-ulb:0.0364, weight:1.94, lr:0.0008
[11:15:48.617] iteration:7043  t-loss:0.1619, loss-lb:0.0952, loss-ulb:0.0344, weight:1.94, lr:0.0008
[11:15:48.808] iteration:7044  t-loss:0.1476, loss-lb:0.1006, loss-ulb:0.0243, weight:1.94, lr:0.0008
[11:15:49.007] iteration:7045  t-loss:0.1522, loss-lb:0.0919, loss-ulb:0.0311, weight:1.94, lr:0.0008
[11:15:49.199] iteration:7046  t-loss:0.1512, loss-lb:0.0928, loss-ulb:0.0302, weight:1.94, lr:0.0008
[11:15:49.390] iteration:7047  t-loss:0.1650, loss-lb:0.1051, loss-ulb:0.0309, weight:1.94, lr:0.0008
[11:15:49.583] iteration:7048  t-loss:0.1755, loss-lb:0.1086, loss-ulb:0.0345, weight:1.94, lr:0.0008
[11:15:49.774] iteration:7049  t-loss:0.1452, loss-lb:0.0952, loss-ulb:0.0258, weight:1.94, lr:0.0008
[11:15:49.965] iteration:7050  t-loss:0.1504, loss-lb:0.0918, loss-ulb:0.0302, weight:1.94, lr:0.0008
[11:15:50.155] iteration:7051  t-loss:0.1519, loss-lb:0.0991, loss-ulb:0.0269, weight:1.96, lr:0.0008
[11:15:50.346] iteration:7052  t-loss:0.1458, loss-lb:0.0949, loss-ulb:0.0259, weight:1.96, lr:0.0008
[11:15:50.535] iteration:7053  t-loss:0.1515, loss-lb:0.0847, loss-ulb:0.0340, weight:1.96, lr:0.0008
[11:15:50.726] iteration:7054  t-loss:0.1501, loss-lb:0.0931, loss-ulb:0.0290, weight:1.96, lr:0.0008
[11:15:50.917] iteration:7055  t-loss:0.1297, loss-lb:0.0897, loss-ulb:0.0204, weight:1.96, lr:0.0008
[11:15:51.108] iteration:7056  t-loss:0.1407, loss-lb:0.0855, loss-ulb:0.0281, weight:1.96, lr:0.0008
[11:15:51.706] iteration:7057  t-loss:0.1663, loss-lb:0.1079, loss-ulb:0.0297, weight:1.96, lr:0.0008
[11:15:51.902] iteration:7058  t-loss:0.1795, loss-lb:0.1010, loss-ulb:0.0399, weight:1.96, lr:0.0008
[11:15:52.094] iteration:7059  t-loss:0.1325, loss-lb:0.0848, loss-ulb:0.0243, weight:1.96, lr:0.0008
[11:15:52.287] iteration:7060  t-loss:0.1435, loss-lb:0.0990, loss-ulb:0.0227, weight:1.96, lr:0.0008
[11:15:52.480] iteration:7061  t-loss:0.1418, loss-lb:0.0933, loss-ulb:0.0247, weight:1.96, lr:0.0008
[11:15:52.672] iteration:7062  t-loss:0.1638, loss-lb:0.1004, loss-ulb:0.0323, weight:1.96, lr:0.0008
[11:15:52.866] iteration:7063  t-loss:0.1399, loss-lb:0.0942, loss-ulb:0.0233, weight:1.96, lr:0.0008
[11:15:53.059] iteration:7064  t-loss:0.1972, loss-lb:0.0934, loss-ulb:0.0529, weight:1.96, lr:0.0008
[11:15:53.251] iteration:7065  t-loss:0.1514, loss-lb:0.0853, loss-ulb:0.0336, weight:1.96, lr:0.0008
[11:15:53.444] iteration:7066  t-loss:0.1670, loss-lb:0.0948, loss-ulb:0.0368, weight:1.96, lr:0.0008
[11:15:53.637] iteration:7067  t-loss:0.2696, loss-lb:0.0890, loss-ulb:0.0920, weight:1.96, lr:0.0008
[11:15:53.830] iteration:7068  t-loss:0.1451, loss-lb:0.0942, loss-ulb:0.0259, weight:1.96, lr:0.0008
[11:15:54.023] iteration:7069  t-loss:0.1604, loss-lb:0.0875, loss-ulb:0.0371, weight:1.96, lr:0.0008
[11:15:54.216] iteration:7070  t-loss:0.1321, loss-lb:0.0905, loss-ulb:0.0212, weight:1.96, lr:0.0008
[11:15:54.408] iteration:7071  t-loss:0.1707, loss-lb:0.1063, loss-ulb:0.0328, weight:1.96, lr:0.0008
[11:15:54.600] iteration:7072  t-loss:0.1512, loss-lb:0.0921, loss-ulb:0.0301, weight:1.96, lr:0.0008
[11:15:54.792] iteration:7073  t-loss:0.2004, loss-lb:0.1017, loss-ulb:0.0502, weight:1.96, lr:0.0008
[11:15:54.984] iteration:7074  t-loss:0.1356, loss-lb:0.0928, loss-ulb:0.0218, weight:1.96, lr:0.0008
[11:15:55.177] iteration:7075  t-loss:0.1466, loss-lb:0.0941, loss-ulb:0.0267, weight:1.96, lr:0.0008
[11:15:55.369] iteration:7076  t-loss:0.1626, loss-lb:0.0941, loss-ulb:0.0349, weight:1.96, lr:0.0008
[11:15:55.562] iteration:7077  t-loss:0.1773, loss-lb:0.1080, loss-ulb:0.0353, weight:1.96, lr:0.0008
[11:15:55.753] iteration:7078  t-loss:0.1670, loss-lb:0.1080, loss-ulb:0.0300, weight:1.96, lr:0.0008
[11:15:55.945] iteration:7079  t-loss:0.1490, loss-lb:0.0958, loss-ulb:0.0271, weight:1.96, lr:0.0008
[11:15:56.138] iteration:7080  t-loss:0.1380, loss-lb:0.0911, loss-ulb:0.0239, weight:1.96, lr:0.0008
[11:15:56.332] iteration:7081  t-loss:0.1541, loss-lb:0.0963, loss-ulb:0.0294, weight:1.96, lr:0.0008
[11:15:56.525] iteration:7082  t-loss:0.1637, loss-lb:0.0879, loss-ulb:0.0386, weight:1.96, lr:0.0008
[11:15:56.716] iteration:7083  t-loss:0.1350, loss-lb:0.0894, loss-ulb:0.0232, weight:1.96, lr:0.0008
[11:15:56.908] iteration:7084  t-loss:0.1538, loss-lb:0.1012, loss-ulb:0.0268, weight:1.96, lr:0.0008
[11:15:57.103] iteration:7085  t-loss:0.1283, loss-lb:0.0858, loss-ulb:0.0217, weight:1.96, lr:0.0008
[11:15:57.296] iteration:7086  t-loss:0.1517, loss-lb:0.0974, loss-ulb:0.0277, weight:1.96, lr:0.0008
[11:15:57.488] iteration:7087  t-loss:0.1577, loss-lb:0.0998, loss-ulb:0.0295, weight:1.96, lr:0.0008
[11:15:57.680] iteration:7088  t-loss:0.1724, loss-lb:0.1065, loss-ulb:0.0336, weight:1.96, lr:0.0008
[11:15:57.873] iteration:7089  t-loss:0.1393, loss-lb:0.0885, loss-ulb:0.0258, weight:1.96, lr:0.0008
[11:15:58.064] iteration:7090  t-loss:0.1374, loss-lb:0.0900, loss-ulb:0.0241, weight:1.96, lr:0.0008
[11:15:58.257] iteration:7091  t-loss:0.1470, loss-lb:0.0911, loss-ulb:0.0284, weight:1.96, lr:0.0008
[11:15:58.450] iteration:7092  t-loss:0.1803, loss-lb:0.0999, loss-ulb:0.0410, weight:1.96, lr:0.0008
[11:15:58.648] iteration:7093  t-loss:0.1855, loss-lb:0.0991, loss-ulb:0.0440, weight:1.96, lr:0.0008
[11:15:58.841] iteration:7094  t-loss:0.1599, loss-lb:0.0855, loss-ulb:0.0379, weight:1.96, lr:0.0008
[11:15:59.037] iteration:7095  t-loss:0.1605, loss-lb:0.1001, loss-ulb:0.0308, weight:1.96, lr:0.0008
[11:15:59.229] iteration:7096  t-loss:0.1610, loss-lb:0.0949, loss-ulb:0.0337, weight:1.96, lr:0.0008
[11:15:59.421] iteration:7097  t-loss:0.1446, loss-lb:0.0854, loss-ulb:0.0301, weight:1.96, lr:0.0008
[11:15:59.613] iteration:7098  t-loss:0.1490, loss-lb:0.0886, loss-ulb:0.0307, weight:1.96, lr:0.0008
[11:15:59.804] iteration:7099  t-loss:0.1828, loss-lb:0.1084, loss-ulb:0.0379, weight:1.96, lr:0.0008
[11:15:59.996] iteration:7100  t-loss:0.1383, loss-lb:0.0902, loss-ulb:0.0245, weight:1.96, lr:0.0008
[11:16:00.187] iteration:7101  t-loss:0.1691, loss-lb:0.0979, loss-ulb:0.0363, weight:1.96, lr:0.0008
[11:16:00.379] iteration:7102  t-loss:0.1349, loss-lb:0.0878, loss-ulb:0.0240, weight:1.96, lr:0.0008
[11:16:00.573] iteration:7103  t-loss:0.1636, loss-lb:0.1037, loss-ulb:0.0305, weight:1.96, lr:0.0008
[11:16:00.764] iteration:7104  t-loss:0.1420, loss-lb:0.0933, loss-ulb:0.0248, weight:1.96, lr:0.0008
[11:16:00.956] iteration:7105  t-loss:0.1665, loss-lb:0.1031, loss-ulb:0.0323, weight:1.96, lr:0.0008
[11:16:01.148] iteration:7106  t-loss:0.1368, loss-lb:0.0913, loss-ulb:0.0231, weight:1.96, lr:0.0008
[11:16:01.340] iteration:7107  t-loss:0.1682, loss-lb:0.0969, loss-ulb:0.0363, weight:1.96, lr:0.0008
[11:16:01.532] iteration:7108  t-loss:0.1513, loss-lb:0.0994, loss-ulb:0.0264, weight:1.96, lr:0.0008
[11:16:01.723] iteration:7109  t-loss:0.1549, loss-lb:0.0955, loss-ulb:0.0303, weight:1.96, lr:0.0008
[11:16:01.915] iteration:7110  t-loss:0.2392, loss-lb:0.0798, loss-ulb:0.0811, weight:1.96, lr:0.0008
[11:16:02.107] iteration:7111  t-loss:0.1839, loss-lb:0.1309, loss-ulb:0.0270, weight:1.96, lr:0.0008
[11:16:02.299] iteration:7112  t-loss:0.1412, loss-lb:0.0968, loss-ulb:0.0226, weight:1.96, lr:0.0008
[11:16:02.491] iteration:7113  t-loss:0.1388, loss-lb:0.0948, loss-ulb:0.0224, weight:1.96, lr:0.0008
[11:16:02.683] iteration:7114  t-loss:0.1683, loss-lb:0.1017, loss-ulb:0.0339, weight:1.96, lr:0.0008
[11:16:02.874] iteration:7115  t-loss:0.1487, loss-lb:0.0978, loss-ulb:0.0259, weight:1.96, lr:0.0008
[11:16:03.066] iteration:7116  t-loss:0.1452, loss-lb:0.0904, loss-ulb:0.0279, weight:1.96, lr:0.0008
[11:16:03.256] iteration:7117  t-loss:0.1396, loss-lb:0.0917, loss-ulb:0.0244, weight:1.96, lr:0.0008
[11:16:03.448] iteration:7118  t-loss:0.1538, loss-lb:0.0926, loss-ulb:0.0312, weight:1.96, lr:0.0008
[11:16:03.641] iteration:7119  t-loss:0.1435, loss-lb:0.0801, loss-ulb:0.0323, weight:1.96, lr:0.0008
[11:16:03.832] iteration:7120  t-loss:0.1885, loss-lb:0.0873, loss-ulb:0.0515, weight:1.96, lr:0.0008
[11:16:04.024] iteration:7121  t-loss:0.1812, loss-lb:0.1206, loss-ulb:0.0308, weight:1.96, lr:0.0008
[11:16:04.215] iteration:7122  t-loss:0.1508, loss-lb:0.0926, loss-ulb:0.0296, weight:1.96, lr:0.0008
[11:16:04.408] iteration:7123  t-loss:0.2099, loss-lb:0.1450, loss-ulb:0.0330, weight:1.96, lr:0.0008
[11:16:04.600] iteration:7124  t-loss:0.1601, loss-lb:0.0960, loss-ulb:0.0327, weight:1.96, lr:0.0008
[11:16:04.793] iteration:7125  t-loss:0.2199, loss-lb:0.0992, loss-ulb:0.0614, weight:1.96, lr:0.0008
[11:16:04.985] iteration:7126  t-loss:0.1361, loss-lb:0.0893, loss-ulb:0.0238, weight:1.96, lr:0.0008
[11:16:05.178] iteration:7127  t-loss:0.1613, loss-lb:0.0992, loss-ulb:0.0316, weight:1.96, lr:0.0008
[11:16:05.371] iteration:7128  t-loss:0.1935, loss-lb:0.1072, loss-ulb:0.0440, weight:1.96, lr:0.0008
[11:16:05.563] iteration:7129  t-loss:0.1397, loss-lb:0.0936, loss-ulb:0.0235, weight:1.96, lr:0.0008
[11:16:05.756] iteration:7130  t-loss:0.2360, loss-lb:0.1064, loss-ulb:0.0660, weight:1.96, lr:0.0008
[11:16:05.949] iteration:7131  t-loss:0.2256, loss-lb:0.0953, loss-ulb:0.0663, weight:1.96, lr:0.0008
[11:16:06.140] iteration:7132  t-loss:0.2008, loss-lb:0.0940, loss-ulb:0.0544, weight:1.96, lr:0.0008
[11:16:06.333] iteration:7133  t-loss:0.1712, loss-lb:0.1172, loss-ulb:0.0275, weight:1.96, lr:0.0008
[11:16:06.524] iteration:7134  t-loss:0.1593, loss-lb:0.0956, loss-ulb:0.0324, weight:1.96, lr:0.0008
[11:16:06.716] iteration:7135  t-loss:0.1645, loss-lb:0.0933, loss-ulb:0.0363, weight:1.96, lr:0.0008
[11:16:06.907] iteration:7136  t-loss:0.1684, loss-lb:0.1006, loss-ulb:0.0345, weight:1.96, lr:0.0008
[11:16:07.098] iteration:7137  t-loss:0.1404, loss-lb:0.0919, loss-ulb:0.0247, weight:1.96, lr:0.0008
[11:16:07.290] iteration:7138  t-loss:0.2256, loss-lb:0.0945, loss-ulb:0.0667, weight:1.96, lr:0.0008
[11:16:07.482] iteration:7139  t-loss:0.1729, loss-lb:0.0935, loss-ulb:0.0405, weight:1.96, lr:0.0008
[11:16:07.673] iteration:7140  t-loss:0.1626, loss-lb:0.0903, loss-ulb:0.0368, weight:1.96, lr:0.0008
[11:16:07.864] iteration:7141  t-loss:0.1470, loss-lb:0.0992, loss-ulb:0.0244, weight:1.96, lr:0.0008
[11:16:08.055] iteration:7142  t-loss:0.1957, loss-lb:0.0922, loss-ulb:0.0527, weight:1.96, lr:0.0008
[11:16:08.246] iteration:7143  t-loss:0.1517, loss-lb:0.0914, loss-ulb:0.0307, weight:1.96, lr:0.0008
[11:16:08.438] iteration:7144  t-loss:0.2242, loss-lb:0.1016, loss-ulb:0.0624, weight:1.96, lr:0.0008
[11:16:08.629] iteration:7145  t-loss:0.3795, loss-lb:0.1207, loss-ulb:0.1317, weight:1.96, lr:0.0008
[11:16:08.821] iteration:7146  t-loss:0.1806, loss-lb:0.0912, loss-ulb:0.0455, weight:1.96, lr:0.0008
[11:16:09.012] iteration:7147  t-loss:0.1896, loss-lb:0.0936, loss-ulb:0.0489, weight:1.96, lr:0.0008
[11:16:09.204] iteration:7148  t-loss:0.1801, loss-lb:0.1049, loss-ulb:0.0383, weight:1.96, lr:0.0008
[11:16:09.398] iteration:7149  t-loss:0.1794, loss-lb:0.0945, loss-ulb:0.0432, weight:1.96, lr:0.0008
[11:16:09.591] iteration:7150  t-loss:0.1817, loss-lb:0.0986, loss-ulb:0.0423, weight:1.96, lr:0.0008
[11:16:09.784] iteration:7151  t-loss:0.1965, loss-lb:0.1001, loss-ulb:0.0491, weight:1.96, lr:0.0008
[11:16:09.976] iteration:7152  t-loss:0.1492, loss-lb:0.0890, loss-ulb:0.0306, weight:1.96, lr:0.0008
[11:16:10.165] iteration:7153  t-loss:0.1581, loss-lb:0.1057, loss-ulb:0.0267, weight:1.96, lr:0.0008
[11:16:10.356] iteration:7154  t-loss:0.1526, loss-lb:0.1021, loss-ulb:0.0257, weight:1.96, lr:0.0008
[11:16:21.760]  <<Test>> - Ep:72  - mean_dice/mean_h95 - S:89.09/2.80, Best-S:90.13, T:90.27/1.40, Best-T:90.27
[11:16:21.760]           - AvgLoss(lb/ulb/all):0.0969/0.0446/0.1850
[11:16:22.283] iteration:7155  t-loss:0.1925, loss-lb:0.1005, loss-ulb:0.0468, weight:1.96, lr:0.0008
[11:16:22.480] iteration:7156  t-loss:0.1754, loss-lb:0.1090, loss-ulb:0.0338, weight:1.96, lr:0.0008
[11:16:22.672] iteration:7157  t-loss:0.1972, loss-lb:0.0993, loss-ulb:0.0498, weight:1.96, lr:0.0008
[11:16:22.870] iteration:7158  t-loss:0.1563, loss-lb:0.1035, loss-ulb:0.0269, weight:1.96, lr:0.0008
[11:16:23.061] iteration:7159  t-loss:0.1494, loss-lb:0.1042, loss-ulb:0.0230, weight:1.96, lr:0.0008
[11:16:23.254] iteration:7160  t-loss:0.1551, loss-lb:0.0988, loss-ulb:0.0287, weight:1.96, lr:0.0008
[11:16:23.445] iteration:7161  t-loss:0.2189, loss-lb:0.1019, loss-ulb:0.0596, weight:1.96, lr:0.0008
[11:16:23.638] iteration:7162  t-loss:0.2919, loss-lb:0.1316, loss-ulb:0.0816, weight:1.96, lr:0.0008
[11:16:23.832] iteration:7163  t-loss:0.1933, loss-lb:0.0964, loss-ulb:0.0493, weight:1.96, lr:0.0008
[11:16:24.024] iteration:7164  t-loss:0.1570, loss-lb:0.0983, loss-ulb:0.0299, weight:1.96, lr:0.0008
[11:16:24.216] iteration:7165  t-loss:0.1755, loss-lb:0.1017, loss-ulb:0.0376, weight:1.96, lr:0.0008
[11:16:24.408] iteration:7166  t-loss:0.1772, loss-lb:0.0935, loss-ulb:0.0426, weight:1.96, lr:0.0008
[11:16:24.602] iteration:7167  t-loss:0.1567, loss-lb:0.0889, loss-ulb:0.0345, weight:1.96, lr:0.0008
[11:16:24.794] iteration:7168  t-loss:0.1486, loss-lb:0.0893, loss-ulb:0.0302, weight:1.96, lr:0.0008
[11:16:24.986] iteration:7169  t-loss:0.1607, loss-lb:0.1083, loss-ulb:0.0267, weight:1.96, lr:0.0008
[11:16:25.178] iteration:7170  t-loss:0.1535, loss-lb:0.1012, loss-ulb:0.0266, weight:1.96, lr:0.0008
[11:16:25.370] iteration:7171  t-loss:0.2538, loss-lb:0.1062, loss-ulb:0.0752, weight:1.96, lr:0.0008
[11:16:25.561] iteration:7172  t-loss:0.1943, loss-lb:0.1044, loss-ulb:0.0458, weight:1.96, lr:0.0008
[11:16:25.753] iteration:7173  t-loss:0.1493, loss-lb:0.1018, loss-ulb:0.0242, weight:1.96, lr:0.0008
[11:16:25.945] iteration:7174  t-loss:0.1418, loss-lb:0.0965, loss-ulb:0.0230, weight:1.96, lr:0.0008
[11:16:26.136] iteration:7175  t-loss:0.1631, loss-lb:0.0968, loss-ulb:0.0338, weight:1.96, lr:0.0008
[11:16:26.328] iteration:7176  t-loss:0.2133, loss-lb:0.1419, loss-ulb:0.0364, weight:1.96, lr:0.0008
[11:16:26.519] iteration:7177  t-loss:0.1587, loss-lb:0.0961, loss-ulb:0.0319, weight:1.96, lr:0.0008
[11:16:26.711] iteration:7178  t-loss:0.1594, loss-lb:0.1012, loss-ulb:0.0296, weight:1.96, lr:0.0008
[11:16:26.902] iteration:7179  t-loss:0.1482, loss-lb:0.0935, loss-ulb:0.0278, weight:1.96, lr:0.0008
[11:16:27.094] iteration:7180  t-loss:0.1769, loss-lb:0.1049, loss-ulb:0.0366, weight:1.96, lr:0.0008
[11:16:27.286] iteration:7181  t-loss:0.1575, loss-lb:0.0981, loss-ulb:0.0303, weight:1.96, lr:0.0008
[11:16:27.476] iteration:7182  t-loss:0.1491, loss-lb:0.1024, loss-ulb:0.0238, weight:1.96, lr:0.0008
[11:16:27.668] iteration:7183  t-loss:0.2007, loss-lb:0.1185, loss-ulb:0.0418, weight:1.96, lr:0.0008
[11:16:27.860] iteration:7184  t-loss:0.1722, loss-lb:0.1154, loss-ulb:0.0289, weight:1.96, lr:0.0008
[11:16:28.052] iteration:7185  t-loss:0.1403, loss-lb:0.0906, loss-ulb:0.0253, weight:1.96, lr:0.0008
[11:16:28.243] iteration:7186  t-loss:0.1484, loss-lb:0.0965, loss-ulb:0.0264, weight:1.96, lr:0.0008
[11:16:28.434] iteration:7187  t-loss:0.1494, loss-lb:0.0872, loss-ulb:0.0317, weight:1.96, lr:0.0008
[11:16:28.625] iteration:7188  t-loss:0.2475, loss-lb:0.0921, loss-ulb:0.0791, weight:1.96, lr:0.0008
[11:16:28.816] iteration:7189  t-loss:0.1409, loss-lb:0.0916, loss-ulb:0.0251, weight:1.96, lr:0.0008
[11:16:29.007] iteration:7190  t-loss:0.1553, loss-lb:0.1009, loss-ulb:0.0277, weight:1.96, lr:0.0008
[11:16:29.199] iteration:7191  t-loss:0.1496, loss-lb:0.0920, loss-ulb:0.0293, weight:1.96, lr:0.0008
[11:16:29.389] iteration:7192  t-loss:0.1683, loss-lb:0.0917, loss-ulb:0.0390, weight:1.96, lr:0.0008
[11:16:29.580] iteration:7193  t-loss:0.2085, loss-lb:0.1254, loss-ulb:0.0423, weight:1.96, lr:0.0008
[11:16:29.770] iteration:7194  t-loss:0.1557, loss-lb:0.0941, loss-ulb:0.0314, weight:1.96, lr:0.0008
[11:16:29.961] iteration:7195  t-loss:0.1521, loss-lb:0.0986, loss-ulb:0.0272, weight:1.96, lr:0.0008
[11:16:30.152] iteration:7196  t-loss:0.1842, loss-lb:0.1030, loss-ulb:0.0414, weight:1.96, lr:0.0008
[11:16:30.344] iteration:7197  t-loss:0.1621, loss-lb:0.1026, loss-ulb:0.0303, weight:1.96, lr:0.0008
[11:16:30.535] iteration:7198  t-loss:0.1758, loss-lb:0.1248, loss-ulb:0.0259, weight:1.96, lr:0.0008
[11:16:30.726] iteration:7199  t-loss:0.1606, loss-lb:0.0996, loss-ulb:0.0311, weight:1.96, lr:0.0008
[11:16:30.920] iteration:7200  t-loss:0.3195, loss-lb:0.1283, loss-ulb:0.0973, weight:1.96, lr:0.0008
[11:16:31.116] iteration:7201  t-loss:0.1984, loss-lb:0.1099, loss-ulb:0.0446, weight:1.98, lr:0.0008
[11:16:31.306] iteration:7202  t-loss:0.2279, loss-lb:0.1011, loss-ulb:0.0639, weight:1.98, lr:0.0008
[11:16:31.497] iteration:7203  t-loss:0.2154, loss-lb:0.1242, loss-ulb:0.0459, weight:1.98, lr:0.0008
[11:16:31.686] iteration:7204  t-loss:0.2095, loss-lb:0.1069, loss-ulb:0.0517, weight:1.98, lr:0.0008
[11:16:31.875] iteration:7205  t-loss:0.1572, loss-lb:0.0949, loss-ulb:0.0314, weight:1.98, lr:0.0008
[11:16:32.063] iteration:7206  t-loss:0.1704, loss-lb:0.1056, loss-ulb:0.0327, weight:1.98, lr:0.0008
[11:16:32.253] iteration:7207  t-loss:0.1641, loss-lb:0.1130, loss-ulb:0.0257, weight:1.98, lr:0.0008
[11:16:32.441] iteration:7208  t-loss:0.2979, loss-lb:0.0995, loss-ulb:0.1000, weight:1.98, lr:0.0008
[11:16:32.630] iteration:7209  t-loss:0.2197, loss-lb:0.0984, loss-ulb:0.0611, weight:1.98, lr:0.0008
[11:16:32.820] iteration:7210  t-loss:0.2420, loss-lb:0.1307, loss-ulb:0.0561, weight:1.98, lr:0.0008
[11:16:33.008] iteration:7211  t-loss:0.2166, loss-lb:0.1544, loss-ulb:0.0314, weight:1.98, lr:0.0008
[11:16:33.197] iteration:7212  t-loss:0.1574, loss-lb:0.1052, loss-ulb:0.0263, weight:1.98, lr:0.0008
[11:16:33.385] iteration:7213  t-loss:0.1669, loss-lb:0.1078, loss-ulb:0.0298, weight:1.98, lr:0.0008
[11:16:33.574] iteration:7214  t-loss:0.2145, loss-lb:0.1515, loss-ulb:0.0317, weight:1.98, lr:0.0008
[11:16:33.761] iteration:7215  t-loss:0.2710, loss-lb:0.1173, loss-ulb:0.0775, weight:1.98, lr:0.0008
[11:16:33.951] iteration:7216  t-loss:0.1685, loss-lb:0.1107, loss-ulb:0.0291, weight:1.98, lr:0.0008
[11:16:34.139] iteration:7217  t-loss:0.1910, loss-lb:0.1040, loss-ulb:0.0439, weight:1.98, lr:0.0008
[11:16:34.327] iteration:7218  t-loss:0.1870, loss-lb:0.1360, loss-ulb:0.0257, weight:1.98, lr:0.0008
[11:16:34.515] iteration:7219  t-loss:0.2117, loss-lb:0.1063, loss-ulb:0.0531, weight:1.98, lr:0.0008
[11:16:34.704] iteration:7220  t-loss:0.1636, loss-lb:0.1080, loss-ulb:0.0280, weight:1.98, lr:0.0008
[11:16:34.891] iteration:7221  t-loss:0.1904, loss-lb:0.1215, loss-ulb:0.0347, weight:1.98, lr:0.0008
[11:16:35.079] iteration:7222  t-loss:0.1710, loss-lb:0.1057, loss-ulb:0.0329, weight:1.98, lr:0.0008
[11:16:35.267] iteration:7223  t-loss:0.1796, loss-lb:0.1254, loss-ulb:0.0273, weight:1.98, lr:0.0008
[11:16:35.455] iteration:7224  t-loss:0.1831, loss-lb:0.1077, loss-ulb:0.0380, weight:1.98, lr:0.0008
[11:16:35.642] iteration:7225  t-loss:0.2950, loss-lb:0.1095, loss-ulb:0.0935, weight:1.98, lr:0.0008
[11:16:35.830] iteration:7226  t-loss:0.1737, loss-lb:0.1099, loss-ulb:0.0322, weight:1.98, lr:0.0008
[11:16:36.019] iteration:7227  t-loss:0.3014, loss-lb:0.1280, loss-ulb:0.0874, weight:1.98, lr:0.0008
[11:16:36.208] iteration:7228  t-loss:0.1530, loss-lb:0.0983, loss-ulb:0.0276, weight:1.98, lr:0.0008
[11:16:36.396] iteration:7229  t-loss:0.2560, loss-lb:0.1290, loss-ulb:0.0640, weight:1.98, lr:0.0008
[11:16:36.583] iteration:7230  t-loss:0.1915, loss-lb:0.1134, loss-ulb:0.0393, weight:1.98, lr:0.0008
[11:16:36.772] iteration:7231  t-loss:0.2089, loss-lb:0.1455, loss-ulb:0.0320, weight:1.98, lr:0.0008
[11:16:36.960] iteration:7232  t-loss:0.2103, loss-lb:0.1372, loss-ulb:0.0369, weight:1.98, lr:0.0008
[11:16:37.149] iteration:7233  t-loss:0.1984, loss-lb:0.1441, loss-ulb:0.0273, weight:1.98, lr:0.0008
[11:16:37.336] iteration:7234  t-loss:0.2048, loss-lb:0.1197, loss-ulb:0.0429, weight:1.98, lr:0.0008
[11:16:37.524] iteration:7235  t-loss:0.2226, loss-lb:0.1336, loss-ulb:0.0448, weight:1.98, lr:0.0008
[11:16:37.712] iteration:7236  t-loss:0.2408, loss-lb:0.1608, loss-ulb:0.0403, weight:1.98, lr:0.0008
[11:16:37.901] iteration:7237  t-loss:0.1581, loss-lb:0.1030, loss-ulb:0.0278, weight:1.98, lr:0.0008
[11:16:38.089] iteration:7238  t-loss:0.1886, loss-lb:0.1105, loss-ulb:0.0394, weight:1.98, lr:0.0008
[11:16:38.277] iteration:7239  t-loss:0.1920, loss-lb:0.1158, loss-ulb:0.0384, weight:1.98, lr:0.0008
[11:16:38.465] iteration:7240  t-loss:0.1798, loss-lb:0.1097, loss-ulb:0.0353, weight:1.98, lr:0.0008
[11:16:38.653] iteration:7241  t-loss:0.2006, loss-lb:0.1083, loss-ulb:0.0465, weight:1.98, lr:0.0008
[11:16:38.842] iteration:7242  t-loss:0.1825, loss-lb:0.1085, loss-ulb:0.0373, weight:1.98, lr:0.0008
[11:16:39.030] iteration:7243  t-loss:0.1842, loss-lb:0.1232, loss-ulb:0.0307, weight:1.98, lr:0.0008
[11:16:39.217] iteration:7244  t-loss:0.1628, loss-lb:0.1028, loss-ulb:0.0302, weight:1.98, lr:0.0008
[11:16:39.406] iteration:7245  t-loss:0.2138, loss-lb:0.1114, loss-ulb:0.0516, weight:1.98, lr:0.0008
[11:16:39.592] iteration:7246  t-loss:0.1723, loss-lb:0.1159, loss-ulb:0.0284, weight:1.98, lr:0.0008
[11:16:39.778] iteration:7247  t-loss:0.2131, loss-lb:0.1083, loss-ulb:0.0529, weight:1.98, lr:0.0008
[11:16:39.964] iteration:7248  t-loss:0.1664, loss-lb:0.1105, loss-ulb:0.0282, weight:1.98, lr:0.0008
[11:16:40.151] iteration:7249  t-loss:0.1691, loss-lb:0.1058, loss-ulb:0.0319, weight:1.98, lr:0.0008
[11:16:40.337] iteration:7250  t-loss:0.1928, loss-lb:0.1172, loss-ulb:0.0381, weight:1.98, lr:0.0008
[11:16:40.522] iteration:7251  t-loss:0.1611, loss-lb:0.1037, loss-ulb:0.0289, weight:1.98, lr:0.0008
[11:16:40.709] iteration:7252  t-loss:0.1820, loss-lb:0.1084, loss-ulb:0.0371, weight:1.98, lr:0.0008
[11:16:41.291] iteration:7253  t-loss:0.2489, loss-lb:0.1172, loss-ulb:0.0664, weight:1.98, lr:0.0008
[11:16:41.484] iteration:7254  t-loss:0.1789, loss-lb:0.1162, loss-ulb:0.0316, weight:1.98, lr:0.0008
[11:16:41.673] iteration:7255  t-loss:0.1512, loss-lb:0.1042, loss-ulb:0.0237, weight:1.98, lr:0.0008
[11:16:41.863] iteration:7256  t-loss:0.2902, loss-lb:0.1021, loss-ulb:0.0948, weight:1.98, lr:0.0008
[11:16:42.052] iteration:7257  t-loss:0.1936, loss-lb:0.1405, loss-ulb:0.0268, weight:1.98, lr:0.0008
[11:16:42.241] iteration:7258  t-loss:0.2151, loss-lb:0.1341, loss-ulb:0.0408, weight:1.98, lr:0.0008
[11:16:42.429] iteration:7259  t-loss:0.1814, loss-lb:0.1172, loss-ulb:0.0323, weight:1.98, lr:0.0008
[11:16:42.619] iteration:7260  t-loss:0.2146, loss-lb:0.0968, loss-ulb:0.0594, weight:1.98, lr:0.0008
[11:16:42.808] iteration:7261  t-loss:0.1639, loss-lb:0.1001, loss-ulb:0.0321, weight:1.98, lr:0.0008
[11:16:42.997] iteration:7262  t-loss:0.1530, loss-lb:0.0997, loss-ulb:0.0268, weight:1.98, lr:0.0008
[11:16:43.187] iteration:7263  t-loss:0.2108, loss-lb:0.0927, loss-ulb:0.0595, weight:1.98, lr:0.0008
[11:16:43.378] iteration:7264  t-loss:0.1602, loss-lb:0.1067, loss-ulb:0.0269, weight:1.98, lr:0.0008
[11:16:43.567] iteration:7265  t-loss:0.2130, loss-lb:0.0979, loss-ulb:0.0580, weight:1.98, lr:0.0008
[11:16:43.756] iteration:7266  t-loss:0.1998, loss-lb:0.1052, loss-ulb:0.0477, weight:1.98, lr:0.0008
[11:16:43.946] iteration:7267  t-loss:0.1868, loss-lb:0.1055, loss-ulb:0.0410, weight:1.98, lr:0.0008
[11:16:44.136] iteration:7268  t-loss:0.1929, loss-lb:0.0902, loss-ulb:0.0518, weight:1.98, lr:0.0008
[11:16:44.326] iteration:7269  t-loss:0.1704, loss-lb:0.1113, loss-ulb:0.0298, weight:1.98, lr:0.0008
[11:16:44.515] iteration:7270  t-loss:0.1554, loss-lb:0.1020, loss-ulb:0.0269, weight:1.98, lr:0.0008
[11:16:44.704] iteration:7271  t-loss:0.1667, loss-lb:0.0946, loss-ulb:0.0363, weight:1.98, lr:0.0008
[11:16:44.893] iteration:7272  t-loss:0.1860, loss-lb:0.1136, loss-ulb:0.0365, weight:1.98, lr:0.0008
[11:16:45.081] iteration:7273  t-loss:0.1532, loss-lb:0.0957, loss-ulb:0.0290, weight:1.98, lr:0.0008
[11:16:45.269] iteration:7274  t-loss:0.1391, loss-lb:0.0916, loss-ulb:0.0240, weight:1.98, lr:0.0008
[11:16:45.459] iteration:7275  t-loss:0.1285, loss-lb:0.0858, loss-ulb:0.0215, weight:1.98, lr:0.0008
[11:16:45.648] iteration:7276  t-loss:0.1674, loss-lb:0.0894, loss-ulb:0.0393, weight:1.98, lr:0.0008
[11:16:45.836] iteration:7277  t-loss:0.1411, loss-lb:0.0973, loss-ulb:0.0221, weight:1.98, lr:0.0008
[11:16:46.026] iteration:7278  t-loss:0.1507, loss-lb:0.0971, loss-ulb:0.0270, weight:1.98, lr:0.0008
[11:16:46.215] iteration:7279  t-loss:0.1898, loss-lb:0.1032, loss-ulb:0.0436, weight:1.98, lr:0.0008
[11:16:46.403] iteration:7280  t-loss:0.1430, loss-lb:0.0892, loss-ulb:0.0271, weight:1.98, lr:0.0008
[11:16:46.592] iteration:7281  t-loss:0.1372, loss-lb:0.0948, loss-ulb:0.0214, weight:1.98, lr:0.0008
[11:16:46.782] iteration:7282  t-loss:0.1553, loss-lb:0.1011, loss-ulb:0.0273, weight:1.98, lr:0.0008
[11:16:46.970] iteration:7283  t-loss:0.1478, loss-lb:0.0833, loss-ulb:0.0325, weight:1.98, lr:0.0008
[11:16:47.159] iteration:7284  t-loss:0.1672, loss-lb:0.1149, loss-ulb:0.0263, weight:1.98, lr:0.0008
[11:16:47.349] iteration:7285  t-loss:0.1337, loss-lb:0.0926, loss-ulb:0.0207, weight:1.98, lr:0.0008
[11:16:47.546] iteration:7286  t-loss:0.2259, loss-lb:0.0983, loss-ulb:0.0643, weight:1.98, lr:0.0008
[11:16:47.739] iteration:7287  t-loss:0.1998, loss-lb:0.0937, loss-ulb:0.0535, weight:1.98, lr:0.0008
[11:16:47.929] iteration:7288  t-loss:0.2098, loss-lb:0.0949, loss-ulb:0.0579, weight:1.98, lr:0.0008
[11:16:48.118] iteration:7289  t-loss:0.1434, loss-lb:0.0983, loss-ulb:0.0227, weight:1.98, lr:0.0008
[11:16:48.307] iteration:7290  t-loss:0.1506, loss-lb:0.1058, loss-ulb:0.0226, weight:1.98, lr:0.0008
[11:16:48.495] iteration:7291  t-loss:0.1529, loss-lb:0.0961, loss-ulb:0.0287, weight:1.98, lr:0.0008
[11:16:48.684] iteration:7292  t-loss:0.1629, loss-lb:0.1115, loss-ulb:0.0259, weight:1.98, lr:0.0008
[11:16:48.873] iteration:7293  t-loss:0.1638, loss-lb:0.0904, loss-ulb:0.0370, weight:1.98, lr:0.0008
[11:16:49.062] iteration:7294  t-loss:0.1640, loss-lb:0.1039, loss-ulb:0.0303, weight:1.98, lr:0.0008
[11:16:49.251] iteration:7295  t-loss:0.1453, loss-lb:0.0916, loss-ulb:0.0271, weight:1.98, lr:0.0008
[11:16:49.440] iteration:7296  t-loss:0.1423, loss-lb:0.0907, loss-ulb:0.0260, weight:1.98, lr:0.0008
[11:16:49.629] iteration:7297  t-loss:0.1522, loss-lb:0.0864, loss-ulb:0.0332, weight:1.98, lr:0.0008
[11:16:49.818] iteration:7298  t-loss:0.2231, loss-lb:0.1021, loss-ulb:0.0610, weight:1.98, lr:0.0008
[11:16:50.006] iteration:7299  t-loss:0.1435, loss-lb:0.0951, loss-ulb:0.0244, weight:1.98, lr:0.0008
[11:16:50.195] iteration:7300  t-loss:0.1642, loss-lb:0.0973, loss-ulb:0.0337, weight:1.98, lr:0.0008
[11:16:50.384] iteration:7301  t-loss:0.1849, loss-lb:0.1015, loss-ulb:0.0420, weight:1.98, lr:0.0008
[11:16:50.573] iteration:7302  t-loss:0.1498, loss-lb:0.0906, loss-ulb:0.0298, weight:1.98, lr:0.0008
[11:16:50.762] iteration:7303  t-loss:0.1885, loss-lb:0.1199, loss-ulb:0.0346, weight:1.98, lr:0.0008
[11:16:50.952] iteration:7304  t-loss:0.1647, loss-lb:0.0934, loss-ulb:0.0359, weight:1.98, lr:0.0008
[11:16:51.141] iteration:7305  t-loss:0.1582, loss-lb:0.0972, loss-ulb:0.0308, weight:1.98, lr:0.0008
[11:16:51.330] iteration:7306  t-loss:0.2584, loss-lb:0.0903, loss-ulb:0.0847, weight:1.98, lr:0.0008
[11:16:51.520] iteration:7307  t-loss:0.1976, loss-lb:0.0934, loss-ulb:0.0525, weight:1.98, lr:0.0008
[11:16:51.710] iteration:7308  t-loss:0.1476, loss-lb:0.1010, loss-ulb:0.0234, weight:1.98, lr:0.0008
[11:16:51.899] iteration:7309  t-loss:0.2405, loss-lb:0.0935, loss-ulb:0.0741, weight:1.98, lr:0.0008
[11:16:52.090] iteration:7310  t-loss:0.1569, loss-lb:0.1004, loss-ulb:0.0285, weight:1.98, lr:0.0008
[11:16:52.279] iteration:7311  t-loss:0.1555, loss-lb:0.0904, loss-ulb:0.0328, weight:1.98, lr:0.0008
[11:16:52.468] iteration:7312  t-loss:0.1460, loss-lb:0.0994, loss-ulb:0.0235, weight:1.98, lr:0.0008
[11:16:52.657] iteration:7313  t-loss:0.1366, loss-lb:0.0954, loss-ulb:0.0208, weight:1.98, lr:0.0008
[11:16:52.846] iteration:7314  t-loss:0.2162, loss-lb:0.1258, loss-ulb:0.0456, weight:1.98, lr:0.0008
[11:16:53.035] iteration:7315  t-loss:0.1935, loss-lb:0.1282, loss-ulb:0.0329, weight:1.98, lr:0.0008
[11:16:53.224] iteration:7316  t-loss:0.1437, loss-lb:0.0925, loss-ulb:0.0258, weight:1.98, lr:0.0008
[11:16:53.414] iteration:7317  t-loss:0.1918, loss-lb:0.0987, loss-ulb:0.0469, weight:1.98, lr:0.0008
[11:16:53.604] iteration:7318  t-loss:0.1867, loss-lb:0.0973, loss-ulb:0.0451, weight:1.98, lr:0.0008
[11:16:53.794] iteration:7319  t-loss:0.1675, loss-lb:0.1157, loss-ulb:0.0261, weight:1.98, lr:0.0008
[11:16:53.983] iteration:7320  t-loss:0.1547, loss-lb:0.1074, loss-ulb:0.0238, weight:1.98, lr:0.0008
[11:16:54.172] iteration:7321  t-loss:0.1613, loss-lb:0.1030, loss-ulb:0.0294, weight:1.98, lr:0.0008
[11:16:54.361] iteration:7322  t-loss:0.1658, loss-lb:0.1034, loss-ulb:0.0314, weight:1.98, lr:0.0008
[11:16:54.549] iteration:7323  t-loss:0.1949, loss-lb:0.0929, loss-ulb:0.0514, weight:1.98, lr:0.0008
[11:16:54.739] iteration:7324  t-loss:0.1493, loss-lb:0.1063, loss-ulb:0.0217, weight:1.98, lr:0.0008
[11:16:54.927] iteration:7325  t-loss:0.1411, loss-lb:0.0926, loss-ulb:0.0244, weight:1.98, lr:0.0008
[11:16:55.116] iteration:7326  t-loss:0.1885, loss-lb:0.1057, loss-ulb:0.0417, weight:1.98, lr:0.0008
[11:16:55.305] iteration:7327  t-loss:0.1458, loss-lb:0.1023, loss-ulb:0.0219, weight:1.98, lr:0.0008
[11:16:55.494] iteration:7328  t-loss:0.1421, loss-lb:0.0925, loss-ulb:0.0250, weight:1.98, lr:0.0008
[11:16:55.682] iteration:7329  t-loss:0.1705, loss-lb:0.1124, loss-ulb:0.0293, weight:1.98, lr:0.0008
[11:16:55.872] iteration:7330  t-loss:0.1499, loss-lb:0.0928, loss-ulb:0.0288, weight:1.98, lr:0.0008
[11:16:56.060] iteration:7331  t-loss:0.1835, loss-lb:0.1025, loss-ulb:0.0408, weight:1.98, lr:0.0008
[11:16:56.250] iteration:7332  t-loss:0.1544, loss-lb:0.0918, loss-ulb:0.0316, weight:1.98, lr:0.0008
[11:16:56.439] iteration:7333  t-loss:0.3694, loss-lb:0.0874, loss-ulb:0.1421, weight:1.98, lr:0.0008
[11:16:56.629] iteration:7334  t-loss:0.2443, loss-lb:0.1151, loss-ulb:0.0651, weight:1.98, lr:0.0008
[11:16:56.818] iteration:7335  t-loss:0.1660, loss-lb:0.0834, loss-ulb:0.0416, weight:1.98, lr:0.0008
[11:16:57.007] iteration:7336  t-loss:0.1364, loss-lb:0.0848, loss-ulb:0.0260, weight:1.98, lr:0.0008
[11:16:57.197] iteration:7337  t-loss:0.1584, loss-lb:0.0995, loss-ulb:0.0296, weight:1.98, lr:0.0008
[11:16:57.385] iteration:7338  t-loss:0.1319, loss-lb:0.0860, loss-ulb:0.0231, weight:1.98, lr:0.0008
[11:16:57.574] iteration:7339  t-loss:0.1873, loss-lb:0.1345, loss-ulb:0.0266, weight:1.98, lr:0.0008
[11:16:57.766] iteration:7340  t-loss:0.1912, loss-lb:0.1233, loss-ulb:0.0342, weight:1.98, lr:0.0008
[11:16:57.959] iteration:7341  t-loss:0.1698, loss-lb:0.1117, loss-ulb:0.0293, weight:1.98, lr:0.0008
[11:16:58.151] iteration:7342  t-loss:0.2635, loss-lb:0.1233, loss-ulb:0.0707, weight:1.98, lr:0.0008
[11:16:58.343] iteration:7343  t-loss:0.1544, loss-lb:0.0960, loss-ulb:0.0294, weight:1.98, lr:0.0008
[11:16:58.533] iteration:7344  t-loss:0.1543, loss-lb:0.0968, loss-ulb:0.0290, weight:1.98, lr:0.0008
[11:16:58.724] iteration:7345  t-loss:0.1540, loss-lb:0.0922, loss-ulb:0.0311, weight:1.98, lr:0.0008
[11:16:58.914] iteration:7346  t-loss:0.1539, loss-lb:0.1041, loss-ulb:0.0251, weight:1.98, lr:0.0008
[11:16:59.105] iteration:7347  t-loss:0.1603, loss-lb:0.1036, loss-ulb:0.0286, weight:1.98, lr:0.0008
[11:16:59.297] iteration:7348  t-loss:0.4102, loss-lb:0.0980, loss-ulb:0.1574, weight:1.98, lr:0.0008
[11:16:59.487] iteration:7349  t-loss:0.1511, loss-lb:0.1046, loss-ulb:0.0234, weight:1.98, lr:0.0008
[11:16:59.678] iteration:7350  t-loss:0.1480, loss-lb:0.0909, loss-ulb:0.0288, weight:1.98, lr:0.0008
[11:17:11.911]  <<Test>> - Ep:74  - mean_dice/mean_h95 - S:89.07/1.58, Best-S:90.13, T:90.15/1.40, Best-T:90.27
[11:17:11.912]           - AvgLoss(lb/ulb/all):0.1011/0.0457/0.1921
[11:17:12.439] iteration:7351  t-loss:0.2026, loss-lb:0.1166, loss-ulb:0.0431, weight:2.00, lr:0.0008
[11:17:12.633] iteration:7352  t-loss:0.1486, loss-lb:0.0926, loss-ulb:0.0281, weight:2.00, lr:0.0008
[11:17:12.822] iteration:7353  t-loss:0.1789, loss-lb:0.0994, loss-ulb:0.0398, weight:2.00, lr:0.0008
[11:17:13.013] iteration:7354  t-loss:0.2231, loss-lb:0.1024, loss-ulb:0.0605, weight:2.00, lr:0.0008
[11:17:13.203] iteration:7355  t-loss:0.1660, loss-lb:0.1033, loss-ulb:0.0314, weight:2.00, lr:0.0008
[11:17:13.393] iteration:7356  t-loss:0.1628, loss-lb:0.1037, loss-ulb:0.0296, weight:2.00, lr:0.0008
[11:17:13.582] iteration:7357  t-loss:0.1484, loss-lb:0.1022, loss-ulb:0.0231, weight:2.00, lr:0.0008
[11:17:13.771] iteration:7358  t-loss:0.1608, loss-lb:0.0995, loss-ulb:0.0307, weight:2.00, lr:0.0008
[11:17:13.961] iteration:7359  t-loss:0.1474, loss-lb:0.1040, loss-ulb:0.0217, weight:2.00, lr:0.0008
[11:17:14.150] iteration:7360  t-loss:0.1489, loss-lb:0.1026, loss-ulb:0.0232, weight:2.00, lr:0.0008
[11:17:14.340] iteration:7361  t-loss:0.1283, loss-lb:0.0832, loss-ulb:0.0226, weight:2.00, lr:0.0008
[11:17:14.529] iteration:7362  t-loss:0.1543, loss-lb:0.1006, loss-ulb:0.0269, weight:2.00, lr:0.0008
[11:17:14.719] iteration:7363  t-loss:0.1433, loss-lb:0.0922, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:17:14.908] iteration:7364  t-loss:0.1388, loss-lb:0.0960, loss-ulb:0.0214, weight:2.00, lr:0.0008
[11:17:15.097] iteration:7365  t-loss:0.1718, loss-lb:0.1132, loss-ulb:0.0294, weight:2.00, lr:0.0008
[11:17:15.287] iteration:7366  t-loss:0.1325, loss-lb:0.0817, loss-ulb:0.0254, weight:2.00, lr:0.0008
[11:17:15.476] iteration:7367  t-loss:0.2015, loss-lb:0.1053, loss-ulb:0.0482, weight:2.00, lr:0.0008
[11:17:15.667] iteration:7368  t-loss:0.1500, loss-lb:0.1005, loss-ulb:0.0248, weight:2.00, lr:0.0008
[11:17:15.856] iteration:7369  t-loss:0.1881, loss-lb:0.1047, loss-ulb:0.0418, weight:2.00, lr:0.0008
[11:17:16.045] iteration:7370  t-loss:0.2546, loss-lb:0.0902, loss-ulb:0.0824, weight:2.00, lr:0.0008
[11:17:16.234] iteration:7371  t-loss:0.1706, loss-lb:0.0914, loss-ulb:0.0397, weight:2.00, lr:0.0008
[11:17:16.424] iteration:7372  t-loss:0.1536, loss-lb:0.0915, loss-ulb:0.0311, weight:2.00, lr:0.0008
[11:17:16.613] iteration:7373  t-loss:0.2009, loss-lb:0.0979, loss-ulb:0.0516, weight:2.00, lr:0.0008
[11:17:16.803] iteration:7374  t-loss:0.2045, loss-lb:0.0902, loss-ulb:0.0573, weight:2.00, lr:0.0008
[11:17:16.991] iteration:7375  t-loss:0.1484, loss-lb:0.0974, loss-ulb:0.0255, weight:2.00, lr:0.0008
[11:17:17.181] iteration:7376  t-loss:0.3172, loss-lb:0.1262, loss-ulb:0.0957, weight:2.00, lr:0.0008
[11:17:17.370] iteration:7377  t-loss:0.2344, loss-lb:0.1095, loss-ulb:0.0626, weight:2.00, lr:0.0008
[11:17:17.558] iteration:7378  t-loss:0.1528, loss-lb:0.0978, loss-ulb:0.0275, weight:2.00, lr:0.0008
[11:17:17.747] iteration:7379  t-loss:0.1626, loss-lb:0.0958, loss-ulb:0.0335, weight:2.00, lr:0.0008
[11:17:17.936] iteration:7380  t-loss:0.1640, loss-lb:0.1070, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:17:18.125] iteration:7381  t-loss:0.1683, loss-lb:0.1051, loss-ulb:0.0317, weight:2.00, lr:0.0008
[11:17:18.314] iteration:7382  t-loss:0.2092, loss-lb:0.0948, loss-ulb:0.0573, weight:2.00, lr:0.0008
[11:17:18.503] iteration:7383  t-loss:0.2356, loss-lb:0.1343, loss-ulb:0.0508, weight:2.00, lr:0.0008
[11:17:18.692] iteration:7384  t-loss:0.2784, loss-lb:0.1170, loss-ulb:0.0809, weight:2.00, lr:0.0008
[11:17:18.882] iteration:7385  t-loss:0.2917, loss-lb:0.1090, loss-ulb:0.0915, weight:2.00, lr:0.0008
[11:17:19.071] iteration:7386  t-loss:0.1773, loss-lb:0.0958, loss-ulb:0.0408, weight:2.00, lr:0.0008
[11:17:19.259] iteration:7387  t-loss:0.1842, loss-lb:0.1054, loss-ulb:0.0395, weight:2.00, lr:0.0008
[11:17:19.449] iteration:7388  t-loss:0.2058, loss-lb:0.1494, loss-ulb:0.0282, weight:2.00, lr:0.0008
[11:17:19.638] iteration:7389  t-loss:0.1975, loss-lb:0.1084, loss-ulb:0.0447, weight:2.00, lr:0.0008
[11:17:19.826] iteration:7390  t-loss:0.1583, loss-lb:0.0954, loss-ulb:0.0315, weight:2.00, lr:0.0008
[11:17:20.015] iteration:7391  t-loss:0.1614, loss-lb:0.1025, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:17:20.213] iteration:7392  t-loss:0.1920, loss-lb:0.1097, loss-ulb:0.0412, weight:2.00, lr:0.0008
[11:17:20.412] iteration:7393  t-loss:0.1896, loss-lb:0.1288, loss-ulb:0.0305, weight:2.00, lr:0.0008
[11:17:20.608] iteration:7394  t-loss:0.1474, loss-lb:0.0944, loss-ulb:0.0266, weight:2.00, lr:0.0008
[11:17:20.800] iteration:7395  t-loss:0.1385, loss-lb:0.0872, loss-ulb:0.0257, weight:2.00, lr:0.0008
[11:17:20.992] iteration:7396  t-loss:0.1649, loss-lb:0.1041, loss-ulb:0.0305, weight:2.00, lr:0.0008
[11:17:21.185] iteration:7397  t-loss:0.1917, loss-lb:0.1009, loss-ulb:0.0455, weight:2.00, lr:0.0008
[11:17:21.377] iteration:7398  t-loss:0.1637, loss-lb:0.0948, loss-ulb:0.0345, weight:2.00, lr:0.0008
[11:17:21.568] iteration:7399  t-loss:0.2234, loss-lb:0.1181, loss-ulb:0.0528, weight:2.00, lr:0.0008
[11:17:21.760] iteration:7400  t-loss:0.2295, loss-lb:0.0985, loss-ulb:0.0656, weight:2.00, lr:0.0008
[11:17:21.951] iteration:7401  t-loss:0.1831, loss-lb:0.1009, loss-ulb:0.0412, weight:2.00, lr:0.0008
[11:17:22.143] iteration:7402  t-loss:0.1474, loss-lb:0.1007, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:17:22.335] iteration:7403  t-loss:0.1469, loss-lb:0.0926, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:17:22.526] iteration:7404  t-loss:0.1713, loss-lb:0.1027, loss-ulb:0.0344, weight:2.00, lr:0.0008
[11:17:22.718] iteration:7405  t-loss:0.1640, loss-lb:0.1007, loss-ulb:0.0317, weight:2.00, lr:0.0008
[11:17:22.911] iteration:7406  t-loss:0.2392, loss-lb:0.1166, loss-ulb:0.0614, weight:2.00, lr:0.0008
[11:17:23.101] iteration:7407  t-loss:0.1600, loss-lb:0.1123, loss-ulb:0.0239, weight:2.00, lr:0.0008
[11:17:23.292] iteration:7408  t-loss:0.1514, loss-lb:0.1015, loss-ulb:0.0250, weight:2.00, lr:0.0008
[11:17:23.484] iteration:7409  t-loss:0.1531, loss-lb:0.1050, loss-ulb:0.0241, weight:2.00, lr:0.0008
[11:17:23.677] iteration:7410  t-loss:0.1895, loss-lb:0.0986, loss-ulb:0.0456, weight:2.00, lr:0.0008
[11:17:23.869] iteration:7411  t-loss:0.1390, loss-lb:0.0915, loss-ulb:0.0238, weight:2.00, lr:0.0008
[11:17:24.061] iteration:7412  t-loss:0.1555, loss-lb:0.1090, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:17:24.254] iteration:7413  t-loss:0.1500, loss-lb:0.0949, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:17:24.446] iteration:7414  t-loss:0.1534, loss-lb:0.0931, loss-ulb:0.0302, weight:2.00, lr:0.0008
[11:17:24.638] iteration:7415  t-loss:0.1386, loss-lb:0.0929, loss-ulb:0.0229, weight:2.00, lr:0.0008
[11:17:24.829] iteration:7416  t-loss:0.1879, loss-lb:0.1059, loss-ulb:0.0411, weight:2.00, lr:0.0008
[11:17:25.022] iteration:7417  t-loss:0.1706, loss-lb:0.1005, loss-ulb:0.0351, weight:2.00, lr:0.0008
[11:17:25.214] iteration:7418  t-loss:0.1812, loss-lb:0.1189, loss-ulb:0.0312, weight:2.00, lr:0.0008
[11:17:25.406] iteration:7419  t-loss:0.1614, loss-lb:0.0921, loss-ulb:0.0347, weight:2.00, lr:0.0008
[11:17:25.599] iteration:7420  t-loss:0.1382, loss-lb:0.0938, loss-ulb:0.0223, weight:2.00, lr:0.0008
[11:17:25.790] iteration:7421  t-loss:0.1427, loss-lb:0.0928, loss-ulb:0.0250, weight:2.00, lr:0.0008
[11:17:25.983] iteration:7422  t-loss:0.1920, loss-lb:0.1229, loss-ulb:0.0346, weight:2.00, lr:0.0008
[11:17:26.175] iteration:7423  t-loss:0.1485, loss-lb:0.0930, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:17:26.366] iteration:7424  t-loss:0.1682, loss-lb:0.1139, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:17:26.559] iteration:7425  t-loss:0.1442, loss-lb:0.0948, loss-ulb:0.0247, weight:2.00, lr:0.0008
[11:17:26.751] iteration:7426  t-loss:0.1757, loss-lb:0.1143, loss-ulb:0.0308, weight:2.00, lr:0.0008
[11:17:26.944] iteration:7427  t-loss:0.1393, loss-lb:0.0879, loss-ulb:0.0258, weight:2.00, lr:0.0008
[11:17:27.135] iteration:7428  t-loss:0.1491, loss-lb:0.0914, loss-ulb:0.0289, weight:2.00, lr:0.0008
[11:17:27.328] iteration:7429  t-loss:0.1557, loss-lb:0.1038, loss-ulb:0.0260, weight:2.00, lr:0.0008
[11:17:27.521] iteration:7430  t-loss:0.1820, loss-lb:0.1157, loss-ulb:0.0332, weight:2.00, lr:0.0008
[11:17:27.713] iteration:7431  t-loss:0.1313, loss-lb:0.0849, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:17:27.906] iteration:7432  t-loss:0.1737, loss-lb:0.0931, loss-ulb:0.0404, weight:2.00, lr:0.0008
[11:17:28.098] iteration:7433  t-loss:0.1545, loss-lb:0.1024, loss-ulb:0.0261, weight:2.00, lr:0.0008
[11:17:28.289] iteration:7434  t-loss:0.1743, loss-lb:0.1250, loss-ulb:0.0247, weight:2.00, lr:0.0008
[11:17:28.483] iteration:7435  t-loss:0.1971, loss-lb:0.1088, loss-ulb:0.0443, weight:2.00, lr:0.0008
[11:17:28.674] iteration:7436  t-loss:0.1553, loss-lb:0.0885, loss-ulb:0.0335, weight:2.00, lr:0.0008
[11:17:28.866] iteration:7437  t-loss:0.1435, loss-lb:0.0974, loss-ulb:0.0231, weight:2.00, lr:0.0008
[11:17:29.058] iteration:7438  t-loss:0.1677, loss-lb:0.0964, loss-ulb:0.0358, weight:2.00, lr:0.0008
[11:17:29.252] iteration:7439  t-loss:0.1517, loss-lb:0.1048, loss-ulb:0.0235, weight:2.00, lr:0.0008
[11:17:29.445] iteration:7440  t-loss:0.1399, loss-lb:0.0947, loss-ulb:0.0226, weight:2.00, lr:0.0008
[11:17:29.636] iteration:7441  t-loss:0.1441, loss-lb:0.0943, loss-ulb:0.0249, weight:2.00, lr:0.0008
[11:17:29.827] iteration:7442  t-loss:0.1792, loss-lb:0.0977, loss-ulb:0.0408, weight:2.00, lr:0.0008
[11:17:30.016] iteration:7443  t-loss:0.1655, loss-lb:0.1097, loss-ulb:0.0280, weight:2.00, lr:0.0008
[11:17:30.207] iteration:7444  t-loss:0.1408, loss-lb:0.0914, loss-ulb:0.0248, weight:2.00, lr:0.0008
[11:17:30.397] iteration:7445  t-loss:0.1499, loss-lb:0.0963, loss-ulb:0.0269, weight:2.00, lr:0.0008
[11:17:30.589] iteration:7446  t-loss:0.1470, loss-lb:0.0967, loss-ulb:0.0252, weight:2.00, lr:0.0008
[11:17:30.778] iteration:7447  t-loss:0.1410, loss-lb:0.0934, loss-ulb:0.0238, weight:2.00, lr:0.0008
[11:17:30.969] iteration:7448  t-loss:0.1409, loss-lb:0.0924, loss-ulb:0.0243, weight:2.00, lr:0.0008
[11:17:31.590] iteration:7449  t-loss:0.1726, loss-lb:0.1054, loss-ulb:0.0337, weight:2.00, lr:0.0008
[11:17:31.785] iteration:7450  t-loss:0.2031, loss-lb:0.1037, loss-ulb:0.0498, weight:2.00, lr:0.0008
[11:17:31.979] iteration:7451  t-loss:0.1763, loss-lb:0.0888, loss-ulb:0.0438, weight:2.00, lr:0.0008
[11:17:32.174] iteration:7452  t-loss:0.1399, loss-lb:0.0936, loss-ulb:0.0232, weight:2.00, lr:0.0008
[11:17:32.371] iteration:7453  t-loss:0.1478, loss-lb:0.0940, loss-ulb:0.0270, weight:2.00, lr:0.0008
[11:17:32.565] iteration:7454  t-loss:0.1411, loss-lb:0.0962, loss-ulb:0.0225, weight:2.00, lr:0.0008
[11:17:32.758] iteration:7455  t-loss:0.1420, loss-lb:0.0955, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:17:32.951] iteration:7456  t-loss:0.1815, loss-lb:0.0939, loss-ulb:0.0439, weight:2.00, lr:0.0008
[11:17:33.142] iteration:7457  t-loss:0.1403, loss-lb:0.0938, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:17:33.333] iteration:7458  t-loss:0.1510, loss-lb:0.0932, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:17:33.524] iteration:7459  t-loss:0.1714, loss-lb:0.0918, loss-ulb:0.0399, weight:2.00, lr:0.0008
[11:17:33.716] iteration:7460  t-loss:0.1509, loss-lb:0.0942, loss-ulb:0.0284, weight:2.00, lr:0.0008
[11:17:33.907] iteration:7461  t-loss:0.1667, loss-lb:0.0986, loss-ulb:0.0341, weight:2.00, lr:0.0008
[11:17:34.100] iteration:7462  t-loss:0.1906, loss-lb:0.1221, loss-ulb:0.0343, weight:2.00, lr:0.0008
[11:17:34.291] iteration:7463  t-loss:0.1442, loss-lb:0.0863, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:17:34.483] iteration:7464  t-loss:0.1684, loss-lb:0.1002, loss-ulb:0.0341, weight:2.00, lr:0.0008
[11:17:34.675] iteration:7465  t-loss:0.2344, loss-lb:0.0971, loss-ulb:0.0688, weight:2.00, lr:0.0008
[11:17:34.867] iteration:7466  t-loss:0.1515, loss-lb:0.1003, loss-ulb:0.0257, weight:2.00, lr:0.0008
[11:17:35.058] iteration:7467  t-loss:0.1641, loss-lb:0.1066, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:17:35.251] iteration:7468  t-loss:0.2153, loss-lb:0.0917, loss-ulb:0.0619, weight:2.00, lr:0.0008
[11:17:35.443] iteration:7469  t-loss:0.1602, loss-lb:0.1019, loss-ulb:0.0292, weight:2.00, lr:0.0008
[11:17:35.634] iteration:7470  t-loss:0.1563, loss-lb:0.1038, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:17:35.827] iteration:7471  t-loss:0.1834, loss-lb:0.1004, loss-ulb:0.0416, weight:2.00, lr:0.0008
[11:17:36.019] iteration:7472  t-loss:0.1434, loss-lb:0.0879, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:17:36.211] iteration:7473  t-loss:0.1647, loss-lb:0.1037, loss-ulb:0.0305, weight:2.00, lr:0.0008
[11:17:36.402] iteration:7474  t-loss:0.2125, loss-lb:0.1392, loss-ulb:0.0367, weight:2.00, lr:0.0008
[11:17:36.593] iteration:7475  t-loss:0.1595, loss-lb:0.1012, loss-ulb:0.0292, weight:2.00, lr:0.0008
[11:17:36.785] iteration:7476  t-loss:0.2104, loss-lb:0.0930, loss-ulb:0.0588, weight:2.00, lr:0.0008
[11:17:36.977] iteration:7477  t-loss:0.1456, loss-lb:0.0966, loss-ulb:0.0246, weight:2.00, lr:0.0008
[11:17:37.169] iteration:7478  t-loss:0.1806, loss-lb:0.0900, loss-ulb:0.0454, weight:2.00, lr:0.0008
[11:17:37.363] iteration:7479  t-loss:0.1655, loss-lb:0.0993, loss-ulb:0.0332, weight:2.00, lr:0.0008
[11:17:37.555] iteration:7480  t-loss:0.1637, loss-lb:0.1107, loss-ulb:0.0265, weight:2.00, lr:0.0008
[11:17:37.746] iteration:7481  t-loss:0.1682, loss-lb:0.0933, loss-ulb:0.0375, weight:2.00, lr:0.0008
[11:17:37.938] iteration:7482  t-loss:0.1582, loss-lb:0.0950, loss-ulb:0.0317, weight:2.00, lr:0.0008
[11:17:38.132] iteration:7483  t-loss:0.1633, loss-lb:0.1159, loss-ulb:0.0237, weight:2.00, lr:0.0008
[11:17:38.323] iteration:7484  t-loss:0.1734, loss-lb:0.1017, loss-ulb:0.0359, weight:2.00, lr:0.0008
[11:17:38.515] iteration:7485  t-loss:0.1614, loss-lb:0.1043, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:17:38.707] iteration:7486  t-loss:0.2039, loss-lb:0.1057, loss-ulb:0.0492, weight:2.00, lr:0.0008
[11:17:38.897] iteration:7487  t-loss:0.1771, loss-lb:0.1010, loss-ulb:0.0381, weight:2.00, lr:0.0008
[11:17:39.090] iteration:7488  t-loss:0.1980, loss-lb:0.0951, loss-ulb:0.0515, weight:2.00, lr:0.0008
[11:17:39.282] iteration:7489  t-loss:0.2170, loss-lb:0.1420, loss-ulb:0.0375, weight:2.00, lr:0.0008
[11:17:39.474] iteration:7490  t-loss:0.1791, loss-lb:0.0933, loss-ulb:0.0430, weight:2.00, lr:0.0008
[11:17:39.665] iteration:7491  t-loss:0.1821, loss-lb:0.1068, loss-ulb:0.0377, weight:2.00, lr:0.0008
[11:17:39.856] iteration:7492  t-loss:0.1638, loss-lb:0.1032, loss-ulb:0.0303, weight:2.00, lr:0.0008
[11:17:40.048] iteration:7493  t-loss:0.1501, loss-lb:0.0909, loss-ulb:0.0297, weight:2.00, lr:0.0008
[11:17:40.238] iteration:7494  t-loss:0.1897, loss-lb:0.0989, loss-ulb:0.0455, weight:2.00, lr:0.0008
[11:17:40.430] iteration:7495  t-loss:0.1717, loss-lb:0.1038, loss-ulb:0.0340, weight:2.00, lr:0.0008
[11:17:40.622] iteration:7496  t-loss:0.1394, loss-lb:0.0926, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:17:40.812] iteration:7497  t-loss:0.1958, loss-lb:0.1137, loss-ulb:0.0411, weight:2.00, lr:0.0008
[11:17:41.003] iteration:7498  t-loss:0.1845, loss-lb:0.0917, loss-ulb:0.0465, weight:2.00, lr:0.0008
[11:17:41.194] iteration:7499  t-loss:0.1875, loss-lb:0.0885, loss-ulb:0.0496, weight:2.00, lr:0.0008
[11:17:41.385] iteration:7500  t-loss:0.1719, loss-lb:0.1164, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:17:41.576] iteration:7501  t-loss:0.1664, loss-lb:0.1026, loss-ulb:0.0319, weight:2.00, lr:0.0008
[11:17:41.768] iteration:7502  t-loss:0.1961, loss-lb:0.0975, loss-ulb:0.0493, weight:2.00, lr:0.0008
[11:17:41.959] iteration:7503  t-loss:0.1684, loss-lb:0.0919, loss-ulb:0.0383, weight:2.00, lr:0.0008
[11:17:42.150] iteration:7504  t-loss:0.1634, loss-lb:0.0973, loss-ulb:0.0330, weight:2.00, lr:0.0008
[11:17:42.341] iteration:7505  t-loss:0.1594, loss-lb:0.0980, loss-ulb:0.0307, weight:2.00, lr:0.0008
[11:17:42.533] iteration:7506  t-loss:0.1716, loss-lb:0.0979, loss-ulb:0.0368, weight:2.00, lr:0.0008
[11:17:42.724] iteration:7507  t-loss:0.1751, loss-lb:0.0968, loss-ulb:0.0392, weight:2.00, lr:0.0008
[11:17:42.917] iteration:7508  t-loss:0.1725, loss-lb:0.1008, loss-ulb:0.0358, weight:2.00, lr:0.0008
[11:17:43.111] iteration:7509  t-loss:0.1974, loss-lb:0.0964, loss-ulb:0.0505, weight:2.00, lr:0.0008
[11:17:43.307] iteration:7510  t-loss:0.3125, loss-lb:0.0950, loss-ulb:0.1088, weight:2.00, lr:0.0008
[11:17:43.503] iteration:7511  t-loss:0.1546, loss-lb:0.0984, loss-ulb:0.0281, weight:2.00, lr:0.0008
[11:17:43.696] iteration:7512  t-loss:0.1839, loss-lb:0.1306, loss-ulb:0.0267, weight:2.00, lr:0.0008
[11:17:43.890] iteration:7513  t-loss:0.1564, loss-lb:0.1004, loss-ulb:0.0280, weight:2.00, lr:0.0008
[11:17:44.081] iteration:7514  t-loss:0.1808, loss-lb:0.1108, loss-ulb:0.0350, weight:2.00, lr:0.0008
[11:17:44.272] iteration:7515  t-loss:0.1684, loss-lb:0.0988, loss-ulb:0.0348, weight:2.00, lr:0.0008
[11:17:44.464] iteration:7516  t-loss:0.1480, loss-lb:0.0954, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:17:44.656] iteration:7517  t-loss:0.1614, loss-lb:0.1058, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:17:44.848] iteration:7518  t-loss:0.1646, loss-lb:0.0902, loss-ulb:0.0372, weight:2.00, lr:0.0008
[11:17:45.040] iteration:7519  t-loss:0.1593, loss-lb:0.1022, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:17:45.231] iteration:7520  t-loss:0.1554, loss-lb:0.0955, loss-ulb:0.0300, weight:2.00, lr:0.0008
[11:17:45.423] iteration:7521  t-loss:0.1501, loss-lb:0.0947, loss-ulb:0.0277, weight:2.00, lr:0.0008
[11:17:45.614] iteration:7522  t-loss:0.2036, loss-lb:0.1109, loss-ulb:0.0463, weight:2.00, lr:0.0008
[11:17:45.806] iteration:7523  t-loss:0.1555, loss-lb:0.1038, loss-ulb:0.0258, weight:2.00, lr:0.0008
[11:17:45.997] iteration:7524  t-loss:0.1462, loss-lb:0.0928, loss-ulb:0.0267, weight:2.00, lr:0.0008
[11:17:46.189] iteration:7525  t-loss:0.2137, loss-lb:0.1073, loss-ulb:0.0532, weight:2.00, lr:0.0008
[11:17:46.381] iteration:7526  t-loss:0.1623, loss-lb:0.0968, loss-ulb:0.0328, weight:2.00, lr:0.0008
[11:17:46.573] iteration:7527  t-loss:0.1460, loss-lb:0.0937, loss-ulb:0.0262, weight:2.00, lr:0.0008
[11:17:46.766] iteration:7528  t-loss:0.2297, loss-lb:0.0975, loss-ulb:0.0661, weight:2.00, lr:0.0008
[11:17:46.957] iteration:7529  t-loss:0.1429, loss-lb:0.0954, loss-ulb:0.0238, weight:2.00, lr:0.0008
[11:17:47.149] iteration:7530  t-loss:0.1444, loss-lb:0.0976, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:17:47.341] iteration:7531  t-loss:0.1535, loss-lb:0.0961, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:17:47.533] iteration:7532  t-loss:0.1451, loss-lb:0.0868, loss-ulb:0.0292, weight:2.00, lr:0.0008
[11:17:47.724] iteration:7533  t-loss:0.1498, loss-lb:0.0953, loss-ulb:0.0273, weight:2.00, lr:0.0008
[11:17:47.916] iteration:7534  t-loss:0.2028, loss-lb:0.0897, loss-ulb:0.0566, weight:2.00, lr:0.0008
[11:17:48.108] iteration:7535  t-loss:0.1877, loss-lb:0.1005, loss-ulb:0.0436, weight:2.00, lr:0.0008
[11:17:48.300] iteration:7536  t-loss:0.1543, loss-lb:0.0986, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:17:48.491] iteration:7537  t-loss:0.1444, loss-lb:0.0976, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:17:48.683] iteration:7538  t-loss:0.1570, loss-lb:0.1074, loss-ulb:0.0248, weight:2.00, lr:0.0008
[11:17:48.874] iteration:7539  t-loss:0.1881, loss-lb:0.1205, loss-ulb:0.0338, weight:2.00, lr:0.0008
[11:17:49.066] iteration:7540  t-loss:0.1459, loss-lb:0.0962, loss-ulb:0.0249, weight:2.00, lr:0.0008
[11:17:49.258] iteration:7541  t-loss:0.2629, loss-lb:0.0900, loss-ulb:0.0864, weight:2.00, lr:0.0008
[11:17:49.448] iteration:7542  t-loss:0.2139, loss-lb:0.0877, loss-ulb:0.0631, weight:2.00, lr:0.0008
[11:17:49.639] iteration:7543  t-loss:0.1418, loss-lb:0.0927, loss-ulb:0.0245, weight:2.00, lr:0.0008
[11:17:49.829] iteration:7544  t-loss:0.1249, loss-lb:0.0852, loss-ulb:0.0198, weight:2.00, lr:0.0008
[11:17:50.019] iteration:7545  t-loss:0.1409, loss-lb:0.0900, loss-ulb:0.0255, weight:2.00, lr:0.0008
[11:17:50.211] iteration:7546  t-loss:0.1373, loss-lb:0.0921, loss-ulb:0.0226, weight:2.00, lr:0.0008
[11:18:01.389]  <<Test>> - Ep:76  - mean_dice/mean_h95 - S:89.69/1.57, Best-S:90.13, T:90.14/1.46, Best-T:90.27
[11:18:01.389]           - AvgLoss(lb/ulb/all):0.0995/0.0351/0.1657
[11:18:01.918] iteration:7547  t-loss:0.1447, loss-lb:0.1025, loss-ulb:0.0211, weight:2.00, lr:0.0008
[11:18:02.116] iteration:7548  t-loss:0.2165, loss-lb:0.1074, loss-ulb:0.0545, weight:2.00, lr:0.0008
[11:18:02.308] iteration:7549  t-loss:0.1441, loss-lb:0.0913, loss-ulb:0.0264, weight:2.00, lr:0.0008
[11:18:02.500] iteration:7550  t-loss:0.1662, loss-lb:0.1063, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:18:02.693] iteration:7551  t-loss:0.1590, loss-lb:0.0993, loss-ulb:0.0298, weight:2.00, lr:0.0008
[11:18:02.884] iteration:7552  t-loss:0.1688, loss-lb:0.1055, loss-ulb:0.0317, weight:2.00, lr:0.0008
[11:18:03.076] iteration:7553  t-loss:0.1569, loss-lb:0.0979, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:18:03.269] iteration:7554  t-loss:0.1810, loss-lb:0.0935, loss-ulb:0.0438, weight:2.00, lr:0.0008
[11:18:03.461] iteration:7555  t-loss:0.2222, loss-lb:0.0885, loss-ulb:0.0669, weight:2.00, lr:0.0008
[11:18:03.652] iteration:7556  t-loss:0.1545, loss-lb:0.0894, loss-ulb:0.0326, weight:2.00, lr:0.0008
[11:18:03.844] iteration:7557  t-loss:0.2183, loss-lb:0.1082, loss-ulb:0.0551, weight:2.00, lr:0.0008
[11:18:04.035] iteration:7558  t-loss:0.1737, loss-lb:0.1069, loss-ulb:0.0334, weight:2.00, lr:0.0008
[11:18:04.227] iteration:7559  t-loss:0.1628, loss-lb:0.0997, loss-ulb:0.0316, weight:2.00, lr:0.0008
[11:18:04.419] iteration:7560  t-loss:0.2014, loss-lb:0.1025, loss-ulb:0.0495, weight:2.00, lr:0.0008
[11:18:04.612] iteration:7561  t-loss:0.1664, loss-lb:0.1006, loss-ulb:0.0329, weight:2.00, lr:0.0008
[11:18:04.809] iteration:7562  t-loss:0.1400, loss-lb:0.0881, loss-ulb:0.0259, weight:2.00, lr:0.0008
[11:18:05.005] iteration:7563  t-loss:0.1849, loss-lb:0.0909, loss-ulb:0.0470, weight:2.00, lr:0.0008
[11:18:05.200] iteration:7564  t-loss:0.1849, loss-lb:0.0998, loss-ulb:0.0426, weight:2.00, lr:0.0008
[11:18:05.394] iteration:7565  t-loss:0.1859, loss-lb:0.1145, loss-ulb:0.0357, weight:2.00, lr:0.0008
[11:18:05.587] iteration:7566  t-loss:0.1746, loss-lb:0.0826, loss-ulb:0.0460, weight:2.00, lr:0.0008
[11:18:05.778] iteration:7567  t-loss:0.1661, loss-lb:0.1080, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:18:05.969] iteration:7568  t-loss:0.1601, loss-lb:0.1112, loss-ulb:0.0245, weight:2.00, lr:0.0008
[11:18:06.162] iteration:7569  t-loss:0.1421, loss-lb:0.0913, loss-ulb:0.0254, weight:2.00, lr:0.0008
[11:18:06.354] iteration:7570  t-loss:0.1704, loss-lb:0.0861, loss-ulb:0.0421, weight:2.00, lr:0.0008
[11:18:06.545] iteration:7571  t-loss:0.1623, loss-lb:0.1048, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:18:06.739] iteration:7572  t-loss:0.1600, loss-lb:0.0969, loss-ulb:0.0315, weight:2.00, lr:0.0008
[11:18:06.929] iteration:7573  t-loss:0.1697, loss-lb:0.0939, loss-ulb:0.0379, weight:2.00, lr:0.0008
[11:18:07.121] iteration:7574  t-loss:0.1486, loss-lb:0.0965, loss-ulb:0.0260, weight:2.00, lr:0.0008
[11:18:07.312] iteration:7575  t-loss:0.1865, loss-lb:0.1004, loss-ulb:0.0430, weight:2.00, lr:0.0008
[11:18:07.504] iteration:7576  t-loss:0.1613, loss-lb:0.0912, loss-ulb:0.0351, weight:2.00, lr:0.0008
[11:18:07.697] iteration:7577  t-loss:0.1588, loss-lb:0.0968, loss-ulb:0.0310, weight:2.00, lr:0.0008
[11:18:07.888] iteration:7578  t-loss:0.1604, loss-lb:0.1046, loss-ulb:0.0279, weight:2.00, lr:0.0008
[11:18:08.082] iteration:7579  t-loss:0.1741, loss-lb:0.0983, loss-ulb:0.0379, weight:2.00, lr:0.0008
[11:18:08.273] iteration:7580  t-loss:0.1701, loss-lb:0.0984, loss-ulb:0.0358, weight:2.00, lr:0.0008
[11:18:08.466] iteration:7581  t-loss:0.2020, loss-lb:0.0844, loss-ulb:0.0588, weight:2.00, lr:0.0008
[11:18:08.663] iteration:7582  t-loss:0.1682, loss-lb:0.0958, loss-ulb:0.0362, weight:2.00, lr:0.0008
[11:18:08.854] iteration:7583  t-loss:0.1567, loss-lb:0.1018, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:18:09.047] iteration:7584  t-loss:0.1683, loss-lb:0.0854, loss-ulb:0.0415, weight:2.00, lr:0.0008
[11:18:09.239] iteration:7585  t-loss:0.1410, loss-lb:0.1019, loss-ulb:0.0196, weight:2.00, lr:0.0008
[11:18:09.431] iteration:7586  t-loss:0.1410, loss-lb:0.0936, loss-ulb:0.0237, weight:2.00, lr:0.0008
[11:18:09.623] iteration:7587  t-loss:0.1613, loss-lb:0.0897, loss-ulb:0.0358, weight:2.00, lr:0.0008
[11:18:09.814] iteration:7588  t-loss:0.1867, loss-lb:0.1084, loss-ulb:0.0392, weight:2.00, lr:0.0008
[11:18:10.008] iteration:7589  t-loss:0.1513, loss-lb:0.0923, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:18:10.200] iteration:7590  t-loss:0.1430, loss-lb:0.0984, loss-ulb:0.0223, weight:2.00, lr:0.0008
[11:18:10.534] iteration:7591  t-loss:0.1563, loss-lb:0.0964, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:18:10.726] iteration:7592  t-loss:0.1528, loss-lb:0.0900, loss-ulb:0.0314, weight:2.00, lr:0.0008
[11:18:10.919] iteration:7593  t-loss:0.2265, loss-lb:0.0911, loss-ulb:0.0677, weight:2.00, lr:0.0008
[11:18:11.112] iteration:7594  t-loss:0.1416, loss-lb:0.0835, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:18:11.304] iteration:7595  t-loss:0.2280, loss-lb:0.1036, loss-ulb:0.0622, weight:2.00, lr:0.0008
[11:18:11.497] iteration:7596  t-loss:0.1359, loss-lb:0.0874, loss-ulb:0.0242, weight:2.00, lr:0.0008
[11:18:11.688] iteration:7597  t-loss:0.1447, loss-lb:0.0924, loss-ulb:0.0261, weight:2.00, lr:0.0008
[11:18:11.881] iteration:7598  t-loss:0.1588, loss-lb:0.0976, loss-ulb:0.0306, weight:2.00, lr:0.0008
[11:18:12.073] iteration:7599  t-loss:0.1663, loss-lb:0.0934, loss-ulb:0.0365, weight:2.00, lr:0.0008
[11:18:12.264] iteration:7600  t-loss:0.1497, loss-lb:0.0923, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:18:12.456] iteration:7601  t-loss:0.1483, loss-lb:0.0975, loss-ulb:0.0254, weight:2.00, lr:0.0008
[11:18:12.646] iteration:7602  t-loss:0.1366, loss-lb:0.0875, loss-ulb:0.0246, weight:2.00, lr:0.0008
[11:18:12.838] iteration:7603  t-loss:0.1533, loss-lb:0.1030, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:18:13.029] iteration:7604  t-loss:0.1443, loss-lb:0.0892, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:18:13.221] iteration:7605  t-loss:0.1431, loss-lb:0.0935, loss-ulb:0.0248, weight:2.00, lr:0.0008
[11:18:13.411] iteration:7606  t-loss:0.1479, loss-lb:0.0922, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:18:13.603] iteration:7607  t-loss:0.1390, loss-lb:0.0930, loss-ulb:0.0230, weight:2.00, lr:0.0008
[11:18:13.794] iteration:7608  t-loss:0.1443, loss-lb:0.0883, loss-ulb:0.0280, weight:2.00, lr:0.0008
[11:18:13.986] iteration:7609  t-loss:0.2206, loss-lb:0.0945, loss-ulb:0.0630, weight:2.00, lr:0.0008
[11:18:14.178] iteration:7610  t-loss:0.1614, loss-lb:0.0941, loss-ulb:0.0336, weight:2.00, lr:0.0008
[11:18:14.369] iteration:7611  t-loss:0.1444, loss-lb:0.0978, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:18:14.560] iteration:7612  t-loss:0.1476, loss-lb:0.0932, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:18:14.751] iteration:7613  t-loss:0.1742, loss-lb:0.1173, loss-ulb:0.0284, weight:2.00, lr:0.0008
[11:18:14.942] iteration:7614  t-loss:0.1677, loss-lb:0.0999, loss-ulb:0.0339, weight:2.00, lr:0.0008
[11:18:15.136] iteration:7615  t-loss:0.1761, loss-lb:0.0878, loss-ulb:0.0442, weight:2.00, lr:0.0008
[11:18:15.330] iteration:7616  t-loss:0.1743, loss-lb:0.1041, loss-ulb:0.0351, weight:2.00, lr:0.0008
[11:18:15.522] iteration:7617  t-loss:0.2325, loss-lb:0.0994, loss-ulb:0.0666, weight:2.00, lr:0.0008
[11:18:15.715] iteration:7618  t-loss:0.1580, loss-lb:0.1063, loss-ulb:0.0258, weight:2.00, lr:0.0008
[11:18:15.907] iteration:7619  t-loss:0.1529, loss-lb:0.1014, loss-ulb:0.0258, weight:2.00, lr:0.0008
[11:18:16.098] iteration:7620  t-loss:0.1511, loss-lb:0.0938, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:18:16.290] iteration:7621  t-loss:0.1714, loss-lb:0.1149, loss-ulb:0.0282, weight:2.00, lr:0.0008
[11:18:16.483] iteration:7622  t-loss:0.1421, loss-lb:0.0892, loss-ulb:0.0264, weight:2.00, lr:0.0008
[11:18:16.675] iteration:7623  t-loss:0.1463, loss-lb:0.0915, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:18:16.868] iteration:7624  t-loss:0.1527, loss-lb:0.1001, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:18:17.060] iteration:7625  t-loss:0.1571, loss-lb:0.0916, loss-ulb:0.0328, weight:2.00, lr:0.0008
[11:18:17.253] iteration:7626  t-loss:0.2184, loss-lb:0.0901, loss-ulb:0.0641, weight:2.00, lr:0.0008
[11:18:17.444] iteration:7627  t-loss:0.1472, loss-lb:0.0886, loss-ulb:0.0293, weight:2.00, lr:0.0008
[11:18:17.638] iteration:7628  t-loss:0.3738, loss-lb:0.0913, loss-ulb:0.1413, weight:2.00, lr:0.0008
[11:18:17.829] iteration:7629  t-loss:0.1523, loss-lb:0.0996, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:18:18.021] iteration:7630  t-loss:0.1462, loss-lb:0.0934, loss-ulb:0.0264, weight:2.00, lr:0.0008
[11:18:18.214] iteration:7631  t-loss:0.1474, loss-lb:0.0899, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:18:18.406] iteration:7632  t-loss:0.1378, loss-lb:0.0837, loss-ulb:0.0271, weight:2.00, lr:0.0008
[11:18:18.598] iteration:7633  t-loss:0.1423, loss-lb:0.0935, loss-ulb:0.0244, weight:2.00, lr:0.0008
[11:18:18.790] iteration:7634  t-loss:0.1595, loss-lb:0.1006, loss-ulb:0.0294, weight:2.00, lr:0.0008
[11:18:18.982] iteration:7635  t-loss:0.1585, loss-lb:0.0989, loss-ulb:0.0298, weight:2.00, lr:0.0008
[11:18:19.174] iteration:7636  t-loss:0.1593, loss-lb:0.1042, loss-ulb:0.0275, weight:2.00, lr:0.0008
[11:18:19.366] iteration:7637  t-loss:0.1474, loss-lb:0.0994, loss-ulb:0.0240, weight:2.00, lr:0.0008
[11:18:19.556] iteration:7638  t-loss:0.1645, loss-lb:0.0995, loss-ulb:0.0325, weight:2.00, lr:0.0008
[11:18:19.747] iteration:7639  t-loss:0.1562, loss-lb:0.1069, loss-ulb:0.0247, weight:2.00, lr:0.0008
[11:18:19.937] iteration:7640  t-loss:0.1408, loss-lb:0.0955, loss-ulb:0.0227, weight:2.00, lr:0.0008
[11:18:20.128] iteration:7641  t-loss:0.1382, loss-lb:0.0866, loss-ulb:0.0258, weight:2.00, lr:0.0008
[11:18:20.320] iteration:7642  t-loss:0.2574, loss-lb:0.1020, loss-ulb:0.0777, weight:2.00, lr:0.0008
[11:18:20.512] iteration:7643  t-loss:0.1505, loss-lb:0.1003, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:18:20.702] iteration:7644  t-loss:0.1528, loss-lb:0.1027, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:18:21.291] iteration:7645  t-loss:0.1816, loss-lb:0.0972, loss-ulb:0.0422, weight:2.00, lr:0.0008
[11:18:21.484] iteration:7646  t-loss:0.1432, loss-lb:0.0881, loss-ulb:0.0275, weight:2.00, lr:0.0008
[11:18:21.676] iteration:7647  t-loss:0.1316, loss-lb:0.0852, loss-ulb:0.0232, weight:2.00, lr:0.0008
[11:18:21.868] iteration:7648  t-loss:0.1575, loss-lb:0.0987, loss-ulb:0.0294, weight:2.00, lr:0.0008
[11:18:22.060] iteration:7649  t-loss:0.1391, loss-lb:0.0938, loss-ulb:0.0227, weight:2.00, lr:0.0008
[11:18:22.252] iteration:7650  t-loss:0.1397, loss-lb:0.0909, loss-ulb:0.0244, weight:2.00, lr:0.0008
[11:18:22.444] iteration:7651  t-loss:0.1486, loss-lb:0.0923, loss-ulb:0.0281, weight:2.00, lr:0.0008
[11:18:22.636] iteration:7652  t-loss:0.1524, loss-lb:0.1027, loss-ulb:0.0248, weight:2.00, lr:0.0008
[11:18:22.828] iteration:7653  t-loss:0.1473, loss-lb:0.0940, loss-ulb:0.0266, weight:2.00, lr:0.0008
[11:18:23.020] iteration:7654  t-loss:0.1865, loss-lb:0.1038, loss-ulb:0.0413, weight:2.00, lr:0.0008
[11:18:23.213] iteration:7655  t-loss:0.1515, loss-lb:0.0956, loss-ulb:0.0279, weight:2.00, lr:0.0008
[11:18:23.406] iteration:7656  t-loss:0.1417, loss-lb:0.0869, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:18:23.598] iteration:7657  t-loss:0.1490, loss-lb:0.0916, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:18:23.790] iteration:7658  t-loss:0.2304, loss-lb:0.0925, loss-ulb:0.0690, weight:2.00, lr:0.0008
[11:18:23.983] iteration:7659  t-loss:0.1346, loss-lb:0.0936, loss-ulb:0.0205, weight:2.00, lr:0.0008
[11:18:24.176] iteration:7660  t-loss:0.1361, loss-lb:0.0906, loss-ulb:0.0228, weight:2.00, lr:0.0008
[11:18:24.367] iteration:7661  t-loss:0.1998, loss-lb:0.1006, loss-ulb:0.0496, weight:2.00, lr:0.0008
[11:18:24.560] iteration:7662  t-loss:0.1502, loss-lb:0.0842, loss-ulb:0.0330, weight:2.00, lr:0.0008
[11:18:24.753] iteration:7663  t-loss:0.1626, loss-lb:0.1051, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:18:24.945] iteration:7664  t-loss:0.1602, loss-lb:0.0978, loss-ulb:0.0312, weight:2.00, lr:0.0008
[11:18:25.137] iteration:7665  t-loss:0.1545, loss-lb:0.0948, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:18:25.331] iteration:7666  t-loss:0.2094, loss-lb:0.0967, loss-ulb:0.0563, weight:2.00, lr:0.0008
[11:18:25.524] iteration:7667  t-loss:0.2079, loss-lb:0.0989, loss-ulb:0.0545, weight:2.00, lr:0.0008
[11:18:25.728] iteration:7668  t-loss:0.1636, loss-lb:0.0883, loss-ulb:0.0376, weight:2.00, lr:0.0008
[11:18:25.927] iteration:7669  t-loss:0.1522, loss-lb:0.1059, loss-ulb:0.0232, weight:2.00, lr:0.0008
[11:18:26.123] iteration:7670  t-loss:0.1685, loss-lb:0.1012, loss-ulb:0.0337, weight:2.00, lr:0.0008
[11:18:26.315] iteration:7671  t-loss:0.1478, loss-lb:0.0902, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:18:26.508] iteration:7672  t-loss:0.1473, loss-lb:0.0947, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:18:26.701] iteration:7673  t-loss:0.1475, loss-lb:0.0973, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:18:26.895] iteration:7674  t-loss:0.1446, loss-lb:0.0934, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:18:27.086] iteration:7675  t-loss:0.1754, loss-lb:0.0870, loss-ulb:0.0442, weight:2.00, lr:0.0008
[11:18:27.278] iteration:7676  t-loss:0.1528, loss-lb:0.0950, loss-ulb:0.0289, weight:2.00, lr:0.0008
[11:18:27.471] iteration:7677  t-loss:0.1335, loss-lb:0.0887, loss-ulb:0.0224, weight:2.00, lr:0.0008
[11:18:27.663] iteration:7678  t-loss:0.1469, loss-lb:0.0838, loss-ulb:0.0316, weight:2.00, lr:0.0008
[11:18:27.855] iteration:7679  t-loss:0.1449, loss-lb:0.0899, loss-ulb:0.0275, weight:2.00, lr:0.0008
[11:18:28.048] iteration:7680  t-loss:0.1415, loss-lb:0.0952, loss-ulb:0.0232, weight:2.00, lr:0.0008
[11:18:28.240] iteration:7681  t-loss:0.1351, loss-lb:0.0943, loss-ulb:0.0204, weight:2.00, lr:0.0008
[11:18:28.432] iteration:7682  t-loss:0.1315, loss-lb:0.0856, loss-ulb:0.0229, weight:2.00, lr:0.0008
[11:18:28.625] iteration:7683  t-loss:0.1424, loss-lb:0.0977, loss-ulb:0.0224, weight:2.00, lr:0.0008
[11:18:28.818] iteration:7684  t-loss:0.1893, loss-lb:0.0997, loss-ulb:0.0448, weight:2.00, lr:0.0008
[11:18:29.010] iteration:7685  t-loss:0.1478, loss-lb:0.0940, loss-ulb:0.0269, weight:2.00, lr:0.0008
[11:18:29.202] iteration:7686  t-loss:0.1858, loss-lb:0.0997, loss-ulb:0.0431, weight:2.00, lr:0.0008
[11:18:29.395] iteration:7687  t-loss:0.1512, loss-lb:0.0917, loss-ulb:0.0298, weight:2.00, lr:0.0008
[11:18:29.588] iteration:7688  t-loss:0.1382, loss-lb:0.0853, loss-ulb:0.0265, weight:2.00, lr:0.0008
[11:18:29.781] iteration:7689  t-loss:0.1572, loss-lb:0.0918, loss-ulb:0.0327, weight:2.00, lr:0.0008
[11:18:29.973] iteration:7690  t-loss:0.1488, loss-lb:0.0856, loss-ulb:0.0316, weight:2.00, lr:0.0008
[11:18:30.166] iteration:7691  t-loss:0.1866, loss-lb:0.0952, loss-ulb:0.0457, weight:2.00, lr:0.0008
[11:18:30.358] iteration:7692  t-loss:0.1435, loss-lb:0.0923, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:18:30.551] iteration:7693  t-loss:0.1593, loss-lb:0.1059, loss-ulb:0.0267, weight:2.00, lr:0.0008
[11:18:30.745] iteration:7694  t-loss:0.1354, loss-lb:0.0860, loss-ulb:0.0247, weight:2.00, lr:0.0008
[11:18:30.937] iteration:7695  t-loss:0.1641, loss-lb:0.0901, loss-ulb:0.0370, weight:2.00, lr:0.0008
[11:18:31.128] iteration:7696  t-loss:0.1442, loss-lb:0.0995, loss-ulb:0.0223, weight:2.00, lr:0.0008
[11:18:31.322] iteration:7697  t-loss:0.3283, loss-lb:0.0880, loss-ulb:0.1202, weight:2.00, lr:0.0008
[11:18:31.514] iteration:7698  t-loss:0.1534, loss-lb:0.1021, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:18:31.706] iteration:7699  t-loss:0.1465, loss-lb:0.0892, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:18:31.898] iteration:7700  t-loss:0.2328, loss-lb:0.0921, loss-ulb:0.0703, weight:2.00, lr:0.0008
[11:18:32.091] iteration:7701  t-loss:0.1657, loss-lb:0.1112, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:18:32.284] iteration:7702  t-loss:0.1290, loss-lb:0.0851, loss-ulb:0.0219, weight:2.00, lr:0.0008
[11:18:32.475] iteration:7703  t-loss:0.1689, loss-lb:0.1013, loss-ulb:0.0338, weight:2.00, lr:0.0008
[11:18:32.667] iteration:7704  t-loss:0.1445, loss-lb:0.0863, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:18:32.861] iteration:7705  t-loss:0.2300, loss-lb:0.0909, loss-ulb:0.0695, weight:2.00, lr:0.0008
[11:18:33.054] iteration:7706  t-loss:0.1805, loss-lb:0.0853, loss-ulb:0.0476, weight:2.00, lr:0.0008
[11:18:33.246] iteration:7707  t-loss:0.1368, loss-lb:0.0949, loss-ulb:0.0210, weight:2.00, lr:0.0008
[11:18:33.438] iteration:7708  t-loss:0.1718, loss-lb:0.1083, loss-ulb:0.0317, weight:2.00, lr:0.0008
[11:18:33.630] iteration:7709  t-loss:0.2122, loss-lb:0.0847, loss-ulb:0.0638, weight:2.00, lr:0.0008
[11:18:33.822] iteration:7710  t-loss:0.1328, loss-lb:0.0870, loss-ulb:0.0229, weight:2.00, lr:0.0008
[11:18:34.015] iteration:7711  t-loss:0.1772, loss-lb:0.1142, loss-ulb:0.0315, weight:2.00, lr:0.0008
[11:18:34.208] iteration:7712  t-loss:0.1481, loss-lb:0.0952, loss-ulb:0.0264, weight:2.00, lr:0.0008
[11:18:34.400] iteration:7713  t-loss:0.3392, loss-lb:0.1302, loss-ulb:0.1045, weight:2.00, lr:0.0008
[11:18:34.593] iteration:7714  t-loss:0.1523, loss-lb:0.0991, loss-ulb:0.0266, weight:2.00, lr:0.0008
[11:18:34.787] iteration:7715  t-loss:0.1802, loss-lb:0.0968, loss-ulb:0.0417, weight:2.00, lr:0.0008
[11:18:34.979] iteration:7716  t-loss:0.1461, loss-lb:0.0880, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:18:35.171] iteration:7717  t-loss:0.1561, loss-lb:0.1036, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:18:35.363] iteration:7718  t-loss:0.1511, loss-lb:0.1042, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:18:35.556] iteration:7719  t-loss:0.1511, loss-lb:0.0904, loss-ulb:0.0303, weight:2.00, lr:0.0008
[11:18:35.747] iteration:7720  t-loss:0.1487, loss-lb:0.0941, loss-ulb:0.0273, weight:2.00, lr:0.0008
[11:18:35.939] iteration:7721  t-loss:0.1491, loss-lb:0.0949, loss-ulb:0.0271, weight:2.00, lr:0.0008
[11:18:36.133] iteration:7722  t-loss:0.1536, loss-lb:0.0979, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:18:36.325] iteration:7723  t-loss:0.1989, loss-lb:0.0938, loss-ulb:0.0526, weight:2.00, lr:0.0008
[11:18:36.517] iteration:7724  t-loss:0.1742, loss-lb:0.1161, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:18:36.709] iteration:7725  t-loss:0.1492, loss-lb:0.0915, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:18:36.902] iteration:7726  t-loss:0.1532, loss-lb:0.1015, loss-ulb:0.0258, weight:2.00, lr:0.0008
[11:18:37.094] iteration:7727  t-loss:0.1567, loss-lb:0.1042, loss-ulb:0.0262, weight:2.00, lr:0.0008
[11:18:37.286] iteration:7728  t-loss:0.1427, loss-lb:0.0966, loss-ulb:0.0231, weight:2.00, lr:0.0008
[11:18:37.478] iteration:7729  t-loss:0.1472, loss-lb:0.0873, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:18:37.670] iteration:7730  t-loss:0.1393, loss-lb:0.0926, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:18:37.862] iteration:7731  t-loss:0.1459, loss-lb:0.0956, loss-ulb:0.0252, weight:2.00, lr:0.0008
[11:18:38.056] iteration:7732  t-loss:0.1578, loss-lb:0.0854, loss-ulb:0.0362, weight:2.00, lr:0.0008
[11:18:38.248] iteration:7733  t-loss:0.1507, loss-lb:0.0924, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:18:38.441] iteration:7734  t-loss:0.1479, loss-lb:0.0859, loss-ulb:0.0310, weight:2.00, lr:0.0008
[11:18:38.634] iteration:7735  t-loss:0.1794, loss-lb:0.1173, loss-ulb:0.0310, weight:2.00, lr:0.0008
[11:18:38.825] iteration:7736  t-loss:0.1476, loss-lb:0.0964, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:18:39.015] iteration:7737  t-loss:0.1399, loss-lb:0.0948, loss-ulb:0.0225, weight:2.00, lr:0.0008
[11:18:39.206] iteration:7738  t-loss:0.1420, loss-lb:0.0918, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:18:39.396] iteration:7739  t-loss:0.1402, loss-lb:0.0869, loss-ulb:0.0266, weight:2.00, lr:0.0008
[11:18:39.588] iteration:7740  t-loss:0.2421, loss-lb:0.1078, loss-ulb:0.0672, weight:2.00, lr:0.0008
[11:18:39.778] iteration:7741  t-loss:0.1536, loss-lb:0.0964, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:18:39.968] iteration:7742  t-loss:0.1554, loss-lb:0.0894, loss-ulb:0.0330, weight:2.00, lr:0.0008
[11:18:52.217]  <<Test>> - Ep:78  - mean_dice/mean_h95 - S:90.18/1.51, Best-S:90.18, T:90.48/1.39, Best-T:90.48
[11:18:52.217]           - AvgLoss(lb/ulb/all):0.0951/0.0310/0.1582
[11:18:52.757] iteration:7743  t-loss:0.1442, loss-lb:0.0938, loss-ulb:0.0252, weight:2.00, lr:0.0008
[11:18:52.956] iteration:7744  t-loss:0.1530, loss-lb:0.0974, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:18:53.148] iteration:7745  t-loss:0.1320, loss-lb:0.0820, loss-ulb:0.0250, weight:2.00, lr:0.0008
[11:18:53.341] iteration:7746  t-loss:0.1924, loss-lb:0.0918, loss-ulb:0.0503, weight:2.00, lr:0.0008
[11:18:53.533] iteration:7747  t-loss:0.2022, loss-lb:0.1109, loss-ulb:0.0456, weight:2.00, lr:0.0008
[11:18:53.727] iteration:7748  t-loss:0.1555, loss-lb:0.0917, loss-ulb:0.0319, weight:2.00, lr:0.0008
[11:18:53.919] iteration:7749  t-loss:0.1585, loss-lb:0.1033, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:18:54.113] iteration:7750  t-loss:0.1573, loss-lb:0.0981, loss-ulb:0.0296, weight:2.00, lr:0.0008
[11:18:54.306] iteration:7751  t-loss:0.1345, loss-lb:0.0871, loss-ulb:0.0237, weight:2.00, lr:0.0008
[11:18:54.499] iteration:7752  t-loss:0.1923, loss-lb:0.0912, loss-ulb:0.0505, weight:2.00, lr:0.0008
[11:18:54.692] iteration:7753  t-loss:0.1393, loss-lb:0.0889, loss-ulb:0.0252, weight:2.00, lr:0.0008
[11:18:54.886] iteration:7754  t-loss:0.1443, loss-lb:0.0886, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:18:55.079] iteration:7755  t-loss:0.2403, loss-lb:0.1777, loss-ulb:0.0313, weight:2.00, lr:0.0008
[11:18:55.272] iteration:7756  t-loss:0.1862, loss-lb:0.0993, loss-ulb:0.0435, weight:2.00, lr:0.0008
[11:18:55.464] iteration:7757  t-loss:0.1621, loss-lb:0.0900, loss-ulb:0.0360, weight:2.00, lr:0.0008
[11:18:55.656] iteration:7758  t-loss:0.1425, loss-lb:0.0940, loss-ulb:0.0242, weight:2.00, lr:0.0008
[11:18:55.851] iteration:7759  t-loss:0.1542, loss-lb:0.1040, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:18:56.044] iteration:7760  t-loss:0.1471, loss-lb:0.0928, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:18:56.239] iteration:7761  t-loss:0.1660, loss-lb:0.1062, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:18:56.431] iteration:7762  t-loss:0.1402, loss-lb:0.0928, loss-ulb:0.0237, weight:2.00, lr:0.0008
[11:18:56.624] iteration:7763  t-loss:0.1824, loss-lb:0.0940, loss-ulb:0.0442, weight:2.00, lr:0.0008
[11:18:56.818] iteration:7764  t-loss:0.1447, loss-lb:0.0928, loss-ulb:0.0260, weight:2.00, lr:0.0008
[11:18:57.010] iteration:7765  t-loss:0.1384, loss-lb:0.0896, loss-ulb:0.0244, weight:2.00, lr:0.0008
[11:18:57.203] iteration:7766  t-loss:0.1564, loss-lb:0.0971, loss-ulb:0.0297, weight:2.00, lr:0.0008
[11:18:57.395] iteration:7767  t-loss:0.1561, loss-lb:0.1025, loss-ulb:0.0268, weight:2.00, lr:0.0008
[11:18:57.587] iteration:7768  t-loss:0.1664, loss-lb:0.1070, loss-ulb:0.0297, weight:2.00, lr:0.0008
[11:18:57.780] iteration:7769  t-loss:0.3613, loss-lb:0.1004, loss-ulb:0.1304, weight:2.00, lr:0.0008
[11:18:57.973] iteration:7770  t-loss:0.1831, loss-lb:0.0901, loss-ulb:0.0465, weight:2.00, lr:0.0008
[11:18:58.168] iteration:7771  t-loss:0.1397, loss-lb:0.0925, loss-ulb:0.0236, weight:2.00, lr:0.0008
[11:18:58.361] iteration:7772  t-loss:0.1429, loss-lb:0.0924, loss-ulb:0.0252, weight:2.00, lr:0.0008
[11:18:58.568] iteration:7773  t-loss:0.1932, loss-lb:0.0940, loss-ulb:0.0496, weight:2.00, lr:0.0008
[11:18:58.768] iteration:7774  t-loss:0.1686, loss-lb:0.0992, loss-ulb:0.0347, weight:2.00, lr:0.0008
[11:18:58.961] iteration:7775  t-loss:0.1797, loss-lb:0.0935, loss-ulb:0.0431, weight:2.00, lr:0.0008
[11:18:59.156] iteration:7776  t-loss:0.1640, loss-lb:0.0974, loss-ulb:0.0333, weight:2.00, lr:0.0008
[11:18:59.349] iteration:7777  t-loss:0.1574, loss-lb:0.0884, loss-ulb:0.0345, weight:2.00, lr:0.0008
[11:18:59.542] iteration:7778  t-loss:0.1645, loss-lb:0.0997, loss-ulb:0.0324, weight:2.00, lr:0.0008
[11:18:59.735] iteration:7779  t-loss:0.1879, loss-lb:0.1018, loss-ulb:0.0431, weight:2.00, lr:0.0008
[11:18:59.928] iteration:7780  t-loss:0.1582, loss-lb:0.0911, loss-ulb:0.0335, weight:2.00, lr:0.0008
[11:19:00.121] iteration:7781  t-loss:0.2362, loss-lb:0.0945, loss-ulb:0.0708, weight:2.00, lr:0.0008
[11:19:00.313] iteration:7782  t-loss:0.1484, loss-lb:0.0894, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:19:00.506] iteration:7783  t-loss:0.2180, loss-lb:0.0883, loss-ulb:0.0648, weight:2.00, lr:0.0008
[11:19:00.698] iteration:7784  t-loss:0.1668, loss-lb:0.1052, loss-ulb:0.0308, weight:2.00, lr:0.0008
[11:19:00.890] iteration:7785  t-loss:0.1667, loss-lb:0.1086, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:19:01.083] iteration:7786  t-loss:0.1528, loss-lb:0.1009, loss-ulb:0.0260, weight:2.00, lr:0.0008
[11:19:01.275] iteration:7787  t-loss:0.1716, loss-lb:0.0924, loss-ulb:0.0396, weight:2.00, lr:0.0008
[11:19:01.468] iteration:7788  t-loss:0.1653, loss-lb:0.1012, loss-ulb:0.0321, weight:2.00, lr:0.0008
[11:19:01.660] iteration:7789  t-loss:0.1481, loss-lb:0.0891, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:19:01.851] iteration:7790  t-loss:0.2026, loss-lb:0.0979, loss-ulb:0.0523, weight:2.00, lr:0.0008
[11:19:02.043] iteration:7791  t-loss:0.1649, loss-lb:0.0993, loss-ulb:0.0328, weight:2.00, lr:0.0008
[11:19:02.235] iteration:7792  t-loss:0.1514, loss-lb:0.0933, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:19:02.428] iteration:7793  t-loss:0.1831, loss-lb:0.1021, loss-ulb:0.0405, weight:2.00, lr:0.0008
[11:19:02.622] iteration:7794  t-loss:0.2131, loss-lb:0.0971, loss-ulb:0.0580, weight:2.00, lr:0.0008
[11:19:02.814] iteration:7795  t-loss:0.1533, loss-lb:0.1019, loss-ulb:0.0257, weight:2.00, lr:0.0008
[11:19:03.006] iteration:7796  t-loss:0.1504, loss-lb:0.1012, loss-ulb:0.0246, weight:2.00, lr:0.0008
[11:19:03.199] iteration:7797  t-loss:0.1438, loss-lb:0.0806, loss-ulb:0.0316, weight:2.00, lr:0.0008
[11:19:03.392] iteration:7798  t-loss:0.1783, loss-lb:0.0983, loss-ulb:0.0400, weight:2.00, lr:0.0008
[11:19:03.585] iteration:7799  t-loss:0.1507, loss-lb:0.0888, loss-ulb:0.0310, weight:2.00, lr:0.0008
[11:19:03.778] iteration:7800  t-loss:0.1485, loss-lb:0.0881, loss-ulb:0.0302, weight:2.00, lr:0.0008
[11:19:03.970] iteration:7801  t-loss:0.1611, loss-lb:0.1143, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:19:04.162] iteration:7802  t-loss:0.1637, loss-lb:0.1063, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:19:04.354] iteration:7803  t-loss:0.1550, loss-lb:0.0886, loss-ulb:0.0332, weight:2.00, lr:0.0008
[11:19:04.547] iteration:7804  t-loss:0.1410, loss-lb:0.0896, loss-ulb:0.0257, weight:2.00, lr:0.0008
[11:19:04.740] iteration:7805  t-loss:0.1415, loss-lb:0.0929, loss-ulb:0.0243, weight:2.00, lr:0.0008
[11:19:04.932] iteration:7806  t-loss:0.1308, loss-lb:0.0865, loss-ulb:0.0221, weight:2.00, lr:0.0008
[11:19:05.124] iteration:7807  t-loss:0.1884, loss-lb:0.0943, loss-ulb:0.0470, weight:2.00, lr:0.0008
[11:19:05.317] iteration:7808  t-loss:0.1595, loss-lb:0.0888, loss-ulb:0.0353, weight:2.00, lr:0.0008
[11:19:05.508] iteration:7809  t-loss:0.1475, loss-lb:0.1019, loss-ulb:0.0228, weight:2.00, lr:0.0008
[11:19:05.701] iteration:7810  t-loss:0.1505, loss-lb:0.0912, loss-ulb:0.0296, weight:2.00, lr:0.0008
[11:19:05.896] iteration:7811  t-loss:0.1920, loss-lb:0.0920, loss-ulb:0.0500, weight:2.00, lr:0.0008
[11:19:06.092] iteration:7812  t-loss:0.1401, loss-lb:0.0877, loss-ulb:0.0262, weight:2.00, lr:0.0008
[11:19:06.285] iteration:7813  t-loss:0.1411, loss-lb:0.0982, loss-ulb:0.0215, weight:2.00, lr:0.0008
[11:19:06.477] iteration:7814  t-loss:0.1452, loss-lb:0.0940, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:19:06.669] iteration:7815  t-loss:0.1418, loss-lb:0.0939, loss-ulb:0.0239, weight:2.00, lr:0.0008
[11:19:06.861] iteration:7816  t-loss:0.1513, loss-lb:0.0908, loss-ulb:0.0302, weight:2.00, lr:0.0008
[11:19:07.050] iteration:7817  t-loss:0.1482, loss-lb:0.0942, loss-ulb:0.0270, weight:2.00, lr:0.0008
[11:19:07.242] iteration:7818  t-loss:0.2064, loss-lb:0.1180, loss-ulb:0.0442, weight:2.00, lr:0.0008
[11:19:07.435] iteration:7819  t-loss:0.1994, loss-lb:0.1346, loss-ulb:0.0324, weight:2.00, lr:0.0008
[11:19:07.627] iteration:7820  t-loss:0.1338, loss-lb:0.0858, loss-ulb:0.0240, weight:2.00, lr:0.0008
[11:19:07.818] iteration:7821  t-loss:0.1526, loss-lb:0.1032, loss-ulb:0.0247, weight:2.00, lr:0.0008
[11:19:08.011] iteration:7822  t-loss:0.1470, loss-lb:0.0960, loss-ulb:0.0255, weight:2.00, lr:0.0008
[11:19:08.210] iteration:7823  t-loss:0.1508, loss-lb:0.0959, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:19:08.403] iteration:7824  t-loss:0.1653, loss-lb:0.1002, loss-ulb:0.0325, weight:2.00, lr:0.0008
[11:19:08.593] iteration:7825  t-loss:0.1543, loss-lb:0.0955, loss-ulb:0.0294, weight:2.00, lr:0.0008
[11:19:08.785] iteration:7826  t-loss:0.1696, loss-lb:0.0905, loss-ulb:0.0395, weight:2.00, lr:0.0008
[11:19:08.985] iteration:7827  t-loss:0.1652, loss-lb:0.0966, loss-ulb:0.0343, weight:2.00, lr:0.0008
[11:19:09.177] iteration:7828  t-loss:0.1770, loss-lb:0.0820, loss-ulb:0.0475, weight:2.00, lr:0.0008
[11:19:09.370] iteration:7829  t-loss:0.1572, loss-lb:0.0981, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:19:09.562] iteration:7830  t-loss:0.1504, loss-lb:0.1038, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:19:09.760] iteration:7831  t-loss:0.1537, loss-lb:0.1051, loss-ulb:0.0243, weight:2.00, lr:0.0008
[11:19:09.952] iteration:7832  t-loss:0.1527, loss-lb:0.0901, loss-ulb:0.0313, weight:2.00, lr:0.0008
[11:19:10.143] iteration:7833  t-loss:0.1541, loss-lb:0.1071, loss-ulb:0.0235, weight:2.00, lr:0.0008
[11:19:10.333] iteration:7834  t-loss:0.1493, loss-lb:0.0959, loss-ulb:0.0267, weight:2.00, lr:0.0008
[11:19:10.524] iteration:7835  t-loss:0.1443, loss-lb:0.0881, loss-ulb:0.0281, weight:2.00, lr:0.0008
[11:19:10.714] iteration:7836  t-loss:0.1640, loss-lb:0.0926, loss-ulb:0.0357, weight:2.00, lr:0.0008
[11:19:10.906] iteration:7837  t-loss:0.1387, loss-lb:0.0913, loss-ulb:0.0237, weight:2.00, lr:0.0008
[11:19:11.096] iteration:7838  t-loss:0.1593, loss-lb:0.0932, loss-ulb:0.0331, weight:2.00, lr:0.0008
[11:19:11.287] iteration:7839  t-loss:0.1496, loss-lb:0.0919, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:19:11.478] iteration:7840  t-loss:0.1489, loss-lb:0.0981, loss-ulb:0.0254, weight:2.00, lr:0.0008
[11:19:12.068] iteration:7841  t-loss:0.1596, loss-lb:0.0941, loss-ulb:0.0328, weight:2.00, lr:0.0008
[11:19:12.262] iteration:7842  t-loss:0.1450, loss-lb:0.0901, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:19:12.454] iteration:7843  t-loss:0.1373, loss-lb:0.0929, loss-ulb:0.0222, weight:2.00, lr:0.0008
[11:19:12.646] iteration:7844  t-loss:0.1588, loss-lb:0.1022, loss-ulb:0.0283, weight:2.00, lr:0.0008
[11:19:12.838] iteration:7845  t-loss:0.1404, loss-lb:0.0856, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:19:13.030] iteration:7846  t-loss:0.1381, loss-lb:0.0973, loss-ulb:0.0204, weight:2.00, lr:0.0008
[11:19:13.221] iteration:7847  t-loss:0.1614, loss-lb:0.0951, loss-ulb:0.0331, weight:2.00, lr:0.0008
[11:19:13.413] iteration:7848  t-loss:0.1657, loss-lb:0.0946, loss-ulb:0.0356, weight:2.00, lr:0.0008
[11:19:13.605] iteration:7849  t-loss:0.1549, loss-lb:0.0995, loss-ulb:0.0277, weight:2.00, lr:0.0008
[11:19:13.796] iteration:7850  t-loss:0.1389, loss-lb:0.0910, loss-ulb:0.0240, weight:2.00, lr:0.0008
[11:19:13.988] iteration:7851  t-loss:0.1500, loss-lb:0.0954, loss-ulb:0.0273, weight:2.00, lr:0.0008
[11:19:14.180] iteration:7852  t-loss:0.1475, loss-lb:0.0929, loss-ulb:0.0273, weight:2.00, lr:0.0008
[11:19:14.371] iteration:7853  t-loss:0.1414, loss-lb:0.0851, loss-ulb:0.0281, weight:2.00, lr:0.0008
[11:19:14.563] iteration:7854  t-loss:0.1532, loss-lb:0.0942, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:19:14.755] iteration:7855  t-loss:0.1434, loss-lb:0.0881, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:19:14.947] iteration:7856  t-loss:0.1577, loss-lb:0.1061, loss-ulb:0.0258, weight:2.00, lr:0.0008
[11:19:15.138] iteration:7857  t-loss:0.1601, loss-lb:0.1041, loss-ulb:0.0280, weight:2.00, lr:0.0008
[11:19:15.330] iteration:7858  t-loss:0.1585, loss-lb:0.1020, loss-ulb:0.0282, weight:2.00, lr:0.0008
[11:19:15.522] iteration:7859  t-loss:0.2539, loss-lb:0.0993, loss-ulb:0.0773, weight:2.00, lr:0.0008
[11:19:15.713] iteration:7860  t-loss:0.1569, loss-lb:0.0886, loss-ulb:0.0341, weight:2.00, lr:0.0008
[11:19:15.904] iteration:7861  t-loss:0.1558, loss-lb:0.0894, loss-ulb:0.0332, weight:2.00, lr:0.0008
[11:19:16.096] iteration:7862  t-loss:0.1523, loss-lb:0.0925, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:19:16.287] iteration:7863  t-loss:0.1301, loss-lb:0.0829, loss-ulb:0.0236, weight:2.00, lr:0.0008
[11:19:16.481] iteration:7864  t-loss:0.1584, loss-lb:0.0957, loss-ulb:0.0313, weight:2.00, lr:0.0008
[11:19:16.674] iteration:7865  t-loss:0.1612, loss-lb:0.0930, loss-ulb:0.0341, weight:2.00, lr:0.0008
[11:19:16.872] iteration:7866  t-loss:0.1552, loss-lb:0.0887, loss-ulb:0.0333, weight:2.00, lr:0.0008
[11:19:17.066] iteration:7867  t-loss:0.1438, loss-lb:0.0895, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:19:17.259] iteration:7868  t-loss:0.1553, loss-lb:0.0888, loss-ulb:0.0332, weight:2.00, lr:0.0008
[11:19:17.452] iteration:7869  t-loss:0.1712, loss-lb:0.0973, loss-ulb:0.0369, weight:2.00, lr:0.0008
[11:19:17.644] iteration:7870  t-loss:0.1562, loss-lb:0.0963, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:19:17.836] iteration:7871  t-loss:0.2200, loss-lb:0.0923, loss-ulb:0.0639, weight:2.00, lr:0.0008
[11:19:18.030] iteration:7872  t-loss:0.1909, loss-lb:0.0943, loss-ulb:0.0483, weight:2.00, lr:0.0008
[11:19:18.223] iteration:7873  t-loss:0.1477, loss-lb:0.0942, loss-ulb:0.0268, weight:2.00, lr:0.0008
[11:19:18.415] iteration:7874  t-loss:0.1495, loss-lb:0.0917, loss-ulb:0.0289, weight:2.00, lr:0.0008
[11:19:18.608] iteration:7875  t-loss:0.1442, loss-lb:0.0892, loss-ulb:0.0275, weight:2.00, lr:0.0008
[11:19:18.804] iteration:7876  t-loss:0.1898, loss-lb:0.0944, loss-ulb:0.0477, weight:2.00, lr:0.0008
[11:19:18.996] iteration:7877  t-loss:0.1598, loss-lb:0.0948, loss-ulb:0.0325, weight:2.00, lr:0.0008
[11:19:19.189] iteration:7878  t-loss:0.1782, loss-lb:0.0933, loss-ulb:0.0425, weight:2.00, lr:0.0008
[11:19:19.380] iteration:7879  t-loss:0.1522, loss-lb:0.0920, loss-ulb:0.0301, weight:2.00, lr:0.0008
[11:19:19.573] iteration:7880  t-loss:0.2197, loss-lb:0.0972, loss-ulb:0.0612, weight:2.00, lr:0.0008
[11:19:19.766] iteration:7881  t-loss:0.1431, loss-lb:0.0923, loss-ulb:0.0254, weight:2.00, lr:0.0008
[11:19:19.958] iteration:7882  t-loss:0.1632, loss-lb:0.0954, loss-ulb:0.0339, weight:2.00, lr:0.0008
[11:19:20.149] iteration:7883  t-loss:0.1518, loss-lb:0.1042, loss-ulb:0.0238, weight:2.00, lr:0.0008
[11:19:20.341] iteration:7884  t-loss:0.1508, loss-lb:0.0956, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:19:20.533] iteration:7885  t-loss:0.1560, loss-lb:0.0920, loss-ulb:0.0320, weight:2.00, lr:0.0008
[11:19:20.725] iteration:7886  t-loss:0.1410, loss-lb:0.0874, loss-ulb:0.0268, weight:2.00, lr:0.0008
[11:19:20.917] iteration:7887  t-loss:0.1421, loss-lb:0.1015, loss-ulb:0.0203, weight:2.00, lr:0.0008
[11:19:21.109] iteration:7888  t-loss:0.1925, loss-lb:0.0835, loss-ulb:0.0545, weight:2.00, lr:0.0008
[11:19:21.300] iteration:7889  t-loss:0.1588, loss-lb:0.1119, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:19:21.493] iteration:7890  t-loss:0.1492, loss-lb:0.0946, loss-ulb:0.0273, weight:2.00, lr:0.0008
[11:19:21.685] iteration:7891  t-loss:0.3077, loss-lb:0.0937, loss-ulb:0.1070, weight:2.00, lr:0.0008
[11:19:21.877] iteration:7892  t-loss:0.2222, loss-lb:0.0950, loss-ulb:0.0636, weight:2.00, lr:0.0008
[11:19:22.070] iteration:7893  t-loss:0.2769, loss-lb:0.1170, loss-ulb:0.0799, weight:2.00, lr:0.0008
[11:19:22.262] iteration:7894  t-loss:0.1441, loss-lb:0.0858, loss-ulb:0.0292, weight:2.00, lr:0.0008
[11:19:22.453] iteration:7895  t-loss:0.1420, loss-lb:0.0940, loss-ulb:0.0240, weight:2.00, lr:0.0008
[11:19:22.646] iteration:7896  t-loss:0.1544, loss-lb:0.0983, loss-ulb:0.0280, weight:2.00, lr:0.0008
[11:19:22.837] iteration:7897  t-loss:0.1479, loss-lb:0.0907, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:19:23.030] iteration:7898  t-loss:0.1640, loss-lb:0.1038, loss-ulb:0.0301, weight:2.00, lr:0.0008
[11:19:23.222] iteration:7899  t-loss:0.1730, loss-lb:0.0938, loss-ulb:0.0396, weight:2.00, lr:0.0008
[11:19:23.415] iteration:7900  t-loss:0.1571, loss-lb:0.0872, loss-ulb:0.0350, weight:2.00, lr:0.0008
[11:19:23.607] iteration:7901  t-loss:0.1533, loss-lb:0.0880, loss-ulb:0.0326, weight:2.00, lr:0.0008
[11:19:23.798] iteration:7902  t-loss:0.1931, loss-lb:0.0974, loss-ulb:0.0478, weight:2.00, lr:0.0008
[11:19:23.989] iteration:7903  t-loss:0.1574, loss-lb:0.0998, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:19:24.181] iteration:7904  t-loss:0.1380, loss-lb:0.0917, loss-ulb:0.0231, weight:2.00, lr:0.0008
[11:19:24.374] iteration:7905  t-loss:0.1414, loss-lb:0.0891, loss-ulb:0.0261, weight:2.00, lr:0.0008
[11:19:24.565] iteration:7906  t-loss:0.1474, loss-lb:0.0878, loss-ulb:0.0298, weight:2.00, lr:0.0008
[11:19:24.757] iteration:7907  t-loss:0.1662, loss-lb:0.1159, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:19:24.947] iteration:7908  t-loss:0.1964, loss-lb:0.1159, loss-ulb:0.0403, weight:2.00, lr:0.0008
[11:19:25.138] iteration:7909  t-loss:0.1493, loss-lb:0.0942, loss-ulb:0.0275, weight:2.00, lr:0.0008
[11:19:25.330] iteration:7910  t-loss:0.1525, loss-lb:0.0927, loss-ulb:0.0299, weight:2.00, lr:0.0008
[11:19:25.521] iteration:7911  t-loss:0.1451, loss-lb:0.0979, loss-ulb:0.0236, weight:2.00, lr:0.0008
[11:19:25.713] iteration:7912  t-loss:0.1529, loss-lb:0.0964, loss-ulb:0.0283, weight:2.00, lr:0.0008
[11:19:25.903] iteration:7913  t-loss:0.1398, loss-lb:0.0891, loss-ulb:0.0254, weight:2.00, lr:0.0008
[11:19:26.096] iteration:7914  t-loss:0.1513, loss-lb:0.0965, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:19:26.286] iteration:7915  t-loss:0.1516, loss-lb:0.0959, loss-ulb:0.0279, weight:2.00, lr:0.0008
[11:19:26.479] iteration:7916  t-loss:0.1528, loss-lb:0.0917, loss-ulb:0.0306, weight:2.00, lr:0.0008
[11:19:26.671] iteration:7917  t-loss:0.1635, loss-lb:0.0991, loss-ulb:0.0322, weight:2.00, lr:0.0008
[11:19:26.862] iteration:7918  t-loss:0.1526, loss-lb:0.0989, loss-ulb:0.0268, weight:2.00, lr:0.0008
[11:19:27.054] iteration:7919  t-loss:0.1731, loss-lb:0.0944, loss-ulb:0.0393, weight:2.00, lr:0.0008
[11:19:27.247] iteration:7920  t-loss:0.1730, loss-lb:0.0984, loss-ulb:0.0373, weight:2.00, lr:0.0008
[11:19:27.439] iteration:7921  t-loss:0.1864, loss-lb:0.0914, loss-ulb:0.0475, weight:2.00, lr:0.0008
[11:19:27.634] iteration:7922  t-loss:0.1525, loss-lb:0.0912, loss-ulb:0.0306, weight:2.00, lr:0.0008
[11:19:27.829] iteration:7923  t-loss:0.2124, loss-lb:0.1017, loss-ulb:0.0554, weight:2.00, lr:0.0008
[11:19:28.022] iteration:7924  t-loss:0.1422, loss-lb:0.0899, loss-ulb:0.0261, weight:2.00, lr:0.0008
[11:19:28.215] iteration:7925  t-loss:0.1416, loss-lb:0.0873, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:19:28.406] iteration:7926  t-loss:0.1554, loss-lb:0.0952, loss-ulb:0.0301, weight:2.00, lr:0.0008
[11:19:28.598] iteration:7927  t-loss:0.1483, loss-lb:0.0876, loss-ulb:0.0304, weight:2.00, lr:0.0008
[11:19:28.790] iteration:7928  t-loss:0.1486, loss-lb:0.0902, loss-ulb:0.0292, weight:2.00, lr:0.0008
[11:19:28.982] iteration:7929  t-loss:0.1757, loss-lb:0.1221, loss-ulb:0.0268, weight:2.00, lr:0.0008
[11:19:29.174] iteration:7930  t-loss:0.1877, loss-lb:0.0899, loss-ulb:0.0489, weight:2.00, lr:0.0008
[11:19:29.367] iteration:7931  t-loss:0.1542, loss-lb:0.0967, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:19:29.557] iteration:7932  t-loss:0.2078, loss-lb:0.1056, loss-ulb:0.0511, weight:2.00, lr:0.0008
[11:19:29.748] iteration:7933  t-loss:0.1522, loss-lb:0.0981, loss-ulb:0.0271, weight:2.00, lr:0.0008
[11:19:29.939] iteration:7934  t-loss:0.1545, loss-lb:0.0935, loss-ulb:0.0305, weight:2.00, lr:0.0008
[11:19:30.130] iteration:7935  t-loss:0.1433, loss-lb:0.0895, loss-ulb:0.0269, weight:2.00, lr:0.0008
[11:19:30.321] iteration:7936  t-loss:0.1732, loss-lb:0.0965, loss-ulb:0.0383, weight:2.00, lr:0.0008
[11:19:30.512] iteration:7937  t-loss:0.1471, loss-lb:0.0917, loss-ulb:0.0277, weight:2.00, lr:0.0008
[11:19:30.702] iteration:7938  t-loss:0.1459, loss-lb:0.0887, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:19:42.062]  <<Test>> - Ep:80  - mean_dice/mean_h95 - S:90.28/2.44, Best-S:90.28, T:90.26/1.35, Best-T:90.48
[11:19:42.062]           - AvgLoss(lb/ulb/all):0.0949/0.0344/0.1638
[11:19:42.605] iteration:7939  t-loss:0.2428, loss-lb:0.0978, loss-ulb:0.0725, weight:2.00, lr:0.0008
[11:19:42.805] iteration:7940  t-loss:0.1623, loss-lb:0.1042, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:19:42.998] iteration:7941  t-loss:0.1849, loss-lb:0.0939, loss-ulb:0.0455, weight:2.00, lr:0.0008
[11:19:43.192] iteration:7942  t-loss:0.1909, loss-lb:0.1450, loss-ulb:0.0229, weight:2.00, lr:0.0008
[11:19:43.384] iteration:7943  t-loss:0.1413, loss-lb:0.0881, loss-ulb:0.0266, weight:2.00, lr:0.0008
[11:19:43.576] iteration:7944  t-loss:0.1922, loss-lb:0.0967, loss-ulb:0.0477, weight:2.00, lr:0.0008
[11:19:43.770] iteration:7945  t-loss:0.1259, loss-lb:0.0874, loss-ulb:0.0192, weight:2.00, lr:0.0008
[11:19:43.962] iteration:7946  t-loss:0.1793, loss-lb:0.0986, loss-ulb:0.0403, weight:2.00, lr:0.0008
[11:19:44.155] iteration:7947  t-loss:0.1582, loss-lb:0.0989, loss-ulb:0.0296, weight:2.00, lr:0.0008
[11:19:44.347] iteration:7948  t-loss:0.1441, loss-lb:0.0939, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:19:44.538] iteration:7949  t-loss:0.1670, loss-lb:0.0895, loss-ulb:0.0388, weight:2.00, lr:0.0008
[11:19:44.731] iteration:7950  t-loss:0.1624, loss-lb:0.1058, loss-ulb:0.0283, weight:2.00, lr:0.0008
[11:19:44.924] iteration:7951  t-loss:0.1447, loss-lb:0.0914, loss-ulb:0.0266, weight:2.00, lr:0.0008
[11:19:45.117] iteration:7952  t-loss:0.1537, loss-lb:0.0969, loss-ulb:0.0284, weight:2.00, lr:0.0008
[11:19:45.309] iteration:7953  t-loss:0.1559, loss-lb:0.1008, loss-ulb:0.0275, weight:2.00, lr:0.0008
[11:19:45.501] iteration:7954  t-loss:0.1811, loss-lb:0.0907, loss-ulb:0.0452, weight:2.00, lr:0.0008
[11:19:45.694] iteration:7955  t-loss:0.1745, loss-lb:0.1078, loss-ulb:0.0334, weight:2.00, lr:0.0008
[11:19:45.886] iteration:7956  t-loss:0.1504, loss-lb:0.0978, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:19:46.077] iteration:7957  t-loss:0.1689, loss-lb:0.1207, loss-ulb:0.0241, weight:2.00, lr:0.0008
[11:19:46.270] iteration:7958  t-loss:0.2021, loss-lb:0.0992, loss-ulb:0.0515, weight:2.00, lr:0.0008
[11:19:46.461] iteration:7959  t-loss:0.1531, loss-lb:0.0923, loss-ulb:0.0304, weight:2.00, lr:0.0008
[11:19:46.652] iteration:7960  t-loss:0.1436, loss-lb:0.0950, loss-ulb:0.0243, weight:2.00, lr:0.0008
[11:19:46.843] iteration:7961  t-loss:0.1632, loss-lb:0.1073, loss-ulb:0.0279, weight:2.00, lr:0.0008
[11:19:47.034] iteration:7962  t-loss:0.2655, loss-lb:0.0839, loss-ulb:0.0908, weight:2.00, lr:0.0008
[11:19:47.225] iteration:7963  t-loss:0.1507, loss-lb:0.1019, loss-ulb:0.0244, weight:2.00, lr:0.0008
[11:19:47.416] iteration:7964  t-loss:0.1532, loss-lb:0.0998, loss-ulb:0.0267, weight:2.00, lr:0.0008
[11:19:47.608] iteration:7965  t-loss:0.2137, loss-lb:0.0935, loss-ulb:0.0601, weight:2.00, lr:0.0008
[11:19:47.799] iteration:7966  t-loss:0.1466, loss-lb:0.0944, loss-ulb:0.0261, weight:2.00, lr:0.0008
[11:19:47.990] iteration:7967  t-loss:0.1804, loss-lb:0.0996, loss-ulb:0.0404, weight:2.00, lr:0.0008
[11:19:48.181] iteration:7968  t-loss:0.1469, loss-lb:0.0959, loss-ulb:0.0255, weight:2.00, lr:0.0008
[11:19:48.371] iteration:7969  t-loss:0.1455, loss-lb:0.1023, loss-ulb:0.0216, weight:2.00, lr:0.0008
[11:19:48.564] iteration:7970  t-loss:0.1570, loss-lb:0.1028, loss-ulb:0.0271, weight:2.00, lr:0.0008
[11:19:48.755] iteration:7971  t-loss:0.1520, loss-lb:0.0842, loss-ulb:0.0339, weight:2.00, lr:0.0008
[11:19:48.946] iteration:7972  t-loss:0.1387, loss-lb:0.0865, loss-ulb:0.0261, weight:2.00, lr:0.0008
[11:19:49.139] iteration:7973  t-loss:0.1639, loss-lb:0.0940, loss-ulb:0.0349, weight:2.00, lr:0.0008
[11:19:49.332] iteration:7974  t-loss:0.1423, loss-lb:0.0916, loss-ulb:0.0254, weight:2.00, lr:0.0008
[11:19:49.523] iteration:7975  t-loss:0.1481, loss-lb:0.0924, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:19:49.716] iteration:7976  t-loss:0.2081, loss-lb:0.1049, loss-ulb:0.0516, weight:2.00, lr:0.0008
[11:19:49.909] iteration:7977  t-loss:0.1504, loss-lb:0.1030, loss-ulb:0.0237, weight:2.00, lr:0.0008
[11:19:50.101] iteration:7978  t-loss:0.1446, loss-lb:0.0917, loss-ulb:0.0264, weight:2.00, lr:0.0008
[11:19:50.293] iteration:7979  t-loss:0.1446, loss-lb:0.0924, loss-ulb:0.0261, weight:2.00, lr:0.0008
[11:19:50.486] iteration:7980  t-loss:0.1461, loss-lb:0.1024, loss-ulb:0.0218, weight:2.00, lr:0.0008
[11:19:50.677] iteration:7981  t-loss:0.1556, loss-lb:0.0870, loss-ulb:0.0343, weight:2.00, lr:0.0008
[11:19:50.871] iteration:7982  t-loss:0.1557, loss-lb:0.0934, loss-ulb:0.0312, weight:2.00, lr:0.0008
[11:19:51.063] iteration:7983  t-loss:0.1608, loss-lb:0.0851, loss-ulb:0.0379, weight:2.00, lr:0.0008
[11:19:51.255] iteration:7984  t-loss:0.1579, loss-lb:0.1078, loss-ulb:0.0250, weight:2.00, lr:0.0008
[11:19:51.448] iteration:7985  t-loss:0.1435, loss-lb:0.0944, loss-ulb:0.0245, weight:2.00, lr:0.0008
[11:19:51.641] iteration:7986  t-loss:0.1446, loss-lb:0.0895, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:19:51.834] iteration:7987  t-loss:0.1576, loss-lb:0.1011, loss-ulb:0.0283, weight:2.00, lr:0.0008
[11:19:52.026] iteration:7988  t-loss:0.1435, loss-lb:0.0878, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:19:52.218] iteration:7989  t-loss:0.1557, loss-lb:0.0896, loss-ulb:0.0331, weight:2.00, lr:0.0008
[11:19:52.411] iteration:7990  t-loss:0.2934, loss-lb:0.0946, loss-ulb:0.0994, weight:2.00, lr:0.0008
[11:19:52.603] iteration:7991  t-loss:0.1543, loss-lb:0.0895, loss-ulb:0.0324, weight:2.00, lr:0.0008
[11:19:52.795] iteration:7992  t-loss:0.1495, loss-lb:0.0879, loss-ulb:0.0308, weight:2.00, lr:0.0008
[11:19:52.989] iteration:7993  t-loss:0.1312, loss-lb:0.0864, loss-ulb:0.0224, weight:2.00, lr:0.0008
[11:19:53.181] iteration:7994  t-loss:0.1663, loss-lb:0.1073, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:19:53.374] iteration:7995  t-loss:0.1635, loss-lb:0.0957, loss-ulb:0.0339, weight:2.00, lr:0.0008
[11:19:53.567] iteration:7996  t-loss:0.1715, loss-lb:0.0898, loss-ulb:0.0409, weight:2.00, lr:0.0008
[11:19:53.759] iteration:7997  t-loss:0.1458, loss-lb:0.0877, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:19:53.953] iteration:7998  t-loss:0.2215, loss-lb:0.1579, loss-ulb:0.0318, weight:2.00, lr:0.0008
[11:19:54.145] iteration:7999  t-loss:0.1273, loss-lb:0.0852, loss-ulb:0.0210, weight:2.00, lr:0.0008
[11:19:54.337] iteration:8000  t-loss:0.1659, loss-lb:0.0965, loss-ulb:0.0347, weight:2.00, lr:0.0008
[11:19:54.529] iteration:8001  t-loss:0.1444, loss-lb:0.0953, loss-ulb:0.0246, weight:2.00, lr:0.0008
[11:19:54.720] iteration:8002  t-loss:0.1612, loss-lb:0.0900, loss-ulb:0.0356, weight:2.00, lr:0.0008
[11:19:54.913] iteration:8003  t-loss:0.1586, loss-lb:0.0906, loss-ulb:0.0340, weight:2.00, lr:0.0008
[11:19:55.107] iteration:8004  t-loss:0.1767, loss-lb:0.1140, loss-ulb:0.0314, weight:2.00, lr:0.0008
[11:19:55.300] iteration:8005  t-loss:0.2580, loss-lb:0.0901, loss-ulb:0.0840, weight:2.00, lr:0.0008
[11:19:55.491] iteration:8006  t-loss:0.1488, loss-lb:0.0964, loss-ulb:0.0262, weight:2.00, lr:0.0008
[11:19:55.684] iteration:8007  t-loss:0.1838, loss-lb:0.0954, loss-ulb:0.0442, weight:2.00, lr:0.0008
[11:19:55.877] iteration:8008  t-loss:0.1356, loss-lb:0.0838, loss-ulb:0.0259, weight:2.00, lr:0.0008
[11:19:56.069] iteration:8009  t-loss:0.1621, loss-lb:0.0984, loss-ulb:0.0318, weight:2.00, lr:0.0008
[11:19:56.261] iteration:8010  t-loss:0.1557, loss-lb:0.1040, loss-ulb:0.0259, weight:2.00, lr:0.0008
[11:19:56.454] iteration:8011  t-loss:0.1370, loss-lb:0.0908, loss-ulb:0.0231, weight:2.00, lr:0.0008
[11:19:56.647] iteration:8012  t-loss:0.1432, loss-lb:0.0965, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:19:56.839] iteration:8013  t-loss:0.1426, loss-lb:0.0906, loss-ulb:0.0260, weight:2.00, lr:0.0008
[11:19:57.031] iteration:8014  t-loss:0.1703, loss-lb:0.1092, loss-ulb:0.0305, weight:2.00, lr:0.0008
[11:19:57.224] iteration:8015  t-loss:0.1536, loss-lb:0.0983, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:19:57.415] iteration:8016  t-loss:0.1623, loss-lb:0.1048, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:19:57.608] iteration:8017  t-loss:0.1674, loss-lb:0.1209, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:19:57.799] iteration:8018  t-loss:0.1521, loss-lb:0.0997, loss-ulb:0.0262, weight:2.00, lr:0.0008
[11:19:57.992] iteration:8019  t-loss:0.1620, loss-lb:0.0936, loss-ulb:0.0342, weight:2.00, lr:0.0008
[11:19:58.184] iteration:8020  t-loss:0.1590, loss-lb:0.1103, loss-ulb:0.0244, weight:2.00, lr:0.0008
[11:19:58.377] iteration:8021  t-loss:0.1988, loss-lb:0.0884, loss-ulb:0.0552, weight:2.00, lr:0.0008
[11:19:58.569] iteration:8022  t-loss:0.1551, loss-lb:0.0908, loss-ulb:0.0321, weight:2.00, lr:0.0008
[11:19:58.763] iteration:8023  t-loss:0.1721, loss-lb:0.1251, loss-ulb:0.0235, weight:2.00, lr:0.0008
[11:19:58.956] iteration:8024  t-loss:0.1948, loss-lb:0.1024, loss-ulb:0.0462, weight:2.00, lr:0.0008
[11:19:59.149] iteration:8025  t-loss:0.1469, loss-lb:0.0884, loss-ulb:0.0292, weight:2.00, lr:0.0008
[11:19:59.341] iteration:8026  t-loss:0.1650, loss-lb:0.0866, loss-ulb:0.0392, weight:2.00, lr:0.0008
[11:19:59.534] iteration:8027  t-loss:0.1871, loss-lb:0.1378, loss-ulb:0.0246, weight:2.00, lr:0.0008
[11:19:59.725] iteration:8028  t-loss:0.2023, loss-lb:0.0869, loss-ulb:0.0577, weight:2.00, lr:0.0008
[11:19:59.916] iteration:8029  t-loss:0.1601, loss-lb:0.1024, loss-ulb:0.0289, weight:2.00, lr:0.0008
[11:20:00.107] iteration:8030  t-loss:0.1638, loss-lb:0.1074, loss-ulb:0.0282, weight:2.00, lr:0.0008
[11:20:00.298] iteration:8031  t-loss:0.1690, loss-lb:0.1003, loss-ulb:0.0343, weight:2.00, lr:0.0008
[11:20:00.490] iteration:8032  t-loss:0.2795, loss-lb:0.0970, loss-ulb:0.0912, weight:2.00, lr:0.0008
[11:20:00.682] iteration:8033  t-loss:0.1380, loss-lb:0.0920, loss-ulb:0.0230, weight:2.00, lr:0.0008
[11:20:00.872] iteration:8034  t-loss:0.1775, loss-lb:0.0979, loss-ulb:0.0398, weight:2.00, lr:0.0008
[11:20:01.062] iteration:8035  t-loss:0.1656, loss-lb:0.0897, loss-ulb:0.0379, weight:2.00, lr:0.0008
[11:20:01.253] iteration:8036  t-loss:0.2414, loss-lb:0.1701, loss-ulb:0.0356, weight:2.00, lr:0.0008
[11:20:01.851] iteration:8037  t-loss:0.1954, loss-lb:0.0962, loss-ulb:0.0496, weight:2.00, lr:0.0008
[11:20:02.047] iteration:8038  t-loss:0.1499, loss-lb:0.0919, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:20:02.239] iteration:8039  t-loss:0.1763, loss-lb:0.1089, loss-ulb:0.0337, weight:2.00, lr:0.0008
[11:20:02.431] iteration:8040  t-loss:0.1445, loss-lb:0.1013, loss-ulb:0.0216, weight:2.00, lr:0.0008
[11:20:02.622] iteration:8041  t-loss:0.1622, loss-lb:0.1124, loss-ulb:0.0249, weight:2.00, lr:0.0008
[11:20:02.815] iteration:8042  t-loss:0.1512, loss-lb:0.1000, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:20:03.007] iteration:8043  t-loss:0.1453, loss-lb:0.0907, loss-ulb:0.0273, weight:2.00, lr:0.0008
[11:20:03.199] iteration:8044  t-loss:0.2817, loss-lb:0.1297, loss-ulb:0.0760, weight:2.00, lr:0.0008
[11:20:03.391] iteration:8045  t-loss:0.1509, loss-lb:0.1032, loss-ulb:0.0239, weight:2.00, lr:0.0008
[11:20:03.584] iteration:8046  t-loss:0.1495, loss-lb:0.0913, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:20:03.776] iteration:8047  t-loss:0.1699, loss-lb:0.1082, loss-ulb:0.0308, weight:2.00, lr:0.0008
[11:20:03.969] iteration:8048  t-loss:0.1699, loss-lb:0.0951, loss-ulb:0.0374, weight:2.00, lr:0.0008
[11:20:04.173] iteration:8049  t-loss:0.1519, loss-lb:0.0957, loss-ulb:0.0281, weight:2.00, lr:0.0008
[11:20:04.371] iteration:8050  t-loss:0.1555, loss-lb:0.0938, loss-ulb:0.0309, weight:2.00, lr:0.0008
[11:20:04.564] iteration:8051  t-loss:0.1574, loss-lb:0.0994, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:20:04.757] iteration:8052  t-loss:0.1413, loss-lb:0.0936, loss-ulb:0.0238, weight:2.00, lr:0.0008
[11:20:04.949] iteration:8053  t-loss:0.1644, loss-lb:0.1075, loss-ulb:0.0284, weight:2.00, lr:0.0008
[11:20:05.143] iteration:8054  t-loss:0.1371, loss-lb:0.0880, loss-ulb:0.0245, weight:2.00, lr:0.0008
[11:20:05.335] iteration:8055  t-loss:0.1401, loss-lb:0.0937, loss-ulb:0.0232, weight:2.00, lr:0.0008
[11:20:05.528] iteration:8056  t-loss:0.1655, loss-lb:0.0988, loss-ulb:0.0334, weight:2.00, lr:0.0008
[11:20:05.720] iteration:8057  t-loss:0.1487, loss-lb:0.1005, loss-ulb:0.0241, weight:2.00, lr:0.0008
[11:20:05.913] iteration:8058  t-loss:0.1719, loss-lb:0.0986, loss-ulb:0.0367, weight:2.00, lr:0.0008
[11:20:06.105] iteration:8059  t-loss:0.1593, loss-lb:0.0928, loss-ulb:0.0332, weight:2.00, lr:0.0008
[11:20:06.298] iteration:8060  t-loss:0.2334, loss-lb:0.0863, loss-ulb:0.0735, weight:2.00, lr:0.0008
[11:20:06.490] iteration:8061  t-loss:0.1451, loss-lb:0.0926, loss-ulb:0.0263, weight:2.00, lr:0.0008
[11:20:06.684] iteration:8062  t-loss:0.1576, loss-lb:0.0907, loss-ulb:0.0335, weight:2.00, lr:0.0008
[11:20:06.876] iteration:8063  t-loss:0.1644, loss-lb:0.0980, loss-ulb:0.0332, weight:2.00, lr:0.0008
[11:20:07.069] iteration:8064  t-loss:0.1617, loss-lb:0.0916, loss-ulb:0.0350, weight:2.00, lr:0.0008
[11:20:07.263] iteration:8065  t-loss:0.1458, loss-lb:0.0914, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:20:07.455] iteration:8066  t-loss:0.1429, loss-lb:0.0966, loss-ulb:0.0231, weight:2.00, lr:0.0008
[11:20:07.647] iteration:8067  t-loss:0.1564, loss-lb:0.1030, loss-ulb:0.0267, weight:2.00, lr:0.0008
[11:20:07.840] iteration:8068  t-loss:0.2058, loss-lb:0.1020, loss-ulb:0.0519, weight:2.00, lr:0.0008
[11:20:08.032] iteration:8069  t-loss:0.1418, loss-lb:0.0942, loss-ulb:0.0238, weight:2.00, lr:0.0008
[11:20:08.225] iteration:8070  t-loss:0.1580, loss-lb:0.0822, loss-ulb:0.0379, weight:2.00, lr:0.0008
[11:20:08.418] iteration:8071  t-loss:0.1466, loss-lb:0.0875, loss-ulb:0.0296, weight:2.00, lr:0.0008
[11:20:08.610] iteration:8072  t-loss:0.1607, loss-lb:0.0980, loss-ulb:0.0313, weight:2.00, lr:0.0008
[11:20:08.803] iteration:8073  t-loss:0.2591, loss-lb:0.0973, loss-ulb:0.0809, weight:2.00, lr:0.0008
[11:20:08.996] iteration:8074  t-loss:0.1427, loss-lb:0.0931, loss-ulb:0.0248, weight:2.00, lr:0.0008
[11:20:09.188] iteration:8075  t-loss:0.1455, loss-lb:0.0976, loss-ulb:0.0240, weight:2.00, lr:0.0008
[11:20:09.380] iteration:8076  t-loss:0.1408, loss-lb:0.0851, loss-ulb:0.0279, weight:2.00, lr:0.0008
[11:20:09.574] iteration:8077  t-loss:0.1632, loss-lb:0.1016, loss-ulb:0.0308, weight:2.00, lr:0.0008
[11:20:09.766] iteration:8078  t-loss:0.1728, loss-lb:0.0944, loss-ulb:0.0392, weight:2.00, lr:0.0008
[11:20:09.959] iteration:8079  t-loss:0.1382, loss-lb:0.0871, loss-ulb:0.0255, weight:2.00, lr:0.0008
[11:20:10.151] iteration:8080  t-loss:0.1580, loss-lb:0.0970, loss-ulb:0.0305, weight:2.00, lr:0.0008
[11:20:10.344] iteration:8081  t-loss:0.1694, loss-lb:0.0964, loss-ulb:0.0365, weight:2.00, lr:0.0008
[11:20:10.536] iteration:8082  t-loss:0.1373, loss-lb:0.0845, loss-ulb:0.0264, weight:2.00, lr:0.0008
[11:20:10.728] iteration:8083  t-loss:0.1484, loss-lb:0.0939, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:20:10.921] iteration:8084  t-loss:0.1463, loss-lb:0.0900, loss-ulb:0.0281, weight:2.00, lr:0.0008
[11:20:11.113] iteration:8085  t-loss:0.1605, loss-lb:0.0976, loss-ulb:0.0314, weight:2.00, lr:0.0008
[11:20:11.305] iteration:8086  t-loss:0.1965, loss-lb:0.1235, loss-ulb:0.0365, weight:2.00, lr:0.0008
[11:20:11.499] iteration:8087  t-loss:0.1695, loss-lb:0.0901, loss-ulb:0.0397, weight:2.00, lr:0.0008
[11:20:11.691] iteration:8088  t-loss:0.1391, loss-lb:0.0911, loss-ulb:0.0240, weight:2.00, lr:0.0008
[11:20:11.883] iteration:8089  t-loss:0.1377, loss-lb:0.0850, loss-ulb:0.0264, weight:2.00, lr:0.0008
[11:20:12.075] iteration:8090  t-loss:0.1522, loss-lb:0.0913, loss-ulb:0.0305, weight:2.00, lr:0.0008
[11:20:12.268] iteration:8091  t-loss:0.1414, loss-lb:0.0875, loss-ulb:0.0270, weight:2.00, lr:0.0008
[11:20:12.459] iteration:8092  t-loss:0.1372, loss-lb:0.0944, loss-ulb:0.0214, weight:2.00, lr:0.0008
[11:20:12.653] iteration:8093  t-loss:0.1535, loss-lb:0.0900, loss-ulb:0.0318, weight:2.00, lr:0.0008
[11:20:12.845] iteration:8094  t-loss:0.1274, loss-lb:0.0833, loss-ulb:0.0221, weight:2.00, lr:0.0008
[11:20:13.037] iteration:8095  t-loss:0.1516, loss-lb:0.0931, loss-ulb:0.0292, weight:2.00, lr:0.0008
[11:20:13.230] iteration:8096  t-loss:0.1472, loss-lb:0.0984, loss-ulb:0.0244, weight:2.00, lr:0.0008
[11:20:13.422] iteration:8097  t-loss:0.1338, loss-lb:0.0836, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:20:13.613] iteration:8098  t-loss:0.1293, loss-lb:0.0827, loss-ulb:0.0233, weight:2.00, lr:0.0008
[11:20:13.806] iteration:8099  t-loss:0.1677, loss-lb:0.0902, loss-ulb:0.0387, weight:2.00, lr:0.0008
[11:20:13.998] iteration:8100  t-loss:0.1724, loss-lb:0.0984, loss-ulb:0.0370, weight:2.00, lr:0.0008
[11:20:14.190] iteration:8101  t-loss:0.1371, loss-lb:0.0885, loss-ulb:0.0243, weight:2.00, lr:0.0008
[11:20:14.383] iteration:8102  t-loss:0.1420, loss-lb:0.0883, loss-ulb:0.0269, weight:2.00, lr:0.0008
[11:20:14.574] iteration:8103  t-loss:0.1649, loss-lb:0.1059, loss-ulb:0.0295, weight:2.00, lr:0.0008
[11:20:14.768] iteration:8104  t-loss:0.1455, loss-lb:0.0881, loss-ulb:0.0287, weight:2.00, lr:0.0008
[11:20:14.960] iteration:8105  t-loss:0.1375, loss-lb:0.0842, loss-ulb:0.0266, weight:2.00, lr:0.0008
[11:20:15.153] iteration:8106  t-loss:0.1364, loss-lb:0.0900, loss-ulb:0.0232, weight:2.00, lr:0.0008
[11:20:15.344] iteration:8107  t-loss:0.1552, loss-lb:0.0950, loss-ulb:0.0301, weight:2.00, lr:0.0008
[11:20:15.538] iteration:8108  t-loss:0.1665, loss-lb:0.0940, loss-ulb:0.0363, weight:2.00, lr:0.0008
[11:20:15.731] iteration:8109  t-loss:0.1470, loss-lb:0.0901, loss-ulb:0.0284, weight:2.00, lr:0.0008
[11:20:15.924] iteration:8110  t-loss:0.1506, loss-lb:0.0921, loss-ulb:0.0293, weight:2.00, lr:0.0008
[11:20:16.117] iteration:8111  t-loss:0.1409, loss-lb:0.0953, loss-ulb:0.0228, weight:2.00, lr:0.0008
[11:20:16.308] iteration:8112  t-loss:0.1584, loss-lb:0.1013, loss-ulb:0.0285, weight:2.00, lr:0.0008
[11:20:16.501] iteration:8113  t-loss:0.1444, loss-lb:0.0920, loss-ulb:0.0262, weight:2.00, lr:0.0008
[11:20:16.694] iteration:8114  t-loss:0.1489, loss-lb:0.0960, loss-ulb:0.0265, weight:2.00, lr:0.0008
[11:20:16.886] iteration:8115  t-loss:0.1558, loss-lb:0.0868, loss-ulb:0.0345, weight:2.00, lr:0.0008
[11:20:17.079] iteration:8116  t-loss:0.1873, loss-lb:0.0875, loss-ulb:0.0499, weight:2.00, lr:0.0008
[11:20:17.272] iteration:8117  t-loss:0.1715, loss-lb:0.0828, loss-ulb:0.0443, weight:2.00, lr:0.0008
[11:20:17.465] iteration:8118  t-loss:0.3349, loss-lb:0.0895, loss-ulb:0.1227, weight:2.00, lr:0.0008
[11:20:17.657] iteration:8119  t-loss:0.1941, loss-lb:0.1077, loss-ulb:0.0432, weight:2.00, lr:0.0008
[11:20:17.848] iteration:8120  t-loss:0.1436, loss-lb:0.0856, loss-ulb:0.0290, weight:2.00, lr:0.0008
[11:20:18.041] iteration:8121  t-loss:0.1367, loss-lb:0.0922, loss-ulb:0.0223, weight:2.00, lr:0.0008
[11:20:18.233] iteration:8122  t-loss:0.1459, loss-lb:0.0884, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:20:18.425] iteration:8123  t-loss:0.1732, loss-lb:0.0912, loss-ulb:0.0410, weight:2.00, lr:0.0008
[11:20:18.617] iteration:8124  t-loss:0.2041, loss-lb:0.1014, loss-ulb:0.0513, weight:2.00, lr:0.0008
[11:20:18.810] iteration:8125  t-loss:0.1309, loss-lb:0.0822, loss-ulb:0.0243, weight:2.00, lr:0.0008
[11:20:19.001] iteration:8126  t-loss:0.1628, loss-lb:0.0940, loss-ulb:0.0344, weight:2.00, lr:0.0008
[11:20:19.194] iteration:8127  t-loss:0.1628, loss-lb:0.1057, loss-ulb:0.0285, weight:2.00, lr:0.0008
[11:20:19.385] iteration:8128  t-loss:0.1558, loss-lb:0.1018, loss-ulb:0.0270, weight:2.00, lr:0.0008
[11:20:19.576] iteration:8129  t-loss:0.1791, loss-lb:0.1057, loss-ulb:0.0367, weight:2.00, lr:0.0008
[11:20:19.766] iteration:8130  t-loss:0.1596, loss-lb:0.0912, loss-ulb:0.0342, weight:2.00, lr:0.0008
[11:20:19.956] iteration:8131  t-loss:0.1480, loss-lb:0.0971, loss-ulb:0.0255, weight:2.00, lr:0.0008
[11:20:20.147] iteration:8132  t-loss:0.1514, loss-lb:0.0967, loss-ulb:0.0274, weight:2.00, lr:0.0008
[11:20:20.338] iteration:8133  t-loss:0.1432, loss-lb:0.0952, loss-ulb:0.0240, weight:2.00, lr:0.0008
[11:20:20.530] iteration:8134  t-loss:0.1583, loss-lb:0.1001, loss-ulb:0.0291, weight:2.00, lr:0.0008
[11:20:32.701]  <<Test>> - Ep:82  - mean_dice/mean_h95 - S:89.44/1.71, Best-S:90.28, T:90.08/1.54, Best-T:90.48
[11:20:32.702]           - AvgLoss(lb/ulb/all):0.0948/0.0379/0.1699
[11:20:33.265] iteration:8135  t-loss:0.1452, loss-lb:0.0948, loss-ulb:0.0252, weight:2.00, lr:0.0008
[11:20:33.462] iteration:8136  t-loss:0.1313, loss-lb:0.0831, loss-ulb:0.0241, weight:2.00, lr:0.0008
[11:20:33.656] iteration:8137  t-loss:0.3216, loss-lb:0.1086, loss-ulb:0.1065, weight:2.00, lr:0.0008
[11:20:33.849] iteration:8138  t-loss:0.1593, loss-lb:0.1087, loss-ulb:0.0253, weight:2.00, lr:0.0008
[11:20:34.042] iteration:8139  t-loss:0.1579, loss-lb:0.0939, loss-ulb:0.0320, weight:2.00, lr:0.0008
[11:20:34.235] iteration:8140  t-loss:0.1837, loss-lb:0.0941, loss-ulb:0.0448, weight:2.00, lr:0.0008
[11:20:34.429] iteration:8141  t-loss:0.2259, loss-lb:0.0915, loss-ulb:0.0672, weight:2.00, lr:0.0008
[11:20:34.622] iteration:8142  t-loss:0.1541, loss-lb:0.0865, loss-ulb:0.0338, weight:2.00, lr:0.0008
[11:20:34.815] iteration:8143  t-loss:0.1724, loss-lb:0.0872, loss-ulb:0.0426, weight:2.00, lr:0.0008
[11:20:35.008] iteration:8144  t-loss:0.1498, loss-lb:0.1029, loss-ulb:0.0235, weight:2.00, lr:0.0008
[11:20:35.201] iteration:8145  t-loss:0.2027, loss-lb:0.0914, loss-ulb:0.0557, weight:2.00, lr:0.0008
[11:20:35.394] iteration:8146  t-loss:0.1755, loss-lb:0.0961, loss-ulb:0.0397, weight:2.00, lr:0.0008
[11:20:35.587] iteration:8147  t-loss:0.2107, loss-lb:0.0900, loss-ulb:0.0604, weight:2.00, lr:0.0008
[11:20:35.780] iteration:8148  t-loss:0.1549, loss-lb:0.0897, loss-ulb:0.0326, weight:2.00, lr:0.0008
[11:20:35.974] iteration:8149  t-loss:0.2718, loss-lb:0.0936, loss-ulb:0.0891, weight:2.00, lr:0.0008
[11:20:36.166] iteration:8150  t-loss:0.1355, loss-lb:0.0887, loss-ulb:0.0234, weight:2.00, lr:0.0008
[11:20:36.359] iteration:8151  t-loss:0.1686, loss-lb:0.1135, loss-ulb:0.0276, weight:2.00, lr:0.0008
[11:20:36.551] iteration:8152  t-loss:0.1454, loss-lb:0.0877, loss-ulb:0.0288, weight:2.00, lr:0.0008
[11:20:36.746] iteration:8153  t-loss:0.1570, loss-lb:0.0999, loss-ulb:0.0285, weight:2.00, lr:0.0008
[11:20:36.952] iteration:8154  t-loss:0.1631, loss-lb:0.1000, loss-ulb:0.0316, weight:2.00, lr:0.0008
[11:20:37.148] iteration:8155  t-loss:0.1826, loss-lb:0.0953, loss-ulb:0.0437, weight:2.00, lr:0.0008
[11:20:37.340] iteration:8156  t-loss:0.1646, loss-lb:0.1087, loss-ulb:0.0279, weight:2.00, lr:0.0008
[11:20:37.532] iteration:8157  t-loss:0.1628, loss-lb:0.0982, loss-ulb:0.0323, weight:2.00, lr:0.0008
[11:20:37.725] iteration:8158  t-loss:0.1352, loss-lb:0.0867, loss-ulb:0.0242, weight:2.00, lr:0.0008
[11:20:37.916] iteration:8159  t-loss:0.1685, loss-lb:0.0946, loss-ulb:0.0369, weight:2.00, lr:0.0008
[11:20:38.109] iteration:8160  t-loss:0.1879, loss-lb:0.0885, loss-ulb:0.0497, weight:2.00, lr:0.0008
[11:20:38.302] iteration:8161  t-loss:0.1269, loss-lb:0.0856, loss-ulb:0.0207, weight:2.00, lr:0.0008
[11:20:38.494] iteration:8162  t-loss:0.1994, loss-lb:0.1025, loss-ulb:0.0485, weight:2.00, lr:0.0008
[11:20:38.687] iteration:8163  t-loss:0.1605, loss-lb:0.0963, loss-ulb:0.0321, weight:2.00, lr:0.0008
[11:20:38.880] iteration:8164  t-loss:0.1464, loss-lb:0.0921, loss-ulb:0.0271, weight:2.00, lr:0.0008
[11:20:39.073] iteration:8165  t-loss:0.1675, loss-lb:0.0873, loss-ulb:0.0401, weight:2.00, lr:0.0008
[11:20:39.266] iteration:8166  t-loss:0.1616, loss-lb:0.0913, loss-ulb:0.0352, weight:2.00, lr:0.0008
[11:20:39.459] iteration:8167  t-loss:0.1480, loss-lb:0.0908, loss-ulb:0.0286, weight:2.00, lr:0.0008
[11:20:39.655] iteration:8168  t-loss:0.1485, loss-lb:0.0931, loss-ulb:0.0277, weight:2.00, lr:0.0008
[11:20:39.851] iteration:8169  t-loss:0.1452, loss-lb:0.0979, loss-ulb:0.0237, weight:2.00, lr:0.0008
[11:20:40.044] iteration:8170  t-loss:0.1457, loss-lb:0.0918, loss-ulb:0.0270, weight:2.00, lr:0.0008
[11:20:40.238] iteration:8171  t-loss:0.3705, loss-lb:0.1684, loss-ulb:0.1010, weight:2.00, lr:0.0008
[11:20:40.431] iteration:8172  t-loss:0.1918, loss-lb:0.0914, loss-ulb:0.0502, weight:2.00, lr:0.0008
[11:20:40.623] iteration:8173  t-loss:0.1523, loss-lb:0.0917, loss-ulb:0.0303, weight:2.00, lr:0.0008
[11:20:40.814] iteration:8174  t-loss:0.1569, loss-lb:0.0940, loss-ulb:0.0314, weight:2.00, lr:0.0008
[11:20:41.008] iteration:8175  t-loss:0.2094, loss-lb:0.0969, loss-ulb:0.0562, weight:2.00, lr:0.0008
[11:20:41.200] iteration:8176  t-loss:0.1466, loss-lb:0.0908, loss-ulb:0.0279, weight:2.00, lr:0.0008
[11:20:41.392] iteration:8177  t-loss:0.1616, loss-lb:0.1046, loss-ulb:0.0285, weight:2.00, lr:0.0008
[11:20:41.585] iteration:8178  t-loss:0.1892, loss-lb:0.1001, loss-ulb:0.0446, weight:2.00, lr:0.0008
[11:20:41.776] iteration:8179  t-loss:0.2224, loss-lb:0.0921, loss-ulb:0.0651, weight:2.00, lr:0.0008
[11:20:41.968] iteration:8180  t-loss:0.1688, loss-lb:0.0954, loss-ulb:0.0367, weight:2.00, lr:0.0008
[11:20:42.161] iteration:8181  t-loss:0.1576, loss-lb:0.0944, loss-ulb:0.0316, weight:2.00, lr:0.0008
[11:20:42.351] iteration:8182  t-loss:0.1505, loss-lb:0.0967, loss-ulb:0.0269, weight:2.00, lr:0.0008
[11:20:42.544] iteration:8183  t-loss:0.1453, loss-lb:0.0883, loss-ulb:0.0285, weight:2.00, lr:0.0008
[11:20:42.735] iteration:8184  t-loss:0.1968, loss-lb:0.0866, loss-ulb:0.0551, weight:2.00, lr:0.0008
[11:20:42.928] iteration:8185  t-loss:0.1726, loss-lb:0.0939, loss-ulb:0.0393, weight:2.00, lr:0.0008
[11:20:43.121] iteration:8186  t-loss:0.1848, loss-lb:0.0903, loss-ulb:0.0473, weight:2.00, lr:0.0008
[11:20:43.313] iteration:8187  t-loss:0.1969, loss-lb:0.1087, loss-ulb:0.0441, weight:2.00, lr:0.0008
[11:20:43.505] iteration:8188  t-loss:0.3534, loss-lb:0.0942, loss-ulb:0.1296, weight:2.00, lr:0.0008
[11:20:43.697] iteration:8189  t-loss:0.1524, loss-lb:0.1021, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:20:43.889] iteration:8190  t-loss:0.1532, loss-lb:0.1074, loss-ulb:0.0229, weight:2.00, lr:0.0008
[11:20:44.081] iteration:8191  t-loss:0.1422, loss-lb:0.0879, loss-ulb:0.0271, weight:2.00, lr:0.0008
[11:20:44.275] iteration:8192  t-loss:0.1483, loss-lb:0.0948, loss-ulb:0.0268, weight:2.00, lr:0.0008
[11:20:44.467] iteration:8193  t-loss:0.1490, loss-lb:0.0937, loss-ulb:0.0277, weight:2.00, lr:0.0008
[11:20:44.658] iteration:8194  t-loss:0.1694, loss-lb:0.0980, loss-ulb:0.0357, weight:2.00, lr:0.0008
[11:20:44.850] iteration:8195  t-loss:0.1429, loss-lb:0.0873, loss-ulb:0.0278, weight:2.00, lr:0.0008
[11:20:45.044] iteration:8196  t-loss:0.1443, loss-lb:0.0956, loss-ulb:0.0243, weight:2.00, lr:0.0008
[11:20:45.236] iteration:8197  t-loss:0.1871, loss-lb:0.1041, loss-ulb:0.0415, weight:2.00, lr:0.0008
[11:20:45.428] iteration:8198  t-loss:0.1738, loss-lb:0.1094, loss-ulb:0.0322, weight:2.00, lr:0.0008
[11:20:45.620] iteration:8199  t-loss:0.1537, loss-lb:0.1025, loss-ulb:0.0256, weight:2.00, lr:0.0008
[11:20:45.811] iteration:8200  t-loss:0.1357, loss-lb:0.0858, loss-ulb:0.0250, weight:2.00, lr:0.0008
[11:20:46.005] iteration:8201  t-loss:0.2228, loss-lb:0.1000, loss-ulb:0.0614, weight:2.00, lr:0.0008
[11:20:46.198] iteration:8202  t-loss:0.1511, loss-lb:0.1039, loss-ulb:0.0236, weight:2.00, lr:0.0008
[11:20:46.389] iteration:8203  t-loss:0.1416, loss-lb:0.0897, loss-ulb:0.0260, weight:2.00, lr:0.0008
[11:20:46.581] iteration:8204  t-loss:0.1713, loss-lb:0.0928, loss-ulb:0.0393, weight:2.00, lr:0.0008
[11:20:46.775] iteration:8205  t-loss:0.1603, loss-lb:0.1060, loss-ulb:0.0272, weight:2.00, lr:0.0008
[11:20:46.968] iteration:8206  t-loss:0.1504, loss-lb:0.1002, loss-ulb:0.0251, weight:2.00, lr:0.0008
[11:20:47.160] iteration:8207  t-loss:0.1474, loss-lb:0.0887, loss-ulb:0.0293, weight:2.00, lr:0.0008
[11:20:47.354] iteration:8208  t-loss:0.1490, loss-lb:0.1041, loss-ulb:0.0225, weight:2.00, lr:0.0008
[11:20:47.545] iteration:8209  t-loss:0.1471, loss-lb:0.0945, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:20:47.737] iteration:8210  t-loss:0.1555, loss-lb:0.1129, loss-ulb:0.0213, weight:2.00, lr:0.0007
[11:20:47.929] iteration:8211  t-loss:0.1597, loss-lb:0.1015, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:20:48.120] iteration:8212  t-loss:0.1537, loss-lb:0.0911, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:20:48.311] iteration:8213  t-loss:0.1660, loss-lb:0.0935, loss-ulb:0.0363, weight:2.00, lr:0.0007
[11:20:48.502] iteration:8214  t-loss:0.1453, loss-lb:0.0938, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:20:48.693] iteration:8215  t-loss:0.1308, loss-lb:0.0889, loss-ulb:0.0209, weight:2.00, lr:0.0007
[11:20:48.885] iteration:8216  t-loss:0.2096, loss-lb:0.1012, loss-ulb:0.0542, weight:2.00, lr:0.0007
[11:20:49.077] iteration:8217  t-loss:0.1683, loss-lb:0.0964, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:20:49.269] iteration:8218  t-loss:0.1411, loss-lb:0.0894, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:20:49.461] iteration:8219  t-loss:0.1695, loss-lb:0.0903, loss-ulb:0.0396, weight:2.00, lr:0.0007
[11:20:49.652] iteration:8220  t-loss:0.1520, loss-lb:0.0934, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:20:49.845] iteration:8221  t-loss:0.1698, loss-lb:0.0936, loss-ulb:0.0381, weight:2.00, lr:0.0007
[11:20:50.036] iteration:8222  t-loss:0.1297, loss-lb:0.0804, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:20:50.229] iteration:8223  t-loss:0.1606, loss-lb:0.0988, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:20:50.427] iteration:8224  t-loss:0.2857, loss-lb:0.0874, loss-ulb:0.0991, weight:2.00, lr:0.0007
[11:20:50.621] iteration:8225  t-loss:0.1802, loss-lb:0.0861, loss-ulb:0.0471, weight:2.00, lr:0.0007
[11:20:50.814] iteration:8226  t-loss:0.1562, loss-lb:0.1102, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:20:51.007] iteration:8227  t-loss:0.1502, loss-lb:0.0849, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:20:51.197] iteration:8228  t-loss:0.1520, loss-lb:0.0911, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:20:51.388] iteration:8229  t-loss:0.1455, loss-lb:0.0840, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:20:51.578] iteration:8230  t-loss:0.1616, loss-lb:0.0839, loss-ulb:0.0388, weight:2.00, lr:0.0007
[11:20:51.769] iteration:8231  t-loss:0.1663, loss-lb:0.1045, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:20:51.958] iteration:8232  t-loss:0.1542, loss-lb:0.0966, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:20:52.550] iteration:8233  t-loss:0.1632, loss-lb:0.0927, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:20:52.748] iteration:8234  t-loss:0.3333, loss-lb:0.1022, loss-ulb:0.1156, weight:2.00, lr:0.0007
[11:20:52.940] iteration:8235  t-loss:0.1717, loss-lb:0.1222, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:20:53.133] iteration:8236  t-loss:0.2297, loss-lb:0.1035, loss-ulb:0.0631, weight:2.00, lr:0.0007
[11:20:53.325] iteration:8237  t-loss:0.1533, loss-lb:0.0916, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:20:53.517] iteration:8238  t-loss:0.1692, loss-lb:0.1117, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:20:53.709] iteration:8239  t-loss:0.1645, loss-lb:0.0909, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:20:53.901] iteration:8240  t-loss:0.1721, loss-lb:0.1130, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:20:54.094] iteration:8241  t-loss:0.1436, loss-lb:0.0910, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:20:54.287] iteration:8242  t-loss:0.1491, loss-lb:0.0968, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:20:54.478] iteration:8243  t-loss:0.1386, loss-lb:0.0873, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:20:54.670] iteration:8244  t-loss:0.3552, loss-lb:0.0997, loss-ulb:0.1278, weight:2.00, lr:0.0007
[11:20:54.863] iteration:8245  t-loss:0.1748, loss-lb:0.0951, loss-ulb:0.0399, weight:2.00, lr:0.0007
[11:20:55.055] iteration:8246  t-loss:0.1701, loss-lb:0.1004, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:20:55.248] iteration:8247  t-loss:0.2970, loss-lb:0.0945, loss-ulb:0.1013, weight:2.00, lr:0.0007
[11:20:55.441] iteration:8248  t-loss:0.1662, loss-lb:0.1054, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:20:55.634] iteration:8249  t-loss:0.1856, loss-lb:0.0937, loss-ulb:0.0459, weight:2.00, lr:0.0007
[11:20:55.825] iteration:8250  t-loss:0.1609, loss-lb:0.1057, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:20:56.017] iteration:8251  t-loss:0.1749, loss-lb:0.0982, loss-ulb:0.0384, weight:2.00, lr:0.0007
[11:20:56.209] iteration:8252  t-loss:0.1488, loss-lb:0.0925, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:20:56.401] iteration:8253  t-loss:0.1594, loss-lb:0.0930, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:20:56.594] iteration:8254  t-loss:0.1643, loss-lb:0.1089, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:20:56.786] iteration:8255  t-loss:0.1537, loss-lb:0.0871, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:20:56.978] iteration:8256  t-loss:0.1468, loss-lb:0.0831, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:20:57.171] iteration:8257  t-loss:0.1747, loss-lb:0.1048, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:20:57.363] iteration:8258  t-loss:0.1587, loss-lb:0.0880, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:20:57.554] iteration:8259  t-loss:0.1524, loss-lb:0.0907, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:20:57.748] iteration:8260  t-loss:0.1457, loss-lb:0.0900, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:20:57.939] iteration:8261  t-loss:0.1470, loss-lb:0.0933, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:20:58.131] iteration:8262  t-loss:0.1700, loss-lb:0.0874, loss-ulb:0.0413, weight:2.00, lr:0.0007
[11:20:58.328] iteration:8263  t-loss:0.1422, loss-lb:0.0972, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:20:58.520] iteration:8264  t-loss:0.1560, loss-lb:0.0933, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:20:58.712] iteration:8265  t-loss:0.1467, loss-lb:0.0885, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:20:58.906] iteration:8266  t-loss:0.1597, loss-lb:0.0963, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:20:59.098] iteration:8267  t-loss:0.1878, loss-lb:0.0935, loss-ulb:0.0472, weight:2.00, lr:0.0007
[11:20:59.291] iteration:8268  t-loss:0.2819, loss-lb:0.0948, loss-ulb:0.0935, weight:2.00, lr:0.0007
[11:20:59.482] iteration:8269  t-loss:0.1503, loss-lb:0.0887, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:20:59.674] iteration:8270  t-loss:0.1397, loss-lb:0.0843, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:20:59.866] iteration:8271  t-loss:0.1881, loss-lb:0.0853, loss-ulb:0.0514, weight:2.00, lr:0.0007
[11:21:00.057] iteration:8272  t-loss:0.1712, loss-lb:0.1102, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:21:00.249] iteration:8273  t-loss:0.1732, loss-lb:0.0961, loss-ulb:0.0386, weight:2.00, lr:0.0007
[11:21:00.441] iteration:8274  t-loss:0.1461, loss-lb:0.0831, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:21:00.633] iteration:8275  t-loss:0.1644, loss-lb:0.1058, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:21:00.826] iteration:8276  t-loss:0.1388, loss-lb:0.0909, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:21:01.020] iteration:8277  t-loss:0.1533, loss-lb:0.0873, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:21:01.216] iteration:8278  t-loss:0.1369, loss-lb:0.0851, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:21:01.412] iteration:8279  t-loss:0.1319, loss-lb:0.0810, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:21:01.607] iteration:8280  t-loss:0.1598, loss-lb:0.0912, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:21:01.801] iteration:8281  t-loss:0.1944, loss-lb:0.1010, loss-ulb:0.0467, weight:2.00, lr:0.0007
[11:21:01.995] iteration:8282  t-loss:0.1676, loss-lb:0.0968, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:21:02.188] iteration:8283  t-loss:0.1567, loss-lb:0.1035, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:21:02.379] iteration:8284  t-loss:0.1559, loss-lb:0.0895, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:21:02.572] iteration:8285  t-loss:0.1764, loss-lb:0.0891, loss-ulb:0.0436, weight:2.00, lr:0.0007
[11:21:02.764] iteration:8286  t-loss:0.1528, loss-lb:0.0930, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:21:02.955] iteration:8287  t-loss:0.1570, loss-lb:0.0959, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:21:03.148] iteration:8288  t-loss:0.1587, loss-lb:0.1029, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:21:03.342] iteration:8289  t-loss:0.1411, loss-lb:0.0910, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:21:03.533] iteration:8290  t-loss:0.1539, loss-lb:0.0891, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:21:03.725] iteration:8291  t-loss:0.1568, loss-lb:0.0980, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:21:03.918] iteration:8292  t-loss:0.1475, loss-lb:0.0840, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:21:04.110] iteration:8293  t-loss:0.1505, loss-lb:0.0912, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:21:04.302] iteration:8294  t-loss:0.1582, loss-lb:0.0927, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:21:04.495] iteration:8295  t-loss:0.1597, loss-lb:0.0947, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:21:04.688] iteration:8296  t-loss:0.1434, loss-lb:0.0880, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:21:04.879] iteration:8297  t-loss:0.1396, loss-lb:0.0942, loss-ulb:0.0227, weight:2.00, lr:0.0007
[11:21:05.072] iteration:8298  t-loss:0.1465, loss-lb:0.0909, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:21:05.264] iteration:8299  t-loss:0.2027, loss-lb:0.0928, loss-ulb:0.0550, weight:2.00, lr:0.0007
[11:21:05.456] iteration:8300  t-loss:0.1318, loss-lb:0.0931, loss-ulb:0.0193, weight:2.00, lr:0.0007
[11:21:05.648] iteration:8301  t-loss:0.1807, loss-lb:0.1068, loss-ulb:0.0369, weight:2.00, lr:0.0007
[11:21:05.840] iteration:8302  t-loss:0.1612, loss-lb:0.0883, loss-ulb:0.0365, weight:2.00, lr:0.0007
[11:21:06.033] iteration:8303  t-loss:0.1360, loss-lb:0.0899, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:21:06.225] iteration:8304  t-loss:0.1561, loss-lb:0.0955, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:21:06.418] iteration:8305  t-loss:0.2680, loss-lb:0.0781, loss-ulb:0.0949, weight:2.00, lr:0.0007
[11:21:06.610] iteration:8306  t-loss:0.1535, loss-lb:0.0895, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:21:06.802] iteration:8307  t-loss:0.2078, loss-lb:0.0918, loss-ulb:0.0580, weight:2.00, lr:0.0007
[11:21:06.993] iteration:8308  t-loss:0.1726, loss-lb:0.1010, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:21:07.185] iteration:8309  t-loss:0.1923, loss-lb:0.0928, loss-ulb:0.0497, weight:2.00, lr:0.0007
[11:21:07.378] iteration:8310  t-loss:0.1463, loss-lb:0.1008, loss-ulb:0.0227, weight:2.00, lr:0.0007
[11:21:07.571] iteration:8311  t-loss:0.1745, loss-lb:0.0893, loss-ulb:0.0426, weight:2.00, lr:0.0007
[11:21:07.764] iteration:8312  t-loss:0.1389, loss-lb:0.0907, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:21:07.956] iteration:8313  t-loss:0.1516, loss-lb:0.0869, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:21:08.147] iteration:8314  t-loss:0.2220, loss-lb:0.0938, loss-ulb:0.0641, weight:2.00, lr:0.0007
[11:21:08.340] iteration:8315  t-loss:0.3327, loss-lb:0.0887, loss-ulb:0.1220, weight:2.00, lr:0.0007
[11:21:08.534] iteration:8316  t-loss:0.2074, loss-lb:0.1023, loss-ulb:0.0525, weight:2.00, lr:0.0007
[11:21:08.726] iteration:8317  t-loss:0.1693, loss-lb:0.0876, loss-ulb:0.0408, weight:2.00, lr:0.0007
[11:21:08.926] iteration:8318  t-loss:0.1370, loss-lb:0.0897, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:21:09.118] iteration:8319  t-loss:0.1902, loss-lb:0.0997, loss-ulb:0.0452, weight:2.00, lr:0.0007
[11:21:09.309] iteration:8320  t-loss:0.2096, loss-lb:0.1110, loss-ulb:0.0493, weight:2.00, lr:0.0007
[11:21:09.502] iteration:8321  t-loss:0.1683, loss-lb:0.1114, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:21:09.720] iteration:8322  t-loss:0.3464, loss-lb:0.1066, loss-ulb:0.1199, weight:2.00, lr:0.0007
[11:21:09.916] iteration:8323  t-loss:0.1521, loss-lb:0.1033, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:21:10.108] iteration:8324  t-loss:0.1901, loss-lb:0.1142, loss-ulb:0.0379, weight:2.00, lr:0.0007
[11:21:10.298] iteration:8325  t-loss:0.1563, loss-lb:0.0949, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:21:10.488] iteration:8326  t-loss:0.1750, loss-lb:0.0989, loss-ulb:0.0381, weight:2.00, lr:0.0007
[11:21:10.678] iteration:8327  t-loss:0.1523, loss-lb:0.0908, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:21:10.868] iteration:8328  t-loss:0.1558, loss-lb:0.1088, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:21:11.057] iteration:8329  t-loss:0.1976, loss-lb:0.1146, loss-ulb:0.0415, weight:2.00, lr:0.0007
[11:21:11.248] iteration:8330  t-loss:0.1569, loss-lb:0.0922, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:21:22.449]  <<Test>> - Ep:84  - mean_dice/mean_h95 - S:88.51/3.15, Best-S:90.28, T:90.10/1.49, Best-T:90.48
[11:21:22.449]           - AvgLoss(lb/ulb/all):0.0954/0.0452/0.1892
[11:21:22.978] iteration:8331  t-loss:0.1807, loss-lb:0.1146, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:21:23.175] iteration:8332  t-loss:0.1622, loss-lb:0.0967, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:21:23.367] iteration:8333  t-loss:0.2208, loss-lb:0.0962, loss-ulb:0.0623, weight:2.00, lr:0.0007
[11:21:23.561] iteration:8334  t-loss:0.2253, loss-lb:0.1049, loss-ulb:0.0602, weight:2.00, lr:0.0007
[11:21:23.755] iteration:8335  t-loss:0.1800, loss-lb:0.1216, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:21:23.947] iteration:8336  t-loss:0.1790, loss-lb:0.1121, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:21:24.141] iteration:8337  t-loss:0.2012, loss-lb:0.1297, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:21:24.333] iteration:8338  t-loss:0.1778, loss-lb:0.1025, loss-ulb:0.0376, weight:2.00, lr:0.0007
[11:21:24.523] iteration:8339  t-loss:0.1816, loss-lb:0.1124, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:21:24.712] iteration:8340  t-loss:0.1828, loss-lb:0.1082, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:21:24.901] iteration:8341  t-loss:0.1903, loss-lb:0.1115, loss-ulb:0.0394, weight:2.00, lr:0.0007
[11:21:25.091] iteration:8342  t-loss:0.2223, loss-lb:0.1116, loss-ulb:0.0553, weight:2.00, lr:0.0007
[11:21:25.281] iteration:8343  t-loss:0.1735, loss-lb:0.1054, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:21:25.469] iteration:8344  t-loss:0.1877, loss-lb:0.1040, loss-ulb:0.0418, weight:2.00, lr:0.0007
[11:21:25.658] iteration:8345  t-loss:0.1697, loss-lb:0.1000, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:21:25.846] iteration:8346  t-loss:0.2470, loss-lb:0.1092, loss-ulb:0.0689, weight:2.00, lr:0.0007
[11:21:26.035] iteration:8347  t-loss:0.2520, loss-lb:0.1201, loss-ulb:0.0660, weight:2.00, lr:0.0007
[11:21:26.224] iteration:8348  t-loss:0.1487, loss-lb:0.0910, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:21:26.412] iteration:8349  t-loss:0.2049, loss-lb:0.1173, loss-ulb:0.0438, weight:2.00, lr:0.0007
[11:21:26.601] iteration:8350  t-loss:0.1826, loss-lb:0.0967, loss-ulb:0.0429, weight:2.00, lr:0.0007
[11:21:26.790] iteration:8351  t-loss:0.1697, loss-lb:0.1023, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:21:26.978] iteration:8352  t-loss:0.2357, loss-lb:0.1746, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:21:27.168] iteration:8353  t-loss:0.2167, loss-lb:0.1019, loss-ulb:0.0574, weight:2.00, lr:0.0007
[11:21:27.357] iteration:8354  t-loss:0.1977, loss-lb:0.0913, loss-ulb:0.0532, weight:2.00, lr:0.0007
[11:21:27.546] iteration:8355  t-loss:0.1504, loss-lb:0.0911, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:21:27.734] iteration:8356  t-loss:0.1942, loss-lb:0.1217, loss-ulb:0.0362, weight:2.00, lr:0.0007
[11:21:27.923] iteration:8357  t-loss:0.4271, loss-lb:0.1202, loss-ulb:0.1534, weight:2.00, lr:0.0007
[11:21:28.114] iteration:8358  t-loss:0.2926, loss-lb:0.0980, loss-ulb:0.0973, weight:2.00, lr:0.0007
[11:21:28.302] iteration:8359  t-loss:0.2734, loss-lb:0.0972, loss-ulb:0.0881, weight:2.00, lr:0.0007
[11:21:28.491] iteration:8360  t-loss:0.1916, loss-lb:0.1068, loss-ulb:0.0424, weight:2.00, lr:0.0007
[11:21:28.681] iteration:8361  t-loss:0.1628, loss-lb:0.0977, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:21:28.870] iteration:8362  t-loss:0.1823, loss-lb:0.1157, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:21:29.059] iteration:8363  t-loss:0.1636, loss-lb:0.0889, loss-ulb:0.0374, weight:2.00, lr:0.0007
[11:21:29.248] iteration:8364  t-loss:0.1617, loss-lb:0.1015, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:21:29.437] iteration:8365  t-loss:0.1967, loss-lb:0.1149, loss-ulb:0.0409, weight:2.00, lr:0.0007
[11:21:29.627] iteration:8366  t-loss:0.1663, loss-lb:0.1045, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:21:29.815] iteration:8367  t-loss:0.1763, loss-lb:0.1083, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:21:30.005] iteration:8368  t-loss:0.2197, loss-lb:0.0971, loss-ulb:0.0613, weight:2.00, lr:0.0007
[11:21:30.193] iteration:8369  t-loss:0.1497, loss-lb:0.1032, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:21:30.382] iteration:8370  t-loss:0.1909, loss-lb:0.1003, loss-ulb:0.0453, weight:2.00, lr:0.0007
[11:21:30.572] iteration:8371  t-loss:0.1551, loss-lb:0.0887, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:21:30.761] iteration:8372  t-loss:0.1469, loss-lb:0.0939, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:21:30.950] iteration:8373  t-loss:0.1670, loss-lb:0.1013, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:21:31.139] iteration:8374  t-loss:0.1532, loss-lb:0.1029, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:21:31.330] iteration:8375  t-loss:0.4209, loss-lb:0.0972, loss-ulb:0.1619, weight:2.00, lr:0.0007
[11:21:31.519] iteration:8376  t-loss:0.1513, loss-lb:0.0973, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:21:31.708] iteration:8377  t-loss:0.1561, loss-lb:0.1003, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:21:31.897] iteration:8378  t-loss:0.1457, loss-lb:0.0906, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:21:32.086] iteration:8379  t-loss:0.1847, loss-lb:0.0968, loss-ulb:0.0440, weight:2.00, lr:0.0007
[11:21:32.275] iteration:8380  t-loss:0.1450, loss-lb:0.0993, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:21:32.463] iteration:8381  t-loss:0.1491, loss-lb:0.0975, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:21:32.652] iteration:8382  t-loss:0.1551, loss-lb:0.1030, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:21:32.841] iteration:8383  t-loss:0.1403, loss-lb:0.0866, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:21:33.030] iteration:8384  t-loss:0.1738, loss-lb:0.0981, loss-ulb:0.0378, weight:2.00, lr:0.0007
[11:21:33.219] iteration:8385  t-loss:0.1591, loss-lb:0.0964, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:21:33.408] iteration:8386  t-loss:0.1440, loss-lb:0.0969, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:21:33.597] iteration:8387  t-loss:0.1424, loss-lb:0.0895, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:21:33.786] iteration:8388  t-loss:0.1620, loss-lb:0.0968, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:21:33.976] iteration:8389  t-loss:0.1747, loss-lb:0.1009, loss-ulb:0.0369, weight:2.00, lr:0.0007
[11:21:34.164] iteration:8390  t-loss:0.1498, loss-lb:0.0913, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:21:34.353] iteration:8391  t-loss:0.1338, loss-lb:0.0885, loss-ulb:0.0226, weight:2.00, lr:0.0007
[11:21:34.542] iteration:8392  t-loss:0.1365, loss-lb:0.0897, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:21:34.732] iteration:8393  t-loss:0.1531, loss-lb:0.0932, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:21:34.921] iteration:8394  t-loss:0.1447, loss-lb:0.0920, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:21:35.110] iteration:8395  t-loss:0.1777, loss-lb:0.1136, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:21:35.298] iteration:8396  t-loss:0.1324, loss-lb:0.0924, loss-ulb:0.0200, weight:2.00, lr:0.0007
[11:21:35.487] iteration:8397  t-loss:0.1479, loss-lb:0.0920, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:21:35.676] iteration:8398  t-loss:0.1452, loss-lb:0.0937, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:21:35.865] iteration:8399  t-loss:0.1578, loss-lb:0.0939, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:21:36.054] iteration:8400  t-loss:0.1396, loss-lb:0.0851, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:21:36.243] iteration:8401  t-loss:0.1436, loss-lb:0.0964, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:21:36.432] iteration:8402  t-loss:0.1320, loss-lb:0.0851, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:21:36.621] iteration:8403  t-loss:0.1942, loss-lb:0.0923, loss-ulb:0.0510, weight:2.00, lr:0.0007
[11:21:36.811] iteration:8404  t-loss:0.1896, loss-lb:0.1008, loss-ulb:0.0444, weight:2.00, lr:0.0007
[11:21:37.001] iteration:8405  t-loss:0.1303, loss-lb:0.0932, loss-ulb:0.0186, weight:2.00, lr:0.0007
[11:21:37.190] iteration:8406  t-loss:0.1411, loss-lb:0.0940, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:21:37.378] iteration:8407  t-loss:0.1436, loss-lb:0.0916, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:21:37.567] iteration:8408  t-loss:0.2066, loss-lb:0.0876, loss-ulb:0.0595, weight:2.00, lr:0.0007
[11:21:37.756] iteration:8409  t-loss:0.1501, loss-lb:0.0967, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:21:37.945] iteration:8410  t-loss:0.1988, loss-lb:0.0909, loss-ulb:0.0540, weight:2.00, lr:0.0007
[11:21:38.134] iteration:8411  t-loss:0.1488, loss-lb:0.0872, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:21:38.322] iteration:8412  t-loss:0.1794, loss-lb:0.0927, loss-ulb:0.0433, weight:2.00, lr:0.0007
[11:21:38.511] iteration:8413  t-loss:0.1586, loss-lb:0.0975, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:21:38.700] iteration:8414  t-loss:0.1635, loss-lb:0.1039, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:21:38.889] iteration:8415  t-loss:0.1418, loss-lb:0.0978, loss-ulb:0.0220, weight:2.00, lr:0.0007
[11:21:39.078] iteration:8416  t-loss:0.1770, loss-lb:0.1124, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:21:39.268] iteration:8417  t-loss:0.1564, loss-lb:0.1067, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:21:39.457] iteration:8418  t-loss:0.2098, loss-lb:0.0938, loss-ulb:0.0580, weight:2.00, lr:0.0007
[11:21:39.646] iteration:8419  t-loss:0.1572, loss-lb:0.1008, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:21:39.835] iteration:8420  t-loss:0.1481, loss-lb:0.0928, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:21:40.023] iteration:8421  t-loss:0.1664, loss-lb:0.0947, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:21:40.211] iteration:8422  t-loss:0.1482, loss-lb:0.0966, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:21:40.399] iteration:8423  t-loss:0.1424, loss-lb:0.0882, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:21:40.586] iteration:8424  t-loss:0.1558, loss-lb:0.0945, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:21:40.775] iteration:8425  t-loss:0.2170, loss-lb:0.1077, loss-ulb:0.0546, weight:2.00, lr:0.0007
[11:21:40.962] iteration:8426  t-loss:0.1965, loss-lb:0.1024, loss-ulb:0.0471, weight:2.00, lr:0.0007
[11:21:41.150] iteration:8427  t-loss:0.2001, loss-lb:0.0971, loss-ulb:0.0515, weight:2.00, lr:0.0007
[11:21:41.337] iteration:8428  t-loss:0.1658, loss-lb:0.1102, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:21:41.931] iteration:8429  t-loss:0.1737, loss-lb:0.0984, loss-ulb:0.0376, weight:2.00, lr:0.0007
[11:21:42.123] iteration:8430  t-loss:0.1628, loss-lb:0.0955, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:21:42.315] iteration:8431  t-loss:0.1495, loss-lb:0.1001, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:21:42.509] iteration:8432  t-loss:0.1451, loss-lb:0.1007, loss-ulb:0.0222, weight:2.00, lr:0.0007
[11:21:42.700] iteration:8433  t-loss:0.1614, loss-lb:0.0991, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:21:42.890] iteration:8434  t-loss:0.3165, loss-lb:0.0961, loss-ulb:0.1102, weight:2.00, lr:0.0007
[11:21:43.079] iteration:8435  t-loss:0.1810, loss-lb:0.0932, loss-ulb:0.0439, weight:2.00, lr:0.0007
[11:21:43.267] iteration:8436  t-loss:0.1660, loss-lb:0.0982, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:21:43.458] iteration:8437  t-loss:0.1576, loss-lb:0.1011, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:21:43.647] iteration:8438  t-loss:0.1423, loss-lb:0.0959, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:21:43.837] iteration:8439  t-loss:0.1858, loss-lb:0.0968, loss-ulb:0.0445, weight:2.00, lr:0.0007
[11:21:44.026] iteration:8440  t-loss:0.1488, loss-lb:0.0938, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:21:44.215] iteration:8441  t-loss:0.1416, loss-lb:0.0893, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:21:44.406] iteration:8442  t-loss:0.1564, loss-lb:0.0919, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:21:44.595] iteration:8443  t-loss:0.2531, loss-lb:0.1181, loss-ulb:0.0675, weight:2.00, lr:0.0007
[11:21:44.786] iteration:8444  t-loss:0.3380, loss-lb:0.0853, loss-ulb:0.1264, weight:2.00, lr:0.0007
[11:21:44.976] iteration:8445  t-loss:0.1532, loss-lb:0.1052, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:21:45.164] iteration:8446  t-loss:0.1974, loss-lb:0.1077, loss-ulb:0.0448, weight:2.00, lr:0.0007
[11:21:45.354] iteration:8447  t-loss:0.1794, loss-lb:0.1054, loss-ulb:0.0370, weight:2.00, lr:0.0007
[11:21:45.543] iteration:8448  t-loss:0.1751, loss-lb:0.1185, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:21:45.732] iteration:8449  t-loss:0.1728, loss-lb:0.0883, loss-ulb:0.0422, weight:2.00, lr:0.0007
[11:21:45.920] iteration:8450  t-loss:0.1525, loss-lb:0.0942, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:21:46.109] iteration:8451  t-loss:0.1503, loss-lb:0.1001, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:21:46.298] iteration:8452  t-loss:0.1371, loss-lb:0.0871, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:21:46.487] iteration:8453  t-loss:0.1609, loss-lb:0.0991, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:21:46.676] iteration:8454  t-loss:0.1792, loss-lb:0.1060, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:21:46.865] iteration:8455  t-loss:0.1680, loss-lb:0.1149, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:21:47.054] iteration:8456  t-loss:0.2037, loss-lb:0.0922, loss-ulb:0.0557, weight:2.00, lr:0.0007
[11:21:47.243] iteration:8457  t-loss:0.1549, loss-lb:0.1068, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:21:47.433] iteration:8458  t-loss:0.1917, loss-lb:0.1059, loss-ulb:0.0429, weight:2.00, lr:0.0007
[11:21:47.622] iteration:8459  t-loss:0.1402, loss-lb:0.0896, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:21:47.812] iteration:8460  t-loss:0.1439, loss-lb:0.0913, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:21:48.002] iteration:8461  t-loss:0.1903, loss-lb:0.0879, loss-ulb:0.0512, weight:2.00, lr:0.0007
[11:21:48.190] iteration:8462  t-loss:0.1668, loss-lb:0.0991, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:21:48.381] iteration:8463  t-loss:0.2684, loss-lb:0.0933, loss-ulb:0.0875, weight:2.00, lr:0.0007
[11:21:48.583] iteration:8464  t-loss:0.1843, loss-lb:0.0957, loss-ulb:0.0443, weight:2.00, lr:0.0007
[11:21:48.776] iteration:8465  t-loss:0.1725, loss-lb:0.1040, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:21:48.967] iteration:8466  t-loss:0.1377, loss-lb:0.0849, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:21:49.159] iteration:8467  t-loss:0.1697, loss-lb:0.0979, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:21:49.358] iteration:8468  t-loss:0.1613, loss-lb:0.1048, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:21:49.550] iteration:8469  t-loss:0.1656, loss-lb:0.0840, loss-ulb:0.0408, weight:2.00, lr:0.0007
[11:21:49.743] iteration:8470  t-loss:0.1597, loss-lb:0.1036, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:21:49.935] iteration:8471  t-loss:0.1728, loss-lb:0.1114, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:21:50.134] iteration:8472  t-loss:0.1536, loss-lb:0.0979, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:21:50.326] iteration:8473  t-loss:0.2356, loss-lb:0.0912, loss-ulb:0.0722, weight:2.00, lr:0.0007
[11:21:50.518] iteration:8474  t-loss:0.2871, loss-lb:0.0875, loss-ulb:0.0998, weight:2.00, lr:0.0007
[11:21:50.710] iteration:8475  t-loss:0.2033, loss-lb:0.0849, loss-ulb:0.0592, weight:2.00, lr:0.0007
[11:21:50.909] iteration:8476  t-loss:0.1461, loss-lb:0.0880, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:21:51.101] iteration:8477  t-loss:0.1680, loss-lb:0.1138, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:21:51.293] iteration:8478  t-loss:0.1710, loss-lb:0.0938, loss-ulb:0.0386, weight:2.00, lr:0.0007
[11:21:51.486] iteration:8479  t-loss:0.1579, loss-lb:0.1069, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:21:51.685] iteration:8480  t-loss:0.1537, loss-lb:0.0975, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:21:51.878] iteration:8481  t-loss:0.1611, loss-lb:0.0931, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:21:52.070] iteration:8482  t-loss:0.1411, loss-lb:0.0863, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:21:52.263] iteration:8483  t-loss:0.1339, loss-lb:0.0876, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:21:52.463] iteration:8484  t-loss:0.1715, loss-lb:0.1050, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:21:52.655] iteration:8485  t-loss:0.1685, loss-lb:0.1030, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:21:52.848] iteration:8486  t-loss:0.1424, loss-lb:0.0935, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:21:53.040] iteration:8487  t-loss:0.2217, loss-lb:0.0896, loss-ulb:0.0660, weight:2.00, lr:0.0007
[11:21:53.239] iteration:8488  t-loss:0.1405, loss-lb:0.0989, loss-ulb:0.0208, weight:2.00, lr:0.0007
[11:21:53.432] iteration:8489  t-loss:0.1383, loss-lb:0.0938, loss-ulb:0.0222, weight:2.00, lr:0.0007
[11:21:53.624] iteration:8490  t-loss:0.1699, loss-lb:0.1004, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:21:53.816] iteration:8491  t-loss:0.1460, loss-lb:0.0895, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:21:54.016] iteration:8492  t-loss:0.2040, loss-lb:0.1300, loss-ulb:0.0370, weight:2.00, lr:0.0007
[11:21:54.208] iteration:8493  t-loss:0.1837, loss-lb:0.1327, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:21:54.400] iteration:8494  t-loss:0.1552, loss-lb:0.1006, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:21:54.592] iteration:8495  t-loss:0.1481, loss-lb:0.0970, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:21:54.792] iteration:8496  t-loss:0.1638, loss-lb:0.1086, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:21:54.985] iteration:8497  t-loss:0.1445, loss-lb:0.0870, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:21:55.177] iteration:8498  t-loss:0.2374, loss-lb:0.0925, loss-ulb:0.0725, weight:2.00, lr:0.0007
[11:21:55.370] iteration:8499  t-loss:0.1592, loss-lb:0.0963, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:21:55.570] iteration:8500  t-loss:0.1938, loss-lb:0.0971, loss-ulb:0.0484, weight:2.00, lr:0.0007
[11:21:55.762] iteration:8501  t-loss:0.1483, loss-lb:0.0936, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:21:55.955] iteration:8502  t-loss:0.1893, loss-lb:0.1073, loss-ulb:0.0410, weight:2.00, lr:0.0007
[11:21:56.147] iteration:8503  t-loss:0.1589, loss-lb:0.0933, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:21:56.346] iteration:8504  t-loss:0.1601, loss-lb:0.1073, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:21:56.538] iteration:8505  t-loss:0.1590, loss-lb:0.0960, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:21:56.730] iteration:8506  t-loss:0.1530, loss-lb:0.0994, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:21:56.923] iteration:8507  t-loss:0.1454, loss-lb:0.0967, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:21:57.122] iteration:8508  t-loss:0.1391, loss-lb:0.0942, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:21:57.314] iteration:8509  t-loss:0.1513, loss-lb:0.1023, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:21:57.507] iteration:8510  t-loss:0.1586, loss-lb:0.1028, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:21:57.701] iteration:8511  t-loss:0.2261, loss-lb:0.1015, loss-ulb:0.0623, weight:2.00, lr:0.0007
[11:21:57.900] iteration:8512  t-loss:0.1418, loss-lb:0.0819, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:21:58.093] iteration:8513  t-loss:0.1613, loss-lb:0.1019, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:21:58.286] iteration:8514  t-loss:0.1440, loss-lb:0.0841, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:21:58.479] iteration:8515  t-loss:0.1586, loss-lb:0.0956, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:21:58.679] iteration:8516  t-loss:0.1587, loss-lb:0.0934, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:21:58.870] iteration:8517  t-loss:0.1499, loss-lb:0.0963, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:21:59.063] iteration:8518  t-loss:0.1527, loss-lb:0.1016, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:21:59.256] iteration:8519  t-loss:0.1455, loss-lb:0.0920, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:21:59.447] iteration:8520  t-loss:0.1539, loss-lb:0.0979, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:21:59.638] iteration:8521  t-loss:0.1390, loss-lb:0.0899, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:21:59.830] iteration:8522  t-loss:0.1945, loss-lb:0.1013, loss-ulb:0.0466, weight:2.00, lr:0.0007
[11:22:00.021] iteration:8523  t-loss:0.1703, loss-lb:0.0824, loss-ulb:0.0440, weight:2.00, lr:0.0007
[11:22:00.212] iteration:8524  t-loss:0.1474, loss-lb:0.0927, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:22:00.401] iteration:8525  t-loss:0.1436, loss-lb:0.1016, loss-ulb:0.0210, weight:2.00, lr:0.0007
[11:22:00.592] iteration:8526  t-loss:0.1468, loss-lb:0.0879, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:22:30.200]  <<Test>> - Ep:86  - mean_dice/mean_h95 - S:89.45/2.24, Best-S:90.28, T:90.17/1.36, Best-T:90.48
[11:22:30.200]           - AvgLoss(lb/ulb/all):0.0977/0.0308/0.1564
[11:22:30.729] iteration:8527  t-loss:0.1457, loss-lb:0.0954, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:22:30.925] iteration:8528  t-loss:0.1437, loss-lb:0.0852, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:22:31.116] iteration:8529  t-loss:0.1497, loss-lb:0.0956, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:22:31.308] iteration:8530  t-loss:0.1941, loss-lb:0.0978, loss-ulb:0.0481, weight:2.00, lr:0.0007
[11:22:31.503] iteration:8531  t-loss:0.1853, loss-lb:0.1143, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:22:31.696] iteration:8532  t-loss:0.1381, loss-lb:0.0881, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:22:31.891] iteration:8533  t-loss:0.1468, loss-lb:0.0894, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:22:32.082] iteration:8534  t-loss:0.1475, loss-lb:0.0947, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:22:32.275] iteration:8535  t-loss:0.1437, loss-lb:0.0989, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:22:32.466] iteration:8536  t-loss:0.1509, loss-lb:0.0953, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:22:32.659] iteration:8537  t-loss:0.1696, loss-lb:0.0981, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:22:32.852] iteration:8538  t-loss:0.2432, loss-lb:0.1209, loss-ulb:0.0611, weight:2.00, lr:0.0007
[11:22:33.043] iteration:8539  t-loss:0.1929, loss-lb:0.1017, loss-ulb:0.0456, weight:2.00, lr:0.0007
[11:22:33.235] iteration:8540  t-loss:0.2274, loss-lb:0.0954, loss-ulb:0.0660, weight:2.00, lr:0.0007
[11:22:33.427] iteration:8541  t-loss:0.1557, loss-lb:0.0866, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:22:33.621] iteration:8542  t-loss:0.1926, loss-lb:0.0881, loss-ulb:0.0523, weight:2.00, lr:0.0007
[11:22:33.813] iteration:8543  t-loss:0.1586, loss-lb:0.1053, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:22:34.006] iteration:8544  t-loss:0.1581, loss-lb:0.0955, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:22:34.197] iteration:8545  t-loss:0.1497, loss-lb:0.0980, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:22:34.390] iteration:8546  t-loss:0.1456, loss-lb:0.0875, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:22:34.583] iteration:8547  t-loss:0.1468, loss-lb:0.0858, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:22:34.776] iteration:8548  t-loss:0.1808, loss-lb:0.1308, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:22:34.973] iteration:8549  t-loss:0.1610, loss-lb:0.0890, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:22:35.166] iteration:8550  t-loss:0.1323, loss-lb:0.0835, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:22:35.361] iteration:8551  t-loss:0.3214, loss-lb:0.1156, loss-ulb:0.1029, weight:2.00, lr:0.0007
[11:22:35.555] iteration:8552  t-loss:0.1524, loss-lb:0.0982, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:22:35.748] iteration:8553  t-loss:0.1788, loss-lb:0.1258, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:22:35.940] iteration:8554  t-loss:0.1726, loss-lb:0.1000, loss-ulb:0.0363, weight:2.00, lr:0.0007
[11:22:36.133] iteration:8555  t-loss:0.1583, loss-lb:0.0971, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:22:36.325] iteration:8556  t-loss:0.1554, loss-lb:0.0936, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:22:36.517] iteration:8557  t-loss:0.2472, loss-lb:0.0871, loss-ulb:0.0801, weight:2.00, lr:0.0007
[11:22:36.709] iteration:8558  t-loss:0.1548, loss-lb:0.1047, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:22:36.901] iteration:8559  t-loss:0.1564, loss-lb:0.0885, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:22:37.094] iteration:8560  t-loss:0.1900, loss-lb:0.1040, loss-ulb:0.0430, weight:2.00, lr:0.0007
[11:22:37.286] iteration:8561  t-loss:0.2545, loss-lb:0.1696, loss-ulb:0.0425, weight:2.00, lr:0.0007
[11:22:37.479] iteration:8562  t-loss:0.2934, loss-lb:0.1335, loss-ulb:0.0799, weight:2.00, lr:0.0007
[11:22:37.671] iteration:8563  t-loss:0.1789, loss-lb:0.0960, loss-ulb:0.0414, weight:2.00, lr:0.0007
[11:22:37.863] iteration:8564  t-loss:0.1689, loss-lb:0.0934, loss-ulb:0.0377, weight:2.00, lr:0.0007
[11:22:38.055] iteration:8565  t-loss:0.1761, loss-lb:0.1040, loss-ulb:0.0361, weight:2.00, lr:0.0007
[11:22:38.248] iteration:8566  t-loss:0.1764, loss-lb:0.0986, loss-ulb:0.0389, weight:2.00, lr:0.0007
[11:22:38.440] iteration:8567  t-loss:0.1560, loss-lb:0.0923, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:22:38.632] iteration:8568  t-loss:0.1599, loss-lb:0.0999, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:22:38.825] iteration:8569  t-loss:0.1639, loss-lb:0.0913, loss-ulb:0.0363, weight:2.00, lr:0.0007
[11:22:39.016] iteration:8570  t-loss:0.1637, loss-lb:0.0975, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:22:39.211] iteration:8571  t-loss:0.1841, loss-lb:0.1170, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:22:39.403] iteration:8572  t-loss:0.1476, loss-lb:0.0903, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:22:39.595] iteration:8573  t-loss:0.1633, loss-lb:0.1116, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:22:39.787] iteration:8574  t-loss:0.1809, loss-lb:0.0948, loss-ulb:0.0430, weight:2.00, lr:0.0007
[11:22:39.980] iteration:8575  t-loss:0.1713, loss-lb:0.0953, loss-ulb:0.0380, weight:2.00, lr:0.0007
[11:22:40.172] iteration:8576  t-loss:0.1507, loss-lb:0.0980, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:22:40.364] iteration:8577  t-loss:0.1829, loss-lb:0.1055, loss-ulb:0.0387, weight:2.00, lr:0.0007
[11:22:40.558] iteration:8578  t-loss:0.1914, loss-lb:0.1035, loss-ulb:0.0440, weight:2.00, lr:0.0007
[11:22:40.750] iteration:8579  t-loss:0.1648, loss-lb:0.0985, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:22:40.942] iteration:8580  t-loss:0.1480, loss-lb:0.0894, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:22:41.134] iteration:8581  t-loss:0.1526, loss-lb:0.0922, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:22:41.327] iteration:8582  t-loss:0.1534, loss-lb:0.0924, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:22:41.520] iteration:8583  t-loss:0.1423, loss-lb:0.0968, loss-ulb:0.0227, weight:2.00, lr:0.0007
[11:22:41.712] iteration:8584  t-loss:0.1447, loss-lb:0.0958, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:22:41.904] iteration:8585  t-loss:0.1525, loss-lb:0.1004, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:22:42.098] iteration:8586  t-loss:0.1461, loss-lb:0.1012, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:22:42.290] iteration:8587  t-loss:0.1573, loss-lb:0.0980, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:22:42.485] iteration:8588  t-loss:0.1453, loss-lb:0.0914, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:22:42.678] iteration:8589  t-loss:0.1422, loss-lb:0.0952, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:22:42.871] iteration:8590  t-loss:0.1411, loss-lb:0.0965, loss-ulb:0.0223, weight:2.00, lr:0.0007
[11:22:43.064] iteration:8591  t-loss:0.1506, loss-lb:0.0969, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:22:43.255] iteration:8592  t-loss:0.1324, loss-lb:0.0873, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:22:43.448] iteration:8593  t-loss:0.1619, loss-lb:0.1137, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:22:43.641] iteration:8594  t-loss:0.1533, loss-lb:0.0946, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:22:43.833] iteration:8595  t-loss:0.2145, loss-lb:0.0849, loss-ulb:0.0648, weight:2.00, lr:0.0007
[11:22:44.025] iteration:8596  t-loss:0.1304, loss-lb:0.0910, loss-ulb:0.0197, weight:2.00, lr:0.0007
[11:22:44.217] iteration:8597  t-loss:0.1751, loss-lb:0.0911, loss-ulb:0.0420, weight:2.00, lr:0.0007
[11:22:44.409] iteration:8598  t-loss:0.1348, loss-lb:0.0845, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:22:44.603] iteration:8599  t-loss:0.1573, loss-lb:0.0953, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:22:44.794] iteration:8600  t-loss:0.1415, loss-lb:0.0966, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:22:44.986] iteration:8601  t-loss:0.1648, loss-lb:0.1097, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:22:45.179] iteration:8602  t-loss:0.1606, loss-lb:0.0906, loss-ulb:0.0350, weight:2.00, lr:0.0007
[11:22:45.371] iteration:8603  t-loss:0.1933, loss-lb:0.0937, loss-ulb:0.0498, weight:2.00, lr:0.0007
[11:22:45.565] iteration:8604  t-loss:0.1496, loss-lb:0.0944, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:22:45.761] iteration:8605  t-loss:0.1965, loss-lb:0.1014, loss-ulb:0.0476, weight:2.00, lr:0.0007
[11:22:45.953] iteration:8606  t-loss:0.1385, loss-lb:0.0901, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:22:46.149] iteration:8607  t-loss:0.1580, loss-lb:0.0853, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:22:46.343] iteration:8608  t-loss:0.1509, loss-lb:0.0918, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:22:46.536] iteration:8609  t-loss:0.1613, loss-lb:0.1022, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:22:46.729] iteration:8610  t-loss:0.1403, loss-lb:0.0881, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:22:46.922] iteration:8611  t-loss:0.1399, loss-lb:0.0851, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:22:47.114] iteration:8612  t-loss:0.2007, loss-lb:0.0897, loss-ulb:0.0555, weight:2.00, lr:0.0007
[11:22:47.306] iteration:8613  t-loss:0.1661, loss-lb:0.0987, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:22:47.499] iteration:8614  t-loss:0.2031, loss-lb:0.1206, loss-ulb:0.0412, weight:2.00, lr:0.0007
[11:22:47.692] iteration:8615  t-loss:0.1537, loss-lb:0.1018, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:22:47.897] iteration:8616  t-loss:0.1342, loss-lb:0.0885, loss-ulb:0.0228, weight:2.00, lr:0.0007
[11:22:48.094] iteration:8617  t-loss:0.1453, loss-lb:0.0935, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:22:48.289] iteration:8618  t-loss:0.2128, loss-lb:0.1065, loss-ulb:0.0531, weight:2.00, lr:0.0007
[11:22:48.481] iteration:8619  t-loss:0.1945, loss-lb:0.1042, loss-ulb:0.0452, weight:2.00, lr:0.0007
[11:22:48.672] iteration:8620  t-loss:0.1452, loss-lb:0.0935, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:22:48.864] iteration:8621  t-loss:0.1387, loss-lb:0.0790, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:22:49.055] iteration:8622  t-loss:0.1450, loss-lb:0.0995, loss-ulb:0.0227, weight:2.00, lr:0.0007
[11:22:49.248] iteration:8623  t-loss:0.1375, loss-lb:0.0822, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:22:49.439] iteration:8624  t-loss:0.1605, loss-lb:0.1022, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:22:50.019] iteration:8625  t-loss:0.1439, loss-lb:0.0933, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:22:50.214] iteration:8626  t-loss:0.1722, loss-lb:0.1186, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:22:50.407] iteration:8627  t-loss:0.1430, loss-lb:0.1004, loss-ulb:0.0213, weight:2.00, lr:0.0007
[11:22:50.600] iteration:8628  t-loss:0.1461, loss-lb:0.0906, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:22:50.792] iteration:8629  t-loss:0.1363, loss-lb:0.0913, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:22:50.985] iteration:8630  t-loss:0.1928, loss-lb:0.0930, loss-ulb:0.0499, weight:2.00, lr:0.0007
[11:22:51.178] iteration:8631  t-loss:0.1626, loss-lb:0.0975, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:22:51.371] iteration:8632  t-loss:0.1586, loss-lb:0.0941, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:22:51.563] iteration:8633  t-loss:0.1564, loss-lb:0.0934, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:22:51.754] iteration:8634  t-loss:0.1496, loss-lb:0.0966, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:22:51.946] iteration:8635  t-loss:0.1442, loss-lb:0.0898, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:22:52.138] iteration:8636  t-loss:0.1452, loss-lb:0.0905, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:22:52.332] iteration:8637  t-loss:0.1650, loss-lb:0.0953, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:22:52.523] iteration:8638  t-loss:0.1712, loss-lb:0.0934, loss-ulb:0.0389, weight:2.00, lr:0.0007
[11:22:52.715] iteration:8639  t-loss:0.1950, loss-lb:0.0860, loss-ulb:0.0545, weight:2.00, lr:0.0007
[11:22:52.907] iteration:8640  t-loss:0.1520, loss-lb:0.0973, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:22:53.099] iteration:8641  t-loss:0.1701, loss-lb:0.1031, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:22:53.293] iteration:8642  t-loss:0.2204, loss-lb:0.0859, loss-ulb:0.0672, weight:2.00, lr:0.0007
[11:22:53.485] iteration:8643  t-loss:0.1499, loss-lb:0.1081, loss-ulb:0.0209, weight:2.00, lr:0.0007
[11:22:53.676] iteration:8644  t-loss:0.1375, loss-lb:0.0897, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:22:53.868] iteration:8645  t-loss:0.2063, loss-lb:0.0931, loss-ulb:0.0566, weight:2.00, lr:0.0007
[11:22:54.059] iteration:8646  t-loss:0.1694, loss-lb:0.0948, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:22:54.250] iteration:8647  t-loss:0.1379, loss-lb:0.0910, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:22:54.442] iteration:8648  t-loss:0.1463, loss-lb:0.0993, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:22:54.633] iteration:8649  t-loss:0.1499, loss-lb:0.0934, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:22:54.825] iteration:8650  t-loss:0.1540, loss-lb:0.0934, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:22:55.017] iteration:8651  t-loss:0.1505, loss-lb:0.0949, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:22:55.208] iteration:8652  t-loss:0.1635, loss-lb:0.0931, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:22:55.399] iteration:8653  t-loss:0.1411, loss-lb:0.0922, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:22:55.592] iteration:8654  t-loss:0.2739, loss-lb:0.0954, loss-ulb:0.0892, weight:2.00, lr:0.0007
[11:22:55.783] iteration:8655  t-loss:0.1533, loss-lb:0.0825, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:22:55.974] iteration:8656  t-loss:0.1496, loss-lb:0.0993, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:22:56.166] iteration:8657  t-loss:0.1408, loss-lb:0.0867, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:22:56.358] iteration:8658  t-loss:0.1483, loss-lb:0.0868, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:22:56.550] iteration:8659  t-loss:0.1790, loss-lb:0.0990, loss-ulb:0.0400, weight:2.00, lr:0.0007
[11:22:56.744] iteration:8660  t-loss:0.1448, loss-lb:0.0888, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:22:56.938] iteration:8661  t-loss:0.1559, loss-lb:0.0878, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:22:57.129] iteration:8662  t-loss:0.1363, loss-lb:0.0826, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:22:57.323] iteration:8663  t-loss:0.1861, loss-lb:0.1003, loss-ulb:0.0429, weight:2.00, lr:0.0007
[11:22:57.516] iteration:8664  t-loss:0.1484, loss-lb:0.0922, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:22:57.707] iteration:8665  t-loss:0.1703, loss-lb:0.1023, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:22:57.900] iteration:8666  t-loss:0.1755, loss-lb:0.0938, loss-ulb:0.0409, weight:2.00, lr:0.0007
[11:22:58.093] iteration:8667  t-loss:0.1616, loss-lb:0.1074, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:22:58.285] iteration:8668  t-loss:0.1526, loss-lb:0.0915, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:22:58.476] iteration:8669  t-loss:0.1461, loss-lb:0.0826, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:22:58.670] iteration:8670  t-loss:0.1769, loss-lb:0.0897, loss-ulb:0.0436, weight:2.00, lr:0.0007
[11:22:58.863] iteration:8671  t-loss:0.1424, loss-lb:0.0945, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:22:59.055] iteration:8672  t-loss:0.1435, loss-lb:0.0827, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:22:59.249] iteration:8673  t-loss:0.1603, loss-lb:0.0858, loss-ulb:0.0372, weight:2.00, lr:0.0007
[11:22:59.442] iteration:8674  t-loss:0.1363, loss-lb:0.0895, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:22:59.634] iteration:8675  t-loss:0.1550, loss-lb:0.1027, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:22:59.826] iteration:8676  t-loss:0.1420, loss-lb:0.0885, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:23:00.020] iteration:8677  t-loss:0.1503, loss-lb:0.0929, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:23:00.213] iteration:8678  t-loss:0.1534, loss-lb:0.0897, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:23:00.405] iteration:8679  t-loss:0.1390, loss-lb:0.0923, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:23:00.596] iteration:8680  t-loss:0.1410, loss-lb:0.0951, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:23:00.789] iteration:8681  t-loss:0.1559, loss-lb:0.0952, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:23:00.982] iteration:8682  t-loss:0.1975, loss-lb:0.0961, loss-ulb:0.0507, weight:2.00, lr:0.0007
[11:23:01.174] iteration:8683  t-loss:0.1479, loss-lb:0.1040, loss-ulb:0.0220, weight:2.00, lr:0.0007
[11:23:01.367] iteration:8684  t-loss:0.1400, loss-lb:0.0923, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:23:01.559] iteration:8685  t-loss:0.1493, loss-lb:0.0900, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:23:01.752] iteration:8686  t-loss:0.1316, loss-lb:0.0818, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:23:01.943] iteration:8687  t-loss:0.1473, loss-lb:0.0850, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:23:02.136] iteration:8688  t-loss:0.1576, loss-lb:0.1031, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:23:02.328] iteration:8689  t-loss:0.2712, loss-lb:0.1304, loss-ulb:0.0704, weight:2.00, lr:0.0007
[11:23:02.520] iteration:8690  t-loss:0.1687, loss-lb:0.0903, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:23:02.712] iteration:8691  t-loss:0.1373, loss-lb:0.0971, loss-ulb:0.0201, weight:2.00, lr:0.0007
[11:23:02.905] iteration:8692  t-loss:0.1796, loss-lb:0.0978, loss-ulb:0.0409, weight:2.00, lr:0.0007
[11:23:03.097] iteration:8693  t-loss:0.1678, loss-lb:0.0971, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:23:03.289] iteration:8694  t-loss:0.1797, loss-lb:0.0914, loss-ulb:0.0442, weight:2.00, lr:0.0007
[11:23:03.482] iteration:8695  t-loss:0.1897, loss-lb:0.1080, loss-ulb:0.0408, weight:2.00, lr:0.0007
[11:23:03.675] iteration:8696  t-loss:0.1791, loss-lb:0.1174, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:23:03.866] iteration:8697  t-loss:0.2270, loss-lb:0.1502, loss-ulb:0.0384, weight:2.00, lr:0.0007
[11:23:04.059] iteration:8698  t-loss:0.1612, loss-lb:0.1047, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:23:04.252] iteration:8699  t-loss:0.2072, loss-lb:0.1097, loss-ulb:0.0488, weight:2.00, lr:0.0007
[11:23:04.444] iteration:8700  t-loss:0.1735, loss-lb:0.1081, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:23:04.635] iteration:8701  t-loss:0.1659, loss-lb:0.0904, loss-ulb:0.0377, weight:2.00, lr:0.0007
[11:23:04.828] iteration:8702  t-loss:0.2006, loss-lb:0.0948, loss-ulb:0.0529, weight:2.00, lr:0.0007
[11:23:05.020] iteration:8703  t-loss:0.2026, loss-lb:0.1091, loss-ulb:0.0467, weight:2.00, lr:0.0007
[11:23:05.214] iteration:8704  t-loss:0.1641, loss-lb:0.1003, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:23:05.407] iteration:8705  t-loss:0.1791, loss-lb:0.1128, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:23:05.600] iteration:8706  t-loss:0.1796, loss-lb:0.1138, loss-ulb:0.0329, weight:2.00, lr:0.0007
[11:23:05.792] iteration:8707  t-loss:0.1576, loss-lb:0.1074, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:23:05.985] iteration:8708  t-loss:0.1759, loss-lb:0.0996, loss-ulb:0.0381, weight:2.00, lr:0.0007
[11:23:06.177] iteration:8709  t-loss:0.1604, loss-lb:0.1024, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:23:06.368] iteration:8710  t-loss:0.1490, loss-lb:0.0903, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:23:06.561] iteration:8711  t-loss:0.1406, loss-lb:0.0951, loss-ulb:0.0227, weight:2.00, lr:0.0007
[11:23:06.754] iteration:8712  t-loss:0.1660, loss-lb:0.0976, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:23:06.946] iteration:8713  t-loss:0.1695, loss-lb:0.0914, loss-ulb:0.0390, weight:2.00, lr:0.0007
[11:23:07.140] iteration:8714  t-loss:0.1682, loss-lb:0.1103, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:23:07.332] iteration:8715  t-loss:0.1774, loss-lb:0.0991, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:23:07.522] iteration:8716  t-loss:0.1605, loss-lb:0.0985, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:23:07.712] iteration:8717  t-loss:0.1699, loss-lb:0.1038, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:23:07.903] iteration:8718  t-loss:0.1837, loss-lb:0.1034, loss-ulb:0.0401, weight:2.00, lr:0.0007
[11:23:08.093] iteration:8719  t-loss:0.1765, loss-lb:0.0869, loss-ulb:0.0448, weight:2.00, lr:0.0007
[11:23:08.284] iteration:8720  t-loss:0.1652, loss-lb:0.1002, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:23:08.474] iteration:8721  t-loss:0.1649, loss-lb:0.1128, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:23:08.664] iteration:8722  t-loss:0.1675, loss-lb:0.0939, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:23:19.683]  <<Test>> - Ep:88  - mean_dice/mean_h95 - S:90.05/1.29, Best-S:90.28, T:90.13/1.41, Best-T:90.48
[11:23:19.683]           - AvgLoss(lb/ulb/all):0.0969/0.0337/0.1689
[11:23:20.210] iteration:8723  t-loss:0.1745, loss-lb:0.1060, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:23:20.409] iteration:8724  t-loss:0.1453, loss-lb:0.0927, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:23:20.608] iteration:8725  t-loss:0.1565, loss-lb:0.0967, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:23:20.813] iteration:8726  t-loss:0.1582, loss-lb:0.1060, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:23:21.011] iteration:8727  t-loss:0.1414, loss-lb:0.0927, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:23:21.204] iteration:8728  t-loss:0.2315, loss-lb:0.1087, loss-ulb:0.0614, weight:2.00, lr:0.0007
[11:23:21.397] iteration:8729  t-loss:0.1477, loss-lb:0.0905, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:23:21.589] iteration:8730  t-loss:0.1488, loss-lb:0.0911, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:23:21.783] iteration:8731  t-loss:0.1444, loss-lb:0.0917, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:23:21.977] iteration:8732  t-loss:0.1314, loss-lb:0.0850, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:23:22.169] iteration:8733  t-loss:0.1552, loss-lb:0.0999, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:23:22.362] iteration:8734  t-loss:0.1569, loss-lb:0.0923, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:23:22.555] iteration:8735  t-loss:0.1481, loss-lb:0.0982, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:23:22.748] iteration:8736  t-loss:0.1471, loss-lb:0.0944, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:23:22.941] iteration:8737  t-loss:0.1437, loss-lb:0.0904, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:23:23.134] iteration:8738  t-loss:0.1418, loss-lb:0.0915, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:23:23.327] iteration:8739  t-loss:0.1859, loss-lb:0.1028, loss-ulb:0.0416, weight:2.00, lr:0.0007
[11:23:23.521] iteration:8740  t-loss:0.1488, loss-lb:0.0987, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:23:23.713] iteration:8741  t-loss:0.1448, loss-lb:0.0948, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:23:23.905] iteration:8742  t-loss:0.2045, loss-lb:0.1488, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:23:24.099] iteration:8743  t-loss:0.1454, loss-lb:0.0887, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:23:24.292] iteration:8744  t-loss:0.1594, loss-lb:0.0962, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:23:24.484] iteration:8745  t-loss:0.1542, loss-lb:0.0907, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:23:24.677] iteration:8746  t-loss:0.1358, loss-lb:0.0821, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:23:24.871] iteration:8747  t-loss:0.3029, loss-lb:0.0962, loss-ulb:0.1033, weight:2.00, lr:0.0007
[11:23:25.064] iteration:8748  t-loss:0.1579, loss-lb:0.0937, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:23:25.258] iteration:8749  t-loss:0.1952, loss-lb:0.1059, loss-ulb:0.0447, weight:2.00, lr:0.0007
[11:23:25.450] iteration:8750  t-loss:0.1671, loss-lb:0.0917, loss-ulb:0.0377, weight:2.00, lr:0.0007
[11:23:25.643] iteration:8751  t-loss:0.2250, loss-lb:0.1815, loss-ulb:0.0217, weight:2.00, lr:0.0007
[11:23:25.836] iteration:8752  t-loss:0.1560, loss-lb:0.0973, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:23:26.030] iteration:8753  t-loss:0.2106, loss-lb:0.0908, loss-ulb:0.0599, weight:2.00, lr:0.0007
[11:23:26.223] iteration:8754  t-loss:0.1427, loss-lb:0.0954, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:23:26.416] iteration:8755  t-loss:0.1632, loss-lb:0.0917, loss-ulb:0.0357, weight:2.00, lr:0.0007
[11:23:26.609] iteration:8756  t-loss:0.1735, loss-lb:0.0952, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:23:26.803] iteration:8757  t-loss:0.1525, loss-lb:0.0888, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:23:26.995] iteration:8758  t-loss:0.1698, loss-lb:0.0911, loss-ulb:0.0394, weight:2.00, lr:0.0007
[11:23:27.188] iteration:8759  t-loss:0.1549, loss-lb:0.0972, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:23:27.381] iteration:8760  t-loss:0.1455, loss-lb:0.0970, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:23:27.574] iteration:8761  t-loss:0.1511, loss-lb:0.0978, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:23:27.766] iteration:8762  t-loss:0.1416, loss-lb:0.0907, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:23:27.959] iteration:8763  t-loss:0.1494, loss-lb:0.0931, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:23:28.150] iteration:8764  t-loss:0.1934, loss-lb:0.0998, loss-ulb:0.0468, weight:2.00, lr:0.0007
[11:23:28.343] iteration:8765  t-loss:0.1344, loss-lb:0.0885, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:23:28.536] iteration:8766  t-loss:0.1560, loss-lb:0.0961, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:23:28.728] iteration:8767  t-loss:0.1819, loss-lb:0.1051, loss-ulb:0.0384, weight:2.00, lr:0.0007
[11:23:28.920] iteration:8768  t-loss:0.1544, loss-lb:0.0941, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:23:29.112] iteration:8769  t-loss:0.1784, loss-lb:0.0985, loss-ulb:0.0400, weight:2.00, lr:0.0007
[11:23:29.306] iteration:8770  t-loss:0.2760, loss-lb:0.0819, loss-ulb:0.0970, weight:2.00, lr:0.0007
[11:23:29.498] iteration:8771  t-loss:0.1611, loss-lb:0.0975, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:23:29.690] iteration:8772  t-loss:0.1687, loss-lb:0.0981, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:23:29.882] iteration:8773  t-loss:0.1420, loss-lb:0.0931, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:23:30.075] iteration:8774  t-loss:0.1502, loss-lb:0.1041, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:23:30.267] iteration:8775  t-loss:0.1437, loss-lb:0.0900, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:23:30.459] iteration:8776  t-loss:0.1587, loss-lb:0.0871, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:23:30.654] iteration:8777  t-loss:0.1486, loss-lb:0.0869, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:23:30.846] iteration:8778  t-loss:0.1607, loss-lb:0.0975, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:23:31.039] iteration:8779  t-loss:0.1523, loss-lb:0.0882, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:23:31.230] iteration:8780  t-loss:0.1758, loss-lb:0.0945, loss-ulb:0.0407, weight:2.00, lr:0.0007
[11:23:31.423] iteration:8781  t-loss:0.1528, loss-lb:0.0957, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:23:31.616] iteration:8782  t-loss:0.2325, loss-lb:0.0877, loss-ulb:0.0724, weight:2.00, lr:0.0007
[11:23:31.809] iteration:8783  t-loss:0.1536, loss-lb:0.0893, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:23:32.001] iteration:8784  t-loss:0.1496, loss-lb:0.0878, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:23:32.193] iteration:8785  t-loss:0.1347, loss-lb:0.0836, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:23:32.385] iteration:8786  t-loss:0.1465, loss-lb:0.0931, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:23:32.578] iteration:8787  t-loss:0.1608, loss-lb:0.0991, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:23:32.770] iteration:8788  t-loss:0.1576, loss-lb:0.0975, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:23:32.962] iteration:8789  t-loss:0.1473, loss-lb:0.1041, loss-ulb:0.0216, weight:2.00, lr:0.0007
[11:23:33.154] iteration:8790  t-loss:0.1585, loss-lb:0.0954, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:23:33.346] iteration:8791  t-loss:0.1427, loss-lb:0.0918, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:23:33.537] iteration:8792  t-loss:0.1389, loss-lb:0.0883, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:23:33.729] iteration:8793  t-loss:0.1934, loss-lb:0.0964, loss-ulb:0.0485, weight:2.00, lr:0.0007
[11:23:33.921] iteration:8794  t-loss:0.2487, loss-lb:0.1272, loss-ulb:0.0607, weight:2.00, lr:0.0007
[11:23:34.114] iteration:8795  t-loss:0.1385, loss-lb:0.0901, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:23:34.306] iteration:8796  t-loss:0.1396, loss-lb:0.0920, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:23:34.498] iteration:8797  t-loss:0.1602, loss-lb:0.1076, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:23:34.690] iteration:8798  t-loss:0.1412, loss-lb:0.0962, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:23:34.882] iteration:8799  t-loss:0.1691, loss-lb:0.0970, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:23:35.075] iteration:8800  t-loss:0.1519, loss-lb:0.0877, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:23:35.266] iteration:8801  t-loss:0.1680, loss-lb:0.1087, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:23:35.458] iteration:8802  t-loss:0.1531, loss-lb:0.0931, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:23:35.650] iteration:8803  t-loss:0.1374, loss-lb:0.0877, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:23:35.843] iteration:8804  t-loss:0.2045, loss-lb:0.1101, loss-ulb:0.0472, weight:2.00, lr:0.0007
[11:23:36.035] iteration:8805  t-loss:0.1825, loss-lb:0.1047, loss-ulb:0.0389, weight:2.00, lr:0.0007
[11:23:36.228] iteration:8806  t-loss:0.1348, loss-lb:0.0884, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:23:36.419] iteration:8807  t-loss:0.1513, loss-lb:0.0907, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:23:36.612] iteration:8808  t-loss:0.1524, loss-lb:0.0815, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:23:36.805] iteration:8809  t-loss:0.1602, loss-lb:0.1011, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:23:36.997] iteration:8810  t-loss:0.1493, loss-lb:0.0994, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:23:37.189] iteration:8811  t-loss:0.1575, loss-lb:0.1088, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:23:37.383] iteration:8812  t-loss:0.1466, loss-lb:0.0866, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:23:37.574] iteration:8813  t-loss:0.1635, loss-lb:0.0965, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:23:37.765] iteration:8814  t-loss:0.1923, loss-lb:0.0954, loss-ulb:0.0485, weight:2.00, lr:0.0007
[11:23:37.956] iteration:8815  t-loss:0.1593, loss-lb:0.0908, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:23:38.146] iteration:8816  t-loss:0.2660, loss-lb:0.0916, loss-ulb:0.0872, weight:2.00, lr:0.0007
[11:23:38.337] iteration:8817  t-loss:0.1447, loss-lb:0.0884, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:23:38.528] iteration:8818  t-loss:0.1363, loss-lb:0.0840, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:23:38.719] iteration:8819  t-loss:0.1546, loss-lb:0.0979, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:23:38.909] iteration:8820  t-loss:0.1388, loss-lb:0.0898, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:23:39.511] iteration:8821  t-loss:0.1522, loss-lb:0.0983, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:23:39.706] iteration:8822  t-loss:0.1453, loss-lb:0.0945, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:23:39.898] iteration:8823  t-loss:0.1408, loss-lb:0.0915, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:23:40.090] iteration:8824  t-loss:0.1796, loss-lb:0.1053, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:23:40.283] iteration:8825  t-loss:0.2095, loss-lb:0.1003, loss-ulb:0.0546, weight:2.00, lr:0.0007
[11:23:40.477] iteration:8826  t-loss:0.1921, loss-lb:0.0939, loss-ulb:0.0491, weight:2.00, lr:0.0007
[11:23:40.670] iteration:8827  t-loss:0.1850, loss-lb:0.0955, loss-ulb:0.0448, weight:2.00, lr:0.0007
[11:23:40.862] iteration:8828  t-loss:0.1617, loss-lb:0.1022, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:23:41.055] iteration:8829  t-loss:0.1583, loss-lb:0.1034, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:23:41.248] iteration:8830  t-loss:0.1991, loss-lb:0.1424, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:23:41.439] iteration:8831  t-loss:0.1634, loss-lb:0.1050, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:23:41.632] iteration:8832  t-loss:0.1406, loss-lb:0.0891, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:23:41.826] iteration:8833  t-loss:0.2429, loss-lb:0.0963, loss-ulb:0.0733, weight:2.00, lr:0.0007
[11:23:42.019] iteration:8834  t-loss:0.3202, loss-lb:0.1548, loss-ulb:0.0827, weight:2.00, lr:0.0007
[11:23:42.215] iteration:8835  t-loss:0.1640, loss-lb:0.1059, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:23:42.408] iteration:8836  t-loss:0.1618, loss-lb:0.1027, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:23:42.600] iteration:8837  t-loss:0.1608, loss-lb:0.1116, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:23:42.793] iteration:8838  t-loss:0.1570, loss-lb:0.1026, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:23:42.985] iteration:8839  t-loss:0.2058, loss-lb:0.1122, loss-ulb:0.0468, weight:2.00, lr:0.0007
[11:23:43.177] iteration:8840  t-loss:0.2037, loss-lb:0.0989, loss-ulb:0.0524, weight:2.00, lr:0.0007
[11:23:43.371] iteration:8841  t-loss:0.2612, loss-lb:0.1215, loss-ulb:0.0699, weight:2.00, lr:0.0007
[11:23:43.563] iteration:8842  t-loss:0.1710, loss-lb:0.0992, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:23:43.756] iteration:8843  t-loss:0.1935, loss-lb:0.0944, loss-ulb:0.0495, weight:2.00, lr:0.0007
[11:23:43.949] iteration:8844  t-loss:0.1506, loss-lb:0.1048, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:23:44.141] iteration:8845  t-loss:0.1998, loss-lb:0.0978, loss-ulb:0.0510, weight:2.00, lr:0.0007
[11:23:44.334] iteration:8846  t-loss:0.1605, loss-lb:0.0982, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:23:44.526] iteration:8847  t-loss:0.1538, loss-lb:0.1034, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:23:44.719] iteration:8848  t-loss:0.2473, loss-lb:0.1697, loss-ulb:0.0388, weight:2.00, lr:0.0007
[11:23:44.912] iteration:8849  t-loss:0.1576, loss-lb:0.0902, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:23:45.103] iteration:8850  t-loss:0.2416, loss-lb:0.0967, loss-ulb:0.0724, weight:2.00, lr:0.0007
[11:23:45.296] iteration:8851  t-loss:0.1530, loss-lb:0.0933, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:23:45.490] iteration:8852  t-loss:0.1837, loss-lb:0.1289, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:23:45.682] iteration:8853  t-loss:0.1728, loss-lb:0.0905, loss-ulb:0.0411, weight:2.00, lr:0.0007
[11:23:45.875] iteration:8854  t-loss:0.2791, loss-lb:0.0932, loss-ulb:0.0930, weight:2.00, lr:0.0007
[11:23:46.066] iteration:8855  t-loss:0.1972, loss-lb:0.0933, loss-ulb:0.0519, weight:2.00, lr:0.0007
[11:23:46.258] iteration:8856  t-loss:0.1454, loss-lb:0.0919, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:23:46.450] iteration:8857  t-loss:0.1869, loss-lb:0.0882, loss-ulb:0.0493, weight:2.00, lr:0.0007
[11:23:46.644] iteration:8858  t-loss:0.1794, loss-lb:0.0978, loss-ulb:0.0408, weight:2.00, lr:0.0007
[11:23:46.840] iteration:8859  t-loss:0.1785, loss-lb:0.0972, loss-ulb:0.0406, weight:2.00, lr:0.0007
[11:23:47.035] iteration:8860  t-loss:0.1626, loss-lb:0.1037, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:23:47.230] iteration:8861  t-loss:0.1412, loss-lb:0.0921, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:23:47.423] iteration:8862  t-loss:0.1503, loss-lb:0.0967, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:23:47.614] iteration:8863  t-loss:0.1762, loss-lb:0.1290, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:23:47.807] iteration:8864  t-loss:0.1565, loss-lb:0.1043, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:23:47.999] iteration:8865  t-loss:0.2046, loss-lb:0.1135, loss-ulb:0.0456, weight:2.00, lr:0.0007
[11:23:48.190] iteration:8866  t-loss:0.1489, loss-lb:0.0936, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:23:48.381] iteration:8867  t-loss:0.1478, loss-lb:0.0875, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:23:48.575] iteration:8868  t-loss:0.1826, loss-lb:0.0915, loss-ulb:0.0456, weight:2.00, lr:0.0007
[11:23:48.767] iteration:8869  t-loss:0.1731, loss-lb:0.0887, loss-ulb:0.0422, weight:2.00, lr:0.0007
[11:23:48.961] iteration:8870  t-loss:0.1523, loss-lb:0.0882, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:23:49.153] iteration:8871  t-loss:0.1506, loss-lb:0.0924, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:23:49.344] iteration:8872  t-loss:0.1491, loss-lb:0.0983, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:23:49.537] iteration:8873  t-loss:0.1519, loss-lb:0.0945, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:23:49.728] iteration:8874  t-loss:0.1511, loss-lb:0.0911, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:23:49.920] iteration:8875  t-loss:0.1447, loss-lb:0.0918, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:23:50.113] iteration:8876  t-loss:0.2131, loss-lb:0.1071, loss-ulb:0.0530, weight:2.00, lr:0.0007
[11:23:50.305] iteration:8877  t-loss:0.1716, loss-lb:0.0974, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:23:50.497] iteration:8878  t-loss:0.1536, loss-lb:0.1055, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:23:50.689] iteration:8879  t-loss:0.1597, loss-lb:0.0977, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:23:50.880] iteration:8880  t-loss:0.1495, loss-lb:0.0929, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:23:51.071] iteration:8881  t-loss:0.1491, loss-lb:0.0979, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:23:51.264] iteration:8882  t-loss:0.1696, loss-lb:0.0951, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:23:51.456] iteration:8883  t-loss:0.1787, loss-lb:0.0840, loss-ulb:0.0473, weight:2.00, lr:0.0007
[11:23:51.648] iteration:8884  t-loss:0.1501, loss-lb:0.0943, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:23:51.840] iteration:8885  t-loss:0.1511, loss-lb:0.0943, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:23:52.031] iteration:8886  t-loss:0.1435, loss-lb:0.0878, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:23:52.223] iteration:8887  t-loss:0.1596, loss-lb:0.0978, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:23:52.416] iteration:8888  t-loss:0.1699, loss-lb:0.0997, loss-ulb:0.0351, weight:2.00, lr:0.0007
[11:23:52.608] iteration:8889  t-loss:0.1641, loss-lb:0.0932, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:23:52.800] iteration:8890  t-loss:0.1852, loss-lb:0.0986, loss-ulb:0.0433, weight:2.00, lr:0.0007
[11:23:52.991] iteration:8891  t-loss:0.1635, loss-lb:0.0983, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:23:53.182] iteration:8892  t-loss:0.1650, loss-lb:0.1087, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:23:53.380] iteration:8893  t-loss:0.1679, loss-lb:0.0979, loss-ulb:0.0350, weight:2.00, lr:0.0007
[11:23:53.583] iteration:8894  t-loss:0.1504, loss-lb:0.0919, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:23:53.778] iteration:8895  t-loss:0.1476, loss-lb:0.0928, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:23:53.970] iteration:8896  t-loss:0.1662, loss-lb:0.0905, loss-ulb:0.0379, weight:2.00, lr:0.0007
[11:23:54.161] iteration:8897  t-loss:0.1485, loss-lb:0.0902, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:23:54.353] iteration:8898  t-loss:0.1331, loss-lb:0.0881, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:23:54.544] iteration:8899  t-loss:0.1468, loss-lb:0.1007, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:23:54.736] iteration:8900  t-loss:0.1432, loss-lb:0.0887, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:23:54.927] iteration:8901  t-loss:0.1297, loss-lb:0.0865, loss-ulb:0.0216, weight:2.00, lr:0.0007
[11:23:55.118] iteration:8902  t-loss:0.1554, loss-lb:0.1008, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:23:55.311] iteration:8903  t-loss:0.1504, loss-lb:0.0933, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:23:55.502] iteration:8904  t-loss:0.1365, loss-lb:0.0908, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:23:55.695] iteration:8905  t-loss:0.1527, loss-lb:0.0894, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:23:55.886] iteration:8906  t-loss:0.1514, loss-lb:0.0849, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:23:56.079] iteration:8907  t-loss:0.2252, loss-lb:0.0954, loss-ulb:0.0649, weight:2.00, lr:0.0007
[11:23:56.270] iteration:8908  t-loss:0.1587, loss-lb:0.0878, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:23:56.463] iteration:8909  t-loss:0.1486, loss-lb:0.0972, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:23:56.655] iteration:8910  t-loss:0.1539, loss-lb:0.0965, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:23:56.845] iteration:8911  t-loss:0.1507, loss-lb:0.1017, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:23:57.035] iteration:8912  t-loss:0.1355, loss-lb:0.0897, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:23:57.226] iteration:8913  t-loss:0.1464, loss-lb:0.0892, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:23:57.418] iteration:8914  t-loss:0.1386, loss-lb:0.0939, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:23:57.612] iteration:8915  t-loss:0.1482, loss-lb:0.0931, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:23:57.806] iteration:8916  t-loss:0.1614, loss-lb:0.0950, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:23:58.001] iteration:8917  t-loss:0.1612, loss-lb:0.0976, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:23:58.191] iteration:8918  t-loss:0.1563, loss-lb:0.0794, loss-ulb:0.0384, weight:2.00, lr:0.0007
[11:24:10.795]  <<Test>> - Ep:90  - mean_dice/mean_h95 - S:89.52/4.68, Best-S:90.28, T:90.02/1.39, Best-T:90.48
[11:24:10.796]           - AvgLoss(lb/ulb/all):0.0986/0.0300/0.1525
[11:24:11.326] iteration:8919  t-loss:0.1505, loss-lb:0.0863, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:24:11.523] iteration:8920  t-loss:0.1475, loss-lb:0.0989, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:24:11.716] iteration:8921  t-loss:0.1576, loss-lb:0.0863, loss-ulb:0.0357, weight:2.00, lr:0.0007
[11:24:11.910] iteration:8922  t-loss:0.1449, loss-lb:0.0958, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:24:12.103] iteration:8923  t-loss:0.1812, loss-lb:0.0959, loss-ulb:0.0426, weight:2.00, lr:0.0007
[11:24:12.297] iteration:8924  t-loss:0.1773, loss-lb:0.0946, loss-ulb:0.0413, weight:2.00, lr:0.0007
[11:24:12.489] iteration:8925  t-loss:0.1669, loss-lb:0.0977, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:24:12.682] iteration:8926  t-loss:0.1693, loss-lb:0.1052, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:24:12.874] iteration:8927  t-loss:0.1862, loss-lb:0.1006, loss-ulb:0.0428, weight:2.00, lr:0.0007
[11:24:13.066] iteration:8928  t-loss:0.1496, loss-lb:0.0920, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:24:13.259] iteration:8929  t-loss:0.1707, loss-lb:0.1001, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:24:13.453] iteration:8930  t-loss:0.1893, loss-lb:0.1129, loss-ulb:0.0382, weight:2.00, lr:0.0007
[11:24:13.645] iteration:8931  t-loss:0.1580, loss-lb:0.0970, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:24:13.837] iteration:8932  t-loss:0.1785, loss-lb:0.0929, loss-ulb:0.0428, weight:2.00, lr:0.0007
[11:24:14.030] iteration:8933  t-loss:0.2166, loss-lb:0.1012, loss-ulb:0.0577, weight:2.00, lr:0.0007
[11:24:14.222] iteration:8934  t-loss:0.1585, loss-lb:0.0971, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:24:14.415] iteration:8935  t-loss:0.1956, loss-lb:0.1052, loss-ulb:0.0452, weight:2.00, lr:0.0007
[11:24:14.608] iteration:8936  t-loss:0.1774, loss-lb:0.1035, loss-ulb:0.0370, weight:2.00, lr:0.0007
[11:24:14.804] iteration:8937  t-loss:0.1819, loss-lb:0.1175, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:24:14.996] iteration:8938  t-loss:0.1803, loss-lb:0.1113, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:24:15.187] iteration:8939  t-loss:0.1456, loss-lb:0.0960, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:24:15.380] iteration:8940  t-loss:0.1598, loss-lb:0.1040, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:24:15.572] iteration:8941  t-loss:0.1646, loss-lb:0.0997, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:24:15.766] iteration:8942  t-loss:0.1654, loss-lb:0.1100, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:24:15.959] iteration:8943  t-loss:0.1768, loss-lb:0.0967, loss-ulb:0.0400, weight:2.00, lr:0.0007
[11:24:16.150] iteration:8944  t-loss:0.2469, loss-lb:0.0912, loss-ulb:0.0779, weight:2.00, lr:0.0007
[11:24:16.343] iteration:8945  t-loss:0.2103, loss-lb:0.0949, loss-ulb:0.0577, weight:2.00, lr:0.0007
[11:24:16.534] iteration:8946  t-loss:0.1562, loss-lb:0.0959, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:24:16.726] iteration:8947  t-loss:0.1584, loss-lb:0.0958, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:24:16.918] iteration:8948  t-loss:0.1488, loss-lb:0.0973, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:24:17.109] iteration:8949  t-loss:0.1466, loss-lb:0.0951, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:24:17.300] iteration:8950  t-loss:0.1791, loss-lb:0.1107, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:24:17.492] iteration:8951  t-loss:0.1584, loss-lb:0.0934, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:24:17.683] iteration:8952  t-loss:0.1500, loss-lb:0.0878, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:24:17.876] iteration:8953  t-loss:0.1742, loss-lb:0.0948, loss-ulb:0.0397, weight:2.00, lr:0.0007
[11:24:18.068] iteration:8954  t-loss:0.1765, loss-lb:0.1048, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:24:18.259] iteration:8955  t-loss:0.1417, loss-lb:0.1001, loss-ulb:0.0208, weight:2.00, lr:0.0007
[11:24:18.450] iteration:8956  t-loss:0.1338, loss-lb:0.0892, loss-ulb:0.0223, weight:2.00, lr:0.0007
[11:24:18.641] iteration:8957  t-loss:0.1557, loss-lb:0.1035, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:24:18.833] iteration:8958  t-loss:0.1468, loss-lb:0.0987, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:24:19.026] iteration:8959  t-loss:0.3335, loss-lb:0.0916, loss-ulb:0.1210, weight:2.00, lr:0.0007
[11:24:19.219] iteration:8960  t-loss:0.1622, loss-lb:0.0921, loss-ulb:0.0351, weight:2.00, lr:0.0007
[11:24:19.413] iteration:8961  t-loss:0.1713, loss-lb:0.1085, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:24:19.610] iteration:8962  t-loss:0.1468, loss-lb:0.0906, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:24:19.805] iteration:8963  t-loss:0.1315, loss-lb:0.0797, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:24:19.998] iteration:8964  t-loss:0.1701, loss-lb:0.0936, loss-ulb:0.0383, weight:2.00, lr:0.0007
[11:24:20.190] iteration:8965  t-loss:0.1511, loss-lb:0.0978, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:24:20.382] iteration:8966  t-loss:0.1874, loss-lb:0.0911, loss-ulb:0.0481, weight:2.00, lr:0.0007
[11:24:20.575] iteration:8967  t-loss:0.1775, loss-lb:0.1008, loss-ulb:0.0383, weight:2.00, lr:0.0007
[11:24:20.767] iteration:8968  t-loss:0.1479, loss-lb:0.0952, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:24:20.958] iteration:8969  t-loss:0.1523, loss-lb:0.0918, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:24:21.150] iteration:8970  t-loss:0.1469, loss-lb:0.0918, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:24:21.342] iteration:8971  t-loss:0.1373, loss-lb:0.0951, loss-ulb:0.0211, weight:2.00, lr:0.0007
[11:24:21.534] iteration:8972  t-loss:0.1500, loss-lb:0.0928, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:24:21.726] iteration:8973  t-loss:0.1513, loss-lb:0.0962, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:24:21.917] iteration:8974  t-loss:0.2346, loss-lb:0.0963, loss-ulb:0.0692, weight:2.00, lr:0.0007
[11:24:22.109] iteration:8975  t-loss:0.1389, loss-lb:0.0933, loss-ulb:0.0228, weight:2.00, lr:0.0007
[11:24:22.301] iteration:8976  t-loss:0.1373, loss-lb:0.0888, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:24:22.495] iteration:8977  t-loss:0.2269, loss-lb:0.1401, loss-ulb:0.0434, weight:2.00, lr:0.0007
[11:24:22.688] iteration:8978  t-loss:0.2441, loss-lb:0.0892, loss-ulb:0.0775, weight:2.00, lr:0.0007
[11:24:22.880] iteration:8979  t-loss:0.1530, loss-lb:0.0959, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:24:23.073] iteration:8980  t-loss:0.1483, loss-lb:0.0855, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:24:23.264] iteration:8981  t-loss:0.1515, loss-lb:0.0907, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:24:23.456] iteration:8982  t-loss:0.1390, loss-lb:0.0947, loss-ulb:0.0222, weight:2.00, lr:0.0007
[11:24:23.648] iteration:8983  t-loss:0.1475, loss-lb:0.0992, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:24:23.839] iteration:8984  t-loss:0.1834, loss-lb:0.0950, loss-ulb:0.0442, weight:2.00, lr:0.0007
[11:24:24.032] iteration:8985  t-loss:0.1543, loss-lb:0.0947, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:24:24.223] iteration:8986  t-loss:0.1540, loss-lb:0.0948, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:24:24.415] iteration:8987  t-loss:0.1457, loss-lb:0.0974, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:24:24.606] iteration:8988  t-loss:0.1557, loss-lb:0.0925, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:24:24.798] iteration:8989  t-loss:0.2567, loss-lb:0.0997, loss-ulb:0.0785, weight:2.00, lr:0.0007
[11:24:24.991] iteration:8990  t-loss:0.1617, loss-lb:0.0871, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:24:25.183] iteration:8991  t-loss:0.1611, loss-lb:0.1080, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:24:25.375] iteration:8992  t-loss:0.1542, loss-lb:0.1022, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:24:25.567] iteration:8993  t-loss:0.1511, loss-lb:0.1008, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:24:25.759] iteration:8994  t-loss:0.1354, loss-lb:0.0858, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:24:25.950] iteration:8995  t-loss:0.1580, loss-lb:0.0912, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:24:26.150] iteration:8996  t-loss:0.2036, loss-lb:0.0979, loss-ulb:0.0528, weight:2.00, lr:0.0007
[11:24:26.352] iteration:8997  t-loss:0.1438, loss-lb:0.0905, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:24:26.548] iteration:8998  t-loss:0.1462, loss-lb:0.0908, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:24:26.740] iteration:8999  t-loss:0.1533, loss-lb:0.0866, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:24:26.932] iteration:9000  t-loss:0.1943, loss-lb:0.1198, loss-ulb:0.0372, weight:2.00, lr:0.0007
[11:24:27.123] iteration:9001  t-loss:0.1560, loss-lb:0.0847, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:24:27.315] iteration:9002  t-loss:0.1351, loss-lb:0.0855, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:24:27.509] iteration:9003  t-loss:0.2043, loss-lb:0.1390, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:24:27.701] iteration:9004  t-loss:0.1925, loss-lb:0.0930, loss-ulb:0.0497, weight:2.00, lr:0.0007
[11:24:27.892] iteration:9005  t-loss:0.1594, loss-lb:0.0975, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:24:28.085] iteration:9006  t-loss:0.1430, loss-lb:0.0886, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:24:28.276] iteration:9007  t-loss:0.1550, loss-lb:0.1044, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:24:28.468] iteration:9008  t-loss:0.3770, loss-lb:0.0928, loss-ulb:0.1421, weight:2.00, lr:0.0007
[11:24:28.659] iteration:9009  t-loss:0.1617, loss-lb:0.0996, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:24:28.850] iteration:9010  t-loss:0.1440, loss-lb:0.0976, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:24:29.039] iteration:9011  t-loss:0.1944, loss-lb:0.0881, loss-ulb:0.0532, weight:2.00, lr:0.0007
[11:24:29.228] iteration:9012  t-loss:0.1370, loss-lb:0.0858, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:24:29.417] iteration:9013  t-loss:0.1448, loss-lb:0.0984, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:24:29.607] iteration:9014  t-loss:0.1434, loss-lb:0.0937, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:24:29.798] iteration:9015  t-loss:0.1396, loss-lb:0.0862, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:24:29.989] iteration:9016  t-loss:0.1464, loss-lb:0.0932, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:24:30.568] iteration:9017  t-loss:0.1566, loss-lb:0.0922, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:24:30.762] iteration:9018  t-loss:0.1363, loss-lb:0.0859, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:24:30.954] iteration:9019  t-loss:0.1383, loss-lb:0.0862, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:24:31.147] iteration:9020  t-loss:0.1350, loss-lb:0.0917, loss-ulb:0.0217, weight:2.00, lr:0.0007
[11:24:31.340] iteration:9021  t-loss:0.1437, loss-lb:0.0968, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:24:31.532] iteration:9022  t-loss:0.1468, loss-lb:0.0942, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:24:31.725] iteration:9023  t-loss:0.1421, loss-lb:0.0904, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:24:31.917] iteration:9024  t-loss:0.1425, loss-lb:0.0871, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:24:32.109] iteration:9025  t-loss:0.1390, loss-lb:0.0869, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:24:32.302] iteration:9026  t-loss:0.1526, loss-lb:0.1016, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:24:32.495] iteration:9027  t-loss:0.1279, loss-lb:0.0778, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:24:32.688] iteration:9028  t-loss:0.1382, loss-lb:0.0950, loss-ulb:0.0216, weight:2.00, lr:0.0007
[11:24:32.880] iteration:9029  t-loss:0.1529, loss-lb:0.0906, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:24:33.073] iteration:9030  t-loss:0.1858, loss-lb:0.1021, loss-ulb:0.0419, weight:2.00, lr:0.0007
[11:24:33.266] iteration:9031  t-loss:0.1829, loss-lb:0.0843, loss-ulb:0.0493, weight:2.00, lr:0.0007
[11:24:33.458] iteration:9032  t-loss:0.1345, loss-lb:0.0916, loss-ulb:0.0214, weight:2.00, lr:0.0007
[11:24:33.650] iteration:9033  t-loss:0.1686, loss-lb:0.1043, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:24:33.844] iteration:9034  t-loss:0.1983, loss-lb:0.0895, loss-ulb:0.0544, weight:2.00, lr:0.0007
[11:24:34.036] iteration:9035  t-loss:0.1464, loss-lb:0.0983, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:24:34.228] iteration:9036  t-loss:0.1912, loss-lb:0.0923, loss-ulb:0.0495, weight:2.00, lr:0.0007
[11:24:34.421] iteration:9037  t-loss:0.1432, loss-lb:0.0828, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:24:34.614] iteration:9038  t-loss:0.1354, loss-lb:0.0882, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:24:34.805] iteration:9039  t-loss:0.1492, loss-lb:0.0860, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:24:34.997] iteration:9040  t-loss:0.1435, loss-lb:0.0847, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:24:35.190] iteration:9041  t-loss:0.1577, loss-lb:0.0952, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:24:35.382] iteration:9042  t-loss:0.2262, loss-lb:0.0888, loss-ulb:0.0687, weight:2.00, lr:0.0007
[11:24:35.575] iteration:9043  t-loss:0.1592, loss-lb:0.0928, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:24:35.767] iteration:9044  t-loss:0.1393, loss-lb:0.0867, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:24:35.960] iteration:9045  t-loss:0.1412, loss-lb:0.0884, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:24:36.153] iteration:9046  t-loss:0.1395, loss-lb:0.0911, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:24:36.346] iteration:9047  t-loss:0.1396, loss-lb:0.0842, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:24:36.538] iteration:9048  t-loss:0.1409, loss-lb:0.0912, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:24:36.730] iteration:9049  t-loss:0.1605, loss-lb:0.0971, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:24:36.923] iteration:9050  t-loss:0.1379, loss-lb:0.0865, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:24:37.116] iteration:9051  t-loss:0.1374, loss-lb:0.0797, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:24:37.309] iteration:9052  t-loss:0.1325, loss-lb:0.0859, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:24:37.503] iteration:9053  t-loss:0.1365, loss-lb:0.0894, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:24:37.695] iteration:9054  t-loss:0.1533, loss-lb:0.0877, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:24:37.889] iteration:9055  t-loss:0.1345, loss-lb:0.0931, loss-ulb:0.0207, weight:2.00, lr:0.0007
[11:24:38.081] iteration:9056  t-loss:0.1374, loss-lb:0.0901, loss-ulb:0.0237, weight:2.00, lr:0.0007
[11:24:38.273] iteration:9057  t-loss:0.1545, loss-lb:0.0929, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:24:38.467] iteration:9058  t-loss:0.1459, loss-lb:0.0838, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:24:38.659] iteration:9059  t-loss:0.1566, loss-lb:0.0975, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:24:38.850] iteration:9060  t-loss:0.1379, loss-lb:0.0865, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:24:39.043] iteration:9061  t-loss:0.1400, loss-lb:0.0812, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:24:39.236] iteration:9062  t-loss:0.1652, loss-lb:0.0852, loss-ulb:0.0400, weight:2.00, lr:0.0007
[11:24:39.428] iteration:9063  t-loss:0.1518, loss-lb:0.0849, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:24:39.620] iteration:9064  t-loss:0.1568, loss-lb:0.0916, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:24:39.812] iteration:9065  t-loss:0.1545, loss-lb:0.0975, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:24:40.003] iteration:9066  t-loss:0.1498, loss-lb:0.0860, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:24:40.196] iteration:9067  t-loss:0.1437, loss-lb:0.0928, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:24:40.389] iteration:9068  t-loss:0.1306, loss-lb:0.0880, loss-ulb:0.0213, weight:2.00, lr:0.0007
[11:24:40.581] iteration:9069  t-loss:0.1528, loss-lb:0.0916, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:24:40.773] iteration:9070  t-loss:0.1761, loss-lb:0.0963, loss-ulb:0.0399, weight:2.00, lr:0.0007
[11:24:40.966] iteration:9071  t-loss:0.1474, loss-lb:0.0848, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:24:41.158] iteration:9072  t-loss:0.1581, loss-lb:0.0944, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:24:41.351] iteration:9073  t-loss:0.2365, loss-lb:0.1040, loss-ulb:0.0662, weight:2.00, lr:0.0007
[11:24:41.544] iteration:9074  t-loss:0.1301, loss-lb:0.0872, loss-ulb:0.0215, weight:2.00, lr:0.0007
[11:24:41.737] iteration:9075  t-loss:0.1587, loss-lb:0.0924, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:24:41.929] iteration:9076  t-loss:0.1378, loss-lb:0.0939, loss-ulb:0.0220, weight:2.00, lr:0.0007
[11:24:42.121] iteration:9077  t-loss:0.1325, loss-lb:0.0850, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:24:42.315] iteration:9078  t-loss:0.1495, loss-lb:0.0831, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:24:42.507] iteration:9079  t-loss:0.1378, loss-lb:0.0888, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:24:42.700] iteration:9080  t-loss:0.1890, loss-lb:0.0989, loss-ulb:0.0451, weight:2.00, lr:0.0007
[11:24:42.893] iteration:9081  t-loss:0.1507, loss-lb:0.0976, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:24:43.084] iteration:9082  t-loss:0.1424, loss-lb:0.0891, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:24:43.277] iteration:9083  t-loss:0.1589, loss-lb:0.0862, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:24:43.469] iteration:9084  t-loss:0.1318, loss-lb:0.0823, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:24:43.663] iteration:9085  t-loss:0.1786, loss-lb:0.0877, loss-ulb:0.0454, weight:2.00, lr:0.0007
[11:24:43.854] iteration:9086  t-loss:0.1305, loss-lb:0.0833, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:24:44.047] iteration:9087  t-loss:0.1394, loss-lb:0.0877, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:24:44.240] iteration:9088  t-loss:0.1797, loss-lb:0.0934, loss-ulb:0.0431, weight:2.00, lr:0.0007
[11:24:44.432] iteration:9089  t-loss:0.1479, loss-lb:0.0903, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:24:44.623] iteration:9090  t-loss:0.1576, loss-lb:0.1047, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:24:44.815] iteration:9091  t-loss:0.1456, loss-lb:0.0936, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:24:45.007] iteration:9092  t-loss:0.1392, loss-lb:0.0902, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:24:45.200] iteration:9093  t-loss:0.1462, loss-lb:0.0973, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:24:45.393] iteration:9094  t-loss:0.2535, loss-lb:0.0874, loss-ulb:0.0831, weight:2.00, lr:0.0007
[11:24:45.586] iteration:9095  t-loss:0.1474, loss-lb:0.0874, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:24:45.778] iteration:9096  t-loss:0.1512, loss-lb:0.0888, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:24:45.970] iteration:9097  t-loss:0.1397, loss-lb:0.0841, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:24:46.163] iteration:9098  t-loss:0.1366, loss-lb:0.0802, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:24:46.355] iteration:9099  t-loss:0.1466, loss-lb:0.0903, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:24:46.547] iteration:9100  t-loss:0.1322, loss-lb:0.0818, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:24:46.740] iteration:9101  t-loss:0.1490, loss-lb:0.0912, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:24:46.932] iteration:9102  t-loss:0.1590, loss-lb:0.0872, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:24:47.124] iteration:9103  t-loss:0.1386, loss-lb:0.0919, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:24:47.317] iteration:9104  t-loss:0.1341, loss-lb:0.0790, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:24:47.509] iteration:9105  t-loss:0.1314, loss-lb:0.0851, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:24:47.701] iteration:9106  t-loss:0.1470, loss-lb:0.0973, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:24:47.894] iteration:9107  t-loss:0.1547, loss-lb:0.0878, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:24:48.084] iteration:9108  t-loss:0.1358, loss-lb:0.0840, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:24:48.275] iteration:9109  t-loss:0.1523, loss-lb:0.0823, loss-ulb:0.0350, weight:2.00, lr:0.0007
[11:24:48.465] iteration:9110  t-loss:0.1581, loss-lb:0.0915, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:24:48.656] iteration:9111  t-loss:0.1422, loss-lb:0.0846, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:24:48.846] iteration:9112  t-loss:0.1691, loss-lb:0.0899, loss-ulb:0.0396, weight:2.00, lr:0.0007
[11:24:49.037] iteration:9113  t-loss:0.1482, loss-lb:0.0951, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:24:49.227] iteration:9114  t-loss:0.1411, loss-lb:0.0848, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:25:00.310]  <<Test>> - Ep:92  - mean_dice/mean_h95 - S:90.06/1.32, Best-S:90.28, T:90.22/1.44, Best-T:90.48
[11:25:00.311]           - AvgLoss(lb/ulb/all):0.0897/0.0293/0.1457
[11:25:00.863] iteration:9115  t-loss:0.1816, loss-lb:0.0875, loss-ulb:0.0471, weight:2.00, lr:0.0007
[11:25:01.060] iteration:9116  t-loss:0.1408, loss-lb:0.0930, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:25:01.255] iteration:9117  t-loss:0.1330, loss-lb:0.0760, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:25:01.448] iteration:9118  t-loss:0.1591, loss-lb:0.1006, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:25:01.640] iteration:9119  t-loss:0.1454, loss-lb:0.0981, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:25:01.833] iteration:9120  t-loss:0.1395, loss-lb:0.0910, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:25:02.025] iteration:9121  t-loss:0.1362, loss-lb:0.0962, loss-ulb:0.0200, weight:2.00, lr:0.0007
[11:25:02.217] iteration:9122  t-loss:0.1719, loss-lb:0.0851, loss-ulb:0.0434, weight:2.00, lr:0.0007
[11:25:02.410] iteration:9123  t-loss:0.1501, loss-lb:0.0825, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:25:02.604] iteration:9124  t-loss:0.1526, loss-lb:0.0888, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:25:02.797] iteration:9125  t-loss:0.2219, loss-lb:0.0923, loss-ulb:0.0648, weight:2.00, lr:0.0007
[11:25:02.989] iteration:9126  t-loss:0.1316, loss-lb:0.0850, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:25:03.182] iteration:9127  t-loss:0.1303, loss-lb:0.0809, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:25:03.375] iteration:9128  t-loss:0.1516, loss-lb:0.0898, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:25:03.568] iteration:9129  t-loss:0.1402, loss-lb:0.0848, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:25:03.762] iteration:9130  t-loss:0.1264, loss-lb:0.0790, loss-ulb:0.0237, weight:2.00, lr:0.0007
[11:25:03.954] iteration:9131  t-loss:0.1630, loss-lb:0.1059, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:25:04.147] iteration:9132  t-loss:0.1611, loss-lb:0.1029, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:25:04.340] iteration:9133  t-loss:0.1531, loss-lb:0.0977, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:25:04.532] iteration:9134  t-loss:0.1366, loss-lb:0.0895, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:25:04.726] iteration:9135  t-loss:0.1668, loss-lb:0.0935, loss-ulb:0.0367, weight:2.00, lr:0.0007
[11:25:04.920] iteration:9136  t-loss:0.1387, loss-lb:0.0855, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:25:05.113] iteration:9137  t-loss:0.1610, loss-lb:0.0836, loss-ulb:0.0387, weight:2.00, lr:0.0007
[11:25:05.306] iteration:9138  t-loss:0.1252, loss-lb:0.0792, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:25:05.498] iteration:9139  t-loss:0.1445, loss-lb:0.0917, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:25:05.690] iteration:9140  t-loss:0.1591, loss-lb:0.0943, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:25:05.884] iteration:9141  t-loss:0.1404, loss-lb:0.0946, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:25:06.077] iteration:9142  t-loss:0.1456, loss-lb:0.0881, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:25:06.269] iteration:9143  t-loss:0.1582, loss-lb:0.0940, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:25:06.461] iteration:9144  t-loss:0.1479, loss-lb:0.0943, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:25:06.653] iteration:9145  t-loss:0.1653, loss-lb:0.0873, loss-ulb:0.0390, weight:2.00, lr:0.0007
[11:25:06.845] iteration:9146  t-loss:0.1514, loss-lb:0.0932, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:25:07.038] iteration:9147  t-loss:0.1296, loss-lb:0.0817, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:25:07.230] iteration:9148  t-loss:0.1388, loss-lb:0.0870, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:25:07.422] iteration:9149  t-loss:0.2017, loss-lb:0.0857, loss-ulb:0.0580, weight:2.00, lr:0.0007
[11:25:07.615] iteration:9150  t-loss:0.1442, loss-lb:0.0946, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:25:07.807] iteration:9151  t-loss:0.1737, loss-lb:0.0879, loss-ulb:0.0429, weight:2.00, lr:0.0007
[11:25:08.000] iteration:9152  t-loss:0.1351, loss-lb:0.0907, loss-ulb:0.0222, weight:2.00, lr:0.0007
[11:25:08.192] iteration:9153  t-loss:0.1484, loss-lb:0.0888, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:25:08.386] iteration:9154  t-loss:0.1871, loss-lb:0.1028, loss-ulb:0.0422, weight:2.00, lr:0.0007
[11:25:08.578] iteration:9155  t-loss:0.1398, loss-lb:0.0842, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:25:08.770] iteration:9156  t-loss:0.1506, loss-lb:0.0977, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:25:08.963] iteration:9157  t-loss:0.1807, loss-lb:0.0873, loss-ulb:0.0467, weight:2.00, lr:0.0007
[11:25:09.156] iteration:9158  t-loss:0.1362, loss-lb:0.0882, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:25:09.347] iteration:9159  t-loss:0.1761, loss-lb:0.0934, loss-ulb:0.0414, weight:2.00, lr:0.0007
[11:25:09.540] iteration:9160  t-loss:0.1661, loss-lb:0.0833, loss-ulb:0.0414, weight:2.00, lr:0.0007
[11:25:09.732] iteration:9161  t-loss:0.1280, loss-lb:0.0812, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:25:09.924] iteration:9162  t-loss:0.1370, loss-lb:0.0886, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:25:10.118] iteration:9163  t-loss:0.1846, loss-lb:0.0948, loss-ulb:0.0449, weight:2.00, lr:0.0007
[11:25:10.311] iteration:9164  t-loss:0.1817, loss-lb:0.0881, loss-ulb:0.0468, weight:2.00, lr:0.0007
[11:25:10.503] iteration:9165  t-loss:0.1800, loss-lb:0.0902, loss-ulb:0.0449, weight:2.00, lr:0.0007
[11:25:10.695] iteration:9166  t-loss:0.1588, loss-lb:0.0991, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:25:10.887] iteration:9167  t-loss:0.1456, loss-lb:0.0906, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:25:11.079] iteration:9168  t-loss:0.1435, loss-lb:0.0850, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:25:11.272] iteration:9169  t-loss:0.1410, loss-lb:0.0854, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:25:11.465] iteration:9170  t-loss:0.1782, loss-lb:0.1015, loss-ulb:0.0384, weight:2.00, lr:0.0007
[11:25:11.657] iteration:9171  t-loss:0.2344, loss-lb:0.0925, loss-ulb:0.0709, weight:2.00, lr:0.0007
[11:25:11.849] iteration:9172  t-loss:0.1489, loss-lb:0.1008, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:25:12.041] iteration:9173  t-loss:0.1531, loss-lb:0.0921, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:25:12.234] iteration:9174  t-loss:0.1770, loss-lb:0.0909, loss-ulb:0.0431, weight:2.00, lr:0.0007
[11:25:12.426] iteration:9175  t-loss:0.2310, loss-lb:0.1664, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:25:12.619] iteration:9176  t-loss:0.1350, loss-lb:0.0834, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:25:12.812] iteration:9177  t-loss:0.1593, loss-lb:0.0896, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:25:13.004] iteration:9178  t-loss:0.1571, loss-lb:0.0950, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:25:13.196] iteration:9179  t-loss:0.1662, loss-lb:0.0880, loss-ulb:0.0391, weight:2.00, lr:0.0007
[11:25:13.388] iteration:9180  t-loss:0.1570, loss-lb:0.0917, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:25:13.582] iteration:9181  t-loss:0.1691, loss-lb:0.0950, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:25:13.774] iteration:9182  t-loss:0.1413, loss-lb:0.0895, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:25:13.966] iteration:9183  t-loss:0.1861, loss-lb:0.0886, loss-ulb:0.0487, weight:2.00, lr:0.0007
[11:25:14.160] iteration:9184  t-loss:0.1892, loss-lb:0.0824, loss-ulb:0.0534, weight:2.00, lr:0.0007
[11:25:14.352] iteration:9185  t-loss:0.1355, loss-lb:0.0884, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:25:14.544] iteration:9186  t-loss:0.1599, loss-lb:0.0989, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:25:14.735] iteration:9187  t-loss:0.1513, loss-lb:0.0953, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:25:14.927] iteration:9188  t-loss:0.1403, loss-lb:0.0883, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:25:15.119] iteration:9189  t-loss:0.2870, loss-lb:0.0913, loss-ulb:0.0978, weight:2.00, lr:0.0007
[11:25:15.311] iteration:9190  t-loss:0.1460, loss-lb:0.0968, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:25:15.505] iteration:9191  t-loss:0.1586, loss-lb:0.0925, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:25:15.697] iteration:9192  t-loss:0.1719, loss-lb:0.1043, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:25:15.889] iteration:9193  t-loss:0.1394, loss-lb:0.0916, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:25:16.082] iteration:9194  t-loss:0.1522, loss-lb:0.0933, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:25:16.274] iteration:9195  t-loss:0.1313, loss-lb:0.0847, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:25:16.466] iteration:9196  t-loss:0.1449, loss-lb:0.0915, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:25:16.660] iteration:9197  t-loss:0.1381, loss-lb:0.0898, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:25:16.853] iteration:9198  t-loss:0.1472, loss-lb:0.0926, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:25:17.045] iteration:9199  t-loss:0.1344, loss-lb:0.0852, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:25:17.237] iteration:9200  t-loss:0.1670, loss-lb:0.0882, loss-ulb:0.0394, weight:2.00, lr:0.0007
[11:25:17.429] iteration:9201  t-loss:0.1346, loss-lb:0.0852, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:25:17.621] iteration:9202  t-loss:0.1543, loss-lb:0.0836, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:25:17.813] iteration:9203  t-loss:0.1416, loss-lb:0.0913, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:25:18.007] iteration:9204  t-loss:0.1642, loss-lb:0.0955, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:25:18.198] iteration:9205  t-loss:0.1418, loss-lb:0.0937, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:25:18.389] iteration:9206  t-loss:0.3532, loss-lb:0.0896, loss-ulb:0.1318, weight:2.00, lr:0.0007
[11:25:18.580] iteration:9207  t-loss:0.1715, loss-lb:0.0820, loss-ulb:0.0447, weight:2.00, lr:0.0007
[11:25:18.771] iteration:9208  t-loss:0.1424, loss-lb:0.0937, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:25:18.962] iteration:9209  t-loss:0.1498, loss-lb:0.0898, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:25:19.152] iteration:9210  t-loss:0.1364, loss-lb:0.0820, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:25:19.344] iteration:9211  t-loss:0.1428, loss-lb:0.0907, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:25:19.534] iteration:9212  t-loss:0.1470, loss-lb:0.0921, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:25:20.107] iteration:9213  t-loss:0.1398, loss-lb:0.0906, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:25:20.313] iteration:9214  t-loss:0.1482, loss-lb:0.0951, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:25:20.506] iteration:9215  t-loss:0.1656, loss-lb:0.0885, loss-ulb:0.0386, weight:2.00, lr:0.0007
[11:25:20.700] iteration:9216  t-loss:0.1647, loss-lb:0.1125, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:25:20.893] iteration:9217  t-loss:0.1361, loss-lb:0.0967, loss-ulb:0.0197, weight:2.00, lr:0.0007
[11:25:21.085] iteration:9218  t-loss:0.1328, loss-lb:0.0847, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:25:21.277] iteration:9219  t-loss:0.1259, loss-lb:0.0841, loss-ulb:0.0209, weight:2.00, lr:0.0007
[11:25:21.469] iteration:9220  t-loss:0.1376, loss-lb:0.0892, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:25:21.661] iteration:9221  t-loss:0.1412, loss-lb:0.0872, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:25:21.853] iteration:9222  t-loss:0.1347, loss-lb:0.0832, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:25:22.045] iteration:9223  t-loss:0.1574, loss-lb:0.0961, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:25:22.237] iteration:9224  t-loss:0.1462, loss-lb:0.0897, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:25:22.429] iteration:9225  t-loss:0.1444, loss-lb:0.0913, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:25:22.620] iteration:9226  t-loss:0.1414, loss-lb:0.0929, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:25:22.813] iteration:9227  t-loss:0.1823, loss-lb:0.1091, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:25:23.003] iteration:9228  t-loss:0.1509, loss-lb:0.0861, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:25:23.195] iteration:9229  t-loss:0.1787, loss-lb:0.0945, loss-ulb:0.0421, weight:2.00, lr:0.0007
[11:25:23.388] iteration:9230  t-loss:0.1816, loss-lb:0.0915, loss-ulb:0.0451, weight:2.00, lr:0.0007
[11:25:23.580] iteration:9231  t-loss:0.1449, loss-lb:0.0947, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:25:23.775] iteration:9232  t-loss:0.1433, loss-lb:0.0812, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:25:23.967] iteration:9233  t-loss:0.1460, loss-lb:0.0951, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:25:24.158] iteration:9234  t-loss:0.1462, loss-lb:0.0894, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:25:24.350] iteration:9235  t-loss:0.1395, loss-lb:0.0885, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:25:24.542] iteration:9236  t-loss:0.1325, loss-lb:0.0818, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:25:24.734] iteration:9237  t-loss:0.1528, loss-lb:0.0911, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:25:24.928] iteration:9238  t-loss:0.1779, loss-lb:0.0886, loss-ulb:0.0447, weight:2.00, lr:0.0007
[11:25:25.120] iteration:9239  t-loss:0.1437, loss-lb:0.0868, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:25:25.310] iteration:9240  t-loss:0.1553, loss-lb:0.0953, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:25:25.503] iteration:9241  t-loss:0.1351, loss-lb:0.0862, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:25:25.695] iteration:9242  t-loss:0.1695, loss-lb:0.0979, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:25:25.886] iteration:9243  t-loss:0.1526, loss-lb:0.0947, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:25:26.079] iteration:9244  t-loss:0.1454, loss-lb:0.0940, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:25:26.270] iteration:9245  t-loss:0.1475, loss-lb:0.0766, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:25:26.462] iteration:9246  t-loss:0.1350, loss-lb:0.0796, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:25:26.654] iteration:9247  t-loss:0.1428, loss-lb:0.0895, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:25:26.846] iteration:9248  t-loss:0.1537, loss-lb:0.0964, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:25:27.038] iteration:9249  t-loss:0.1856, loss-lb:0.0844, loss-ulb:0.0506, weight:2.00, lr:0.0007
[11:25:27.229] iteration:9250  t-loss:0.1712, loss-lb:0.0969, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:25:27.421] iteration:9251  t-loss:0.1488, loss-lb:0.0889, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:25:27.614] iteration:9252  t-loss:0.1387, loss-lb:0.0892, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:25:27.805] iteration:9253  t-loss:0.1534, loss-lb:0.0937, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:25:27.998] iteration:9254  t-loss:0.1581, loss-lb:0.0810, loss-ulb:0.0386, weight:2.00, lr:0.0007
[11:25:28.190] iteration:9255  t-loss:0.1861, loss-lb:0.1176, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:25:28.381] iteration:9256  t-loss:0.2349, loss-lb:0.0890, loss-ulb:0.0730, weight:2.00, lr:0.0007
[11:25:28.572] iteration:9257  t-loss:0.1582, loss-lb:0.0810, loss-ulb:0.0386, weight:2.00, lr:0.0007
[11:25:28.763] iteration:9258  t-loss:0.1816, loss-lb:0.0984, loss-ulb:0.0416, weight:2.00, lr:0.0007
[11:25:28.954] iteration:9259  t-loss:0.1515, loss-lb:0.0946, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:25:29.146] iteration:9260  t-loss:0.1858, loss-lb:0.0964, loss-ulb:0.0447, weight:2.00, lr:0.0007
[11:25:29.337] iteration:9261  t-loss:0.1635, loss-lb:0.0932, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:25:29.529] iteration:9262  t-loss:0.1616, loss-lb:0.0925, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:25:29.720] iteration:9263  t-loss:0.1421, loss-lb:0.0845, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:25:29.912] iteration:9264  t-loss:0.1502, loss-lb:0.0880, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:25:30.103] iteration:9265  t-loss:0.1520, loss-lb:0.1016, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:25:30.293] iteration:9266  t-loss:0.1460, loss-lb:0.0880, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:25:30.483] iteration:9267  t-loss:0.1527, loss-lb:0.0966, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:25:30.675] iteration:9268  t-loss:0.1447, loss-lb:0.0955, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:25:30.868] iteration:9269  t-loss:0.1407, loss-lb:0.0940, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:25:31.065] iteration:9270  t-loss:0.1530, loss-lb:0.0902, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:25:31.260] iteration:9271  t-loss:0.1575, loss-lb:0.0877, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:25:31.455] iteration:9272  t-loss:0.1508, loss-lb:0.0991, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:25:31.651] iteration:9273  t-loss:0.1754, loss-lb:0.0958, loss-ulb:0.0398, weight:2.00, lr:0.0007
[11:25:31.865] iteration:9274  t-loss:0.1502, loss-lb:0.0897, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:25:32.062] iteration:9275  t-loss:0.1446, loss-lb:0.0909, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:25:32.255] iteration:9276  t-loss:0.1823, loss-lb:0.1315, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:25:32.447] iteration:9277  t-loss:0.1434, loss-lb:0.0961, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:25:32.639] iteration:9278  t-loss:0.1465, loss-lb:0.0879, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:25:32.831] iteration:9279  t-loss:0.1534, loss-lb:0.0944, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:25:33.022] iteration:9280  t-loss:0.1530, loss-lb:0.0953, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:25:33.214] iteration:9281  t-loss:0.1445, loss-lb:0.0896, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:25:33.405] iteration:9282  t-loss:0.1395, loss-lb:0.0864, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:25:33.598] iteration:9283  t-loss:0.1455, loss-lb:0.0956, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:25:33.791] iteration:9284  t-loss:0.1533, loss-lb:0.0920, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:25:33.983] iteration:9285  t-loss:0.1594, loss-lb:0.0917, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:25:34.174] iteration:9286  t-loss:0.1522, loss-lb:0.0925, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:25:34.367] iteration:9287  t-loss:0.1334, loss-lb:0.0862, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:25:34.559] iteration:9288  t-loss:0.1763, loss-lb:0.0838, loss-ulb:0.0463, weight:2.00, lr:0.0007
[11:25:34.751] iteration:9289  t-loss:0.1543, loss-lb:0.1002, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:25:34.943] iteration:9290  t-loss:0.1939, loss-lb:0.0880, loss-ulb:0.0529, weight:2.00, lr:0.0007
[11:25:35.134] iteration:9291  t-loss:0.1537, loss-lb:0.1024, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:25:35.326] iteration:9292  t-loss:0.1396, loss-lb:0.0912, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:25:35.518] iteration:9293  t-loss:0.1723, loss-lb:0.0936, loss-ulb:0.0393, weight:2.00, lr:0.0007
[11:25:35.710] iteration:9294  t-loss:0.1904, loss-lb:0.1044, loss-ulb:0.0430, weight:2.00, lr:0.0007
[11:25:35.902] iteration:9295  t-loss:0.1728, loss-lb:0.1097, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:25:36.094] iteration:9296  t-loss:0.2016, loss-lb:0.0959, loss-ulb:0.0529, weight:2.00, lr:0.0007
[11:25:36.285] iteration:9297  t-loss:0.1434, loss-lb:0.0908, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:25:36.477] iteration:9298  t-loss:0.1378, loss-lb:0.0878, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:25:36.668] iteration:9299  t-loss:0.1812, loss-lb:0.0939, loss-ulb:0.0436, weight:2.00, lr:0.0007
[11:25:36.860] iteration:9300  t-loss:0.1446, loss-lb:0.0906, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:25:37.053] iteration:9301  t-loss:0.1845, loss-lb:0.1085, loss-ulb:0.0380, weight:2.00, lr:0.0007
[11:25:37.245] iteration:9302  t-loss:0.1566, loss-lb:0.1078, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:25:37.436] iteration:9303  t-loss:0.1637, loss-lb:0.1052, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:25:37.628] iteration:9304  t-loss:0.1583, loss-lb:0.0950, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:25:37.818] iteration:9305  t-loss:0.1846, loss-lb:0.0962, loss-ulb:0.0442, weight:2.00, lr:0.0007
[11:25:38.010] iteration:9306  t-loss:0.1883, loss-lb:0.0913, loss-ulb:0.0485, weight:2.00, lr:0.0007
[11:25:38.202] iteration:9307  t-loss:0.1603, loss-lb:0.0917, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:25:38.392] iteration:9308  t-loss:0.1560, loss-lb:0.0980, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:25:38.582] iteration:9309  t-loss:0.1829, loss-lb:0.1065, loss-ulb:0.0382, weight:2.00, lr:0.0007
[11:25:38.773] iteration:9310  t-loss:0.2032, loss-lb:0.1024, loss-ulb:0.0504, weight:2.00, lr:0.0007
[11:25:51.320]  <<Test>> - Ep:94  - mean_dice/mean_h95 - S:89.91/1.42, Best-S:90.28, T:90.26/1.31, Best-T:90.48
[11:25:51.320]           - AvgLoss(lb/ulb/all):0.0933/0.0353/0.1688
[11:25:51.852] iteration:9311  t-loss:0.1728, loss-lb:0.0995, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:25:52.049] iteration:9312  t-loss:0.1842, loss-lb:0.0978, loss-ulb:0.0432, weight:2.00, lr:0.0007
[11:25:52.241] iteration:9313  t-loss:0.1733, loss-lb:0.0885, loss-ulb:0.0424, weight:2.00, lr:0.0007
[11:25:52.434] iteration:9314  t-loss:0.1581, loss-lb:0.1094, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:25:52.629] iteration:9315  t-loss:0.1624, loss-lb:0.1068, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:25:52.824] iteration:9316  t-loss:0.1643, loss-lb:0.1000, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:25:53.018] iteration:9317  t-loss:0.1707, loss-lb:0.1032, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:25:53.214] iteration:9318  t-loss:0.1688, loss-lb:0.1079, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:25:53.407] iteration:9319  t-loss:0.1869, loss-lb:0.1047, loss-ulb:0.0411, weight:2.00, lr:0.0007
[11:25:53.600] iteration:9320  t-loss:0.1851, loss-lb:0.0988, loss-ulb:0.0432, weight:2.00, lr:0.0007
[11:25:53.792] iteration:9321  t-loss:0.1487, loss-lb:0.0930, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:25:53.985] iteration:9322  t-loss:0.3332, loss-lb:0.0921, loss-ulb:0.1206, weight:2.00, lr:0.0007
[11:25:54.178] iteration:9323  t-loss:0.1746, loss-lb:0.0997, loss-ulb:0.0375, weight:2.00, lr:0.0007
[11:25:54.371] iteration:9324  t-loss:0.2451, loss-lb:0.1373, loss-ulb:0.0539, weight:2.00, lr:0.0007
[11:25:54.564] iteration:9325  t-loss:0.1659, loss-lb:0.1039, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:25:54.756] iteration:9326  t-loss:0.1974, loss-lb:0.0940, loss-ulb:0.0517, weight:2.00, lr:0.0007
[11:25:54.948] iteration:9327  t-loss:0.1994, loss-lb:0.0966, loss-ulb:0.0514, weight:2.00, lr:0.0007
[11:25:55.142] iteration:9328  t-loss:0.2168, loss-lb:0.1293, loss-ulb:0.0437, weight:2.00, lr:0.0007
[11:25:55.339] iteration:9329  t-loss:0.2007, loss-lb:0.1024, loss-ulb:0.0491, weight:2.00, lr:0.0007
[11:25:55.532] iteration:9330  t-loss:0.1359, loss-lb:0.0881, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:25:55.725] iteration:9331  t-loss:0.2272, loss-lb:0.1138, loss-ulb:0.0567, weight:2.00, lr:0.0007
[11:25:55.918] iteration:9332  t-loss:0.1531, loss-lb:0.0986, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:25:56.112] iteration:9333  t-loss:0.2096, loss-lb:0.1368, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:25:56.305] iteration:9334  t-loss:0.1599, loss-lb:0.0902, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:25:56.498] iteration:9335  t-loss:0.1416, loss-lb:0.0957, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:25:56.692] iteration:9336  t-loss:0.1614, loss-lb:0.1048, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:25:56.884] iteration:9337  t-loss:0.1606, loss-lb:0.0992, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:25:57.076] iteration:9338  t-loss:0.1862, loss-lb:0.1136, loss-ulb:0.0363, weight:2.00, lr:0.0007
[11:25:57.270] iteration:9339  t-loss:0.1741, loss-lb:0.1138, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:25:57.463] iteration:9340  t-loss:0.1961, loss-lb:0.1026, loss-ulb:0.0467, weight:2.00, lr:0.0007
[11:25:57.657] iteration:9341  t-loss:0.1852, loss-lb:0.1047, loss-ulb:0.0403, weight:2.00, lr:0.0007
[11:25:57.850] iteration:9342  t-loss:0.1453, loss-lb:0.0976, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:25:58.044] iteration:9343  t-loss:0.1747, loss-lb:0.0896, loss-ulb:0.0426, weight:2.00, lr:0.0007
[11:25:58.237] iteration:9344  t-loss:0.1609, loss-lb:0.0998, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:25:58.430] iteration:9345  t-loss:0.1559, loss-lb:0.0884, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:25:58.622] iteration:9346  t-loss:0.1594, loss-lb:0.1066, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:25:58.813] iteration:9347  t-loss:0.1532, loss-lb:0.0970, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:25:59.006] iteration:9348  t-loss:0.1435, loss-lb:0.0959, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:25:59.198] iteration:9349  t-loss:0.1566, loss-lb:0.0948, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:25:59.390] iteration:9350  t-loss:0.1475, loss-lb:0.0991, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:25:59.583] iteration:9351  t-loss:0.2098, loss-lb:0.1031, loss-ulb:0.0534, weight:2.00, lr:0.0007
[11:25:59.776] iteration:9352  t-loss:0.1566, loss-lb:0.0953, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:25:59.967] iteration:9353  t-loss:0.1540, loss-lb:0.1004, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:26:00.159] iteration:9354  t-loss:0.1515, loss-lb:0.0915, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:26:00.353] iteration:9355  t-loss:0.1509, loss-lb:0.0906, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:26:00.545] iteration:9356  t-loss:0.1602, loss-lb:0.0979, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:26:00.736] iteration:9357  t-loss:0.1554, loss-lb:0.0851, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:26:00.927] iteration:9358  t-loss:0.1491, loss-lb:0.0906, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:26:01.117] iteration:9359  t-loss:0.1488, loss-lb:0.0994, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:26:01.306] iteration:9360  t-loss:0.1491, loss-lb:0.0925, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:26:01.497] iteration:9361  t-loss:0.1208, loss-lb:0.0737, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:26:01.688] iteration:9362  t-loss:0.1647, loss-lb:0.1007, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:26:01.879] iteration:9363  t-loss:0.1683, loss-lb:0.0938, loss-ulb:0.0372, weight:2.00, lr:0.0007
[11:26:02.069] iteration:9364  t-loss:0.1655, loss-lb:0.0886, loss-ulb:0.0385, weight:2.00, lr:0.0007
[11:26:02.259] iteration:9365  t-loss:0.1421, loss-lb:0.0994, loss-ulb:0.0214, weight:2.00, lr:0.0007
[11:26:02.450] iteration:9366  t-loss:0.1481, loss-lb:0.0836, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:26:02.641] iteration:9367  t-loss:0.1707, loss-lb:0.1023, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:26:02.832] iteration:9368  t-loss:0.1351, loss-lb:0.0890, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:26:03.022] iteration:9369  t-loss:0.1627, loss-lb:0.0896, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:26:03.215] iteration:9370  t-loss:0.1556, loss-lb:0.0992, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:26:03.406] iteration:9371  t-loss:0.1498, loss-lb:0.0948, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:26:03.599] iteration:9372  t-loss:0.1491, loss-lb:0.0927, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:26:03.792] iteration:9373  t-loss:0.1464, loss-lb:0.0933, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:26:03.985] iteration:9374  t-loss:0.1668, loss-lb:0.0953, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:26:04.178] iteration:9375  t-loss:0.1451, loss-lb:0.0906, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:26:04.371] iteration:9376  t-loss:0.1549, loss-lb:0.0913, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:26:04.580] iteration:9377  t-loss:0.1636, loss-lb:0.1026, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:26:04.780] iteration:9378  t-loss:0.2040, loss-lb:0.0971, loss-ulb:0.0535, weight:2.00, lr:0.0007
[11:26:04.974] iteration:9379  t-loss:0.1588, loss-lb:0.0895, loss-ulb:0.0347, weight:2.00, lr:0.0007
[11:26:05.166] iteration:9380  t-loss:0.1713, loss-lb:0.0864, loss-ulb:0.0424, weight:2.00, lr:0.0007
[11:26:05.360] iteration:9381  t-loss:0.1599, loss-lb:0.1063, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:26:05.553] iteration:9382  t-loss:0.1616, loss-lb:0.1066, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:26:05.747] iteration:9383  t-loss:0.1393, loss-lb:0.0802, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:26:05.938] iteration:9384  t-loss:0.1457, loss-lb:0.0920, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:26:06.131] iteration:9385  t-loss:0.1522, loss-lb:0.0955, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:26:06.325] iteration:9386  t-loss:0.1873, loss-lb:0.0957, loss-ulb:0.0458, weight:2.00, lr:0.0007
[11:26:06.517] iteration:9387  t-loss:0.1540, loss-lb:0.0974, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:26:06.710] iteration:9388  t-loss:0.1566, loss-lb:0.1019, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:26:06.903] iteration:9389  t-loss:0.1519, loss-lb:0.0918, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:26:07.097] iteration:9390  t-loss:0.2606, loss-lb:0.0898, loss-ulb:0.0854, weight:2.00, lr:0.0007
[11:26:07.289] iteration:9391  t-loss:0.1529, loss-lb:0.0808, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:26:07.482] iteration:9392  t-loss:0.1561, loss-lb:0.0933, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:26:07.674] iteration:9393  t-loss:0.1407, loss-lb:0.0894, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:26:07.867] iteration:9394  t-loss:0.1447, loss-lb:0.0910, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:26:08.061] iteration:9395  t-loss:0.2971, loss-lb:0.0930, loss-ulb:0.1021, weight:2.00, lr:0.0007
[11:26:08.254] iteration:9396  t-loss:0.1435, loss-lb:0.0840, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:26:08.446] iteration:9397  t-loss:0.1553, loss-lb:0.0938, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:26:08.640] iteration:9398  t-loss:0.1764, loss-lb:0.0910, loss-ulb:0.0427, weight:2.00, lr:0.0007
[11:26:08.836] iteration:9399  t-loss:0.1407, loss-lb:0.0856, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:26:09.029] iteration:9400  t-loss:0.2870, loss-lb:0.0886, loss-ulb:0.0992, weight:2.00, lr:0.0007
[11:26:09.221] iteration:9401  t-loss:0.1545, loss-lb:0.1007, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:26:09.412] iteration:9402  t-loss:0.1687, loss-lb:0.0870, loss-ulb:0.0409, weight:2.00, lr:0.0007
[11:26:09.602] iteration:9403  t-loss:0.1471, loss-lb:0.0988, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:26:09.792] iteration:9404  t-loss:0.1498, loss-lb:0.0888, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:26:09.984] iteration:9405  t-loss:0.1505, loss-lb:0.0867, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:26:10.174] iteration:9406  t-loss:0.1608, loss-lb:0.0888, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:26:10.365] iteration:9407  t-loss:0.1365, loss-lb:0.0918, loss-ulb:0.0223, weight:2.00, lr:0.0007
[11:26:10.556] iteration:9408  t-loss:0.1371, loss-lb:0.0902, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:26:11.172] iteration:9409  t-loss:0.1707, loss-lb:0.0986, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:26:11.369] iteration:9410  t-loss:0.1636, loss-lb:0.0943, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:26:11.562] iteration:9411  t-loss:0.1488, loss-lb:0.0826, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:26:11.755] iteration:9412  t-loss:0.1983, loss-lb:0.0951, loss-ulb:0.0516, weight:2.00, lr:0.0007
[11:26:11.947] iteration:9413  t-loss:0.1477, loss-lb:0.0941, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:26:12.139] iteration:9414  t-loss:0.1465, loss-lb:0.0941, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:26:12.332] iteration:9415  t-loss:0.1821, loss-lb:0.0948, loss-ulb:0.0436, weight:2.00, lr:0.0007
[11:26:12.525] iteration:9416  t-loss:0.1695, loss-lb:0.1043, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:26:12.718] iteration:9417  t-loss:0.1331, loss-lb:0.0808, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:26:12.910] iteration:9418  t-loss:0.1498, loss-lb:0.0955, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:26:13.103] iteration:9419  t-loss:0.1548, loss-lb:0.0913, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:26:13.296] iteration:9420  t-loss:0.1830, loss-lb:0.0900, loss-ulb:0.0465, weight:2.00, lr:0.0007
[11:26:13.488] iteration:9421  t-loss:0.2044, loss-lb:0.0951, loss-ulb:0.0547, weight:2.00, lr:0.0007
[11:26:13.680] iteration:9422  t-loss:0.1443, loss-lb:0.0985, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:26:13.877] iteration:9423  t-loss:0.1625, loss-lb:0.1018, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:26:14.069] iteration:9424  t-loss:0.1537, loss-lb:0.0903, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:26:14.262] iteration:9425  t-loss:0.1630, loss-lb:0.1048, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:26:14.455] iteration:9426  t-loss:0.1712, loss-lb:0.1049, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:26:14.646] iteration:9427  t-loss:0.1551, loss-lb:0.0965, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:26:14.839] iteration:9428  t-loss:0.1442, loss-lb:0.0837, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:26:15.031] iteration:9429  t-loss:0.1991, loss-lb:0.1073, loss-ulb:0.0459, weight:2.00, lr:0.0007
[11:26:15.224] iteration:9430  t-loss:0.2263, loss-lb:0.0962, loss-ulb:0.0650, weight:2.00, lr:0.0007
[11:26:15.418] iteration:9431  t-loss:0.1602, loss-lb:0.1127, loss-ulb:0.0237, weight:2.00, lr:0.0007
[11:26:15.610] iteration:9432  t-loss:0.1309, loss-lb:0.0818, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:26:15.802] iteration:9433  t-loss:0.1551, loss-lb:0.1047, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:26:15.995] iteration:9434  t-loss:0.1586, loss-lb:0.0985, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:26:16.186] iteration:9435  t-loss:0.1808, loss-lb:0.0920, loss-ulb:0.0444, weight:2.00, lr:0.0007
[11:26:16.379] iteration:9436  t-loss:0.1866, loss-lb:0.0937, loss-ulb:0.0465, weight:2.00, lr:0.0007
[11:26:16.572] iteration:9437  t-loss:0.1628, loss-lb:0.0932, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:26:16.765] iteration:9438  t-loss:0.1594, loss-lb:0.1004, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:26:16.957] iteration:9439  t-loss:0.1463, loss-lb:0.0901, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:26:17.149] iteration:9440  t-loss:0.1794, loss-lb:0.1017, loss-ulb:0.0388, weight:2.00, lr:0.0007
[11:26:17.341] iteration:9441  t-loss:0.1403, loss-lb:0.0848, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:26:17.532] iteration:9442  t-loss:0.1592, loss-lb:0.1015, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:26:17.726] iteration:9443  t-loss:0.3418, loss-lb:0.1021, loss-ulb:0.1199, weight:2.00, lr:0.0007
[11:26:17.919] iteration:9444  t-loss:0.1568, loss-lb:0.1016, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:26:18.111] iteration:9445  t-loss:0.1720, loss-lb:0.0858, loss-ulb:0.0431, weight:2.00, lr:0.0007
[11:26:18.303] iteration:9446  t-loss:0.1465, loss-lb:0.0859, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:26:18.497] iteration:9447  t-loss:0.1498, loss-lb:0.0948, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:26:18.690] iteration:9448  t-loss:0.1541, loss-lb:0.0972, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:26:18.882] iteration:9449  t-loss:0.1469, loss-lb:0.0916, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:26:19.075] iteration:9450  t-loss:0.1507, loss-lb:0.0903, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:26:19.268] iteration:9451  t-loss:0.1563, loss-lb:0.0955, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:26:19.460] iteration:9452  t-loss:0.1380, loss-lb:0.0900, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:26:19.653] iteration:9453  t-loss:0.1295, loss-lb:0.0791, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:26:19.846] iteration:9454  t-loss:0.1356, loss-lb:0.0958, loss-ulb:0.0199, weight:2.00, lr:0.0007
[11:26:20.039] iteration:9455  t-loss:0.1375, loss-lb:0.0827, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:26:20.233] iteration:9456  t-loss:0.1393, loss-lb:0.0892, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:26:20.426] iteration:9457  t-loss:0.1697, loss-lb:0.1009, loss-ulb:0.0344, weight:2.00, lr:0.0007
[11:26:20.619] iteration:9458  t-loss:0.1361, loss-lb:0.0844, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:26:20.811] iteration:9459  t-loss:0.1381, loss-lb:0.0881, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:26:21.003] iteration:9460  t-loss:0.1381, loss-lb:0.0792, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:26:21.195] iteration:9461  t-loss:0.1331, loss-lb:0.0907, loss-ulb:0.0212, weight:2.00, lr:0.0007
[11:26:21.388] iteration:9462  t-loss:0.1844, loss-lb:0.1036, loss-ulb:0.0404, weight:2.00, lr:0.0007
[11:26:21.581] iteration:9463  t-loss:0.1266, loss-lb:0.0873, loss-ulb:0.0197, weight:2.00, lr:0.0007
[11:26:21.773] iteration:9464  t-loss:0.1495, loss-lb:0.0915, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:26:21.965] iteration:9465  t-loss:0.1309, loss-lb:0.0858, loss-ulb:0.0226, weight:2.00, lr:0.0007
[11:26:22.158] iteration:9466  t-loss:0.1353, loss-lb:0.0859, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:26:22.351] iteration:9467  t-loss:0.1407, loss-lb:0.0887, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:26:22.543] iteration:9468  t-loss:0.1389, loss-lb:0.0879, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:26:22.736] iteration:9469  t-loss:0.1494, loss-lb:0.0883, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:26:22.929] iteration:9470  t-loss:0.1847, loss-lb:0.1012, loss-ulb:0.0417, weight:2.00, lr:0.0007
[11:26:23.121] iteration:9471  t-loss:0.1437, loss-lb:0.0939, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:26:23.318] iteration:9472  t-loss:0.1491, loss-lb:0.0890, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:26:23.510] iteration:9473  t-loss:0.1358, loss-lb:0.0904, loss-ulb:0.0227, weight:2.00, lr:0.0007
[11:26:23.702] iteration:9474  t-loss:0.1376, loss-lb:0.0967, loss-ulb:0.0204, weight:2.00, lr:0.0007
[11:26:23.894] iteration:9475  t-loss:0.1517, loss-lb:0.0978, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:26:24.087] iteration:9476  t-loss:0.1954, loss-lb:0.0916, loss-ulb:0.0519, weight:2.00, lr:0.0007
[11:26:24.280] iteration:9477  t-loss:0.1419, loss-lb:0.0841, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:26:24.473] iteration:9478  t-loss:0.1403, loss-lb:0.0908, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:26:24.664] iteration:9479  t-loss:0.1542, loss-lb:0.0900, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:26:24.856] iteration:9480  t-loss:0.1588, loss-lb:0.0928, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:26:25.048] iteration:9481  t-loss:0.2278, loss-lb:0.0998, loss-ulb:0.0640, weight:2.00, lr:0.0007
[11:26:25.241] iteration:9482  t-loss:0.1356, loss-lb:0.0851, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:26:25.433] iteration:9483  t-loss:0.1483, loss-lb:0.0858, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:26:25.626] iteration:9484  t-loss:0.1834, loss-lb:0.0889, loss-ulb:0.0473, weight:2.00, lr:0.0007
[11:26:25.819] iteration:9485  t-loss:0.1626, loss-lb:0.1128, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:26:26.010] iteration:9486  t-loss:0.1393, loss-lb:0.0910, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:26:26.204] iteration:9487  t-loss:0.2483, loss-lb:0.0902, loss-ulb:0.0791, weight:2.00, lr:0.0007
[11:26:26.397] iteration:9488  t-loss:0.1795, loss-lb:0.0893, loss-ulb:0.0451, weight:2.00, lr:0.0007
[11:26:26.589] iteration:9489  t-loss:0.1618, loss-lb:0.0990, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:26:26.781] iteration:9490  t-loss:0.1501, loss-lb:0.0979, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:26:26.974] iteration:9491  t-loss:0.1920, loss-lb:0.0878, loss-ulb:0.0521, weight:2.00, lr:0.0007
[11:26:27.166] iteration:9492  t-loss:0.1772, loss-lb:0.1009, loss-ulb:0.0381, weight:2.00, lr:0.0007
[11:26:27.358] iteration:9493  t-loss:0.1745, loss-lb:0.0886, loss-ulb:0.0429, weight:2.00, lr:0.0007
[11:26:27.551] iteration:9494  t-loss:0.1556, loss-lb:0.0915, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:26:27.745] iteration:9495  t-loss:0.1657, loss-lb:0.1049, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:26:27.937] iteration:9496  t-loss:0.1673, loss-lb:0.0894, loss-ulb:0.0390, weight:2.00, lr:0.0007
[11:26:28.129] iteration:9497  t-loss:0.1469, loss-lb:0.0987, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:26:28.322] iteration:9498  t-loss:0.2363, loss-lb:0.1037, loss-ulb:0.0663, weight:2.00, lr:0.0007
[11:26:28.513] iteration:9499  t-loss:0.1547, loss-lb:0.0979, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:26:28.704] iteration:9500  t-loss:0.1711, loss-lb:0.0956, loss-ulb:0.0377, weight:2.00, lr:0.0007
[11:26:28.894] iteration:9501  t-loss:0.1955, loss-lb:0.1094, loss-ulb:0.0430, weight:2.00, lr:0.0007
[11:26:29.085] iteration:9502  t-loss:0.1664, loss-lb:0.1047, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:26:29.276] iteration:9503  t-loss:0.2058, loss-lb:0.0875, loss-ulb:0.0592, weight:2.00, lr:0.0007
[11:26:29.466] iteration:9504  t-loss:0.1697, loss-lb:0.0901, loss-ulb:0.0398, weight:2.00, lr:0.0007
[11:26:29.657] iteration:9505  t-loss:0.1997, loss-lb:0.0997, loss-ulb:0.0500, weight:2.00, lr:0.0007
[11:26:29.848] iteration:9506  t-loss:0.1632, loss-lb:0.0895, loss-ulb:0.0369, weight:2.00, lr:0.0007
[11:26:40.873]  <<Test>> - Ep:96  - mean_dice/mean_h95 - S:89.04/2.09, Best-S:90.28, T:90.10/1.36, Best-T:90.48
[11:26:40.874]           - AvgLoss(lb/ulb/all):0.0938/0.0416/0.1791
[11:26:41.412] iteration:9507  t-loss:0.1593, loss-lb:0.0988, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:26:41.609] iteration:9508  t-loss:0.1961, loss-lb:0.1083, loss-ulb:0.0439, weight:2.00, lr:0.0007
[11:26:41.802] iteration:9509  t-loss:0.1828, loss-lb:0.1082, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:26:41.996] iteration:9510  t-loss:0.1707, loss-lb:0.1112, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:26:42.188] iteration:9511  t-loss:0.1564, loss-lb:0.1097, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:26:42.380] iteration:9512  t-loss:0.1704, loss-lb:0.1148, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:26:42.574] iteration:9513  t-loss:0.1802, loss-lb:0.1138, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:26:42.767] iteration:9514  t-loss:0.1674, loss-lb:0.1065, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:26:42.961] iteration:9515  t-loss:0.1942, loss-lb:0.0937, loss-ulb:0.0503, weight:2.00, lr:0.0007
[11:26:43.152] iteration:9516  t-loss:0.1648, loss-lb:0.0973, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:26:43.346] iteration:9517  t-loss:0.1945, loss-lb:0.1292, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:26:43.539] iteration:9518  t-loss:0.1597, loss-lb:0.1075, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:26:43.732] iteration:9519  t-loss:0.1513, loss-lb:0.0911, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:26:43.926] iteration:9520  t-loss:0.2235, loss-lb:0.0988, loss-ulb:0.0623, weight:2.00, lr:0.0007
[11:26:44.120] iteration:9521  t-loss:0.1627, loss-lb:0.0952, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:26:44.313] iteration:9522  t-loss:0.1704, loss-lb:0.1037, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:26:44.507] iteration:9523  t-loss:0.1576, loss-lb:0.1034, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:26:44.698] iteration:9524  t-loss:0.2531, loss-lb:0.1031, loss-ulb:0.0750, weight:2.00, lr:0.0007
[11:26:44.891] iteration:9525  t-loss:0.1607, loss-lb:0.0927, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:26:45.083] iteration:9526  t-loss:0.1936, loss-lb:0.1154, loss-ulb:0.0391, weight:2.00, lr:0.0007
[11:26:45.276] iteration:9527  t-loss:0.1524, loss-lb:0.0956, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:26:45.469] iteration:9528  t-loss:0.1840, loss-lb:0.0975, loss-ulb:0.0433, weight:2.00, lr:0.0007
[11:26:45.661] iteration:9529  t-loss:0.2188, loss-lb:0.1114, loss-ulb:0.0537, weight:2.00, lr:0.0007
[11:26:45.854] iteration:9530  t-loss:0.1690, loss-lb:0.1094, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:26:46.046] iteration:9531  t-loss:0.1573, loss-lb:0.0955, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:26:46.238] iteration:9532  t-loss:0.1581, loss-lb:0.1005, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:26:46.431] iteration:9533  t-loss:0.1550, loss-lb:0.0958, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:26:46.624] iteration:9534  t-loss:0.1475, loss-lb:0.0914, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:26:46.817] iteration:9535  t-loss:0.1896, loss-lb:0.0999, loss-ulb:0.0449, weight:2.00, lr:0.0007
[11:26:47.009] iteration:9536  t-loss:0.1494, loss-lb:0.0955, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:26:47.202] iteration:9537  t-loss:0.1591, loss-lb:0.1034, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:26:47.395] iteration:9538  t-loss:0.1708, loss-lb:0.1136, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:26:47.588] iteration:9539  t-loss:0.1559, loss-lb:0.0826, loss-ulb:0.0367, weight:2.00, lr:0.0007
[11:26:47.780] iteration:9540  t-loss:0.1328, loss-lb:0.0899, loss-ulb:0.0214, weight:2.00, lr:0.0007
[11:26:47.974] iteration:9541  t-loss:0.1507, loss-lb:0.0936, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:26:48.165] iteration:9542  t-loss:0.1431, loss-lb:0.0920, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:26:48.357] iteration:9543  t-loss:0.1710, loss-lb:0.1041, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:26:48.550] iteration:9544  t-loss:0.2170, loss-lb:0.0990, loss-ulb:0.0590, weight:2.00, lr:0.0007
[11:26:48.743] iteration:9545  t-loss:0.1494, loss-lb:0.0947, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:26:48.936] iteration:9546  t-loss:0.2680, loss-lb:0.0963, loss-ulb:0.0858, weight:2.00, lr:0.0007
[11:26:49.129] iteration:9547  t-loss:0.1482, loss-lb:0.0907, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:26:49.322] iteration:9548  t-loss:0.1526, loss-lb:0.0915, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:26:49.513] iteration:9549  t-loss:0.2164, loss-lb:0.0964, loss-ulb:0.0600, weight:2.00, lr:0.0007
[11:26:49.705] iteration:9550  t-loss:0.1524, loss-lb:0.1062, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:26:49.898] iteration:9551  t-loss:0.1551, loss-lb:0.0934, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:26:50.089] iteration:9552  t-loss:0.2135, loss-lb:0.0870, loss-ulb:0.0632, weight:2.00, lr:0.0007
[11:26:50.281] iteration:9553  t-loss:0.1676, loss-lb:0.0893, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:26:50.474] iteration:9554  t-loss:0.1616, loss-lb:0.1050, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:26:50.666] iteration:9555  t-loss:0.1641, loss-lb:0.1018, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:26:50.860] iteration:9556  t-loss:0.1769, loss-lb:0.0946, loss-ulb:0.0411, weight:2.00, lr:0.0007
[11:26:51.053] iteration:9557  t-loss:0.1538, loss-lb:0.0906, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:26:51.244] iteration:9558  t-loss:0.1560, loss-lb:0.0985, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:26:51.437] iteration:9559  t-loss:0.2133, loss-lb:0.1070, loss-ulb:0.0532, weight:2.00, lr:0.0007
[11:26:51.629] iteration:9560  t-loss:0.1538, loss-lb:0.0947, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:26:51.821] iteration:9561  t-loss:0.1407, loss-lb:0.0916, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:26:52.013] iteration:9562  t-loss:0.1867, loss-lb:0.0948, loss-ulb:0.0460, weight:2.00, lr:0.0007
[11:26:52.205] iteration:9563  t-loss:0.1657, loss-lb:0.0976, loss-ulb:0.0341, weight:2.00, lr:0.0007
[11:26:52.399] iteration:9564  t-loss:0.1599, loss-lb:0.0886, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:26:52.593] iteration:9565  t-loss:0.1952, loss-lb:0.0969, loss-ulb:0.0492, weight:2.00, lr:0.0007
[11:26:52.785] iteration:9566  t-loss:0.1656, loss-lb:0.1189, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:26:52.978] iteration:9567  t-loss:0.1618, loss-lb:0.1035, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:26:53.170] iteration:9568  t-loss:0.1700, loss-lb:0.1037, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:26:53.362] iteration:9569  t-loss:0.1712, loss-lb:0.0926, loss-ulb:0.0393, weight:2.00, lr:0.0007
[11:26:53.555] iteration:9570  t-loss:0.1492, loss-lb:0.0870, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:26:53.750] iteration:9571  t-loss:0.2120, loss-lb:0.0929, loss-ulb:0.0595, weight:2.00, lr:0.0007
[11:26:53.944] iteration:9572  t-loss:0.1496, loss-lb:0.0938, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:26:54.139] iteration:9573  t-loss:0.1686, loss-lb:0.1086, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:26:54.331] iteration:9574  t-loss:0.2091, loss-lb:0.0929, loss-ulb:0.0581, weight:2.00, lr:0.0007
[11:26:54.523] iteration:9575  t-loss:0.1904, loss-lb:0.0962, loss-ulb:0.0471, weight:2.00, lr:0.0007
[11:26:54.714] iteration:9576  t-loss:0.1533, loss-lb:0.0906, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:26:54.906] iteration:9577  t-loss:0.1769, loss-lb:0.1125, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:26:55.097] iteration:9578  t-loss:0.1825, loss-lb:0.1056, loss-ulb:0.0385, weight:2.00, lr:0.0007
[11:26:55.289] iteration:9579  t-loss:0.1587, loss-lb:0.0884, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:26:55.481] iteration:9580  t-loss:0.1545, loss-lb:0.1075, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:26:55.674] iteration:9581  t-loss:0.1569, loss-lb:0.1006, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:26:55.866] iteration:9582  t-loss:0.1492, loss-lb:0.0977, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:26:56.057] iteration:9583  t-loss:0.1508, loss-lb:0.1038, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:26:56.249] iteration:9584  t-loss:0.1572, loss-lb:0.0961, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:26:56.441] iteration:9585  t-loss:0.1360, loss-lb:0.0922, loss-ulb:0.0219, weight:2.00, lr:0.0007
[11:26:56.633] iteration:9586  t-loss:0.1509, loss-lb:0.0899, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:26:56.825] iteration:9587  t-loss:0.1597, loss-lb:0.1012, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:26:57.017] iteration:9588  t-loss:0.1677, loss-lb:0.1111, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:26:57.208] iteration:9589  t-loss:0.1430, loss-lb:0.0870, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:26:57.399] iteration:9590  t-loss:0.1481, loss-lb:0.0871, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:26:57.591] iteration:9591  t-loss:0.1577, loss-lb:0.0904, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:26:57.782] iteration:9592  t-loss:0.1598, loss-lb:0.0892, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:26:57.975] iteration:9593  t-loss:0.1532, loss-lb:0.0957, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:26:58.167] iteration:9594  t-loss:0.1406, loss-lb:0.0933, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:26:58.358] iteration:9595  t-loss:0.1568, loss-lb:0.0894, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:26:58.550] iteration:9596  t-loss:0.1609, loss-lb:0.0940, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:26:58.741] iteration:9597  t-loss:0.1432, loss-lb:0.0908, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:26:58.932] iteration:9598  t-loss:0.1671, loss-lb:0.0962, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:26:59.122] iteration:9599  t-loss:0.1642, loss-lb:0.0864, loss-ulb:0.0389, weight:2.00, lr:0.0007
[11:26:59.312] iteration:9600  t-loss:0.1638, loss-lb:0.0968, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:26:59.503] iteration:9601  t-loss:0.1370, loss-lb:0.0863, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:26:59.694] iteration:9602  t-loss:0.1405, loss-lb:0.0895, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:26:59.885] iteration:9603  t-loss:0.1365, loss-lb:0.0871, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:27:00.076] iteration:9604  t-loss:0.1361, loss-lb:0.0867, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:27:00.676] iteration:9605  t-loss:0.2182, loss-lb:0.0893, loss-ulb:0.0644, weight:2.00, lr:0.0007
[11:27:00.873] iteration:9606  t-loss:0.1461, loss-lb:0.0847, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:27:01.066] iteration:9607  t-loss:0.1519, loss-lb:0.0910, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:27:01.257] iteration:9608  t-loss:0.1844, loss-lb:0.0915, loss-ulb:0.0464, weight:2.00, lr:0.0007
[11:27:01.449] iteration:9609  t-loss:0.1488, loss-lb:0.0970, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:27:01.639] iteration:9610  t-loss:0.1432, loss-lb:0.0997, loss-ulb:0.0218, weight:2.00, lr:0.0007
[11:27:01.831] iteration:9611  t-loss:0.1405, loss-lb:0.0909, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:27:02.022] iteration:9612  t-loss:0.1601, loss-lb:0.0929, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:27:02.214] iteration:9613  t-loss:0.1980, loss-lb:0.0872, loss-ulb:0.0554, weight:2.00, lr:0.0007
[11:27:02.406] iteration:9614  t-loss:0.1556, loss-lb:0.0939, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:27:02.597] iteration:9615  t-loss:0.2004, loss-lb:0.0909, loss-ulb:0.0548, weight:2.00, lr:0.0007
[11:27:02.788] iteration:9616  t-loss:0.1447, loss-lb:0.0848, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:27:02.979] iteration:9617  t-loss:0.1406, loss-lb:0.0905, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:27:03.170] iteration:9618  t-loss:0.1736, loss-lb:0.0955, loss-ulb:0.0390, weight:2.00, lr:0.0007
[11:27:03.362] iteration:9619  t-loss:0.1455, loss-lb:0.0928, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:27:03.553] iteration:9620  t-loss:0.1427, loss-lb:0.0915, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:27:03.744] iteration:9621  t-loss:0.1889, loss-lb:0.1373, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:27:03.935] iteration:9622  t-loss:0.1526, loss-lb:0.0925, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:27:04.128] iteration:9623  t-loss:0.3060, loss-lb:0.0960, loss-ulb:0.1050, weight:2.00, lr:0.0007
[11:27:04.321] iteration:9624  t-loss:0.1724, loss-lb:0.0905, loss-ulb:0.0409, weight:2.00, lr:0.0007
[11:27:04.518] iteration:9625  t-loss:0.1582, loss-lb:0.0965, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:27:04.712] iteration:9626  t-loss:0.1354, loss-lb:0.0909, loss-ulb:0.0222, weight:2.00, lr:0.0007
[11:27:04.907] iteration:9627  t-loss:0.1389, loss-lb:0.0887, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:27:05.099] iteration:9628  t-loss:0.1330, loss-lb:0.0790, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:27:05.292] iteration:9629  t-loss:0.1430, loss-lb:0.0911, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:27:05.485] iteration:9630  t-loss:0.3290, loss-lb:0.1025, loss-ulb:0.1132, weight:2.00, lr:0.0007
[11:27:05.678] iteration:9631  t-loss:0.1494, loss-lb:0.0968, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:27:05.870] iteration:9632  t-loss:0.1745, loss-lb:0.0981, loss-ulb:0.0382, weight:2.00, lr:0.0007
[11:27:06.063] iteration:9633  t-loss:0.2217, loss-lb:0.0989, loss-ulb:0.0614, weight:2.00, lr:0.0007
[11:27:06.256] iteration:9634  t-loss:0.1486, loss-lb:0.1008, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:27:06.447] iteration:9635  t-loss:0.1359, loss-lb:0.0849, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:27:06.641] iteration:9636  t-loss:0.1391, loss-lb:0.0880, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:27:06.834] iteration:9637  t-loss:0.1579, loss-lb:0.0942, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:27:07.025] iteration:9638  t-loss:0.1504, loss-lb:0.1039, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:27:07.221] iteration:9639  t-loss:0.1509, loss-lb:0.0938, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:27:07.414] iteration:9640  t-loss:0.1419, loss-lb:0.0954, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:27:07.606] iteration:9641  t-loss:0.1564, loss-lb:0.0977, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:27:07.800] iteration:9642  t-loss:0.1399, loss-lb:0.0864, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:27:07.991] iteration:9643  t-loss:0.1530, loss-lb:0.1010, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:27:08.180] iteration:9644  t-loss:0.1428, loss-lb:0.0875, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:27:08.371] iteration:9645  t-loss:0.1377, loss-lb:0.0844, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:27:08.564] iteration:9646  t-loss:0.2054, loss-lb:0.0919, loss-ulb:0.0567, weight:2.00, lr:0.0007
[11:27:08.757] iteration:9647  t-loss:0.1483, loss-lb:0.0988, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:27:08.948] iteration:9648  t-loss:0.1498, loss-lb:0.0905, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:27:09.140] iteration:9649  t-loss:0.2111, loss-lb:0.0956, loss-ulb:0.0578, weight:2.00, lr:0.0007
[11:27:09.332] iteration:9650  t-loss:0.1382, loss-lb:0.0839, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:27:09.524] iteration:9651  t-loss:0.1464, loss-lb:0.0879, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:27:09.716] iteration:9652  t-loss:0.1371, loss-lb:0.0864, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:27:09.908] iteration:9653  t-loss:0.1564, loss-lb:0.0940, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:27:10.118] iteration:9654  t-loss:0.1423, loss-lb:0.0924, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:27:10.317] iteration:9655  t-loss:0.1723, loss-lb:0.0833, loss-ulb:0.0445, weight:2.00, lr:0.0007
[11:27:10.510] iteration:9656  t-loss:0.1491, loss-lb:0.0876, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:27:10.703] iteration:9657  t-loss:0.2146, loss-lb:0.0928, loss-ulb:0.0609, weight:2.00, lr:0.0007
[11:27:10.894] iteration:9658  t-loss:0.1550, loss-lb:0.0941, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:27:11.087] iteration:9659  t-loss:0.1424, loss-lb:0.0886, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:27:11.278] iteration:9660  t-loss:0.1408, loss-lb:0.0931, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:27:11.469] iteration:9661  t-loss:0.1864, loss-lb:0.0934, loss-ulb:0.0465, weight:2.00, lr:0.0007
[11:27:11.659] iteration:9662  t-loss:0.1546, loss-lb:0.0850, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:27:11.851] iteration:9663  t-loss:0.1837, loss-lb:0.0888, loss-ulb:0.0474, weight:2.00, lr:0.0007
[11:27:12.044] iteration:9664  t-loss:0.1541, loss-lb:0.0899, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:27:12.239] iteration:9665  t-loss:0.1435, loss-lb:0.0924, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:27:12.430] iteration:9666  t-loss:0.1331, loss-lb:0.0852, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:27:12.623] iteration:9667  t-loss:0.2809, loss-lb:0.0888, loss-ulb:0.0961, weight:2.00, lr:0.0007
[11:27:12.814] iteration:9668  t-loss:0.1626, loss-lb:0.0996, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:27:13.005] iteration:9669  t-loss:0.1552, loss-lb:0.0947, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:27:13.196] iteration:9670  t-loss:0.1344, loss-lb:0.0940, loss-ulb:0.0202, weight:2.00, lr:0.0007
[11:27:13.387] iteration:9671  t-loss:0.1444, loss-lb:0.1013, loss-ulb:0.0215, weight:2.00, lr:0.0007
[11:27:13.579] iteration:9672  t-loss:0.1909, loss-lb:0.0919, loss-ulb:0.0495, weight:2.00, lr:0.0007
[11:27:13.772] iteration:9673  t-loss:0.2668, loss-lb:0.0943, loss-ulb:0.0862, weight:2.00, lr:0.0007
[11:27:13.963] iteration:9674  t-loss:0.1435, loss-lb:0.0892, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:27:14.155] iteration:9675  t-loss:0.1690, loss-lb:0.1104, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:27:14.345] iteration:9676  t-loss:0.1650, loss-lb:0.1035, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:27:14.537] iteration:9677  t-loss:0.1605, loss-lb:0.0959, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:27:14.728] iteration:9678  t-loss:0.1970, loss-lb:0.0920, loss-ulb:0.0525, weight:2.00, lr:0.0007
[11:27:14.921] iteration:9679  t-loss:0.2247, loss-lb:0.0961, loss-ulb:0.0643, weight:2.00, lr:0.0007
[11:27:15.114] iteration:9680  t-loss:0.1371, loss-lb:0.0894, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:27:15.308] iteration:9681  t-loss:0.2263, loss-lb:0.0935, loss-ulb:0.0664, weight:2.00, lr:0.0007
[11:27:15.505] iteration:9682  t-loss:0.1683, loss-lb:0.0942, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:27:15.700] iteration:9683  t-loss:0.3060, loss-lb:0.0972, loss-ulb:0.1044, weight:2.00, lr:0.0007
[11:27:15.895] iteration:9684  t-loss:0.1736, loss-lb:0.1033, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:27:16.086] iteration:9685  t-loss:0.1332, loss-lb:0.0796, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:27:16.278] iteration:9686  t-loss:0.1668, loss-lb:0.1111, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:27:16.470] iteration:9687  t-loss:0.1499, loss-lb:0.0917, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:27:16.661] iteration:9688  t-loss:0.1489, loss-lb:0.0981, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:27:16.854] iteration:9689  t-loss:0.1527, loss-lb:0.0874, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:27:17.045] iteration:9690  t-loss:0.1644, loss-lb:0.0846, loss-ulb:0.0399, weight:2.00, lr:0.0007
[11:27:17.237] iteration:9691  t-loss:0.1929, loss-lb:0.1027, loss-ulb:0.0451, weight:2.00, lr:0.0007
[11:27:17.430] iteration:9692  t-loss:0.1902, loss-lb:0.0958, loss-ulb:0.0472, weight:2.00, lr:0.0007
[11:27:17.622] iteration:9693  t-loss:0.1574, loss-lb:0.1022, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:27:17.813] iteration:9694  t-loss:0.1595, loss-lb:0.0867, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:27:18.005] iteration:9695  t-loss:0.1624, loss-lb:0.0915, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:27:18.196] iteration:9696  t-loss:0.3104, loss-lb:0.0917, loss-ulb:0.1093, weight:2.00, lr:0.0007
[11:27:18.388] iteration:9697  t-loss:0.2132, loss-lb:0.1007, loss-ulb:0.0563, weight:2.00, lr:0.0007
[11:27:18.577] iteration:9698  t-loss:0.1440, loss-lb:0.0957, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:27:18.769] iteration:9699  t-loss:0.1622, loss-lb:0.1037, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:27:18.960] iteration:9700  t-loss:0.1435, loss-lb:0.0921, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:27:19.151] iteration:9701  t-loss:0.1307, loss-lb:0.0782, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:27:19.342] iteration:9702  t-loss:0.1938, loss-lb:0.0881, loss-ulb:0.0528, weight:2.00, lr:0.0007
[11:27:31.965]  <<Test>> - Ep:98  - mean_dice/mean_h95 - S:89.73/1.45, Best-S:90.28, T:90.28/1.37, Best-T:90.48
[11:27:31.965]           - AvgLoss(lb/ulb/all):0.0933/0.0418/0.1778
[11:27:32.464] iteration:9703  t-loss:0.1527, loss-lb:0.1037, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:27:32.661] iteration:9704  t-loss:0.1638, loss-lb:0.1049, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:27:32.854] iteration:9705  t-loss:0.1444, loss-lb:0.0918, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:27:33.047] iteration:9706  t-loss:0.1846, loss-lb:0.0953, loss-ulb:0.0447, weight:2.00, lr:0.0007
[11:27:33.239] iteration:9707  t-loss:0.1566, loss-lb:0.0955, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:27:33.435] iteration:9708  t-loss:0.1567, loss-lb:0.1022, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:27:33.629] iteration:9709  t-loss:0.1582, loss-lb:0.0971, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:27:33.821] iteration:9710  t-loss:0.1504, loss-lb:0.0888, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:27:34.013] iteration:9711  t-loss:0.1467, loss-lb:0.0871, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:27:34.207] iteration:9712  t-loss:0.2311, loss-lb:0.1000, loss-ulb:0.0655, weight:2.00, lr:0.0007
[11:27:34.399] iteration:9713  t-loss:0.1585, loss-lb:0.0889, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:27:34.591] iteration:9714  t-loss:0.1473, loss-lb:0.0893, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:27:34.783] iteration:9715  t-loss:0.1483, loss-lb:0.0951, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:27:34.974] iteration:9716  t-loss:0.1486, loss-lb:0.0882, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:27:35.166] iteration:9717  t-loss:0.1651, loss-lb:0.1052, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:27:35.357] iteration:9718  t-loss:0.1409, loss-lb:0.0966, loss-ulb:0.0221, weight:2.00, lr:0.0007
[11:27:35.549] iteration:9719  t-loss:0.1580, loss-lb:0.0957, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:27:35.742] iteration:9720  t-loss:0.1650, loss-lb:0.0957, loss-ulb:0.0347, weight:2.00, lr:0.0007
[11:27:35.934] iteration:9721  t-loss:0.1411, loss-lb:0.0917, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:27:36.126] iteration:9722  t-loss:0.1537, loss-lb:0.0880, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:27:36.318] iteration:9723  t-loss:0.1823, loss-lb:0.0944, loss-ulb:0.0439, weight:2.00, lr:0.0007
[11:27:36.509] iteration:9724  t-loss:0.1511, loss-lb:0.0932, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:27:36.700] iteration:9725  t-loss:0.1475, loss-lb:0.0976, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:27:36.894] iteration:9726  t-loss:0.1355, loss-lb:0.0925, loss-ulb:0.0215, weight:2.00, lr:0.0007
[11:27:37.087] iteration:9727  t-loss:0.1548, loss-lb:0.0857, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:27:37.280] iteration:9728  t-loss:0.1599, loss-lb:0.0953, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:27:37.474] iteration:9729  t-loss:0.1481, loss-lb:0.0836, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:27:37.668] iteration:9730  t-loss:0.1508, loss-lb:0.0912, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:27:37.861] iteration:9731  t-loss:0.1368, loss-lb:0.0903, loss-ulb:0.0233, weight:2.00, lr:0.0007
[11:27:38.053] iteration:9732  t-loss:0.1437, loss-lb:0.0899, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:27:38.246] iteration:9733  t-loss:0.1321, loss-lb:0.0851, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:27:38.440] iteration:9734  t-loss:0.1581, loss-lb:0.1082, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:27:38.633] iteration:9735  t-loss:0.1371, loss-lb:0.0833, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:27:38.826] iteration:9736  t-loss:0.1500, loss-lb:0.0889, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:27:39.019] iteration:9737  t-loss:0.1791, loss-lb:0.1185, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:27:39.213] iteration:9738  t-loss:0.1390, loss-lb:0.0904, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:27:39.407] iteration:9739  t-loss:0.1490, loss-lb:0.0924, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:27:39.599] iteration:9740  t-loss:0.1415, loss-lb:0.1005, loss-ulb:0.0205, weight:2.00, lr:0.0007
[11:27:39.792] iteration:9741  t-loss:0.1607, loss-lb:0.0953, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:27:39.984] iteration:9742  t-loss:0.1356, loss-lb:0.0879, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:27:40.176] iteration:9743  t-loss:0.1437, loss-lb:0.0898, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:27:40.365] iteration:9744  t-loss:0.1567, loss-lb:0.0883, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:27:40.557] iteration:9745  t-loss:0.1303, loss-lb:0.0818, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:27:40.749] iteration:9746  t-loss:0.1359, loss-lb:0.0887, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:27:40.940] iteration:9747  t-loss:0.1648, loss-lb:0.1103, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:27:41.135] iteration:9748  t-loss:0.2543, loss-lb:0.0887, loss-ulb:0.0828, weight:2.00, lr:0.0007
[11:27:41.328] iteration:9749  t-loss:0.1391, loss-lb:0.0823, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:27:41.520] iteration:9750  t-loss:0.1381, loss-lb:0.0880, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:27:41.712] iteration:9751  t-loss:0.1363, loss-lb:0.0910, loss-ulb:0.0226, weight:2.00, lr:0.0007
[11:27:41.905] iteration:9752  t-loss:0.1596, loss-lb:0.0821, loss-ulb:0.0387, weight:2.00, lr:0.0007
[11:27:42.096] iteration:9753  t-loss:0.1380, loss-lb:0.0931, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:27:42.289] iteration:9754  t-loss:0.1503, loss-lb:0.0915, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:27:42.481] iteration:9755  t-loss:0.2608, loss-lb:0.0896, loss-ulb:0.0856, weight:2.00, lr:0.0007
[11:27:42.673] iteration:9756  t-loss:0.1431, loss-lb:0.0856, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:27:42.878] iteration:9757  t-loss:0.1392, loss-lb:0.0861, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:27:43.078] iteration:9758  t-loss:0.1467, loss-lb:0.0970, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:27:43.271] iteration:9759  t-loss:0.1930, loss-lb:0.0892, loss-ulb:0.0519, weight:2.00, lr:0.0007
[11:27:43.462] iteration:9760  t-loss:0.1385, loss-lb:0.0833, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:27:43.654] iteration:9761  t-loss:0.1450, loss-lb:0.0909, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:27:43.847] iteration:9762  t-loss:0.1458, loss-lb:0.0876, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:27:44.038] iteration:9763  t-loss:0.1320, loss-lb:0.0817, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:27:44.228] iteration:9764  t-loss:0.1402, loss-lb:0.0900, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:27:44.422] iteration:9765  t-loss:0.1555, loss-lb:0.0987, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:27:44.615] iteration:9766  t-loss:0.1531, loss-lb:0.0908, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:27:44.807] iteration:9767  t-loss:0.1523, loss-lb:0.0926, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:27:45.000] iteration:9768  t-loss:0.1392, loss-lb:0.0880, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:27:45.192] iteration:9769  t-loss:0.1489, loss-lb:0.0918, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:27:45.384] iteration:9770  t-loss:0.1330, loss-lb:0.0809, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:27:45.576] iteration:9771  t-loss:0.1275, loss-lb:0.0870, loss-ulb:0.0202, weight:2.00, lr:0.0007
[11:27:45.768] iteration:9772  t-loss:0.1511, loss-lb:0.1009, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:27:45.960] iteration:9773  t-loss:0.1527, loss-lb:0.0853, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:27:46.153] iteration:9774  t-loss:0.1572, loss-lb:0.0881, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:27:46.344] iteration:9775  t-loss:0.1766, loss-lb:0.1061, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:27:46.536] iteration:9776  t-loss:0.1264, loss-lb:0.0807, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:27:46.730] iteration:9777  t-loss:0.1937, loss-lb:0.0922, loss-ulb:0.0507, weight:2.00, lr:0.0007
[11:27:46.922] iteration:9778  t-loss:0.1431, loss-lb:0.0913, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:27:47.113] iteration:9779  t-loss:0.1437, loss-lb:0.0934, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:27:47.306] iteration:9780  t-loss:0.1429, loss-lb:0.0891, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:27:47.499] iteration:9781  t-loss:0.1517, loss-lb:0.0857, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:27:47.692] iteration:9782  t-loss:0.1645, loss-lb:0.0859, loss-ulb:0.0393, weight:2.00, lr:0.0007
[11:27:47.882] iteration:9783  t-loss:0.1489, loss-lb:0.0822, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:27:48.076] iteration:9784  t-loss:0.1802, loss-lb:0.0920, loss-ulb:0.0441, weight:2.00, lr:0.0007
[11:27:48.269] iteration:9785  t-loss:0.1358, loss-lb:0.0857, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:27:48.461] iteration:9786  t-loss:0.1398, loss-lb:0.0897, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:27:48.652] iteration:9787  t-loss:0.1515, loss-lb:0.0957, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:27:48.850] iteration:9788  t-loss:0.1355, loss-lb:0.0868, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:27:49.042] iteration:9789  t-loss:0.1434, loss-lb:0.0911, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:27:49.234] iteration:9790  t-loss:0.1494, loss-lb:0.0879, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:27:49.427] iteration:9791  t-loss:0.1387, loss-lb:0.0895, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:27:49.620] iteration:9792  t-loss:0.1649, loss-lb:0.0912, loss-ulb:0.0369, weight:2.00, lr:0.0007
[11:27:49.812] iteration:9793  t-loss:0.1737, loss-lb:0.0925, loss-ulb:0.0406, weight:2.00, lr:0.0007
[11:27:50.003] iteration:9794  t-loss:0.1346, loss-lb:0.0921, loss-ulb:0.0212, weight:2.00, lr:0.0007
[11:27:50.195] iteration:9795  t-loss:0.1894, loss-lb:0.0825, loss-ulb:0.0535, weight:2.00, lr:0.0007
[11:27:50.385] iteration:9796  t-loss:0.1766, loss-lb:0.1000, loss-ulb:0.0383, weight:2.00, lr:0.0007
[11:27:50.576] iteration:9797  t-loss:0.1421, loss-lb:0.0837, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:27:50.768] iteration:9798  t-loss:0.1652, loss-lb:0.1015, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:27:50.958] iteration:9799  t-loss:0.1576, loss-lb:0.1014, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:27:51.150] iteration:9800  t-loss:0.2190, loss-lb:0.0954, loss-ulb:0.0618, weight:2.00, lr:0.0007
[11:27:51.734] iteration:9801  t-loss:0.1740, loss-lb:0.1005, loss-ulb:0.0367, weight:2.00, lr:0.0007
[11:27:51.928] iteration:9802  t-loss:0.1660, loss-lb:0.0961, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:27:52.121] iteration:9803  t-loss:0.1507, loss-lb:0.0907, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:27:52.313] iteration:9804  t-loss:0.1476, loss-lb:0.0888, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:27:52.505] iteration:9805  t-loss:0.1460, loss-lb:0.0960, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:27:52.697] iteration:9806  t-loss:0.1553, loss-lb:0.1046, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:27:52.889] iteration:9807  t-loss:0.1613, loss-lb:0.1081, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:27:53.082] iteration:9808  t-loss:0.1572, loss-lb:0.0940, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:27:53.274] iteration:9809  t-loss:0.1482, loss-lb:0.0887, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:27:53.467] iteration:9810  t-loss:0.1420, loss-lb:0.0781, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:27:53.658] iteration:9811  t-loss:0.1745, loss-lb:0.0911, loss-ulb:0.0417, weight:2.00, lr:0.0007
[11:27:53.850] iteration:9812  t-loss:0.1498, loss-lb:0.0968, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:27:54.044] iteration:9813  t-loss:0.1859, loss-lb:0.0904, loss-ulb:0.0478, weight:2.00, lr:0.0007
[11:27:54.238] iteration:9814  t-loss:0.1675, loss-lb:0.0918, loss-ulb:0.0378, weight:2.00, lr:0.0007
[11:27:54.430] iteration:9815  t-loss:0.1536, loss-lb:0.0949, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:27:54.623] iteration:9816  t-loss:0.1701, loss-lb:0.0917, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:27:54.816] iteration:9817  t-loss:0.1599, loss-lb:0.1051, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:27:55.008] iteration:9818  t-loss:0.1787, loss-lb:0.0942, loss-ulb:0.0423, weight:2.00, lr:0.0007
[11:27:55.200] iteration:9819  t-loss:0.1514, loss-lb:0.0908, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:27:55.393] iteration:9820  t-loss:0.2024, loss-lb:0.0972, loss-ulb:0.0526, weight:2.00, lr:0.0007
[11:27:55.585] iteration:9821  t-loss:0.1660, loss-lb:0.0975, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:27:55.777] iteration:9822  t-loss:0.1588, loss-lb:0.1027, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:27:55.970] iteration:9823  t-loss:0.1564, loss-lb:0.1037, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:27:56.163] iteration:9824  t-loss:0.1539, loss-lb:0.0930, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:27:56.356] iteration:9825  t-loss:0.1340, loss-lb:0.0871, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:27:56.549] iteration:9826  t-loss:0.1741, loss-lb:0.0967, loss-ulb:0.0387, weight:2.00, lr:0.0007
[11:27:56.741] iteration:9827  t-loss:0.1473, loss-lb:0.0917, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:27:56.933] iteration:9828  t-loss:0.2253, loss-lb:0.0836, loss-ulb:0.0709, weight:2.00, lr:0.0007
[11:27:57.126] iteration:9829  t-loss:0.1578, loss-lb:0.0961, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:27:57.319] iteration:9830  t-loss:0.1446, loss-lb:0.0945, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:27:57.512] iteration:9831  t-loss:0.2195, loss-lb:0.0889, loss-ulb:0.0653, weight:2.00, lr:0.0007
[11:27:57.705] iteration:9832  t-loss:0.1605, loss-lb:0.0940, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:27:57.897] iteration:9833  t-loss:0.1534, loss-lb:0.0929, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:27:58.090] iteration:9834  t-loss:0.1422, loss-lb:0.0903, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:27:58.282] iteration:9835  t-loss:0.1604, loss-lb:0.1002, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:27:58.475] iteration:9836  t-loss:0.1569, loss-lb:0.0998, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:27:58.669] iteration:9837  t-loss:0.1482, loss-lb:0.0827, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:27:58.861] iteration:9838  t-loss:0.1453, loss-lb:0.0923, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:27:59.054] iteration:9839  t-loss:0.1360, loss-lb:0.0925, loss-ulb:0.0217, weight:2.00, lr:0.0007
[11:27:59.252] iteration:9840  t-loss:0.1436, loss-lb:0.0887, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:27:59.451] iteration:9841  t-loss:0.1621, loss-lb:0.0942, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:27:59.644] iteration:9842  t-loss:0.3289, loss-lb:0.1137, loss-ulb:0.1076, weight:2.00, lr:0.0007
[11:27:59.836] iteration:9843  t-loss:0.1615, loss-lb:0.0819, loss-ulb:0.0398, weight:2.00, lr:0.0007
[11:28:00.029] iteration:9844  t-loss:0.1395, loss-lb:0.0919, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:28:00.228] iteration:9845  t-loss:0.1775, loss-lb:0.0858, loss-ulb:0.0459, weight:2.00, lr:0.0007
[11:28:00.421] iteration:9846  t-loss:0.1640, loss-lb:0.0897, loss-ulb:0.0372, weight:2.00, lr:0.0007
[11:28:00.613] iteration:9847  t-loss:0.1610, loss-lb:0.0934, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:28:00.805] iteration:9848  t-loss:0.1582, loss-lb:0.0996, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:28:01.005] iteration:9849  t-loss:0.1488, loss-lb:0.0944, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:28:01.198] iteration:9850  t-loss:0.1766, loss-lb:0.1129, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:28:01.391] iteration:9851  t-loss:0.1452, loss-lb:0.0963, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:28:01.583] iteration:9852  t-loss:0.1789, loss-lb:0.0986, loss-ulb:0.0402, weight:2.00, lr:0.0007
[11:28:01.775] iteration:9853  t-loss:0.2687, loss-lb:0.0811, loss-ulb:0.0938, weight:2.00, lr:0.0007
[11:28:01.969] iteration:9854  t-loss:0.1439, loss-lb:0.0904, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:28:02.161] iteration:9855  t-loss:0.1513, loss-lb:0.0911, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:28:02.352] iteration:9856  t-loss:0.1607, loss-lb:0.1059, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:28:02.546] iteration:9857  t-loss:0.1767, loss-lb:0.0982, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:28:02.740] iteration:9858  t-loss:0.1432, loss-lb:0.0855, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:28:02.932] iteration:9859  t-loss:0.2011, loss-lb:0.0957, loss-ulb:0.0527, weight:2.00, lr:0.0007
[11:28:03.125] iteration:9860  t-loss:0.1455, loss-lb:0.0930, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:28:03.317] iteration:9861  t-loss:0.1735, loss-lb:0.0805, loss-ulb:0.0465, weight:2.00, lr:0.0007
[11:28:03.510] iteration:9862  t-loss:0.1487, loss-lb:0.0893, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:28:03.702] iteration:9863  t-loss:0.1381, loss-lb:0.0894, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:28:03.896] iteration:9864  t-loss:0.1556, loss-lb:0.0884, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:28:04.089] iteration:9865  t-loss:0.1610, loss-lb:0.0967, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:28:04.282] iteration:9866  t-loss:0.1641, loss-lb:0.1059, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:28:04.474] iteration:9867  t-loss:0.1487, loss-lb:0.0945, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:28:04.666] iteration:9868  t-loss:0.1518, loss-lb:0.0963, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:28:04.859] iteration:9869  t-loss:0.1775, loss-lb:0.0891, loss-ulb:0.0442, weight:2.00, lr:0.0007
[11:28:05.050] iteration:9870  t-loss:0.1383, loss-lb:0.0890, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:28:05.245] iteration:9871  t-loss:0.1522, loss-lb:0.0867, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:28:05.437] iteration:9872  t-loss:0.1799, loss-lb:0.1206, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:28:05.629] iteration:9873  t-loss:0.1731, loss-lb:0.1077, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:28:05.821] iteration:9874  t-loss:0.1360, loss-lb:0.0888, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:28:06.014] iteration:9875  t-loss:0.1749, loss-lb:0.1003, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:28:06.206] iteration:9876  t-loss:0.1575, loss-lb:0.0945, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:28:06.398] iteration:9877  t-loss:0.1358, loss-lb:0.0808, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:28:06.591] iteration:9878  t-loss:0.1478, loss-lb:0.0955, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:28:06.783] iteration:9879  t-loss:0.1454, loss-lb:0.0935, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:28:06.976] iteration:9880  t-loss:0.1551, loss-lb:0.0946, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:28:07.169] iteration:9881  t-loss:0.2056, loss-lb:0.0890, loss-ulb:0.0583, weight:2.00, lr:0.0007
[11:28:07.361] iteration:9882  t-loss:0.1577, loss-lb:0.1049, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:28:07.553] iteration:9883  t-loss:0.1748, loss-lb:0.1072, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:28:07.746] iteration:9884  t-loss:0.1617, loss-lb:0.0888, loss-ulb:0.0365, weight:2.00, lr:0.0007
[11:28:07.940] iteration:9885  t-loss:0.1570, loss-lb:0.1075, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:28:08.131] iteration:9886  t-loss:0.1411, loss-lb:0.0897, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:28:08.325] iteration:9887  t-loss:0.1544, loss-lb:0.0862, loss-ulb:0.0341, weight:2.00, lr:0.0007
[11:28:08.518] iteration:9888  t-loss:0.1871, loss-lb:0.0876, loss-ulb:0.0498, weight:2.00, lr:0.0007
[11:28:08.711] iteration:9889  t-loss:0.1338, loss-lb:0.0883, loss-ulb:0.0228, weight:2.00, lr:0.0007
[11:28:08.903] iteration:9890  t-loss:0.1636, loss-lb:0.0978, loss-ulb:0.0329, weight:2.00, lr:0.0007
[11:28:09.094] iteration:9891  t-loss:0.1321, loss-lb:0.0844, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:28:09.285] iteration:9892  t-loss:0.1378, loss-lb:0.0848, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:28:09.475] iteration:9893  t-loss:0.1635, loss-lb:0.0856, loss-ulb:0.0389, weight:2.00, lr:0.0007
[11:28:09.667] iteration:9894  t-loss:0.1495, loss-lb:0.0902, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:28:09.857] iteration:9895  t-loss:0.1509, loss-lb:0.0902, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:28:10.048] iteration:9896  t-loss:0.1520, loss-lb:0.0923, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:28:10.239] iteration:9897  t-loss:0.1459, loss-lb:0.0903, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:28:10.431] iteration:9898  t-loss:0.1554, loss-lb:0.0819, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:28:21.475]  <<Test>> - Ep:100  - mean_dice/mean_h95 - S:90.03/1.28, Best-S:90.28, T:90.24/1.35, Best-T:90.48
[11:28:21.475]           - AvgLoss(lb/ulb/all):0.0937/0.0323/0.1562
[11:28:21.998] iteration:9899  t-loss:0.1449, loss-lb:0.0853, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:28:22.196] iteration:9900  t-loss:0.1530, loss-lb:0.0933, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:28:22.389] iteration:9901  t-loss:0.1426, loss-lb:0.0918, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:28:22.582] iteration:9902  t-loss:0.1514, loss-lb:0.0981, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:28:22.774] iteration:9903  t-loss:0.1565, loss-lb:0.0872, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:28:22.967] iteration:9904  t-loss:0.1363, loss-lb:0.0878, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:28:23.161] iteration:9905  t-loss:0.1559, loss-lb:0.1072, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:28:23.355] iteration:9906  t-loss:0.1409, loss-lb:0.0887, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:28:23.548] iteration:9907  t-loss:0.1569, loss-lb:0.0830, loss-ulb:0.0370, weight:2.00, lr:0.0007
[11:28:23.740] iteration:9908  t-loss:0.1902, loss-lb:0.0903, loss-ulb:0.0500, weight:2.00, lr:0.0007
[11:28:23.933] iteration:9909  t-loss:0.1360, loss-lb:0.0855, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:28:24.126] iteration:9910  t-loss:0.1607, loss-lb:0.0994, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:28:24.318] iteration:9911  t-loss:0.1447, loss-lb:0.0997, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:28:24.511] iteration:9912  t-loss:0.1406, loss-lb:0.0852, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:28:24.704] iteration:9913  t-loss:0.1449, loss-lb:0.0830, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:28:24.899] iteration:9914  t-loss:0.1433, loss-lb:0.0814, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:28:25.091] iteration:9915  t-loss:0.1478, loss-lb:0.0886, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:28:25.283] iteration:9916  t-loss:0.1561, loss-lb:0.1026, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:28:25.476] iteration:9917  t-loss:0.1401, loss-lb:0.0939, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:28:25.670] iteration:9918  t-loss:0.1575, loss-lb:0.0877, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:28:25.863] iteration:9919  t-loss:0.1321, loss-lb:0.0874, loss-ulb:0.0223, weight:2.00, lr:0.0007
[11:28:26.056] iteration:9920  t-loss:0.1592, loss-lb:0.1002, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:28:26.249] iteration:9921  t-loss:0.1581, loss-lb:0.1029, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:28:26.441] iteration:9922  t-loss:0.1402, loss-lb:0.0872, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:28:26.633] iteration:9923  t-loss:0.1338, loss-lb:0.0842, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:28:26.826] iteration:9924  t-loss:0.2006, loss-lb:0.1017, loss-ulb:0.0495, weight:2.00, lr:0.0007
[11:28:27.019] iteration:9925  t-loss:0.1342, loss-lb:0.0851, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:28:27.211] iteration:9926  t-loss:0.1366, loss-lb:0.0911, loss-ulb:0.0227, weight:2.00, lr:0.0007
[11:28:27.411] iteration:9927  t-loss:0.1701, loss-lb:0.0917, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:28:27.605] iteration:9928  t-loss:0.1352, loss-lb:0.0869, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:28:27.801] iteration:9929  t-loss:0.1537, loss-lb:0.0874, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:28:27.995] iteration:9930  t-loss:0.1454, loss-lb:0.0869, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:28:28.186] iteration:9931  t-loss:0.1350, loss-lb:0.0777, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:28:28.379] iteration:9932  t-loss:0.1965, loss-lb:0.0871, loss-ulb:0.0547, weight:2.00, lr:0.0007
[11:28:28.572] iteration:9933  t-loss:0.1492, loss-lb:0.0940, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:28:28.764] iteration:9934  t-loss:0.1631, loss-lb:0.0906, loss-ulb:0.0362, weight:2.00, lr:0.0007
[11:28:28.956] iteration:9935  t-loss:0.1477, loss-lb:0.0943, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:28:29.148] iteration:9936  t-loss:0.1972, loss-lb:0.0948, loss-ulb:0.0512, weight:2.00, lr:0.0007
[11:28:29.341] iteration:9937  t-loss:0.1663, loss-lb:0.0950, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:28:29.533] iteration:9938  t-loss:0.1261, loss-lb:0.0778, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:28:29.724] iteration:9939  t-loss:0.1495, loss-lb:0.0882, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:28:29.917] iteration:9940  t-loss:0.1462, loss-lb:0.0907, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:28:30.109] iteration:9941  t-loss:0.4148, loss-lb:0.1025, loss-ulb:0.1562, weight:2.00, lr:0.0007
[11:28:30.302] iteration:9942  t-loss:0.1514, loss-lb:0.0940, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:28:30.494] iteration:9943  t-loss:0.2379, loss-lb:0.0782, loss-ulb:0.0799, weight:2.00, lr:0.0007
[11:28:30.686] iteration:9944  t-loss:0.1413, loss-lb:0.0813, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:28:30.878] iteration:9945  t-loss:0.1333, loss-lb:0.0818, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:28:31.069] iteration:9946  t-loss:0.1425, loss-lb:0.0865, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:28:31.261] iteration:9947  t-loss:0.1578, loss-lb:0.0893, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:28:31.452] iteration:9948  t-loss:0.1509, loss-lb:0.0975, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:28:31.645] iteration:9949  t-loss:0.1267, loss-lb:0.0766, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:28:31.836] iteration:9950  t-loss:0.1307, loss-lb:0.0838, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:28:32.027] iteration:9951  t-loss:0.1603, loss-lb:0.0963, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:28:32.220] iteration:9952  t-loss:0.1797, loss-lb:0.1013, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:28:32.410] iteration:9953  t-loss:0.1409, loss-lb:0.0854, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:28:32.603] iteration:9954  t-loss:0.1436, loss-lb:0.0916, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:28:32.797] iteration:9955  t-loss:0.1928, loss-lb:0.0926, loss-ulb:0.0501, weight:2.00, lr:0.0007
[11:28:32.989] iteration:9956  t-loss:0.1374, loss-lb:0.0825, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:28:33.181] iteration:9957  t-loss:0.1321, loss-lb:0.0841, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:28:33.373] iteration:9958  t-loss:0.1645, loss-lb:0.0917, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:28:33.565] iteration:9959  t-loss:0.1476, loss-lb:0.0856, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:28:33.758] iteration:9960  t-loss:0.1551, loss-lb:0.0909, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:28:33.950] iteration:9961  t-loss:0.1409, loss-lb:0.0863, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:28:34.141] iteration:9962  t-loss:0.1379, loss-lb:0.0941, loss-ulb:0.0219, weight:2.00, lr:0.0007
[11:28:34.333] iteration:9963  t-loss:0.1826, loss-lb:0.1086, loss-ulb:0.0370, weight:2.00, lr:0.0007
[11:28:34.525] iteration:9964  t-loss:0.1367, loss-lb:0.0868, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:28:34.717] iteration:9965  t-loss:0.1648, loss-lb:0.1052, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:28:34.909] iteration:9966  t-loss:0.1605, loss-lb:0.0952, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:28:35.101] iteration:9967  t-loss:0.1298, loss-lb:0.0826, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:28:35.292] iteration:9968  t-loss:0.1631, loss-lb:0.0846, loss-ulb:0.0392, weight:2.00, lr:0.0007
[11:28:35.484] iteration:9969  t-loss:0.1416, loss-lb:0.0933, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:28:35.675] iteration:9970  t-loss:0.1518, loss-lb:0.0902, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:28:35.867] iteration:9971  t-loss:0.1456, loss-lb:0.0859, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:28:36.059] iteration:9972  t-loss:0.1506, loss-lb:0.0900, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:28:36.250] iteration:9973  t-loss:0.1561, loss-lb:0.0948, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:28:36.441] iteration:9974  t-loss:0.1771, loss-lb:0.1153, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:28:36.632] iteration:9975  t-loss:0.1478, loss-lb:0.0851, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:28:36.824] iteration:9976  t-loss:0.1322, loss-lb:0.0843, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:28:37.016] iteration:9977  t-loss:0.1504, loss-lb:0.0876, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:28:37.207] iteration:9978  t-loss:0.1321, loss-lb:0.0858, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:28:37.398] iteration:9979  t-loss:0.1420, loss-lb:0.0831, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:28:37.589] iteration:9980  t-loss:0.1629, loss-lb:0.0929, loss-ulb:0.0350, weight:2.00, lr:0.0007
[11:28:37.781] iteration:9981  t-loss:0.1569, loss-lb:0.0908, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:28:37.973] iteration:9982  t-loss:0.1590, loss-lb:0.0814, loss-ulb:0.0388, weight:2.00, lr:0.0007
[11:28:38.168] iteration:9983  t-loss:0.1399, loss-lb:0.0888, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:28:38.362] iteration:9984  t-loss:0.1377, loss-lb:0.0914, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:28:38.555] iteration:9985  t-loss:0.1495, loss-lb:0.0846, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:28:38.747] iteration:9986  t-loss:0.1438, loss-lb:0.0825, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:28:38.938] iteration:9987  t-loss:0.1345, loss-lb:0.0927, loss-ulb:0.0209, weight:2.00, lr:0.0007
[11:28:39.131] iteration:9988  t-loss:0.2657, loss-lb:0.0938, loss-ulb:0.0860, weight:2.00, lr:0.0007
[11:28:39.323] iteration:9989  t-loss:0.1635, loss-lb:0.0926, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:28:39.513] iteration:9990  t-loss:0.1682, loss-lb:0.0911, loss-ulb:0.0386, weight:2.00, lr:0.0007
[11:28:39.703] iteration:9991  t-loss:0.1405, loss-lb:0.0896, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:28:39.896] iteration:9992  t-loss:0.2687, loss-lb:0.0956, loss-ulb:0.0865, weight:2.00, lr:0.0007
[11:28:40.086] iteration:9993  t-loss:0.1424, loss-lb:0.0932, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:28:40.277] iteration:9994  t-loss:0.1478, loss-lb:0.0917, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:28:40.467] iteration:9995  t-loss:0.1842, loss-lb:0.0852, loss-ulb:0.0495, weight:2.00, lr:0.0007
[11:28:40.657] iteration:9996  t-loss:0.1340, loss-lb:0.0823, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:28:41.265] iteration:9997  t-loss:0.1362, loss-lb:0.0905, loss-ulb:0.0228, weight:2.00, lr:0.0007
[11:28:41.460] iteration:9998  t-loss:0.1316, loss-lb:0.0886, loss-ulb:0.0215, weight:2.00, lr:0.0007
[11:28:41.651] iteration:9999  t-loss:0.1363, loss-lb:0.0860, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:28:41.844] iteration:10000  t-loss:0.1613, loss-lb:0.0984, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:28:42.036] iteration:10001  t-loss:0.1321, loss-lb:0.0862, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:28:42.227] iteration:10002  t-loss:0.1314, loss-lb:0.0890, loss-ulb:0.0212, weight:2.00, lr:0.0007
[11:28:42.419] iteration:10003  t-loss:0.1680, loss-lb:0.1045, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:28:42.611] iteration:10004  t-loss:0.1419, loss-lb:0.0852, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:28:42.802] iteration:10005  t-loss:0.1541, loss-lb:0.0913, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:28:42.994] iteration:10006  t-loss:0.1437, loss-lb:0.0884, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:28:43.185] iteration:10007  t-loss:0.1574, loss-lb:0.0952, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:28:43.377] iteration:10008  t-loss:0.1693, loss-lb:0.0896, loss-ulb:0.0398, weight:2.00, lr:0.0007
[11:28:43.568] iteration:10009  t-loss:0.1395, loss-lb:0.0823, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:28:43.760] iteration:10010  t-loss:0.1367, loss-lb:0.0890, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:28:43.951] iteration:10011  t-loss:0.1780, loss-lb:0.0911, loss-ulb:0.0434, weight:2.00, lr:0.0007
[11:28:44.143] iteration:10012  t-loss:0.1549, loss-lb:0.0859, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:28:44.335] iteration:10013  t-loss:0.1567, loss-lb:0.0997, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:28:44.527] iteration:10014  t-loss:0.1734, loss-lb:0.0902, loss-ulb:0.0416, weight:2.00, lr:0.0007
[11:28:44.719] iteration:10015  t-loss:0.1401, loss-lb:0.0916, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:28:44.911] iteration:10016  t-loss:0.1442, loss-lb:0.0822, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:28:45.102] iteration:10017  t-loss:0.1482, loss-lb:0.1040, loss-ulb:0.0221, weight:2.00, lr:0.0007
[11:28:45.294] iteration:10018  t-loss:0.1656, loss-lb:0.0935, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:28:45.484] iteration:10019  t-loss:0.1476, loss-lb:0.0893, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:28:45.676] iteration:10020  t-loss:0.1837, loss-lb:0.0879, loss-ulb:0.0479, weight:2.00, lr:0.0007
[11:28:45.868] iteration:10021  t-loss:0.1358, loss-lb:0.0864, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:28:46.059] iteration:10022  t-loss:0.1379, loss-lb:0.0858, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:28:46.252] iteration:10023  t-loss:0.2859, loss-lb:0.0816, loss-ulb:0.1022, weight:2.00, lr:0.0007
[11:28:46.443] iteration:10024  t-loss:0.1535, loss-lb:0.0873, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:28:46.636] iteration:10025  t-loss:0.1346, loss-lb:0.0887, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:28:46.827] iteration:10026  t-loss:0.1459, loss-lb:0.0915, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:28:47.018] iteration:10027  t-loss:0.1615, loss-lb:0.0903, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:28:47.212] iteration:10028  t-loss:0.1808, loss-lb:0.1143, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:28:47.403] iteration:10029  t-loss:0.1323, loss-lb:0.0806, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:28:47.595] iteration:10030  t-loss:0.2594, loss-lb:0.0951, loss-ulb:0.0821, weight:2.00, lr:0.0007
[11:28:47.788] iteration:10031  t-loss:0.1469, loss-lb:0.0868, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:28:47.979] iteration:10032  t-loss:0.1472, loss-lb:0.0939, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:28:48.170] iteration:10033  t-loss:0.1388, loss-lb:0.0916, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:28:48.374] iteration:10034  t-loss:0.1428, loss-lb:0.0906, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:28:48.571] iteration:10035  t-loss:0.1616, loss-lb:0.0998, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:28:48.770] iteration:10036  t-loss:0.1385, loss-lb:0.0815, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:28:48.963] iteration:10037  t-loss:0.1394, loss-lb:0.0831, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:28:49.163] iteration:10038  t-loss:0.1405, loss-lb:0.0861, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:28:49.358] iteration:10039  t-loss:0.1800, loss-lb:0.0901, loss-ulb:0.0449, weight:2.00, lr:0.0007
[11:28:49.551] iteration:10040  t-loss:0.1384, loss-lb:0.0856, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:28:49.745] iteration:10041  t-loss:0.1504, loss-lb:0.0849, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:28:49.942] iteration:10042  t-loss:0.1386, loss-lb:0.0913, loss-ulb:0.0237, weight:2.00, lr:0.0007
[11:28:50.134] iteration:10043  t-loss:0.1635, loss-lb:0.0842, loss-ulb:0.0397, weight:2.00, lr:0.0007
[11:28:50.325] iteration:10044  t-loss:0.1362, loss-lb:0.0817, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:28:50.518] iteration:10045  t-loss:0.1658, loss-lb:0.1128, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:28:50.710] iteration:10046  t-loss:0.1540, loss-lb:0.0950, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:28:50.902] iteration:10047  t-loss:0.1409, loss-lb:0.0932, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:28:51.095] iteration:10048  t-loss:0.2219, loss-lb:0.0920, loss-ulb:0.0650, weight:2.00, lr:0.0007
[11:28:51.288] iteration:10049  t-loss:0.1740, loss-lb:0.0952, loss-ulb:0.0394, weight:2.00, lr:0.0007
[11:28:51.480] iteration:10050  t-loss:0.1567, loss-lb:0.0915, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:28:51.673] iteration:10051  t-loss:0.1411, loss-lb:0.0832, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:28:51.864] iteration:10052  t-loss:0.1551, loss-lb:0.0895, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:28:52.057] iteration:10053  t-loss:0.1708, loss-lb:0.0922, loss-ulb:0.0393, weight:2.00, lr:0.0007
[11:28:52.249] iteration:10054  t-loss:0.1334, loss-lb:0.0837, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:28:52.441] iteration:10055  t-loss:0.1646, loss-lb:0.0984, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:28:52.633] iteration:10056  t-loss:0.1419, loss-lb:0.0916, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:28:52.824] iteration:10057  t-loss:0.1298, loss-lb:0.0781, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:28:53.036] iteration:10058  t-loss:0.1401, loss-lb:0.0907, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:28:53.227] iteration:10059  t-loss:0.1516, loss-lb:0.0839, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:28:53.419] iteration:10060  t-loss:0.1403, loss-lb:0.0819, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:28:53.611] iteration:10061  t-loss:0.1663, loss-lb:0.0909, loss-ulb:0.0377, weight:2.00, lr:0.0007
[11:28:53.803] iteration:10062  t-loss:0.1624, loss-lb:0.0948, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:28:53.996] iteration:10063  t-loss:0.1701, loss-lb:0.0966, loss-ulb:0.0367, weight:2.00, lr:0.0007
[11:28:54.187] iteration:10064  t-loss:0.1391, loss-lb:0.0878, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:28:54.379] iteration:10065  t-loss:0.1345, loss-lb:0.0869, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:28:54.572] iteration:10066  t-loss:0.1526, loss-lb:0.0957, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:28:54.765] iteration:10067  t-loss:0.1647, loss-lb:0.0869, loss-ulb:0.0389, weight:2.00, lr:0.0007
[11:28:54.957] iteration:10068  t-loss:0.1562, loss-lb:0.0910, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:28:55.149] iteration:10069  t-loss:0.1555, loss-lb:0.0842, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:28:55.341] iteration:10070  t-loss:0.1609, loss-lb:0.1085, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:28:55.530] iteration:10071  t-loss:0.1556, loss-lb:0.0898, loss-ulb:0.0329, weight:2.00, lr:0.0007
[11:28:55.723] iteration:10072  t-loss:0.1564, loss-lb:0.0939, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:28:55.914] iteration:10073  t-loss:0.1638, loss-lb:0.0988, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:28:56.107] iteration:10074  t-loss:0.1351, loss-lb:0.0834, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:28:56.299] iteration:10075  t-loss:0.1387, loss-lb:0.0853, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:28:56.495] iteration:10076  t-loss:0.2674, loss-lb:0.0971, loss-ulb:0.0851, weight:2.00, lr:0.0007
[11:28:56.686] iteration:10077  t-loss:0.1375, loss-lb:0.0825, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:28:56.880] iteration:10078  t-loss:0.1468, loss-lb:0.0944, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:28:57.071] iteration:10079  t-loss:0.1399, loss-lb:0.0875, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:28:57.263] iteration:10080  t-loss:0.1452, loss-lb:0.0868, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:28:57.455] iteration:10081  t-loss:0.1596, loss-lb:0.0976, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:28:57.648] iteration:10082  t-loss:0.1739, loss-lb:0.0852, loss-ulb:0.0443, weight:2.00, lr:0.0007
[11:28:57.839] iteration:10083  t-loss:0.1483, loss-lb:0.0943, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:28:58.030] iteration:10084  t-loss:0.1561, loss-lb:0.0927, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:28:58.222] iteration:10085  t-loss:0.1477, loss-lb:0.0899, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:28:58.413] iteration:10086  t-loss:0.1396, loss-lb:0.0844, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:28:58.603] iteration:10087  t-loss:0.1459, loss-lb:0.1061, loss-ulb:0.0199, weight:2.00, lr:0.0007
[11:28:58.793] iteration:10088  t-loss:0.1646, loss-lb:0.0995, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:28:58.984] iteration:10089  t-loss:0.1470, loss-lb:0.0867, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:28:59.174] iteration:10090  t-loss:0.1479, loss-lb:0.0950, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:28:59.364] iteration:10091  t-loss:0.1376, loss-lb:0.0867, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:28:59.555] iteration:10092  t-loss:0.1395, loss-lb:0.0896, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:28:59.748] iteration:10093  t-loss:0.1589, loss-lb:0.0958, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:28:59.940] iteration:10094  t-loss:0.1330, loss-lb:0.0883, loss-ulb:0.0223, weight:2.00, lr:0.0007
[11:29:12.298]  <<Test>> - Ep:102  - mean_dice/mean_h95 - S:89.82/1.38, Best-S:90.28, T:90.11/1.32, Best-T:90.48
[11:29:12.299]           - AvgLoss(lb/ulb/all):0.0906/0.0312/0.1538
[11:29:12.831] iteration:10095  t-loss:0.1496, loss-lb:0.0939, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:29:13.028] iteration:10096  t-loss:0.1679, loss-lb:0.0990, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:29:13.220] iteration:10097  t-loss:0.1407, loss-lb:0.0776, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:29:13.413] iteration:10098  t-loss:0.1489, loss-lb:0.0889, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:29:13.605] iteration:10099  t-loss:0.1248, loss-lb:0.0831, loss-ulb:0.0208, weight:2.00, lr:0.0007
[11:29:13.798] iteration:10100  t-loss:0.1522, loss-lb:0.0862, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:29:13.990] iteration:10101  t-loss:0.1435, loss-lb:0.0817, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:29:14.185] iteration:10102  t-loss:0.1397, loss-lb:0.0874, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:29:14.377] iteration:10103  t-loss:0.1293, loss-lb:0.0785, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:29:14.570] iteration:10104  t-loss:0.1992, loss-lb:0.1030, loss-ulb:0.0481, weight:2.00, lr:0.0007
[11:29:14.762] iteration:10105  t-loss:0.1464, loss-lb:0.0889, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:29:14.953] iteration:10106  t-loss:0.1442, loss-lb:0.0920, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:29:15.146] iteration:10107  t-loss:0.1367, loss-lb:0.0874, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:29:15.340] iteration:10108  t-loss:0.1478, loss-lb:0.0855, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:29:15.532] iteration:10109  t-loss:0.1536, loss-lb:0.0956, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:29:15.725] iteration:10110  t-loss:0.1723, loss-lb:0.0884, loss-ulb:0.0419, weight:2.00, lr:0.0007
[11:29:15.918] iteration:10111  t-loss:0.1589, loss-lb:0.1012, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:29:16.112] iteration:10112  t-loss:0.2330, loss-lb:0.0875, loss-ulb:0.0728, weight:2.00, lr:0.0007
[11:29:16.304] iteration:10113  t-loss:0.1453, loss-lb:0.0964, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:29:16.504] iteration:10114  t-loss:0.1583, loss-lb:0.0887, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:29:16.696] iteration:10115  t-loss:0.1419, loss-lb:0.0926, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:29:16.889] iteration:10116  t-loss:0.1641, loss-lb:0.1073, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:29:17.082] iteration:10117  t-loss:0.1509, loss-lb:0.0893, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:29:17.276] iteration:10118  t-loss:0.1319, loss-lb:0.0813, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:29:17.468] iteration:10119  t-loss:0.1482, loss-lb:0.0892, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:29:17.662] iteration:10120  t-loss:0.1641, loss-lb:0.0926, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:29:17.854] iteration:10121  t-loss:0.1574, loss-lb:0.0933, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:29:18.047] iteration:10122  t-loss:0.1320, loss-lb:0.0784, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:29:18.240] iteration:10123  t-loss:0.1438, loss-lb:0.0879, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:29:18.434] iteration:10124  t-loss:0.1939, loss-lb:0.1189, loss-ulb:0.0375, weight:2.00, lr:0.0007
[11:29:18.625] iteration:10125  t-loss:0.1312, loss-lb:0.0854, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:29:18.818] iteration:10126  t-loss:0.1538, loss-lb:0.0899, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:29:19.011] iteration:10127  t-loss:0.2792, loss-lb:0.0913, loss-ulb:0.0939, weight:2.00, lr:0.0007
[11:29:19.204] iteration:10128  t-loss:0.2601, loss-lb:0.0851, loss-ulb:0.0875, weight:2.00, lr:0.0007
[11:29:19.396] iteration:10129  t-loss:0.1382, loss-lb:0.0838, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:29:19.588] iteration:10130  t-loss:0.1533, loss-lb:0.0803, loss-ulb:0.0365, weight:2.00, lr:0.0007
[11:29:19.780] iteration:10131  t-loss:0.1343, loss-lb:0.0926, loss-ulb:0.0208, weight:2.00, lr:0.0007
[11:29:19.973] iteration:10132  t-loss:0.1390, loss-lb:0.0941, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:29:20.165] iteration:10133  t-loss:0.1615, loss-lb:0.0940, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:29:20.358] iteration:10134  t-loss:0.1286, loss-lb:0.0787, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:29:20.550] iteration:10135  t-loss:0.1460, loss-lb:0.0874, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:29:20.743] iteration:10136  t-loss:0.1543, loss-lb:0.0921, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:29:20.934] iteration:10137  t-loss:0.1479, loss-lb:0.0967, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:29:21.140] iteration:10138  t-loss:0.1556, loss-lb:0.0927, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:29:21.339] iteration:10139  t-loss:0.1427, loss-lb:0.0843, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:29:21.534] iteration:10140  t-loss:0.1560, loss-lb:0.0921, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:29:21.725] iteration:10141  t-loss:0.1286, loss-lb:0.0802, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:29:21.917] iteration:10142  t-loss:0.1461, loss-lb:0.0840, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:29:22.109] iteration:10143  t-loss:0.1331, loss-lb:0.0870, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:29:22.302] iteration:10144  t-loss:0.1296, loss-lb:0.0815, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:29:22.493] iteration:10145  t-loss:0.1397, loss-lb:0.0862, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:29:22.685] iteration:10146  t-loss:0.1433, loss-lb:0.0939, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:29:22.877] iteration:10147  t-loss:0.1730, loss-lb:0.0824, loss-ulb:0.0453, weight:2.00, lr:0.0007
[11:29:23.070] iteration:10148  t-loss:0.1618, loss-lb:0.0954, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:29:23.262] iteration:10149  t-loss:0.1450, loss-lb:0.0923, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:29:23.454] iteration:10150  t-loss:0.1499, loss-lb:0.0848, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:29:23.647] iteration:10151  t-loss:0.1587, loss-lb:0.0946, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:29:23.841] iteration:10152  t-loss:0.2925, loss-lb:0.0877, loss-ulb:0.1024, weight:2.00, lr:0.0007
[11:29:24.034] iteration:10153  t-loss:0.1456, loss-lb:0.0921, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:29:24.225] iteration:10154  t-loss:0.1311, loss-lb:0.0849, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:29:24.418] iteration:10155  t-loss:0.1615, loss-lb:0.0854, loss-ulb:0.0381, weight:2.00, lr:0.0007
[11:29:24.611] iteration:10156  t-loss:0.1290, loss-lb:0.0815, loss-ulb:0.0237, weight:2.00, lr:0.0007
[11:29:24.803] iteration:10157  t-loss:0.1757, loss-lb:0.0908, loss-ulb:0.0425, weight:2.00, lr:0.0007
[11:29:24.995] iteration:10158  t-loss:0.1321, loss-lb:0.0792, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:29:25.189] iteration:10159  t-loss:0.1515, loss-lb:0.0884, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:29:25.381] iteration:10160  t-loss:0.1523, loss-lb:0.0928, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:29:25.573] iteration:10161  t-loss:0.1559, loss-lb:0.1009, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:29:25.766] iteration:10162  t-loss:0.1478, loss-lb:0.0919, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:29:25.958] iteration:10163  t-loss:0.1529, loss-lb:0.0944, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:29:26.150] iteration:10164  t-loss:0.1493, loss-lb:0.0848, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:29:26.343] iteration:10165  t-loss:0.4103, loss-lb:0.1094, loss-ulb:0.1504, weight:2.00, lr:0.0007
[11:29:26.536] iteration:10166  t-loss:0.1481, loss-lb:0.0934, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:29:26.728] iteration:10167  t-loss:0.1538, loss-lb:0.0846, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:29:26.921] iteration:10168  t-loss:0.1425, loss-lb:0.0869, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:29:27.114] iteration:10169  t-loss:0.1846, loss-lb:0.0873, loss-ulb:0.0487, weight:2.00, lr:0.0007
[11:29:27.306] iteration:10170  t-loss:0.1505, loss-lb:0.0960, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:29:27.499] iteration:10171  t-loss:0.1425, loss-lb:0.0956, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:29:27.692] iteration:10172  t-loss:0.1497, loss-lb:0.0916, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:29:27.885] iteration:10173  t-loss:0.1685, loss-lb:0.0930, loss-ulb:0.0378, weight:2.00, lr:0.0007
[11:29:28.077] iteration:10174  t-loss:0.1545, loss-lb:0.0900, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:29:28.271] iteration:10175  t-loss:0.1906, loss-lb:0.0945, loss-ulb:0.0480, weight:2.00, lr:0.0007
[11:29:28.464] iteration:10176  t-loss:0.1536, loss-lb:0.0864, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:29:28.655] iteration:10177  t-loss:0.1478, loss-lb:0.0891, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:29:28.848] iteration:10178  t-loss:0.1431, loss-lb:0.0866, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:29:29.041] iteration:10179  t-loss:0.1308, loss-lb:0.0823, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:29:29.233] iteration:10180  t-loss:0.1512, loss-lb:0.0827, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:29:29.426] iteration:10181  t-loss:0.1495, loss-lb:0.0927, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:29:29.619] iteration:10182  t-loss:0.1685, loss-lb:0.0837, loss-ulb:0.0424, weight:2.00, lr:0.0007
[11:29:29.813] iteration:10183  t-loss:0.1931, loss-lb:0.0987, loss-ulb:0.0472, weight:2.00, lr:0.0007
[11:29:30.004] iteration:10184  t-loss:0.1545, loss-lb:0.0889, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:29:30.196] iteration:10185  t-loss:0.1549, loss-lb:0.0888, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:29:30.388] iteration:10186  t-loss:0.1474, loss-lb:0.0915, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:29:30.579] iteration:10187  t-loss:0.1704, loss-lb:0.0928, loss-ulb:0.0388, weight:2.00, lr:0.0007
[11:29:30.771] iteration:10188  t-loss:0.1768, loss-lb:0.0848, loss-ulb:0.0460, weight:2.00, lr:0.0007
[11:29:30.961] iteration:10189  t-loss:0.1343, loss-lb:0.0783, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:29:31.152] iteration:10190  t-loss:0.1528, loss-lb:0.0919, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:29:31.344] iteration:10191  t-loss:0.1601, loss-lb:0.1052, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:29:31.534] iteration:10192  t-loss:0.1467, loss-lb:0.0836, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:29:32.123] iteration:10193  t-loss:0.1514, loss-lb:0.0981, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:29:32.318] iteration:10194  t-loss:0.1508, loss-lb:0.0847, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:29:32.512] iteration:10195  t-loss:0.2139, loss-lb:0.0856, loss-ulb:0.0641, weight:2.00, lr:0.0007
[11:29:32.705] iteration:10196  t-loss:0.1614, loss-lb:0.0960, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:29:32.897] iteration:10197  t-loss:0.2195, loss-lb:0.0931, loss-ulb:0.0632, weight:2.00, lr:0.0007
[11:29:33.090] iteration:10198  t-loss:0.1402, loss-lb:0.0931, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:29:33.284] iteration:10199  t-loss:0.1509, loss-lb:0.0910, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:29:33.476] iteration:10200  t-loss:0.1592, loss-lb:0.0903, loss-ulb:0.0344, weight:2.00, lr:0.0007
[11:29:33.667] iteration:10201  t-loss:0.1506, loss-lb:0.0895, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:29:33.859] iteration:10202  t-loss:0.1613, loss-lb:0.1142, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:29:34.051] iteration:10203  t-loss:0.1884, loss-lb:0.0935, loss-ulb:0.0474, weight:2.00, lr:0.0007
[11:29:34.243] iteration:10204  t-loss:0.1509, loss-lb:0.0972, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:29:34.435] iteration:10205  t-loss:0.1634, loss-lb:0.0897, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:29:34.629] iteration:10206  t-loss:0.2179, loss-lb:0.0984, loss-ulb:0.0598, weight:2.00, lr:0.0007
[11:29:34.821] iteration:10207  t-loss:0.2154, loss-lb:0.0907, loss-ulb:0.0623, weight:2.00, lr:0.0007
[11:29:35.014] iteration:10208  t-loss:0.1476, loss-lb:0.0910, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:29:35.207] iteration:10209  t-loss:0.1575, loss-lb:0.0961, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:29:35.399] iteration:10210  t-loss:0.1619, loss-lb:0.0883, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:29:35.591] iteration:10211  t-loss:0.1518, loss-lb:0.0949, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:29:35.783] iteration:10212  t-loss:0.1872, loss-lb:0.0886, loss-ulb:0.0493, weight:2.00, lr:0.0007
[11:29:35.976] iteration:10213  t-loss:0.1724, loss-lb:0.0927, loss-ulb:0.0398, weight:2.00, lr:0.0007
[11:29:36.167] iteration:10214  t-loss:0.1629, loss-lb:0.0898, loss-ulb:0.0365, weight:2.00, lr:0.0007
[11:29:36.359] iteration:10215  t-loss:0.1677, loss-lb:0.0929, loss-ulb:0.0374, weight:2.00, lr:0.0007
[11:29:36.552] iteration:10216  t-loss:0.1333, loss-lb:0.0805, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:29:36.745] iteration:10217  t-loss:0.2022, loss-lb:0.0904, loss-ulb:0.0559, weight:2.00, lr:0.0007
[11:29:36.937] iteration:10218  t-loss:0.1604, loss-lb:0.0962, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:29:37.129] iteration:10219  t-loss:0.1593, loss-lb:0.1021, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:29:37.321] iteration:10220  t-loss:0.1845, loss-lb:0.1000, loss-ulb:0.0423, weight:2.00, lr:0.0007
[11:29:37.513] iteration:10221  t-loss:0.1467, loss-lb:0.0938, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:29:37.706] iteration:10222  t-loss:0.1613, loss-lb:0.0893, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:29:37.899] iteration:10223  t-loss:0.2220, loss-lb:0.0880, loss-ulb:0.0670, weight:2.00, lr:0.0007
[11:29:38.091] iteration:10224  t-loss:0.1498, loss-lb:0.0934, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:29:38.282] iteration:10225  t-loss:0.1491, loss-lb:0.0830, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:29:38.475] iteration:10226  t-loss:0.1676, loss-lb:0.0832, loss-ulb:0.0422, weight:2.00, lr:0.0007
[11:29:38.667] iteration:10227  t-loss:0.1629, loss-lb:0.1076, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:29:38.860] iteration:10228  t-loss:0.2915, loss-lb:0.0945, loss-ulb:0.0985, weight:2.00, lr:0.0007
[11:29:39.052] iteration:10229  t-loss:0.1586, loss-lb:0.0948, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:29:39.245] iteration:10230  t-loss:0.1565, loss-lb:0.0943, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:29:39.438] iteration:10231  t-loss:0.1519, loss-lb:0.0832, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:29:39.629] iteration:10232  t-loss:0.1374, loss-lb:0.0857, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:29:39.820] iteration:10233  t-loss:0.1328, loss-lb:0.0836, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:29:40.015] iteration:10234  t-loss:0.1836, loss-lb:0.1172, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:29:40.208] iteration:10235  t-loss:0.1661, loss-lb:0.0976, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:29:40.399] iteration:10236  t-loss:0.1650, loss-lb:0.0970, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:29:40.590] iteration:10237  t-loss:0.1401, loss-lb:0.0867, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:29:40.782] iteration:10238  t-loss:0.1472, loss-lb:0.0847, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:29:40.975] iteration:10239  t-loss:0.1421, loss-lb:0.0813, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:29:41.167] iteration:10240  t-loss:0.1364, loss-lb:0.0803, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:29:41.359] iteration:10241  t-loss:0.1438, loss-lb:0.0969, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:29:41.551] iteration:10242  t-loss:0.1472, loss-lb:0.0985, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:29:41.744] iteration:10243  t-loss:0.1297, loss-lb:0.0806, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:29:41.936] iteration:10244  t-loss:0.1450, loss-lb:0.0966, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:29:42.127] iteration:10245  t-loss:0.1452, loss-lb:0.0930, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:29:42.320] iteration:10246  t-loss:0.1755, loss-lb:0.0922, loss-ulb:0.0417, weight:2.00, lr:0.0007
[11:29:42.512] iteration:10247  t-loss:0.1252, loss-lb:0.0814, loss-ulb:0.0219, weight:2.00, lr:0.0007
[11:29:42.705] iteration:10248  t-loss:0.1371, loss-lb:0.0889, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:29:42.896] iteration:10249  t-loss:0.1419, loss-lb:0.0922, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:29:43.090] iteration:10250  t-loss:0.1396, loss-lb:0.0864, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:29:43.283] iteration:10251  t-loss:0.1414, loss-lb:0.0887, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:29:43.476] iteration:10252  t-loss:0.1425, loss-lb:0.0900, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:29:43.669] iteration:10253  t-loss:0.1405, loss-lb:0.0849, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:29:43.863] iteration:10254  t-loss:0.1460, loss-lb:0.0902, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:29:44.054] iteration:10255  t-loss:0.1422, loss-lb:0.0864, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:29:44.247] iteration:10256  t-loss:0.1323, loss-lb:0.0800, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:29:44.438] iteration:10257  t-loss:0.1425, loss-lb:0.0880, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:29:44.631] iteration:10258  t-loss:0.1381, loss-lb:0.0894, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:29:44.823] iteration:10259  t-loss:0.1475, loss-lb:0.0895, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:29:45.015] iteration:10260  t-loss:0.1541, loss-lb:0.0971, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:29:45.207] iteration:10261  t-loss:0.1429, loss-lb:0.0887, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:29:45.400] iteration:10262  t-loss:0.1392, loss-lb:0.0830, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:29:45.593] iteration:10263  t-loss:0.2818, loss-lb:0.0883, loss-ulb:0.0968, weight:2.00, lr:0.0007
[11:29:45.785] iteration:10264  t-loss:0.1381, loss-lb:0.0863, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:29:45.976] iteration:10265  t-loss:0.1560, loss-lb:0.0903, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:29:46.168] iteration:10266  t-loss:0.1525, loss-lb:0.0964, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:29:46.361] iteration:10267  t-loss:0.2339, loss-lb:0.0862, loss-ulb:0.0739, weight:2.00, lr:0.0007
[11:29:46.554] iteration:10268  t-loss:0.1616, loss-lb:0.0864, loss-ulb:0.0376, weight:2.00, lr:0.0007
[11:29:46.745] iteration:10269  t-loss:0.1438, loss-lb:0.0877, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:29:46.938] iteration:10270  t-loss:0.1552, loss-lb:0.0884, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:29:47.130] iteration:10271  t-loss:0.1411, loss-lb:0.0863, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:29:47.324] iteration:10272  t-loss:0.1621, loss-lb:0.0901, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:29:47.515] iteration:10273  t-loss:0.1584, loss-lb:0.0785, loss-ulb:0.0400, weight:2.00, lr:0.0007
[11:29:47.709] iteration:10274  t-loss:0.1551, loss-lb:0.0898, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:29:47.902] iteration:10275  t-loss:0.1282, loss-lb:0.0799, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:29:48.093] iteration:10276  t-loss:0.1526, loss-lb:0.0938, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:29:48.285] iteration:10277  t-loss:0.1448, loss-lb:0.0832, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:29:48.478] iteration:10278  t-loss:0.1422, loss-lb:0.0881, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:29:48.671] iteration:10279  t-loss:0.1525, loss-lb:0.0921, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:29:48.863] iteration:10280  t-loss:0.1420, loss-lb:0.0833, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:29:49.054] iteration:10281  t-loss:0.1389, loss-lb:0.0850, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:29:49.249] iteration:10282  t-loss:0.1817, loss-lb:0.0933, loss-ulb:0.0442, weight:2.00, lr:0.0007
[11:29:49.440] iteration:10283  t-loss:0.1412, loss-lb:0.0861, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:29:49.632] iteration:10284  t-loss:0.1431, loss-lb:0.0772, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:29:49.822] iteration:10285  t-loss:0.1626, loss-lb:0.0967, loss-ulb:0.0329, weight:2.00, lr:0.0007
[11:29:50.013] iteration:10286  t-loss:0.1329, loss-lb:0.0846, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:29:50.203] iteration:10287  t-loss:0.1288, loss-lb:0.0779, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:29:50.394] iteration:10288  t-loss:0.1375, loss-lb:0.0880, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:29:50.584] iteration:10289  t-loss:0.1496, loss-lb:0.0841, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:29:50.774] iteration:10290  t-loss:0.1554, loss-lb:0.0838, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:30:01.904]  <<Test>> - Ep:104  - mean_dice/mean_h95 - S:89.77/2.20, Best-S:90.28, T:90.02/1.34, Best-T:90.48
[11:30:01.904]           - AvgLoss(lb/ulb/all):0.0900/0.0307/0.1475
[11:30:02.447] iteration:10291  t-loss:0.1498, loss-lb:0.0904, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:30:02.642] iteration:10292  t-loss:0.1434, loss-lb:0.0872, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:30:02.835] iteration:10293  t-loss:0.1469, loss-lb:0.0845, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:30:03.029] iteration:10294  t-loss:0.1562, loss-lb:0.0845, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:30:03.221] iteration:10295  t-loss:0.1478, loss-lb:0.0936, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:03.413] iteration:10296  t-loss:0.1270, loss-lb:0.0851, loss-ulb:0.0210, weight:2.00, lr:0.0007
[11:30:03.606] iteration:10297  t-loss:0.1668, loss-lb:0.1005, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:30:03.797] iteration:10298  t-loss:0.1339, loss-lb:0.0833, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:30:03.990] iteration:10299  t-loss:0.1367, loss-lb:0.0851, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:30:04.182] iteration:10300  t-loss:0.1284, loss-lb:0.0761, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:30:04.376] iteration:10301  t-loss:0.1439, loss-lb:0.0834, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:30:04.570] iteration:10302  t-loss:0.2324, loss-lb:0.0924, loss-ulb:0.0700, weight:2.00, lr:0.0007
[11:30:04.762] iteration:10303  t-loss:0.1364, loss-lb:0.0918, loss-ulb:0.0223, weight:2.00, lr:0.0007
[11:30:04.954] iteration:10304  t-loss:0.1378, loss-lb:0.0790, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:30:05.147] iteration:10305  t-loss:0.2134, loss-lb:0.0821, loss-ulb:0.0656, weight:2.00, lr:0.0007
[11:30:05.339] iteration:10306  t-loss:0.1570, loss-lb:0.0899, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:30:05.531] iteration:10307  t-loss:0.1431, loss-lb:0.0879, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:30:05.724] iteration:10308  t-loss:0.1488, loss-lb:0.0846, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:30:05.916] iteration:10309  t-loss:0.1550, loss-lb:0.1045, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:30:06.109] iteration:10310  t-loss:0.1826, loss-lb:0.0823, loss-ulb:0.0501, weight:2.00, lr:0.0007
[11:30:06.300] iteration:10311  t-loss:0.1454, loss-lb:0.0834, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:30:06.493] iteration:10312  t-loss:0.1529, loss-lb:0.0812, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:30:06.685] iteration:10313  t-loss:0.1498, loss-lb:0.0858, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:30:06.877] iteration:10314  t-loss:0.1254, loss-lb:0.0823, loss-ulb:0.0216, weight:2.00, lr:0.0007
[11:30:07.070] iteration:10315  t-loss:0.2635, loss-lb:0.0886, loss-ulb:0.0875, weight:2.00, lr:0.0007
[11:30:07.262] iteration:10316  t-loss:0.1496, loss-lb:0.0815, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:30:07.453] iteration:10317  t-loss:0.1971, loss-lb:0.0848, loss-ulb:0.0561, weight:2.00, lr:0.0007
[11:30:07.644] iteration:10318  t-loss:0.1492, loss-lb:0.0817, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:30:07.837] iteration:10319  t-loss:0.1479, loss-lb:0.0916, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:30:08.028] iteration:10320  t-loss:0.1486, loss-lb:0.0962, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:30:08.221] iteration:10321  t-loss:0.1581, loss-lb:0.0934, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:30:08.412] iteration:10322  t-loss:0.1434, loss-lb:0.0825, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:30:08.604] iteration:10323  t-loss:0.1488, loss-lb:0.0901, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:30:08.796] iteration:10324  t-loss:0.1271, loss-lb:0.0749, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:30:08.989] iteration:10325  t-loss:0.2117, loss-lb:0.0867, loss-ulb:0.0625, weight:2.00, lr:0.0007
[11:30:09.180] iteration:10326  t-loss:0.1555, loss-lb:0.0929, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:30:09.371] iteration:10327  t-loss:0.1426, loss-lb:0.0888, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:30:09.562] iteration:10328  t-loss:0.1466, loss-lb:0.0806, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:30:09.754] iteration:10329  t-loss:0.1470, loss-lb:0.0914, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:30:09.945] iteration:10330  t-loss:0.1469, loss-lb:0.0921, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:30:10.136] iteration:10331  t-loss:0.1407, loss-lb:0.0824, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:30:10.329] iteration:10332  t-loss:0.1351, loss-lb:0.0861, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:30:10.520] iteration:10333  t-loss:0.1707, loss-lb:0.0893, loss-ulb:0.0407, weight:2.00, lr:0.0007
[11:30:10.712] iteration:10334  t-loss:0.1478, loss-lb:0.0872, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:30:10.905] iteration:10335  t-loss:0.1429, loss-lb:0.0796, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:30:11.100] iteration:10336  t-loss:0.1942, loss-lb:0.0884, loss-ulb:0.0529, weight:2.00, lr:0.0007
[11:30:11.296] iteration:10337  t-loss:0.1395, loss-lb:0.0866, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:30:11.490] iteration:10338  t-loss:0.1445, loss-lb:0.0934, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:30:11.685] iteration:10339  t-loss:0.1381, loss-lb:0.0910, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:30:11.877] iteration:10340  t-loss:0.1503, loss-lb:0.0915, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:30:12.069] iteration:10341  t-loss:0.1441, loss-lb:0.0977, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:30:12.261] iteration:10342  t-loss:0.1405, loss-lb:0.0927, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:30:12.454] iteration:10343  t-loss:0.1423, loss-lb:0.0880, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:12.647] iteration:10344  t-loss:0.1790, loss-lb:0.0800, loss-ulb:0.0495, weight:2.00, lr:0.0007
[11:30:12.839] iteration:10345  t-loss:0.2019, loss-lb:0.0839, loss-ulb:0.0590, weight:2.00, lr:0.0007
[11:30:13.032] iteration:10346  t-loss:0.1452, loss-lb:0.0927, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:30:13.224] iteration:10347  t-loss:0.1431, loss-lb:0.0884, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:30:13.417] iteration:10348  t-loss:0.1694, loss-lb:0.0884, loss-ulb:0.0405, weight:2.00, lr:0.0007
[11:30:13.609] iteration:10349  t-loss:0.1511, loss-lb:0.0869, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:30:13.800] iteration:10350  t-loss:0.1676, loss-lb:0.0861, loss-ulb:0.0407, weight:2.00, lr:0.0007
[11:30:13.994] iteration:10351  t-loss:0.1308, loss-lb:0.0824, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:30:14.186] iteration:10352  t-loss:0.2245, loss-lb:0.0933, loss-ulb:0.0656, weight:2.00, lr:0.0007
[11:30:14.377] iteration:10353  t-loss:0.1388, loss-lb:0.0872, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:30:14.569] iteration:10354  t-loss:0.1338, loss-lb:0.0880, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:30:14.760] iteration:10355  t-loss:0.1522, loss-lb:0.0857, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:30:14.952] iteration:10356  t-loss:0.1398, loss-lb:0.0828, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:30:15.143] iteration:10357  t-loss:0.1754, loss-lb:0.1037, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:30:15.335] iteration:10358  t-loss:0.1511, loss-lb:0.0919, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:30:15.526] iteration:10359  t-loss:0.1595, loss-lb:0.0887, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:30:15.718] iteration:10360  t-loss:0.1476, loss-lb:0.0895, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:30:15.911] iteration:10361  t-loss:0.1592, loss-lb:0.0907, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:30:16.102] iteration:10362  t-loss:0.1503, loss-lb:0.0930, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:30:16.294] iteration:10363  t-loss:0.2136, loss-lb:0.0887, loss-ulb:0.0624, weight:2.00, lr:0.0007
[11:30:16.488] iteration:10364  t-loss:0.1354, loss-lb:0.0890, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:30:16.680] iteration:10365  t-loss:0.1406, loss-lb:0.0861, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:30:16.873] iteration:10366  t-loss:0.1505, loss-lb:0.0922, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:30:17.064] iteration:10367  t-loss:0.1386, loss-lb:0.0847, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:30:17.256] iteration:10368  t-loss:0.1430, loss-lb:0.0931, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:30:17.448] iteration:10369  t-loss:0.1450, loss-lb:0.0914, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:30:17.639] iteration:10370  t-loss:0.1443, loss-lb:0.0830, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:30:17.834] iteration:10371  t-loss:0.1325, loss-lb:0.0864, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:30:18.026] iteration:10372  t-loss:0.1795, loss-lb:0.0965, loss-ulb:0.0415, weight:2.00, lr:0.0007
[11:30:18.217] iteration:10373  t-loss:0.1399, loss-lb:0.0858, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:18.408] iteration:10374  t-loss:0.1450, loss-lb:0.0850, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:30:18.600] iteration:10375  t-loss:0.1591, loss-lb:0.0979, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:30:18.793] iteration:10376  t-loss:0.1500, loss-lb:0.0874, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:30:18.985] iteration:10377  t-loss:0.1916, loss-lb:0.0935, loss-ulb:0.0491, weight:2.00, lr:0.0007
[11:30:19.177] iteration:10378  t-loss:0.1715, loss-lb:0.0837, loss-ulb:0.0439, weight:2.00, lr:0.0007
[11:30:19.368] iteration:10379  t-loss:0.1404, loss-lb:0.0833, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:30:19.560] iteration:10380  t-loss:0.1600, loss-lb:0.1066, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:30:19.751] iteration:10381  t-loss:0.1547, loss-lb:0.0857, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:30:19.941] iteration:10382  t-loss:0.1419, loss-lb:0.0875, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:30:20.131] iteration:10383  t-loss:0.1719, loss-lb:0.0953, loss-ulb:0.0383, weight:2.00, lr:0.0007
[11:30:20.322] iteration:10384  t-loss:0.1581, loss-lb:0.0917, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:30:20.511] iteration:10385  t-loss:0.1633, loss-lb:0.0910, loss-ulb:0.0361, weight:2.00, lr:0.0007
[11:30:20.702] iteration:10386  t-loss:0.1425, loss-lb:0.0882, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:30:20.892] iteration:10387  t-loss:0.1441, loss-lb:0.0857, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:30:21.082] iteration:10388  t-loss:0.1376, loss-lb:0.0829, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:30:21.659] iteration:10389  t-loss:0.1321, loss-lb:0.0817, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:30:21.856] iteration:10390  t-loss:0.1477, loss-lb:0.0910, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:30:22.050] iteration:10391  t-loss:0.1402, loss-lb:0.0915, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:30:22.248] iteration:10392  t-loss:0.1288, loss-lb:0.0868, loss-ulb:0.0210, weight:2.00, lr:0.0007
[11:30:22.443] iteration:10393  t-loss:0.1388, loss-lb:0.0799, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:30:22.638] iteration:10394  t-loss:0.1431, loss-lb:0.0829, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:30:22.832] iteration:10395  t-loss:0.1602, loss-lb:0.0852, loss-ulb:0.0375, weight:2.00, lr:0.0007
[11:30:23.024] iteration:10396  t-loss:0.1940, loss-lb:0.1362, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:30:23.217] iteration:10397  t-loss:0.1467, loss-lb:0.0883, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:30:23.409] iteration:10398  t-loss:0.1346, loss-lb:0.0822, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:30:23.601] iteration:10399  t-loss:0.1765, loss-lb:0.0969, loss-ulb:0.0398, weight:2.00, lr:0.0007
[11:30:23.793] iteration:10400  t-loss:0.1744, loss-lb:0.0920, loss-ulb:0.0412, weight:2.00, lr:0.0007
[11:30:23.986] iteration:10401  t-loss:0.1614, loss-lb:0.0874, loss-ulb:0.0370, weight:2.00, lr:0.0007
[11:30:24.181] iteration:10402  t-loss:0.1695, loss-lb:0.0869, loss-ulb:0.0413, weight:2.00, lr:0.0007
[11:30:24.374] iteration:10403  t-loss:0.1967, loss-lb:0.0860, loss-ulb:0.0554, weight:2.00, lr:0.0007
[11:30:24.566] iteration:10404  t-loss:0.1383, loss-lb:0.0841, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:24.758] iteration:10405  t-loss:0.1359, loss-lb:0.0879, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:30:24.950] iteration:10406  t-loss:0.1438, loss-lb:0.0847, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:30:25.143] iteration:10407  t-loss:0.1771, loss-lb:0.0880, loss-ulb:0.0445, weight:2.00, lr:0.0007
[11:30:25.336] iteration:10408  t-loss:0.1985, loss-lb:0.1111, loss-ulb:0.0437, weight:2.00, lr:0.0007
[11:30:25.528] iteration:10409  t-loss:0.1438, loss-lb:0.0850, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:30:25.721] iteration:10410  t-loss:0.1819, loss-lb:0.0937, loss-ulb:0.0441, weight:2.00, lr:0.0007
[11:30:25.913] iteration:10411  t-loss:0.1446, loss-lb:0.0999, loss-ulb:0.0223, weight:2.00, lr:0.0007
[11:30:26.105] iteration:10412  t-loss:0.1217, loss-lb:0.0745, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:30:26.297] iteration:10413  t-loss:0.1602, loss-lb:0.0899, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:30:26.489] iteration:10414  t-loss:0.1919, loss-lb:0.0940, loss-ulb:0.0490, weight:2.00, lr:0.0007
[11:30:26.687] iteration:10415  t-loss:0.1718, loss-lb:0.0860, loss-ulb:0.0429, weight:2.00, lr:0.0007
[11:30:26.882] iteration:10416  t-loss:0.1414, loss-lb:0.0919, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:30:27.078] iteration:10417  t-loss:0.1378, loss-lb:0.0883, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:30:27.268] iteration:10418  t-loss:0.1685, loss-lb:0.0992, loss-ulb:0.0347, weight:2.00, lr:0.0007
[11:30:27.460] iteration:10419  t-loss:0.1395, loss-lb:0.0898, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:30:27.652] iteration:10420  t-loss:0.1419, loss-lb:0.0905, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:30:27.845] iteration:10421  t-loss:0.1310, loss-lb:0.0773, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:30:28.038] iteration:10422  t-loss:0.1425, loss-lb:0.0834, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:30:28.234] iteration:10423  t-loss:0.1939, loss-lb:0.0936, loss-ulb:0.0502, weight:2.00, lr:0.0007
[11:30:28.426] iteration:10424  t-loss:0.1867, loss-lb:0.0992, loss-ulb:0.0438, weight:2.00, lr:0.0007
[11:30:28.618] iteration:10425  t-loss:0.1696, loss-lb:0.1034, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:30:28.811] iteration:10426  t-loss:0.1683, loss-lb:0.0939, loss-ulb:0.0372, weight:2.00, lr:0.0007
[11:30:29.003] iteration:10427  t-loss:0.1676, loss-lb:0.1003, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:30:29.197] iteration:10428  t-loss:0.1800, loss-lb:0.0850, loss-ulb:0.0475, weight:2.00, lr:0.0007
[11:30:29.389] iteration:10429  t-loss:0.1758, loss-lb:0.0822, loss-ulb:0.0468, weight:2.00, lr:0.0007
[11:30:29.581] iteration:10430  t-loss:0.2137, loss-lb:0.0912, loss-ulb:0.0612, weight:2.00, lr:0.0007
[11:30:29.772] iteration:10431  t-loss:0.1879, loss-lb:0.0865, loss-ulb:0.0507, weight:2.00, lr:0.0007
[11:30:29.965] iteration:10432  t-loss:0.1394, loss-lb:0.0895, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:30:30.157] iteration:10433  t-loss:0.1375, loss-lb:0.0843, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:30:30.348] iteration:10434  t-loss:0.1629, loss-lb:0.0941, loss-ulb:0.0344, weight:2.00, lr:0.0007
[11:30:30.539] iteration:10435  t-loss:0.1669, loss-lb:0.0951, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:30:30.731] iteration:10436  t-loss:0.1842, loss-lb:0.0864, loss-ulb:0.0489, weight:2.00, lr:0.0007
[11:30:30.922] iteration:10437  t-loss:0.2096, loss-lb:0.0994, loss-ulb:0.0551, weight:2.00, lr:0.0007
[11:30:31.114] iteration:10438  t-loss:0.1801, loss-lb:0.1034, loss-ulb:0.0383, weight:2.00, lr:0.0007
[11:30:31.307] iteration:10439  t-loss:0.2687, loss-lb:0.0987, loss-ulb:0.0850, weight:2.00, lr:0.0007
[11:30:31.498] iteration:10440  t-loss:0.1531, loss-lb:0.1013, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:30:31.689] iteration:10441  t-loss:0.1676, loss-lb:0.1111, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:30:31.881] iteration:10442  t-loss:0.1471, loss-lb:0.0975, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:30:32.072] iteration:10443  t-loss:0.1690, loss-lb:0.0962, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:30:32.263] iteration:10444  t-loss:0.1778, loss-lb:0.1201, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:30:32.455] iteration:10445  t-loss:0.1329, loss-lb:0.0809, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:30:32.648] iteration:10446  t-loss:0.1581, loss-lb:0.0962, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:30:32.842] iteration:10447  t-loss:0.1807, loss-lb:0.1136, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:30:33.038] iteration:10448  t-loss:0.1615, loss-lb:0.0906, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:30:33.232] iteration:10449  t-loss:0.1691, loss-lb:0.0985, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:30:33.427] iteration:10450  t-loss:0.1493, loss-lb:0.0938, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:30:33.620] iteration:10451  t-loss:0.1498, loss-lb:0.0904, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:30:33.812] iteration:10452  t-loss:0.1473, loss-lb:0.0957, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:30:34.005] iteration:10453  t-loss:0.1525, loss-lb:0.0983, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:34.196] iteration:10454  t-loss:0.1586, loss-lb:0.0896, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:30:34.388] iteration:10455  t-loss:0.1506, loss-lb:0.0910, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:30:34.579] iteration:10456  t-loss:0.1443, loss-lb:0.0957, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:30:34.771] iteration:10457  t-loss:0.1648, loss-lb:0.0921, loss-ulb:0.0363, weight:2.00, lr:0.0007
[11:30:34.963] iteration:10458  t-loss:0.1664, loss-lb:0.0893, loss-ulb:0.0385, weight:2.00, lr:0.0007
[11:30:35.155] iteration:10459  t-loss:0.1711, loss-lb:0.0939, loss-ulb:0.0386, weight:2.00, lr:0.0007
[11:30:35.347] iteration:10460  t-loss:0.1479, loss-lb:0.0931, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:30:35.539] iteration:10461  t-loss:0.1842, loss-lb:0.0971, loss-ulb:0.0436, weight:2.00, lr:0.0007
[11:30:35.731] iteration:10462  t-loss:0.1847, loss-lb:0.0901, loss-ulb:0.0473, weight:2.00, lr:0.0007
[11:30:35.923] iteration:10463  t-loss:0.1412, loss-lb:0.0848, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:30:36.115] iteration:10464  t-loss:0.1771, loss-lb:0.0904, loss-ulb:0.0433, weight:2.00, lr:0.0007
[11:30:36.307] iteration:10465  t-loss:0.1566, loss-lb:0.0864, loss-ulb:0.0351, weight:2.00, lr:0.0007
[11:30:36.499] iteration:10466  t-loss:0.1617, loss-lb:0.0882, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:30:36.690] iteration:10467  t-loss:0.1594, loss-lb:0.0888, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:30:36.883] iteration:10468  t-loss:0.1939, loss-lb:0.0855, loss-ulb:0.0542, weight:2.00, lr:0.0007
[11:30:37.074] iteration:10469  t-loss:0.1481, loss-lb:0.0835, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:30:37.267] iteration:10470  t-loss:0.1434, loss-lb:0.0943, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:30:37.459] iteration:10471  t-loss:0.1450, loss-lb:0.0964, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:30:37.650] iteration:10472  t-loss:0.1446, loss-lb:0.0870, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:30:37.843] iteration:10473  t-loss:0.1788, loss-lb:0.1021, loss-ulb:0.0383, weight:2.00, lr:0.0007
[11:30:38.034] iteration:10474  t-loss:0.1766, loss-lb:0.0821, loss-ulb:0.0472, weight:2.00, lr:0.0007
[11:30:38.228] iteration:10475  t-loss:0.2241, loss-lb:0.0878, loss-ulb:0.0681, weight:2.00, lr:0.0007
[11:30:38.420] iteration:10476  t-loss:0.1364, loss-lb:0.0829, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:30:38.611] iteration:10477  t-loss:0.1441, loss-lb:0.0949, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:30:38.803] iteration:10478  t-loss:0.1500, loss-lb:0.0847, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:30:38.994] iteration:10479  t-loss:0.1570, loss-lb:0.0890, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:30:39.184] iteration:10480  t-loss:0.1489, loss-lb:0.0866, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:30:39.373] iteration:10481  t-loss:0.1717, loss-lb:0.0949, loss-ulb:0.0384, weight:2.00, lr:0.0007
[11:30:39.564] iteration:10482  t-loss:0.1512, loss-lb:0.0919, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:30:39.755] iteration:10483  t-loss:0.1435, loss-lb:0.0893, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:39.946] iteration:10484  t-loss:0.1670, loss-lb:0.1002, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:30:40.136] iteration:10485  t-loss:0.1474, loss-lb:0.0992, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:30:40.326] iteration:10486  t-loss:0.1420, loss-lb:0.0877, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:52.561]  <<Test>> - Ep:106  - mean_dice/mean_h95 - S:89.80/1.50, Best-S:90.28, T:89.93/1.37, Best-T:90.48
[11:30:52.561]           - AvgLoss(lb/ulb/all):0.0920/0.0341/0.1587
[11:30:53.110] iteration:10487  t-loss:0.1912, loss-lb:0.0851, loss-ulb:0.0530, weight:2.00, lr:0.0007
[11:30:53.307] iteration:10488  t-loss:0.1561, loss-lb:0.0895, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:30:53.506] iteration:10489  t-loss:0.1725, loss-lb:0.0862, loss-ulb:0.0431, weight:2.00, lr:0.0007
[11:30:53.699] iteration:10490  t-loss:0.1825, loss-lb:0.0936, loss-ulb:0.0445, weight:2.00, lr:0.0007
[11:30:53.891] iteration:10491  t-loss:0.1742, loss-lb:0.0896, loss-ulb:0.0423, weight:2.00, lr:0.0007
[11:30:54.085] iteration:10492  t-loss:0.1392, loss-lb:0.0919, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:30:54.284] iteration:10493  t-loss:0.1373, loss-lb:0.0925, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:30:54.476] iteration:10494  t-loss:0.1470, loss-lb:0.0889, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:30:54.670] iteration:10495  t-loss:0.1409, loss-lb:0.0839, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:30:54.862] iteration:10496  t-loss:0.1503, loss-lb:0.0932, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:30:55.063] iteration:10497  t-loss:0.1405, loss-lb:0.0849, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:30:55.258] iteration:10498  t-loss:0.1466, loss-lb:0.1008, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:30:55.450] iteration:10499  t-loss:0.1459, loss-lb:0.0927, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:30:55.643] iteration:10500  t-loss:0.1529, loss-lb:0.0827, loss-ulb:0.0351, weight:2.00, lr:0.0007
[11:30:55.843] iteration:10501  t-loss:0.1433, loss-lb:0.0871, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:30:56.037] iteration:10502  t-loss:0.1573, loss-lb:0.0827, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:30:56.230] iteration:10503  t-loss:0.1589, loss-lb:0.1007, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:30:56.423] iteration:10504  t-loss:0.2224, loss-lb:0.0919, loss-ulb:0.0653, weight:2.00, lr:0.0007
[11:30:56.624] iteration:10505  t-loss:0.1477, loss-lb:0.0936, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:30:56.817] iteration:10506  t-loss:0.1522, loss-lb:0.0806, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:30:57.009] iteration:10507  t-loss:0.1736, loss-lb:0.0954, loss-ulb:0.0391, weight:2.00, lr:0.0007
[11:30:57.202] iteration:10508  t-loss:0.1480, loss-lb:0.0949, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:30:57.403] iteration:10509  t-loss:0.1623, loss-lb:0.0795, loss-ulb:0.0414, weight:2.00, lr:0.0007
[11:30:57.595] iteration:10510  t-loss:0.1326, loss-lb:0.0816, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:30:57.787] iteration:10511  t-loss:0.1528, loss-lb:0.0946, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:30:57.980] iteration:10512  t-loss:0.1530, loss-lb:0.0864, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:30:58.180] iteration:10513  t-loss:0.1901, loss-lb:0.0931, loss-ulb:0.0485, weight:2.00, lr:0.0007
[11:30:58.372] iteration:10514  t-loss:0.1580, loss-lb:0.0940, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:30:58.564] iteration:10515  t-loss:0.1727, loss-lb:0.1130, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:30:58.756] iteration:10516  t-loss:0.1500, loss-lb:0.0922, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:30:58.955] iteration:10517  t-loss:0.1547, loss-lb:0.0914, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:30:59.148] iteration:10518  t-loss:0.1460, loss-lb:0.0932, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:30:59.351] iteration:10519  t-loss:0.1662, loss-lb:0.0792, loss-ulb:0.0435, weight:2.00, lr:0.0007
[11:30:59.556] iteration:10520  t-loss:0.1343, loss-lb:0.0810, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:30:59.754] iteration:10521  t-loss:0.1434, loss-lb:0.0875, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:30:59.951] iteration:10522  t-loss:0.1962, loss-lb:0.0880, loss-ulb:0.0541, weight:2.00, lr:0.0007
[11:31:00.145] iteration:10523  t-loss:0.1692, loss-lb:0.0943, loss-ulb:0.0375, weight:2.00, lr:0.0007
[11:31:00.337] iteration:10524  t-loss:0.1579, loss-lb:0.0877, loss-ulb:0.0351, weight:2.00, lr:0.0007
[11:31:00.531] iteration:10525  t-loss:0.1522, loss-lb:0.0872, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:31:00.724] iteration:10526  t-loss:0.1426, loss-lb:0.0903, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:31:00.918] iteration:10527  t-loss:0.1782, loss-lb:0.0990, loss-ulb:0.0396, weight:2.00, lr:0.0007
[11:31:01.110] iteration:10528  t-loss:0.1732, loss-lb:0.0980, loss-ulb:0.0376, weight:2.00, lr:0.0007
[11:31:01.302] iteration:10529  t-loss:0.1663, loss-lb:0.0931, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:31:01.494] iteration:10530  t-loss:0.1511, loss-lb:0.0965, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:31:01.687] iteration:10531  t-loss:0.1863, loss-lb:0.1000, loss-ulb:0.0431, weight:2.00, lr:0.0007
[11:31:01.879] iteration:10532  t-loss:0.1393, loss-lb:0.0834, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:31:02.071] iteration:10533  t-loss:0.1386, loss-lb:0.0839, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:31:02.262] iteration:10534  t-loss:0.1510, loss-lb:0.0931, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:31:02.454] iteration:10535  t-loss:0.1766, loss-lb:0.1141, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:31:02.649] iteration:10536  t-loss:0.1668, loss-lb:0.1065, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:31:02.841] iteration:10537  t-loss:0.1469, loss-lb:0.0943, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:31:03.033] iteration:10538  t-loss:0.1526, loss-lb:0.0851, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:31:03.226] iteration:10539  t-loss:0.1757, loss-lb:0.1020, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:31:03.418] iteration:10540  t-loss:0.1321, loss-lb:0.0812, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:31:03.610] iteration:10541  t-loss:0.1492, loss-lb:0.0861, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:31:03.804] iteration:10542  t-loss:0.1655, loss-lb:0.0913, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:31:03.997] iteration:10543  t-loss:0.1614, loss-lb:0.0975, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:31:04.190] iteration:10544  t-loss:0.1452, loss-lb:0.0913, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:31:04.381] iteration:10545  t-loss:0.1554, loss-lb:0.0948, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:31:04.574] iteration:10546  t-loss:0.3036, loss-lb:0.1023, loss-ulb:0.1006, weight:2.00, lr:0.0007
[11:31:04.767] iteration:10547  t-loss:0.1903, loss-lb:0.0890, loss-ulb:0.0507, weight:2.00, lr:0.0007
[11:31:04.959] iteration:10548  t-loss:0.1598, loss-lb:0.0873, loss-ulb:0.0363, weight:2.00, lr:0.0007
[11:31:05.151] iteration:10549  t-loss:0.1687, loss-lb:0.0954, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:31:05.344] iteration:10550  t-loss:0.1346, loss-lb:0.0816, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:31:05.536] iteration:10551  t-loss:0.1431, loss-lb:0.0893, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:31:05.729] iteration:10552  t-loss:0.1810, loss-lb:0.0946, loss-ulb:0.0432, weight:2.00, lr:0.0007
[11:31:05.922] iteration:10553  t-loss:0.1387, loss-lb:0.0908, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:31:06.115] iteration:10554  t-loss:0.2456, loss-lb:0.0916, loss-ulb:0.0770, weight:2.00, lr:0.0007
[11:31:06.306] iteration:10555  t-loss:0.1399, loss-lb:0.0899, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:31:06.499] iteration:10556  t-loss:0.1647, loss-lb:0.0924, loss-ulb:0.0361, weight:2.00, lr:0.0007
[11:31:06.692] iteration:10557  t-loss:0.1610, loss-lb:0.0898, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:31:06.883] iteration:10558  t-loss:0.1856, loss-lb:0.0914, loss-ulb:0.0471, weight:2.00, lr:0.0007
[11:31:07.075] iteration:10559  t-loss:0.1396, loss-lb:0.0892, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:31:07.268] iteration:10560  t-loss:0.1497, loss-lb:0.0901, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:31:07.460] iteration:10561  t-loss:0.1324, loss-lb:0.0799, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:31:07.651] iteration:10562  t-loss:0.1462, loss-lb:0.0883, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:31:07.845] iteration:10563  t-loss:0.2284, loss-lb:0.0947, loss-ulb:0.0668, weight:2.00, lr:0.0007
[11:31:08.037] iteration:10564  t-loss:0.1547, loss-lb:0.0874, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:31:08.230] iteration:10565  t-loss:0.1395, loss-lb:0.0904, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:31:08.423] iteration:10566  t-loss:0.1394, loss-lb:0.0889, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:31:08.616] iteration:10567  t-loss:0.1595, loss-lb:0.1116, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:31:08.809] iteration:10568  t-loss:0.1472, loss-lb:0.0945, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:31:09.002] iteration:10569  t-loss:0.1409, loss-lb:0.0859, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:31:09.196] iteration:10570  t-loss:0.1593, loss-lb:0.0779, loss-ulb:0.0407, weight:2.00, lr:0.0007
[11:31:09.389] iteration:10571  t-loss:0.1380, loss-lb:0.0875, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:31:09.580] iteration:10572  t-loss:0.1350, loss-lb:0.0845, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:31:09.773] iteration:10573  t-loss:0.1487, loss-lb:0.0976, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:31:09.966] iteration:10574  t-loss:0.1314, loss-lb:0.0867, loss-ulb:0.0224, weight:2.00, lr:0.0007
[11:31:10.158] iteration:10575  t-loss:0.1395, loss-lb:0.0841, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:31:10.351] iteration:10576  t-loss:0.1353, loss-lb:0.0828, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:31:10.544] iteration:10577  t-loss:0.1792, loss-lb:0.0906, loss-ulb:0.0443, weight:2.00, lr:0.0007
[11:31:10.733] iteration:10578  t-loss:0.1434, loss-lb:0.0829, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:31:10.924] iteration:10579  t-loss:0.1395, loss-lb:0.0789, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:31:11.114] iteration:10580  t-loss:0.1527, loss-lb:0.0880, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:31:11.306] iteration:10581  t-loss:0.1340, loss-lb:0.0838, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:31:11.499] iteration:10582  t-loss:0.1693, loss-lb:0.0864, loss-ulb:0.0414, weight:2.00, lr:0.0007
[11:31:11.690] iteration:10583  t-loss:0.1258, loss-lb:0.0776, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:31:11.881] iteration:10584  t-loss:0.1336, loss-lb:0.0812, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:31:12.481] iteration:10585  t-loss:0.1342, loss-lb:0.0836, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:31:12.678] iteration:10586  t-loss:0.1410, loss-lb:0.0857, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:31:12.871] iteration:10587  t-loss:0.1580, loss-lb:0.0883, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:31:13.062] iteration:10588  t-loss:0.1418, loss-lb:0.0875, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:31:13.255] iteration:10589  t-loss:0.1729, loss-lb:0.0885, loss-ulb:0.0422, weight:2.00, lr:0.0007
[11:31:13.447] iteration:10590  t-loss:0.1382, loss-lb:0.0887, loss-ulb:0.0247, weight:2.00, lr:0.0007
[11:31:13.639] iteration:10591  t-loss:0.1445, loss-lb:0.0954, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:31:13.832] iteration:10592  t-loss:0.1798, loss-lb:0.0893, loss-ulb:0.0453, weight:2.00, lr:0.0007
[11:31:14.025] iteration:10593  t-loss:0.1409, loss-lb:0.0818, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:31:14.218] iteration:10594  t-loss:0.1566, loss-lb:0.0859, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:31:14.410] iteration:10595  t-loss:0.1467, loss-lb:0.0816, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:31:14.605] iteration:10596  t-loss:0.1420, loss-lb:0.0845, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:31:14.799] iteration:10597  t-loss:0.1496, loss-lb:0.0862, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:31:14.992] iteration:10598  t-loss:0.2203, loss-lb:0.1176, loss-ulb:0.0513, weight:2.00, lr:0.0007
[11:31:15.184] iteration:10599  t-loss:0.1387, loss-lb:0.0883, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:31:15.377] iteration:10600  t-loss:0.1518, loss-lb:0.0801, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:31:15.570] iteration:10601  t-loss:0.1433, loss-lb:0.0825, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:31:15.764] iteration:10602  t-loss:0.1740, loss-lb:0.0859, loss-ulb:0.0441, weight:2.00, lr:0.0007
[11:31:15.956] iteration:10603  t-loss:0.1517, loss-lb:0.0922, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:31:16.149] iteration:10604  t-loss:0.1504, loss-lb:0.0825, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:31:16.340] iteration:10605  t-loss:0.1432, loss-lb:0.0905, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:31:16.533] iteration:10606  t-loss:0.1614, loss-lb:0.0905, loss-ulb:0.0355, weight:2.00, lr:0.0007
[11:31:16.725] iteration:10607  t-loss:0.1511, loss-lb:0.0886, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:31:16.917] iteration:10608  t-loss:0.1401, loss-lb:0.0832, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:31:17.109] iteration:10609  t-loss:0.1411, loss-lb:0.0857, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:31:17.303] iteration:10610  t-loss:0.1342, loss-lb:0.0883, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:31:17.495] iteration:10611  t-loss:0.1282, loss-lb:0.0771, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:31:17.688] iteration:10612  t-loss:0.1346, loss-lb:0.0907, loss-ulb:0.0220, weight:2.00, lr:0.0007
[11:31:17.881] iteration:10613  t-loss:0.1444, loss-lb:0.0858, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:31:18.074] iteration:10614  t-loss:0.1892, loss-lb:0.0963, loss-ulb:0.0464, weight:2.00, lr:0.0007
[11:31:18.266] iteration:10615  t-loss:0.1377, loss-lb:0.0820, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:31:18.459] iteration:10616  t-loss:0.1399, loss-lb:0.0943, loss-ulb:0.0228, weight:2.00, lr:0.0007
[11:31:18.651] iteration:10617  t-loss:0.1403, loss-lb:0.0889, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:31:18.844] iteration:10618  t-loss:0.1277, loss-lb:0.0767, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:31:19.037] iteration:10619  t-loss:0.1396, loss-lb:0.0842, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:31:19.229] iteration:10620  t-loss:0.1283, loss-lb:0.0862, loss-ulb:0.0210, weight:2.00, lr:0.0007
[11:31:19.421] iteration:10621  t-loss:0.1544, loss-lb:0.0936, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:31:19.614] iteration:10622  t-loss:0.1427, loss-lb:0.0834, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:31:19.807] iteration:10623  t-loss:0.1447, loss-lb:0.0910, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:31:19.998] iteration:10624  t-loss:0.1438, loss-lb:0.0895, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:31:20.191] iteration:10625  t-loss:0.1756, loss-lb:0.0877, loss-ulb:0.0440, weight:2.00, lr:0.0007
[11:31:20.384] iteration:10626  t-loss:0.2068, loss-lb:0.0849, loss-ulb:0.0610, weight:2.00, lr:0.0007
[11:31:20.576] iteration:10627  t-loss:0.1376, loss-lb:0.0879, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:31:20.769] iteration:10628  t-loss:0.2008, loss-lb:0.0947, loss-ulb:0.0530, weight:2.00, lr:0.0007
[11:31:20.961] iteration:10629  t-loss:0.1355, loss-lb:0.0761, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:31:21.154] iteration:10630  t-loss:0.1430, loss-lb:0.0792, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:31:21.346] iteration:10631  t-loss:0.1463, loss-lb:0.0921, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:31:21.538] iteration:10632  t-loss:0.1390, loss-lb:0.0799, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:31:21.731] iteration:10633  t-loss:0.1693, loss-lb:0.0976, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:31:21.924] iteration:10634  t-loss:0.1296, loss-lb:0.0783, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:31:22.116] iteration:10635  t-loss:0.1353, loss-lb:0.0849, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:31:22.308] iteration:10636  t-loss:0.1474, loss-lb:0.0801, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:31:22.500] iteration:10637  t-loss:0.1429, loss-lb:0.0822, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:31:22.693] iteration:10638  t-loss:0.1493, loss-lb:0.0904, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:31:22.884] iteration:10639  t-loss:0.1658, loss-lb:0.0996, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:31:23.076] iteration:10640  t-loss:0.1465, loss-lb:0.0869, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:31:23.268] iteration:10641  t-loss:0.1585, loss-lb:0.0885, loss-ulb:0.0350, weight:2.00, lr:0.0007
[11:31:23.461] iteration:10642  t-loss:0.1839, loss-lb:0.0906, loss-ulb:0.0467, weight:2.00, lr:0.0007
[11:31:23.653] iteration:10643  t-loss:0.1574, loss-lb:0.0883, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:31:23.847] iteration:10644  t-loss:0.1604, loss-lb:0.0939, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:31:24.038] iteration:10645  t-loss:0.1591, loss-lb:0.0888, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:31:24.232] iteration:10646  t-loss:0.1366, loss-lb:0.0849, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:31:24.424] iteration:10647  t-loss:0.1448, loss-lb:0.0846, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:31:24.617] iteration:10648  t-loss:0.1288, loss-lb:0.0784, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:31:24.809] iteration:10649  t-loss:0.1630, loss-lb:0.0898, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:31:25.001] iteration:10650  t-loss:0.1472, loss-lb:0.0892, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:31:25.193] iteration:10651  t-loss:0.1538, loss-lb:0.0987, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:31:25.385] iteration:10652  t-loss:0.1496, loss-lb:0.0829, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:31:25.578] iteration:10653  t-loss:0.1463, loss-lb:0.0902, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:31:25.771] iteration:10654  t-loss:0.2085, loss-lb:0.0888, loss-ulb:0.0599, weight:2.00, lr:0.0007
[11:31:25.963] iteration:10655  t-loss:0.1278, loss-lb:0.0744, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:31:26.156] iteration:10656  t-loss:0.1377, loss-lb:0.0892, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:31:26.348] iteration:10657  t-loss:0.1534, loss-lb:0.0920, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:31:26.540] iteration:10658  t-loss:0.1368, loss-lb:0.0895, loss-ulb:0.0237, weight:2.00, lr:0.0007
[11:31:26.733] iteration:10659  t-loss:0.1376, loss-lb:0.0877, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:31:26.925] iteration:10660  t-loss:0.1410, loss-lb:0.0859, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:31:27.117] iteration:10661  t-loss:0.1383, loss-lb:0.0863, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:31:27.310] iteration:10662  t-loss:0.1381, loss-lb:0.0877, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:31:27.501] iteration:10663  t-loss:0.1619, loss-lb:0.1124, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:31:27.694] iteration:10664  t-loss:0.1458, loss-lb:0.0791, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:31:27.887] iteration:10665  t-loss:0.1550, loss-lb:0.0836, loss-ulb:0.0357, weight:2.00, lr:0.0007
[11:31:28.079] iteration:10666  t-loss:0.1500, loss-lb:0.0956, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:31:28.271] iteration:10667  t-loss:0.2057, loss-lb:0.0923, loss-ulb:0.0567, weight:2.00, lr:0.0007
[11:31:28.463] iteration:10668  t-loss:0.1721, loss-lb:0.0880, loss-ulb:0.0420, weight:2.00, lr:0.0007
[11:31:28.657] iteration:10669  t-loss:0.1473, loss-lb:0.0962, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:31:28.849] iteration:10670  t-loss:0.1497, loss-lb:0.0885, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:31:29.043] iteration:10671  t-loss:0.1912, loss-lb:0.0908, loss-ulb:0.0502, weight:2.00, lr:0.0007
[11:31:29.235] iteration:10672  t-loss:0.1369, loss-lb:0.0863, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:31:29.429] iteration:10673  t-loss:0.1552, loss-lb:0.0945, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:31:29.621] iteration:10674  t-loss:0.1602, loss-lb:0.0994, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:31:29.812] iteration:10675  t-loss:0.1436, loss-lb:0.0905, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:31:30.003] iteration:10676  t-loss:0.1440, loss-lb:0.0877, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:31:30.194] iteration:10677  t-loss:0.1292, loss-lb:0.0822, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:31:30.385] iteration:10678  t-loss:0.1697, loss-lb:0.0950, loss-ulb:0.0374, weight:2.00, lr:0.0007
[11:31:30.576] iteration:10679  t-loss:0.1564, loss-lb:0.0858, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:31:30.767] iteration:10680  t-loss:0.1423, loss-lb:0.0871, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:31:30.958] iteration:10681  t-loss:0.1506, loss-lb:0.0893, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:31:31.148] iteration:10682  t-loss:0.2160, loss-lb:0.0926, loss-ulb:0.0617, weight:2.00, lr:0.0007
[11:31:42.491]  <<Test>> - Ep:108  - mean_dice/mean_h95 - S:89.71/1.36, Best-S:90.28, T:89.86/1.37, Best-T:90.48
[11:31:42.491]           - AvgLoss(lb/ulb/all):0.0881/0.0341/0.1591
[11:31:43.029] iteration:10683  t-loss:0.1644, loss-lb:0.0987, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:31:43.226] iteration:10684  t-loss:0.1341, loss-lb:0.0852, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:31:43.418] iteration:10685  t-loss:0.1401, loss-lb:0.0882, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:31:43.609] iteration:10686  t-loss:0.1595, loss-lb:0.0922, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:31:43.803] iteration:10687  t-loss:0.1559, loss-lb:0.0868, loss-ulb:0.0346, weight:2.00, lr:0.0007
[11:31:43.995] iteration:10688  t-loss:0.1354, loss-lb:0.0829, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:31:44.187] iteration:10689  t-loss:0.1634, loss-lb:0.0959, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:31:44.379] iteration:10690  t-loss:0.2253, loss-lb:0.0914, loss-ulb:0.0669, weight:2.00, lr:0.0007
[11:31:44.571] iteration:10691  t-loss:0.1340, loss-lb:0.0838, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:31:44.760] iteration:10692  t-loss:0.2048, loss-lb:0.0962, loss-ulb:0.0543, weight:2.00, lr:0.0007
[11:31:44.954] iteration:10693  t-loss:0.1476, loss-lb:0.0892, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:31:45.148] iteration:10694  t-loss:0.1636, loss-lb:0.0859, loss-ulb:0.0388, weight:2.00, lr:0.0007
[11:31:45.345] iteration:10695  t-loss:0.1793, loss-lb:0.0921, loss-ulb:0.0436, weight:2.00, lr:0.0007
[11:31:45.540] iteration:10696  t-loss:0.1431, loss-lb:0.0899, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:31:45.733] iteration:10697  t-loss:0.1876, loss-lb:0.0984, loss-ulb:0.0446, weight:2.00, lr:0.0007
[11:31:45.925] iteration:10698  t-loss:0.1670, loss-lb:0.0906, loss-ulb:0.0382, weight:2.00, lr:0.0007
[11:31:46.117] iteration:10699  t-loss:0.1361, loss-lb:0.0855, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:31:46.309] iteration:10700  t-loss:0.1837, loss-lb:0.1008, loss-ulb:0.0414, weight:2.00, lr:0.0007
[11:31:46.502] iteration:10701  t-loss:0.1465, loss-lb:0.0923, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:31:46.694] iteration:10702  t-loss:0.1483, loss-lb:0.0931, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:31:46.885] iteration:10703  t-loss:0.1511, loss-lb:0.0856, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:31:47.076] iteration:10704  t-loss:0.1623, loss-lb:0.0908, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:31:47.268] iteration:10705  t-loss:0.1435, loss-lb:0.0856, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:31:47.460] iteration:10706  t-loss:0.1403, loss-lb:0.0814, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:31:47.652] iteration:10707  t-loss:0.1441, loss-lb:0.0882, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:31:47.845] iteration:10708  t-loss:0.1847, loss-lb:0.0950, loss-ulb:0.0449, weight:2.00, lr:0.0007
[11:31:48.037] iteration:10709  t-loss:0.1507, loss-lb:0.0913, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:31:48.228] iteration:10710  t-loss:0.1534, loss-lb:0.0937, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:31:48.420] iteration:10711  t-loss:0.1751, loss-lb:0.0948, loss-ulb:0.0402, weight:2.00, lr:0.0007
[11:31:48.612] iteration:10712  t-loss:0.1535, loss-lb:0.0944, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:31:48.804] iteration:10713  t-loss:0.1784, loss-lb:0.0894, loss-ulb:0.0445, weight:2.00, lr:0.0007
[11:31:48.996] iteration:10714  t-loss:0.1392, loss-lb:0.0805, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:31:49.187] iteration:10715  t-loss:0.1482, loss-lb:0.0839, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:31:49.379] iteration:10716  t-loss:0.1477, loss-lb:0.0875, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:31:49.572] iteration:10717  t-loss:0.1624, loss-lb:0.1026, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:31:49.763] iteration:10718  t-loss:0.1676, loss-lb:0.1121, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:31:49.956] iteration:10719  t-loss:0.1681, loss-lb:0.0981, loss-ulb:0.0350, weight:2.00, lr:0.0007
[11:31:50.147] iteration:10720  t-loss:0.1337, loss-lb:0.0840, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:31:50.339] iteration:10721  t-loss:0.1423, loss-lb:0.0904, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:31:50.531] iteration:10722  t-loss:0.1673, loss-lb:0.0868, loss-ulb:0.0402, weight:2.00, lr:0.0007
[11:31:50.722] iteration:10723  t-loss:0.1365, loss-lb:0.0809, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:31:50.914] iteration:10724  t-loss:0.1489, loss-lb:0.0998, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:31:51.106] iteration:10725  t-loss:0.2629, loss-lb:0.0831, loss-ulb:0.0899, weight:2.00, lr:0.0007
[11:31:51.301] iteration:10726  t-loss:0.1428, loss-lb:0.0847, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:31:51.494] iteration:10727  t-loss:0.1425, loss-lb:0.0781, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:31:51.685] iteration:10728  t-loss:0.1439, loss-lb:0.0864, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:31:51.877] iteration:10729  t-loss:0.1297, loss-lb:0.0789, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:31:52.068] iteration:10730  t-loss:0.1395, loss-lb:0.0846, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:31:52.260] iteration:10731  t-loss:0.1537, loss-lb:0.0929, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:31:52.452] iteration:10732  t-loss:0.1503, loss-lb:0.0845, loss-ulb:0.0329, weight:2.00, lr:0.0007
[11:31:52.644] iteration:10733  t-loss:0.1469, loss-lb:0.0880, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:31:52.837] iteration:10734  t-loss:0.1831, loss-lb:0.0917, loss-ulb:0.0457, weight:2.00, lr:0.0007
[11:31:53.029] iteration:10735  t-loss:0.1378, loss-lb:0.0881, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:31:53.220] iteration:10736  t-loss:0.1779, loss-lb:0.0840, loss-ulb:0.0469, weight:2.00, lr:0.0007
[11:31:53.412] iteration:10737  t-loss:0.1422, loss-lb:0.0873, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:31:53.603] iteration:10738  t-loss:0.1551, loss-lb:0.0870, loss-ulb:0.0341, weight:2.00, lr:0.0007
[11:31:53.794] iteration:10739  t-loss:0.1422, loss-lb:0.0847, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:31:53.985] iteration:10740  t-loss:0.1369, loss-lb:0.0858, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:31:54.176] iteration:10741  t-loss:0.1591, loss-lb:0.1011, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:31:54.369] iteration:10742  t-loss:0.2163, loss-lb:0.0981, loss-ulb:0.0591, weight:2.00, lr:0.0007
[11:31:54.560] iteration:10743  t-loss:0.1428, loss-lb:0.0838, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:31:54.751] iteration:10744  t-loss:0.1446, loss-lb:0.0732, loss-ulb:0.0357, weight:2.00, lr:0.0007
[11:31:54.942] iteration:10745  t-loss:0.1401, loss-lb:0.0811, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:31:55.134] iteration:10746  t-loss:0.1472, loss-lb:0.0871, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:31:55.327] iteration:10747  t-loss:0.2558, loss-lb:0.0910, loss-ulb:0.0824, weight:2.00, lr:0.0007
[11:31:55.518] iteration:10748  t-loss:0.1305, loss-lb:0.0845, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:31:55.710] iteration:10749  t-loss:0.1364, loss-lb:0.0845, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:31:55.905] iteration:10750  t-loss:0.1411, loss-lb:0.0839, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:31:56.099] iteration:10751  t-loss:0.1523, loss-lb:0.0882, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:31:56.296] iteration:10752  t-loss:0.1620, loss-lb:0.0887, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:31:56.491] iteration:10753  t-loss:0.1389, loss-lb:0.0852, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:31:56.684] iteration:10754  t-loss:0.1467, loss-lb:0.0825, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:31:56.877] iteration:10755  t-loss:0.1510, loss-lb:0.0925, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:31:57.070] iteration:10756  t-loss:0.2769, loss-lb:0.0959, loss-ulb:0.0905, weight:2.00, lr:0.0007
[11:31:57.263] iteration:10757  t-loss:0.1788, loss-lb:0.0908, loss-ulb:0.0440, weight:2.00, lr:0.0007
[11:31:57.455] iteration:10758  t-loss:0.1488, loss-lb:0.0884, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:31:57.646] iteration:10759  t-loss:0.1513, loss-lb:0.0784, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:31:57.839] iteration:10760  t-loss:0.1464, loss-lb:0.0897, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:31:58.031] iteration:10761  t-loss:0.1452, loss-lb:0.0870, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:31:58.222] iteration:10762  t-loss:0.1385, loss-lb:0.0790, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:31:58.415] iteration:10763  t-loss:0.1393, loss-lb:0.0847, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:31:58.606] iteration:10764  t-loss:0.1535, loss-lb:0.1001, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:31:58.798] iteration:10765  t-loss:0.1273, loss-lb:0.0847, loss-ulb:0.0213, weight:2.00, lr:0.0007
[11:31:58.990] iteration:10766  t-loss:0.1321, loss-lb:0.0805, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:31:59.181] iteration:10767  t-loss:0.1377, loss-lb:0.0909, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:31:59.374] iteration:10768  t-loss:0.1622, loss-lb:0.0873, loss-ulb:0.0375, weight:2.00, lr:0.0007
[11:31:59.565] iteration:10769  t-loss:0.1754, loss-lb:0.0974, loss-ulb:0.0390, weight:2.00, lr:0.0007
[11:31:59.757] iteration:10770  t-loss:0.1350, loss-lb:0.0825, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:31:59.950] iteration:10771  t-loss:0.1516, loss-lb:0.0819, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:32:00.143] iteration:10772  t-loss:0.1482, loss-lb:0.0889, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:32:00.335] iteration:10773  t-loss:0.2438, loss-lb:0.0894, loss-ulb:0.0772, weight:2.00, lr:0.0007
[11:32:00.526] iteration:10774  t-loss:0.1567, loss-lb:0.1000, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:32:00.717] iteration:10775  t-loss:0.1484, loss-lb:0.0860, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:32:00.907] iteration:10776  t-loss:0.1391, loss-lb:0.0929, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:32:01.098] iteration:10777  t-loss:0.1435, loss-lb:0.0843, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:32:01.289] iteration:10778  t-loss:0.1793, loss-lb:0.0771, loss-ulb:0.0511, weight:2.00, lr:0.0007
[11:32:01.479] iteration:10779  t-loss:0.1363, loss-lb:0.0805, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:32:01.670] iteration:10780  t-loss:0.1562, loss-lb:0.0840, loss-ulb:0.0361, weight:2.00, lr:0.0007
[11:32:02.255] iteration:10781  t-loss:0.1620, loss-lb:0.0924, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:32:02.451] iteration:10782  t-loss:0.1299, loss-lb:0.0775, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:32:02.642] iteration:10783  t-loss:0.1366, loss-lb:0.0870, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:32:02.840] iteration:10784  t-loss:0.1359, loss-lb:0.0903, loss-ulb:0.0228, weight:2.00, lr:0.0007
[11:32:03.032] iteration:10785  t-loss:0.1358, loss-lb:0.0842, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:32:03.224] iteration:10786  t-loss:0.1470, loss-lb:0.0948, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:32:03.417] iteration:10787  t-loss:0.2356, loss-lb:0.0910, loss-ulb:0.0723, weight:2.00, lr:0.0007
[11:32:03.610] iteration:10788  t-loss:0.1540, loss-lb:0.0867, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:32:03.801] iteration:10789  t-loss:0.1713, loss-lb:0.0904, loss-ulb:0.0405, weight:2.00, lr:0.0007
[11:32:03.991] iteration:10790  t-loss:0.1535, loss-lb:0.0913, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:32:04.182] iteration:10791  t-loss:0.1616, loss-lb:0.0891, loss-ulb:0.0362, weight:2.00, lr:0.0007
[11:32:04.374] iteration:10792  t-loss:0.1499, loss-lb:0.0894, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:32:04.565] iteration:10793  t-loss:0.1748, loss-lb:0.0864, loss-ulb:0.0442, weight:2.00, lr:0.0007
[11:32:04.757] iteration:10794  t-loss:0.1927, loss-lb:0.0964, loss-ulb:0.0482, weight:2.00, lr:0.0007
[11:32:04.960] iteration:10795  t-loss:0.1623, loss-lb:0.0780, loss-ulb:0.0421, weight:2.00, lr:0.0007
[11:32:05.160] iteration:10796  t-loss:0.2518, loss-lb:0.0856, loss-ulb:0.0831, weight:2.00, lr:0.0007
[11:32:05.356] iteration:10797  t-loss:0.1532, loss-lb:0.0890, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:32:05.550] iteration:10798  t-loss:0.1384, loss-lb:0.0875, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:32:05.743] iteration:10799  t-loss:0.1965, loss-lb:0.0981, loss-ulb:0.0492, weight:2.00, lr:0.0007
[11:32:05.935] iteration:10800  t-loss:0.1391, loss-lb:0.0806, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:32:06.127] iteration:10801  t-loss:0.1463, loss-lb:0.0885, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:32:06.317] iteration:10802  t-loss:0.1654, loss-lb:0.0964, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:32:06.510] iteration:10803  t-loss:0.1449, loss-lb:0.0829, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:32:06.702] iteration:10804  t-loss:0.1427, loss-lb:0.0901, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:32:06.896] iteration:10805  t-loss:0.1434, loss-lb:0.0865, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:32:07.092] iteration:10806  t-loss:0.1510, loss-lb:0.0888, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:32:07.288] iteration:10807  t-loss:0.1502, loss-lb:0.0923, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:32:07.482] iteration:10808  t-loss:0.1633, loss-lb:0.0967, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:32:07.674] iteration:10809  t-loss:0.1534, loss-lb:0.0991, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:32:07.866] iteration:10810  t-loss:0.1628, loss-lb:0.1054, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:32:08.059] iteration:10811  t-loss:0.2096, loss-lb:0.0803, loss-ulb:0.0646, weight:2.00, lr:0.0007
[11:32:08.251] iteration:10812  t-loss:0.1524, loss-lb:0.1054, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:32:08.443] iteration:10813  t-loss:0.1637, loss-lb:0.0960, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:32:08.635] iteration:10814  t-loss:0.1531, loss-lb:0.0896, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:32:08.827] iteration:10815  t-loss:0.1459, loss-lb:0.0927, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:32:09.019] iteration:10816  t-loss:0.1763, loss-lb:0.0888, loss-ulb:0.0437, weight:2.00, lr:0.0007
[11:32:09.211] iteration:10817  t-loss:0.1436, loss-lb:0.0930, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:32:09.402] iteration:10818  t-loss:0.2402, loss-lb:0.0880, loss-ulb:0.0761, weight:2.00, lr:0.0007
[11:32:09.594] iteration:10819  t-loss:0.1564, loss-lb:0.0936, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:32:09.785] iteration:10820  t-loss:0.1545, loss-lb:0.0916, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:32:09.977] iteration:10821  t-loss:0.1416, loss-lb:0.0909, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:32:10.169] iteration:10822  t-loss:0.1611, loss-lb:0.0935, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:32:10.361] iteration:10823  t-loss:0.1596, loss-lb:0.0909, loss-ulb:0.0344, weight:2.00, lr:0.0007
[11:32:10.553] iteration:10824  t-loss:0.1404, loss-lb:0.0905, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:32:10.746] iteration:10825  t-loss:0.1679, loss-lb:0.0820, loss-ulb:0.0430, weight:2.00, lr:0.0007
[11:32:10.937] iteration:10826  t-loss:0.1419, loss-lb:0.0890, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:32:11.129] iteration:10827  t-loss:0.1384, loss-lb:0.0852, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:32:11.320] iteration:10828  t-loss:0.1560, loss-lb:0.0849, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:32:11.513] iteration:10829  t-loss:0.1443, loss-lb:0.0893, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:32:11.705] iteration:10830  t-loss:0.1436, loss-lb:0.0992, loss-ulb:0.0222, weight:2.00, lr:0.0007
[11:32:11.898] iteration:10831  t-loss:0.1903, loss-lb:0.0929, loss-ulb:0.0487, weight:2.00, lr:0.0007
[11:32:12.089] iteration:10832  t-loss:0.1465, loss-lb:0.0934, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:32:12.281] iteration:10833  t-loss:0.1397, loss-lb:0.0915, loss-ulb:0.0241, weight:2.00, lr:0.0007
[11:32:12.475] iteration:10834  t-loss:0.2199, loss-lb:0.0970, loss-ulb:0.0615, weight:2.00, lr:0.0007
[11:32:12.667] iteration:10835  t-loss:0.1503, loss-lb:0.0803, loss-ulb:0.0350, weight:2.00, lr:0.0007
[11:32:12.858] iteration:10836  t-loss:0.1501, loss-lb:0.0945, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:32:13.051] iteration:10837  t-loss:0.2083, loss-lb:0.0923, loss-ulb:0.0580, weight:2.00, lr:0.0007
[11:32:13.244] iteration:10838  t-loss:0.1638, loss-lb:0.0935, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:32:13.436] iteration:10839  t-loss:0.1911, loss-lb:0.0936, loss-ulb:0.0488, weight:2.00, lr:0.0007
[11:32:13.628] iteration:10840  t-loss:0.1439, loss-lb:0.0950, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:32:13.821] iteration:10841  t-loss:0.1344, loss-lb:0.0771, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:32:14.013] iteration:10842  t-loss:0.1505, loss-lb:0.0983, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:32:14.205] iteration:10843  t-loss:0.1363, loss-lb:0.0842, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:32:14.398] iteration:10844  t-loss:0.2860, loss-lb:0.1022, loss-ulb:0.0919, weight:2.00, lr:0.0007
[11:32:14.590] iteration:10845  t-loss:0.1516, loss-lb:0.0940, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:32:14.784] iteration:10846  t-loss:0.2429, loss-lb:0.0888, loss-ulb:0.0770, weight:2.00, lr:0.0007
[11:32:14.977] iteration:10847  t-loss:0.1744, loss-lb:0.1107, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:32:15.169] iteration:10848  t-loss:0.1566, loss-lb:0.0950, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:32:15.360] iteration:10849  t-loss:0.1739, loss-lb:0.0912, loss-ulb:0.0414, weight:2.00, lr:0.0007
[11:32:15.551] iteration:10850  t-loss:0.1572, loss-lb:0.0885, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:32:15.743] iteration:10851  t-loss:0.1583, loss-lb:0.0872, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:32:15.934] iteration:10852  t-loss:0.2044, loss-lb:0.1069, loss-ulb:0.0487, weight:2.00, lr:0.0007
[11:32:16.127] iteration:10853  t-loss:0.1444, loss-lb:0.0922, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:32:16.317] iteration:10854  t-loss:0.1501, loss-lb:0.0908, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:32:16.509] iteration:10855  t-loss:0.1564, loss-lb:0.0935, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:32:16.703] iteration:10856  t-loss:0.2311, loss-lb:0.0855, loss-ulb:0.0728, weight:2.00, lr:0.0007
[11:32:16.895] iteration:10857  t-loss:0.1481, loss-lb:0.0937, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:32:17.087] iteration:10858  t-loss:0.1448, loss-lb:0.0873, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:32:17.279] iteration:10859  t-loss:0.1607, loss-lb:0.0967, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:32:17.471] iteration:10860  t-loss:0.1362, loss-lb:0.0856, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:32:17.663] iteration:10861  t-loss:0.1519, loss-lb:0.0862, loss-ulb:0.0329, weight:2.00, lr:0.0007
[11:32:17.856] iteration:10862  t-loss:0.1496, loss-lb:0.0992, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:32:18.047] iteration:10863  t-loss:0.1669, loss-lb:0.0981, loss-ulb:0.0344, weight:2.00, lr:0.0007
[11:32:18.240] iteration:10864  t-loss:0.1508, loss-lb:0.0868, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:32:18.434] iteration:10865  t-loss:0.1589, loss-lb:0.1031, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:32:18.627] iteration:10866  t-loss:0.1535, loss-lb:0.0837, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:32:18.818] iteration:10867  t-loss:0.1389, loss-lb:0.0924, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:32:19.011] iteration:10868  t-loss:0.1650, loss-lb:0.0937, loss-ulb:0.0357, weight:2.00, lr:0.0007
[11:32:19.204] iteration:10869  t-loss:0.1725, loss-lb:0.0830, loss-ulb:0.0447, weight:2.00, lr:0.0007
[11:32:19.397] iteration:10870  t-loss:0.1544, loss-lb:0.0908, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:32:19.587] iteration:10871  t-loss:0.1404, loss-lb:0.0902, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:32:19.779] iteration:10872  t-loss:0.1713, loss-lb:0.0896, loss-ulb:0.0409, weight:2.00, lr:0.0007
[11:32:19.970] iteration:10873  t-loss:0.2697, loss-lb:0.0943, loss-ulb:0.0877, weight:2.00, lr:0.0007
[11:32:20.161] iteration:10874  t-loss:0.1582, loss-lb:0.1006, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:32:20.354] iteration:10875  t-loss:0.1468, loss-lb:0.0945, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:32:20.546] iteration:10876  t-loss:0.1956, loss-lb:0.0870, loss-ulb:0.0543, weight:2.00, lr:0.0007
[11:32:20.736] iteration:10877  t-loss:0.1337, loss-lb:0.0824, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:32:20.926] iteration:10878  t-loss:0.1525, loss-lb:0.0861, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:32:33.195]  <<Test>> - Ep:110  - mean_dice/mean_h95 - S:89.43/2.38, Best-S:90.28, T:89.85/1.36, Best-T:90.48
[11:32:33.195]           - AvgLoss(lb/ulb/all):0.0910/0.0351/0.1614
[11:32:33.746] iteration:10879  t-loss:0.1586, loss-lb:0.0980, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:32:33.942] iteration:10880  t-loss:0.1556, loss-lb:0.0830, loss-ulb:0.0363, weight:2.00, lr:0.0007
[11:32:34.135] iteration:10881  t-loss:0.1433, loss-lb:0.0839, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:32:34.328] iteration:10882  t-loss:0.1586, loss-lb:0.0920, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:32:34.521] iteration:10883  t-loss:0.1450, loss-lb:0.0974, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:32:34.714] iteration:10884  t-loss:0.1503, loss-lb:0.0988, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:32:34.906] iteration:10885  t-loss:0.1359, loss-lb:0.0886, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:32:35.100] iteration:10886  t-loss:0.1490, loss-lb:0.0905, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:32:35.293] iteration:10887  t-loss:0.1512, loss-lb:0.0859, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:32:35.487] iteration:10888  t-loss:0.2091, loss-lb:0.0898, loss-ulb:0.0596, weight:2.00, lr:0.0007
[11:32:35.679] iteration:10889  t-loss:0.1580, loss-lb:0.0842, loss-ulb:0.0369, weight:2.00, lr:0.0007
[11:32:35.873] iteration:10890  t-loss:0.2040, loss-lb:0.0993, loss-ulb:0.0524, weight:2.00, lr:0.0007
[11:32:36.066] iteration:10891  t-loss:0.1557, loss-lb:0.1029, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:32:36.260] iteration:10892  t-loss:0.2272, loss-lb:0.0937, loss-ulb:0.0668, weight:2.00, lr:0.0007
[11:32:36.455] iteration:10893  t-loss:0.1677, loss-lb:0.0846, loss-ulb:0.0415, weight:2.00, lr:0.0007
[11:32:36.650] iteration:10894  t-loss:0.1346, loss-lb:0.0818, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:32:36.842] iteration:10895  t-loss:0.1691, loss-lb:0.1070, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:32:37.035] iteration:10896  t-loss:0.1412, loss-lb:0.0849, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:32:37.228] iteration:10897  t-loss:0.1725, loss-lb:0.0940, loss-ulb:0.0393, weight:2.00, lr:0.0007
[11:32:37.422] iteration:10898  t-loss:0.1684, loss-lb:0.0861, loss-ulb:0.0412, weight:2.00, lr:0.0007
[11:32:37.616] iteration:10899  t-loss:0.1357, loss-lb:0.0885, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:32:37.823] iteration:10900  t-loss:0.1601, loss-lb:0.1019, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:32:38.023] iteration:10901  t-loss:0.1646, loss-lb:0.0779, loss-ulb:0.0434, weight:2.00, lr:0.0007
[11:32:38.217] iteration:10902  t-loss:0.1473, loss-lb:0.0973, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:32:38.409] iteration:10903  t-loss:0.1376, loss-lb:0.0844, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:32:38.602] iteration:10904  t-loss:0.1520, loss-lb:0.0928, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:32:38.795] iteration:10905  t-loss:0.1899, loss-lb:0.0886, loss-ulb:0.0506, weight:2.00, lr:0.0007
[11:32:38.987] iteration:10906  t-loss:0.1599, loss-lb:0.0895, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:32:39.180] iteration:10907  t-loss:0.1458, loss-lb:0.0858, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:32:39.373] iteration:10908  t-loss:0.1451, loss-lb:0.0907, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:32:39.566] iteration:10909  t-loss:0.1326, loss-lb:0.0797, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:32:39.759] iteration:10910  t-loss:0.1602, loss-lb:0.0981, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:32:39.951] iteration:10911  t-loss:0.1536, loss-lb:0.0926, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:32:40.143] iteration:10912  t-loss:0.1462, loss-lb:0.0991, loss-ulb:0.0235, weight:2.00, lr:0.0007
[11:32:40.336] iteration:10913  t-loss:0.1494, loss-lb:0.0809, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:32:40.528] iteration:10914  t-loss:0.1393, loss-lb:0.0891, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:32:40.720] iteration:10915  t-loss:0.1442, loss-lb:0.0887, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:32:40.913] iteration:10916  t-loss:0.1348, loss-lb:0.0836, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:32:41.110] iteration:10917  t-loss:0.1518, loss-lb:0.0902, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:32:41.302] iteration:10918  t-loss:0.1403, loss-lb:0.0826, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:32:41.495] iteration:10919  t-loss:0.1408, loss-lb:0.0870, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:32:41.687] iteration:10920  t-loss:0.1581, loss-lb:0.0933, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:32:41.879] iteration:10921  t-loss:0.1454, loss-lb:0.0883, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:32:42.072] iteration:10922  t-loss:0.1580, loss-lb:0.0878, loss-ulb:0.0351, weight:2.00, lr:0.0007
[11:32:42.264] iteration:10923  t-loss:0.1336, loss-lb:0.0824, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:32:42.458] iteration:10924  t-loss:0.1401, loss-lb:0.0869, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:32:42.649] iteration:10925  t-loss:0.1356, loss-lb:0.0855, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:32:42.842] iteration:10926  t-loss:0.1289, loss-lb:0.0781, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:32:43.035] iteration:10927  t-loss:0.1562, loss-lb:0.0957, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:32:43.228] iteration:10928  t-loss:0.1516, loss-lb:0.0840, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:32:43.421] iteration:10929  t-loss:0.1420, loss-lb:0.0901, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:32:43.613] iteration:10930  t-loss:0.1511, loss-lb:0.0850, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:32:43.806] iteration:10931  t-loss:0.1256, loss-lb:0.0782, loss-ulb:0.0237, weight:2.00, lr:0.0007
[11:32:43.998] iteration:10932  t-loss:0.1385, loss-lb:0.0843, loss-ulb:0.0271, weight:2.00, lr:0.0007
[11:32:44.189] iteration:10933  t-loss:0.1351, loss-lb:0.0842, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:32:44.381] iteration:10934  t-loss:0.1556, loss-lb:0.0931, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:32:44.575] iteration:10935  t-loss:0.1937, loss-lb:0.0920, loss-ulb:0.0508, weight:2.00, lr:0.0007
[11:32:44.767] iteration:10936  t-loss:0.1457, loss-lb:0.0913, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:32:44.960] iteration:10937  t-loss:0.1351, loss-lb:0.0791, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:32:45.153] iteration:10938  t-loss:0.1560, loss-lb:0.0805, loss-ulb:0.0378, weight:2.00, lr:0.0007
[11:32:45.346] iteration:10939  t-loss:0.1395, loss-lb:0.0786, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:32:45.538] iteration:10940  t-loss:0.1420, loss-lb:0.0932, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:32:45.731] iteration:10941  t-loss:0.1406, loss-lb:0.0792, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:32:45.924] iteration:10942  t-loss:0.1367, loss-lb:0.0803, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:32:46.115] iteration:10943  t-loss:0.1344, loss-lb:0.0844, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:32:46.307] iteration:10944  t-loss:0.1428, loss-lb:0.0851, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:32:46.499] iteration:10945  t-loss:0.1347, loss-lb:0.0870, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:32:46.692] iteration:10946  t-loss:0.1507, loss-lb:0.0897, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:32:46.883] iteration:10947  t-loss:0.1179, loss-lb:0.0779, loss-ulb:0.0200, weight:2.00, lr:0.0007
[11:32:47.076] iteration:10948  t-loss:0.1430, loss-lb:0.0800, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:32:47.269] iteration:10949  t-loss:0.1413, loss-lb:0.0822, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:32:47.461] iteration:10950  t-loss:0.1450, loss-lb:0.0888, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:32:47.653] iteration:10951  t-loss:0.1490, loss-lb:0.0886, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:32:47.846] iteration:10952  t-loss:0.1719, loss-lb:0.0986, loss-ulb:0.0366, weight:2.00, lr:0.0007
[11:32:48.038] iteration:10953  t-loss:0.1524, loss-lb:0.0893, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:32:48.230] iteration:10954  t-loss:0.1345, loss-lb:0.0826, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:32:48.422] iteration:10955  t-loss:0.1446, loss-lb:0.0860, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:32:48.616] iteration:10956  t-loss:0.1340, loss-lb:0.0811, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:32:48.809] iteration:10957  t-loss:0.1662, loss-lb:0.1154, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:32:49.002] iteration:10958  t-loss:0.1428, loss-lb:0.0884, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:32:49.195] iteration:10959  t-loss:0.1434, loss-lb:0.0818, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:32:49.389] iteration:10960  t-loss:0.1349, loss-lb:0.0877, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:32:49.581] iteration:10961  t-loss:0.1425, loss-lb:0.0895, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:32:49.774] iteration:10962  t-loss:0.1465, loss-lb:0.0884, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:32:49.968] iteration:10963  t-loss:0.1557, loss-lb:0.0850, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:32:50.161] iteration:10964  t-loss:0.1388, loss-lb:0.0829, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:32:50.354] iteration:10965  t-loss:0.2228, loss-lb:0.0889, loss-ulb:0.0669, weight:2.00, lr:0.0007
[11:32:50.546] iteration:10966  t-loss:0.2049, loss-lb:0.0868, loss-ulb:0.0591, weight:2.00, lr:0.0007
[11:32:50.740] iteration:10967  t-loss:0.2648, loss-lb:0.0942, loss-ulb:0.0853, weight:2.00, lr:0.0007
[11:32:50.932] iteration:10968  t-loss:0.1532, loss-lb:0.0812, loss-ulb:0.0360, weight:2.00, lr:0.0007
[11:32:51.125] iteration:10969  t-loss:0.2070, loss-lb:0.0922, loss-ulb:0.0574, weight:2.00, lr:0.0007
[11:32:51.316] iteration:10970  t-loss:0.1650, loss-lb:0.0968, loss-ulb:0.0341, weight:2.00, lr:0.0007
[11:32:51.506] iteration:10971  t-loss:0.1449, loss-lb:0.0923, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:32:51.697] iteration:10972  t-loss:0.1464, loss-lb:0.0870, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:32:51.888] iteration:10973  t-loss:0.1384, loss-lb:0.0864, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:32:52.079] iteration:10974  t-loss:0.2031, loss-lb:0.0848, loss-ulb:0.0591, weight:2.00, lr:0.0007
[11:32:52.270] iteration:10975  t-loss:0.1430, loss-lb:0.0861, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:32:52.462] iteration:10976  t-loss:0.1761, loss-lb:0.1006, loss-ulb:0.0377, weight:2.00, lr:0.0007
[11:32:53.072] iteration:10977  t-loss:0.1707, loss-lb:0.0888, loss-ulb:0.0410, weight:2.00, lr:0.0007
[11:32:53.266] iteration:10978  t-loss:0.1586, loss-lb:0.0870, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:32:53.460] iteration:10979  t-loss:0.1624, loss-lb:0.1001, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:32:53.652] iteration:10980  t-loss:0.1488, loss-lb:0.0903, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:32:53.844] iteration:10981  t-loss:0.1663, loss-lb:0.1013, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:32:54.037] iteration:10982  t-loss:0.1471, loss-lb:0.0855, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:32:54.230] iteration:10983  t-loss:0.1434, loss-lb:0.0884, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:32:54.423] iteration:10984  t-loss:0.1470, loss-lb:0.0810, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:32:54.615] iteration:10985  t-loss:0.1426, loss-lb:0.0840, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:32:54.809] iteration:10986  t-loss:0.2021, loss-lb:0.0895, loss-ulb:0.0563, weight:2.00, lr:0.0007
[11:32:55.001] iteration:10987  t-loss:0.1538, loss-lb:0.0882, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:32:55.193] iteration:10988  t-loss:0.1725, loss-lb:0.0859, loss-ulb:0.0433, weight:2.00, lr:0.0007
[11:32:55.385] iteration:10989  t-loss:0.1771, loss-lb:0.1010, loss-ulb:0.0381, weight:2.00, lr:0.0007
[11:32:55.578] iteration:10990  t-loss:0.1532, loss-lb:0.0861, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:32:55.771] iteration:10991  t-loss:0.2244, loss-lb:0.0846, loss-ulb:0.0699, weight:2.00, lr:0.0007
[11:32:55.964] iteration:10992  t-loss:0.1548, loss-lb:0.0819, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:32:56.156] iteration:10993  t-loss:0.2125, loss-lb:0.1075, loss-ulb:0.0525, weight:2.00, lr:0.0007
[11:32:56.348] iteration:10994  t-loss:0.1442, loss-lb:0.0921, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:32:56.541] iteration:10995  t-loss:0.1625, loss-lb:0.0929, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:32:56.733] iteration:10996  t-loss:0.1446, loss-lb:0.0862, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:32:56.925] iteration:10997  t-loss:0.1497, loss-lb:0.0934, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:32:57.117] iteration:10998  t-loss:0.2300, loss-lb:0.0850, loss-ulb:0.0725, weight:2.00, lr:0.0007
[11:32:57.310] iteration:10999  t-loss:0.1524, loss-lb:0.0916, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:32:57.502] iteration:11000  t-loss:0.1879, loss-lb:0.0791, loss-ulb:0.0544, weight:2.00, lr:0.0007
[11:32:57.694] iteration:11001  t-loss:0.1684, loss-lb:0.1039, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:32:57.887] iteration:11002  t-loss:0.1576, loss-lb:0.1028, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:32:58.079] iteration:11003  t-loss:0.1536, loss-lb:0.0905, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:32:58.271] iteration:11004  t-loss:0.1593, loss-lb:0.0955, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:32:58.464] iteration:11005  t-loss:0.1456, loss-lb:0.0846, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:32:58.657] iteration:11006  t-loss:0.1433, loss-lb:0.0884, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:32:58.849] iteration:11007  t-loss:0.1984, loss-lb:0.0949, loss-ulb:0.0518, weight:2.00, lr:0.0007
[11:32:59.041] iteration:11008  t-loss:0.1459, loss-lb:0.0951, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:32:59.234] iteration:11009  t-loss:0.1337, loss-lb:0.0831, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:32:59.426] iteration:11010  t-loss:0.2099, loss-lb:0.0863, loss-ulb:0.0618, weight:2.00, lr:0.0007
[11:32:59.620] iteration:11011  t-loss:0.1413, loss-lb:0.0837, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:32:59.812] iteration:11012  t-loss:0.1501, loss-lb:0.0940, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:33:00.004] iteration:11013  t-loss:0.1611, loss-lb:0.0907, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:33:00.197] iteration:11014  t-loss:0.1394, loss-lb:0.0922, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:33:00.391] iteration:11015  t-loss:0.1496, loss-lb:0.0969, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:33:00.583] iteration:11016  t-loss:0.2196, loss-lb:0.0873, loss-ulb:0.0661, weight:2.00, lr:0.0007
[11:33:00.776] iteration:11017  t-loss:0.1531, loss-lb:0.1025, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:33:00.970] iteration:11018  t-loss:0.1872, loss-lb:0.0910, loss-ulb:0.0481, weight:2.00, lr:0.0007
[11:33:01.162] iteration:11019  t-loss:0.1511, loss-lb:0.0880, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:33:01.354] iteration:11020  t-loss:0.2186, loss-lb:0.0977, loss-ulb:0.0605, weight:2.00, lr:0.0007
[11:33:01.549] iteration:11021  t-loss:0.1519, loss-lb:0.0841, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:33:01.741] iteration:11022  t-loss:0.1499, loss-lb:0.1003, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:33:01.935] iteration:11023  t-loss:0.1428, loss-lb:0.0783, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:33:02.127] iteration:11024  t-loss:0.1402, loss-lb:0.0832, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:33:02.320] iteration:11025  t-loss:0.1719, loss-lb:0.0962, loss-ulb:0.0379, weight:2.00, lr:0.0007
[11:33:02.512] iteration:11026  t-loss:0.1304, loss-lb:0.0872, loss-ulb:0.0216, weight:2.00, lr:0.0007
[11:33:02.705] iteration:11027  t-loss:0.1427, loss-lb:0.0881, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:33:02.898] iteration:11028  t-loss:0.1557, loss-lb:0.1010, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:33:03.091] iteration:11029  t-loss:0.1815, loss-lb:0.0966, loss-ulb:0.0424, weight:2.00, lr:0.0007
[11:33:03.284] iteration:11030  t-loss:0.1474, loss-lb:0.0878, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:33:03.476] iteration:11031  t-loss:0.1447, loss-lb:0.0929, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:33:03.669] iteration:11032  t-loss:0.1593, loss-lb:0.0955, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:33:03.861] iteration:11033  t-loss:0.1374, loss-lb:0.0924, loss-ulb:0.0225, weight:2.00, lr:0.0007
[11:33:04.053] iteration:11034  t-loss:0.1485, loss-lb:0.0876, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:33:04.246] iteration:11035  t-loss:0.1533, loss-lb:0.0962, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:33:04.439] iteration:11036  t-loss:0.2052, loss-lb:0.0952, loss-ulb:0.0550, weight:2.00, lr:0.0007
[11:33:04.632] iteration:11037  t-loss:0.1632, loss-lb:0.0873, loss-ulb:0.0379, weight:2.00, lr:0.0007
[11:33:04.824] iteration:11038  t-loss:0.1714, loss-lb:0.0813, loss-ulb:0.0450, weight:2.00, lr:0.0007
[11:33:05.017] iteration:11039  t-loss:0.1485, loss-lb:0.0896, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:33:05.211] iteration:11040  t-loss:0.1527, loss-lb:0.1013, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:33:05.403] iteration:11041  t-loss:0.1400, loss-lb:0.0872, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:33:05.595] iteration:11042  t-loss:0.1799, loss-lb:0.0880, loss-ulb:0.0460, weight:2.00, lr:0.0007
[11:33:05.788] iteration:11043  t-loss:0.1666, loss-lb:0.0939, loss-ulb:0.0364, weight:2.00, lr:0.0007
[11:33:05.980] iteration:11044  t-loss:0.1609, loss-lb:0.0853, loss-ulb:0.0378, weight:2.00, lr:0.0007
[11:33:06.172] iteration:11045  t-loss:0.1465, loss-lb:0.0854, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:33:06.364] iteration:11046  t-loss:0.1524, loss-lb:0.0925, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:33:06.558] iteration:11047  t-loss:0.3148, loss-lb:0.0942, loss-ulb:0.1103, weight:2.00, lr:0.0007
[11:33:06.750] iteration:11048  t-loss:0.1834, loss-lb:0.1176, loss-ulb:0.0329, weight:2.00, lr:0.0007
[11:33:06.942] iteration:11049  t-loss:0.2062, loss-lb:0.0953, loss-ulb:0.0554, weight:2.00, lr:0.0007
[11:33:07.135] iteration:11050  t-loss:0.1468, loss-lb:0.0919, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:33:07.326] iteration:11051  t-loss:0.1369, loss-lb:0.0820, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:33:07.519] iteration:11052  t-loss:0.1369, loss-lb:0.0834, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:33:07.714] iteration:11053  t-loss:0.1545, loss-lb:0.0874, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:33:07.909] iteration:11054  t-loss:0.1571, loss-lb:0.0893, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:33:08.105] iteration:11055  t-loss:0.1789, loss-lb:0.0881, loss-ulb:0.0454, weight:2.00, lr:0.0007
[11:33:08.298] iteration:11056  t-loss:0.1748, loss-lb:0.1039, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:33:08.491] iteration:11057  t-loss:0.1313, loss-lb:0.0827, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:33:08.682] iteration:11058  t-loss:0.1455, loss-lb:0.0873, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:33:08.874] iteration:11059  t-loss:0.1524, loss-lb:0.0963, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:33:09.065] iteration:11060  t-loss:0.1505, loss-lb:0.0925, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:33:09.258] iteration:11061  t-loss:0.1427, loss-lb:0.0834, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:33:09.450] iteration:11062  t-loss:0.1406, loss-lb:0.0818, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:33:09.642] iteration:11063  t-loss:0.1372, loss-lb:0.0847, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:33:09.834] iteration:11064  t-loss:0.1465, loss-lb:0.0941, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:33:10.028] iteration:11065  t-loss:0.1871, loss-lb:0.1023, loss-ulb:0.0424, weight:2.00, lr:0.0007
[11:33:10.219] iteration:11066  t-loss:0.1623, loss-lb:0.0938, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:33:10.414] iteration:11067  t-loss:0.1436, loss-lb:0.0889, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:33:10.614] iteration:11068  t-loss:0.1433, loss-lb:0.0935, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:33:10.811] iteration:11069  t-loss:0.1878, loss-lb:0.0869, loss-ulb:0.0504, weight:2.00, lr:0.0007
[11:33:11.002] iteration:11070  t-loss:0.1377, loss-lb:0.0831, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:33:11.192] iteration:11071  t-loss:0.1257, loss-lb:0.0849, loss-ulb:0.0204, weight:2.00, lr:0.0007
[11:33:11.383] iteration:11072  t-loss:0.1606, loss-lb:0.0894, loss-ulb:0.0356, weight:2.00, lr:0.0007
[11:33:11.573] iteration:11073  t-loss:0.1429, loss-lb:0.0893, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:33:11.765] iteration:11074  t-loss:0.1577, loss-lb:0.0994, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:33:22.946]  <<Test>> - Ep:112  - mean_dice/mean_h95 - S:88.86/3.57, Best-S:90.28, T:90.00/1.34, Best-T:90.48
[11:33:22.947]           - AvgLoss(lb/ulb/all):0.0908/0.0311/0.1525
[11:33:23.472] iteration:11075  t-loss:0.2723, loss-lb:0.0977, loss-ulb:0.0873, weight:2.00, lr:0.0007
[11:33:23.670] iteration:11076  t-loss:0.1466, loss-lb:0.0917, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:33:23.863] iteration:11077  t-loss:0.1468, loss-lb:0.0933, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:33:24.056] iteration:11078  t-loss:0.1509, loss-lb:0.0970, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:33:24.248] iteration:11079  t-loss:0.1556, loss-lb:0.0976, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:33:24.442] iteration:11080  t-loss:0.1831, loss-lb:0.0868, loss-ulb:0.0482, weight:2.00, lr:0.0007
[11:33:24.635] iteration:11081  t-loss:0.1448, loss-lb:0.0866, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:33:24.827] iteration:11082  t-loss:0.1515, loss-lb:0.0838, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:33:25.020] iteration:11083  t-loss:0.2010, loss-lb:0.1479, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:33:25.212] iteration:11084  t-loss:0.1349, loss-lb:0.0801, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:33:25.406] iteration:11085  t-loss:0.1822, loss-lb:0.0942, loss-ulb:0.0440, weight:2.00, lr:0.0007
[11:33:25.597] iteration:11086  t-loss:0.1537, loss-lb:0.0934, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:33:25.790] iteration:11087  t-loss:0.1545, loss-lb:0.0895, loss-ulb:0.0325, weight:2.00, lr:0.0007
[11:33:25.983] iteration:11088  t-loss:0.1972, loss-lb:0.0775, loss-ulb:0.0598, weight:2.00, lr:0.0007
[11:33:26.175] iteration:11089  t-loss:0.1664, loss-lb:0.0992, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:33:26.367] iteration:11090  t-loss:0.1444, loss-lb:0.0886, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:33:26.558] iteration:11091  t-loss:0.1654, loss-lb:0.0972, loss-ulb:0.0341, weight:2.00, lr:0.0007
[11:33:26.750] iteration:11092  t-loss:0.1511, loss-lb:0.0869, loss-ulb:0.0321, weight:2.00, lr:0.0007
[11:33:26.943] iteration:11093  t-loss:0.1383, loss-lb:0.0895, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:33:27.134] iteration:11094  t-loss:0.1907, loss-lb:0.0911, loss-ulb:0.0498, weight:2.00, lr:0.0007
[11:33:27.326] iteration:11095  t-loss:0.1434, loss-lb:0.0880, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:33:27.516] iteration:11096  t-loss:0.1653, loss-lb:0.1028, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:33:27.708] iteration:11097  t-loss:0.1362, loss-lb:0.0887, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:33:27.900] iteration:11098  t-loss:0.1452, loss-lb:0.0894, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:33:28.091] iteration:11099  t-loss:0.1643, loss-lb:0.0801, loss-ulb:0.0421, weight:2.00, lr:0.0007
[11:33:28.283] iteration:11100  t-loss:0.1416, loss-lb:0.0878, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:33:28.474] iteration:11101  t-loss:0.1868, loss-lb:0.1243, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:33:28.665] iteration:11102  t-loss:0.1438, loss-lb:0.0939, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:33:28.858] iteration:11103  t-loss:0.1434, loss-lb:0.0921, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:33:29.049] iteration:11104  t-loss:0.1574, loss-lb:0.0961, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:33:29.243] iteration:11105  t-loss:0.1798, loss-lb:0.0984, loss-ulb:0.0407, weight:2.00, lr:0.0007
[11:33:29.439] iteration:11106  t-loss:0.1650, loss-lb:0.0874, loss-ulb:0.0388, weight:2.00, lr:0.0007
[11:33:29.635] iteration:11107  t-loss:0.1757, loss-lb:0.0841, loss-ulb:0.0458, weight:2.00, lr:0.0007
[11:33:29.830] iteration:11108  t-loss:0.1420, loss-lb:0.0765, loss-ulb:0.0328, weight:2.00, lr:0.0007
[11:33:30.024] iteration:11109  t-loss:0.1364, loss-lb:0.0928, loss-ulb:0.0218, weight:2.00, lr:0.0007
[11:33:30.218] iteration:11110  t-loss:0.1456, loss-lb:0.0870, loss-ulb:0.0293, weight:2.00, lr:0.0007
[11:33:30.410] iteration:11111  t-loss:0.1540, loss-lb:0.0892, loss-ulb:0.0324, weight:2.00, lr:0.0007
[11:33:30.605] iteration:11112  t-loss:0.2182, loss-lb:0.0918, loss-ulb:0.0632, weight:2.00, lr:0.0007
[11:33:30.796] iteration:11113  t-loss:0.1514, loss-lb:0.0994, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:33:30.988] iteration:11114  t-loss:0.1468, loss-lb:0.0909, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:33:31.181] iteration:11115  t-loss:0.1469, loss-lb:0.0835, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:33:31.373] iteration:11116  t-loss:0.1487, loss-lb:0.0843, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:33:31.566] iteration:11117  t-loss:0.1684, loss-lb:0.1012, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:33:31.758] iteration:11118  t-loss:0.1356, loss-lb:0.0779, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:33:31.949] iteration:11119  t-loss:0.1417, loss-lb:0.0811, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:33:32.141] iteration:11120  t-loss:0.1482, loss-lb:0.0822, loss-ulb:0.0330, weight:2.00, lr:0.0007
[11:33:32.333] iteration:11121  t-loss:0.1343, loss-lb:0.0840, loss-ulb:0.0252, weight:2.00, lr:0.0007
[11:33:32.526] iteration:11122  t-loss:0.1410, loss-lb:0.0810, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:33:32.717] iteration:11123  t-loss:0.1592, loss-lb:0.0894, loss-ulb:0.0349, weight:2.00, lr:0.0007
[11:33:32.909] iteration:11124  t-loss:0.1505, loss-lb:0.0879, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:33:33.101] iteration:11125  t-loss:0.1583, loss-lb:0.0879, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:33:33.292] iteration:11126  t-loss:0.1398, loss-lb:0.0821, loss-ulb:0.0289, weight:2.00, lr:0.0007
[11:33:33.485] iteration:11127  t-loss:0.1579, loss-lb:0.0856, loss-ulb:0.0362, weight:2.00, lr:0.0007
[11:33:33.676] iteration:11128  t-loss:0.1497, loss-lb:0.0879, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:33:33.868] iteration:11129  t-loss:0.1530, loss-lb:0.0814, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:33:34.061] iteration:11130  t-loss:0.1611, loss-lb:0.1051, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:33:34.252] iteration:11131  t-loss:0.1381, loss-lb:0.0851, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:33:34.445] iteration:11132  t-loss:0.1315, loss-lb:0.0840, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:33:34.637] iteration:11133  t-loss:0.1462, loss-lb:0.0842, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:33:34.828] iteration:11134  t-loss:0.1440, loss-lb:0.0904, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:33:35.021] iteration:11135  t-loss:0.1447, loss-lb:0.0914, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:33:35.212] iteration:11136  t-loss:0.1444, loss-lb:0.1017, loss-ulb:0.0213, weight:2.00, lr:0.0007
[11:33:35.405] iteration:11137  t-loss:0.1298, loss-lb:0.0835, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:33:35.598] iteration:11138  t-loss:0.1512, loss-lb:0.0857, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:33:35.789] iteration:11139  t-loss:0.1597, loss-lb:0.0908, loss-ulb:0.0345, weight:2.00, lr:0.0007
[11:33:35.981] iteration:11140  t-loss:0.1297, loss-lb:0.0813, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:33:36.173] iteration:11141  t-loss:0.1386, loss-lb:0.0865, loss-ulb:0.0260, weight:2.00, lr:0.0007
[11:33:36.365] iteration:11142  t-loss:0.1485, loss-lb:0.0963, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:33:36.559] iteration:11143  t-loss:0.1842, loss-lb:0.0948, loss-ulb:0.0447, weight:2.00, lr:0.0007
[11:33:36.750] iteration:11144  t-loss:0.1263, loss-lb:0.0822, loss-ulb:0.0220, weight:2.00, lr:0.0007
[11:33:36.943] iteration:11145  t-loss:0.1945, loss-lb:0.1434, loss-ulb:0.0256, weight:2.00, lr:0.0007
[11:33:37.135] iteration:11146  t-loss:0.1568, loss-lb:0.0991, loss-ulb:0.0288, weight:2.00, lr:0.0007
[11:33:37.327] iteration:11147  t-loss:0.1476, loss-lb:0.0862, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:33:37.519] iteration:11148  t-loss:0.2643, loss-lb:0.0881, loss-ulb:0.0881, weight:2.00, lr:0.0007
[11:33:37.711] iteration:11149  t-loss:0.1623, loss-lb:0.0885, loss-ulb:0.0369, weight:2.00, lr:0.0007
[11:33:37.902] iteration:11150  t-loss:0.1441, loss-lb:0.0878, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:33:38.094] iteration:11151  t-loss:0.1563, loss-lb:0.0929, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:33:38.286] iteration:11152  t-loss:0.1604, loss-lb:0.0858, loss-ulb:0.0373, weight:2.00, lr:0.0007
[11:33:38.476] iteration:11153  t-loss:0.1409, loss-lb:0.0880, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:33:38.669] iteration:11154  t-loss:0.2902, loss-lb:0.0981, loss-ulb:0.0960, weight:2.00, lr:0.0007
[11:33:38.860] iteration:11155  t-loss:0.1348, loss-lb:0.0860, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:33:39.051] iteration:11156  t-loss:0.1717, loss-lb:0.1079, loss-ulb:0.0319, weight:2.00, lr:0.0007
[11:33:39.243] iteration:11157  t-loss:0.1631, loss-lb:0.1030, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:33:39.434] iteration:11158  t-loss:0.1389, loss-lb:0.0889, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:33:39.626] iteration:11159  t-loss:0.1553, loss-lb:0.0939, loss-ulb:0.0307, weight:2.00, lr:0.0007
[11:33:39.817] iteration:11160  t-loss:0.1465, loss-lb:0.0858, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:33:40.011] iteration:11161  t-loss:0.1472, loss-lb:0.0898, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:33:40.204] iteration:11162  t-loss:0.1595, loss-lb:0.0889, loss-ulb:0.0353, weight:2.00, lr:0.0007
[11:33:40.403] iteration:11163  t-loss:0.1991, loss-lb:0.0968, loss-ulb:0.0512, weight:2.00, lr:0.0007
[11:33:40.598] iteration:11164  t-loss:0.2230, loss-lb:0.0877, loss-ulb:0.0677, weight:2.00, lr:0.0007
[11:33:40.792] iteration:11165  t-loss:0.1944, loss-lb:0.0930, loss-ulb:0.0507, weight:2.00, lr:0.0007
[11:33:40.983] iteration:11166  t-loss:0.1518, loss-lb:0.0912, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:33:41.174] iteration:11167  t-loss:0.1504, loss-lb:0.0869, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:33:41.364] iteration:11168  t-loss:0.1943, loss-lb:0.1194, loss-ulb:0.0374, weight:2.00, lr:0.0007
[11:33:41.554] iteration:11169  t-loss:0.1296, loss-lb:0.0815, loss-ulb:0.0240, weight:2.00, lr:0.0007
[11:33:41.745] iteration:11170  t-loss:0.1438, loss-lb:0.0928, loss-ulb:0.0255, weight:2.00, lr:0.0007
[11:33:41.935] iteration:11171  t-loss:0.1705, loss-lb:0.0897, loss-ulb:0.0404, weight:2.00, lr:0.0007
[11:33:42.126] iteration:11172  t-loss:0.1637, loss-lb:0.0895, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:33:42.736] iteration:11173  t-loss:0.1568, loss-lb:0.0977, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:33:42.932] iteration:11174  t-loss:0.1443, loss-lb:0.0903, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:33:43.124] iteration:11175  t-loss:0.1496, loss-lb:0.0874, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:33:43.331] iteration:11176  t-loss:0.1529, loss-lb:0.0902, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:33:43.529] iteration:11177  t-loss:0.1547, loss-lb:0.0992, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:33:43.723] iteration:11178  t-loss:0.1347, loss-lb:0.0803, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:33:43.916] iteration:11179  t-loss:0.2622, loss-lb:0.0881, loss-ulb:0.0871, weight:2.00, lr:0.0007
[11:33:44.107] iteration:11180  t-loss:0.1760, loss-lb:0.0945, loss-ulb:0.0408, weight:2.00, lr:0.0007
[11:33:44.299] iteration:11181  t-loss:0.1482, loss-lb:0.0924, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:33:44.491] iteration:11182  t-loss:0.1408, loss-lb:0.0828, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:33:44.683] iteration:11183  t-loss:0.1498, loss-lb:0.0877, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:33:44.875] iteration:11184  t-loss:0.1450, loss-lb:0.0917, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:33:45.068] iteration:11185  t-loss:0.1327, loss-lb:0.0841, loss-ulb:0.0243, weight:2.00, lr:0.0007
[11:33:45.260] iteration:11186  t-loss:0.1404, loss-lb:0.0786, loss-ulb:0.0309, weight:2.00, lr:0.0007
[11:33:45.452] iteration:11187  t-loss:0.1372, loss-lb:0.0865, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:33:45.645] iteration:11188  t-loss:0.1430, loss-lb:0.0818, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:33:45.836] iteration:11189  t-loss:0.1785, loss-lb:0.1066, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:33:46.028] iteration:11190  t-loss:0.1682, loss-lb:0.1152, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:33:46.221] iteration:11191  t-loss:0.1487, loss-lb:0.0896, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:33:46.412] iteration:11192  t-loss:0.1358, loss-lb:0.0804, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:33:46.604] iteration:11193  t-loss:0.1746, loss-lb:0.0857, loss-ulb:0.0444, weight:2.00, lr:0.0007
[11:33:46.796] iteration:11194  t-loss:0.1392, loss-lb:0.0869, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:33:46.986] iteration:11195  t-loss:0.1415, loss-lb:0.0890, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:33:47.179] iteration:11196  t-loss:0.1341, loss-lb:0.0789, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:33:47.371] iteration:11197  t-loss:0.1563, loss-lb:0.1075, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:33:47.563] iteration:11198  t-loss:0.1603, loss-lb:0.0968, loss-ulb:0.0317, weight:2.00, lr:0.0007
[11:33:47.756] iteration:11199  t-loss:0.1515, loss-lb:0.0808, loss-ulb:0.0354, weight:2.00, lr:0.0007
[11:33:47.949] iteration:11200  t-loss:0.2161, loss-lb:0.0870, loss-ulb:0.0646, weight:2.00, lr:0.0007
[11:33:48.141] iteration:11201  t-loss:0.1549, loss-lb:0.0980, loss-ulb:0.0285, weight:2.00, lr:0.0007
[11:33:48.334] iteration:11202  t-loss:0.2198, loss-lb:0.0970, loss-ulb:0.0614, weight:2.00, lr:0.0007
[11:33:48.525] iteration:11203  t-loss:0.1310, loss-lb:0.0788, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:33:48.717] iteration:11204  t-loss:0.1372, loss-lb:0.0857, loss-ulb:0.0258, weight:2.00, lr:0.0007
[11:33:48.909] iteration:11205  t-loss:0.2134, loss-lb:0.0903, loss-ulb:0.0615, weight:2.00, lr:0.0007
[11:33:49.102] iteration:11206  t-loss:0.1506, loss-lb:0.0948, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:33:49.294] iteration:11207  t-loss:0.1672, loss-lb:0.0909, loss-ulb:0.0382, weight:2.00, lr:0.0007
[11:33:49.486] iteration:11208  t-loss:0.1480, loss-lb:0.0924, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:33:49.677] iteration:11209  t-loss:0.1379, loss-lb:0.0839, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:33:49.868] iteration:11210  t-loss:0.1427, loss-lb:0.0852, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:33:50.060] iteration:11211  t-loss:0.1710, loss-lb:0.0973, loss-ulb:0.0368, weight:2.00, lr:0.0007
[11:33:50.251] iteration:11212  t-loss:0.1469, loss-lb:0.0909, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:33:50.443] iteration:11213  t-loss:0.2215, loss-lb:0.0891, loss-ulb:0.0662, weight:2.00, lr:0.0007
[11:33:50.634] iteration:11214  t-loss:0.2336, loss-lb:0.0842, loss-ulb:0.0747, weight:2.00, lr:0.0007
[11:33:50.827] iteration:11215  t-loss:0.1589, loss-lb:0.0888, loss-ulb:0.0351, weight:2.00, lr:0.0007
[11:33:51.019] iteration:11216  t-loss:0.1436, loss-lb:0.0911, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:33:51.212] iteration:11217  t-loss:0.1428, loss-lb:0.0832, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:33:51.404] iteration:11218  t-loss:0.1483, loss-lb:0.0912, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:33:51.596] iteration:11219  t-loss:0.1480, loss-lb:0.0882, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:33:51.788] iteration:11220  t-loss:0.1720, loss-lb:0.0956, loss-ulb:0.0382, weight:2.00, lr:0.0007
[11:33:51.980] iteration:11221  t-loss:0.1743, loss-lb:0.1027, loss-ulb:0.0358, weight:2.00, lr:0.0007
[11:33:52.173] iteration:11222  t-loss:0.1461, loss-lb:0.0859, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:33:52.366] iteration:11223  t-loss:0.1298, loss-lb:0.0790, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:33:52.560] iteration:11224  t-loss:0.1450, loss-lb:0.0928, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:33:52.752] iteration:11225  t-loss:0.1514, loss-lb:0.0902, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:33:52.945] iteration:11226  t-loss:0.1519, loss-lb:0.0834, loss-ulb:0.0342, weight:2.00, lr:0.0007
[11:33:53.138] iteration:11227  t-loss:0.1348, loss-lb:0.0791, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:33:53.331] iteration:11228  t-loss:0.1404, loss-lb:0.0815, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:33:53.524] iteration:11229  t-loss:0.1828, loss-lb:0.0909, loss-ulb:0.0459, weight:2.00, lr:0.0007
[11:33:53.716] iteration:11230  t-loss:0.1393, loss-lb:0.0876, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:33:53.909] iteration:11231  t-loss:0.1463, loss-lb:0.0891, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:33:54.101] iteration:11232  t-loss:0.1410, loss-lb:0.0903, loss-ulb:0.0253, weight:2.00, lr:0.0007
[11:33:54.293] iteration:11233  t-loss:0.1539, loss-lb:0.0867, loss-ulb:0.0336, weight:2.00, lr:0.0007
[11:33:54.485] iteration:11234  t-loss:0.1416, loss-lb:0.0815, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:33:54.678] iteration:11235  t-loss:0.1342, loss-lb:0.0843, loss-ulb:0.0250, weight:2.00, lr:0.0007
[11:33:54.871] iteration:11236  t-loss:0.1445, loss-lb:0.0861, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:33:55.063] iteration:11237  t-loss:0.1472, loss-lb:0.0942, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:33:55.255] iteration:11238  t-loss:0.1622, loss-lb:0.0899, loss-ulb:0.0362, weight:2.00, lr:0.0007
[11:33:55.447] iteration:11239  t-loss:0.1598, loss-lb:0.0968, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:33:55.638] iteration:11240  t-loss:0.1495, loss-lb:0.0815, loss-ulb:0.0340, weight:2.00, lr:0.0007
[11:33:55.831] iteration:11241  t-loss:0.1711, loss-lb:0.1175, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:33:56.024] iteration:11242  t-loss:0.1487, loss-lb:0.0852, loss-ulb:0.0318, weight:2.00, lr:0.0007
[11:33:56.216] iteration:11243  t-loss:0.1606, loss-lb:0.0932, loss-ulb:0.0337, weight:2.00, lr:0.0007
[11:33:56.409] iteration:11244  t-loss:0.1498, loss-lb:0.0911, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:33:56.602] iteration:11245  t-loss:0.1530, loss-lb:0.0957, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:33:56.794] iteration:11246  t-loss:0.1692, loss-lb:0.0845, loss-ulb:0.0424, weight:2.00, lr:0.0007
[11:33:56.986] iteration:11247  t-loss:0.1289, loss-lb:0.0775, loss-ulb:0.0257, weight:2.00, lr:0.0007
[11:33:57.178] iteration:11248  t-loss:0.1346, loss-lb:0.0838, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:33:57.370] iteration:11249  t-loss:0.1424, loss-lb:0.0874, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:33:57.564] iteration:11250  t-loss:0.1533, loss-lb:0.0872, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:33:57.756] iteration:11251  t-loss:0.1449, loss-lb:0.0859, loss-ulb:0.0295, weight:2.00, lr:0.0007
[11:33:57.948] iteration:11252  t-loss:0.1505, loss-lb:0.1003, loss-ulb:0.0251, weight:2.00, lr:0.0007
[11:33:58.141] iteration:11253  t-loss:0.1405, loss-lb:0.0821, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:33:58.333] iteration:11254  t-loss:0.1517, loss-lb:0.0888, loss-ulb:0.0314, weight:2.00, lr:0.0007
[11:33:58.525] iteration:11255  t-loss:0.1416, loss-lb:0.0856, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:33:58.718] iteration:11256  t-loss:0.1691, loss-lb:0.0845, loss-ulb:0.0423, weight:2.00, lr:0.0007
[11:33:58.912] iteration:11257  t-loss:0.1469, loss-lb:0.0914, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:33:59.105] iteration:11258  t-loss:0.1277, loss-lb:0.0769, loss-ulb:0.0254, weight:2.00, lr:0.0007
[11:33:59.297] iteration:11259  t-loss:0.1429, loss-lb:0.0967, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:33:59.490] iteration:11260  t-loss:0.1412, loss-lb:0.0888, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:33:59.683] iteration:11261  t-loss:0.1604, loss-lb:0.0964, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:33:59.874] iteration:11262  t-loss:0.1346, loss-lb:0.0855, loss-ulb:0.0246, weight:2.00, lr:0.0007
[11:34:00.067] iteration:11263  t-loss:0.1356, loss-lb:0.0838, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:34:00.259] iteration:11264  t-loss:0.1467, loss-lb:0.0933, loss-ulb:0.0267, weight:2.00, lr:0.0007
[11:34:00.451] iteration:11265  t-loss:0.2084, loss-lb:0.0854, loss-ulb:0.0615, weight:2.00, lr:0.0007
[11:34:00.641] iteration:11266  t-loss:0.1784, loss-lb:0.0939, loss-ulb:0.0423, weight:2.00, lr:0.0007
[11:34:00.832] iteration:11267  t-loss:0.1455, loss-lb:0.0804, loss-ulb:0.0326, weight:2.00, lr:0.0007
[11:34:01.023] iteration:11268  t-loss:0.1812, loss-lb:0.0902, loss-ulb:0.0455, weight:2.00, lr:0.0007
[11:34:01.213] iteration:11269  t-loss:0.1350, loss-lb:0.0819, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:34:01.404] iteration:11270  t-loss:0.1431, loss-lb:0.0858, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:34:13.490]  <<Test>> - Ep:114  - mean_dice/mean_h95 - S:90.06/1.25, Best-S:90.28, T:89.78/1.92, Best-T:90.48
[11:34:13.490]           - AvgLoss(lb/ulb/all):0.0891/0.0317/0.1513
[11:34:14.022] iteration:11271  t-loss:0.1531, loss-lb:0.0933, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:34:14.221] iteration:11272  t-loss:0.1428, loss-lb:0.0821, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:34:14.415] iteration:11273  t-loss:0.1548, loss-lb:0.0902, loss-ulb:0.0323, weight:2.00, lr:0.0007
[11:34:14.608] iteration:11274  t-loss:0.1568, loss-lb:0.0898, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:34:14.801] iteration:11275  t-loss:0.1452, loss-lb:0.0832, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:34:14.994] iteration:11276  t-loss:0.1508, loss-lb:0.0832, loss-ulb:0.0338, weight:2.00, lr:0.0007
[11:34:15.186] iteration:11277  t-loss:0.1790, loss-lb:0.0879, loss-ulb:0.0455, weight:2.00, lr:0.0007
[11:34:15.381] iteration:11278  t-loss:0.1512, loss-lb:0.0954, loss-ulb:0.0279, weight:2.00, lr:0.0007
[11:34:15.575] iteration:11279  t-loss:0.2443, loss-lb:0.0730, loss-ulb:0.0857, weight:2.00, lr:0.0007
[11:34:15.768] iteration:11280  t-loss:0.1476, loss-lb:0.0895, loss-ulb:0.0290, weight:2.00, lr:0.0007
[11:34:15.968] iteration:11281  t-loss:0.1371, loss-lb:0.0831, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:34:16.175] iteration:11282  t-loss:0.2027, loss-lb:0.0808, loss-ulb:0.0609, weight:2.00, lr:0.0007
[11:34:16.374] iteration:11283  t-loss:0.1655, loss-lb:0.0826, loss-ulb:0.0415, weight:2.00, lr:0.0007
[11:34:16.569] iteration:11284  t-loss:0.2077, loss-lb:0.0867, loss-ulb:0.0605, weight:2.00, lr:0.0007
[11:34:16.768] iteration:11285  t-loss:0.2125, loss-lb:0.0835, loss-ulb:0.0645, weight:2.00, lr:0.0007
[11:34:16.961] iteration:11286  t-loss:0.1423, loss-lb:0.0857, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:34:17.155] iteration:11287  t-loss:0.1560, loss-lb:0.1005, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:34:17.352] iteration:11288  t-loss:0.1581, loss-lb:0.0977, loss-ulb:0.0302, weight:2.00, lr:0.0007
[11:34:17.547] iteration:11289  t-loss:0.1454, loss-lb:0.0909, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:34:17.740] iteration:11290  t-loss:0.1460, loss-lb:0.0852, loss-ulb:0.0304, weight:2.00, lr:0.0007
[11:34:17.933] iteration:11291  t-loss:0.1417, loss-lb:0.0849, loss-ulb:0.0284, weight:2.00, lr:0.0007
[11:34:18.126] iteration:11292  t-loss:0.2192, loss-lb:0.0873, loss-ulb:0.0659, weight:2.00, lr:0.0007
[11:34:18.319] iteration:11293  t-loss:0.1415, loss-lb:0.0844, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:34:18.512] iteration:11294  t-loss:0.1365, loss-lb:0.0824, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:34:18.705] iteration:11295  t-loss:0.1442, loss-lb:0.0867, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:34:18.897] iteration:11296  t-loss:0.1490, loss-lb:0.0898, loss-ulb:0.0296, weight:2.00, lr:0.0007
[11:34:19.090] iteration:11297  t-loss:0.1517, loss-lb:0.0831, loss-ulb:0.0343, weight:2.00, lr:0.0007
[11:34:19.284] iteration:11298  t-loss:0.1443, loss-lb:0.0827, loss-ulb:0.0308, weight:2.00, lr:0.0007
[11:34:19.476] iteration:11299  t-loss:0.1452, loss-lb:0.0840, loss-ulb:0.0306, weight:2.00, lr:0.0007
[11:34:19.668] iteration:11300  t-loss:0.1290, loss-lb:0.0803, loss-ulb:0.0244, weight:2.00, lr:0.0007
[11:34:19.862] iteration:11301  t-loss:0.1476, loss-lb:0.0845, loss-ulb:0.0316, weight:2.00, lr:0.0007
[11:34:20.056] iteration:11302  t-loss:0.1376, loss-lb:0.0812, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:34:20.250] iteration:11303  t-loss:0.1508, loss-lb:0.0827, loss-ulb:0.0341, weight:2.00, lr:0.0007
[11:34:20.442] iteration:11304  t-loss:0.1441, loss-lb:0.0904, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:34:20.636] iteration:11305  t-loss:0.1302, loss-lb:0.0771, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:34:20.829] iteration:11306  t-loss:0.1786, loss-lb:0.0942, loss-ulb:0.0422, weight:2.00, lr:0.0007
[11:34:21.022] iteration:11307  t-loss:0.1651, loss-lb:0.0805, loss-ulb:0.0423, weight:2.00, lr:0.0007
[11:34:21.215] iteration:11308  t-loss:0.2067, loss-lb:0.0888, loss-ulb:0.0589, weight:2.00, lr:0.0007
[11:34:21.408] iteration:11309  t-loss:0.1408, loss-lb:0.0880, loss-ulb:0.0264, weight:2.00, lr:0.0007
[11:34:21.599] iteration:11310  t-loss:0.1464, loss-lb:0.0871, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:34:21.791] iteration:11311  t-loss:0.1481, loss-lb:0.0827, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:34:21.984] iteration:11312  t-loss:0.1390, loss-lb:0.0865, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:34:22.177] iteration:11313  t-loss:0.1310, loss-lb:0.0884, loss-ulb:0.0213, weight:2.00, lr:0.0007
[11:34:22.369] iteration:11314  t-loss:0.1339, loss-lb:0.0866, loss-ulb:0.0236, weight:2.00, lr:0.0007
[11:34:22.561] iteration:11315  t-loss:0.1418, loss-lb:0.0836, loss-ulb:0.0291, weight:2.00, lr:0.0007
[11:34:22.754] iteration:11316  t-loss:0.1425, loss-lb:0.0804, loss-ulb:0.0310, weight:2.00, lr:0.0007
[11:34:22.950] iteration:11317  t-loss:0.1302, loss-lb:0.0771, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:34:23.144] iteration:11318  t-loss:0.1331, loss-lb:0.0758, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:34:23.337] iteration:11319  t-loss:0.1418, loss-lb:0.0865, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:34:23.531] iteration:11320  t-loss:0.1420, loss-lb:0.0889, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:34:23.723] iteration:11321  t-loss:0.1350, loss-lb:0.0811, loss-ulb:0.0269, weight:2.00, lr:0.0007
[11:34:23.916] iteration:11322  t-loss:0.1269, loss-lb:0.0801, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:34:24.108] iteration:11323  t-loss:0.1365, loss-lb:0.0890, loss-ulb:0.0238, weight:2.00, lr:0.0007
[11:34:24.302] iteration:11324  t-loss:0.1771, loss-lb:0.0918, loss-ulb:0.0426, weight:2.00, lr:0.0007
[11:34:24.495] iteration:11325  t-loss:0.1311, loss-lb:0.0789, loss-ulb:0.0261, weight:2.00, lr:0.0007
[11:34:24.688] iteration:11326  t-loss:0.1379, loss-lb:0.0921, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:34:24.881] iteration:11327  t-loss:0.1656, loss-lb:0.0887, loss-ulb:0.0384, weight:2.00, lr:0.0007
[11:34:25.074] iteration:11328  t-loss:0.1675, loss-lb:0.0787, loss-ulb:0.0444, weight:2.00, lr:0.0007
[11:34:25.266] iteration:11329  t-loss:0.1435, loss-lb:0.0978, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:34:25.458] iteration:11330  t-loss:0.1424, loss-lb:0.0965, loss-ulb:0.0230, weight:2.00, lr:0.0007
[11:34:25.650] iteration:11331  t-loss:0.1956, loss-lb:0.0759, loss-ulb:0.0599, weight:2.00, lr:0.0007
[11:34:25.843] iteration:11332  t-loss:0.1632, loss-lb:0.1027, loss-ulb:0.0303, weight:2.00, lr:0.0007
[11:34:26.035] iteration:11333  t-loss:0.1361, loss-lb:0.0866, loss-ulb:0.0248, weight:2.00, lr:0.0007
[11:34:26.228] iteration:11334  t-loss:0.1409, loss-lb:0.0837, loss-ulb:0.0286, weight:2.00, lr:0.0007
[11:34:26.420] iteration:11335  t-loss:0.1790, loss-lb:0.0895, loss-ulb:0.0448, weight:2.00, lr:0.0007
[11:34:26.613] iteration:11336  t-loss:0.1408, loss-lb:0.0878, loss-ulb:0.0265, weight:2.00, lr:0.0007
[11:34:26.806] iteration:11337  t-loss:0.1370, loss-lb:0.0838, loss-ulb:0.0266, weight:2.00, lr:0.0007
[11:34:26.998] iteration:11338  t-loss:0.1384, loss-lb:0.0811, loss-ulb:0.0287, weight:2.00, lr:0.0007
[11:34:27.190] iteration:11339  t-loss:0.1438, loss-lb:0.0844, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:34:27.383] iteration:11340  t-loss:0.1345, loss-lb:0.0797, loss-ulb:0.0274, weight:2.00, lr:0.0007
[11:34:27.575] iteration:11341  t-loss:0.1538, loss-lb:0.0928, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:34:27.767] iteration:11342  t-loss:0.1864, loss-lb:0.0964, loss-ulb:0.0450, weight:2.00, lr:0.0007
[11:34:27.960] iteration:11343  t-loss:0.1457, loss-lb:0.0856, loss-ulb:0.0301, weight:2.00, lr:0.0007
[11:34:28.155] iteration:11344  t-loss:0.1429, loss-lb:0.0835, loss-ulb:0.0297, weight:2.00, lr:0.0007
[11:34:28.348] iteration:11345  t-loss:0.1450, loss-lb:0.0811, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:34:28.540] iteration:11346  t-loss:0.1481, loss-lb:0.0934, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:34:28.733] iteration:11347  t-loss:0.1347, loss-lb:0.0823, loss-ulb:0.0262, weight:2.00, lr:0.0007
[11:34:28.926] iteration:11348  t-loss:0.1409, loss-lb:0.0930, loss-ulb:0.0239, weight:2.00, lr:0.0007
[11:34:29.117] iteration:11349  t-loss:0.1518, loss-lb:0.0964, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:34:29.309] iteration:11350  t-loss:0.1314, loss-lb:0.0779, loss-ulb:0.0268, weight:2.00, lr:0.0007
[11:34:29.503] iteration:11351  t-loss:0.1473, loss-lb:0.0829, loss-ulb:0.0322, weight:2.00, lr:0.0007
[11:34:29.696] iteration:11352  t-loss:0.1508, loss-lb:0.0947, loss-ulb:0.0281, weight:2.00, lr:0.0007
[11:34:29.888] iteration:11353  t-loss:0.1392, loss-lb:0.0833, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:34:30.082] iteration:11354  t-loss:0.1648, loss-lb:0.0774, loss-ulb:0.0437, weight:2.00, lr:0.0007
[11:34:30.275] iteration:11355  t-loss:0.1378, loss-lb:0.0880, loss-ulb:0.0249, weight:2.00, lr:0.0007
[11:34:30.467] iteration:11356  t-loss:0.1272, loss-lb:0.0810, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:34:30.660] iteration:11357  t-loss:0.1389, loss-lb:0.0926, loss-ulb:0.0231, weight:2.00, lr:0.0007
[11:34:30.853] iteration:11358  t-loss:0.1452, loss-lb:0.0790, loss-ulb:0.0331, weight:2.00, lr:0.0007
[11:34:31.046] iteration:11359  t-loss:0.1337, loss-lb:0.0869, loss-ulb:0.0234, weight:2.00, lr:0.0007
[11:34:31.238] iteration:11360  t-loss:0.1569, loss-lb:0.0928, loss-ulb:0.0320, weight:2.00, lr:0.0007
[11:34:31.430] iteration:11361  t-loss:0.1305, loss-lb:0.0814, loss-ulb:0.0245, weight:2.00, lr:0.0007
[11:34:31.623] iteration:11362  t-loss:0.1510, loss-lb:0.0857, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:34:31.814] iteration:11363  t-loss:0.1483, loss-lb:0.0829, loss-ulb:0.0327, weight:2.00, lr:0.0007
[11:34:32.005] iteration:11364  t-loss:0.1598, loss-lb:0.0879, loss-ulb:0.0359, weight:2.00, lr:0.0007
[11:34:32.196] iteration:11365  t-loss:0.1310, loss-lb:0.0853, loss-ulb:0.0229, weight:2.00, lr:0.0007
[11:34:32.387] iteration:11366  t-loss:0.2121, loss-lb:0.0849, loss-ulb:0.0636, weight:2.00, lr:0.0007
[11:34:32.578] iteration:11367  t-loss:0.1359, loss-lb:0.0841, loss-ulb:0.0259, weight:2.00, lr:0.0007
[11:34:32.769] iteration:11368  t-loss:0.1549, loss-lb:0.0861, loss-ulb:0.0344, weight:2.00, lr:0.0007
[11:34:33.370] iteration:11369  t-loss:0.1396, loss-lb:0.0870, loss-ulb:0.0263, weight:2.00, lr:0.0007
[11:34:33.567] iteration:11370  t-loss:0.1984, loss-lb:0.0918, loss-ulb:0.0533, weight:2.00, lr:0.0007
[11:34:33.760] iteration:11371  t-loss:0.1333, loss-lb:0.0773, loss-ulb:0.0280, weight:2.00, lr:0.0007
[11:34:33.953] iteration:11372  t-loss:0.1538, loss-lb:0.0908, loss-ulb:0.0315, weight:2.00, lr:0.0007
[11:34:34.146] iteration:11373  t-loss:0.2004, loss-lb:0.0928, loss-ulb:0.0538, weight:2.00, lr:0.0007
[11:34:34.340] iteration:11374  t-loss:0.1790, loss-lb:0.0837, loss-ulb:0.0477, weight:2.00, lr:0.0007
[11:34:34.533] iteration:11375  t-loss:0.1658, loss-lb:0.0916, loss-ulb:0.0371, weight:2.00, lr:0.0007
[11:34:34.726] iteration:11376  t-loss:0.1593, loss-lb:0.0925, loss-ulb:0.0334, weight:2.00, lr:0.0007
[11:34:34.918] iteration:11377  t-loss:0.1263, loss-lb:0.0798, loss-ulb:0.0232, weight:2.00, lr:0.0007
[11:34:35.111] iteration:11378  t-loss:0.1431, loss-lb:0.0809, loss-ulb:0.0311, weight:2.00, lr:0.0007
[11:34:35.304] iteration:11379  t-loss:0.1464, loss-lb:0.0768, loss-ulb:0.0348, weight:2.00, lr:0.0007
[11:34:35.497] iteration:11380  t-loss:0.1457, loss-lb:0.0831, loss-ulb:0.0313, weight:2.00, lr:0.0007
[11:34:35.690] iteration:11381  t-loss:0.1358, loss-lb:0.0915, loss-ulb:0.0222, weight:2.00, lr:0.0007
[11:34:35.882] iteration:11382  t-loss:0.1482, loss-lb:0.0818, loss-ulb:0.0332, weight:2.00, lr:0.0007
[11:34:36.075] iteration:11383  t-loss:0.1878, loss-lb:0.1114, loss-ulb:0.0382, weight:2.00, lr:0.0007
[11:34:36.268] iteration:11384  t-loss:0.1497, loss-lb:0.1014, loss-ulb:0.0242, weight:2.00, lr:0.0007
[11:34:36.460] iteration:11385  t-loss:0.1570, loss-lb:0.0830, loss-ulb:0.0370, weight:2.00, lr:0.0007
[11:34:36.653] iteration:11386  t-loss:0.1413, loss-lb:0.0874, loss-ulb:0.0270, weight:2.00, lr:0.0007
[11:34:36.845] iteration:11387  t-loss:0.1515, loss-lb:0.0918, loss-ulb:0.0298, weight:2.00, lr:0.0007
[11:34:37.038] iteration:11388  t-loss:0.1402, loss-lb:0.0857, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:34:37.231] iteration:11389  t-loss:0.1396, loss-lb:0.0843, loss-ulb:0.0277, weight:2.00, lr:0.0007
[11:34:37.424] iteration:11390  t-loss:0.1936, loss-lb:0.0890, loss-ulb:0.0523, weight:2.00, lr:0.0007
[11:34:37.619] iteration:11391  t-loss:0.1855, loss-lb:0.0856, loss-ulb:0.0500, weight:2.00, lr:0.0007
[11:34:37.811] iteration:11392  t-loss:0.1501, loss-lb:0.0824, loss-ulb:0.0339, weight:2.00, lr:0.0007
[11:34:38.004] iteration:11393  t-loss:0.1544, loss-lb:0.0879, loss-ulb:0.0333, weight:2.00, lr:0.0007
[11:34:38.197] iteration:11394  t-loss:0.1590, loss-lb:0.0886, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:34:38.390] iteration:11395  t-loss:0.1434, loss-lb:0.0837, loss-ulb:0.0299, weight:2.00, lr:0.0007
[11:34:38.583] iteration:11396  t-loss:0.1848, loss-lb:0.0935, loss-ulb:0.0456, weight:2.00, lr:0.0007
[11:34:38.776] iteration:11397  t-loss:0.1546, loss-lb:0.0842, loss-ulb:0.0352, weight:2.00, lr:0.0007
[11:34:38.968] iteration:11398  t-loss:0.1430, loss-lb:0.0880, loss-ulb:0.0275, weight:2.00, lr:0.0007
[11:34:39.161] iteration:11399  t-loss:0.1405, loss-lb:0.0838, loss-ulb:0.0283, weight:2.00, lr:0.0007
[11:34:39.353] iteration:11400  t-loss:0.1500, loss-lb:0.0831, loss-ulb:0.0335, weight:2.00, lr:0.0007
[11:34:39.548] iteration:11401  t-loss:0.1418, loss-lb:0.0834, loss-ulb:0.0292, weight:2.00, lr:0.0007
[11:34:39.741] iteration:11402  t-loss:0.1339, loss-lb:0.0794, loss-ulb:0.0273, weight:2.00, lr:0.0007
[11:34:39.934] iteration:11403  t-loss:0.1397, loss-lb:0.0834, loss-ulb:0.0282, weight:2.00, lr:0.0007
[11:34:40.126] iteration:11404  t-loss:0.1535, loss-lb:0.0946, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:34:40.319] iteration:11405  t-loss:0.1473, loss-lb:0.0873, loss-ulb:0.0300, weight:2.00, lr:0.0007
[11:34:40.512] iteration:11406  t-loss:0.1490, loss-lb:0.0865, loss-ulb:0.0312, weight:2.00, lr:0.0007
[11:34:40.705] iteration:11407  t-loss:0.1458, loss-lb:0.0914, loss-ulb:0.0272, weight:2.00, lr:0.0007
[11:34:40.897] iteration:11408  t-loss:0.1612, loss-lb:0.1057, loss-ulb:0.0278, weight:2.00, lr:0.0007
[11:34:41.090] iteration:11409  t-loss:0.1476, loss-lb:0.0866, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:34:41.282] iteration:11410  t-loss:0.1475, loss-lb:0.0887, loss-ulb:0.0294, weight:2.00, lr:0.0007
[11:34:41.477] iteration:11411  t-loss:0.1396, loss-lb:0.0785, loss-ulb:0.0305, weight:2.00, lr:0.0007
[11:34:41.671] iteration:11412  t-loss:0.1398, loss-lb:0.0847, loss-ulb:0.0276, weight:2.00, lr:0.0007
[11:34:41.868] iteration:11413  t-loss:0.1485, loss-lb:0.0885, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:34:42.062] iteration:11414  t-loss:0.1971, loss-lb:0.0835, loss-ulb:0.0568, weight:2.00, lr:0.0006
[11:34:42.257] iteration:11415  t-loss:0.1423, loss-lb:0.0871, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:34:42.450] iteration:11416  t-loss:0.2472, loss-lb:0.1148, loss-ulb:0.0662, weight:2.00, lr:0.0006
[11:34:42.642] iteration:11417  t-loss:0.1537, loss-lb:0.0934, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:34:42.835] iteration:11418  t-loss:0.1248, loss-lb:0.0783, loss-ulb:0.0233, weight:2.00, lr:0.0006
[11:34:43.026] iteration:11419  t-loss:0.1477, loss-lb:0.0868, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:34:43.218] iteration:11420  t-loss:0.1473, loss-lb:0.0897, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:34:43.411] iteration:11421  t-loss:0.1398, loss-lb:0.0815, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:34:43.604] iteration:11422  t-loss:0.1456, loss-lb:0.0846, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:34:43.797] iteration:11423  t-loss:0.1470, loss-lb:0.0907, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:34:43.990] iteration:11424  t-loss:0.2571, loss-lb:0.0918, loss-ulb:0.0826, weight:2.00, lr:0.0006
[11:34:44.182] iteration:11425  t-loss:0.1437, loss-lb:0.0872, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:34:44.378] iteration:11426  t-loss:0.1352, loss-lb:0.0833, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:34:44.570] iteration:11427  t-loss:0.1552, loss-lb:0.0853, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:34:44.758] iteration:11428  t-loss:0.1454, loss-lb:0.0910, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:34:44.955] iteration:11429  t-loss:0.1295, loss-lb:0.0787, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:34:45.147] iteration:11430  t-loss:0.1407, loss-lb:0.0833, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:34:45.337] iteration:11431  t-loss:0.1398, loss-lb:0.0827, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:34:45.528] iteration:11432  t-loss:0.1540, loss-lb:0.0917, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:34:45.721] iteration:11433  t-loss:0.1711, loss-lb:0.0825, loss-ulb:0.0443, weight:2.00, lr:0.0006
[11:34:45.912] iteration:11434  t-loss:0.1438, loss-lb:0.0865, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:34:46.105] iteration:11435  t-loss:0.1642, loss-lb:0.0986, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:34:46.297] iteration:11436  t-loss:0.1264, loss-lb:0.0804, loss-ulb:0.0230, weight:2.00, lr:0.0006
[11:34:46.489] iteration:11437  t-loss:0.1594, loss-lb:0.0856, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:34:46.682] iteration:11438  t-loss:0.1560, loss-lb:0.0976, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:34:46.875] iteration:11439  t-loss:0.1365, loss-lb:0.0832, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:34:47.066] iteration:11440  t-loss:0.1527, loss-lb:0.0930, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:34:47.258] iteration:11441  t-loss:0.1607, loss-lb:0.1003, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:34:47.450] iteration:11442  t-loss:0.1372, loss-lb:0.0816, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:34:47.642] iteration:11443  t-loss:0.1412, loss-lb:0.0829, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:34:47.834] iteration:11444  t-loss:0.1397, loss-lb:0.0919, loss-ulb:0.0239, weight:2.00, lr:0.0006
[11:34:48.027] iteration:11445  t-loss:0.2187, loss-lb:0.0857, loss-ulb:0.0665, weight:2.00, lr:0.0006
[11:34:48.218] iteration:11446  t-loss:0.1507, loss-lb:0.0845, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:34:48.410] iteration:11447  t-loss:0.1533, loss-lb:0.0844, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:34:48.602] iteration:11448  t-loss:0.1347, loss-lb:0.0807, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:34:48.807] iteration:11449  t-loss:0.1477, loss-lb:0.0846, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:34:49.002] iteration:11450  t-loss:0.1558, loss-lb:0.0902, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:34:49.196] iteration:11451  t-loss:0.1370, loss-lb:0.0853, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:34:49.388] iteration:11452  t-loss:0.1409, loss-lb:0.0806, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:34:49.581] iteration:11453  t-loss:0.1484, loss-lb:0.0851, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:34:49.772] iteration:11454  t-loss:0.1347, loss-lb:0.0838, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:34:49.964] iteration:11455  t-loss:0.2672, loss-lb:0.0938, loss-ulb:0.0867, weight:2.00, lr:0.0006
[11:34:50.155] iteration:11456  t-loss:0.1345, loss-lb:0.0799, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:34:50.346] iteration:11457  t-loss:0.1519, loss-lb:0.0860, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:34:50.538] iteration:11458  t-loss:0.1460, loss-lb:0.0886, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:34:50.729] iteration:11459  t-loss:0.2478, loss-lb:0.0962, loss-ulb:0.0758, weight:2.00, lr:0.0006
[11:34:50.919] iteration:11460  t-loss:0.1762, loss-lb:0.0907, loss-ulb:0.0428, weight:2.00, lr:0.0006
[11:34:51.108] iteration:11461  t-loss:0.2017, loss-lb:0.1001, loss-ulb:0.0508, weight:2.00, lr:0.0006
[11:34:51.298] iteration:11462  t-loss:0.1677, loss-lb:0.0856, loss-ulb:0.0411, weight:2.00, lr:0.0006
[11:34:51.487] iteration:11463  t-loss:0.1470, loss-lb:0.0925, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:34:51.677] iteration:11464  t-loss:0.1529, loss-lb:0.0870, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:34:51.867] iteration:11465  t-loss:0.1339, loss-lb:0.0801, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:34:52.056] iteration:11466  t-loss:0.2019, loss-lb:0.1173, loss-ulb:0.0423, weight:2.00, lr:0.0006
[11:35:04.931]  <<Test>> - Ep:116  - mean_dice/mean_h95 - S:89.09/1.38, Best-S:90.28, T:89.96/1.32, Best-T:90.48
[11:35:04.931]           - AvgLoss(lb/ulb/all):0.0878/0.0377/0.1641
[11:35:05.460] iteration:11467  t-loss:0.1526, loss-lb:0.0876, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:35:05.656] iteration:11468  t-loss:0.1525, loss-lb:0.0836, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:35:05.851] iteration:11469  t-loss:0.1374, loss-lb:0.0811, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:35:06.043] iteration:11470  t-loss:0.1487, loss-lb:0.0887, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:35:06.235] iteration:11471  t-loss:0.1562, loss-lb:0.0856, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:35:06.429] iteration:11472  t-loss:0.1442, loss-lb:0.0906, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:35:06.621] iteration:11473  t-loss:0.1517, loss-lb:0.0930, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:35:06.813] iteration:11474  t-loss:0.1766, loss-lb:0.0961, loss-ulb:0.0403, weight:2.00, lr:0.0006
[11:35:07.006] iteration:11475  t-loss:0.1341, loss-lb:0.0787, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:35:07.199] iteration:11476  t-loss:0.1649, loss-lb:0.0841, loss-ulb:0.0404, weight:2.00, lr:0.0006
[11:35:07.393] iteration:11477  t-loss:0.1897, loss-lb:0.0861, loss-ulb:0.0518, weight:2.00, lr:0.0006
[11:35:07.586] iteration:11478  t-loss:0.1423, loss-lb:0.0888, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:35:07.778] iteration:11479  t-loss:0.1822, loss-lb:0.0873, loss-ulb:0.0475, weight:2.00, lr:0.0006
[11:35:07.973] iteration:11480  t-loss:0.1483, loss-lb:0.0934, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:35:08.167] iteration:11481  t-loss:0.1556, loss-lb:0.0877, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:35:08.361] iteration:11482  t-loss:0.1469, loss-lb:0.0840, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:35:08.558] iteration:11483  t-loss:0.1683, loss-lb:0.0792, loss-ulb:0.0446, weight:2.00, lr:0.0006
[11:35:08.751] iteration:11484  t-loss:0.1425, loss-lb:0.0905, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:35:08.943] iteration:11485  t-loss:0.1423, loss-lb:0.0921, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:35:09.137] iteration:11486  t-loss:0.1450, loss-lb:0.0812, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:35:09.330] iteration:11487  t-loss:0.1566, loss-lb:0.0879, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:35:09.527] iteration:11488  t-loss:0.1530, loss-lb:0.0942, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:35:09.720] iteration:11489  t-loss:0.1514, loss-lb:0.0942, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:35:09.910] iteration:11490  t-loss:0.1664, loss-lb:0.0866, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:35:10.102] iteration:11491  t-loss:0.1383, loss-lb:0.0834, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:35:10.296] iteration:11492  t-loss:0.1720, loss-lb:0.0928, loss-ulb:0.0396, weight:2.00, lr:0.0006
[11:35:10.488] iteration:11493  t-loss:0.1454, loss-lb:0.0878, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:35:10.680] iteration:11494  t-loss:0.1586, loss-lb:0.1060, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:35:10.873] iteration:11495  t-loss:0.1506, loss-lb:0.0858, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:35:11.066] iteration:11496  t-loss:0.1573, loss-lb:0.0933, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:35:11.257] iteration:11497  t-loss:0.1407, loss-lb:0.0858, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:35:11.449] iteration:11498  t-loss:0.1348, loss-lb:0.0814, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:35:11.640] iteration:11499  t-loss:0.1378, loss-lb:0.0757, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:35:11.831] iteration:11500  t-loss:0.1425, loss-lb:0.0842, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:35:12.023] iteration:11501  t-loss:0.1402, loss-lb:0.0846, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:35:12.214] iteration:11502  t-loss:0.1703, loss-lb:0.0913, loss-ulb:0.0395, weight:2.00, lr:0.0006
[11:35:12.406] iteration:11503  t-loss:0.1591, loss-lb:0.0810, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:35:12.598] iteration:11504  t-loss:0.1468, loss-lb:0.0936, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:35:12.788] iteration:11505  t-loss:0.1597, loss-lb:0.0923, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:35:12.980] iteration:11506  t-loss:0.1389, loss-lb:0.0896, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:35:13.171] iteration:11507  t-loss:0.1615, loss-lb:0.0909, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:35:13.365] iteration:11508  t-loss:0.1678, loss-lb:0.1048, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:35:13.557] iteration:11509  t-loss:0.1367, loss-lb:0.0835, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:35:13.749] iteration:11510  t-loss:0.1757, loss-lb:0.0886, loss-ulb:0.0435, weight:2.00, lr:0.0006
[11:35:13.941] iteration:11511  t-loss:0.1346, loss-lb:0.0843, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:35:14.133] iteration:11512  t-loss:0.1381, loss-lb:0.0843, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:35:14.326] iteration:11513  t-loss:0.1411, loss-lb:0.0878, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:35:14.521] iteration:11514  t-loss:0.1762, loss-lb:0.0951, loss-ulb:0.0405, weight:2.00, lr:0.0006
[11:35:14.717] iteration:11515  t-loss:0.1553, loss-lb:0.0871, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:35:14.912] iteration:11516  t-loss:0.1482, loss-lb:0.0908, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:35:15.104] iteration:11517  t-loss:0.1726, loss-lb:0.0960, loss-ulb:0.0383, weight:2.00, lr:0.0006
[11:35:15.297] iteration:11518  t-loss:0.1715, loss-lb:0.1005, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:35:15.490] iteration:11519  t-loss:0.1773, loss-lb:0.0967, loss-ulb:0.0403, weight:2.00, lr:0.0006
[11:35:15.683] iteration:11520  t-loss:0.2303, loss-lb:0.0886, loss-ulb:0.0709, weight:2.00, lr:0.0006
[11:35:15.875] iteration:11521  t-loss:0.2422, loss-lb:0.0804, loss-ulb:0.0809, weight:2.00, lr:0.0006
[11:35:16.067] iteration:11522  t-loss:0.2103, loss-lb:0.0931, loss-ulb:0.0586, weight:2.00, lr:0.0006
[11:35:16.258] iteration:11523  t-loss:0.1891, loss-lb:0.0882, loss-ulb:0.0505, weight:2.00, lr:0.0006
[11:35:16.450] iteration:11524  t-loss:0.1914, loss-lb:0.1233, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:35:16.642] iteration:11525  t-loss:0.1376, loss-lb:0.0878, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:35:16.835] iteration:11526  t-loss:0.1526, loss-lb:0.0912, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:35:17.026] iteration:11527  t-loss:0.1584, loss-lb:0.0905, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:35:17.218] iteration:11528  t-loss:0.1438, loss-lb:0.0837, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:35:17.411] iteration:11529  t-loss:0.2070, loss-lb:0.0896, loss-ulb:0.0587, weight:2.00, lr:0.0006
[11:35:17.603] iteration:11530  t-loss:0.2031, loss-lb:0.0876, loss-ulb:0.0577, weight:2.00, lr:0.0006
[11:35:17.796] iteration:11531  t-loss:0.2464, loss-lb:0.0874, loss-ulb:0.0795, weight:2.00, lr:0.0006
[11:35:17.989] iteration:11532  t-loss:0.1542, loss-lb:0.0904, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:35:18.182] iteration:11533  t-loss:0.1667, loss-lb:0.1149, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:35:18.374] iteration:11534  t-loss:0.1658, loss-lb:0.1043, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:35:18.567] iteration:11535  t-loss:0.2123, loss-lb:0.0942, loss-ulb:0.0591, weight:2.00, lr:0.0006
[11:35:18.765] iteration:11536  t-loss:0.1621, loss-lb:0.1037, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:35:18.958] iteration:11537  t-loss:0.1513, loss-lb:0.0910, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:35:19.149] iteration:11538  t-loss:0.1476, loss-lb:0.0928, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:35:19.340] iteration:11539  t-loss:0.1847, loss-lb:0.1038, loss-ulb:0.0404, weight:2.00, lr:0.0006
[11:35:19.540] iteration:11540  t-loss:0.1504, loss-lb:0.0959, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:35:19.731] iteration:11541  t-loss:0.1990, loss-lb:0.0887, loss-ulb:0.0551, weight:2.00, lr:0.0006
[11:35:19.924] iteration:11542  t-loss:0.2021, loss-lb:0.1364, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:35:20.115] iteration:11543  t-loss:0.1827, loss-lb:0.0925, loss-ulb:0.0451, weight:2.00, lr:0.0006
[11:35:20.316] iteration:11544  t-loss:0.2168, loss-lb:0.1060, loss-ulb:0.0554, weight:2.00, lr:0.0006
[11:35:20.507] iteration:11545  t-loss:0.1518, loss-lb:0.0989, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:35:20.699] iteration:11546  t-loss:0.1857, loss-lb:0.1023, loss-ulb:0.0417, weight:2.00, lr:0.0006
[11:35:20.890] iteration:11547  t-loss:0.1584, loss-lb:0.0966, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:35:21.088] iteration:11548  t-loss:0.1559, loss-lb:0.0877, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:35:21.279] iteration:11549  t-loss:0.1967, loss-lb:0.0941, loss-ulb:0.0513, weight:2.00, lr:0.0006
[11:35:21.473] iteration:11550  t-loss:0.1645, loss-lb:0.0910, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:35:21.678] iteration:11551  t-loss:0.1546, loss-lb:0.0999, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:35:21.875] iteration:11552  t-loss:0.1540, loss-lb:0.0948, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:35:22.067] iteration:11553  t-loss:0.1475, loss-lb:0.0964, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:35:22.259] iteration:11554  t-loss:0.1412, loss-lb:0.0839, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:35:22.451] iteration:11555  t-loss:0.1833, loss-lb:0.1025, loss-ulb:0.0404, weight:2.00, lr:0.0006
[11:35:22.644] iteration:11556  t-loss:0.1708, loss-lb:0.0909, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:35:22.834] iteration:11557  t-loss:0.1437, loss-lb:0.0859, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:35:23.024] iteration:11558  t-loss:0.1489, loss-lb:0.0949, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:35:23.213] iteration:11559  t-loss:0.1683, loss-lb:0.1082, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:35:23.404] iteration:11560  t-loss:0.1570, loss-lb:0.0899, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:35:23.594] iteration:11561  t-loss:0.1605, loss-lb:0.1037, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:35:23.784] iteration:11562  t-loss:0.1462, loss-lb:0.0948, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:35:23.973] iteration:11563  t-loss:0.1627, loss-lb:0.0887, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:35:24.163] iteration:11564  t-loss:0.1536, loss-lb:0.0867, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:35:24.744] iteration:11565  t-loss:0.1343, loss-lb:0.0886, loss-ulb:0.0229, weight:2.00, lr:0.0006
[11:35:24.938] iteration:11566  t-loss:0.1482, loss-lb:0.0899, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:35:25.130] iteration:11567  t-loss:0.1364, loss-lb:0.0762, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:35:25.322] iteration:11568  t-loss:0.1799, loss-lb:0.0937, loss-ulb:0.0431, weight:2.00, lr:0.0006
[11:35:25.515] iteration:11569  t-loss:0.1359, loss-lb:0.0871, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:35:25.707] iteration:11570  t-loss:0.1434, loss-lb:0.0941, loss-ulb:0.0247, weight:2.00, lr:0.0006
[11:35:25.899] iteration:11571  t-loss:0.1371, loss-lb:0.0813, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:35:26.091] iteration:11572  t-loss:0.1680, loss-lb:0.0963, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:35:26.284] iteration:11573  t-loss:0.1383, loss-lb:0.0824, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:35:26.477] iteration:11574  t-loss:0.1459, loss-lb:0.0875, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:35:26.668] iteration:11575  t-loss:0.1408, loss-lb:0.0853, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:35:26.861] iteration:11576  t-loss:0.1478, loss-lb:0.0829, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:35:27.054] iteration:11577  t-loss:0.1831, loss-lb:0.0940, loss-ulb:0.0445, weight:2.00, lr:0.0006
[11:35:27.245] iteration:11578  t-loss:0.1502, loss-lb:0.0967, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:35:27.437] iteration:11579  t-loss:0.1536, loss-lb:0.0819, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:35:27.630] iteration:11580  t-loss:0.1598, loss-lb:0.0911, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:35:27.823] iteration:11581  t-loss:0.1437, loss-lb:0.0882, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:35:28.016] iteration:11582  t-loss:0.1645, loss-lb:0.1017, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:35:28.208] iteration:11583  t-loss:0.1395, loss-lb:0.0865, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:35:28.400] iteration:11584  t-loss:0.1897, loss-lb:0.0829, loss-ulb:0.0534, weight:2.00, lr:0.0006
[11:35:28.592] iteration:11585  t-loss:0.1499, loss-lb:0.0899, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:35:28.785] iteration:11586  t-loss:0.1808, loss-lb:0.0838, loss-ulb:0.0485, weight:2.00, lr:0.0006
[11:35:28.976] iteration:11587  t-loss:0.1493, loss-lb:0.0904, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:35:29.168] iteration:11588  t-loss:0.1531, loss-lb:0.0936, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:35:29.361] iteration:11589  t-loss:0.1604, loss-lb:0.0870, loss-ulb:0.0367, weight:2.00, lr:0.0006
[11:35:29.552] iteration:11590  t-loss:0.1448, loss-lb:0.0847, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:35:29.744] iteration:11591  t-loss:0.1512, loss-lb:0.0880, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:35:29.936] iteration:11592  t-loss:0.1653, loss-lb:0.1099, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:35:30.128] iteration:11593  t-loss:0.1588, loss-lb:0.0859, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:35:30.321] iteration:11594  t-loss:0.1927, loss-lb:0.0867, loss-ulb:0.0530, weight:2.00, lr:0.0006
[11:35:30.514] iteration:11595  t-loss:0.2059, loss-lb:0.0952, loss-ulb:0.0554, weight:2.00, lr:0.0006
[11:35:30.706] iteration:11596  t-loss:0.1577, loss-lb:0.0998, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:35:30.899] iteration:11597  t-loss:0.1593, loss-lb:0.0866, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:35:31.091] iteration:11598  t-loss:0.1381, loss-lb:0.0844, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:35:31.284] iteration:11599  t-loss:0.1531, loss-lb:0.0915, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:35:31.475] iteration:11600  t-loss:0.1387, loss-lb:0.0897, loss-ulb:0.0245, weight:2.00, lr:0.0006
[11:35:31.668] iteration:11601  t-loss:0.1380, loss-lb:0.0836, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:35:31.862] iteration:11602  t-loss:0.2309, loss-lb:0.0850, loss-ulb:0.0730, weight:2.00, lr:0.0006
[11:35:32.053] iteration:11603  t-loss:0.2132, loss-lb:0.0972, loss-ulb:0.0580, weight:2.00, lr:0.0006
[11:35:32.246] iteration:11604  t-loss:0.2196, loss-lb:0.0834, loss-ulb:0.0681, weight:2.00, lr:0.0006
[11:35:32.438] iteration:11605  t-loss:0.1516, loss-lb:0.0967, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:35:32.630] iteration:11606  t-loss:0.1795, loss-lb:0.0915, loss-ulb:0.0440, weight:2.00, lr:0.0006
[11:35:32.822] iteration:11607  t-loss:0.1476, loss-lb:0.0958, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:35:33.015] iteration:11608  t-loss:0.1444, loss-lb:0.0784, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:35:33.207] iteration:11609  t-loss:0.1531, loss-lb:0.0873, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:35:33.399] iteration:11610  t-loss:0.1615, loss-lb:0.0891, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:35:33.591] iteration:11611  t-loss:0.1361, loss-lb:0.0803, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:35:33.784] iteration:11612  t-loss:0.1379, loss-lb:0.0832, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:35:33.975] iteration:11613  t-loss:0.1597, loss-lb:0.0935, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:35:34.168] iteration:11614  t-loss:0.1480, loss-lb:0.0888, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:35:34.362] iteration:11615  t-loss:0.1651, loss-lb:0.0796, loss-ulb:0.0427, weight:2.00, lr:0.0006
[11:35:34.552] iteration:11616  t-loss:0.1367, loss-lb:0.0801, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:35:34.745] iteration:11617  t-loss:0.1340, loss-lb:0.0852, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:35:34.938] iteration:11618  t-loss:0.1361, loss-lb:0.0812, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:35:35.130] iteration:11619  t-loss:0.1303, loss-lb:0.0823, loss-ulb:0.0240, weight:2.00, lr:0.0006
[11:35:35.322] iteration:11620  t-loss:0.1549, loss-lb:0.0929, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:35:35.515] iteration:11621  t-loss:0.1743, loss-lb:0.0920, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:35:35.707] iteration:11622  t-loss:0.1479, loss-lb:0.0869, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:35:35.900] iteration:11623  t-loss:0.1495, loss-lb:0.0906, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:35:36.093] iteration:11624  t-loss:0.1481, loss-lb:0.0847, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:35:36.285] iteration:11625  t-loss:0.1450, loss-lb:0.0872, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:35:36.478] iteration:11626  t-loss:0.2754, loss-lb:0.0790, loss-ulb:0.0982, weight:2.00, lr:0.0006
[11:35:36.671] iteration:11627  t-loss:0.1338, loss-lb:0.0797, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:35:36.862] iteration:11628  t-loss:0.1383, loss-lb:0.0877, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:35:37.054] iteration:11629  t-loss:0.1468, loss-lb:0.0873, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:35:37.248] iteration:11630  t-loss:0.1589, loss-lb:0.1008, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:35:37.440] iteration:11631  t-loss:0.1557, loss-lb:0.0882, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:35:37.632] iteration:11632  t-loss:0.1762, loss-lb:0.0975, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:35:37.825] iteration:11633  t-loss:0.1459, loss-lb:0.0908, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:35:38.017] iteration:11634  t-loss:0.1405, loss-lb:0.0825, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:35:38.208] iteration:11635  t-loss:0.1426, loss-lb:0.0790, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:35:38.401] iteration:11636  t-loss:0.1661, loss-lb:0.1017, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:35:38.593] iteration:11637  t-loss:0.2094, loss-lb:0.0938, loss-ulb:0.0578, weight:2.00, lr:0.0006
[11:35:38.785] iteration:11638  t-loss:0.1447, loss-lb:0.0941, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:35:38.977] iteration:11639  t-loss:0.1412, loss-lb:0.0813, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:35:39.168] iteration:11640  t-loss:0.1473, loss-lb:0.0904, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:35:39.362] iteration:11641  t-loss:0.1410, loss-lb:0.0907, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:35:39.553] iteration:11642  t-loss:0.1480, loss-lb:0.0864, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:35:39.745] iteration:11643  t-loss:0.1360, loss-lb:0.0820, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:35:39.937] iteration:11644  t-loss:0.1562, loss-lb:0.0928, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:35:40.128] iteration:11645  t-loss:0.1424, loss-lb:0.0844, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:35:40.321] iteration:11646  t-loss:0.1811, loss-lb:0.1042, loss-ulb:0.0385, weight:2.00, lr:0.0006
[11:35:40.513] iteration:11647  t-loss:0.1497, loss-lb:0.0815, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:35:40.705] iteration:11648  t-loss:0.1390, loss-lb:0.0819, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:35:40.897] iteration:11649  t-loss:0.1450, loss-lb:0.0813, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:35:41.089] iteration:11650  t-loss:0.1351, loss-lb:0.0824, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:35:41.281] iteration:11651  t-loss:0.1802, loss-lb:0.0911, loss-ulb:0.0445, weight:2.00, lr:0.0006
[11:35:41.474] iteration:11652  t-loss:0.1426, loss-lb:0.0804, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:35:41.667] iteration:11653  t-loss:0.1483, loss-lb:0.0939, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:35:41.860] iteration:11654  t-loss:0.1784, loss-lb:0.0822, loss-ulb:0.0481, weight:2.00, lr:0.0006
[11:35:42.054] iteration:11655  t-loss:0.1632, loss-lb:0.1082, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:35:42.244] iteration:11656  t-loss:0.1354, loss-lb:0.0845, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:35:42.435] iteration:11657  t-loss:0.1370, loss-lb:0.0778, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:35:42.625] iteration:11658  t-loss:0.1873, loss-lb:0.1196, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:35:42.816] iteration:11659  t-loss:0.1606, loss-lb:0.0894, loss-ulb:0.0356, weight:2.00, lr:0.0006
[11:35:43.007] iteration:11660  t-loss:0.1536, loss-lb:0.0905, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:35:43.198] iteration:11661  t-loss:0.1342, loss-lb:0.0792, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:35:43.389] iteration:11662  t-loss:0.1459, loss-lb:0.0843, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:35:55.883]  <<Test>> - Ep:118  - mean_dice/mean_h95 - S:89.47/2.36, Best-S:90.28, T:89.72/1.41, Best-T:90.48
[11:35:55.883]           - AvgLoss(lb/ulb/all):0.0885/0.0320/0.1526
[11:35:56.414] iteration:11663  t-loss:0.1771, loss-lb:0.0872, loss-ulb:0.0449, weight:2.00, lr:0.0006
[11:35:56.612] iteration:11664  t-loss:0.1365, loss-lb:0.0780, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:35:56.805] iteration:11665  t-loss:0.1509, loss-lb:0.0818, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:35:56.999] iteration:11666  t-loss:0.2056, loss-lb:0.0970, loss-ulb:0.0543, weight:2.00, lr:0.0006
[11:35:57.192] iteration:11667  t-loss:0.1451, loss-lb:0.0874, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:35:57.385] iteration:11668  t-loss:0.1713, loss-lb:0.1047, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:35:57.578] iteration:11669  t-loss:0.1484, loss-lb:0.0933, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:35:57.771] iteration:11670  t-loss:0.1487, loss-lb:0.0881, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:35:57.964] iteration:11671  t-loss:0.1557, loss-lb:0.0839, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:35:58.157] iteration:11672  t-loss:0.1343, loss-lb:0.0851, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:35:58.351] iteration:11673  t-loss:0.2101, loss-lb:0.0900, loss-ulb:0.0600, weight:2.00, lr:0.0006
[11:35:58.545] iteration:11674  t-loss:0.1746, loss-lb:0.0911, loss-ulb:0.0417, weight:2.00, lr:0.0006
[11:35:58.739] iteration:11675  t-loss:0.1453, loss-lb:0.0863, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:35:58.932] iteration:11676  t-loss:0.1373, loss-lb:0.0788, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:35:59.124] iteration:11677  t-loss:0.1476, loss-lb:0.0814, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:35:59.318] iteration:11678  t-loss:0.2445, loss-lb:0.1005, loss-ulb:0.0720, weight:2.00, lr:0.0006
[11:35:59.512] iteration:11679  t-loss:0.1399, loss-lb:0.0838, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:35:59.705] iteration:11680  t-loss:0.1479, loss-lb:0.0916, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:35:59.898] iteration:11681  t-loss:0.1469, loss-lb:0.0936, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:36:00.091] iteration:11682  t-loss:0.1491, loss-lb:0.0857, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:36:00.284] iteration:11683  t-loss:0.1446, loss-lb:0.0892, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:36:00.478] iteration:11684  t-loss:0.1593, loss-lb:0.0994, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:36:00.671] iteration:11685  t-loss:0.1323, loss-lb:0.0827, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:36:00.863] iteration:11686  t-loss:0.1391, loss-lb:0.0798, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:36:01.056] iteration:11687  t-loss:0.1530, loss-lb:0.0866, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:36:01.249] iteration:11688  t-loss:0.1745, loss-lb:0.0929, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:36:01.442] iteration:11689  t-loss:0.1574, loss-lb:0.0929, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:36:01.634] iteration:11690  t-loss:0.1569, loss-lb:0.0902, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:36:01.828] iteration:11691  t-loss:0.1315, loss-lb:0.0794, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:36:02.021] iteration:11692  t-loss:0.1389, loss-lb:0.0796, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:36:02.214] iteration:11693  t-loss:0.1493, loss-lb:0.0869, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:36:02.406] iteration:11694  t-loss:0.1552, loss-lb:0.0984, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:36:02.599] iteration:11695  t-loss:0.1359, loss-lb:0.0788, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:36:02.792] iteration:11696  t-loss:0.1437, loss-lb:0.0834, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:36:02.984] iteration:11697  t-loss:0.1555, loss-lb:0.0945, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:36:03.176] iteration:11698  t-loss:0.1643, loss-lb:0.0931, loss-ulb:0.0356, weight:2.00, lr:0.0006
[11:36:03.368] iteration:11699  t-loss:0.1477, loss-lb:0.0864, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:36:03.561] iteration:11700  t-loss:0.1407, loss-lb:0.0878, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:36:03.753] iteration:11701  t-loss:0.1546, loss-lb:0.0916, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:36:03.947] iteration:11702  t-loss:0.2339, loss-lb:0.0861, loss-ulb:0.0739, weight:2.00, lr:0.0006
[11:36:04.140] iteration:11703  t-loss:0.1673, loss-lb:0.0923, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:36:04.332] iteration:11704  t-loss:0.1419, loss-lb:0.0857, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:36:04.524] iteration:11705  t-loss:0.1622, loss-lb:0.0892, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:36:04.716] iteration:11706  t-loss:0.1336, loss-lb:0.0857, loss-ulb:0.0239, weight:2.00, lr:0.0006
[11:36:04.910] iteration:11707  t-loss:0.1474, loss-lb:0.0831, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:36:05.102] iteration:11708  t-loss:0.1426, loss-lb:0.0793, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:36:05.294] iteration:11709  t-loss:0.1510, loss-lb:0.0825, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:36:05.487] iteration:11710  t-loss:0.1736, loss-lb:0.0836, loss-ulb:0.0450, weight:2.00, lr:0.0006
[11:36:05.680] iteration:11711  t-loss:0.1495, loss-lb:0.0840, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:36:05.872] iteration:11712  t-loss:0.1426, loss-lb:0.0830, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:36:06.066] iteration:11713  t-loss:0.1520, loss-lb:0.0830, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:36:06.257] iteration:11714  t-loss:0.1594, loss-lb:0.0943, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:36:06.450] iteration:11715  t-loss:0.1488, loss-lb:0.0965, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:36:06.643] iteration:11716  t-loss:0.1613, loss-lb:0.0962, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:36:06.836] iteration:11717  t-loss:0.1343, loss-lb:0.0891, loss-ulb:0.0226, weight:2.00, lr:0.0006
[11:36:07.029] iteration:11718  t-loss:0.1615, loss-lb:0.1071, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:36:07.222] iteration:11719  t-loss:0.1640, loss-lb:0.0971, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:36:07.413] iteration:11720  t-loss:0.1393, loss-lb:0.0853, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:36:07.604] iteration:11721  t-loss:0.1422, loss-lb:0.0893, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:36:07.796] iteration:11722  t-loss:0.1382, loss-lb:0.0870, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:36:07.988] iteration:11723  t-loss:0.1400, loss-lb:0.0835, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:36:08.180] iteration:11724  t-loss:0.1432, loss-lb:0.0844, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:36:08.372] iteration:11725  t-loss:0.1429, loss-lb:0.0875, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:36:08.565] iteration:11726  t-loss:0.1974, loss-lb:0.0881, loss-ulb:0.0546, weight:2.00, lr:0.0006
[11:36:08.757] iteration:11727  t-loss:0.1447, loss-lb:0.0925, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:36:08.949] iteration:11728  t-loss:0.1611, loss-lb:0.1009, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:36:09.141] iteration:11729  t-loss:0.2277, loss-lb:0.0813, loss-ulb:0.0732, weight:2.00, lr:0.0006
[11:36:09.334] iteration:11730  t-loss:0.1272, loss-lb:0.0808, loss-ulb:0.0232, weight:2.00, lr:0.0006
[11:36:09.527] iteration:11731  t-loss:0.1527, loss-lb:0.0952, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:36:09.718] iteration:11732  t-loss:0.1484, loss-lb:0.0903, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:36:09.912] iteration:11733  t-loss:0.1507, loss-lb:0.0950, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:36:10.104] iteration:11734  t-loss:0.1588, loss-lb:0.0909, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:36:10.295] iteration:11735  t-loss:0.1399, loss-lb:0.0804, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:36:10.489] iteration:11736  t-loss:0.1561, loss-lb:0.0810, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:36:10.681] iteration:11737  t-loss:0.1519, loss-lb:0.0812, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:36:10.872] iteration:11738  t-loss:0.1778, loss-lb:0.1015, loss-ulb:0.0381, weight:2.00, lr:0.0006
[11:36:11.064] iteration:11739  t-loss:0.1314, loss-lb:0.0809, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:36:11.257] iteration:11740  t-loss:0.1522, loss-lb:0.0844, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:36:11.448] iteration:11741  t-loss:0.1790, loss-lb:0.0918, loss-ulb:0.0436, weight:2.00, lr:0.0006
[11:36:11.640] iteration:11742  t-loss:0.1468, loss-lb:0.0889, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:36:11.834] iteration:11743  t-loss:0.1430, loss-lb:0.0803, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:36:12.025] iteration:11744  t-loss:0.1517, loss-lb:0.0929, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:36:12.217] iteration:11745  t-loss:0.1578, loss-lb:0.0881, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:36:12.410] iteration:11746  t-loss:0.1361, loss-lb:0.0789, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:36:12.603] iteration:11747  t-loss:0.1348, loss-lb:0.0768, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:36:12.794] iteration:11748  t-loss:0.1428, loss-lb:0.0861, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:36:12.987] iteration:11749  t-loss:0.2106, loss-lb:0.0886, loss-ulb:0.0610, weight:2.00, lr:0.0006
[11:36:13.179] iteration:11750  t-loss:0.1278, loss-lb:0.0825, loss-ulb:0.0227, weight:2.00, lr:0.0006
[11:36:13.372] iteration:11751  t-loss:0.1480, loss-lb:0.0898, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:36:13.563] iteration:11752  t-loss:0.1343, loss-lb:0.0843, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:36:13.756] iteration:11753  t-loss:0.2052, loss-lb:0.0853, loss-ulb:0.0599, weight:2.00, lr:0.0006
[11:36:13.947] iteration:11754  t-loss:0.1566, loss-lb:0.0829, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:36:14.138] iteration:11755  t-loss:0.2282, loss-lb:0.0847, loss-ulb:0.0718, weight:2.00, lr:0.0006
[11:36:14.330] iteration:11756  t-loss:0.1519, loss-lb:0.0916, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:36:14.520] iteration:11757  t-loss:0.1555, loss-lb:0.1069, loss-ulb:0.0243, weight:2.00, lr:0.0006
[11:36:14.711] iteration:11758  t-loss:0.1499, loss-lb:0.0869, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:36:14.901] iteration:11759  t-loss:0.1535, loss-lb:0.0869, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:36:15.093] iteration:11760  t-loss:0.2395, loss-lb:0.0828, loss-ulb:0.0784, weight:2.00, lr:0.0006
[11:36:15.677] iteration:11761  t-loss:0.1537, loss-lb:0.0957, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:36:15.873] iteration:11762  t-loss:0.1403, loss-lb:0.0817, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:36:16.067] iteration:11763  t-loss:0.1448, loss-lb:0.0894, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:36:16.259] iteration:11764  t-loss:0.1298, loss-lb:0.0860, loss-ulb:0.0219, weight:2.00, lr:0.0006
[11:36:16.452] iteration:11765  t-loss:0.1530, loss-lb:0.0781, loss-ulb:0.0374, weight:2.00, lr:0.0006
[11:36:16.645] iteration:11766  t-loss:0.2661, loss-lb:0.0855, loss-ulb:0.0903, weight:2.00, lr:0.0006
[11:36:16.837] iteration:11767  t-loss:0.1396, loss-lb:0.0913, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:36:17.030] iteration:11768  t-loss:0.1452, loss-lb:0.0800, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:36:17.220] iteration:11769  t-loss:0.1467, loss-lb:0.0936, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:36:17.413] iteration:11770  t-loss:0.1734, loss-lb:0.0853, loss-ulb:0.0440, weight:2.00, lr:0.0006
[11:36:17.606] iteration:11771  t-loss:0.2286, loss-lb:0.0834, loss-ulb:0.0726, weight:2.00, lr:0.0006
[11:36:17.798] iteration:11772  t-loss:0.1423, loss-lb:0.0875, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:36:17.991] iteration:11773  t-loss:0.2540, loss-lb:0.0915, loss-ulb:0.0813, weight:2.00, lr:0.0006
[11:36:18.183] iteration:11774  t-loss:0.1620, loss-lb:0.0892, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:36:18.375] iteration:11775  t-loss:0.1387, loss-lb:0.0797, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:36:18.567] iteration:11776  t-loss:0.2792, loss-lb:0.1217, loss-ulb:0.0787, weight:2.00, lr:0.0006
[11:36:18.759] iteration:11777  t-loss:0.1559, loss-lb:0.0924, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:36:18.951] iteration:11778  t-loss:0.1482, loss-lb:0.0907, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:36:19.142] iteration:11779  t-loss:0.1642, loss-lb:0.0922, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:36:19.334] iteration:11780  t-loss:0.1558, loss-lb:0.0877, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:36:19.526] iteration:11781  t-loss:0.1596, loss-lb:0.1009, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:36:19.717] iteration:11782  t-loss:0.2021, loss-lb:0.0958, loss-ulb:0.0531, weight:2.00, lr:0.0006
[11:36:19.908] iteration:11783  t-loss:0.1472, loss-lb:0.0896, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:36:20.099] iteration:11784  t-loss:0.1428, loss-lb:0.0791, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:36:20.291] iteration:11785  t-loss:0.1516, loss-lb:0.0885, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:36:20.485] iteration:11786  t-loss:0.1702, loss-lb:0.0914, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:36:20.676] iteration:11787  t-loss:0.1813, loss-lb:0.1008, loss-ulb:0.0402, weight:2.00, lr:0.0006
[11:36:20.868] iteration:11788  t-loss:0.1573, loss-lb:0.0936, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:36:21.059] iteration:11789  t-loss:0.1780, loss-lb:0.0856, loss-ulb:0.0462, weight:2.00, lr:0.0006
[11:36:21.249] iteration:11790  t-loss:0.1893, loss-lb:0.1022, loss-ulb:0.0435, weight:2.00, lr:0.0006
[11:36:21.442] iteration:11791  t-loss:0.2847, loss-lb:0.0943, loss-ulb:0.0952, weight:2.00, lr:0.0006
[11:36:21.634] iteration:11792  t-loss:0.1380, loss-lb:0.0824, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:36:21.827] iteration:11793  t-loss:0.1923, loss-lb:0.0878, loss-ulb:0.0523, weight:2.00, lr:0.0006
[11:36:22.019] iteration:11794  t-loss:0.1497, loss-lb:0.0876, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:36:22.211] iteration:11795  t-loss:0.1509, loss-lb:0.0945, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:36:22.403] iteration:11796  t-loss:0.1794, loss-lb:0.1008, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:36:22.595] iteration:11797  t-loss:0.1527, loss-lb:0.0925, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:36:22.786] iteration:11798  t-loss:0.1350, loss-lb:0.0837, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:36:22.978] iteration:11799  t-loss:0.1478, loss-lb:0.0886, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:36:23.170] iteration:11800  t-loss:0.1359, loss-lb:0.0794, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:36:23.361] iteration:11801  t-loss:0.1348, loss-lb:0.0869, loss-ulb:0.0240, weight:2.00, lr:0.0006
[11:36:23.553] iteration:11802  t-loss:0.1556, loss-lb:0.0901, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:36:23.744] iteration:11803  t-loss:0.1479, loss-lb:0.0972, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:36:23.935] iteration:11804  t-loss:0.1406, loss-lb:0.0821, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:36:24.126] iteration:11805  t-loss:0.1339, loss-lb:0.0824, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:36:24.317] iteration:11806  t-loss:0.1344, loss-lb:0.0831, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:36:24.508] iteration:11807  t-loss:0.1433, loss-lb:0.0851, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:36:24.701] iteration:11808  t-loss:0.1502, loss-lb:0.0817, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:36:24.892] iteration:11809  t-loss:0.1939, loss-lb:0.1336, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:36:25.084] iteration:11810  t-loss:0.1543, loss-lb:0.0883, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:36:25.276] iteration:11811  t-loss:0.1434, loss-lb:0.0832, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:36:25.467] iteration:11812  t-loss:0.1845, loss-lb:0.0825, loss-ulb:0.0510, weight:2.00, lr:0.0006
[11:36:25.659] iteration:11813  t-loss:0.1965, loss-lb:0.0942, loss-ulb:0.0511, weight:2.00, lr:0.0006
[11:36:25.849] iteration:11814  t-loss:0.1416, loss-lb:0.0912, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:36:26.041] iteration:11815  t-loss:0.1465, loss-lb:0.0894, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:36:26.235] iteration:11816  t-loss:0.1735, loss-lb:0.0936, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:36:26.428] iteration:11817  t-loss:0.1392, loss-lb:0.0825, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:36:26.626] iteration:11818  t-loss:0.1441, loss-lb:0.0918, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:36:26.821] iteration:11819  t-loss:0.1395, loss-lb:0.0829, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:36:27.017] iteration:11820  t-loss:0.1899, loss-lb:0.0857, loss-ulb:0.0521, weight:2.00, lr:0.0006
[11:36:27.222] iteration:11821  t-loss:0.1488, loss-lb:0.0840, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:36:27.422] iteration:11822  t-loss:0.2168, loss-lb:0.0871, loss-ulb:0.0648, weight:2.00, lr:0.0006
[11:36:27.616] iteration:11823  t-loss:0.1579, loss-lb:0.0880, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:36:27.809] iteration:11824  t-loss:0.2094, loss-lb:0.0846, loss-ulb:0.0624, weight:2.00, lr:0.0006
[11:36:28.000] iteration:11825  t-loss:0.1473, loss-lb:0.0886, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:36:28.192] iteration:11826  t-loss:0.1420, loss-lb:0.0829, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:36:28.383] iteration:11827  t-loss:0.1675, loss-lb:0.1076, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:36:28.575] iteration:11828  t-loss:0.1641, loss-lb:0.0924, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:36:28.767] iteration:11829  t-loss:0.1554, loss-lb:0.0908, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:36:28.959] iteration:11830  t-loss:0.1379, loss-lb:0.0886, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:36:29.151] iteration:11831  t-loss:0.1538, loss-lb:0.0879, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:36:29.342] iteration:11832  t-loss:0.1565, loss-lb:0.0902, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:36:29.533] iteration:11833  t-loss:0.1722, loss-lb:0.0955, loss-ulb:0.0384, weight:2.00, lr:0.0006
[11:36:29.726] iteration:11834  t-loss:0.1540, loss-lb:0.0892, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:36:29.917] iteration:11835  t-loss:0.1352, loss-lb:0.0835, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:36:30.110] iteration:11836  t-loss:0.1367, loss-lb:0.0884, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:36:30.302] iteration:11837  t-loss:0.1464, loss-lb:0.0847, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:36:30.494] iteration:11838  t-loss:0.1472, loss-lb:0.0905, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:36:30.685] iteration:11839  t-loss:0.1451, loss-lb:0.0889, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:36:30.877] iteration:11840  t-loss:0.1697, loss-lb:0.0941, loss-ulb:0.0378, weight:2.00, lr:0.0006
[11:36:31.068] iteration:11841  t-loss:0.1247, loss-lb:0.0750, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:36:31.260] iteration:11842  t-loss:0.1518, loss-lb:0.0910, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:36:31.452] iteration:11843  t-loss:0.1419, loss-lb:0.0856, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:36:31.644] iteration:11844  t-loss:0.1470, loss-lb:0.0903, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:36:31.836] iteration:11845  t-loss:0.1546, loss-lb:0.0893, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:36:32.027] iteration:11846  t-loss:0.1458, loss-lb:0.0860, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:36:32.220] iteration:11847  t-loss:0.3017, loss-lb:0.0983, loss-ulb:0.1017, weight:2.00, lr:0.0006
[11:36:32.413] iteration:11848  t-loss:0.1421, loss-lb:0.0898, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:36:32.604] iteration:11849  t-loss:0.1363, loss-lb:0.0851, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:36:32.795] iteration:11850  t-loss:0.1675, loss-lb:0.0824, loss-ulb:0.0425, weight:2.00, lr:0.0006
[11:36:32.987] iteration:11851  t-loss:0.1378, loss-lb:0.0851, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:36:33.178] iteration:11852  t-loss:0.1670, loss-lb:0.0900, loss-ulb:0.0385, weight:2.00, lr:0.0006
[11:36:33.368] iteration:11853  t-loss:0.1442, loss-lb:0.0822, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:36:33.558] iteration:11854  t-loss:0.1424, loss-lb:0.0854, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:36:33.750] iteration:11855  t-loss:0.2345, loss-lb:0.0820, loss-ulb:0.0762, weight:2.00, lr:0.0006
[11:36:33.940] iteration:11856  t-loss:0.2488, loss-lb:0.0939, loss-ulb:0.0774, weight:2.00, lr:0.0006
[11:36:34.130] iteration:11857  t-loss:0.1404, loss-lb:0.0859, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:36:34.320] iteration:11858  t-loss:0.1674, loss-lb:0.0871, loss-ulb:0.0402, weight:2.00, lr:0.0006
[11:36:45.861]  <<Test>> - Ep:120  - mean_dice/mean_h95 - S:89.11/5.31, Best-S:90.28, T:89.94/2.00, Best-T:90.48
[11:36:45.862]           - AvgLoss(lb/ulb/all):0.0892/0.0391/0.1655
[11:36:46.390] iteration:11859  t-loss:0.3286, loss-lb:0.0930, loss-ulb:0.1178, weight:2.00, lr:0.0006
[11:36:46.587] iteration:11860  t-loss:0.1574, loss-lb:0.0921, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:36:46.780] iteration:11861  t-loss:0.2399, loss-lb:0.0954, loss-ulb:0.0722, weight:2.00, lr:0.0006
[11:36:46.972] iteration:11862  t-loss:0.1476, loss-lb:0.0929, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:36:47.164] iteration:11863  t-loss:0.1534, loss-lb:0.0925, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:36:47.356] iteration:11864  t-loss:0.1677, loss-lb:0.0984, loss-ulb:0.0347, weight:2.00, lr:0.0006
[11:36:47.548] iteration:11865  t-loss:0.1505, loss-lb:0.0944, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:36:47.740] iteration:11866  t-loss:0.1968, loss-lb:0.0986, loss-ulb:0.0491, weight:2.00, lr:0.0006
[11:36:47.932] iteration:11867  t-loss:0.1659, loss-lb:0.0974, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:36:48.125] iteration:11868  t-loss:0.1591, loss-lb:0.1019, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:36:48.321] iteration:11869  t-loss:0.1447, loss-lb:0.0944, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:36:48.518] iteration:11870  t-loss:0.1468, loss-lb:0.0842, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:36:48.714] iteration:11871  t-loss:0.1492, loss-lb:0.0874, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:36:48.907] iteration:11872  t-loss:0.2330, loss-lb:0.1008, loss-ulb:0.0661, weight:2.00, lr:0.0006
[11:36:49.100] iteration:11873  t-loss:0.1653, loss-lb:0.0845, loss-ulb:0.0404, weight:2.00, lr:0.0006
[11:36:49.293] iteration:11874  t-loss:0.1720, loss-lb:0.0974, loss-ulb:0.0373, weight:2.00, lr:0.0006
[11:36:49.485] iteration:11875  t-loss:0.1507, loss-lb:0.0884, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:36:49.677] iteration:11876  t-loss:0.2282, loss-lb:0.0988, loss-ulb:0.0647, weight:2.00, lr:0.0006
[11:36:49.871] iteration:11877  t-loss:0.1641, loss-lb:0.1025, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:36:50.062] iteration:11878  t-loss:0.1914, loss-lb:0.1344, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:36:50.253] iteration:11879  t-loss:0.1358, loss-lb:0.0868, loss-ulb:0.0245, weight:2.00, lr:0.0006
[11:36:50.444] iteration:11880  t-loss:0.2763, loss-lb:0.0907, loss-ulb:0.0928, weight:2.00, lr:0.0006
[11:36:50.637] iteration:11881  t-loss:0.1473, loss-lb:0.0854, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:36:50.828] iteration:11882  t-loss:0.2198, loss-lb:0.0911, loss-ulb:0.0644, weight:2.00, lr:0.0006
[11:36:51.019] iteration:11883  t-loss:0.2131, loss-lb:0.1313, loss-ulb:0.0409, weight:2.00, lr:0.0006
[11:36:51.210] iteration:11884  t-loss:0.1606, loss-lb:0.0978, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:36:51.402] iteration:11885  t-loss:0.1595, loss-lb:0.0970, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:36:51.594] iteration:11886  t-loss:0.1517, loss-lb:0.0904, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:36:51.786] iteration:11887  t-loss:0.1456, loss-lb:0.0851, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:36:51.978] iteration:11888  t-loss:0.1511, loss-lb:0.0960, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:36:52.170] iteration:11889  t-loss:0.1700, loss-lb:0.0863, loss-ulb:0.0419, weight:2.00, lr:0.0006
[11:36:52.362] iteration:11890  t-loss:0.1511, loss-lb:0.0927, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:36:52.555] iteration:11891  t-loss:0.2097, loss-lb:0.0948, loss-ulb:0.0574, weight:2.00, lr:0.0006
[11:36:52.746] iteration:11892  t-loss:0.1438, loss-lb:0.0865, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:36:52.940] iteration:11893  t-loss:0.2894, loss-lb:0.0900, loss-ulb:0.0997, weight:2.00, lr:0.0006
[11:36:53.131] iteration:11894  t-loss:0.1713, loss-lb:0.0882, loss-ulb:0.0416, weight:2.00, lr:0.0006
[11:36:53.323] iteration:11895  t-loss:0.1671, loss-lb:0.0907, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:36:53.515] iteration:11896  t-loss:0.1663, loss-lb:0.1012, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:36:53.705] iteration:11897  t-loss:0.1664, loss-lb:0.0931, loss-ulb:0.0367, weight:2.00, lr:0.0006
[11:36:53.897] iteration:11898  t-loss:0.1600, loss-lb:0.0879, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:36:54.088] iteration:11899  t-loss:0.1677, loss-lb:0.0992, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:36:54.280] iteration:11900  t-loss:0.1620, loss-lb:0.0957, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:36:54.472] iteration:11901  t-loss:0.1527, loss-lb:0.0966, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:36:54.664] iteration:11902  t-loss:0.1618, loss-lb:0.0961, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:36:54.856] iteration:11903  t-loss:0.1506, loss-lb:0.0768, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:36:55.047] iteration:11904  t-loss:0.1330, loss-lb:0.0814, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:36:55.239] iteration:11905  t-loss:0.1387, loss-lb:0.0839, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:36:55.431] iteration:11906  t-loss:0.1592, loss-lb:0.0903, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:36:55.631] iteration:11907  t-loss:0.1562, loss-lb:0.1015, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:36:55.823] iteration:11908  t-loss:0.1844, loss-lb:0.0899, loss-ulb:0.0473, weight:2.00, lr:0.0006
[11:36:56.014] iteration:11909  t-loss:0.1429, loss-lb:0.0832, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:36:56.205] iteration:11910  t-loss:0.2448, loss-lb:0.0835, loss-ulb:0.0806, weight:2.00, lr:0.0006
[11:36:56.405] iteration:11911  t-loss:0.1637, loss-lb:0.0966, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:36:56.597] iteration:11912  t-loss:0.1633, loss-lb:0.0895, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:36:56.789] iteration:11913  t-loss:0.1453, loss-lb:0.0860, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:36:56.980] iteration:11914  t-loss:0.1477, loss-lb:0.0987, loss-ulb:0.0245, weight:2.00, lr:0.0006
[11:36:57.179] iteration:11915  t-loss:0.2011, loss-lb:0.0867, loss-ulb:0.0572, weight:2.00, lr:0.0006
[11:36:57.371] iteration:11916  t-loss:0.2241, loss-lb:0.0894, loss-ulb:0.0673, weight:2.00, lr:0.0006
[11:36:57.563] iteration:11917  t-loss:0.1835, loss-lb:0.1068, loss-ulb:0.0384, weight:2.00, lr:0.0006
[11:36:57.754] iteration:11918  t-loss:0.1603, loss-lb:0.0975, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:36:57.952] iteration:11919  t-loss:0.1617, loss-lb:0.0936, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:36:58.143] iteration:11920  t-loss:0.1680, loss-lb:0.0952, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:36:58.335] iteration:11921  t-loss:0.1625, loss-lb:0.0986, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:36:58.526] iteration:11922  t-loss:0.1455, loss-lb:0.0892, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:36:58.726] iteration:11923  t-loss:0.1474, loss-lb:0.0954, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:36:58.919] iteration:11924  t-loss:0.1534, loss-lb:0.0930, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:36:59.112] iteration:11925  t-loss:0.1405, loss-lb:0.0909, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:36:59.304] iteration:11926  t-loss:0.1519, loss-lb:0.0931, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:36:59.506] iteration:11927  t-loss:0.1694, loss-lb:0.1051, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:36:59.697] iteration:11928  t-loss:0.1507, loss-lb:0.0915, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:36:59.903] iteration:11929  t-loss:0.1492, loss-lb:0.0917, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:37:00.100] iteration:11930  t-loss:0.1483, loss-lb:0.0916, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:37:00.303] iteration:11931  t-loss:0.1579, loss-lb:0.0998, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:37:00.497] iteration:11932  t-loss:0.1750, loss-lb:0.0859, loss-ulb:0.0446, weight:2.00, lr:0.0006
[11:37:00.691] iteration:11933  t-loss:0.1284, loss-lb:0.0782, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:37:00.883] iteration:11934  t-loss:0.1474, loss-lb:0.0952, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:37:01.075] iteration:11935  t-loss:0.1467, loss-lb:0.0874, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:37:01.268] iteration:11936  t-loss:0.1393, loss-lb:0.0872, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:37:01.461] iteration:11937  t-loss:0.1429, loss-lb:0.0875, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:37:01.653] iteration:11938  t-loss:0.1643, loss-lb:0.0997, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:37:01.846] iteration:11939  t-loss:0.1486, loss-lb:0.0908, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:37:02.038] iteration:11940  t-loss:0.1469, loss-lb:0.0919, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:37:02.230] iteration:11941  t-loss:0.1503, loss-lb:0.0882, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:37:02.422] iteration:11942  t-loss:0.1492, loss-lb:0.0805, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:37:02.614] iteration:11943  t-loss:0.2336, loss-lb:0.0852, loss-ulb:0.0742, weight:2.00, lr:0.0006
[11:37:02.806] iteration:11944  t-loss:0.1437, loss-lb:0.0756, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:37:03.000] iteration:11945  t-loss:0.1516, loss-lb:0.0900, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:37:03.192] iteration:11946  t-loss:0.1666, loss-lb:0.1098, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:37:03.384] iteration:11947  t-loss:0.1474, loss-lb:0.0996, loss-ulb:0.0239, weight:2.00, lr:0.0006
[11:37:03.577] iteration:11948  t-loss:0.1407, loss-lb:0.0927, loss-ulb:0.0240, weight:2.00, lr:0.0006
[11:37:03.769] iteration:11949  t-loss:0.1449, loss-lb:0.0884, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:37:03.959] iteration:11950  t-loss:0.1519, loss-lb:0.0990, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:37:04.150] iteration:11951  t-loss:0.1770, loss-lb:0.1152, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:37:04.341] iteration:11952  t-loss:0.1239, loss-lb:0.0790, loss-ulb:0.0225, weight:2.00, lr:0.0006
[11:37:04.532] iteration:11953  t-loss:0.1328, loss-lb:0.0779, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:37:04.721] iteration:11954  t-loss:0.1395, loss-lb:0.0885, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:37:04.912] iteration:11955  t-loss:0.1367, loss-lb:0.0891, loss-ulb:0.0238, weight:2.00, lr:0.0006
[11:37:05.102] iteration:11956  t-loss:0.1768, loss-lb:0.0896, loss-ulb:0.0436, weight:2.00, lr:0.0006
[11:37:05.697] iteration:11957  t-loss:0.1509, loss-lb:0.0869, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:37:05.891] iteration:11958  t-loss:0.1435, loss-lb:0.0895, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:37:06.083] iteration:11959  t-loss:0.1237, loss-lb:0.0822, loss-ulb:0.0208, weight:2.00, lr:0.0006
[11:37:06.276] iteration:11960  t-loss:0.1904, loss-lb:0.0854, loss-ulb:0.0525, weight:2.00, lr:0.0006
[11:37:06.468] iteration:11961  t-loss:0.1463, loss-lb:0.0963, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:37:06.660] iteration:11962  t-loss:0.1327, loss-lb:0.0838, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:37:06.852] iteration:11963  t-loss:0.1421, loss-lb:0.0904, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:37:07.048] iteration:11964  t-loss:0.1439, loss-lb:0.0858, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:37:07.240] iteration:11965  t-loss:0.1342, loss-lb:0.0847, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:37:07.432] iteration:11966  t-loss:0.1327, loss-lb:0.0835, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:37:07.624] iteration:11967  t-loss:0.1505, loss-lb:0.0919, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:37:07.818] iteration:11968  t-loss:0.1532, loss-lb:0.0823, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:37:08.010] iteration:11969  t-loss:0.1445, loss-lb:0.0853, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:37:08.202] iteration:11970  t-loss:0.1358, loss-lb:0.0852, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:37:08.395] iteration:11971  t-loss:0.1481, loss-lb:0.0908, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:37:08.589] iteration:11972  t-loss:0.1377, loss-lb:0.0808, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:37:08.780] iteration:11973  t-loss:0.1441, loss-lb:0.0795, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:37:08.973] iteration:11974  t-loss:0.1458, loss-lb:0.0828, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:37:09.165] iteration:11975  t-loss:0.1428, loss-lb:0.0861, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:37:09.358] iteration:11976  t-loss:0.1431, loss-lb:0.0933, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:37:09.551] iteration:11977  t-loss:0.1897, loss-lb:0.0922, loss-ulb:0.0488, weight:2.00, lr:0.0006
[11:37:09.743] iteration:11978  t-loss:0.1536, loss-lb:0.0878, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:37:09.935] iteration:11979  t-loss:0.1335, loss-lb:0.0801, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:37:10.127] iteration:11980  t-loss:0.1229, loss-lb:0.0793, loss-ulb:0.0218, weight:2.00, lr:0.0006
[11:37:10.320] iteration:11981  t-loss:0.1489, loss-lb:0.0943, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:37:10.513] iteration:11982  t-loss:0.1479, loss-lb:0.0890, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:37:10.704] iteration:11983  t-loss:0.1398, loss-lb:0.0870, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:37:10.897] iteration:11984  t-loss:0.2189, loss-lb:0.0874, loss-ulb:0.0658, weight:2.00, lr:0.0006
[11:37:11.090] iteration:11985  t-loss:0.1372, loss-lb:0.0814, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:37:11.283] iteration:11986  t-loss:0.2097, loss-lb:0.0874, loss-ulb:0.0612, weight:2.00, lr:0.0006
[11:37:11.476] iteration:11987  t-loss:0.3202, loss-lb:0.0842, loss-ulb:0.1180, weight:2.00, lr:0.0006
[11:37:11.669] iteration:11988  t-loss:0.2025, loss-lb:0.0780, loss-ulb:0.0622, weight:2.00, lr:0.0006
[11:37:11.861] iteration:11989  t-loss:0.1396, loss-lb:0.0777, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:37:12.053] iteration:11990  t-loss:0.1554, loss-lb:0.0858, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:37:12.246] iteration:11991  t-loss:0.1736, loss-lb:0.0829, loss-ulb:0.0453, weight:2.00, lr:0.0006
[11:37:12.439] iteration:11992  t-loss:0.1557, loss-lb:0.0944, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:37:12.632] iteration:11993  t-loss:0.2025, loss-lb:0.0818, loss-ulb:0.0603, weight:2.00, lr:0.0006
[11:37:12.824] iteration:11994  t-loss:0.1315, loss-lb:0.0823, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:37:13.016] iteration:11995  t-loss:0.1433, loss-lb:0.0921, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:37:13.208] iteration:11996  t-loss:0.1676, loss-lb:0.1061, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:37:13.401] iteration:11997  t-loss:0.1608, loss-lb:0.0912, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:37:13.593] iteration:11998  t-loss:0.2340, loss-lb:0.0948, loss-ulb:0.0696, weight:2.00, lr:0.0006
[11:37:13.785] iteration:11999  t-loss:0.1427, loss-lb:0.0749, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:37:13.977] iteration:12000  t-loss:0.1424, loss-lb:0.0791, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:37:14.169] iteration:12001  t-loss:0.1553, loss-lb:0.0833, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:37:14.361] iteration:12002  t-loss:0.1442, loss-lb:0.0861, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:37:14.554] iteration:12003  t-loss:0.2683, loss-lb:0.0853, loss-ulb:0.0915, weight:2.00, lr:0.0006
[11:37:14.746] iteration:12004  t-loss:0.1458, loss-lb:0.0779, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:37:14.939] iteration:12005  t-loss:0.1393, loss-lb:0.0878, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:37:15.133] iteration:12006  t-loss:0.1667, loss-lb:0.0817, loss-ulb:0.0425, weight:2.00, lr:0.0006
[11:37:15.324] iteration:12007  t-loss:0.1248, loss-lb:0.0792, loss-ulb:0.0228, weight:2.00, lr:0.0006
[11:37:15.516] iteration:12008  t-loss:0.1475, loss-lb:0.0880, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:37:15.708] iteration:12009  t-loss:0.1555, loss-lb:0.0937, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:37:15.899] iteration:12010  t-loss:0.1710, loss-lb:0.0869, loss-ulb:0.0420, weight:2.00, lr:0.0006
[11:37:16.092] iteration:12011  t-loss:0.1331, loss-lb:0.0828, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:37:16.285] iteration:12012  t-loss:0.1893, loss-lb:0.0995, loss-ulb:0.0449, weight:2.00, lr:0.0006
[11:37:16.478] iteration:12013  t-loss:0.1416, loss-lb:0.0878, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:37:16.670] iteration:12014  t-loss:0.1603, loss-lb:0.0761, loss-ulb:0.0421, weight:2.00, lr:0.0006
[11:37:16.862] iteration:12015  t-loss:0.1349, loss-lb:0.0808, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:37:17.054] iteration:12016  t-loss:0.1506, loss-lb:0.0942, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:37:17.246] iteration:12017  t-loss:0.1539, loss-lb:0.0896, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:37:17.438] iteration:12018  t-loss:0.1334, loss-lb:0.0801, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:37:17.630] iteration:12019  t-loss:0.1695, loss-lb:0.1117, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:37:17.823] iteration:12020  t-loss:0.1342, loss-lb:0.0868, loss-ulb:0.0237, weight:2.00, lr:0.0006
[11:37:18.014] iteration:12021  t-loss:0.1510, loss-lb:0.0962, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:37:18.207] iteration:12022  t-loss:0.1761, loss-lb:0.0959, loss-ulb:0.0401, weight:2.00, lr:0.0006
[11:37:18.399] iteration:12023  t-loss:0.1387, loss-lb:0.0821, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:37:18.591] iteration:12024  t-loss:0.1608, loss-lb:0.0939, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:37:18.784] iteration:12025  t-loss:0.1471, loss-lb:0.0887, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:37:18.976] iteration:12026  t-loss:0.1379, loss-lb:0.0802, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:37:19.168] iteration:12027  t-loss:0.1617, loss-lb:0.1040, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:37:19.361] iteration:12028  t-loss:0.1557, loss-lb:0.0930, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:37:19.554] iteration:12029  t-loss:0.2955, loss-lb:0.0900, loss-ulb:0.1027, weight:2.00, lr:0.0006
[11:37:19.746] iteration:12030  t-loss:0.1433, loss-lb:0.0825, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:37:19.939] iteration:12031  t-loss:0.1491, loss-lb:0.0828, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:37:20.131] iteration:12032  t-loss:0.1493, loss-lb:0.0950, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:37:20.324] iteration:12033  t-loss:0.1482, loss-lb:0.0884, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:37:20.516] iteration:12034  t-loss:0.1427, loss-lb:0.0888, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:37:20.709] iteration:12035  t-loss:0.1446, loss-lb:0.0887, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:37:20.902] iteration:12036  t-loss:0.1684, loss-lb:0.0942, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:37:21.095] iteration:12037  t-loss:0.1474, loss-lb:0.0830, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:37:21.286] iteration:12038  t-loss:0.1622, loss-lb:0.1005, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:37:21.479] iteration:12039  t-loss:0.1397, loss-lb:0.0891, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:37:21.671] iteration:12040  t-loss:0.1480, loss-lb:0.0851, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:37:21.863] iteration:12041  t-loss:0.1750, loss-lb:0.0959, loss-ulb:0.0396, weight:2.00, lr:0.0006
[11:37:22.055] iteration:12042  t-loss:0.1382, loss-lb:0.0887, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:37:22.247] iteration:12043  t-loss:0.1581, loss-lb:0.0997, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:37:22.439] iteration:12044  t-loss:0.1618, loss-lb:0.0840, loss-ulb:0.0389, weight:2.00, lr:0.0006
[11:37:22.633] iteration:12045  t-loss:0.1652, loss-lb:0.0951, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:37:22.826] iteration:12046  t-loss:0.1388, loss-lb:0.0887, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:37:23.017] iteration:12047  t-loss:0.1439, loss-lb:0.0895, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:37:23.208] iteration:12048  t-loss:0.1499, loss-lb:0.0853, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:37:23.399] iteration:12049  t-loss:0.1566, loss-lb:0.0872, loss-ulb:0.0347, weight:2.00, lr:0.0006
[11:37:23.589] iteration:12050  t-loss:0.1462, loss-lb:0.0852, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:37:23.779] iteration:12051  t-loss:0.1329, loss-lb:0.0814, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:37:23.970] iteration:12052  t-loss:0.1435, loss-lb:0.0856, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:37:24.161] iteration:12053  t-loss:0.1507, loss-lb:0.0886, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:37:24.352] iteration:12054  t-loss:0.1681, loss-lb:0.0888, loss-ulb:0.0397, weight:2.00, lr:0.0006
[11:37:36.690]  <<Test>> - Ep:122  - mean_dice/mean_h95 - S:89.64/1.34, Best-S:90.28, T:89.95/1.37, Best-T:90.48
[11:37:36.690]           - AvgLoss(lb/ulb/all):0.0876/0.0314/0.1520
[11:37:37.232] iteration:12055  t-loss:0.1488, loss-lb:0.0877, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:37:37.430] iteration:12056  t-loss:0.1429, loss-lb:0.0888, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:37:37.623] iteration:12057  t-loss:0.1740, loss-lb:0.0875, loss-ulb:0.0433, weight:2.00, lr:0.0006
[11:37:37.817] iteration:12058  t-loss:0.1394, loss-lb:0.0877, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:37:38.011] iteration:12059  t-loss:0.1475, loss-lb:0.0929, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:37:38.203] iteration:12060  t-loss:0.1346, loss-lb:0.0834, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:37:38.396] iteration:12061  t-loss:0.1395, loss-lb:0.0868, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:37:38.588] iteration:12062  t-loss:0.1531, loss-lb:0.0865, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:37:38.782] iteration:12063  t-loss:0.2174, loss-lb:0.0994, loss-ulb:0.0590, weight:2.00, lr:0.0006
[11:37:38.974] iteration:12064  t-loss:0.1558, loss-lb:0.0891, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:37:39.167] iteration:12065  t-loss:0.1959, loss-lb:0.1198, loss-ulb:0.0381, weight:2.00, lr:0.0006
[11:37:39.361] iteration:12066  t-loss:0.1522, loss-lb:0.0948, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:37:39.553] iteration:12067  t-loss:0.1617, loss-lb:0.0894, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:37:39.747] iteration:12068  t-loss:0.2181, loss-lb:0.0895, loss-ulb:0.0643, weight:2.00, lr:0.0006
[11:37:39.941] iteration:12069  t-loss:0.1816, loss-lb:0.0848, loss-ulb:0.0484, weight:2.00, lr:0.0006
[11:37:40.134] iteration:12070  t-loss:0.1601, loss-lb:0.0897, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:37:40.327] iteration:12071  t-loss:0.1744, loss-lb:0.0956, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:37:40.520] iteration:12072  t-loss:0.1835, loss-lb:0.0887, loss-ulb:0.0474, weight:2.00, lr:0.0006
[11:37:40.712] iteration:12073  t-loss:0.1611, loss-lb:0.0956, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:37:40.905] iteration:12074  t-loss:0.1512, loss-lb:0.0891, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:37:41.098] iteration:12075  t-loss:0.1557, loss-lb:0.1047, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:37:41.291] iteration:12076  t-loss:0.1672, loss-lb:0.0947, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:37:41.485] iteration:12077  t-loss:0.1533, loss-lb:0.0988, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:37:41.678] iteration:12078  t-loss:0.1481, loss-lb:0.0858, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:37:41.871] iteration:12079  t-loss:0.1511, loss-lb:0.0980, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:37:42.063] iteration:12080  t-loss:0.1480, loss-lb:0.0890, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:37:42.256] iteration:12081  t-loss:0.1607, loss-lb:0.0899, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:37:42.449] iteration:12082  t-loss:0.1654, loss-lb:0.0838, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:37:42.641] iteration:12083  t-loss:0.1662, loss-lb:0.0897, loss-ulb:0.0383, weight:2.00, lr:0.0006
[11:37:42.835] iteration:12084  t-loss:0.1729, loss-lb:0.1035, loss-ulb:0.0347, weight:2.00, lr:0.0006
[11:37:43.026] iteration:12085  t-loss:0.1693, loss-lb:0.0911, loss-ulb:0.0391, weight:2.00, lr:0.0006
[11:37:43.219] iteration:12086  t-loss:0.1415, loss-lb:0.0850, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:37:43.411] iteration:12087  t-loss:0.1590, loss-lb:0.0865, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:37:43.604] iteration:12088  t-loss:0.2204, loss-lb:0.1701, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:37:43.797] iteration:12089  t-loss:0.1741, loss-lb:0.1008, loss-ulb:0.0367, weight:2.00, lr:0.0006
[11:37:43.990] iteration:12090  t-loss:0.1672, loss-lb:0.0886, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:37:44.182] iteration:12091  t-loss:0.1454, loss-lb:0.0835, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:37:44.375] iteration:12092  t-loss:0.1657, loss-lb:0.1084, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:37:44.567] iteration:12093  t-loss:0.1776, loss-lb:0.1001, loss-ulb:0.0387, weight:2.00, lr:0.0006
[11:37:44.759] iteration:12094  t-loss:0.1499, loss-lb:0.0920, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:37:44.952] iteration:12095  t-loss:0.1481, loss-lb:0.0872, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:37:45.144] iteration:12096  t-loss:0.1453, loss-lb:0.0899, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:37:45.336] iteration:12097  t-loss:0.1639, loss-lb:0.0884, loss-ulb:0.0377, weight:2.00, lr:0.0006
[11:37:45.528] iteration:12098  t-loss:0.1429, loss-lb:0.0833, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:37:45.723] iteration:12099  t-loss:0.1733, loss-lb:0.0849, loss-ulb:0.0442, weight:2.00, lr:0.0006
[11:37:45.915] iteration:12100  t-loss:0.1513, loss-lb:0.0958, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:37:46.107] iteration:12101  t-loss:0.1561, loss-lb:0.0791, loss-ulb:0.0385, weight:2.00, lr:0.0006
[11:37:46.299] iteration:12102  t-loss:0.1534, loss-lb:0.0791, loss-ulb:0.0372, weight:2.00, lr:0.0006
[11:37:46.492] iteration:12103  t-loss:0.1633, loss-lb:0.1054, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:37:46.684] iteration:12104  t-loss:0.1338, loss-lb:0.0762, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:37:46.877] iteration:12105  t-loss:0.1826, loss-lb:0.0849, loss-ulb:0.0488, weight:2.00, lr:0.0006
[11:37:47.070] iteration:12106  t-loss:0.1530, loss-lb:0.0868, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:37:47.263] iteration:12107  t-loss:0.1655, loss-lb:0.0995, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:37:47.458] iteration:12108  t-loss:0.1454, loss-lb:0.0869, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:37:47.651] iteration:12109  t-loss:0.1510, loss-lb:0.0859, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:37:47.844] iteration:12110  t-loss:0.1841, loss-lb:0.0954, loss-ulb:0.0443, weight:2.00, lr:0.0006
[11:37:48.038] iteration:12111  t-loss:0.1817, loss-lb:0.0942, loss-ulb:0.0438, weight:2.00, lr:0.0006
[11:37:48.231] iteration:12112  t-loss:0.1451, loss-lb:0.0878, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:37:48.423] iteration:12113  t-loss:0.1710, loss-lb:0.0943, loss-ulb:0.0384, weight:2.00, lr:0.0006
[11:37:48.615] iteration:12114  t-loss:0.2313, loss-lb:0.0976, loss-ulb:0.0668, weight:2.00, lr:0.0006
[11:37:48.808] iteration:12115  t-loss:0.2440, loss-lb:0.0959, loss-ulb:0.0740, weight:2.00, lr:0.0006
[11:37:49.003] iteration:12116  t-loss:0.1489, loss-lb:0.0850, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:37:49.199] iteration:12117  t-loss:0.1562, loss-lb:0.1014, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:37:49.394] iteration:12118  t-loss:0.1669, loss-lb:0.0988, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:37:49.589] iteration:12119  t-loss:0.1906, loss-lb:0.0916, loss-ulb:0.0495, weight:2.00, lr:0.0006
[11:37:49.780] iteration:12120  t-loss:0.1485, loss-lb:0.0873, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:37:49.972] iteration:12121  t-loss:0.1720, loss-lb:0.1075, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:37:50.164] iteration:12122  t-loss:0.1659, loss-lb:0.0944, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:37:50.356] iteration:12123  t-loss:0.1603, loss-lb:0.0965, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:37:50.549] iteration:12124  t-loss:0.1348, loss-lb:0.0831, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:37:50.741] iteration:12125  t-loss:0.1502, loss-lb:0.0904, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:37:50.933] iteration:12126  t-loss:0.1862, loss-lb:0.1064, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:37:51.126] iteration:12127  t-loss:0.1966, loss-lb:0.0861, loss-ulb:0.0552, weight:2.00, lr:0.0006
[11:37:51.318] iteration:12128  t-loss:0.1864, loss-lb:0.1160, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:37:51.509] iteration:12129  t-loss:0.1461, loss-lb:0.0930, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:37:51.702] iteration:12130  t-loss:0.1821, loss-lb:0.0881, loss-ulb:0.0470, weight:2.00, lr:0.0006
[11:37:51.895] iteration:12131  t-loss:0.1464, loss-lb:0.0868, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:37:52.087] iteration:12132  t-loss:0.1670, loss-lb:0.1011, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:37:52.279] iteration:12133  t-loss:0.1639, loss-lb:0.0958, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:37:52.471] iteration:12134  t-loss:0.1685, loss-lb:0.1003, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:37:52.663] iteration:12135  t-loss:0.1464, loss-lb:0.0883, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:37:52.856] iteration:12136  t-loss:0.1765, loss-lb:0.0912, loss-ulb:0.0427, weight:2.00, lr:0.0006
[11:37:53.048] iteration:12137  t-loss:0.2176, loss-lb:0.0971, loss-ulb:0.0603, weight:2.00, lr:0.0006
[11:37:53.240] iteration:12138  t-loss:0.1531, loss-lb:0.0887, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:37:53.432] iteration:12139  t-loss:0.1490, loss-lb:0.0863, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:37:53.625] iteration:12140  t-loss:0.1472, loss-lb:0.0743, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:37:53.818] iteration:12141  t-loss:0.1540, loss-lb:0.0855, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:37:54.010] iteration:12142  t-loss:0.1670, loss-lb:0.0961, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:37:54.203] iteration:12143  t-loss:0.1404, loss-lb:0.0963, loss-ulb:0.0221, weight:2.00, lr:0.0006
[11:37:54.396] iteration:12144  t-loss:0.2780, loss-lb:0.1089, loss-ulb:0.0845, weight:2.00, lr:0.0006
[11:37:54.586] iteration:12145  t-loss:0.1428, loss-lb:0.0939, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:37:54.778] iteration:12146  t-loss:0.1833, loss-lb:0.0862, loss-ulb:0.0485, weight:2.00, lr:0.0006
[11:37:54.968] iteration:12147  t-loss:0.1430, loss-lb:0.0918, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:37:55.158] iteration:12148  t-loss:0.1460, loss-lb:0.0864, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:37:55.349] iteration:12149  t-loss:0.1532, loss-lb:0.0882, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:37:55.540] iteration:12150  t-loss:0.2149, loss-lb:0.0900, loss-ulb:0.0624, weight:2.00, lr:0.0006
[11:37:55.731] iteration:12151  t-loss:0.1371, loss-lb:0.0828, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:37:55.923] iteration:12152  t-loss:0.1491, loss-lb:0.0895, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:37:56.497] iteration:12153  t-loss:0.2602, loss-lb:0.1007, loss-ulb:0.0798, weight:2.00, lr:0.0006
[11:37:56.691] iteration:12154  t-loss:0.1406, loss-lb:0.0843, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:37:56.882] iteration:12155  t-loss:0.1454, loss-lb:0.0897, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:37:57.075] iteration:12156  t-loss:0.1596, loss-lb:0.0940, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:37:57.266] iteration:12157  t-loss:0.1455, loss-lb:0.0893, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:37:57.457] iteration:12158  t-loss:0.1918, loss-lb:0.0896, loss-ulb:0.0511, weight:2.00, lr:0.0006
[11:37:57.648] iteration:12159  t-loss:0.1392, loss-lb:0.0821, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:37:57.839] iteration:12160  t-loss:0.1536, loss-lb:0.0926, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:37:58.032] iteration:12161  t-loss:0.1578, loss-lb:0.0828, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:37:58.223] iteration:12162  t-loss:0.1534, loss-lb:0.0878, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:37:58.415] iteration:12163  t-loss:0.1530, loss-lb:0.0922, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:37:58.607] iteration:12164  t-loss:0.1438, loss-lb:0.0874, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:37:58.798] iteration:12165  t-loss:0.1393, loss-lb:0.0860, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:37:58.990] iteration:12166  t-loss:0.1524, loss-lb:0.0955, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:37:59.182] iteration:12167  t-loss:0.1551, loss-lb:0.0878, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:37:59.374] iteration:12168  t-loss:0.1537, loss-lb:0.0950, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:37:59.569] iteration:12169  t-loss:0.1472, loss-lb:0.0934, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:37:59.763] iteration:12170  t-loss:0.3021, loss-lb:0.0909, loss-ulb:0.1056, weight:2.00, lr:0.0006
[11:37:59.957] iteration:12171  t-loss:0.1522, loss-lb:0.0902, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:38:00.152] iteration:12172  t-loss:0.1320, loss-lb:0.0848, loss-ulb:0.0236, weight:2.00, lr:0.0006
[11:38:00.346] iteration:12173  t-loss:0.1361, loss-lb:0.0823, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:38:00.537] iteration:12174  t-loss:0.1401, loss-lb:0.0867, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:38:00.730] iteration:12175  t-loss:0.1545, loss-lb:0.0835, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:38:00.922] iteration:12176  t-loss:0.1722, loss-lb:0.0897, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:38:01.115] iteration:12177  t-loss:0.1451, loss-lb:0.0833, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:38:01.307] iteration:12178  t-loss:0.1445, loss-lb:0.0938, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:38:01.500] iteration:12179  t-loss:0.1508, loss-lb:0.0905, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:38:01.692] iteration:12180  t-loss:0.1515, loss-lb:0.0906, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:38:01.884] iteration:12181  t-loss:0.1414, loss-lb:0.0825, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:38:02.075] iteration:12182  t-loss:0.1555, loss-lb:0.0887, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:38:02.266] iteration:12183  t-loss:0.1528, loss-lb:0.0829, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:38:02.458] iteration:12184  t-loss:0.1580, loss-lb:0.0925, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:38:02.649] iteration:12185  t-loss:0.2332, loss-lb:0.0832, loss-ulb:0.0750, weight:2.00, lr:0.0006
[11:38:02.841] iteration:12186  t-loss:0.1337, loss-lb:0.0767, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:38:03.033] iteration:12187  t-loss:0.1517, loss-lb:0.0947, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:38:03.224] iteration:12188  t-loss:0.1674, loss-lb:0.0850, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:38:03.416] iteration:12189  t-loss:0.1496, loss-lb:0.0857, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:38:03.607] iteration:12190  t-loss:0.1921, loss-lb:0.0865, loss-ulb:0.0528, weight:2.00, lr:0.0006
[11:38:03.799] iteration:12191  t-loss:0.1408, loss-lb:0.0860, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:38:03.992] iteration:12192  t-loss:0.1559, loss-lb:0.0855, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:38:04.184] iteration:12193  t-loss:0.1462, loss-lb:0.0870, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:38:04.377] iteration:12194  t-loss:0.1645, loss-lb:0.1001, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:38:04.568] iteration:12195  t-loss:0.1512, loss-lb:0.0899, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:38:04.760] iteration:12196  t-loss:0.1531, loss-lb:0.0912, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:38:04.954] iteration:12197  t-loss:0.1317, loss-lb:0.0754, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:38:05.146] iteration:12198  t-loss:0.1549, loss-lb:0.0828, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:38:05.342] iteration:12199  t-loss:0.1403, loss-lb:0.0891, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:38:05.547] iteration:12200  t-loss:0.1324, loss-lb:0.0836, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:38:05.746] iteration:12201  t-loss:0.1449, loss-lb:0.0881, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:38:05.941] iteration:12202  t-loss:0.1377, loss-lb:0.0848, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:38:06.134] iteration:12203  t-loss:0.2884, loss-lb:0.0855, loss-ulb:0.1015, weight:2.00, lr:0.0006
[11:38:06.325] iteration:12204  t-loss:0.1406, loss-lb:0.0875, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:38:06.520] iteration:12205  t-loss:0.1357, loss-lb:0.0845, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:38:06.712] iteration:12206  t-loss:0.1482, loss-lb:0.0891, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:38:06.906] iteration:12207  t-loss:0.1361, loss-lb:0.0850, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:38:07.097] iteration:12208  t-loss:0.1481, loss-lb:0.0839, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:38:07.289] iteration:12209  t-loss:0.1697, loss-lb:0.0827, loss-ulb:0.0435, weight:2.00, lr:0.0006
[11:38:07.481] iteration:12210  t-loss:0.1550, loss-lb:0.0921, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:38:07.673] iteration:12211  t-loss:0.1476, loss-lb:0.0874, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:38:07.865] iteration:12212  t-loss:0.1552, loss-lb:0.0824, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:38:08.056] iteration:12213  t-loss:0.1351, loss-lb:0.0759, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:38:08.248] iteration:12214  t-loss:0.1583, loss-lb:0.0862, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:38:08.438] iteration:12215  t-loss:0.1351, loss-lb:0.0828, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:38:08.635] iteration:12216  t-loss:0.1380, loss-lb:0.0794, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:38:08.826] iteration:12217  t-loss:0.1653, loss-lb:0.0999, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:38:09.018] iteration:12218  t-loss:0.1502, loss-lb:0.0921, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:38:09.209] iteration:12219  t-loss:0.1699, loss-lb:0.0993, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:38:09.400] iteration:12220  t-loss:0.1525, loss-lb:0.0909, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:38:09.591] iteration:12221  t-loss:0.1386, loss-lb:0.0780, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:38:09.783] iteration:12222  t-loss:0.1476, loss-lb:0.0884, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:38:09.975] iteration:12223  t-loss:0.1414, loss-lb:0.0880, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:38:10.166] iteration:12224  t-loss:0.1547, loss-lb:0.0917, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:38:10.359] iteration:12225  t-loss:0.1401, loss-lb:0.0837, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:38:10.552] iteration:12226  t-loss:0.1686, loss-lb:0.0938, loss-ulb:0.0374, weight:2.00, lr:0.0006
[11:38:10.744] iteration:12227  t-loss:0.1407, loss-lb:0.0890, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:38:10.940] iteration:12228  t-loss:0.1487, loss-lb:0.0911, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:38:11.134] iteration:12229  t-loss:0.1329, loss-lb:0.0741, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:38:11.329] iteration:12230  t-loss:0.1318, loss-lb:0.0835, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:38:11.523] iteration:12231  t-loss:0.2553, loss-lb:0.0864, loss-ulb:0.0844, weight:2.00, lr:0.0006
[11:38:11.715] iteration:12232  t-loss:0.1349, loss-lb:0.0890, loss-ulb:0.0230, weight:2.00, lr:0.0006
[11:38:11.907] iteration:12233  t-loss:0.1400, loss-lb:0.0804, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:38:12.100] iteration:12234  t-loss:0.1741, loss-lb:0.1040, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:38:12.293] iteration:12235  t-loss:0.1403, loss-lb:0.0862, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:38:12.483] iteration:12236  t-loss:0.1454, loss-lb:0.0827, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:38:12.678] iteration:12237  t-loss:0.1324, loss-lb:0.0830, loss-ulb:0.0247, weight:2.00, lr:0.0006
[11:38:12.870] iteration:12238  t-loss:0.1469, loss-lb:0.0905, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:38:13.060] iteration:12239  t-loss:0.1465, loss-lb:0.0967, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:38:13.253] iteration:12240  t-loss:0.1641, loss-lb:0.0797, loss-ulb:0.0422, weight:2.00, lr:0.0006
[11:38:13.447] iteration:12241  t-loss:0.1759, loss-lb:0.0852, loss-ulb:0.0454, weight:2.00, lr:0.0006
[11:38:13.638] iteration:12242  t-loss:0.1423, loss-lb:0.0866, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:38:13.829] iteration:12243  t-loss:0.1467, loss-lb:0.0876, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:38:14.019] iteration:12244  t-loss:0.1996, loss-lb:0.0950, loss-ulb:0.0523, weight:2.00, lr:0.0006
[11:38:14.211] iteration:12245  t-loss:0.2207, loss-lb:0.0880, loss-ulb:0.0663, weight:2.00, lr:0.0006
[11:38:14.401] iteration:12246  t-loss:0.1504, loss-lb:0.0890, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:38:14.592] iteration:12247  t-loss:0.1434, loss-lb:0.0807, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:38:14.782] iteration:12248  t-loss:0.1380, loss-lb:0.0773, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:38:14.972] iteration:12249  t-loss:0.1289, loss-lb:0.0844, loss-ulb:0.0223, weight:2.00, lr:0.0006
[11:38:15.164] iteration:12250  t-loss:0.2641, loss-lb:0.0930, loss-ulb:0.0855, weight:2.00, lr:0.0006
[11:38:26.696]  <<Test>> - Ep:124  - mean_dice/mean_h95 - S:90.30/1.29, Best-S:90.30, T:90.05/1.34, Best-T:90.48
[11:38:26.696]           - AvgLoss(lb/ulb/all):0.0875/0.0386/0.1645
[11:38:27.215] iteration:12251  t-loss:0.1470, loss-lb:0.0886, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:38:27.410] iteration:12252  t-loss:0.1455, loss-lb:0.0918, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:38:27.602] iteration:12253  t-loss:0.1422, loss-lb:0.0797, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:38:27.794] iteration:12254  t-loss:0.1487, loss-lb:0.0881, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:38:27.987] iteration:12255  t-loss:0.1468, loss-lb:0.0842, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:38:28.179] iteration:12256  t-loss:0.1500, loss-lb:0.0850, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:38:28.372] iteration:12257  t-loss:0.1302, loss-lb:0.0845, loss-ulb:0.0228, weight:2.00, lr:0.0006
[11:38:28.564] iteration:12258  t-loss:0.1832, loss-lb:0.0852, loss-ulb:0.0490, weight:2.00, lr:0.0006
[11:38:28.757] iteration:12259  t-loss:0.1437, loss-lb:0.0888, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:38:28.949] iteration:12260  t-loss:0.1480, loss-lb:0.0855, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:38:29.141] iteration:12261  t-loss:0.1562, loss-lb:0.0903, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:38:29.334] iteration:12262  t-loss:0.1650, loss-lb:0.0906, loss-ulb:0.0372, weight:2.00, lr:0.0006
[11:38:29.526] iteration:12263  t-loss:0.1454, loss-lb:0.0854, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:38:29.717] iteration:12264  t-loss:0.2492, loss-lb:0.0846, loss-ulb:0.0823, weight:2.00, lr:0.0006
[11:38:29.909] iteration:12265  t-loss:0.1377, loss-lb:0.0778, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:38:30.100] iteration:12266  t-loss:0.1404, loss-lb:0.0816, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:38:30.290] iteration:12267  t-loss:0.1642, loss-lb:0.1055, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:38:30.483] iteration:12268  t-loss:0.1553, loss-lb:0.0984, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:38:30.674] iteration:12269  t-loss:0.1489, loss-lb:0.0925, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:38:30.864] iteration:12270  t-loss:0.1394, loss-lb:0.0851, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:38:31.057] iteration:12271  t-loss:0.1446, loss-lb:0.0918, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:38:31.249] iteration:12272  t-loss:0.2110, loss-lb:0.1064, loss-ulb:0.0523, weight:2.00, lr:0.0006
[11:38:31.446] iteration:12273  t-loss:0.1688, loss-lb:0.0932, loss-ulb:0.0378, weight:2.00, lr:0.0006
[11:38:31.637] iteration:12274  t-loss:0.1543, loss-lb:0.0896, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:38:31.829] iteration:12275  t-loss:0.2298, loss-lb:0.1063, loss-ulb:0.0617, weight:2.00, lr:0.0006
[11:38:32.020] iteration:12276  t-loss:0.1463, loss-lb:0.0982, loss-ulb:0.0240, weight:2.00, lr:0.0006
[11:38:32.211] iteration:12277  t-loss:0.1955, loss-lb:0.0926, loss-ulb:0.0515, weight:2.00, lr:0.0006
[11:38:32.402] iteration:12278  t-loss:0.2968, loss-lb:0.0945, loss-ulb:0.1012, weight:2.00, lr:0.0006
[11:38:32.595] iteration:12279  t-loss:0.1929, loss-lb:0.0989, loss-ulb:0.0470, weight:2.00, lr:0.0006
[11:38:32.787] iteration:12280  t-loss:0.1605, loss-lb:0.0921, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:38:32.980] iteration:12281  t-loss:0.1879, loss-lb:0.0973, loss-ulb:0.0453, weight:2.00, lr:0.0006
[11:38:33.171] iteration:12282  t-loss:0.1532, loss-lb:0.0992, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:38:33.363] iteration:12283  t-loss:0.1664, loss-lb:0.0904, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:38:33.555] iteration:12284  t-loss:0.1488, loss-lb:0.0783, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:38:33.748] iteration:12285  t-loss:0.1545, loss-lb:0.0941, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:38:33.940] iteration:12286  t-loss:0.1522, loss-lb:0.0923, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:38:34.133] iteration:12287  t-loss:0.2139, loss-lb:0.0954, loss-ulb:0.0592, weight:2.00, lr:0.0006
[11:38:34.325] iteration:12288  t-loss:0.1553, loss-lb:0.0972, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:38:34.517] iteration:12289  t-loss:0.1488, loss-lb:0.0882, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:38:34.710] iteration:12290  t-loss:0.1596, loss-lb:0.0943, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:38:34.903] iteration:12291  t-loss:0.1548, loss-lb:0.1073, loss-ulb:0.0237, weight:2.00, lr:0.0006
[11:38:35.095] iteration:12292  t-loss:0.1747, loss-lb:0.1012, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:38:35.286] iteration:12293  t-loss:0.1541, loss-lb:0.0959, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:38:35.477] iteration:12294  t-loss:0.1375, loss-lb:0.0806, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:38:35.669] iteration:12295  t-loss:0.1556, loss-lb:0.0886, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:38:35.862] iteration:12296  t-loss:0.1467, loss-lb:0.0840, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:38:36.054] iteration:12297  t-loss:0.2074, loss-lb:0.0918, loss-ulb:0.0578, weight:2.00, lr:0.0006
[11:38:36.245] iteration:12298  t-loss:0.1903, loss-lb:0.0995, loss-ulb:0.0454, weight:2.00, lr:0.0006
[11:38:36.435] iteration:12299  t-loss:0.1721, loss-lb:0.1061, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:38:36.627] iteration:12300  t-loss:0.1440, loss-lb:0.0939, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:38:36.819] iteration:12301  t-loss:0.1577, loss-lb:0.0901, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:38:37.010] iteration:12302  t-loss:0.1468, loss-lb:0.0852, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:38:37.204] iteration:12303  t-loss:0.1561, loss-lb:0.0978, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:38:37.396] iteration:12304  t-loss:0.1545, loss-lb:0.0909, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:38:37.589] iteration:12305  t-loss:0.1765, loss-lb:0.0947, loss-ulb:0.0409, weight:2.00, lr:0.0006
[11:38:37.780] iteration:12306  t-loss:0.1853, loss-lb:0.1242, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:38:37.974] iteration:12307  t-loss:0.1564, loss-lb:0.0922, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:38:38.186] iteration:12308  t-loss:0.1484, loss-lb:0.0873, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:38:38.389] iteration:12309  t-loss:0.1739, loss-lb:0.0949, loss-ulb:0.0395, weight:2.00, lr:0.0006
[11:38:38.588] iteration:12310  t-loss:0.1661, loss-lb:0.0899, loss-ulb:0.0381, weight:2.00, lr:0.0006
[11:38:38.776] iteration:12311  t-loss:0.1393, loss-lb:0.0822, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:38:38.970] iteration:12312  t-loss:0.1479, loss-lb:0.0863, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:38:39.163] iteration:12313  t-loss:0.1684, loss-lb:0.0889, loss-ulb:0.0397, weight:2.00, lr:0.0006
[11:38:39.355] iteration:12314  t-loss:0.1552, loss-lb:0.1023, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:38:39.547] iteration:12315  t-loss:0.1481, loss-lb:0.0916, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:38:39.739] iteration:12316  t-loss:0.1500, loss-lb:0.1009, loss-ulb:0.0245, weight:2.00, lr:0.0006
[11:38:39.931] iteration:12317  t-loss:0.1539, loss-lb:0.1090, loss-ulb:0.0225, weight:2.00, lr:0.0006
[11:38:40.123] iteration:12318  t-loss:0.1632, loss-lb:0.0932, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:38:40.317] iteration:12319  t-loss:0.1643, loss-lb:0.1112, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:38:40.509] iteration:12320  t-loss:0.1664, loss-lb:0.0862, loss-ulb:0.0401, weight:2.00, lr:0.0006
[11:38:40.703] iteration:12321  t-loss:0.1621, loss-lb:0.0906, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:38:40.895] iteration:12322  t-loss:0.1485, loss-lb:0.0948, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:38:41.087] iteration:12323  t-loss:0.1479, loss-lb:0.0940, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:38:41.279] iteration:12324  t-loss:0.1404, loss-lb:0.0850, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:38:41.472] iteration:12325  t-loss:0.1456, loss-lb:0.0819, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:38:41.663] iteration:12326  t-loss:0.1597, loss-lb:0.0993, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:38:41.855] iteration:12327  t-loss:0.1525, loss-lb:0.0937, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:38:42.048] iteration:12328  t-loss:0.1786, loss-lb:0.0895, loss-ulb:0.0445, weight:2.00, lr:0.0006
[11:38:42.240] iteration:12329  t-loss:0.1423, loss-lb:0.0851, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:38:42.432] iteration:12330  t-loss:0.1547, loss-lb:0.0871, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:38:42.624] iteration:12331  t-loss:0.1390, loss-lb:0.0856, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:38:42.818] iteration:12332  t-loss:0.1570, loss-lb:0.0924, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:38:43.011] iteration:12333  t-loss:0.1531, loss-lb:0.0981, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:38:43.203] iteration:12334  t-loss:0.1579, loss-lb:0.0861, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:38:43.395] iteration:12335  t-loss:0.1364, loss-lb:0.0838, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:38:43.588] iteration:12336  t-loss:0.1485, loss-lb:0.0835, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:38:43.781] iteration:12337  t-loss:0.1337, loss-lb:0.0842, loss-ulb:0.0247, weight:2.00, lr:0.0006
[11:38:43.973] iteration:12338  t-loss:0.1687, loss-lb:0.0828, loss-ulb:0.0429, weight:2.00, lr:0.0006
[11:38:44.166] iteration:12339  t-loss:0.1531, loss-lb:0.0856, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:38:44.359] iteration:12340  t-loss:0.2964, loss-lb:0.0936, loss-ulb:0.1014, weight:2.00, lr:0.0006
[11:38:44.550] iteration:12341  t-loss:0.1428, loss-lb:0.0804, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:38:44.742] iteration:12342  t-loss:0.2093, loss-lb:0.0865, loss-ulb:0.0614, weight:2.00, lr:0.0006
[11:38:44.934] iteration:12343  t-loss:0.1507, loss-lb:0.0844, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:38:45.125] iteration:12344  t-loss:0.2059, loss-lb:0.0967, loss-ulb:0.0546, weight:2.00, lr:0.0006
[11:38:45.316] iteration:12345  t-loss:0.1544, loss-lb:0.0873, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:38:45.506] iteration:12346  t-loss:0.1501, loss-lb:0.0949, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:38:45.697] iteration:12347  t-loss:0.1424, loss-lb:0.0848, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:38:45.888] iteration:12348  t-loss:0.1933, loss-lb:0.0952, loss-ulb:0.0490, weight:2.00, lr:0.0006
[11:38:46.514] iteration:12349  t-loss:0.2455, loss-lb:0.0921, loss-ulb:0.0767, weight:2.00, lr:0.0006
[11:38:46.711] iteration:12350  t-loss:0.1773, loss-lb:0.1026, loss-ulb:0.0374, weight:2.00, lr:0.0006
[11:38:46.902] iteration:12351  t-loss:0.1873, loss-lb:0.1135, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:38:47.095] iteration:12352  t-loss:0.1490, loss-lb:0.0966, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:38:47.287] iteration:12353  t-loss:0.1655, loss-lb:0.0866, loss-ulb:0.0395, weight:2.00, lr:0.0006
[11:38:47.479] iteration:12354  t-loss:0.1584, loss-lb:0.0929, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:38:47.672] iteration:12355  t-loss:0.1550, loss-lb:0.0888, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:38:47.864] iteration:12356  t-loss:0.1749, loss-lb:0.0825, loss-ulb:0.0462, weight:2.00, lr:0.0006
[11:38:48.057] iteration:12357  t-loss:0.1914, loss-lb:0.1028, loss-ulb:0.0443, weight:2.00, lr:0.0006
[11:38:48.248] iteration:12358  t-loss:0.1728, loss-lb:0.0895, loss-ulb:0.0416, weight:2.00, lr:0.0006
[11:38:48.441] iteration:12359  t-loss:0.1618, loss-lb:0.0832, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:38:48.634] iteration:12360  t-loss:0.1390, loss-lb:0.0894, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:38:48.826] iteration:12361  t-loss:0.1479, loss-lb:0.0853, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:38:49.018] iteration:12362  t-loss:0.1551, loss-lb:0.0860, loss-ulb:0.0346, weight:2.00, lr:0.0006
[11:38:49.210] iteration:12363  t-loss:0.1641, loss-lb:0.0881, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:38:49.402] iteration:12364  t-loss:0.1519, loss-lb:0.0893, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:38:49.594] iteration:12365  t-loss:0.1981, loss-lb:0.0908, loss-ulb:0.0536, weight:2.00, lr:0.0006
[11:38:49.787] iteration:12366  t-loss:0.1500, loss-lb:0.0909, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:38:49.979] iteration:12367  t-loss:0.1465, loss-lb:0.0970, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:38:50.172] iteration:12368  t-loss:0.1538, loss-lb:0.0911, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:38:50.364] iteration:12369  t-loss:0.1612, loss-lb:0.0862, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:38:50.557] iteration:12370  t-loss:0.2106, loss-lb:0.1020, loss-ulb:0.0543, weight:2.00, lr:0.0006
[11:38:50.749] iteration:12371  t-loss:0.1698, loss-lb:0.1033, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:38:50.941] iteration:12372  t-loss:0.1568, loss-lb:0.0774, loss-ulb:0.0397, weight:2.00, lr:0.0006
[11:38:51.135] iteration:12373  t-loss:0.1446, loss-lb:0.0831, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:38:51.330] iteration:12374  t-loss:0.2336, loss-lb:0.0947, loss-ulb:0.0695, weight:2.00, lr:0.0006
[11:38:51.522] iteration:12375  t-loss:0.1485, loss-lb:0.0921, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:38:51.714] iteration:12376  t-loss:0.1375, loss-lb:0.0809, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:38:51.906] iteration:12377  t-loss:0.1673, loss-lb:0.1124, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:38:52.099] iteration:12378  t-loss:0.1517, loss-lb:0.1045, loss-ulb:0.0236, weight:2.00, lr:0.0006
[11:38:52.291] iteration:12379  t-loss:0.1501, loss-lb:0.0839, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:38:52.484] iteration:12380  t-loss:0.1573, loss-lb:0.0929, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:38:52.677] iteration:12381  t-loss:0.2079, loss-lb:0.0863, loss-ulb:0.0608, weight:2.00, lr:0.0006
[11:38:52.869] iteration:12382  t-loss:0.1357, loss-lb:0.0844, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:38:53.062] iteration:12383  t-loss:0.1349, loss-lb:0.0885, loss-ulb:0.0232, weight:2.00, lr:0.0006
[11:38:53.254] iteration:12384  t-loss:0.1568, loss-lb:0.0985, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:38:53.445] iteration:12385  t-loss:0.1396, loss-lb:0.0890, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:38:53.640] iteration:12386  t-loss:0.1377, loss-lb:0.0826, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:38:53.831] iteration:12387  t-loss:0.1716, loss-lb:0.0935, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:38:54.023] iteration:12388  t-loss:0.1488, loss-lb:0.0847, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:38:54.216] iteration:12389  t-loss:0.1437, loss-lb:0.0876, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:38:54.409] iteration:12390  t-loss:0.1615, loss-lb:0.0915, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:38:54.603] iteration:12391  t-loss:0.2010, loss-lb:0.0944, loss-ulb:0.0533, weight:2.00, lr:0.0006
[11:38:54.795] iteration:12392  t-loss:0.1339, loss-lb:0.0779, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:38:54.988] iteration:12393  t-loss:0.1456, loss-lb:0.0806, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:38:55.180] iteration:12394  t-loss:0.1435, loss-lb:0.0862, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:38:55.373] iteration:12395  t-loss:0.1355, loss-lb:0.0799, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:38:55.566] iteration:12396  t-loss:0.1428, loss-lb:0.0879, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:38:55.758] iteration:12397  t-loss:0.1504, loss-lb:0.0862, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:38:55.950] iteration:12398  t-loss:0.1493, loss-lb:0.0824, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:38:56.142] iteration:12399  t-loss:0.1448, loss-lb:0.0901, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:38:56.336] iteration:12400  t-loss:0.2035, loss-lb:0.0848, loss-ulb:0.0594, weight:2.00, lr:0.0006
[11:38:56.527] iteration:12401  t-loss:0.1481, loss-lb:0.0858, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:38:56.719] iteration:12402  t-loss:0.1414, loss-lb:0.0855, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:38:56.912] iteration:12403  t-loss:0.1625, loss-lb:0.0839, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:38:57.104] iteration:12404  t-loss:0.1501, loss-lb:0.0895, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:38:57.295] iteration:12405  t-loss:0.1413, loss-lb:0.0836, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:38:57.489] iteration:12406  t-loss:0.1587, loss-lb:0.0860, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:38:57.682] iteration:12407  t-loss:0.2129, loss-lb:0.0861, loss-ulb:0.0634, weight:2.00, lr:0.0006
[11:38:57.873] iteration:12408  t-loss:0.1606, loss-lb:0.0848, loss-ulb:0.0379, weight:2.00, lr:0.0006
[11:38:58.065] iteration:12409  t-loss:0.1378, loss-lb:0.0847, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:38:58.258] iteration:12410  t-loss:0.1266, loss-lb:0.0809, loss-ulb:0.0228, weight:2.00, lr:0.0006
[11:38:58.451] iteration:12411  t-loss:0.1364, loss-lb:0.0911, loss-ulb:0.0227, weight:2.00, lr:0.0006
[11:38:58.643] iteration:12412  t-loss:0.1433, loss-lb:0.0866, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:38:58.834] iteration:12413  t-loss:0.1344, loss-lb:0.0829, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:38:59.027] iteration:12414  t-loss:0.1421, loss-lb:0.0819, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:38:59.219] iteration:12415  t-loss:0.1402, loss-lb:0.0895, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:38:59.412] iteration:12416  t-loss:0.1982, loss-lb:0.0977, loss-ulb:0.0503, weight:2.00, lr:0.0006
[11:38:59.604] iteration:12417  t-loss:0.1410, loss-lb:0.0880, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:38:59.799] iteration:12418  t-loss:0.1387, loss-lb:0.0760, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:38:59.992] iteration:12419  t-loss:0.1366, loss-lb:0.0829, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:39:00.183] iteration:12420  t-loss:0.1419, loss-lb:0.0856, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:39:00.376] iteration:12421  t-loss:0.1448, loss-lb:0.0824, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:39:00.569] iteration:12422  t-loss:0.1526, loss-lb:0.0912, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:39:00.760] iteration:12423  t-loss:0.1370, loss-lb:0.0914, loss-ulb:0.0228, weight:2.00, lr:0.0006
[11:39:00.952] iteration:12424  t-loss:0.1520, loss-lb:0.0922, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:39:01.146] iteration:12425  t-loss:0.2747, loss-lb:0.0792, loss-ulb:0.0977, weight:2.00, lr:0.0006
[11:39:01.337] iteration:12426  t-loss:0.1517, loss-lb:0.0930, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:39:01.530] iteration:12427  t-loss:0.1397, loss-lb:0.0894, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:39:01.723] iteration:12428  t-loss:0.1430, loss-lb:0.0839, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:39:01.915] iteration:12429  t-loss:0.1499, loss-lb:0.0825, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:39:02.106] iteration:12430  t-loss:0.1834, loss-lb:0.0897, loss-ulb:0.0469, weight:2.00, lr:0.0006
[11:39:02.300] iteration:12431  t-loss:0.1556, loss-lb:0.0827, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:39:02.493] iteration:12432  t-loss:0.1469, loss-lb:0.0781, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:39:02.685] iteration:12433  t-loss:0.1407, loss-lb:0.0814, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:39:02.877] iteration:12434  t-loss:0.1324, loss-lb:0.0785, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:39:03.070] iteration:12435  t-loss:0.1298, loss-lb:0.0810, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:39:03.262] iteration:12436  t-loss:0.1586, loss-lb:0.0883, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:39:03.455] iteration:12437  t-loss:0.1459, loss-lb:0.0913, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:39:03.649] iteration:12438  t-loss:0.1823, loss-lb:0.0932, loss-ulb:0.0446, weight:2.00, lr:0.0006
[11:39:03.841] iteration:12439  t-loss:0.1389, loss-lb:0.0852, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:39:04.031] iteration:12440  t-loss:0.2229, loss-lb:0.0846, loss-ulb:0.0691, weight:2.00, lr:0.0006
[11:39:04.222] iteration:12441  t-loss:0.1455, loss-lb:0.0877, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:39:04.413] iteration:12442  t-loss:0.1461, loss-lb:0.0870, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:39:04.603] iteration:12443  t-loss:0.1410, loss-lb:0.0850, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:39:04.795] iteration:12444  t-loss:0.2259, loss-lb:0.0878, loss-ulb:0.0690, weight:2.00, lr:0.0006
[11:39:04.985] iteration:12445  t-loss:0.1321, loss-lb:0.0824, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:39:05.177] iteration:12446  t-loss:0.1416, loss-lb:0.0862, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:39:17.435]  <<Test>> - Ep:126  - mean_dice/mean_h95 - S:88.48/6.66, Best-S:90.30, T:90.04/1.29, Best-T:90.48
[11:39:17.436]           - AvgLoss(lb/ulb/all):0.0881/0.0349/0.1551
[11:39:17.969] iteration:12447  t-loss:0.1895, loss-lb:0.0890, loss-ulb:0.0502, weight:2.00, lr:0.0006
[11:39:18.168] iteration:12448  t-loss:0.1889, loss-lb:0.0840, loss-ulb:0.0524, weight:2.00, lr:0.0006
[11:39:18.361] iteration:12449  t-loss:0.1272, loss-lb:0.0748, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:39:18.554] iteration:12450  t-loss:0.1336, loss-lb:0.0823, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:39:18.748] iteration:12451  t-loss:0.2188, loss-lb:0.0998, loss-ulb:0.0595, weight:2.00, lr:0.0006
[11:39:18.940] iteration:12452  t-loss:0.1431, loss-lb:0.0867, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:39:19.134] iteration:12453  t-loss:0.1595, loss-lb:0.0958, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:39:19.327] iteration:12454  t-loss:0.1896, loss-lb:0.1010, loss-ulb:0.0443, weight:2.00, lr:0.0006
[11:39:19.519] iteration:12455  t-loss:0.1444, loss-lb:0.0838, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:39:19.712] iteration:12456  t-loss:0.1489, loss-lb:0.0935, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:39:19.906] iteration:12457  t-loss:0.1610, loss-lb:0.0926, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:39:20.101] iteration:12458  t-loss:0.1638, loss-lb:0.0958, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:39:20.294] iteration:12459  t-loss:0.1793, loss-lb:0.0840, loss-ulb:0.0477, weight:2.00, lr:0.0006
[11:39:20.486] iteration:12460  t-loss:0.1439, loss-lb:0.0896, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:39:20.680] iteration:12461  t-loss:0.1570, loss-lb:0.0921, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:39:20.875] iteration:12462  t-loss:0.2062, loss-lb:0.0824, loss-ulb:0.0619, weight:2.00, lr:0.0006
[11:39:21.067] iteration:12463  t-loss:0.1810, loss-lb:0.0990, loss-ulb:0.0410, weight:2.00, lr:0.0006
[11:39:21.260] iteration:12464  t-loss:0.1780, loss-lb:0.1062, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:39:21.453] iteration:12465  t-loss:0.1463, loss-lb:0.0920, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:39:21.644] iteration:12466  t-loss:0.1712, loss-lb:0.0801, loss-ulb:0.0455, weight:2.00, lr:0.0006
[11:39:21.836] iteration:12467  t-loss:0.1692, loss-lb:0.0832, loss-ulb:0.0430, weight:2.00, lr:0.0006
[11:39:22.028] iteration:12468  t-loss:0.1580, loss-lb:0.0944, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:39:22.220] iteration:12469  t-loss:0.1402, loss-lb:0.0890, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:39:22.418] iteration:12470  t-loss:0.1776, loss-lb:0.0763, loss-ulb:0.0506, weight:2.00, lr:0.0006
[11:39:22.611] iteration:12471  t-loss:0.1572, loss-lb:0.0946, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:39:22.805] iteration:12472  t-loss:0.1636, loss-lb:0.0949, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:39:22.997] iteration:12473  t-loss:0.1719, loss-lb:0.1035, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:39:23.189] iteration:12474  t-loss:0.1563, loss-lb:0.0947, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:39:23.381] iteration:12475  t-loss:0.1420, loss-lb:0.0890, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:39:23.573] iteration:12476  t-loss:0.1561, loss-lb:0.1004, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:39:23.765] iteration:12477  t-loss:0.1485, loss-lb:0.0843, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:39:23.957] iteration:12478  t-loss:0.1497, loss-lb:0.0945, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:39:24.150] iteration:12479  t-loss:0.1861, loss-lb:0.0829, loss-ulb:0.0516, weight:2.00, lr:0.0006
[11:39:24.343] iteration:12480  t-loss:0.1574, loss-lb:0.0945, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:39:24.534] iteration:12481  t-loss:0.1967, loss-lb:0.0890, loss-ulb:0.0539, weight:2.00, lr:0.0006
[11:39:24.726] iteration:12482  t-loss:0.1662, loss-lb:0.0858, loss-ulb:0.0402, weight:2.00, lr:0.0006
[11:39:24.918] iteration:12483  t-loss:0.1491, loss-lb:0.0871, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:39:25.110] iteration:12484  t-loss:0.3502, loss-lb:0.0921, loss-ulb:0.1291, weight:2.00, lr:0.0006
[11:39:25.303] iteration:12485  t-loss:0.1512, loss-lb:0.0895, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:39:25.494] iteration:12486  t-loss:0.1445, loss-lb:0.0874, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:39:25.687] iteration:12487  t-loss:0.1621, loss-lb:0.0985, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:39:25.879] iteration:12488  t-loss:0.1538, loss-lb:0.0987, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:39:26.071] iteration:12489  t-loss:0.1640, loss-lb:0.0918, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:39:26.263] iteration:12490  t-loss:0.1798, loss-lb:0.0836, loss-ulb:0.0481, weight:2.00, lr:0.0006
[11:39:26.455] iteration:12491  t-loss:0.1705, loss-lb:0.0920, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:39:26.646] iteration:12492  t-loss:0.1560, loss-lb:0.0956, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:39:26.839] iteration:12493  t-loss:0.1504, loss-lb:0.0835, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:39:27.031] iteration:12494  t-loss:0.1501, loss-lb:0.0880, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:39:27.222] iteration:12495  t-loss:0.1547, loss-lb:0.0953, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:39:27.415] iteration:12496  t-loss:0.1518, loss-lb:0.1007, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:39:27.608] iteration:12497  t-loss:0.1452, loss-lb:0.0888, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:39:27.800] iteration:12498  t-loss:0.1770, loss-lb:0.0899, loss-ulb:0.0435, weight:2.00, lr:0.0006
[11:39:27.992] iteration:12499  t-loss:0.1603, loss-lb:0.0915, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:39:28.185] iteration:12500  t-loss:0.1484, loss-lb:0.0792, loss-ulb:0.0346, weight:2.00, lr:0.0006
[11:39:28.376] iteration:12501  t-loss:0.1529, loss-lb:0.0874, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:39:28.570] iteration:12502  t-loss:0.1521, loss-lb:0.0922, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:39:28.763] iteration:12503  t-loss:0.1475, loss-lb:0.0899, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:39:28.956] iteration:12504  t-loss:0.1464, loss-lb:0.0891, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:39:29.147] iteration:12505  t-loss:0.1521, loss-lb:0.0911, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:39:29.339] iteration:12506  t-loss:0.1660, loss-lb:0.0884, loss-ulb:0.0388, weight:2.00, lr:0.0006
[11:39:29.534] iteration:12507  t-loss:0.1648, loss-lb:0.0884, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:39:29.725] iteration:12508  t-loss:0.1670, loss-lb:0.0803, loss-ulb:0.0434, weight:2.00, lr:0.0006
[11:39:29.918] iteration:12509  t-loss:0.1628, loss-lb:0.0831, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:39:30.109] iteration:12510  t-loss:0.1484, loss-lb:0.0954, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:39:30.301] iteration:12511  t-loss:0.1566, loss-lb:0.0991, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:39:30.493] iteration:12512  t-loss:0.1614, loss-lb:0.0965, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:39:30.684] iteration:12513  t-loss:0.1405, loss-lb:0.0855, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:39:30.876] iteration:12514  t-loss:0.1514, loss-lb:0.0944, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:39:31.068] iteration:12515  t-loss:0.1533, loss-lb:0.0941, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:39:31.260] iteration:12516  t-loss:0.1573, loss-lb:0.0874, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:39:31.451] iteration:12517  t-loss:0.1396, loss-lb:0.0809, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:39:31.642] iteration:12518  t-loss:0.1516, loss-lb:0.0939, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:39:31.833] iteration:12519  t-loss:0.1431, loss-lb:0.0824, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:39:32.024] iteration:12520  t-loss:0.1390, loss-lb:0.0826, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:39:32.215] iteration:12521  t-loss:0.1468, loss-lb:0.0973, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:39:32.406] iteration:12522  t-loss:0.1436, loss-lb:0.0855, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:39:32.599] iteration:12523  t-loss:0.1394, loss-lb:0.0872, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:39:32.791] iteration:12524  t-loss:0.1464, loss-lb:0.0840, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:39:32.985] iteration:12525  t-loss:0.1481, loss-lb:0.0877, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:39:33.179] iteration:12526  t-loss:0.1420, loss-lb:0.0868, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:39:33.373] iteration:12527  t-loss:0.1373, loss-lb:0.0790, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:39:33.567] iteration:12528  t-loss:0.1495, loss-lb:0.0974, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:39:33.760] iteration:12529  t-loss:0.1410, loss-lb:0.0881, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:39:33.953] iteration:12530  t-loss:0.1362, loss-lb:0.0847, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:39:34.145] iteration:12531  t-loss:0.1404, loss-lb:0.0797, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:39:34.337] iteration:12532  t-loss:0.1450, loss-lb:0.0791, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:39:34.529] iteration:12533  t-loss:0.1564, loss-lb:0.0829, loss-ulb:0.0367, weight:2.00, lr:0.0006
[11:39:34.720] iteration:12534  t-loss:0.1493, loss-lb:0.0856, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:39:34.911] iteration:12535  t-loss:0.1372, loss-lb:0.0884, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:39:35.104] iteration:12536  t-loss:0.1302, loss-lb:0.0825, loss-ulb:0.0238, weight:2.00, lr:0.0006
[11:39:35.294] iteration:12537  t-loss:0.1358, loss-lb:0.0816, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:39:35.485] iteration:12538  t-loss:0.1397, loss-lb:0.0870, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:39:35.675] iteration:12539  t-loss:0.1771, loss-lb:0.0815, loss-ulb:0.0478, weight:2.00, lr:0.0006
[11:39:35.867] iteration:12540  t-loss:0.1368, loss-lb:0.0884, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:39:36.057] iteration:12541  t-loss:0.1555, loss-lb:0.0970, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:39:36.248] iteration:12542  t-loss:0.1539, loss-lb:0.0826, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:39:36.438] iteration:12543  t-loss:0.1587, loss-lb:0.0838, loss-ulb:0.0374, weight:2.00, lr:0.0006
[11:39:36.628] iteration:12544  t-loss:0.1396, loss-lb:0.0777, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:39:37.270] iteration:12545  t-loss:0.1420, loss-lb:0.0878, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:39:37.465] iteration:12546  t-loss:0.1333, loss-lb:0.0853, loss-ulb:0.0240, weight:2.00, lr:0.0006
[11:39:37.655] iteration:12547  t-loss:0.1568, loss-lb:0.0808, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:39:37.847] iteration:12548  t-loss:0.1406, loss-lb:0.0817, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:39:38.040] iteration:12549  t-loss:0.1306, loss-lb:0.0824, loss-ulb:0.0241, weight:2.00, lr:0.0006
[11:39:38.231] iteration:12550  t-loss:0.1372, loss-lb:0.0829, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:39:38.425] iteration:12551  t-loss:0.1403, loss-lb:0.0800, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:39:38.617] iteration:12552  t-loss:0.1404, loss-lb:0.0872, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:39:38.808] iteration:12553  t-loss:0.1520, loss-lb:0.1001, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:39:38.999] iteration:12554  t-loss:0.1373, loss-lb:0.0810, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:39:39.192] iteration:12555  t-loss:0.1464, loss-lb:0.0874, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:39:39.384] iteration:12556  t-loss:0.1480, loss-lb:0.0978, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:39:39.577] iteration:12557  t-loss:0.1869, loss-lb:0.0888, loss-ulb:0.0491, weight:2.00, lr:0.0006
[11:39:39.769] iteration:12558  t-loss:0.1692, loss-lb:0.0832, loss-ulb:0.0430, weight:2.00, lr:0.0006
[11:39:39.961] iteration:12559  t-loss:0.1433, loss-lb:0.0824, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:39:40.153] iteration:12560  t-loss:0.1583, loss-lb:0.0815, loss-ulb:0.0384, weight:2.00, lr:0.0006
[11:39:40.346] iteration:12561  t-loss:0.1369, loss-lb:0.0842, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:39:40.538] iteration:12562  t-loss:0.1763, loss-lb:0.0997, loss-ulb:0.0383, weight:2.00, lr:0.0006
[11:39:40.730] iteration:12563  t-loss:0.1336, loss-lb:0.0826, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:39:40.923] iteration:12564  t-loss:0.1487, loss-lb:0.0834, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:39:41.114] iteration:12565  t-loss:0.1355, loss-lb:0.0806, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:39:41.306] iteration:12566  t-loss:0.1359, loss-lb:0.0796, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:39:41.498] iteration:12567  t-loss:0.1454, loss-lb:0.0993, loss-ulb:0.0231, weight:2.00, lr:0.0006
[11:39:41.690] iteration:12568  t-loss:0.1387, loss-lb:0.0840, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:39:41.881] iteration:12569  t-loss:0.1324, loss-lb:0.0791, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:39:42.071] iteration:12570  t-loss:0.1482, loss-lb:0.0950, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:39:42.263] iteration:12571  t-loss:0.1412, loss-lb:0.0837, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:39:42.454] iteration:12572  t-loss:0.1381, loss-lb:0.0854, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:39:42.645] iteration:12573  t-loss:0.1650, loss-lb:0.0831, loss-ulb:0.0410, weight:2.00, lr:0.0006
[11:39:42.837] iteration:12574  t-loss:0.1419, loss-lb:0.0863, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:39:43.029] iteration:12575  t-loss:0.1418, loss-lb:0.0864, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:39:43.220] iteration:12576  t-loss:0.1629, loss-lb:0.0889, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:39:43.412] iteration:12577  t-loss:0.1350, loss-lb:0.0880, loss-ulb:0.0235, weight:2.00, lr:0.0006
[11:39:43.605] iteration:12578  t-loss:0.1389, loss-lb:0.0861, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:39:43.817] iteration:12579  t-loss:0.1412, loss-lb:0.0781, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:39:44.017] iteration:12580  t-loss:0.1590, loss-lb:0.0804, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:39:44.211] iteration:12581  t-loss:0.1391, loss-lb:0.0832, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:39:44.406] iteration:12582  t-loss:0.1896, loss-lb:0.0880, loss-ulb:0.0508, weight:2.00, lr:0.0006
[11:39:44.598] iteration:12583  t-loss:0.1530, loss-lb:0.0878, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:39:44.791] iteration:12584  t-loss:0.1380, loss-lb:0.0834, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:39:44.982] iteration:12585  t-loss:0.1394, loss-lb:0.0851, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:39:45.176] iteration:12586  t-loss:0.1940, loss-lb:0.0870, loss-ulb:0.0535, weight:2.00, lr:0.0006
[11:39:45.368] iteration:12587  t-loss:0.1581, loss-lb:0.0917, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:39:45.559] iteration:12588  t-loss:0.1597, loss-lb:0.1019, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:39:45.751] iteration:12589  t-loss:0.1308, loss-lb:0.0805, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:39:45.943] iteration:12590  t-loss:0.1446, loss-lb:0.0850, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:39:46.136] iteration:12591  t-loss:0.1688, loss-lb:0.0844, loss-ulb:0.0422, weight:2.00, lr:0.0006
[11:39:46.328] iteration:12592  t-loss:0.1428, loss-lb:0.0738, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:39:46.520] iteration:12593  t-loss:0.1635, loss-lb:0.0849, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:39:46.712] iteration:12594  t-loss:0.1431, loss-lb:0.0940, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:39:46.903] iteration:12595  t-loss:0.1520, loss-lb:0.0946, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:39:47.097] iteration:12596  t-loss:0.1888, loss-lb:0.0868, loss-ulb:0.0510, weight:2.00, lr:0.0006
[11:39:47.288] iteration:12597  t-loss:0.1995, loss-lb:0.1438, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:39:47.479] iteration:12598  t-loss:0.1818, loss-lb:0.0897, loss-ulb:0.0460, weight:2.00, lr:0.0006
[11:39:47.672] iteration:12599  t-loss:0.1303, loss-lb:0.0824, loss-ulb:0.0240, weight:2.00, lr:0.0006
[11:39:47.863] iteration:12600  t-loss:0.1402, loss-lb:0.0811, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:39:48.055] iteration:12601  t-loss:0.1688, loss-lb:0.0964, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:39:48.248] iteration:12602  t-loss:0.1921, loss-lb:0.0900, loss-ulb:0.0511, weight:2.00, lr:0.0006
[11:39:48.441] iteration:12603  t-loss:0.1542, loss-lb:0.0933, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:39:48.633] iteration:12604  t-loss:0.1424, loss-lb:0.0820, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:39:48.826] iteration:12605  t-loss:0.1500, loss-lb:0.0831, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:39:49.018] iteration:12606  t-loss:0.1616, loss-lb:0.0942, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:39:49.209] iteration:12607  t-loss:0.1284, loss-lb:0.0769, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:39:49.403] iteration:12608  t-loss:0.1366, loss-lb:0.0842, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:39:49.595] iteration:12609  t-loss:0.1515, loss-lb:0.0938, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:39:49.786] iteration:12610  t-loss:0.1439, loss-lb:0.0774, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:39:49.978] iteration:12611  t-loss:0.1503, loss-lb:0.0902, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:39:50.170] iteration:12612  t-loss:0.1550, loss-lb:0.0893, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:39:50.362] iteration:12613  t-loss:0.1451, loss-lb:0.0831, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:39:50.555] iteration:12614  t-loss:0.1316, loss-lb:0.0814, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:39:50.747] iteration:12615  t-loss:0.1400, loss-lb:0.0858, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:39:50.940] iteration:12616  t-loss:0.1711, loss-lb:0.0829, loss-ulb:0.0441, weight:2.00, lr:0.0006
[11:39:51.132] iteration:12617  t-loss:0.1341, loss-lb:0.0798, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:39:51.323] iteration:12618  t-loss:0.1442, loss-lb:0.0910, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:39:51.516] iteration:12619  t-loss:0.1592, loss-lb:0.0946, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:39:51.708] iteration:12620  t-loss:0.1533, loss-lb:0.0911, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:39:51.901] iteration:12621  t-loss:0.1433, loss-lb:0.0908, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:39:52.092] iteration:12622  t-loss:0.1571, loss-lb:0.0891, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:39:52.283] iteration:12623  t-loss:0.1435, loss-lb:0.0872, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:39:52.475] iteration:12624  t-loss:0.1418, loss-lb:0.0894, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:39:52.667] iteration:12625  t-loss:0.1601, loss-lb:0.0993, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:39:52.858] iteration:12626  t-loss:0.1407, loss-lb:0.0852, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:39:53.050] iteration:12627  t-loss:0.1908, loss-lb:0.0865, loss-ulb:0.0522, weight:2.00, lr:0.0006
[11:39:53.241] iteration:12628  t-loss:0.1483, loss-lb:0.0840, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:39:53.433] iteration:12629  t-loss:0.1514, loss-lb:0.0776, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:39:53.625] iteration:12630  t-loss:0.1436, loss-lb:0.0835, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:39:53.817] iteration:12631  t-loss:0.1429, loss-lb:0.0888, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:39:54.008] iteration:12632  t-loss:0.1329, loss-lb:0.0839, loss-ulb:0.0245, weight:2.00, lr:0.0006
[11:39:54.200] iteration:12633  t-loss:0.1290, loss-lb:0.0782, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:39:54.391] iteration:12634  t-loss:0.1405, loss-lb:0.0808, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:39:54.582] iteration:12635  t-loss:0.1394, loss-lb:0.0850, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:39:54.773] iteration:12636  t-loss:0.1527, loss-lb:0.0942, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:39:54.966] iteration:12637  t-loss:0.1532, loss-lb:0.0848, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:39:55.160] iteration:12638  t-loss:0.1669, loss-lb:0.0954, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:39:55.354] iteration:12639  t-loss:0.1857, loss-lb:0.0833, loss-ulb:0.0512, weight:2.00, lr:0.0006
[11:39:55.547] iteration:12640  t-loss:0.1769, loss-lb:0.0925, loss-ulb:0.0422, weight:2.00, lr:0.0006
[11:39:55.737] iteration:12641  t-loss:0.1277, loss-lb:0.0746, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:39:55.929] iteration:12642  t-loss:0.1314, loss-lb:0.0782, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:40:07.217]  <<Test>> - Ep:128  - mean_dice/mean_h95 - S:89.03/4.28, Best-S:90.30, T:89.97/1.35, Best-T:90.48
[11:40:07.217]           - AvgLoss(lb/ulb/all):0.0868/0.0322/0.1500
[11:40:07.763] iteration:12643  t-loss:0.1438, loss-lb:0.0843, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:40:07.961] iteration:12644  t-loss:0.1521, loss-lb:0.0879, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:40:08.154] iteration:12645  t-loss:0.1392, loss-lb:0.0769, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:40:08.347] iteration:12646  t-loss:0.1331, loss-lb:0.0848, loss-ulb:0.0241, weight:2.00, lr:0.0006
[11:40:08.540] iteration:12647  t-loss:0.1380, loss-lb:0.0888, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:40:08.732] iteration:12648  t-loss:0.1394, loss-lb:0.0876, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:40:08.925] iteration:12649  t-loss:0.1379, loss-lb:0.0881, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:40:09.120] iteration:12650  t-loss:0.1730, loss-lb:0.0905, loss-ulb:0.0413, weight:2.00, lr:0.0006
[11:40:09.312] iteration:12651  t-loss:0.1940, loss-lb:0.0905, loss-ulb:0.0518, weight:2.00, lr:0.0006
[11:40:09.504] iteration:12652  t-loss:0.1563, loss-lb:0.0917, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:40:09.697] iteration:12653  t-loss:0.1618, loss-lb:0.0858, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:40:09.891] iteration:12654  t-loss:0.1544, loss-lb:0.0960, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:40:10.085] iteration:12655  t-loss:0.2032, loss-lb:0.0942, loss-ulb:0.0545, weight:2.00, lr:0.0006
[11:40:10.279] iteration:12656  t-loss:0.2928, loss-lb:0.0954, loss-ulb:0.0987, weight:2.00, lr:0.0006
[11:40:10.472] iteration:12657  t-loss:0.1508, loss-lb:0.0862, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:40:10.665] iteration:12658  t-loss:0.1986, loss-lb:0.0908, loss-ulb:0.0539, weight:2.00, lr:0.0006
[11:40:10.857] iteration:12659  t-loss:0.1531, loss-lb:0.0950, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:40:11.049] iteration:12660  t-loss:0.2142, loss-lb:0.0984, loss-ulb:0.0579, weight:2.00, lr:0.0006
[11:40:11.242] iteration:12661  t-loss:0.1455, loss-lb:0.0934, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:40:11.434] iteration:12662  t-loss:0.1573, loss-lb:0.0918, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:40:11.628] iteration:12663  t-loss:0.1519, loss-lb:0.0911, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:40:11.820] iteration:12664  t-loss:0.1811, loss-lb:0.0896, loss-ulb:0.0458, weight:2.00, lr:0.0006
[11:40:12.013] iteration:12665  t-loss:0.1542, loss-lb:0.0913, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:40:12.204] iteration:12666  t-loss:0.1664, loss-lb:0.0945, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:40:12.396] iteration:12667  t-loss:0.1638, loss-lb:0.0973, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:40:12.588] iteration:12668  t-loss:0.1499, loss-lb:0.0851, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:40:12.781] iteration:12669  t-loss:0.2086, loss-lb:0.0841, loss-ulb:0.0623, weight:2.00, lr:0.0006
[11:40:12.973] iteration:12670  t-loss:0.1439, loss-lb:0.0818, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:40:13.166] iteration:12671  t-loss:0.1843, loss-lb:0.0977, loss-ulb:0.0433, weight:2.00, lr:0.0006
[11:40:13.359] iteration:12672  t-loss:0.1489, loss-lb:0.0921, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:40:13.551] iteration:12673  t-loss:0.1647, loss-lb:0.0917, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:40:13.743] iteration:12674  t-loss:0.1704, loss-lb:0.1035, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:40:13.935] iteration:12675  t-loss:0.1781, loss-lb:0.1175, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:40:14.128] iteration:12676  t-loss:0.1412, loss-lb:0.0808, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:40:14.321] iteration:12677  t-loss:0.1449, loss-lb:0.0867, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:40:14.513] iteration:12678  t-loss:0.1606, loss-lb:0.0935, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:40:14.707] iteration:12679  t-loss:0.1522, loss-lb:0.0944, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:40:14.900] iteration:12680  t-loss:0.1523, loss-lb:0.0873, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:40:15.092] iteration:12681  t-loss:0.1481, loss-lb:0.0965, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:40:15.284] iteration:12682  t-loss:0.1440, loss-lb:0.0887, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:40:15.478] iteration:12683  t-loss:0.1654, loss-lb:0.0948, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:40:15.671] iteration:12684  t-loss:0.2214, loss-lb:0.0829, loss-ulb:0.0692, weight:2.00, lr:0.0006
[11:40:15.863] iteration:12685  t-loss:0.1525, loss-lb:0.0913, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:40:16.055] iteration:12686  t-loss:0.1455, loss-lb:0.0851, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:40:16.249] iteration:12687  t-loss:0.1515, loss-lb:0.0844, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:40:16.449] iteration:12688  t-loss:0.1512, loss-lb:0.0798, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:40:16.653] iteration:12689  t-loss:0.1479, loss-lb:0.0903, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:40:16.851] iteration:12690  t-loss:0.1419, loss-lb:0.0767, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:40:17.043] iteration:12691  t-loss:0.1611, loss-lb:0.0916, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:40:17.237] iteration:12692  t-loss:0.1969, loss-lb:0.0781, loss-ulb:0.0594, weight:2.00, lr:0.0006
[11:40:17.429] iteration:12693  t-loss:0.1720, loss-lb:0.0832, loss-ulb:0.0444, weight:2.00, lr:0.0006
[11:40:17.622] iteration:12694  t-loss:0.1487, loss-lb:0.0943, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:40:17.814] iteration:12695  t-loss:0.1562, loss-lb:0.0853, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:40:18.006] iteration:12696  t-loss:0.1454, loss-lb:0.0873, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:40:18.198] iteration:12697  t-loss:0.1599, loss-lb:0.0894, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:40:18.391] iteration:12698  t-loss:0.1583, loss-lb:0.0956, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:40:18.583] iteration:12699  t-loss:0.1471, loss-lb:0.0887, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:40:18.776] iteration:12700  t-loss:0.1406, loss-lb:0.0842, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:40:18.969] iteration:12701  t-loss:0.1425, loss-lb:0.0903, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:40:19.162] iteration:12702  t-loss:0.1405, loss-lb:0.0908, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:40:19.355] iteration:12703  t-loss:0.1410, loss-lb:0.0800, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:40:19.547] iteration:12704  t-loss:0.2178, loss-lb:0.0873, loss-ulb:0.0652, weight:2.00, lr:0.0006
[11:40:19.739] iteration:12705  t-loss:0.1573, loss-lb:0.0886, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:40:19.933] iteration:12706  t-loss:0.1381, loss-lb:0.0830, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:40:20.125] iteration:12707  t-loss:0.1768, loss-lb:0.1024, loss-ulb:0.0372, weight:2.00, lr:0.0006
[11:40:20.317] iteration:12708  t-loss:0.1584, loss-lb:0.0813, loss-ulb:0.0386, weight:2.00, lr:0.0006
[11:40:20.510] iteration:12709  t-loss:0.1586, loss-lb:0.0972, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:40:20.702] iteration:12710  t-loss:0.1500, loss-lb:0.0790, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:40:20.894] iteration:12711  t-loss:0.1368, loss-lb:0.0794, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:40:21.087] iteration:12712  t-loss:0.1494, loss-lb:0.0889, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:40:21.279] iteration:12713  t-loss:0.1508, loss-lb:0.0893, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:40:21.471] iteration:12714  t-loss:0.1380, loss-lb:0.0834, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:40:21.664] iteration:12715  t-loss:0.1446, loss-lb:0.0848, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:40:21.857] iteration:12716  t-loss:0.2000, loss-lb:0.0793, loss-ulb:0.0603, weight:2.00, lr:0.0006
[11:40:22.049] iteration:12717  t-loss:0.1462, loss-lb:0.0904, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:40:22.241] iteration:12718  t-loss:0.1532, loss-lb:0.0949, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:40:22.434] iteration:12719  t-loss:0.1776, loss-lb:0.0931, loss-ulb:0.0423, weight:2.00, lr:0.0006
[11:40:22.627] iteration:12720  t-loss:0.1495, loss-lb:0.0907, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:40:22.818] iteration:12721  t-loss:0.1456, loss-lb:0.0936, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:40:23.012] iteration:12722  t-loss:0.1402, loss-lb:0.0835, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:40:23.204] iteration:12723  t-loss:0.1397, loss-lb:0.0777, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:40:23.396] iteration:12724  t-loss:0.1424, loss-lb:0.0853, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:40:23.589] iteration:12725  t-loss:0.1470, loss-lb:0.0901, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:40:23.781] iteration:12726  t-loss:0.1445, loss-lb:0.0864, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:40:23.973] iteration:12727  t-loss:0.1345, loss-lb:0.0825, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:40:24.166] iteration:12728  t-loss:0.1612, loss-lb:0.0833, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:40:24.359] iteration:12729  t-loss:0.1356, loss-lb:0.0831, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:40:24.551] iteration:12730  t-loss:0.1594, loss-lb:0.0937, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:40:24.743] iteration:12731  t-loss:0.1446, loss-lb:0.0860, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:40:24.937] iteration:12732  t-loss:0.1414, loss-lb:0.0845, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:40:25.129] iteration:12733  t-loss:0.2330, loss-lb:0.0809, loss-ulb:0.0761, weight:2.00, lr:0.0006
[11:40:25.320] iteration:12734  t-loss:0.1415, loss-lb:0.0878, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:40:25.511] iteration:12735  t-loss:0.1451, loss-lb:0.0780, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:40:25.702] iteration:12736  t-loss:0.1643, loss-lb:0.0908, loss-ulb:0.0367, weight:2.00, lr:0.0006
[11:40:25.894] iteration:12737  t-loss:0.2887, loss-lb:0.0844, loss-ulb:0.1021, weight:2.00, lr:0.0006
[11:40:26.084] iteration:12738  t-loss:0.1475, loss-lb:0.0871, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:40:26.275] iteration:12739  t-loss:0.1406, loss-lb:0.0828, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:40:26.465] iteration:12740  t-loss:0.1522, loss-lb:0.0824, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:40:27.058] iteration:12741  t-loss:0.1458, loss-lb:0.0885, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:40:27.255] iteration:12742  t-loss:0.1495, loss-lb:0.0875, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:40:27.447] iteration:12743  t-loss:0.1382, loss-lb:0.0845, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:40:27.639] iteration:12744  t-loss:0.1467, loss-lb:0.0844, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:40:27.832] iteration:12745  t-loss:0.1513, loss-lb:0.0812, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:40:28.025] iteration:12746  t-loss:0.1344, loss-lb:0.0843, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:40:28.217] iteration:12747  t-loss:0.1375, loss-lb:0.0871, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:40:28.409] iteration:12748  t-loss:0.1316, loss-lb:0.0770, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:40:28.602] iteration:12749  t-loss:0.1593, loss-lb:0.1105, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:40:28.795] iteration:12750  t-loss:0.1550, loss-lb:0.0843, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:40:28.989] iteration:12751  t-loss:0.1359, loss-lb:0.0874, loss-ulb:0.0243, weight:2.00, lr:0.0006
[11:40:29.181] iteration:12752  t-loss:0.1492, loss-lb:0.0888, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:40:29.373] iteration:12753  t-loss:0.1516, loss-lb:0.0794, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:40:29.566] iteration:12754  t-loss:0.1403, loss-lb:0.0875, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:40:29.757] iteration:12755  t-loss:0.1475, loss-lb:0.0920, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:40:29.949] iteration:12756  t-loss:0.1332, loss-lb:0.0791, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:40:30.143] iteration:12757  t-loss:0.1473, loss-lb:0.0943, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:40:30.337] iteration:12758  t-loss:0.1359, loss-lb:0.0790, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:40:30.529] iteration:12759  t-loss:0.1781, loss-lb:0.0854, loss-ulb:0.0463, weight:2.00, lr:0.0006
[11:40:30.722] iteration:12760  t-loss:0.1331, loss-lb:0.0759, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:40:30.914] iteration:12761  t-loss:0.1714, loss-lb:0.0795, loss-ulb:0.0459, weight:2.00, lr:0.0006
[11:40:31.106] iteration:12762  t-loss:0.1755, loss-lb:0.0847, loss-ulb:0.0454, weight:2.00, lr:0.0006
[11:40:31.298] iteration:12763  t-loss:0.1379, loss-lb:0.0789, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:40:31.491] iteration:12764  t-loss:0.1496, loss-lb:0.0771, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:40:31.684] iteration:12765  t-loss:0.1409, loss-lb:0.0775, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:40:31.877] iteration:12766  t-loss:0.2029, loss-lb:0.0924, loss-ulb:0.0552, weight:2.00, lr:0.0006
[11:40:32.070] iteration:12767  t-loss:0.1497, loss-lb:0.0934, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:40:32.262] iteration:12768  t-loss:0.1940, loss-lb:0.0837, loss-ulb:0.0551, weight:2.00, lr:0.0006
[11:40:32.454] iteration:12769  t-loss:0.1456, loss-lb:0.0812, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:40:32.646] iteration:12770  t-loss:0.1455, loss-lb:0.0837, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:40:32.839] iteration:12771  t-loss:0.1369, loss-lb:0.0830, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:40:33.030] iteration:12772  t-loss:0.1552, loss-lb:0.0908, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:40:33.223] iteration:12773  t-loss:0.1381, loss-lb:0.0812, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:40:33.415] iteration:12774  t-loss:0.1329, loss-lb:0.0820, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:40:33.607] iteration:12775  t-loss:0.1443, loss-lb:0.0885, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:40:33.799] iteration:12776  t-loss:0.1414, loss-lb:0.0862, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:40:33.992] iteration:12777  t-loss:0.1865, loss-lb:0.0857, loss-ulb:0.0504, weight:2.00, lr:0.0006
[11:40:34.183] iteration:12778  t-loss:0.1370, loss-lb:0.0826, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:40:34.375] iteration:12779  t-loss:0.1386, loss-lb:0.0822, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:40:34.568] iteration:12780  t-loss:0.1368, loss-lb:0.0819, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:40:34.761] iteration:12781  t-loss:0.2197, loss-lb:0.0878, loss-ulb:0.0659, weight:2.00, lr:0.0006
[11:40:34.954] iteration:12782  t-loss:0.1678, loss-lb:0.0844, loss-ulb:0.0417, weight:2.00, lr:0.0006
[11:40:35.146] iteration:12783  t-loss:0.1431, loss-lb:0.0830, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:40:35.339] iteration:12784  t-loss:0.1395, loss-lb:0.0798, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:40:35.531] iteration:12785  t-loss:0.1472, loss-lb:0.0831, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:40:35.723] iteration:12786  t-loss:0.1420, loss-lb:0.0872, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:40:35.916] iteration:12787  t-loss:0.1436, loss-lb:0.0888, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:40:36.108] iteration:12788  t-loss:0.1603, loss-lb:0.0754, loss-ulb:0.0425, weight:2.00, lr:0.0006
[11:40:36.301] iteration:12789  t-loss:0.1534, loss-lb:0.0941, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:40:36.495] iteration:12790  t-loss:0.2077, loss-lb:0.0789, loss-ulb:0.0644, weight:2.00, lr:0.0006
[11:40:36.687] iteration:12791  t-loss:0.1388, loss-lb:0.0792, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:40:36.880] iteration:12792  t-loss:0.1476, loss-lb:0.0873, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:40:37.073] iteration:12793  t-loss:0.1479, loss-lb:0.0813, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:40:37.265] iteration:12794  t-loss:0.1368, loss-lb:0.0822, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:40:37.458] iteration:12795  t-loss:0.1362, loss-lb:0.0742, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:40:37.650] iteration:12796  t-loss:0.1554, loss-lb:0.0966, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:40:37.842] iteration:12797  t-loss:0.1497, loss-lb:0.0882, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:40:38.034] iteration:12798  t-loss:0.1366, loss-lb:0.0849, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:40:38.227] iteration:12799  t-loss:0.1360, loss-lb:0.0805, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:40:38.420] iteration:12800  t-loss:0.1548, loss-lb:0.0788, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:40:38.613] iteration:12801  t-loss:0.1528, loss-lb:0.0888, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:40:38.805] iteration:12802  t-loss:0.1454, loss-lb:0.0865, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:40:38.997] iteration:12803  t-loss:0.1325, loss-lb:0.0815, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:40:39.190] iteration:12804  t-loss:0.1499, loss-lb:0.0859, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:40:39.382] iteration:12805  t-loss:0.1359, loss-lb:0.0835, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:40:39.574] iteration:12806  t-loss:0.1380, loss-lb:0.0799, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:40:39.767] iteration:12807  t-loss:0.1749, loss-lb:0.0855, loss-ulb:0.0447, weight:2.00, lr:0.0006
[11:40:39.960] iteration:12808  t-loss:0.1665, loss-lb:0.0969, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:40:40.151] iteration:12809  t-loss:0.1422, loss-lb:0.0845, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:40:40.343] iteration:12810  t-loss:0.1313, loss-lb:0.0812, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:40:40.537] iteration:12811  t-loss:0.1484, loss-lb:0.0797, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:40:40.729] iteration:12812  t-loss:0.1502, loss-lb:0.0908, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:40:40.921] iteration:12813  t-loss:0.1565, loss-lb:0.0869, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:40:41.114] iteration:12814  t-loss:0.1604, loss-lb:0.0813, loss-ulb:0.0395, weight:2.00, lr:0.0006
[11:40:41.307] iteration:12815  t-loss:0.2096, loss-lb:0.0994, loss-ulb:0.0551, weight:2.00, lr:0.0006
[11:40:41.500] iteration:12816  t-loss:0.1492, loss-lb:0.0934, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:40:41.692] iteration:12817  t-loss:0.1557, loss-lb:0.0852, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:40:41.884] iteration:12818  t-loss:0.2318, loss-lb:0.0869, loss-ulb:0.0725, weight:2.00, lr:0.0006
[11:40:42.076] iteration:12819  t-loss:0.1694, loss-lb:0.1111, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:40:42.269] iteration:12820  t-loss:0.1411, loss-lb:0.0847, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:40:42.461] iteration:12821  t-loss:0.1709, loss-lb:0.0942, loss-ulb:0.0384, weight:2.00, lr:0.0006
[11:40:42.653] iteration:12822  t-loss:0.1638, loss-lb:0.0920, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:40:42.845] iteration:12823  t-loss:0.1307, loss-lb:0.0806, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:40:43.037] iteration:12824  t-loss:0.1470, loss-lb:0.0818, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:40:43.229] iteration:12825  t-loss:0.1618, loss-lb:0.0928, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:40:43.422] iteration:12826  t-loss:0.1398, loss-lb:0.0783, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:40:43.614] iteration:12827  t-loss:0.1723, loss-lb:0.0963, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:40:43.806] iteration:12828  t-loss:0.1356, loss-lb:0.0809, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:40:43.999] iteration:12829  t-loss:0.1736, loss-lb:0.0970, loss-ulb:0.0383, weight:2.00, lr:0.0006
[11:40:44.191] iteration:12830  t-loss:0.1522, loss-lb:0.0965, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:40:44.383] iteration:12831  t-loss:0.1836, loss-lb:0.0855, loss-ulb:0.0490, weight:2.00, lr:0.0006
[11:40:44.575] iteration:12832  t-loss:0.1884, loss-lb:0.0873, loss-ulb:0.0506, weight:2.00, lr:0.0006
[11:40:44.766] iteration:12833  t-loss:0.1504, loss-lb:0.0867, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:40:44.956] iteration:12834  t-loss:0.1527, loss-lb:0.0855, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:40:45.148] iteration:12835  t-loss:0.1312, loss-lb:0.0776, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:40:45.339] iteration:12836  t-loss:0.1704, loss-lb:0.0884, loss-ulb:0.0410, weight:2.00, lr:0.0006
[11:40:45.530] iteration:12837  t-loss:0.1464, loss-lb:0.0842, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:40:45.721] iteration:12838  t-loss:0.1596, loss-lb:0.0977, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:40:58.443]  <<Test>> - Ep:130  - mean_dice/mean_h95 - S:89.71/1.37, Best-S:90.30, T:89.76/1.88, Best-T:90.48
[11:40:58.443]           - AvgLoss(lb/ulb/all):0.0858/0.0340/0.1570
[11:40:58.979] iteration:12839  t-loss:0.1588, loss-lb:0.0974, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:40:59.175] iteration:12840  t-loss:0.1473, loss-lb:0.0898, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:40:59.368] iteration:12841  t-loss:0.1430, loss-lb:0.0840, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:40:59.562] iteration:12842  t-loss:0.1346, loss-lb:0.0843, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:40:59.753] iteration:12843  t-loss:0.1382, loss-lb:0.0825, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:40:59.945] iteration:12844  t-loss:0.1491, loss-lb:0.0934, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:41:00.139] iteration:12845  t-loss:0.1369, loss-lb:0.0807, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:41:00.332] iteration:12846  t-loss:0.1498, loss-lb:0.0816, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:41:00.525] iteration:12847  t-loss:0.2373, loss-lb:0.0727, loss-ulb:0.0823, weight:2.00, lr:0.0006
[11:41:00.718] iteration:12848  t-loss:0.2391, loss-lb:0.0791, loss-ulb:0.0800, weight:2.00, lr:0.0006
[11:41:00.910] iteration:12849  t-loss:0.1290, loss-lb:0.0793, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:41:01.103] iteration:12850  t-loss:0.1477, loss-lb:0.0918, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:41:01.296] iteration:12851  t-loss:0.1832, loss-lb:0.0772, loss-ulb:0.0530, weight:2.00, lr:0.0006
[11:41:01.487] iteration:12852  t-loss:0.2068, loss-lb:0.0947, loss-ulb:0.0560, weight:2.00, lr:0.0006
[11:41:01.681] iteration:12853  t-loss:0.1705, loss-lb:0.0817, loss-ulb:0.0444, weight:2.00, lr:0.0006
[11:41:01.874] iteration:12854  t-loss:0.1882, loss-lb:0.0880, loss-ulb:0.0501, weight:2.00, lr:0.0006
[11:41:02.066] iteration:12855  t-loss:0.1741, loss-lb:0.0915, loss-ulb:0.0413, weight:2.00, lr:0.0006
[11:41:02.258] iteration:12856  t-loss:0.1670, loss-lb:0.0959, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:41:02.450] iteration:12857  t-loss:0.1755, loss-lb:0.1080, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:41:02.643] iteration:12858  t-loss:0.1627, loss-lb:0.0887, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:41:02.835] iteration:12859  t-loss:0.1770, loss-lb:0.0938, loss-ulb:0.0416, weight:2.00, lr:0.0006
[11:41:03.028] iteration:12860  t-loss:0.1697, loss-lb:0.0909, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:41:03.221] iteration:12861  t-loss:0.1592, loss-lb:0.0896, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:41:03.413] iteration:12862  t-loss:0.1425, loss-lb:0.0812, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:41:03.605] iteration:12863  t-loss:0.1583, loss-lb:0.0876, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:41:03.797] iteration:12864  t-loss:0.1811, loss-lb:0.1023, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:41:03.989] iteration:12865  t-loss:0.2322, loss-lb:0.0908, loss-ulb:0.0707, weight:2.00, lr:0.0006
[11:41:04.182] iteration:12866  t-loss:0.1466, loss-lb:0.0913, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:41:04.374] iteration:12867  t-loss:0.1603, loss-lb:0.0874, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:41:04.565] iteration:12868  t-loss:0.1858, loss-lb:0.0912, loss-ulb:0.0473, weight:2.00, lr:0.0006
[11:41:04.756] iteration:12869  t-loss:0.1489, loss-lb:0.0898, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:41:04.948] iteration:12870  t-loss:0.1515, loss-lb:0.0892, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:41:05.140] iteration:12871  t-loss:0.2473, loss-lb:0.0878, loss-ulb:0.0798, weight:2.00, lr:0.0006
[11:41:05.331] iteration:12872  t-loss:0.1556, loss-lb:0.0976, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:41:05.522] iteration:12873  t-loss:0.1713, loss-lb:0.0930, loss-ulb:0.0391, weight:2.00, lr:0.0006
[11:41:05.713] iteration:12874  t-loss:0.1522, loss-lb:0.0901, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:41:05.905] iteration:12875  t-loss:0.1475, loss-lb:0.0849, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:41:06.097] iteration:12876  t-loss:0.2074, loss-lb:0.0894, loss-ulb:0.0590, weight:2.00, lr:0.0006
[11:41:06.288] iteration:12877  t-loss:0.1630, loss-lb:0.0922, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:41:06.481] iteration:12878  t-loss:0.2140, loss-lb:0.1254, loss-ulb:0.0443, weight:2.00, lr:0.0006
[11:41:06.674] iteration:12879  t-loss:0.2584, loss-lb:0.0874, loss-ulb:0.0855, weight:2.00, lr:0.0006
[11:41:06.873] iteration:12880  t-loss:0.1574, loss-lb:0.0932, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:41:07.066] iteration:12881  t-loss:0.1677, loss-lb:0.1110, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:41:07.259] iteration:12882  t-loss:0.1689, loss-lb:0.0971, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:41:07.453] iteration:12883  t-loss:0.1744, loss-lb:0.0922, loss-ulb:0.0411, weight:2.00, lr:0.0006
[11:41:07.644] iteration:12884  t-loss:0.1398, loss-lb:0.0866, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:41:07.837] iteration:12885  t-loss:0.1491, loss-lb:0.0915, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:41:08.029] iteration:12886  t-loss:0.1872, loss-lb:0.0891, loss-ulb:0.0490, weight:2.00, lr:0.0006
[11:41:08.220] iteration:12887  t-loss:0.1569, loss-lb:0.0982, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:41:08.414] iteration:12888  t-loss:0.1582, loss-lb:0.1030, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:41:08.608] iteration:12889  t-loss:0.1653, loss-lb:0.0993, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:41:08.800] iteration:12890  t-loss:0.1569, loss-lb:0.0848, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:41:08.993] iteration:12891  t-loss:0.1919, loss-lb:0.0840, loss-ulb:0.0539, weight:2.00, lr:0.0006
[11:41:09.184] iteration:12892  t-loss:0.1874, loss-lb:0.1152, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:41:09.376] iteration:12893  t-loss:0.1461, loss-lb:0.0870, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:41:09.567] iteration:12894  t-loss:0.1516, loss-lb:0.0897, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:41:09.761] iteration:12895  t-loss:0.1552, loss-lb:0.0992, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:41:09.952] iteration:12896  t-loss:0.1537, loss-lb:0.0939, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:41:10.145] iteration:12897  t-loss:0.2023, loss-lb:0.0822, loss-ulb:0.0601, weight:2.00, lr:0.0006
[11:41:10.337] iteration:12898  t-loss:0.1524, loss-lb:0.0958, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:41:10.528] iteration:12899  t-loss:0.1368, loss-lb:0.0819, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:41:10.720] iteration:12900  t-loss:0.1473, loss-lb:0.0897, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:41:10.912] iteration:12901  t-loss:0.1312, loss-lb:0.0794, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:41:11.103] iteration:12902  t-loss:0.1383, loss-lb:0.0875, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:41:11.295] iteration:12903  t-loss:0.1571, loss-lb:0.0862, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:41:11.487] iteration:12904  t-loss:0.1636, loss-lb:0.0864, loss-ulb:0.0386, weight:2.00, lr:0.0006
[11:41:11.678] iteration:12905  t-loss:0.1671, loss-lb:0.0895, loss-ulb:0.0388, weight:2.00, lr:0.0006
[11:41:11.869] iteration:12906  t-loss:0.1512, loss-lb:0.0926, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:41:12.061] iteration:12907  t-loss:0.1521, loss-lb:0.0868, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:41:12.253] iteration:12908  t-loss:0.1822, loss-lb:0.0831, loss-ulb:0.0496, weight:2.00, lr:0.0006
[11:41:12.445] iteration:12909  t-loss:0.1746, loss-lb:0.0958, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:41:12.637] iteration:12910  t-loss:0.1665, loss-lb:0.0906, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:41:12.829] iteration:12911  t-loss:0.2107, loss-lb:0.0854, loss-ulb:0.0626, weight:2.00, lr:0.0006
[11:41:13.020] iteration:12912  t-loss:0.1476, loss-lb:0.0932, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:41:13.212] iteration:12913  t-loss:0.1450, loss-lb:0.0911, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:41:13.403] iteration:12914  t-loss:0.2087, loss-lb:0.1476, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:41:13.595] iteration:12915  t-loss:0.1516, loss-lb:0.0865, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:41:13.788] iteration:12916  t-loss:0.1631, loss-lb:0.0980, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:41:13.979] iteration:12917  t-loss:0.1610, loss-lb:0.0839, loss-ulb:0.0386, weight:2.00, lr:0.0006
[11:41:14.171] iteration:12918  t-loss:0.1651, loss-lb:0.0825, loss-ulb:0.0413, weight:2.00, lr:0.0006
[11:41:14.362] iteration:12919  t-loss:0.1687, loss-lb:0.1069, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:41:14.554] iteration:12920  t-loss:0.1497, loss-lb:0.0914, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:41:14.746] iteration:12921  t-loss:0.1622, loss-lb:0.0961, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:41:14.937] iteration:12922  t-loss:0.1621, loss-lb:0.0906, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:41:15.129] iteration:12923  t-loss:0.1396, loss-lb:0.0847, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:41:15.319] iteration:12924  t-loss:0.1601, loss-lb:0.0805, loss-ulb:0.0398, weight:2.00, lr:0.0006
[11:41:15.512] iteration:12925  t-loss:0.2142, loss-lb:0.0869, loss-ulb:0.0636, weight:2.00, lr:0.0006
[11:41:15.703] iteration:12926  t-loss:0.1673, loss-lb:0.0948, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:41:15.894] iteration:12927  t-loss:0.1682, loss-lb:0.1035, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:41:16.086] iteration:12928  t-loss:0.1732, loss-lb:0.0942, loss-ulb:0.0395, weight:2.00, lr:0.0006
[11:41:16.277] iteration:12929  t-loss:0.1595, loss-lb:0.0969, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:41:16.467] iteration:12930  t-loss:0.1507, loss-lb:0.0939, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:41:16.657] iteration:12931  t-loss:0.1534, loss-lb:0.0924, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:41:16.846] iteration:12932  t-loss:0.2617, loss-lb:0.0935, loss-ulb:0.0841, weight:2.00, lr:0.0006
[11:41:17.036] iteration:12933  t-loss:0.1515, loss-lb:0.0813, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:41:17.226] iteration:12934  t-loss:0.1552, loss-lb:0.0969, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:41:17.420] iteration:12935  t-loss:0.1411, loss-lb:0.0872, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:41:17.615] iteration:12936  t-loss:0.1783, loss-lb:0.0859, loss-ulb:0.0462, weight:2.00, lr:0.0006
[11:41:18.235] iteration:12937  t-loss:0.1686, loss-lb:0.0946, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:41:18.433] iteration:12938  t-loss:0.2124, loss-lb:0.0944, loss-ulb:0.0590, weight:2.00, lr:0.0006
[11:41:18.626] iteration:12939  t-loss:0.1441, loss-lb:0.0868, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:41:18.818] iteration:12940  t-loss:0.1427, loss-lb:0.0967, loss-ulb:0.0230, weight:2.00, lr:0.0006
[11:41:19.010] iteration:12941  t-loss:0.1438, loss-lb:0.0911, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:41:19.202] iteration:12942  t-loss:0.1506, loss-lb:0.0955, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:41:19.395] iteration:12943  t-loss:0.1402, loss-lb:0.0886, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:41:19.587] iteration:12944  t-loss:0.1568, loss-lb:0.0943, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:41:19.778] iteration:12945  t-loss:0.1434, loss-lb:0.0901, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:41:19.970] iteration:12946  t-loss:0.1391, loss-lb:0.0821, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:41:20.162] iteration:12947  t-loss:0.1669, loss-lb:0.0919, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:41:20.354] iteration:12948  t-loss:0.1573, loss-lb:0.0905, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:41:20.547] iteration:12949  t-loss:0.1407, loss-lb:0.0841, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:41:20.738] iteration:12950  t-loss:0.1516, loss-lb:0.0876, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:41:20.931] iteration:12951  t-loss:0.1617, loss-lb:0.0966, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:41:21.122] iteration:12952  t-loss:0.1541, loss-lb:0.0876, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:41:21.314] iteration:12953  t-loss:0.1412, loss-lb:0.0858, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:41:21.508] iteration:12954  t-loss:0.1856, loss-lb:0.0877, loss-ulb:0.0489, weight:2.00, lr:0.0006
[11:41:21.699] iteration:12955  t-loss:0.1621, loss-lb:0.0891, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:41:21.892] iteration:12956  t-loss:0.2987, loss-lb:0.0852, loss-ulb:0.1067, weight:2.00, lr:0.0006
[11:41:22.084] iteration:12957  t-loss:0.1444, loss-lb:0.0849, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:41:22.275] iteration:12958  t-loss:0.1587, loss-lb:0.0892, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:41:22.468] iteration:12959  t-loss:0.2496, loss-lb:0.0963, loss-ulb:0.0767, weight:2.00, lr:0.0006
[11:41:22.659] iteration:12960  t-loss:0.1418, loss-lb:0.0806, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:41:22.851] iteration:12961  t-loss:0.1384, loss-lb:0.0852, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:41:23.057] iteration:12962  t-loss:0.1895, loss-lb:0.0907, loss-ulb:0.0494, weight:2.00, lr:0.0006
[11:41:23.256] iteration:12963  t-loss:0.1483, loss-lb:0.0891, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:41:23.452] iteration:12964  t-loss:0.1493, loss-lb:0.0824, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:41:23.644] iteration:12965  t-loss:0.1517, loss-lb:0.0999, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:41:23.837] iteration:12966  t-loss:0.1388, loss-lb:0.0832, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:41:24.028] iteration:12967  t-loss:0.1380, loss-lb:0.0826, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:41:24.220] iteration:12968  t-loss:0.1494, loss-lb:0.0893, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:41:24.412] iteration:12969  t-loss:0.1380, loss-lb:0.0772, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:41:24.603] iteration:12970  t-loss:0.1353, loss-lb:0.0797, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:41:24.795] iteration:12971  t-loss:0.1536, loss-lb:0.0860, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:41:24.987] iteration:12972  t-loss:0.2603, loss-lb:0.0867, loss-ulb:0.0868, weight:2.00, lr:0.0006
[11:41:25.178] iteration:12973  t-loss:0.1454, loss-lb:0.0873, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:41:25.370] iteration:12974  t-loss:0.1560, loss-lb:0.0839, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:41:25.561] iteration:12975  t-loss:0.1457, loss-lb:0.0805, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:41:25.752] iteration:12976  t-loss:0.1605, loss-lb:0.0890, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:41:25.944] iteration:12977  t-loss:0.1396, loss-lb:0.0898, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:41:26.135] iteration:12978  t-loss:0.1556, loss-lb:0.0800, loss-ulb:0.0378, weight:2.00, lr:0.0006
[11:41:26.326] iteration:12979  t-loss:0.1776, loss-lb:0.0905, loss-ulb:0.0436, weight:2.00, lr:0.0006
[11:41:26.517] iteration:12980  t-loss:0.2251, loss-lb:0.0850, loss-ulb:0.0701, weight:2.00, lr:0.0006
[11:41:26.709] iteration:12981  t-loss:0.1392, loss-lb:0.0866, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:41:26.901] iteration:12982  t-loss:0.1907, loss-lb:0.0901, loss-ulb:0.0503, weight:2.00, lr:0.0006
[11:41:27.092] iteration:12983  t-loss:0.1755, loss-lb:0.0843, loss-ulb:0.0456, weight:2.00, lr:0.0006
[11:41:27.283] iteration:12984  t-loss:0.1692, loss-lb:0.0869, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:41:27.474] iteration:12985  t-loss:0.1778, loss-lb:0.0851, loss-ulb:0.0464, weight:2.00, lr:0.0006
[11:41:27.666] iteration:12986  t-loss:0.1614, loss-lb:0.0850, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:41:27.857] iteration:12987  t-loss:0.1961, loss-lb:0.0846, loss-ulb:0.0557, weight:2.00, lr:0.0006
[11:41:28.049] iteration:12988  t-loss:0.1410, loss-lb:0.0965, loss-ulb:0.0222, weight:2.00, lr:0.0006
[11:41:28.243] iteration:12989  t-loss:0.1474, loss-lb:0.0830, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:41:28.438] iteration:12990  t-loss:0.1603, loss-lb:0.0877, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:41:28.631] iteration:12991  t-loss:0.1556, loss-lb:0.0971, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:41:28.826] iteration:12992  t-loss:0.1450, loss-lb:0.0926, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:41:29.019] iteration:12993  t-loss:0.1777, loss-lb:0.0924, loss-ulb:0.0426, weight:2.00, lr:0.0006
[11:41:29.211] iteration:12994  t-loss:0.1495, loss-lb:0.0959, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:41:29.403] iteration:12995  t-loss:0.1691, loss-lb:0.0911, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:41:29.595] iteration:12996  t-loss:0.2341, loss-lb:0.0888, loss-ulb:0.0727, weight:2.00, lr:0.0006
[11:41:29.786] iteration:12997  t-loss:0.1718, loss-lb:0.0897, loss-ulb:0.0411, weight:2.00, lr:0.0006
[11:41:29.978] iteration:12998  t-loss:0.1390, loss-lb:0.0837, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:41:30.171] iteration:12999  t-loss:0.1524, loss-lb:0.0981, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:41:30.362] iteration:13000  t-loss:0.1426, loss-lb:0.0833, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:41:30.554] iteration:13001  t-loss:0.1933, loss-lb:0.1140, loss-ulb:0.0397, weight:2.00, lr:0.0006
[11:41:30.746] iteration:13002  t-loss:0.1488, loss-lb:0.0850, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:41:30.938] iteration:13003  t-loss:0.1599, loss-lb:0.0911, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:41:31.130] iteration:13004  t-loss:0.1608, loss-lb:0.0833, loss-ulb:0.0387, weight:2.00, lr:0.0006
[11:41:31.323] iteration:13005  t-loss:0.2118, loss-lb:0.0876, loss-ulb:0.0621, weight:2.00, lr:0.0006
[11:41:31.516] iteration:13006  t-loss:0.1522, loss-lb:0.0898, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:41:31.707] iteration:13007  t-loss:0.1595, loss-lb:0.0890, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:41:31.898] iteration:13008  t-loss:0.1606, loss-lb:0.0954, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:41:32.090] iteration:13009  t-loss:0.1574, loss-lb:0.0886, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:41:32.282] iteration:13010  t-loss:0.1480, loss-lb:0.0913, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:41:32.475] iteration:13011  t-loss:0.1568, loss-lb:0.0865, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:41:32.667] iteration:13012  t-loss:0.2362, loss-lb:0.0969, loss-ulb:0.0696, weight:2.00, lr:0.0006
[11:41:32.858] iteration:13013  t-loss:0.1385, loss-lb:0.0874, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:41:33.049] iteration:13014  t-loss:0.1380, loss-lb:0.0798, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:41:33.241] iteration:13015  t-loss:0.1523, loss-lb:0.1059, loss-ulb:0.0232, weight:2.00, lr:0.0006
[11:41:33.432] iteration:13016  t-loss:0.1728, loss-lb:0.0852, loss-ulb:0.0438, weight:2.00, lr:0.0006
[11:41:33.624] iteration:13017  t-loss:0.1411, loss-lb:0.0820, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:41:33.815] iteration:13018  t-loss:0.1529, loss-lb:0.0924, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:41:34.007] iteration:13019  t-loss:0.1385, loss-lb:0.0891, loss-ulb:0.0247, weight:2.00, lr:0.0006
[11:41:34.199] iteration:13020  t-loss:0.1662, loss-lb:0.0893, loss-ulb:0.0384, weight:2.00, lr:0.0006
[11:41:34.390] iteration:13021  t-loss:0.1289, loss-lb:0.0769, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:41:34.582] iteration:13022  t-loss:0.1416, loss-lb:0.0825, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:41:34.775] iteration:13023  t-loss:0.1448, loss-lb:0.0866, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:41:34.967] iteration:13024  t-loss:0.1466, loss-lb:0.0818, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:41:35.159] iteration:13025  t-loss:0.1271, loss-lb:0.0740, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:41:35.350] iteration:13026  t-loss:0.1431, loss-lb:0.0873, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:41:35.541] iteration:13027  t-loss:0.1401, loss-lb:0.0849, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:41:35.732] iteration:13028  t-loss:0.1617, loss-lb:0.0950, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:41:35.922] iteration:13029  t-loss:0.1561, loss-lb:0.0889, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:41:36.113] iteration:13030  t-loss:0.1390, loss-lb:0.0883, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:41:36.305] iteration:13031  t-loss:0.2570, loss-lb:0.0827, loss-ulb:0.0872, weight:2.00, lr:0.0006
[11:41:36.495] iteration:13032  t-loss:0.1807, loss-lb:0.0887, loss-ulb:0.0460, weight:2.00, lr:0.0006
[11:41:36.685] iteration:13033  t-loss:0.1427, loss-lb:0.0835, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:41:36.875] iteration:13034  t-loss:0.1596, loss-lb:0.0886, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:41:48.041]  <<Test>> - Ep:132  - mean_dice/mean_h95 - S:90.29/1.28, Best-S:90.30, T:90.00/1.35, Best-T:90.48
[11:41:48.042]           - AvgLoss(lb/ulb/all):0.0883/0.0340/0.1546
[11:41:48.592] iteration:13035  t-loss:0.1321, loss-lb:0.0830, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:41:48.787] iteration:13036  t-loss:0.1470, loss-lb:0.0873, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:41:48.980] iteration:13037  t-loss:0.1552, loss-lb:0.0828, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:41:49.173] iteration:13038  t-loss:0.1369, loss-lb:0.0880, loss-ulb:0.0245, weight:2.00, lr:0.0006
[11:41:49.367] iteration:13039  t-loss:0.2309, loss-lb:0.0796, loss-ulb:0.0756, weight:2.00, lr:0.0006
[11:41:49.561] iteration:13040  t-loss:0.1869, loss-lb:0.0885, loss-ulb:0.0492, weight:2.00, lr:0.0006
[11:41:49.755] iteration:13041  t-loss:0.1378, loss-lb:0.0838, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:41:49.948] iteration:13042  t-loss:0.1701, loss-lb:0.0942, loss-ulb:0.0379, weight:2.00, lr:0.0006
[11:41:50.141] iteration:13043  t-loss:0.1441, loss-lb:0.0871, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:41:50.335] iteration:13044  t-loss:0.1476, loss-lb:0.0951, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:41:50.528] iteration:13045  t-loss:0.1841, loss-lb:0.0876, loss-ulb:0.0483, weight:2.00, lr:0.0006
[11:41:50.722] iteration:13046  t-loss:0.2452, loss-lb:0.0937, loss-ulb:0.0757, weight:2.00, lr:0.0006
[11:41:50.915] iteration:13047  t-loss:0.1581, loss-lb:0.0871, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:41:51.109] iteration:13048  t-loss:0.1442, loss-lb:0.0897, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:41:51.301] iteration:13049  t-loss:0.1522, loss-lb:0.0926, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:41:51.494] iteration:13050  t-loss:0.1800, loss-lb:0.1146, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:41:51.687] iteration:13051  t-loss:0.1656, loss-lb:0.0984, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:41:51.880] iteration:13052  t-loss:0.1491, loss-lb:0.0903, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:41:52.071] iteration:13053  t-loss:0.1379, loss-lb:0.0832, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:41:52.264] iteration:13054  t-loss:0.1504, loss-lb:0.0800, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:41:52.457] iteration:13055  t-loss:0.2880, loss-lb:0.0849, loss-ulb:0.1015, weight:2.00, lr:0.0006
[11:41:52.649] iteration:13056  t-loss:0.1560, loss-lb:0.0972, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:41:52.841] iteration:13057  t-loss:0.1425, loss-lb:0.0843, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:41:53.033] iteration:13058  t-loss:0.1484, loss-lb:0.0904, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:41:53.225] iteration:13059  t-loss:0.1595, loss-lb:0.0859, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:41:53.417] iteration:13060  t-loss:0.1350, loss-lb:0.0779, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:41:53.609] iteration:13061  t-loss:0.1477, loss-lb:0.0877, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:41:53.801] iteration:13062  t-loss:0.1526, loss-lb:0.0893, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:41:53.993] iteration:13063  t-loss:0.1314, loss-lb:0.0807, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:41:54.186] iteration:13064  t-loss:0.1527, loss-lb:0.0897, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:41:54.377] iteration:13065  t-loss:0.1385, loss-lb:0.0809, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:41:54.570] iteration:13066  t-loss:0.1372, loss-lb:0.0837, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:41:54.762] iteration:13067  t-loss:0.1375, loss-lb:0.0804, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:41:54.953] iteration:13068  t-loss:0.1491, loss-lb:0.0851, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:41:55.145] iteration:13069  t-loss:0.1421, loss-lb:0.0937, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:41:55.338] iteration:13070  t-loss:0.1384, loss-lb:0.0828, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:41:55.530] iteration:13071  t-loss:0.1310, loss-lb:0.0852, loss-ulb:0.0229, weight:2.00, lr:0.0006
[11:41:55.724] iteration:13072  t-loss:0.1347, loss-lb:0.0791, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:41:55.928] iteration:13073  t-loss:0.1518, loss-lb:0.0842, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:41:56.125] iteration:13074  t-loss:0.1457, loss-lb:0.0893, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:41:56.318] iteration:13075  t-loss:0.1359, loss-lb:0.0791, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:41:56.511] iteration:13076  t-loss:0.2030, loss-lb:0.1327, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:41:56.702] iteration:13077  t-loss:0.1454, loss-lb:0.0888, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:41:56.897] iteration:13078  t-loss:0.1327, loss-lb:0.0834, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:41:57.090] iteration:13079  t-loss:0.1566, loss-lb:0.0750, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:41:57.283] iteration:13080  t-loss:0.1500, loss-lb:0.0889, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:41:57.474] iteration:13081  t-loss:0.1391, loss-lb:0.0815, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:41:57.666] iteration:13082  t-loss:0.1338, loss-lb:0.0762, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:41:57.859] iteration:13083  t-loss:0.1685, loss-lb:0.0866, loss-ulb:0.0410, weight:2.00, lr:0.0006
[11:41:58.052] iteration:13084  t-loss:0.1582, loss-lb:0.0904, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:41:58.244] iteration:13085  t-loss:0.1530, loss-lb:0.0836, loss-ulb:0.0347, weight:2.00, lr:0.0006
[11:41:58.436] iteration:13086  t-loss:0.1541, loss-lb:0.0795, loss-ulb:0.0373, weight:2.00, lr:0.0006
[11:41:58.629] iteration:13087  t-loss:0.1464, loss-lb:0.0837, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:41:58.821] iteration:13088  t-loss:0.1443, loss-lb:0.0787, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:41:59.013] iteration:13089  t-loss:0.1917, loss-lb:0.0817, loss-ulb:0.0550, weight:2.00, lr:0.0006
[11:41:59.206] iteration:13090  t-loss:0.1690, loss-lb:0.0940, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:41:59.398] iteration:13091  t-loss:0.2156, loss-lb:0.0776, loss-ulb:0.0690, weight:2.00, lr:0.0006
[11:41:59.590] iteration:13092  t-loss:0.1608, loss-lb:0.0979, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:41:59.782] iteration:13093  t-loss:0.1351, loss-lb:0.0893, loss-ulb:0.0229, weight:2.00, lr:0.0006
[11:41:59.974] iteration:13094  t-loss:0.1577, loss-lb:0.0763, loss-ulb:0.0407, weight:2.00, lr:0.0006
[11:42:00.167] iteration:13095  t-loss:0.1590, loss-lb:0.0827, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:42:00.361] iteration:13096  t-loss:0.1504, loss-lb:0.0772, loss-ulb:0.0366, weight:2.00, lr:0.0006
[11:42:00.553] iteration:13097  t-loss:0.1465, loss-lb:0.0809, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:42:00.745] iteration:13098  t-loss:0.1452, loss-lb:0.0840, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:42:00.938] iteration:13099  t-loss:0.1471, loss-lb:0.0844, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:42:01.129] iteration:13100  t-loss:0.1401, loss-lb:0.0824, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:42:01.321] iteration:13101  t-loss:0.1562, loss-lb:0.0923, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:42:01.514] iteration:13102  t-loss:0.1493, loss-lb:0.0895, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:42:01.706] iteration:13103  t-loss:0.1506, loss-lb:0.0894, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:42:01.898] iteration:13104  t-loss:0.1404, loss-lb:0.0813, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:42:02.091] iteration:13105  t-loss:0.1486, loss-lb:0.0766, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:42:02.285] iteration:13106  t-loss:0.2630, loss-lb:0.0874, loss-ulb:0.0878, weight:2.00, lr:0.0006
[11:42:02.477] iteration:13107  t-loss:0.1525, loss-lb:0.0828, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:42:02.669] iteration:13108  t-loss:0.1317, loss-lb:0.0800, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:42:02.862] iteration:13109  t-loss:0.1419, loss-lb:0.0763, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:42:03.054] iteration:13110  t-loss:0.1499, loss-lb:0.0853, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:42:03.246] iteration:13111  t-loss:0.1423, loss-lb:0.0796, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:42:03.439] iteration:13112  t-loss:0.1363, loss-lb:0.0876, loss-ulb:0.0243, weight:2.00, lr:0.0006
[11:42:03.630] iteration:13113  t-loss:0.1538, loss-lb:0.0907, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:42:03.822] iteration:13114  t-loss:0.1644, loss-lb:0.0888, loss-ulb:0.0378, weight:2.00, lr:0.0006
[11:42:04.015] iteration:13115  t-loss:0.1451, loss-lb:0.0937, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:42:04.208] iteration:13116  t-loss:0.1434, loss-lb:0.0825, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:42:04.400] iteration:13117  t-loss:0.1453, loss-lb:0.0843, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:42:04.592] iteration:13118  t-loss:0.1542, loss-lb:0.0901, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:42:04.785] iteration:13119  t-loss:0.1638, loss-lb:0.0935, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:42:04.977] iteration:13120  t-loss:0.1353, loss-lb:0.0824, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:42:05.170] iteration:13121  t-loss:0.1402, loss-lb:0.0775, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:42:05.364] iteration:13122  t-loss:0.2318, loss-lb:0.0759, loss-ulb:0.0779, weight:2.00, lr:0.0006
[11:42:05.558] iteration:13123  t-loss:0.1783, loss-lb:0.0929, loss-ulb:0.0427, weight:2.00, lr:0.0006
[11:42:05.749] iteration:13124  t-loss:0.1573, loss-lb:0.0870, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:42:05.941] iteration:13125  t-loss:0.1393, loss-lb:0.0837, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:42:06.132] iteration:13126  t-loss:0.1589, loss-lb:0.0903, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:42:06.323] iteration:13127  t-loss:0.1613, loss-lb:0.0958, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:42:06.513] iteration:13128  t-loss:0.1429, loss-lb:0.0823, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:42:06.704] iteration:13129  t-loss:0.1434, loss-lb:0.0772, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:42:06.894] iteration:13130  t-loss:0.1460, loss-lb:0.0889, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:42:07.085] iteration:13131  t-loss:0.1273, loss-lb:0.0806, loss-ulb:0.0234, weight:2.00, lr:0.0006
[11:42:07.276] iteration:13132  t-loss:0.3423, loss-lb:0.0822, loss-ulb:0.1301, weight:2.00, lr:0.0006
[11:42:07.870] iteration:13133  t-loss:0.1625, loss-lb:0.0838, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:42:08.066] iteration:13134  t-loss:0.1602, loss-lb:0.0890, loss-ulb:0.0356, weight:2.00, lr:0.0006
[11:42:08.265] iteration:13135  t-loss:0.1416, loss-lb:0.0831, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:42:08.457] iteration:13136  t-loss:0.1549, loss-lb:0.0893, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:42:08.650] iteration:13137  t-loss:0.1313, loss-lb:0.0759, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:42:08.843] iteration:13138  t-loss:0.1439, loss-lb:0.0875, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:42:09.042] iteration:13139  t-loss:0.1309, loss-lb:0.0775, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:42:09.235] iteration:13140  t-loss:0.1464, loss-lb:0.0798, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:42:09.426] iteration:13141  t-loss:0.1386, loss-lb:0.0837, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:42:09.618] iteration:13142  t-loss:0.1603, loss-lb:0.0992, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:42:09.817] iteration:13143  t-loss:0.1791, loss-lb:0.0879, loss-ulb:0.0456, weight:2.00, lr:0.0006
[11:42:10.011] iteration:13144  t-loss:0.1573, loss-lb:0.0915, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:42:10.203] iteration:13145  t-loss:0.1425, loss-lb:0.0866, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:42:10.396] iteration:13146  t-loss:0.1771, loss-lb:0.0816, loss-ulb:0.0478, weight:2.00, lr:0.0006
[11:42:10.595] iteration:13147  t-loss:0.1746, loss-lb:0.0810, loss-ulb:0.0468, weight:2.00, lr:0.0006
[11:42:10.788] iteration:13148  t-loss:0.1442, loss-lb:0.0868, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:42:10.979] iteration:13149  t-loss:0.1742, loss-lb:0.0949, loss-ulb:0.0397, weight:2.00, lr:0.0006
[11:42:11.172] iteration:13150  t-loss:0.1634, loss-lb:0.0969, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:42:11.371] iteration:13151  t-loss:0.1377, loss-lb:0.0853, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:42:11.563] iteration:13152  t-loss:0.1460, loss-lb:0.0781, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:42:11.756] iteration:13153  t-loss:0.1542, loss-lb:0.0950, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:42:11.948] iteration:13154  t-loss:0.1540, loss-lb:0.0877, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:42:12.148] iteration:13155  t-loss:0.1615, loss-lb:0.0779, loss-ulb:0.0418, weight:2.00, lr:0.0006
[11:42:12.340] iteration:13156  t-loss:0.1393, loss-lb:0.0833, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:42:12.534] iteration:13157  t-loss:0.2532, loss-lb:0.0852, loss-ulb:0.0840, weight:2.00, lr:0.0006
[11:42:12.726] iteration:13158  t-loss:0.1559, loss-lb:0.0890, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:42:12.925] iteration:13159  t-loss:0.1450, loss-lb:0.0897, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:42:13.116] iteration:13160  t-loss:0.1442, loss-lb:0.0847, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:42:13.310] iteration:13161  t-loss:0.1522, loss-lb:0.0871, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:42:13.503] iteration:13162  t-loss:0.1438, loss-lb:0.0836, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:42:13.702] iteration:13163  t-loss:0.1399, loss-lb:0.0891, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:42:13.898] iteration:13164  t-loss:0.1461, loss-lb:0.0878, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:42:14.090] iteration:13165  t-loss:0.1392, loss-lb:0.0723, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:42:14.283] iteration:13166  t-loss:0.1332, loss-lb:0.0811, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:42:14.476] iteration:13167  t-loss:0.1426, loss-lb:0.0775, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:42:14.668] iteration:13168  t-loss:0.1385, loss-lb:0.0802, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:42:14.861] iteration:13169  t-loss:0.1580, loss-lb:0.0941, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:42:15.055] iteration:13170  t-loss:0.1382, loss-lb:0.0846, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:42:15.247] iteration:13171  t-loss:0.1610, loss-lb:0.0938, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:42:15.440] iteration:13172  t-loss:0.1755, loss-lb:0.0895, loss-ulb:0.0430, weight:2.00, lr:0.0006
[11:42:15.632] iteration:13173  t-loss:0.1416, loss-lb:0.0827, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:42:15.825] iteration:13174  t-loss:0.1523, loss-lb:0.0797, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:42:16.017] iteration:13175  t-loss:0.1561, loss-lb:0.0953, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:42:16.210] iteration:13176  t-loss:0.1631, loss-lb:0.0824, loss-ulb:0.0404, weight:2.00, lr:0.0006
[11:42:16.402] iteration:13177  t-loss:0.1355, loss-lb:0.0813, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:42:16.594] iteration:13178  t-loss:0.1391, loss-lb:0.0752, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:42:16.788] iteration:13179  t-loss:0.1369, loss-lb:0.0829, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:42:16.980] iteration:13180  t-loss:0.1485, loss-lb:0.0870, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:42:17.173] iteration:13181  t-loss:0.1351, loss-lb:0.0807, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:42:17.365] iteration:13182  t-loss:0.1364, loss-lb:0.0840, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:42:17.558] iteration:13183  t-loss:0.1427, loss-lb:0.0823, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:42:17.750] iteration:13184  t-loss:0.1654, loss-lb:0.0844, loss-ulb:0.0405, weight:2.00, lr:0.0006
[11:42:17.944] iteration:13185  t-loss:0.2363, loss-lb:0.0911, loss-ulb:0.0726, weight:2.00, lr:0.0006
[11:42:18.136] iteration:13186  t-loss:0.1324, loss-lb:0.0768, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:42:18.329] iteration:13187  t-loss:0.1882, loss-lb:0.1065, loss-ulb:0.0409, weight:2.00, lr:0.0006
[11:42:18.522] iteration:13188  t-loss:0.1312, loss-lb:0.0774, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:42:18.714] iteration:13189  t-loss:0.1408, loss-lb:0.0771, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:42:18.908] iteration:13190  t-loss:0.1645, loss-lb:0.0920, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:42:19.100] iteration:13191  t-loss:0.1416, loss-lb:0.0867, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:42:19.292] iteration:13192  t-loss:0.1766, loss-lb:0.0818, loss-ulb:0.0474, weight:2.00, lr:0.0006
[11:42:19.484] iteration:13193  t-loss:0.1265, loss-lb:0.0763, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:42:19.677] iteration:13194  t-loss:0.1405, loss-lb:0.0809, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:42:19.869] iteration:13195  t-loss:0.1386, loss-lb:0.0786, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:42:20.062] iteration:13196  t-loss:0.1452, loss-lb:0.0849, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:42:20.254] iteration:13197  t-loss:0.1570, loss-lb:0.0997, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:42:20.448] iteration:13198  t-loss:0.1524, loss-lb:0.0896, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:42:20.641] iteration:13199  t-loss:0.1353, loss-lb:0.0917, loss-ulb:0.0218, weight:2.00, lr:0.0006
[11:42:20.835] iteration:13200  t-loss:0.1379, loss-lb:0.0746, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:42:21.028] iteration:13201  t-loss:0.2058, loss-lb:0.0775, loss-ulb:0.0642, weight:2.00, lr:0.0006
[11:42:21.221] iteration:13202  t-loss:0.1402, loss-lb:0.0786, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:42:21.413] iteration:13203  t-loss:0.1405, loss-lb:0.0859, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:42:21.607] iteration:13204  t-loss:0.1442, loss-lb:0.0859, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:42:21.801] iteration:13205  t-loss:0.2410, loss-lb:0.0914, loss-ulb:0.0748, weight:2.00, lr:0.0006
[11:42:21.993] iteration:13206  t-loss:0.1523, loss-lb:0.0797, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:42:22.185] iteration:13207  t-loss:0.1394, loss-lb:0.0841, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:42:22.378] iteration:13208  t-loss:0.1588, loss-lb:0.0830, loss-ulb:0.0379, weight:2.00, lr:0.0006
[11:42:22.571] iteration:13209  t-loss:0.1546, loss-lb:0.0838, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:42:22.763] iteration:13210  t-loss:0.1469, loss-lb:0.0890, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:42:22.955] iteration:13211  t-loss:0.1437, loss-lb:0.0852, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:42:23.149] iteration:13212  t-loss:0.1641, loss-lb:0.0889, loss-ulb:0.0376, weight:2.00, lr:0.0006
[11:42:23.340] iteration:13213  t-loss:0.1629, loss-lb:0.0835, loss-ulb:0.0397, weight:2.00, lr:0.0006
[11:42:23.532] iteration:13214  t-loss:0.1363, loss-lb:0.0806, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:42:23.726] iteration:13215  t-loss:0.1490, loss-lb:0.0859, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:42:23.919] iteration:13216  t-loss:0.1499, loss-lb:0.0789, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:42:24.111] iteration:13217  t-loss:0.1355, loss-lb:0.0884, loss-ulb:0.0236, weight:2.00, lr:0.0006
[11:42:24.303] iteration:13218  t-loss:0.1420, loss-lb:0.0897, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:42:24.497] iteration:13219  t-loss:0.2253, loss-lb:0.0826, loss-ulb:0.0714, weight:2.00, lr:0.0006
[11:42:24.689] iteration:13220  t-loss:0.1385, loss-lb:0.0807, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:42:24.882] iteration:13221  t-loss:0.1378, loss-lb:0.0763, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:42:25.076] iteration:13222  t-loss:0.1403, loss-lb:0.0745, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:42:25.268] iteration:13223  t-loss:0.1471, loss-lb:0.0872, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:42:25.459] iteration:13224  t-loss:0.1639, loss-lb:0.1023, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:42:25.650] iteration:13225  t-loss:0.1375, loss-lb:0.0777, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:42:25.840] iteration:13226  t-loss:0.1388, loss-lb:0.0801, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:42:26.033] iteration:13227  t-loss:0.1365, loss-lb:0.0790, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:42:26.223] iteration:13228  t-loss:0.1636, loss-lb:0.0948, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:42:26.414] iteration:13229  t-loss:0.1542, loss-lb:0.0777, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:42:26.605] iteration:13230  t-loss:0.1697, loss-lb:0.1070, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:42:39.474]  <<Test>> - Ep:134  - mean_dice/mean_h95 - S:89.99/1.28, Best-S:90.30, T:89.97/1.32, Best-T:90.48
[11:42:39.474]           - AvgLoss(lb/ulb/all):0.0851/0.0334/0.1518
[11:42:40.023] iteration:13231  t-loss:0.1461, loss-lb:0.0841, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:42:40.222] iteration:13232  t-loss:0.1742, loss-lb:0.0862, loss-ulb:0.0440, weight:2.00, lr:0.0006
[11:42:40.417] iteration:13233  t-loss:0.1479, loss-lb:0.0843, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:42:40.610] iteration:13234  t-loss:0.1750, loss-lb:0.0847, loss-ulb:0.0452, weight:2.00, lr:0.0006
[11:42:40.801] iteration:13235  t-loss:0.1449, loss-lb:0.0885, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:42:40.992] iteration:13236  t-loss:0.1328, loss-lb:0.0846, loss-ulb:0.0241, weight:2.00, lr:0.0006
[11:42:41.184] iteration:13237  t-loss:0.1379, loss-lb:0.0856, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:42:41.375] iteration:13238  t-loss:0.1497, loss-lb:0.0856, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:42:41.568] iteration:13239  t-loss:0.1311, loss-lb:0.0813, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:42:41.761] iteration:13240  t-loss:0.1730, loss-lb:0.0773, loss-ulb:0.0479, weight:2.00, lr:0.0006
[11:42:41.954] iteration:13241  t-loss:0.1566, loss-lb:0.0830, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:42:42.148] iteration:13242  t-loss:0.1429, loss-lb:0.0832, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:42:42.340] iteration:13243  t-loss:0.1414, loss-lb:0.0871, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:42:42.532] iteration:13244  t-loss:0.1583, loss-lb:0.0818, loss-ulb:0.0383, weight:2.00, lr:0.0006
[11:42:42.726] iteration:13245  t-loss:0.1458, loss-lb:0.0832, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:42:42.919] iteration:13246  t-loss:0.1456, loss-lb:0.0899, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:42:43.111] iteration:13247  t-loss:0.1608, loss-lb:0.0973, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:42:43.302] iteration:13248  t-loss:0.1464, loss-lb:0.0863, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:42:43.496] iteration:13249  t-loss:0.1540, loss-lb:0.0922, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:42:43.689] iteration:13250  t-loss:0.1346, loss-lb:0.0779, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:42:43.881] iteration:13251  t-loss:0.1422, loss-lb:0.0878, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:42:44.072] iteration:13252  t-loss:0.1422, loss-lb:0.0880, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:42:44.265] iteration:13253  t-loss:0.1376, loss-lb:0.0826, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:42:44.457] iteration:13254  t-loss:0.1500, loss-lb:0.0797, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:42:44.649] iteration:13255  t-loss:0.1450, loss-lb:0.0869, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:42:44.842] iteration:13256  t-loss:0.1938, loss-lb:0.0817, loss-ulb:0.0560, weight:2.00, lr:0.0006
[11:42:45.037] iteration:13257  t-loss:0.1585, loss-lb:0.0904, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:42:45.230] iteration:13258  t-loss:0.1423, loss-lb:0.0810, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:42:45.422] iteration:13259  t-loss:0.1594, loss-lb:0.0761, loss-ulb:0.0416, weight:2.00, lr:0.0006
[11:42:45.614] iteration:13260  t-loss:0.1566, loss-lb:0.0808, loss-ulb:0.0379, weight:2.00, lr:0.0006
[11:42:45.806] iteration:13261  t-loss:0.1365, loss-lb:0.0759, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:42:45.997] iteration:13262  t-loss:0.1458, loss-lb:0.0888, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:42:46.190] iteration:13263  t-loss:0.1344, loss-lb:0.0828, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:42:46.380] iteration:13264  t-loss:0.1476, loss-lb:0.0809, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:42:46.572] iteration:13265  t-loss:0.1363, loss-lb:0.0780, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:42:46.764] iteration:13266  t-loss:0.1289, loss-lb:0.0789, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:42:46.955] iteration:13267  t-loss:0.1481, loss-lb:0.0840, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:42:47.146] iteration:13268  t-loss:0.1378, loss-lb:0.0829, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:42:47.339] iteration:13269  t-loss:0.1464, loss-lb:0.0879, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:42:47.530] iteration:13270  t-loss:0.1423, loss-lb:0.0860, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:42:47.722] iteration:13271  t-loss:0.1710, loss-lb:0.0905, loss-ulb:0.0402, weight:2.00, lr:0.0006
[11:42:47.913] iteration:13272  t-loss:0.1418, loss-lb:0.0911, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:42:48.104] iteration:13273  t-loss:0.1519, loss-lb:0.0806, loss-ulb:0.0356, weight:2.00, lr:0.0006
[11:42:48.297] iteration:13274  t-loss:0.1378, loss-lb:0.0735, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:42:48.488] iteration:13275  t-loss:0.1292, loss-lb:0.0689, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:42:48.678] iteration:13276  t-loss:0.1342, loss-lb:0.0849, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:42:48.870] iteration:13277  t-loss:0.1933, loss-lb:0.0786, loss-ulb:0.0573, weight:2.00, lr:0.0006
[11:42:49.062] iteration:13278  t-loss:0.1339, loss-lb:0.0807, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:42:49.254] iteration:13279  t-loss:0.1450, loss-lb:0.0867, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:42:49.444] iteration:13280  t-loss:0.1491, loss-lb:0.0968, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:42:49.637] iteration:13281  t-loss:0.1340, loss-lb:0.0758, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:42:49.828] iteration:13282  t-loss:0.1763, loss-lb:0.0859, loss-ulb:0.0452, weight:2.00, lr:0.0006
[11:42:50.020] iteration:13283  t-loss:0.1361, loss-lb:0.0833, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:42:50.211] iteration:13284  t-loss:0.2418, loss-lb:0.0902, loss-ulb:0.0758, weight:2.00, lr:0.0006
[11:42:50.405] iteration:13285  t-loss:0.1300, loss-lb:0.0767, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:42:50.601] iteration:13286  t-loss:0.1574, loss-lb:0.0845, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:42:50.794] iteration:13287  t-loss:0.1447, loss-lb:0.0820, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:42:50.987] iteration:13288  t-loss:0.1409, loss-lb:0.0852, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:42:51.180] iteration:13289  t-loss:0.1596, loss-lb:0.0915, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:42:51.373] iteration:13290  t-loss:0.1572, loss-lb:0.0833, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:42:51.565] iteration:13291  t-loss:0.1439, loss-lb:0.0760, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:42:51.755] iteration:13292  t-loss:0.1398, loss-lb:0.0855, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:42:51.949] iteration:13293  t-loss:0.1389, loss-lb:0.0867, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:42:52.141] iteration:13294  t-loss:0.1720, loss-lb:0.0867, loss-ulb:0.0426, weight:2.00, lr:0.0006
[11:42:52.333] iteration:13295  t-loss:0.1419, loss-lb:0.0800, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:42:52.523] iteration:13296  t-loss:0.1547, loss-lb:0.0887, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:42:52.716] iteration:13297  t-loss:0.1485, loss-lb:0.0876, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:42:52.907] iteration:13298  t-loss:0.1364, loss-lb:0.0787, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:42:53.100] iteration:13299  t-loss:0.2015, loss-lb:0.0817, loss-ulb:0.0599, weight:2.00, lr:0.0006
[11:42:53.291] iteration:13300  t-loss:0.1382, loss-lb:0.0872, loss-ulb:0.0255, weight:2.00, lr:0.0006
[11:42:53.483] iteration:13301  t-loss:0.1505, loss-lb:0.0829, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:42:53.674] iteration:13302  t-loss:0.1475, loss-lb:0.0755, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:42:53.866] iteration:13303  t-loss:0.1501, loss-lb:0.0894, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:42:54.057] iteration:13304  t-loss:0.1625, loss-lb:0.0839, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:42:54.249] iteration:13305  t-loss:0.1399, loss-lb:0.0825, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:42:54.442] iteration:13306  t-loss:0.1478, loss-lb:0.0856, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:42:54.632] iteration:13307  t-loss:0.1422, loss-lb:0.0835, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:42:54.824] iteration:13308  t-loss:0.1534, loss-lb:0.0846, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:42:55.016] iteration:13309  t-loss:0.1486, loss-lb:0.0842, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:42:55.208] iteration:13310  t-loss:0.1432, loss-lb:0.0872, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:42:55.400] iteration:13311  t-loss:0.1413, loss-lb:0.0806, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:42:55.590] iteration:13312  t-loss:0.1570, loss-lb:0.1019, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:42:55.782] iteration:13313  t-loss:0.1375, loss-lb:0.0830, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:42:55.975] iteration:13314  t-loss:0.1658, loss-lb:0.0839, loss-ulb:0.0409, weight:2.00, lr:0.0006
[11:42:56.168] iteration:13315  t-loss:0.1329, loss-lb:0.0780, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:42:56.358] iteration:13316  t-loss:0.1386, loss-lb:0.0833, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:42:56.550] iteration:13317  t-loss:0.1481, loss-lb:0.0876, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:42:56.742] iteration:13318  t-loss:0.1475, loss-lb:0.0762, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:42:56.934] iteration:13319  t-loss:0.1413, loss-lb:0.0881, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:42:57.124] iteration:13320  t-loss:0.1536, loss-lb:0.0880, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:42:57.316] iteration:13321  t-loss:0.1332, loss-lb:0.0810, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:42:57.506] iteration:13322  t-loss:0.1604, loss-lb:0.0916, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:42:57.697] iteration:13323  t-loss:0.1504, loss-lb:0.0868, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:42:57.888] iteration:13324  t-loss:0.2008, loss-lb:0.0851, loss-ulb:0.0578, weight:2.00, lr:0.0006
[11:42:58.079] iteration:13325  t-loss:0.1449, loss-lb:0.0836, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:42:58.270] iteration:13326  t-loss:0.1416, loss-lb:0.0864, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:42:58.462] iteration:13327  t-loss:0.1290, loss-lb:0.0825, loss-ulb:0.0232, weight:2.00, lr:0.0006
[11:42:58.651] iteration:13328  t-loss:0.1901, loss-lb:0.0780, loss-ulb:0.0560, weight:2.00, lr:0.0006
[11:42:59.260] iteration:13329  t-loss:0.1355, loss-lb:0.0835, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:42:59.455] iteration:13330  t-loss:0.2375, loss-lb:0.0900, loss-ulb:0.0737, weight:2.00, lr:0.0006
[11:42:59.646] iteration:13331  t-loss:0.1391, loss-lb:0.0767, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:42:59.838] iteration:13332  t-loss:0.1441, loss-lb:0.0845, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:43:00.029] iteration:13333  t-loss:0.2028, loss-lb:0.0826, loss-ulb:0.0601, weight:2.00, lr:0.0006
[11:43:00.220] iteration:13334  t-loss:0.1629, loss-lb:0.0917, loss-ulb:0.0356, weight:2.00, lr:0.0006
[11:43:00.412] iteration:13335  t-loss:0.3288, loss-lb:0.0820, loss-ulb:0.1234, weight:2.00, lr:0.0006
[11:43:00.604] iteration:13336  t-loss:0.3210, loss-lb:0.0864, loss-ulb:0.1173, weight:2.00, lr:0.0006
[11:43:00.795] iteration:13337  t-loss:0.1572, loss-lb:0.0887, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:43:00.987] iteration:13338  t-loss:0.2633, loss-lb:0.0871, loss-ulb:0.0881, weight:2.00, lr:0.0006
[11:43:01.181] iteration:13339  t-loss:0.1487, loss-lb:0.0772, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:43:01.394] iteration:13340  t-loss:0.1583, loss-lb:0.0915, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:43:01.598] iteration:13341  t-loss:0.1568, loss-lb:0.0875, loss-ulb:0.0346, weight:2.00, lr:0.0006
[11:43:01.795] iteration:13342  t-loss:0.1480, loss-lb:0.0850, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:43:01.987] iteration:13343  t-loss:0.1554, loss-lb:0.0848, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:43:02.179] iteration:13344  t-loss:0.1675, loss-lb:0.0911, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:43:02.371] iteration:13345  t-loss:0.1724, loss-lb:0.0972, loss-ulb:0.0376, weight:2.00, lr:0.0006
[11:43:02.566] iteration:13346  t-loss:0.1659, loss-lb:0.0881, loss-ulb:0.0389, weight:2.00, lr:0.0006
[11:43:02.758] iteration:13347  t-loss:0.1413, loss-lb:0.0816, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:43:02.950] iteration:13348  t-loss:0.1781, loss-lb:0.0834, loss-ulb:0.0474, weight:2.00, lr:0.0006
[11:43:03.142] iteration:13349  t-loss:0.1435, loss-lb:0.0816, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:43:03.334] iteration:13350  t-loss:0.1377, loss-lb:0.0817, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:43:03.527] iteration:13351  t-loss:0.1585, loss-lb:0.0845, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:43:03.719] iteration:13352  t-loss:0.1595, loss-lb:0.0941, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:43:03.910] iteration:13353  t-loss:0.1381, loss-lb:0.0793, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:43:04.102] iteration:13354  t-loss:0.1543, loss-lb:0.0970, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:43:04.295] iteration:13355  t-loss:0.2096, loss-lb:0.0861, loss-ulb:0.0618, weight:2.00, lr:0.0006
[11:43:04.487] iteration:13356  t-loss:0.1336, loss-lb:0.0770, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:43:04.679] iteration:13357  t-loss:0.1544, loss-lb:0.0828, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:43:04.871] iteration:13358  t-loss:0.1647, loss-lb:0.0961, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:43:05.063] iteration:13359  t-loss:0.1606, loss-lb:0.0826, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:43:05.255] iteration:13360  t-loss:0.1506, loss-lb:0.0893, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:43:05.448] iteration:13361  t-loss:0.1462, loss-lb:0.0761, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:43:05.641] iteration:13362  t-loss:0.1392, loss-lb:0.0849, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:43:05.833] iteration:13363  t-loss:0.1788, loss-lb:0.0867, loss-ulb:0.0461, weight:2.00, lr:0.0006
[11:43:06.026] iteration:13364  t-loss:0.1735, loss-lb:0.0960, loss-ulb:0.0388, weight:2.00, lr:0.0006
[11:43:06.217] iteration:13365  t-loss:0.1499, loss-lb:0.0865, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:43:06.409] iteration:13366  t-loss:0.1384, loss-lb:0.0862, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:43:06.601] iteration:13367  t-loss:0.1538, loss-lb:0.0928, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:43:06.793] iteration:13368  t-loss:0.1508, loss-lb:0.0882, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:43:06.986] iteration:13369  t-loss:0.1582, loss-lb:0.0840, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:43:07.178] iteration:13370  t-loss:0.1893, loss-lb:0.0872, loss-ulb:0.0511, weight:2.00, lr:0.0006
[11:43:07.371] iteration:13371  t-loss:0.1421, loss-lb:0.0867, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:43:07.563] iteration:13372  t-loss:0.1464, loss-lb:0.0834, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:43:07.754] iteration:13373  t-loss:0.1264, loss-lb:0.0757, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:43:07.946] iteration:13374  t-loss:0.1305, loss-lb:0.0724, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:43:08.138] iteration:13375  t-loss:0.1537, loss-lb:0.0937, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:43:08.329] iteration:13376  t-loss:0.1453, loss-lb:0.0777, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:43:08.521] iteration:13377  t-loss:0.1641, loss-lb:0.0901, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:43:08.714] iteration:13378  t-loss:0.1393, loss-lb:0.0765, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:43:08.905] iteration:13379  t-loss:0.1570, loss-lb:0.0931, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:43:09.097] iteration:13380  t-loss:0.1443, loss-lb:0.0828, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:43:09.288] iteration:13381  t-loss:0.1325, loss-lb:0.0788, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:43:09.479] iteration:13382  t-loss:0.1726, loss-lb:0.0765, loss-ulb:0.0480, weight:2.00, lr:0.0006
[11:43:09.672] iteration:13383  t-loss:0.1379, loss-lb:0.0808, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:43:09.863] iteration:13384  t-loss:0.1389, loss-lb:0.0856, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:43:10.055] iteration:13385  t-loss:0.1668, loss-lb:0.0855, loss-ulb:0.0406, weight:2.00, lr:0.0006
[11:43:10.248] iteration:13386  t-loss:0.1432, loss-lb:0.0780, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:43:10.438] iteration:13387  t-loss:0.1607, loss-lb:0.0837, loss-ulb:0.0385, weight:2.00, lr:0.0006
[11:43:10.630] iteration:13388  t-loss:0.1561, loss-lb:0.0927, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:43:10.821] iteration:13389  t-loss:0.1551, loss-lb:0.0840, loss-ulb:0.0356, weight:2.00, lr:0.0006
[11:43:11.013] iteration:13390  t-loss:0.1692, loss-lb:0.1133, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:43:11.206] iteration:13391  t-loss:0.1598, loss-lb:0.0989, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:43:11.398] iteration:13392  t-loss:0.1989, loss-lb:0.1000, loss-ulb:0.0494, weight:2.00, lr:0.0006
[11:43:11.589] iteration:13393  t-loss:0.1502, loss-lb:0.0886, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:43:11.781] iteration:13394  t-loss:0.1398, loss-lb:0.0865, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:43:11.973] iteration:13395  t-loss:0.1453, loss-lb:0.0926, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:43:12.165] iteration:13396  t-loss:0.1438, loss-lb:0.0775, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:43:12.358] iteration:13397  t-loss:0.1454, loss-lb:0.0775, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:43:12.551] iteration:13398  t-loss:0.1667, loss-lb:0.1034, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:43:12.744] iteration:13399  t-loss:0.1459, loss-lb:0.0892, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:43:12.936] iteration:13400  t-loss:0.1384, loss-lb:0.0839, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:43:13.129] iteration:13401  t-loss:0.1443, loss-lb:0.0889, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:43:13.322] iteration:13402  t-loss:0.2677, loss-lb:0.0851, loss-ulb:0.0913, weight:2.00, lr:0.0006
[11:43:13.514] iteration:13403  t-loss:0.1440, loss-lb:0.0905, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:43:13.706] iteration:13404  t-loss:0.1438, loss-lb:0.0916, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:43:13.899] iteration:13405  t-loss:0.1644, loss-lb:0.0884, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:43:14.091] iteration:13406  t-loss:0.1547, loss-lb:0.0871, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:43:14.283] iteration:13407  t-loss:0.1455, loss-lb:0.0893, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:43:14.475] iteration:13408  t-loss:0.1504, loss-lb:0.0818, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:43:14.667] iteration:13409  t-loss:0.1327, loss-lb:0.0819, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:43:14.859] iteration:13410  t-loss:0.1590, loss-lb:0.0905, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:43:15.053] iteration:13411  t-loss:0.1588, loss-lb:0.0876, loss-ulb:0.0356, weight:2.00, lr:0.0006
[11:43:15.245] iteration:13412  t-loss:0.1358, loss-lb:0.0784, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:43:15.437] iteration:13413  t-loss:0.1505, loss-lb:0.0857, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:43:15.630] iteration:13414  t-loss:0.1473, loss-lb:0.0879, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:43:15.823] iteration:13415  t-loss:0.2492, loss-lb:0.0844, loss-ulb:0.0824, weight:2.00, lr:0.0006
[11:43:16.015] iteration:13416  t-loss:0.1469, loss-lb:0.0794, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:43:16.207] iteration:13417  t-loss:0.1362, loss-lb:0.0868, loss-ulb:0.0247, weight:2.00, lr:0.0006
[11:43:16.400] iteration:13418  t-loss:0.1553, loss-lb:0.0863, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:43:16.592] iteration:13419  t-loss:0.1443, loss-lb:0.0918, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:43:16.783] iteration:13420  t-loss:0.1450, loss-lb:0.0855, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:43:16.973] iteration:13421  t-loss:0.1549, loss-lb:0.0936, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:43:17.162] iteration:13422  t-loss:0.1491, loss-lb:0.0883, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:43:17.353] iteration:13423  t-loss:0.1284, loss-lb:0.0800, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:43:17.544] iteration:13424  t-loss:0.1412, loss-lb:0.0879, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:43:17.734] iteration:13425  t-loss:0.1415, loss-lb:0.0866, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:43:17.925] iteration:13426  t-loss:0.1282, loss-lb:0.0741, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:43:29.058]  <<Test>> - Ep:136  - mean_dice/mean_h95 - S:89.42/3.79, Best-S:90.30, T:89.99/1.35, Best-T:90.48
[11:43:29.058]           - AvgLoss(lb/ulb/all):0.0862/0.0323/0.1500
[11:43:29.591] iteration:13427  t-loss:0.1378, loss-lb:0.0831, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:43:29.785] iteration:13428  t-loss:0.1431, loss-lb:0.0845, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:43:29.979] iteration:13429  t-loss:0.1431, loss-lb:0.0820, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:43:30.172] iteration:13430  t-loss:0.1483, loss-lb:0.0952, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:43:30.366] iteration:13431  t-loss:0.2877, loss-lb:0.0847, loss-ulb:0.1015, weight:2.00, lr:0.0006
[11:43:30.559] iteration:13432  t-loss:0.1733, loss-lb:0.0923, loss-ulb:0.0405, weight:2.00, lr:0.0006
[11:43:30.751] iteration:13433  t-loss:0.1420, loss-lb:0.0800, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:43:30.944] iteration:13434  t-loss:0.1501, loss-lb:0.0912, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:43:31.138] iteration:13435  t-loss:0.2227, loss-lb:0.0852, loss-ulb:0.0688, weight:2.00, lr:0.0006
[11:43:31.330] iteration:13436  t-loss:0.1461, loss-lb:0.0805, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:43:31.523] iteration:13437  t-loss:0.1505, loss-lb:0.0848, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:43:31.716] iteration:13438  t-loss:0.1684, loss-lb:0.0901, loss-ulb:0.0392, weight:2.00, lr:0.0006
[11:43:31.910] iteration:13439  t-loss:0.1459, loss-lb:0.0862, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:43:32.102] iteration:13440  t-loss:0.1769, loss-lb:0.0856, loss-ulb:0.0457, weight:2.00, lr:0.0006
[11:43:32.294] iteration:13441  t-loss:0.1367, loss-lb:0.0811, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:43:32.488] iteration:13442  t-loss:0.1588, loss-lb:0.0942, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:43:32.681] iteration:13443  t-loss:0.1541, loss-lb:0.1004, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:43:32.873] iteration:13444  t-loss:0.1657, loss-lb:0.0896, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:43:33.065] iteration:13445  t-loss:0.2127, loss-lb:0.0954, loss-ulb:0.0586, weight:2.00, lr:0.0006
[11:43:33.258] iteration:13446  t-loss:0.1463, loss-lb:0.0812, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:43:33.451] iteration:13447  t-loss:0.1456, loss-lb:0.0820, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:43:33.643] iteration:13448  t-loss:0.2454, loss-lb:0.1033, loss-ulb:0.0711, weight:2.00, lr:0.0006
[11:43:33.836] iteration:13449  t-loss:0.1758, loss-lb:0.0851, loss-ulb:0.0454, weight:2.00, lr:0.0006
[11:43:34.033] iteration:13450  t-loss:0.1348, loss-lb:0.0827, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:43:34.239] iteration:13451  t-loss:0.2525, loss-lb:0.0799, loss-ulb:0.0863, weight:2.00, lr:0.0006
[11:43:34.436] iteration:13452  t-loss:0.1975, loss-lb:0.1099, loss-ulb:0.0438, weight:2.00, lr:0.0006
[11:43:34.628] iteration:13453  t-loss:0.1748, loss-lb:0.1024, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:43:34.821] iteration:13454  t-loss:0.2434, loss-lb:0.0972, loss-ulb:0.0731, weight:2.00, lr:0.0006
[11:43:35.014] iteration:13455  t-loss:0.1663, loss-lb:0.1067, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:43:35.206] iteration:13456  t-loss:0.1919, loss-lb:0.0955, loss-ulb:0.0482, weight:2.00, lr:0.0006
[11:43:35.398] iteration:13457  t-loss:0.1469, loss-lb:0.0798, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:43:35.590] iteration:13458  t-loss:0.1419, loss-lb:0.0931, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:43:35.783] iteration:13459  t-loss:0.1553, loss-lb:0.0855, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:43:35.975] iteration:13460  t-loss:0.2440, loss-lb:0.1040, loss-ulb:0.0700, weight:2.00, lr:0.0006
[11:43:36.169] iteration:13461  t-loss:0.1514, loss-lb:0.0923, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:43:36.362] iteration:13462  t-loss:0.2522, loss-lb:0.0963, loss-ulb:0.0780, weight:2.00, lr:0.0006
[11:43:36.553] iteration:13463  t-loss:0.1519, loss-lb:0.0910, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:43:36.745] iteration:13464  t-loss:0.1315, loss-lb:0.0831, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:43:36.937] iteration:13465  t-loss:0.1537, loss-lb:0.0968, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:43:37.129] iteration:13466  t-loss:0.1584, loss-lb:0.0953, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:43:37.322] iteration:13467  t-loss:0.1974, loss-lb:0.1020, loss-ulb:0.0477, weight:2.00, lr:0.0006
[11:43:37.514] iteration:13468  t-loss:0.2124, loss-lb:0.0983, loss-ulb:0.0571, weight:2.00, lr:0.0006
[11:43:37.706] iteration:13469  t-loss:0.1760, loss-lb:0.1043, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:43:37.897] iteration:13470  t-loss:0.1589, loss-lb:0.0875, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:43:38.090] iteration:13471  t-loss:0.1615, loss-lb:0.0874, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:43:38.284] iteration:13472  t-loss:0.3251, loss-lb:0.0982, loss-ulb:0.1134, weight:2.00, lr:0.0006
[11:43:38.475] iteration:13473  t-loss:0.1580, loss-lb:0.0871, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:43:38.667] iteration:13474  t-loss:0.1505, loss-lb:0.0825, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:43:38.859] iteration:13475  t-loss:0.1674, loss-lb:0.0992, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:43:39.052] iteration:13476  t-loss:0.1428, loss-lb:0.0871, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:43:39.245] iteration:13477  t-loss:0.2010, loss-lb:0.0914, loss-ulb:0.0548, weight:2.00, lr:0.0006
[11:43:39.438] iteration:13478  t-loss:0.1452, loss-lb:0.0945, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:43:39.630] iteration:13479  t-loss:0.1662, loss-lb:0.0876, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:43:39.822] iteration:13480  t-loss:0.1462, loss-lb:0.0920, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:43:40.015] iteration:13481  t-loss:0.1559, loss-lb:0.0895, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:43:40.207] iteration:13482  t-loss:0.1392, loss-lb:0.0875, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:43:40.400] iteration:13483  t-loss:0.1394, loss-lb:0.0844, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:43:40.592] iteration:13484  t-loss:0.1566, loss-lb:0.0935, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:43:40.784] iteration:13485  t-loss:0.1376, loss-lb:0.0806, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:43:40.976] iteration:13486  t-loss:0.1590, loss-lb:0.0867, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:43:41.168] iteration:13487  t-loss:0.1495, loss-lb:0.0845, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:43:41.361] iteration:13488  t-loss:0.1505, loss-lb:0.0784, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:43:41.554] iteration:13489  t-loss:0.1601, loss-lb:0.0849, loss-ulb:0.0376, weight:2.00, lr:0.0006
[11:43:41.746] iteration:13490  t-loss:0.1493, loss-lb:0.0968, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:43:41.939] iteration:13491  t-loss:0.1401, loss-lb:0.0848, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:43:42.132] iteration:13492  t-loss:0.1663, loss-lb:0.0894, loss-ulb:0.0384, weight:2.00, lr:0.0006
[11:43:42.324] iteration:13493  t-loss:0.1379, loss-lb:0.0877, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:43:42.517] iteration:13494  t-loss:0.1413, loss-lb:0.0870, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:43:42.709] iteration:13495  t-loss:0.1837, loss-lb:0.0945, loss-ulb:0.0446, weight:2.00, lr:0.0006
[11:43:42.900] iteration:13496  t-loss:0.1377, loss-lb:0.0809, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:43:43.092] iteration:13497  t-loss:0.1590, loss-lb:0.0825, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:43:43.285] iteration:13498  t-loss:0.1472, loss-lb:0.0927, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:43:43.478] iteration:13499  t-loss:0.1442, loss-lb:0.0859, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:43:43.670] iteration:13500  t-loss:0.1491, loss-lb:0.0790, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:43:43.863] iteration:13501  t-loss:0.1464, loss-lb:0.0803, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:43:44.055] iteration:13502  t-loss:0.1441, loss-lb:0.0875, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:43:44.247] iteration:13503  t-loss:0.1589, loss-lb:0.0921, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:43:44.439] iteration:13504  t-loss:0.1728, loss-lb:0.0964, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:43:44.631] iteration:13505  t-loss:0.1955, loss-lb:0.0938, loss-ulb:0.0508, weight:2.00, lr:0.0006
[11:43:44.824] iteration:13506  t-loss:0.1462, loss-lb:0.0931, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:43:45.016] iteration:13507  t-loss:0.1567, loss-lb:0.0819, loss-ulb:0.0374, weight:2.00, lr:0.0006
[11:43:45.208] iteration:13508  t-loss:0.1579, loss-lb:0.0897, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:43:45.402] iteration:13509  t-loss:0.1865, loss-lb:0.0946, loss-ulb:0.0459, weight:2.00, lr:0.0006
[11:43:45.595] iteration:13510  t-loss:0.1581, loss-lb:0.0885, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:43:45.788] iteration:13511  t-loss:0.1839, loss-lb:0.0852, loss-ulb:0.0494, weight:2.00, lr:0.0006
[11:43:45.980] iteration:13512  t-loss:0.1475, loss-lb:0.0799, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:43:46.173] iteration:13513  t-loss:0.1542, loss-lb:0.0954, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:43:46.365] iteration:13514  t-loss:0.3029, loss-lb:0.0916, loss-ulb:0.1057, weight:2.00, lr:0.0006
[11:43:46.559] iteration:13515  t-loss:0.1567, loss-lb:0.0906, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:43:46.751] iteration:13516  t-loss:0.1466, loss-lb:0.0815, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:43:46.943] iteration:13517  t-loss:0.1432, loss-lb:0.0836, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:43:47.133] iteration:13518  t-loss:0.1654, loss-lb:0.0970, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:43:47.324] iteration:13519  t-loss:0.1498, loss-lb:0.0868, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:43:47.515] iteration:13520  t-loss:0.1555, loss-lb:0.0868, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:43:47.705] iteration:13521  t-loss:0.1267, loss-lb:0.0834, loss-ulb:0.0216, weight:2.00, lr:0.0006
[11:43:47.895] iteration:13522  t-loss:0.1484, loss-lb:0.0872, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:43:48.086] iteration:13523  t-loss:0.1382, loss-lb:0.0859, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:43:48.277] iteration:13524  t-loss:0.1357, loss-lb:0.0808, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:43:48.882] iteration:13525  t-loss:0.1519, loss-lb:0.0954, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:43:49.079] iteration:13526  t-loss:0.1445, loss-lb:0.0833, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:43:49.271] iteration:13527  t-loss:0.1409, loss-lb:0.0815, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:43:49.464] iteration:13528  t-loss:0.1333, loss-lb:0.0885, loss-ulb:0.0224, weight:2.00, lr:0.0006
[11:43:49.656] iteration:13529  t-loss:0.1399, loss-lb:0.0844, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:43:49.847] iteration:13530  t-loss:0.1422, loss-lb:0.0868, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:43:50.041] iteration:13531  t-loss:0.1337, loss-lb:0.0809, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:43:50.233] iteration:13532  t-loss:0.1452, loss-lb:0.0918, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:43:50.425] iteration:13533  t-loss:0.1313, loss-lb:0.0834, loss-ulb:0.0239, weight:2.00, lr:0.0006
[11:43:50.618] iteration:13534  t-loss:0.1333, loss-lb:0.0811, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:43:50.811] iteration:13535  t-loss:0.1408, loss-lb:0.0798, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:43:51.003] iteration:13536  t-loss:0.1506, loss-lb:0.0866, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:43:51.194] iteration:13537  t-loss:0.1534, loss-lb:0.0848, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:43:51.386] iteration:13538  t-loss:0.1498, loss-lb:0.0842, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:43:51.578] iteration:13539  t-loss:0.1532, loss-lb:0.0899, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:43:51.778] iteration:13540  t-loss:0.1568, loss-lb:0.1009, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:43:51.970] iteration:13541  t-loss:0.1368, loss-lb:0.0806, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:43:52.162] iteration:13542  t-loss:0.1528, loss-lb:0.0776, loss-ulb:0.0376, weight:2.00, lr:0.0006
[11:43:52.354] iteration:13543  t-loss:0.1432, loss-lb:0.0883, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:43:52.546] iteration:13544  t-loss:0.1513, loss-lb:0.0903, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:43:52.738] iteration:13545  t-loss:0.1440, loss-lb:0.0776, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:43:52.930] iteration:13546  t-loss:0.1509, loss-lb:0.0870, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:43:53.122] iteration:13547  t-loss:0.1419, loss-lb:0.0904, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:43:53.313] iteration:13548  t-loss:0.1320, loss-lb:0.0743, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:43:53.507] iteration:13549  t-loss:0.1501, loss-lb:0.0855, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:43:53.700] iteration:13550  t-loss:0.1786, loss-lb:0.0792, loss-ulb:0.0497, weight:2.00, lr:0.0006
[11:43:53.892] iteration:13551  t-loss:0.1699, loss-lb:0.0894, loss-ulb:0.0403, weight:2.00, lr:0.0006
[11:43:54.085] iteration:13552  t-loss:0.1314, loss-lb:0.0806, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:43:54.278] iteration:13553  t-loss:0.1494, loss-lb:0.0865, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:43:54.470] iteration:13554  t-loss:0.1431, loss-lb:0.0829, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:43:54.662] iteration:13555  t-loss:0.1489, loss-lb:0.0827, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:43:54.855] iteration:13556  t-loss:0.1446, loss-lb:0.0831, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:43:55.047] iteration:13557  t-loss:0.1515, loss-lb:0.0855, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:43:55.240] iteration:13558  t-loss:0.1329, loss-lb:0.0813, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:43:55.433] iteration:13559  t-loss:0.1466, loss-lb:0.0806, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:43:55.627] iteration:13560  t-loss:0.1540, loss-lb:0.0777, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:43:55.819] iteration:13561  t-loss:0.1511, loss-lb:0.0863, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:43:56.011] iteration:13562  t-loss:0.1403, loss-lb:0.0812, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:43:56.205] iteration:13563  t-loss:0.1388, loss-lb:0.0872, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:43:56.397] iteration:13564  t-loss:0.1565, loss-lb:0.0866, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:43:56.589] iteration:13565  t-loss:0.1492, loss-lb:0.0814, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:43:56.781] iteration:13566  t-loss:0.1605, loss-lb:0.0835, loss-ulb:0.0385, weight:2.00, lr:0.0006
[11:43:56.975] iteration:13567  t-loss:0.1467, loss-lb:0.0888, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:43:57.167] iteration:13568  t-loss:0.1303, loss-lb:0.0803, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:43:57.359] iteration:13569  t-loss:0.1537, loss-lb:0.0813, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:43:57.550] iteration:13570  t-loss:0.1401, loss-lb:0.0872, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:43:57.743] iteration:13571  t-loss:0.1473, loss-lb:0.0849, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:43:57.937] iteration:13572  t-loss:0.1240, loss-lb:0.0769, loss-ulb:0.0236, weight:2.00, lr:0.0006
[11:43:58.130] iteration:13573  t-loss:0.1382, loss-lb:0.0815, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:43:58.321] iteration:13574  t-loss:0.1465, loss-lb:0.0793, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:43:58.513] iteration:13575  t-loss:0.1309, loss-lb:0.0765, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:43:58.705] iteration:13576  t-loss:0.1378, loss-lb:0.0748, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:43:58.897] iteration:13577  t-loss:0.1707, loss-lb:0.0944, loss-ulb:0.0381, weight:2.00, lr:0.0006
[11:43:59.089] iteration:13578  t-loss:0.1458, loss-lb:0.0855, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:43:59.284] iteration:13579  t-loss:0.1902, loss-lb:0.0761, loss-ulb:0.0571, weight:2.00, lr:0.0006
[11:43:59.477] iteration:13580  t-loss:0.1443, loss-lb:0.0853, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:43:59.669] iteration:13581  t-loss:0.1386, loss-lb:0.0879, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:43:59.862] iteration:13582  t-loss:0.2136, loss-lb:0.0855, loss-ulb:0.0640, weight:2.00, lr:0.0006
[11:44:00.054] iteration:13583  t-loss:0.1395, loss-lb:0.0811, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:44:00.246] iteration:13584  t-loss:0.1688, loss-lb:0.0834, loss-ulb:0.0427, weight:2.00, lr:0.0006
[11:44:00.439] iteration:13585  t-loss:0.1700, loss-lb:0.0724, loss-ulb:0.0488, weight:2.00, lr:0.0006
[11:44:00.632] iteration:13586  t-loss:0.1477, loss-lb:0.0801, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:44:00.826] iteration:13587  t-loss:0.1515, loss-lb:0.0906, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:44:01.018] iteration:13588  t-loss:0.1437, loss-lb:0.0832, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:44:01.212] iteration:13589  t-loss:0.1360, loss-lb:0.0851, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:44:01.404] iteration:13590  t-loss:0.1495, loss-lb:0.0833, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:44:01.596] iteration:13591  t-loss:0.1435, loss-lb:0.0917, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:44:01.788] iteration:13592  t-loss:0.1467, loss-lb:0.0897, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:44:01.982] iteration:13593  t-loss:0.1689, loss-lb:0.0857, loss-ulb:0.0416, weight:2.00, lr:0.0006
[11:44:02.179] iteration:13594  t-loss:0.1353, loss-lb:0.0856, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:44:02.374] iteration:13595  t-loss:0.1345, loss-lb:0.0885, loss-ulb:0.0230, weight:2.00, lr:0.0006
[11:44:02.570] iteration:13596  t-loss:0.2195, loss-lb:0.0840, loss-ulb:0.0678, weight:2.00, lr:0.0006
[11:44:02.762] iteration:13597  t-loss:0.1299, loss-lb:0.0806, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:44:02.954] iteration:13598  t-loss:0.1406, loss-lb:0.0844, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:44:03.146] iteration:13599  t-loss:0.1367, loss-lb:0.0823, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:44:03.338] iteration:13600  t-loss:0.1386, loss-lb:0.0757, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:44:03.529] iteration:13601  t-loss:0.1210, loss-lb:0.0733, loss-ulb:0.0238, weight:2.00, lr:0.0006
[11:44:03.720] iteration:13602  t-loss:0.1516, loss-lb:0.0827, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:44:03.913] iteration:13603  t-loss:0.1475, loss-lb:0.0872, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:44:04.104] iteration:13604  t-loss:0.1444, loss-lb:0.0862, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:44:04.297] iteration:13605  t-loss:0.1341, loss-lb:0.0746, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:44:04.489] iteration:13606  t-loss:0.1455, loss-lb:0.0816, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:44:04.681] iteration:13607  t-loss:0.1705, loss-lb:0.0807, loss-ulb:0.0449, weight:2.00, lr:0.0006
[11:44:04.873] iteration:13608  t-loss:0.1436, loss-lb:0.0783, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:44:05.065] iteration:13609  t-loss:0.1431, loss-lb:0.0891, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:44:05.256] iteration:13610  t-loss:0.1234, loss-lb:0.0767, loss-ulb:0.0233, weight:2.00, lr:0.0006
[11:44:05.447] iteration:13611  t-loss:0.1368, loss-lb:0.0836, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:44:05.639] iteration:13612  t-loss:0.1364, loss-lb:0.0766, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:44:05.831] iteration:13613  t-loss:0.1569, loss-lb:0.0905, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:44:06.024] iteration:13614  t-loss:0.1549, loss-lb:0.0788, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:44:06.216] iteration:13615  t-loss:0.1407, loss-lb:0.0811, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:44:06.406] iteration:13616  t-loss:0.1528, loss-lb:0.0957, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:44:06.596] iteration:13617  t-loss:0.1364, loss-lb:0.0780, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:44:06.790] iteration:13618  t-loss:0.1399, loss-lb:0.0812, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:44:06.992] iteration:13619  t-loss:0.1215, loss-lb:0.0746, loss-ulb:0.0234, weight:2.00, lr:0.0006
[11:44:07.189] iteration:13620  t-loss:0.1433, loss-lb:0.0845, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:44:07.381] iteration:13621  t-loss:0.1375, loss-lb:0.0729, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:44:07.571] iteration:13622  t-loss:0.1522, loss-lb:0.0846, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:44:20.233]  <<Test>> - Ep:138  - mean_dice/mean_h95 - S:89.83/1.88, Best-S:90.30, T:90.05/1.33, Best-T:90.48
[11:44:20.233]           - AvgLoss(lb/ulb/all):0.0834/0.0306/0.1431
[11:44:20.772] iteration:13623  t-loss:0.1478, loss-lb:0.0811, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:44:20.968] iteration:13624  t-loss:0.1980, loss-lb:0.0820, loss-ulb:0.0580, weight:2.00, lr:0.0006
[11:44:21.160] iteration:13625  t-loss:0.1528, loss-lb:0.0784, loss-ulb:0.0372, weight:2.00, lr:0.0006
[11:44:21.352] iteration:13626  t-loss:0.1581, loss-lb:0.0783, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:44:21.545] iteration:13627  t-loss:0.1289, loss-lb:0.0783, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:44:21.738] iteration:13628  t-loss:0.1436, loss-lb:0.0889, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:44:21.930] iteration:13629  t-loss:0.1430, loss-lb:0.0889, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:44:22.121] iteration:13630  t-loss:0.1397, loss-lb:0.0790, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:44:22.313] iteration:13631  t-loss:0.1395, loss-lb:0.0845, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:44:22.504] iteration:13632  t-loss:0.1383, loss-lb:0.0810, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:44:22.697] iteration:13633  t-loss:0.1310, loss-lb:0.0767, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:44:22.889] iteration:13634  t-loss:0.1624, loss-lb:0.0764, loss-ulb:0.0430, weight:2.00, lr:0.0006
[11:44:23.080] iteration:13635  t-loss:0.1461, loss-lb:0.0868, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:44:23.272] iteration:13636  t-loss:0.2843, loss-lb:0.0877, loss-ulb:0.0983, weight:2.00, lr:0.0006
[11:44:23.465] iteration:13637  t-loss:0.2090, loss-lb:0.0817, loss-ulb:0.0637, weight:2.00, lr:0.0006
[11:44:23.658] iteration:13638  t-loss:0.1488, loss-lb:0.0824, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:44:23.854] iteration:13639  t-loss:0.1511, loss-lb:0.0864, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:44:24.050] iteration:13640  t-loss:0.1555, loss-lb:0.0930, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:44:24.245] iteration:13641  t-loss:0.3101, loss-lb:0.0816, loss-ulb:0.1142, weight:2.00, lr:0.0006
[11:44:24.438] iteration:13642  t-loss:0.1297, loss-lb:0.0744, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:44:24.633] iteration:13643  t-loss:0.1262, loss-lb:0.0761, loss-ulb:0.0250, weight:2.00, lr:0.0006
[11:44:24.826] iteration:13644  t-loss:0.1296, loss-lb:0.0781, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:44:25.018] iteration:13645  t-loss:0.1377, loss-lb:0.0884, loss-ulb:0.0246, weight:2.00, lr:0.0006
[11:44:25.210] iteration:13646  t-loss:0.1485, loss-lb:0.0851, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:44:25.404] iteration:13647  t-loss:0.1618, loss-lb:0.0889, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:44:25.597] iteration:13648  t-loss:0.1585, loss-lb:0.0853, loss-ulb:0.0366, weight:2.00, lr:0.0006
[11:44:25.789] iteration:13649  t-loss:0.1377, loss-lb:0.0763, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:44:25.979] iteration:13650  t-loss:0.1266, loss-lb:0.0771, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:44:26.170] iteration:13651  t-loss:0.1349, loss-lb:0.0788, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:44:26.362] iteration:13652  t-loss:0.1470, loss-lb:0.0886, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:44:26.554] iteration:13653  t-loss:0.1457, loss-lb:0.0847, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:44:26.745] iteration:13654  t-loss:0.1527, loss-lb:0.0800, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:44:26.935] iteration:13655  t-loss:0.1465, loss-lb:0.0915, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:44:27.127] iteration:13656  t-loss:0.1283, loss-lb:0.0770, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:44:27.319] iteration:13657  t-loss:0.1421, loss-lb:0.0822, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:44:27.510] iteration:13658  t-loss:0.1400, loss-lb:0.0789, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:44:27.702] iteration:13659  t-loss:0.1378, loss-lb:0.0824, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:44:27.894] iteration:13660  t-loss:0.1296, loss-lb:0.0752, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:44:28.086] iteration:13661  t-loss:0.1392, loss-lb:0.0929, loss-ulb:0.0232, weight:2.00, lr:0.0006
[11:44:28.277] iteration:13662  t-loss:0.1325, loss-lb:0.0789, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:44:28.471] iteration:13663  t-loss:0.1478, loss-lb:0.0844, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:44:28.663] iteration:13664  t-loss:0.1451, loss-lb:0.0865, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:44:28.855] iteration:13665  t-loss:0.2090, loss-lb:0.0864, loss-ulb:0.0613, weight:2.00, lr:0.0006
[11:44:29.046] iteration:13666  t-loss:0.1408, loss-lb:0.0858, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:44:29.237] iteration:13667  t-loss:0.1333, loss-lb:0.0755, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:44:29.430] iteration:13668  t-loss:0.1564, loss-lb:0.0917, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:44:29.622] iteration:13669  t-loss:0.1299, loss-lb:0.0760, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:44:29.812] iteration:13670  t-loss:0.1371, loss-lb:0.0724, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:44:30.005] iteration:13671  t-loss:0.1752, loss-lb:0.0876, loss-ulb:0.0438, weight:2.00, lr:0.0006
[11:44:30.197] iteration:13672  t-loss:0.1404, loss-lb:0.0823, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:44:30.388] iteration:13673  t-loss:0.1513, loss-lb:0.0776, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:44:30.581] iteration:13674  t-loss:0.1703, loss-lb:0.0882, loss-ulb:0.0411, weight:2.00, lr:0.0006
[11:44:30.772] iteration:13675  t-loss:0.1462, loss-lb:0.0812, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:44:30.964] iteration:13676  t-loss:0.1509, loss-lb:0.0870, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:44:31.156] iteration:13677  t-loss:0.1437, loss-lb:0.0779, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:44:31.347] iteration:13678  t-loss:0.1677, loss-lb:0.0937, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:44:31.539] iteration:13679  t-loss:0.1508, loss-lb:0.0903, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:44:31.730] iteration:13680  t-loss:0.1389, loss-lb:0.0829, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:44:31.922] iteration:13681  t-loss:0.2654, loss-lb:0.0888, loss-ulb:0.0883, weight:2.00, lr:0.0006
[11:44:32.114] iteration:13682  t-loss:0.1766, loss-lb:0.0828, loss-ulb:0.0469, weight:2.00, lr:0.0006
[11:44:32.306] iteration:13683  t-loss:0.1343, loss-lb:0.0759, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:44:32.499] iteration:13684  t-loss:0.2179, loss-lb:0.0833, loss-ulb:0.0673, weight:2.00, lr:0.0006
[11:44:32.691] iteration:13685  t-loss:0.1305, loss-lb:0.0835, loss-ulb:0.0235, weight:2.00, lr:0.0006
[11:44:32.882] iteration:13686  t-loss:0.1432, loss-lb:0.0839, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:44:33.075] iteration:13687  t-loss:0.2004, loss-lb:0.0831, loss-ulb:0.0586, weight:2.00, lr:0.0006
[11:44:33.267] iteration:13688  t-loss:0.1683, loss-lb:0.0844, loss-ulb:0.0419, weight:2.00, lr:0.0006
[11:44:33.458] iteration:13689  t-loss:0.1673, loss-lb:0.0876, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:44:33.647] iteration:13690  t-loss:0.1396, loss-lb:0.0849, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:44:33.838] iteration:13691  t-loss:0.1558, loss-lb:0.0834, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:44:34.030] iteration:13692  t-loss:0.1602, loss-lb:0.0936, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:44:34.221] iteration:13693  t-loss:0.2178, loss-lb:0.0960, loss-ulb:0.0609, weight:2.00, lr:0.0006
[11:44:34.412] iteration:13694  t-loss:0.1484, loss-lb:0.0809, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:44:34.606] iteration:13695  t-loss:0.1542, loss-lb:0.0902, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:44:34.801] iteration:13696  t-loss:0.1558, loss-lb:0.0827, loss-ulb:0.0366, weight:2.00, lr:0.0006
[11:44:34.995] iteration:13697  t-loss:0.1428, loss-lb:0.0860, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:44:35.190] iteration:13698  t-loss:0.1673, loss-lb:0.0934, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:44:35.385] iteration:13699  t-loss:0.1397, loss-lb:0.0844, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:44:35.580] iteration:13700  t-loss:0.2076, loss-lb:0.0935, loss-ulb:0.0571, weight:2.00, lr:0.0006
[11:44:35.771] iteration:13701  t-loss:0.1446, loss-lb:0.0784, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:44:35.965] iteration:13702  t-loss:0.1606, loss-lb:0.0846, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:44:36.158] iteration:13703  t-loss:0.1451, loss-lb:0.0851, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:44:36.350] iteration:13704  t-loss:0.1766, loss-lb:0.0806, loss-ulb:0.0480, weight:2.00, lr:0.0006
[11:44:36.542] iteration:13705  t-loss:0.1481, loss-lb:0.0888, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:44:36.733] iteration:13706  t-loss:0.1383, loss-lb:0.0824, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:44:36.924] iteration:13707  t-loss:0.1480, loss-lb:0.0840, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:44:37.116] iteration:13708  t-loss:0.1468, loss-lb:0.0815, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:44:37.308] iteration:13709  t-loss:0.1462, loss-lb:0.0899, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:44:37.499] iteration:13710  t-loss:0.1338, loss-lb:0.0819, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:44:37.691] iteration:13711  t-loss:0.1468, loss-lb:0.0847, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:44:37.884] iteration:13712  t-loss:0.1433, loss-lb:0.0793, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:44:38.075] iteration:13713  t-loss:0.1491, loss-lb:0.0830, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:44:38.266] iteration:13714  t-loss:0.1486, loss-lb:0.0870, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:44:38.459] iteration:13715  t-loss:0.1475, loss-lb:0.0845, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:44:38.649] iteration:13716  t-loss:0.1489, loss-lb:0.0932, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:44:38.841] iteration:13717  t-loss:0.1530, loss-lb:0.0812, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:44:39.033] iteration:13718  t-loss:0.1588, loss-lb:0.0948, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:44:39.224] iteration:13719  t-loss:0.1438, loss-lb:0.0799, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:44:39.412] iteration:13720  t-loss:0.1720, loss-lb:0.0795, loss-ulb:0.0463, weight:2.00, lr:0.0006
[11:44:40.036] iteration:13721  t-loss:0.1550, loss-lb:0.0929, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:44:40.231] iteration:13722  t-loss:0.1345, loss-lb:0.0808, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:44:40.422] iteration:13723  t-loss:0.1560, loss-lb:0.0853, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:44:40.614] iteration:13724  t-loss:0.1452, loss-lb:0.0880, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:44:40.806] iteration:13725  t-loss:0.1430, loss-lb:0.0854, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:44:40.998] iteration:13726  t-loss:0.1514, loss-lb:0.0753, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:44:41.190] iteration:13727  t-loss:0.1383, loss-lb:0.0785, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:44:41.383] iteration:13728  t-loss:0.1410, loss-lb:0.0817, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:44:41.574] iteration:13729  t-loss:0.1406, loss-lb:0.0831, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:44:41.767] iteration:13730  t-loss:0.1429, loss-lb:0.0809, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:44:41.958] iteration:13731  t-loss:0.1372, loss-lb:0.0814, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:44:42.150] iteration:13732  t-loss:0.1521, loss-lb:0.0839, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:44:42.343] iteration:13733  t-loss:0.1337, loss-lb:0.0848, loss-ulb:0.0244, weight:2.00, lr:0.0006
[11:44:42.534] iteration:13734  t-loss:0.1349, loss-lb:0.0844, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:44:42.725] iteration:13735  t-loss:0.1408, loss-lb:0.0895, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:44:42.917] iteration:13736  t-loss:0.1766, loss-lb:0.0797, loss-ulb:0.0484, weight:2.00, lr:0.0006
[11:44:43.108] iteration:13737  t-loss:0.1434, loss-lb:0.0822, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:44:43.299] iteration:13738  t-loss:0.1479, loss-lb:0.0889, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:44:43.490] iteration:13739  t-loss:0.1827, loss-lb:0.0965, loss-ulb:0.0431, weight:2.00, lr:0.0006
[11:44:43.682] iteration:13740  t-loss:0.1380, loss-lb:0.0790, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:44:43.873] iteration:13741  t-loss:0.1575, loss-lb:0.0886, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:44:44.064] iteration:13742  t-loss:0.1455, loss-lb:0.0810, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:44:44.258] iteration:13743  t-loss:0.1362, loss-lb:0.0770, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:44:44.449] iteration:13744  t-loss:0.1392, loss-lb:0.0862, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:44:44.640] iteration:13745  t-loss:0.1498, loss-lb:0.0849, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:44:44.833] iteration:13746  t-loss:0.1693, loss-lb:0.0963, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:44:45.024] iteration:13747  t-loss:0.1952, loss-lb:0.0686, loss-ulb:0.0633, weight:2.00, lr:0.0006
[11:44:45.216] iteration:13748  t-loss:0.1446, loss-lb:0.0760, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:44:45.410] iteration:13749  t-loss:0.3201, loss-lb:0.0817, loss-ulb:0.1192, weight:2.00, lr:0.0006
[11:44:45.602] iteration:13750  t-loss:0.1399, loss-lb:0.0848, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:44:45.795] iteration:13751  t-loss:0.1744, loss-lb:0.0896, loss-ulb:0.0424, weight:2.00, lr:0.0006
[11:44:45.986] iteration:13752  t-loss:0.1490, loss-lb:0.0776, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:44:46.179] iteration:13753  t-loss:0.1375, loss-lb:0.0818, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:44:46.371] iteration:13754  t-loss:0.1747, loss-lb:0.0859, loss-ulb:0.0444, weight:2.00, lr:0.0006
[11:44:46.563] iteration:13755  t-loss:0.1493, loss-lb:0.0982, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:44:46.756] iteration:13756  t-loss:0.1662, loss-lb:0.0922, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:44:46.948] iteration:13757  t-loss:0.1402, loss-lb:0.0794, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:44:47.140] iteration:13758  t-loss:0.1425, loss-lb:0.0901, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:44:47.334] iteration:13759  t-loss:0.2041, loss-lb:0.0908, loss-ulb:0.0567, weight:2.00, lr:0.0006
[11:44:47.526] iteration:13760  t-loss:0.1451, loss-lb:0.0827, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:44:47.718] iteration:13761  t-loss:0.1903, loss-lb:0.0878, loss-ulb:0.0512, weight:2.00, lr:0.0006
[11:44:47.911] iteration:13762  t-loss:0.1485, loss-lb:0.0905, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:44:48.105] iteration:13763  t-loss:0.1568, loss-lb:0.0865, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:44:48.298] iteration:13764  t-loss:0.1417, loss-lb:0.0859, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:44:48.491] iteration:13765  t-loss:0.1316, loss-lb:0.0804, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:44:48.684] iteration:13766  t-loss:0.1508, loss-lb:0.0791, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:44:48.876] iteration:13767  t-loss:0.1247, loss-lb:0.0740, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:44:49.068] iteration:13768  t-loss:0.1622, loss-lb:0.0879, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:44:49.260] iteration:13769  t-loss:0.1624, loss-lb:0.0949, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:44:49.454] iteration:13770  t-loss:0.1607, loss-lb:0.0782, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:44:49.647] iteration:13771  t-loss:0.1275, loss-lb:0.0691, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:44:49.838] iteration:13772  t-loss:0.1463, loss-lb:0.0815, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:44:50.031] iteration:13773  t-loss:0.1507, loss-lb:0.0932, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:44:50.223] iteration:13774  t-loss:0.1454, loss-lb:0.0834, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:44:50.415] iteration:13775  t-loss:0.1432, loss-lb:0.0831, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:44:50.610] iteration:13776  t-loss:0.1750, loss-lb:0.0844, loss-ulb:0.0453, weight:2.00, lr:0.0006
[11:44:50.803] iteration:13777  t-loss:0.2221, loss-lb:0.0895, loss-ulb:0.0663, weight:2.00, lr:0.0006
[11:44:50.996] iteration:13778  t-loss:0.1310, loss-lb:0.0766, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:44:51.188] iteration:13779  t-loss:0.1615, loss-lb:0.0900, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:44:51.380] iteration:13780  t-loss:0.1424, loss-lb:0.0839, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:44:51.573] iteration:13781  t-loss:0.1425, loss-lb:0.0712, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:44:51.766] iteration:13782  t-loss:0.1836, loss-lb:0.0761, loss-ulb:0.0537, weight:2.00, lr:0.0006
[11:44:51.959] iteration:13783  t-loss:0.1416, loss-lb:0.0828, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:44:52.151] iteration:13784  t-loss:0.1518, loss-lb:0.0888, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:44:52.344] iteration:13785  t-loss:0.1866, loss-lb:0.0884, loss-ulb:0.0491, weight:2.00, lr:0.0006
[11:44:52.538] iteration:13786  t-loss:0.1669, loss-lb:0.0867, loss-ulb:0.0401, weight:2.00, lr:0.0006
[11:44:52.731] iteration:13787  t-loss:0.1391, loss-lb:0.0887, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:44:52.924] iteration:13788  t-loss:0.1701, loss-lb:0.0841, loss-ulb:0.0430, weight:2.00, lr:0.0006
[11:44:53.116] iteration:13789  t-loss:0.1379, loss-lb:0.0831, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:44:53.309] iteration:13790  t-loss:0.1616, loss-lb:0.0812, loss-ulb:0.0402, weight:2.00, lr:0.0006
[11:44:53.502] iteration:13791  t-loss:0.1816, loss-lb:0.0809, loss-ulb:0.0503, weight:2.00, lr:0.0006
[11:44:53.693] iteration:13792  t-loss:0.1533, loss-lb:0.0959, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:44:53.886] iteration:13793  t-loss:0.1517, loss-lb:0.0879, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:44:54.079] iteration:13794  t-loss:0.1480, loss-lb:0.0798, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:44:54.273] iteration:13795  t-loss:0.1299, loss-lb:0.0791, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:44:54.465] iteration:13796  t-loss:0.1463, loss-lb:0.0916, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:44:54.658] iteration:13797  t-loss:0.1607, loss-lb:0.0810, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:44:54.851] iteration:13798  t-loss:0.1469, loss-lb:0.0805, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:44:55.043] iteration:13799  t-loss:0.1412, loss-lb:0.0872, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:44:55.236] iteration:13800  t-loss:0.1499, loss-lb:0.0866, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:44:55.428] iteration:13801  t-loss:0.1359, loss-lb:0.0853, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:44:55.621] iteration:13802  t-loss:0.1526, loss-lb:0.0939, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:44:55.813] iteration:13803  t-loss:0.1372, loss-lb:0.0815, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:44:56.005] iteration:13804  t-loss:0.1455, loss-lb:0.0796, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:44:56.198] iteration:13805  t-loss:0.1538, loss-lb:0.0835, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:44:56.390] iteration:13806  t-loss:0.1338, loss-lb:0.0746, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:44:56.581] iteration:13807  t-loss:0.1399, loss-lb:0.0801, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:44:56.774] iteration:13808  t-loss:0.1387, loss-lb:0.0809, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:44:56.967] iteration:13809  t-loss:0.1440, loss-lb:0.0781, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:44:57.159] iteration:13810  t-loss:0.2108, loss-lb:0.0816, loss-ulb:0.0646, weight:2.00, lr:0.0006
[11:44:57.351] iteration:13811  t-loss:0.1587, loss-lb:0.0885, loss-ulb:0.0351, weight:2.00, lr:0.0006
[11:44:57.542] iteration:13812  t-loss:0.1459, loss-lb:0.0885, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:44:57.733] iteration:13813  t-loss:0.1579, loss-lb:0.0843, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:44:57.924] iteration:13814  t-loss:0.1352, loss-lb:0.0801, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:44:58.114] iteration:13815  t-loss:0.1506, loss-lb:0.0984, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:44:58.306] iteration:13816  t-loss:0.1659, loss-lb:0.0889, loss-ulb:0.0385, weight:2.00, lr:0.0006
[11:44:58.496] iteration:13817  t-loss:0.1401, loss-lb:0.0771, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:44:58.688] iteration:13818  t-loss:0.1470, loss-lb:0.0812, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:45:09.842]  <<Test>> - Ep:140  - mean_dice/mean_h95 - S:89.69/1.39, Best-S:90.30, T:90.17/1.33, Best-T:90.48
[11:45:09.842]           - AvgLoss(lb/ulb/all):0.0841/0.0326/0.1492
[11:45:10.372] iteration:13819  t-loss:0.1675, loss-lb:0.0931, loss-ulb:0.0372, weight:2.00, lr:0.0006
[11:45:10.571] iteration:13820  t-loss:0.1329, loss-lb:0.0741, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:45:10.764] iteration:13821  t-loss:0.1304, loss-lb:0.0827, loss-ulb:0.0238, weight:2.00, lr:0.0006
[11:45:10.956] iteration:13822  t-loss:0.1537, loss-lb:0.1001, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:45:11.149] iteration:13823  t-loss:0.1437, loss-lb:0.0792, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:45:11.342] iteration:13824  t-loss:0.1447, loss-lb:0.0842, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:45:11.535] iteration:13825  t-loss:0.1527, loss-lb:0.0828, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:45:11.728] iteration:13826  t-loss:0.2021, loss-lb:0.0860, loss-ulb:0.0580, weight:2.00, lr:0.0006
[11:45:11.920] iteration:13827  t-loss:0.1546, loss-lb:0.0913, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:45:12.113] iteration:13828  t-loss:0.1394, loss-lb:0.0829, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:45:12.308] iteration:13829  t-loss:0.1540, loss-lb:0.0955, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:45:12.514] iteration:13830  t-loss:0.1518, loss-lb:0.0909, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:45:12.712] iteration:13831  t-loss:0.1483, loss-lb:0.0801, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:45:12.908] iteration:13832  t-loss:0.1990, loss-lb:0.0885, loss-ulb:0.0553, weight:2.00, lr:0.0006
[11:45:13.100] iteration:13833  t-loss:0.1411, loss-lb:0.0801, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:45:13.292] iteration:13834  t-loss:0.1440, loss-lb:0.0794, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:45:13.484] iteration:13835  t-loss:0.1626, loss-lb:0.0902, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:45:13.677] iteration:13836  t-loss:0.1712, loss-lb:0.1025, loss-ulb:0.0343, weight:2.00, lr:0.0006
[11:45:13.870] iteration:13837  t-loss:0.1988, loss-lb:0.0928, loss-ulb:0.0530, weight:2.00, lr:0.0006
[11:45:14.062] iteration:13838  t-loss:0.1346, loss-lb:0.0783, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:45:14.256] iteration:13839  t-loss:0.1818, loss-lb:0.0832, loss-ulb:0.0493, weight:2.00, lr:0.0006
[11:45:14.448] iteration:13840  t-loss:0.1456, loss-lb:0.0843, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:45:14.640] iteration:13841  t-loss:0.1263, loss-lb:0.0746, loss-ulb:0.0259, weight:2.00, lr:0.0006
[11:45:14.833] iteration:13842  t-loss:0.1277, loss-lb:0.0796, loss-ulb:0.0241, weight:2.00, lr:0.0006
[11:45:15.025] iteration:13843  t-loss:0.1391, loss-lb:0.0815, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:45:15.216] iteration:13844  t-loss:0.1679, loss-lb:0.0884, loss-ulb:0.0397, weight:2.00, lr:0.0006
[11:45:15.409] iteration:13845  t-loss:0.1304, loss-lb:0.0766, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:45:15.601] iteration:13846  t-loss:0.1458, loss-lb:0.0767, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:45:15.793] iteration:13847  t-loss:0.1301, loss-lb:0.0806, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:45:15.987] iteration:13848  t-loss:0.1255, loss-lb:0.0756, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:45:16.179] iteration:13849  t-loss:0.1289, loss-lb:0.0756, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:45:16.371] iteration:13850  t-loss:0.1633, loss-lb:0.1035, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:45:16.564] iteration:13851  t-loss:0.1650, loss-lb:0.0860, loss-ulb:0.0395, weight:2.00, lr:0.0006
[11:45:16.756] iteration:13852  t-loss:0.1538, loss-lb:0.0866, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:45:16.948] iteration:13853  t-loss:0.1436, loss-lb:0.0905, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:45:17.141] iteration:13854  t-loss:0.1437, loss-lb:0.0808, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:45:17.334] iteration:13855  t-loss:0.1369, loss-lb:0.0843, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:45:17.525] iteration:13856  t-loss:0.1446, loss-lb:0.0763, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:45:17.718] iteration:13857  t-loss:0.1361, loss-lb:0.0812, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:45:17.911] iteration:13858  t-loss:0.1453, loss-lb:0.0860, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:45:18.104] iteration:13859  t-loss:0.1467, loss-lb:0.0839, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:45:18.296] iteration:13860  t-loss:0.1530, loss-lb:0.0830, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:45:18.488] iteration:13861  t-loss:0.1368, loss-lb:0.0814, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:45:18.680] iteration:13862  t-loss:0.1349, loss-lb:0.0794, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:45:18.873] iteration:13863  t-loss:0.1518, loss-lb:0.0801, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:45:19.066] iteration:13864  t-loss:0.1460, loss-lb:0.0789, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:45:19.258] iteration:13865  t-loss:0.1426, loss-lb:0.0816, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:45:19.450] iteration:13866  t-loss:0.1478, loss-lb:0.0823, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:45:19.642] iteration:13867  t-loss:0.1572, loss-lb:0.0991, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:45:19.834] iteration:13868  t-loss:0.1383, loss-lb:0.0838, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:45:20.026] iteration:13869  t-loss:0.1316, loss-lb:0.0768, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:45:20.220] iteration:13870  t-loss:0.1531, loss-lb:0.0871, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:45:20.412] iteration:13871  t-loss:0.1538, loss-lb:0.0834, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:45:20.603] iteration:13872  t-loss:0.1712, loss-lb:0.0970, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:45:20.796] iteration:13873  t-loss:0.1298, loss-lb:0.0737, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:45:20.990] iteration:13874  t-loss:0.1478, loss-lb:0.0823, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:45:21.182] iteration:13875  t-loss:0.1387, loss-lb:0.0848, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:45:21.375] iteration:13876  t-loss:0.1318, loss-lb:0.0812, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:45:21.567] iteration:13877  t-loss:0.1588, loss-lb:0.0844, loss-ulb:0.0372, weight:2.00, lr:0.0006
[11:45:21.760] iteration:13878  t-loss:0.1366, loss-lb:0.0786, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:45:21.952] iteration:13879  t-loss:0.1300, loss-lb:0.0744, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:45:22.145] iteration:13880  t-loss:0.1362, loss-lb:0.0723, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:45:22.338] iteration:13881  t-loss:0.1736, loss-lb:0.0856, loss-ulb:0.0440, weight:2.00, lr:0.0006
[11:45:22.538] iteration:13882  t-loss:0.1508, loss-lb:0.0799, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:45:22.730] iteration:13883  t-loss:0.1737, loss-lb:0.0861, loss-ulb:0.0438, weight:2.00, lr:0.0006
[11:45:22.924] iteration:13884  t-loss:0.1377, loss-lb:0.0871, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:45:23.115] iteration:13885  t-loss:0.1497, loss-lb:0.0900, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:45:23.308] iteration:13886  t-loss:0.1555, loss-lb:0.0806, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:45:23.500] iteration:13887  t-loss:0.1965, loss-lb:0.0829, loss-ulb:0.0568, weight:2.00, lr:0.0006
[11:45:23.692] iteration:13888  t-loss:0.1428, loss-lb:0.0905, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:45:23.884] iteration:13889  t-loss:0.1388, loss-lb:0.0828, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:45:24.077] iteration:13890  t-loss:0.1410, loss-lb:0.0829, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:45:24.270] iteration:13891  t-loss:0.3134, loss-lb:0.0702, loss-ulb:0.1216, weight:2.00, lr:0.0006
[11:45:24.462] iteration:13892  t-loss:0.1368, loss-lb:0.0815, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:45:24.654] iteration:13893  t-loss:0.1362, loss-lb:0.0827, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:45:24.853] iteration:13894  t-loss:0.1527, loss-lb:0.0830, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:45:25.045] iteration:13895  t-loss:0.1477, loss-lb:0.0793, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:45:25.237] iteration:13896  t-loss:0.1356, loss-lb:0.0799, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:45:25.430] iteration:13897  t-loss:0.1468, loss-lb:0.0899, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:45:25.630] iteration:13898  t-loss:0.1615, loss-lb:0.0947, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:45:25.823] iteration:13899  t-loss:0.2905, loss-lb:0.0851, loss-ulb:0.1027, weight:2.00, lr:0.0006
[11:45:26.015] iteration:13900  t-loss:0.1506, loss-lb:0.0857, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:45:26.208] iteration:13901  t-loss:0.1358, loss-lb:0.0770, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:45:26.408] iteration:13902  t-loss:0.1518, loss-lb:0.0808, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:45:26.601] iteration:13903  t-loss:0.1481, loss-lb:0.0797, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:45:26.792] iteration:13904  t-loss:0.1864, loss-lb:0.0818, loss-ulb:0.0523, weight:2.00, lr:0.0006
[11:45:26.984] iteration:13905  t-loss:0.1537, loss-lb:0.0901, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:45:27.184] iteration:13906  t-loss:0.1380, loss-lb:0.0786, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:45:27.377] iteration:13907  t-loss:0.1333, loss-lb:0.0785, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:45:27.569] iteration:13908  t-loss:0.1632, loss-lb:0.0831, loss-ulb:0.0401, weight:2.00, lr:0.0006
[11:45:27.761] iteration:13909  t-loss:0.1733, loss-lb:0.0897, loss-ulb:0.0418, weight:2.00, lr:0.0006
[11:45:27.951] iteration:13910  t-loss:0.1471, loss-lb:0.0797, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:45:28.142] iteration:13911  t-loss:0.1459, loss-lb:0.0852, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:45:28.333] iteration:13912  t-loss:0.1654, loss-lb:0.0921, loss-ulb:0.0366, weight:2.00, lr:0.0006
[11:45:28.524] iteration:13913  t-loss:0.1299, loss-lb:0.0754, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:45:28.715] iteration:13914  t-loss:0.2123, loss-lb:0.0873, loss-ulb:0.0625, weight:2.00, lr:0.0006
[11:45:28.906] iteration:13915  t-loss:0.1452, loss-lb:0.0843, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:45:29.097] iteration:13916  t-loss:0.1469, loss-lb:0.0849, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:45:29.700] iteration:13917  t-loss:0.1575, loss-lb:0.0907, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:45:29.896] iteration:13918  t-loss:0.1641, loss-lb:0.0844, loss-ulb:0.0398, weight:2.00, lr:0.0006
[11:45:30.090] iteration:13919  t-loss:0.1587, loss-lb:0.0898, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:45:30.283] iteration:13920  t-loss:0.1529, loss-lb:0.0897, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:45:30.474] iteration:13921  t-loss:0.1359, loss-lb:0.0813, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:45:30.668] iteration:13922  t-loss:0.1525, loss-lb:0.0797, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:45:30.862] iteration:13923  t-loss:0.1483, loss-lb:0.0833, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:45:31.054] iteration:13924  t-loss:0.1541, loss-lb:0.0811, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:45:31.246] iteration:13925  t-loss:0.1350, loss-lb:0.0826, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:45:31.440] iteration:13926  t-loss:0.1338, loss-lb:0.0807, loss-ulb:0.0265, weight:2.00, lr:0.0006
[11:45:31.632] iteration:13927  t-loss:0.1516, loss-lb:0.0866, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:45:31.825] iteration:13928  t-loss:0.1691, loss-lb:0.0856, loss-ulb:0.0417, weight:2.00, lr:0.0006
[11:45:32.018] iteration:13929  t-loss:0.1555, loss-lb:0.0971, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:45:32.212] iteration:13930  t-loss:0.1507, loss-lb:0.0900, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:45:32.403] iteration:13931  t-loss:0.1508, loss-lb:0.0830, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:45:32.597] iteration:13932  t-loss:0.1656, loss-lb:0.0799, loss-ulb:0.0428, weight:2.00, lr:0.0006
[11:45:32.790] iteration:13933  t-loss:0.1411, loss-lb:0.0859, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:45:32.982] iteration:13934  t-loss:0.2363, loss-lb:0.0891, loss-ulb:0.0736, weight:2.00, lr:0.0006
[11:45:33.174] iteration:13935  t-loss:0.1577, loss-lb:0.0894, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:45:33.367] iteration:13936  t-loss:0.1625, loss-lb:0.0894, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:45:33.560] iteration:13937  t-loss:0.1824, loss-lb:0.0797, loss-ulb:0.0513, weight:2.00, lr:0.0006
[11:45:33.753] iteration:13938  t-loss:0.1734, loss-lb:0.0830, loss-ulb:0.0452, weight:2.00, lr:0.0006
[11:45:33.946] iteration:13939  t-loss:0.1681, loss-lb:0.0871, loss-ulb:0.0405, weight:2.00, lr:0.0006
[11:45:34.139] iteration:13940  t-loss:0.1613, loss-lb:0.0792, loss-ulb:0.0411, weight:2.00, lr:0.0006
[11:45:34.331] iteration:13941  t-loss:0.1530, loss-lb:0.0749, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:45:34.523] iteration:13942  t-loss:0.1493, loss-lb:0.0794, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:45:34.715] iteration:13943  t-loss:0.1482, loss-lb:0.0818, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:45:34.908] iteration:13944  t-loss:0.1382, loss-lb:0.0849, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:45:35.101] iteration:13945  t-loss:0.1655, loss-lb:0.0999, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:45:35.294] iteration:13946  t-loss:0.1662, loss-lb:0.0848, loss-ulb:0.0407, weight:2.00, lr:0.0006
[11:45:35.489] iteration:13947  t-loss:0.1405, loss-lb:0.0823, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:45:35.687] iteration:13948  t-loss:0.2399, loss-lb:0.1014, loss-ulb:0.0692, weight:2.00, lr:0.0006
[11:45:35.883] iteration:13949  t-loss:0.1885, loss-lb:0.1008, loss-ulb:0.0439, weight:2.00, lr:0.0006
[11:45:36.076] iteration:13950  t-loss:0.1312, loss-lb:0.0740, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:45:36.268] iteration:13951  t-loss:0.1363, loss-lb:0.0790, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:45:36.459] iteration:13952  t-loss:0.1446, loss-lb:0.0872, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:45:36.649] iteration:13953  t-loss:0.1537, loss-lb:0.0828, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:45:36.841] iteration:13954  t-loss:0.1490, loss-lb:0.0843, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:45:37.033] iteration:13955  t-loss:0.1619, loss-lb:0.0922, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:45:37.225] iteration:13956  t-loss:0.1394, loss-lb:0.0873, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:45:37.416] iteration:13957  t-loss:0.2208, loss-lb:0.0823, loss-ulb:0.0692, weight:2.00, lr:0.0006
[11:45:37.609] iteration:13958  t-loss:0.1524, loss-lb:0.0849, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:45:37.801] iteration:13959  t-loss:0.1638, loss-lb:0.0881, loss-ulb:0.0378, weight:2.00, lr:0.0006
[11:45:37.993] iteration:13960  t-loss:0.2195, loss-lb:0.0794, loss-ulb:0.0701, weight:2.00, lr:0.0006
[11:45:38.187] iteration:13961  t-loss:0.1790, loss-lb:0.0910, loss-ulb:0.0440, weight:2.00, lr:0.0006
[11:45:38.379] iteration:13962  t-loss:0.1359, loss-lb:0.0723, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:45:38.571] iteration:13963  t-loss:0.1691, loss-lb:0.0841, loss-ulb:0.0425, weight:2.00, lr:0.0006
[11:45:38.762] iteration:13964  t-loss:0.1498, loss-lb:0.0770, loss-ulb:0.0364, weight:2.00, lr:0.0006
[11:45:38.955] iteration:13965  t-loss:0.1765, loss-lb:0.0885, loss-ulb:0.0440, weight:2.00, lr:0.0006
[11:45:39.146] iteration:13966  t-loss:0.1698, loss-lb:0.0971, loss-ulb:0.0363, weight:2.00, lr:0.0006
[11:45:39.338] iteration:13967  t-loss:0.1539, loss-lb:0.0821, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:45:39.530] iteration:13968  t-loss:0.1504, loss-lb:0.0884, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:45:39.724] iteration:13969  t-loss:0.2827, loss-lb:0.0873, loss-ulb:0.0977, weight:2.00, lr:0.0006
[11:45:39.917] iteration:13970  t-loss:0.1357, loss-lb:0.0792, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:45:40.108] iteration:13971  t-loss:0.1373, loss-lb:0.0819, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:45:40.300] iteration:13972  t-loss:0.1781, loss-lb:0.0959, loss-ulb:0.0411, weight:2.00, lr:0.0006
[11:45:40.493] iteration:13973  t-loss:0.1587, loss-lb:0.0890, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:45:40.685] iteration:13974  t-loss:0.1528, loss-lb:0.0866, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:45:40.877] iteration:13975  t-loss:0.2383, loss-lb:0.0857, loss-ulb:0.0763, weight:2.00, lr:0.0006
[11:45:41.069] iteration:13976  t-loss:0.1830, loss-lb:0.1064, loss-ulb:0.0383, weight:2.00, lr:0.0006
[11:45:41.261] iteration:13977  t-loss:0.1380, loss-lb:0.0794, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:45:41.452] iteration:13978  t-loss:0.1391, loss-lb:0.0838, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:45:41.645] iteration:13979  t-loss:0.1599, loss-lb:0.0759, loss-ulb:0.0420, weight:2.00, lr:0.0006
[11:45:41.837] iteration:13980  t-loss:0.1558, loss-lb:0.0973, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:45:42.029] iteration:13981  t-loss:0.1468, loss-lb:0.0877, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:45:42.221] iteration:13982  t-loss:0.1495, loss-lb:0.0893, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:45:42.414] iteration:13983  t-loss:0.1790, loss-lb:0.0904, loss-ulb:0.0443, weight:2.00, lr:0.0006
[11:45:42.605] iteration:13984  t-loss:0.1677, loss-lb:0.1048, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:45:42.797] iteration:13985  t-loss:0.1580, loss-lb:0.0955, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:45:42.988] iteration:13986  t-loss:0.1434, loss-lb:0.0878, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:45:43.180] iteration:13987  t-loss:0.1521, loss-lb:0.0778, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:45:43.373] iteration:13988  t-loss:0.1374, loss-lb:0.0837, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:45:43.566] iteration:13989  t-loss:0.1661, loss-lb:0.0896, loss-ulb:0.0382, weight:2.00, lr:0.0006
[11:45:43.757] iteration:13990  t-loss:0.1546, loss-lb:0.0870, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:45:43.950] iteration:13991  t-loss:0.1371, loss-lb:0.0825, loss-ulb:0.0273, weight:2.00, lr:0.0006
[11:45:44.141] iteration:13992  t-loss:0.1438, loss-lb:0.0900, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:45:44.333] iteration:13993  t-loss:0.1778, loss-lb:0.0884, loss-ulb:0.0447, weight:2.00, lr:0.0006
[11:45:44.526] iteration:13994  t-loss:0.1566, loss-lb:0.0950, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:45:44.719] iteration:13995  t-loss:0.1367, loss-lb:0.0871, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:45:44.910] iteration:13996  t-loss:0.1541, loss-lb:0.0887, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:45:45.105] iteration:13997  t-loss:0.1512, loss-lb:0.0900, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:45:45.307] iteration:13998  t-loss:0.2844, loss-lb:0.2188, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:45:45.504] iteration:13999  t-loss:0.1331, loss-lb:0.0857, loss-ulb:0.0237, weight:2.00, lr:0.0006
[11:45:45.697] iteration:14000  t-loss:0.2139, loss-lb:0.1061, loss-ulb:0.0539, weight:2.00, lr:0.0006
[11:45:45.888] iteration:14001  t-loss:0.1779, loss-lb:0.1008, loss-ulb:0.0386, weight:2.00, lr:0.0006
[11:45:46.081] iteration:14002  t-loss:0.1675, loss-lb:0.0933, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:45:46.277] iteration:14003  t-loss:0.1793, loss-lb:0.1008, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:45:46.474] iteration:14004  t-loss:0.2029, loss-lb:0.0905, loss-ulb:0.0562, weight:2.00, lr:0.0006
[11:45:46.668] iteration:14005  t-loss:0.1607, loss-lb:0.0930, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:45:46.863] iteration:14006  t-loss:0.2139, loss-lb:0.0983, loss-ulb:0.0578, weight:2.00, lr:0.0006
[11:45:47.055] iteration:14007  t-loss:0.1552, loss-lb:0.0965, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:45:47.246] iteration:14008  t-loss:0.1627, loss-lb:0.0930, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:45:47.437] iteration:14009  t-loss:0.1496, loss-lb:0.0971, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:45:47.628] iteration:14010  t-loss:0.2070, loss-lb:0.1026, loss-ulb:0.0522, weight:2.00, lr:0.0006
[11:45:47.819] iteration:14011  t-loss:0.1605, loss-lb:0.1118, loss-ulb:0.0243, weight:2.00, lr:0.0006
[11:45:48.009] iteration:14012  t-loss:0.1644, loss-lb:0.0928, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:45:48.199] iteration:14013  t-loss:0.1645, loss-lb:0.0846, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:45:48.390] iteration:14014  t-loss:0.1611, loss-lb:0.0947, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:46:01.179]  <<Test>> - Ep:142  - mean_dice/mean_h95 - S:89.70/1.64, Best-S:90.30, T:90.07/1.51, Best-T:90.48
[11:46:01.180]           - AvgLoss(lb/ulb/all):0.0894/0.0369/0.1750
[11:46:01.725] iteration:14015  t-loss:0.2169, loss-lb:0.0993, loss-ulb:0.0588, weight:2.00, lr:0.0006
[11:46:01.922] iteration:14016  t-loss:0.1584, loss-lb:0.0975, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:46:02.114] iteration:14017  t-loss:0.1408, loss-lb:0.0797, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:46:02.308] iteration:14018  t-loss:0.2154, loss-lb:0.0859, loss-ulb:0.0648, weight:2.00, lr:0.0006
[11:46:02.500] iteration:14019  t-loss:0.1388, loss-lb:0.0827, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:46:02.694] iteration:14020  t-loss:0.1820, loss-lb:0.0977, loss-ulb:0.0422, weight:2.00, lr:0.0006
[11:46:02.887] iteration:14021  t-loss:0.1631, loss-lb:0.0901, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:46:03.079] iteration:14022  t-loss:0.1568, loss-lb:0.0975, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:46:03.272] iteration:14023  t-loss:0.1471, loss-lb:0.0860, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:46:03.464] iteration:14024  t-loss:0.1569, loss-lb:0.0972, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:46:03.656] iteration:14025  t-loss:0.1478, loss-lb:0.0878, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:46:03.849] iteration:14026  t-loss:0.1641, loss-lb:0.0935, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:46:04.042] iteration:14027  t-loss:0.1889, loss-lb:0.0930, loss-ulb:0.0479, weight:2.00, lr:0.0006
[11:46:04.235] iteration:14028  t-loss:0.2363, loss-lb:0.0939, loss-ulb:0.0712, weight:2.00, lr:0.0006
[11:46:04.427] iteration:14029  t-loss:0.1594, loss-lb:0.0877, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:46:04.620] iteration:14030  t-loss:0.1595, loss-lb:0.0959, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:46:04.812] iteration:14031  t-loss:0.1672, loss-lb:0.0925, loss-ulb:0.0374, weight:2.00, lr:0.0006
[11:46:05.004] iteration:14032  t-loss:0.1687, loss-lb:0.0908, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:46:05.197] iteration:14033  t-loss:0.1697, loss-lb:0.0960, loss-ulb:0.0369, weight:2.00, lr:0.0006
[11:46:05.389] iteration:14034  t-loss:0.1493, loss-lb:0.0859, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:46:05.580] iteration:14035  t-loss:0.1553, loss-lb:0.0803, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:46:05.772] iteration:14036  t-loss:0.1719, loss-lb:0.0893, loss-ulb:0.0413, weight:2.00, lr:0.0006
[11:46:05.965] iteration:14037  t-loss:0.1419, loss-lb:0.0783, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:46:06.156] iteration:14038  t-loss:0.1439, loss-lb:0.0868, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:46:06.349] iteration:14039  t-loss:0.1564, loss-lb:0.0827, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:46:06.541] iteration:14040  t-loss:0.1509, loss-lb:0.0849, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:46:06.734] iteration:14041  t-loss:0.2441, loss-lb:0.0950, loss-ulb:0.0745, weight:2.00, lr:0.0006
[11:46:06.925] iteration:14042  t-loss:0.1410, loss-lb:0.0881, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:46:07.118] iteration:14043  t-loss:0.1493, loss-lb:0.0873, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:46:07.311] iteration:14044  t-loss:0.1684, loss-lb:0.0827, loss-ulb:0.0428, weight:2.00, lr:0.0006
[11:46:07.502] iteration:14045  t-loss:0.1773, loss-lb:0.0949, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:46:07.694] iteration:14046  t-loss:0.1389, loss-lb:0.0876, loss-ulb:0.0257, weight:2.00, lr:0.0006
[11:46:07.885] iteration:14047  t-loss:0.1454, loss-lb:0.0871, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:46:08.078] iteration:14048  t-loss:0.1511, loss-lb:0.0779, loss-ulb:0.0366, weight:2.00, lr:0.0006
[11:46:08.272] iteration:14049  t-loss:0.1568, loss-lb:0.0886, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:46:08.470] iteration:14050  t-loss:0.3390, loss-lb:0.0907, loss-ulb:0.1241, weight:2.00, lr:0.0006
[11:46:08.664] iteration:14051  t-loss:0.1447, loss-lb:0.0838, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:46:08.857] iteration:14052  t-loss:0.1582, loss-lb:0.0888, loss-ulb:0.0347, weight:2.00, lr:0.0006
[11:46:09.049] iteration:14053  t-loss:0.1580, loss-lb:0.0922, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:46:09.242] iteration:14054  t-loss:0.2195, loss-lb:0.0928, loss-ulb:0.0633, weight:2.00, lr:0.0006
[11:46:09.433] iteration:14055  t-loss:0.1864, loss-lb:0.0829, loss-ulb:0.0518, weight:2.00, lr:0.0006
[11:46:09.626] iteration:14056  t-loss:0.1731, loss-lb:0.1001, loss-ulb:0.0365, weight:2.00, lr:0.0006
[11:46:09.818] iteration:14057  t-loss:0.2073, loss-lb:0.1067, loss-ulb:0.0503, weight:2.00, lr:0.0006
[11:46:10.009] iteration:14058  t-loss:0.1483, loss-lb:0.0830, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:46:10.201] iteration:14059  t-loss:0.1475, loss-lb:0.0811, loss-ulb:0.0332, weight:2.00, lr:0.0006
[11:46:10.395] iteration:14060  t-loss:0.1820, loss-lb:0.0959, loss-ulb:0.0430, weight:2.00, lr:0.0006
[11:46:10.586] iteration:14061  t-loss:0.1511, loss-lb:0.0912, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:46:10.778] iteration:14062  t-loss:0.1889, loss-lb:0.1008, loss-ulb:0.0441, weight:2.00, lr:0.0006
[11:46:10.970] iteration:14063  t-loss:0.2051, loss-lb:0.0976, loss-ulb:0.0538, weight:2.00, lr:0.0006
[11:46:11.163] iteration:14064  t-loss:0.1554, loss-lb:0.0923, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:46:11.355] iteration:14065  t-loss:0.1645, loss-lb:0.0912, loss-ulb:0.0366, weight:2.00, lr:0.0006
[11:46:11.548] iteration:14066  t-loss:0.2224, loss-lb:0.1013, loss-ulb:0.0606, weight:2.00, lr:0.0006
[11:46:11.739] iteration:14067  t-loss:0.1985, loss-lb:0.0925, loss-ulb:0.0530, weight:2.00, lr:0.0006
[11:46:11.931] iteration:14068  t-loss:0.2351, loss-lb:0.1070, loss-ulb:0.0641, weight:2.00, lr:0.0006
[11:46:12.123] iteration:14069  t-loss:0.1850, loss-lb:0.1010, loss-ulb:0.0420, weight:2.00, lr:0.0006
[11:46:12.315] iteration:14070  t-loss:0.3213, loss-lb:0.1066, loss-ulb:0.1074, weight:2.00, lr:0.0006
[11:46:12.507] iteration:14071  t-loss:0.1583, loss-lb:0.0970, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:46:12.700] iteration:14072  t-loss:0.2667, loss-lb:0.0980, loss-ulb:0.0843, weight:2.00, lr:0.0006
[11:46:12.892] iteration:14073  t-loss:0.1694, loss-lb:0.0878, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:46:13.084] iteration:14074  t-loss:0.2270, loss-lb:0.1283, loss-ulb:0.0494, weight:2.00, lr:0.0006
[11:46:13.275] iteration:14075  t-loss:0.1567, loss-lb:0.0926, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:46:13.467] iteration:14076  t-loss:0.1982, loss-lb:0.0955, loss-ulb:0.0514, weight:2.00, lr:0.0006
[11:46:13.662] iteration:14077  t-loss:0.2160, loss-lb:0.0938, loss-ulb:0.0611, weight:2.00, lr:0.0006
[11:46:13.855] iteration:14078  t-loss:0.1674, loss-lb:0.1022, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:46:14.047] iteration:14079  t-loss:0.1780, loss-lb:0.0905, loss-ulb:0.0437, weight:2.00, lr:0.0006
[11:46:14.240] iteration:14080  t-loss:0.2536, loss-lb:0.1146, loss-ulb:0.0695, weight:2.00, lr:0.0006
[11:46:14.432] iteration:14081  t-loss:0.1577, loss-lb:0.0886, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:46:14.622] iteration:14082  t-loss:0.2180, loss-lb:0.0970, loss-ulb:0.0605, weight:2.00, lr:0.0006
[11:46:14.815] iteration:14083  t-loss:0.1568, loss-lb:0.0940, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:46:15.008] iteration:14084  t-loss:0.1636, loss-lb:0.0926, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:46:15.199] iteration:14085  t-loss:0.1767, loss-lb:0.1012, loss-ulb:0.0377, weight:2.00, lr:0.0006
[11:46:15.391] iteration:14086  t-loss:0.1629, loss-lb:0.1033, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:46:15.583] iteration:14087  t-loss:0.1608, loss-lb:0.0890, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:46:15.774] iteration:14088  t-loss:0.2966, loss-lb:0.0876, loss-ulb:0.1045, weight:2.00, lr:0.0006
[11:46:15.966] iteration:14089  t-loss:0.1443, loss-lb:0.0804, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:46:16.158] iteration:14090  t-loss:0.1510, loss-lb:0.0923, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:46:16.349] iteration:14091  t-loss:0.1659, loss-lb:0.1029, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:46:16.541] iteration:14092  t-loss:0.3371, loss-lb:0.0958, loss-ulb:0.1207, weight:2.00, lr:0.0006
[11:46:16.732] iteration:14093  t-loss:0.1649, loss-lb:0.0892, loss-ulb:0.0379, weight:2.00, lr:0.0006
[11:46:16.925] iteration:14094  t-loss:0.1757, loss-lb:0.0932, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:46:17.117] iteration:14095  t-loss:0.2052, loss-lb:0.0898, loss-ulb:0.0577, weight:2.00, lr:0.0006
[11:46:17.308] iteration:14096  t-loss:0.1449, loss-lb:0.0943, loss-ulb:0.0253, weight:2.00, lr:0.0006
[11:46:17.500] iteration:14097  t-loss:0.1591, loss-lb:0.0978, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:46:17.691] iteration:14098  t-loss:0.1627, loss-lb:0.0842, loss-ulb:0.0393, weight:2.00, lr:0.0006
[11:46:17.889] iteration:14099  t-loss:0.1528, loss-lb:0.0908, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:46:18.094] iteration:14100  t-loss:0.1439, loss-lb:0.0845, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:46:18.291] iteration:14101  t-loss:0.1722, loss-lb:0.0998, loss-ulb:0.0362, weight:2.00, lr:0.0006
[11:46:18.482] iteration:14102  t-loss:0.1428, loss-lb:0.0834, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:46:18.674] iteration:14103  t-loss:0.1532, loss-lb:0.0922, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:46:18.867] iteration:14104  t-loss:0.1608, loss-lb:0.0961, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:46:19.058] iteration:14105  t-loss:0.1717, loss-lb:0.1148, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:46:19.249] iteration:14106  t-loss:0.1500, loss-lb:0.0927, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:46:19.441] iteration:14107  t-loss:0.1867, loss-lb:0.0951, loss-ulb:0.0458, weight:2.00, lr:0.0006
[11:46:19.632] iteration:14108  t-loss:0.1968, loss-lb:0.1069, loss-ulb:0.0450, weight:2.00, lr:0.0006
[11:46:19.823] iteration:14109  t-loss:0.1463, loss-lb:0.0860, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:46:20.014] iteration:14110  t-loss:0.2390, loss-lb:0.0962, loss-ulb:0.0714, weight:2.00, lr:0.0006
[11:46:20.204] iteration:14111  t-loss:0.1537, loss-lb:0.0895, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:46:20.395] iteration:14112  t-loss:0.1665, loss-lb:0.0847, loss-ulb:0.0409, weight:2.00, lr:0.0006
[11:46:20.972] iteration:14113  t-loss:0.1837, loss-lb:0.1244, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:46:21.170] iteration:14114  t-loss:0.1945, loss-lb:0.0904, loss-ulb:0.0521, weight:2.00, lr:0.0006
[11:46:21.363] iteration:14115  t-loss:0.1645, loss-lb:0.0968, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:46:21.556] iteration:14116  t-loss:0.1657, loss-lb:0.0938, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:46:21.749] iteration:14117  t-loss:0.1760, loss-lb:0.1003, loss-ulb:0.0378, weight:2.00, lr:0.0006
[11:46:21.942] iteration:14118  t-loss:0.1577, loss-lb:0.0876, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:46:22.133] iteration:14119  t-loss:0.1417, loss-lb:0.0882, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:46:22.326] iteration:14120  t-loss:0.1563, loss-lb:0.0973, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:46:22.520] iteration:14121  t-loss:0.1465, loss-lb:0.0860, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:46:22.712] iteration:14122  t-loss:0.1414, loss-lb:0.0831, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:46:22.905] iteration:14123  t-loss:0.1640, loss-lb:0.0955, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:46:23.098] iteration:14124  t-loss:0.1367, loss-lb:0.0850, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:46:23.289] iteration:14125  t-loss:0.2117, loss-lb:0.0896, loss-ulb:0.0610, weight:2.00, lr:0.0006
[11:46:23.483] iteration:14126  t-loss:0.1442, loss-lb:0.0838, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:46:23.675] iteration:14127  t-loss:0.1577, loss-lb:0.0863, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:46:23.868] iteration:14128  t-loss:0.2147, loss-lb:0.0880, loss-ulb:0.0634, weight:2.00, lr:0.0006
[11:46:24.061] iteration:14129  t-loss:0.1614, loss-lb:0.1021, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:46:24.252] iteration:14130  t-loss:0.1442, loss-lb:0.0839, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:46:24.445] iteration:14131  t-loss:0.1585, loss-lb:0.0952, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:46:24.639] iteration:14132  t-loss:0.2254, loss-lb:0.1291, loss-ulb:0.0481, weight:2.00, lr:0.0006
[11:46:24.832] iteration:14133  t-loss:0.1322, loss-lb:0.0864, loss-ulb:0.0229, weight:2.00, lr:0.0006
[11:46:25.023] iteration:14134  t-loss:0.1678, loss-lb:0.0963, loss-ulb:0.0358, weight:2.00, lr:0.0006
[11:46:25.216] iteration:14135  t-loss:0.1527, loss-lb:0.0864, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:46:25.409] iteration:14136  t-loss:0.1992, loss-lb:0.0900, loss-ulb:0.0546, weight:2.00, lr:0.0006
[11:46:25.601] iteration:14137  t-loss:0.1716, loss-lb:0.0956, loss-ulb:0.0380, weight:2.00, lr:0.0006
[11:46:25.795] iteration:14138  t-loss:0.1406, loss-lb:0.0885, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:46:25.988] iteration:14139  t-loss:0.1526, loss-lb:0.0918, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:46:26.180] iteration:14140  t-loss:0.1801, loss-lb:0.0862, loss-ulb:0.0469, weight:2.00, lr:0.0006
[11:46:26.373] iteration:14141  t-loss:0.1358, loss-lb:0.0820, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:46:26.565] iteration:14142  t-loss:0.1847, loss-lb:0.0862, loss-ulb:0.0493, weight:2.00, lr:0.0006
[11:46:26.757] iteration:14143  t-loss:0.1453, loss-lb:0.0896, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:46:26.949] iteration:14144  t-loss:0.1525, loss-lb:0.0875, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:46:27.141] iteration:14145  t-loss:0.1592, loss-lb:0.0917, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:46:27.333] iteration:14146  t-loss:0.1692, loss-lb:0.0822, loss-ulb:0.0435, weight:2.00, lr:0.0006
[11:46:27.525] iteration:14147  t-loss:0.1359, loss-lb:0.0836, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:46:27.718] iteration:14148  t-loss:0.1805, loss-lb:0.0949, loss-ulb:0.0428, weight:2.00, lr:0.0006
[11:46:27.911] iteration:14149  t-loss:0.1741, loss-lb:0.0868, loss-ulb:0.0436, weight:2.00, lr:0.0006
[11:46:28.102] iteration:14150  t-loss:0.1610, loss-lb:0.1009, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:46:28.295] iteration:14151  t-loss:0.1721, loss-lb:0.0904, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:46:28.488] iteration:14152  t-loss:0.1432, loss-lb:0.0888, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:46:28.680] iteration:14153  t-loss:0.1516, loss-lb:0.0854, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:46:28.873] iteration:14154  t-loss:0.1578, loss-lb:0.0836, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:46:29.066] iteration:14155  t-loss:0.1469, loss-lb:0.0908, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:46:29.259] iteration:14156  t-loss:0.1499, loss-lb:0.0917, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:46:29.450] iteration:14157  t-loss:0.1825, loss-lb:0.0878, loss-ulb:0.0473, weight:2.00, lr:0.0006
[11:46:29.642] iteration:14158  t-loss:0.1605, loss-lb:0.0886, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:46:29.835] iteration:14159  t-loss:0.1435, loss-lb:0.0856, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:46:30.027] iteration:14160  t-loss:0.1433, loss-lb:0.0805, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:46:30.219] iteration:14161  t-loss:0.1545, loss-lb:0.0900, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:46:30.412] iteration:14162  t-loss:0.1427, loss-lb:0.0818, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:46:30.605] iteration:14163  t-loss:0.1764, loss-lb:0.0897, loss-ulb:0.0434, weight:2.00, lr:0.0006
[11:46:30.797] iteration:14164  t-loss:0.1360, loss-lb:0.0817, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:46:30.990] iteration:14165  t-loss:0.1848, loss-lb:0.0909, loss-ulb:0.0469, weight:2.00, lr:0.0006
[11:46:31.183] iteration:14166  t-loss:0.1478, loss-lb:0.0827, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:46:31.375] iteration:14167  t-loss:0.1516, loss-lb:0.0854, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:46:31.567] iteration:14168  t-loss:0.1584, loss-lb:0.0939, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:46:31.759] iteration:14169  t-loss:0.1448, loss-lb:0.0890, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:46:31.954] iteration:14170  t-loss:0.1549, loss-lb:0.0963, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:46:32.148] iteration:14171  t-loss:0.2425, loss-lb:0.0809, loss-ulb:0.0808, weight:2.00, lr:0.0006
[11:46:32.341] iteration:14172  t-loss:0.1385, loss-lb:0.0844, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:46:32.533] iteration:14173  t-loss:0.1423, loss-lb:0.0815, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:46:32.725] iteration:14174  t-loss:0.1457, loss-lb:0.0795, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:46:32.919] iteration:14175  t-loss:0.1559, loss-lb:0.0911, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:46:33.112] iteration:14176  t-loss:0.1627, loss-lb:0.0839, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:46:33.304] iteration:14177  t-loss:0.1551, loss-lb:0.0958, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:46:33.496] iteration:14178  t-loss:0.1404, loss-lb:0.0849, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:46:33.689] iteration:14179  t-loss:0.1568, loss-lb:0.0914, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:46:33.881] iteration:14180  t-loss:0.1501, loss-lb:0.0871, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:46:34.074] iteration:14181  t-loss:0.1673, loss-lb:0.0845, loss-ulb:0.0414, weight:2.00, lr:0.0006
[11:46:34.266] iteration:14182  t-loss:0.1404, loss-lb:0.0832, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:46:34.458] iteration:14183  t-loss:0.1391, loss-lb:0.0750, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:46:34.650] iteration:14184  t-loss:0.1509, loss-lb:0.0953, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:46:34.844] iteration:14185  t-loss:0.1663, loss-lb:0.0854, loss-ulb:0.0404, weight:2.00, lr:0.0006
[11:46:35.035] iteration:14186  t-loss:0.1417, loss-lb:0.0854, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:46:35.227] iteration:14187  t-loss:0.1356, loss-lb:0.0823, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:46:35.420] iteration:14188  t-loss:0.1559, loss-lb:0.0927, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:46:35.612] iteration:14189  t-loss:0.1368, loss-lb:0.0796, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:46:35.805] iteration:14190  t-loss:0.1555, loss-lb:0.0813, loss-ulb:0.0371, weight:2.00, lr:0.0006
[11:46:35.998] iteration:14191  t-loss:0.1535, loss-lb:0.0959, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:46:36.190] iteration:14192  t-loss:0.1464, loss-lb:0.0816, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:46:36.381] iteration:14193  t-loss:0.1405, loss-lb:0.0834, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:46:36.574] iteration:14194  t-loss:0.1458, loss-lb:0.0881, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:46:36.766] iteration:14195  t-loss:0.1426, loss-lb:0.0929, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:46:36.958] iteration:14196  t-loss:0.1369, loss-lb:0.0826, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:46:37.151] iteration:14197  t-loss:0.1605, loss-lb:0.0991, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:46:37.344] iteration:14198  t-loss:0.1567, loss-lb:0.0849, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:46:37.537] iteration:14199  t-loss:0.1349, loss-lb:0.0866, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:46:37.729] iteration:14200  t-loss:0.1870, loss-lb:0.0719, loss-ulb:0.0575, weight:2.00, lr:0.0006
[11:46:37.923] iteration:14201  t-loss:0.1664, loss-lb:0.0889, loss-ulb:0.0387, weight:2.00, lr:0.0006
[11:46:38.116] iteration:14202  t-loss:0.1406, loss-lb:0.0780, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:46:38.307] iteration:14203  t-loss:0.1583, loss-lb:0.0977, loss-ulb:0.0303, weight:2.00, lr:0.0006
[11:46:38.497] iteration:14204  t-loss:0.1402, loss-lb:0.0842, loss-ulb:0.0280, weight:2.00, lr:0.0006
[11:46:38.687] iteration:14205  t-loss:0.1583, loss-lb:0.0958, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:46:38.879] iteration:14206  t-loss:0.1382, loss-lb:0.0838, loss-ulb:0.0272, weight:2.00, lr:0.0006
[11:46:39.069] iteration:14207  t-loss:0.1315, loss-lb:0.0786, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:46:39.260] iteration:14208  t-loss:0.1445, loss-lb:0.0814, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:46:39.451] iteration:14209  t-loss:0.1401, loss-lb:0.0769, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:46:39.642] iteration:14210  t-loss:0.1794, loss-lb:0.0864, loss-ulb:0.0465, weight:2.00, lr:0.0006
[11:46:50.874]  <<Test>> - Ep:144  - mean_dice/mean_h95 - S:89.65/1.64, Best-S:90.30, T:89.99/1.36, Best-T:90.48
[11:46:50.874]           - AvgLoss(lb/ulb/all):0.0885/0.0321/0.1501
[11:46:51.424] iteration:14211  t-loss:0.1521, loss-lb:0.0918, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:46:51.620] iteration:14212  t-loss:0.1434, loss-lb:0.0836, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:46:51.812] iteration:14213  t-loss:0.1430, loss-lb:0.0793, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:46:52.005] iteration:14214  t-loss:0.1545, loss-lb:0.0862, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:46:52.199] iteration:14215  t-loss:0.1498, loss-lb:0.0932, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:46:52.391] iteration:14216  t-loss:0.1594, loss-lb:0.0895, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:46:52.583] iteration:14217  t-loss:0.1330, loss-lb:0.0791, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:46:52.777] iteration:14218  t-loss:0.1444, loss-lb:0.0814, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:46:52.972] iteration:14219  t-loss:0.1341, loss-lb:0.0776, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:46:53.165] iteration:14220  t-loss:0.1388, loss-lb:0.0772, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:46:53.357] iteration:14221  t-loss:0.1409, loss-lb:0.0822, loss-ulb:0.0293, weight:2.00, lr:0.0006
[11:46:53.551] iteration:14222  t-loss:0.1352, loss-lb:0.0853, loss-ulb:0.0249, weight:2.00, lr:0.0006
[11:46:53.744] iteration:14223  t-loss:0.1680, loss-lb:0.0854, loss-ulb:0.0413, weight:2.00, lr:0.0006
[11:46:53.937] iteration:14224  t-loss:0.1722, loss-lb:0.0886, loss-ulb:0.0418, weight:2.00, lr:0.0006
[11:46:54.129] iteration:14225  t-loss:0.1344, loss-lb:0.0755, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:46:54.322] iteration:14226  t-loss:0.1433, loss-lb:0.0775, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:46:54.514] iteration:14227  t-loss:0.1573, loss-lb:0.1034, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:46:54.706] iteration:14228  t-loss:0.1983, loss-lb:0.0982, loss-ulb:0.0501, weight:2.00, lr:0.0006
[11:46:54.899] iteration:14229  t-loss:0.1544, loss-lb:0.0952, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:46:55.092] iteration:14230  t-loss:0.2020, loss-lb:0.0840, loss-ulb:0.0590, weight:2.00, lr:0.0006
[11:46:55.286] iteration:14231  t-loss:0.1401, loss-lb:0.0874, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:46:55.478] iteration:14232  t-loss:0.1424, loss-lb:0.0856, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:46:55.670] iteration:14233  t-loss:0.1386, loss-lb:0.0829, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:46:55.862] iteration:14234  t-loss:0.1339, loss-lb:0.0754, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:46:56.056] iteration:14235  t-loss:0.1369, loss-lb:0.0885, loss-ulb:0.0242, weight:2.00, lr:0.0006
[11:46:56.248] iteration:14236  t-loss:0.1464, loss-lb:0.0797, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:46:56.440] iteration:14237  t-loss:0.1608, loss-lb:0.0851, loss-ulb:0.0378, weight:2.00, lr:0.0006
[11:46:56.631] iteration:14238  t-loss:0.1448, loss-lb:0.0910, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:46:56.825] iteration:14239  t-loss:0.1607, loss-lb:0.0861, loss-ulb:0.0373, weight:2.00, lr:0.0006
[11:46:57.019] iteration:14240  t-loss:0.1585, loss-lb:0.0782, loss-ulb:0.0402, weight:2.00, lr:0.0006
[11:46:57.210] iteration:14241  t-loss:0.1668, loss-lb:0.0821, loss-ulb:0.0423, weight:2.00, lr:0.0006
[11:46:57.403] iteration:14242  t-loss:0.1318, loss-lb:0.0867, loss-ulb:0.0226, weight:2.00, lr:0.0006
[11:46:57.595] iteration:14243  t-loss:0.1575, loss-lb:0.0764, loss-ulb:0.0406, weight:2.00, lr:0.0006
[11:46:57.787] iteration:14244  t-loss:0.1387, loss-lb:0.0855, loss-ulb:0.0266, weight:2.00, lr:0.0006
[11:46:57.980] iteration:14245  t-loss:0.1456, loss-lb:0.0862, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:46:58.172] iteration:14246  t-loss:0.1425, loss-lb:0.0801, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:46:58.363] iteration:14247  t-loss:0.1409, loss-lb:0.0809, loss-ulb:0.0300, weight:2.00, lr:0.0006
[11:46:58.556] iteration:14248  t-loss:0.2681, loss-lb:0.0847, loss-ulb:0.0917, weight:2.00, lr:0.0006
[11:46:58.748] iteration:14249  t-loss:0.1648, loss-lb:0.1009, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:46:58.943] iteration:14250  t-loss:0.1502, loss-lb:0.0864, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:46:59.137] iteration:14251  t-loss:0.1721, loss-lb:0.0912, loss-ulb:0.0404, weight:2.00, lr:0.0006
[11:46:59.329] iteration:14252  t-loss:0.1551, loss-lb:0.0906, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:46:59.522] iteration:14253  t-loss:0.1535, loss-lb:0.0861, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:46:59.716] iteration:14254  t-loss:0.1514, loss-lb:0.0842, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:46:59.910] iteration:14255  t-loss:0.2975, loss-lb:0.0851, loss-ulb:0.1062, weight:2.00, lr:0.0006
[11:47:00.101] iteration:14256  t-loss:0.1557, loss-lb:0.0888, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:47:00.293] iteration:14257  t-loss:0.1464, loss-lb:0.0912, loss-ulb:0.0276, weight:2.00, lr:0.0006
[11:47:00.486] iteration:14258  t-loss:0.1496, loss-lb:0.0847, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:47:00.678] iteration:14259  t-loss:0.1512, loss-lb:0.0860, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:47:00.870] iteration:14260  t-loss:0.1441, loss-lb:0.0804, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:47:01.062] iteration:14261  t-loss:0.1519, loss-lb:0.0841, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:47:01.254] iteration:14262  t-loss:0.1431, loss-lb:0.0868, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:47:01.446] iteration:14263  t-loss:0.1389, loss-lb:0.0811, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:47:01.639] iteration:14264  t-loss:0.1571, loss-lb:0.0962, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:47:01.831] iteration:14265  t-loss:0.1534, loss-lb:0.0831, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:47:02.023] iteration:14266  t-loss:0.1477, loss-lb:0.0910, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:47:02.215] iteration:14267  t-loss:0.1534, loss-lb:0.0886, loss-ulb:0.0324, weight:2.00, lr:0.0006
[11:47:02.406] iteration:14268  t-loss:0.1327, loss-lb:0.0786, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:47:02.598] iteration:14269  t-loss:0.1836, loss-lb:0.1021, loss-ulb:0.0407, weight:2.00, lr:0.0006
[11:47:02.790] iteration:14270  t-loss:0.1470, loss-lb:0.0898, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:47:02.982] iteration:14271  t-loss:0.1411, loss-lb:0.0768, loss-ulb:0.0321, weight:2.00, lr:0.0006
[11:47:03.175] iteration:14272  t-loss:0.1741, loss-lb:0.0813, loss-ulb:0.0464, weight:2.00, lr:0.0006
[11:47:03.366] iteration:14273  t-loss:0.1535, loss-lb:0.0919, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:47:03.559] iteration:14274  t-loss:0.1966, loss-lb:0.0847, loss-ulb:0.0560, weight:2.00, lr:0.0006
[11:47:03.751] iteration:14275  t-loss:0.1496, loss-lb:0.0852, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:47:03.942] iteration:14276  t-loss:0.1658, loss-lb:0.0790, loss-ulb:0.0434, weight:2.00, lr:0.0006
[11:47:04.134] iteration:14277  t-loss:0.1642, loss-lb:0.0971, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:47:04.326] iteration:14278  t-loss:0.1421, loss-lb:0.0905, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:47:04.519] iteration:14279  t-loss:0.1474, loss-lb:0.0796, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:47:04.710] iteration:14280  t-loss:0.1516, loss-lb:0.0913, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:47:04.902] iteration:14281  t-loss:0.1537, loss-lb:0.0854, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:47:05.096] iteration:14282  t-loss:0.1615, loss-lb:0.0836, loss-ulb:0.0389, weight:2.00, lr:0.0006
[11:47:05.288] iteration:14283  t-loss:0.1363, loss-lb:0.0801, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:47:05.479] iteration:14284  t-loss:0.1440, loss-lb:0.0850, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:47:05.671] iteration:14285  t-loss:0.1392, loss-lb:0.0838, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:47:05.863] iteration:14286  t-loss:0.1525, loss-lb:0.0900, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:47:06.055] iteration:14287  t-loss:0.1407, loss-lb:0.0905, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:47:06.248] iteration:14288  t-loss:0.1384, loss-lb:0.0846, loss-ulb:0.0269, weight:2.00, lr:0.0006
[11:47:06.442] iteration:14289  t-loss:0.1370, loss-lb:0.0846, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:47:06.634] iteration:14290  t-loss:0.1393, loss-lb:0.0827, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:47:06.826] iteration:14291  t-loss:0.1623, loss-lb:0.0795, loss-ulb:0.0414, weight:2.00, lr:0.0006
[11:47:07.018] iteration:14292  t-loss:0.1556, loss-lb:0.0875, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:47:07.211] iteration:14293  t-loss:0.1428, loss-lb:0.0810, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:47:07.403] iteration:14294  t-loss:0.1619, loss-lb:0.0823, loss-ulb:0.0398, weight:2.00, lr:0.0006
[11:47:07.597] iteration:14295  t-loss:0.3216, loss-lb:0.0938, loss-ulb:0.1139, weight:2.00, lr:0.0006
[11:47:07.789] iteration:14296  t-loss:0.1373, loss-lb:0.0729, loss-ulb:0.0322, weight:2.00, lr:0.0006
[11:47:07.981] iteration:14297  t-loss:0.1461, loss-lb:0.0862, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:47:08.173] iteration:14298  t-loss:0.1436, loss-lb:0.0803, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:47:08.364] iteration:14299  t-loss:0.1775, loss-lb:0.0870, loss-ulb:0.0452, weight:2.00, lr:0.0006
[11:47:08.556] iteration:14300  t-loss:0.2198, loss-lb:0.0986, loss-ulb:0.0606, weight:2.00, lr:0.0006
[11:47:08.749] iteration:14301  t-loss:0.1367, loss-lb:0.0802, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:47:08.939] iteration:14302  t-loss:0.1589, loss-lb:0.0848, loss-ulb:0.0370, weight:2.00, lr:0.0006
[11:47:09.136] iteration:14303  t-loss:0.1904, loss-lb:0.1282, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:47:09.329] iteration:14304  t-loss:0.1564, loss-lb:0.0893, loss-ulb:0.0336, weight:2.00, lr:0.0006
[11:47:09.524] iteration:14305  t-loss:0.1273, loss-lb:0.0733, loss-ulb:0.0270, weight:2.00, lr:0.0006
[11:47:09.718] iteration:14306  t-loss:0.1774, loss-lb:0.0875, loss-ulb:0.0449, weight:2.00, lr:0.0006
[11:47:09.908] iteration:14307  t-loss:0.1464, loss-lb:0.0860, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:47:10.098] iteration:14308  t-loss:0.1439, loss-lb:0.0808, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:47:10.690] iteration:14309  t-loss:0.1447, loss-lb:0.0839, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:47:10.885] iteration:14310  t-loss:0.1598, loss-lb:0.0827, loss-ulb:0.0385, weight:2.00, lr:0.0006
[11:47:11.077] iteration:14311  t-loss:0.1651, loss-lb:0.0915, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:47:11.268] iteration:14312  t-loss:0.1506, loss-lb:0.0911, loss-ulb:0.0298, weight:2.00, lr:0.0006
[11:47:11.460] iteration:14313  t-loss:0.1461, loss-lb:0.0953, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:47:11.652] iteration:14314  t-loss:0.1481, loss-lb:0.0832, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:47:11.843] iteration:14315  t-loss:0.1421, loss-lb:0.0839, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:47:12.036] iteration:14316  t-loss:0.1344, loss-lb:0.0831, loss-ulb:0.0256, weight:2.00, lr:0.0006
[11:47:12.227] iteration:14317  t-loss:0.1504, loss-lb:0.0925, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:47:12.419] iteration:14318  t-loss:0.1439, loss-lb:0.0733, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:47:12.612] iteration:14319  t-loss:0.1571, loss-lb:0.0850, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:47:12.804] iteration:14320  t-loss:0.1430, loss-lb:0.0777, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:47:12.995] iteration:14321  t-loss:0.1482, loss-lb:0.0860, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:47:13.187] iteration:14322  t-loss:0.1855, loss-lb:0.1030, loss-ulb:0.0413, weight:2.00, lr:0.0006
[11:47:13.380] iteration:14323  t-loss:0.1281, loss-lb:0.0824, loss-ulb:0.0229, weight:2.00, lr:0.0006
[11:47:13.572] iteration:14324  t-loss:0.1454, loss-lb:0.0828, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:47:13.764] iteration:14325  t-loss:0.1476, loss-lb:0.0816, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:47:13.956] iteration:14326  t-loss:0.1671, loss-lb:0.0854, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:47:14.147] iteration:14327  t-loss:0.1393, loss-lb:0.0819, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:47:14.339] iteration:14328  t-loss:0.1474, loss-lb:0.0838, loss-ulb:0.0318, weight:2.00, lr:0.0006
[11:47:14.533] iteration:14329  t-loss:0.1456, loss-lb:0.0796, loss-ulb:0.0330, weight:2.00, lr:0.0006
[11:47:14.724] iteration:14330  t-loss:0.1450, loss-lb:0.0892, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:47:14.917] iteration:14331  t-loss:0.1491, loss-lb:0.0865, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:47:15.108] iteration:14332  t-loss:0.1351, loss-lb:0.0728, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:47:15.299] iteration:14333  t-loss:0.1337, loss-lb:0.0832, loss-ulb:0.0252, weight:2.00, lr:0.0006
[11:47:15.493] iteration:14334  t-loss:0.1348, loss-lb:0.0811, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:47:15.684] iteration:14335  t-loss:0.1444, loss-lb:0.0768, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:47:15.877] iteration:14336  t-loss:0.1776, loss-lb:0.0860, loss-ulb:0.0458, weight:2.00, lr:0.0006
[11:47:16.070] iteration:14337  t-loss:0.1407, loss-lb:0.0826, loss-ulb:0.0290, weight:2.00, lr:0.0006
[11:47:16.261] iteration:14338  t-loss:0.1521, loss-lb:0.0953, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:47:16.453] iteration:14339  t-loss:0.1674, loss-lb:0.0916, loss-ulb:0.0379, weight:2.00, lr:0.0006
[11:47:16.645] iteration:14340  t-loss:0.1475, loss-lb:0.0843, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:47:16.837] iteration:14341  t-loss:0.1520, loss-lb:0.0739, loss-ulb:0.0390, weight:2.00, lr:0.0006
[11:47:17.028] iteration:14342  t-loss:0.1460, loss-lb:0.0791, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:47:17.220] iteration:14343  t-loss:0.1332, loss-lb:0.0761, loss-ulb:0.0285, weight:2.00, lr:0.0006
[11:47:17.411] iteration:14344  t-loss:0.1490, loss-lb:0.0858, loss-ulb:0.0316, weight:2.00, lr:0.0006
[11:47:17.603] iteration:14345  t-loss:0.1650, loss-lb:0.0827, loss-ulb:0.0412, weight:2.00, lr:0.0006
[11:47:17.794] iteration:14346  t-loss:0.1318, loss-lb:0.0777, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:47:17.985] iteration:14347  t-loss:0.1578, loss-lb:0.0967, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:47:18.177] iteration:14348  t-loss:0.1610, loss-lb:0.1002, loss-ulb:0.0304, weight:2.00, lr:0.0006
[11:47:18.369] iteration:14349  t-loss:0.2262, loss-lb:0.0757, loss-ulb:0.0752, weight:2.00, lr:0.0006
[11:47:18.561] iteration:14350  t-loss:0.1397, loss-lb:0.0820, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:47:18.752] iteration:14351  t-loss:0.1476, loss-lb:0.0851, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:47:18.944] iteration:14352  t-loss:0.1693, loss-lb:0.0808, loss-ulb:0.0442, weight:2.00, lr:0.0006
[11:47:19.135] iteration:14353  t-loss:0.1481, loss-lb:0.0870, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:47:19.328] iteration:14354  t-loss:0.1544, loss-lb:0.0848, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:47:19.520] iteration:14355  t-loss:0.1583, loss-lb:0.0812, loss-ulb:0.0386, weight:2.00, lr:0.0006
[11:47:19.713] iteration:14356  t-loss:0.1602, loss-lb:0.0897, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:47:19.920] iteration:14357  t-loss:0.1562, loss-lb:0.0883, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:47:20.116] iteration:14358  t-loss:0.2116, loss-lb:0.0895, loss-ulb:0.0610, weight:2.00, lr:0.0006
[11:47:20.313] iteration:14359  t-loss:0.1498, loss-lb:0.0828, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:47:20.506] iteration:14360  t-loss:0.1763, loss-lb:0.0850, loss-ulb:0.0456, weight:2.00, lr:0.0006
[11:47:20.698] iteration:14361  t-loss:0.1386, loss-lb:0.0798, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:47:20.892] iteration:14362  t-loss:0.1843, loss-lb:0.0776, loss-ulb:0.0533, weight:2.00, lr:0.0006
[11:47:21.084] iteration:14363  t-loss:0.1417, loss-lb:0.0808, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:47:21.276] iteration:14364  t-loss:0.1549, loss-lb:0.0851, loss-ulb:0.0349, weight:2.00, lr:0.0006
[11:47:21.468] iteration:14365  t-loss:0.1533, loss-lb:0.0941, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:47:21.661] iteration:14366  t-loss:0.1432, loss-lb:0.0878, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:47:21.854] iteration:14367  t-loss:0.1376, loss-lb:0.0794, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:47:22.046] iteration:14368  t-loss:0.1458, loss-lb:0.0842, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:47:22.239] iteration:14369  t-loss:0.1619, loss-lb:0.0781, loss-ulb:0.0419, weight:2.00, lr:0.0006
[11:47:22.432] iteration:14370  t-loss:0.1456, loss-lb:0.0811, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:47:22.625] iteration:14371  t-loss:0.1496, loss-lb:0.0850, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:47:22.817] iteration:14372  t-loss:0.1399, loss-lb:0.0788, loss-ulb:0.0306, weight:2.00, lr:0.0006
[11:47:23.009] iteration:14373  t-loss:0.1429, loss-lb:0.0835, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:47:23.203] iteration:14374  t-loss:0.1689, loss-lb:0.1027, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:47:23.398] iteration:14375  t-loss:0.1888, loss-lb:0.0878, loss-ulb:0.0505, weight:2.00, lr:0.0006
[11:47:23.604] iteration:14376  t-loss:0.1986, loss-lb:0.0841, loss-ulb:0.0573, weight:2.00, lr:0.0006
[11:47:23.805] iteration:14377  t-loss:0.2379, loss-lb:0.0771, loss-ulb:0.0804, weight:2.00, lr:0.0006
[11:47:23.997] iteration:14378  t-loss:0.1580, loss-lb:0.0893, loss-ulb:0.0344, weight:2.00, lr:0.0006
[11:47:24.191] iteration:14379  t-loss:0.1617, loss-lb:0.0908, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:47:24.383] iteration:14380  t-loss:0.1789, loss-lb:0.0812, loss-ulb:0.0489, weight:2.00, lr:0.0006
[11:47:24.575] iteration:14381  t-loss:0.1555, loss-lb:0.0832, loss-ulb:0.0361, weight:2.00, lr:0.0006
[11:47:24.768] iteration:14382  t-loss:0.1361, loss-lb:0.0812, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:47:24.960] iteration:14383  t-loss:0.1362, loss-lb:0.0787, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:47:25.153] iteration:14384  t-loss:0.1581, loss-lb:0.0962, loss-ulb:0.0309, weight:2.00, lr:0.0006
[11:47:25.346] iteration:14385  t-loss:0.2040, loss-lb:0.0810, loss-ulb:0.0615, weight:2.00, lr:0.0006
[11:47:25.538] iteration:14386  t-loss:0.1327, loss-lb:0.0811, loss-ulb:0.0258, weight:2.00, lr:0.0006
[11:47:25.730] iteration:14387  t-loss:0.1409, loss-lb:0.0883, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:47:25.923] iteration:14388  t-loss:0.1383, loss-lb:0.0785, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:47:26.115] iteration:14389  t-loss:0.1356, loss-lb:0.0755, loss-ulb:0.0301, weight:2.00, lr:0.0006
[11:47:26.308] iteration:14390  t-loss:0.2479, loss-lb:0.0878, loss-ulb:0.0800, weight:2.00, lr:0.0006
[11:47:26.500] iteration:14391  t-loss:0.1476, loss-lb:0.0809, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:47:26.692] iteration:14392  t-loss:0.1460, loss-lb:0.0827, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:47:26.883] iteration:14393  t-loss:0.1463, loss-lb:0.0807, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:47:27.076] iteration:14394  t-loss:0.1310, loss-lb:0.0783, loss-ulb:0.0263, weight:2.00, lr:0.0006
[11:47:27.270] iteration:14395  t-loss:0.1484, loss-lb:0.0926, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:47:27.462] iteration:14396  t-loss:0.1384, loss-lb:0.0833, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:47:27.655] iteration:14397  t-loss:0.1556, loss-lb:0.0849, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:47:27.855] iteration:14398  t-loss:0.1367, loss-lb:0.0732, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:47:28.046] iteration:14399  t-loss:0.1470, loss-lb:0.0875, loss-ulb:0.0297, weight:2.00, lr:0.0006
[11:47:28.236] iteration:14400  t-loss:0.1392, loss-lb:0.0823, loss-ulb:0.0284, weight:2.00, lr:0.0006
[11:47:28.426] iteration:14401  t-loss:0.1440, loss-lb:0.0785, loss-ulb:0.0327, weight:2.00, lr:0.0006
[11:47:28.616] iteration:14402  t-loss:0.1474, loss-lb:0.0800, loss-ulb:0.0337, weight:2.00, lr:0.0006
[11:47:28.806] iteration:14403  t-loss:0.1387, loss-lb:0.0783, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:47:28.996] iteration:14404  t-loss:0.1502, loss-lb:0.0875, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:47:29.186] iteration:14405  t-loss:0.1446, loss-lb:0.0806, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:47:29.377] iteration:14406  t-loss:0.1401, loss-lb:0.0818, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:47:41.990]  <<Test>> - Ep:146  - mean_dice/mean_h95 - S:89.79/1.36, Best-S:90.30, T:90.02/1.38, Best-T:90.48
[11:47:41.990]           - AvgLoss(lb/ulb/all):0.0840/0.0330/0.1482
[11:47:42.572] iteration:14407  t-loss:0.1577, loss-lb:0.0927, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:47:42.768] iteration:14408  t-loss:0.1555, loss-lb:0.0871, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:47:42.961] iteration:14409  t-loss:0.1560, loss-lb:0.0743, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:47:43.154] iteration:14410  t-loss:0.1499, loss-lb:0.0815, loss-ulb:0.0342, weight:2.00, lr:0.0006
[11:47:43.347] iteration:14411  t-loss:0.1492, loss-lb:0.0968, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:47:43.540] iteration:14412  t-loss:0.1347, loss-lb:0.0793, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:47:43.732] iteration:14413  t-loss:0.1540, loss-lb:0.0905, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:47:43.925] iteration:14414  t-loss:0.1697, loss-lb:0.0898, loss-ulb:0.0399, weight:2.00, lr:0.0006
[11:47:44.118] iteration:14415  t-loss:0.1271, loss-lb:0.0729, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:47:44.310] iteration:14416  t-loss:0.1489, loss-lb:0.0790, loss-ulb:0.0350, weight:2.00, lr:0.0006
[11:47:44.504] iteration:14417  t-loss:0.3074, loss-lb:0.0801, loss-ulb:0.1136, weight:2.00, lr:0.0006
[11:47:44.696] iteration:14418  t-loss:0.1387, loss-lb:0.0815, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:47:44.889] iteration:14419  t-loss:0.1395, loss-lb:0.0832, loss-ulb:0.0281, weight:2.00, lr:0.0006
[11:47:45.081] iteration:14420  t-loss:0.1438, loss-lb:0.0882, loss-ulb:0.0278, weight:2.00, lr:0.0006
[11:47:45.274] iteration:14421  t-loss:0.1598, loss-lb:0.0836, loss-ulb:0.0381, weight:2.00, lr:0.0006
[11:47:45.468] iteration:14422  t-loss:0.2039, loss-lb:0.0847, loss-ulb:0.0596, weight:2.00, lr:0.0006
[11:47:45.661] iteration:14423  t-loss:0.1510, loss-lb:0.0906, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:47:45.853] iteration:14424  t-loss:0.1359, loss-lb:0.0808, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:47:46.046] iteration:14425  t-loss:0.1668, loss-lb:0.0920, loss-ulb:0.0374, weight:2.00, lr:0.0006
[11:47:46.239] iteration:14426  t-loss:0.2180, loss-lb:0.0787, loss-ulb:0.0697, weight:2.00, lr:0.0006
[11:47:46.431] iteration:14427  t-loss:0.1471, loss-lb:0.0874, loss-ulb:0.0299, weight:2.00, lr:0.0006
[11:47:46.624] iteration:14428  t-loss:0.1886, loss-lb:0.0871, loss-ulb:0.0507, weight:2.00, lr:0.0006
[11:47:46.817] iteration:14429  t-loss:0.2223, loss-lb:0.0746, loss-ulb:0.0739, weight:2.00, lr:0.0006
[11:47:47.012] iteration:14430  t-loss:0.2122, loss-lb:0.0784, loss-ulb:0.0669, weight:2.00, lr:0.0006
[11:47:47.204] iteration:14431  t-loss:0.1527, loss-lb:0.0862, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:47:47.398] iteration:14432  t-loss:0.1666, loss-lb:0.0861, loss-ulb:0.0402, weight:2.00, lr:0.0006
[11:47:47.590] iteration:14433  t-loss:0.1332, loss-lb:0.0791, loss-ulb:0.0271, weight:2.00, lr:0.0006
[11:47:47.784] iteration:14434  t-loss:0.1494, loss-lb:0.0874, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:47:47.978] iteration:14435  t-loss:0.1524, loss-lb:0.0804, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:47:48.170] iteration:14436  t-loss:0.1536, loss-lb:0.0921, loss-ulb:0.0308, weight:2.00, lr:0.0006
[11:47:48.361] iteration:14437  t-loss:0.1605, loss-lb:0.0868, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:47:48.555] iteration:14438  t-loss:0.2009, loss-lb:0.0904, loss-ulb:0.0553, weight:2.00, lr:0.0006
[11:47:48.747] iteration:14439  t-loss:0.1901, loss-lb:0.1086, loss-ulb:0.0407, weight:2.00, lr:0.0006
[11:47:48.940] iteration:14440  t-loss:0.1497, loss-lb:0.0847, loss-ulb:0.0325, weight:2.00, lr:0.0006
[11:47:49.133] iteration:14441  t-loss:0.1353, loss-lb:0.0864, loss-ulb:0.0245, weight:2.00, lr:0.0006
[11:47:49.325] iteration:14442  t-loss:0.1383, loss-lb:0.0798, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:47:49.516] iteration:14443  t-loss:0.1505, loss-lb:0.0928, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:47:49.708] iteration:14444  t-loss:0.1460, loss-lb:0.0798, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:47:49.899] iteration:14445  t-loss:0.1307, loss-lb:0.0782, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:47:50.090] iteration:14446  t-loss:0.1498, loss-lb:0.0877, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:47:50.281] iteration:14447  t-loss:0.2142, loss-lb:0.0825, loss-ulb:0.0658, weight:2.00, lr:0.0006
[11:47:50.473] iteration:14448  t-loss:0.1601, loss-lb:0.0854, loss-ulb:0.0373, weight:2.00, lr:0.0006
[11:47:50.664] iteration:14449  t-loss:0.1729, loss-lb:0.0881, loss-ulb:0.0424, weight:2.00, lr:0.0006
[11:47:50.855] iteration:14450  t-loss:0.1506, loss-lb:0.0877, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:47:51.046] iteration:14451  t-loss:0.1504, loss-lb:0.0841, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:47:51.237] iteration:14452  t-loss:0.1405, loss-lb:0.0802, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:47:51.429] iteration:14453  t-loss:0.1526, loss-lb:0.0836, loss-ulb:0.0345, weight:2.00, lr:0.0006
[11:47:51.620] iteration:14454  t-loss:0.1631, loss-lb:0.0886, loss-ulb:0.0372, weight:2.00, lr:0.0006
[11:47:51.812] iteration:14455  t-loss:0.1700, loss-lb:0.0851, loss-ulb:0.0424, weight:2.00, lr:0.0006
[11:47:52.005] iteration:14456  t-loss:0.1424, loss-lb:0.0840, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:47:52.197] iteration:14457  t-loss:0.1699, loss-lb:0.0847, loss-ulb:0.0426, weight:2.00, lr:0.0006
[11:47:52.391] iteration:14458  t-loss:0.1498, loss-lb:0.0869, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:47:52.583] iteration:14459  t-loss:0.1437, loss-lb:0.0775, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:47:52.774] iteration:14460  t-loss:0.1543, loss-lb:0.0885, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:47:52.966] iteration:14461  t-loss:0.1654, loss-lb:0.0872, loss-ulb:0.0391, weight:2.00, lr:0.0006
[11:47:53.159] iteration:14462  t-loss:0.1516, loss-lb:0.0779, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:47:53.352] iteration:14463  t-loss:0.1454, loss-lb:0.0864, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:47:53.544] iteration:14464  t-loss:0.1333, loss-lb:0.0756, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:47:53.736] iteration:14465  t-loss:0.1415, loss-lb:0.0887, loss-ulb:0.0264, weight:2.00, lr:0.0006
[11:47:53.928] iteration:14466  t-loss:0.1435, loss-lb:0.0788, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:47:54.120] iteration:14467  t-loss:0.1349, loss-lb:0.0784, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:47:54.313] iteration:14468  t-loss:0.1346, loss-lb:0.0824, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:47:54.506] iteration:14469  t-loss:0.1590, loss-lb:0.0919, loss-ulb:0.0335, weight:2.00, lr:0.0006
[11:47:54.698] iteration:14470  t-loss:0.1634, loss-lb:0.0800, loss-ulb:0.0417, weight:2.00, lr:0.0006
[11:47:54.892] iteration:14471  t-loss:0.2349, loss-lb:0.0836, loss-ulb:0.0756, weight:2.00, lr:0.0006
[11:47:55.085] iteration:14472  t-loss:0.1480, loss-lb:0.0972, loss-ulb:0.0254, weight:2.00, lr:0.0006
[11:47:55.277] iteration:14473  t-loss:0.1406, loss-lb:0.0833, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:47:55.470] iteration:14474  t-loss:0.2171, loss-lb:0.0882, loss-ulb:0.0644, weight:2.00, lr:0.0006
[11:47:55.663] iteration:14475  t-loss:0.1534, loss-lb:0.0876, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:47:55.854] iteration:14476  t-loss:0.1398, loss-lb:0.0815, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:47:56.047] iteration:14477  t-loss:0.1687, loss-lb:0.0906, loss-ulb:0.0391, weight:2.00, lr:0.0006
[11:47:56.252] iteration:14478  t-loss:0.1566, loss-lb:0.0890, loss-ulb:0.0338, weight:2.00, lr:0.0006
[11:47:56.451] iteration:14479  t-loss:0.1443, loss-lb:0.0765, loss-ulb:0.0339, weight:2.00, lr:0.0006
[11:47:56.647] iteration:14480  t-loss:0.1388, loss-lb:0.0893, loss-ulb:0.0248, weight:2.00, lr:0.0006
[11:47:56.840] iteration:14481  t-loss:0.1318, loss-lb:0.0795, loss-ulb:0.0261, weight:2.00, lr:0.0006
[11:47:57.032] iteration:14482  t-loss:0.1498, loss-lb:0.0858, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:47:57.224] iteration:14483  t-loss:0.1402, loss-lb:0.0788, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:47:57.417] iteration:14484  t-loss:0.1338, loss-lb:0.0802, loss-ulb:0.0268, weight:2.00, lr:0.0006
[11:47:57.608] iteration:14485  t-loss:0.1458, loss-lb:0.0764, loss-ulb:0.0347, weight:2.00, lr:0.0006
[11:47:57.801] iteration:14486  t-loss:0.1384, loss-lb:0.0750, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:47:57.993] iteration:14487  t-loss:0.1430, loss-lb:0.0855, loss-ulb:0.0287, weight:2.00, lr:0.0006
[11:47:58.185] iteration:14488  t-loss:0.1426, loss-lb:0.0780, loss-ulb:0.0323, weight:2.00, lr:0.0006
[11:47:58.378] iteration:14489  t-loss:0.1488, loss-lb:0.0864, loss-ulb:0.0312, weight:2.00, lr:0.0006
[11:47:58.570] iteration:14490  t-loss:0.1572, loss-lb:0.0819, loss-ulb:0.0376, weight:2.00, lr:0.0006
[11:47:58.764] iteration:14491  t-loss:0.1315, loss-lb:0.0837, loss-ulb:0.0239, weight:2.00, lr:0.0006
[11:47:58.956] iteration:14492  t-loss:0.1449, loss-lb:0.0925, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:47:59.150] iteration:14493  t-loss:0.2356, loss-lb:0.0853, loss-ulb:0.0752, weight:2.00, lr:0.0006
[11:47:59.342] iteration:14494  t-loss:0.1816, loss-lb:0.0882, loss-ulb:0.0467, weight:2.00, lr:0.0006
[11:47:59.535] iteration:14495  t-loss:0.1555, loss-lb:0.0902, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:47:59.727] iteration:14496  t-loss:0.1484, loss-lb:0.0816, loss-ulb:0.0334, weight:2.00, lr:0.0006
[11:47:59.919] iteration:14497  t-loss:0.1489, loss-lb:0.0810, loss-ulb:0.0340, weight:2.00, lr:0.0006
[11:48:00.110] iteration:14498  t-loss:0.1655, loss-lb:0.0890, loss-ulb:0.0383, weight:2.00, lr:0.0006
[11:48:00.300] iteration:14499  t-loss:0.1530, loss-lb:0.0872, loss-ulb:0.0329, weight:2.00, lr:0.0006
[11:48:00.491] iteration:14500  t-loss:0.1366, loss-lb:0.0799, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:48:00.681] iteration:14501  t-loss:0.1261, loss-lb:0.0758, loss-ulb:0.0251, weight:2.00, lr:0.0006
[11:48:00.872] iteration:14502  t-loss:0.1404, loss-lb:0.0831, loss-ulb:0.0286, weight:2.00, lr:0.0006
[11:48:01.063] iteration:14503  t-loss:0.1342, loss-lb:0.0759, loss-ulb:0.0291, weight:2.00, lr:0.0006
[11:48:01.255] iteration:14504  t-loss:0.1514, loss-lb:0.0851, loss-ulb:0.0331, weight:2.00, lr:0.0006
[11:48:01.843] iteration:14505  t-loss:0.1551, loss-lb:0.0885, loss-ulb:0.0333, weight:2.00, lr:0.0006
[11:48:02.038] iteration:14506  t-loss:0.1452, loss-lb:0.0839, loss-ulb:0.0307, weight:2.00, lr:0.0006
[11:48:02.233] iteration:14507  t-loss:0.4684, loss-lb:0.0843, loss-ulb:0.1920, weight:2.00, lr:0.0006
[11:48:02.427] iteration:14508  t-loss:0.1909, loss-lb:0.0950, loss-ulb:0.0479, weight:2.00, lr:0.0006
[11:48:02.620] iteration:14509  t-loss:0.1594, loss-lb:0.0806, loss-ulb:0.0394, weight:2.00, lr:0.0006
[11:48:02.813] iteration:14510  t-loss:0.1436, loss-lb:0.0852, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:48:03.007] iteration:14511  t-loss:0.1800, loss-lb:0.0886, loss-ulb:0.0457, weight:2.00, lr:0.0006
[11:48:03.201] iteration:14512  t-loss:0.1398, loss-lb:0.0821, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:48:03.392] iteration:14513  t-loss:0.1367, loss-lb:0.0847, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:48:03.585] iteration:14514  t-loss:0.1462, loss-lb:0.0646, loss-ulb:0.0408, weight:2.00, lr:0.0006
[11:48:03.778] iteration:14515  t-loss:0.1498, loss-lb:0.0778, loss-ulb:0.0360, weight:2.00, lr:0.0006
[11:48:03.970] iteration:14516  t-loss:0.1499, loss-lb:0.0817, loss-ulb:0.0341, weight:2.00, lr:0.0006
[11:48:04.162] iteration:14517  t-loss:0.1384, loss-lb:0.0756, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:48:04.355] iteration:14518  t-loss:0.1688, loss-lb:0.0826, loss-ulb:0.0431, weight:2.00, lr:0.0006
[11:48:04.548] iteration:14519  t-loss:0.1422, loss-lb:0.0802, loss-ulb:0.0310, weight:2.00, lr:0.0006
[11:48:04.740] iteration:14520  t-loss:0.1373, loss-lb:0.0784, loss-ulb:0.0295, weight:2.00, lr:0.0006
[11:48:04.932] iteration:14521  t-loss:0.1366, loss-lb:0.0846, loss-ulb:0.0260, weight:2.00, lr:0.0006
[11:48:05.125] iteration:14522  t-loss:0.1537, loss-lb:0.0800, loss-ulb:0.0368, weight:2.00, lr:0.0006
[11:48:05.318] iteration:14523  t-loss:0.1398, loss-lb:0.0864, loss-ulb:0.0267, weight:2.00, lr:0.0006
[11:48:05.509] iteration:14524  t-loss:0.1354, loss-lb:0.0777, loss-ulb:0.0288, weight:2.00, lr:0.0006
[11:48:05.701] iteration:14525  t-loss:0.1634, loss-lb:0.0920, loss-ulb:0.0357, weight:2.00, lr:0.0006
[11:48:05.893] iteration:14526  t-loss:0.1423, loss-lb:0.0874, loss-ulb:0.0275, weight:2.00, lr:0.0006
[11:48:06.085] iteration:14527  t-loss:0.1419, loss-lb:0.0831, loss-ulb:0.0294, weight:2.00, lr:0.0006
[11:48:06.278] iteration:14528  t-loss:0.1571, loss-lb:0.0865, loss-ulb:0.0353, weight:2.00, lr:0.0006
[11:48:06.472] iteration:14529  t-loss:0.1374, loss-lb:0.0752, loss-ulb:0.0311, weight:2.00, lr:0.0006
[11:48:06.664] iteration:14530  t-loss:0.1446, loss-lb:0.0806, loss-ulb:0.0320, weight:2.00, lr:0.0006
[11:48:06.856] iteration:14531  t-loss:0.1405, loss-lb:0.0827, loss-ulb:0.0289, weight:2.00, lr:0.0006
[11:48:07.049] iteration:14532  t-loss:0.1417, loss-lb:0.0783, loss-ulb:0.0317, weight:2.00, lr:0.0006
[11:48:07.242] iteration:14533  t-loss:0.1386, loss-lb:0.0802, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:48:07.435] iteration:14534  t-loss:0.1406, loss-lb:0.0803, loss-ulb:0.0302, weight:2.00, lr:0.0006
[11:48:07.628] iteration:14535  t-loss:0.1455, loss-lb:0.0827, loss-ulb:0.0314, weight:2.00, lr:0.0006
[11:48:07.821] iteration:14536  t-loss:0.1459, loss-lb:0.0829, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:48:08.015] iteration:14537  t-loss:0.2164, loss-lb:0.0704, loss-ulb:0.0730, weight:2.00, lr:0.0006
[11:48:08.206] iteration:14538  t-loss:0.1453, loss-lb:0.0861, loss-ulb:0.0296, weight:2.00, lr:0.0006
[11:48:08.398] iteration:14539  t-loss:0.1388, loss-lb:0.0825, loss-ulb:0.0282, weight:2.00, lr:0.0006
[11:48:08.591] iteration:14540  t-loss:0.1527, loss-lb:0.0817, loss-ulb:0.0355, weight:2.00, lr:0.0006
[11:48:08.783] iteration:14541  t-loss:0.1381, loss-lb:0.0771, loss-ulb:0.0305, weight:2.00, lr:0.0006
[11:48:08.976] iteration:14542  t-loss:0.1391, loss-lb:0.0762, loss-ulb:0.0315, weight:2.00, lr:0.0006
[11:48:09.169] iteration:14543  t-loss:0.1461, loss-lb:0.0908, loss-ulb:0.0277, weight:2.00, lr:0.0006
[11:48:09.360] iteration:14544  t-loss:0.1492, loss-lb:0.0855, loss-ulb:0.0319, weight:2.00, lr:0.0006
[11:48:09.553] iteration:14545  t-loss:0.3622, loss-lb:0.0778, loss-ulb:0.1422, weight:2.00, lr:0.0006
[11:48:09.748] iteration:14546  t-loss:0.1480, loss-lb:0.0789, loss-ulb:0.0346, weight:2.00, lr:0.0006
[11:48:09.942] iteration:14547  t-loss:0.1442, loss-lb:0.0816, loss-ulb:0.0313, weight:2.00, lr:0.0006
[11:48:10.134] iteration:14548  t-loss:0.1245, loss-lb:0.0721, loss-ulb:0.0262, weight:2.00, lr:0.0006
[11:48:10.327] iteration:14549  t-loss:0.1395, loss-lb:0.0838, loss-ulb:0.0279, weight:2.00, lr:0.0006
[11:48:10.520] iteration:14550  t-loss:0.1578, loss-lb:0.0926, loss-ulb:0.0326, weight:2.00, lr:0.0006
[11:48:10.713] iteration:14551  t-loss:0.2076, loss-lb:0.0764, loss-ulb:0.0656, weight:2.00, lr:0.0006
[11:48:10.906] iteration:14552  t-loss:0.1392, loss-lb:0.0808, loss-ulb:0.0292, weight:2.00, lr:0.0006
[11:48:11.098] iteration:14553  t-loss:0.1599, loss-lb:0.0896, loss-ulb:0.0352, weight:2.00, lr:0.0006
[11:48:11.291] iteration:14554  t-loss:0.2296, loss-lb:0.0755, loss-ulb:0.0771, weight:2.00, lr:0.0006
[11:48:11.483] iteration:14555  t-loss:0.1527, loss-lb:0.0819, loss-ulb:0.0354, weight:2.00, lr:0.0006
[11:48:11.676] iteration:14556  t-loss:0.1405, loss-lb:0.0839, loss-ulb:0.0283, weight:2.00, lr:0.0006
[11:48:11.869] iteration:14557  t-loss:0.1398, loss-lb:0.0849, loss-ulb:0.0274, weight:2.00, lr:0.0006
[11:48:12.062] iteration:14558  t-loss:0.1445, loss-lb:0.0750, loss-ulb:0.0348, weight:2.00, lr:0.0006
[11:48:12.254] iteration:14559  t-loss:0.1495, loss-lb:0.0746, loss-ulb:0.0375, weight:2.00, lr:0.0006
[11:48:12.446] iteration:14560  t-loss:0.1430, loss-lb:0.0774, loss-ulb:0.0328, weight:2.00, lr:0.0006
[11:48:12.638] iteration:14561  t-loss:0.1550, loss-lb:0.0832, loss-ulb:0.0359, weight:2.00, lr:0.0006
[11:48:12.830] iteration:14562  t-loss:0.1352, loss-lb:0.0785, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:48:13.022] iteration:14563  t-loss:0.1529, loss-lb:0.0882, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:48:13.215] iteration:14564  t-loss:0.1577, loss-lb:0.0818, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:48:13.407] iteration:14565  t-loss:0.1417, loss-lb:0.0768, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:48:13.599] iteration:14566  t-loss:0.1337, loss-lb:0.0762, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:48:13.791] iteration:14567  t-loss:0.1394, loss-lb:0.0790, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:48:13.983] iteration:14568  t-loss:0.1566, loss-lb:0.0776, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:48:14.176] iteration:14569  t-loss:0.1586, loss-lb:0.0852, loss-ulb:0.0367, weight:2.00, lr:0.0005
[11:48:14.369] iteration:14570  t-loss:0.1612, loss-lb:0.0949, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:48:14.561] iteration:14571  t-loss:0.1533, loss-lb:0.0819, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:48:14.753] iteration:14572  t-loss:0.1517, loss-lb:0.0874, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:48:14.947] iteration:14573  t-loss:0.1430, loss-lb:0.0832, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:48:15.140] iteration:14574  t-loss:0.1387, loss-lb:0.0833, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:48:15.332] iteration:14575  t-loss:0.1359, loss-lb:0.0834, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:48:15.525] iteration:14576  t-loss:0.1419, loss-lb:0.0780, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:48:15.718] iteration:14577  t-loss:0.2009, loss-lb:0.0871, loss-ulb:0.0569, weight:2.00, lr:0.0005
[11:48:15.910] iteration:14578  t-loss:0.1388, loss-lb:0.0801, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:48:16.102] iteration:14579  t-loss:0.1555, loss-lb:0.0788, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:48:16.295] iteration:14580  t-loss:0.1918, loss-lb:0.0932, loss-ulb:0.0493, weight:2.00, lr:0.0005
[11:48:16.488] iteration:14581  t-loss:0.1723, loss-lb:0.0877, loss-ulb:0.0423, weight:2.00, lr:0.0005
[11:48:16.680] iteration:14582  t-loss:0.1329, loss-lb:0.0785, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:48:16.871] iteration:14583  t-loss:0.1500, loss-lb:0.0840, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:48:17.064] iteration:14584  t-loss:0.1387, loss-lb:0.0810, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:48:17.257] iteration:14585  t-loss:0.1672, loss-lb:0.0762, loss-ulb:0.0455, weight:2.00, lr:0.0005
[11:48:17.450] iteration:14586  t-loss:0.1459, loss-lb:0.0874, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:48:17.641] iteration:14587  t-loss:0.1353, loss-lb:0.0787, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:48:17.833] iteration:14588  t-loss:0.1392, loss-lb:0.0767, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:48:18.026] iteration:14589  t-loss:0.1284, loss-lb:0.0784, loss-ulb:0.0250, weight:2.00, lr:0.0005
[11:48:18.217] iteration:14590  t-loss:0.1383, loss-lb:0.0752, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:48:18.411] iteration:14591  t-loss:0.2955, loss-lb:0.0803, loss-ulb:0.1076, weight:2.00, lr:0.0005
[11:48:18.604] iteration:14592  t-loss:0.1349, loss-lb:0.0837, loss-ulb:0.0256, weight:2.00, lr:0.0005
[11:48:18.796] iteration:14593  t-loss:0.1304, loss-lb:0.0797, loss-ulb:0.0254, weight:2.00, lr:0.0005
[11:48:18.988] iteration:14594  t-loss:0.1564, loss-lb:0.0829, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:48:19.180] iteration:14595  t-loss:0.1457, loss-lb:0.0823, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:48:19.372] iteration:14596  t-loss:0.2091, loss-lb:0.0790, loss-ulb:0.0651, weight:2.00, lr:0.0005
[11:48:19.562] iteration:14597  t-loss:0.1450, loss-lb:0.0789, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:48:19.754] iteration:14598  t-loss:0.1625, loss-lb:0.0873, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:48:19.944] iteration:14599  t-loss:0.1393, loss-lb:0.0759, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:48:20.135] iteration:14600  t-loss:0.1518, loss-lb:0.0942, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:48:20.327] iteration:14601  t-loss:0.1470, loss-lb:0.0777, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:48:20.519] iteration:14602  t-loss:0.1575, loss-lb:0.0927, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:48:31.756]  <<Test>> - Ep:148  - mean_dice/mean_h95 - S:90.99/1.20, Best-S:90.99, T:89.77/1.39, Best-T:90.48
[11:48:31.756]           - AvgLoss(lb/ulb/all):0.0819/0.0372/0.1559
[11:48:32.265] iteration:14603  t-loss:0.1781, loss-lb:0.0857, loss-ulb:0.0462, weight:2.00, lr:0.0005
[11:48:32.462] iteration:14604  t-loss:0.1454, loss-lb:0.0826, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:48:32.654] iteration:14605  t-loss:0.1442, loss-lb:0.0814, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:48:32.847] iteration:14606  t-loss:0.1522, loss-lb:0.0829, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:48:33.040] iteration:14607  t-loss:0.1556, loss-lb:0.0849, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:48:33.233] iteration:14608  t-loss:0.2087, loss-lb:0.0876, loss-ulb:0.0606, weight:2.00, lr:0.0005
[11:48:33.426] iteration:14609  t-loss:0.1860, loss-lb:0.1047, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:48:33.618] iteration:14610  t-loss:0.1706, loss-lb:0.0942, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:48:33.811] iteration:14611  t-loss:0.1441, loss-lb:0.0880, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:48:34.005] iteration:14612  t-loss:0.1588, loss-lb:0.0839, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:48:34.197] iteration:14613  t-loss:0.1826, loss-lb:0.0907, loss-ulb:0.0460, weight:2.00, lr:0.0005
[11:48:34.391] iteration:14614  t-loss:0.2437, loss-lb:0.0843, loss-ulb:0.0797, weight:2.00, lr:0.0005
[11:48:34.584] iteration:14615  t-loss:0.1510, loss-lb:0.0846, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:48:34.778] iteration:14616  t-loss:0.1327, loss-lb:0.0784, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:48:34.973] iteration:14617  t-loss:0.1699, loss-lb:0.0826, loss-ulb:0.0437, weight:2.00, lr:0.0005
[11:48:35.167] iteration:14618  t-loss:0.1378, loss-lb:0.0768, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:48:35.359] iteration:14619  t-loss:0.1408, loss-lb:0.0844, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:48:35.552] iteration:14620  t-loss:0.1538, loss-lb:0.0837, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:48:35.745] iteration:14621  t-loss:0.1500, loss-lb:0.0901, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:48:35.937] iteration:14622  t-loss:0.1690, loss-lb:0.1004, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:48:36.130] iteration:14623  t-loss:0.1462, loss-lb:0.0877, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:48:36.325] iteration:14624  t-loss:0.1643, loss-lb:0.0973, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:48:36.517] iteration:14625  t-loss:0.2074, loss-lb:0.0833, loss-ulb:0.0621, weight:2.00, lr:0.0005
[11:48:36.710] iteration:14626  t-loss:0.1340, loss-lb:0.0793, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:48:36.903] iteration:14627  t-loss:0.1431, loss-lb:0.0883, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:48:37.095] iteration:14628  t-loss:0.1630, loss-lb:0.0892, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:48:37.288] iteration:14629  t-loss:0.1633, loss-lb:0.0912, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:48:37.480] iteration:14630  t-loss:0.1531, loss-lb:0.0866, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:48:37.673] iteration:14631  t-loss:0.1822, loss-lb:0.0795, loss-ulb:0.0514, weight:2.00, lr:0.0005
[11:48:37.865] iteration:14632  t-loss:0.2124, loss-lb:0.0882, loss-ulb:0.0621, weight:2.00, lr:0.0005
[11:48:38.057] iteration:14633  t-loss:0.1678, loss-lb:0.1040, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:48:38.251] iteration:14634  t-loss:0.1684, loss-lb:0.0791, loss-ulb:0.0447, weight:2.00, lr:0.0005
[11:48:38.443] iteration:14635  t-loss:0.1560, loss-lb:0.0786, loss-ulb:0.0387, weight:2.00, lr:0.0005
[11:48:38.637] iteration:14636  t-loss:0.1721, loss-lb:0.0863, loss-ulb:0.0429, weight:2.00, lr:0.0005
[11:48:38.829] iteration:14637  t-loss:0.1524, loss-lb:0.0976, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:48:39.023] iteration:14638  t-loss:0.2083, loss-lb:0.0977, loss-ulb:0.0553, weight:2.00, lr:0.0005
[11:48:39.215] iteration:14639  t-loss:0.1490, loss-lb:0.0871, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:48:39.408] iteration:14640  t-loss:0.1569, loss-lb:0.0801, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:48:39.600] iteration:14641  t-loss:0.1363, loss-lb:0.0819, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:48:39.792] iteration:14642  t-loss:0.1616, loss-lb:0.0899, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:48:39.985] iteration:14643  t-loss:0.1556, loss-lb:0.0926, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:48:40.178] iteration:14644  t-loss:0.1422, loss-lb:0.0833, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:48:40.371] iteration:14645  t-loss:0.1790, loss-lb:0.0933, loss-ulb:0.0429, weight:2.00, lr:0.0005
[11:48:40.564] iteration:14646  t-loss:0.1748, loss-lb:0.0853, loss-ulb:0.0448, weight:2.00, lr:0.0005
[11:48:40.758] iteration:14647  t-loss:0.1359, loss-lb:0.0754, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:48:40.950] iteration:14648  t-loss:0.1582, loss-lb:0.0832, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:48:41.142] iteration:14649  t-loss:0.1405, loss-lb:0.0810, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:48:41.335] iteration:14650  t-loss:0.1648, loss-lb:0.0858, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:48:41.528] iteration:14651  t-loss:0.1646, loss-lb:0.0953, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:48:41.720] iteration:14652  t-loss:0.1469, loss-lb:0.0874, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:48:41.914] iteration:14653  t-loss:0.3430, loss-lb:0.0825, loss-ulb:0.1302, weight:2.00, lr:0.0005
[11:48:42.109] iteration:14654  t-loss:0.1538, loss-lb:0.0893, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:48:42.306] iteration:14655  t-loss:0.1534, loss-lb:0.0805, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:48:42.500] iteration:14656  t-loss:0.1462, loss-lb:0.0860, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:48:42.693] iteration:14657  t-loss:0.1425, loss-lb:0.0773, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:48:42.886] iteration:14658  t-loss:0.1622, loss-lb:0.0897, loss-ulb:0.0362, weight:2.00, lr:0.0005
[11:48:43.078] iteration:14659  t-loss:0.1738, loss-lb:0.0846, loss-ulb:0.0446, weight:2.00, lr:0.0005
[11:48:43.269] iteration:14660  t-loss:0.1503, loss-lb:0.0821, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:48:43.461] iteration:14661  t-loss:0.2125, loss-lb:0.0919, loss-ulb:0.0603, weight:2.00, lr:0.0005
[11:48:43.653] iteration:14662  t-loss:0.1457, loss-lb:0.0801, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:48:43.845] iteration:14663  t-loss:0.1449, loss-lb:0.0853, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:48:44.037] iteration:14664  t-loss:0.1410, loss-lb:0.0839, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:48:44.229] iteration:14665  t-loss:0.1415, loss-lb:0.0807, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:48:44.421] iteration:14666  t-loss:0.1625, loss-lb:0.0813, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:48:44.613] iteration:14667  t-loss:0.1412, loss-lb:0.0896, loss-ulb:0.0258, weight:2.00, lr:0.0005
[11:48:44.806] iteration:14668  t-loss:0.2179, loss-lb:0.0916, loss-ulb:0.0631, weight:2.00, lr:0.0005
[11:48:44.997] iteration:14669  t-loss:0.1435, loss-lb:0.0838, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:48:45.189] iteration:14670  t-loss:0.1597, loss-lb:0.0795, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:48:45.380] iteration:14671  t-loss:0.1414, loss-lb:0.0839, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:48:45.571] iteration:14672  t-loss:0.1430, loss-lb:0.0782, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:48:45.764] iteration:14673  t-loss:0.1511, loss-lb:0.0987, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:48:45.956] iteration:14674  t-loss:0.1552, loss-lb:0.0876, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:48:46.148] iteration:14675  t-loss:0.1573, loss-lb:0.0794, loss-ulb:0.0390, weight:2.00, lr:0.0005
[11:48:46.339] iteration:14676  t-loss:0.1529, loss-lb:0.0914, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:48:46.530] iteration:14677  t-loss:0.1564, loss-lb:0.0886, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:48:46.722] iteration:14678  t-loss:0.1839, loss-lb:0.0879, loss-ulb:0.0480, weight:2.00, lr:0.0005
[11:48:46.913] iteration:14679  t-loss:0.1407, loss-lb:0.0804, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:48:47.105] iteration:14680  t-loss:0.1637, loss-lb:0.0871, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:48:47.296] iteration:14681  t-loss:0.1778, loss-lb:0.1059, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:48:47.488] iteration:14682  t-loss:0.1559, loss-lb:0.0916, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:48:47.682] iteration:14683  t-loss:0.1840, loss-lb:0.0840, loss-ulb:0.0500, weight:2.00, lr:0.0005
[11:48:47.873] iteration:14684  t-loss:0.1766, loss-lb:0.0925, loss-ulb:0.0420, weight:2.00, lr:0.0005
[11:48:48.065] iteration:14685  t-loss:0.1453, loss-lb:0.0822, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:48:48.258] iteration:14686  t-loss:0.1584, loss-lb:0.0883, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:48:48.449] iteration:14687  t-loss:0.1452, loss-lb:0.0821, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:48:48.641] iteration:14688  t-loss:0.1479, loss-lb:0.0822, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:48:48.833] iteration:14689  t-loss:0.1637, loss-lb:0.0932, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:48:49.025] iteration:14690  t-loss:0.1493, loss-lb:0.0853, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:48:49.218] iteration:14691  t-loss:0.1514, loss-lb:0.0860, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:48:49.409] iteration:14692  t-loss:0.1740, loss-lb:0.1018, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:48:49.600] iteration:14693  t-loss:0.1540, loss-lb:0.0826, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:48:49.790] iteration:14694  t-loss:0.1640, loss-lb:0.0881, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:48:49.981] iteration:14695  t-loss:0.4453, loss-lb:0.0922, loss-ulb:0.1765, weight:2.00, lr:0.0005
[11:48:50.171] iteration:14696  t-loss:0.2351, loss-lb:0.0917, loss-ulb:0.0717, weight:2.00, lr:0.0005
[11:48:50.361] iteration:14697  t-loss:0.1549, loss-lb:0.0862, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:48:50.551] iteration:14698  t-loss:0.1578, loss-lb:0.0926, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:48:50.740] iteration:14699  t-loss:0.1443, loss-lb:0.0799, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:48:50.929] iteration:14700  t-loss:0.1929, loss-lb:0.0843, loss-ulb:0.0543, weight:2.00, lr:0.0005
[11:48:51.507] iteration:14701  t-loss:0.1507, loss-lb:0.0807, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:48:51.702] iteration:14702  t-loss:0.1826, loss-lb:0.0931, loss-ulb:0.0447, weight:2.00, lr:0.0005
[11:48:51.894] iteration:14703  t-loss:0.1448, loss-lb:0.0880, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:48:52.085] iteration:14704  t-loss:0.2477, loss-lb:0.1046, loss-ulb:0.0715, weight:2.00, lr:0.0005
[11:48:52.276] iteration:14705  t-loss:0.1880, loss-lb:0.0914, loss-ulb:0.0483, weight:2.00, lr:0.0005
[11:48:52.469] iteration:14706  t-loss:0.1932, loss-lb:0.0945, loss-ulb:0.0493, weight:2.00, lr:0.0005
[11:48:52.661] iteration:14707  t-loss:0.2042, loss-lb:0.0907, loss-ulb:0.0568, weight:2.00, lr:0.0005
[11:48:52.854] iteration:14708  t-loss:0.1527, loss-lb:0.0923, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:48:53.049] iteration:14709  t-loss:0.1472, loss-lb:0.0870, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:48:53.245] iteration:14710  t-loss:0.2778, loss-lb:0.0807, loss-ulb:0.0986, weight:2.00, lr:0.0005
[11:48:53.439] iteration:14711  t-loss:0.1688, loss-lb:0.0870, loss-ulb:0.0409, weight:2.00, lr:0.0005
[11:48:53.633] iteration:14712  t-loss:0.1470, loss-lb:0.0884, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:48:53.826] iteration:14713  t-loss:0.1649, loss-lb:0.0876, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:48:54.018] iteration:14714  t-loss:0.3536, loss-lb:0.0921, loss-ulb:0.1307, weight:2.00, lr:0.0005
[11:48:54.210] iteration:14715  t-loss:0.1490, loss-lb:0.0919, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:48:54.402] iteration:14716  t-loss:0.1786, loss-lb:0.0929, loss-ulb:0.0429, weight:2.00, lr:0.0005
[11:48:54.594] iteration:14717  t-loss:0.1642, loss-lb:0.0989, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:48:54.786] iteration:14718  t-loss:0.1893, loss-lb:0.0827, loss-ulb:0.0533, weight:2.00, lr:0.0005
[11:48:54.977] iteration:14719  t-loss:0.1796, loss-lb:0.1055, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:48:55.169] iteration:14720  t-loss:0.1920, loss-lb:0.1003, loss-ulb:0.0459, weight:2.00, lr:0.0005
[11:48:55.361] iteration:14721  t-loss:0.2121, loss-lb:0.0945, loss-ulb:0.0588, weight:2.00, lr:0.0005
[11:48:55.553] iteration:14722  t-loss:0.1896, loss-lb:0.1000, loss-ulb:0.0448, weight:2.00, lr:0.0005
[11:48:55.745] iteration:14723  t-loss:0.1525, loss-lb:0.0884, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:48:55.937] iteration:14724  t-loss:0.1519, loss-lb:0.0838, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:48:56.128] iteration:14725  t-loss:0.1593, loss-lb:0.1025, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:48:56.321] iteration:14726  t-loss:0.1590, loss-lb:0.0892, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:48:56.512] iteration:14727  t-loss:0.1589, loss-lb:0.0943, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:48:56.704] iteration:14728  t-loss:0.1726, loss-lb:0.0842, loss-ulb:0.0442, weight:2.00, lr:0.0005
[11:48:56.897] iteration:14729  t-loss:0.1444, loss-lb:0.0865, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:48:57.090] iteration:14730  t-loss:0.1585, loss-lb:0.0937, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:48:57.281] iteration:14731  t-loss:0.1409, loss-lb:0.0869, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:48:57.473] iteration:14732  t-loss:0.1557, loss-lb:0.0898, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:48:57.665] iteration:14733  t-loss:0.1490, loss-lb:0.0791, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:48:57.857] iteration:14734  t-loss:0.1557, loss-lb:0.0828, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:48:58.050] iteration:14735  t-loss:0.1446, loss-lb:0.0841, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:48:58.242] iteration:14736  t-loss:0.1561, loss-lb:0.1033, loss-ulb:0.0264, weight:2.00, lr:0.0005
[11:48:58.434] iteration:14737  t-loss:0.1557, loss-lb:0.0798, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:48:58.625] iteration:14738  t-loss:0.1291, loss-lb:0.0770, loss-ulb:0.0260, weight:2.00, lr:0.0005
[11:48:58.816] iteration:14739  t-loss:0.1655, loss-lb:0.0979, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:48:59.009] iteration:14740  t-loss:0.2670, loss-lb:0.1166, loss-ulb:0.0752, weight:2.00, lr:0.0005
[11:48:59.202] iteration:14741  t-loss:0.1357, loss-lb:0.0830, loss-ulb:0.0263, weight:2.00, lr:0.0005
[11:48:59.395] iteration:14742  t-loss:0.1568, loss-lb:0.0913, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:48:59.587] iteration:14743  t-loss:0.1496, loss-lb:0.0873, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:48:59.778] iteration:14744  t-loss:0.1447, loss-lb:0.0811, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:48:59.970] iteration:14745  t-loss:0.1402, loss-lb:0.0825, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:49:00.162] iteration:14746  t-loss:0.1352, loss-lb:0.0806, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:49:00.354] iteration:14747  t-loss:0.1328, loss-lb:0.0739, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:49:00.546] iteration:14748  t-loss:0.1479, loss-lb:0.0836, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:49:00.736] iteration:14749  t-loss:0.1576, loss-lb:0.0898, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:49:00.929] iteration:14750  t-loss:0.1538, loss-lb:0.0877, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:49:01.120] iteration:14751  t-loss:0.1395, loss-lb:0.0798, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:49:01.311] iteration:14752  t-loss:0.1511, loss-lb:0.0882, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:49:01.503] iteration:14753  t-loss:0.1740, loss-lb:0.0887, loss-ulb:0.0427, weight:2.00, lr:0.0005
[11:49:01.696] iteration:14754  t-loss:0.1402, loss-lb:0.0796, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:49:01.898] iteration:14755  t-loss:0.1438, loss-lb:0.0867, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:49:02.094] iteration:14756  t-loss:0.1532, loss-lb:0.0968, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:49:02.288] iteration:14757  t-loss:0.2189, loss-lb:0.1015, loss-ulb:0.0587, weight:2.00, lr:0.0005
[11:49:02.479] iteration:14758  t-loss:0.1382, loss-lb:0.0814, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:49:02.671] iteration:14759  t-loss:0.1561, loss-lb:0.0829, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:49:02.864] iteration:14760  t-loss:0.1447, loss-lb:0.0838, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:49:03.056] iteration:14761  t-loss:0.1577, loss-lb:0.0871, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:49:03.247] iteration:14762  t-loss:0.1679, loss-lb:0.0856, loss-ulb:0.0412, weight:2.00, lr:0.0005
[11:49:03.440] iteration:14763  t-loss:0.1643, loss-lb:0.0901, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:49:03.633] iteration:14764  t-loss:0.1462, loss-lb:0.0903, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:49:03.827] iteration:14765  t-loss:0.1431, loss-lb:0.0845, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:49:04.024] iteration:14766  t-loss:0.1619, loss-lb:0.0950, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:49:04.219] iteration:14767  t-loss:0.1401, loss-lb:0.0838, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:49:04.412] iteration:14768  t-loss:0.1503, loss-lb:0.0870, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:49:04.605] iteration:14769  t-loss:0.1473, loss-lb:0.0865, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:49:04.798] iteration:14770  t-loss:0.1347, loss-lb:0.0804, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:49:04.990] iteration:14771  t-loss:0.2183, loss-lb:0.0918, loss-ulb:0.0633, weight:2.00, lr:0.0005
[11:49:05.181] iteration:14772  t-loss:0.1458, loss-lb:0.0855, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:49:05.374] iteration:14773  t-loss:0.1820, loss-lb:0.0773, loss-ulb:0.0523, weight:2.00, lr:0.0005
[11:49:05.565] iteration:14774  t-loss:0.1440, loss-lb:0.0839, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:49:05.758] iteration:14775  t-loss:0.1388, loss-lb:0.0821, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:49:05.951] iteration:14776  t-loss:0.1575, loss-lb:0.0818, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:49:06.142] iteration:14777  t-loss:0.1556, loss-lb:0.0820, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:49:06.335] iteration:14778  t-loss:0.1380, loss-lb:0.0825, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:49:06.527] iteration:14779  t-loss:0.1522, loss-lb:0.0906, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:49:06.719] iteration:14780  t-loss:0.1597, loss-lb:0.0894, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:49:06.912] iteration:14781  t-loss:0.2589, loss-lb:0.0747, loss-ulb:0.0921, weight:2.00, lr:0.0005
[11:49:07.103] iteration:14782  t-loss:0.1493, loss-lb:0.0894, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:49:07.297] iteration:14783  t-loss:0.2148, loss-lb:0.0847, loss-ulb:0.0651, weight:2.00, lr:0.0005
[11:49:07.490] iteration:14784  t-loss:0.1502, loss-lb:0.0886, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:49:07.682] iteration:14785  t-loss:0.1498, loss-lb:0.0807, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:49:07.875] iteration:14786  t-loss:0.1361, loss-lb:0.0799, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:49:08.068] iteration:14787  t-loss:0.1469, loss-lb:0.0832, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:49:08.260] iteration:14788  t-loss:0.1493, loss-lb:0.0911, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:49:08.452] iteration:14789  t-loss:0.1432, loss-lb:0.0860, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:49:08.644] iteration:14790  t-loss:0.1632, loss-lb:0.0968, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:49:08.837] iteration:14791  t-loss:0.1386, loss-lb:0.0835, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:49:09.027] iteration:14792  t-loss:0.1546, loss-lb:0.1031, loss-ulb:0.0258, weight:2.00, lr:0.0005
[11:49:09.218] iteration:14793  t-loss:0.1486, loss-lb:0.0874, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:49:09.407] iteration:14794  t-loss:0.1427, loss-lb:0.0884, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:49:09.598] iteration:14795  t-loss:0.1379, loss-lb:0.0814, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:49:09.789] iteration:14796  t-loss:0.1669, loss-lb:0.0763, loss-ulb:0.0453, weight:2.00, lr:0.0005
[11:49:09.979] iteration:14797  t-loss:0.1510, loss-lb:0.0799, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:49:10.172] iteration:14798  t-loss:0.2502, loss-lb:0.0805, loss-ulb:0.0848, weight:2.00, lr:0.0005
[11:49:22.861]  <<Test>> - Ep:150  - mean_dice/mean_h95 - S:89.66/1.82, Best-S:90.99, T:90.29/1.36, Best-T:90.48
[11:49:22.862]           - AvgLoss(lb/ulb/all):0.0878/0.0387/0.1632
[11:49:23.401] iteration:14799  t-loss:0.1514, loss-lb:0.0863, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:49:23.595] iteration:14800  t-loss:0.1393, loss-lb:0.0829, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:49:23.787] iteration:14801  t-loss:0.1515, loss-lb:0.0876, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:49:23.979] iteration:14802  t-loss:0.1335, loss-lb:0.0835, loss-ulb:0.0250, weight:2.00, lr:0.0005
[11:49:24.171] iteration:14803  t-loss:0.1412, loss-lb:0.0851, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:49:24.363] iteration:14804  t-loss:0.1478, loss-lb:0.0865, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:49:24.555] iteration:14805  t-loss:0.1661, loss-lb:0.0878, loss-ulb:0.0391, weight:2.00, lr:0.0005
[11:49:24.746] iteration:14806  t-loss:0.1461, loss-lb:0.0842, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:49:24.937] iteration:14807  t-loss:0.1481, loss-lb:0.0761, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:49:25.131] iteration:14808  t-loss:0.1265, loss-lb:0.0755, loss-ulb:0.0255, weight:2.00, lr:0.0005
[11:49:25.323] iteration:14809  t-loss:0.1767, loss-lb:0.0920, loss-ulb:0.0424, weight:2.00, lr:0.0005
[11:49:25.516] iteration:14810  t-loss:0.1328, loss-lb:0.0786, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:49:25.709] iteration:14811  t-loss:0.1493, loss-lb:0.0822, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:49:25.902] iteration:14812  t-loss:0.1709, loss-lb:0.0862, loss-ulb:0.0424, weight:2.00, lr:0.0005
[11:49:26.094] iteration:14813  t-loss:0.1412, loss-lb:0.0794, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:49:26.287] iteration:14814  t-loss:0.1363, loss-lb:0.0742, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:49:26.482] iteration:14815  t-loss:0.1660, loss-lb:0.0908, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:49:26.675] iteration:14816  t-loss:0.1449, loss-lb:0.0886, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:49:26.869] iteration:14817  t-loss:0.1517, loss-lb:0.0887, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:49:27.061] iteration:14818  t-loss:0.1700, loss-lb:0.0843, loss-ulb:0.0429, weight:2.00, lr:0.0005
[11:49:27.254] iteration:14819  t-loss:0.1371, loss-lb:0.0771, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:49:27.447] iteration:14820  t-loss:0.1692, loss-lb:0.1090, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:49:27.641] iteration:14821  t-loss:0.1613, loss-lb:0.0922, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:49:27.834] iteration:14822  t-loss:0.1397, loss-lb:0.0759, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:49:28.027] iteration:14823  t-loss:0.1573, loss-lb:0.0907, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:49:28.220] iteration:14824  t-loss:0.2041, loss-lb:0.0889, loss-ulb:0.0576, weight:2.00, lr:0.0005
[11:49:28.412] iteration:14825  t-loss:0.1537, loss-lb:0.0943, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:49:28.604] iteration:14826  t-loss:0.1595, loss-lb:0.0893, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:49:28.797] iteration:14827  t-loss:0.1449, loss-lb:0.0883, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:49:28.989] iteration:14828  t-loss:0.2149, loss-lb:0.0931, loss-ulb:0.0609, weight:2.00, lr:0.0005
[11:49:29.181] iteration:14829  t-loss:0.1347, loss-lb:0.0793, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:49:29.374] iteration:14830  t-loss:0.1262, loss-lb:0.0768, loss-ulb:0.0247, weight:2.00, lr:0.0005
[11:49:29.567] iteration:14831  t-loss:0.2157, loss-lb:0.0766, loss-ulb:0.0696, weight:2.00, lr:0.0005
[11:49:29.759] iteration:14832  t-loss:0.1376, loss-lb:0.0832, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:49:29.951] iteration:14833  t-loss:0.1373, loss-lb:0.0795, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:49:30.143] iteration:14834  t-loss:0.1377, loss-lb:0.0803, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:49:30.335] iteration:14835  t-loss:0.1557, loss-lb:0.0939, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:49:30.527] iteration:14836  t-loss:0.1695, loss-lb:0.0803, loss-ulb:0.0446, weight:2.00, lr:0.0005
[11:49:30.719] iteration:14837  t-loss:0.1836, loss-lb:0.0909, loss-ulb:0.0463, weight:2.00, lr:0.0005
[11:49:30.912] iteration:14838  t-loss:0.1388, loss-lb:0.0812, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:49:31.104] iteration:14839  t-loss:0.1585, loss-lb:0.0930, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:49:31.296] iteration:14840  t-loss:0.1982, loss-lb:0.0870, loss-ulb:0.0556, weight:2.00, lr:0.0005
[11:49:31.490] iteration:14841  t-loss:0.1639, loss-lb:0.0862, loss-ulb:0.0389, weight:2.00, lr:0.0005
[11:49:31.683] iteration:14842  t-loss:0.1588, loss-lb:0.0914, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:49:31.875] iteration:14843  t-loss:0.1450, loss-lb:0.0777, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:49:32.067] iteration:14844  t-loss:0.1672, loss-lb:0.0882, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:49:32.260] iteration:14845  t-loss:0.1651, loss-lb:0.0900, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:49:32.452] iteration:14846  t-loss:0.1284, loss-lb:0.0751, loss-ulb:0.0266, weight:2.00, lr:0.0005
[11:49:32.645] iteration:14847  t-loss:0.1536, loss-lb:0.0777, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:49:32.838] iteration:14848  t-loss:0.1611, loss-lb:0.0822, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:49:33.031] iteration:14849  t-loss:0.1620, loss-lb:0.0884, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:49:33.223] iteration:14850  t-loss:0.1538, loss-lb:0.0898, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:49:33.417] iteration:14851  t-loss:0.1747, loss-lb:0.0857, loss-ulb:0.0445, weight:2.00, lr:0.0005
[11:49:33.609] iteration:14852  t-loss:0.1529, loss-lb:0.0872, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:49:33.801] iteration:14853  t-loss:0.1414, loss-lb:0.0832, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:49:33.993] iteration:14854  t-loss:0.1489, loss-lb:0.0909, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:49:34.186] iteration:14855  t-loss:0.1519, loss-lb:0.0931, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:49:34.378] iteration:14856  t-loss:0.1430, loss-lb:0.0814, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:49:34.582] iteration:14857  t-loss:0.1399, loss-lb:0.0897, loss-ulb:0.0251, weight:2.00, lr:0.0005
[11:49:34.780] iteration:14858  t-loss:0.1653, loss-lb:0.0948, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:49:34.975] iteration:14859  t-loss:0.1811, loss-lb:0.0872, loss-ulb:0.0470, weight:2.00, lr:0.0005
[11:49:35.169] iteration:14860  t-loss:0.1340, loss-lb:0.0814, loss-ulb:0.0263, weight:2.00, lr:0.0005
[11:49:35.361] iteration:14861  t-loss:0.1412, loss-lb:0.0853, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:49:35.553] iteration:14862  t-loss:0.1803, loss-lb:0.0828, loss-ulb:0.0488, weight:2.00, lr:0.0005
[11:49:35.745] iteration:14863  t-loss:0.1419, loss-lb:0.0836, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:49:35.938] iteration:14864  t-loss:0.1559, loss-lb:0.0941, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:49:36.130] iteration:14865  t-loss:0.1423, loss-lb:0.0836, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:49:36.322] iteration:14866  t-loss:0.1449, loss-lb:0.0854, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:49:36.515] iteration:14867  t-loss:0.1785, loss-lb:0.0805, loss-ulb:0.0490, weight:2.00, lr:0.0005
[11:49:36.707] iteration:14868  t-loss:0.1405, loss-lb:0.0813, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:49:36.899] iteration:14869  t-loss:0.1518, loss-lb:0.0823, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:49:37.092] iteration:14870  t-loss:0.1724, loss-lb:0.0902, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:49:37.283] iteration:14871  t-loss:0.1503, loss-lb:0.0791, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:49:37.476] iteration:14872  t-loss:0.1364, loss-lb:0.0850, loss-ulb:0.0257, weight:2.00, lr:0.0005
[11:49:37.668] iteration:14873  t-loss:0.1400, loss-lb:0.0762, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:49:37.861] iteration:14874  t-loss:0.1425, loss-lb:0.0860, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:49:38.054] iteration:14875  t-loss:0.1586, loss-lb:0.0921, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:49:38.247] iteration:14876  t-loss:0.1615, loss-lb:0.0843, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:49:38.439] iteration:14877  t-loss:0.1457, loss-lb:0.0939, loss-ulb:0.0259, weight:2.00, lr:0.0005
[11:49:38.632] iteration:14878  t-loss:0.1678, loss-lb:0.0886, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:49:38.824] iteration:14879  t-loss:0.1334, loss-lb:0.0764, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:49:39.016] iteration:14880  t-loss:0.1482, loss-lb:0.0834, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:49:39.208] iteration:14881  t-loss:0.1379, loss-lb:0.0842, loss-ulb:0.0268, weight:2.00, lr:0.0005
[11:49:39.400] iteration:14882  t-loss:0.1643, loss-lb:0.0794, loss-ulb:0.0425, weight:2.00, lr:0.0005
[11:49:39.594] iteration:14883  t-loss:0.1415, loss-lb:0.0854, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:49:39.785] iteration:14884  t-loss:0.1384, loss-lb:0.0776, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:49:39.979] iteration:14885  t-loss:0.2456, loss-lb:0.0832, loss-ulb:0.0812, weight:2.00, lr:0.0005
[11:49:40.172] iteration:14886  t-loss:0.1359, loss-lb:0.0771, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:49:40.364] iteration:14887  t-loss:0.1554, loss-lb:0.0966, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:49:40.557] iteration:14888  t-loss:0.1573, loss-lb:0.0910, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:49:40.749] iteration:14889  t-loss:0.1476, loss-lb:0.0861, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:49:40.941] iteration:14890  t-loss:0.1889, loss-lb:0.0970, loss-ulb:0.0460, weight:2.00, lr:0.0005
[11:49:41.132] iteration:14891  t-loss:0.1536, loss-lb:0.0772, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:49:41.323] iteration:14892  t-loss:0.1543, loss-lb:0.0884, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:49:41.514] iteration:14893  t-loss:0.1427, loss-lb:0.0889, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:49:41.705] iteration:14894  t-loss:0.1761, loss-lb:0.0821, loss-ulb:0.0470, weight:2.00, lr:0.0005
[11:49:41.896] iteration:14895  t-loss:0.1355, loss-lb:0.0813, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:49:42.087] iteration:14896  t-loss:0.1690, loss-lb:0.0816, loss-ulb:0.0437, weight:2.00, lr:0.0005
[11:49:42.656] iteration:14897  t-loss:0.1391, loss-lb:0.0822, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:49:42.853] iteration:14898  t-loss:0.1565, loss-lb:0.0843, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:49:43.045] iteration:14899  t-loss:0.1400, loss-lb:0.0784, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:49:43.239] iteration:14900  t-loss:0.1509, loss-lb:0.0834, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:49:43.432] iteration:14901  t-loss:0.1831, loss-lb:0.1043, loss-ulb:0.0394, weight:2.00, lr:0.0005
[11:49:43.625] iteration:14902  t-loss:0.1311, loss-lb:0.0734, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:49:43.817] iteration:14903  t-loss:0.1751, loss-lb:0.0984, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:49:44.011] iteration:14904  t-loss:0.1669, loss-lb:0.1043, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:49:44.204] iteration:14905  t-loss:0.1464, loss-lb:0.0853, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:49:44.396] iteration:14906  t-loss:0.1463, loss-lb:0.0822, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:49:44.589] iteration:14907  t-loss:0.2167, loss-lb:0.0810, loss-ulb:0.0678, weight:2.00, lr:0.0005
[11:49:44.786] iteration:14908  t-loss:0.1538, loss-lb:0.0827, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:49:44.979] iteration:14909  t-loss:0.1557, loss-lb:0.0819, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:49:45.172] iteration:14910  t-loss:0.1936, loss-lb:0.1074, loss-ulb:0.0431, weight:2.00, lr:0.0005
[11:49:45.365] iteration:14911  t-loss:0.2276, loss-lb:0.1432, loss-ulb:0.0422, weight:2.00, lr:0.0005
[11:49:45.557] iteration:14912  t-loss:0.2565, loss-lb:0.0937, loss-ulb:0.0814, weight:2.00, lr:0.0005
[11:49:45.750] iteration:14913  t-loss:0.2316, loss-lb:0.1413, loss-ulb:0.0452, weight:2.00, lr:0.0005
[11:49:45.943] iteration:14914  t-loss:0.1817, loss-lb:0.1067, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:49:46.137] iteration:14915  t-loss:0.1858, loss-lb:0.1000, loss-ulb:0.0429, weight:2.00, lr:0.0005
[11:49:46.328] iteration:14916  t-loss:0.2793, loss-lb:0.0926, loss-ulb:0.0933, weight:2.00, lr:0.0005
[11:49:46.520] iteration:14917  t-loss:0.2243, loss-lb:0.1565, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:49:46.713] iteration:14918  t-loss:0.2081, loss-lb:0.1185, loss-ulb:0.0448, weight:2.00, lr:0.0005
[11:49:46.905] iteration:14919  t-loss:0.1571, loss-lb:0.0897, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:49:47.098] iteration:14920  t-loss:0.2186, loss-lb:0.0979, loss-ulb:0.0603, weight:2.00, lr:0.0005
[11:49:47.291] iteration:14921  t-loss:0.1748, loss-lb:0.1087, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:49:47.483] iteration:14922  t-loss:0.2229, loss-lb:0.0967, loss-ulb:0.0631, weight:2.00, lr:0.0005
[11:49:47.675] iteration:14923  t-loss:0.1755, loss-lb:0.0886, loss-ulb:0.0434, weight:2.00, lr:0.0005
[11:49:47.867] iteration:14924  t-loss:0.2011, loss-lb:0.0830, loss-ulb:0.0590, weight:2.00, lr:0.0005
[11:49:48.060] iteration:14925  t-loss:0.1695, loss-lb:0.0942, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:49:48.252] iteration:14926  t-loss:0.1655, loss-lb:0.0944, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:49:48.443] iteration:14927  t-loss:0.1708, loss-lb:0.0917, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:49:48.635] iteration:14928  t-loss:0.1457, loss-lb:0.0900, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:49:48.829] iteration:14929  t-loss:0.1590, loss-lb:0.0853, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:49:49.022] iteration:14930  t-loss:0.1860, loss-lb:0.1139, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:49:49.214] iteration:14931  t-loss:0.1670, loss-lb:0.0880, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:49:49.408] iteration:14932  t-loss:0.1420, loss-lb:0.0835, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:49:49.600] iteration:14933  t-loss:0.1410, loss-lb:0.0909, loss-ulb:0.0250, weight:2.00, lr:0.0005
[11:49:49.793] iteration:14934  t-loss:0.1528, loss-lb:0.0935, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:49:49.985] iteration:14935  t-loss:0.1675, loss-lb:0.0985, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:49:50.177] iteration:14936  t-loss:0.1471, loss-lb:0.0927, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:49:50.371] iteration:14937  t-loss:0.1752, loss-lb:0.0965, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:49:50.563] iteration:14938  t-loss:0.1861, loss-lb:0.0888, loss-ulb:0.0486, weight:2.00, lr:0.0005
[11:49:50.755] iteration:14939  t-loss:0.1563, loss-lb:0.0903, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:49:50.948] iteration:14940  t-loss:0.1449, loss-lb:0.0897, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:49:51.141] iteration:14941  t-loss:0.1727, loss-lb:0.0892, loss-ulb:0.0418, weight:2.00, lr:0.0005
[11:49:51.335] iteration:14942  t-loss:0.1904, loss-lb:0.0898, loss-ulb:0.0503, weight:2.00, lr:0.0005
[11:49:51.527] iteration:14943  t-loss:0.1575, loss-lb:0.0828, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:49:51.721] iteration:14944  t-loss:0.1554, loss-lb:0.0838, loss-ulb:0.0358, weight:2.00, lr:0.0005
[11:49:51.915] iteration:14945  t-loss:0.1974, loss-lb:0.0935, loss-ulb:0.0520, weight:2.00, lr:0.0005
[11:49:52.108] iteration:14946  t-loss:0.1528, loss-lb:0.0946, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:49:52.301] iteration:14947  t-loss:0.1407, loss-lb:0.0923, loss-ulb:0.0242, weight:2.00, lr:0.0005
[11:49:52.494] iteration:14948  t-loss:0.1491, loss-lb:0.0829, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:49:52.687] iteration:14949  t-loss:0.2085, loss-lb:0.0886, loss-ulb:0.0599, weight:2.00, lr:0.0005
[11:49:52.879] iteration:14950  t-loss:0.1625, loss-lb:0.0882, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:49:53.071] iteration:14951  t-loss:0.1529, loss-lb:0.0804, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:49:53.264] iteration:14952  t-loss:0.1568, loss-lb:0.0950, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:49:53.456] iteration:14953  t-loss:0.1502, loss-lb:0.0954, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:49:53.649] iteration:14954  t-loss:0.1552, loss-lb:0.0876, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:49:53.842] iteration:14955  t-loss:0.1508, loss-lb:0.0876, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:49:54.035] iteration:14956  t-loss:0.1483, loss-lb:0.0879, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:49:54.226] iteration:14957  t-loss:0.1406, loss-lb:0.0834, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:49:54.420] iteration:14958  t-loss:0.1635, loss-lb:0.0982, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:49:54.613] iteration:14959  t-loss:0.1601, loss-lb:0.0794, loss-ulb:0.0403, weight:2.00, lr:0.0005
[11:49:54.807] iteration:14960  t-loss:0.1518, loss-lb:0.0853, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:49:54.999] iteration:14961  t-loss:0.1467, loss-lb:0.0836, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:49:55.191] iteration:14962  t-loss:0.1570, loss-lb:0.0797, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:49:55.384] iteration:14963  t-loss:0.1404, loss-lb:0.0849, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:49:55.576] iteration:14964  t-loss:0.1559, loss-lb:0.0770, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:49:55.769] iteration:14965  t-loss:0.1598, loss-lb:0.0875, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:49:55.962] iteration:14966  t-loss:0.1434, loss-lb:0.0823, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:49:56.155] iteration:14967  t-loss:0.1347, loss-lb:0.0805, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:49:56.347] iteration:14968  t-loss:0.2053, loss-lb:0.0877, loss-ulb:0.0588, weight:2.00, lr:0.0005
[11:49:56.541] iteration:14969  t-loss:0.2582, loss-lb:0.1049, loss-ulb:0.0767, weight:2.00, lr:0.0005
[11:49:56.733] iteration:14970  t-loss:0.1647, loss-lb:0.0857, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:49:56.927] iteration:14971  t-loss:0.1519, loss-lb:0.0813, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:49:57.120] iteration:14972  t-loss:0.1655, loss-lb:0.0923, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:49:57.312] iteration:14973  t-loss:0.1443, loss-lb:0.0827, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:49:57.505] iteration:14974  t-loss:0.1476, loss-lb:0.0869, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:49:57.698] iteration:14975  t-loss:0.1644, loss-lb:0.0902, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:49:57.890] iteration:14976  t-loss:0.1492, loss-lb:0.0771, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:49:58.083] iteration:14977  t-loss:0.1527, loss-lb:0.0838, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:49:58.275] iteration:14978  t-loss:0.1441, loss-lb:0.0873, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:49:58.467] iteration:14979  t-loss:0.1265, loss-lb:0.0808, loss-ulb:0.0228, weight:2.00, lr:0.0005
[11:49:58.659] iteration:14980  t-loss:0.1561, loss-lb:0.0801, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:49:58.853] iteration:14981  t-loss:0.1419, loss-lb:0.0755, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:49:59.046] iteration:14982  t-loss:0.1924, loss-lb:0.0796, loss-ulb:0.0564, weight:2.00, lr:0.0005
[11:49:59.240] iteration:14983  t-loss:0.1452, loss-lb:0.0958, loss-ulb:0.0247, weight:2.00, lr:0.0005
[11:49:59.433] iteration:14984  t-loss:0.1366, loss-lb:0.0761, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:49:59.626] iteration:14985  t-loss:0.1523, loss-lb:0.0912, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:49:59.818] iteration:14986  t-loss:0.1448, loss-lb:0.0905, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:50:00.009] iteration:14987  t-loss:0.1796, loss-lb:0.1156, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:50:00.200] iteration:14988  t-loss:0.1736, loss-lb:0.0961, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:50:00.391] iteration:14989  t-loss:0.1457, loss-lb:0.0839, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:50:00.583] iteration:14990  t-loss:0.1422, loss-lb:0.0835, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:50:00.773] iteration:14991  t-loss:0.1385, loss-lb:0.0766, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:50:00.964] iteration:14992  t-loss:0.1369, loss-lb:0.0854, loss-ulb:0.0257, weight:2.00, lr:0.0005
[11:50:01.156] iteration:14993  t-loss:0.1547, loss-lb:0.0769, loss-ulb:0.0389, weight:2.00, lr:0.0005
[11:50:01.346] iteration:14994  t-loss:0.1814, loss-lb:0.0859, loss-ulb:0.0477, weight:2.00, lr:0.0005
[11:50:12.569]  <<Test>> - Ep:152  - mean_dice/mean_h95 - S:89.68/1.38, Best-S:90.99, T:89.94/1.39, Best-T:90.48
[11:50:12.570]           - AvgLoss(lb/ulb/all):0.0908/0.0337/0.1529
[11:50:13.093] iteration:14995  t-loss:0.1393, loss-lb:0.0833, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:50:13.292] iteration:14996  t-loss:0.1852, loss-lb:0.1015, loss-ulb:0.0418, weight:2.00, lr:0.0005
[11:50:13.485] iteration:14997  t-loss:0.1471, loss-lb:0.0724, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:50:13.679] iteration:14998  t-loss:0.1574, loss-lb:0.0953, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:50:13.872] iteration:14999  t-loss:0.1646, loss-lb:0.0848, loss-ulb:0.0399, weight:2.00, lr:0.0005
[11:50:14.066] iteration:15000  t-loss:0.1413, loss-lb:0.0819, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:50:14.259] iteration:15001  t-loss:0.1416, loss-lb:0.0820, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:50:14.452] iteration:15002  t-loss:0.1713, loss-lb:0.0961, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:50:14.645] iteration:15003  t-loss:0.1418, loss-lb:0.0866, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:50:14.838] iteration:15004  t-loss:0.1474, loss-lb:0.0817, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:50:15.032] iteration:15005  t-loss:0.1466, loss-lb:0.0849, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:50:15.228] iteration:15006  t-loss:0.1729, loss-lb:0.0867, loss-ulb:0.0431, weight:2.00, lr:0.0005
[11:50:15.425] iteration:15007  t-loss:0.1669, loss-lb:0.0807, loss-ulb:0.0431, weight:2.00, lr:0.0005
[11:50:15.622] iteration:15008  t-loss:0.1342, loss-lb:0.0832, loss-ulb:0.0255, weight:2.00, lr:0.0005
[11:50:15.816] iteration:15009  t-loss:0.1497, loss-lb:0.0850, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:50:16.009] iteration:15010  t-loss:0.1495, loss-lb:0.0814, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:50:16.202] iteration:15011  t-loss:0.1409, loss-lb:0.0871, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:50:16.394] iteration:15012  t-loss:0.1756, loss-lb:0.0894, loss-ulb:0.0431, weight:2.00, lr:0.0005
[11:50:16.586] iteration:15013  t-loss:0.1538, loss-lb:0.0864, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:50:16.778] iteration:15014  t-loss:0.1428, loss-lb:0.0735, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:50:16.970] iteration:15015  t-loss:0.1909, loss-lb:0.0931, loss-ulb:0.0489, weight:2.00, lr:0.0005
[11:50:17.164] iteration:15016  t-loss:0.2147, loss-lb:0.0936, loss-ulb:0.0605, weight:2.00, lr:0.0005
[11:50:17.360] iteration:15017  t-loss:0.1449, loss-lb:0.0887, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:50:17.553] iteration:15018  t-loss:0.1511, loss-lb:0.0899, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:50:17.746] iteration:15019  t-loss:0.1370, loss-lb:0.0853, loss-ulb:0.0259, weight:2.00, lr:0.0005
[11:50:17.938] iteration:15020  t-loss:0.2427, loss-lb:0.0827, loss-ulb:0.0800, weight:2.00, lr:0.0005
[11:50:18.130] iteration:15021  t-loss:0.1510, loss-lb:0.0934, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:50:18.321] iteration:15022  t-loss:0.1648, loss-lb:0.0858, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:50:18.514] iteration:15023  t-loss:0.1630, loss-lb:0.0773, loss-ulb:0.0428, weight:2.00, lr:0.0005
[11:50:18.706] iteration:15024  t-loss:0.2195, loss-lb:0.0940, loss-ulb:0.0628, weight:2.00, lr:0.0005
[11:50:18.897] iteration:15025  t-loss:0.2174, loss-lb:0.0796, loss-ulb:0.0689, weight:2.00, lr:0.0005
[11:50:19.089] iteration:15026  t-loss:0.1585, loss-lb:0.0895, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:50:19.281] iteration:15027  t-loss:0.1578, loss-lb:0.0802, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:50:19.473] iteration:15028  t-loss:0.2157, loss-lb:0.1429, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:50:19.666] iteration:15029  t-loss:0.1583, loss-lb:0.0846, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:50:19.857] iteration:15030  t-loss:0.1519, loss-lb:0.0749, loss-ulb:0.0385, weight:2.00, lr:0.0005
[11:50:20.050] iteration:15031  t-loss:0.2058, loss-lb:0.0865, loss-ulb:0.0596, weight:2.00, lr:0.0005
[11:50:20.242] iteration:15032  t-loss:0.1866, loss-lb:0.0925, loss-ulb:0.0470, weight:2.00, lr:0.0005
[11:50:20.435] iteration:15033  t-loss:0.1737, loss-lb:0.1111, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:50:20.626] iteration:15034  t-loss:0.1790, loss-lb:0.1064, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:50:20.819] iteration:15035  t-loss:0.1591, loss-lb:0.0806, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:50:21.011] iteration:15036  t-loss:0.1662, loss-lb:0.0938, loss-ulb:0.0362, weight:2.00, lr:0.0005
[11:50:21.203] iteration:15037  t-loss:0.1577, loss-lb:0.0956, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:50:21.395] iteration:15038  t-loss:0.1443, loss-lb:0.0839, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:50:21.587] iteration:15039  t-loss:0.1701, loss-lb:0.0769, loss-ulb:0.0466, weight:2.00, lr:0.0005
[11:50:21.778] iteration:15040  t-loss:0.1472, loss-lb:0.0852, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:50:21.972] iteration:15041  t-loss:0.1392, loss-lb:0.0815, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:50:22.164] iteration:15042  t-loss:0.1634, loss-lb:0.0889, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:50:22.355] iteration:15043  t-loss:0.1559, loss-lb:0.0903, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:50:22.547] iteration:15044  t-loss:0.1494, loss-lb:0.0818, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:50:22.738] iteration:15045  t-loss:0.1666, loss-lb:0.0900, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:50:22.930] iteration:15046  t-loss:0.1628, loss-lb:0.1029, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:50:23.120] iteration:15047  t-loss:0.1685, loss-lb:0.0946, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:50:23.314] iteration:15048  t-loss:0.1676, loss-lb:0.0877, loss-ulb:0.0400, weight:2.00, lr:0.0005
[11:50:23.506] iteration:15049  t-loss:0.1584, loss-lb:0.0952, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:50:23.698] iteration:15050  t-loss:0.1429, loss-lb:0.0827, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:50:23.890] iteration:15051  t-loss:0.1473, loss-lb:0.0885, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:50:24.082] iteration:15052  t-loss:0.1380, loss-lb:0.0925, loss-ulb:0.0227, weight:2.00, lr:0.0005
[11:50:24.273] iteration:15053  t-loss:0.1557, loss-lb:0.0889, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:50:24.465] iteration:15054  t-loss:0.1608, loss-lb:0.0795, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:50:24.655] iteration:15055  t-loss:0.1455, loss-lb:0.0891, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:50:24.846] iteration:15056  t-loss:0.1454, loss-lb:0.0862, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:50:25.037] iteration:15057  t-loss:0.1412, loss-lb:0.0798, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:50:25.228] iteration:15058  t-loss:0.1501, loss-lb:0.0806, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:50:25.420] iteration:15059  t-loss:0.1423, loss-lb:0.0863, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:50:25.612] iteration:15060  t-loss:0.1356, loss-lb:0.0826, loss-ulb:0.0265, weight:2.00, lr:0.0005
[11:50:25.806] iteration:15061  t-loss:0.1690, loss-lb:0.0976, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:50:26.001] iteration:15062  t-loss:0.1449, loss-lb:0.0787, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:50:26.196] iteration:15063  t-loss:0.1461, loss-lb:0.0791, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:50:26.392] iteration:15064  t-loss:0.1318, loss-lb:0.0806, loss-ulb:0.0256, weight:2.00, lr:0.0005
[11:50:26.584] iteration:15065  t-loss:0.1571, loss-lb:0.0810, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:50:26.777] iteration:15066  t-loss:0.2010, loss-lb:0.0959, loss-ulb:0.0526, weight:2.00, lr:0.0005
[11:50:26.969] iteration:15067  t-loss:0.1418, loss-lb:0.0906, loss-ulb:0.0256, weight:2.00, lr:0.0005
[11:50:27.161] iteration:15068  t-loss:0.1561, loss-lb:0.0909, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:50:27.352] iteration:15069  t-loss:0.1542, loss-lb:0.0829, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:50:27.543] iteration:15070  t-loss:0.1532, loss-lb:0.0855, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:50:27.736] iteration:15071  t-loss:0.1581, loss-lb:0.0933, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:50:27.928] iteration:15072  t-loss:0.1432, loss-lb:0.0834, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:50:28.122] iteration:15073  t-loss:0.1436, loss-lb:0.0889, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:50:28.314] iteration:15074  t-loss:0.1641, loss-lb:0.0947, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:50:28.506] iteration:15075  t-loss:0.1512, loss-lb:0.0783, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:50:28.698] iteration:15076  t-loss:0.1684, loss-lb:0.0948, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:50:28.891] iteration:15077  t-loss:0.1493, loss-lb:0.0821, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:50:29.083] iteration:15078  t-loss:0.1403, loss-lb:0.0804, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:50:29.275] iteration:15079  t-loss:0.1878, loss-lb:0.0873, loss-ulb:0.0502, weight:2.00, lr:0.0005
[11:50:29.469] iteration:15080  t-loss:0.1603, loss-lb:0.0713, loss-ulb:0.0445, weight:2.00, lr:0.0005
[11:50:29.661] iteration:15081  t-loss:0.1515, loss-lb:0.0908, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:50:29.852] iteration:15082  t-loss:0.1433, loss-lb:0.0807, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:50:30.049] iteration:15083  t-loss:0.1515, loss-lb:0.0901, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:50:30.242] iteration:15084  t-loss:0.1424, loss-lb:0.0795, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:50:30.434] iteration:15085  t-loss:0.1565, loss-lb:0.0860, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:50:30.625] iteration:15086  t-loss:0.1573, loss-lb:0.0817, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:50:30.815] iteration:15087  t-loss:0.1938, loss-lb:0.0776, loss-ulb:0.0581, weight:2.00, lr:0.0005
[11:50:31.008] iteration:15088  t-loss:0.1503, loss-lb:0.0871, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:50:31.200] iteration:15089  t-loss:0.1433, loss-lb:0.0796, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:50:31.392] iteration:15090  t-loss:0.1632, loss-lb:0.1031, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:50:31.582] iteration:15091  t-loss:0.1347, loss-lb:0.0783, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:50:31.772] iteration:15092  t-loss:0.1571, loss-lb:0.0774, loss-ulb:0.0399, weight:2.00, lr:0.0005
[11:50:32.398] iteration:15093  t-loss:0.1721, loss-lb:0.0860, loss-ulb:0.0430, weight:2.00, lr:0.0005
[11:50:32.594] iteration:15094  t-loss:0.1890, loss-lb:0.0907, loss-ulb:0.0492, weight:2.00, lr:0.0005
[11:50:32.787] iteration:15095  t-loss:0.1361, loss-lb:0.0814, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:50:32.978] iteration:15096  t-loss:0.1429, loss-lb:0.0851, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:50:33.171] iteration:15097  t-loss:0.2028, loss-lb:0.0899, loss-ulb:0.0565, weight:2.00, lr:0.0005
[11:50:33.364] iteration:15098  t-loss:0.1577, loss-lb:0.0840, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:50:33.556] iteration:15099  t-loss:0.1440, loss-lb:0.0847, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:50:33.749] iteration:15100  t-loss:0.1643, loss-lb:0.0908, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:50:33.941] iteration:15101  t-loss:0.1424, loss-lb:0.0831, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:50:34.132] iteration:15102  t-loss:0.1562, loss-lb:0.0850, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:50:34.324] iteration:15103  t-loss:0.1678, loss-lb:0.0915, loss-ulb:0.0381, weight:2.00, lr:0.0005
[11:50:34.516] iteration:15104  t-loss:0.1401, loss-lb:0.0863, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:50:34.710] iteration:15105  t-loss:0.1964, loss-lb:0.0823, loss-ulb:0.0570, weight:2.00, lr:0.0005
[11:50:34.901] iteration:15106  t-loss:0.1379, loss-lb:0.0817, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:50:35.094] iteration:15107  t-loss:0.1684, loss-lb:0.0861, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:50:35.285] iteration:15108  t-loss:0.1365, loss-lb:0.0782, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:50:35.476] iteration:15109  t-loss:0.1468, loss-lb:0.0930, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:50:35.669] iteration:15110  t-loss:0.1588, loss-lb:0.0903, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:50:35.860] iteration:15111  t-loss:0.1440, loss-lb:0.0825, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:50:36.052] iteration:15112  t-loss:0.1575, loss-lb:0.0749, loss-ulb:0.0413, weight:2.00, lr:0.0005
[11:50:36.243] iteration:15113  t-loss:0.1402, loss-lb:0.0812, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:50:36.436] iteration:15114  t-loss:0.2272, loss-lb:0.0918, loss-ulb:0.0677, weight:2.00, lr:0.0005
[11:50:36.630] iteration:15115  t-loss:0.1391, loss-lb:0.0886, loss-ulb:0.0252, weight:2.00, lr:0.0005
[11:50:36.826] iteration:15116  t-loss:0.1332, loss-lb:0.0816, loss-ulb:0.0258, weight:2.00, lr:0.0005
[11:50:37.024] iteration:15117  t-loss:0.1450, loss-lb:0.0852, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:50:37.219] iteration:15118  t-loss:0.1497, loss-lb:0.0833, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:50:37.419] iteration:15119  t-loss:0.1975, loss-lb:0.0957, loss-ulb:0.0509, weight:2.00, lr:0.0005
[11:50:37.610] iteration:15120  t-loss:0.1293, loss-lb:0.0780, loss-ulb:0.0257, weight:2.00, lr:0.0005
[11:50:37.802] iteration:15121  t-loss:0.1428, loss-lb:0.0833, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:50:37.994] iteration:15122  t-loss:0.1411, loss-lb:0.0801, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:50:38.185] iteration:15123  t-loss:0.1583, loss-lb:0.0836, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:50:38.376] iteration:15124  t-loss:0.1393, loss-lb:0.0842, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:50:38.569] iteration:15125  t-loss:0.1495, loss-lb:0.0822, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:50:38.761] iteration:15126  t-loss:0.1784, loss-lb:0.0805, loss-ulb:0.0490, weight:2.00, lr:0.0005
[11:50:38.961] iteration:15127  t-loss:0.1389, loss-lb:0.0805, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:50:39.154] iteration:15128  t-loss:0.1978, loss-lb:0.0941, loss-ulb:0.0519, weight:2.00, lr:0.0005
[11:50:39.345] iteration:15129  t-loss:0.1567, loss-lb:0.0880, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:50:39.541] iteration:15130  t-loss:0.1862, loss-lb:0.0778, loss-ulb:0.0542, weight:2.00, lr:0.0005
[11:50:39.733] iteration:15131  t-loss:0.1370, loss-lb:0.0763, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:50:39.927] iteration:15132  t-loss:0.2933, loss-lb:0.0841, loss-ulb:0.1046, weight:2.00, lr:0.0005
[11:50:40.131] iteration:15133  t-loss:0.1487, loss-lb:0.0917, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:50:40.328] iteration:15134  t-loss:0.1745, loss-lb:0.0956, loss-ulb:0.0394, weight:2.00, lr:0.0005
[11:50:40.529] iteration:15135  t-loss:0.1390, loss-lb:0.0830, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:50:40.721] iteration:15136  t-loss:0.1434, loss-lb:0.0765, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:50:40.911] iteration:15137  t-loss:0.1482, loss-lb:0.0804, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:50:41.103] iteration:15138  t-loss:0.1596, loss-lb:0.0863, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:50:41.295] iteration:15139  t-loss:0.1334, loss-lb:0.0837, loss-ulb:0.0248, weight:2.00, lr:0.0005
[11:50:41.486] iteration:15140  t-loss:0.1471, loss-lb:0.0762, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:50:41.679] iteration:15141  t-loss:0.1655, loss-lb:0.0883, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:50:41.872] iteration:15142  t-loss:0.1443, loss-lb:0.0807, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:50:42.063] iteration:15143  t-loss:0.1439, loss-lb:0.0914, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:50:42.256] iteration:15144  t-loss:0.1386, loss-lb:0.0819, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:50:42.447] iteration:15145  t-loss:0.1575, loss-lb:0.0837, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:50:42.639] iteration:15146  t-loss:0.1781, loss-lb:0.0824, loss-ulb:0.0479, weight:2.00, lr:0.0005
[11:50:42.831] iteration:15147  t-loss:0.1448, loss-lb:0.0853, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:50:43.023] iteration:15148  t-loss:0.1736, loss-lb:0.0946, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:50:43.215] iteration:15149  t-loss:0.1561, loss-lb:0.0968, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:50:43.408] iteration:15150  t-loss:0.1628, loss-lb:0.0927, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:50:43.599] iteration:15151  t-loss:0.1529, loss-lb:0.0867, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:50:43.791] iteration:15152  t-loss:0.1919, loss-lb:0.0847, loss-ulb:0.0536, weight:2.00, lr:0.0005
[11:50:43.982] iteration:15153  t-loss:0.1461, loss-lb:0.0782, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:50:44.174] iteration:15154  t-loss:0.1477, loss-lb:0.0816, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:50:44.366] iteration:15155  t-loss:0.1590, loss-lb:0.0795, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:50:44.557] iteration:15156  t-loss:0.1460, loss-lb:0.0815, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:50:44.750] iteration:15157  t-loss:0.1471, loss-lb:0.0899, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:50:44.941] iteration:15158  t-loss:0.1564, loss-lb:0.0812, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:50:45.132] iteration:15159  t-loss:0.1453, loss-lb:0.0869, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:50:45.324] iteration:15160  t-loss:0.1488, loss-lb:0.0863, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:50:45.514] iteration:15161  t-loss:0.1406, loss-lb:0.0802, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:50:45.707] iteration:15162  t-loss:0.1644, loss-lb:0.0853, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:50:45.897] iteration:15163  t-loss:0.1414, loss-lb:0.0809, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:50:46.090] iteration:15164  t-loss:0.1581, loss-lb:0.0906, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:50:46.281] iteration:15165  t-loss:0.1855, loss-lb:0.0826, loss-ulb:0.0514, weight:2.00, lr:0.0005
[11:50:46.472] iteration:15166  t-loss:0.1645, loss-lb:0.0793, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:50:46.664] iteration:15167  t-loss:0.1651, loss-lb:0.0901, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:50:46.855] iteration:15168  t-loss:0.1629, loss-lb:0.0872, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:50:47.047] iteration:15169  t-loss:0.1632, loss-lb:0.0785, loss-ulb:0.0424, weight:2.00, lr:0.0005
[11:50:47.238] iteration:15170  t-loss:0.1478, loss-lb:0.0864, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:50:47.431] iteration:15171  t-loss:0.1386, loss-lb:0.0857, loss-ulb:0.0265, weight:2.00, lr:0.0005
[11:50:47.626] iteration:15172  t-loss:0.1738, loss-lb:0.0981, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:50:47.824] iteration:15173  t-loss:0.2697, loss-lb:0.0737, loss-ulb:0.0980, weight:2.00, lr:0.0005
[11:50:48.019] iteration:15174  t-loss:0.1438, loss-lb:0.0919, loss-ulb:0.0260, weight:2.00, lr:0.0005
[11:50:48.215] iteration:15175  t-loss:0.1466, loss-lb:0.0827, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:50:48.408] iteration:15176  t-loss:0.1487, loss-lb:0.0807, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:50:48.601] iteration:15177  t-loss:0.1490, loss-lb:0.0884, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:50:48.793] iteration:15178  t-loss:0.1445, loss-lb:0.0799, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:50:48.986] iteration:15179  t-loss:0.1503, loss-lb:0.0878, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:50:49.177] iteration:15180  t-loss:0.1477, loss-lb:0.0843, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:50:49.370] iteration:15181  t-loss:0.1795, loss-lb:0.0853, loss-ulb:0.0471, weight:2.00, lr:0.0005
[11:50:49.562] iteration:15182  t-loss:0.1480, loss-lb:0.0839, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:50:49.754] iteration:15183  t-loss:0.1417, loss-lb:0.0834, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:50:49.944] iteration:15184  t-loss:0.1493, loss-lb:0.0799, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:50:50.138] iteration:15185  t-loss:0.1504, loss-lb:0.0853, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:50:50.328] iteration:15186  t-loss:0.1488, loss-lb:0.0815, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:50:50.519] iteration:15187  t-loss:0.1442, loss-lb:0.0789, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:50:50.710] iteration:15188  t-loss:0.1479, loss-lb:0.0827, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:50:50.900] iteration:15189  t-loss:0.1377, loss-lb:0.0736, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:50:51.092] iteration:15190  t-loss:0.1461, loss-lb:0.0814, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:51:03.606]  <<Test>> - Ep:154  - mean_dice/mean_h95 - S:89.85/1.38, Best-S:90.99, T:90.43/1.30, Best-T:90.48
[11:51:03.606]           - AvgLoss(lb/ulb/all):0.0845/0.0359/0.1553
[11:51:04.148] iteration:15191  t-loss:0.1506, loss-lb:0.0967, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:51:04.346] iteration:15192  t-loss:0.1439, loss-lb:0.0784, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:51:04.539] iteration:15193  t-loss:0.1314, loss-lb:0.0775, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:51:04.732] iteration:15194  t-loss:0.1489, loss-lb:0.0850, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:51:04.924] iteration:15195  t-loss:0.1401, loss-lb:0.0808, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:51:05.117] iteration:15196  t-loss:0.1771, loss-lb:0.0942, loss-ulb:0.0414, weight:2.00, lr:0.0005
[11:51:05.310] iteration:15197  t-loss:0.1467, loss-lb:0.0846, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:51:05.502] iteration:15198  t-loss:0.1523, loss-lb:0.0838, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:51:05.695] iteration:15199  t-loss:0.1600, loss-lb:0.0942, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:51:05.889] iteration:15200  t-loss:0.1319, loss-lb:0.0744, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:51:06.082] iteration:15201  t-loss:0.1513, loss-lb:0.0870, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:51:06.275] iteration:15202  t-loss:0.1373, loss-lb:0.0768, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:51:06.467] iteration:15203  t-loss:0.1336, loss-lb:0.0803, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:51:06.660] iteration:15204  t-loss:0.1387, loss-lb:0.0828, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:51:06.853] iteration:15205  t-loss:0.1347, loss-lb:0.0771, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:51:07.045] iteration:15206  t-loss:0.1407, loss-lb:0.0749, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:51:07.238] iteration:15207  t-loss:0.1560, loss-lb:0.0920, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:51:07.431] iteration:15208  t-loss:0.1762, loss-lb:0.0911, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:51:07.625] iteration:15209  t-loss:0.1472, loss-lb:0.0892, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:51:07.818] iteration:15210  t-loss:0.1508, loss-lb:0.0883, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:51:08.010] iteration:15211  t-loss:0.1525, loss-lb:0.0799, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:51:08.202] iteration:15212  t-loss:0.1495, loss-lb:0.0863, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:51:08.395] iteration:15213  t-loss:0.1417, loss-lb:0.0857, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:51:08.589] iteration:15214  t-loss:0.1393, loss-lb:0.0796, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:51:08.781] iteration:15215  t-loss:0.1284, loss-lb:0.0815, loss-ulb:0.0234, weight:2.00, lr:0.0005
[11:51:08.974] iteration:15216  t-loss:0.2313, loss-lb:0.0819, loss-ulb:0.0747, weight:2.00, lr:0.0005
[11:51:09.168] iteration:15217  t-loss:0.1691, loss-lb:0.0842, loss-ulb:0.0424, weight:2.00, lr:0.0005
[11:51:09.362] iteration:15218  t-loss:0.1571, loss-lb:0.0857, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:51:09.557] iteration:15219  t-loss:0.1782, loss-lb:0.0756, loss-ulb:0.0513, weight:2.00, lr:0.0005
[11:51:09.751] iteration:15220  t-loss:0.1398, loss-lb:0.0770, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:51:09.943] iteration:15221  t-loss:0.1548, loss-lb:0.0806, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:51:10.136] iteration:15222  t-loss:0.1448, loss-lb:0.0860, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:51:10.328] iteration:15223  t-loss:0.1334, loss-lb:0.0710, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:51:10.521] iteration:15224  t-loss:0.1481, loss-lb:0.0806, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:51:10.713] iteration:15225  t-loss:0.1418, loss-lb:0.0829, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:51:10.906] iteration:15226  t-loss:0.1344, loss-lb:0.0759, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:51:11.099] iteration:15227  t-loss:0.1453, loss-lb:0.0828, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:51:11.290] iteration:15228  t-loss:0.1321, loss-lb:0.0790, loss-ulb:0.0266, weight:2.00, lr:0.0005
[11:51:11.482] iteration:15229  t-loss:0.1399, loss-lb:0.0860, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:51:11.675] iteration:15230  t-loss:0.1545, loss-lb:0.0842, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:51:11.867] iteration:15231  t-loss:0.1407, loss-lb:0.0840, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:51:12.061] iteration:15232  t-loss:0.1599, loss-lb:0.0824, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:51:12.253] iteration:15233  t-loss:0.1522, loss-lb:0.0869, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:51:12.445] iteration:15234  t-loss:0.1260, loss-lb:0.0733, loss-ulb:0.0264, weight:2.00, lr:0.0005
[11:51:12.638] iteration:15235  t-loss:0.1762, loss-lb:0.1227, loss-ulb:0.0268, weight:2.00, lr:0.0005
[11:51:12.842] iteration:15236  t-loss:0.1507, loss-lb:0.0761, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:51:13.041] iteration:15237  t-loss:0.1352, loss-lb:0.0736, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:51:13.235] iteration:15238  t-loss:0.1256, loss-lb:0.0748, loss-ulb:0.0254, weight:2.00, lr:0.0005
[11:51:13.427] iteration:15239  t-loss:0.1513, loss-lb:0.0922, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:51:13.619] iteration:15240  t-loss:0.1441, loss-lb:0.0826, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:51:13.811] iteration:15241  t-loss:0.1460, loss-lb:0.0774, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:51:14.004] iteration:15242  t-loss:0.1736, loss-lb:0.0885, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:51:14.196] iteration:15243  t-loss:0.1461, loss-lb:0.0885, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:51:14.390] iteration:15244  t-loss:0.1793, loss-lb:0.0788, loss-ulb:0.0502, weight:2.00, lr:0.0005
[11:51:14.583] iteration:15245  t-loss:0.1439, loss-lb:0.0866, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:51:14.775] iteration:15246  t-loss:0.1367, loss-lb:0.0794, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:51:14.968] iteration:15247  t-loss:0.1638, loss-lb:0.0815, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:51:15.161] iteration:15248  t-loss:0.1502, loss-lb:0.0796, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:51:15.355] iteration:15249  t-loss:0.1512, loss-lb:0.0824, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:51:15.546] iteration:15250  t-loss:0.1456, loss-lb:0.0835, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:51:15.738] iteration:15251  t-loss:0.1262, loss-lb:0.0737, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:51:15.931] iteration:15252  t-loss:0.1461, loss-lb:0.0760, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:51:16.123] iteration:15253  t-loss:0.1403, loss-lb:0.0763, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:51:16.316] iteration:15254  t-loss:0.1465, loss-lb:0.0822, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:51:16.508] iteration:15255  t-loss:0.2860, loss-lb:0.0840, loss-ulb:0.1010, weight:2.00, lr:0.0005
[11:51:16.700] iteration:15256  t-loss:0.1392, loss-lb:0.0778, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:51:16.892] iteration:15257  t-loss:0.1454, loss-lb:0.0864, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:51:17.085] iteration:15258  t-loss:0.1476, loss-lb:0.0847, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:51:17.277] iteration:15259  t-loss:0.1374, loss-lb:0.0806, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:51:17.471] iteration:15260  t-loss:0.1382, loss-lb:0.0792, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:51:17.663] iteration:15261  t-loss:0.1504, loss-lb:0.0829, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:51:17.857] iteration:15262  t-loss:0.1439, loss-lb:0.0801, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:51:18.049] iteration:15263  t-loss:0.1366, loss-lb:0.0800, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:51:18.241] iteration:15264  t-loss:0.1599, loss-lb:0.1032, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:51:18.434] iteration:15265  t-loss:0.1494, loss-lb:0.0844, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:51:18.626] iteration:15266  t-loss:0.1569, loss-lb:0.0922, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:51:18.818] iteration:15267  t-loss:0.1391, loss-lb:0.0832, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:51:19.011] iteration:15268  t-loss:0.1540, loss-lb:0.0848, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:51:19.205] iteration:15269  t-loss:0.1573, loss-lb:0.0992, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:51:19.398] iteration:15270  t-loss:0.1661, loss-lb:0.0801, loss-ulb:0.0430, weight:2.00, lr:0.0005
[11:51:19.591] iteration:15271  t-loss:0.1282, loss-lb:0.0752, loss-ulb:0.0265, weight:2.00, lr:0.0005
[11:51:19.784] iteration:15272  t-loss:0.3008, loss-lb:0.0812, loss-ulb:0.1098, weight:2.00, lr:0.0005
[11:51:19.978] iteration:15273  t-loss:0.1454, loss-lb:0.0854, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:51:20.170] iteration:15274  t-loss:0.1434, loss-lb:0.0832, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:51:20.363] iteration:15275  t-loss:0.1413, loss-lb:0.0878, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:51:20.556] iteration:15276  t-loss:0.1523, loss-lb:0.0779, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:51:20.750] iteration:15277  t-loss:0.1494, loss-lb:0.0921, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:51:20.944] iteration:15278  t-loss:0.2559, loss-lb:0.0847, loss-ulb:0.0856, weight:2.00, lr:0.0005
[11:51:21.136] iteration:15279  t-loss:0.1430, loss-lb:0.0824, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:51:21.329] iteration:15280  t-loss:0.1393, loss-lb:0.0800, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:51:21.523] iteration:15281  t-loss:0.1486, loss-lb:0.0887, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:51:21.716] iteration:15282  t-loss:0.1655, loss-lb:0.0860, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:51:21.907] iteration:15283  t-loss:0.1592, loss-lb:0.0787, loss-ulb:0.0403, weight:2.00, lr:0.0005
[11:51:22.101] iteration:15284  t-loss:0.1753, loss-lb:0.0796, loss-ulb:0.0478, weight:2.00, lr:0.0005
[11:51:22.294] iteration:15285  t-loss:0.1381, loss-lb:0.0795, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:51:22.484] iteration:15286  t-loss:0.1510, loss-lb:0.0877, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:51:22.676] iteration:15287  t-loss:0.1527, loss-lb:0.0815, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:51:22.866] iteration:15288  t-loss:0.1493, loss-lb:0.0936, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:51:23.445] iteration:15289  t-loss:0.1439, loss-lb:0.0822, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:51:23.642] iteration:15290  t-loss:0.1323, loss-lb:0.0813, loss-ulb:0.0255, weight:2.00, lr:0.0005
[11:51:23.834] iteration:15291  t-loss:0.1475, loss-lb:0.0818, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:51:24.026] iteration:15292  t-loss:0.1466, loss-lb:0.0810, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:51:24.219] iteration:15293  t-loss:0.1428, loss-lb:0.0822, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:51:24.411] iteration:15294  t-loss:0.1747, loss-lb:0.0879, loss-ulb:0.0434, weight:2.00, lr:0.0005
[11:51:24.603] iteration:15295  t-loss:0.1396, loss-lb:0.0786, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:51:24.796] iteration:15296  t-loss:0.1635, loss-lb:0.0864, loss-ulb:0.0385, weight:2.00, lr:0.0005
[11:51:24.987] iteration:15297  t-loss:0.1407, loss-lb:0.0841, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:51:25.180] iteration:15298  t-loss:0.2046, loss-lb:0.0909, loss-ulb:0.0568, weight:2.00, lr:0.0005
[11:51:25.374] iteration:15299  t-loss:0.1455, loss-lb:0.0875, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:51:25.566] iteration:15300  t-loss:0.1827, loss-lb:0.0831, loss-ulb:0.0498, weight:2.00, lr:0.0005
[11:51:25.759] iteration:15301  t-loss:0.1523, loss-lb:0.0824, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:51:25.952] iteration:15302  t-loss:0.1381, loss-lb:0.0774, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:51:26.146] iteration:15303  t-loss:0.1477, loss-lb:0.0780, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:51:26.339] iteration:15304  t-loss:0.2004, loss-lb:0.0801, loss-ulb:0.0601, weight:2.00, lr:0.0005
[11:51:26.531] iteration:15305  t-loss:0.2368, loss-lb:0.0879, loss-ulb:0.0744, weight:2.00, lr:0.0005
[11:51:26.724] iteration:15306  t-loss:0.1432, loss-lb:0.0882, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:51:26.916] iteration:15307  t-loss:0.1465, loss-lb:0.0906, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:51:27.108] iteration:15308  t-loss:0.1596, loss-lb:0.0977, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:51:27.300] iteration:15309  t-loss:0.1560, loss-lb:0.0932, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:51:27.492] iteration:15310  t-loss:0.1625, loss-lb:0.0976, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:51:27.685] iteration:15311  t-loss:0.1652, loss-lb:0.1038, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:51:27.877] iteration:15312  t-loss:0.2351, loss-lb:0.1096, loss-ulb:0.0627, weight:2.00, lr:0.0005
[11:51:28.070] iteration:15313  t-loss:0.1510, loss-lb:0.0788, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:51:28.263] iteration:15314  t-loss:0.1737, loss-lb:0.0943, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:51:28.454] iteration:15315  t-loss:0.1625, loss-lb:0.0912, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:51:28.649] iteration:15316  t-loss:0.2090, loss-lb:0.0893, loss-ulb:0.0599, weight:2.00, lr:0.0005
[11:51:28.842] iteration:15317  t-loss:0.1388, loss-lb:0.0789, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:51:29.033] iteration:15318  t-loss:0.1580, loss-lb:0.0888, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:51:29.226] iteration:15319  t-loss:0.1377, loss-lb:0.0850, loss-ulb:0.0264, weight:2.00, lr:0.0005
[11:51:29.419] iteration:15320  t-loss:0.1460, loss-lb:0.0957, loss-ulb:0.0251, weight:2.00, lr:0.0005
[11:51:29.612] iteration:15321  t-loss:0.1418, loss-lb:0.0798, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:51:29.805] iteration:15322  t-loss:0.1453, loss-lb:0.0787, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:51:29.998] iteration:15323  t-loss:0.1394, loss-lb:0.0786, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:51:30.192] iteration:15324  t-loss:0.1577, loss-lb:0.0934, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:51:30.385] iteration:15325  t-loss:0.1931, loss-lb:0.0942, loss-ulb:0.0495, weight:2.00, lr:0.0005
[11:51:30.577] iteration:15326  t-loss:0.1493, loss-lb:0.0952, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:51:30.769] iteration:15327  t-loss:0.1492, loss-lb:0.0948, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:51:30.962] iteration:15328  t-loss:0.1542, loss-lb:0.0871, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:51:31.154] iteration:15329  t-loss:0.1497, loss-lb:0.0809, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:51:31.347] iteration:15330  t-loss:0.1516, loss-lb:0.0868, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:51:31.540] iteration:15331  t-loss:0.2413, loss-lb:0.0810, loss-ulb:0.0801, weight:2.00, lr:0.0005
[11:51:31.733] iteration:15332  t-loss:0.1455, loss-lb:0.0784, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:51:31.926] iteration:15333  t-loss:0.1523, loss-lb:0.0832, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:51:32.118] iteration:15334  t-loss:0.1746, loss-lb:0.0961, loss-ulb:0.0392, weight:2.00, lr:0.0005
[11:51:32.313] iteration:15335  t-loss:0.1406, loss-lb:0.0858, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:51:32.507] iteration:15336  t-loss:0.1366, loss-lb:0.0778, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:51:32.701] iteration:15337  t-loss:0.1723, loss-lb:0.0838, loss-ulb:0.0442, weight:2.00, lr:0.0005
[11:51:32.894] iteration:15338  t-loss:0.1755, loss-lb:0.0807, loss-ulb:0.0474, weight:2.00, lr:0.0005
[11:51:33.086] iteration:15339  t-loss:0.1489, loss-lb:0.0925, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:51:33.280] iteration:15340  t-loss:0.1388, loss-lb:0.0783, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:51:33.473] iteration:15341  t-loss:0.1448, loss-lb:0.0825, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:51:33.666] iteration:15342  t-loss:0.1935, loss-lb:0.0801, loss-ulb:0.0567, weight:2.00, lr:0.0005
[11:51:33.859] iteration:15343  t-loss:0.1457, loss-lb:0.0894, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:51:34.051] iteration:15344  t-loss:0.1444, loss-lb:0.0882, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:51:34.243] iteration:15345  t-loss:0.1515, loss-lb:0.0890, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:51:34.436] iteration:15346  t-loss:0.1462, loss-lb:0.0828, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:51:34.629] iteration:15347  t-loss:0.1500, loss-lb:0.0933, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:51:34.822] iteration:15348  t-loss:0.1508, loss-lb:0.0788, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:51:35.014] iteration:15349  t-loss:0.1450, loss-lb:0.0823, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:51:35.208] iteration:15350  t-loss:0.1943, loss-lb:0.0750, loss-ulb:0.0597, weight:2.00, lr:0.0005
[11:51:35.402] iteration:15351  t-loss:0.1439, loss-lb:0.0784, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:51:35.595] iteration:15352  t-loss:0.1505, loss-lb:0.0834, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:51:35.788] iteration:15353  t-loss:0.1464, loss-lb:0.0847, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:51:35.979] iteration:15354  t-loss:0.1522, loss-lb:0.0818, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:51:36.172] iteration:15355  t-loss:0.1432, loss-lb:0.0847, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:51:36.366] iteration:15356  t-loss:0.1538, loss-lb:0.0876, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:51:36.559] iteration:15357  t-loss:0.1543, loss-lb:0.0862, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:51:36.753] iteration:15358  t-loss:0.2426, loss-lb:0.0835, loss-ulb:0.0796, weight:2.00, lr:0.0005
[11:51:36.945] iteration:15359  t-loss:0.1471, loss-lb:0.0813, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:51:37.137] iteration:15360  t-loss:0.1524, loss-lb:0.0875, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:51:37.331] iteration:15361  t-loss:0.1769, loss-lb:0.0875, loss-ulb:0.0447, weight:2.00, lr:0.0005
[11:51:37.524] iteration:15362  t-loss:0.2681, loss-lb:0.0762, loss-ulb:0.0959, weight:2.00, lr:0.0005
[11:51:37.717] iteration:15363  t-loss:0.1385, loss-lb:0.0797, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:51:37.909] iteration:15364  t-loss:0.1425, loss-lb:0.0842, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:51:38.101] iteration:15365  t-loss:0.1389, loss-lb:0.0753, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:51:38.292] iteration:15366  t-loss:0.1608, loss-lb:0.0850, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:51:38.484] iteration:15367  t-loss:0.1290, loss-lb:0.0775, loss-ulb:0.0258, weight:2.00, lr:0.0005
[11:51:38.677] iteration:15368  t-loss:0.1361, loss-lb:0.0814, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:51:38.870] iteration:15369  t-loss:0.1494, loss-lb:0.0819, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:51:39.064] iteration:15370  t-loss:0.1371, loss-lb:0.0814, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:51:39.256] iteration:15371  t-loss:0.1390, loss-lb:0.0782, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:51:39.449] iteration:15372  t-loss:0.1407, loss-lb:0.0817, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:51:39.642] iteration:15373  t-loss:0.1443, loss-lb:0.0813, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:51:39.834] iteration:15374  t-loss:0.1319, loss-lb:0.0779, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:51:40.027] iteration:15375  t-loss:0.1478, loss-lb:0.0784, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:51:40.219] iteration:15376  t-loss:0.1373, loss-lb:0.0785, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:51:40.411] iteration:15377  t-loss:0.1444, loss-lb:0.0820, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:51:40.603] iteration:15378  t-loss:0.1476, loss-lb:0.0859, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:51:40.795] iteration:15379  t-loss:0.1504, loss-lb:0.0840, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:51:40.986] iteration:15380  t-loss:0.2095, loss-lb:0.0862, loss-ulb:0.0617, weight:2.00, lr:0.0005
[11:51:41.176] iteration:15381  t-loss:0.1339, loss-lb:0.0786, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:51:41.366] iteration:15382  t-loss:0.1456, loss-lb:0.0802, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:51:41.557] iteration:15383  t-loss:0.1331, loss-lb:0.0758, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:51:41.747] iteration:15384  t-loss:0.1421, loss-lb:0.0861, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:51:41.938] iteration:15385  t-loss:0.1335, loss-lb:0.0816, loss-ulb:0.0260, weight:2.00, lr:0.0005
[11:51:42.128] iteration:15386  t-loss:0.1465, loss-lb:0.0779, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:51:53.475]  <<Test>> - Ep:156  - mean_dice/mean_h95 - S:90.03/1.36, Best-S:90.99, T:90.20/1.33, Best-T:90.48
[11:51:53.475]           - AvgLoss(lb/ulb/all):0.0846/0.0316/0.1440
[11:51:54.020] iteration:15387  t-loss:0.1554, loss-lb:0.0924, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:51:54.217] iteration:15388  t-loss:0.1524, loss-lb:0.0812, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:51:54.410] iteration:15389  t-loss:0.1323, loss-lb:0.0795, loss-ulb:0.0264, weight:2.00, lr:0.0005
[11:51:54.603] iteration:15390  t-loss:0.1393, loss-lb:0.0813, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:51:54.794] iteration:15391  t-loss:0.1455, loss-lb:0.0814, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:51:54.986] iteration:15392  t-loss:0.1373, loss-lb:0.0839, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:51:55.179] iteration:15393  t-loss:0.1378, loss-lb:0.0814, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:51:55.373] iteration:15394  t-loss:0.1473, loss-lb:0.0750, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:51:55.565] iteration:15395  t-loss:0.1592, loss-lb:0.0826, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:51:55.756] iteration:15396  t-loss:0.1647, loss-lb:0.0797, loss-ulb:0.0425, weight:2.00, lr:0.0005
[11:51:55.949] iteration:15397  t-loss:0.1404, loss-lb:0.0852, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:51:56.142] iteration:15398  t-loss:0.1405, loss-lb:0.0760, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:51:56.335] iteration:15399  t-loss:0.1382, loss-lb:0.0790, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:51:56.526] iteration:15400  t-loss:0.1398, loss-lb:0.0781, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:51:56.719] iteration:15401  t-loss:0.1794, loss-lb:0.0794, loss-ulb:0.0500, weight:2.00, lr:0.0005
[11:51:56.911] iteration:15402  t-loss:0.1402, loss-lb:0.0822, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:51:57.103] iteration:15403  t-loss:0.1428, loss-lb:0.0858, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:51:57.296] iteration:15404  t-loss:0.1406, loss-lb:0.0857, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:51:57.489] iteration:15405  t-loss:0.1438, loss-lb:0.0829, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:51:57.681] iteration:15406  t-loss:0.1430, loss-lb:0.0810, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:51:57.872] iteration:15407  t-loss:0.1510, loss-lb:0.0849, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:51:58.063] iteration:15408  t-loss:0.1369, loss-lb:0.0791, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:51:58.256] iteration:15409  t-loss:0.2323, loss-lb:0.0800, loss-ulb:0.0762, weight:2.00, lr:0.0005
[11:51:58.448] iteration:15410  t-loss:0.1325, loss-lb:0.0786, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:51:58.639] iteration:15411  t-loss:0.1565, loss-lb:0.0852, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:51:58.830] iteration:15412  t-loss:0.1438, loss-lb:0.0826, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:51:59.022] iteration:15413  t-loss:0.1300, loss-lb:0.0710, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:51:59.215] iteration:15414  t-loss:0.1579, loss-lb:0.0806, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:51:59.410] iteration:15415  t-loss:0.1557, loss-lb:0.0816, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:51:59.605] iteration:15416  t-loss:0.2229, loss-lb:0.0849, loss-ulb:0.0690, weight:2.00, lr:0.0005
[11:51:59.801] iteration:15417  t-loss:0.1689, loss-lb:0.0709, loss-ulb:0.0490, weight:2.00, lr:0.0005
[11:51:59.993] iteration:15418  t-loss:0.1492, loss-lb:0.0934, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:52:00.186] iteration:15419  t-loss:0.1405, loss-lb:0.0790, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:52:00.377] iteration:15420  t-loss:0.1340, loss-lb:0.0729, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:52:00.570] iteration:15421  t-loss:0.1352, loss-lb:0.0800, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:52:00.762] iteration:15422  t-loss:0.1532, loss-lb:0.0847, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:52:00.954] iteration:15423  t-loss:0.1733, loss-lb:0.0840, loss-ulb:0.0447, weight:2.00, lr:0.0005
[11:52:01.146] iteration:15424  t-loss:0.1438, loss-lb:0.0796, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:52:01.338] iteration:15425  t-loss:0.2974, loss-lb:0.0920, loss-ulb:0.1027, weight:2.00, lr:0.0005
[11:52:01.530] iteration:15426  t-loss:0.1519, loss-lb:0.0776, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:52:01.722] iteration:15427  t-loss:0.1351, loss-lb:0.0772, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:52:01.913] iteration:15428  t-loss:0.1381, loss-lb:0.0810, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:52:02.106] iteration:15429  t-loss:0.1413, loss-lb:0.0845, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:52:02.297] iteration:15430  t-loss:0.1319, loss-lb:0.0753, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:52:02.488] iteration:15431  t-loss:0.2025, loss-lb:0.0818, loss-ulb:0.0603, weight:2.00, lr:0.0005
[11:52:02.680] iteration:15432  t-loss:0.1457, loss-lb:0.0755, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:52:02.871] iteration:15433  t-loss:0.1478, loss-lb:0.0831, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:52:03.064] iteration:15434  t-loss:0.1420, loss-lb:0.0766, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:52:03.255] iteration:15435  t-loss:0.1558, loss-lb:0.0862, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:52:03.448] iteration:15436  t-loss:0.1274, loss-lb:0.0792, loss-ulb:0.0241, weight:2.00, lr:0.0005
[11:52:03.641] iteration:15437  t-loss:0.1481, loss-lb:0.0799, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:52:03.832] iteration:15438  t-loss:0.1537, loss-lb:0.0880, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:52:04.024] iteration:15439  t-loss:0.1449, loss-lb:0.0828, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:52:04.215] iteration:15440  t-loss:0.1385, loss-lb:0.0798, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:52:04.407] iteration:15441  t-loss:0.1465, loss-lb:0.0817, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:52:04.600] iteration:15442  t-loss:0.1320, loss-lb:0.0812, loss-ulb:0.0254, weight:2.00, lr:0.0005
[11:52:04.791] iteration:15443  t-loss:0.1659, loss-lb:0.0955, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:52:04.986] iteration:15444  t-loss:0.1887, loss-lb:0.0876, loss-ulb:0.0506, weight:2.00, lr:0.0005
[11:52:05.177] iteration:15445  t-loss:0.1475, loss-lb:0.0910, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:52:05.369] iteration:15446  t-loss:0.1433, loss-lb:0.0783, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:52:05.560] iteration:15447  t-loss:0.1419, loss-lb:0.0798, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:52:05.751] iteration:15448  t-loss:0.1603, loss-lb:0.0774, loss-ulb:0.0414, weight:2.00, lr:0.0005
[11:52:05.943] iteration:15449  t-loss:0.1351, loss-lb:0.0775, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:52:06.134] iteration:15450  t-loss:0.1434, loss-lb:0.0813, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:52:06.326] iteration:15451  t-loss:0.1460, loss-lb:0.0775, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:52:06.520] iteration:15452  t-loss:0.1472, loss-lb:0.0874, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:52:06.711] iteration:15453  t-loss:0.1384, loss-lb:0.0808, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:52:06.903] iteration:15454  t-loss:0.1397, loss-lb:0.0840, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:52:07.094] iteration:15455  t-loss:0.1642, loss-lb:0.0756, loss-ulb:0.0443, weight:2.00, lr:0.0005
[11:52:07.286] iteration:15456  t-loss:0.1299, loss-lb:0.0810, loss-ulb:0.0244, weight:2.00, lr:0.0005
[11:52:07.478] iteration:15457  t-loss:0.1534, loss-lb:0.0789, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:52:07.668] iteration:15458  t-loss:0.1517, loss-lb:0.0871, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:52:07.860] iteration:15459  t-loss:0.1615, loss-lb:0.0793, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:52:08.052] iteration:15460  t-loss:0.1412, loss-lb:0.0811, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:52:08.243] iteration:15461  t-loss:0.1458, loss-lb:0.0838, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:52:08.435] iteration:15462  t-loss:0.1623, loss-lb:0.0840, loss-ulb:0.0392, weight:2.00, lr:0.0005
[11:52:08.626] iteration:15463  t-loss:0.1664, loss-lb:0.0871, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:52:08.818] iteration:15464  t-loss:0.1505, loss-lb:0.0894, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:52:09.009] iteration:15465  t-loss:0.1541, loss-lb:0.0871, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:52:09.200] iteration:15466  t-loss:0.1496, loss-lb:0.0790, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:52:09.391] iteration:15467  t-loss:0.1328, loss-lb:0.0772, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:52:09.582] iteration:15468  t-loss:0.1600, loss-lb:0.0846, loss-ulb:0.0377, weight:2.00, lr:0.0005
[11:52:09.774] iteration:15469  t-loss:0.1648, loss-lb:0.0752, loss-ulb:0.0448, weight:2.00, lr:0.0005
[11:52:09.965] iteration:15470  t-loss:0.1836, loss-lb:0.0790, loss-ulb:0.0523, weight:2.00, lr:0.0005
[11:52:10.159] iteration:15471  t-loss:0.1601, loss-lb:0.0932, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:52:10.354] iteration:15472  t-loss:0.1386, loss-lb:0.0844, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:52:10.548] iteration:15473  t-loss:0.1446, loss-lb:0.0846, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:52:10.743] iteration:15474  t-loss:0.1384, loss-lb:0.0785, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:52:10.934] iteration:15475  t-loss:0.1414, loss-lb:0.0835, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:52:11.127] iteration:15476  t-loss:0.1571, loss-lb:0.0779, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:52:11.319] iteration:15477  t-loss:0.2081, loss-lb:0.0839, loss-ulb:0.0621, weight:2.00, lr:0.0005
[11:52:11.512] iteration:15478  t-loss:0.1613, loss-lb:0.0934, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:52:11.702] iteration:15479  t-loss:0.1545, loss-lb:0.0838, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:52:11.892] iteration:15480  t-loss:0.1600, loss-lb:0.0872, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:52:12.084] iteration:15481  t-loss:0.1662, loss-lb:0.0808, loss-ulb:0.0427, weight:2.00, lr:0.0005
[11:52:12.274] iteration:15482  t-loss:0.1462, loss-lb:0.0893, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:52:12.465] iteration:15483  t-loss:0.1476, loss-lb:0.0786, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:52:12.654] iteration:15484  t-loss:0.1455, loss-lb:0.0821, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:52:13.246] iteration:15485  t-loss:0.1646, loss-lb:0.0818, loss-ulb:0.0414, weight:2.00, lr:0.0005
[11:52:13.440] iteration:15486  t-loss:0.1525, loss-lb:0.0873, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:52:13.632] iteration:15487  t-loss:0.1409, loss-lb:0.0834, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:52:13.825] iteration:15488  t-loss:0.1658, loss-lb:0.0901, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:52:14.017] iteration:15489  t-loss:0.1455, loss-lb:0.0861, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:52:14.208] iteration:15490  t-loss:0.1458, loss-lb:0.0869, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:52:14.400] iteration:15491  t-loss:0.1472, loss-lb:0.0818, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:52:14.592] iteration:15492  t-loss:0.1439, loss-lb:0.0824, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:52:14.782] iteration:15493  t-loss:0.1806, loss-lb:0.0739, loss-ulb:0.0533, weight:2.00, lr:0.0005
[11:52:14.975] iteration:15494  t-loss:0.1439, loss-lb:0.0786, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:52:15.167] iteration:15495  t-loss:0.1414, loss-lb:0.0836, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:52:15.359] iteration:15496  t-loss:0.2194, loss-lb:0.0892, loss-ulb:0.0651, weight:2.00, lr:0.0005
[11:52:15.552] iteration:15497  t-loss:0.1493, loss-lb:0.0826, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:52:15.744] iteration:15498  t-loss:0.1778, loss-lb:0.0884, loss-ulb:0.0447, weight:2.00, lr:0.0005
[11:52:15.936] iteration:15499  t-loss:0.1480, loss-lb:0.0790, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:52:16.128] iteration:15500  t-loss:0.1642, loss-lb:0.0937, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:52:16.321] iteration:15501  t-loss:0.2228, loss-lb:0.1014, loss-ulb:0.0607, weight:2.00, lr:0.0005
[11:52:16.512] iteration:15502  t-loss:0.1574, loss-lb:0.0905, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:52:16.704] iteration:15503  t-loss:0.2136, loss-lb:0.0908, loss-ulb:0.0614, weight:2.00, lr:0.0005
[11:52:16.896] iteration:15504  t-loss:0.1527, loss-lb:0.0860, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:52:17.087] iteration:15505  t-loss:0.1499, loss-lb:0.0836, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:52:17.280] iteration:15506  t-loss:0.1722, loss-lb:0.1019, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:52:17.472] iteration:15507  t-loss:0.1805, loss-lb:0.0957, loss-ulb:0.0424, weight:2.00, lr:0.0005
[11:52:17.663] iteration:15508  t-loss:0.1475, loss-lb:0.0823, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:52:17.856] iteration:15509  t-loss:0.1667, loss-lb:0.0945, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:52:18.048] iteration:15510  t-loss:0.1688, loss-lb:0.0977, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:52:18.239] iteration:15511  t-loss:0.1444, loss-lb:0.0861, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:52:18.443] iteration:15512  t-loss:0.1538, loss-lb:0.0896, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:52:18.640] iteration:15513  t-loss:0.1379, loss-lb:0.0818, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:52:18.836] iteration:15514  t-loss:0.1626, loss-lb:0.0887, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:52:19.027] iteration:15515  t-loss:0.1475, loss-lb:0.0842, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:52:19.219] iteration:15516  t-loss:0.2103, loss-lb:0.0847, loss-ulb:0.0628, weight:2.00, lr:0.0005
[11:52:19.411] iteration:15517  t-loss:0.2811, loss-lb:0.0792, loss-ulb:0.1009, weight:2.00, lr:0.0005
[11:52:19.603] iteration:15518  t-loss:0.1522, loss-lb:0.0844, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:52:19.795] iteration:15519  t-loss:0.1959, loss-lb:0.0940, loss-ulb:0.0509, weight:2.00, lr:0.0005
[11:52:19.987] iteration:15520  t-loss:0.1731, loss-lb:0.0967, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:52:20.177] iteration:15521  t-loss:0.1688, loss-lb:0.0845, loss-ulb:0.0422, weight:2.00, lr:0.0005
[11:52:20.368] iteration:15522  t-loss:0.1599, loss-lb:0.0850, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:52:20.560] iteration:15523  t-loss:0.1404, loss-lb:0.0833, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:52:20.753] iteration:15524  t-loss:0.1367, loss-lb:0.0819, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:52:20.945] iteration:15525  t-loss:0.1623, loss-lb:0.0883, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:52:21.138] iteration:15526  t-loss:0.1537, loss-lb:0.0938, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:52:21.334] iteration:15527  t-loss:0.1510, loss-lb:0.0950, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:52:21.527] iteration:15528  t-loss:0.1710, loss-lb:0.0824, loss-ulb:0.0443, weight:2.00, lr:0.0005
[11:52:21.724] iteration:15529  t-loss:0.2390, loss-lb:0.0751, loss-ulb:0.0819, weight:2.00, lr:0.0005
[11:52:21.916] iteration:15530  t-loss:0.1431, loss-lb:0.0844, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:52:22.108] iteration:15531  t-loss:0.1481, loss-lb:0.0854, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:52:22.302] iteration:15532  t-loss:0.1377, loss-lb:0.0782, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:52:22.494] iteration:15533  t-loss:0.1666, loss-lb:0.0931, loss-ulb:0.0367, weight:2.00, lr:0.0005
[11:52:22.689] iteration:15534  t-loss:0.1518, loss-lb:0.0887, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:52:22.881] iteration:15535  t-loss:0.1898, loss-lb:0.0848, loss-ulb:0.0525, weight:2.00, lr:0.0005
[11:52:23.072] iteration:15536  t-loss:0.1561, loss-lb:0.0991, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:52:23.267] iteration:15537  t-loss:0.1408, loss-lb:0.0812, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:52:23.459] iteration:15538  t-loss:0.1288, loss-lb:0.0764, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:52:23.652] iteration:15539  t-loss:0.1392, loss-lb:0.0829, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:52:23.845] iteration:15540  t-loss:0.1542, loss-lb:0.0911, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:52:24.037] iteration:15541  t-loss:0.1518, loss-lb:0.0867, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:52:24.231] iteration:15542  t-loss:0.1972, loss-lb:0.0932, loss-ulb:0.0520, weight:2.00, lr:0.0005
[11:52:24.422] iteration:15543  t-loss:0.1683, loss-lb:0.0800, loss-ulb:0.0442, weight:2.00, lr:0.0005
[11:52:24.615] iteration:15544  t-loss:0.1368, loss-lb:0.0794, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:52:24.807] iteration:15545  t-loss:0.1389, loss-lb:0.0792, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:52:24.998] iteration:15546  t-loss:0.1530, loss-lb:0.0734, loss-ulb:0.0398, weight:2.00, lr:0.0005
[11:52:25.191] iteration:15547  t-loss:0.1809, loss-lb:0.0827, loss-ulb:0.0491, weight:2.00, lr:0.0005
[11:52:25.383] iteration:15548  t-loss:0.1375, loss-lb:0.0830, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:52:25.575] iteration:15549  t-loss:0.1479, loss-lb:0.0884, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:52:25.767] iteration:15550  t-loss:0.1461, loss-lb:0.0895, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:52:25.960] iteration:15551  t-loss:0.1685, loss-lb:0.0931, loss-ulb:0.0377, weight:2.00, lr:0.0005
[11:52:26.152] iteration:15552  t-loss:0.3113, loss-lb:0.0880, loss-ulb:0.1117, weight:2.00, lr:0.0005
[11:52:26.343] iteration:15553  t-loss:0.1372, loss-lb:0.0810, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:52:26.536] iteration:15554  t-loss:0.1505, loss-lb:0.0882, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:52:26.729] iteration:15555  t-loss:0.1526, loss-lb:0.0891, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:52:26.922] iteration:15556  t-loss:0.2079, loss-lb:0.0998, loss-ulb:0.0540, weight:2.00, lr:0.0005
[11:52:27.114] iteration:15557  t-loss:0.1500, loss-lb:0.0771, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:52:27.305] iteration:15558  t-loss:0.1480, loss-lb:0.0794, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:52:27.497] iteration:15559  t-loss:0.1385, loss-lb:0.0830, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:52:27.690] iteration:15560  t-loss:0.1910, loss-lb:0.0835, loss-ulb:0.0537, weight:2.00, lr:0.0005
[11:52:27.882] iteration:15561  t-loss:0.1652, loss-lb:0.1082, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:52:28.075] iteration:15562  t-loss:0.2627, loss-lb:0.0826, loss-ulb:0.0901, weight:2.00, lr:0.0005
[11:52:28.267] iteration:15563  t-loss:0.1406, loss-lb:0.0758, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:52:28.459] iteration:15564  t-loss:0.1958, loss-lb:0.0808, loss-ulb:0.0575, weight:2.00, lr:0.0005
[11:52:28.652] iteration:15565  t-loss:0.1626, loss-lb:0.0768, loss-ulb:0.0429, weight:2.00, lr:0.0005
[11:52:28.843] iteration:15566  t-loss:0.1507, loss-lb:0.0937, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:52:29.036] iteration:15567  t-loss:0.1509, loss-lb:0.0827, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:52:29.227] iteration:15568  t-loss:0.1554, loss-lb:0.0848, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:52:29.418] iteration:15569  t-loss:0.1569, loss-lb:0.0820, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:52:29.609] iteration:15570  t-loss:0.1640, loss-lb:0.0796, loss-ulb:0.0422, weight:2.00, lr:0.0005
[11:52:29.801] iteration:15571  t-loss:0.1527, loss-lb:0.0805, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:52:29.993] iteration:15572  t-loss:0.1435, loss-lb:0.0761, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:52:30.184] iteration:15573  t-loss:0.1629, loss-lb:0.0905, loss-ulb:0.0362, weight:2.00, lr:0.0005
[11:52:30.376] iteration:15574  t-loss:0.1675, loss-lb:0.0910, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:52:30.566] iteration:15575  t-loss:0.1434, loss-lb:0.0798, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:52:30.756] iteration:15576  t-loss:0.1812, loss-lb:0.0863, loss-ulb:0.0474, weight:2.00, lr:0.0005
[11:52:30.946] iteration:15577  t-loss:0.1612, loss-lb:0.0939, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:52:31.136] iteration:15578  t-loss:0.1389, loss-lb:0.0759, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:52:31.325] iteration:15579  t-loss:0.1349, loss-lb:0.0753, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:52:31.515] iteration:15580  t-loss:0.1531, loss-lb:0.0872, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:52:31.706] iteration:15581  t-loss:0.1898, loss-lb:0.0890, loss-ulb:0.0504, weight:2.00, lr:0.0005
[11:52:31.897] iteration:15582  t-loss:0.1472, loss-lb:0.0893, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:52:44.239]  <<Test>> - Ep:158  - mean_dice/mean_h95 - S:90.37/1.28, Best-S:90.99, T:90.11/1.37, Best-T:90.48
[11:52:44.239]           - AvgLoss(lb/ulb/all):0.0859/0.0370/0.1576
[11:52:44.765] iteration:15583  t-loss:0.2746, loss-lb:0.0930, loss-ulb:0.0908, weight:2.00, lr:0.0005
[11:52:44.962] iteration:15584  t-loss:0.1447, loss-lb:0.0795, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:52:45.153] iteration:15585  t-loss:0.1484, loss-lb:0.0795, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:52:45.345] iteration:15586  t-loss:0.1483, loss-lb:0.0912, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:52:45.538] iteration:15587  t-loss:0.1516, loss-lb:0.0809, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:52:45.730] iteration:15588  t-loss:0.1358, loss-lb:0.0798, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:52:45.923] iteration:15589  t-loss:0.1840, loss-lb:0.0833, loss-ulb:0.0503, weight:2.00, lr:0.0005
[11:52:46.114] iteration:15590  t-loss:0.1445, loss-lb:0.0797, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:52:46.307] iteration:15591  t-loss:0.1460, loss-lb:0.0858, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:52:46.499] iteration:15592  t-loss:0.1549, loss-lb:0.0919, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:52:46.691] iteration:15593  t-loss:0.1416, loss-lb:0.0823, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:52:46.883] iteration:15594  t-loss:0.1607, loss-lb:0.0887, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:52:47.075] iteration:15595  t-loss:0.1428, loss-lb:0.0812, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:52:47.266] iteration:15596  t-loss:0.1463, loss-lb:0.0816, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:52:47.458] iteration:15597  t-loss:0.1457, loss-lb:0.0826, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:52:47.651] iteration:15598  t-loss:0.1438, loss-lb:0.0883, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:52:47.842] iteration:15599  t-loss:0.1381, loss-lb:0.0763, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:52:48.034] iteration:15600  t-loss:0.1359, loss-lb:0.0799, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:52:48.226] iteration:15601  t-loss:0.1683, loss-lb:0.0762, loss-ulb:0.0460, weight:2.00, lr:0.0005
[11:52:48.418] iteration:15602  t-loss:0.1241, loss-lb:0.0743, loss-ulb:0.0249, weight:2.00, lr:0.0005
[11:52:48.610] iteration:15603  t-loss:0.1415, loss-lb:0.0833, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:52:48.802] iteration:15604  t-loss:0.2160, loss-lb:0.0986, loss-ulb:0.0587, weight:2.00, lr:0.0005
[11:52:48.993] iteration:15605  t-loss:0.1372, loss-lb:0.0867, loss-ulb:0.0252, weight:2.00, lr:0.0005
[11:52:49.185] iteration:15606  t-loss:0.1399, loss-lb:0.0766, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:52:49.376] iteration:15607  t-loss:0.1387, loss-lb:0.0851, loss-ulb:0.0268, weight:2.00, lr:0.0005
[11:52:49.569] iteration:15608  t-loss:0.1739, loss-lb:0.0848, loss-ulb:0.0445, weight:2.00, lr:0.0005
[11:52:49.760] iteration:15609  t-loss:0.1512, loss-lb:0.0852, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:52:49.951] iteration:15610  t-loss:0.1590, loss-lb:0.0821, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:52:50.144] iteration:15611  t-loss:0.1513, loss-lb:0.0907, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:52:50.336] iteration:15612  t-loss:0.2148, loss-lb:0.0857, loss-ulb:0.0646, weight:2.00, lr:0.0005
[11:52:50.528] iteration:15613  t-loss:0.1503, loss-lb:0.0789, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:52:50.721] iteration:15614  t-loss:0.1447, loss-lb:0.0795, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:52:50.914] iteration:15615  t-loss:0.1671, loss-lb:0.0741, loss-ulb:0.0465, weight:2.00, lr:0.0005
[11:52:51.110] iteration:15616  t-loss:0.1442, loss-lb:0.0832, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:52:51.313] iteration:15617  t-loss:0.1483, loss-lb:0.0828, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:52:51.510] iteration:15618  t-loss:0.1422, loss-lb:0.0787, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:52:51.703] iteration:15619  t-loss:0.2137, loss-lb:0.0871, loss-ulb:0.0633, weight:2.00, lr:0.0005
[11:52:51.895] iteration:15620  t-loss:0.1438, loss-lb:0.0812, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:52:52.089] iteration:15621  t-loss:0.1448, loss-lb:0.0902, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:52:52.294] iteration:15622  t-loss:0.1415, loss-lb:0.0773, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:52:52.491] iteration:15623  t-loss:0.1526, loss-lb:0.0819, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:52:52.684] iteration:15624  t-loss:0.1634, loss-lb:0.0929, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:52:52.877] iteration:15625  t-loss:0.1345, loss-lb:0.0863, loss-ulb:0.0241, weight:2.00, lr:0.0005
[11:52:53.069] iteration:15626  t-loss:0.1418, loss-lb:0.0734, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:52:53.262] iteration:15627  t-loss:0.1829, loss-lb:0.0838, loss-ulb:0.0496, weight:2.00, lr:0.0005
[11:52:53.455] iteration:15628  t-loss:0.1490, loss-lb:0.0828, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:52:53.647] iteration:15629  t-loss:0.1537, loss-lb:0.0808, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:52:53.840] iteration:15630  t-loss:0.2163, loss-lb:0.0773, loss-ulb:0.0695, weight:2.00, lr:0.0005
[11:52:54.033] iteration:15631  t-loss:0.1488, loss-lb:0.0828, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:52:54.226] iteration:15632  t-loss:0.1490, loss-lb:0.0854, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:52:54.420] iteration:15633  t-loss:0.2275, loss-lb:0.0827, loss-ulb:0.0724, weight:2.00, lr:0.0005
[11:52:54.612] iteration:15634  t-loss:0.1730, loss-lb:0.0835, loss-ulb:0.0447, weight:2.00, lr:0.0005
[11:52:54.804] iteration:15635  t-loss:0.1535, loss-lb:0.0857, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:52:54.996] iteration:15636  t-loss:0.1506, loss-lb:0.0695, loss-ulb:0.0405, weight:2.00, lr:0.0005
[11:52:55.189] iteration:15637  t-loss:0.1674, loss-lb:0.0893, loss-ulb:0.0390, weight:2.00, lr:0.0005
[11:52:55.380] iteration:15638  t-loss:0.1703, loss-lb:0.0964, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:52:55.574] iteration:15639  t-loss:0.1461, loss-lb:0.0893, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:52:55.766] iteration:15640  t-loss:0.1513, loss-lb:0.0830, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:52:55.959] iteration:15641  t-loss:0.1318, loss-lb:0.0801, loss-ulb:0.0259, weight:2.00, lr:0.0005
[11:52:56.153] iteration:15642  t-loss:0.1489, loss-lb:0.0872, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:52:56.345] iteration:15643  t-loss:0.1443, loss-lb:0.0770, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:52:56.539] iteration:15644  t-loss:0.1773, loss-lb:0.0862, loss-ulb:0.0456, weight:2.00, lr:0.0005
[11:52:56.732] iteration:15645  t-loss:0.1349, loss-lb:0.0811, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:52:56.924] iteration:15646  t-loss:0.1380, loss-lb:0.0835, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:52:57.117] iteration:15647  t-loss:0.1564, loss-lb:0.0777, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:52:57.310] iteration:15648  t-loss:0.2062, loss-lb:0.0877, loss-ulb:0.0592, weight:2.00, lr:0.0005
[11:52:57.502] iteration:15649  t-loss:0.1450, loss-lb:0.0775, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:52:57.693] iteration:15650  t-loss:0.1583, loss-lb:0.0865, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:52:57.886] iteration:15651  t-loss:0.1401, loss-lb:0.0781, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:52:58.078] iteration:15652  t-loss:0.1438, loss-lb:0.0761, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:52:58.270] iteration:15653  t-loss:0.1572, loss-lb:0.0980, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:52:58.463] iteration:15654  t-loss:0.1647, loss-lb:0.0839, loss-ulb:0.0404, weight:2.00, lr:0.0005
[11:52:58.656] iteration:15655  t-loss:0.1591, loss-lb:0.0799, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:52:58.848] iteration:15656  t-loss:0.1369, loss-lb:0.0766, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:52:59.040] iteration:15657  t-loss:0.1495, loss-lb:0.0794, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:52:59.232] iteration:15658  t-loss:0.1486, loss-lb:0.0887, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:52:59.424] iteration:15659  t-loss:0.2028, loss-lb:0.0774, loss-ulb:0.0627, weight:2.00, lr:0.0005
[11:52:59.616] iteration:15660  t-loss:0.1440, loss-lb:0.0834, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:52:59.808] iteration:15661  t-loss:0.1446, loss-lb:0.0775, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:53:00.001] iteration:15662  t-loss:0.1488, loss-lb:0.0892, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:53:00.193] iteration:15663  t-loss:0.1327, loss-lb:0.0759, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:53:00.385] iteration:15664  t-loss:0.1275, loss-lb:0.0775, loss-ulb:0.0250, weight:2.00, lr:0.0005
[11:53:00.579] iteration:15665  t-loss:0.1335, loss-lb:0.0808, loss-ulb:0.0263, weight:2.00, lr:0.0005
[11:53:00.771] iteration:15666  t-loss:0.1446, loss-lb:0.0736, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:53:00.963] iteration:15667  t-loss:0.1478, loss-lb:0.0863, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:53:01.155] iteration:15668  t-loss:0.1365, loss-lb:0.0776, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:53:01.348] iteration:15669  t-loss:0.1484, loss-lb:0.0778, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:53:01.540] iteration:15670  t-loss:0.1578, loss-lb:0.0710, loss-ulb:0.0434, weight:2.00, lr:0.0005
[11:53:01.733] iteration:15671  t-loss:0.1450, loss-lb:0.0836, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:53:01.925] iteration:15672  t-loss:0.1503, loss-lb:0.0796, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:53:02.117] iteration:15673  t-loss:0.1498, loss-lb:0.0829, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:53:02.309] iteration:15674  t-loss:0.1873, loss-lb:0.0879, loss-ulb:0.0497, weight:2.00, lr:0.0005
[11:53:02.500] iteration:15675  t-loss:0.1422, loss-lb:0.0811, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:53:02.692] iteration:15676  t-loss:0.1448, loss-lb:0.0748, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:53:02.884] iteration:15677  t-loss:0.1469, loss-lb:0.0842, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:53:03.074] iteration:15678  t-loss:0.1540, loss-lb:0.0924, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:53:03.265] iteration:15679  t-loss:0.1643, loss-lb:0.0815, loss-ulb:0.0414, weight:2.00, lr:0.0005
[11:53:03.457] iteration:15680  t-loss:0.1252, loss-lb:0.0729, loss-ulb:0.0261, weight:2.00, lr:0.0005
[11:53:04.033] iteration:15681  t-loss:0.1507, loss-lb:0.0777, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:53:04.229] iteration:15682  t-loss:0.1708, loss-lb:0.0790, loss-ulb:0.0459, weight:2.00, lr:0.0005
[11:53:04.421] iteration:15683  t-loss:0.1521, loss-lb:0.0841, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:53:04.614] iteration:15684  t-loss:0.1642, loss-lb:0.0886, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:53:04.807] iteration:15685  t-loss:0.2359, loss-lb:0.0839, loss-ulb:0.0760, weight:2.00, lr:0.0005
[11:53:05.000] iteration:15686  t-loss:0.1415, loss-lb:0.0826, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:53:05.193] iteration:15687  t-loss:0.2185, loss-lb:0.0871, loss-ulb:0.0657, weight:2.00, lr:0.0005
[11:53:05.385] iteration:15688  t-loss:0.2027, loss-lb:0.0795, loss-ulb:0.0616, weight:2.00, lr:0.0005
[11:53:05.578] iteration:15689  t-loss:0.1390, loss-lb:0.0765, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:53:05.771] iteration:15690  t-loss:0.1486, loss-lb:0.0842, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:53:05.963] iteration:15691  t-loss:0.1397, loss-lb:0.0791, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:53:06.155] iteration:15692  t-loss:0.1560, loss-lb:0.0927, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:53:06.349] iteration:15693  t-loss:0.2006, loss-lb:0.0822, loss-ulb:0.0592, weight:2.00, lr:0.0005
[11:53:06.541] iteration:15694  t-loss:0.1339, loss-lb:0.0811, loss-ulb:0.0264, weight:2.00, lr:0.0005
[11:53:06.733] iteration:15695  t-loss:0.1265, loss-lb:0.0703, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:53:06.925] iteration:15696  t-loss:0.1580, loss-lb:0.0799, loss-ulb:0.0391, weight:2.00, lr:0.0005
[11:53:07.118] iteration:15697  t-loss:0.1378, loss-lb:0.0838, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:53:07.312] iteration:15698  t-loss:0.1839, loss-lb:0.0914, loss-ulb:0.0462, weight:2.00, lr:0.0005
[11:53:07.504] iteration:15699  t-loss:0.1410, loss-lb:0.0855, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:53:07.697] iteration:15700  t-loss:0.1530, loss-lb:0.0804, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:53:07.890] iteration:15701  t-loss:0.1520, loss-lb:0.0859, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:53:08.081] iteration:15702  t-loss:0.1648, loss-lb:0.0967, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:53:08.274] iteration:15703  t-loss:0.1508, loss-lb:0.0860, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:53:08.468] iteration:15704  t-loss:0.1427, loss-lb:0.0840, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:53:08.661] iteration:15705  t-loss:0.1668, loss-lb:0.0879, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:53:08.854] iteration:15706  t-loss:0.1410, loss-lb:0.0869, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:53:09.046] iteration:15707  t-loss:0.1327, loss-lb:0.0751, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:53:09.240] iteration:15708  t-loss:0.1357, loss-lb:0.0768, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:53:09.434] iteration:15709  t-loss:0.1755, loss-lb:0.0794, loss-ulb:0.0480, weight:2.00, lr:0.0005
[11:53:09.626] iteration:15710  t-loss:0.1527, loss-lb:0.0856, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:53:09.818] iteration:15711  t-loss:0.1302, loss-lb:0.0755, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:53:10.011] iteration:15712  t-loss:0.1477, loss-lb:0.0802, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:53:10.204] iteration:15713  t-loss:0.1537, loss-lb:0.0735, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:53:10.396] iteration:15714  t-loss:0.1421, loss-lb:0.0851, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:53:10.589] iteration:15715  t-loss:0.1304, loss-lb:0.0785, loss-ulb:0.0259, weight:2.00, lr:0.0005
[11:53:10.783] iteration:15716  t-loss:0.1490, loss-lb:0.0864, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:53:10.976] iteration:15717  t-loss:0.1416, loss-lb:0.0827, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:53:11.169] iteration:15718  t-loss:0.1478, loss-lb:0.0824, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:53:11.362] iteration:15719  t-loss:0.1435, loss-lb:0.0866, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:53:11.555] iteration:15720  t-loss:0.1368, loss-lb:0.0792, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:53:11.748] iteration:15721  t-loss:0.1832, loss-lb:0.0799, loss-ulb:0.0517, weight:2.00, lr:0.0005
[11:53:11.941] iteration:15722  t-loss:0.1479, loss-lb:0.0860, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:53:12.134] iteration:15723  t-loss:0.1590, loss-lb:0.0804, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:53:12.326] iteration:15724  t-loss:0.1299, loss-lb:0.0701, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:53:12.519] iteration:15725  t-loss:0.1381, loss-lb:0.0758, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:53:12.713] iteration:15726  t-loss:0.1930, loss-lb:0.0873, loss-ulb:0.0528, weight:2.00, lr:0.0005
[11:53:12.906] iteration:15727  t-loss:0.1450, loss-lb:0.0711, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:53:13.100] iteration:15728  t-loss:0.1373, loss-lb:0.0779, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:53:13.292] iteration:15729  t-loss:0.1394, loss-lb:0.0809, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:53:13.485] iteration:15730  t-loss:0.1675, loss-lb:0.0778, loss-ulb:0.0448, weight:2.00, lr:0.0005
[11:53:13.677] iteration:15731  t-loss:0.1403, loss-lb:0.0796, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:53:13.869] iteration:15732  t-loss:0.1537, loss-lb:0.0840, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:53:14.062] iteration:15733  t-loss:0.1428, loss-lb:0.0855, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:53:14.256] iteration:15734  t-loss:0.1520, loss-lb:0.0823, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:53:14.448] iteration:15735  t-loss:0.1410, loss-lb:0.0821, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:53:14.640] iteration:15736  t-loss:0.1955, loss-lb:0.0803, loss-ulb:0.0576, weight:2.00, lr:0.0005
[11:53:14.833] iteration:15737  t-loss:0.1699, loss-lb:0.0906, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:53:15.025] iteration:15738  t-loss:0.1442, loss-lb:0.0784, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:53:15.217] iteration:15739  t-loss:0.1449, loss-lb:0.0762, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:53:15.410] iteration:15740  t-loss:0.1620, loss-lb:0.0800, loss-ulb:0.0410, weight:2.00, lr:0.0005
[11:53:15.603] iteration:15741  t-loss:0.1457, loss-lb:0.0755, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:53:15.798] iteration:15742  t-loss:0.1432, loss-lb:0.0751, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:53:15.991] iteration:15743  t-loss:0.1582, loss-lb:0.0751, loss-ulb:0.0416, weight:2.00, lr:0.0005
[11:53:16.184] iteration:15744  t-loss:0.1387, loss-lb:0.0835, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:53:16.377] iteration:15745  t-loss:0.1369, loss-lb:0.0807, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:53:16.570] iteration:15746  t-loss:0.1404, loss-lb:0.0790, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:53:16.761] iteration:15747  t-loss:0.1490, loss-lb:0.0816, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:53:16.954] iteration:15748  t-loss:0.1461, loss-lb:0.0894, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:53:17.147] iteration:15749  t-loss:0.1468, loss-lb:0.0890, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:53:17.340] iteration:15750  t-loss:0.1327, loss-lb:0.0744, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:53:17.533] iteration:15751  t-loss:0.1580, loss-lb:0.0916, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:53:17.724] iteration:15752  t-loss:0.1410, loss-lb:0.0850, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:53:17.917] iteration:15753  t-loss:0.1406, loss-lb:0.0807, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:53:18.109] iteration:15754  t-loss:0.1584, loss-lb:0.0822, loss-ulb:0.0381, weight:2.00, lr:0.0005
[11:53:18.301] iteration:15755  t-loss:0.1520, loss-lb:0.0831, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:53:18.494] iteration:15756  t-loss:0.1467, loss-lb:0.0802, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:53:18.686] iteration:15757  t-loss:0.1837, loss-lb:0.1087, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:53:18.879] iteration:15758  t-loss:0.1547, loss-lb:0.0839, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:53:19.071] iteration:15759  t-loss:0.1374, loss-lb:0.0748, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:53:19.264] iteration:15760  t-loss:0.1444, loss-lb:0.0803, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:53:19.457] iteration:15761  t-loss:0.1442, loss-lb:0.0773, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:53:19.651] iteration:15762  t-loss:0.2107, loss-lb:0.0900, loss-ulb:0.0604, weight:2.00, lr:0.0005
[11:53:19.843] iteration:15763  t-loss:0.1427, loss-lb:0.0799, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:53:20.037] iteration:15764  t-loss:0.1847, loss-lb:0.0798, loss-ulb:0.0524, weight:2.00, lr:0.0005
[11:53:20.230] iteration:15765  t-loss:0.1429, loss-lb:0.0774, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:53:20.423] iteration:15766  t-loss:0.1541, loss-lb:0.0862, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:53:20.617] iteration:15767  t-loss:0.1550, loss-lb:0.0804, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:53:20.809] iteration:15768  t-loss:0.1417, loss-lb:0.0814, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:53:21.003] iteration:15769  t-loss:0.1523, loss-lb:0.0902, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:53:21.196] iteration:15770  t-loss:0.1562, loss-lb:0.0827, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:53:21.387] iteration:15771  t-loss:0.1424, loss-lb:0.0823, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:53:21.577] iteration:15772  t-loss:0.2052, loss-lb:0.0898, loss-ulb:0.0577, weight:2.00, lr:0.0005
[11:53:21.769] iteration:15773  t-loss:0.1460, loss-lb:0.0800, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:53:21.963] iteration:15774  t-loss:0.1340, loss-lb:0.0741, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:53:22.156] iteration:15775  t-loss:0.1620, loss-lb:0.0769, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:53:22.352] iteration:15776  t-loss:0.1522, loss-lb:0.0886, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:53:22.544] iteration:15777  t-loss:0.1520, loss-lb:0.0784, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:53:22.736] iteration:15778  t-loss:0.1424, loss-lb:0.0762, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:53:34.188]  <<Test>> - Ep:160  - mean_dice/mean_h95 - S:90.18/1.35, Best-S:90.99, T:90.08/1.38, Best-T:90.48
[11:53:34.189]           - AvgLoss(lb/ulb/all):0.0820/0.0369/0.1551
[11:53:34.723] iteration:15779  t-loss:0.1546, loss-lb:0.0908, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:53:34.918] iteration:15780  t-loss:0.1753, loss-lb:0.0908, loss-ulb:0.0422, weight:2.00, lr:0.0005
[11:53:35.110] iteration:15781  t-loss:0.1724, loss-lb:0.0840, loss-ulb:0.0442, weight:2.00, lr:0.0005
[11:53:35.302] iteration:15782  t-loss:0.1413, loss-lb:0.0778, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:53:35.494] iteration:15783  t-loss:0.1815, loss-lb:0.0907, loss-ulb:0.0454, weight:2.00, lr:0.0005
[11:53:35.686] iteration:15784  t-loss:0.1371, loss-lb:0.0848, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:53:35.878] iteration:15785  t-loss:0.1429, loss-lb:0.0853, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:53:36.070] iteration:15786  t-loss:0.1778, loss-lb:0.0776, loss-ulb:0.0501, weight:2.00, lr:0.0005
[11:53:36.261] iteration:15787  t-loss:0.1366, loss-lb:0.0796, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:53:36.453] iteration:15788  t-loss:0.1823, loss-lb:0.0824, loss-ulb:0.0500, weight:2.00, lr:0.0005
[11:53:36.644] iteration:15789  t-loss:0.1357, loss-lb:0.0777, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:53:36.837] iteration:15790  t-loss:0.1612, loss-lb:0.0913, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:53:37.029] iteration:15791  t-loss:0.1641, loss-lb:0.0876, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:53:37.220] iteration:15792  t-loss:0.1730, loss-lb:0.0922, loss-ulb:0.0404, weight:2.00, lr:0.0005
[11:53:37.412] iteration:15793  t-loss:0.2265, loss-lb:0.0793, loss-ulb:0.0736, weight:2.00, lr:0.0005
[11:53:37.604] iteration:15794  t-loss:0.1631, loss-lb:0.0828, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:53:37.795] iteration:15795  t-loss:0.1601, loss-lb:0.0852, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:53:37.987] iteration:15796  t-loss:0.1566, loss-lb:0.0936, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:53:38.178] iteration:15797  t-loss:0.1581, loss-lb:0.0868, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:53:38.370] iteration:15798  t-loss:0.1582, loss-lb:0.0849, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:53:38.560] iteration:15799  t-loss:0.1525, loss-lb:0.0837, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:53:38.752] iteration:15800  t-loss:0.1338, loss-lb:0.0821, loss-ulb:0.0258, weight:2.00, lr:0.0005
[11:53:38.943] iteration:15801  t-loss:0.1550, loss-lb:0.0859, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:53:39.134] iteration:15802  t-loss:0.1338, loss-lb:0.0785, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:53:39.326] iteration:15803  t-loss:0.1475, loss-lb:0.0883, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:53:39.517] iteration:15804  t-loss:0.1857, loss-lb:0.1085, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:53:39.709] iteration:15805  t-loss:0.1543, loss-lb:0.0773, loss-ulb:0.0385, weight:2.00, lr:0.0005
[11:53:39.899] iteration:15806  t-loss:0.1649, loss-lb:0.0852, loss-ulb:0.0398, weight:2.00, lr:0.0005
[11:53:40.093] iteration:15807  t-loss:0.2786, loss-lb:0.0722, loss-ulb:0.1032, weight:2.00, lr:0.0005
[11:53:40.286] iteration:15808  t-loss:0.1576, loss-lb:0.0823, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:53:40.480] iteration:15809  t-loss:0.1544, loss-lb:0.0881, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:53:40.671] iteration:15810  t-loss:0.1486, loss-lb:0.0906, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:53:40.862] iteration:15811  t-loss:0.1501, loss-lb:0.0762, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:53:41.055] iteration:15812  t-loss:0.1505, loss-lb:0.0773, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:53:41.246] iteration:15813  t-loss:0.1494, loss-lb:0.0801, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:53:41.440] iteration:15814  t-loss:0.1408, loss-lb:0.0808, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:53:41.631] iteration:15815  t-loss:0.1502, loss-lb:0.0880, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:53:41.822] iteration:15816  t-loss:0.1461, loss-lb:0.0821, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:53:42.014] iteration:15817  t-loss:0.1410, loss-lb:0.0835, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:53:42.205] iteration:15818  t-loss:0.1374, loss-lb:0.0833, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:53:42.397] iteration:15819  t-loss:0.2012, loss-lb:0.0916, loss-ulb:0.0548, weight:2.00, lr:0.0005
[11:53:42.589] iteration:15820  t-loss:0.1440, loss-lb:0.0820, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:53:42.779] iteration:15821  t-loss:0.1655, loss-lb:0.0829, loss-ulb:0.0413, weight:2.00, lr:0.0005
[11:53:42.970] iteration:15822  t-loss:0.1493, loss-lb:0.0813, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:53:43.161] iteration:15823  t-loss:0.1365, loss-lb:0.0745, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:53:43.350] iteration:15824  t-loss:0.1451, loss-lb:0.0833, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:53:43.543] iteration:15825  t-loss:0.1492, loss-lb:0.0795, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:53:43.738] iteration:15826  t-loss:0.1429, loss-lb:0.0719, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:53:43.934] iteration:15827  t-loss:0.2391, loss-lb:0.0856, loss-ulb:0.0767, weight:2.00, lr:0.0005
[11:53:44.129] iteration:15828  t-loss:0.1901, loss-lb:0.0856, loss-ulb:0.0523, weight:2.00, lr:0.0005
[11:53:44.322] iteration:15829  t-loss:0.1548, loss-lb:0.0834, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:53:44.515] iteration:15830  t-loss:0.1495, loss-lb:0.0814, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:53:44.706] iteration:15831  t-loss:0.1548, loss-lb:0.0834, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:53:44.898] iteration:15832  t-loss:0.1373, loss-lb:0.0820, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:53:45.088] iteration:15833  t-loss:0.1355, loss-lb:0.0786, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:53:45.280] iteration:15834  t-loss:0.1353, loss-lb:0.0757, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:53:45.472] iteration:15835  t-loss:0.1515, loss-lb:0.0829, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:53:45.664] iteration:15836  t-loss:0.1417, loss-lb:0.0846, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:53:45.857] iteration:15837  t-loss:0.1696, loss-lb:0.0769, loss-ulb:0.0464, weight:2.00, lr:0.0005
[11:53:46.048] iteration:15838  t-loss:0.1459, loss-lb:0.0783, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:53:46.240] iteration:15839  t-loss:0.1376, loss-lb:0.0819, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:53:46.433] iteration:15840  t-loss:0.1650, loss-lb:0.0932, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:53:46.624] iteration:15841  t-loss:0.1476, loss-lb:0.0825, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:53:46.816] iteration:15842  t-loss:0.1443, loss-lb:0.0770, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:53:47.008] iteration:15843  t-loss:0.1407, loss-lb:0.0796, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:53:47.200] iteration:15844  t-loss:0.1509, loss-lb:0.0863, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:53:47.392] iteration:15845  t-loss:0.1394, loss-lb:0.0879, loss-ulb:0.0257, weight:2.00, lr:0.0005
[11:53:47.582] iteration:15846  t-loss:0.1374, loss-lb:0.0806, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:53:47.774] iteration:15847  t-loss:0.1800, loss-lb:0.0899, loss-ulb:0.0451, weight:2.00, lr:0.0005
[11:53:47.965] iteration:15848  t-loss:0.1493, loss-lb:0.0830, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:53:48.157] iteration:15849  t-loss:0.1408, loss-lb:0.0799, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:53:48.350] iteration:15850  t-loss:0.1468, loss-lb:0.0825, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:53:48.541] iteration:15851  t-loss:0.1507, loss-lb:0.0817, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:53:48.741] iteration:15852  t-loss:0.1378, loss-lb:0.0815, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:53:48.933] iteration:15853  t-loss:0.1377, loss-lb:0.0693, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:53:49.124] iteration:15854  t-loss:0.1554, loss-lb:0.0912, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:53:49.315] iteration:15855  t-loss:0.1447, loss-lb:0.0806, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:53:49.507] iteration:15856  t-loss:0.1498, loss-lb:0.0863, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:53:49.703] iteration:15857  t-loss:0.1398, loss-lb:0.0836, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:53:49.895] iteration:15858  t-loss:0.1378, loss-lb:0.0756, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:53:50.086] iteration:15859  t-loss:0.1412, loss-lb:0.0812, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:53:50.278] iteration:15860  t-loss:0.1397, loss-lb:0.0782, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:53:50.470] iteration:15861  t-loss:0.1423, loss-lb:0.0889, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:53:50.661] iteration:15862  t-loss:0.1488, loss-lb:0.0854, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:53:50.853] iteration:15863  t-loss:0.1269, loss-lb:0.0740, loss-ulb:0.0265, weight:2.00, lr:0.0005
[11:53:51.046] iteration:15864  t-loss:0.1433, loss-lb:0.0800, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:53:51.236] iteration:15865  t-loss:0.1356, loss-lb:0.0839, loss-ulb:0.0258, weight:2.00, lr:0.0005
[11:53:51.428] iteration:15866  t-loss:0.1577, loss-lb:0.0767, loss-ulb:0.0405, weight:2.00, lr:0.0005
[11:53:51.620] iteration:15867  t-loss:0.1487, loss-lb:0.0875, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:53:51.812] iteration:15868  t-loss:0.2554, loss-lb:0.0887, loss-ulb:0.0834, weight:2.00, lr:0.0005
[11:53:52.002] iteration:15869  t-loss:0.1269, loss-lb:0.0744, loss-ulb:0.0263, weight:2.00, lr:0.0005
[11:53:52.192] iteration:15870  t-loss:0.1407, loss-lb:0.0823, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:53:52.382] iteration:15871  t-loss:0.2124, loss-lb:0.0787, loss-ulb:0.0668, weight:2.00, lr:0.0005
[11:53:52.572] iteration:15872  t-loss:0.1440, loss-lb:0.0906, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:53:52.761] iteration:15873  t-loss:0.1491, loss-lb:0.0773, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:53:52.951] iteration:15874  t-loss:0.1404, loss-lb:0.0829, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:53:53.140] iteration:15875  t-loss:0.1286, loss-lb:0.0714, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:53:53.329] iteration:15876  t-loss:0.1469, loss-lb:0.0914, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:53:53.941] iteration:15877  t-loss:0.1701, loss-lb:0.0846, loss-ulb:0.0427, weight:2.00, lr:0.0005
[11:53:54.135] iteration:15878  t-loss:0.1505, loss-lb:0.0845, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:53:54.327] iteration:15879  t-loss:0.1387, loss-lb:0.0743, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:53:54.521] iteration:15880  t-loss:0.1294, loss-lb:0.0812, loss-ulb:0.0241, weight:2.00, lr:0.0005
[11:53:54.716] iteration:15881  t-loss:0.1569, loss-lb:0.0811, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:53:54.911] iteration:15882  t-loss:0.1333, loss-lb:0.0805, loss-ulb:0.0264, weight:2.00, lr:0.0005
[11:53:55.106] iteration:15883  t-loss:0.1477, loss-lb:0.0856, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:53:55.298] iteration:15884  t-loss:0.1576, loss-lb:0.0808, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:53:55.490] iteration:15885  t-loss:0.1685, loss-lb:0.0917, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:53:55.681] iteration:15886  t-loss:0.1317, loss-lb:0.0698, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:53:55.874] iteration:15887  t-loss:0.1413, loss-lb:0.0797, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:53:56.065] iteration:15888  t-loss:0.1412, loss-lb:0.0800, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:53:56.258] iteration:15889  t-loss:0.1414, loss-lb:0.0802, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:53:56.450] iteration:15890  t-loss:0.1542, loss-lb:0.0801, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:53:56.641] iteration:15891  t-loss:0.1475, loss-lb:0.0742, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:53:56.835] iteration:15892  t-loss:0.1332, loss-lb:0.0777, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:53:57.027] iteration:15893  t-loss:0.1554, loss-lb:0.0919, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:53:57.220] iteration:15894  t-loss:0.1715, loss-lb:0.0834, loss-ulb:0.0441, weight:2.00, lr:0.0005
[11:53:57.412] iteration:15895  t-loss:0.1384, loss-lb:0.0800, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:53:57.605] iteration:15896  t-loss:0.1539, loss-lb:0.0754, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:53:57.810] iteration:15897  t-loss:0.1627, loss-lb:0.0816, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:53:58.005] iteration:15898  t-loss:0.1359, loss-lb:0.0824, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:53:58.201] iteration:15899  t-loss:0.1428, loss-lb:0.0814, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:53:58.392] iteration:15900  t-loss:0.1531, loss-lb:0.0774, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:53:58.585] iteration:15901  t-loss:0.2527, loss-lb:0.0847, loss-ulb:0.0840, weight:2.00, lr:0.0005
[11:53:58.778] iteration:15902  t-loss:0.1886, loss-lb:0.0903, loss-ulb:0.0491, weight:2.00, lr:0.0005
[11:53:58.970] iteration:15903  t-loss:0.1460, loss-lb:0.0804, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:53:59.162] iteration:15904  t-loss:0.1403, loss-lb:0.0790, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:53:59.354] iteration:15905  t-loss:0.1321, loss-lb:0.0755, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:53:59.546] iteration:15906  t-loss:0.1454, loss-lb:0.0808, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:53:59.738] iteration:15907  t-loss:0.1774, loss-lb:0.0825, loss-ulb:0.0474, weight:2.00, lr:0.0005
[11:53:59.930] iteration:15908  t-loss:0.1512, loss-lb:0.0840, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:54:00.121] iteration:15909  t-loss:0.1225, loss-lb:0.0701, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:54:00.314] iteration:15910  t-loss:0.1400, loss-lb:0.0760, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:54:00.507] iteration:15911  t-loss:0.1436, loss-lb:0.0853, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:54:00.698] iteration:15912  t-loss:0.1449, loss-lb:0.0783, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:54:00.889] iteration:15913  t-loss:0.1408, loss-lb:0.0773, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:54:01.081] iteration:15914  t-loss:0.2586, loss-lb:0.0826, loss-ulb:0.0880, weight:2.00, lr:0.0005
[11:54:01.274] iteration:15915  t-loss:0.1565, loss-lb:0.0861, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:54:01.466] iteration:15916  t-loss:0.1630, loss-lb:0.0776, loss-ulb:0.0427, weight:2.00, lr:0.0005
[11:54:01.658] iteration:15917  t-loss:0.1424, loss-lb:0.0821, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:54:01.850] iteration:15918  t-loss:0.1467, loss-lb:0.0802, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:54:02.042] iteration:15919  t-loss:0.1410, loss-lb:0.0828, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:54:02.234] iteration:15920  t-loss:0.1413, loss-lb:0.0838, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:54:02.426] iteration:15921  t-loss:0.1564, loss-lb:0.0865, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:54:02.620] iteration:15922  t-loss:0.1638, loss-lb:0.0801, loss-ulb:0.0419, weight:2.00, lr:0.0005
[11:54:02.811] iteration:15923  t-loss:0.1554, loss-lb:0.0815, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:54:03.002] iteration:15924  t-loss:0.1340, loss-lb:0.0768, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:54:03.194] iteration:15925  t-loss:0.2050, loss-lb:0.0865, loss-ulb:0.0592, weight:2.00, lr:0.0005
[11:54:03.385] iteration:15926  t-loss:0.1448, loss-lb:0.0827, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:54:03.576] iteration:15927  t-loss:0.1422, loss-lb:0.0870, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:54:03.768] iteration:15928  t-loss:0.1624, loss-lb:0.1082, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:54:03.959] iteration:15929  t-loss:0.1495, loss-lb:0.0845, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:54:04.151] iteration:15930  t-loss:0.1430, loss-lb:0.0826, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:54:04.343] iteration:15931  t-loss:0.1537, loss-lb:0.0798, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:54:04.534] iteration:15932  t-loss:0.1506, loss-lb:0.0841, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:54:04.725] iteration:15933  t-loss:0.1438, loss-lb:0.0811, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:54:04.916] iteration:15934  t-loss:0.1494, loss-lb:0.0822, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:54:05.107] iteration:15935  t-loss:0.1546, loss-lb:0.0886, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:54:05.299] iteration:15936  t-loss:0.1644, loss-lb:0.0799, loss-ulb:0.0423, weight:2.00, lr:0.0005
[11:54:05.491] iteration:15937  t-loss:0.1541, loss-lb:0.0763, loss-ulb:0.0389, weight:2.00, lr:0.0005
[11:54:05.684] iteration:15938  t-loss:0.1355, loss-lb:0.0746, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:54:05.875] iteration:15939  t-loss:0.1396, loss-lb:0.0777, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:54:06.068] iteration:15940  t-loss:0.2152, loss-lb:0.0808, loss-ulb:0.0672, weight:2.00, lr:0.0005
[11:54:06.261] iteration:15941  t-loss:0.1636, loss-lb:0.1020, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:54:06.452] iteration:15942  t-loss:0.1433, loss-lb:0.0797, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:54:06.644] iteration:15943  t-loss:0.1524, loss-lb:0.0845, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:54:06.837] iteration:15944  t-loss:0.1531, loss-lb:0.0861, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:54:07.028] iteration:15945  t-loss:0.1463, loss-lb:0.0783, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:54:07.223] iteration:15946  t-loss:0.1402, loss-lb:0.0858, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:54:07.415] iteration:15947  t-loss:0.1386, loss-lb:0.0778, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:54:07.607] iteration:15948  t-loss:0.1980, loss-lb:0.1385, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:54:07.799] iteration:15949  t-loss:0.1484, loss-lb:0.0776, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:54:07.991] iteration:15950  t-loss:0.1505, loss-lb:0.0841, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:54:08.184] iteration:15951  t-loss:0.1466, loss-lb:0.0822, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:54:08.377] iteration:15952  t-loss:0.2447, loss-lb:0.0796, loss-ulb:0.0826, weight:2.00, lr:0.0005
[11:54:08.569] iteration:15953  t-loss:0.1427, loss-lb:0.0835, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:54:08.763] iteration:15954  t-loss:0.1607, loss-lb:0.0774, loss-ulb:0.0417, weight:2.00, lr:0.0005
[11:54:08.956] iteration:15955  t-loss:0.1367, loss-lb:0.0782, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:54:09.148] iteration:15956  t-loss:0.1695, loss-lb:0.0854, loss-ulb:0.0421, weight:2.00, lr:0.0005
[11:54:09.341] iteration:15957  t-loss:0.1482, loss-lb:0.0789, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:54:09.534] iteration:15958  t-loss:0.1796, loss-lb:0.0814, loss-ulb:0.0491, weight:2.00, lr:0.0005
[11:54:09.727] iteration:15959  t-loss:0.1403, loss-lb:0.0846, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:54:09.919] iteration:15960  t-loss:0.1512, loss-lb:0.0829, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:54:10.112] iteration:15961  t-loss:0.1337, loss-lb:0.0736, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:54:10.304] iteration:15962  t-loss:0.1495, loss-lb:0.0748, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:54:10.496] iteration:15963  t-loss:0.1441, loss-lb:0.0817, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:54:10.689] iteration:15964  t-loss:0.1480, loss-lb:0.0755, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:54:10.882] iteration:15965  t-loss:0.1589, loss-lb:0.0873, loss-ulb:0.0358, weight:2.00, lr:0.0005
[11:54:11.074] iteration:15966  t-loss:0.1448, loss-lb:0.0823, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:54:11.266] iteration:15967  t-loss:0.1606, loss-lb:0.0968, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:54:11.457] iteration:15968  t-loss:0.1415, loss-lb:0.0825, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:54:11.647] iteration:15969  t-loss:0.1430, loss-lb:0.0789, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:54:11.838] iteration:15970  t-loss:0.1664, loss-lb:0.0872, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:54:12.028] iteration:15971  t-loss:0.1315, loss-lb:0.0704, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:54:12.220] iteration:15972  t-loss:0.1451, loss-lb:0.0833, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:54:12.410] iteration:15973  t-loss:0.1435, loss-lb:0.0827, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:54:12.601] iteration:15974  t-loss:0.1374, loss-lb:0.0755, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:54:24.901]  <<Test>> - Ep:162  - mean_dice/mean_h95 - S:90.36/1.32, Best-S:90.99, T:90.19/1.35, Best-T:90.48
[11:54:24.901]           - AvgLoss(lb/ulb/all):0.0823/0.0337/0.1487
[11:54:25.426] iteration:15975  t-loss:0.1401, loss-lb:0.0784, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:54:25.624] iteration:15976  t-loss:0.1354, loss-lb:0.0788, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:54:25.816] iteration:15977  t-loss:0.1461, loss-lb:0.0804, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:54:26.009] iteration:15978  t-loss:0.1377, loss-lb:0.0792, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:54:26.200] iteration:15979  t-loss:0.1648, loss-lb:0.0823, loss-ulb:0.0412, weight:2.00, lr:0.0005
[11:54:26.392] iteration:15980  t-loss:0.2122, loss-lb:0.0919, loss-ulb:0.0602, weight:2.00, lr:0.0005
[11:54:26.584] iteration:15981  t-loss:0.1650, loss-lb:0.0851, loss-ulb:0.0399, weight:2.00, lr:0.0005
[11:54:26.775] iteration:15982  t-loss:0.1473, loss-lb:0.0778, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:54:26.966] iteration:15983  t-loss:0.1486, loss-lb:0.0759, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:54:27.158] iteration:15984  t-loss:0.1367, loss-lb:0.0782, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:54:27.350] iteration:15985  t-loss:0.1601, loss-lb:0.0802, loss-ulb:0.0399, weight:2.00, lr:0.0005
[11:54:27.543] iteration:15986  t-loss:0.1512, loss-lb:0.0755, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:54:27.734] iteration:15987  t-loss:0.1571, loss-lb:0.0775, loss-ulb:0.0398, weight:2.00, lr:0.0005
[11:54:27.926] iteration:15988  t-loss:0.1471, loss-lb:0.0794, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:54:28.117] iteration:15989  t-loss:0.1489, loss-lb:0.0785, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:54:28.309] iteration:15990  t-loss:0.1313, loss-lb:0.0818, loss-ulb:0.0247, weight:2.00, lr:0.0005
[11:54:28.502] iteration:15991  t-loss:0.1454, loss-lb:0.0898, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:54:28.694] iteration:15992  t-loss:0.1447, loss-lb:0.0848, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:54:28.885] iteration:15993  t-loss:0.1394, loss-lb:0.0806, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:54:29.078] iteration:15994  t-loss:0.1428, loss-lb:0.0801, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:54:29.270] iteration:15995  t-loss:0.1510, loss-lb:0.0778, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:54:29.462] iteration:15996  t-loss:0.1324, loss-lb:0.0761, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:54:29.653] iteration:15997  t-loss:0.1445, loss-lb:0.0892, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:54:29.845] iteration:15998  t-loss:0.1265, loss-lb:0.0747, loss-ulb:0.0259, weight:2.00, lr:0.0005
[11:54:30.037] iteration:15999  t-loss:0.1644, loss-lb:0.0815, loss-ulb:0.0415, weight:2.00, lr:0.0005
[11:54:30.229] iteration:16000  t-loss:0.1832, loss-lb:0.1078, loss-ulb:0.0377, weight:2.00, lr:0.0005
[11:54:30.426] iteration:16001  t-loss:0.1530, loss-lb:0.0825, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:54:30.627] iteration:16002  t-loss:0.1483, loss-lb:0.0817, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:54:30.827] iteration:16003  t-loss:0.2398, loss-lb:0.0791, loss-ulb:0.0803, weight:2.00, lr:0.0005
[11:54:31.020] iteration:16004  t-loss:0.1400, loss-lb:0.0734, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:54:31.215] iteration:16005  t-loss:0.1375, loss-lb:0.0748, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:54:31.408] iteration:16006  t-loss:0.1577, loss-lb:0.0865, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:54:31.601] iteration:16007  t-loss:0.1499, loss-lb:0.0743, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:54:31.793] iteration:16008  t-loss:0.1360, loss-lb:0.0740, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:54:31.986] iteration:16009  t-loss:0.1515, loss-lb:0.0792, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:54:32.178] iteration:16010  t-loss:0.1487, loss-lb:0.0918, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:54:32.370] iteration:16011  t-loss:0.1980, loss-lb:0.0822, loss-ulb:0.0579, weight:2.00, lr:0.0005
[11:54:32.561] iteration:16012  t-loss:0.1520, loss-lb:0.0840, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:54:32.753] iteration:16013  t-loss:0.1586, loss-lb:0.0909, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:54:32.945] iteration:16014  t-loss:0.1565, loss-lb:0.0972, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:54:33.137] iteration:16015  t-loss:0.1571, loss-lb:0.0852, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:54:33.330] iteration:16016  t-loss:0.1879, loss-lb:0.0917, loss-ulb:0.0481, weight:2.00, lr:0.0005
[11:54:33.522] iteration:16017  t-loss:0.1648, loss-lb:0.0971, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:54:33.715] iteration:16018  t-loss:0.1518, loss-lb:0.0842, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:54:33.907] iteration:16019  t-loss:0.1811, loss-lb:0.0797, loss-ulb:0.0507, weight:2.00, lr:0.0005
[11:54:34.099] iteration:16020  t-loss:0.1971, loss-lb:0.0836, loss-ulb:0.0567, weight:2.00, lr:0.0005
[11:54:34.292] iteration:16021  t-loss:0.1344, loss-lb:0.0795, loss-ulb:0.0274, weight:2.00, lr:0.0005
[11:54:34.485] iteration:16022  t-loss:0.1577, loss-lb:0.0801, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:54:34.677] iteration:16023  t-loss:0.1635, loss-lb:0.0956, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:54:34.869] iteration:16024  t-loss:0.1904, loss-lb:0.0888, loss-ulb:0.0508, weight:2.00, lr:0.0005
[11:54:35.062] iteration:16025  t-loss:0.1476, loss-lb:0.0772, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:54:35.255] iteration:16026  t-loss:0.1601, loss-lb:0.0859, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:54:35.446] iteration:16027  t-loss:0.1487, loss-lb:0.0785, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:54:35.639] iteration:16028  t-loss:0.1487, loss-lb:0.0868, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:54:35.832] iteration:16029  t-loss:0.1734, loss-lb:0.0853, loss-ulb:0.0440, weight:2.00, lr:0.0005
[11:54:36.023] iteration:16030  t-loss:0.1717, loss-lb:0.0885, loss-ulb:0.0416, weight:2.00, lr:0.0005
[11:54:36.217] iteration:16031  t-loss:0.1917, loss-lb:0.0821, loss-ulb:0.0548, weight:2.00, lr:0.0005
[11:54:36.410] iteration:16032  t-loss:0.1385, loss-lb:0.0820, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:54:36.602] iteration:16033  t-loss:0.1574, loss-lb:0.0817, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:54:36.795] iteration:16034  t-loss:0.1469, loss-lb:0.0881, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:54:36.987] iteration:16035  t-loss:0.1433, loss-lb:0.0777, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:54:37.180] iteration:16036  t-loss:0.1699, loss-lb:0.0888, loss-ulb:0.0405, weight:2.00, lr:0.0005
[11:54:37.372] iteration:16037  t-loss:0.1658, loss-lb:0.0784, loss-ulb:0.0437, weight:2.00, lr:0.0005
[11:54:37.564] iteration:16038  t-loss:0.1494, loss-lb:0.0819, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:54:37.757] iteration:16039  t-loss:0.1438, loss-lb:0.0773, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:54:37.948] iteration:16040  t-loss:0.1648, loss-lb:0.0865, loss-ulb:0.0392, weight:2.00, lr:0.0005
[11:54:38.140] iteration:16041  t-loss:0.1454, loss-lb:0.0828, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:54:38.332] iteration:16042  t-loss:0.1341, loss-lb:0.0829, loss-ulb:0.0256, weight:2.00, lr:0.0005
[11:54:38.525] iteration:16043  t-loss:0.1500, loss-lb:0.0816, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:54:38.718] iteration:16044  t-loss:0.2111, loss-lb:0.0776, loss-ulb:0.0668, weight:2.00, lr:0.0005
[11:54:38.910] iteration:16045  t-loss:0.1378, loss-lb:0.0857, loss-ulb:0.0260, weight:2.00, lr:0.0005
[11:54:39.102] iteration:16046  t-loss:0.1535, loss-lb:0.0823, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:54:39.295] iteration:16047  t-loss:0.1928, loss-lb:0.0841, loss-ulb:0.0544, weight:2.00, lr:0.0005
[11:54:39.487] iteration:16048  t-loss:0.1554, loss-lb:0.0891, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:54:39.680] iteration:16049  t-loss:0.1618, loss-lb:0.0894, loss-ulb:0.0362, weight:2.00, lr:0.0005
[11:54:39.873] iteration:16050  t-loss:0.1990, loss-lb:0.0846, loss-ulb:0.0572, weight:2.00, lr:0.0005
[11:54:40.064] iteration:16051  t-loss:0.1547, loss-lb:0.0818, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:54:40.258] iteration:16052  t-loss:0.1868, loss-lb:0.0759, loss-ulb:0.0554, weight:2.00, lr:0.0005
[11:54:40.449] iteration:16053  t-loss:0.1447, loss-lb:0.0813, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:54:40.642] iteration:16054  t-loss:0.1595, loss-lb:0.0866, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:54:40.834] iteration:16055  t-loss:0.1477, loss-lb:0.0827, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:54:41.026] iteration:16056  t-loss:0.1468, loss-lb:0.0782, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:54:41.218] iteration:16057  t-loss:0.1458, loss-lb:0.0835, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:54:41.411] iteration:16058  t-loss:0.2155, loss-lb:0.0895, loss-ulb:0.0630, weight:2.00, lr:0.0005
[11:54:41.605] iteration:16059  t-loss:0.1714, loss-lb:0.1004, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:54:41.797] iteration:16060  t-loss:0.1500, loss-lb:0.0802, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:54:41.989] iteration:16061  t-loss:0.1984, loss-lb:0.0844, loss-ulb:0.0570, weight:2.00, lr:0.0005
[11:54:42.182] iteration:16062  t-loss:0.1638, loss-lb:0.0903, loss-ulb:0.0367, weight:2.00, lr:0.0005
[11:54:42.374] iteration:16063  t-loss:0.1755, loss-lb:0.0905, loss-ulb:0.0425, weight:2.00, lr:0.0005
[11:54:42.567] iteration:16064  t-loss:0.2854, loss-lb:0.1012, loss-ulb:0.0921, weight:2.00, lr:0.0005
[11:54:42.759] iteration:16065  t-loss:0.1673, loss-lb:0.0958, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:54:42.949] iteration:16066  t-loss:0.1343, loss-lb:0.0746, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:54:43.139] iteration:16067  t-loss:0.1674, loss-lb:0.0840, loss-ulb:0.0417, weight:2.00, lr:0.0005
[11:54:43.331] iteration:16068  t-loss:0.1811, loss-lb:0.1080, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:54:43.520] iteration:16069  t-loss:0.1522, loss-lb:0.0922, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:54:43.712] iteration:16070  t-loss:0.2121, loss-lb:0.0927, loss-ulb:0.0597, weight:2.00, lr:0.0005
[11:54:43.902] iteration:16071  t-loss:0.1567, loss-lb:0.0837, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:54:44.092] iteration:16072  t-loss:0.1503, loss-lb:0.0885, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:54:44.712] iteration:16073  t-loss:0.1776, loss-lb:0.0858, loss-ulb:0.0459, weight:2.00, lr:0.0005
[11:54:44.910] iteration:16074  t-loss:0.1802, loss-lb:0.0887, loss-ulb:0.0458, weight:2.00, lr:0.0005
[11:54:45.103] iteration:16075  t-loss:0.1414, loss-lb:0.0831, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:54:45.296] iteration:16076  t-loss:0.2086, loss-lb:0.0909, loss-ulb:0.0589, weight:2.00, lr:0.0005
[11:54:45.488] iteration:16077  t-loss:0.1586, loss-lb:0.0917, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:54:45.681] iteration:16078  t-loss:0.1507, loss-lb:0.0840, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:54:45.874] iteration:16079  t-loss:0.1831, loss-lb:0.0840, loss-ulb:0.0496, weight:2.00, lr:0.0005
[11:54:46.067] iteration:16080  t-loss:0.1705, loss-lb:0.0884, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:54:46.259] iteration:16081  t-loss:0.1758, loss-lb:0.0912, loss-ulb:0.0423, weight:2.00, lr:0.0005
[11:54:46.451] iteration:16082  t-loss:0.1559, loss-lb:0.0845, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:54:46.644] iteration:16083  t-loss:0.2241, loss-lb:0.1034, loss-ulb:0.0604, weight:2.00, lr:0.0005
[11:54:46.836] iteration:16084  t-loss:0.2614, loss-lb:0.2050, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:54:47.029] iteration:16085  t-loss:0.1508, loss-lb:0.0919, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:54:47.223] iteration:16086  t-loss:0.1710, loss-lb:0.0896, loss-ulb:0.0407, weight:2.00, lr:0.0005
[11:54:47.416] iteration:16087  t-loss:0.1731, loss-lb:0.0946, loss-ulb:0.0392, weight:2.00, lr:0.0005
[11:54:47.608] iteration:16088  t-loss:0.1551, loss-lb:0.0823, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:54:47.801] iteration:16089  t-loss:0.1482, loss-lb:0.0820, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:54:47.994] iteration:16090  t-loss:0.1592, loss-lb:0.0882, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:54:48.185] iteration:16091  t-loss:0.1609, loss-lb:0.0941, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:54:48.378] iteration:16092  t-loss:0.1895, loss-lb:0.0862, loss-ulb:0.0517, weight:2.00, lr:0.0005
[11:54:48.570] iteration:16093  t-loss:0.1562, loss-lb:0.0868, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:54:48.762] iteration:16094  t-loss:0.1576, loss-lb:0.0884, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:54:48.955] iteration:16095  t-loss:0.1740, loss-lb:0.1127, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:54:49.147] iteration:16096  t-loss:0.1475, loss-lb:0.0834, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:54:49.340] iteration:16097  t-loss:0.1560, loss-lb:0.0880, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:54:49.532] iteration:16098  t-loss:0.1424, loss-lb:0.0840, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:54:49.724] iteration:16099  t-loss:0.1423, loss-lb:0.0839, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:54:49.919] iteration:16100  t-loss:0.1500, loss-lb:0.0703, loss-ulb:0.0399, weight:2.00, lr:0.0005
[11:54:50.111] iteration:16101  t-loss:0.1455, loss-lb:0.0885, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:54:50.304] iteration:16102  t-loss:0.1656, loss-lb:0.0772, loss-ulb:0.0442, weight:2.00, lr:0.0005
[11:54:50.496] iteration:16103  t-loss:0.1524, loss-lb:0.0795, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:54:50.690] iteration:16104  t-loss:0.1910, loss-lb:0.0941, loss-ulb:0.0484, weight:2.00, lr:0.0005
[11:54:50.883] iteration:16105  t-loss:0.1616, loss-lb:0.0821, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:54:51.075] iteration:16106  t-loss:0.1419, loss-lb:0.0850, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:54:51.268] iteration:16107  t-loss:0.1399, loss-lb:0.0859, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:54:51.461] iteration:16108  t-loss:0.1452, loss-lb:0.0906, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:54:51.654] iteration:16109  t-loss:0.1418, loss-lb:0.0761, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:54:51.846] iteration:16110  t-loss:0.1457, loss-lb:0.0795, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:54:52.039] iteration:16111  t-loss:0.1527, loss-lb:0.1000, loss-ulb:0.0264, weight:2.00, lr:0.0005
[11:54:52.231] iteration:16112  t-loss:0.1965, loss-lb:0.0888, loss-ulb:0.0539, weight:2.00, lr:0.0005
[11:54:52.423] iteration:16113  t-loss:0.1551, loss-lb:0.1011, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:54:52.616] iteration:16114  t-loss:0.1842, loss-lb:0.0911, loss-ulb:0.0465, weight:2.00, lr:0.0005
[11:54:52.807] iteration:16115  t-loss:0.1893, loss-lb:0.0857, loss-ulb:0.0518, weight:2.00, lr:0.0005
[11:54:53.000] iteration:16116  t-loss:0.1593, loss-lb:0.0835, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:54:53.192] iteration:16117  t-loss:0.1504, loss-lb:0.0854, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:54:53.385] iteration:16118  t-loss:0.1409, loss-lb:0.0810, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:54:53.578] iteration:16119  t-loss:0.1411, loss-lb:0.0819, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:54:53.772] iteration:16120  t-loss:0.1555, loss-lb:0.0771, loss-ulb:0.0392, weight:2.00, lr:0.0005
[11:54:53.965] iteration:16121  t-loss:0.1493, loss-lb:0.0865, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:54:54.157] iteration:16122  t-loss:0.1444, loss-lb:0.0790, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:54:54.348] iteration:16123  t-loss:0.1464, loss-lb:0.0819, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:54:54.542] iteration:16124  t-loss:0.1943, loss-lb:0.0866, loss-ulb:0.0539, weight:2.00, lr:0.0005
[11:54:54.735] iteration:16125  t-loss:0.1626, loss-lb:0.0966, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:54:54.926] iteration:16126  t-loss:0.1562, loss-lb:0.0884, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:54:55.118] iteration:16127  t-loss:0.1577, loss-lb:0.0806, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:54:55.312] iteration:16128  t-loss:0.1697, loss-lb:0.0843, loss-ulb:0.0427, weight:2.00, lr:0.0005
[11:54:55.504] iteration:16129  t-loss:0.1495, loss-lb:0.0841, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:54:55.700] iteration:16130  t-loss:0.1521, loss-lb:0.0966, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:54:55.894] iteration:16131  t-loss:0.2901, loss-lb:0.0833, loss-ulb:0.1034, weight:2.00, lr:0.0005
[11:54:56.089] iteration:16132  t-loss:0.1425, loss-lb:0.0861, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:54:56.283] iteration:16133  t-loss:0.2496, loss-lb:0.0823, loss-ulb:0.0836, weight:2.00, lr:0.0005
[11:54:56.476] iteration:16134  t-loss:0.1339, loss-lb:0.0766, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:54:56.667] iteration:16135  t-loss:0.1404, loss-lb:0.0811, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:54:56.859] iteration:16136  t-loss:0.1533, loss-lb:0.0801, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:54:57.052] iteration:16137  t-loss:0.1541, loss-lb:0.0794, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:54:57.245] iteration:16138  t-loss:0.1440, loss-lb:0.0782, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:54:57.436] iteration:16139  t-loss:0.1368, loss-lb:0.0823, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:54:57.629] iteration:16140  t-loss:0.2165, loss-lb:0.0818, loss-ulb:0.0673, weight:2.00, lr:0.0005
[11:54:57.822] iteration:16141  t-loss:0.1464, loss-lb:0.0908, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:54:58.015] iteration:16142  t-loss:0.1378, loss-lb:0.0800, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:54:58.206] iteration:16143  t-loss:0.1383, loss-lb:0.0792, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:54:58.398] iteration:16144  t-loss:0.2493, loss-lb:0.0811, loss-ulb:0.0841, weight:2.00, lr:0.0005
[11:54:58.591] iteration:16145  t-loss:0.2215, loss-lb:0.0827, loss-ulb:0.0694, weight:2.00, lr:0.0005
[11:54:58.783] iteration:16146  t-loss:0.1515, loss-lb:0.0884, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:54:58.975] iteration:16147  t-loss:0.1454, loss-lb:0.0754, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:54:59.166] iteration:16148  t-loss:0.1482, loss-lb:0.0818, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:54:59.359] iteration:16149  t-loss:0.1366, loss-lb:0.0826, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:54:59.550] iteration:16150  t-loss:0.1503, loss-lb:0.0784, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:54:59.742] iteration:16151  t-loss:0.1438, loss-lb:0.0885, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:54:59.934] iteration:16152  t-loss:0.1427, loss-lb:0.0776, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:55:00.125] iteration:16153  t-loss:0.1452, loss-lb:0.0766, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:55:00.318] iteration:16154  t-loss:0.1370, loss-lb:0.0826, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:55:00.509] iteration:16155  t-loss:0.1386, loss-lb:0.0775, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:55:00.701] iteration:16156  t-loss:0.1526, loss-lb:0.0836, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:55:00.893] iteration:16157  t-loss:0.1397, loss-lb:0.0842, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:55:01.084] iteration:16158  t-loss:0.1421, loss-lb:0.0766, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:55:01.276] iteration:16159  t-loss:0.1573, loss-lb:0.0842, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:55:01.470] iteration:16160  t-loss:0.1472, loss-lb:0.0904, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:55:01.662] iteration:16161  t-loss:0.2542, loss-lb:0.0855, loss-ulb:0.0844, weight:2.00, lr:0.0005
[11:55:01.855] iteration:16162  t-loss:0.1471, loss-lb:0.0831, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:55:02.047] iteration:16163  t-loss:0.2153, loss-lb:0.0841, loss-ulb:0.0656, weight:2.00, lr:0.0005
[11:55:02.237] iteration:16164  t-loss:0.1442, loss-lb:0.0898, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:55:02.427] iteration:16165  t-loss:0.1534, loss-lb:0.0837, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:55:02.617] iteration:16166  t-loss:0.1374, loss-lb:0.0819, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:55:02.809] iteration:16167  t-loss:0.2398, loss-lb:0.0724, loss-ulb:0.0837, weight:2.00, lr:0.0005
[11:55:02.999] iteration:16168  t-loss:0.1827, loss-lb:0.0863, loss-ulb:0.0482, weight:2.00, lr:0.0005
[11:55:03.196] iteration:16169  t-loss:0.1314, loss-lb:0.0782, loss-ulb:0.0266, weight:2.00, lr:0.0005
[11:55:03.397] iteration:16170  t-loss:0.1582, loss-lb:0.0822, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:55:14.984]  <<Test>> - Ep:164  - mean_dice/mean_h95 - S:89.78/1.39, Best-S:90.99, T:89.96/1.36, Best-T:90.48
[11:55:14.984]           - AvgLoss(lb/ulb/all):0.0862/0.0390/0.1605
[11:55:15.518] iteration:16171  t-loss:0.1915, loss-lb:0.0870, loss-ulb:0.0523, weight:2.00, lr:0.0005
[11:55:15.710] iteration:16172  t-loss:0.1387, loss-lb:0.0749, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:55:15.901] iteration:16173  t-loss:0.1420, loss-lb:0.0761, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:55:16.091] iteration:16174  t-loss:0.1585, loss-lb:0.1005, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:55:16.284] iteration:16175  t-loss:0.1635, loss-lb:0.0822, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:55:16.476] iteration:16176  t-loss:0.2560, loss-lb:0.0803, loss-ulb:0.0878, weight:2.00, lr:0.0005
[11:55:16.667] iteration:16177  t-loss:0.1542, loss-lb:0.0776, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:55:16.864] iteration:16178  t-loss:0.2378, loss-lb:0.0842, loss-ulb:0.0768, weight:2.00, lr:0.0005
[11:55:17.058] iteration:16179  t-loss:0.1847, loss-lb:0.0838, loss-ulb:0.0505, weight:2.00, lr:0.0005
[11:55:17.251] iteration:16180  t-loss:0.1509, loss-lb:0.0816, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:55:17.448] iteration:16181  t-loss:0.1390, loss-lb:0.0815, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:55:17.643] iteration:16182  t-loss:0.1432, loss-lb:0.0845, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:55:17.835] iteration:16183  t-loss:0.1500, loss-lb:0.0869, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:55:18.027] iteration:16184  t-loss:0.1698, loss-lb:0.0815, loss-ulb:0.0441, weight:2.00, lr:0.0005
[11:55:18.220] iteration:16185  t-loss:0.1960, loss-lb:0.0776, loss-ulb:0.0592, weight:2.00, lr:0.0005
[11:55:18.410] iteration:16186  t-loss:0.1378, loss-lb:0.0766, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:55:18.602] iteration:16187  t-loss:0.1587, loss-lb:0.0838, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:55:18.793] iteration:16188  t-loss:0.1482, loss-lb:0.0849, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:55:18.985] iteration:16189  t-loss:0.1540, loss-lb:0.0890, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:55:19.175] iteration:16190  t-loss:0.1587, loss-lb:0.0740, loss-ulb:0.0423, weight:2.00, lr:0.0005
[11:55:19.367] iteration:16191  t-loss:0.1349, loss-lb:0.0746, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:55:19.559] iteration:16192  t-loss:0.1530, loss-lb:0.0903, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:55:19.750] iteration:16193  t-loss:0.1467, loss-lb:0.0824, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:55:19.941] iteration:16194  t-loss:0.1319, loss-lb:0.0734, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:55:20.132] iteration:16195  t-loss:0.1787, loss-lb:0.0870, loss-ulb:0.0458, weight:2.00, lr:0.0005
[11:55:20.324] iteration:16196  t-loss:0.1463, loss-lb:0.0850, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:55:20.515] iteration:16197  t-loss:0.1303, loss-lb:0.0792, loss-ulb:0.0255, weight:2.00, lr:0.0005
[11:55:20.707] iteration:16198  t-loss:0.1463, loss-lb:0.0793, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:55:20.899] iteration:16199  t-loss:0.1355, loss-lb:0.0806, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:55:21.091] iteration:16200  t-loss:0.1364, loss-lb:0.0758, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:55:21.284] iteration:16201  t-loss:0.1361, loss-lb:0.0762, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:55:21.475] iteration:16202  t-loss:0.1323, loss-lb:0.0727, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:55:21.667] iteration:16203  t-loss:0.1422, loss-lb:0.0825, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:55:21.858] iteration:16204  t-loss:0.1489, loss-lb:0.0785, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:55:22.051] iteration:16205  t-loss:0.1392, loss-lb:0.0794, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:55:22.245] iteration:16206  t-loss:0.1699, loss-lb:0.0818, loss-ulb:0.0441, weight:2.00, lr:0.0005
[11:55:22.436] iteration:16207  t-loss:0.1434, loss-lb:0.0832, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:55:22.628] iteration:16208  t-loss:0.1387, loss-lb:0.0849, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:55:22.819] iteration:16209  t-loss:0.1540, loss-lb:0.0845, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:55:23.010] iteration:16210  t-loss:0.1564, loss-lb:0.0790, loss-ulb:0.0387, weight:2.00, lr:0.0005
[11:55:23.204] iteration:16211  t-loss:0.1405, loss-lb:0.0788, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:55:23.397] iteration:16212  t-loss:0.1494, loss-lb:0.0902, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:55:23.589] iteration:16213  t-loss:0.1998, loss-lb:0.0810, loss-ulb:0.0594, weight:2.00, lr:0.0005
[11:55:23.782] iteration:16214  t-loss:0.1329, loss-lb:0.0681, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:55:23.982] iteration:16215  t-loss:0.1392, loss-lb:0.0795, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:55:24.175] iteration:16216  t-loss:0.2475, loss-lb:0.0816, loss-ulb:0.0829, weight:2.00, lr:0.0005
[11:55:24.368] iteration:16217  t-loss:0.1430, loss-lb:0.0752, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:55:24.559] iteration:16218  t-loss:0.1697, loss-lb:0.0793, loss-ulb:0.0452, weight:2.00, lr:0.0005
[11:55:24.760] iteration:16219  t-loss:0.1389, loss-lb:0.0852, loss-ulb:0.0268, weight:2.00, lr:0.0005
[11:55:24.952] iteration:16220  t-loss:0.1637, loss-lb:0.0813, loss-ulb:0.0412, weight:2.00, lr:0.0005
[11:55:25.144] iteration:16221  t-loss:0.1418, loss-lb:0.0773, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:55:25.335] iteration:16222  t-loss:0.1436, loss-lb:0.0781, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:55:25.527] iteration:16223  t-loss:0.1531, loss-lb:0.0835, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:55:25.719] iteration:16224  t-loss:0.1458, loss-lb:0.0694, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:55:25.910] iteration:16225  t-loss:0.1463, loss-lb:0.0803, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:55:26.101] iteration:16226  t-loss:0.1416, loss-lb:0.0839, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:55:26.292] iteration:16227  t-loss:0.1410, loss-lb:0.0791, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:55:26.483] iteration:16228  t-loss:0.1479, loss-lb:0.0779, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:55:26.675] iteration:16229  t-loss:0.1472, loss-lb:0.0876, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:55:26.864] iteration:16230  t-loss:0.1476, loss-lb:0.0769, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:55:27.056] iteration:16231  t-loss:0.1498, loss-lb:0.0770, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:55:27.249] iteration:16232  t-loss:0.1563, loss-lb:0.0904, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:55:27.439] iteration:16233  t-loss:0.1412, loss-lb:0.0794, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:55:27.631] iteration:16234  t-loss:0.1548, loss-lb:0.0763, loss-ulb:0.0392, weight:2.00, lr:0.0005
[11:55:27.823] iteration:16235  t-loss:0.1559, loss-lb:0.0942, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:55:28.016] iteration:16236  t-loss:0.1514, loss-lb:0.0763, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:55:28.212] iteration:16237  t-loss:0.1850, loss-lb:0.0812, loss-ulb:0.0519, weight:2.00, lr:0.0005
[11:55:28.405] iteration:16238  t-loss:0.1473, loss-lb:0.0796, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:55:28.599] iteration:16239  t-loss:0.1596, loss-lb:0.0831, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:55:28.791] iteration:16240  t-loss:0.1340, loss-lb:0.0773, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:55:28.984] iteration:16241  t-loss:0.1415, loss-lb:0.0824, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:55:29.175] iteration:16242  t-loss:0.1492, loss-lb:0.0855, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:55:29.367] iteration:16243  t-loss:0.1556, loss-lb:0.0808, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:55:29.559] iteration:16244  t-loss:0.1446, loss-lb:0.0852, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:55:29.750] iteration:16245  t-loss:0.1593, loss-lb:0.0724, loss-ulb:0.0435, weight:2.00, lr:0.0005
[11:55:29.941] iteration:16246  t-loss:0.1556, loss-lb:0.0861, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:55:30.138] iteration:16247  t-loss:0.1521, loss-lb:0.0872, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:55:30.331] iteration:16248  t-loss:0.1504, loss-lb:0.0816, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:55:30.523] iteration:16249  t-loss:0.1321, loss-lb:0.0808, loss-ulb:0.0257, weight:2.00, lr:0.0005
[11:55:30.714] iteration:16250  t-loss:0.1327, loss-lb:0.0736, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:55:30.909] iteration:16251  t-loss:0.1485, loss-lb:0.0709, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:55:31.101] iteration:16252  t-loss:0.1398, loss-lb:0.0826, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:55:31.294] iteration:16253  t-loss:0.1614, loss-lb:0.0776, loss-ulb:0.0419, weight:2.00, lr:0.0005
[11:55:31.487] iteration:16254  t-loss:0.1463, loss-lb:0.0768, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:55:31.679] iteration:16255  t-loss:0.1473, loss-lb:0.0799, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:55:31.871] iteration:16256  t-loss:0.1258, loss-lb:0.0719, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:55:32.064] iteration:16257  t-loss:0.1610, loss-lb:0.0911, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:55:32.255] iteration:16258  t-loss:0.1332, loss-lb:0.0735, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:55:32.449] iteration:16259  t-loss:0.2619, loss-lb:0.0889, loss-ulb:0.0865, weight:2.00, lr:0.0005
[11:55:32.641] iteration:16260  t-loss:0.1466, loss-lb:0.0777, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:55:32.834] iteration:16261  t-loss:0.1325, loss-lb:0.0805, loss-ulb:0.0260, weight:2.00, lr:0.0005
[11:55:33.024] iteration:16262  t-loss:0.1533, loss-lb:0.0815, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:55:33.216] iteration:16263  t-loss:0.2306, loss-lb:0.0798, loss-ulb:0.0754, weight:2.00, lr:0.0005
[11:55:33.408] iteration:16264  t-loss:0.1611, loss-lb:0.0792, loss-ulb:0.0410, weight:2.00, lr:0.0005
[11:55:33.600] iteration:16265  t-loss:0.2317, loss-lb:0.0831, loss-ulb:0.0743, weight:2.00, lr:0.0005
[11:55:33.793] iteration:16266  t-loss:0.1393, loss-lb:0.0808, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:55:33.983] iteration:16267  t-loss:0.1416, loss-lb:0.0841, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:55:34.173] iteration:16268  t-loss:0.1455, loss-lb:0.0750, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:55:34.779] iteration:16269  t-loss:0.1484, loss-lb:0.0813, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:55:34.973] iteration:16270  t-loss:0.1854, loss-lb:0.0801, loss-ulb:0.0527, weight:2.00, lr:0.0005
[11:55:35.164] iteration:16271  t-loss:0.1625, loss-lb:0.0820, loss-ulb:0.0402, weight:2.00, lr:0.0005
[11:55:35.357] iteration:16272  t-loss:0.1501, loss-lb:0.0800, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:55:35.549] iteration:16273  t-loss:0.1323, loss-lb:0.0815, loss-ulb:0.0254, weight:2.00, lr:0.0005
[11:55:35.742] iteration:16274  t-loss:0.1377, loss-lb:0.0818, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:55:35.935] iteration:16275  t-loss:0.1511, loss-lb:0.0819, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:55:36.134] iteration:16276  t-loss:0.1506, loss-lb:0.0850, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:55:36.334] iteration:16277  t-loss:0.1750, loss-lb:0.0834, loss-ulb:0.0458, weight:2.00, lr:0.0005
[11:55:36.529] iteration:16278  t-loss:0.1327, loss-lb:0.0749, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:55:36.720] iteration:16279  t-loss:0.1545, loss-lb:0.0756, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:55:36.912] iteration:16280  t-loss:0.1841, loss-lb:0.0793, loss-ulb:0.0524, weight:2.00, lr:0.0005
[11:55:37.104] iteration:16281  t-loss:0.1529, loss-lb:0.0882, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:55:37.297] iteration:16282  t-loss:0.1541, loss-lb:0.0765, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:55:37.488] iteration:16283  t-loss:0.1626, loss-lb:0.0864, loss-ulb:0.0381, weight:2.00, lr:0.0005
[11:55:37.683] iteration:16284  t-loss:0.1573, loss-lb:0.0781, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:55:37.875] iteration:16285  t-loss:0.1464, loss-lb:0.0787, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:55:38.066] iteration:16286  t-loss:0.1629, loss-lb:0.0856, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:55:38.259] iteration:16287  t-loss:0.1268, loss-lb:0.0771, loss-ulb:0.0249, weight:2.00, lr:0.0005
[11:55:38.450] iteration:16288  t-loss:0.1518, loss-lb:0.0771, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:55:38.642] iteration:16289  t-loss:0.1347, loss-lb:0.0790, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:55:38.834] iteration:16290  t-loss:0.1481, loss-lb:0.0812, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:55:39.026] iteration:16291  t-loss:0.1441, loss-lb:0.0805, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:55:39.221] iteration:16292  t-loss:0.1480, loss-lb:0.0854, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:55:39.414] iteration:16293  t-loss:0.1774, loss-lb:0.0820, loss-ulb:0.0477, weight:2.00, lr:0.0005
[11:55:39.608] iteration:16294  t-loss:0.2462, loss-lb:0.0882, loss-ulb:0.0790, weight:2.00, lr:0.0005
[11:55:39.800] iteration:16295  t-loss:0.1551, loss-lb:0.0819, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:55:39.994] iteration:16296  t-loss:0.1629, loss-lb:0.0906, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:55:40.186] iteration:16297  t-loss:0.1493, loss-lb:0.0824, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:55:40.379] iteration:16298  t-loss:0.1669, loss-lb:0.0906, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:55:40.570] iteration:16299  t-loss:0.1466, loss-lb:0.0756, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:55:40.763] iteration:16300  t-loss:0.1463, loss-lb:0.0800, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:55:40.956] iteration:16301  t-loss:0.1506, loss-lb:0.0744, loss-ulb:0.0381, weight:2.00, lr:0.0005
[11:55:41.148] iteration:16302  t-loss:0.1477, loss-lb:0.0803, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:55:41.341] iteration:16303  t-loss:0.1405, loss-lb:0.0727, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:55:41.534] iteration:16304  t-loss:0.1552, loss-lb:0.0795, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:55:41.727] iteration:16305  t-loss:0.1782, loss-lb:0.0879, loss-ulb:0.0452, weight:2.00, lr:0.0005
[11:55:41.919] iteration:16306  t-loss:0.1332, loss-lb:0.0818, loss-ulb:0.0257, weight:2.00, lr:0.0005
[11:55:42.111] iteration:16307  t-loss:0.1422, loss-lb:0.0855, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:55:42.304] iteration:16308  t-loss:0.1605, loss-lb:0.0879, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:55:42.496] iteration:16309  t-loss:0.1677, loss-lb:0.0762, loss-ulb:0.0458, weight:2.00, lr:0.0005
[11:55:42.688] iteration:16310  t-loss:0.1509, loss-lb:0.0880, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:55:42.882] iteration:16311  t-loss:0.1560, loss-lb:0.0784, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:55:43.076] iteration:16312  t-loss:0.1423, loss-lb:0.0794, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:55:43.270] iteration:16313  t-loss:0.1753, loss-lb:0.0808, loss-ulb:0.0473, weight:2.00, lr:0.0005
[11:55:43.462] iteration:16314  t-loss:0.1464, loss-lb:0.0876, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:55:43.655] iteration:16315  t-loss:0.1471, loss-lb:0.0752, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:55:43.847] iteration:16316  t-loss:0.1451, loss-lb:0.0780, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:55:44.039] iteration:16317  t-loss:0.1749, loss-lb:0.0832, loss-ulb:0.0459, weight:2.00, lr:0.0005
[11:55:44.232] iteration:16318  t-loss:0.1343, loss-lb:0.0729, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:55:44.424] iteration:16319  t-loss:0.1482, loss-lb:0.0751, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:55:44.616] iteration:16320  t-loss:0.1583, loss-lb:0.0890, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:55:44.809] iteration:16321  t-loss:0.1486, loss-lb:0.0784, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:55:45.000] iteration:16322  t-loss:0.1515, loss-lb:0.0741, loss-ulb:0.0387, weight:2.00, lr:0.0005
[11:55:45.193] iteration:16323  t-loss:0.1510, loss-lb:0.0911, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:55:45.386] iteration:16324  t-loss:0.1489, loss-lb:0.0818, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:55:45.580] iteration:16325  t-loss:0.1679, loss-lb:0.0847, loss-ulb:0.0416, weight:2.00, lr:0.0005
[11:55:45.772] iteration:16326  t-loss:0.1545, loss-lb:0.0827, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:55:45.966] iteration:16327  t-loss:0.1396, loss-lb:0.0801, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:55:46.159] iteration:16328  t-loss:0.1324, loss-lb:0.0785, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:55:46.352] iteration:16329  t-loss:0.1320, loss-lb:0.0720, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:55:46.543] iteration:16330  t-loss:0.1330, loss-lb:0.0757, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:55:46.736] iteration:16331  t-loss:0.1523, loss-lb:0.0847, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:55:46.929] iteration:16332  t-loss:0.1414, loss-lb:0.0834, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:55:47.120] iteration:16333  t-loss:0.1660, loss-lb:0.0814, loss-ulb:0.0423, weight:2.00, lr:0.0005
[11:55:47.312] iteration:16334  t-loss:0.1473, loss-lb:0.0814, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:55:47.505] iteration:16335  t-loss:0.1463, loss-lb:0.0813, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:55:47.698] iteration:16336  t-loss:0.1440, loss-lb:0.0751, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:55:47.890] iteration:16337  t-loss:0.1522, loss-lb:0.0850, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:55:48.083] iteration:16338  t-loss:0.1517, loss-lb:0.0798, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:55:48.275] iteration:16339  t-loss:0.1352, loss-lb:0.0766, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:55:48.468] iteration:16340  t-loss:0.1453, loss-lb:0.0796, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:55:48.661] iteration:16341  t-loss:0.1378, loss-lb:0.0757, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:55:48.852] iteration:16342  t-loss:0.1476, loss-lb:0.0838, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:55:49.044] iteration:16343  t-loss:0.1589, loss-lb:0.0766, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:55:49.237] iteration:16344  t-loss:0.1937, loss-lb:0.0829, loss-ulb:0.0554, weight:2.00, lr:0.0005
[11:55:49.430] iteration:16345  t-loss:0.1507, loss-lb:0.0857, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:55:49.623] iteration:16346  t-loss:0.1511, loss-lb:0.0774, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:55:49.816] iteration:16347  t-loss:0.1399, loss-lb:0.0843, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:55:50.009] iteration:16348  t-loss:0.1402, loss-lb:0.0837, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:55:50.200] iteration:16349  t-loss:0.1389, loss-lb:0.0733, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:55:50.392] iteration:16350  t-loss:0.1391, loss-lb:0.0793, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:55:50.586] iteration:16351  t-loss:0.1373, loss-lb:0.0744, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:55:50.779] iteration:16352  t-loss:0.1515, loss-lb:0.0811, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:55:50.972] iteration:16353  t-loss:0.1341, loss-lb:0.0790, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:55:51.164] iteration:16354  t-loss:0.1340, loss-lb:0.0770, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:55:51.357] iteration:16355  t-loss:0.1531, loss-lb:0.0875, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:55:51.550] iteration:16356  t-loss:0.2791, loss-lb:0.0737, loss-ulb:0.1027, weight:2.00, lr:0.0005
[11:55:51.744] iteration:16357  t-loss:0.1543, loss-lb:0.0778, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:55:51.936] iteration:16358  t-loss:0.1584, loss-lb:0.0892, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:55:52.128] iteration:16359  t-loss:0.1449, loss-lb:0.0831, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:55:52.319] iteration:16360  t-loss:0.1638, loss-lb:0.0789, loss-ulb:0.0424, weight:2.00, lr:0.0005
[11:55:52.510] iteration:16361  t-loss:0.1571, loss-lb:0.0785, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:55:52.700] iteration:16362  t-loss:0.1538, loss-lb:0.0903, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:55:52.891] iteration:16363  t-loss:0.1344, loss-lb:0.0741, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:55:53.082] iteration:16364  t-loss:0.1464, loss-lb:0.0873, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:55:53.273] iteration:16365  t-loss:0.1578, loss-lb:0.0785, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:55:53.465] iteration:16366  t-loss:0.1511, loss-lb:0.0769, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:56:05.954]  <<Test>> - Ep:166  - mean_dice/mean_h95 - S:89.79/1.80, Best-S:90.99, T:90.04/1.33, Best-T:90.48
[11:56:05.955]           - AvgLoss(lb/ulb/all):0.0808/0.0365/0.1535
[11:56:06.492] iteration:16367  t-loss:0.1723, loss-lb:0.0850, loss-ulb:0.0437, weight:2.00, lr:0.0005
[11:56:06.687] iteration:16368  t-loss:0.1377, loss-lb:0.0801, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:56:06.880] iteration:16369  t-loss:0.1483, loss-lb:0.0837, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:56:07.072] iteration:16370  t-loss:0.1468, loss-lb:0.0806, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:56:07.265] iteration:16371  t-loss:0.1279, loss-lb:0.0776, loss-ulb:0.0251, weight:2.00, lr:0.0005
[11:56:07.456] iteration:16372  t-loss:0.1543, loss-lb:0.0861, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:56:07.649] iteration:16373  t-loss:0.1370, loss-lb:0.0765, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:56:07.841] iteration:16374  t-loss:0.1607, loss-lb:0.0807, loss-ulb:0.0400, weight:2.00, lr:0.0005
[11:56:08.032] iteration:16375  t-loss:0.1366, loss-lb:0.0765, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:56:08.225] iteration:16376  t-loss:0.1637, loss-lb:0.0871, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:56:08.416] iteration:16377  t-loss:0.1603, loss-lb:0.0881, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:56:08.608] iteration:16378  t-loss:0.1597, loss-lb:0.0796, loss-ulb:0.0400, weight:2.00, lr:0.0005
[11:56:08.813] iteration:16379  t-loss:0.1576, loss-lb:0.0956, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:56:09.011] iteration:16380  t-loss:0.1416, loss-lb:0.0734, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:56:09.205] iteration:16381  t-loss:0.1548, loss-lb:0.0831, loss-ulb:0.0358, weight:2.00, lr:0.0005
[11:56:09.398] iteration:16382  t-loss:0.1457, loss-lb:0.0844, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:56:09.591] iteration:16383  t-loss:0.1431, loss-lb:0.0821, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:56:09.782] iteration:16384  t-loss:0.1454, loss-lb:0.0811, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:56:09.974] iteration:16385  t-loss:0.1500, loss-lb:0.0878, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:56:10.166] iteration:16386  t-loss:0.1448, loss-lb:0.0785, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:56:10.358] iteration:16387  t-loss:0.1564, loss-lb:0.0831, loss-ulb:0.0367, weight:2.00, lr:0.0005
[11:56:10.551] iteration:16388  t-loss:0.1518, loss-lb:0.0839, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:56:10.744] iteration:16389  t-loss:0.1410, loss-lb:0.0832, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:56:10.936] iteration:16390  t-loss:0.1367, loss-lb:0.0761, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:56:11.127] iteration:16391  t-loss:0.1534, loss-lb:0.0801, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:56:11.320] iteration:16392  t-loss:0.1446, loss-lb:0.0776, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:56:11.511] iteration:16393  t-loss:0.1474, loss-lb:0.0844, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:56:11.703] iteration:16394  t-loss:0.2081, loss-lb:0.0836, loss-ulb:0.0623, weight:2.00, lr:0.0005
[11:56:11.895] iteration:16395  t-loss:0.1412, loss-lb:0.0767, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:56:12.088] iteration:16396  t-loss:0.2279, loss-lb:0.0814, loss-ulb:0.0732, weight:2.00, lr:0.0005
[11:56:12.279] iteration:16397  t-loss:0.1537, loss-lb:0.0872, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:56:12.471] iteration:16398  t-loss:0.1335, loss-lb:0.0792, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:56:12.664] iteration:16399  t-loss:0.1558, loss-lb:0.0728, loss-ulb:0.0415, weight:2.00, lr:0.0005
[11:56:12.856] iteration:16400  t-loss:0.1396, loss-lb:0.0756, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:56:13.048] iteration:16401  t-loss:0.1685, loss-lb:0.0998, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:56:13.242] iteration:16402  t-loss:0.1632, loss-lb:0.0800, loss-ulb:0.0416, weight:2.00, lr:0.0005
[11:56:13.434] iteration:16403  t-loss:0.1432, loss-lb:0.0841, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:56:13.626] iteration:16404  t-loss:0.1473, loss-lb:0.0800, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:56:13.818] iteration:16405  t-loss:0.1456, loss-lb:0.0835, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:56:14.010] iteration:16406  t-loss:0.1514, loss-lb:0.0772, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:56:14.202] iteration:16407  t-loss:0.1918, loss-lb:0.0863, loss-ulb:0.0527, weight:2.00, lr:0.0005
[11:56:14.394] iteration:16408  t-loss:0.2243, loss-lb:0.0946, loss-ulb:0.0648, weight:2.00, lr:0.0005
[11:56:14.586] iteration:16409  t-loss:0.1457, loss-lb:0.0773, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:56:14.780] iteration:16410  t-loss:0.1579, loss-lb:0.0768, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:56:14.973] iteration:16411  t-loss:0.1712, loss-lb:0.0720, loss-ulb:0.0496, weight:2.00, lr:0.0005
[11:56:15.165] iteration:16412  t-loss:0.1862, loss-lb:0.0813, loss-ulb:0.0525, weight:2.00, lr:0.0005
[11:56:15.357] iteration:16413  t-loss:0.1386, loss-lb:0.0819, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:56:15.549] iteration:16414  t-loss:0.1615, loss-lb:0.0742, loss-ulb:0.0437, weight:2.00, lr:0.0005
[11:56:15.742] iteration:16415  t-loss:0.2701, loss-lb:0.0914, loss-ulb:0.0893, weight:2.00, lr:0.0005
[11:56:15.935] iteration:16416  t-loss:0.1415, loss-lb:0.0815, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:56:16.128] iteration:16417  t-loss:0.1642, loss-lb:0.0681, loss-ulb:0.0481, weight:2.00, lr:0.0005
[11:56:16.320] iteration:16418  t-loss:0.1608, loss-lb:0.0792, loss-ulb:0.0408, weight:2.00, lr:0.0005
[11:56:16.512] iteration:16419  t-loss:0.1629, loss-lb:0.0778, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:56:16.704] iteration:16420  t-loss:0.1566, loss-lb:0.0852, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:56:16.897] iteration:16421  t-loss:0.1728, loss-lb:0.0828, loss-ulb:0.0450, weight:2.00, lr:0.0005
[11:56:17.088] iteration:16422  t-loss:0.1601, loss-lb:0.0861, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:56:17.281] iteration:16423  t-loss:0.1669, loss-lb:0.0806, loss-ulb:0.0432, weight:2.00, lr:0.0005
[11:56:17.473] iteration:16424  t-loss:0.1670, loss-lb:0.0867, loss-ulb:0.0402, weight:2.00, lr:0.0005
[11:56:17.666] iteration:16425  t-loss:0.1662, loss-lb:0.0840, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:56:17.857] iteration:16426  t-loss:0.1515, loss-lb:0.0780, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:56:18.050] iteration:16427  t-loss:0.1579, loss-lb:0.0794, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:56:18.242] iteration:16428  t-loss:0.1504, loss-lb:0.0803, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:56:18.434] iteration:16429  t-loss:0.1430, loss-lb:0.0850, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:56:18.627] iteration:16430  t-loss:0.2401, loss-lb:0.0845, loss-ulb:0.0778, weight:2.00, lr:0.0005
[11:56:18.819] iteration:16431  t-loss:0.1944, loss-lb:0.0893, loss-ulb:0.0526, weight:2.00, lr:0.0005
[11:56:19.011] iteration:16432  t-loss:0.1376, loss-lb:0.0797, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:56:19.204] iteration:16433  t-loss:0.1474, loss-lb:0.0797, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:56:19.395] iteration:16434  t-loss:0.1528, loss-lb:0.0870, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:56:19.587] iteration:16435  t-loss:0.1542, loss-lb:0.0847, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:56:19.778] iteration:16436  t-loss:0.1374, loss-lb:0.0769, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:56:19.971] iteration:16437  t-loss:0.1954, loss-lb:0.0864, loss-ulb:0.0545, weight:2.00, lr:0.0005
[11:56:20.163] iteration:16438  t-loss:0.1739, loss-lb:0.0857, loss-ulb:0.0441, weight:2.00, lr:0.0005
[11:56:20.357] iteration:16439  t-loss:0.1627, loss-lb:0.0901, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:56:20.549] iteration:16440  t-loss:0.1538, loss-lb:0.0951, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:56:20.741] iteration:16441  t-loss:0.1600, loss-lb:0.0886, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:56:20.935] iteration:16442  t-loss:0.1912, loss-lb:0.0807, loss-ulb:0.0553, weight:2.00, lr:0.0005
[11:56:21.126] iteration:16443  t-loss:0.1486, loss-lb:0.0872, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:56:21.318] iteration:16444  t-loss:0.1330, loss-lb:0.0740, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:56:21.511] iteration:16445  t-loss:0.1481, loss-lb:0.0829, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:56:21.704] iteration:16446  t-loss:0.1531, loss-lb:0.0793, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:56:21.896] iteration:16447  t-loss:0.1527, loss-lb:0.0751, loss-ulb:0.0388, weight:2.00, lr:0.0005
[11:56:22.088] iteration:16448  t-loss:0.1354, loss-lb:0.0792, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:56:22.282] iteration:16449  t-loss:0.1887, loss-lb:0.0841, loss-ulb:0.0523, weight:2.00, lr:0.0005
[11:56:22.474] iteration:16450  t-loss:0.1420, loss-lb:0.0831, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:56:22.667] iteration:16451  t-loss:0.1461, loss-lb:0.0811, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:56:22.859] iteration:16452  t-loss:0.1402, loss-lb:0.0801, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:56:23.052] iteration:16453  t-loss:0.1539, loss-lb:0.0800, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:56:23.245] iteration:16454  t-loss:0.1537, loss-lb:0.0846, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:56:23.438] iteration:16455  t-loss:0.1500, loss-lb:0.0790, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:56:23.631] iteration:16456  t-loss:0.1397, loss-lb:0.0745, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:56:23.822] iteration:16457  t-loss:0.1588, loss-lb:0.0880, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:56:24.013] iteration:16458  t-loss:0.1451, loss-lb:0.0758, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:56:24.204] iteration:16459  t-loss:0.1858, loss-lb:0.0818, loss-ulb:0.0520, weight:2.00, lr:0.0005
[11:56:24.395] iteration:16460  t-loss:0.1503, loss-lb:0.0825, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:56:24.587] iteration:16461  t-loss:0.1567, loss-lb:0.0790, loss-ulb:0.0389, weight:2.00, lr:0.0005
[11:56:24.777] iteration:16462  t-loss:0.1634, loss-lb:0.0777, loss-ulb:0.0429, weight:2.00, lr:0.0005
[11:56:24.968] iteration:16463  t-loss:0.1520, loss-lb:0.0840, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:56:25.158] iteration:16464  t-loss:0.1516, loss-lb:0.0930, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:56:25.744] iteration:16465  t-loss:0.1400, loss-lb:0.0764, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:56:25.940] iteration:16466  t-loss:0.1596, loss-lb:0.0844, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:56:26.134] iteration:16467  t-loss:0.1628, loss-lb:0.0754, loss-ulb:0.0437, weight:2.00, lr:0.0005
[11:56:26.327] iteration:16468  t-loss:0.1434, loss-lb:0.0847, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:56:26.520] iteration:16469  t-loss:0.1482, loss-lb:0.0840, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:56:26.712] iteration:16470  t-loss:0.1440, loss-lb:0.0821, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:56:26.905] iteration:16471  t-loss:0.1595, loss-lb:0.0885, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:56:27.096] iteration:16472  t-loss:0.1617, loss-lb:0.0780, loss-ulb:0.0418, weight:2.00, lr:0.0005
[11:56:27.289] iteration:16473  t-loss:0.1480, loss-lb:0.0826, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:56:27.482] iteration:16474  t-loss:0.1361, loss-lb:0.0752, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:56:27.674] iteration:16475  t-loss:0.1421, loss-lb:0.0774, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:56:27.866] iteration:16476  t-loss:0.1355, loss-lb:0.0791, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:56:28.059] iteration:16477  t-loss:0.2057, loss-lb:0.0788, loss-ulb:0.0634, weight:2.00, lr:0.0005
[11:56:28.252] iteration:16478  t-loss:0.1604, loss-lb:0.0827, loss-ulb:0.0389, weight:2.00, lr:0.0005
[11:56:28.445] iteration:16479  t-loss:0.1276, loss-lb:0.0710, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:56:28.636] iteration:16480  t-loss:0.1512, loss-lb:0.0831, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:56:28.830] iteration:16481  t-loss:0.1698, loss-lb:0.0903, loss-ulb:0.0398, weight:2.00, lr:0.0005
[11:56:29.025] iteration:16482  t-loss:0.1506, loss-lb:0.0734, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:56:29.221] iteration:16483  t-loss:0.1377, loss-lb:0.0832, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:56:29.416] iteration:16484  t-loss:0.1570, loss-lb:0.0776, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:56:29.609] iteration:16485  t-loss:0.1539, loss-lb:0.0891, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:56:29.800] iteration:16486  t-loss:0.1511, loss-lb:0.0813, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:56:29.992] iteration:16487  t-loss:0.1469, loss-lb:0.0841, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:56:30.183] iteration:16488  t-loss:0.1369, loss-lb:0.0740, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:56:30.376] iteration:16489  t-loss:0.1639, loss-lb:0.0727, loss-ulb:0.0456, weight:2.00, lr:0.0005
[11:56:30.568] iteration:16490  t-loss:0.1649, loss-lb:0.0858, loss-ulb:0.0396, weight:2.00, lr:0.0005
[11:56:30.760] iteration:16491  t-loss:0.1465, loss-lb:0.0798, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:56:30.952] iteration:16492  t-loss:0.2671, loss-lb:0.1084, loss-ulb:0.0793, weight:2.00, lr:0.0005
[11:56:31.144] iteration:16493  t-loss:0.1461, loss-lb:0.0904, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:56:31.336] iteration:16494  t-loss:0.1371, loss-lb:0.0770, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:56:31.527] iteration:16495  t-loss:0.1520, loss-lb:0.0774, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:56:31.720] iteration:16496  t-loss:0.2245, loss-lb:0.0776, loss-ulb:0.0735, weight:2.00, lr:0.0005
[11:56:31.913] iteration:16497  t-loss:0.2052, loss-lb:0.0811, loss-ulb:0.0620, weight:2.00, lr:0.0005
[11:56:32.105] iteration:16498  t-loss:0.1445, loss-lb:0.0826, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:56:32.297] iteration:16499  t-loss:0.1449, loss-lb:0.0748, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:56:32.489] iteration:16500  t-loss:0.1537, loss-lb:0.0885, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:56:32.682] iteration:16501  t-loss:0.1488, loss-lb:0.0854, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:56:32.873] iteration:16502  t-loss:0.1429, loss-lb:0.0849, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:56:33.065] iteration:16503  t-loss:0.1514, loss-lb:0.0771, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:56:33.257] iteration:16504  t-loss:0.1653, loss-lb:0.0839, loss-ulb:0.0407, weight:2.00, lr:0.0005
[11:56:33.449] iteration:16505  t-loss:0.1985, loss-lb:0.0857, loss-ulb:0.0564, weight:2.00, lr:0.0005
[11:56:33.641] iteration:16506  t-loss:0.1599, loss-lb:0.0839, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:56:33.833] iteration:16507  t-loss:0.1736, loss-lb:0.0907, loss-ulb:0.0415, weight:2.00, lr:0.0005
[11:56:34.024] iteration:16508  t-loss:0.2128, loss-lb:0.0885, loss-ulb:0.0622, weight:2.00, lr:0.0005
[11:56:34.217] iteration:16509  t-loss:0.1618, loss-lb:0.0761, loss-ulb:0.0428, weight:2.00, lr:0.0005
[11:56:34.408] iteration:16510  t-loss:0.1401, loss-lb:0.0797, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:56:34.601] iteration:16511  t-loss:0.1306, loss-lb:0.0811, loss-ulb:0.0248, weight:2.00, lr:0.0005
[11:56:34.794] iteration:16512  t-loss:0.1380, loss-lb:0.0737, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:56:34.987] iteration:16513  t-loss:0.1551, loss-lb:0.0925, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:56:35.179] iteration:16514  t-loss:0.1405, loss-lb:0.0799, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:56:35.370] iteration:16515  t-loss:0.1454, loss-lb:0.0798, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:56:35.563] iteration:16516  t-loss:0.1520, loss-lb:0.0879, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:56:35.754] iteration:16517  t-loss:0.1366, loss-lb:0.0815, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:56:35.946] iteration:16518  t-loss:0.2023, loss-lb:0.1352, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:56:36.138] iteration:16519  t-loss:0.1364, loss-lb:0.0708, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:56:36.331] iteration:16520  t-loss:0.1656, loss-lb:0.0854, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:56:36.523] iteration:16521  t-loss:0.1601, loss-lb:0.0822, loss-ulb:0.0389, weight:2.00, lr:0.0005
[11:56:36.716] iteration:16522  t-loss:0.1443, loss-lb:0.0781, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:56:36.908] iteration:16523  t-loss:0.1559, loss-lb:0.0818, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:56:37.101] iteration:16524  t-loss:0.1315, loss-lb:0.0744, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:56:37.293] iteration:16525  t-loss:0.1332, loss-lb:0.0751, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:56:37.485] iteration:16526  t-loss:0.1337, loss-lb:0.0779, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:56:37.677] iteration:16527  t-loss:0.1430, loss-lb:0.0822, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:56:37.868] iteration:16528  t-loss:0.1410, loss-lb:0.0859, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:56:38.060] iteration:16529  t-loss:0.1866, loss-lb:0.0794, loss-ulb:0.0536, weight:2.00, lr:0.0005
[11:56:38.252] iteration:16530  t-loss:0.1473, loss-lb:0.0802, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:56:38.444] iteration:16531  t-loss:0.1388, loss-lb:0.0845, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:56:38.636] iteration:16532  t-loss:0.2406, loss-lb:0.0887, loss-ulb:0.0759, weight:2.00, lr:0.0005
[11:56:38.829] iteration:16533  t-loss:0.2020, loss-lb:0.0921, loss-ulb:0.0549, weight:2.00, lr:0.0005
[11:56:39.020] iteration:16534  t-loss:0.1594, loss-lb:0.0783, loss-ulb:0.0405, weight:2.00, lr:0.0005
[11:56:39.211] iteration:16535  t-loss:0.1480, loss-lb:0.0797, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:56:39.404] iteration:16536  t-loss:0.1343, loss-lb:0.0761, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:56:39.596] iteration:16537  t-loss:0.1510, loss-lb:0.0932, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:56:39.791] iteration:16538  t-loss:0.1990, loss-lb:0.0828, loss-ulb:0.0581, weight:2.00, lr:0.0005
[11:56:39.987] iteration:16539  t-loss:0.1503, loss-lb:0.0812, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:56:40.181] iteration:16540  t-loss:0.3625, loss-lb:0.0860, loss-ulb:0.1383, weight:2.00, lr:0.0005
[11:56:40.376] iteration:16541  t-loss:0.1369, loss-lb:0.0788, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:56:40.569] iteration:16542  t-loss:0.1470, loss-lb:0.0815, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:56:40.760] iteration:16543  t-loss:0.1484, loss-lb:0.0791, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:56:40.956] iteration:16544  t-loss:0.1452, loss-lb:0.0836, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:56:41.147] iteration:16545  t-loss:0.1544, loss-lb:0.0824, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:56:41.336] iteration:16546  t-loss:0.1729, loss-lb:0.0877, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:56:41.535] iteration:16547  t-loss:0.1511, loss-lb:0.0800, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:56:41.742] iteration:16548  t-loss:0.1302, loss-lb:0.0744, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:56:41.934] iteration:16549  t-loss:0.2020, loss-lb:0.0833, loss-ulb:0.0594, weight:2.00, lr:0.0005
[11:56:42.126] iteration:16550  t-loss:0.1832, loss-lb:0.0820, loss-ulb:0.0506, weight:2.00, lr:0.0005
[11:56:42.319] iteration:16551  t-loss:0.1521, loss-lb:0.0819, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:56:42.514] iteration:16552  t-loss:0.1559, loss-lb:0.0787, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:56:42.711] iteration:16553  t-loss:0.1506, loss-lb:0.0836, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:56:42.905] iteration:16554  t-loss:0.1429, loss-lb:0.0835, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:56:43.098] iteration:16555  t-loss:0.1458, loss-lb:0.0809, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:56:43.291] iteration:16556  t-loss:0.1376, loss-lb:0.0763, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:56:43.488] iteration:16557  t-loss:0.1489, loss-lb:0.0854, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:56:43.679] iteration:16558  t-loss:0.1574, loss-lb:0.0859, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:56:43.876] iteration:16559  t-loss:0.1419, loss-lb:0.0781, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:56:44.066] iteration:16560  t-loss:0.1631, loss-lb:0.0874, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:56:44.258] iteration:16561  t-loss:0.1306, loss-lb:0.0759, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:56:44.453] iteration:16562  t-loss:0.1655, loss-lb:0.0740, loss-ulb:0.0458, weight:2.00, lr:0.0005
[11:56:55.818]  <<Test>> - Ep:168  - mean_dice/mean_h95 - S:90.13/1.27, Best-S:90.99, T:90.14/1.32, Best-T:90.48
[11:56:55.819]           - AvgLoss(lb/ulb/all):0.0822/0.0364/0.1540
[11:56:56.344] iteration:16563  t-loss:0.1574, loss-lb:0.0792, loss-ulb:0.0391, weight:2.00, lr:0.0005
[11:56:56.540] iteration:16564  t-loss:0.1316, loss-lb:0.0754, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:56:56.733] iteration:16565  t-loss:0.1389, loss-lb:0.0736, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:56:56.925] iteration:16566  t-loss:0.1453, loss-lb:0.0827, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:56:57.115] iteration:16567  t-loss:0.1497, loss-lb:0.0859, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:56:57.307] iteration:16568  t-loss:0.1687, loss-lb:0.0886, loss-ulb:0.0400, weight:2.00, lr:0.0005
[11:56:57.498] iteration:16569  t-loss:0.1402, loss-lb:0.0792, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:56:57.690] iteration:16570  t-loss:0.1481, loss-lb:0.0793, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:56:57.881] iteration:16571  t-loss:0.1694, loss-lb:0.0815, loss-ulb:0.0439, weight:2.00, lr:0.0005
[11:56:58.074] iteration:16572  t-loss:0.1465, loss-lb:0.0750, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:56:58.265] iteration:16573  t-loss:0.1703, loss-lb:0.0875, loss-ulb:0.0414, weight:2.00, lr:0.0005
[11:56:58.457] iteration:16574  t-loss:0.1688, loss-lb:0.0752, loss-ulb:0.0468, weight:2.00, lr:0.0005
[11:56:58.650] iteration:16575  t-loss:0.1760, loss-lb:0.0760, loss-ulb:0.0500, weight:2.00, lr:0.0005
[11:56:58.841] iteration:16576  t-loss:0.1669, loss-lb:0.0885, loss-ulb:0.0392, weight:2.00, lr:0.0005
[11:56:59.030] iteration:16577  t-loss:0.1489, loss-lb:0.0818, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:56:59.223] iteration:16578  t-loss:0.1647, loss-lb:0.0865, loss-ulb:0.0391, weight:2.00, lr:0.0005
[11:56:59.414] iteration:16579  t-loss:0.1459, loss-lb:0.0832, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:56:59.605] iteration:16580  t-loss:0.1535, loss-lb:0.0828, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:56:59.797] iteration:16581  t-loss:0.1942, loss-lb:0.0906, loss-ulb:0.0518, weight:2.00, lr:0.0005
[11:56:59.988] iteration:16582  t-loss:0.1517, loss-lb:0.0791, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:57:00.179] iteration:16583  t-loss:0.1559, loss-lb:0.0801, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:57:00.369] iteration:16584  t-loss:0.1525, loss-lb:0.0851, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:57:00.560] iteration:16585  t-loss:0.1438, loss-lb:0.0790, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:57:00.753] iteration:16586  t-loss:0.2314, loss-lb:0.0793, loss-ulb:0.0761, weight:2.00, lr:0.0005
[11:57:00.944] iteration:16587  t-loss:0.1523, loss-lb:0.0820, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:57:01.136] iteration:16588  t-loss:0.1327, loss-lb:0.0783, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:57:01.327] iteration:16589  t-loss:0.1296, loss-lb:0.0815, loss-ulb:0.0240, weight:2.00, lr:0.0005
[11:57:01.521] iteration:16590  t-loss:0.1651, loss-lb:0.0826, loss-ulb:0.0412, weight:2.00, lr:0.0005
[11:57:01.717] iteration:16591  t-loss:0.1313, loss-lb:0.0742, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:57:01.912] iteration:16592  t-loss:0.1557, loss-lb:0.0839, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:57:02.106] iteration:16593  t-loss:0.1352, loss-lb:0.0799, loss-ulb:0.0277, weight:2.00, lr:0.0005
[11:57:02.298] iteration:16594  t-loss:0.1418, loss-lb:0.0819, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:57:02.491] iteration:16595  t-loss:0.1492, loss-lb:0.0787, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:57:02.682] iteration:16596  t-loss:0.1428, loss-lb:0.0763, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:57:02.875] iteration:16597  t-loss:0.1353, loss-lb:0.0752, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:57:03.067] iteration:16598  t-loss:0.1425, loss-lb:0.0767, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:57:03.258] iteration:16599  t-loss:0.1540, loss-lb:0.0804, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:57:03.452] iteration:16600  t-loss:0.1301, loss-lb:0.0744, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:57:03.644] iteration:16601  t-loss:0.1577, loss-lb:0.0904, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:57:03.834] iteration:16602  t-loss:0.1315, loss-lb:0.0692, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:57:04.026] iteration:16603  t-loss:0.1417, loss-lb:0.0785, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:57:04.218] iteration:16604  t-loss:0.1955, loss-lb:0.0838, loss-ulb:0.0558, weight:2.00, lr:0.0005
[11:57:04.410] iteration:16605  t-loss:0.1399, loss-lb:0.0796, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:57:04.602] iteration:16606  t-loss:0.1439, loss-lb:0.0808, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:57:04.793] iteration:16607  t-loss:0.1408, loss-lb:0.0805, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:57:04.984] iteration:16608  t-loss:0.2163, loss-lb:0.0781, loss-ulb:0.0691, weight:2.00, lr:0.0005
[11:57:05.177] iteration:16609  t-loss:0.1375, loss-lb:0.0729, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:57:05.369] iteration:16610  t-loss:0.1467, loss-lb:0.0801, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:57:05.561] iteration:16611  t-loss:0.1544, loss-lb:0.0722, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:57:05.752] iteration:16612  t-loss:0.1460, loss-lb:0.0813, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:57:05.943] iteration:16613  t-loss:0.1353, loss-lb:0.0706, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:57:06.135] iteration:16614  t-loss:0.1506, loss-lb:0.0833, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:57:06.328] iteration:16615  t-loss:0.2080, loss-lb:0.0877, loss-ulb:0.0601, weight:2.00, lr:0.0005
[11:57:06.519] iteration:16616  t-loss:0.1661, loss-lb:0.0785, loss-ulb:0.0438, weight:2.00, lr:0.0005
[11:57:06.711] iteration:16617  t-loss:0.1551, loss-lb:0.0812, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:57:06.905] iteration:16618  t-loss:0.1488, loss-lb:0.0866, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:57:07.097] iteration:16619  t-loss:0.1548, loss-lb:0.0860, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:57:07.289] iteration:16620  t-loss:0.1392, loss-lb:0.0747, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:57:07.482] iteration:16621  t-loss:0.1364, loss-lb:0.0740, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:57:07.673] iteration:16622  t-loss:0.1560, loss-lb:0.0825, loss-ulb:0.0367, weight:2.00, lr:0.0005
[11:57:07.866] iteration:16623  t-loss:0.1577, loss-lb:0.0774, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:57:08.059] iteration:16624  t-loss:0.1483, loss-lb:0.0807, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:57:08.251] iteration:16625  t-loss:0.1413, loss-lb:0.0789, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:57:08.442] iteration:16626  t-loss:0.1449, loss-lb:0.0809, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:57:08.635] iteration:16627  t-loss:0.1470, loss-lb:0.0783, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:57:08.826] iteration:16628  t-loss:0.1408, loss-lb:0.0823, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:57:09.018] iteration:16629  t-loss:0.1498, loss-lb:0.0860, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:57:09.210] iteration:16630  t-loss:0.1484, loss-lb:0.0803, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:57:09.402] iteration:16631  t-loss:0.1561, loss-lb:0.0839, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:57:09.594] iteration:16632  t-loss:0.1276, loss-lb:0.0699, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:57:09.786] iteration:16633  t-loss:0.1477, loss-lb:0.0846, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:57:09.977] iteration:16634  t-loss:0.1369, loss-lb:0.0844, loss-ulb:0.0263, weight:2.00, lr:0.0005
[11:57:10.169] iteration:16635  t-loss:0.1590, loss-lb:0.0738, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:57:10.361] iteration:16636  t-loss:0.1401, loss-lb:0.0877, loss-ulb:0.0262, weight:2.00, lr:0.0005
[11:57:10.552] iteration:16637  t-loss:0.1442, loss-lb:0.0725, loss-ulb:0.0359, weight:2.00, lr:0.0005
[11:57:10.743] iteration:16638  t-loss:0.1578, loss-lb:0.0859, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:57:10.934] iteration:16639  t-loss:0.1515, loss-lb:0.0819, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:57:11.127] iteration:16640  t-loss:0.1379, loss-lb:0.0773, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:57:11.317] iteration:16641  t-loss:0.1394, loss-lb:0.0785, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:57:11.509] iteration:16642  t-loss:0.1423, loss-lb:0.0757, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:57:11.701] iteration:16643  t-loss:0.1513, loss-lb:0.0708, loss-ulb:0.0403, weight:2.00, lr:0.0005
[11:57:11.891] iteration:16644  t-loss:0.1519, loss-lb:0.0913, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:57:12.083] iteration:16645  t-loss:0.1457, loss-lb:0.0795, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:57:12.275] iteration:16646  t-loss:0.1378, loss-lb:0.0756, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:57:12.468] iteration:16647  t-loss:0.1496, loss-lb:0.0833, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:57:12.660] iteration:16648  t-loss:0.1339, loss-lb:0.0727, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:57:12.852] iteration:16649  t-loss:0.1430, loss-lb:0.0830, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:57:13.045] iteration:16650  t-loss:0.1418, loss-lb:0.0758, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:57:13.238] iteration:16651  t-loss:0.1435, loss-lb:0.0852, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:57:13.431] iteration:16652  t-loss:0.1887, loss-lb:0.0826, loss-ulb:0.0530, weight:2.00, lr:0.0005
[11:57:13.622] iteration:16653  t-loss:0.1467, loss-lb:0.0773, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:57:13.814] iteration:16654  t-loss:0.1464, loss-lb:0.0802, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:57:14.006] iteration:16655  t-loss:0.1721, loss-lb:0.0789, loss-ulb:0.0466, weight:2.00, lr:0.0005
[11:57:14.198] iteration:16656  t-loss:0.1348, loss-lb:0.0741, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:57:14.400] iteration:16657  t-loss:0.1278, loss-lb:0.0669, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:57:14.597] iteration:16658  t-loss:0.1464, loss-lb:0.0833, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:57:14.791] iteration:16659  t-loss:0.1350, loss-lb:0.0712, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:57:14.981] iteration:16660  t-loss:0.1418, loss-lb:0.0836, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:57:15.577] iteration:16661  t-loss:0.1372, loss-lb:0.0835, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:57:15.772] iteration:16662  t-loss:0.1390, loss-lb:0.0764, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:57:15.967] iteration:16663  t-loss:0.2488, loss-lb:0.0735, loss-ulb:0.0877, weight:2.00, lr:0.0005
[11:57:16.160] iteration:16664  t-loss:0.1589, loss-lb:0.0789, loss-ulb:0.0400, weight:2.00, lr:0.0005
[11:57:16.352] iteration:16665  t-loss:0.1511, loss-lb:0.0876, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:57:16.546] iteration:16666  t-loss:0.1418, loss-lb:0.0800, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:57:16.738] iteration:16667  t-loss:0.1391, loss-lb:0.0778, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:57:16.930] iteration:16668  t-loss:0.1406, loss-lb:0.0787, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:57:17.122] iteration:16669  t-loss:0.1417, loss-lb:0.0742, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:57:17.313] iteration:16670  t-loss:0.1411, loss-lb:0.0722, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:57:17.506] iteration:16671  t-loss:0.1504, loss-lb:0.0812, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:57:17.698] iteration:16672  t-loss:0.1577, loss-lb:0.0832, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:57:17.889] iteration:16673  t-loss:0.1400, loss-lb:0.0817, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:57:18.083] iteration:16674  t-loss:0.1794, loss-lb:0.1090, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:57:18.276] iteration:16675  t-loss:0.1505, loss-lb:0.0800, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:57:18.469] iteration:16676  t-loss:0.1577, loss-lb:0.0756, loss-ulb:0.0410, weight:2.00, lr:0.0005
[11:57:18.661] iteration:16677  t-loss:0.1346, loss-lb:0.0753, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:57:18.853] iteration:16678  t-loss:0.1443, loss-lb:0.0775, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:57:19.046] iteration:16679  t-loss:0.1562, loss-lb:0.0790, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:57:19.238] iteration:16680  t-loss:0.1545, loss-lb:0.0866, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:57:19.430] iteration:16681  t-loss:0.1601, loss-lb:0.0805, loss-ulb:0.0398, weight:2.00, lr:0.0005
[11:57:19.622] iteration:16682  t-loss:0.1379, loss-lb:0.0783, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:57:19.814] iteration:16683  t-loss:0.1376, loss-lb:0.0750, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:57:20.007] iteration:16684  t-loss:0.1489, loss-lb:0.0704, loss-ulb:0.0393, weight:2.00, lr:0.0005
[11:57:20.199] iteration:16685  t-loss:0.1439, loss-lb:0.0804, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:57:20.390] iteration:16686  t-loss:0.1615, loss-lb:0.0846, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:57:20.583] iteration:16687  t-loss:0.1452, loss-lb:0.0763, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:57:20.776] iteration:16688  t-loss:0.1495, loss-lb:0.0750, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:57:20.968] iteration:16689  t-loss:0.1429, loss-lb:0.0762, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:57:21.161] iteration:16690  t-loss:0.1180, loss-lb:0.0734, loss-ulb:0.0223, weight:2.00, lr:0.0005
[11:57:21.354] iteration:16691  t-loss:0.1487, loss-lb:0.0759, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:57:21.546] iteration:16692  t-loss:0.1456, loss-lb:0.0793, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:57:21.738] iteration:16693  t-loss:0.1511, loss-lb:0.0837, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:57:21.931] iteration:16694  t-loss:0.1477, loss-lb:0.0770, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:57:22.124] iteration:16695  t-loss:0.1485, loss-lb:0.0784, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:57:22.316] iteration:16696  t-loss:0.1495, loss-lb:0.0850, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:57:22.508] iteration:16697  t-loss:0.1408, loss-lb:0.0773, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:57:22.702] iteration:16698  t-loss:0.1668, loss-lb:0.0776, loss-ulb:0.0446, weight:2.00, lr:0.0005
[11:57:22.894] iteration:16699  t-loss:0.1481, loss-lb:0.0807, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:57:23.087] iteration:16700  t-loss:0.1529, loss-lb:0.0787, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:57:23.280] iteration:16701  t-loss:0.1608, loss-lb:0.0763, loss-ulb:0.0423, weight:2.00, lr:0.0005
[11:57:23.474] iteration:16702  t-loss:0.1467, loss-lb:0.0792, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:57:23.667] iteration:16703  t-loss:0.1451, loss-lb:0.0817, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:57:23.859] iteration:16704  t-loss:0.1402, loss-lb:0.0782, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:57:24.054] iteration:16705  t-loss:0.1356, loss-lb:0.0784, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:57:24.247] iteration:16706  t-loss:0.1512, loss-lb:0.0813, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:57:24.439] iteration:16707  t-loss:0.1607, loss-lb:0.0936, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:57:24.631] iteration:16708  t-loss:0.1410, loss-lb:0.0791, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:57:24.825] iteration:16709  t-loss:0.1471, loss-lb:0.0804, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:57:25.018] iteration:16710  t-loss:0.1585, loss-lb:0.0826, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:57:25.211] iteration:16711  t-loss:0.1456, loss-lb:0.0731, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:57:25.403] iteration:16712  t-loss:0.1977, loss-lb:0.0858, loss-ulb:0.0559, weight:2.00, lr:0.0005
[11:57:25.596] iteration:16713  t-loss:0.1393, loss-lb:0.0747, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:57:25.788] iteration:16714  t-loss:0.1525, loss-lb:0.0713, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:57:25.980] iteration:16715  t-loss:0.1290, loss-lb:0.0782, loss-ulb:0.0254, weight:2.00, lr:0.0005
[11:57:26.172] iteration:16716  t-loss:0.1481, loss-lb:0.0849, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:57:26.364] iteration:16717  t-loss:0.1427, loss-lb:0.0825, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:57:26.557] iteration:16718  t-loss:0.1365, loss-lb:0.0722, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:57:26.749] iteration:16719  t-loss:0.1452, loss-lb:0.0794, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:57:26.941] iteration:16720  t-loss:0.1522, loss-lb:0.0780, loss-ulb:0.0371, weight:2.00, lr:0.0005
[11:57:27.133] iteration:16721  t-loss:0.1511, loss-lb:0.0940, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:57:27.325] iteration:16722  t-loss:0.1417, loss-lb:0.0817, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:57:27.518] iteration:16723  t-loss:0.1282, loss-lb:0.0721, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:57:27.714] iteration:16724  t-loss:0.1775, loss-lb:0.0773, loss-ulb:0.0501, weight:2.00, lr:0.0005
[11:57:27.905] iteration:16725  t-loss:0.1463, loss-lb:0.0788, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:57:28.097] iteration:16726  t-loss:0.1364, loss-lb:0.0774, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:57:28.291] iteration:16727  t-loss:0.1709, loss-lb:0.0937, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:57:28.484] iteration:16728  t-loss:0.1735, loss-lb:0.0975, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:57:28.678] iteration:16729  t-loss:0.1619, loss-lb:0.0855, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:57:28.871] iteration:16730  t-loss:0.1978, loss-lb:0.0809, loss-ulb:0.0584, weight:2.00, lr:0.0005
[11:57:29.064] iteration:16731  t-loss:0.1611, loss-lb:0.0791, loss-ulb:0.0410, weight:2.00, lr:0.0005
[11:57:29.257] iteration:16732  t-loss:0.1426, loss-lb:0.0770, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:57:29.449] iteration:16733  t-loss:0.1462, loss-lb:0.0768, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:57:29.641] iteration:16734  t-loss:0.1543, loss-lb:0.0905, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:57:29.835] iteration:16735  t-loss:0.1725, loss-lb:0.0767, loss-ulb:0.0479, weight:2.00, lr:0.0005
[11:57:30.027] iteration:16736  t-loss:0.1454, loss-lb:0.0831, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:57:30.219] iteration:16737  t-loss:0.1725, loss-lb:0.0943, loss-ulb:0.0391, weight:2.00, lr:0.0005
[11:57:30.411] iteration:16738  t-loss:0.1351, loss-lb:0.0724, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:57:30.604] iteration:16739  t-loss:0.1439, loss-lb:0.0796, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:57:30.796] iteration:16740  t-loss:0.1428, loss-lb:0.0759, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:57:30.990] iteration:16741  t-loss:0.1948, loss-lb:0.0781, loss-ulb:0.0584, weight:2.00, lr:0.0005
[11:57:31.183] iteration:16742  t-loss:0.1462, loss-lb:0.0898, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:57:31.377] iteration:16743  t-loss:0.1546, loss-lb:0.0850, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:57:31.569] iteration:16744  t-loss:0.1282, loss-lb:0.0722, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:57:31.761] iteration:16745  t-loss:0.1402, loss-lb:0.0772, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:57:31.955] iteration:16746  t-loss:0.1486, loss-lb:0.0825, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:57:32.149] iteration:16747  t-loss:0.1464, loss-lb:0.0825, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:57:32.341] iteration:16748  t-loss:0.1446, loss-lb:0.0721, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:57:32.533] iteration:16749  t-loss:0.1723, loss-lb:0.0846, loss-ulb:0.0438, weight:2.00, lr:0.0005
[11:57:32.726] iteration:16750  t-loss:0.1413, loss-lb:0.0774, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:57:32.917] iteration:16751  t-loss:0.1404, loss-lb:0.0786, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:57:33.108] iteration:16752  t-loss:0.1486, loss-lb:0.0781, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:57:33.299] iteration:16753  t-loss:0.1935, loss-lb:0.0819, loss-ulb:0.0558, weight:2.00, lr:0.0005
[11:57:33.490] iteration:16754  t-loss:0.1446, loss-lb:0.0775, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:57:33.682] iteration:16755  t-loss:0.1337, loss-lb:0.0751, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:57:33.874] iteration:16756  t-loss:0.2303, loss-lb:0.0884, loss-ulb:0.0709, weight:2.00, lr:0.0005
[11:57:34.064] iteration:16757  t-loss:0.1358, loss-lb:0.0768, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:57:34.254] iteration:16758  t-loss:0.1398, loss-lb:0.0716, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:57:46.489]  <<Test>> - Ep:170  - mean_dice/mean_h95 - S:89.97/1.32, Best-S:90.99, T:89.97/1.33, Best-T:90.48
[11:57:46.490]           - AvgLoss(lb/ulb/all):0.0800/0.0372/0.1535
[11:57:47.031] iteration:16759  t-loss:0.1712, loss-lb:0.0813, loss-ulb:0.0449, weight:2.00, lr:0.0005
[11:57:47.231] iteration:16760  t-loss:0.1398, loss-lb:0.0753, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:57:47.422] iteration:16761  t-loss:0.1383, loss-lb:0.0762, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:57:47.611] iteration:16762  t-loss:0.1476, loss-lb:0.0809, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:57:47.799] iteration:16763  t-loss:0.1434, loss-lb:0.0735, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:57:47.988] iteration:16764  t-loss:0.1617, loss-lb:0.0945, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:57:48.177] iteration:16765  t-loss:0.1493, loss-lb:0.0784, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:57:48.366] iteration:16766  t-loss:0.1529, loss-lb:0.0772, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:57:48.554] iteration:16767  t-loss:0.1436, loss-lb:0.0869, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:57:48.743] iteration:16768  t-loss:0.1708, loss-lb:0.0838, loss-ulb:0.0435, weight:2.00, lr:0.0005
[11:57:48.932] iteration:16769  t-loss:0.1445, loss-lb:0.0773, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:57:49.120] iteration:16770  t-loss:0.1754, loss-lb:0.0860, loss-ulb:0.0447, weight:2.00, lr:0.0005
[11:57:49.310] iteration:16771  t-loss:0.1656, loss-lb:0.0765, loss-ulb:0.0446, weight:2.00, lr:0.0005
[11:57:49.499] iteration:16772  t-loss:0.2337, loss-lb:0.0825, loss-ulb:0.0756, weight:2.00, lr:0.0005
[11:57:49.687] iteration:16773  t-loss:0.1524, loss-lb:0.0756, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:57:49.876] iteration:16774  t-loss:0.1448, loss-lb:0.0801, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:57:50.065] iteration:16775  t-loss:0.1637, loss-lb:0.0881, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:57:50.254] iteration:16776  t-loss:0.1504, loss-lb:0.0920, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:57:50.442] iteration:16777  t-loss:0.1472, loss-lb:0.0877, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:57:50.631] iteration:16778  t-loss:0.1587, loss-lb:0.0843, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:57:50.819] iteration:16779  t-loss:0.1359, loss-lb:0.0790, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:57:51.007] iteration:16780  t-loss:0.1431, loss-lb:0.0831, loss-ulb:0.0300, weight:2.00, lr:0.0005
[11:57:51.196] iteration:16781  t-loss:0.1543, loss-lb:0.0914, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:57:51.384] iteration:16782  t-loss:0.1439, loss-lb:0.0796, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:57:51.573] iteration:16783  t-loss:0.1626, loss-lb:0.0792, loss-ulb:0.0417, weight:2.00, lr:0.0005
[11:57:51.761] iteration:16784  t-loss:0.1427, loss-lb:0.0800, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:57:51.949] iteration:16785  t-loss:0.1496, loss-lb:0.0799, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:57:52.138] iteration:16786  t-loss:0.1509, loss-lb:0.0832, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:57:52.327] iteration:16787  t-loss:0.1385, loss-lb:0.0736, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:57:52.515] iteration:16788  t-loss:0.1451, loss-lb:0.0772, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:57:52.704] iteration:16789  t-loss:0.1458, loss-lb:0.0790, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:57:52.892] iteration:16790  t-loss:0.1347, loss-lb:0.0786, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:57:53.081] iteration:16791  t-loss:0.1412, loss-lb:0.0788, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:57:53.269] iteration:16792  t-loss:0.1408, loss-lb:0.0694, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:57:53.458] iteration:16793  t-loss:0.1274, loss-lb:0.0760, loss-ulb:0.0257, weight:2.00, lr:0.0005
[11:57:53.647] iteration:16794  t-loss:0.1528, loss-lb:0.0830, loss-ulb:0.0349, weight:2.00, lr:0.0005
[11:57:53.837] iteration:16795  t-loss:0.1437, loss-lb:0.0834, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:57:54.026] iteration:16796  t-loss:0.1404, loss-lb:0.0759, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:57:54.215] iteration:16797  t-loss:0.1451, loss-lb:0.0836, loss-ulb:0.0308, weight:2.00, lr:0.0005
[11:57:54.404] iteration:16798  t-loss:0.1342, loss-lb:0.0799, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:57:54.593] iteration:16799  t-loss:0.1477, loss-lb:0.0851, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:57:54.782] iteration:16800  t-loss:0.1359, loss-lb:0.0796, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:57:54.971] iteration:16801  t-loss:0.1504, loss-lb:0.0792, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:57:55.160] iteration:16802  t-loss:0.1326, loss-lb:0.0723, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:57:55.350] iteration:16803  t-loss:0.1442, loss-lb:0.0733, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:57:55.538] iteration:16804  t-loss:0.1469, loss-lb:0.0815, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:57:55.727] iteration:16805  t-loss:0.1373, loss-lb:0.0769, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:57:55.915] iteration:16806  t-loss:0.1316, loss-lb:0.0761, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:57:56.104] iteration:16807  t-loss:0.1585, loss-lb:0.0787, loss-ulb:0.0399, weight:2.00, lr:0.0005
[11:57:56.293] iteration:16808  t-loss:0.1440, loss-lb:0.0787, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:57:56.481] iteration:16809  t-loss:0.1400, loss-lb:0.0762, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:57:56.670] iteration:16810  t-loss:0.1391, loss-lb:0.0788, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:57:56.859] iteration:16811  t-loss:0.1757, loss-lb:0.0877, loss-ulb:0.0440, weight:2.00, lr:0.0005
[11:57:57.047] iteration:16812  t-loss:0.1836, loss-lb:0.0786, loss-ulb:0.0525, weight:2.00, lr:0.0005
[11:57:57.236] iteration:16813  t-loss:0.1345, loss-lb:0.0711, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:57:57.425] iteration:16814  t-loss:0.1458, loss-lb:0.0812, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:57:57.614] iteration:16815  t-loss:0.1587, loss-lb:0.0796, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:57:57.803] iteration:16816  t-loss:0.1550, loss-lb:0.0761, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:57:57.992] iteration:16817  t-loss:0.1512, loss-lb:0.0761, loss-ulb:0.0376, weight:2.00, lr:0.0005
[11:57:58.181] iteration:16818  t-loss:0.1464, loss-lb:0.0784, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:57:58.370] iteration:16819  t-loss:0.1612, loss-lb:0.0811, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:57:58.559] iteration:16820  t-loss:0.1544, loss-lb:0.0775, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:57:58.748] iteration:16821  t-loss:0.1400, loss-lb:0.0813, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:57:58.937] iteration:16822  t-loss:0.1364, loss-lb:0.0818, loss-ulb:0.0273, weight:2.00, lr:0.0005
[11:57:59.126] iteration:16823  t-loss:0.1438, loss-lb:0.0828, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:57:59.314] iteration:16824  t-loss:0.1394, loss-lb:0.0779, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:57:59.503] iteration:16825  t-loss:0.1388, loss-lb:0.0781, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:57:59.693] iteration:16826  t-loss:0.1470, loss-lb:0.0760, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:57:59.883] iteration:16827  t-loss:0.1581, loss-lb:0.0816, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:58:00.072] iteration:16828  t-loss:0.1374, loss-lb:0.0760, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:58:00.261] iteration:16829  t-loss:0.1487, loss-lb:0.0822, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:58:00.449] iteration:16830  t-loss:0.1569, loss-lb:0.0845, loss-ulb:0.0362, weight:2.00, lr:0.0005
[11:58:00.639] iteration:16831  t-loss:0.1337, loss-lb:0.0785, loss-ulb:0.0276, weight:2.00, lr:0.0005
[11:58:00.828] iteration:16832  t-loss:0.1441, loss-lb:0.0803, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:58:01.018] iteration:16833  t-loss:0.1453, loss-lb:0.0783, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:58:01.208] iteration:16834  t-loss:0.1585, loss-lb:0.0925, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:58:01.397] iteration:16835  t-loss:0.1424, loss-lb:0.0798, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:58:01.587] iteration:16836  t-loss:0.1432, loss-lb:0.0793, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:58:01.776] iteration:16837  t-loss:0.1509, loss-lb:0.0789, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:58:01.966] iteration:16838  t-loss:0.1383, loss-lb:0.0720, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:58:02.155] iteration:16839  t-loss:0.1327, loss-lb:0.0751, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:58:02.349] iteration:16840  t-loss:0.2449, loss-lb:0.0854, loss-ulb:0.0797, weight:2.00, lr:0.0005
[11:58:02.547] iteration:16841  t-loss:0.1572, loss-lb:0.0848, loss-ulb:0.0362, weight:2.00, lr:0.0005
[11:58:02.741] iteration:16842  t-loss:0.1382, loss-lb:0.0755, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:58:02.936] iteration:16843  t-loss:0.1474, loss-lb:0.0761, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:58:03.127] iteration:16844  t-loss:0.1352, loss-lb:0.0729, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:58:03.320] iteration:16845  t-loss:0.2728, loss-lb:0.0748, loss-ulb:0.0990, weight:2.00, lr:0.0005
[11:58:03.514] iteration:16846  t-loss:0.1627, loss-lb:0.0763, loss-ulb:0.0432, weight:2.00, lr:0.0005
[11:58:03.708] iteration:16847  t-loss:0.1640, loss-lb:0.0818, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:58:03.899] iteration:16848  t-loss:0.1482, loss-lb:0.0872, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:58:04.091] iteration:16849  t-loss:0.1366, loss-lb:0.0806, loss-ulb:0.0280, weight:2.00, lr:0.0005
[11:58:04.282] iteration:16850  t-loss:0.1495, loss-lb:0.0759, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:58:04.472] iteration:16851  t-loss:0.1462, loss-lb:0.0731, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:58:04.662] iteration:16852  t-loss:0.1469, loss-lb:0.0823, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:58:04.855] iteration:16853  t-loss:0.1391, loss-lb:0.0807, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:58:05.047] iteration:16854  t-loss:0.1336, loss-lb:0.0756, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:58:05.238] iteration:16855  t-loss:0.1501, loss-lb:0.0769, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:58:05.428] iteration:16856  t-loss:0.1474, loss-lb:0.0844, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:58:06.003] iteration:16857  t-loss:0.1479, loss-lb:0.0787, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:58:06.198] iteration:16858  t-loss:0.1462, loss-lb:0.0810, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:58:06.391] iteration:16859  t-loss:0.1409, loss-lb:0.0776, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:58:06.583] iteration:16860  t-loss:0.1379, loss-lb:0.0777, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:58:06.777] iteration:16861  t-loss:0.1568, loss-lb:0.0824, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:58:06.969] iteration:16862  t-loss:0.1546, loss-lb:0.0898, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:58:07.160] iteration:16863  t-loss:0.1461, loss-lb:0.0813, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:58:07.353] iteration:16864  t-loss:0.1430, loss-lb:0.0771, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:58:07.545] iteration:16865  t-loss:0.1350, loss-lb:0.0706, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:58:07.736] iteration:16866  t-loss:0.1396, loss-lb:0.0744, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:58:07.929] iteration:16867  t-loss:0.1628, loss-lb:0.0833, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:58:08.122] iteration:16868  t-loss:0.1440, loss-lb:0.0740, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:58:08.314] iteration:16869  t-loss:0.1516, loss-lb:0.0795, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:58:08.506] iteration:16870  t-loss:0.1573, loss-lb:0.0817, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:58:08.699] iteration:16871  t-loss:0.1447, loss-lb:0.0762, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:58:08.892] iteration:16872  t-loss:0.1382, loss-lb:0.0742, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:58:09.083] iteration:16873  t-loss:0.1426, loss-lb:0.0799, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:58:09.275] iteration:16874  t-loss:0.1500, loss-lb:0.0851, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:58:09.468] iteration:16875  t-loss:0.1862, loss-lb:0.0787, loss-ulb:0.0538, weight:2.00, lr:0.0005
[11:58:09.660] iteration:16876  t-loss:0.1539, loss-lb:0.0798, loss-ulb:0.0370, weight:2.00, lr:0.0005
[11:58:09.852] iteration:16877  t-loss:0.1428, loss-lb:0.0804, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:58:10.046] iteration:16878  t-loss:0.1799, loss-lb:0.0819, loss-ulb:0.0490, weight:2.00, lr:0.0005
[11:58:10.239] iteration:16879  t-loss:0.1414, loss-lb:0.0769, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:58:10.430] iteration:16880  t-loss:0.1473, loss-lb:0.0738, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:58:10.622] iteration:16881  t-loss:0.1660, loss-lb:0.0949, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:58:10.814] iteration:16882  t-loss:0.1384, loss-lb:0.0812, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:58:11.006] iteration:16883  t-loss:0.1454, loss-lb:0.0849, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:58:11.197] iteration:16884  t-loss:0.1608, loss-lb:0.0797, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:58:11.390] iteration:16885  t-loss:0.2247, loss-lb:0.0824, loss-ulb:0.0711, weight:2.00, lr:0.0005
[11:58:11.582] iteration:16886  t-loss:0.1404, loss-lb:0.0766, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:58:11.774] iteration:16887  t-loss:0.1400, loss-lb:0.0777, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:58:11.966] iteration:16888  t-loss:0.1397, loss-lb:0.0745, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:58:12.159] iteration:16889  t-loss:0.1478, loss-lb:0.0848, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:58:12.351] iteration:16890  t-loss:0.2396, loss-lb:0.0907, loss-ulb:0.0744, weight:2.00, lr:0.0005
[11:58:12.545] iteration:16891  t-loss:0.1678, loss-lb:0.0801, loss-ulb:0.0439, weight:2.00, lr:0.0005
[11:58:12.738] iteration:16892  t-loss:0.1477, loss-lb:0.0955, loss-ulb:0.0261, weight:2.00, lr:0.0005
[11:58:12.931] iteration:16893  t-loss:0.1663, loss-lb:0.0743, loss-ulb:0.0460, weight:2.00, lr:0.0005
[11:58:13.124] iteration:16894  t-loss:0.1378, loss-lb:0.0774, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:58:13.319] iteration:16895  t-loss:0.1608, loss-lb:0.0798, loss-ulb:0.0405, weight:2.00, lr:0.0005
[11:58:13.513] iteration:16896  t-loss:0.1363, loss-lb:0.0796, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:58:13.709] iteration:16897  t-loss:0.1487, loss-lb:0.0782, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:58:13.902] iteration:16898  t-loss:0.1509, loss-lb:0.0842, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:58:14.096] iteration:16899  t-loss:0.1515, loss-lb:0.0850, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:58:14.287] iteration:16900  t-loss:0.1396, loss-lb:0.0793, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:58:14.479] iteration:16901  t-loss:0.1493, loss-lb:0.0712, loss-ulb:0.0391, weight:2.00, lr:0.0005
[11:58:14.673] iteration:16902  t-loss:0.1411, loss-lb:0.0766, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:58:14.865] iteration:16903  t-loss:0.1398, loss-lb:0.0750, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:58:15.058] iteration:16904  t-loss:0.1617, loss-lb:0.0805, loss-ulb:0.0406, weight:2.00, lr:0.0005
[11:58:15.250] iteration:16905  t-loss:0.1680, loss-lb:0.0816, loss-ulb:0.0432, weight:2.00, lr:0.0005
[11:58:15.442] iteration:16906  t-loss:0.1422, loss-lb:0.0830, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:58:15.634] iteration:16907  t-loss:0.1435, loss-lb:0.0861, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:58:15.826] iteration:16908  t-loss:0.1528, loss-lb:0.0801, loss-ulb:0.0364, weight:2.00, lr:0.0005
[11:58:16.020] iteration:16909  t-loss:0.1396, loss-lb:0.0799, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:58:16.212] iteration:16910  t-loss:0.1364, loss-lb:0.0766, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:58:16.404] iteration:16911  t-loss:0.1322, loss-lb:0.0718, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:58:16.596] iteration:16912  t-loss:0.1481, loss-lb:0.0847, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:58:16.788] iteration:16913  t-loss:0.1527, loss-lb:0.0849, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:58:16.981] iteration:16914  t-loss:0.1497, loss-lb:0.0718, loss-ulb:0.0390, weight:2.00, lr:0.0005
[11:58:17.173] iteration:16915  t-loss:0.2019, loss-lb:0.0741, loss-ulb:0.0639, weight:2.00, lr:0.0005
[11:58:17.365] iteration:16916  t-loss:0.1479, loss-lb:0.0770, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:58:17.558] iteration:16917  t-loss:0.1582, loss-lb:0.0768, loss-ulb:0.0407, weight:2.00, lr:0.0005
[11:58:17.750] iteration:16918  t-loss:0.1303, loss-lb:0.0713, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:58:17.942] iteration:16919  t-loss:0.1574, loss-lb:0.0806, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:58:18.134] iteration:16920  t-loss:0.1415, loss-lb:0.0762, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:58:18.326] iteration:16921  t-loss:0.1370, loss-lb:0.0758, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:58:18.519] iteration:16922  t-loss:0.1548, loss-lb:0.0795, loss-ulb:0.0377, weight:2.00, lr:0.0005
[11:58:18.710] iteration:16923  t-loss:0.1425, loss-lb:0.0812, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:58:18.903] iteration:16924  t-loss:0.2030, loss-lb:0.0919, loss-ulb:0.0556, weight:2.00, lr:0.0005
[11:58:19.096] iteration:16925  t-loss:0.1607, loss-lb:0.1020, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:58:19.288] iteration:16926  t-loss:0.1303, loss-lb:0.0710, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:58:19.480] iteration:16927  t-loss:0.1783, loss-lb:0.0757, loss-ulb:0.0513, weight:2.00, lr:0.0005
[11:58:19.671] iteration:16928  t-loss:0.1325, loss-lb:0.0769, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:58:19.876] iteration:16929  t-loss:0.1477, loss-lb:0.0880, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:58:20.075] iteration:16930  t-loss:0.1779, loss-lb:0.0817, loss-ulb:0.0481, weight:2.00, lr:0.0005
[11:58:20.270] iteration:16931  t-loss:0.1588, loss-lb:0.0799, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:58:20.462] iteration:16932  t-loss:0.1556, loss-lb:0.0932, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:58:20.655] iteration:16933  t-loss:0.1752, loss-lb:0.0871, loss-ulb:0.0440, weight:2.00, lr:0.0005
[11:58:20.847] iteration:16934  t-loss:0.1613, loss-lb:0.0899, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:58:21.040] iteration:16935  t-loss:0.1389, loss-lb:0.0745, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:58:21.231] iteration:16936  t-loss:0.1629, loss-lb:0.0859, loss-ulb:0.0385, weight:2.00, lr:0.0005
[11:58:21.423] iteration:16937  t-loss:0.1448, loss-lb:0.0741, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:58:21.614] iteration:16938  t-loss:0.1513, loss-lb:0.0826, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:58:21.807] iteration:16939  t-loss:0.1449, loss-lb:0.0855, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:58:21.998] iteration:16940  t-loss:0.1449, loss-lb:0.0745, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:58:22.189] iteration:16941  t-loss:0.2021, loss-lb:0.0810, loss-ulb:0.0605, weight:2.00, lr:0.0005
[11:58:22.381] iteration:16942  t-loss:0.1409, loss-lb:0.0836, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:58:22.573] iteration:16943  t-loss:0.1632, loss-lb:0.0860, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:58:22.765] iteration:16944  t-loss:0.1556, loss-lb:0.0798, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:58:22.956] iteration:16945  t-loss:0.1585, loss-lb:0.0995, loss-ulb:0.0295, weight:2.00, lr:0.0005
[11:58:23.147] iteration:16946  t-loss:0.1412, loss-lb:0.0905, loss-ulb:0.0253, weight:2.00, lr:0.0005
[11:58:23.337] iteration:16947  t-loss:0.1447, loss-lb:0.0838, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:58:23.527] iteration:16948  t-loss:0.1838, loss-lb:0.0893, loss-ulb:0.0472, weight:2.00, lr:0.0005
[11:58:23.718] iteration:16949  t-loss:0.1649, loss-lb:0.0920, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:58:23.909] iteration:16950  t-loss:0.1589, loss-lb:0.0826, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:58:24.101] iteration:16951  t-loss:0.1612, loss-lb:0.1015, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:58:24.295] iteration:16952  t-loss:0.1382, loss-lb:0.0779, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:58:24.488] iteration:16953  t-loss:0.1806, loss-lb:0.0761, loss-ulb:0.0522, weight:2.00, lr:0.0005
[11:58:24.679] iteration:16954  t-loss:0.1588, loss-lb:0.0823, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:58:36.077]  <<Test>> - Ep:172  - mean_dice/mean_h95 - S:90.15/1.27, Best-S:90.99, T:89.94/1.35, Best-T:90.48
[11:58:36.077]           - AvgLoss(lb/ulb/all):0.0812/0.0364/0.1570
[11:58:36.596] iteration:16955  t-loss:0.1491, loss-lb:0.0838, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:58:36.794] iteration:16956  t-loss:0.1465, loss-lb:0.0808, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:58:36.987] iteration:16957  t-loss:0.1605, loss-lb:0.0810, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:58:37.180] iteration:16958  t-loss:0.1598, loss-lb:0.0881, loss-ulb:0.0358, weight:2.00, lr:0.0005
[11:58:37.373] iteration:16959  t-loss:0.1475, loss-lb:0.0901, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:58:37.566] iteration:16960  t-loss:0.1574, loss-lb:0.0766, loss-ulb:0.0404, weight:2.00, lr:0.0005
[11:58:37.758] iteration:16961  t-loss:0.1505, loss-lb:0.0804, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:58:37.952] iteration:16962  t-loss:0.1823, loss-lb:0.0803, loss-ulb:0.0510, weight:2.00, lr:0.0005
[11:58:38.146] iteration:16963  t-loss:0.1390, loss-lb:0.0804, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:58:38.338] iteration:16964  t-loss:0.1531, loss-lb:0.0856, loss-ulb:0.0338, weight:2.00, lr:0.0005
[11:58:38.531] iteration:16965  t-loss:0.1613, loss-lb:0.0811, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:58:38.724] iteration:16966  t-loss:0.1868, loss-lb:0.0831, loss-ulb:0.0518, weight:2.00, lr:0.0005
[11:58:38.916] iteration:16967  t-loss:0.1679, loss-lb:0.0998, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:58:39.110] iteration:16968  t-loss:0.1558, loss-lb:0.0847, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:58:39.304] iteration:16969  t-loss:0.1850, loss-lb:0.0866, loss-ulb:0.0492, weight:2.00, lr:0.0005
[11:58:39.496] iteration:16970  t-loss:0.1708, loss-lb:0.0792, loss-ulb:0.0458, weight:2.00, lr:0.0005
[11:58:39.689] iteration:16971  t-loss:0.1717, loss-lb:0.0782, loss-ulb:0.0467, weight:2.00, lr:0.0005
[11:58:39.882] iteration:16972  t-loss:0.1901, loss-lb:0.0765, loss-ulb:0.0568, weight:2.00, lr:0.0005
[11:58:40.074] iteration:16973  t-loss:0.1434, loss-lb:0.0876, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:58:40.267] iteration:16974  t-loss:0.2081, loss-lb:0.0911, loss-ulb:0.0585, weight:2.00, lr:0.0005
[11:58:40.460] iteration:16975  t-loss:0.1530, loss-lb:0.0843, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:58:40.651] iteration:16976  t-loss:0.1524, loss-lb:0.0831, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:58:40.844] iteration:16977  t-loss:0.1681, loss-lb:0.0806, loss-ulb:0.0438, weight:2.00, lr:0.0005
[11:58:41.037] iteration:16978  t-loss:0.1643, loss-lb:0.0983, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:58:41.229] iteration:16979  t-loss:0.1464, loss-lb:0.0732, loss-ulb:0.0366, weight:2.00, lr:0.0005
[11:58:41.420] iteration:16980  t-loss:0.1427, loss-lb:0.0849, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:58:41.613] iteration:16981  t-loss:0.1663, loss-lb:0.0802, loss-ulb:0.0430, weight:2.00, lr:0.0005
[11:58:41.805] iteration:16982  t-loss:0.1510, loss-lb:0.0789, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:58:41.998] iteration:16983  t-loss:0.1629, loss-lb:0.0834, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:58:42.192] iteration:16984  t-loss:0.1638, loss-lb:0.0773, loss-ulb:0.0432, weight:2.00, lr:0.0005
[11:58:42.387] iteration:16985  t-loss:0.1472, loss-lb:0.0785, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:58:42.580] iteration:16986  t-loss:0.1854, loss-lb:0.0875, loss-ulb:0.0489, weight:2.00, lr:0.0005
[11:58:42.772] iteration:16987  t-loss:0.2846, loss-lb:0.0852, loss-ulb:0.0997, weight:2.00, lr:0.0005
[11:58:42.965] iteration:16988  t-loss:0.1486, loss-lb:0.0817, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:58:43.157] iteration:16989  t-loss:0.1687, loss-lb:0.0803, loss-ulb:0.0442, weight:2.00, lr:0.0005
[11:58:43.347] iteration:16990  t-loss:0.1525, loss-lb:0.0917, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:58:43.538] iteration:16991  t-loss:0.1394, loss-lb:0.0822, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:58:43.730] iteration:16992  t-loss:0.1313, loss-lb:0.0780, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:58:43.921] iteration:16993  t-loss:0.1508, loss-lb:0.0821, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:58:44.113] iteration:16994  t-loss:0.1824, loss-lb:0.0907, loss-ulb:0.0458, weight:2.00, lr:0.0005
[11:58:44.305] iteration:16995  t-loss:0.1633, loss-lb:0.0876, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:58:44.497] iteration:16996  t-loss:0.2120, loss-lb:0.0797, loss-ulb:0.0661, weight:2.00, lr:0.0005
[11:58:44.689] iteration:16997  t-loss:0.1934, loss-lb:0.0786, loss-ulb:0.0574, weight:2.00, lr:0.0005
[11:58:44.880] iteration:16998  t-loss:0.1513, loss-lb:0.0859, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:58:45.071] iteration:16999  t-loss:0.1412, loss-lb:0.0702, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:58:45.264] iteration:17000  t-loss:0.2223, loss-lb:0.0779, loss-ulb:0.0722, weight:2.00, lr:0.0005
[11:58:45.455] iteration:17001  t-loss:0.1507, loss-lb:0.0776, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:58:45.648] iteration:17002  t-loss:0.1913, loss-lb:0.0765, loss-ulb:0.0574, weight:2.00, lr:0.0005
[11:58:45.840] iteration:17003  t-loss:0.1830, loss-lb:0.0941, loss-ulb:0.0445, weight:2.00, lr:0.0005
[11:58:46.033] iteration:17004  t-loss:0.2019, loss-lb:0.0841, loss-ulb:0.0589, weight:2.00, lr:0.0005
[11:58:46.228] iteration:17005  t-loss:0.1549, loss-lb:0.0801, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:58:46.420] iteration:17006  t-loss:0.1671, loss-lb:0.0856, loss-ulb:0.0408, weight:2.00, lr:0.0005
[11:58:46.613] iteration:17007  t-loss:0.1762, loss-lb:0.0781, loss-ulb:0.0491, weight:2.00, lr:0.0005
[11:58:46.805] iteration:17008  t-loss:0.1684, loss-lb:0.0729, loss-ulb:0.0478, weight:2.00, lr:0.0005
[11:58:46.998] iteration:17009  t-loss:0.1493, loss-lb:0.0757, loss-ulb:0.0368, weight:2.00, lr:0.0005
[11:58:47.191] iteration:17010  t-loss:0.1538, loss-lb:0.0901, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:58:47.383] iteration:17011  t-loss:0.1964, loss-lb:0.0881, loss-ulb:0.0541, weight:2.00, lr:0.0005
[11:58:47.574] iteration:17012  t-loss:0.1611, loss-lb:0.1012, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:58:47.767] iteration:17013  t-loss:0.1481, loss-lb:0.0845, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:58:47.959] iteration:17014  t-loss:0.1609, loss-lb:0.0895, loss-ulb:0.0357, weight:2.00, lr:0.0005
[11:58:48.151] iteration:17015  t-loss:0.1475, loss-lb:0.0832, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:58:48.343] iteration:17016  t-loss:0.1429, loss-lb:0.0801, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:58:48.536] iteration:17017  t-loss:0.1434, loss-lb:0.0743, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:58:48.729] iteration:17018  t-loss:0.1452, loss-lb:0.0830, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:58:48.922] iteration:17019  t-loss:0.1555, loss-lb:0.0889, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:58:49.114] iteration:17020  t-loss:0.1554, loss-lb:0.0771, loss-ulb:0.0391, weight:2.00, lr:0.0005
[11:58:49.307] iteration:17021  t-loss:0.1444, loss-lb:0.0851, loss-ulb:0.0296, weight:2.00, lr:0.0005
[11:58:49.499] iteration:17022  t-loss:0.1416, loss-lb:0.0817, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:58:49.692] iteration:17023  t-loss:0.1520, loss-lb:0.0813, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:58:49.884] iteration:17024  t-loss:0.1611, loss-lb:0.0814, loss-ulb:0.0399, weight:2.00, lr:0.0005
[11:58:50.076] iteration:17025  t-loss:0.1469, loss-lb:0.0799, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:58:50.269] iteration:17026  t-loss:0.1382, loss-lb:0.0770, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:58:50.461] iteration:17027  t-loss:0.1461, loss-lb:0.0838, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:58:50.653] iteration:17028  t-loss:0.1328, loss-lb:0.0787, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:58:50.845] iteration:17029  t-loss:0.1435, loss-lb:0.0791, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:58:51.037] iteration:17030  t-loss:0.1321, loss-lb:0.0770, loss-ulb:0.0275, weight:2.00, lr:0.0005
[11:58:51.230] iteration:17031  t-loss:0.1382, loss-lb:0.0772, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:58:51.421] iteration:17032  t-loss:0.1577, loss-lb:0.0875, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:58:51.614] iteration:17033  t-loss:0.1405, loss-lb:0.0834, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:58:51.807] iteration:17034  t-loss:0.1509, loss-lb:0.0748, loss-ulb:0.0381, weight:2.00, lr:0.0005
[11:58:51.998] iteration:17035  t-loss:0.1418, loss-lb:0.0806, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:58:52.191] iteration:17036  t-loss:0.1300, loss-lb:0.0720, loss-ulb:0.0290, weight:2.00, lr:0.0005
[11:58:52.384] iteration:17037  t-loss:0.1431, loss-lb:0.0805, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:58:52.582] iteration:17038  t-loss:0.1400, loss-lb:0.0751, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:58:52.787] iteration:17039  t-loss:0.1432, loss-lb:0.0830, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:58:52.984] iteration:17040  t-loss:0.1563, loss-lb:0.0761, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:58:53.177] iteration:17041  t-loss:0.1465, loss-lb:0.0896, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:58:53.369] iteration:17042  t-loss:0.1582, loss-lb:0.0779, loss-ulb:0.0401, weight:2.00, lr:0.0005
[11:58:53.561] iteration:17043  t-loss:0.1546, loss-lb:0.0970, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:58:53.753] iteration:17044  t-loss:0.1299, loss-lb:0.0776, loss-ulb:0.0261, weight:2.00, lr:0.0005
[11:58:53.945] iteration:17045  t-loss:0.1641, loss-lb:0.0799, loss-ulb:0.0421, weight:2.00, lr:0.0005
[11:58:54.136] iteration:17046  t-loss:0.1428, loss-lb:0.0790, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:58:54.326] iteration:17047  t-loss:0.1466, loss-lb:0.0785, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:58:54.517] iteration:17048  t-loss:0.1490, loss-lb:0.0813, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:58:54.708] iteration:17049  t-loss:0.1485, loss-lb:0.0794, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:58:54.899] iteration:17050  t-loss:0.1626, loss-lb:0.0800, loss-ulb:0.0413, weight:2.00, lr:0.0005
[11:58:55.090] iteration:17051  t-loss:0.1346, loss-lb:0.0713, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:58:55.281] iteration:17052  t-loss:0.1340, loss-lb:0.0751, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:58:55.864] iteration:17053  t-loss:0.1689, loss-lb:0.0872, loss-ulb:0.0409, weight:2.00, lr:0.0005
[11:58:56.060] iteration:17054  t-loss:0.1412, loss-lb:0.0731, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:58:56.252] iteration:17055  t-loss:0.1507, loss-lb:0.0752, loss-ulb:0.0377, weight:2.00, lr:0.0005
[11:58:56.445] iteration:17056  t-loss:0.1496, loss-lb:0.0853, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:58:56.637] iteration:17057  t-loss:0.1455, loss-lb:0.0852, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:58:56.829] iteration:17058  t-loss:0.1418, loss-lb:0.0773, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:58:57.022] iteration:17059  t-loss:0.1459, loss-lb:0.0824, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:58:57.214] iteration:17060  t-loss:0.1414, loss-lb:0.0777, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:58:57.406] iteration:17061  t-loss:0.1501, loss-lb:0.0771, loss-ulb:0.0365, weight:2.00, lr:0.0005
[11:58:57.599] iteration:17062  t-loss:0.1457, loss-lb:0.0850, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:58:57.791] iteration:17063  t-loss:0.1427, loss-lb:0.0777, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:58:57.983] iteration:17064  t-loss:0.1350, loss-lb:0.0739, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:58:58.175] iteration:17065  t-loss:0.1469, loss-lb:0.0764, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:58:58.367] iteration:17066  t-loss:0.1366, loss-lb:0.0829, loss-ulb:0.0269, weight:2.00, lr:0.0005
[11:58:58.558] iteration:17067  t-loss:0.1394, loss-lb:0.0751, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:58:58.750] iteration:17068  t-loss:0.1390, loss-lb:0.0823, loss-ulb:0.0283, weight:2.00, lr:0.0005
[11:58:58.944] iteration:17069  t-loss:0.1470, loss-lb:0.0826, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:58:59.136] iteration:17070  t-loss:0.1672, loss-lb:0.0806, loss-ulb:0.0433, weight:2.00, lr:0.0005
[11:58:59.328] iteration:17071  t-loss:0.1434, loss-lb:0.0822, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:58:59.520] iteration:17072  t-loss:0.1425, loss-lb:0.0850, loss-ulb:0.0287, weight:2.00, lr:0.0005
[11:58:59.712] iteration:17073  t-loss:0.1463, loss-lb:0.0806, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:58:59.904] iteration:17074  t-loss:0.1433, loss-lb:0.0823, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:59:00.097] iteration:17075  t-loss:0.1643, loss-lb:0.0753, loss-ulb:0.0445, weight:2.00, lr:0.0005
[11:59:00.289] iteration:17076  t-loss:0.1372, loss-lb:0.0741, loss-ulb:0.0315, weight:2.00, lr:0.0005
[11:59:00.481] iteration:17077  t-loss:0.1440, loss-lb:0.0799, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:59:00.674] iteration:17078  t-loss:0.1434, loss-lb:0.0753, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:59:00.866] iteration:17079  t-loss:0.1585, loss-lb:0.0795, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:59:01.058] iteration:17080  t-loss:0.1506, loss-lb:0.0823, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:59:01.251] iteration:17081  t-loss:0.1338, loss-lb:0.0756, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:59:01.444] iteration:17082  t-loss:0.1426, loss-lb:0.0739, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:59:01.636] iteration:17083  t-loss:0.1625, loss-lb:0.0798, loss-ulb:0.0414, weight:2.00, lr:0.0005
[11:59:01.829] iteration:17084  t-loss:0.1481, loss-lb:0.0826, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:59:02.021] iteration:17085  t-loss:0.1680, loss-lb:0.0777, loss-ulb:0.0451, weight:2.00, lr:0.0005
[11:59:02.214] iteration:17086  t-loss:0.1420, loss-lb:0.0778, loss-ulb:0.0321, weight:2.00, lr:0.0005
[11:59:02.406] iteration:17087  t-loss:0.1467, loss-lb:0.0849, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:59:02.599] iteration:17088  t-loss:0.1366, loss-lb:0.0765, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:59:02.791] iteration:17089  t-loss:0.1366, loss-lb:0.0791, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:59:02.983] iteration:17090  t-loss:0.1429, loss-lb:0.0775, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:59:03.175] iteration:17091  t-loss:0.1373, loss-lb:0.0746, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:59:03.367] iteration:17092  t-loss:0.1509, loss-lb:0.0837, loss-ulb:0.0336, weight:2.00, lr:0.0005
[11:59:03.559] iteration:17093  t-loss:0.1348, loss-lb:0.0753, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:59:03.752] iteration:17094  t-loss:0.2200, loss-lb:0.0872, loss-ulb:0.0664, weight:2.00, lr:0.0005
[11:59:03.945] iteration:17095  t-loss:0.1558, loss-lb:0.0814, loss-ulb:0.0372, weight:2.00, lr:0.0005
[11:59:04.138] iteration:17096  t-loss:0.1404, loss-lb:0.0742, loss-ulb:0.0331, weight:2.00, lr:0.0005
[11:59:04.332] iteration:17097  t-loss:0.1343, loss-lb:0.0722, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:59:04.525] iteration:17098  t-loss:0.1380, loss-lb:0.0792, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:59:04.717] iteration:17099  t-loss:0.1525, loss-lb:0.0779, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:59:04.910] iteration:17100  t-loss:0.1500, loss-lb:0.0798, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:59:05.102] iteration:17101  t-loss:0.1538, loss-lb:0.0868, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:59:05.294] iteration:17102  t-loss:0.1266, loss-lb:0.0707, loss-ulb:0.0279, weight:2.00, lr:0.0005
[11:59:05.488] iteration:17103  t-loss:0.1391, loss-lb:0.0782, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:59:05.681] iteration:17104  t-loss:0.1392, loss-lb:0.0725, loss-ulb:0.0334, weight:2.00, lr:0.0005
[11:59:05.872] iteration:17105  t-loss:0.1304, loss-lb:0.0763, loss-ulb:0.0271, weight:2.00, lr:0.0005
[11:59:06.064] iteration:17106  t-loss:0.1530, loss-lb:0.0761, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:59:06.258] iteration:17107  t-loss:0.1395, loss-lb:0.0729, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:59:06.449] iteration:17108  t-loss:0.1359, loss-lb:0.0796, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:59:06.642] iteration:17109  t-loss:0.1511, loss-lb:0.0852, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:59:06.833] iteration:17110  t-loss:0.1454, loss-lb:0.0801, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:59:07.025] iteration:17111  t-loss:0.1541, loss-lb:0.0887, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:59:07.218] iteration:17112  t-loss:0.1372, loss-lb:0.0746, loss-ulb:0.0313, weight:2.00, lr:0.0005
[11:59:07.410] iteration:17113  t-loss:0.1316, loss-lb:0.0745, loss-ulb:0.0285, weight:2.00, lr:0.0005
[11:59:07.603] iteration:17114  t-loss:0.1386, loss-lb:0.0695, loss-ulb:0.0346, weight:2.00, lr:0.0005
[11:59:07.797] iteration:17115  t-loss:0.1523, loss-lb:0.0810, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:59:07.989] iteration:17116  t-loss:0.1719, loss-lb:0.0807, loss-ulb:0.0456, weight:2.00, lr:0.0005
[11:59:08.181] iteration:17117  t-loss:0.1396, loss-lb:0.0811, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:59:08.374] iteration:17118  t-loss:0.1452, loss-lb:0.0799, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:59:08.567] iteration:17119  t-loss:0.1547, loss-lb:0.0802, loss-ulb:0.0373, weight:2.00, lr:0.0005
[11:59:08.758] iteration:17120  t-loss:0.1632, loss-lb:0.0948, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:59:08.952] iteration:17121  t-loss:0.1996, loss-lb:0.0770, loss-ulb:0.0613, weight:2.00, lr:0.0005
[11:59:09.146] iteration:17122  t-loss:0.1855, loss-lb:0.0780, loss-ulb:0.0538, weight:2.00, lr:0.0005
[11:59:09.338] iteration:17123  t-loss:0.1466, loss-lb:0.0772, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:59:09.530] iteration:17124  t-loss:0.1937, loss-lb:0.0920, loss-ulb:0.0509, weight:2.00, lr:0.0005
[11:59:09.724] iteration:17125  t-loss:0.1341, loss-lb:0.0756, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:59:09.917] iteration:17126  t-loss:0.1396, loss-lb:0.0853, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:59:10.110] iteration:17127  t-loss:0.1451, loss-lb:0.0794, loss-ulb:0.0329, weight:2.00, lr:0.0005
[11:59:10.301] iteration:17128  t-loss:0.1550, loss-lb:0.0842, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:59:10.494] iteration:17129  t-loss:0.1484, loss-lb:0.0767, loss-ulb:0.0358, weight:2.00, lr:0.0005
[11:59:10.685] iteration:17130  t-loss:0.1557, loss-lb:0.0808, loss-ulb:0.0374, weight:2.00, lr:0.0005
[11:59:10.878] iteration:17131  t-loss:0.1455, loss-lb:0.0769, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:59:11.071] iteration:17132  t-loss:0.1434, loss-lb:0.0796, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:59:11.263] iteration:17133  t-loss:0.1398, loss-lb:0.0834, loss-ulb:0.0282, weight:2.00, lr:0.0005
[11:59:11.455] iteration:17134  t-loss:0.1686, loss-lb:0.0879, loss-ulb:0.0403, weight:2.00, lr:0.0005
[11:59:11.648] iteration:17135  t-loss:0.1485, loss-lb:0.0845, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:59:11.840] iteration:17136  t-loss:0.1411, loss-lb:0.0727, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:59:12.035] iteration:17137  t-loss:0.1911, loss-lb:0.0773, loss-ulb:0.0569, weight:2.00, lr:0.0005
[11:59:12.227] iteration:17138  t-loss:0.1370, loss-lb:0.0713, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:59:12.420] iteration:17139  t-loss:0.1427, loss-lb:0.0782, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:59:12.612] iteration:17140  t-loss:0.1439, loss-lb:0.0783, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:59:12.805] iteration:17141  t-loss:0.1525, loss-lb:0.0847, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:59:12.998] iteration:17142  t-loss:0.1450, loss-lb:0.0815, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:59:13.190] iteration:17143  t-loss:0.1563, loss-lb:0.0769, loss-ulb:0.0397, weight:2.00, lr:0.0005
[11:59:13.382] iteration:17144  t-loss:0.1499, loss-lb:0.0799, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:59:13.572] iteration:17145  t-loss:0.1543, loss-lb:0.0728, loss-ulb:0.0407, weight:2.00, lr:0.0005
[11:59:13.764] iteration:17146  t-loss:0.1790, loss-lb:0.0819, loss-ulb:0.0486, weight:2.00, lr:0.0005
[11:59:13.954] iteration:17147  t-loss:0.1474, loss-lb:0.0829, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:59:14.145] iteration:17148  t-loss:0.1560, loss-lb:0.0877, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:59:14.335] iteration:17149  t-loss:0.1376, loss-lb:0.0730, loss-ulb:0.0323, weight:2.00, lr:0.0005
[11:59:14.527] iteration:17150  t-loss:0.1885, loss-lb:0.0771, loss-ulb:0.0557, weight:2.00, lr:0.0005
[11:59:26.953]  <<Test>> - Ep:174  - mean_dice/mean_h95 - S:89.78/1.37, Best-S:90.99, T:89.86/1.34, Best-T:90.48
[11:59:26.954]           - AvgLoss(lb/ulb/all):0.0794/0.0370/0.1534
[11:59:27.474] iteration:17151  t-loss:0.1335, loss-lb:0.0774, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:59:27.665] iteration:17152  t-loss:0.1451, loss-lb:0.0729, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:59:27.854] iteration:17153  t-loss:0.1283, loss-lb:0.0726, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:59:28.044] iteration:17154  t-loss:0.1513, loss-lb:0.0824, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:59:28.234] iteration:17155  t-loss:0.1392, loss-lb:0.0835, loss-ulb:0.0278, weight:2.00, lr:0.0005
[11:59:28.424] iteration:17156  t-loss:0.1475, loss-lb:0.0841, loss-ulb:0.0317, weight:2.00, lr:0.0005
[11:59:28.614] iteration:17157  t-loss:0.1431, loss-lb:0.0863, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:59:28.803] iteration:17158  t-loss:0.1579, loss-lb:0.0734, loss-ulb:0.0422, weight:2.00, lr:0.0005
[11:59:28.993] iteration:17159  t-loss:0.1640, loss-lb:0.0959, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:59:29.183] iteration:17160  t-loss:0.1444, loss-lb:0.0941, loss-ulb:0.0251, weight:2.00, lr:0.0005
[11:59:29.374] iteration:17161  t-loss:0.1418, loss-lb:0.0762, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:59:29.564] iteration:17162  t-loss:0.1371, loss-lb:0.0809, loss-ulb:0.0281, weight:2.00, lr:0.0005
[11:59:29.753] iteration:17163  t-loss:0.1607, loss-lb:0.0841, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:59:29.942] iteration:17164  t-loss:0.1300, loss-lb:0.0705, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:59:30.132] iteration:17165  t-loss:0.1295, loss-lb:0.0763, loss-ulb:0.0266, weight:2.00, lr:0.0005
[11:59:30.321] iteration:17166  t-loss:0.1512, loss-lb:0.0914, loss-ulb:0.0299, weight:2.00, lr:0.0005
[11:59:30.511] iteration:17167  t-loss:0.1629, loss-lb:0.0864, loss-ulb:0.0382, weight:2.00, lr:0.0005
[11:59:30.702] iteration:17168  t-loss:0.1366, loss-lb:0.0779, loss-ulb:0.0294, weight:2.00, lr:0.0005
[11:59:30.891] iteration:17169  t-loss:0.1539, loss-lb:0.0842, loss-ulb:0.0348, weight:2.00, lr:0.0005
[11:59:31.080] iteration:17170  t-loss:0.1495, loss-lb:0.0868, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:59:31.269] iteration:17171  t-loss:0.1410, loss-lb:0.0736, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:59:31.459] iteration:17172  t-loss:0.1430, loss-lb:0.0807, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:59:31.648] iteration:17173  t-loss:0.1454, loss-lb:0.0825, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:59:31.837] iteration:17174  t-loss:0.1407, loss-lb:0.0788, loss-ulb:0.0309, weight:2.00, lr:0.0005
[11:59:32.027] iteration:17175  t-loss:0.1568, loss-lb:0.0798, loss-ulb:0.0385, weight:2.00, lr:0.0005
[11:59:32.217] iteration:17176  t-loss:0.1766, loss-lb:0.0897, loss-ulb:0.0435, weight:2.00, lr:0.0005
[11:59:32.407] iteration:17177  t-loss:0.1579, loss-lb:0.0811, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:59:32.596] iteration:17178  t-loss:0.1436, loss-lb:0.0786, loss-ulb:0.0325, weight:2.00, lr:0.0005
[11:59:32.787] iteration:17179  t-loss:0.1297, loss-lb:0.0757, loss-ulb:0.0270, weight:2.00, lr:0.0005
[11:59:32.977] iteration:17180  t-loss:0.2396, loss-lb:0.0799, loss-ulb:0.0798, weight:2.00, lr:0.0005
[11:59:33.165] iteration:17181  t-loss:0.1406, loss-lb:0.0820, loss-ulb:0.0293, weight:2.00, lr:0.0005
[11:59:33.355] iteration:17182  t-loss:0.1491, loss-lb:0.0870, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:59:33.543] iteration:17183  t-loss:0.1348, loss-lb:0.0763, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:59:33.732] iteration:17184  t-loss:0.1426, loss-lb:0.0790, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:59:33.923] iteration:17185  t-loss:0.2394, loss-lb:0.0809, loss-ulb:0.0793, weight:2.00, lr:0.0005
[11:59:34.112] iteration:17186  t-loss:0.1734, loss-lb:0.0865, loss-ulb:0.0434, weight:2.00, lr:0.0005
[11:59:34.301] iteration:17187  t-loss:0.1464, loss-lb:0.0823, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:59:34.491] iteration:17188  t-loss:0.2321, loss-lb:0.0779, loss-ulb:0.0771, weight:2.00, lr:0.0005
[11:59:34.680] iteration:17189  t-loss:0.1410, loss-lb:0.0754, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:59:34.870] iteration:17190  t-loss:0.1615, loss-lb:0.0911, loss-ulb:0.0352, weight:2.00, lr:0.0005
[11:59:35.059] iteration:17191  t-loss:0.1485, loss-lb:0.0800, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:59:35.249] iteration:17192  t-loss:0.1589, loss-lb:0.0879, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:59:35.438] iteration:17193  t-loss:0.1608, loss-lb:0.0795, loss-ulb:0.0407, weight:2.00, lr:0.0005
[11:59:35.628] iteration:17194  t-loss:0.1687, loss-lb:0.0778, loss-ulb:0.0455, weight:2.00, lr:0.0005
[11:59:35.820] iteration:17195  t-loss:0.1995, loss-lb:0.0755, loss-ulb:0.0620, weight:2.00, lr:0.0005
[11:59:36.011] iteration:17196  t-loss:0.1332, loss-lb:0.0730, loss-ulb:0.0301, weight:2.00, lr:0.0005
[11:59:36.200] iteration:17197  t-loss:0.1431, loss-lb:0.0746, loss-ulb:0.0343, weight:2.00, lr:0.0005
[11:59:36.389] iteration:17198  t-loss:0.1385, loss-lb:0.0803, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:59:36.577] iteration:17199  t-loss:0.1573, loss-lb:0.0813, loss-ulb:0.0380, weight:2.00, lr:0.0005
[11:59:36.765] iteration:17200  t-loss:0.1457, loss-lb:0.0813, loss-ulb:0.0322, weight:2.00, lr:0.0005
[11:59:36.954] iteration:17201  t-loss:0.1452, loss-lb:0.0725, loss-ulb:0.0363, weight:2.00, lr:0.0005
[11:59:37.142] iteration:17202  t-loss:0.1644, loss-lb:0.0791, loss-ulb:0.0426, weight:2.00, lr:0.0005
[11:59:37.331] iteration:17203  t-loss:0.1395, loss-lb:0.0755, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:59:37.519] iteration:17204  t-loss:0.1351, loss-lb:0.0774, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:59:37.707] iteration:17205  t-loss:0.1467, loss-lb:0.0789, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:59:37.895] iteration:17206  t-loss:0.1732, loss-lb:0.0964, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:59:38.084] iteration:17207  t-loss:0.1859, loss-lb:0.0984, loss-ulb:0.0437, weight:2.00, lr:0.0005
[11:59:38.273] iteration:17208  t-loss:0.1417, loss-lb:0.0840, loss-ulb:0.0288, weight:2.00, lr:0.0005
[11:59:38.461] iteration:17209  t-loss:0.1423, loss-lb:0.0817, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:59:38.649] iteration:17210  t-loss:0.1415, loss-lb:0.0764, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:59:38.839] iteration:17211  t-loss:0.1484, loss-lb:0.0779, loss-ulb:0.0353, weight:2.00, lr:0.0005
[11:59:39.029] iteration:17212  t-loss:0.1416, loss-lb:0.0777, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:59:39.217] iteration:17213  t-loss:0.1482, loss-lb:0.0794, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:59:39.406] iteration:17214  t-loss:0.1372, loss-lb:0.0762, loss-ulb:0.0305, weight:2.00, lr:0.0005
[11:59:39.594] iteration:17215  t-loss:0.1471, loss-lb:0.0796, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:59:39.782] iteration:17216  t-loss:0.1833, loss-lb:0.0785, loss-ulb:0.0524, weight:2.00, lr:0.0005
[11:59:39.971] iteration:17217  t-loss:0.1488, loss-lb:0.0786, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:59:40.158] iteration:17218  t-loss:0.1570, loss-lb:0.0783, loss-ulb:0.0394, weight:2.00, lr:0.0005
[11:59:40.349] iteration:17219  t-loss:0.1641, loss-lb:0.0758, loss-ulb:0.0441, weight:2.00, lr:0.0005
[11:59:40.538] iteration:17220  t-loss:0.1797, loss-lb:0.0750, loss-ulb:0.0523, weight:2.00, lr:0.0005
[11:59:40.727] iteration:17221  t-loss:0.1469, loss-lb:0.0840, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:59:40.915] iteration:17222  t-loss:0.1463, loss-lb:0.0816, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:59:41.103] iteration:17223  t-loss:0.1520, loss-lb:0.0825, loss-ulb:0.0347, weight:2.00, lr:0.0005
[11:59:41.291] iteration:17224  t-loss:0.1620, loss-lb:0.0899, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:59:41.480] iteration:17225  t-loss:0.1400, loss-lb:0.0793, loss-ulb:0.0304, weight:2.00, lr:0.0005
[11:59:41.669] iteration:17226  t-loss:0.1523, loss-lb:0.0813, loss-ulb:0.0355, weight:2.00, lr:0.0005
[11:59:41.857] iteration:17227  t-loss:0.1794, loss-lb:0.0831, loss-ulb:0.0482, weight:2.00, lr:0.0005
[11:59:42.045] iteration:17228  t-loss:0.1537, loss-lb:0.0780, loss-ulb:0.0378, weight:2.00, lr:0.0005
[11:59:42.234] iteration:17229  t-loss:0.1512, loss-lb:0.0811, loss-ulb:0.0351, weight:2.00, lr:0.0005
[11:59:42.422] iteration:17230  t-loss:0.1494, loss-lb:0.0857, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:59:42.611] iteration:17231  t-loss:0.1453, loss-lb:0.0801, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:59:42.808] iteration:17232  t-loss:0.1558, loss-lb:0.0841, loss-ulb:0.0358, weight:2.00, lr:0.0005
[11:59:43.002] iteration:17233  t-loss:0.2573, loss-lb:0.0874, loss-ulb:0.0849, weight:2.00, lr:0.0005
[11:59:43.194] iteration:17234  t-loss:0.1497, loss-lb:0.0841, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:59:43.385] iteration:17235  t-loss:0.1412, loss-lb:0.0792, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:59:43.578] iteration:17236  t-loss:0.1488, loss-lb:0.0775, loss-ulb:0.0356, weight:2.00, lr:0.0005
[11:59:43.769] iteration:17237  t-loss:0.1594, loss-lb:0.0844, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:59:43.960] iteration:17238  t-loss:0.1510, loss-lb:0.0832, loss-ulb:0.0339, weight:2.00, lr:0.0005
[11:59:44.153] iteration:17239  t-loss:0.1462, loss-lb:0.0753, loss-ulb:0.0354, weight:2.00, lr:0.0005
[11:59:44.345] iteration:17240  t-loss:0.1789, loss-lb:0.0826, loss-ulb:0.0481, weight:2.00, lr:0.0005
[11:59:44.535] iteration:17241  t-loss:0.1497, loss-lb:0.0759, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:59:44.726] iteration:17242  t-loss:0.1482, loss-lb:0.0863, loss-ulb:0.0310, weight:2.00, lr:0.0005
[11:59:44.916] iteration:17243  t-loss:0.1504, loss-lb:0.0898, loss-ulb:0.0303, weight:2.00, lr:0.0005
[11:59:45.105] iteration:17244  t-loss:0.1518, loss-lb:0.0830, loss-ulb:0.0344, weight:2.00, lr:0.0005
[11:59:45.296] iteration:17245  t-loss:0.2480, loss-lb:0.0760, loss-ulb:0.0860, weight:2.00, lr:0.0005
[11:59:45.485] iteration:17246  t-loss:0.1520, loss-lb:0.0748, loss-ulb:0.0386, weight:2.00, lr:0.0005
[11:59:45.675] iteration:17247  t-loss:0.1316, loss-lb:0.0719, loss-ulb:0.0298, weight:2.00, lr:0.0005
[11:59:45.864] iteration:17248  t-loss:0.1470, loss-lb:0.0841, loss-ulb:0.0314, weight:2.00, lr:0.0005
[11:59:46.437] iteration:17249  t-loss:0.1441, loss-lb:0.0857, loss-ulb:0.0292, weight:2.00, lr:0.0005
[11:59:46.631] iteration:17250  t-loss:0.1352, loss-lb:0.0739, loss-ulb:0.0306, weight:2.00, lr:0.0005
[11:59:46.820] iteration:17251  t-loss:0.1682, loss-lb:0.0743, loss-ulb:0.0470, weight:2.00, lr:0.0005
[11:59:47.011] iteration:17252  t-loss:0.1536, loss-lb:0.0845, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:59:47.200] iteration:17253  t-loss:0.1556, loss-lb:0.0789, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:59:47.390] iteration:17254  t-loss:0.1462, loss-lb:0.0799, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:59:47.579] iteration:17255  t-loss:0.1579, loss-lb:0.0775, loss-ulb:0.0402, weight:2.00, lr:0.0005
[11:59:47.767] iteration:17256  t-loss:0.1517, loss-lb:0.0857, loss-ulb:0.0330, weight:2.00, lr:0.0005
[11:59:47.955] iteration:17257  t-loss:0.1509, loss-lb:0.0771, loss-ulb:0.0369, weight:2.00, lr:0.0005
[11:59:48.144] iteration:17258  t-loss:0.1483, loss-lb:0.0800, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:59:48.333] iteration:17259  t-loss:0.1474, loss-lb:0.0818, loss-ulb:0.0328, weight:2.00, lr:0.0005
[11:59:48.522] iteration:17260  t-loss:0.1493, loss-lb:0.0857, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:59:48.711] iteration:17261  t-loss:0.1472, loss-lb:0.0773, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:59:48.899] iteration:17262  t-loss:0.1562, loss-lb:0.0795, loss-ulb:0.0383, weight:2.00, lr:0.0005
[11:59:49.087] iteration:17263  t-loss:0.1479, loss-lb:0.0797, loss-ulb:0.0341, weight:2.00, lr:0.0005
[11:59:49.276] iteration:17264  t-loss:0.1769, loss-lb:0.0947, loss-ulb:0.0411, weight:2.00, lr:0.0005
[11:59:49.465] iteration:17265  t-loss:0.1525, loss-lb:0.0804, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:59:49.653] iteration:17266  t-loss:0.1429, loss-lb:0.0765, loss-ulb:0.0332, weight:2.00, lr:0.0005
[11:59:49.842] iteration:17267  t-loss:0.1433, loss-lb:0.0793, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:59:50.030] iteration:17268  t-loss:0.1390, loss-lb:0.0768, loss-ulb:0.0311, weight:2.00, lr:0.0005
[11:59:50.219] iteration:17269  t-loss:0.1339, loss-lb:0.0796, loss-ulb:0.0272, weight:2.00, lr:0.0005
[11:59:50.407] iteration:17270  t-loss:0.1484, loss-lb:0.0830, loss-ulb:0.0327, weight:2.00, lr:0.0005
[11:59:50.597] iteration:17271  t-loss:0.1687, loss-lb:0.0773, loss-ulb:0.0457, weight:2.00, lr:0.0005
[11:59:50.786] iteration:17272  t-loss:0.1673, loss-lb:0.0768, loss-ulb:0.0452, weight:2.00, lr:0.0005
[11:59:50.974] iteration:17273  t-loss:0.1324, loss-lb:0.0751, loss-ulb:0.0286, weight:2.00, lr:0.0005
[11:59:51.162] iteration:17274  t-loss:0.1601, loss-lb:0.0729, loss-ulb:0.0436, weight:2.00, lr:0.0005
[11:59:51.351] iteration:17275  t-loss:0.1565, loss-lb:0.0775, loss-ulb:0.0395, weight:2.00, lr:0.0005
[11:59:51.540] iteration:17276  t-loss:0.1479, loss-lb:0.0874, loss-ulb:0.0302, weight:2.00, lr:0.0005
[11:59:51.729] iteration:17277  t-loss:0.1407, loss-lb:0.0813, loss-ulb:0.0297, weight:2.00, lr:0.0005
[11:59:51.917] iteration:17278  t-loss:0.1547, loss-lb:0.0862, loss-ulb:0.0342, weight:2.00, lr:0.0005
[11:59:52.105] iteration:17279  t-loss:0.1524, loss-lb:0.0823, loss-ulb:0.0350, weight:2.00, lr:0.0005
[11:59:52.293] iteration:17280  t-loss:0.1517, loss-lb:0.0884, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:59:52.483] iteration:17281  t-loss:0.1519, loss-lb:0.0871, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:59:52.671] iteration:17282  t-loss:0.1554, loss-lb:0.0797, loss-ulb:0.0379, weight:2.00, lr:0.0005
[11:59:52.860] iteration:17283  t-loss:0.1415, loss-lb:0.0791, loss-ulb:0.0312, weight:2.00, lr:0.0005
[11:59:53.048] iteration:17284  t-loss:0.1466, loss-lb:0.0885, loss-ulb:0.0291, weight:2.00, lr:0.0005
[11:59:53.237] iteration:17285  t-loss:0.1507, loss-lb:0.0817, loss-ulb:0.0345, weight:2.00, lr:0.0005
[11:59:53.426] iteration:17286  t-loss:0.1558, loss-lb:0.0781, loss-ulb:0.0389, weight:2.00, lr:0.0005
[11:59:53.614] iteration:17287  t-loss:0.1475, loss-lb:0.0840, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:59:53.803] iteration:17288  t-loss:0.1489, loss-lb:0.0766, loss-ulb:0.0361, weight:2.00, lr:0.0005
[11:59:53.991] iteration:17289  t-loss:0.1542, loss-lb:0.0822, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:59:54.180] iteration:17290  t-loss:0.1598, loss-lb:0.0849, loss-ulb:0.0375, weight:2.00, lr:0.0005
[11:59:54.370] iteration:17291  t-loss:0.1875, loss-lb:0.0939, loss-ulb:0.0468, weight:2.00, lr:0.0005
[11:59:54.557] iteration:17292  t-loss:0.1311, loss-lb:0.0776, loss-ulb:0.0267, weight:2.00, lr:0.0005
[11:59:54.746] iteration:17293  t-loss:0.1491, loss-lb:0.0772, loss-ulb:0.0360, weight:2.00, lr:0.0005
[11:59:54.934] iteration:17294  t-loss:0.1918, loss-lb:0.0760, loss-ulb:0.0579, weight:2.00, lr:0.0005
[11:59:55.122] iteration:17295  t-loss:0.1466, loss-lb:0.0787, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:59:55.311] iteration:17296  t-loss:0.2155, loss-lb:0.0727, loss-ulb:0.0714, weight:2.00, lr:0.0005
[11:59:55.499] iteration:17297  t-loss:0.2352, loss-lb:0.1004, loss-ulb:0.0674, weight:2.00, lr:0.0005
[11:59:55.687] iteration:17298  t-loss:0.1695, loss-lb:0.0812, loss-ulb:0.0442, weight:2.00, lr:0.0005
[11:59:55.875] iteration:17299  t-loss:0.1424, loss-lb:0.0786, loss-ulb:0.0319, weight:2.00, lr:0.0005
[11:59:56.063] iteration:17300  t-loss:0.1531, loss-lb:0.0857, loss-ulb:0.0337, weight:2.00, lr:0.0005
[11:59:56.252] iteration:17301  t-loss:0.1405, loss-lb:0.0826, loss-ulb:0.0289, weight:2.00, lr:0.0005
[11:59:56.440] iteration:17302  t-loss:0.1419, loss-lb:0.0750, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:59:56.628] iteration:17303  t-loss:0.1551, loss-lb:0.0783, loss-ulb:0.0384, weight:2.00, lr:0.0005
[11:59:56.815] iteration:17304  t-loss:0.1749, loss-lb:0.0844, loss-ulb:0.0452, weight:2.00, lr:0.0005
[11:59:57.004] iteration:17305  t-loss:0.1539, loss-lb:0.0902, loss-ulb:0.0318, weight:2.00, lr:0.0005
[11:59:57.193] iteration:17306  t-loss:0.1390, loss-lb:0.0759, loss-ulb:0.0316, weight:2.00, lr:0.0005
[11:59:57.383] iteration:17307  t-loss:0.1455, loss-lb:0.0785, loss-ulb:0.0335, weight:2.00, lr:0.0005
[11:59:57.575] iteration:17308  t-loss:0.1436, loss-lb:0.0823, loss-ulb:0.0307, weight:2.00, lr:0.0005
[11:59:57.765] iteration:17309  t-loss:0.1428, loss-lb:0.0763, loss-ulb:0.0333, weight:2.00, lr:0.0005
[11:59:57.955] iteration:17310  t-loss:0.1696, loss-lb:0.0877, loss-ulb:0.0409, weight:2.00, lr:0.0005
[11:59:58.149] iteration:17311  t-loss:0.1473, loss-lb:0.0833, loss-ulb:0.0320, weight:2.00, lr:0.0005
[11:59:58.342] iteration:17312  t-loss:0.1360, loss-lb:0.0791, loss-ulb:0.0284, weight:2.00, lr:0.0005
[11:59:58.532] iteration:17313  t-loss:0.1446, loss-lb:0.0799, loss-ulb:0.0324, weight:2.00, lr:0.0005
[11:59:58.720] iteration:17314  t-loss:0.1855, loss-lb:0.0834, loss-ulb:0.0510, weight:2.00, lr:0.0005
[11:59:58.910] iteration:17315  t-loss:0.2206, loss-lb:0.0834, loss-ulb:0.0686, weight:2.00, lr:0.0005
[11:59:59.099] iteration:17316  t-loss:0.2406, loss-lb:0.0842, loss-ulb:0.0782, weight:2.00, lr:0.0005
[11:59:59.287] iteration:17317  t-loss:0.1518, loss-lb:0.0837, loss-ulb:0.0340, weight:2.00, lr:0.0005
[11:59:59.475] iteration:17318  t-loss:0.1400, loss-lb:0.0749, loss-ulb:0.0326, weight:2.00, lr:0.0005
[11:59:59.666] iteration:17319  t-loss:0.2089, loss-lb:0.0814, loss-ulb:0.0638, weight:2.00, lr:0.0005
[11:59:59.854] iteration:17320  t-loss:0.1426, loss-lb:0.0768, loss-ulb:0.0329, weight:2.00, lr:0.0005
[12:00:00.042] iteration:17321  t-loss:0.1453, loss-lb:0.0825, loss-ulb:0.0314, weight:2.00, lr:0.0005
[12:00:00.231] iteration:17322  t-loss:0.1382, loss-lb:0.0852, loss-ulb:0.0265, weight:2.00, lr:0.0005
[12:00:00.419] iteration:17323  t-loss:0.1550, loss-lb:0.0795, loss-ulb:0.0378, weight:2.00, lr:0.0005
[12:00:00.608] iteration:17324  t-loss:0.1365, loss-lb:0.0755, loss-ulb:0.0305, weight:2.00, lr:0.0005
[12:00:00.796] iteration:17325  t-loss:0.1553, loss-lb:0.0850, loss-ulb:0.0352, weight:2.00, lr:0.0005
[12:00:00.985] iteration:17326  t-loss:0.2074, loss-lb:0.0813, loss-ulb:0.0631, weight:2.00, lr:0.0005
[12:00:01.174] iteration:17327  t-loss:0.2427, loss-lb:0.0820, loss-ulb:0.0803, weight:2.00, lr:0.0005
[12:00:01.364] iteration:17328  t-loss:0.1529, loss-lb:0.0822, loss-ulb:0.0354, weight:2.00, lr:0.0005
[12:00:01.552] iteration:17329  t-loss:0.1358, loss-lb:0.0800, loss-ulb:0.0279, weight:2.00, lr:0.0005
[12:00:01.740] iteration:17330  t-loss:0.1497, loss-lb:0.0888, loss-ulb:0.0305, weight:2.00, lr:0.0005
[12:00:01.929] iteration:17331  t-loss:0.1481, loss-lb:0.0744, loss-ulb:0.0368, weight:2.00, lr:0.0005
[12:00:02.117] iteration:17332  t-loss:0.1505, loss-lb:0.0782, loss-ulb:0.0361, weight:2.00, lr:0.0005
[12:00:02.306] iteration:17333  t-loss:0.1624, loss-lb:0.0830, loss-ulb:0.0397, weight:2.00, lr:0.0005
[12:00:02.495] iteration:17334  t-loss:0.1488, loss-lb:0.0791, loss-ulb:0.0349, weight:2.00, lr:0.0005
[12:00:02.683] iteration:17335  t-loss:0.1531, loss-lb:0.0901, loss-ulb:0.0315, weight:2.00, lr:0.0005
[12:00:02.872] iteration:17336  t-loss:0.1407, loss-lb:0.0790, loss-ulb:0.0308, weight:2.00, lr:0.0005
[12:00:03.061] iteration:17337  t-loss:0.1445, loss-lb:0.0876, loss-ulb:0.0285, weight:2.00, lr:0.0005
[12:00:03.250] iteration:17338  t-loss:0.1433, loss-lb:0.0750, loss-ulb:0.0342, weight:2.00, lr:0.0005
[12:00:03.439] iteration:17339  t-loss:0.1593, loss-lb:0.0967, loss-ulb:0.0313, weight:2.00, lr:0.0005
[12:00:03.627] iteration:17340  t-loss:0.1462, loss-lb:0.0820, loss-ulb:0.0321, weight:2.00, lr:0.0005
[12:00:03.814] iteration:17341  t-loss:0.1682, loss-lb:0.0796, loss-ulb:0.0443, weight:2.00, lr:0.0005
[12:00:04.003] iteration:17342  t-loss:0.1886, loss-lb:0.0754, loss-ulb:0.0566, weight:2.00, lr:0.0005
[12:00:04.190] iteration:17343  t-loss:0.1490, loss-lb:0.0763, loss-ulb:0.0364, weight:2.00, lr:0.0005
[12:00:04.378] iteration:17344  t-loss:0.1572, loss-lb:0.0832, loss-ulb:0.0370, weight:2.00, lr:0.0005
[12:00:04.565] iteration:17345  t-loss:0.1295, loss-lb:0.0748, loss-ulb:0.0274, weight:2.00, lr:0.0005
[12:00:04.752] iteration:17346  t-loss:0.1538, loss-lb:0.0770, loss-ulb:0.0384, weight:2.00, lr:0.0005
[12:00:16.337]  <<Test>> - Ep:176  - mean_dice/mean_h95 - S:89.87/1.39, Best-S:90.99, T:89.88/1.37, Best-T:90.48
[12:00:16.338]           - AvgLoss(lb/ulb/all):0.0812/0.0375/0.1562
[12:00:16.864] iteration:17347  t-loss:0.1350, loss-lb:0.0796, loss-ulb:0.0277, weight:2.00, lr:0.0005
[12:00:17.053] iteration:17348  t-loss:0.1519, loss-lb:0.0750, loss-ulb:0.0385, weight:2.00, lr:0.0005
[12:00:17.245] iteration:17349  t-loss:0.1893, loss-lb:0.0766, loss-ulb:0.0563, weight:2.00, lr:0.0005
[12:00:17.436] iteration:17350  t-loss:0.1466, loss-lb:0.0847, loss-ulb:0.0310, weight:2.00, lr:0.0005
[12:00:17.627] iteration:17351  t-loss:0.1926, loss-lb:0.0836, loss-ulb:0.0545, weight:2.00, lr:0.0005
[12:00:17.818] iteration:17352  t-loss:0.1427, loss-lb:0.0751, loss-ulb:0.0338, weight:2.00, lr:0.0005
[12:00:18.009] iteration:17353  t-loss:0.1786, loss-lb:0.0877, loss-ulb:0.0455, weight:2.00, lr:0.0005
[12:00:18.201] iteration:17354  t-loss:0.1534, loss-lb:0.0868, loss-ulb:0.0333, weight:2.00, lr:0.0005
[12:00:18.390] iteration:17355  t-loss:0.1401, loss-lb:0.0798, loss-ulb:0.0301, weight:2.00, lr:0.0005
[12:00:18.581] iteration:17356  t-loss:0.1477, loss-lb:0.0824, loss-ulb:0.0327, weight:2.00, lr:0.0005
[12:00:18.773] iteration:17357  t-loss:0.1634, loss-lb:0.0792, loss-ulb:0.0421, weight:2.00, lr:0.0005
[12:00:18.967] iteration:17358  t-loss:0.2070, loss-lb:0.0824, loss-ulb:0.0623, weight:2.00, lr:0.0005
[12:00:19.158] iteration:17359  t-loss:0.1385, loss-lb:0.0782, loss-ulb:0.0302, weight:2.00, lr:0.0005
[12:00:19.351] iteration:17360  t-loss:0.1856, loss-lb:0.0803, loss-ulb:0.0527, weight:2.00, lr:0.0005
[12:00:19.544] iteration:17361  t-loss:0.1517, loss-lb:0.0768, loss-ulb:0.0374, weight:2.00, lr:0.0005
[12:00:19.736] iteration:17362  t-loss:0.1478, loss-lb:0.0760, loss-ulb:0.0359, weight:2.00, lr:0.0005
[12:00:19.927] iteration:17363  t-loss:0.1494, loss-lb:0.0888, loss-ulb:0.0303, weight:2.00, lr:0.0005
[12:00:20.120] iteration:17364  t-loss:0.1480, loss-lb:0.0855, loss-ulb:0.0313, weight:2.00, lr:0.0005
[12:00:20.311] iteration:17365  t-loss:0.1482, loss-lb:0.0868, loss-ulb:0.0307, weight:2.00, lr:0.0005
[12:00:20.504] iteration:17366  t-loss:0.1622, loss-lb:0.0751, loss-ulb:0.0436, weight:2.00, lr:0.0005
[12:00:20.695] iteration:17367  t-loss:0.1404, loss-lb:0.0821, loss-ulb:0.0291, weight:2.00, lr:0.0005
[12:00:20.887] iteration:17368  t-loss:0.1389, loss-lb:0.0794, loss-ulb:0.0297, weight:2.00, lr:0.0005
[12:00:21.080] iteration:17369  t-loss:0.1512, loss-lb:0.0872, loss-ulb:0.0320, weight:2.00, lr:0.0005
[12:00:21.272] iteration:17370  t-loss:0.1376, loss-lb:0.0738, loss-ulb:0.0319, weight:2.00, lr:0.0005
[12:00:21.462] iteration:17371  t-loss:0.1391, loss-lb:0.0767, loss-ulb:0.0312, weight:2.00, lr:0.0005
[12:00:21.654] iteration:17372  t-loss:0.1445, loss-lb:0.0828, loss-ulb:0.0309, weight:2.00, lr:0.0005
[12:00:21.846] iteration:17373  t-loss:0.1716, loss-lb:0.1016, loss-ulb:0.0350, weight:2.00, lr:0.0005
[12:00:22.039] iteration:17374  t-loss:0.1500, loss-lb:0.0826, loss-ulb:0.0337, weight:2.00, lr:0.0005
[12:00:22.231] iteration:17375  t-loss:0.1456, loss-lb:0.0778, loss-ulb:0.0339, weight:2.00, lr:0.0005
[12:00:22.424] iteration:17376  t-loss:0.1588, loss-lb:0.0879, loss-ulb:0.0355, weight:2.00, lr:0.0005
[12:00:22.616] iteration:17377  t-loss:0.1494, loss-lb:0.0796, loss-ulb:0.0349, weight:2.00, lr:0.0005
[12:00:22.809] iteration:17378  t-loss:0.1535, loss-lb:0.0797, loss-ulb:0.0369, weight:2.00, lr:0.0005
[12:00:23.000] iteration:17379  t-loss:0.1422, loss-lb:0.0746, loss-ulb:0.0338, weight:2.00, lr:0.0005
[12:00:23.193] iteration:17380  t-loss:0.1969, loss-lb:0.0718, loss-ulb:0.0626, weight:2.00, lr:0.0005
[12:00:23.386] iteration:17381  t-loss:0.1411, loss-lb:0.0809, loss-ulb:0.0301, weight:2.00, lr:0.0005
[12:00:23.579] iteration:17382  t-loss:0.1410, loss-lb:0.0764, loss-ulb:0.0323, weight:2.00, lr:0.0005
[12:00:23.770] iteration:17383  t-loss:0.1886, loss-lb:0.0944, loss-ulb:0.0471, weight:2.00, lr:0.0005
[12:00:23.963] iteration:17384  t-loss:0.1610, loss-lb:0.0804, loss-ulb:0.0403, weight:2.00, lr:0.0005
[12:00:24.156] iteration:17385  t-loss:0.1556, loss-lb:0.0859, loss-ulb:0.0349, weight:2.00, lr:0.0005
[12:00:24.350] iteration:17386  t-loss:0.1831, loss-lb:0.0782, loss-ulb:0.0525, weight:2.00, lr:0.0005
[12:00:24.542] iteration:17387  t-loss:0.1654, loss-lb:0.0840, loss-ulb:0.0407, weight:2.00, lr:0.0005
[12:00:24.735] iteration:17388  t-loss:0.1468, loss-lb:0.0841, loss-ulb:0.0314, weight:2.00, lr:0.0005
[12:00:24.927] iteration:17389  t-loss:0.1347, loss-lb:0.0703, loss-ulb:0.0322, weight:2.00, lr:0.0005
[12:00:25.120] iteration:17390  t-loss:0.1761, loss-lb:0.0771, loss-ulb:0.0495, weight:2.00, lr:0.0005
[12:00:25.312] iteration:17391  t-loss:0.1517, loss-lb:0.0816, loss-ulb:0.0350, weight:2.00, lr:0.0005
[12:00:25.505] iteration:17392  t-loss:0.1435, loss-lb:0.0792, loss-ulb:0.0322, weight:2.00, lr:0.0005
[12:00:25.698] iteration:17393  t-loss:0.1600, loss-lb:0.0822, loss-ulb:0.0389, weight:2.00, lr:0.0005
[12:00:25.892] iteration:17394  t-loss:0.1498, loss-lb:0.0814, loss-ulb:0.0342, weight:2.00, lr:0.0005
[12:00:26.083] iteration:17395  t-loss:0.1514, loss-lb:0.0892, loss-ulb:0.0311, weight:2.00, lr:0.0005
[12:00:26.276] iteration:17396  t-loss:0.1348, loss-lb:0.0751, loss-ulb:0.0298, weight:2.00, lr:0.0005
[12:00:26.469] iteration:17397  t-loss:0.2274, loss-lb:0.0802, loss-ulb:0.0736, weight:2.00, lr:0.0005
[12:00:26.662] iteration:17398  t-loss:0.1465, loss-lb:0.0906, loss-ulb:0.0280, weight:2.00, lr:0.0005
[12:00:26.854] iteration:17399  t-loss:0.1495, loss-lb:0.0861, loss-ulb:0.0317, weight:2.00, lr:0.0005
[12:00:27.048] iteration:17400  t-loss:0.1463, loss-lb:0.0788, loss-ulb:0.0338, weight:2.00, lr:0.0005
[12:00:27.241] iteration:17401  t-loss:0.1605, loss-lb:0.0810, loss-ulb:0.0397, weight:2.00, lr:0.0005
[12:00:27.433] iteration:17402  t-loss:0.1412, loss-lb:0.0781, loss-ulb:0.0316, weight:2.00, lr:0.0005
[12:00:27.624] iteration:17403  t-loss:0.1604, loss-lb:0.0837, loss-ulb:0.0384, weight:2.00, lr:0.0005
[12:00:27.815] iteration:17404  t-loss:0.1438, loss-lb:0.0733, loss-ulb:0.0353, weight:2.00, lr:0.0005
[12:00:28.007] iteration:17405  t-loss:0.1499, loss-lb:0.0810, loss-ulb:0.0344, weight:2.00, lr:0.0005
[12:00:28.199] iteration:17406  t-loss:0.1504, loss-lb:0.0925, loss-ulb:0.0289, weight:2.00, lr:0.0005
[12:00:28.391] iteration:17407  t-loss:0.1428, loss-lb:0.0778, loss-ulb:0.0325, weight:2.00, lr:0.0005
[12:00:28.584] iteration:17408  t-loss:0.1390, loss-lb:0.0791, loss-ulb:0.0299, weight:2.00, lr:0.0005
[12:00:28.777] iteration:17409  t-loss:0.1398, loss-lb:0.0773, loss-ulb:0.0313, weight:2.00, lr:0.0005
[12:00:28.968] iteration:17410  t-loss:0.1342, loss-lb:0.0851, loss-ulb:0.0246, weight:2.00, lr:0.0005
[12:00:29.160] iteration:17411  t-loss:0.1892, loss-lb:0.0814, loss-ulb:0.0539, weight:2.00, lr:0.0005
[12:00:29.354] iteration:17412  t-loss:0.1402, loss-lb:0.0793, loss-ulb:0.0305, weight:2.00, lr:0.0005
[12:00:29.547] iteration:17413  t-loss:0.1417, loss-lb:0.0851, loss-ulb:0.0283, weight:2.00, lr:0.0005
[12:00:29.739] iteration:17414  t-loss:0.1585, loss-lb:0.0766, loss-ulb:0.0410, weight:2.00, lr:0.0005
[12:00:29.931] iteration:17415  t-loss:0.1403, loss-lb:0.0761, loss-ulb:0.0321, weight:2.00, lr:0.0005
[12:00:30.126] iteration:17416  t-loss:0.1765, loss-lb:0.0824, loss-ulb:0.0470, weight:2.00, lr:0.0005
[12:00:30.318] iteration:17417  t-loss:0.1501, loss-lb:0.0816, loss-ulb:0.0343, weight:2.00, lr:0.0005
[12:00:30.510] iteration:17418  t-loss:0.1526, loss-lb:0.0797, loss-ulb:0.0365, weight:2.00, lr:0.0005
[12:00:30.701] iteration:17419  t-loss:0.1661, loss-lb:0.0875, loss-ulb:0.0393, weight:2.00, lr:0.0005
[12:00:30.903] iteration:17420  t-loss:0.1416, loss-lb:0.0758, loss-ulb:0.0329, weight:2.00, lr:0.0005
[12:00:31.104] iteration:17421  t-loss:0.1554, loss-lb:0.0828, loss-ulb:0.0363, weight:2.00, lr:0.0005
[12:00:31.300] iteration:17422  t-loss:0.1569, loss-lb:0.0802, loss-ulb:0.0384, weight:2.00, lr:0.0005
[12:00:31.491] iteration:17423  t-loss:0.1469, loss-lb:0.0806, loss-ulb:0.0331, weight:2.00, lr:0.0005
[12:00:31.684] iteration:17424  t-loss:0.1442, loss-lb:0.0781, loss-ulb:0.0331, weight:2.00, lr:0.0005
[12:00:31.876] iteration:17425  t-loss:0.1374, loss-lb:0.0798, loss-ulb:0.0288, weight:2.00, lr:0.0005
[12:00:32.068] iteration:17426  t-loss:0.1498, loss-lb:0.0793, loss-ulb:0.0353, weight:2.00, lr:0.0005
[12:00:32.259] iteration:17427  t-loss:0.1354, loss-lb:0.0754, loss-ulb:0.0300, weight:2.00, lr:0.0005
[12:00:32.452] iteration:17428  t-loss:0.1470, loss-lb:0.0837, loss-ulb:0.0316, weight:2.00, lr:0.0005
[12:00:32.644] iteration:17429  t-loss:0.1500, loss-lb:0.0777, loss-ulb:0.0362, weight:2.00, lr:0.0005
[12:00:32.837] iteration:17430  t-loss:0.1526, loss-lb:0.0848, loss-ulb:0.0339, weight:2.00, lr:0.0005
[12:00:33.029] iteration:17431  t-loss:0.1495, loss-lb:0.0761, loss-ulb:0.0367, weight:2.00, lr:0.0005
[12:00:33.222] iteration:17432  t-loss:0.1528, loss-lb:0.0768, loss-ulb:0.0380, weight:2.00, lr:0.0005
[12:00:33.414] iteration:17433  t-loss:0.1645, loss-lb:0.0803, loss-ulb:0.0421, weight:2.00, lr:0.0005
[12:00:33.606] iteration:17434  t-loss:0.1462, loss-lb:0.0771, loss-ulb:0.0345, weight:2.00, lr:0.0005
[12:00:33.799] iteration:17435  t-loss:0.1750, loss-lb:0.0795, loss-ulb:0.0477, weight:2.00, lr:0.0005
[12:00:33.991] iteration:17436  t-loss:0.1514, loss-lb:0.0854, loss-ulb:0.0330, weight:2.00, lr:0.0005
[12:00:34.183] iteration:17437  t-loss:0.1843, loss-lb:0.0808, loss-ulb:0.0518, weight:2.00, lr:0.0005
[12:00:34.375] iteration:17438  t-loss:0.1579, loss-lb:0.0798, loss-ulb:0.0390, weight:2.00, lr:0.0005
[12:00:34.565] iteration:17439  t-loss:0.1592, loss-lb:0.0749, loss-ulb:0.0422, weight:2.00, lr:0.0005
[12:00:34.756] iteration:17440  t-loss:0.1573, loss-lb:0.0813, loss-ulb:0.0380, weight:2.00, lr:0.0005
[12:00:34.946] iteration:17441  t-loss:0.2127, loss-lb:0.0811, loss-ulb:0.0658, weight:2.00, lr:0.0005
[12:00:35.137] iteration:17442  t-loss:0.1776, loss-lb:0.0826, loss-ulb:0.0475, weight:2.00, lr:0.0005
[12:00:35.329] iteration:17443  t-loss:0.1376, loss-lb:0.0717, loss-ulb:0.0330, weight:2.00, lr:0.0005
[12:00:35.520] iteration:17444  t-loss:0.1434, loss-lb:0.0789, loss-ulb:0.0322, weight:2.00, lr:0.0005
[12:00:36.118] iteration:17445  t-loss:0.1271, loss-lb:0.0752, loss-ulb:0.0260, weight:2.00, lr:0.0005
[12:00:36.312] iteration:17446  t-loss:0.1491, loss-lb:0.0817, loss-ulb:0.0337, weight:2.00, lr:0.0005
[12:00:36.504] iteration:17447  t-loss:0.1331, loss-lb:0.0795, loss-ulb:0.0268, weight:2.00, lr:0.0005
[12:00:36.697] iteration:17448  t-loss:0.1362, loss-lb:0.0754, loss-ulb:0.0304, weight:2.00, lr:0.0005
[12:00:36.890] iteration:17449  t-loss:0.1774, loss-lb:0.0903, loss-ulb:0.0436, weight:2.00, lr:0.0005
[12:00:37.083] iteration:17450  t-loss:0.1424, loss-lb:0.0819, loss-ulb:0.0302, weight:2.00, lr:0.0005
[12:00:37.275] iteration:17451  t-loss:0.1397, loss-lb:0.0858, loss-ulb:0.0269, weight:2.00, lr:0.0005
[12:00:37.467] iteration:17452  t-loss:0.1488, loss-lb:0.0848, loss-ulb:0.0320, weight:2.00, lr:0.0005
[12:00:37.660] iteration:17453  t-loss:0.1348, loss-lb:0.0737, loss-ulb:0.0305, weight:2.00, lr:0.0005
[12:00:37.852] iteration:17454  t-loss:0.1964, loss-lb:0.0799, loss-ulb:0.0582, weight:2.00, lr:0.0005
[12:00:38.044] iteration:17455  t-loss:0.1615, loss-lb:0.0793, loss-ulb:0.0411, weight:2.00, lr:0.0005
[12:00:38.238] iteration:17456  t-loss:0.1459, loss-lb:0.0814, loss-ulb:0.0323, weight:2.00, lr:0.0005
[12:00:38.430] iteration:17457  t-loss:0.1544, loss-lb:0.0813, loss-ulb:0.0366, weight:2.00, lr:0.0005
[12:00:38.623] iteration:17458  t-loss:0.1466, loss-lb:0.0839, loss-ulb:0.0314, weight:2.00, lr:0.0005
[12:00:38.815] iteration:17459  t-loss:0.1450, loss-lb:0.0763, loss-ulb:0.0343, weight:2.00, lr:0.0005
[12:00:39.008] iteration:17460  t-loss:0.1796, loss-lb:0.0963, loss-ulb:0.0417, weight:2.00, lr:0.0005
[12:00:39.201] iteration:17461  t-loss:0.1523, loss-lb:0.0823, loss-ulb:0.0350, weight:2.00, lr:0.0005
[12:00:39.394] iteration:17462  t-loss:0.1562, loss-lb:0.0790, loss-ulb:0.0386, weight:2.00, lr:0.0005
[12:00:39.586] iteration:17463  t-loss:0.1485, loss-lb:0.0810, loss-ulb:0.0338, weight:2.00, lr:0.0005
[12:00:39.779] iteration:17464  t-loss:0.2309, loss-lb:0.0741, loss-ulb:0.0784, weight:2.00, lr:0.0005
[12:00:39.971] iteration:17465  t-loss:0.2177, loss-lb:0.0766, loss-ulb:0.0705, weight:2.00, lr:0.0005
[12:00:40.164] iteration:17466  t-loss:0.1430, loss-lb:0.0811, loss-ulb:0.0309, weight:2.00, lr:0.0005
[12:00:40.357] iteration:17467  t-loss:0.1426, loss-lb:0.0778, loss-ulb:0.0324, weight:2.00, lr:0.0005
[12:00:40.549] iteration:17468  t-loss:0.1760, loss-lb:0.0793, loss-ulb:0.0483, weight:2.00, lr:0.0005
[12:00:40.742] iteration:17469  t-loss:0.1413, loss-lb:0.0744, loss-ulb:0.0334, weight:2.00, lr:0.0005
[12:00:40.936] iteration:17470  t-loss:0.1766, loss-lb:0.0777, loss-ulb:0.0494, weight:2.00, lr:0.0005
[12:00:41.128] iteration:17471  t-loss:0.1763, loss-lb:0.0792, loss-ulb:0.0486, weight:2.00, lr:0.0005
[12:00:41.320] iteration:17472  t-loss:0.2566, loss-lb:0.0855, loss-ulb:0.0856, weight:2.00, lr:0.0005
[12:00:41.514] iteration:17473  t-loss:0.1572, loss-lb:0.0924, loss-ulb:0.0324, weight:2.00, lr:0.0005
[12:00:41.706] iteration:17474  t-loss:0.1450, loss-lb:0.0817, loss-ulb:0.0317, weight:2.00, lr:0.0005
[12:00:41.900] iteration:17475  t-loss:0.1569, loss-lb:0.0782, loss-ulb:0.0394, weight:2.00, lr:0.0005
[12:00:42.093] iteration:17476  t-loss:0.1490, loss-lb:0.0825, loss-ulb:0.0332, weight:2.00, lr:0.0005
[12:00:42.286] iteration:17477  t-loss:0.1633, loss-lb:0.0710, loss-ulb:0.0461, weight:2.00, lr:0.0005
[12:00:42.478] iteration:17478  t-loss:0.1457, loss-lb:0.0794, loss-ulb:0.0332, weight:2.00, lr:0.0005
[12:00:42.671] iteration:17479  t-loss:0.1780, loss-lb:0.0792, loss-ulb:0.0494, weight:2.00, lr:0.0005
[12:00:42.862] iteration:17480  t-loss:0.1627, loss-lb:0.0873, loss-ulb:0.0377, weight:2.00, lr:0.0005
[12:00:43.055] iteration:17481  t-loss:0.1457, loss-lb:0.0812, loss-ulb:0.0323, weight:2.00, lr:0.0005
[12:00:43.246] iteration:17482  t-loss:0.1403, loss-lb:0.0808, loss-ulb:0.0297, weight:2.00, lr:0.0005
[12:00:43.438] iteration:17483  t-loss:0.1444, loss-lb:0.0849, loss-ulb:0.0298, weight:2.00, lr:0.0005
[12:00:43.631] iteration:17484  t-loss:0.1429, loss-lb:0.0832, loss-ulb:0.0299, weight:2.00, lr:0.0005
[12:00:43.823] iteration:17485  t-loss:0.1974, loss-lb:0.0828, loss-ulb:0.0573, weight:2.00, lr:0.0005
[12:00:44.016] iteration:17486  t-loss:0.1440, loss-lb:0.0810, loss-ulb:0.0315, weight:2.00, lr:0.0005
[12:00:44.209] iteration:17487  t-loss:0.1784, loss-lb:0.0828, loss-ulb:0.0478, weight:2.00, lr:0.0005
[12:00:44.401] iteration:17488  t-loss:0.1512, loss-lb:0.0762, loss-ulb:0.0375, weight:2.00, lr:0.0005
[12:00:44.593] iteration:17489  t-loss:0.1480, loss-lb:0.0686, loss-ulb:0.0397, weight:2.00, lr:0.0005
[12:00:44.785] iteration:17490  t-loss:0.1465, loss-lb:0.0865, loss-ulb:0.0300, weight:2.00, lr:0.0005
[12:00:44.977] iteration:17491  t-loss:0.1369, loss-lb:0.0762, loss-ulb:0.0304, weight:2.00, lr:0.0005
[12:00:45.171] iteration:17492  t-loss:0.1721, loss-lb:0.0844, loss-ulb:0.0438, weight:2.00, lr:0.0005
[12:00:45.364] iteration:17493  t-loss:0.1981, loss-lb:0.0818, loss-ulb:0.0582, weight:2.00, lr:0.0005
[12:00:45.556] iteration:17494  t-loss:0.1491, loss-lb:0.0750, loss-ulb:0.0370, weight:2.00, lr:0.0005
[12:00:45.748] iteration:17495  t-loss:0.1511, loss-lb:0.0805, loss-ulb:0.0353, weight:2.00, lr:0.0005
[12:00:45.939] iteration:17496  t-loss:0.1549, loss-lb:0.0819, loss-ulb:0.0365, weight:2.00, lr:0.0005
[12:00:46.131] iteration:17497  t-loss:0.1449, loss-lb:0.0855, loss-ulb:0.0297, weight:2.00, lr:0.0005
[12:00:46.324] iteration:17498  t-loss:0.1663, loss-lb:0.0812, loss-ulb:0.0426, weight:2.00, lr:0.0005
[12:00:46.515] iteration:17499  t-loss:0.1467, loss-lb:0.0804, loss-ulb:0.0332, weight:2.00, lr:0.0005
[12:00:46.707] iteration:17500  t-loss:0.1514, loss-lb:0.0873, loss-ulb:0.0320, weight:2.00, lr:0.0005
[12:00:46.900] iteration:17501  t-loss:0.1530, loss-lb:0.0857, loss-ulb:0.0337, weight:2.00, lr:0.0005
[12:00:47.092] iteration:17502  t-loss:0.1604, loss-lb:0.0858, loss-ulb:0.0373, weight:2.00, lr:0.0005
[12:00:47.284] iteration:17503  t-loss:0.1667, loss-lb:0.1038, loss-ulb:0.0315, weight:2.00, lr:0.0005
[12:00:47.477] iteration:17504  t-loss:0.1434, loss-lb:0.0822, loss-ulb:0.0306, weight:2.00, lr:0.0005
[12:00:47.669] iteration:17505  t-loss:0.1347, loss-lb:0.0802, loss-ulb:0.0273, weight:2.00, lr:0.0005
[12:00:47.862] iteration:17506  t-loss:0.1663, loss-lb:0.0833, loss-ulb:0.0415, weight:2.00, lr:0.0005
[12:00:48.054] iteration:17507  t-loss:0.1396, loss-lb:0.0795, loss-ulb:0.0300, weight:2.00, lr:0.0005
[12:00:48.246] iteration:17508  t-loss:0.1376, loss-lb:0.0811, loss-ulb:0.0282, weight:2.00, lr:0.0005
[12:00:48.438] iteration:17509  t-loss:0.1437, loss-lb:0.0788, loss-ulb:0.0325, weight:2.00, lr:0.0005
[12:00:48.631] iteration:17510  t-loss:0.1437, loss-lb:0.0776, loss-ulb:0.0331, weight:2.00, lr:0.0005
[12:00:48.824] iteration:17511  t-loss:0.1491, loss-lb:0.0761, loss-ulb:0.0365, weight:2.00, lr:0.0005
[12:00:49.017] iteration:17512  t-loss:0.1583, loss-lb:0.0832, loss-ulb:0.0376, weight:2.00, lr:0.0005
[12:00:49.209] iteration:17513  t-loss:0.1492, loss-lb:0.0872, loss-ulb:0.0310, weight:2.00, lr:0.0005
[12:00:49.402] iteration:17514  t-loss:0.2942, loss-lb:0.0743, loss-ulb:0.1099, weight:2.00, lr:0.0005
[12:00:49.594] iteration:17515  t-loss:0.1567, loss-lb:0.0838, loss-ulb:0.0364, weight:2.00, lr:0.0005
[12:00:49.786] iteration:17516  t-loss:0.1495, loss-lb:0.0853, loss-ulb:0.0321, weight:2.00, lr:0.0005
[12:00:49.979] iteration:17517  t-loss:0.1480, loss-lb:0.0814, loss-ulb:0.0333, weight:2.00, lr:0.0005
[12:00:50.172] iteration:17518  t-loss:0.1726, loss-lb:0.0801, loss-ulb:0.0462, weight:2.00, lr:0.0005
[12:00:50.364] iteration:17519  t-loss:0.1513, loss-lb:0.0816, loss-ulb:0.0348, weight:2.00, lr:0.0005
[12:00:50.557] iteration:17520  t-loss:0.1517, loss-lb:0.0897, loss-ulb:0.0310, weight:2.00, lr:0.0005
[12:00:50.749] iteration:17521  t-loss:0.1440, loss-lb:0.0809, loss-ulb:0.0315, weight:2.00, lr:0.0005
[12:00:50.940] iteration:17522  t-loss:0.1439, loss-lb:0.0812, loss-ulb:0.0314, weight:2.00, lr:0.0005
[12:00:51.133] iteration:17523  t-loss:0.1576, loss-lb:0.0793, loss-ulb:0.0392, weight:2.00, lr:0.0005
[12:00:51.327] iteration:17524  t-loss:0.1665, loss-lb:0.0782, loss-ulb:0.0441, weight:2.00, lr:0.0005
[12:00:51.520] iteration:17525  t-loss:0.1528, loss-lb:0.0763, loss-ulb:0.0383, weight:2.00, lr:0.0005
[12:00:51.712] iteration:17526  t-loss:0.1488, loss-lb:0.0826, loss-ulb:0.0331, weight:2.00, lr:0.0005
[12:00:51.907] iteration:17527  t-loss:0.1559, loss-lb:0.0756, loss-ulb:0.0402, weight:2.00, lr:0.0005
[12:00:52.099] iteration:17528  t-loss:0.1420, loss-lb:0.0771, loss-ulb:0.0325, weight:2.00, lr:0.0005
[12:00:52.291] iteration:17529  t-loss:0.1503, loss-lb:0.0726, loss-ulb:0.0388, weight:2.00, lr:0.0005
[12:00:52.483] iteration:17530  t-loss:0.1355, loss-lb:0.0722, loss-ulb:0.0316, weight:2.00, lr:0.0005
[12:00:52.676] iteration:17531  t-loss:0.1458, loss-lb:0.0812, loss-ulb:0.0323, weight:2.00, lr:0.0005
[12:00:52.869] iteration:17532  t-loss:0.1812, loss-lb:0.0890, loss-ulb:0.0461, weight:2.00, lr:0.0005
[12:00:53.063] iteration:17533  t-loss:0.1920, loss-lb:0.0802, loss-ulb:0.0559, weight:2.00, lr:0.0005
[12:00:53.256] iteration:17534  t-loss:0.1501, loss-lb:0.0757, loss-ulb:0.0372, weight:2.00, lr:0.0005
[12:00:53.448] iteration:17535  t-loss:0.1597, loss-lb:0.0882, loss-ulb:0.0357, weight:2.00, lr:0.0005
[12:00:53.639] iteration:17536  t-loss:0.1652, loss-lb:0.0981, loss-ulb:0.0336, weight:2.00, lr:0.0005
[12:00:53.830] iteration:17537  t-loss:0.1317, loss-lb:0.0739, loss-ulb:0.0289, weight:2.00, lr:0.0005
[12:00:54.022] iteration:17538  t-loss:0.1495, loss-lb:0.0783, loss-ulb:0.0356, weight:2.00, lr:0.0005
[12:00:54.213] iteration:17539  t-loss:0.1532, loss-lb:0.0861, loss-ulb:0.0336, weight:2.00, lr:0.0005
[12:00:54.405] iteration:17540  t-loss:0.1387, loss-lb:0.0776, loss-ulb:0.0306, weight:2.00, lr:0.0005
[12:00:54.595] iteration:17541  t-loss:0.1431, loss-lb:0.0784, loss-ulb:0.0323, weight:2.00, lr:0.0005
[12:00:54.786] iteration:17542  t-loss:0.1343, loss-lb:0.0723, loss-ulb:0.0310, weight:2.00, lr:0.0005
[12:01:06.928]  <<Test>> - Ep:178  - mean_dice/mean_h95 - S:89.96/1.30, Best-S:90.99, T:89.97/1.34, Best-T:90.48
[12:01:06.928]           - AvgLoss(lb/ulb/all):0.0811/0.0365/0.1527
[12:01:07.507] iteration:17543  t-loss:0.1448, loss-lb:0.0838, loss-ulb:0.0305, weight:2.00, lr:0.0005
[12:01:07.703] iteration:17544  t-loss:0.1435, loss-lb:0.0728, loss-ulb:0.0353, weight:2.00, lr:0.0005
[12:01:07.897] iteration:17545  t-loss:0.1534, loss-lb:0.0793, loss-ulb:0.0370, weight:2.00, lr:0.0005
[12:01:08.090] iteration:17546  t-loss:0.1594, loss-lb:0.0856, loss-ulb:0.0369, weight:2.00, lr:0.0005
[12:01:08.282] iteration:17547  t-loss:0.1632, loss-lb:0.0783, loss-ulb:0.0425, weight:2.00, lr:0.0005
[12:01:08.475] iteration:17548  t-loss:0.1493, loss-lb:0.0776, loss-ulb:0.0358, weight:2.00, lr:0.0005
[12:01:08.667] iteration:17549  t-loss:0.1424, loss-lb:0.0813, loss-ulb:0.0306, weight:2.00, lr:0.0005
[12:01:08.859] iteration:17550  t-loss:0.1476, loss-lb:0.0766, loss-ulb:0.0355, weight:2.00, lr:0.0005
[12:01:09.053] iteration:17551  t-loss:0.1379, loss-lb:0.0769, loss-ulb:0.0305, weight:2.00, lr:0.0005
[12:01:09.247] iteration:17552  t-loss:0.1610, loss-lb:0.0745, loss-ulb:0.0432, weight:2.00, lr:0.0005
[12:01:09.440] iteration:17553  t-loss:0.1441, loss-lb:0.0746, loss-ulb:0.0348, weight:2.00, lr:0.0005
[12:01:09.631] iteration:17554  t-loss:0.1466, loss-lb:0.0857, loss-ulb:0.0304, weight:2.00, lr:0.0005
[12:01:09.822] iteration:17555  t-loss:0.1659, loss-lb:0.0748, loss-ulb:0.0456, weight:2.00, lr:0.0005
[12:01:10.014] iteration:17556  t-loss:0.1457, loss-lb:0.0772, loss-ulb:0.0343, weight:2.00, lr:0.0005
[12:01:10.206] iteration:17557  t-loss:0.1740, loss-lb:0.0770, loss-ulb:0.0485, weight:2.00, lr:0.0005
[12:01:10.397] iteration:17558  t-loss:0.1337, loss-lb:0.0733, loss-ulb:0.0302, weight:2.00, lr:0.0005
[12:01:10.588] iteration:17559  t-loss:0.1706, loss-lb:0.0858, loss-ulb:0.0424, weight:2.00, lr:0.0005
[12:01:10.780] iteration:17560  t-loss:0.1389, loss-lb:0.0841, loss-ulb:0.0274, weight:2.00, lr:0.0005
[12:01:10.971] iteration:17561  t-loss:0.1418, loss-lb:0.0788, loss-ulb:0.0315, weight:2.00, lr:0.0005
[12:01:11.162] iteration:17562  t-loss:0.2002, loss-lb:0.0822, loss-ulb:0.0590, weight:2.00, lr:0.0005
[12:01:11.353] iteration:17563  t-loss:0.1681, loss-lb:0.0829, loss-ulb:0.0426, weight:2.00, lr:0.0005
[12:01:11.545] iteration:17564  t-loss:0.1451, loss-lb:0.0792, loss-ulb:0.0330, weight:2.00, lr:0.0005
[12:01:11.738] iteration:17565  t-loss:0.1451, loss-lb:0.0738, loss-ulb:0.0356, weight:2.00, lr:0.0005
[12:01:11.936] iteration:17566  t-loss:0.1434, loss-lb:0.0729, loss-ulb:0.0352, weight:2.00, lr:0.0005
[12:01:12.126] iteration:17567  t-loss:0.1343, loss-lb:0.0776, loss-ulb:0.0284, weight:2.00, lr:0.0005
[12:01:12.318] iteration:17568  t-loss:0.1559, loss-lb:0.0836, loss-ulb:0.0362, weight:2.00, lr:0.0005
[12:01:12.509] iteration:17569  t-loss:0.1306, loss-lb:0.0747, loss-ulb:0.0279, weight:2.00, lr:0.0005
[12:01:12.702] iteration:17570  t-loss:0.1637, loss-lb:0.0882, loss-ulb:0.0378, weight:2.00, lr:0.0005
[12:01:12.893] iteration:17571  t-loss:0.2748, loss-lb:0.0797, loss-ulb:0.0975, weight:2.00, lr:0.0005
[12:01:13.084] iteration:17572  t-loss:0.1691, loss-lb:0.0869, loss-ulb:0.0411, weight:2.00, lr:0.0005
[12:01:13.276] iteration:17573  t-loss:0.1890, loss-lb:0.0822, loss-ulb:0.0534, weight:2.00, lr:0.0005
[12:01:13.468] iteration:17574  t-loss:0.1573, loss-lb:0.0847, loss-ulb:0.0363, weight:2.00, lr:0.0005
[12:01:13.660] iteration:17575  t-loss:0.1583, loss-lb:0.0787, loss-ulb:0.0398, weight:2.00, lr:0.0005
[12:01:13.854] iteration:17576  t-loss:0.1377, loss-lb:0.0763, loss-ulb:0.0307, weight:2.00, lr:0.0005
[12:01:14.046] iteration:17577  t-loss:0.1412, loss-lb:0.0743, loss-ulb:0.0334, weight:2.00, lr:0.0005
[12:01:14.238] iteration:17578  t-loss:0.1961, loss-lb:0.0821, loss-ulb:0.0570, weight:2.00, lr:0.0005
[12:01:14.429] iteration:17579  t-loss:0.1409, loss-lb:0.0773, loss-ulb:0.0318, weight:2.00, lr:0.0005
[12:01:14.623] iteration:17580  t-loss:0.1497, loss-lb:0.0797, loss-ulb:0.0350, weight:2.00, lr:0.0005
[12:01:14.815] iteration:17581  t-loss:0.1626, loss-lb:0.0768, loss-ulb:0.0429, weight:2.00, lr:0.0005
[12:01:15.007] iteration:17582  t-loss:0.1699, loss-lb:0.0860, loss-ulb:0.0419, weight:2.00, lr:0.0005
[12:01:15.197] iteration:17583  t-loss:0.1695, loss-lb:0.0815, loss-ulb:0.0440, weight:2.00, lr:0.0005
[12:01:15.387] iteration:17584  t-loss:0.1480, loss-lb:0.0867, loss-ulb:0.0306, weight:2.00, lr:0.0005
[12:01:15.580] iteration:17585  t-loss:0.1494, loss-lb:0.0797, loss-ulb:0.0348, weight:2.00, lr:0.0005
[12:01:15.773] iteration:17586  t-loss:0.1582, loss-lb:0.0798, loss-ulb:0.0392, weight:2.00, lr:0.0005
[12:01:15.964] iteration:17587  t-loss:0.1569, loss-lb:0.0820, loss-ulb:0.0375, weight:2.00, lr:0.0005
[12:01:16.157] iteration:17588  t-loss:0.1397, loss-lb:0.0807, loss-ulb:0.0295, weight:2.00, lr:0.0005
[12:01:16.349] iteration:17589  t-loss:0.1402, loss-lb:0.0710, loss-ulb:0.0346, weight:2.00, lr:0.0005
[12:01:16.541] iteration:17590  t-loss:0.1563, loss-lb:0.0763, loss-ulb:0.0400, weight:2.00, lr:0.0005
[12:01:16.730] iteration:17591  t-loss:0.1495, loss-lb:0.0793, loss-ulb:0.0351, weight:2.00, lr:0.0005
[12:01:16.921] iteration:17592  t-loss:0.1368, loss-lb:0.0801, loss-ulb:0.0283, weight:2.00, lr:0.0005
[12:01:17.112] iteration:17593  t-loss:0.1624, loss-lb:0.0863, loss-ulb:0.0380, weight:2.00, lr:0.0005
[12:01:17.304] iteration:17594  t-loss:0.1533, loss-lb:0.0794, loss-ulb:0.0369, weight:2.00, lr:0.0005
[12:01:17.495] iteration:17595  t-loss:0.1516, loss-lb:0.0852, loss-ulb:0.0332, weight:2.00, lr:0.0005
[12:01:17.687] iteration:17596  t-loss:0.1544, loss-lb:0.0779, loss-ulb:0.0382, weight:2.00, lr:0.0005
[12:01:17.878] iteration:17597  t-loss:0.1480, loss-lb:0.0788, loss-ulb:0.0346, weight:2.00, lr:0.0005
[12:01:18.070] iteration:17598  t-loss:0.1518, loss-lb:0.0838, loss-ulb:0.0340, weight:2.00, lr:0.0005
[12:01:18.261] iteration:17599  t-loss:0.1814, loss-lb:0.0842, loss-ulb:0.0486, weight:2.00, lr:0.0005
[12:01:18.451] iteration:17600  t-loss:0.1391, loss-lb:0.0833, loss-ulb:0.0279, weight:2.00, lr:0.0005
[12:01:18.642] iteration:17601  t-loss:0.1550, loss-lb:0.0886, loss-ulb:0.0332, weight:2.00, lr:0.0005
[12:01:18.834] iteration:17602  t-loss:0.1404, loss-lb:0.0707, loss-ulb:0.0348, weight:2.00, lr:0.0005
[12:01:19.024] iteration:17603  t-loss:0.1393, loss-lb:0.0726, loss-ulb:0.0334, weight:2.00, lr:0.0005
[12:01:19.215] iteration:17604  t-loss:0.1479, loss-lb:0.0768, loss-ulb:0.0356, weight:2.00, lr:0.0005
[12:01:19.406] iteration:17605  t-loss:0.1428, loss-lb:0.0843, loss-ulb:0.0292, weight:2.00, lr:0.0005
[12:01:19.598] iteration:17606  t-loss:0.1440, loss-lb:0.0757, loss-ulb:0.0342, weight:2.00, lr:0.0005
[12:01:19.790] iteration:17607  t-loss:0.1611, loss-lb:0.0883, loss-ulb:0.0364, weight:2.00, lr:0.0005
[12:01:19.988] iteration:17608  t-loss:0.2047, loss-lb:0.0790, loss-ulb:0.0629, weight:2.00, lr:0.0005
[12:01:20.183] iteration:17609  t-loss:0.1575, loss-lb:0.0810, loss-ulb:0.0383, weight:2.00, lr:0.0005
[12:01:20.380] iteration:17610  t-loss:0.1443, loss-lb:0.0865, loss-ulb:0.0289, weight:2.00, lr:0.0005
[12:01:20.573] iteration:17611  t-loss:0.1637, loss-lb:0.0798, loss-ulb:0.0420, weight:2.00, lr:0.0005
[12:01:20.763] iteration:17612  t-loss:0.1510, loss-lb:0.0712, loss-ulb:0.0399, weight:2.00, lr:0.0005
[12:01:20.955] iteration:17613  t-loss:0.1478, loss-lb:0.0821, loss-ulb:0.0329, weight:2.00, lr:0.0005
[12:01:21.148] iteration:17614  t-loss:0.1276, loss-lb:0.0724, loss-ulb:0.0276, weight:2.00, lr:0.0005
[12:01:21.339] iteration:17615  t-loss:0.1618, loss-lb:0.0849, loss-ulb:0.0384, weight:2.00, lr:0.0005
[12:01:21.532] iteration:17616  t-loss:0.1403, loss-lb:0.0847, loss-ulb:0.0278, weight:2.00, lr:0.0005
[12:01:21.724] iteration:17617  t-loss:0.1357, loss-lb:0.0765, loss-ulb:0.0296, weight:2.00, lr:0.0005
[12:01:21.917] iteration:17618  t-loss:0.1865, loss-lb:0.0850, loss-ulb:0.0507, weight:2.00, lr:0.0005
[12:01:22.107] iteration:17619  t-loss:0.1529, loss-lb:0.0838, loss-ulb:0.0345, weight:2.00, lr:0.0005
[12:01:22.299] iteration:17620  t-loss:0.1954, loss-lb:0.0793, loss-ulb:0.0580, weight:2.00, lr:0.0005
[12:01:22.491] iteration:17621  t-loss:0.1479, loss-lb:0.0780, loss-ulb:0.0349, weight:2.00, lr:0.0005
[12:01:22.682] iteration:17622  t-loss:0.1380, loss-lb:0.0714, loss-ulb:0.0333, weight:2.00, lr:0.0005
[12:01:22.878] iteration:17623  t-loss:0.1391, loss-lb:0.0699, loss-ulb:0.0346, weight:2.00, lr:0.0005
[12:01:23.071] iteration:17624  t-loss:0.1504, loss-lb:0.0799, loss-ulb:0.0353, weight:2.00, lr:0.0005
[12:01:23.263] iteration:17625  t-loss:0.1599, loss-lb:0.0807, loss-ulb:0.0396, weight:2.00, lr:0.0005
[12:01:23.456] iteration:17626  t-loss:0.1581, loss-lb:0.0769, loss-ulb:0.0406, weight:2.00, lr:0.0005
[12:01:23.648] iteration:17627  t-loss:0.1538, loss-lb:0.0850, loss-ulb:0.0344, weight:2.00, lr:0.0005
[12:01:23.840] iteration:17628  t-loss:0.1400, loss-lb:0.0747, loss-ulb:0.0326, weight:2.00, lr:0.0005
[12:01:24.033] iteration:17629  t-loss:0.1517, loss-lb:0.0756, loss-ulb:0.0381, weight:2.00, lr:0.0005
[12:01:24.226] iteration:17630  t-loss:0.1466, loss-lb:0.0880, loss-ulb:0.0293, weight:2.00, lr:0.0005
[12:01:24.417] iteration:17631  t-loss:0.1406, loss-lb:0.0773, loss-ulb:0.0316, weight:2.00, lr:0.0005
[12:01:24.610] iteration:17632  t-loss:0.1483, loss-lb:0.0828, loss-ulb:0.0328, weight:2.00, lr:0.0005
[12:01:24.801] iteration:17633  t-loss:0.1447, loss-lb:0.0808, loss-ulb:0.0319, weight:2.00, lr:0.0005
[12:01:24.991] iteration:17634  t-loss:0.1372, loss-lb:0.0793, loss-ulb:0.0289, weight:2.00, lr:0.0005
[12:01:25.183] iteration:17635  t-loss:0.2616, loss-lb:0.0827, loss-ulb:0.0895, weight:2.00, lr:0.0005
[12:01:25.375] iteration:17636  t-loss:0.1515, loss-lb:0.0878, loss-ulb:0.0318, weight:2.00, lr:0.0005
[12:01:25.566] iteration:17637  t-loss:0.1337, loss-lb:0.0701, loss-ulb:0.0318, weight:2.00, lr:0.0005
[12:01:25.757] iteration:17638  t-loss:0.1479, loss-lb:0.0775, loss-ulb:0.0352, weight:2.00, lr:0.0005
[12:01:25.948] iteration:17639  t-loss:0.2025, loss-lb:0.0784, loss-ulb:0.0620, weight:2.00, lr:0.0005
[12:01:26.139] iteration:17640  t-loss:0.1453, loss-lb:0.0796, loss-ulb:0.0328, weight:2.00, lr:0.0005
[12:01:26.737] iteration:17641  t-loss:0.1469, loss-lb:0.0759, loss-ulb:0.0355, weight:2.00, lr:0.0005
[12:01:26.931] iteration:17642  t-loss:0.2117, loss-lb:0.0736, loss-ulb:0.0691, weight:2.00, lr:0.0005
[12:01:27.121] iteration:17643  t-loss:0.1517, loss-lb:0.0788, loss-ulb:0.0364, weight:2.00, lr:0.0005
[12:01:27.312] iteration:17644  t-loss:0.1480, loss-lb:0.0858, loss-ulb:0.0311, weight:2.00, lr:0.0005
[12:01:27.504] iteration:17645  t-loss:0.1499, loss-lb:0.0913, loss-ulb:0.0293, weight:2.00, lr:0.0005
[12:01:27.697] iteration:17646  t-loss:0.1422, loss-lb:0.0788, loss-ulb:0.0317, weight:2.00, lr:0.0005
[12:01:27.888] iteration:17647  t-loss:0.1386, loss-lb:0.0781, loss-ulb:0.0302, weight:2.00, lr:0.0005
[12:01:28.080] iteration:17648  t-loss:0.1831, loss-lb:0.0916, loss-ulb:0.0458, weight:2.00, lr:0.0004
[12:01:28.270] iteration:17649  t-loss:0.1520, loss-lb:0.0763, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:01:28.462] iteration:17650  t-loss:0.1414, loss-lb:0.0774, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:01:28.654] iteration:17651  t-loss:0.1499, loss-lb:0.0747, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:01:28.846] iteration:17652  t-loss:0.1866, loss-lb:0.0839, loss-ulb:0.0513, weight:2.00, lr:0.0004
[12:01:29.038] iteration:17653  t-loss:0.1353, loss-lb:0.0733, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:01:29.228] iteration:17654  t-loss:0.1451, loss-lb:0.0829, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:01:29.420] iteration:17655  t-loss:0.1391, loss-lb:0.0768, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:01:29.613] iteration:17656  t-loss:0.1409, loss-lb:0.0803, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:01:29.804] iteration:17657  t-loss:0.1552, loss-lb:0.0850, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:01:29.997] iteration:17658  t-loss:0.1808, loss-lb:0.0826, loss-ulb:0.0491, weight:2.00, lr:0.0004
[12:01:30.188] iteration:17659  t-loss:0.1560, loss-lb:0.0874, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:01:30.380] iteration:17660  t-loss:0.1601, loss-lb:0.0820, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:01:30.573] iteration:17661  t-loss:0.1472, loss-lb:0.0819, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:01:30.767] iteration:17662  t-loss:0.1358, loss-lb:0.0766, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:01:30.964] iteration:17663  t-loss:0.1669, loss-lb:0.0827, loss-ulb:0.0421, weight:2.00, lr:0.0004
[12:01:31.159] iteration:17664  t-loss:0.1399, loss-lb:0.0790, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:01:31.351] iteration:17665  t-loss:0.1565, loss-lb:0.0916, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:01:31.545] iteration:17666  t-loss:0.1687, loss-lb:0.1036, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:01:31.738] iteration:17667  t-loss:0.3969, loss-lb:0.0807, loss-ulb:0.1581, weight:2.00, lr:0.0004
[12:01:31.929] iteration:17668  t-loss:0.3111, loss-lb:0.0833, loss-ulb:0.1139, weight:2.00, lr:0.0004
[12:01:32.122] iteration:17669  t-loss:0.1703, loss-lb:0.0832, loss-ulb:0.0436, weight:2.00, lr:0.0004
[12:01:32.316] iteration:17670  t-loss:0.1527, loss-lb:0.0898, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:01:32.508] iteration:17671  t-loss:0.1887, loss-lb:0.0822, loss-ulb:0.0532, weight:2.00, lr:0.0004
[12:01:32.700] iteration:17672  t-loss:0.1579, loss-lb:0.0874, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:01:32.893] iteration:17673  t-loss:0.1536, loss-lb:0.0765, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:01:33.085] iteration:17674  t-loss:0.1504, loss-lb:0.0843, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:01:33.277] iteration:17675  t-loss:0.1611, loss-lb:0.0843, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:01:33.469] iteration:17676  t-loss:0.1536, loss-lb:0.0843, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:01:33.661] iteration:17677  t-loss:0.1557, loss-lb:0.0885, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:01:33.853] iteration:17678  t-loss:0.1745, loss-lb:0.0823, loss-ulb:0.0461, weight:2.00, lr:0.0004
[12:01:34.045] iteration:17679  t-loss:0.1561, loss-lb:0.0874, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:01:34.237] iteration:17680  t-loss:0.1505, loss-lb:0.0779, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:01:34.431] iteration:17681  t-loss:0.1914, loss-lb:0.0859, loss-ulb:0.0528, weight:2.00, lr:0.0004
[12:01:34.623] iteration:17682  t-loss:0.1498, loss-lb:0.0892, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:01:34.815] iteration:17683  t-loss:0.1759, loss-lb:0.0795, loss-ulb:0.0482, weight:2.00, lr:0.0004
[12:01:35.009] iteration:17684  t-loss:0.2021, loss-lb:0.0941, loss-ulb:0.0540, weight:2.00, lr:0.0004
[12:01:35.201] iteration:17685  t-loss:0.1462, loss-lb:0.0836, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:01:35.393] iteration:17686  t-loss:0.1544, loss-lb:0.0822, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:01:35.585] iteration:17687  t-loss:0.1580, loss-lb:0.0885, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:01:35.793] iteration:17688  t-loss:0.1694, loss-lb:0.0780, loss-ulb:0.0457, weight:2.00, lr:0.0004
[12:01:35.986] iteration:17689  t-loss:0.1629, loss-lb:0.0833, loss-ulb:0.0398, weight:2.00, lr:0.0004
[12:01:36.177] iteration:17690  t-loss:0.1601, loss-lb:0.0845, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:01:36.371] iteration:17691  t-loss:0.1395, loss-lb:0.0806, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:01:36.575] iteration:17692  t-loss:0.1524, loss-lb:0.0883, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:01:36.774] iteration:17693  t-loss:0.1782, loss-lb:0.0965, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:01:36.967] iteration:17694  t-loss:0.1548, loss-lb:0.0822, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:01:37.159] iteration:17695  t-loss:0.1488, loss-lb:0.0849, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:01:37.352] iteration:17696  t-loss:0.1492, loss-lb:0.0818, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:01:37.544] iteration:17697  t-loss:0.1590, loss-lb:0.0810, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:01:37.737] iteration:17698  t-loss:0.1839, loss-lb:0.0784, loss-ulb:0.0528, weight:2.00, lr:0.0004
[12:01:37.930] iteration:17699  t-loss:0.1475, loss-lb:0.0863, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:01:38.122] iteration:17700  t-loss:0.1461, loss-lb:0.0882, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:01:38.313] iteration:17701  t-loss:0.1474, loss-lb:0.0789, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:01:38.505] iteration:17702  t-loss:0.1424, loss-lb:0.0754, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:01:38.697] iteration:17703  t-loss:0.1671, loss-lb:0.0783, loss-ulb:0.0444, weight:2.00, lr:0.0004
[12:01:38.889] iteration:17704  t-loss:0.1363, loss-lb:0.0771, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:01:39.080] iteration:17705  t-loss:0.1405, loss-lb:0.0794, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:01:39.271] iteration:17706  t-loss:0.1594, loss-lb:0.0905, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:01:39.463] iteration:17707  t-loss:0.1915, loss-lb:0.0822, loss-ulb:0.0546, weight:2.00, lr:0.0004
[12:01:39.655] iteration:17708  t-loss:0.1603, loss-lb:0.0815, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:01:39.847] iteration:17709  t-loss:0.1643, loss-lb:0.0836, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:01:40.038] iteration:17710  t-loss:0.1393, loss-lb:0.0763, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:01:40.230] iteration:17711  t-loss:0.1505, loss-lb:0.0816, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:01:40.422] iteration:17712  t-loss:0.1652, loss-lb:0.0866, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:01:40.614] iteration:17713  t-loss:0.1436, loss-lb:0.0701, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:01:40.805] iteration:17714  t-loss:0.1647, loss-lb:0.0900, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:01:40.998] iteration:17715  t-loss:0.1804, loss-lb:0.0857, loss-ulb:0.0473, weight:2.00, lr:0.0004
[12:01:41.190] iteration:17716  t-loss:0.1792, loss-lb:0.0765, loss-ulb:0.0513, weight:2.00, lr:0.0004
[12:01:41.382] iteration:17717  t-loss:0.2274, loss-lb:0.0841, loss-ulb:0.0716, weight:2.00, lr:0.0004
[12:01:41.575] iteration:17718  t-loss:0.1584, loss-lb:0.0803, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:01:41.770] iteration:17719  t-loss:0.1614, loss-lb:0.0854, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:01:41.966] iteration:17720  t-loss:0.1459, loss-lb:0.0801, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:01:42.161] iteration:17721  t-loss:0.1355, loss-lb:0.0794, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:01:42.353] iteration:17722  t-loss:0.1951, loss-lb:0.0870, loss-ulb:0.0540, weight:2.00, lr:0.0004
[12:01:42.545] iteration:17723  t-loss:0.1464, loss-lb:0.0804, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:01:42.737] iteration:17724  t-loss:0.1390, loss-lb:0.0754, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:01:42.929] iteration:17725  t-loss:0.1589, loss-lb:0.0826, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:01:43.121] iteration:17726  t-loss:0.1336, loss-lb:0.0701, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:01:43.313] iteration:17727  t-loss:0.1362, loss-lb:0.0761, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:01:43.505] iteration:17728  t-loss:0.1438, loss-lb:0.0844, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:01:43.697] iteration:17729  t-loss:0.1622, loss-lb:0.0862, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:01:43.889] iteration:17730  t-loss:0.1544, loss-lb:0.0868, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:01:44.080] iteration:17731  t-loss:0.1601, loss-lb:0.0817, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:01:44.271] iteration:17732  t-loss:0.1569, loss-lb:0.0818, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:01:44.462] iteration:17733  t-loss:0.1489, loss-lb:0.0773, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:01:44.653] iteration:17734  t-loss:0.1486, loss-lb:0.0849, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:01:44.843] iteration:17735  t-loss:0.1815, loss-lb:0.0810, loss-ulb:0.0503, weight:2.00, lr:0.0004
[12:01:45.035] iteration:17736  t-loss:0.1888, loss-lb:0.0819, loss-ulb:0.0534, weight:2.00, lr:0.0004
[12:01:45.225] iteration:17737  t-loss:0.1558, loss-lb:0.0807, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:01:45.416] iteration:17738  t-loss:0.1531, loss-lb:0.0839, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:01:56.745]  <<Test>> - Ep:180  - mean_dice/mean_h95 - S:89.71/1.35, Best-S:90.99, T:90.01/1.34, Best-T:90.48
[12:01:56.745]           - AvgLoss(lb/ulb/all):0.0825/0.0370/0.1553
[12:01:57.282] iteration:17739  t-loss:0.1420, loss-lb:0.0796, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:01:57.482] iteration:17740  t-loss:0.1608, loss-lb:0.0832, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:01:57.675] iteration:17741  t-loss:0.1417, loss-lb:0.0741, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:01:57.869] iteration:17742  t-loss:0.1451, loss-lb:0.0802, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:01:58.063] iteration:17743  t-loss:0.1516, loss-lb:0.0862, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:01:58.255] iteration:17744  t-loss:0.1531, loss-lb:0.0822, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:01:58.448] iteration:17745  t-loss:0.1436, loss-lb:0.0816, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:01:58.642] iteration:17746  t-loss:0.1949, loss-lb:0.0810, loss-ulb:0.0570, weight:2.00, lr:0.0004
[12:01:58.835] iteration:17747  t-loss:0.1399, loss-lb:0.0746, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:01:59.028] iteration:17748  t-loss:0.1446, loss-lb:0.0746, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:01:59.221] iteration:17749  t-loss:0.1311, loss-lb:0.0734, loss-ulb:0.0289, weight:2.00, lr:0.0004
[12:01:59.414] iteration:17750  t-loss:0.1461, loss-lb:0.0864, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:01:59.607] iteration:17751  t-loss:0.1479, loss-lb:0.0836, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:01:59.801] iteration:17752  t-loss:0.1458, loss-lb:0.0871, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:01:59.994] iteration:17753  t-loss:0.2121, loss-lb:0.0784, loss-ulb:0.0669, weight:2.00, lr:0.0004
[12:02:00.187] iteration:17754  t-loss:0.1388, loss-lb:0.0756, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:02:00.380] iteration:17755  t-loss:0.1551, loss-lb:0.0822, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:02:00.574] iteration:17756  t-loss:0.1641, loss-lb:0.0833, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:02:00.766] iteration:17757  t-loss:0.1395, loss-lb:0.0790, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:02:00.959] iteration:17758  t-loss:0.1387, loss-lb:0.0839, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:02:01.152] iteration:17759  t-loss:0.1538, loss-lb:0.0833, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:02:01.346] iteration:17760  t-loss:0.1702, loss-lb:0.0780, loss-ulb:0.0461, weight:2.00, lr:0.0004
[12:02:01.538] iteration:17761  t-loss:0.1391, loss-lb:0.0803, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:02:01.732] iteration:17762  t-loss:0.1395, loss-lb:0.0766, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:02:01.925] iteration:17763  t-loss:0.1390, loss-lb:0.0774, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:02:02.118] iteration:17764  t-loss:0.1702, loss-lb:0.0814, loss-ulb:0.0444, weight:2.00, lr:0.0004
[12:02:02.309] iteration:17765  t-loss:0.1428, loss-lb:0.0846, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:02:02.502] iteration:17766  t-loss:0.1528, loss-lb:0.0923, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:02:02.695] iteration:17767  t-loss:0.1434, loss-lb:0.0803, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:02:02.888] iteration:17768  t-loss:0.1395, loss-lb:0.0836, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:02:03.080] iteration:17769  t-loss:0.1577, loss-lb:0.0814, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:02:03.273] iteration:17770  t-loss:0.1471, loss-lb:0.0813, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:02:03.465] iteration:17771  t-loss:0.1675, loss-lb:0.0868, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:02:03.657] iteration:17772  t-loss:0.1530, loss-lb:0.0711, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:02:03.850] iteration:17773  t-loss:0.1289, loss-lb:0.0738, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:02:04.043] iteration:17774  t-loss:0.1659, loss-lb:0.0880, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:02:04.234] iteration:17775  t-loss:0.1632, loss-lb:0.0924, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:02:04.427] iteration:17776  t-loss:0.1344, loss-lb:0.0779, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:02:04.621] iteration:17777  t-loss:0.1794, loss-lb:0.0794, loss-ulb:0.0500, weight:2.00, lr:0.0004
[12:02:04.814] iteration:17778  t-loss:0.1736, loss-lb:0.0828, loss-ulb:0.0454, weight:2.00, lr:0.0004
[12:02:05.008] iteration:17779  t-loss:0.1833, loss-lb:0.0953, loss-ulb:0.0440, weight:2.00, lr:0.0004
[12:02:05.200] iteration:17780  t-loss:0.1656, loss-lb:0.0854, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:02:05.393] iteration:17781  t-loss:0.2707, loss-lb:0.0809, loss-ulb:0.0949, weight:2.00, lr:0.0004
[12:02:05.585] iteration:17782  t-loss:0.1532, loss-lb:0.0837, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:02:05.778] iteration:17783  t-loss:0.1446, loss-lb:0.0783, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:02:05.970] iteration:17784  t-loss:0.1488, loss-lb:0.0781, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:02:06.163] iteration:17785  t-loss:0.1481, loss-lb:0.0809, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:02:06.355] iteration:17786  t-loss:0.1948, loss-lb:0.0784, loss-ulb:0.0582, weight:2.00, lr:0.0004
[12:02:06.548] iteration:17787  t-loss:0.1696, loss-lb:0.0875, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:02:06.743] iteration:17788  t-loss:0.1359, loss-lb:0.0767, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:02:06.935] iteration:17789  t-loss:0.1730, loss-lb:0.0779, loss-ulb:0.0475, weight:2.00, lr:0.0004
[12:02:07.128] iteration:17790  t-loss:0.1756, loss-lb:0.1049, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:02:07.320] iteration:17791  t-loss:0.1644, loss-lb:0.0876, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:02:07.512] iteration:17792  t-loss:0.1484, loss-lb:0.0789, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:02:07.705] iteration:17793  t-loss:0.1466, loss-lb:0.0794, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:02:07.897] iteration:17794  t-loss:0.1555, loss-lb:0.0769, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:02:08.089] iteration:17795  t-loss:0.1451, loss-lb:0.0839, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:02:08.282] iteration:17796  t-loss:0.1434, loss-lb:0.0791, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:02:08.474] iteration:17797  t-loss:0.1675, loss-lb:0.0909, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:02:08.666] iteration:17798  t-loss:0.1555, loss-lb:0.0905, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:02:08.860] iteration:17799  t-loss:0.1861, loss-lb:0.0840, loss-ulb:0.0511, weight:2.00, lr:0.0004
[12:02:09.052] iteration:17800  t-loss:0.1750, loss-lb:0.0756, loss-ulb:0.0497, weight:2.00, lr:0.0004
[12:02:09.258] iteration:17801  t-loss:0.1289, loss-lb:0.0778, loss-ulb:0.0255, weight:2.00, lr:0.0004
[12:02:09.457] iteration:17802  t-loss:0.1367, loss-lb:0.0801, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:02:09.652] iteration:17803  t-loss:0.1484, loss-lb:0.0775, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:02:09.844] iteration:17804  t-loss:0.1529, loss-lb:0.0872, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:02:10.036] iteration:17805  t-loss:0.1534, loss-lb:0.0850, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:02:10.229] iteration:17806  t-loss:0.1503, loss-lb:0.0803, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:02:10.421] iteration:17807  t-loss:0.1761, loss-lb:0.0929, loss-ulb:0.0416, weight:2.00, lr:0.0004
[12:02:10.613] iteration:17808  t-loss:0.1439, loss-lb:0.0785, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:02:10.807] iteration:17809  t-loss:0.1465, loss-lb:0.0791, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:02:11.000] iteration:17810  t-loss:0.2196, loss-lb:0.0802, loss-ulb:0.0697, weight:2.00, lr:0.0004
[12:02:11.192] iteration:17811  t-loss:0.1763, loss-lb:0.0839, loss-ulb:0.0462, weight:2.00, lr:0.0004
[12:02:11.385] iteration:17812  t-loss:0.1469, loss-lb:0.0823, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:02:11.577] iteration:17813  t-loss:0.1440, loss-lb:0.0775, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:02:11.770] iteration:17814  t-loss:0.1655, loss-lb:0.0825, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:02:11.963] iteration:17815  t-loss:0.1385, loss-lb:0.0752, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:02:12.156] iteration:17816  t-loss:0.1544, loss-lb:0.0871, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:02:12.348] iteration:17817  t-loss:0.1588, loss-lb:0.0912, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:02:12.540] iteration:17818  t-loss:0.1456, loss-lb:0.0781, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:02:12.733] iteration:17819  t-loss:0.1382, loss-lb:0.0726, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:02:12.925] iteration:17820  t-loss:0.1445, loss-lb:0.0749, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:02:13.118] iteration:17821  t-loss:0.1647, loss-lb:0.0825, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:02:13.310] iteration:17822  t-loss:0.1544, loss-lb:0.0770, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:02:13.503] iteration:17823  t-loss:0.1432, loss-lb:0.0746, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:02:13.696] iteration:17824  t-loss:0.1599, loss-lb:0.0849, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:02:13.889] iteration:17825  t-loss:0.2971, loss-lb:0.0806, loss-ulb:0.1083, weight:2.00, lr:0.0004
[12:02:14.081] iteration:17826  t-loss:0.1533, loss-lb:0.0766, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:02:14.274] iteration:17827  t-loss:0.1536, loss-lb:0.0856, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:02:14.467] iteration:17828  t-loss:0.1362, loss-lb:0.0839, loss-ulb:0.0262, weight:2.00, lr:0.0004
[12:02:14.658] iteration:17829  t-loss:0.1548, loss-lb:0.0799, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:02:14.849] iteration:17830  t-loss:0.1491, loss-lb:0.0807, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:02:15.040] iteration:17831  t-loss:0.1434, loss-lb:0.0850, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:02:15.232] iteration:17832  t-loss:0.1561, loss-lb:0.0927, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:02:15.422] iteration:17833  t-loss:0.1416, loss-lb:0.0752, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:02:15.613] iteration:17834  t-loss:0.1625, loss-lb:0.0851, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:02:15.804] iteration:17835  t-loss:0.1696, loss-lb:0.0830, loss-ulb:0.0433, weight:2.00, lr:0.0004
[12:02:15.995] iteration:17836  t-loss:0.1547, loss-lb:0.0840, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:02:16.580] iteration:17837  t-loss:0.1563, loss-lb:0.0806, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:02:16.774] iteration:17838  t-loss:0.1372, loss-lb:0.0826, loss-ulb:0.0273, weight:2.00, lr:0.0004
[12:02:16.966] iteration:17839  t-loss:0.1519, loss-lb:0.0874, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:02:17.159] iteration:17840  t-loss:0.1405, loss-lb:0.0846, loss-ulb:0.0280, weight:2.00, lr:0.0004
[12:02:17.352] iteration:17841  t-loss:0.1407, loss-lb:0.0793, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:02:17.544] iteration:17842  t-loss:0.1379, loss-lb:0.0763, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:02:17.737] iteration:17843  t-loss:0.1330, loss-lb:0.0759, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:02:17.929] iteration:17844  t-loss:0.1681, loss-lb:0.0825, loss-ulb:0.0428, weight:2.00, lr:0.0004
[12:02:18.122] iteration:17845  t-loss:0.1414, loss-lb:0.0758, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:02:18.315] iteration:17846  t-loss:0.1460, loss-lb:0.0756, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:02:18.507] iteration:17847  t-loss:0.1636, loss-lb:0.0844, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:02:18.699] iteration:17848  t-loss:0.1487, loss-lb:0.0775, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:02:18.892] iteration:17849  t-loss:0.1662, loss-lb:0.0868, loss-ulb:0.0397, weight:2.00, lr:0.0004
[12:02:19.083] iteration:17850  t-loss:0.1575, loss-lb:0.0934, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:02:19.275] iteration:17851  t-loss:0.1484, loss-lb:0.0739, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:02:19.469] iteration:17852  t-loss:0.1732, loss-lb:0.0696, loss-ulb:0.0518, weight:2.00, lr:0.0004
[12:02:19.662] iteration:17853  t-loss:0.1538, loss-lb:0.0810, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:02:19.854] iteration:17854  t-loss:0.1475, loss-lb:0.0824, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:02:20.046] iteration:17855  t-loss:0.1602, loss-lb:0.0863, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:02:20.238] iteration:17856  t-loss:0.1402, loss-lb:0.0760, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:02:20.431] iteration:17857  t-loss:0.1515, loss-lb:0.0761, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:02:20.624] iteration:17858  t-loss:0.1633, loss-lb:0.0885, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:02:20.817] iteration:17859  t-loss:0.1581, loss-lb:0.0804, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:02:21.010] iteration:17860  t-loss:0.1409, loss-lb:0.0776, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:02:21.202] iteration:17861  t-loss:0.1592, loss-lb:0.0809, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:02:21.395] iteration:17862  t-loss:0.1405, loss-lb:0.0749, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:02:21.588] iteration:17863  t-loss:0.1693, loss-lb:0.0814, loss-ulb:0.0439, weight:2.00, lr:0.0004
[12:02:21.780] iteration:17864  t-loss:0.1460, loss-lb:0.0807, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:02:21.973] iteration:17865  t-loss:0.1430, loss-lb:0.0793, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:02:22.166] iteration:17866  t-loss:0.1452, loss-lb:0.0844, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:02:22.359] iteration:17867  t-loss:0.1465, loss-lb:0.0770, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:02:22.551] iteration:17868  t-loss:0.1461, loss-lb:0.0820, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:02:22.744] iteration:17869  t-loss:0.1525, loss-lb:0.0780, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:02:22.937] iteration:17870  t-loss:0.1535, loss-lb:0.0795, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:02:23.131] iteration:17871  t-loss:0.1402, loss-lb:0.0767, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:02:23.324] iteration:17872  t-loss:0.1692, loss-lb:0.0974, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:02:23.517] iteration:17873  t-loss:0.2032, loss-lb:0.0877, loss-ulb:0.0577, weight:2.00, lr:0.0004
[12:02:23.710] iteration:17874  t-loss:0.1526, loss-lb:0.0821, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:02:23.902] iteration:17875  t-loss:0.1451, loss-lb:0.0797, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:02:24.095] iteration:17876  t-loss:0.1390, loss-lb:0.0807, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:02:24.287] iteration:17877  t-loss:0.1367, loss-lb:0.0763, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:02:24.481] iteration:17878  t-loss:0.1497, loss-lb:0.0757, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:02:24.674] iteration:17879  t-loss:0.2032, loss-lb:0.1048, loss-ulb:0.0492, weight:2.00, lr:0.0004
[12:02:24.867] iteration:17880  t-loss:0.1549, loss-lb:0.0744, loss-ulb:0.0402, weight:2.00, lr:0.0004
[12:02:25.060] iteration:17881  t-loss:0.1282, loss-lb:0.0761, loss-ulb:0.0261, weight:2.00, lr:0.0004
[12:02:25.252] iteration:17882  t-loss:0.1590, loss-lb:0.0772, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:02:25.445] iteration:17883  t-loss:0.1413, loss-lb:0.0754, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:02:25.638] iteration:17884  t-loss:0.1536, loss-lb:0.0764, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:02:25.830] iteration:17885  t-loss:0.1433, loss-lb:0.0857, loss-ulb:0.0288, weight:2.00, lr:0.0004
[12:02:26.023] iteration:17886  t-loss:0.1468, loss-lb:0.0777, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:02:26.217] iteration:17887  t-loss:0.2204, loss-lb:0.0795, loss-ulb:0.0704, weight:2.00, lr:0.0004
[12:02:26.410] iteration:17888  t-loss:0.1667, loss-lb:0.0791, loss-ulb:0.0438, weight:2.00, lr:0.0004
[12:02:26.602] iteration:17889  t-loss:0.1697, loss-lb:0.0881, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:02:26.794] iteration:17890  t-loss:0.1365, loss-lb:0.0737, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:02:26.987] iteration:17891  t-loss:0.1369, loss-lb:0.0754, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:02:27.180] iteration:17892  t-loss:0.1338, loss-lb:0.0747, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:02:27.372] iteration:17893  t-loss:0.1531, loss-lb:0.0775, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:02:27.565] iteration:17894  t-loss:0.1596, loss-lb:0.0766, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:02:27.758] iteration:17895  t-loss:0.1499, loss-lb:0.0796, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:02:27.949] iteration:17896  t-loss:0.1469, loss-lb:0.0774, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:02:28.143] iteration:17897  t-loss:0.1284, loss-lb:0.0749, loss-ulb:0.0268, weight:2.00, lr:0.0004
[12:02:28.336] iteration:17898  t-loss:0.1371, loss-lb:0.0730, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:02:28.528] iteration:17899  t-loss:0.1490, loss-lb:0.0822, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:02:28.720] iteration:17900  t-loss:0.1532, loss-lb:0.0824, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:02:28.913] iteration:17901  t-loss:0.1515, loss-lb:0.0807, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:02:29.106] iteration:17902  t-loss:0.1450, loss-lb:0.0748, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:02:29.299] iteration:17903  t-loss:0.1534, loss-lb:0.0833, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:02:29.493] iteration:17904  t-loss:0.1405, loss-lb:0.0787, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:02:29.685] iteration:17905  t-loss:0.1388, loss-lb:0.0804, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:02:29.878] iteration:17906  t-loss:0.1489, loss-lb:0.0838, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:02:30.071] iteration:17907  t-loss:0.1514, loss-lb:0.0726, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:02:30.263] iteration:17908  t-loss:0.1412, loss-lb:0.0799, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:02:30.456] iteration:17909  t-loss:0.1423, loss-lb:0.0861, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:02:30.648] iteration:17910  t-loss:0.1489, loss-lb:0.0792, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:02:30.841] iteration:17911  t-loss:0.1561, loss-lb:0.0789, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:02:31.034] iteration:17912  t-loss:0.1499, loss-lb:0.0828, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:02:31.226] iteration:17913  t-loss:0.1625, loss-lb:0.0776, loss-ulb:0.0424, weight:2.00, lr:0.0004
[12:02:31.420] iteration:17914  t-loss:0.1298, loss-lb:0.0689, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:02:31.613] iteration:17915  t-loss:0.1488, loss-lb:0.0887, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:02:31.806] iteration:17916  t-loss:0.1446, loss-lb:0.0786, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:02:31.998] iteration:17917  t-loss:0.1272, loss-lb:0.0705, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:02:32.191] iteration:17918  t-loss:0.1490, loss-lb:0.0829, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:02:32.385] iteration:17919  t-loss:0.1472, loss-lb:0.0813, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:02:32.576] iteration:17920  t-loss:0.1600, loss-lb:0.0843, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:02:32.770] iteration:17921  t-loss:0.1822, loss-lb:0.0703, loss-ulb:0.0559, weight:2.00, lr:0.0004
[12:02:32.963] iteration:17922  t-loss:0.1472, loss-lb:0.0805, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:02:33.156] iteration:17923  t-loss:0.1519, loss-lb:0.0898, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:02:33.350] iteration:17924  t-loss:0.1503, loss-lb:0.0813, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:02:33.544] iteration:17925  t-loss:0.1688, loss-lb:0.1011, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:02:33.737] iteration:17926  t-loss:0.1548, loss-lb:0.0761, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:02:33.929] iteration:17927  t-loss:0.1388, loss-lb:0.0771, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:02:34.121] iteration:17928  t-loss:0.1465, loss-lb:0.0797, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:02:34.312] iteration:17929  t-loss:0.1263, loss-lb:0.0698, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:02:34.503] iteration:17930  t-loss:0.1362, loss-lb:0.0815, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:02:34.694] iteration:17931  t-loss:0.1312, loss-lb:0.0751, loss-ulb:0.0280, weight:2.00, lr:0.0004
[12:02:34.885] iteration:17932  t-loss:0.1523, loss-lb:0.0880, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:02:35.076] iteration:17933  t-loss:0.1403, loss-lb:0.0753, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:02:35.267] iteration:17934  t-loss:0.1456, loss-lb:0.0758, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:02:48.135]  <<Test>> - Ep:182  - mean_dice/mean_h95 - S:89.82/1.34, Best-S:90.99, T:89.80/1.35, Best-T:90.48
[12:02:48.136]           - AvgLoss(lb/ulb/all):0.0801/0.0335/0.1475
[12:02:48.661] iteration:17935  t-loss:0.1542, loss-lb:0.0783, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:02:48.861] iteration:17936  t-loss:0.1495, loss-lb:0.0724, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:02:49.058] iteration:17937  t-loss:0.1348, loss-lb:0.0739, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:02:49.249] iteration:17938  t-loss:0.1437, loss-lb:0.0753, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:02:49.442] iteration:17939  t-loss:0.1431, loss-lb:0.0920, loss-ulb:0.0255, weight:2.00, lr:0.0004
[12:02:49.635] iteration:17940  t-loss:0.1388, loss-lb:0.0753, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:02:49.827] iteration:17941  t-loss:0.1578, loss-lb:0.0893, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:02:50.020] iteration:17942  t-loss:0.1574, loss-lb:0.0829, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:02:50.213] iteration:17943  t-loss:0.1363, loss-lb:0.0806, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:02:50.406] iteration:17944  t-loss:0.1531, loss-lb:0.0720, loss-ulb:0.0406, weight:2.00, lr:0.0004
[12:02:50.598] iteration:17945  t-loss:0.1374, loss-lb:0.0745, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:02:50.790] iteration:17946  t-loss:0.1360, loss-lb:0.0720, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:02:50.983] iteration:17947  t-loss:0.1875, loss-lb:0.0847, loss-ulb:0.0514, weight:2.00, lr:0.0004
[12:02:51.176] iteration:17948  t-loss:0.1484, loss-lb:0.0842, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:02:51.367] iteration:17949  t-loss:0.1428, loss-lb:0.0727, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:02:51.559] iteration:17950  t-loss:0.1560, loss-lb:0.0884, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:02:51.751] iteration:17951  t-loss:0.1664, loss-lb:0.0839, loss-ulb:0.0412, weight:2.00, lr:0.0004
[12:02:51.944] iteration:17952  t-loss:0.1445, loss-lb:0.0754, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:02:52.136] iteration:17953  t-loss:0.1471, loss-lb:0.0883, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:02:52.327] iteration:17954  t-loss:0.1451, loss-lb:0.0750, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:02:52.521] iteration:17955  t-loss:0.1418, loss-lb:0.0762, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:02:52.713] iteration:17956  t-loss:0.1479, loss-lb:0.0812, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:02:52.905] iteration:17957  t-loss:0.1359, loss-lb:0.0791, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:02:53.096] iteration:17958  t-loss:0.1435, loss-lb:0.0759, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:02:53.289] iteration:17959  t-loss:0.1411, loss-lb:0.0785, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:02:53.484] iteration:17960  t-loss:0.1430, loss-lb:0.0778, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:02:53.679] iteration:17961  t-loss:0.1476, loss-lb:0.0823, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:02:53.873] iteration:17962  t-loss:0.1429, loss-lb:0.0735, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:02:54.069] iteration:17963  t-loss:0.1518, loss-lb:0.0779, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:02:54.264] iteration:17964  t-loss:0.1652, loss-lb:0.0852, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:02:54.456] iteration:17965  t-loss:0.1389, loss-lb:0.0755, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:02:54.646] iteration:17966  t-loss:0.1323, loss-lb:0.0772, loss-ulb:0.0275, weight:2.00, lr:0.0004
[12:02:54.838] iteration:17967  t-loss:0.1438, loss-lb:0.0861, loss-ulb:0.0289, weight:2.00, lr:0.0004
[12:02:55.031] iteration:17968  t-loss:0.1554, loss-lb:0.0715, loss-ulb:0.0420, weight:2.00, lr:0.0004
[12:02:55.224] iteration:17969  t-loss:0.1434, loss-lb:0.0740, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:02:55.415] iteration:17970  t-loss:0.1508, loss-lb:0.0763, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:02:55.609] iteration:17971  t-loss:0.1436, loss-lb:0.0866, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:02:55.801] iteration:17972  t-loss:0.1546, loss-lb:0.0845, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:02:55.992] iteration:17973  t-loss:0.1507, loss-lb:0.0859, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:02:56.183] iteration:17974  t-loss:0.1433, loss-lb:0.0741, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:02:56.376] iteration:17975  t-loss:0.1357, loss-lb:0.0800, loss-ulb:0.0278, weight:2.00, lr:0.0004
[12:02:56.570] iteration:17976  t-loss:0.1501, loss-lb:0.0774, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:02:56.762] iteration:17977  t-loss:0.1383, loss-lb:0.0787, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:02:56.952] iteration:17978  t-loss:0.1545, loss-lb:0.0713, loss-ulb:0.0416, weight:2.00, lr:0.0004
[12:02:57.144] iteration:17979  t-loss:0.1479, loss-lb:0.0803, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:02:57.335] iteration:17980  t-loss:0.1518, loss-lb:0.0761, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:02:57.528] iteration:17981  t-loss:0.1343, loss-lb:0.0697, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:02:57.719] iteration:17982  t-loss:0.1405, loss-lb:0.0710, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:02:57.913] iteration:17983  t-loss:0.1499, loss-lb:0.0858, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:02:58.106] iteration:17984  t-loss:0.1336, loss-lb:0.0756, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:02:58.298] iteration:17985  t-loss:0.1418, loss-lb:0.0731, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:02:58.489] iteration:17986  t-loss:0.1385, loss-lb:0.0837, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:02:58.682] iteration:17987  t-loss:0.1438, loss-lb:0.0751, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:02:58.875] iteration:17988  t-loss:0.1584, loss-lb:0.0735, loss-ulb:0.0425, weight:2.00, lr:0.0004
[12:02:59.067] iteration:17989  t-loss:0.1281, loss-lb:0.0687, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:02:59.259] iteration:17990  t-loss:0.1495, loss-lb:0.0876, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:02:59.453] iteration:17991  t-loss:0.1493, loss-lb:0.0922, loss-ulb:0.0286, weight:2.00, lr:0.0004
[12:02:59.644] iteration:17992  t-loss:0.1422, loss-lb:0.0719, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:02:59.836] iteration:17993  t-loss:0.1357, loss-lb:0.0734, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:03:00.029] iteration:17994  t-loss:0.1445, loss-lb:0.0767, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:03:00.220] iteration:17995  t-loss:0.1549, loss-lb:0.0796, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:03:00.412] iteration:17996  t-loss:0.1307, loss-lb:0.0727, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:03:00.604] iteration:17997  t-loss:0.1454, loss-lb:0.0785, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:03:00.797] iteration:17998  t-loss:0.1599, loss-lb:0.0898, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:03:00.990] iteration:17999  t-loss:0.1519, loss-lb:0.0914, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:03:01.182] iteration:18000  t-loss:0.1557, loss-lb:0.0822, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:03:01.373] iteration:18001  t-loss:0.1559, loss-lb:0.0942, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:03:01.566] iteration:18002  t-loss:0.1479, loss-lb:0.0799, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:03:01.758] iteration:18003  t-loss:0.1532, loss-lb:0.0757, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:03:01.950] iteration:18004  t-loss:0.1382, loss-lb:0.0722, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:03:02.142] iteration:18005  t-loss:0.1432, loss-lb:0.0780, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:03:02.335] iteration:18006  t-loss:0.1414, loss-lb:0.0772, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:03:02.527] iteration:18007  t-loss:0.1500, loss-lb:0.0783, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:03:02.719] iteration:18008  t-loss:0.1445, loss-lb:0.0735, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:03:02.910] iteration:18009  t-loss:0.1391, loss-lb:0.0787, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:03:03.102] iteration:18010  t-loss:0.1532, loss-lb:0.0817, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:03:03.294] iteration:18011  t-loss:0.2800, loss-lb:0.0805, loss-ulb:0.0998, weight:2.00, lr:0.0004
[12:03:03.486] iteration:18012  t-loss:0.1441, loss-lb:0.0799, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:03:03.678] iteration:18013  t-loss:0.1548, loss-lb:0.0853, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:03:03.871] iteration:18014  t-loss:0.1736, loss-lb:0.0763, loss-ulb:0.0487, weight:2.00, lr:0.0004
[12:03:04.062] iteration:18015  t-loss:0.1279, loss-lb:0.0721, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:03:04.254] iteration:18016  t-loss:0.1429, loss-lb:0.0840, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:03:04.449] iteration:18017  t-loss:0.1348, loss-lb:0.0709, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:03:04.643] iteration:18018  t-loss:0.1505, loss-lb:0.0771, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:03:04.840] iteration:18019  t-loss:0.2126, loss-lb:0.0818, loss-ulb:0.0654, weight:2.00, lr:0.0004
[12:03:05.035] iteration:18020  t-loss:0.1425, loss-lb:0.0791, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:03:05.228] iteration:18021  t-loss:0.1421, loss-lb:0.0783, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:03:05.422] iteration:18022  t-loss:0.1346, loss-lb:0.0798, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:03:05.614] iteration:18023  t-loss:0.1431, loss-lb:0.0765, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:03:05.807] iteration:18024  t-loss:0.1357, loss-lb:0.0739, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:03:05.997] iteration:18025  t-loss:0.1443, loss-lb:0.0812, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:03:06.189] iteration:18026  t-loss:0.1961, loss-lb:0.0861, loss-ulb:0.0550, weight:2.00, lr:0.0004
[12:03:06.380] iteration:18027  t-loss:0.1593, loss-lb:0.0755, loss-ulb:0.0419, weight:2.00, lr:0.0004
[12:03:06.571] iteration:18028  t-loss:0.1595, loss-lb:0.0859, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:03:06.763] iteration:18029  t-loss:0.1540, loss-lb:0.0761, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:03:06.954] iteration:18030  t-loss:0.1376, loss-lb:0.0710, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:03:07.145] iteration:18031  t-loss:0.1562, loss-lb:0.0704, loss-ulb:0.0429, weight:2.00, lr:0.0004
[12:03:07.334] iteration:18032  t-loss:0.1281, loss-lb:0.0761, loss-ulb:0.0260, weight:2.00, lr:0.0004
[12:03:07.963] iteration:18033  t-loss:0.1413, loss-lb:0.0761, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:03:08.157] iteration:18034  t-loss:0.1625, loss-lb:0.0796, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:03:08.349] iteration:18035  t-loss:0.1733, loss-lb:0.0830, loss-ulb:0.0452, weight:2.00, lr:0.0004
[12:03:08.542] iteration:18036  t-loss:0.1685, loss-lb:0.0758, loss-ulb:0.0463, weight:2.00, lr:0.0004
[12:03:08.735] iteration:18037  t-loss:0.1450, loss-lb:0.0882, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:03:08.928] iteration:18038  t-loss:0.1472, loss-lb:0.0825, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:03:09.120] iteration:18039  t-loss:0.1489, loss-lb:0.0836, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:03:09.312] iteration:18040  t-loss:0.1458, loss-lb:0.0744, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:03:09.504] iteration:18041  t-loss:0.1662, loss-lb:0.1066, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:03:09.697] iteration:18042  t-loss:0.1355, loss-lb:0.0753, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:03:09.889] iteration:18043  t-loss:0.1364, loss-lb:0.0755, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:03:10.082] iteration:18044  t-loss:0.1350, loss-lb:0.0785, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:03:10.273] iteration:18045  t-loss:0.1527, loss-lb:0.0743, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:03:10.465] iteration:18046  t-loss:0.1475, loss-lb:0.0834, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:03:10.658] iteration:18047  t-loss:0.1572, loss-lb:0.0826, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:03:10.849] iteration:18048  t-loss:0.1331, loss-lb:0.0710, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:03:11.042] iteration:18049  t-loss:0.1619, loss-lb:0.0929, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:03:11.235] iteration:18050  t-loss:0.1379, loss-lb:0.0727, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:03:11.426] iteration:18051  t-loss:0.1636, loss-lb:0.0971, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:03:11.619] iteration:18052  t-loss:0.1470, loss-lb:0.0756, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:03:11.812] iteration:18053  t-loss:0.1709, loss-lb:0.0862, loss-ulb:0.0423, weight:2.00, lr:0.0004
[12:03:12.004] iteration:18054  t-loss:0.1459, loss-lb:0.0790, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:03:12.196] iteration:18055  t-loss:0.1371, loss-lb:0.0752, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:03:12.388] iteration:18056  t-loss:0.1409, loss-lb:0.0723, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:03:12.580] iteration:18057  t-loss:0.1397, loss-lb:0.0786, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:03:12.773] iteration:18058  t-loss:0.1776, loss-lb:0.0828, loss-ulb:0.0474, weight:2.00, lr:0.0004
[12:03:12.965] iteration:18059  t-loss:0.1381, loss-lb:0.0738, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:03:13.156] iteration:18060  t-loss:0.1610, loss-lb:0.0792, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:03:13.348] iteration:18061  t-loss:0.1488, loss-lb:0.0768, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:03:13.539] iteration:18062  t-loss:0.1442, loss-lb:0.0796, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:03:13.732] iteration:18063  t-loss:0.1865, loss-lb:0.0831, loss-ulb:0.0517, weight:2.00, lr:0.0004
[12:03:13.924] iteration:18064  t-loss:0.1320, loss-lb:0.0743, loss-ulb:0.0289, weight:2.00, lr:0.0004
[12:03:14.117] iteration:18065  t-loss:0.2133, loss-lb:0.0769, loss-ulb:0.0682, weight:2.00, lr:0.0004
[12:03:14.308] iteration:18066  t-loss:0.1331, loss-lb:0.0701, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:03:14.502] iteration:18067  t-loss:0.1389, loss-lb:0.0734, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:03:14.693] iteration:18068  t-loss:0.1431, loss-lb:0.0751, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:03:14.885] iteration:18069  t-loss:0.1343, loss-lb:0.0708, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:03:15.077] iteration:18070  t-loss:0.1662, loss-lb:0.0853, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:03:15.270] iteration:18071  t-loss:0.2624, loss-lb:0.0787, loss-ulb:0.0919, weight:2.00, lr:0.0004
[12:03:15.463] iteration:18072  t-loss:0.1952, loss-lb:0.0774, loss-ulb:0.0589, weight:2.00, lr:0.0004
[12:03:15.660] iteration:18073  t-loss:0.2597, loss-lb:0.0790, loss-ulb:0.0904, weight:2.00, lr:0.0004
[12:03:15.871] iteration:18074  t-loss:0.1450, loss-lb:0.0824, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:03:16.071] iteration:18075  t-loss:0.1522, loss-lb:0.0824, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:03:16.267] iteration:18076  t-loss:0.1519, loss-lb:0.0774, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:03:16.460] iteration:18077  t-loss:0.1527, loss-lb:0.0761, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:03:16.652] iteration:18078  t-loss:0.1367, loss-lb:0.0753, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:03:16.845] iteration:18079  t-loss:0.1404, loss-lb:0.0834, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:03:17.037] iteration:18080  t-loss:0.1655, loss-lb:0.0748, loss-ulb:0.0453, weight:2.00, lr:0.0004
[12:03:17.229] iteration:18081  t-loss:0.1493, loss-lb:0.0771, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:03:17.422] iteration:18082  t-loss:0.1933, loss-lb:0.0781, loss-ulb:0.0576, weight:2.00, lr:0.0004
[12:03:17.614] iteration:18083  t-loss:0.1557, loss-lb:0.0870, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:03:17.805] iteration:18084  t-loss:0.1710, loss-lb:0.1023, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:03:17.997] iteration:18085  t-loss:0.1525, loss-lb:0.0852, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:03:18.189] iteration:18086  t-loss:0.1535, loss-lb:0.0792, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:03:18.381] iteration:18087  t-loss:0.1619, loss-lb:0.0760, loss-ulb:0.0429, weight:2.00, lr:0.0004
[12:03:18.574] iteration:18088  t-loss:0.1430, loss-lb:0.0754, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:03:18.766] iteration:18089  t-loss:0.1367, loss-lb:0.0847, loss-ulb:0.0260, weight:2.00, lr:0.0004
[12:03:18.958] iteration:18090  t-loss:0.1316, loss-lb:0.0784, loss-ulb:0.0266, weight:2.00, lr:0.0004
[12:03:19.151] iteration:18091  t-loss:0.2107, loss-lb:0.0746, loss-ulb:0.0681, weight:2.00, lr:0.0004
[12:03:19.343] iteration:18092  t-loss:0.1620, loss-lb:0.0897, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:03:19.536] iteration:18093  t-loss:0.1444, loss-lb:0.0742, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:03:19.727] iteration:18094  t-loss:0.1490, loss-lb:0.0817, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:03:19.919] iteration:18095  t-loss:0.1340, loss-lb:0.0774, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:03:20.111] iteration:18096  t-loss:0.1521, loss-lb:0.0827, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:03:20.303] iteration:18097  t-loss:0.2040, loss-lb:0.0832, loss-ulb:0.0604, weight:2.00, lr:0.0004
[12:03:20.494] iteration:18098  t-loss:0.1494, loss-lb:0.0756, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:03:20.687] iteration:18099  t-loss:0.1492, loss-lb:0.0824, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:03:20.879] iteration:18100  t-loss:0.1675, loss-lb:0.0849, loss-ulb:0.0413, weight:2.00, lr:0.0004
[12:03:21.071] iteration:18101  t-loss:0.1531, loss-lb:0.0842, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:03:21.264] iteration:18102  t-loss:0.1648, loss-lb:0.0877, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:03:21.456] iteration:18103  t-loss:0.1621, loss-lb:0.0903, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:03:21.648] iteration:18104  t-loss:0.1677, loss-lb:0.0993, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:03:21.841] iteration:18105  t-loss:0.2099, loss-lb:0.1400, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:03:22.034] iteration:18106  t-loss:0.1801, loss-lb:0.0897, loss-ulb:0.0452, weight:2.00, lr:0.0004
[12:03:22.227] iteration:18107  t-loss:0.2614, loss-lb:0.0888, loss-ulb:0.0863, weight:2.00, lr:0.0004
[12:03:22.418] iteration:18108  t-loss:0.1722, loss-lb:0.0912, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:03:22.609] iteration:18109  t-loss:0.1641, loss-lb:0.0871, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:03:22.802] iteration:18110  t-loss:0.1428, loss-lb:0.0876, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:03:22.993] iteration:18111  t-loss:0.1514, loss-lb:0.0882, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:03:23.186] iteration:18112  t-loss:0.1786, loss-lb:0.0822, loss-ulb:0.0482, weight:2.00, lr:0.0004
[12:03:23.378] iteration:18113  t-loss:0.1645, loss-lb:0.0936, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:03:23.569] iteration:18114  t-loss:0.1596, loss-lb:0.0915, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:03:23.761] iteration:18115  t-loss:0.1573, loss-lb:0.0866, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:03:23.953] iteration:18116  t-loss:0.1670, loss-lb:0.0877, loss-ulb:0.0397, weight:2.00, lr:0.0004
[12:03:24.144] iteration:18117  t-loss:0.1500, loss-lb:0.0865, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:03:24.336] iteration:18118  t-loss:0.1751, loss-lb:0.1020, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:03:24.528] iteration:18119  t-loss:0.2273, loss-lb:0.0939, loss-ulb:0.0667, weight:2.00, lr:0.0004
[12:03:24.719] iteration:18120  t-loss:0.2037, loss-lb:0.0937, loss-ulb:0.0550, weight:2.00, lr:0.0004
[12:03:24.911] iteration:18121  t-loss:0.1601, loss-lb:0.0968, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:03:25.103] iteration:18122  t-loss:0.1674, loss-lb:0.0939, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:03:25.294] iteration:18123  t-loss:0.1778, loss-lb:0.0912, loss-ulb:0.0433, weight:2.00, lr:0.0004
[12:03:25.484] iteration:18124  t-loss:0.1785, loss-lb:0.0980, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:03:25.674] iteration:18125  t-loss:0.1756, loss-lb:0.0893, loss-ulb:0.0432, weight:2.00, lr:0.0004
[12:03:25.864] iteration:18126  t-loss:0.1630, loss-lb:0.0870, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:03:26.055] iteration:18127  t-loss:0.1518, loss-lb:0.0811, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:03:26.246] iteration:18128  t-loss:0.1947, loss-lb:0.1032, loss-ulb:0.0458, weight:2.00, lr:0.0004
[12:03:26.437] iteration:18129  t-loss:0.1505, loss-lb:0.0817, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:03:26.628] iteration:18130  t-loss:0.1673, loss-lb:0.0888, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:03:37.834]  <<Test>> - Ep:184  - mean_dice/mean_h95 - S:89.37/2.10, Best-S:90.99, T:89.85/1.35, Best-T:90.48
[12:03:37.834]           - AvgLoss(lb/ulb/all):0.0837/0.0401/0.1711
[12:03:38.370] iteration:18131  t-loss:0.1474, loss-lb:0.0886, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:03:38.562] iteration:18132  t-loss:0.1564, loss-lb:0.0941, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:03:38.753] iteration:18133  t-loss:0.1458, loss-lb:0.0790, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:03:38.945] iteration:18134  t-loss:0.1758, loss-lb:0.1009, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:03:39.137] iteration:18135  t-loss:0.2320, loss-lb:0.0871, loss-ulb:0.0725, weight:2.00, lr:0.0004
[12:03:39.330] iteration:18136  t-loss:0.1588, loss-lb:0.0896, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:03:39.522] iteration:18137  t-loss:0.1810, loss-lb:0.0811, loss-ulb:0.0499, weight:2.00, lr:0.0004
[12:03:39.715] iteration:18138  t-loss:0.1792, loss-lb:0.0897, loss-ulb:0.0448, weight:2.00, lr:0.0004
[12:03:39.905] iteration:18139  t-loss:0.1380, loss-lb:0.0766, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:03:40.097] iteration:18140  t-loss:0.1369, loss-lb:0.0806, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:03:40.288] iteration:18141  t-loss:0.1606, loss-lb:0.0790, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:03:40.480] iteration:18142  t-loss:0.1575, loss-lb:0.0935, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:03:40.671] iteration:18143  t-loss:0.1762, loss-lb:0.0811, loss-ulb:0.0475, weight:2.00, lr:0.0004
[12:03:40.863] iteration:18144  t-loss:0.1566, loss-lb:0.0907, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:03:41.056] iteration:18145  t-loss:0.1580, loss-lb:0.0876, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:03:41.248] iteration:18146  t-loss:0.1522, loss-lb:0.0832, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:03:41.439] iteration:18147  t-loss:0.2289, loss-lb:0.0916, loss-ulb:0.0686, weight:2.00, lr:0.0004
[12:03:41.629] iteration:18148  t-loss:0.1446, loss-lb:0.0796, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:03:41.820] iteration:18149  t-loss:0.1535, loss-lb:0.0928, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:03:42.013] iteration:18150  t-loss:0.1514, loss-lb:0.0850, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:03:42.204] iteration:18151  t-loss:0.1366, loss-lb:0.0802, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:03:42.396] iteration:18152  t-loss:0.1513, loss-lb:0.0864, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:03:42.588] iteration:18153  t-loss:0.1683, loss-lb:0.0796, loss-ulb:0.0443, weight:2.00, lr:0.0004
[12:03:42.780] iteration:18154  t-loss:0.1466, loss-lb:0.0854, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:03:42.971] iteration:18155  t-loss:0.1374, loss-lb:0.0848, loss-ulb:0.0263, weight:2.00, lr:0.0004
[12:03:43.164] iteration:18156  t-loss:0.1477, loss-lb:0.0836, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:03:43.356] iteration:18157  t-loss:0.1607, loss-lb:0.0876, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:03:43.548] iteration:18158  t-loss:0.1609, loss-lb:0.0850, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:03:43.738] iteration:18159  t-loss:0.1576, loss-lb:0.0793, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:03:43.935] iteration:18160  t-loss:0.1417, loss-lb:0.0809, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:03:44.126] iteration:18161  t-loss:0.1394, loss-lb:0.0808, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:03:44.319] iteration:18162  t-loss:0.1462, loss-lb:0.0831, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:03:44.512] iteration:18163  t-loss:0.1490, loss-lb:0.0840, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:03:44.704] iteration:18164  t-loss:0.1380, loss-lb:0.0740, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:03:44.897] iteration:18165  t-loss:0.1405, loss-lb:0.0804, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:03:45.089] iteration:18166  t-loss:0.1554, loss-lb:0.0939, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:03:45.282] iteration:18167  t-loss:0.1847, loss-lb:0.0835, loss-ulb:0.0506, weight:2.00, lr:0.0004
[12:03:45.474] iteration:18168  t-loss:0.1357, loss-lb:0.0764, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:03:45.668] iteration:18169  t-loss:0.2097, loss-lb:0.0858, loss-ulb:0.0620, weight:2.00, lr:0.0004
[12:03:45.861] iteration:18170  t-loss:0.1492, loss-lb:0.0834, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:03:46.052] iteration:18171  t-loss:0.1441, loss-lb:0.0793, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:03:46.246] iteration:18172  t-loss:0.1635, loss-lb:0.0847, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:03:46.438] iteration:18173  t-loss:0.1472, loss-lb:0.0847, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:03:46.630] iteration:18174  t-loss:0.1546, loss-lb:0.0787, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:03:46.823] iteration:18175  t-loss:0.1527, loss-lb:0.0778, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:03:47.015] iteration:18176  t-loss:0.1478, loss-lb:0.0798, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:03:47.207] iteration:18177  t-loss:0.1411, loss-lb:0.0797, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:03:47.399] iteration:18178  t-loss:0.1409, loss-lb:0.0775, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:03:47.592] iteration:18179  t-loss:0.1442, loss-lb:0.0817, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:03:47.784] iteration:18180  t-loss:0.1362, loss-lb:0.0767, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:03:47.975] iteration:18181  t-loss:0.1360, loss-lb:0.0766, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:03:48.169] iteration:18182  t-loss:0.2215, loss-lb:0.0852, loss-ulb:0.0682, weight:2.00, lr:0.0004
[12:03:48.363] iteration:18183  t-loss:0.2767, loss-lb:0.0862, loss-ulb:0.0952, weight:2.00, lr:0.0004
[12:03:48.566] iteration:18184  t-loss:0.1542, loss-lb:0.0740, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:03:48.769] iteration:18185  t-loss:0.1362, loss-lb:0.0737, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:03:48.965] iteration:18186  t-loss:0.1601, loss-lb:0.0808, loss-ulb:0.0397, weight:2.00, lr:0.0004
[12:03:49.157] iteration:18187  t-loss:0.1726, loss-lb:0.0764, loss-ulb:0.0481, weight:2.00, lr:0.0004
[12:03:49.349] iteration:18188  t-loss:0.1337, loss-lb:0.0796, loss-ulb:0.0271, weight:2.00, lr:0.0004
[12:03:49.542] iteration:18189  t-loss:0.1725, loss-lb:0.1021, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:03:49.735] iteration:18190  t-loss:0.1553, loss-lb:0.0909, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:03:49.927] iteration:18191  t-loss:0.2126, loss-lb:0.0704, loss-ulb:0.0711, weight:2.00, lr:0.0004
[12:03:50.119] iteration:18192  t-loss:0.1534, loss-lb:0.0819, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:03:50.312] iteration:18193  t-loss:0.1331, loss-lb:0.0781, loss-ulb:0.0275, weight:2.00, lr:0.0004
[12:03:50.506] iteration:18194  t-loss:0.1450, loss-lb:0.0793, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:03:50.698] iteration:18195  t-loss:0.1574, loss-lb:0.0931, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:03:50.889] iteration:18196  t-loss:0.1520, loss-lb:0.0840, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:03:51.082] iteration:18197  t-loss:0.1436, loss-lb:0.0839, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:03:51.273] iteration:18198  t-loss:0.1506, loss-lb:0.0727, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:03:51.466] iteration:18199  t-loss:0.1599, loss-lb:0.0788, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:03:51.659] iteration:18200  t-loss:0.1728, loss-lb:0.0804, loss-ulb:0.0462, weight:2.00, lr:0.0004
[12:03:51.853] iteration:18201  t-loss:0.2355, loss-lb:0.0831, loss-ulb:0.0762, weight:2.00, lr:0.0004
[12:03:52.045] iteration:18202  t-loss:0.1832, loss-lb:0.0946, loss-ulb:0.0443, weight:2.00, lr:0.0004
[12:03:52.238] iteration:18203  t-loss:0.1416, loss-lb:0.0803, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:03:52.431] iteration:18204  t-loss:0.1462, loss-lb:0.0845, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:03:52.623] iteration:18205  t-loss:0.1456, loss-lb:0.0807, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:03:52.816] iteration:18206  t-loss:0.1495, loss-lb:0.0824, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:03:53.008] iteration:18207  t-loss:0.1420, loss-lb:0.0739, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:03:53.201] iteration:18208  t-loss:0.1456, loss-lb:0.0816, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:03:53.393] iteration:18209  t-loss:0.1515, loss-lb:0.0880, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:03:53.586] iteration:18210  t-loss:0.1602, loss-lb:0.0791, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:03:53.778] iteration:18211  t-loss:0.1465, loss-lb:0.0807, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:03:53.971] iteration:18212  t-loss:0.1603, loss-lb:0.0908, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:03:54.163] iteration:18213  t-loss:0.1462, loss-lb:0.0842, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:03:54.355] iteration:18214  t-loss:0.1405, loss-lb:0.0804, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:03:54.548] iteration:18215  t-loss:0.1332, loss-lb:0.0761, loss-ulb:0.0286, weight:2.00, lr:0.0004
[12:03:54.741] iteration:18216  t-loss:0.1517, loss-lb:0.0765, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:03:54.933] iteration:18217  t-loss:0.1412, loss-lb:0.0745, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:03:55.126] iteration:18218  t-loss:0.1494, loss-lb:0.0848, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:03:55.318] iteration:18219  t-loss:0.1934, loss-lb:0.0809, loss-ulb:0.0562, weight:2.00, lr:0.0004
[12:03:55.510] iteration:18220  t-loss:0.1402, loss-lb:0.0771, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:03:55.704] iteration:18221  t-loss:0.1505, loss-lb:0.0814, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:03:55.895] iteration:18222  t-loss:0.1706, loss-lb:0.0830, loss-ulb:0.0438, weight:2.00, lr:0.0004
[12:03:56.086] iteration:18223  t-loss:0.1668, loss-lb:0.0865, loss-ulb:0.0402, weight:2.00, lr:0.0004
[12:03:56.277] iteration:18224  t-loss:0.1574, loss-lb:0.0812, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:03:56.468] iteration:18225  t-loss:0.1509, loss-lb:0.0765, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:03:56.660] iteration:18226  t-loss:0.1403, loss-lb:0.0865, loss-ulb:0.0269, weight:2.00, lr:0.0004
[12:03:56.851] iteration:18227  t-loss:0.1433, loss-lb:0.0787, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:03:57.042] iteration:18228  t-loss:0.1553, loss-lb:0.0795, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:03:57.621] iteration:18229  t-loss:0.1529, loss-lb:0.0863, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:03:57.816] iteration:18230  t-loss:0.1361, loss-lb:0.0810, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:03:58.008] iteration:18231  t-loss:0.1608, loss-lb:0.0769, loss-ulb:0.0420, weight:2.00, lr:0.0004
[12:03:58.201] iteration:18232  t-loss:0.1425, loss-lb:0.0785, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:03:58.393] iteration:18233  t-loss:0.1386, loss-lb:0.0768, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:03:58.586] iteration:18234  t-loss:0.1333, loss-lb:0.0730, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:03:58.779] iteration:18235  t-loss:0.3349, loss-lb:0.0945, loss-ulb:0.1202, weight:2.00, lr:0.0004
[12:03:58.972] iteration:18236  t-loss:0.1685, loss-lb:0.0753, loss-ulb:0.0466, weight:2.00, lr:0.0004
[12:03:59.164] iteration:18237  t-loss:0.1456, loss-lb:0.0779, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:03:59.357] iteration:18238  t-loss:0.1568, loss-lb:0.0774, loss-ulb:0.0397, weight:2.00, lr:0.0004
[12:03:59.550] iteration:18239  t-loss:0.2246, loss-lb:0.0866, loss-ulb:0.0690, weight:2.00, lr:0.0004
[12:03:59.742] iteration:18240  t-loss:0.1680, loss-lb:0.1045, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:03:59.935] iteration:18241  t-loss:0.1747, loss-lb:0.0837, loss-ulb:0.0455, weight:2.00, lr:0.0004
[12:04:00.127] iteration:18242  t-loss:0.1486, loss-lb:0.0707, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:04:00.319] iteration:18243  t-loss:0.1411, loss-lb:0.0803, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:04:00.512] iteration:18244  t-loss:0.1501, loss-lb:0.0760, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:04:00.703] iteration:18245  t-loss:0.1439, loss-lb:0.0798, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:04:00.896] iteration:18246  t-loss:0.1586, loss-lb:0.0876, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:04:01.089] iteration:18247  t-loss:0.1424, loss-lb:0.0785, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:04:01.280] iteration:18248  t-loss:0.1713, loss-lb:0.0794, loss-ulb:0.0460, weight:2.00, lr:0.0004
[12:04:01.473] iteration:18249  t-loss:0.2034, loss-lb:0.0790, loss-ulb:0.0622, weight:2.00, lr:0.0004
[12:04:01.665] iteration:18250  t-loss:0.1462, loss-lb:0.0814, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:04:01.857] iteration:18251  t-loss:0.1533, loss-lb:0.0871, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:04:02.050] iteration:18252  t-loss:0.1499, loss-lb:0.0769, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:04:02.242] iteration:18253  t-loss:0.1508, loss-lb:0.0825, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:04:02.435] iteration:18254  t-loss:0.1579, loss-lb:0.0891, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:04:02.627] iteration:18255  t-loss:0.1519, loss-lb:0.0759, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:04:02.819] iteration:18256  t-loss:0.1684, loss-lb:0.0765, loss-ulb:0.0460, weight:2.00, lr:0.0004
[12:04:03.012] iteration:18257  t-loss:0.1526, loss-lb:0.0745, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:04:03.204] iteration:18258  t-loss:0.1868, loss-lb:0.0781, loss-ulb:0.0543, weight:2.00, lr:0.0004
[12:04:03.397] iteration:18259  t-loss:0.1553, loss-lb:0.0790, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:04:03.589] iteration:18260  t-loss:0.1434, loss-lb:0.0792, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:04:03.781] iteration:18261  t-loss:0.1419, loss-lb:0.0817, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:04:03.975] iteration:18262  t-loss:0.1497, loss-lb:0.0745, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:04:04.169] iteration:18263  t-loss:0.1360, loss-lb:0.0797, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:04:04.363] iteration:18264  t-loss:0.1755, loss-lb:0.0785, loss-ulb:0.0485, weight:2.00, lr:0.0004
[12:04:04.555] iteration:18265  t-loss:0.1427, loss-lb:0.0776, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:04:04.747] iteration:18266  t-loss:0.1892, loss-lb:0.0736, loss-ulb:0.0578, weight:2.00, lr:0.0004
[12:04:04.940] iteration:18267  t-loss:0.1442, loss-lb:0.0765, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:04:05.132] iteration:18268  t-loss:0.1528, loss-lb:0.0898, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:04:05.324] iteration:18269  t-loss:0.1747, loss-lb:0.0847, loss-ulb:0.0450, weight:2.00, lr:0.0004
[12:04:05.517] iteration:18270  t-loss:0.1800, loss-lb:0.0889, loss-ulb:0.0456, weight:2.00, lr:0.0004
[12:04:05.709] iteration:18271  t-loss:0.1541, loss-lb:0.0801, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:04:05.902] iteration:18272  t-loss:0.1877, loss-lb:0.0789, loss-ulb:0.0544, weight:2.00, lr:0.0004
[12:04:06.095] iteration:18273  t-loss:0.1953, loss-lb:0.0828, loss-ulb:0.0563, weight:2.00, lr:0.0004
[12:04:06.288] iteration:18274  t-loss:0.1424, loss-lb:0.0786, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:04:06.481] iteration:18275  t-loss:0.1682, loss-lb:0.0778, loss-ulb:0.0452, weight:2.00, lr:0.0004
[12:04:06.674] iteration:18276  t-loss:0.1484, loss-lb:0.0789, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:04:06.866] iteration:18277  t-loss:0.2005, loss-lb:0.0894, loss-ulb:0.0555, weight:2.00, lr:0.0004
[12:04:07.058] iteration:18278  t-loss:0.1599, loss-lb:0.0727, loss-ulb:0.0436, weight:2.00, lr:0.0004
[12:04:07.251] iteration:18279  t-loss:0.1970, loss-lb:0.0813, loss-ulb:0.0579, weight:2.00, lr:0.0004
[12:04:07.445] iteration:18280  t-loss:0.1774, loss-lb:0.0812, loss-ulb:0.0481, weight:2.00, lr:0.0004
[12:04:07.636] iteration:18281  t-loss:0.1514, loss-lb:0.0797, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:04:07.830] iteration:18282  t-loss:0.1620, loss-lb:0.0852, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:04:08.024] iteration:18283  t-loss:0.1360, loss-lb:0.0762, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:04:08.216] iteration:18284  t-loss:0.1553, loss-lb:0.0896, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:04:08.410] iteration:18285  t-loss:0.1701, loss-lb:0.0930, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:04:08.602] iteration:18286  t-loss:0.1594, loss-lb:0.0801, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:04:08.795] iteration:18287  t-loss:0.1397, loss-lb:0.0751, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:04:08.987] iteration:18288  t-loss:0.1533, loss-lb:0.0753, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:04:09.179] iteration:18289  t-loss:0.1543, loss-lb:0.0835, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:04:09.373] iteration:18290  t-loss:0.1373, loss-lb:0.0798, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:04:09.565] iteration:18291  t-loss:0.1324, loss-lb:0.0750, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:04:09.757] iteration:18292  t-loss:0.1488, loss-lb:0.0832, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:04:09.949] iteration:18293  t-loss:0.1512, loss-lb:0.0914, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:04:10.142] iteration:18294  t-loss:0.1660, loss-lb:0.0878, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:04:10.335] iteration:18295  t-loss:0.1927, loss-lb:0.0867, loss-ulb:0.0530, weight:2.00, lr:0.0004
[12:04:10.528] iteration:18296  t-loss:0.1669, loss-lb:0.0950, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:04:10.721] iteration:18297  t-loss:0.2101, loss-lb:0.0880, loss-ulb:0.0611, weight:2.00, lr:0.0004
[12:04:10.914] iteration:18298  t-loss:0.1362, loss-lb:0.0729, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:04:11.106] iteration:18299  t-loss:0.1356, loss-lb:0.0789, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:04:11.299] iteration:18300  t-loss:0.1452, loss-lb:0.0827, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:04:11.491] iteration:18301  t-loss:0.1390, loss-lb:0.0812, loss-ulb:0.0289, weight:2.00, lr:0.0004
[12:04:11.684] iteration:18302  t-loss:0.1377, loss-lb:0.0778, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:04:11.877] iteration:18303  t-loss:0.1372, loss-lb:0.0827, loss-ulb:0.0272, weight:2.00, lr:0.0004
[12:04:12.069] iteration:18304  t-loss:0.1650, loss-lb:0.0863, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:04:12.263] iteration:18305  t-loss:0.1963, loss-lb:0.0974, loss-ulb:0.0494, weight:2.00, lr:0.0004
[12:04:12.455] iteration:18306  t-loss:0.1413, loss-lb:0.0799, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:04:12.649] iteration:18307  t-loss:0.1668, loss-lb:0.0936, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:04:12.841] iteration:18308  t-loss:0.1858, loss-lb:0.0805, loss-ulb:0.0526, weight:2.00, lr:0.0004
[12:04:13.033] iteration:18309  t-loss:0.1512, loss-lb:0.0777, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:04:13.226] iteration:18310  t-loss:0.1432, loss-lb:0.0856, loss-ulb:0.0288, weight:2.00, lr:0.0004
[12:04:13.418] iteration:18311  t-loss:0.1432, loss-lb:0.0822, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:04:13.610] iteration:18312  t-loss:0.1668, loss-lb:0.0842, loss-ulb:0.0413, weight:2.00, lr:0.0004
[12:04:13.805] iteration:18313  t-loss:0.1518, loss-lb:0.0737, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:04:13.999] iteration:18314  t-loss:0.1403, loss-lb:0.0741, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:04:14.192] iteration:18315  t-loss:0.1943, loss-lb:0.0882, loss-ulb:0.0530, weight:2.00, lr:0.0004
[12:04:14.384] iteration:18316  t-loss:0.1482, loss-lb:0.0780, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:04:14.577] iteration:18317  t-loss:0.1600, loss-lb:0.0842, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:04:14.771] iteration:18318  t-loss:0.1470, loss-lb:0.0811, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:04:14.964] iteration:18319  t-loss:0.1713, loss-lb:0.1011, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:04:15.155] iteration:18320  t-loss:0.1601, loss-lb:0.0811, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:04:15.347] iteration:18321  t-loss:0.1544, loss-lb:0.0875, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:04:15.538] iteration:18322  t-loss:0.1603, loss-lb:0.0811, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:04:15.730] iteration:18323  t-loss:0.1422, loss-lb:0.0769, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:04:15.925] iteration:18324  t-loss:0.1459, loss-lb:0.0791, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:04:16.119] iteration:18325  t-loss:0.1927, loss-lb:0.0750, loss-ulb:0.0589, weight:2.00, lr:0.0004
[12:04:16.315] iteration:18326  t-loss:0.1582, loss-lb:0.0861, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:04:29.470]  <<Test>> - Ep:186  - mean_dice/mean_h95 - S:89.57/1.38, Best-S:90.99, T:89.66/1.41, Best-T:90.48
[12:04:29.470]           - AvgLoss(lb/ulb/all):0.0817/0.0383/0.1592
[12:04:29.988] iteration:18327  t-loss:0.1418, loss-lb:0.0767, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:04:30.181] iteration:18328  t-loss:0.1442, loss-lb:0.0784, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:04:30.374] iteration:18329  t-loss:0.1765, loss-lb:0.0943, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:04:30.566] iteration:18330  t-loss:0.1454, loss-lb:0.0836, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:04:30.757] iteration:18331  t-loss:0.1484, loss-lb:0.0770, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:04:30.949] iteration:18332  t-loss:0.1552, loss-lb:0.0832, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:04:31.142] iteration:18333  t-loss:0.1428, loss-lb:0.0795, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:04:31.332] iteration:18334  t-loss:0.1568, loss-lb:0.0815, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:04:31.524] iteration:18335  t-loss:0.1674, loss-lb:0.0824, loss-ulb:0.0425, weight:2.00, lr:0.0004
[12:04:31.716] iteration:18336  t-loss:0.1490, loss-lb:0.0822, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:04:31.907] iteration:18337  t-loss:0.2589, loss-lb:0.0786, loss-ulb:0.0902, weight:2.00, lr:0.0004
[12:04:32.098] iteration:18338  t-loss:0.1433, loss-lb:0.0812, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:04:32.290] iteration:18339  t-loss:0.1497, loss-lb:0.0814, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:04:32.481] iteration:18340  t-loss:0.1563, loss-lb:0.0798, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:04:32.673] iteration:18341  t-loss:0.1519, loss-lb:0.0797, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:04:32.865] iteration:18342  t-loss:0.1508, loss-lb:0.0817, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:04:33.057] iteration:18343  t-loss:0.1484, loss-lb:0.0894, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:04:33.248] iteration:18344  t-loss:0.1577, loss-lb:0.0818, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:04:33.439] iteration:18345  t-loss:0.1334, loss-lb:0.0800, loss-ulb:0.0267, weight:2.00, lr:0.0004
[12:04:33.631] iteration:18346  t-loss:0.1342, loss-lb:0.0732, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:04:33.823] iteration:18347  t-loss:0.1608, loss-lb:0.0900, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:04:34.014] iteration:18348  t-loss:0.1569, loss-lb:0.0828, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:04:34.206] iteration:18349  t-loss:0.1493, loss-lb:0.0767, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:04:34.397] iteration:18350  t-loss:0.1332, loss-lb:0.0727, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:04:34.589] iteration:18351  t-loss:0.1382, loss-lb:0.0738, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:04:34.781] iteration:18352  t-loss:0.1368, loss-lb:0.0827, loss-ulb:0.0270, weight:2.00, lr:0.0004
[12:04:34.973] iteration:18353  t-loss:0.1517, loss-lb:0.0774, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:04:35.165] iteration:18354  t-loss:0.1886, loss-lb:0.0891, loss-ulb:0.0498, weight:2.00, lr:0.0004
[12:04:35.356] iteration:18355  t-loss:0.1334, loss-lb:0.0761, loss-ulb:0.0286, weight:2.00, lr:0.0004
[12:04:35.547] iteration:18356  t-loss:0.1367, loss-lb:0.0735, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:04:35.739] iteration:18357  t-loss:0.1484, loss-lb:0.0741, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:04:35.931] iteration:18358  t-loss:0.1461, loss-lb:0.0782, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:04:36.122] iteration:18359  t-loss:0.1343, loss-lb:0.0754, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:04:36.314] iteration:18360  t-loss:0.1356, loss-lb:0.0761, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:04:36.505] iteration:18361  t-loss:0.1478, loss-lb:0.0736, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:04:36.698] iteration:18362  t-loss:0.1363, loss-lb:0.0798, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:04:36.890] iteration:18363  t-loss:0.1510, loss-lb:0.0715, loss-ulb:0.0398, weight:2.00, lr:0.0004
[12:04:37.081] iteration:18364  t-loss:0.1362, loss-lb:0.0759, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:04:37.273] iteration:18365  t-loss:0.1820, loss-lb:0.0882, loss-ulb:0.0469, weight:2.00, lr:0.0004
[12:04:37.465] iteration:18366  t-loss:0.1442, loss-lb:0.0809, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:04:37.660] iteration:18367  t-loss:0.1580, loss-lb:0.0671, loss-ulb:0.0454, weight:2.00, lr:0.0004
[12:04:37.856] iteration:18368  t-loss:0.1592, loss-lb:0.0792, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:04:38.052] iteration:18369  t-loss:0.1630, loss-lb:0.0879, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:04:38.246] iteration:18370  t-loss:0.1552, loss-lb:0.0878, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:04:38.440] iteration:18371  t-loss:0.1481, loss-lb:0.0737, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:04:38.633] iteration:18372  t-loss:0.1694, loss-lb:0.0713, loss-ulb:0.0490, weight:2.00, lr:0.0004
[12:04:38.826] iteration:18373  t-loss:0.1331, loss-lb:0.0720, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:04:39.017] iteration:18374  t-loss:0.1433, loss-lb:0.0804, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:04:39.209] iteration:18375  t-loss:0.1395, loss-lb:0.0772, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:04:39.402] iteration:18376  t-loss:0.1693, loss-lb:0.0757, loss-ulb:0.0468, weight:2.00, lr:0.0004
[12:04:39.594] iteration:18377  t-loss:0.1639, loss-lb:0.0792, loss-ulb:0.0424, weight:2.00, lr:0.0004
[12:04:39.787] iteration:18378  t-loss:0.1891, loss-lb:0.0848, loss-ulb:0.0522, weight:2.00, lr:0.0004
[12:04:39.979] iteration:18379  t-loss:0.1561, loss-lb:0.0857, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:04:40.171] iteration:18380  t-loss:0.1505, loss-lb:0.0784, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:04:40.363] iteration:18381  t-loss:0.1588, loss-lb:0.0892, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:04:40.556] iteration:18382  t-loss:0.1475, loss-lb:0.0837, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:04:40.748] iteration:18383  t-loss:0.1552, loss-lb:0.0851, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:04:40.941] iteration:18384  t-loss:0.1396, loss-lb:0.0773, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:04:41.133] iteration:18385  t-loss:0.1672, loss-lb:0.0984, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:04:41.325] iteration:18386  t-loss:0.1566, loss-lb:0.0780, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:04:41.518] iteration:18387  t-loss:0.1602, loss-lb:0.0794, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:04:41.711] iteration:18388  t-loss:0.1437, loss-lb:0.0735, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:04:41.902] iteration:18389  t-loss:0.1416, loss-lb:0.0848, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:04:42.096] iteration:18390  t-loss:0.1447, loss-lb:0.0821, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:04:42.288] iteration:18391  t-loss:0.1294, loss-lb:0.0782, loss-ulb:0.0256, weight:2.00, lr:0.0004
[12:04:42.480] iteration:18392  t-loss:0.1420, loss-lb:0.0733, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:04:42.674] iteration:18393  t-loss:0.1990, loss-lb:0.0794, loss-ulb:0.0598, weight:2.00, lr:0.0004
[12:04:42.865] iteration:18394  t-loss:0.1414, loss-lb:0.0807, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:04:43.057] iteration:18395  t-loss:0.1414, loss-lb:0.0760, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:04:43.250] iteration:18396  t-loss:0.2187, loss-lb:0.0843, loss-ulb:0.0672, weight:2.00, lr:0.0004
[12:04:43.443] iteration:18397  t-loss:0.1439, loss-lb:0.0785, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:04:43.635] iteration:18398  t-loss:0.1469, loss-lb:0.0782, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:04:43.827] iteration:18399  t-loss:0.1493, loss-lb:0.0860, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:04:44.019] iteration:18400  t-loss:0.1319, loss-lb:0.0772, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:04:44.212] iteration:18401  t-loss:0.1515, loss-lb:0.0788, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:04:44.405] iteration:18402  t-loss:0.1590, loss-lb:0.0825, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:04:44.597] iteration:18403  t-loss:0.1412, loss-lb:0.0776, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:04:44.789] iteration:18404  t-loss:0.1387, loss-lb:0.0802, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:04:44.981] iteration:18405  t-loss:0.1501, loss-lb:0.0859, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:04:45.174] iteration:18406  t-loss:0.1464, loss-lb:0.0752, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:04:45.366] iteration:18407  t-loss:0.1289, loss-lb:0.0715, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:04:45.559] iteration:18408  t-loss:0.1395, loss-lb:0.0723, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:04:45.751] iteration:18409  t-loss:0.1667, loss-lb:0.0949, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:04:45.942] iteration:18410  t-loss:0.1627, loss-lb:0.0766, loss-ulb:0.0430, weight:2.00, lr:0.0004
[12:04:46.135] iteration:18411  t-loss:0.1364, loss-lb:0.0715, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:04:46.327] iteration:18412  t-loss:0.1818, loss-lb:0.0687, loss-ulb:0.0565, weight:2.00, lr:0.0004
[12:04:46.519] iteration:18413  t-loss:0.1523, loss-lb:0.0812, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:04:46.711] iteration:18414  t-loss:0.1673, loss-lb:0.0832, loss-ulb:0.0421, weight:2.00, lr:0.0004
[12:04:46.902] iteration:18415  t-loss:0.1451, loss-lb:0.0758, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:04:47.094] iteration:18416  t-loss:0.1964, loss-lb:0.0769, loss-ulb:0.0597, weight:2.00, lr:0.0004
[12:04:47.286] iteration:18417  t-loss:0.1393, loss-lb:0.0820, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:04:47.476] iteration:18418  t-loss:0.1584, loss-lb:0.0795, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:04:47.666] iteration:18419  t-loss:0.1452, loss-lb:0.0767, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:04:47.856] iteration:18420  t-loss:0.1377, loss-lb:0.0752, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:04:48.048] iteration:18421  t-loss:0.1434, loss-lb:0.0839, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:04:48.239] iteration:18422  t-loss:0.1813, loss-lb:0.0909, loss-ulb:0.0452, weight:2.00, lr:0.0004
[12:04:48.431] iteration:18423  t-loss:0.1385, loss-lb:0.0818, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:04:48.623] iteration:18424  t-loss:0.1423, loss-lb:0.0748, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:04:49.250] iteration:18425  t-loss:0.1356, loss-lb:0.0780, loss-ulb:0.0288, weight:2.00, lr:0.0004
[12:04:49.445] iteration:18426  t-loss:0.1357, loss-lb:0.0739, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:04:49.637] iteration:18427  t-loss:0.1532, loss-lb:0.0781, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:04:49.830] iteration:18428  t-loss:0.1552, loss-lb:0.0774, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:04:50.021] iteration:18429  t-loss:0.1429, loss-lb:0.0741, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:04:50.214] iteration:18430  t-loss:0.1348, loss-lb:0.0774, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:04:50.406] iteration:18431  t-loss:0.1497, loss-lb:0.0725, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:04:50.598] iteration:18432  t-loss:0.1624, loss-lb:0.0770, loss-ulb:0.0427, weight:2.00, lr:0.0004
[12:04:50.791] iteration:18433  t-loss:0.1443, loss-lb:0.0838, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:04:50.983] iteration:18434  t-loss:0.1319, loss-lb:0.0758, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:04:51.174] iteration:18435  t-loss:0.1462, loss-lb:0.0823, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:04:51.367] iteration:18436  t-loss:0.1526, loss-lb:0.0790, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:04:51.560] iteration:18437  t-loss:0.1664, loss-lb:0.0828, loss-ulb:0.0418, weight:2.00, lr:0.0004
[12:04:51.753] iteration:18438  t-loss:0.1545, loss-lb:0.0876, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:04:51.945] iteration:18439  t-loss:0.1571, loss-lb:0.0811, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:04:52.138] iteration:18440  t-loss:0.1535, loss-lb:0.0847, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:04:52.331] iteration:18441  t-loss:0.1498, loss-lb:0.0782, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:04:52.523] iteration:18442  t-loss:0.1411, loss-lb:0.0847, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:04:52.716] iteration:18443  t-loss:0.1468, loss-lb:0.0797, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:04:52.908] iteration:18444  t-loss:0.1468, loss-lb:0.0713, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:04:53.101] iteration:18445  t-loss:0.1599, loss-lb:0.0790, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:04:53.294] iteration:18446  t-loss:0.2418, loss-lb:0.0729, loss-ulb:0.0844, weight:2.00, lr:0.0004
[12:04:53.487] iteration:18447  t-loss:0.1542, loss-lb:0.0763, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:04:53.680] iteration:18448  t-loss:0.1514, loss-lb:0.0812, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:04:53.872] iteration:18449  t-loss:0.1495, loss-lb:0.0873, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:04:54.074] iteration:18450  t-loss:0.1580, loss-lb:0.0800, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:04:54.275] iteration:18451  t-loss:0.1387, loss-lb:0.0722, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:04:54.470] iteration:18452  t-loss:0.1460, loss-lb:0.0764, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:04:54.665] iteration:18453  t-loss:0.1339, loss-lb:0.0802, loss-ulb:0.0269, weight:2.00, lr:0.0004
[12:04:54.857] iteration:18454  t-loss:0.1756, loss-lb:0.0778, loss-ulb:0.0489, weight:2.00, lr:0.0004
[12:04:55.051] iteration:18455  t-loss:0.1612, loss-lb:0.0754, loss-ulb:0.0429, weight:2.00, lr:0.0004
[12:04:55.243] iteration:18456  t-loss:0.1504, loss-lb:0.0750, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:04:55.436] iteration:18457  t-loss:0.1517, loss-lb:0.0785, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:04:55.630] iteration:18458  t-loss:0.1711, loss-lb:0.0834, loss-ulb:0.0438, weight:2.00, lr:0.0004
[12:04:55.823] iteration:18459  t-loss:0.1431, loss-lb:0.0712, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:04:56.015] iteration:18460  t-loss:0.1449, loss-lb:0.0779, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:04:56.207] iteration:18461  t-loss:0.1491, loss-lb:0.0791, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:04:56.399] iteration:18462  t-loss:0.1729, loss-lb:0.0786, loss-ulb:0.0471, weight:2.00, lr:0.0004
[12:04:56.591] iteration:18463  t-loss:0.1607, loss-lb:0.0850, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:04:56.784] iteration:18464  t-loss:0.2721, loss-lb:0.0843, loss-ulb:0.0939, weight:2.00, lr:0.0004
[12:04:56.976] iteration:18465  t-loss:0.1485, loss-lb:0.0828, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:04:57.168] iteration:18466  t-loss:0.1497, loss-lb:0.0789, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:04:57.360] iteration:18467  t-loss:0.1501, loss-lb:0.0836, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:04:57.550] iteration:18468  t-loss:0.1444, loss-lb:0.0777, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:04:57.742] iteration:18469  t-loss:0.1621, loss-lb:0.0703, loss-ulb:0.0459, weight:2.00, lr:0.0004
[12:04:57.935] iteration:18470  t-loss:0.1489, loss-lb:0.0804, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:04:58.125] iteration:18471  t-loss:0.1504, loss-lb:0.0831, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:04:58.318] iteration:18472  t-loss:0.2362, loss-lb:0.0676, loss-ulb:0.0843, weight:2.00, lr:0.0004
[12:04:58.510] iteration:18473  t-loss:0.1574, loss-lb:0.0811, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:04:58.701] iteration:18474  t-loss:0.1497, loss-lb:0.0923, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:04:58.894] iteration:18475  t-loss:0.2136, loss-lb:0.0823, loss-ulb:0.0657, weight:2.00, lr:0.0004
[12:04:59.085] iteration:18476  t-loss:0.1417, loss-lb:0.0816, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:04:59.278] iteration:18477  t-loss:0.1821, loss-lb:0.0992, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:04:59.470] iteration:18478  t-loss:0.1906, loss-lb:0.0786, loss-ulb:0.0560, weight:2.00, lr:0.0004
[12:04:59.663] iteration:18479  t-loss:0.1419, loss-lb:0.0815, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:04:59.855] iteration:18480  t-loss:0.1454, loss-lb:0.0777, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:05:00.049] iteration:18481  t-loss:0.1770, loss-lb:0.0942, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:05:00.241] iteration:18482  t-loss:0.1469, loss-lb:0.0885, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:05:00.433] iteration:18483  t-loss:0.1406, loss-lb:0.0782, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:05:00.626] iteration:18484  t-loss:0.1562, loss-lb:0.0856, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:05:00.819] iteration:18485  t-loss:0.1488, loss-lb:0.0742, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:05:01.011] iteration:18486  t-loss:0.1410, loss-lb:0.0822, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:05:01.204] iteration:18487  t-loss:0.1396, loss-lb:0.0795, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:05:01.399] iteration:18488  t-loss:0.1460, loss-lb:0.0761, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:05:01.593] iteration:18489  t-loss:0.1440, loss-lb:0.0819, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:05:01.788] iteration:18490  t-loss:0.1395, loss-lb:0.0795, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:05:01.981] iteration:18491  t-loss:0.1422, loss-lb:0.0847, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:05:02.174] iteration:18492  t-loss:0.1460, loss-lb:0.0761, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:05:02.367] iteration:18493  t-loss:0.1393, loss-lb:0.0754, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:05:02.561] iteration:18494  t-loss:0.1448, loss-lb:0.0804, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:05:02.757] iteration:18495  t-loss:0.1672, loss-lb:0.0780, loss-ulb:0.0446, weight:2.00, lr:0.0004
[12:05:02.950] iteration:18496  t-loss:0.1511, loss-lb:0.0741, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:05:03.143] iteration:18497  t-loss:0.1383, loss-lb:0.0723, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:05:03.336] iteration:18498  t-loss:0.1485, loss-lb:0.0791, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:05:03.529] iteration:18499  t-loss:0.1397, loss-lb:0.0773, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:05:03.724] iteration:18500  t-loss:0.2014, loss-lb:0.0890, loss-ulb:0.0562, weight:2.00, lr:0.0004
[12:05:03.918] iteration:18501  t-loss:0.1515, loss-lb:0.0799, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:05:04.110] iteration:18502  t-loss:0.1319, loss-lb:0.0760, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:05:04.302] iteration:18503  t-loss:0.1413, loss-lb:0.0794, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:05:04.495] iteration:18504  t-loss:0.1546, loss-lb:0.0785, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:05:04.688] iteration:18505  t-loss:0.1380, loss-lb:0.0743, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:05:04.881] iteration:18506  t-loss:0.2064, loss-lb:0.0833, loss-ulb:0.0615, weight:2.00, lr:0.0004
[12:05:05.074] iteration:18507  t-loss:0.1454, loss-lb:0.0799, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:05:05.267] iteration:18508  t-loss:0.1483, loss-lb:0.0789, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:05:05.460] iteration:18509  t-loss:0.1886, loss-lb:0.0800, loss-ulb:0.0543, weight:2.00, lr:0.0004
[12:05:05.652] iteration:18510  t-loss:0.1502, loss-lb:0.0727, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:05:05.845] iteration:18511  t-loss:0.1389, loss-lb:0.0830, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:05:06.039] iteration:18512  t-loss:0.1394, loss-lb:0.0832, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:05:06.231] iteration:18513  t-loss:0.1823, loss-lb:0.0913, loss-ulb:0.0455, weight:2.00, lr:0.0004
[12:05:06.424] iteration:18514  t-loss:0.1349, loss-lb:0.0698, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:05:06.616] iteration:18515  t-loss:0.1513, loss-lb:0.0814, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:05:06.807] iteration:18516  t-loss:0.1560, loss-lb:0.0848, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:05:06.998] iteration:18517  t-loss:0.1593, loss-lb:0.0792, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:05:07.188] iteration:18518  t-loss:0.1543, loss-lb:0.0833, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:05:07.379] iteration:18519  t-loss:0.2332, loss-lb:0.0823, loss-ulb:0.0755, weight:2.00, lr:0.0004
[12:05:07.571] iteration:18520  t-loss:0.1565, loss-lb:0.0732, loss-ulb:0.0417, weight:2.00, lr:0.0004
[12:05:07.761] iteration:18521  t-loss:0.1543, loss-lb:0.0740, loss-ulb:0.0402, weight:2.00, lr:0.0004
[12:05:07.952] iteration:18522  t-loss:0.1477, loss-lb:0.0822, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:05:20.162]  <<Test>> - Ep:188  - mean_dice/mean_h95 - S:89.84/1.35, Best-S:90.99, T:89.69/1.39, Best-T:90.48
[12:05:20.163]           - AvgLoss(lb/ulb/all):0.0797/0.0397/0.1590
[12:05:20.704] iteration:18523  t-loss:0.1559, loss-lb:0.0742, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:05:20.898] iteration:18524  t-loss:0.1694, loss-lb:0.0803, loss-ulb:0.0446, weight:2.00, lr:0.0004
[12:05:21.090] iteration:18525  t-loss:0.1385, loss-lb:0.0783, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:05:21.282] iteration:18526  t-loss:0.1442, loss-lb:0.0808, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:05:21.473] iteration:18527  t-loss:0.1504, loss-lb:0.0810, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:05:21.665] iteration:18528  t-loss:0.1513, loss-lb:0.0870, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:05:21.857] iteration:18529  t-loss:0.1571, loss-lb:0.0814, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:05:22.049] iteration:18530  t-loss:0.1729, loss-lb:0.0822, loss-ulb:0.0453, weight:2.00, lr:0.0004
[12:05:22.241] iteration:18531  t-loss:0.1451, loss-lb:0.0752, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:05:22.432] iteration:18532  t-loss:0.1421, loss-lb:0.0744, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:05:22.625] iteration:18533  t-loss:0.1724, loss-lb:0.0796, loss-ulb:0.0464, weight:2.00, lr:0.0004
[12:05:22.817] iteration:18534  t-loss:0.1447, loss-lb:0.0894, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:05:23.009] iteration:18535  t-loss:0.1538, loss-lb:0.0817, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:05:23.201] iteration:18536  t-loss:0.1447, loss-lb:0.0827, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:05:23.393] iteration:18537  t-loss:0.1366, loss-lb:0.0742, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:05:23.584] iteration:18538  t-loss:0.1324, loss-lb:0.0725, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:05:23.777] iteration:18539  t-loss:0.1472, loss-lb:0.0830, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:05:23.969] iteration:18540  t-loss:0.1698, loss-lb:0.0837, loss-ulb:0.0430, weight:2.00, lr:0.0004
[12:05:24.161] iteration:18541  t-loss:0.1663, loss-lb:0.0910, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:05:24.352] iteration:18542  t-loss:0.1483, loss-lb:0.0743, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:05:24.544] iteration:18543  t-loss:0.1662, loss-lb:0.0755, loss-ulb:0.0453, weight:2.00, lr:0.0004
[12:05:24.736] iteration:18544  t-loss:0.1540, loss-lb:0.0882, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:05:24.927] iteration:18545  t-loss:0.1362, loss-lb:0.0779, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:05:25.118] iteration:18546  t-loss:0.1430, loss-lb:0.0748, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:05:25.311] iteration:18547  t-loss:0.1594, loss-lb:0.0774, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:05:25.502] iteration:18548  t-loss:0.1520, loss-lb:0.0814, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:05:25.694] iteration:18549  t-loss:0.1471, loss-lb:0.0885, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:05:25.885] iteration:18550  t-loss:0.1471, loss-lb:0.0777, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:05:26.076] iteration:18551  t-loss:0.1283, loss-lb:0.0726, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:05:26.268] iteration:18552  t-loss:0.1496, loss-lb:0.0752, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:05:26.460] iteration:18553  t-loss:0.1348, loss-lb:0.0764, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:05:26.651] iteration:18554  t-loss:0.1439, loss-lb:0.0843, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:05:26.856] iteration:18555  t-loss:0.1370, loss-lb:0.0761, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:05:27.055] iteration:18556  t-loss:0.1404, loss-lb:0.0722, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:05:27.250] iteration:18557  t-loss:0.1467, loss-lb:0.0786, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:05:27.442] iteration:18558  t-loss:0.1651, loss-lb:0.0762, loss-ulb:0.0445, weight:2.00, lr:0.0004
[12:05:27.635] iteration:18559  t-loss:0.1806, loss-lb:0.0752, loss-ulb:0.0527, weight:2.00, lr:0.0004
[12:05:27.828] iteration:18560  t-loss:0.1668, loss-lb:0.0784, loss-ulb:0.0442, weight:2.00, lr:0.0004
[12:05:28.021] iteration:18561  t-loss:0.1509, loss-lb:0.0863, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:05:28.213] iteration:18562  t-loss:0.1272, loss-lb:0.0716, loss-ulb:0.0278, weight:2.00, lr:0.0004
[12:05:28.406] iteration:18563  t-loss:0.1385, loss-lb:0.0762, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:05:28.599] iteration:18564  t-loss:0.1804, loss-lb:0.0893, loss-ulb:0.0455, weight:2.00, lr:0.0004
[12:05:28.791] iteration:18565  t-loss:0.1629, loss-lb:0.0917, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:05:28.984] iteration:18566  t-loss:0.1471, loss-lb:0.0785, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:05:29.177] iteration:18567  t-loss:0.1568, loss-lb:0.0712, loss-ulb:0.0428, weight:2.00, lr:0.0004
[12:05:29.369] iteration:18568  t-loss:0.1672, loss-lb:0.0741, loss-ulb:0.0466, weight:2.00, lr:0.0004
[12:05:29.561] iteration:18569  t-loss:0.1395, loss-lb:0.0724, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:05:29.754] iteration:18570  t-loss:0.1822, loss-lb:0.0786, loss-ulb:0.0518, weight:2.00, lr:0.0004
[12:05:29.946] iteration:18571  t-loss:0.1515, loss-lb:0.0849, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:05:30.140] iteration:18572  t-loss:0.2123, loss-lb:0.0857, loss-ulb:0.0633, weight:2.00, lr:0.0004
[12:05:30.332] iteration:18573  t-loss:0.1288, loss-lb:0.0718, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:05:30.524] iteration:18574  t-loss:0.1582, loss-lb:0.0812, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:05:30.716] iteration:18575  t-loss:0.1899, loss-lb:0.0846, loss-ulb:0.0527, weight:2.00, lr:0.0004
[12:05:30.908] iteration:18576  t-loss:0.1518, loss-lb:0.0756, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:05:31.101] iteration:18577  t-loss:0.1416, loss-lb:0.0753, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:05:31.293] iteration:18578  t-loss:0.1383, loss-lb:0.0824, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:05:31.487] iteration:18579  t-loss:0.1329, loss-lb:0.0706, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:05:31.679] iteration:18580  t-loss:0.1414, loss-lb:0.0821, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:05:31.872] iteration:18581  t-loss:0.1846, loss-lb:0.0772, loss-ulb:0.0537, weight:2.00, lr:0.0004
[12:05:32.064] iteration:18582  t-loss:0.1651, loss-lb:0.0753, loss-ulb:0.0449, weight:2.00, lr:0.0004
[12:05:32.257] iteration:18583  t-loss:0.1738, loss-lb:0.0836, loss-ulb:0.0451, weight:2.00, lr:0.0004
[12:05:32.450] iteration:18584  t-loss:0.1559, loss-lb:0.0804, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:05:32.643] iteration:18585  t-loss:0.1483, loss-lb:0.0835, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:05:32.835] iteration:18586  t-loss:0.1575, loss-lb:0.0873, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:05:33.027] iteration:18587  t-loss:0.1345, loss-lb:0.0847, loss-ulb:0.0249, weight:2.00, lr:0.0004
[12:05:33.220] iteration:18588  t-loss:0.1381, loss-lb:0.0748, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:05:33.412] iteration:18589  t-loss:0.1459, loss-lb:0.0873, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:05:33.605] iteration:18590  t-loss:0.2002, loss-lb:0.0778, loss-ulb:0.0612, weight:2.00, lr:0.0004
[12:05:33.797] iteration:18591  t-loss:0.1392, loss-lb:0.0749, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:05:33.989] iteration:18592  t-loss:0.1310, loss-lb:0.0775, loss-ulb:0.0267, weight:2.00, lr:0.0004
[12:05:34.183] iteration:18593  t-loss:0.2834, loss-lb:0.0730, loss-ulb:0.1052, weight:2.00, lr:0.0004
[12:05:34.376] iteration:18594  t-loss:0.2130, loss-lb:0.0757, loss-ulb:0.0687, weight:2.00, lr:0.0004
[12:05:34.568] iteration:18595  t-loss:0.2196, loss-lb:0.0787, loss-ulb:0.0704, weight:2.00, lr:0.0004
[12:05:34.760] iteration:18596  t-loss:0.1541, loss-lb:0.0974, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:05:34.953] iteration:18597  t-loss:0.1777, loss-lb:0.0810, loss-ulb:0.0484, weight:2.00, lr:0.0004
[12:05:35.145] iteration:18598  t-loss:0.1475, loss-lb:0.0823, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:05:35.338] iteration:18599  t-loss:0.1690, loss-lb:0.0898, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:05:35.530] iteration:18600  t-loss:0.1395, loss-lb:0.0763, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:05:35.724] iteration:18601  t-loss:0.1485, loss-lb:0.0858, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:05:35.916] iteration:18602  t-loss:0.1492, loss-lb:0.0786, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:05:36.108] iteration:18603  t-loss:0.1456, loss-lb:0.0827, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:05:36.301] iteration:18604  t-loss:0.1532, loss-lb:0.0804, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:05:36.495] iteration:18605  t-loss:0.1738, loss-lb:0.0870, loss-ulb:0.0434, weight:2.00, lr:0.0004
[12:05:36.689] iteration:18606  t-loss:0.1580, loss-lb:0.0799, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:05:36.881] iteration:18607  t-loss:0.1672, loss-lb:0.0818, loss-ulb:0.0427, weight:2.00, lr:0.0004
[12:05:37.074] iteration:18608  t-loss:0.1567, loss-lb:0.0731, loss-ulb:0.0418, weight:2.00, lr:0.0004
[12:05:37.266] iteration:18609  t-loss:0.1465, loss-lb:0.0812, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:05:37.458] iteration:18610  t-loss:0.2021, loss-lb:0.0874, loss-ulb:0.0573, weight:2.00, lr:0.0004
[12:05:37.651] iteration:18611  t-loss:0.1627, loss-lb:0.0872, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:05:37.845] iteration:18612  t-loss:0.1535, loss-lb:0.0774, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:05:38.037] iteration:18613  t-loss:0.1688, loss-lb:0.0778, loss-ulb:0.0455, weight:2.00, lr:0.0004
[12:05:38.227] iteration:18614  t-loss:0.1489, loss-lb:0.0822, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:05:38.418] iteration:18615  t-loss:0.1473, loss-lb:0.0737, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:05:38.608] iteration:18616  t-loss:0.1489, loss-lb:0.0759, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:05:38.799] iteration:18617  t-loss:0.1347, loss-lb:0.0731, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:05:38.988] iteration:18618  t-loss:0.1895, loss-lb:0.0864, loss-ulb:0.0516, weight:2.00, lr:0.0004
[12:05:39.179] iteration:18619  t-loss:0.1523, loss-lb:0.0819, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:05:39.370] iteration:18620  t-loss:0.2464, loss-lb:0.0754, loss-ulb:0.0855, weight:2.00, lr:0.0004
[12:05:39.972] iteration:18621  t-loss:0.1567, loss-lb:0.0826, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:05:40.167] iteration:18622  t-loss:0.1395, loss-lb:0.0775, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:05:40.359] iteration:18623  t-loss:0.1602, loss-lb:0.0780, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:05:40.552] iteration:18624  t-loss:0.1893, loss-lb:0.0674, loss-ulb:0.0610, weight:2.00, lr:0.0004
[12:05:40.745] iteration:18625  t-loss:0.1412, loss-lb:0.0766, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:05:40.937] iteration:18626  t-loss:0.1539, loss-lb:0.0826, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:05:41.129] iteration:18627  t-loss:0.1524, loss-lb:0.0817, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:05:41.322] iteration:18628  t-loss:0.1638, loss-lb:0.0922, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:05:41.515] iteration:18629  t-loss:0.1544, loss-lb:0.0853, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:05:41.708] iteration:18630  t-loss:0.1783, loss-lb:0.0781, loss-ulb:0.0501, weight:2.00, lr:0.0004
[12:05:41.900] iteration:18631  t-loss:0.1799, loss-lb:0.0859, loss-ulb:0.0470, weight:2.00, lr:0.0004
[12:05:42.093] iteration:18632  t-loss:0.1586, loss-lb:0.0847, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:05:42.286] iteration:18633  t-loss:0.1468, loss-lb:0.0799, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:05:42.479] iteration:18634  t-loss:0.1537, loss-lb:0.0891, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:05:42.671] iteration:18635  t-loss:0.1493, loss-lb:0.0805, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:05:42.864] iteration:18636  t-loss:0.1626, loss-lb:0.0801, loss-ulb:0.0412, weight:2.00, lr:0.0004
[12:05:43.057] iteration:18637  t-loss:0.1564, loss-lb:0.0837, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:05:43.249] iteration:18638  t-loss:0.1757, loss-lb:0.0899, loss-ulb:0.0429, weight:2.00, lr:0.0004
[12:05:43.442] iteration:18639  t-loss:0.1620, loss-lb:0.0843, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:05:43.634] iteration:18640  t-loss:0.1777, loss-lb:0.0815, loss-ulb:0.0481, weight:2.00, lr:0.0004
[12:05:43.826] iteration:18641  t-loss:0.1448, loss-lb:0.0801, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:05:44.018] iteration:18642  t-loss:0.1414, loss-lb:0.0746, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:05:44.212] iteration:18643  t-loss:0.1459, loss-lb:0.0808, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:05:44.404] iteration:18644  t-loss:0.2154, loss-lb:0.0788, loss-ulb:0.0683, weight:2.00, lr:0.0004
[12:05:44.596] iteration:18645  t-loss:0.1396, loss-lb:0.0756, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:05:44.789] iteration:18646  t-loss:0.1448, loss-lb:0.0855, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:05:44.981] iteration:18647  t-loss:0.1553, loss-lb:0.0845, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:05:45.174] iteration:18648  t-loss:0.1532, loss-lb:0.0870, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:05:45.367] iteration:18649  t-loss:0.1536, loss-lb:0.0930, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:05:45.559] iteration:18650  t-loss:0.1832, loss-lb:0.0935, loss-ulb:0.0448, weight:2.00, lr:0.0004
[12:05:45.752] iteration:18651  t-loss:0.1779, loss-lb:0.0963, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:05:45.944] iteration:18652  t-loss:0.1687, loss-lb:0.1019, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:05:46.139] iteration:18653  t-loss:0.2085, loss-lb:0.0861, loss-ulb:0.0612, weight:2.00, lr:0.0004
[12:05:46.332] iteration:18654  t-loss:0.1614, loss-lb:0.0866, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:05:46.525] iteration:18655  t-loss:0.1670, loss-lb:0.0799, loss-ulb:0.0436, weight:2.00, lr:0.0004
[12:05:46.717] iteration:18656  t-loss:0.1427, loss-lb:0.0770, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:05:46.910] iteration:18657  t-loss:0.1544, loss-lb:0.0820, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:05:47.102] iteration:18658  t-loss:0.1497, loss-lb:0.0856, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:05:47.294] iteration:18659  t-loss:0.1697, loss-lb:0.0979, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:05:47.487] iteration:18660  t-loss:0.1622, loss-lb:0.0904, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:05:47.679] iteration:18661  t-loss:0.1799, loss-lb:0.0882, loss-ulb:0.0459, weight:2.00, lr:0.0004
[12:05:47.873] iteration:18662  t-loss:0.2071, loss-lb:0.0845, loss-ulb:0.0613, weight:2.00, lr:0.0004
[12:05:48.065] iteration:18663  t-loss:0.1922, loss-lb:0.1029, loss-ulb:0.0446, weight:2.00, lr:0.0004
[12:05:48.258] iteration:18664  t-loss:0.1453, loss-lb:0.0795, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:05:48.449] iteration:18665  t-loss:0.1416, loss-lb:0.0799, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:05:48.642] iteration:18666  t-loss:0.1545, loss-lb:0.0843, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:05:48.835] iteration:18667  t-loss:0.1607, loss-lb:0.0721, loss-ulb:0.0443, weight:2.00, lr:0.0004
[12:05:49.027] iteration:18668  t-loss:0.1336, loss-lb:0.0802, loss-ulb:0.0267, weight:2.00, lr:0.0004
[12:05:49.219] iteration:18669  t-loss:0.1693, loss-lb:0.0849, loss-ulb:0.0422, weight:2.00, lr:0.0004
[12:05:49.411] iteration:18670  t-loss:0.1486, loss-lb:0.0804, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:05:49.606] iteration:18671  t-loss:0.1671, loss-lb:0.0843, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:05:49.801] iteration:18672  t-loss:0.1598, loss-lb:0.0885, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:05:49.998] iteration:18673  t-loss:0.1646, loss-lb:0.0897, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:05:50.193] iteration:18674  t-loss:0.1576, loss-lb:0.0795, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:05:50.386] iteration:18675  t-loss:0.1355, loss-lb:0.0758, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:05:50.579] iteration:18676  t-loss:0.1497, loss-lb:0.0839, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:05:50.778] iteration:18677  t-loss:0.1540, loss-lb:0.0887, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:05:50.972] iteration:18678  t-loss:0.1506, loss-lb:0.0831, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:05:51.164] iteration:18679  t-loss:0.1369, loss-lb:0.0763, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:05:51.355] iteration:18680  t-loss:0.1466, loss-lb:0.0807, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:05:51.553] iteration:18681  t-loss:0.1508, loss-lb:0.0859, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:05:51.745] iteration:18682  t-loss:0.1489, loss-lb:0.0817, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:05:51.941] iteration:18683  t-loss:0.1434, loss-lb:0.0796, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:05:52.134] iteration:18684  t-loss:0.2840, loss-lb:0.0832, loss-ulb:0.1004, weight:2.00, lr:0.0004
[12:05:52.326] iteration:18685  t-loss:0.1519, loss-lb:0.0807, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:05:52.519] iteration:18686  t-loss:0.1875, loss-lb:0.0871, loss-ulb:0.0502, weight:2.00, lr:0.0004
[12:05:52.713] iteration:18687  t-loss:0.2093, loss-lb:0.0829, loss-ulb:0.0632, weight:2.00, lr:0.0004
[12:05:52.907] iteration:18688  t-loss:0.1297, loss-lb:0.0733, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:05:53.100] iteration:18689  t-loss:0.1542, loss-lb:0.0842, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:05:53.291] iteration:18690  t-loss:0.1439, loss-lb:0.0803, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:05:53.485] iteration:18691  t-loss:0.2416, loss-lb:0.0881, loss-ulb:0.0768, weight:2.00, lr:0.0004
[12:05:53.677] iteration:18692  t-loss:0.1524, loss-lb:0.0824, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:05:53.868] iteration:18693  t-loss:0.1604, loss-lb:0.0835, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:05:54.061] iteration:18694  t-loss:0.1561, loss-lb:0.0835, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:05:54.254] iteration:18695  t-loss:0.1415, loss-lb:0.0764, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:05:54.446] iteration:18696  t-loss:0.1625, loss-lb:0.0920, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:05:54.638] iteration:18697  t-loss:0.1423, loss-lb:0.0756, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:05:54.830] iteration:18698  t-loss:0.1551, loss-lb:0.0784, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:05:55.021] iteration:18699  t-loss:0.1420, loss-lb:0.0831, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:05:55.214] iteration:18700  t-loss:0.1531, loss-lb:0.0883, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:05:55.407] iteration:18701  t-loss:0.1301, loss-lb:0.0754, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:05:55.600] iteration:18702  t-loss:0.1520, loss-lb:0.0875, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:05:55.793] iteration:18703  t-loss:0.1626, loss-lb:0.0741, loss-ulb:0.0442, weight:2.00, lr:0.0004
[12:05:55.985] iteration:18704  t-loss:0.1550, loss-lb:0.0798, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:05:56.178] iteration:18705  t-loss:0.1464, loss-lb:0.0805, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:05:56.373] iteration:18706  t-loss:0.1293, loss-lb:0.0688, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:05:56.565] iteration:18707  t-loss:0.1611, loss-lb:0.0881, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:05:56.757] iteration:18708  t-loss:0.1431, loss-lb:0.0759, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:05:56.950] iteration:18709  t-loss:0.1485, loss-lb:0.0788, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:05:57.142] iteration:18710  t-loss:0.1540, loss-lb:0.0843, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:05:57.333] iteration:18711  t-loss:0.1394, loss-lb:0.0748, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:05:57.525] iteration:18712  t-loss:0.1462, loss-lb:0.0845, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:05:57.715] iteration:18713  t-loss:0.1478, loss-lb:0.0760, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:05:57.906] iteration:18714  t-loss:0.1363, loss-lb:0.0755, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:05:58.096] iteration:18715  t-loss:0.1327, loss-lb:0.0714, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:05:58.286] iteration:18716  t-loss:0.1376, loss-lb:0.0794, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:05:58.476] iteration:18717  t-loss:0.1445, loss-lb:0.0760, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:05:58.668] iteration:18718  t-loss:0.1497, loss-lb:0.0714, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:06:11.631]  <<Test>> - Ep:190  - mean_dice/mean_h95 - S:89.95/1.36, Best-S:90.99, T:89.92/1.34, Best-T:90.48
[12:06:11.632]           - AvgLoss(lb/ulb/all):0.0824/0.0334/0.1456
[12:06:12.224] iteration:18719  t-loss:0.1507, loss-lb:0.0805, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:06:12.421] iteration:18720  t-loss:0.1566, loss-lb:0.0824, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:06:12.613] iteration:18721  t-loss:0.1418, loss-lb:0.0756, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:06:12.805] iteration:18722  t-loss:0.1498, loss-lb:0.0843, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:06:12.996] iteration:18723  t-loss:0.1405, loss-lb:0.0821, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:06:13.186] iteration:18724  t-loss:0.1425, loss-lb:0.0758, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:06:13.378] iteration:18725  t-loss:0.1350, loss-lb:0.0712, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:06:13.570] iteration:18726  t-loss:0.1563, loss-lb:0.0856, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:06:13.762] iteration:18727  t-loss:0.1202, loss-lb:0.0683, loss-ulb:0.0259, weight:2.00, lr:0.0004
[12:06:13.953] iteration:18728  t-loss:0.1417, loss-lb:0.0751, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:06:14.146] iteration:18729  t-loss:0.1471, loss-lb:0.0798, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:06:14.338] iteration:18730  t-loss:0.1529, loss-lb:0.0846, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:06:14.530] iteration:18731  t-loss:0.1508, loss-lb:0.0850, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:06:14.721] iteration:18732  t-loss:0.1335, loss-lb:0.0764, loss-ulb:0.0286, weight:2.00, lr:0.0004
[12:06:14.915] iteration:18733  t-loss:0.1450, loss-lb:0.0752, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:06:15.106] iteration:18734  t-loss:0.1591, loss-lb:0.0783, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:06:15.298] iteration:18735  t-loss:0.1449, loss-lb:0.0856, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:06:15.488] iteration:18736  t-loss:0.1366, loss-lb:0.0744, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:06:15.681] iteration:18737  t-loss:0.1817, loss-lb:0.0799, loss-ulb:0.0509, weight:2.00, lr:0.0004
[12:06:15.873] iteration:18738  t-loss:0.1399, loss-lb:0.0713, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:06:16.064] iteration:18739  t-loss:0.1315, loss-lb:0.0690, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:06:16.254] iteration:18740  t-loss:0.1659, loss-lb:0.0804, loss-ulb:0.0428, weight:2.00, lr:0.0004
[12:06:16.446] iteration:18741  t-loss:0.1531, loss-lb:0.0847, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:06:16.637] iteration:18742  t-loss:0.1648, loss-lb:0.0741, loss-ulb:0.0453, weight:2.00, lr:0.0004
[12:06:16.829] iteration:18743  t-loss:0.1497, loss-lb:0.0817, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:06:17.020] iteration:18744  t-loss:0.1733, loss-lb:0.0767, loss-ulb:0.0483, weight:2.00, lr:0.0004
[12:06:17.212] iteration:18745  t-loss:0.2049, loss-lb:0.0780, loss-ulb:0.0635, weight:2.00, lr:0.0004
[12:06:17.404] iteration:18746  t-loss:0.1292, loss-lb:0.0757, loss-ulb:0.0268, weight:2.00, lr:0.0004
[12:06:17.596] iteration:18747  t-loss:0.1448, loss-lb:0.0796, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:06:17.786] iteration:18748  t-loss:0.1445, loss-lb:0.0810, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:06:17.978] iteration:18749  t-loss:0.1407, loss-lb:0.0830, loss-ulb:0.0289, weight:2.00, lr:0.0004
[12:06:18.170] iteration:18750  t-loss:0.1830, loss-lb:0.0789, loss-ulb:0.0520, weight:2.00, lr:0.0004
[12:06:18.361] iteration:18751  t-loss:0.1734, loss-lb:0.0815, loss-ulb:0.0459, weight:2.00, lr:0.0004
[12:06:18.552] iteration:18752  t-loss:0.1335, loss-lb:0.0720, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:06:18.742] iteration:18753  t-loss:0.1366, loss-lb:0.0778, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:06:18.934] iteration:18754  t-loss:0.1922, loss-lb:0.0904, loss-ulb:0.0509, weight:2.00, lr:0.0004
[12:06:19.125] iteration:18755  t-loss:0.1794, loss-lb:0.0874, loss-ulb:0.0460, weight:2.00, lr:0.0004
[12:06:19.316] iteration:18756  t-loss:0.1347, loss-lb:0.0746, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:06:19.509] iteration:18757  t-loss:0.1561, loss-lb:0.0880, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:06:19.700] iteration:18758  t-loss:0.1420, loss-lb:0.0761, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:06:19.892] iteration:18759  t-loss:0.1398, loss-lb:0.0828, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:06:20.082] iteration:18760  t-loss:0.1791, loss-lb:0.0761, loss-ulb:0.0515, weight:2.00, lr:0.0004
[12:06:20.272] iteration:18761  t-loss:0.1742, loss-lb:0.0820, loss-ulb:0.0461, weight:2.00, lr:0.0004
[12:06:20.464] iteration:18762  t-loss:0.1365, loss-lb:0.0734, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:06:20.656] iteration:18763  t-loss:0.1488, loss-lb:0.0717, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:06:20.846] iteration:18764  t-loss:0.1490, loss-lb:0.0747, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:06:21.038] iteration:18765  t-loss:0.1361, loss-lb:0.0736, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:06:21.230] iteration:18766  t-loss:0.1598, loss-lb:0.0785, loss-ulb:0.0407, weight:2.00, lr:0.0004
[12:06:21.422] iteration:18767  t-loss:0.1568, loss-lb:0.0802, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:06:21.612] iteration:18768  t-loss:0.1767, loss-lb:0.0844, loss-ulb:0.0462, weight:2.00, lr:0.0004
[12:06:21.803] iteration:18769  t-loss:0.1575, loss-lb:0.0860, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:06:21.995] iteration:18770  t-loss:0.1424, loss-lb:0.0816, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:06:22.187] iteration:18771  t-loss:0.1575, loss-lb:0.0825, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:06:22.380] iteration:18772  t-loss:0.1790, loss-lb:0.0835, loss-ulb:0.0478, weight:2.00, lr:0.0004
[12:06:22.576] iteration:18773  t-loss:0.1377, loss-lb:0.0745, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:06:22.771] iteration:18774  t-loss:0.1500, loss-lb:0.0884, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:06:22.966] iteration:18775  t-loss:0.1565, loss-lb:0.0887, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:06:23.157] iteration:18776  t-loss:0.1493, loss-lb:0.0823, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:06:23.350] iteration:18777  t-loss:0.1466, loss-lb:0.0854, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:06:23.542] iteration:18778  t-loss:0.1550, loss-lb:0.0773, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:06:23.734] iteration:18779  t-loss:0.1766, loss-lb:0.0837, loss-ulb:0.0464, weight:2.00, lr:0.0004
[12:06:23.927] iteration:18780  t-loss:0.2364, loss-lb:0.0717, loss-ulb:0.0824, weight:2.00, lr:0.0004
[12:06:24.119] iteration:18781  t-loss:0.1543, loss-lb:0.0738, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:06:24.311] iteration:18782  t-loss:0.1479, loss-lb:0.0805, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:06:24.503] iteration:18783  t-loss:0.1472, loss-lb:0.0773, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:06:24.695] iteration:18784  t-loss:0.1480, loss-lb:0.0845, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:06:24.895] iteration:18785  t-loss:0.1656, loss-lb:0.0827, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:06:25.086] iteration:18786  t-loss:0.1387, loss-lb:0.0780, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:06:25.278] iteration:18787  t-loss:0.1513, loss-lb:0.0871, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:06:25.470] iteration:18788  t-loss:0.1261, loss-lb:0.0679, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:06:25.669] iteration:18789  t-loss:0.1356, loss-lb:0.0748, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:06:25.863] iteration:18790  t-loss:0.1890, loss-lb:0.0797, loss-ulb:0.0547, weight:2.00, lr:0.0004
[12:06:26.054] iteration:18791  t-loss:0.1470, loss-lb:0.0746, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:06:26.246] iteration:18792  t-loss:0.1568, loss-lb:0.0801, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:06:26.445] iteration:18793  t-loss:0.1468, loss-lb:0.0738, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:06:26.638] iteration:18794  t-loss:0.1454, loss-lb:0.0766, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:06:26.830] iteration:18795  t-loss:0.1422, loss-lb:0.0810, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:06:27.022] iteration:18796  t-loss:0.1798, loss-lb:0.0839, loss-ulb:0.0479, weight:2.00, lr:0.0004
[12:06:27.222] iteration:18797  t-loss:0.1441, loss-lb:0.0808, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:06:27.414] iteration:18798  t-loss:0.1777, loss-lb:0.0865, loss-ulb:0.0456, weight:2.00, lr:0.0004
[12:06:27.605] iteration:18799  t-loss:0.1413, loss-lb:0.0774, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:06:27.797] iteration:18800  t-loss:0.1466, loss-lb:0.0817, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:06:27.997] iteration:18801  t-loss:0.1428, loss-lb:0.0828, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:06:28.189] iteration:18802  t-loss:0.1499, loss-lb:0.0834, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:06:28.381] iteration:18803  t-loss:0.1488, loss-lb:0.0764, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:06:28.573] iteration:18804  t-loss:0.1291, loss-lb:0.0709, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:06:28.774] iteration:18805  t-loss:0.1451, loss-lb:0.0775, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:06:28.967] iteration:18806  t-loss:0.1332, loss-lb:0.0779, loss-ulb:0.0277, weight:2.00, lr:0.0004
[12:06:29.161] iteration:18807  t-loss:0.1455, loss-lb:0.0822, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:06:29.352] iteration:18808  t-loss:0.1353, loss-lb:0.0714, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:06:29.543] iteration:18809  t-loss:0.1394, loss-lb:0.0808, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:06:29.736] iteration:18810  t-loss:0.1382, loss-lb:0.0755, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:06:29.926] iteration:18811  t-loss:0.1432, loss-lb:0.0773, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:06:30.119] iteration:18812  t-loss:0.1574, loss-lb:0.0804, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:06:30.309] iteration:18813  t-loss:0.1375, loss-lb:0.0748, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:06:30.500] iteration:18814  t-loss:0.1464, loss-lb:0.0740, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:06:30.690] iteration:18815  t-loss:0.1592, loss-lb:0.0737, loss-ulb:0.0427, weight:2.00, lr:0.0004
[12:06:30.882] iteration:18816  t-loss:0.1501, loss-lb:0.0782, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:06:31.484] iteration:18817  t-loss:0.1386, loss-lb:0.0728, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:06:31.676] iteration:18818  t-loss:0.1512, loss-lb:0.0768, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:06:31.867] iteration:18819  t-loss:0.1291, loss-lb:0.0711, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:06:32.058] iteration:18820  t-loss:0.1518, loss-lb:0.0793, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:06:32.250] iteration:18821  t-loss:0.1511, loss-lb:0.0856, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:06:32.451] iteration:18822  t-loss:0.1415, loss-lb:0.0812, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:06:32.650] iteration:18823  t-loss:0.1403, loss-lb:0.0801, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:06:32.860] iteration:18824  t-loss:0.1480, loss-lb:0.0785, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:06:33.053] iteration:18825  t-loss:0.1399, loss-lb:0.0733, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:06:33.245] iteration:18826  t-loss:0.1394, loss-lb:0.0751, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:06:33.438] iteration:18827  t-loss:0.1461, loss-lb:0.0772, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:06:33.631] iteration:18828  t-loss:0.1423, loss-lb:0.0788, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:06:33.823] iteration:18829  t-loss:0.1471, loss-lb:0.0855, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:06:34.016] iteration:18830  t-loss:0.1393, loss-lb:0.0775, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:06:34.209] iteration:18831  t-loss:0.1497, loss-lb:0.0847, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:06:34.402] iteration:18832  t-loss:0.1350, loss-lb:0.0750, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:06:34.595] iteration:18833  t-loss:0.1624, loss-lb:0.0768, loss-ulb:0.0428, weight:2.00, lr:0.0004
[12:06:34.788] iteration:18834  t-loss:0.1552, loss-lb:0.0873, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:06:34.981] iteration:18835  t-loss:0.1425, loss-lb:0.0781, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:06:35.173] iteration:18836  t-loss:0.1393, loss-lb:0.0781, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:06:35.366] iteration:18837  t-loss:0.1982, loss-lb:0.0751, loss-ulb:0.0615, weight:2.00, lr:0.0004
[12:06:35.559] iteration:18838  t-loss:0.1411, loss-lb:0.0735, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:06:35.752] iteration:18839  t-loss:0.1415, loss-lb:0.0788, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:06:35.944] iteration:18840  t-loss:0.1304, loss-lb:0.0694, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:06:36.137] iteration:18841  t-loss:0.1492, loss-lb:0.0848, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:06:36.330] iteration:18842  t-loss:0.1418, loss-lb:0.0699, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:06:36.523] iteration:18843  t-loss:0.2093, loss-lb:0.0844, loss-ulb:0.0624, weight:2.00, lr:0.0004
[12:06:36.717] iteration:18844  t-loss:0.1601, loss-lb:0.0869, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:06:36.911] iteration:18845  t-loss:0.1441, loss-lb:0.0807, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:06:37.103] iteration:18846  t-loss:0.1583, loss-lb:0.0838, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:06:37.296] iteration:18847  t-loss:0.1458, loss-lb:0.0719, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:06:37.488] iteration:18848  t-loss:0.1390, loss-lb:0.0788, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:06:37.680] iteration:18849  t-loss:0.1371, loss-lb:0.0765, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:06:37.874] iteration:18850  t-loss:0.2830, loss-lb:0.0780, loss-ulb:0.1025, weight:2.00, lr:0.0004
[12:06:38.067] iteration:18851  t-loss:0.1923, loss-lb:0.0744, loss-ulb:0.0590, weight:2.00, lr:0.0004
[12:06:38.259] iteration:18852  t-loss:0.1352, loss-lb:0.0793, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:06:38.452] iteration:18853  t-loss:0.1321, loss-lb:0.0750, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:06:38.643] iteration:18854  t-loss:0.1371, loss-lb:0.0706, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:06:38.836] iteration:18855  t-loss:0.1361, loss-lb:0.0759, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:06:39.028] iteration:18856  t-loss:0.1620, loss-lb:0.0858, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:06:39.221] iteration:18857  t-loss:0.1343, loss-lb:0.0760, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:06:39.414] iteration:18858  t-loss:0.1643, loss-lb:0.0792, loss-ulb:0.0426, weight:2.00, lr:0.0004
[12:06:39.606] iteration:18859  t-loss:0.1511, loss-lb:0.0805, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:06:39.799] iteration:18860  t-loss:0.1397, loss-lb:0.0777, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:06:39.992] iteration:18861  t-loss:0.1476, loss-lb:0.0745, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:06:40.184] iteration:18862  t-loss:0.1517, loss-lb:0.0718, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:06:40.377] iteration:18863  t-loss:0.1393, loss-lb:0.0720, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:06:40.569] iteration:18864  t-loss:0.1411, loss-lb:0.0775, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:06:40.762] iteration:18865  t-loss:0.1819, loss-lb:0.0825, loss-ulb:0.0497, weight:2.00, lr:0.0004
[12:06:40.955] iteration:18866  t-loss:0.1574, loss-lb:0.0814, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:06:41.148] iteration:18867  t-loss:0.1757, loss-lb:0.0800, loss-ulb:0.0478, weight:2.00, lr:0.0004
[12:06:41.341] iteration:18868  t-loss:0.1703, loss-lb:0.0855, loss-ulb:0.0424, weight:2.00, lr:0.0004
[12:06:41.535] iteration:18869  t-loss:0.1443, loss-lb:0.0843, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:06:41.726] iteration:18870  t-loss:0.1394, loss-lb:0.0733, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:06:41.918] iteration:18871  t-loss:0.1396, loss-lb:0.0700, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:06:42.111] iteration:18872  t-loss:0.1437, loss-lb:0.0756, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:06:42.304] iteration:18873  t-loss:0.1339, loss-lb:0.0778, loss-ulb:0.0280, weight:2.00, lr:0.0004
[12:06:42.497] iteration:18874  t-loss:0.1322, loss-lb:0.0690, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:06:42.690] iteration:18875  t-loss:0.1394, loss-lb:0.0799, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:06:42.884] iteration:18876  t-loss:0.1394, loss-lb:0.0727, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:06:43.077] iteration:18877  t-loss:0.1380, loss-lb:0.0765, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:06:43.272] iteration:18878  t-loss:0.1761, loss-lb:0.0805, loss-ulb:0.0478, weight:2.00, lr:0.0004
[12:06:43.465] iteration:18879  t-loss:0.1313, loss-lb:0.0747, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:06:43.658] iteration:18880  t-loss:0.1422, loss-lb:0.0825, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:06:43.851] iteration:18881  t-loss:0.1894, loss-lb:0.0869, loss-ulb:0.0513, weight:2.00, lr:0.0004
[12:06:44.043] iteration:18882  t-loss:0.1492, loss-lb:0.0765, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:06:44.235] iteration:18883  t-loss:0.1828, loss-lb:0.0921, loss-ulb:0.0453, weight:2.00, lr:0.0004
[12:06:44.429] iteration:18884  t-loss:0.1324, loss-lb:0.0716, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:06:44.621] iteration:18885  t-loss:0.1937, loss-lb:0.0810, loss-ulb:0.0564, weight:2.00, lr:0.0004
[12:06:44.819] iteration:18886  t-loss:0.1399, loss-lb:0.0763, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:06:45.013] iteration:18887  t-loss:0.1509, loss-lb:0.0821, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:06:45.205] iteration:18888  t-loss:0.1418, loss-lb:0.0761, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:06:45.397] iteration:18889  t-loss:0.1686, loss-lb:0.0769, loss-ulb:0.0458, weight:2.00, lr:0.0004
[12:06:45.590] iteration:18890  t-loss:0.1615, loss-lb:0.0799, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:06:45.782] iteration:18891  t-loss:0.1520, loss-lb:0.0813, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:06:45.975] iteration:18892  t-loss:0.1449, loss-lb:0.0795, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:06:46.170] iteration:18893  t-loss:0.1292, loss-lb:0.0722, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:06:46.362] iteration:18894  t-loss:0.1376, loss-lb:0.0735, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:06:46.555] iteration:18895  t-loss:0.1818, loss-lb:0.0896, loss-ulb:0.0461, weight:2.00, lr:0.0004
[12:06:46.748] iteration:18896  t-loss:0.1379, loss-lb:0.0793, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:06:46.940] iteration:18897  t-loss:0.1360, loss-lb:0.0727, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:06:47.133] iteration:18898  t-loss:0.1407, loss-lb:0.0842, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:06:47.326] iteration:18899  t-loss:0.1737, loss-lb:0.0728, loss-ulb:0.0505, weight:2.00, lr:0.0004
[12:06:47.518] iteration:18900  t-loss:0.1398, loss-lb:0.0758, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:06:47.711] iteration:18901  t-loss:0.1518, loss-lb:0.0754, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:06:47.904] iteration:18902  t-loss:0.1486, loss-lb:0.0696, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:06:48.097] iteration:18903  t-loss:0.1457, loss-lb:0.0829, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:06:48.288] iteration:18904  t-loss:0.1638, loss-lb:0.0907, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:06:48.481] iteration:18905  t-loss:0.1572, loss-lb:0.0825, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:06:48.673] iteration:18906  t-loss:0.1532, loss-lb:0.0827, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:06:48.867] iteration:18907  t-loss:0.1735, loss-lb:0.0854, loss-ulb:0.0441, weight:2.00, lr:0.0004
[12:06:49.058] iteration:18908  t-loss:0.1568, loss-lb:0.0890, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:06:49.250] iteration:18909  t-loss:0.1437, loss-lb:0.0753, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:06:49.441] iteration:18910  t-loss:0.1964, loss-lb:0.0823, loss-ulb:0.0571, weight:2.00, lr:0.0004
[12:06:49.632] iteration:18911  t-loss:0.1492, loss-lb:0.0842, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:06:49.823] iteration:18912  t-loss:0.1541, loss-lb:0.0842, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:06:50.014] iteration:18913  t-loss:0.1506, loss-lb:0.0788, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:06:50.204] iteration:18914  t-loss:0.1582, loss-lb:0.0822, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:07:02.471]  <<Test>> - Ep:192  - mean_dice/mean_h95 - S:89.65/1.37, Best-S:90.99, T:89.89/1.31, Best-T:90.48
[12:07:02.471]           - AvgLoss(lb/ulb/all):0.0786/0.0373/0.1556
[12:07:03.007] iteration:18915  t-loss:0.1470, loss-lb:0.0757, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:07:03.204] iteration:18916  t-loss:0.1377, loss-lb:0.0795, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:07:03.397] iteration:18917  t-loss:0.1431, loss-lb:0.0703, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:07:03.591] iteration:18918  t-loss:0.1651, loss-lb:0.0768, loss-ulb:0.0441, weight:2.00, lr:0.0004
[12:07:03.784] iteration:18919  t-loss:0.1443, loss-lb:0.0844, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:07:03.976] iteration:18920  t-loss:0.1466, loss-lb:0.0862, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:07:04.170] iteration:18921  t-loss:0.1402, loss-lb:0.0843, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:07:04.363] iteration:18922  t-loss:0.1417, loss-lb:0.0735, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:07:04.556] iteration:18923  t-loss:0.1404, loss-lb:0.0733, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:07:04.749] iteration:18924  t-loss:0.1608, loss-lb:0.0722, loss-ulb:0.0443, weight:2.00, lr:0.0004
[12:07:04.942] iteration:18925  t-loss:0.1534, loss-lb:0.0924, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:07:05.147] iteration:18926  t-loss:0.1522, loss-lb:0.0805, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:07:05.348] iteration:18927  t-loss:0.1292, loss-lb:0.0704, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:07:05.544] iteration:18928  t-loss:0.1407, loss-lb:0.0734, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:07:05.737] iteration:18929  t-loss:0.1656, loss-lb:0.0732, loss-ulb:0.0462, weight:2.00, lr:0.0004
[12:07:05.930] iteration:18930  t-loss:0.1534, loss-lb:0.0750, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:07:06.123] iteration:18931  t-loss:0.1669, loss-lb:0.0999, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:07:06.316] iteration:18932  t-loss:0.1466, loss-lb:0.0829, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:07:06.509] iteration:18933  t-loss:0.1744, loss-lb:0.0869, loss-ulb:0.0438, weight:2.00, lr:0.0004
[12:07:06.703] iteration:18934  t-loss:0.1455, loss-lb:0.0746, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:07:06.896] iteration:18935  t-loss:0.1303, loss-lb:0.0775, loss-ulb:0.0264, weight:2.00, lr:0.0004
[12:07:07.088] iteration:18936  t-loss:0.1616, loss-lb:0.0811, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:07:07.281] iteration:18937  t-loss:0.1352, loss-lb:0.0768, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:07:07.474] iteration:18938  t-loss:0.1548, loss-lb:0.0782, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:07:07.667] iteration:18939  t-loss:0.1561, loss-lb:0.0783, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:07:07.861] iteration:18940  t-loss:0.1611, loss-lb:0.0787, loss-ulb:0.0412, weight:2.00, lr:0.0004
[12:07:08.053] iteration:18941  t-loss:0.1515, loss-lb:0.0836, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:07:08.246] iteration:18942  t-loss:0.1479, loss-lb:0.0774, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:07:08.440] iteration:18943  t-loss:0.1506, loss-lb:0.0775, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:07:08.633] iteration:18944  t-loss:0.1501, loss-lb:0.0774, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:07:08.826] iteration:18945  t-loss:0.1337, loss-lb:0.0757, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:07:09.020] iteration:18946  t-loss:0.1354, loss-lb:0.0718, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:07:09.212] iteration:18947  t-loss:0.1423, loss-lb:0.0740, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:07:09.405] iteration:18948  t-loss:0.1259, loss-lb:0.0712, loss-ulb:0.0273, weight:2.00, lr:0.0004
[12:07:09.598] iteration:18949  t-loss:0.1256, loss-lb:0.0743, loss-ulb:0.0257, weight:2.00, lr:0.0004
[12:07:09.792] iteration:18950  t-loss:0.2392, loss-lb:0.0742, loss-ulb:0.0825, weight:2.00, lr:0.0004
[12:07:09.986] iteration:18951  t-loss:0.2507, loss-lb:0.0849, loss-ulb:0.0829, weight:2.00, lr:0.0004
[12:07:10.179] iteration:18952  t-loss:0.1465, loss-lb:0.0781, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:07:10.371] iteration:18953  t-loss:0.1495, loss-lb:0.0823, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:07:10.563] iteration:18954  t-loss:0.1408, loss-lb:0.0846, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:07:10.757] iteration:18955  t-loss:0.1369, loss-lb:0.0702, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:07:10.949] iteration:18956  t-loss:0.1545, loss-lb:0.0772, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:07:11.141] iteration:18957  t-loss:0.1550, loss-lb:0.0782, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:07:11.334] iteration:18958  t-loss:0.1542, loss-lb:0.0858, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:07:11.526] iteration:18959  t-loss:0.1364, loss-lb:0.0710, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:07:11.719] iteration:18960  t-loss:0.1539, loss-lb:0.0716, loss-ulb:0.0412, weight:2.00, lr:0.0004
[12:07:11.912] iteration:18961  t-loss:0.1513, loss-lb:0.0792, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:07:12.104] iteration:18962  t-loss:0.1384, loss-lb:0.0705, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:07:12.296] iteration:18963  t-loss:0.2427, loss-lb:0.0813, loss-ulb:0.0807, weight:2.00, lr:0.0004
[12:07:12.490] iteration:18964  t-loss:0.1418, loss-lb:0.0794, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:07:12.681] iteration:18965  t-loss:0.1472, loss-lb:0.0770, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:07:12.873] iteration:18966  t-loss:0.1470, loss-lb:0.0881, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:07:13.066] iteration:18967  t-loss:0.1489, loss-lb:0.0737, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:07:13.258] iteration:18968  t-loss:0.1517, loss-lb:0.0714, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:07:13.450] iteration:18969  t-loss:0.1657, loss-lb:0.0672, loss-ulb:0.0492, weight:2.00, lr:0.0004
[12:07:13.642] iteration:18970  t-loss:0.1442, loss-lb:0.0816, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:07:13.835] iteration:18971  t-loss:0.1639, loss-lb:0.0812, loss-ulb:0.0413, weight:2.00, lr:0.0004
[12:07:14.030] iteration:18972  t-loss:0.1604, loss-lb:0.0811, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:07:14.221] iteration:18973  t-loss:0.1752, loss-lb:0.0805, loss-ulb:0.0474, weight:2.00, lr:0.0004
[12:07:14.414] iteration:18974  t-loss:0.1442, loss-lb:0.0728, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:07:14.606] iteration:18975  t-loss:0.2670, loss-lb:0.0758, loss-ulb:0.0956, weight:2.00, lr:0.0004
[12:07:14.798] iteration:18976  t-loss:0.1345, loss-lb:0.0764, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:07:14.991] iteration:18977  t-loss:0.1336, loss-lb:0.0783, loss-ulb:0.0277, weight:2.00, lr:0.0004
[12:07:15.183] iteration:18978  t-loss:0.1325, loss-lb:0.0718, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:07:15.374] iteration:18979  t-loss:0.1480, loss-lb:0.0831, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:07:15.567] iteration:18980  t-loss:0.1457, loss-lb:0.0745, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:07:15.760] iteration:18981  t-loss:0.1719, loss-lb:0.0790, loss-ulb:0.0464, weight:2.00, lr:0.0004
[12:07:15.951] iteration:18982  t-loss:0.1508, loss-lb:0.0892, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:07:16.144] iteration:18983  t-loss:0.1483, loss-lb:0.0792, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:07:16.336] iteration:18984  t-loss:0.1296, loss-lb:0.0709, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:07:16.528] iteration:18985  t-loss:0.1436, loss-lb:0.0803, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:07:16.720] iteration:18986  t-loss:0.1430, loss-lb:0.0786, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:07:16.913] iteration:18987  t-loss:0.1616, loss-lb:0.0941, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:07:17.104] iteration:18988  t-loss:0.1486, loss-lb:0.0856, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:07:17.296] iteration:18989  t-loss:0.1368, loss-lb:0.0744, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:07:17.489] iteration:18990  t-loss:0.1791, loss-lb:0.0778, loss-ulb:0.0506, weight:2.00, lr:0.0004
[12:07:17.683] iteration:18991  t-loss:0.2402, loss-lb:0.0835, loss-ulb:0.0783, weight:2.00, lr:0.0004
[12:07:17.875] iteration:18992  t-loss:0.1487, loss-lb:0.0848, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:07:18.067] iteration:18993  t-loss:0.1432, loss-lb:0.0729, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:07:18.260] iteration:18994  t-loss:0.1618, loss-lb:0.0812, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:07:18.452] iteration:18995  t-loss:0.1346, loss-lb:0.0717, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:07:18.645] iteration:18996  t-loss:0.1833, loss-lb:0.0831, loss-ulb:0.0501, weight:2.00, lr:0.0004
[12:07:18.838] iteration:18997  t-loss:0.1703, loss-lb:0.1002, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:07:19.031] iteration:18998  t-loss:0.1389, loss-lb:0.0767, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:07:19.223] iteration:18999  t-loss:0.1616, loss-lb:0.0754, loss-ulb:0.0431, weight:2.00, lr:0.0004
[12:07:19.416] iteration:19000  t-loss:0.1549, loss-lb:0.0784, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:07:19.608] iteration:19001  t-loss:0.1377, loss-lb:0.0775, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:07:19.800] iteration:19002  t-loss:0.1377, loss-lb:0.0737, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:07:19.992] iteration:19003  t-loss:0.1399, loss-lb:0.0781, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:07:20.186] iteration:19004  t-loss:0.1453, loss-lb:0.0717, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:07:20.378] iteration:19005  t-loss:0.1399, loss-lb:0.0719, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:07:20.569] iteration:19006  t-loss:0.1580, loss-lb:0.0751, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:07:20.759] iteration:19007  t-loss:0.1629, loss-lb:0.0761, loss-ulb:0.0434, weight:2.00, lr:0.0004
[12:07:20.950] iteration:19008  t-loss:0.1436, loss-lb:0.0776, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:07:21.140] iteration:19009  t-loss:0.1462, loss-lb:0.0796, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:07:21.331] iteration:19010  t-loss:0.1654, loss-lb:0.0843, loss-ulb:0.0406, weight:2.00, lr:0.0004
[12:07:21.522] iteration:19011  t-loss:0.2216, loss-lb:0.0813, loss-ulb:0.0701, weight:2.00, lr:0.0004
[12:07:21.713] iteration:19012  t-loss:0.1512, loss-lb:0.0774, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:07:22.304] iteration:19013  t-loss:0.1380, loss-lb:0.0775, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:07:22.501] iteration:19014  t-loss:0.1335, loss-lb:0.0731, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:07:22.694] iteration:19015  t-loss:0.1513, loss-lb:0.0763, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:07:22.884] iteration:19016  t-loss:0.1554, loss-lb:0.0843, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:07:23.077] iteration:19017  t-loss:0.1670, loss-lb:0.0808, loss-ulb:0.0431, weight:2.00, lr:0.0004
[12:07:23.271] iteration:19018  t-loss:0.1613, loss-lb:0.0849, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:07:23.467] iteration:19019  t-loss:0.1772, loss-lb:0.0898, loss-ulb:0.0437, weight:2.00, lr:0.0004
[12:07:23.660] iteration:19020  t-loss:0.2261, loss-lb:0.0777, loss-ulb:0.0742, weight:2.00, lr:0.0004
[12:07:23.854] iteration:19021  t-loss:0.1363, loss-lb:0.0715, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:07:24.047] iteration:19022  t-loss:0.1379, loss-lb:0.0734, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:07:24.242] iteration:19023  t-loss:0.1388, loss-lb:0.0736, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:07:24.434] iteration:19024  t-loss:0.1453, loss-lb:0.0775, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:07:24.625] iteration:19025  t-loss:0.1586, loss-lb:0.0715, loss-ulb:0.0436, weight:2.00, lr:0.0004
[12:07:24.817] iteration:19026  t-loss:0.2030, loss-lb:0.0817, loss-ulb:0.0606, weight:2.00, lr:0.0004
[12:07:25.009] iteration:19027  t-loss:0.1586, loss-lb:0.0843, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:07:25.202] iteration:19028  t-loss:0.1521, loss-lb:0.0737, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:07:25.394] iteration:19029  t-loss:0.1644, loss-lb:0.0896, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:07:25.586] iteration:19030  t-loss:0.1493, loss-lb:0.0813, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:07:25.779] iteration:19031  t-loss:0.1606, loss-lb:0.0865, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:07:25.970] iteration:19032  t-loss:0.1541, loss-lb:0.0785, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:07:26.163] iteration:19033  t-loss:0.1585, loss-lb:0.0722, loss-ulb:0.0431, weight:2.00, lr:0.0004
[12:07:26.354] iteration:19034  t-loss:0.1339, loss-lb:0.0753, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:07:26.546] iteration:19035  t-loss:0.1533, loss-lb:0.0809, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:07:26.738] iteration:19036  t-loss:0.1497, loss-lb:0.0765, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:07:26.929] iteration:19037  t-loss:0.1344, loss-lb:0.0723, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:07:27.122] iteration:19038  t-loss:0.1634, loss-lb:0.0833, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:07:27.313] iteration:19039  t-loss:0.1599, loss-lb:0.0885, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:07:27.505] iteration:19040  t-loss:0.1619, loss-lb:0.0774, loss-ulb:0.0423, weight:2.00, lr:0.0004
[12:07:27.698] iteration:19041  t-loss:0.1434, loss-lb:0.0749, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:07:27.889] iteration:19042  t-loss:0.1578, loss-lb:0.0738, loss-ulb:0.0420, weight:2.00, lr:0.0004
[12:07:28.081] iteration:19043  t-loss:0.1408, loss-lb:0.0773, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:07:28.272] iteration:19044  t-loss:0.1584, loss-lb:0.0805, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:07:28.465] iteration:19045  t-loss:0.1409, loss-lb:0.0724, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:07:28.658] iteration:19046  t-loss:0.1484, loss-lb:0.0705, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:07:28.849] iteration:19047  t-loss:0.1390, loss-lb:0.0771, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:07:29.042] iteration:19048  t-loss:0.1368, loss-lb:0.0826, loss-ulb:0.0271, weight:2.00, lr:0.0004
[12:07:29.234] iteration:19049  t-loss:0.1526, loss-lb:0.0772, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:07:29.425] iteration:19050  t-loss:0.1540, loss-lb:0.0767, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:07:29.618] iteration:19051  t-loss:0.1603, loss-lb:0.0793, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:07:29.809] iteration:19052  t-loss:0.1294, loss-lb:0.0694, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:07:30.000] iteration:19053  t-loss:0.1551, loss-lb:0.0730, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:07:30.192] iteration:19054  t-loss:0.1381, loss-lb:0.0761, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:07:30.384] iteration:19055  t-loss:0.1516, loss-lb:0.0805, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:07:30.576] iteration:19056  t-loss:0.1518, loss-lb:0.0750, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:07:30.769] iteration:19057  t-loss:0.1419, loss-lb:0.0760, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:07:30.961] iteration:19058  t-loss:0.1471, loss-lb:0.0738, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:07:31.152] iteration:19059  t-loss:0.1325, loss-lb:0.0729, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:07:31.348] iteration:19060  t-loss:0.1490, loss-lb:0.0766, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:07:31.541] iteration:19061  t-loss:0.1875, loss-lb:0.0735, loss-ulb:0.0570, weight:2.00, lr:0.0004
[12:07:31.732] iteration:19062  t-loss:0.1389, loss-lb:0.0748, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:07:31.924] iteration:19063  t-loss:0.1630, loss-lb:0.0790, loss-ulb:0.0420, weight:2.00, lr:0.0004
[12:07:32.115] iteration:19064  t-loss:0.1373, loss-lb:0.0714, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:07:32.306] iteration:19065  t-loss:0.1567, loss-lb:0.0784, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:07:32.498] iteration:19066  t-loss:0.1346, loss-lb:0.0738, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:07:32.689] iteration:19067  t-loss:0.1259, loss-lb:0.0688, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:07:32.881] iteration:19068  t-loss:0.1568, loss-lb:0.0815, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:07:33.073] iteration:19069  t-loss:0.1337, loss-lb:0.0783, loss-ulb:0.0277, weight:2.00, lr:0.0004
[12:07:33.264] iteration:19070  t-loss:0.1442, loss-lb:0.0767, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:07:33.457] iteration:19071  t-loss:0.1391, loss-lb:0.0742, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:07:33.647] iteration:19072  t-loss:0.1412, loss-lb:0.0689, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:07:33.840] iteration:19073  t-loss:0.1394, loss-lb:0.0778, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:07:34.033] iteration:19074  t-loss:0.1447, loss-lb:0.0809, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:07:34.227] iteration:19075  t-loss:0.1893, loss-lb:0.0991, loss-ulb:0.0451, weight:2.00, lr:0.0004
[12:07:34.425] iteration:19076  t-loss:0.1435, loss-lb:0.0807, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:07:34.620] iteration:19077  t-loss:0.1441, loss-lb:0.0810, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:07:34.816] iteration:19078  t-loss:0.1466, loss-lb:0.0782, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:07:35.008] iteration:19079  t-loss:0.1660, loss-lb:0.0788, loss-ulb:0.0436, weight:2.00, lr:0.0004
[12:07:35.200] iteration:19080  t-loss:0.1547, loss-lb:0.0795, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:07:35.393] iteration:19081  t-loss:0.1470, loss-lb:0.0745, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:07:35.585] iteration:19082  t-loss:0.1514, loss-lb:0.0781, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:07:35.777] iteration:19083  t-loss:0.1408, loss-lb:0.0737, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:07:35.970] iteration:19084  t-loss:0.1291, loss-lb:0.0733, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:07:36.161] iteration:19085  t-loss:0.1493, loss-lb:0.0881, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:07:36.354] iteration:19086  t-loss:0.1391, loss-lb:0.0747, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:07:36.546] iteration:19087  t-loss:0.2246, loss-lb:0.0790, loss-ulb:0.0728, weight:2.00, lr:0.0004
[12:07:36.739] iteration:19088  t-loss:0.1507, loss-lb:0.0947, loss-ulb:0.0280, weight:2.00, lr:0.0004
[12:07:36.931] iteration:19089  t-loss:0.2072, loss-lb:0.0807, loss-ulb:0.0633, weight:2.00, lr:0.0004
[12:07:37.123] iteration:19090  t-loss:0.1481, loss-lb:0.0827, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:07:37.316] iteration:19091  t-loss:0.1392, loss-lb:0.0793, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:07:37.507] iteration:19092  t-loss:0.1598, loss-lb:0.0752, loss-ulb:0.0423, weight:2.00, lr:0.0004
[12:07:37.700] iteration:19093  t-loss:0.1526, loss-lb:0.0781, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:07:37.899] iteration:19094  t-loss:0.1523, loss-lb:0.0912, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:07:38.100] iteration:19095  t-loss:0.1363, loss-lb:0.0732, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:07:38.298] iteration:19096  t-loss:0.1370, loss-lb:0.0766, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:07:38.489] iteration:19097  t-loss:0.1441, loss-lb:0.0809, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:07:38.681] iteration:19098  t-loss:0.1296, loss-lb:0.0663, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:07:38.874] iteration:19099  t-loss:0.1323, loss-lb:0.0788, loss-ulb:0.0267, weight:2.00, lr:0.0004
[12:07:39.066] iteration:19100  t-loss:0.1361, loss-lb:0.0698, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:07:39.259] iteration:19101  t-loss:0.1549, loss-lb:0.0818, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:07:39.451] iteration:19102  t-loss:0.1722, loss-lb:0.0834, loss-ulb:0.0444, weight:2.00, lr:0.0004
[12:07:39.643] iteration:19103  t-loss:0.1514, loss-lb:0.0822, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:07:39.833] iteration:19104  t-loss:0.1391, loss-lb:0.0725, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:07:40.025] iteration:19105  t-loss:0.1425, loss-lb:0.0784, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:07:40.216] iteration:19106  t-loss:0.1463, loss-lb:0.0752, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:07:40.408] iteration:19107  t-loss:0.2098, loss-lb:0.0805, loss-ulb:0.0647, weight:2.00, lr:0.0004
[12:07:40.599] iteration:19108  t-loss:0.1457, loss-lb:0.0775, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:07:40.791] iteration:19109  t-loss:0.1448, loss-lb:0.0737, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:07:40.982] iteration:19110  t-loss:0.1431, loss-lb:0.0779, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:07:53.988]  <<Test>> - Ep:194  - mean_dice/mean_h95 - S:89.79/1.36, Best-S:90.99, T:89.82/1.35, Best-T:90.48
[12:07:53.989]           - AvgLoss(lb/ulb/all):0.0779/0.0354/0.1485
[12:07:54.520] iteration:19111  t-loss:0.1445, loss-lb:0.0822, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:07:54.716] iteration:19112  t-loss:0.1382, loss-lb:0.0733, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:07:54.908] iteration:19113  t-loss:0.1421, loss-lb:0.0713, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:07:55.100] iteration:19114  t-loss:0.3217, loss-lb:0.0805, loss-ulb:0.1206, weight:2.00, lr:0.0004
[12:07:55.291] iteration:19115  t-loss:0.1427, loss-lb:0.0871, loss-ulb:0.0278, weight:2.00, lr:0.0004
[12:07:55.482] iteration:19116  t-loss:0.1541, loss-lb:0.0773, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:07:55.674] iteration:19117  t-loss:0.2664, loss-lb:0.0710, loss-ulb:0.0977, weight:2.00, lr:0.0004
[12:07:55.867] iteration:19118  t-loss:0.1402, loss-lb:0.0686, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:07:56.059] iteration:19119  t-loss:0.1357, loss-lb:0.0771, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:07:56.253] iteration:19120  t-loss:0.1477, loss-lb:0.0705, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:07:56.445] iteration:19121  t-loss:0.1986, loss-lb:0.0818, loss-ulb:0.0584, weight:2.00, lr:0.0004
[12:07:56.640] iteration:19122  t-loss:0.1754, loss-lb:0.0782, loss-ulb:0.0486, weight:2.00, lr:0.0004
[12:07:56.834] iteration:19123  t-loss:0.1800, loss-lb:0.0809, loss-ulb:0.0496, weight:2.00, lr:0.0004
[12:07:57.025] iteration:19124  t-loss:0.1428, loss-lb:0.0763, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:07:57.216] iteration:19125  t-loss:0.1411, loss-lb:0.0777, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:07:57.408] iteration:19126  t-loss:0.1610, loss-lb:0.0849, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:07:57.600] iteration:19127  t-loss:0.2210, loss-lb:0.0845, loss-ulb:0.0682, weight:2.00, lr:0.0004
[12:07:57.791] iteration:19128  t-loss:0.1524, loss-lb:0.0775, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:07:57.984] iteration:19129  t-loss:0.2222, loss-lb:0.0794, loss-ulb:0.0714, weight:2.00, lr:0.0004
[12:07:58.175] iteration:19130  t-loss:0.1491, loss-lb:0.0752, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:07:58.366] iteration:19131  t-loss:0.1482, loss-lb:0.0793, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:07:58.558] iteration:19132  t-loss:0.1557, loss-lb:0.0870, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:07:58.751] iteration:19133  t-loss:0.1397, loss-lb:0.0792, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:07:58.943] iteration:19134  t-loss:0.1411, loss-lb:0.0841, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:07:59.135] iteration:19135  t-loss:0.1821, loss-lb:0.0998, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:07:59.326] iteration:19136  t-loss:0.1513, loss-lb:0.0756, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:07:59.518] iteration:19137  t-loss:0.1425, loss-lb:0.0720, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:07:59.709] iteration:19138  t-loss:0.1470, loss-lb:0.0777, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:07:59.900] iteration:19139  t-loss:0.1463, loss-lb:0.0828, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:08:00.093] iteration:19140  t-loss:0.1595, loss-lb:0.0843, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:08:00.284] iteration:19141  t-loss:0.1559, loss-lb:0.0726, loss-ulb:0.0417, weight:2.00, lr:0.0004
[12:08:00.477] iteration:19142  t-loss:0.1409, loss-lb:0.0792, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:08:00.670] iteration:19143  t-loss:0.2217, loss-lb:0.0705, loss-ulb:0.0756, weight:2.00, lr:0.0004
[12:08:00.862] iteration:19144  t-loss:0.1541, loss-lb:0.0920, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:08:01.053] iteration:19145  t-loss:0.1478, loss-lb:0.0746, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:08:01.245] iteration:19146  t-loss:0.1463, loss-lb:0.0829, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:08:01.437] iteration:19147  t-loss:0.1424, loss-lb:0.0834, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:08:01.629] iteration:19148  t-loss:0.1568, loss-lb:0.0833, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:08:01.821] iteration:19149  t-loss:0.1524, loss-lb:0.0878, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:08:02.012] iteration:19150  t-loss:0.1514, loss-lb:0.0797, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:08:02.204] iteration:19151  t-loss:0.1562, loss-lb:0.0718, loss-ulb:0.0422, weight:2.00, lr:0.0004
[12:08:02.396] iteration:19152  t-loss:0.1579, loss-lb:0.0914, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:08:02.588] iteration:19153  t-loss:0.1445, loss-lb:0.0792, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:08:02.780] iteration:19154  t-loss:0.1429, loss-lb:0.0755, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:08:02.972] iteration:19155  t-loss:0.1406, loss-lb:0.0729, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:08:03.164] iteration:19156  t-loss:0.1516, loss-lb:0.0799, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:08:03.357] iteration:19157  t-loss:0.1493, loss-lb:0.0773, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:08:03.549] iteration:19158  t-loss:0.1639, loss-lb:0.0757, loss-ulb:0.0441, weight:2.00, lr:0.0004
[12:08:03.740] iteration:19159  t-loss:0.1517, loss-lb:0.0788, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:08:03.933] iteration:19160  t-loss:0.1503, loss-lb:0.0809, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:08:04.124] iteration:19161  t-loss:0.1373, loss-lb:0.0749, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:08:04.317] iteration:19162  t-loss:0.1471, loss-lb:0.0787, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:08:04.509] iteration:19163  t-loss:0.1524, loss-lb:0.0771, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:08:04.700] iteration:19164  t-loss:0.1525, loss-lb:0.0824, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:08:04.892] iteration:19165  t-loss:0.2362, loss-lb:0.0780, loss-ulb:0.0791, weight:2.00, lr:0.0004
[12:08:05.083] iteration:19166  t-loss:0.1496, loss-lb:0.0833, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:08:05.274] iteration:19167  t-loss:0.1579, loss-lb:0.0881, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:08:05.466] iteration:19168  t-loss:0.1321, loss-lb:0.0765, loss-ulb:0.0278, weight:2.00, lr:0.0004
[12:08:05.658] iteration:19169  t-loss:0.1519, loss-lb:0.0784, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:08:05.849] iteration:19170  t-loss:0.1440, loss-lb:0.0755, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:08:06.040] iteration:19171  t-loss:0.1355, loss-lb:0.0780, loss-ulb:0.0288, weight:2.00, lr:0.0004
[12:08:06.232] iteration:19172  t-loss:0.1361, loss-lb:0.0694, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:08:06.424] iteration:19173  t-loss:0.1392, loss-lb:0.0744, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:08:06.616] iteration:19174  t-loss:0.1266, loss-lb:0.0704, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:08:06.809] iteration:19175  t-loss:0.1465, loss-lb:0.0848, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:08:07.001] iteration:19176  t-loss:0.1346, loss-lb:0.0760, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:08:07.194] iteration:19177  t-loss:0.1470, loss-lb:0.0831, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:08:07.386] iteration:19178  t-loss:0.1567, loss-lb:0.0763, loss-ulb:0.0402, weight:2.00, lr:0.0004
[12:08:07.578] iteration:19179  t-loss:0.1361, loss-lb:0.0827, loss-ulb:0.0267, weight:2.00, lr:0.0004
[12:08:07.771] iteration:19180  t-loss:0.1456, loss-lb:0.0823, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:08:07.965] iteration:19181  t-loss:0.1963, loss-lb:0.0843, loss-ulb:0.0560, weight:2.00, lr:0.0004
[12:08:08.157] iteration:19182  t-loss:0.1467, loss-lb:0.0776, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:08:08.349] iteration:19183  t-loss:0.1570, loss-lb:0.0776, loss-ulb:0.0397, weight:2.00, lr:0.0004
[12:08:08.543] iteration:19184  t-loss:0.1524, loss-lb:0.0793, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:08:08.737] iteration:19185  t-loss:0.1383, loss-lb:0.0726, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:08:08.929] iteration:19186  t-loss:0.1359, loss-lb:0.0816, loss-ulb:0.0272, weight:2.00, lr:0.0004
[12:08:09.121] iteration:19187  t-loss:0.1310, loss-lb:0.0692, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:08:09.314] iteration:19188  t-loss:0.1397, loss-lb:0.0739, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:08:09.506] iteration:19189  t-loss:0.1447, loss-lb:0.0824, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:08:09.699] iteration:19190  t-loss:0.1483, loss-lb:0.0811, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:08:09.891] iteration:19191  t-loss:0.1382, loss-lb:0.0751, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:08:10.083] iteration:19192  t-loss:0.1563, loss-lb:0.0914, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:08:10.276] iteration:19193  t-loss:0.1470, loss-lb:0.0755, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:08:10.469] iteration:19194  t-loss:0.1430, loss-lb:0.0721, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:08:10.669] iteration:19195  t-loss:0.1410, loss-lb:0.0769, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:08:10.871] iteration:19196  t-loss:0.1349, loss-lb:0.0757, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:08:11.068] iteration:19197  t-loss:0.1328, loss-lb:0.0813, loss-ulb:0.0257, weight:2.00, lr:0.0004
[12:08:11.261] iteration:19198  t-loss:0.1319, loss-lb:0.0723, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:08:11.452] iteration:19199  t-loss:0.1402, loss-lb:0.0787, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:08:11.645] iteration:19200  t-loss:0.1338, loss-lb:0.0772, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:08:11.837] iteration:19201  t-loss:0.1721, loss-lb:0.0792, loss-ulb:0.0464, weight:2.00, lr:0.0004
[12:08:12.028] iteration:19202  t-loss:0.1488, loss-lb:0.0828, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:08:12.219] iteration:19203  t-loss:0.1469, loss-lb:0.0750, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:08:12.410] iteration:19204  t-loss:0.1606, loss-lb:0.0773, loss-ulb:0.0417, weight:2.00, lr:0.0004
[12:08:12.601] iteration:19205  t-loss:0.1620, loss-lb:0.0774, loss-ulb:0.0423, weight:2.00, lr:0.0004
[12:08:12.793] iteration:19206  t-loss:0.2045, loss-lb:0.0743, loss-ulb:0.0651, weight:2.00, lr:0.0004
[12:08:12.984] iteration:19207  t-loss:0.1497, loss-lb:0.0864, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:08:13.174] iteration:19208  t-loss:0.1494, loss-lb:0.0748, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:08:13.757] iteration:19209  t-loss:0.1517, loss-lb:0.0790, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:08:13.952] iteration:19210  t-loss:0.1416, loss-lb:0.0757, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:08:14.145] iteration:19211  t-loss:0.1429, loss-lb:0.0776, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:08:14.337] iteration:19212  t-loss:0.1432, loss-lb:0.0784, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:08:14.530] iteration:19213  t-loss:0.1688, loss-lb:0.0869, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:08:14.723] iteration:19214  t-loss:0.1570, loss-lb:0.0757, loss-ulb:0.0407, weight:2.00, lr:0.0004
[12:08:14.915] iteration:19215  t-loss:0.1368, loss-lb:0.0752, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:08:15.107] iteration:19216  t-loss:0.1326, loss-lb:0.0701, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:08:15.301] iteration:19217  t-loss:0.1324, loss-lb:0.0756, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:08:15.494] iteration:19218  t-loss:0.1637, loss-lb:0.0755, loss-ulb:0.0441, weight:2.00, lr:0.0004
[12:08:15.686] iteration:19219  t-loss:0.1384, loss-lb:0.0853, loss-ulb:0.0265, weight:2.00, lr:0.0004
[12:08:15.878] iteration:19220  t-loss:0.1308, loss-lb:0.0750, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:08:16.072] iteration:19221  t-loss:0.1355, loss-lb:0.0714, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:08:16.266] iteration:19222  t-loss:0.2026, loss-lb:0.0761, loss-ulb:0.0632, weight:2.00, lr:0.0004
[12:08:16.459] iteration:19223  t-loss:0.1491, loss-lb:0.0756, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:08:16.651] iteration:19224  t-loss:0.1744, loss-lb:0.0727, loss-ulb:0.0509, weight:2.00, lr:0.0004
[12:08:16.844] iteration:19225  t-loss:0.1710, loss-lb:0.0772, loss-ulb:0.0469, weight:2.00, lr:0.0004
[12:08:17.037] iteration:19226  t-loss:0.1630, loss-lb:0.0910, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:08:17.229] iteration:19227  t-loss:0.1377, loss-lb:0.0697, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:08:17.421] iteration:19228  t-loss:0.1367, loss-lb:0.0771, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:08:17.614] iteration:19229  t-loss:0.2035, loss-lb:0.0842, loss-ulb:0.0596, weight:2.00, lr:0.0004
[12:08:17.805] iteration:19230  t-loss:0.1455, loss-lb:0.0863, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:08:17.997] iteration:19231  t-loss:0.1509, loss-lb:0.0765, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:08:18.190] iteration:19232  t-loss:0.1471, loss-lb:0.0760, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:08:18.382] iteration:19233  t-loss:0.1424, loss-lb:0.0756, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:08:18.575] iteration:19234  t-loss:0.1427, loss-lb:0.0839, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:08:18.768] iteration:19235  t-loss:0.1426, loss-lb:0.0738, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:08:18.960] iteration:19236  t-loss:0.1558, loss-lb:0.0806, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:08:19.153] iteration:19237  t-loss:0.1417, loss-lb:0.0795, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:08:19.345] iteration:19238  t-loss:0.1484, loss-lb:0.0747, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:08:19.538] iteration:19239  t-loss:0.1434, loss-lb:0.0717, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:08:19.731] iteration:19240  t-loss:0.1441, loss-lb:0.0811, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:08:19.924] iteration:19241  t-loss:0.1546, loss-lb:0.0728, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:08:20.116] iteration:19242  t-loss:0.1464, loss-lb:0.0781, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:08:20.310] iteration:19243  t-loss:0.1947, loss-lb:0.0789, loss-ulb:0.0579, weight:2.00, lr:0.0004
[12:08:20.504] iteration:19244  t-loss:0.2101, loss-lb:0.0804, loss-ulb:0.0649, weight:2.00, lr:0.0004
[12:08:20.698] iteration:19245  t-loss:0.2031, loss-lb:0.0928, loss-ulb:0.0552, weight:2.00, lr:0.0004
[12:08:20.891] iteration:19246  t-loss:0.1375, loss-lb:0.0732, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:08:21.084] iteration:19247  t-loss:0.1976, loss-lb:0.0785, loss-ulb:0.0596, weight:2.00, lr:0.0004
[12:08:21.277] iteration:19248  t-loss:0.1462, loss-lb:0.0792, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:08:21.470] iteration:19249  t-loss:0.1591, loss-lb:0.0689, loss-ulb:0.0451, weight:2.00, lr:0.0004
[12:08:21.662] iteration:19250  t-loss:0.1465, loss-lb:0.0784, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:08:21.855] iteration:19251  t-loss:0.1504, loss-lb:0.0874, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:08:22.049] iteration:19252  t-loss:0.1447, loss-lb:0.0702, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:08:22.243] iteration:19253  t-loss:0.2056, loss-lb:0.0742, loss-ulb:0.0657, weight:2.00, lr:0.0004
[12:08:22.436] iteration:19254  t-loss:0.1504, loss-lb:0.0815, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:08:22.628] iteration:19255  t-loss:0.1452, loss-lb:0.0746, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:08:22.822] iteration:19256  t-loss:0.1304, loss-lb:0.0672, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:08:23.016] iteration:19257  t-loss:0.1461, loss-lb:0.0836, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:08:23.208] iteration:19258  t-loss:0.1443, loss-lb:0.0815, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:08:23.401] iteration:19259  t-loss:0.1402, loss-lb:0.0722, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:08:23.593] iteration:19260  t-loss:0.1475, loss-lb:0.0759, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:08:23.786] iteration:19261  t-loss:0.2064, loss-lb:0.0809, loss-ulb:0.0627, weight:2.00, lr:0.0004
[12:08:23.979] iteration:19262  t-loss:0.1519, loss-lb:0.0770, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:08:24.173] iteration:19263  t-loss:0.1300, loss-lb:0.0774, loss-ulb:0.0263, weight:2.00, lr:0.0004
[12:08:24.366] iteration:19264  t-loss:0.1453, loss-lb:0.0817, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:08:24.558] iteration:19265  t-loss:0.1402, loss-lb:0.0803, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:08:24.754] iteration:19266  t-loss:0.1373, loss-lb:0.0787, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:08:24.946] iteration:19267  t-loss:0.1440, loss-lb:0.0713, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:08:25.140] iteration:19268  t-loss:0.1423, loss-lb:0.0758, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:08:25.332] iteration:19269  t-loss:0.1406, loss-lb:0.0750, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:08:25.526] iteration:19270  t-loss:0.1948, loss-lb:0.0749, loss-ulb:0.0599, weight:2.00, lr:0.0004
[12:08:25.719] iteration:19271  t-loss:0.1392, loss-lb:0.0784, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:08:25.912] iteration:19272  t-loss:0.1393, loss-lb:0.0848, loss-ulb:0.0273, weight:2.00, lr:0.0004
[12:08:26.104] iteration:19273  t-loss:0.1376, loss-lb:0.0775, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:08:26.297] iteration:19274  t-loss:0.1379, loss-lb:0.0751, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:08:26.489] iteration:19275  t-loss:0.1379, loss-lb:0.0775, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:08:26.681] iteration:19276  t-loss:0.1329, loss-lb:0.0735, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:08:26.873] iteration:19277  t-loss:0.1615, loss-lb:0.0772, loss-ulb:0.0421, weight:2.00, lr:0.0004
[12:08:27.066] iteration:19278  t-loss:0.2110, loss-lb:0.0762, loss-ulb:0.0674, weight:2.00, lr:0.0004
[12:08:27.259] iteration:19279  t-loss:0.1390, loss-lb:0.0767, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:08:27.452] iteration:19280  t-loss:0.1529, loss-lb:0.0883, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:08:27.646] iteration:19281  t-loss:0.2214, loss-lb:0.0782, loss-ulb:0.0716, weight:2.00, lr:0.0004
[12:08:27.839] iteration:19282  t-loss:0.1450, loss-lb:0.0718, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:08:28.033] iteration:19283  t-loss:0.1456, loss-lb:0.0776, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:08:28.224] iteration:19284  t-loss:0.1417, loss-lb:0.0798, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:08:28.417] iteration:19285  t-loss:0.1391, loss-lb:0.0777, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:08:28.610] iteration:19286  t-loss:0.1368, loss-lb:0.0738, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:08:28.804] iteration:19287  t-loss:0.1434, loss-lb:0.0766, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:08:28.997] iteration:19288  t-loss:0.1433, loss-lb:0.0743, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:08:29.189] iteration:19289  t-loss:0.1413, loss-lb:0.0765, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:08:29.382] iteration:19290  t-loss:0.1608, loss-lb:0.0899, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:08:29.575] iteration:19291  t-loss:0.1546, loss-lb:0.0732, loss-ulb:0.0407, weight:2.00, lr:0.0004
[12:08:29.768] iteration:19292  t-loss:0.1402, loss-lb:0.0737, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:08:29.961] iteration:19293  t-loss:0.2116, loss-lb:0.0780, loss-ulb:0.0668, weight:2.00, lr:0.0004
[12:08:30.154] iteration:19294  t-loss:0.1477, loss-lb:0.0910, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:08:30.347] iteration:19295  t-loss:0.1453, loss-lb:0.0761, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:08:30.540] iteration:19296  t-loss:0.1484, loss-lb:0.0764, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:08:30.732] iteration:19297  t-loss:0.1443, loss-lb:0.0753, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:08:30.926] iteration:19298  t-loss:0.2114, loss-lb:0.0811, loss-ulb:0.0651, weight:2.00, lr:0.0004
[12:08:31.117] iteration:19299  t-loss:0.1549, loss-lb:0.0840, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:08:31.309] iteration:19300  t-loss:0.1504, loss-lb:0.0802, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:08:31.499] iteration:19301  t-loss:0.1511, loss-lb:0.0750, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:08:31.690] iteration:19302  t-loss:0.1506, loss-lb:0.0832, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:08:31.880] iteration:19303  t-loss:0.1370, loss-lb:0.0742, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:08:32.070] iteration:19304  t-loss:0.1397, loss-lb:0.0791, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:08:32.261] iteration:19305  t-loss:0.1401, loss-lb:0.0743, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:08:32.451] iteration:19306  t-loss:0.1567, loss-lb:0.0830, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:08:44.672]  <<Test>> - Ep:196  - mean_dice/mean_h95 - S:89.73/1.37, Best-S:90.99, T:89.74/1.40, Best-T:90.48
[12:08:44.673]           - AvgLoss(lb/ulb/all):0.0778/0.0375/0.1536
[12:08:45.221] iteration:19307  t-loss:0.1712, loss-lb:0.0840, loss-ulb:0.0436, weight:2.00, lr:0.0004
[12:08:45.415] iteration:19308  t-loss:0.1488, loss-lb:0.0817, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:08:45.607] iteration:19309  t-loss:0.1440, loss-lb:0.0752, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:08:45.799] iteration:19310  t-loss:0.1680, loss-lb:0.0826, loss-ulb:0.0427, weight:2.00, lr:0.0004
[12:08:45.991] iteration:19311  t-loss:0.1436, loss-lb:0.0804, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:08:46.183] iteration:19312  t-loss:0.1385, loss-lb:0.0764, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:08:46.375] iteration:19313  t-loss:0.1382, loss-lb:0.0797, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:08:46.567] iteration:19314  t-loss:0.1450, loss-lb:0.0730, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:08:46.760] iteration:19315  t-loss:0.1799, loss-lb:0.0829, loss-ulb:0.0485, weight:2.00, lr:0.0004
[12:08:46.952] iteration:19316  t-loss:0.1413, loss-lb:0.0824, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:08:47.145] iteration:19317  t-loss:0.2418, loss-lb:0.0774, loss-ulb:0.0822, weight:2.00, lr:0.0004
[12:08:47.337] iteration:19318  t-loss:0.1412, loss-lb:0.0784, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:08:47.529] iteration:19319  t-loss:0.1438, loss-lb:0.0777, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:08:47.722] iteration:19320  t-loss:0.1753, loss-lb:0.0785, loss-ulb:0.0484, weight:2.00, lr:0.0004
[12:08:47.913] iteration:19321  t-loss:0.1456, loss-lb:0.0815, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:08:48.106] iteration:19322  t-loss:0.1477, loss-lb:0.0812, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:08:48.298] iteration:19323  t-loss:0.1640, loss-lb:0.0896, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:08:48.489] iteration:19324  t-loss:0.1432, loss-lb:0.0790, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:08:48.681] iteration:19325  t-loss:0.1579, loss-lb:0.0880, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:08:48.872] iteration:19326  t-loss:0.1668, loss-lb:0.0814, loss-ulb:0.0427, weight:2.00, lr:0.0004
[12:08:49.065] iteration:19327  t-loss:0.1426, loss-lb:0.0758, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:08:49.259] iteration:19328  t-loss:0.2279, loss-lb:0.0892, loss-ulb:0.0694, weight:2.00, lr:0.0004
[12:08:49.451] iteration:19329  t-loss:0.1589, loss-lb:0.0816, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:08:49.643] iteration:19330  t-loss:0.1482, loss-lb:0.0728, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:08:49.835] iteration:19331  t-loss:0.1383, loss-lb:0.0720, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:08:50.027] iteration:19332  t-loss:0.1473, loss-lb:0.0823, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:08:50.219] iteration:19333  t-loss:0.1533, loss-lb:0.0873, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:08:50.412] iteration:19334  t-loss:0.1669, loss-lb:0.0806, loss-ulb:0.0432, weight:2.00, lr:0.0004
[12:08:50.604] iteration:19335  t-loss:0.1498, loss-lb:0.0829, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:08:50.796] iteration:19336  t-loss:0.1413, loss-lb:0.0754, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:08:50.987] iteration:19337  t-loss:0.1482, loss-lb:0.0807, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:08:51.179] iteration:19338  t-loss:0.1574, loss-lb:0.0749, loss-ulb:0.0413, weight:2.00, lr:0.0004
[12:08:51.371] iteration:19339  t-loss:0.1399, loss-lb:0.0750, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:08:51.563] iteration:19340  t-loss:0.1358, loss-lb:0.0776, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:08:51.756] iteration:19341  t-loss:0.2082, loss-lb:0.0723, loss-ulb:0.0680, weight:2.00, lr:0.0004
[12:08:51.949] iteration:19342  t-loss:0.1972, loss-lb:0.0776, loss-ulb:0.0598, weight:2.00, lr:0.0004
[12:08:52.142] iteration:19343  t-loss:0.1425, loss-lb:0.0766, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:08:52.334] iteration:19344  t-loss:0.1445, loss-lb:0.0797, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:08:52.527] iteration:19345  t-loss:0.1579, loss-lb:0.0758, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:08:52.719] iteration:19346  t-loss:0.1650, loss-lb:0.0839, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:08:52.912] iteration:19347  t-loss:0.1564, loss-lb:0.0734, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:08:53.104] iteration:19348  t-loss:0.1655, loss-lb:0.0978, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:08:53.297] iteration:19349  t-loss:0.1429, loss-lb:0.0711, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:08:53.492] iteration:19350  t-loss:0.1755, loss-lb:0.0804, loss-ulb:0.0476, weight:2.00, lr:0.0004
[12:08:53.685] iteration:19351  t-loss:0.1545, loss-lb:0.0743, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:08:53.878] iteration:19352  t-loss:0.1472, loss-lb:0.0801, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:08:54.069] iteration:19353  t-loss:0.1434, loss-lb:0.0777, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:08:54.263] iteration:19354  t-loss:0.1487, loss-lb:0.0710, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:08:54.456] iteration:19355  t-loss:0.1551, loss-lb:0.0845, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:08:54.648] iteration:19356  t-loss:0.1305, loss-lb:0.0704, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:08:54.841] iteration:19357  t-loss:0.2088, loss-lb:0.0752, loss-ulb:0.0668, weight:2.00, lr:0.0004
[12:08:55.034] iteration:19358  t-loss:0.1618, loss-lb:0.0825, loss-ulb:0.0397, weight:2.00, lr:0.0004
[12:08:55.225] iteration:19359  t-loss:0.1483, loss-lb:0.0780, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:08:55.418] iteration:19360  t-loss:0.1457, loss-lb:0.0743, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:08:55.610] iteration:19361  t-loss:0.1531, loss-lb:0.0782, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:08:55.803] iteration:19362  t-loss:0.1611, loss-lb:0.0886, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:08:55.995] iteration:19363  t-loss:0.1519, loss-lb:0.0794, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:08:56.187] iteration:19364  t-loss:0.1343, loss-lb:0.0727, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:08:56.378] iteration:19365  t-loss:0.1519, loss-lb:0.0789, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:08:56.571] iteration:19366  t-loss:0.1631, loss-lb:0.0905, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:08:56.767] iteration:19367  t-loss:0.1418, loss-lb:0.0687, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:08:56.962] iteration:19368  t-loss:0.1705, loss-lb:0.0733, loss-ulb:0.0486, weight:2.00, lr:0.0004
[12:08:57.158] iteration:19369  t-loss:0.2679, loss-lb:0.0725, loss-ulb:0.0977, weight:2.00, lr:0.0004
[12:08:57.352] iteration:19370  t-loss:0.1414, loss-lb:0.0772, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:08:57.545] iteration:19371  t-loss:0.1457, loss-lb:0.0796, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:08:57.737] iteration:19372  t-loss:0.1419, loss-lb:0.0815, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:08:57.929] iteration:19373  t-loss:0.1498, loss-lb:0.0867, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:08:58.120] iteration:19374  t-loss:0.1506, loss-lb:0.0785, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:08:58.312] iteration:19375  t-loss:0.1470, loss-lb:0.0768, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:08:58.504] iteration:19376  t-loss:0.1375, loss-lb:0.0735, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:08:58.697] iteration:19377  t-loss:0.1768, loss-lb:0.0821, loss-ulb:0.0474, weight:2.00, lr:0.0004
[12:08:58.889] iteration:19378  t-loss:0.1575, loss-lb:0.0864, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:08:59.081] iteration:19379  t-loss:0.1430, loss-lb:0.0722, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:08:59.273] iteration:19380  t-loss:0.1628, loss-lb:0.0827, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:08:59.465] iteration:19381  t-loss:0.1717, loss-lb:0.0823, loss-ulb:0.0447, weight:2.00, lr:0.0004
[12:08:59.659] iteration:19382  t-loss:0.2012, loss-lb:0.0755, loss-ulb:0.0629, weight:2.00, lr:0.0004
[12:08:59.850] iteration:19383  t-loss:0.1435, loss-lb:0.0763, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:09:00.042] iteration:19384  t-loss:0.1596, loss-lb:0.0775, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:09:00.233] iteration:19385  t-loss:0.1342, loss-lb:0.0774, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:09:00.425] iteration:19386  t-loss:0.1366, loss-lb:0.0783, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:09:00.617] iteration:19387  t-loss:0.1503, loss-lb:0.0730, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:09:00.809] iteration:19388  t-loss:0.1521, loss-lb:0.0872, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:09:01.002] iteration:19389  t-loss:0.2401, loss-lb:0.0732, loss-ulb:0.0835, weight:2.00, lr:0.0004
[12:09:01.194] iteration:19390  t-loss:0.1433, loss-lb:0.0768, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:09:01.393] iteration:19391  t-loss:0.1330, loss-lb:0.0733, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:09:01.585] iteration:19392  t-loss:0.1372, loss-lb:0.0717, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:09:01.778] iteration:19393  t-loss:0.1613, loss-lb:0.0867, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:09:01.970] iteration:19394  t-loss:0.1385, loss-lb:0.0762, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:09:02.168] iteration:19395  t-loss:0.1428, loss-lb:0.0763, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:09:02.360] iteration:19396  t-loss:0.1490, loss-lb:0.0790, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:09:02.552] iteration:19397  t-loss:0.1431, loss-lb:0.0766, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:09:02.742] iteration:19398  t-loss:0.1740, loss-lb:0.0782, loss-ulb:0.0479, weight:2.00, lr:0.0004
[12:09:02.934] iteration:19399  t-loss:0.1356, loss-lb:0.0792, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:09:03.125] iteration:19400  t-loss:0.1409, loss-lb:0.0825, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:09:03.316] iteration:19401  t-loss:0.1426, loss-lb:0.0741, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:09:03.506] iteration:19402  t-loss:0.1396, loss-lb:0.0810, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:09:03.697] iteration:19403  t-loss:0.1367, loss-lb:0.0693, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:09:03.887] iteration:19404  t-loss:0.1485, loss-lb:0.0814, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:09:04.485] iteration:19405  t-loss:0.1432, loss-lb:0.0761, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:09:04.679] iteration:19406  t-loss:0.1518, loss-lb:0.0887, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:09:04.871] iteration:19407  t-loss:0.1524, loss-lb:0.0873, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:09:05.063] iteration:19408  t-loss:0.1481, loss-lb:0.0791, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:09:05.255] iteration:19409  t-loss:0.1573, loss-lb:0.0801, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:09:05.448] iteration:19410  t-loss:0.1421, loss-lb:0.0777, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:09:05.639] iteration:19411  t-loss:0.1457, loss-lb:0.0704, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:09:05.832] iteration:19412  t-loss:0.1585, loss-lb:0.0743, loss-ulb:0.0421, weight:2.00, lr:0.0004
[12:09:06.023] iteration:19413  t-loss:0.1349, loss-lb:0.0809, loss-ulb:0.0270, weight:2.00, lr:0.0004
[12:09:06.215] iteration:19414  t-loss:0.1464, loss-lb:0.0727, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:09:06.408] iteration:19415  t-loss:0.2051, loss-lb:0.0751, loss-ulb:0.0650, weight:2.00, lr:0.0004
[12:09:06.600] iteration:19416  t-loss:0.1495, loss-lb:0.0786, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:09:06.792] iteration:19417  t-loss:0.1270, loss-lb:0.0752, loss-ulb:0.0259, weight:2.00, lr:0.0004
[12:09:06.984] iteration:19418  t-loss:0.1603, loss-lb:0.0848, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:09:07.175] iteration:19419  t-loss:0.1752, loss-lb:0.0778, loss-ulb:0.0487, weight:2.00, lr:0.0004
[12:09:07.368] iteration:19420  t-loss:0.1369, loss-lb:0.0742, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:09:07.563] iteration:19421  t-loss:0.1666, loss-lb:0.0887, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:09:07.759] iteration:19422  t-loss:0.1424, loss-lb:0.0845, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:09:07.954] iteration:19423  t-loss:0.1394, loss-lb:0.0807, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:09:08.147] iteration:19424  t-loss:0.1600, loss-lb:0.0778, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:09:08.339] iteration:19425  t-loss:0.1500, loss-lb:0.0773, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:09:08.530] iteration:19426  t-loss:0.1466, loss-lb:0.0801, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:09:08.722] iteration:19427  t-loss:0.1441, loss-lb:0.0754, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:09:08.914] iteration:19428  t-loss:0.1513, loss-lb:0.0723, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:09:09.106] iteration:19429  t-loss:0.1341, loss-lb:0.0708, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:09:09.297] iteration:19430  t-loss:0.1416, loss-lb:0.0826, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:09:09.489] iteration:19431  t-loss:0.1402, loss-lb:0.0781, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:09:09.681] iteration:19432  t-loss:0.1441, loss-lb:0.0798, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:09:09.873] iteration:19433  t-loss:0.1475, loss-lb:0.0687, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:09:10.065] iteration:19434  t-loss:0.1454, loss-lb:0.0807, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:09:10.258] iteration:19435  t-loss:0.1447, loss-lb:0.0746, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:09:10.450] iteration:19436  t-loss:0.1562, loss-lb:0.0850, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:09:10.643] iteration:19437  t-loss:0.1302, loss-lb:0.0693, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:09:10.835] iteration:19438  t-loss:0.1417, loss-lb:0.0739, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:09:11.027] iteration:19439  t-loss:0.1332, loss-lb:0.0713, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:09:11.219] iteration:19440  t-loss:0.1467, loss-lb:0.0763, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:09:11.412] iteration:19441  t-loss:0.2126, loss-lb:0.0780, loss-ulb:0.0673, weight:2.00, lr:0.0004
[12:09:11.611] iteration:19442  t-loss:0.1647, loss-lb:0.0751, loss-ulb:0.0448, weight:2.00, lr:0.0004
[12:09:11.803] iteration:19443  t-loss:0.1388, loss-lb:0.0800, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:09:11.994] iteration:19444  t-loss:0.1467, loss-lb:0.0809, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:09:12.186] iteration:19445  t-loss:0.1447, loss-lb:0.0756, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:09:12.379] iteration:19446  t-loss:0.1414, loss-lb:0.0760, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:09:12.571] iteration:19447  t-loss:0.1444, loss-lb:0.0800, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:09:12.763] iteration:19448  t-loss:0.1353, loss-lb:0.0751, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:09:12.955] iteration:19449  t-loss:0.1315, loss-lb:0.0727, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:09:13.154] iteration:19450  t-loss:0.1743, loss-lb:0.0717, loss-ulb:0.0513, weight:2.00, lr:0.0004
[12:09:13.347] iteration:19451  t-loss:0.1545, loss-lb:0.0800, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:09:13.540] iteration:19452  t-loss:0.1415, loss-lb:0.0732, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:09:13.731] iteration:19453  t-loss:0.1537, loss-lb:0.0815, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:09:13.924] iteration:19454  t-loss:0.1586, loss-lb:0.0848, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:09:14.116] iteration:19455  t-loss:0.2306, loss-lb:0.0756, loss-ulb:0.0775, weight:2.00, lr:0.0004
[12:09:14.308] iteration:19456  t-loss:0.1698, loss-lb:0.0794, loss-ulb:0.0452, weight:2.00, lr:0.0004
[12:09:14.502] iteration:19457  t-loss:0.1375, loss-lb:0.0808, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:09:14.694] iteration:19458  t-loss:0.1617, loss-lb:0.0790, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:09:14.885] iteration:19459  t-loss:0.1524, loss-lb:0.0736, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:09:15.086] iteration:19460  t-loss:0.1419, loss-lb:0.0788, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:09:15.278] iteration:19461  t-loss:0.1309, loss-lb:0.0688, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:09:15.472] iteration:19462  t-loss:0.1478, loss-lb:0.0718, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:09:15.663] iteration:19463  t-loss:0.1399, loss-lb:0.0820, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:09:15.855] iteration:19464  t-loss:0.2573, loss-lb:0.0799, loss-ulb:0.0887, weight:2.00, lr:0.0004
[12:09:16.047] iteration:19465  t-loss:0.1413, loss-lb:0.0767, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:09:16.252] iteration:19466  t-loss:0.1549, loss-lb:0.0889, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:09:16.449] iteration:19467  t-loss:0.1336, loss-lb:0.0660, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:09:16.644] iteration:19468  t-loss:0.1310, loss-lb:0.0729, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:09:16.835] iteration:19469  t-loss:0.1378, loss-lb:0.0757, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:09:17.027] iteration:19470  t-loss:0.1730, loss-lb:0.0744, loss-ulb:0.0493, weight:2.00, lr:0.0004
[12:09:17.220] iteration:19471  t-loss:0.1974, loss-lb:0.0867, loss-ulb:0.0554, weight:2.00, lr:0.0004
[12:09:17.411] iteration:19472  t-loss:0.1438, loss-lb:0.0819, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:09:17.603] iteration:19473  t-loss:0.1517, loss-lb:0.0830, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:09:17.794] iteration:19474  t-loss:0.1366, loss-lb:0.0697, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:09:17.986] iteration:19475  t-loss:0.1543, loss-lb:0.0857, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:09:18.179] iteration:19476  t-loss:0.1593, loss-lb:0.0770, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:09:18.372] iteration:19477  t-loss:0.1564, loss-lb:0.0824, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:09:18.568] iteration:19478  t-loss:0.1434, loss-lb:0.0793, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:09:18.763] iteration:19479  t-loss:0.1482, loss-lb:0.0745, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:09:18.956] iteration:19480  t-loss:0.1489, loss-lb:0.0808, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:09:19.149] iteration:19481  t-loss:0.1385, loss-lb:0.0759, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:09:19.341] iteration:19482  t-loss:0.1415, loss-lb:0.0759, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:09:19.533] iteration:19483  t-loss:0.1384, loss-lb:0.0756, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:09:19.724] iteration:19484  t-loss:0.1532, loss-lb:0.0854, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:09:19.915] iteration:19485  t-loss:0.1380, loss-lb:0.0728, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:09:20.108] iteration:19486  t-loss:0.2366, loss-lb:0.0826, loss-ulb:0.0770, weight:2.00, lr:0.0004
[12:09:20.300] iteration:19487  t-loss:0.1455, loss-lb:0.0750, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:09:20.493] iteration:19488  t-loss:0.1483, loss-lb:0.0721, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:09:20.685] iteration:19489  t-loss:0.1575, loss-lb:0.0785, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:09:20.877] iteration:19490  t-loss:0.1412, loss-lb:0.0708, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:09:21.069] iteration:19491  t-loss:0.1617, loss-lb:0.0799, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:09:21.261] iteration:19492  t-loss:0.1388, loss-lb:0.0702, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:09:21.453] iteration:19493  t-loss:0.1535, loss-lb:0.0773, loss-ulb:0.0381, weight:2.00, lr:0.0004
[12:09:21.644] iteration:19494  t-loss:0.1661, loss-lb:0.0896, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:09:21.836] iteration:19495  t-loss:0.1522, loss-lb:0.0762, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:09:22.026] iteration:19496  t-loss:0.1582, loss-lb:0.0727, loss-ulb:0.0428, weight:2.00, lr:0.0004
[12:09:22.218] iteration:19497  t-loss:0.1416, loss-lb:0.0738, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:09:22.408] iteration:19498  t-loss:0.1480, loss-lb:0.0838, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:09:22.600] iteration:19499  t-loss:0.1486, loss-lb:0.0732, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:09:22.791] iteration:19500  t-loss:0.1318, loss-lb:0.0736, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:09:22.981] iteration:19501  t-loss:0.1452, loss-lb:0.0718, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:09:23.174] iteration:19502  t-loss:0.1478, loss-lb:0.0741, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:09:36.268]  <<Test>> - Ep:198  - mean_dice/mean_h95 - S:89.81/1.33, Best-S:90.99, T:89.85/1.36, Best-T:90.48
[12:09:36.268]           - AvgLoss(lb/ulb/all):0.0775/0.0381/0.1526
[12:09:36.809] iteration:19503  t-loss:0.1393, loss-lb:0.0744, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:09:37.005] iteration:19504  t-loss:0.1558, loss-lb:0.0784, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:09:37.196] iteration:19505  t-loss:0.1394, loss-lb:0.0744, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:09:37.388] iteration:19506  t-loss:0.1439, loss-lb:0.0798, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:09:37.579] iteration:19507  t-loss:0.1511, loss-lb:0.0790, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:09:37.770] iteration:19508  t-loss:0.1388, loss-lb:0.0753, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:09:37.961] iteration:19509  t-loss:0.1473, loss-lb:0.0789, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:09:38.151] iteration:19510  t-loss:0.1510, loss-lb:0.0777, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:09:38.342] iteration:19511  t-loss:0.1432, loss-lb:0.0768, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:09:38.533] iteration:19512  t-loss:0.1368, loss-lb:0.0768, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:09:38.724] iteration:19513  t-loss:0.1388, loss-lb:0.0762, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:09:38.915] iteration:19514  t-loss:0.1537, loss-lb:0.0764, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:09:39.107] iteration:19515  t-loss:0.1252, loss-lb:0.0714, loss-ulb:0.0269, weight:2.00, lr:0.0004
[12:09:39.299] iteration:19516  t-loss:0.1451, loss-lb:0.0780, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:09:39.490] iteration:19517  t-loss:0.1296, loss-lb:0.0750, loss-ulb:0.0273, weight:2.00, lr:0.0004
[12:09:39.682] iteration:19518  t-loss:0.1341, loss-lb:0.0721, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:09:39.874] iteration:19519  t-loss:0.1543, loss-lb:0.0867, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:09:40.065] iteration:19520  t-loss:0.1258, loss-lb:0.0732, loss-ulb:0.0263, weight:2.00, lr:0.0004
[12:09:40.258] iteration:19521  t-loss:0.1719, loss-lb:0.0868, loss-ulb:0.0425, weight:2.00, lr:0.0004
[12:09:40.449] iteration:19522  t-loss:0.1552, loss-lb:0.0770, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:09:40.642] iteration:19523  t-loss:0.1517, loss-lb:0.0832, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:09:40.834] iteration:19524  t-loss:0.1505, loss-lb:0.0821, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:09:41.025] iteration:19525  t-loss:0.1395, loss-lb:0.0718, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:09:41.217] iteration:19526  t-loss:0.1552, loss-lb:0.0729, loss-ulb:0.0412, weight:2.00, lr:0.0004
[12:09:41.409] iteration:19527  t-loss:0.1466, loss-lb:0.0791, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:09:41.601] iteration:19528  t-loss:0.1699, loss-lb:0.0770, loss-ulb:0.0465, weight:2.00, lr:0.0004
[12:09:41.793] iteration:19529  t-loss:0.1383, loss-lb:0.0744, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:09:41.985] iteration:19530  t-loss:0.1453, loss-lb:0.0769, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:09:42.178] iteration:19531  t-loss:0.1765, loss-lb:0.0732, loss-ulb:0.0516, weight:2.00, lr:0.0004
[12:09:42.370] iteration:19532  t-loss:0.1867, loss-lb:0.0831, loss-ulb:0.0518, weight:2.00, lr:0.0004
[12:09:42.563] iteration:19533  t-loss:0.1405, loss-lb:0.0771, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:09:42.756] iteration:19534  t-loss:0.1541, loss-lb:0.0864, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:09:42.949] iteration:19535  t-loss:0.1686, loss-lb:0.0673, loss-ulb:0.0507, weight:2.00, lr:0.0004
[12:09:43.140] iteration:19536  t-loss:0.1337, loss-lb:0.0784, loss-ulb:0.0277, weight:2.00, lr:0.0004
[12:09:43.332] iteration:19537  t-loss:0.1434, loss-lb:0.0733, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:09:43.525] iteration:19538  t-loss:0.1558, loss-lb:0.0787, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:09:43.716] iteration:19539  t-loss:0.1428, loss-lb:0.0779, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:09:43.908] iteration:19540  t-loss:0.1297, loss-lb:0.0704, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:09:44.101] iteration:19541  t-loss:0.1647, loss-lb:0.0985, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:09:44.293] iteration:19542  t-loss:0.1575, loss-lb:0.0767, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:09:44.485] iteration:19543  t-loss:0.1529, loss-lb:0.0829, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:09:44.678] iteration:19544  t-loss:0.1400, loss-lb:0.0752, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:09:44.870] iteration:19545  t-loss:0.1604, loss-lb:0.0859, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:09:45.064] iteration:19546  t-loss:0.1636, loss-lb:0.0748, loss-ulb:0.0444, weight:2.00, lr:0.0004
[12:09:45.256] iteration:19547  t-loss:0.1380, loss-lb:0.0712, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:09:45.449] iteration:19548  t-loss:0.1328, loss-lb:0.0732, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:09:45.641] iteration:19549  t-loss:0.1359, loss-lb:0.0701, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:09:45.833] iteration:19550  t-loss:0.1440, loss-lb:0.0737, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:09:46.026] iteration:19551  t-loss:0.1641, loss-lb:0.0800, loss-ulb:0.0420, weight:2.00, lr:0.0004
[12:09:46.219] iteration:19552  t-loss:0.1672, loss-lb:0.0839, loss-ulb:0.0417, weight:2.00, lr:0.0004
[12:09:46.411] iteration:19553  t-loss:0.1401, loss-lb:0.0736, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:09:46.605] iteration:19554  t-loss:0.1609, loss-lb:0.0765, loss-ulb:0.0422, weight:2.00, lr:0.0004
[12:09:46.797] iteration:19555  t-loss:0.1539, loss-lb:0.0813, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:09:46.990] iteration:19556  t-loss:0.1487, loss-lb:0.0727, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:09:47.183] iteration:19557  t-loss:0.1453, loss-lb:0.0741, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:09:47.376] iteration:19558  t-loss:0.2122, loss-lb:0.0666, loss-ulb:0.0728, weight:2.00, lr:0.0004
[12:09:47.569] iteration:19559  t-loss:0.1503, loss-lb:0.0858, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:09:47.761] iteration:19560  t-loss:0.1397, loss-lb:0.0760, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:09:47.953] iteration:19561  t-loss:0.1476, loss-lb:0.0826, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:09:48.146] iteration:19562  t-loss:0.1500, loss-lb:0.0759, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:09:48.339] iteration:19563  t-loss:0.1448, loss-lb:0.0745, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:09:48.533] iteration:19564  t-loss:0.1408, loss-lb:0.0710, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:09:48.725] iteration:19565  t-loss:0.1294, loss-lb:0.0714, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:09:48.918] iteration:19566  t-loss:0.1460, loss-lb:0.0767, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:09:49.123] iteration:19567  t-loss:0.1399, loss-lb:0.0775, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:09:49.320] iteration:19568  t-loss:0.1366, loss-lb:0.0779, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:09:49.514] iteration:19569  t-loss:0.1505, loss-lb:0.0887, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:09:49.706] iteration:19570  t-loss:0.1431, loss-lb:0.0767, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:09:49.899] iteration:19571  t-loss:0.1798, loss-lb:0.0763, loss-ulb:0.0518, weight:2.00, lr:0.0004
[12:09:50.092] iteration:19572  t-loss:0.1471, loss-lb:0.0780, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:09:50.285] iteration:19573  t-loss:0.1429, loss-lb:0.0776, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:09:50.477] iteration:19574  t-loss:0.1762, loss-lb:0.0938, loss-ulb:0.0412, weight:2.00, lr:0.0004
[12:09:50.670] iteration:19575  t-loss:0.1401, loss-lb:0.0730, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:09:50.862] iteration:19576  t-loss:0.1324, loss-lb:0.0768, loss-ulb:0.0278, weight:2.00, lr:0.0004
[12:09:51.054] iteration:19577  t-loss:0.1478, loss-lb:0.0811, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:09:51.247] iteration:19578  t-loss:0.1604, loss-lb:0.0789, loss-ulb:0.0407, weight:2.00, lr:0.0004
[12:09:51.439] iteration:19579  t-loss:0.1447, loss-lb:0.0729, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:09:51.632] iteration:19580  t-loss:0.1534, loss-lb:0.0812, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:09:51.825] iteration:19581  t-loss:0.1723, loss-lb:0.0797, loss-ulb:0.0463, weight:2.00, lr:0.0004
[12:09:52.017] iteration:19582  t-loss:0.1469, loss-lb:0.0808, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:09:52.210] iteration:19583  t-loss:0.1381, loss-lb:0.0724, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:09:52.403] iteration:19584  t-loss:0.1407, loss-lb:0.0735, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:09:52.595] iteration:19585  t-loss:0.1422, loss-lb:0.0763, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:09:52.788] iteration:19586  t-loss:0.1417, loss-lb:0.0719, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:09:52.980] iteration:19587  t-loss:0.1500, loss-lb:0.0764, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:09:53.173] iteration:19588  t-loss:0.1364, loss-lb:0.0695, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:09:53.366] iteration:19589  t-loss:0.1460, loss-lb:0.0847, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:09:53.558] iteration:19590  t-loss:0.1389, loss-lb:0.0749, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:09:53.751] iteration:19591  t-loss:0.1478, loss-lb:0.0797, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:09:53.944] iteration:19592  t-loss:0.1462, loss-lb:0.0762, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:09:54.135] iteration:19593  t-loss:0.1505, loss-lb:0.0793, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:09:54.326] iteration:19594  t-loss:0.1383, loss-lb:0.0751, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:09:54.517] iteration:19595  t-loss:0.1456, loss-lb:0.0755, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:09:54.709] iteration:19596  t-loss:0.1339, loss-lb:0.0749, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:09:54.899] iteration:19597  t-loss:0.1356, loss-lb:0.0750, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:09:55.090] iteration:19598  t-loss:0.1379, loss-lb:0.0770, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:09:55.281] iteration:19599  t-loss:0.1476, loss-lb:0.0724, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:09:55.472] iteration:19600  t-loss:0.1414, loss-lb:0.0749, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:09:56.040] iteration:19601  t-loss:0.1657, loss-lb:0.0755, loss-ulb:0.0451, weight:2.00, lr:0.0004
[12:09:56.236] iteration:19602  t-loss:0.1584, loss-lb:0.0719, loss-ulb:0.0433, weight:2.00, lr:0.0004
[12:09:56.429] iteration:19603  t-loss:0.1342, loss-lb:0.0681, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:09:56.622] iteration:19604  t-loss:0.1514, loss-lb:0.0869, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:09:56.815] iteration:19605  t-loss:0.1519, loss-lb:0.0816, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:09:57.008] iteration:19606  t-loss:0.1446, loss-lb:0.0812, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:09:57.201] iteration:19607  t-loss:0.2013, loss-lb:0.0730, loss-ulb:0.0641, weight:2.00, lr:0.0004
[12:09:57.394] iteration:19608  t-loss:0.1528, loss-lb:0.0794, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:09:57.586] iteration:19609  t-loss:0.1391, loss-lb:0.0729, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:09:57.782] iteration:19610  t-loss:0.1521, loss-lb:0.0803, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:09:57.974] iteration:19611  t-loss:0.1452, loss-lb:0.0812, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:09:58.168] iteration:19612  t-loss:0.1435, loss-lb:0.0757, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:09:58.360] iteration:19613  t-loss:0.1629, loss-lb:0.0843, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:09:58.552] iteration:19614  t-loss:0.1408, loss-lb:0.0779, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:09:58.745] iteration:19615  t-loss:0.1405, loss-lb:0.0757, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:09:58.938] iteration:19616  t-loss:0.1435, loss-lb:0.0777, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:09:59.131] iteration:19617  t-loss:0.1519, loss-lb:0.0813, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:09:59.323] iteration:19618  t-loss:0.1694, loss-lb:0.1081, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:09:59.515] iteration:19619  t-loss:0.1438, loss-lb:0.0791, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:09:59.708] iteration:19620  t-loss:0.1373, loss-lb:0.0701, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:09:59.900] iteration:19621  t-loss:0.1400, loss-lb:0.0702, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:10:00.092] iteration:19622  t-loss:0.1389, loss-lb:0.0781, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:10:00.286] iteration:19623  t-loss:0.1771, loss-lb:0.0743, loss-ulb:0.0514, weight:2.00, lr:0.0004
[12:10:00.478] iteration:19624  t-loss:0.1494, loss-lb:0.0786, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:10:00.671] iteration:19625  t-loss:0.1742, loss-lb:0.0800, loss-ulb:0.0471, weight:2.00, lr:0.0004
[12:10:00.864] iteration:19626  t-loss:0.1355, loss-lb:0.0756, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:10:01.056] iteration:19627  t-loss:0.1408, loss-lb:0.0777, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:10:01.248] iteration:19628  t-loss:0.1423, loss-lb:0.0746, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:10:01.440] iteration:19629  t-loss:0.1486, loss-lb:0.0789, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:10:01.632] iteration:19630  t-loss:0.1459, loss-lb:0.0762, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:10:01.825] iteration:19631  t-loss:0.1426, loss-lb:0.0772, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:10:02.018] iteration:19632  t-loss:0.1481, loss-lb:0.0827, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:10:02.210] iteration:19633  t-loss:0.1481, loss-lb:0.0758, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:10:02.405] iteration:19634  t-loss:0.2876, loss-lb:0.0772, loss-ulb:0.1052, weight:2.00, lr:0.0004
[12:10:02.599] iteration:19635  t-loss:0.1597, loss-lb:0.0798, loss-ulb:0.0399, weight:2.00, lr:0.0004
[12:10:02.791] iteration:19636  t-loss:0.1349, loss-lb:0.0787, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:10:02.984] iteration:19637  t-loss:0.1393, loss-lb:0.0777, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:10:03.177] iteration:19638  t-loss:0.1938, loss-lb:0.0764, loss-ulb:0.0587, weight:2.00, lr:0.0004
[12:10:03.370] iteration:19639  t-loss:0.1560, loss-lb:0.0835, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:10:03.562] iteration:19640  t-loss:0.1389, loss-lb:0.0770, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:10:03.755] iteration:19641  t-loss:0.1483, loss-lb:0.0722, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:10:03.948] iteration:19642  t-loss:0.1496, loss-lb:0.0776, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:10:04.140] iteration:19643  t-loss:0.1439, loss-lb:0.0812, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:10:04.332] iteration:19644  t-loss:0.1327, loss-lb:0.0734, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:10:04.526] iteration:19645  t-loss:0.2070, loss-lb:0.0741, loss-ulb:0.0665, weight:2.00, lr:0.0004
[12:10:04.720] iteration:19646  t-loss:0.1711, loss-lb:0.0742, loss-ulb:0.0485, weight:2.00, lr:0.0004
[12:10:04.912] iteration:19647  t-loss:0.1490, loss-lb:0.0773, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:10:05.106] iteration:19648  t-loss:0.1492, loss-lb:0.0739, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:10:05.298] iteration:19649  t-loss:0.1776, loss-lb:0.0770, loss-ulb:0.0503, weight:2.00, lr:0.0004
[12:10:05.490] iteration:19650  t-loss:0.1495, loss-lb:0.0723, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:10:05.683] iteration:19651  t-loss:0.1639, loss-lb:0.0711, loss-ulb:0.0464, weight:2.00, lr:0.0004
[12:10:05.876] iteration:19652  t-loss:0.1975, loss-lb:0.0689, loss-ulb:0.0643, weight:2.00, lr:0.0004
[12:10:06.068] iteration:19653  t-loss:0.1508, loss-lb:0.0786, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:10:06.261] iteration:19654  t-loss:0.1680, loss-lb:0.0817, loss-ulb:0.0432, weight:2.00, lr:0.0004
[12:10:06.453] iteration:19655  t-loss:0.1449, loss-lb:0.0806, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:10:06.646] iteration:19656  t-loss:0.1517, loss-lb:0.0890, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:10:06.838] iteration:19657  t-loss:0.1544, loss-lb:0.0834, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:10:07.030] iteration:19658  t-loss:0.1540, loss-lb:0.0761, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:10:07.224] iteration:19659  t-loss:0.1424, loss-lb:0.0726, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:10:07.415] iteration:19660  t-loss:0.1382, loss-lb:0.0719, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:10:07.608] iteration:19661  t-loss:0.1453, loss-lb:0.0727, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:10:07.800] iteration:19662  t-loss:0.1287, loss-lb:0.0688, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:10:07.992] iteration:19663  t-loss:0.1655, loss-lb:0.0800, loss-ulb:0.0428, weight:2.00, lr:0.0004
[12:10:08.185] iteration:19664  t-loss:0.1408, loss-lb:0.0844, loss-ulb:0.0282, weight:2.00, lr:0.0004
[12:10:08.377] iteration:19665  t-loss:0.1464, loss-lb:0.0755, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:10:08.570] iteration:19666  t-loss:0.1352, loss-lb:0.0803, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:10:08.764] iteration:19667  t-loss:0.1466, loss-lb:0.0822, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:10:08.955] iteration:19668  t-loss:0.1476, loss-lb:0.0764, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:10:09.148] iteration:19669  t-loss:0.1530, loss-lb:0.0835, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:10:09.340] iteration:19670  t-loss:0.1349, loss-lb:0.0730, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:10:09.532] iteration:19671  t-loss:0.1531, loss-lb:0.0788, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:10:09.725] iteration:19672  t-loss:0.1380, loss-lb:0.0746, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:10:09.918] iteration:19673  t-loss:0.1455, loss-lb:0.0734, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:10:10.110] iteration:19674  t-loss:0.1742, loss-lb:0.0761, loss-ulb:0.0491, weight:2.00, lr:0.0004
[12:10:10.303] iteration:19675  t-loss:0.1355, loss-lb:0.0740, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:10:10.495] iteration:19676  t-loss:0.1608, loss-lb:0.0792, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:10:10.688] iteration:19677  t-loss:0.1415, loss-lb:0.0742, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:10:10.880] iteration:19678  t-loss:0.1493, loss-lb:0.0729, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:10:11.073] iteration:19679  t-loss:0.1406, loss-lb:0.0799, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:10:11.267] iteration:19680  t-loss:0.1379, loss-lb:0.0688, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:10:11.459] iteration:19681  t-loss:0.1529, loss-lb:0.0760, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:10:11.653] iteration:19682  t-loss:0.1442, loss-lb:0.0804, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:10:11.846] iteration:19683  t-loss:0.1404, loss-lb:0.0701, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:10:12.038] iteration:19684  t-loss:0.1995, loss-lb:0.0767, loss-ulb:0.0614, weight:2.00, lr:0.0004
[12:10:12.231] iteration:19685  t-loss:0.1845, loss-lb:0.0694, loss-ulb:0.0576, weight:2.00, lr:0.0004
[12:10:12.423] iteration:19686  t-loss:0.1498, loss-lb:0.0728, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:10:12.617] iteration:19687  t-loss:0.2043, loss-lb:0.0815, loss-ulb:0.0614, weight:2.00, lr:0.0004
[12:10:12.809] iteration:19688  t-loss:0.1629, loss-lb:0.0875, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:10:13.002] iteration:19689  t-loss:0.1741, loss-lb:0.0913, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:10:13.194] iteration:19690  t-loss:0.1662, loss-lb:0.0777, loss-ulb:0.0443, weight:2.00, lr:0.0004
[12:10:13.386] iteration:19691  t-loss:0.1354, loss-lb:0.0767, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:10:13.577] iteration:19692  t-loss:0.1666, loss-lb:0.0817, loss-ulb:0.0424, weight:2.00, lr:0.0004
[12:10:13.768] iteration:19693  t-loss:0.1489, loss-lb:0.0795, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:10:13.959] iteration:19694  t-loss:0.1475, loss-lb:0.0847, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:10:14.151] iteration:19695  t-loss:0.1434, loss-lb:0.0728, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:10:14.342] iteration:19696  t-loss:0.1537, loss-lb:0.0820, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:10:14.533] iteration:19697  t-loss:0.1447, loss-lb:0.0747, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:10:14.723] iteration:19698  t-loss:0.1596, loss-lb:0.0828, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:10:26.898]  <<Test>> - Ep:200  - mean_dice/mean_h95 - S:89.92/1.30, Best-S:90.99, T:89.72/1.39, Best-T:90.48
[12:10:26.899]           - AvgLoss(lb/ulb/all):0.0776/0.0398/0.1579
[12:10:27.435] iteration:19699  t-loss:0.1413, loss-lb:0.0764, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:10:27.632] iteration:19700  t-loss:0.1408, loss-lb:0.0765, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:10:27.824] iteration:19701  t-loss:0.1346, loss-lb:0.0706, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:10:28.017] iteration:19702  t-loss:0.1408, loss-lb:0.0825, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:10:28.211] iteration:19703  t-loss:0.1772, loss-lb:0.0778, loss-ulb:0.0497, weight:2.00, lr:0.0004
[12:10:28.404] iteration:19704  t-loss:0.1497, loss-lb:0.0801, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:10:28.597] iteration:19705  t-loss:0.1510, loss-lb:0.0744, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:10:28.790] iteration:19706  t-loss:0.1414, loss-lb:0.0776, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:10:28.983] iteration:19707  t-loss:0.1363, loss-lb:0.0723, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:10:29.177] iteration:19708  t-loss:0.1418, loss-lb:0.0796, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:10:29.370] iteration:19709  t-loss:0.1581, loss-lb:0.0835, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:10:29.563] iteration:19710  t-loss:0.1441, loss-lb:0.0766, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:10:29.756] iteration:19711  t-loss:0.1607, loss-lb:0.0832, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:10:29.950] iteration:19712  t-loss:0.1419, loss-lb:0.0754, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:10:30.144] iteration:19713  t-loss:0.1467, loss-lb:0.0754, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:10:30.337] iteration:19714  t-loss:0.1486, loss-lb:0.0795, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:10:30.535] iteration:19715  t-loss:0.1414, loss-lb:0.0793, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:10:30.733] iteration:19716  t-loss:0.1505, loss-lb:0.0799, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:10:30.927] iteration:19717  t-loss:0.1413, loss-lb:0.0802, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:10:31.120] iteration:19718  t-loss:0.1595, loss-lb:0.0805, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:10:31.312] iteration:19719  t-loss:0.1450, loss-lb:0.0764, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:10:31.504] iteration:19720  t-loss:0.1526, loss-lb:0.0686, loss-ulb:0.0420, weight:2.00, lr:0.0004
[12:10:31.697] iteration:19721  t-loss:0.1386, loss-lb:0.0774, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:10:31.888] iteration:19722  t-loss:0.1859, loss-lb:0.0726, loss-ulb:0.0566, weight:2.00, lr:0.0004
[12:10:32.082] iteration:19723  t-loss:0.1734, loss-lb:0.0733, loss-ulb:0.0500, weight:2.00, lr:0.0004
[12:10:32.275] iteration:19724  t-loss:0.1412, loss-lb:0.0789, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:10:32.468] iteration:19725  t-loss:0.1388, loss-lb:0.0799, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:10:32.661] iteration:19726  t-loss:0.1481, loss-lb:0.0788, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:10:32.853] iteration:19727  t-loss:0.1395, loss-lb:0.0725, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:10:33.046] iteration:19728  t-loss:0.1342, loss-lb:0.0795, loss-ulb:0.0273, weight:2.00, lr:0.0004
[12:10:33.238] iteration:19729  t-loss:0.1376, loss-lb:0.0728, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:10:33.431] iteration:19730  t-loss:0.1521, loss-lb:0.0801, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:10:33.623] iteration:19731  t-loss:0.1434, loss-lb:0.0731, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:10:33.815] iteration:19732  t-loss:0.1412, loss-lb:0.0773, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:10:34.008] iteration:19733  t-loss:0.1546, loss-lb:0.0785, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:10:34.200] iteration:19734  t-loss:0.1598, loss-lb:0.0779, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:10:34.394] iteration:19735  t-loss:0.1590, loss-lb:0.0826, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:10:34.586] iteration:19736  t-loss:0.1567, loss-lb:0.0855, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:10:34.778] iteration:19737  t-loss:0.1408, loss-lb:0.0795, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:10:34.971] iteration:19738  t-loss:0.1704, loss-lb:0.0828, loss-ulb:0.0438, weight:2.00, lr:0.0004
[12:10:35.162] iteration:19739  t-loss:0.1971, loss-lb:0.0726, loss-ulb:0.0623, weight:2.00, lr:0.0004
[12:10:35.355] iteration:19740  t-loss:0.1740, loss-lb:0.0882, loss-ulb:0.0429, weight:2.00, lr:0.0004
[12:10:35.548] iteration:19741  t-loss:0.1610, loss-lb:0.0796, loss-ulb:0.0407, weight:2.00, lr:0.0004
[12:10:35.739] iteration:19742  t-loss:0.1440, loss-lb:0.0768, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:10:35.931] iteration:19743  t-loss:0.1562, loss-lb:0.0731, loss-ulb:0.0416, weight:2.00, lr:0.0004
[12:10:36.122] iteration:19744  t-loss:0.1456, loss-lb:0.0824, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:10:36.314] iteration:19745  t-loss:0.1319, loss-lb:0.0717, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:10:36.507] iteration:19746  t-loss:0.1312, loss-lb:0.0644, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:10:36.699] iteration:19747  t-loss:0.1676, loss-lb:0.0837, loss-ulb:0.0419, weight:2.00, lr:0.0004
[12:10:36.891] iteration:19748  t-loss:0.1399, loss-lb:0.0783, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:10:37.083] iteration:19749  t-loss:0.1411, loss-lb:0.0761, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:10:37.276] iteration:19750  t-loss:0.1742, loss-lb:0.0836, loss-ulb:0.0453, weight:2.00, lr:0.0004
[12:10:37.467] iteration:19751  t-loss:0.1415, loss-lb:0.0724, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:10:37.659] iteration:19752  t-loss:0.1355, loss-lb:0.0724, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:10:37.851] iteration:19753  t-loss:0.1429, loss-lb:0.0768, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:10:38.043] iteration:19754  t-loss:0.1819, loss-lb:0.0796, loss-ulb:0.0511, weight:2.00, lr:0.0004
[12:10:38.236] iteration:19755  t-loss:0.1601, loss-lb:0.0869, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:10:38.428] iteration:19756  t-loss:0.1533, loss-lb:0.0781, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:10:38.619] iteration:19757  t-loss:0.1646, loss-lb:0.0813, loss-ulb:0.0417, weight:2.00, lr:0.0004
[12:10:38.811] iteration:19758  t-loss:0.1764, loss-lb:0.0756, loss-ulb:0.0504, weight:2.00, lr:0.0004
[12:10:39.002] iteration:19759  t-loss:0.1292, loss-lb:0.0702, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:10:39.196] iteration:19760  t-loss:0.1556, loss-lb:0.0785, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:10:39.389] iteration:19761  t-loss:0.1592, loss-lb:0.0813, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:10:39.581] iteration:19762  t-loss:0.1552, loss-lb:0.0792, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:10:39.772] iteration:19763  t-loss:0.1457, loss-lb:0.0857, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:10:39.964] iteration:19764  t-loss:0.2049, loss-lb:0.0803, loss-ulb:0.0623, weight:2.00, lr:0.0004
[12:10:40.156] iteration:19765  t-loss:0.1490, loss-lb:0.0791, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:10:40.347] iteration:19766  t-loss:0.1534, loss-lb:0.0831, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:10:40.538] iteration:19767  t-loss:0.1528, loss-lb:0.0800, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:10:40.729] iteration:19768  t-loss:0.1884, loss-lb:0.0802, loss-ulb:0.0541, weight:2.00, lr:0.0004
[12:10:40.922] iteration:19769  t-loss:0.1474, loss-lb:0.0798, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:10:41.117] iteration:19770  t-loss:0.1531, loss-lb:0.0796, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:10:41.315] iteration:19771  t-loss:0.1394, loss-lb:0.0726, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:10:41.509] iteration:19772  t-loss:0.1484, loss-lb:0.0818, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:10:41.703] iteration:19773  t-loss:0.1549, loss-lb:0.0729, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:10:41.895] iteration:19774  t-loss:0.1558, loss-lb:0.0845, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:10:42.087] iteration:19775  t-loss:0.1757, loss-lb:0.0836, loss-ulb:0.0461, weight:2.00, lr:0.0004
[12:10:42.279] iteration:19776  t-loss:0.1513, loss-lb:0.0814, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:10:42.471] iteration:19777  t-loss:0.1450, loss-lb:0.0749, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:10:42.662] iteration:19778  t-loss:0.1592, loss-lb:0.0823, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:10:42.855] iteration:19779  t-loss:0.1545, loss-lb:0.0722, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:10:43.047] iteration:19780  t-loss:0.1792, loss-lb:0.0909, loss-ulb:0.0442, weight:2.00, lr:0.0004
[12:10:43.240] iteration:19781  t-loss:0.2075, loss-lb:0.0733, loss-ulb:0.0671, weight:2.00, lr:0.0004
[12:10:43.432] iteration:19782  t-loss:0.1469, loss-lb:0.0883, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:10:43.623] iteration:19783  t-loss:0.1898, loss-lb:0.0755, loss-ulb:0.0572, weight:2.00, lr:0.0004
[12:10:43.816] iteration:19784  t-loss:0.1666, loss-lb:0.0720, loss-ulb:0.0473, weight:2.00, lr:0.0004
[12:10:44.007] iteration:19785  t-loss:0.1523, loss-lb:0.0809, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:10:44.200] iteration:19786  t-loss:0.2769, loss-lb:0.0749, loss-ulb:0.1010, weight:2.00, lr:0.0004
[12:10:44.392] iteration:19787  t-loss:0.1432, loss-lb:0.0767, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:10:44.584] iteration:19788  t-loss:0.2459, loss-lb:0.0857, loss-ulb:0.0801, weight:2.00, lr:0.0004
[12:10:44.774] iteration:19789  t-loss:0.1485, loss-lb:0.0822, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:10:44.964] iteration:19790  t-loss:0.1741, loss-lb:0.0774, loss-ulb:0.0484, weight:2.00, lr:0.0004
[12:10:45.155] iteration:19791  t-loss:0.1536, loss-lb:0.0822, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:10:45.346] iteration:19792  t-loss:0.1602, loss-lb:0.0943, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:10:45.536] iteration:19793  t-loss:0.1575, loss-lb:0.0855, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:10:45.725] iteration:19794  t-loss:0.1418, loss-lb:0.0836, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:10:45.915] iteration:19795  t-loss:0.1462, loss-lb:0.0813, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:10:46.105] iteration:19796  t-loss:0.1563, loss-lb:0.0919, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:10:46.728] iteration:19797  t-loss:0.1619, loss-lb:0.0818, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:10:46.923] iteration:19798  t-loss:0.2184, loss-lb:0.0842, loss-ulb:0.0671, weight:2.00, lr:0.0004
[12:10:47.114] iteration:19799  t-loss:0.1501, loss-lb:0.0775, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:10:47.306] iteration:19800  t-loss:0.1562, loss-lb:0.0878, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:10:47.498] iteration:19801  t-loss:0.1550, loss-lb:0.0825, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:10:47.690] iteration:19802  t-loss:0.1505, loss-lb:0.0821, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:10:47.882] iteration:19803  t-loss:0.1627, loss-lb:0.0910, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:10:48.074] iteration:19804  t-loss:0.1583, loss-lb:0.0827, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:10:48.265] iteration:19805  t-loss:0.1668, loss-lb:0.0788, loss-ulb:0.0440, weight:2.00, lr:0.0004
[12:10:48.457] iteration:19806  t-loss:0.1773, loss-lb:0.0778, loss-ulb:0.0498, weight:2.00, lr:0.0004
[12:10:48.649] iteration:19807  t-loss:0.1379, loss-lb:0.0782, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:10:48.841] iteration:19808  t-loss:0.1703, loss-lb:0.0794, loss-ulb:0.0455, weight:2.00, lr:0.0004
[12:10:49.035] iteration:19809  t-loss:0.2420, loss-lb:0.1083, loss-ulb:0.0668, weight:2.00, lr:0.0004
[12:10:49.227] iteration:19810  t-loss:0.1484, loss-lb:0.0799, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:10:49.417] iteration:19811  t-loss:0.1584, loss-lb:0.0871, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:10:49.610] iteration:19812  t-loss:0.1719, loss-lb:0.0933, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:10:49.802] iteration:19813  t-loss:0.1647, loss-lb:0.0842, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:10:49.993] iteration:19814  t-loss:0.1472, loss-lb:0.0786, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:10:50.185] iteration:19815  t-loss:0.1540, loss-lb:0.0885, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:10:50.376] iteration:19816  t-loss:0.1606, loss-lb:0.0767, loss-ulb:0.0419, weight:2.00, lr:0.0004
[12:10:50.568] iteration:19817  t-loss:0.2312, loss-lb:0.1008, loss-ulb:0.0652, weight:2.00, lr:0.0004
[12:10:50.760] iteration:19818  t-loss:0.1963, loss-lb:0.0876, loss-ulb:0.0543, weight:2.00, lr:0.0004
[12:10:50.953] iteration:19819  t-loss:0.2926, loss-lb:0.0796, loss-ulb:0.1065, weight:2.00, lr:0.0004
[12:10:51.144] iteration:19820  t-loss:0.1421, loss-lb:0.0781, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:10:51.336] iteration:19821  t-loss:0.1404, loss-lb:0.0808, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:10:51.527] iteration:19822  t-loss:0.1372, loss-lb:0.0696, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:10:51.719] iteration:19823  t-loss:0.1751, loss-lb:0.0854, loss-ulb:0.0449, weight:2.00, lr:0.0004
[12:10:51.915] iteration:19824  t-loss:0.1339, loss-lb:0.0773, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:10:52.111] iteration:19825  t-loss:0.1444, loss-lb:0.0869, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:10:52.306] iteration:19826  t-loss:0.1654, loss-lb:0.0934, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:10:52.498] iteration:19827  t-loss:0.1778, loss-lb:0.0789, loss-ulb:0.0495, weight:2.00, lr:0.0004
[12:10:52.691] iteration:19828  t-loss:0.1448, loss-lb:0.0839, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:10:52.883] iteration:19829  t-loss:0.1465, loss-lb:0.0822, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:10:53.075] iteration:19830  t-loss:0.1576, loss-lb:0.0824, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:10:53.267] iteration:19831  t-loss:0.1919, loss-lb:0.0887, loss-ulb:0.0516, weight:2.00, lr:0.0004
[12:10:53.459] iteration:19832  t-loss:0.1639, loss-lb:0.0797, loss-ulb:0.0421, weight:2.00, lr:0.0004
[12:10:53.652] iteration:19833  t-loss:0.1446, loss-lb:0.0822, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:10:53.844] iteration:19834  t-loss:0.1393, loss-lb:0.0786, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:10:54.035] iteration:19835  t-loss:0.1483, loss-lb:0.0802, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:10:54.227] iteration:19836  t-loss:0.1632, loss-lb:0.0755, loss-ulb:0.0439, weight:2.00, lr:0.0004
[12:10:54.420] iteration:19837  t-loss:0.1923, loss-lb:0.0809, loss-ulb:0.0557, weight:2.00, lr:0.0004
[12:10:54.612] iteration:19838  t-loss:0.1604, loss-lb:0.0889, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:10:54.804] iteration:19839  t-loss:0.1511, loss-lb:0.0844, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:10:54.996] iteration:19840  t-loss:0.1465, loss-lb:0.0844, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:10:55.188] iteration:19841  t-loss:0.1735, loss-lb:0.0674, loss-ulb:0.0530, weight:2.00, lr:0.0004
[12:10:55.380] iteration:19842  t-loss:0.1571, loss-lb:0.0774, loss-ulb:0.0399, weight:2.00, lr:0.0004
[12:10:55.585] iteration:19843  t-loss:0.1384, loss-lb:0.0716, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:10:55.785] iteration:19844  t-loss:0.1432, loss-lb:0.0758, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:10:55.982] iteration:19845  t-loss:0.1620, loss-lb:0.0840, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:10:56.174] iteration:19846  t-loss:0.1521, loss-lb:0.0788, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:10:56.366] iteration:19847  t-loss:0.1399, loss-lb:0.0731, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:10:56.557] iteration:19848  t-loss:0.1629, loss-lb:0.0822, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:10:56.749] iteration:19849  t-loss:0.1618, loss-lb:0.0777, loss-ulb:0.0421, weight:2.00, lr:0.0004
[12:10:56.942] iteration:19850  t-loss:0.3057, loss-lb:0.0772, loss-ulb:0.1142, weight:2.00, lr:0.0004
[12:10:57.133] iteration:19851  t-loss:0.1299, loss-lb:0.0752, loss-ulb:0.0273, weight:2.00, lr:0.0004
[12:10:57.326] iteration:19852  t-loss:0.1565, loss-lb:0.0843, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:10:57.518] iteration:19853  t-loss:0.1713, loss-lb:0.0894, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:10:57.710] iteration:19854  t-loss:0.1325, loss-lb:0.0759, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:10:57.902] iteration:19855  t-loss:0.1381, loss-lb:0.0775, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:10:58.093] iteration:19856  t-loss:0.1406, loss-lb:0.0793, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:10:58.286] iteration:19857  t-loss:0.1386, loss-lb:0.0779, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:10:58.479] iteration:19858  t-loss:0.1534, loss-lb:0.0731, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:10:58.671] iteration:19859  t-loss:0.1508, loss-lb:0.0764, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:10:58.864] iteration:19860  t-loss:0.1505, loss-lb:0.0729, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:10:59.056] iteration:19861  t-loss:0.1826, loss-lb:0.0856, loss-ulb:0.0485, weight:2.00, lr:0.0004
[12:10:59.247] iteration:19862  t-loss:0.1483, loss-lb:0.0793, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:10:59.440] iteration:19863  t-loss:0.1420, loss-lb:0.0769, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:10:59.633] iteration:19864  t-loss:0.1638, loss-lb:0.0764, loss-ulb:0.0437, weight:2.00, lr:0.0004
[12:10:59.824] iteration:19865  t-loss:0.1423, loss-lb:0.0736, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:11:00.016] iteration:19866  t-loss:0.1326, loss-lb:0.0710, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:11:00.208] iteration:19867  t-loss:0.1514, loss-lb:0.0857, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:11:00.400] iteration:19868  t-loss:0.1370, loss-lb:0.0767, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:11:00.593] iteration:19869  t-loss:0.1790, loss-lb:0.0773, loss-ulb:0.0508, weight:2.00, lr:0.0004
[12:11:00.784] iteration:19870  t-loss:0.1446, loss-lb:0.0816, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:11:00.976] iteration:19871  t-loss:0.1403, loss-lb:0.0741, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:11:01.168] iteration:19872  t-loss:0.1485, loss-lb:0.0782, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:11:01.360] iteration:19873  t-loss:0.1429, loss-lb:0.0736, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:11:01.553] iteration:19874  t-loss:0.1415, loss-lb:0.0783, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:11:01.745] iteration:19875  t-loss:0.1471, loss-lb:0.0772, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:11:01.936] iteration:19876  t-loss:0.1442, loss-lb:0.0726, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:11:02.127] iteration:19877  t-loss:0.1411, loss-lb:0.0772, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:11:02.319] iteration:19878  t-loss:0.1596, loss-lb:0.0916, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:11:02.512] iteration:19879  t-loss:0.1441, loss-lb:0.0707, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:11:02.705] iteration:19880  t-loss:0.1423, loss-lb:0.0730, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:11:02.899] iteration:19881  t-loss:0.1313, loss-lb:0.0729, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:11:03.096] iteration:19882  t-loss:0.1333, loss-lb:0.0734, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:11:03.290] iteration:19883  t-loss:0.1498, loss-lb:0.0852, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:11:03.483] iteration:19884  t-loss:0.1497, loss-lb:0.0739, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:11:03.677] iteration:19885  t-loss:0.1673, loss-lb:0.0794, loss-ulb:0.0440, weight:2.00, lr:0.0004
[12:11:03.870] iteration:19886  t-loss:0.1376, loss-lb:0.0766, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:11:04.062] iteration:19887  t-loss:0.1506, loss-lb:0.0865, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:11:04.252] iteration:19888  t-loss:0.1390, loss-lb:0.0790, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:11:04.443] iteration:19889  t-loss:0.1532, loss-lb:0.0748, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:11:04.634] iteration:19890  t-loss:0.1327, loss-lb:0.0744, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:11:04.825] iteration:19891  t-loss:0.1366, loss-lb:0.0795, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:11:05.017] iteration:19892  t-loss:0.1495, loss-lb:0.0861, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:11:05.208] iteration:19893  t-loss:0.1486, loss-lb:0.0787, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:11:05.399] iteration:19894  t-loss:0.1375, loss-lb:0.0714, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:11:18.162]  <<Test>> - Ep:202  - mean_dice/mean_h95 - S:89.89/1.33, Best-S:90.99, T:89.95/1.32, Best-T:90.48
[12:11:18.162]           - AvgLoss(lb/ulb/all):0.0802/0.0335/0.1448
[12:11:18.696] iteration:19895  t-loss:0.1340, loss-lb:0.0755, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:11:18.895] iteration:19896  t-loss:0.1390, loss-lb:0.0835, loss-ulb:0.0278, weight:2.00, lr:0.0004
[12:11:19.086] iteration:19897  t-loss:0.1337, loss-lb:0.0740, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:11:19.278] iteration:19898  t-loss:0.1450, loss-lb:0.0831, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:11:19.470] iteration:19899  t-loss:0.1406, loss-lb:0.0770, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:11:19.662] iteration:19900  t-loss:0.1765, loss-lb:0.0799, loss-ulb:0.0483, weight:2.00, lr:0.0004
[12:11:19.854] iteration:19901  t-loss:0.1376, loss-lb:0.0758, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:11:20.047] iteration:19902  t-loss:0.1434, loss-lb:0.0747, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:11:20.240] iteration:19903  t-loss:0.1343, loss-lb:0.0715, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:11:20.431] iteration:19904  t-loss:0.1411, loss-lb:0.0697, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:11:20.623] iteration:19905  t-loss:0.1630, loss-lb:0.0845, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:11:20.817] iteration:19906  t-loss:0.3147, loss-lb:0.0730, loss-ulb:0.1208, weight:2.00, lr:0.0004
[12:11:21.007] iteration:19907  t-loss:0.1413, loss-lb:0.0776, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:11:21.199] iteration:19908  t-loss:0.1460, loss-lb:0.0770, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:11:21.392] iteration:19909  t-loss:0.1459, loss-lb:0.0757, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:11:21.584] iteration:19910  t-loss:0.1300, loss-lb:0.0747, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:11:21.776] iteration:19911  t-loss:0.1670, loss-lb:0.0827, loss-ulb:0.0422, weight:2.00, lr:0.0004
[12:11:21.967] iteration:19912  t-loss:0.1397, loss-lb:0.0800, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:11:22.159] iteration:19913  t-loss:0.1977, loss-lb:0.0792, loss-ulb:0.0593, weight:2.00, lr:0.0004
[12:11:22.351] iteration:19914  t-loss:0.1484, loss-lb:0.0779, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:11:22.543] iteration:19915  t-loss:0.1435, loss-lb:0.0777, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:11:22.736] iteration:19916  t-loss:0.3398, loss-lb:0.0771, loss-ulb:0.1313, weight:2.00, lr:0.0004
[12:11:22.928] iteration:19917  t-loss:0.1644, loss-lb:0.0898, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:11:23.119] iteration:19918  t-loss:0.1513, loss-lb:0.0811, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:11:23.311] iteration:19919  t-loss:0.1735, loss-lb:0.0960, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:11:23.504] iteration:19920  t-loss:0.1777, loss-lb:0.1030, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:11:23.695] iteration:19921  t-loss:0.1788, loss-lb:0.0828, loss-ulb:0.0480, weight:2.00, lr:0.0004
[12:11:23.887] iteration:19922  t-loss:0.1632, loss-lb:0.0880, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:11:24.081] iteration:19923  t-loss:0.2242, loss-lb:0.0912, loss-ulb:0.0665, weight:2.00, lr:0.0004
[12:11:24.273] iteration:19924  t-loss:0.3092, loss-lb:0.0783, loss-ulb:0.1155, weight:2.00, lr:0.0004
[12:11:24.466] iteration:19925  t-loss:0.1709, loss-lb:0.0887, loss-ulb:0.0411, weight:2.00, lr:0.0004
[12:11:24.658] iteration:19926  t-loss:0.1763, loss-lb:0.0804, loss-ulb:0.0479, weight:2.00, lr:0.0004
[12:11:24.850] iteration:19927  t-loss:0.1408, loss-lb:0.0780, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:11:25.042] iteration:19928  t-loss:0.1407, loss-lb:0.0806, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:11:25.233] iteration:19929  t-loss:0.1719, loss-lb:0.0830, loss-ulb:0.0445, weight:2.00, lr:0.0004
[12:11:25.425] iteration:19930  t-loss:0.1635, loss-lb:0.0897, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:11:25.617] iteration:19931  t-loss:0.1745, loss-lb:0.0831, loss-ulb:0.0457, weight:2.00, lr:0.0004
[12:11:25.809] iteration:19932  t-loss:0.1677, loss-lb:0.0825, loss-ulb:0.0426, weight:2.00, lr:0.0004
[12:11:26.001] iteration:19933  t-loss:0.1591, loss-lb:0.0945, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:11:26.195] iteration:19934  t-loss:0.1801, loss-lb:0.0814, loss-ulb:0.0493, weight:2.00, lr:0.0004
[12:11:26.387] iteration:19935  t-loss:0.1495, loss-lb:0.0837, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:11:26.579] iteration:19936  t-loss:0.1464, loss-lb:0.0770, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:11:26.772] iteration:19937  t-loss:0.1626, loss-lb:0.0872, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:11:26.965] iteration:19938  t-loss:0.1431, loss-lb:0.0858, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:11:27.157] iteration:19939  t-loss:0.1621, loss-lb:0.0724, loss-ulb:0.0448, weight:2.00, lr:0.0004
[12:11:27.349] iteration:19940  t-loss:0.1534, loss-lb:0.0856, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:11:27.541] iteration:19941  t-loss:0.1563, loss-lb:0.0755, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:11:27.733] iteration:19942  t-loss:0.1855, loss-lb:0.0762, loss-ulb:0.0547, weight:2.00, lr:0.0004
[12:11:27.925] iteration:19943  t-loss:0.1519, loss-lb:0.0843, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:11:28.119] iteration:19944  t-loss:0.1635, loss-lb:0.0869, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:11:28.324] iteration:19945  t-loss:0.1432, loss-lb:0.0721, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:11:28.524] iteration:19946  t-loss:0.1470, loss-lb:0.0838, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:11:28.720] iteration:19947  t-loss:0.1430, loss-lb:0.0828, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:11:28.913] iteration:19948  t-loss:0.1478, loss-lb:0.0837, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:11:29.106] iteration:19949  t-loss:0.1399, loss-lb:0.0807, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:11:29.298] iteration:19950  t-loss:0.1368, loss-lb:0.0784, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:11:29.490] iteration:19951  t-loss:0.1360, loss-lb:0.0742, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:11:29.683] iteration:19952  t-loss:0.1350, loss-lb:0.0791, loss-ulb:0.0280, weight:2.00, lr:0.0004
[12:11:29.874] iteration:19953  t-loss:0.1567, loss-lb:0.0913, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:11:30.067] iteration:19954  t-loss:0.1349, loss-lb:0.0736, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:11:30.260] iteration:19955  t-loss:0.1344, loss-lb:0.0787, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:11:30.453] iteration:19956  t-loss:0.1422, loss-lb:0.0810, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:11:30.645] iteration:19957  t-loss:0.1385, loss-lb:0.0788, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:11:30.837] iteration:19958  t-loss:0.1501, loss-lb:0.0881, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:11:31.029] iteration:19959  t-loss:0.1406, loss-lb:0.0753, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:11:31.224] iteration:19960  t-loss:0.2110, loss-lb:0.0810, loss-ulb:0.0650, weight:2.00, lr:0.0004
[12:11:31.416] iteration:19961  t-loss:0.1483, loss-lb:0.0821, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:11:31.608] iteration:19962  t-loss:0.1454, loss-lb:0.0760, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:11:31.800] iteration:19963  t-loss:0.1489, loss-lb:0.0763, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:11:31.992] iteration:19964  t-loss:0.1339, loss-lb:0.0732, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:11:32.184] iteration:19965  t-loss:0.1492, loss-lb:0.0788, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:11:32.377] iteration:19966  t-loss:0.1460, loss-lb:0.0767, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:11:32.570] iteration:19967  t-loss:0.1526, loss-lb:0.0919, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:11:32.762] iteration:19968  t-loss:0.2051, loss-lb:0.0813, loss-ulb:0.0619, weight:2.00, lr:0.0004
[12:11:32.955] iteration:19969  t-loss:0.1345, loss-lb:0.0704, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:11:33.147] iteration:19970  t-loss:0.1401, loss-lb:0.0801, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:11:33.339] iteration:19971  t-loss:0.1549, loss-lb:0.0777, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:11:33.531] iteration:19972  t-loss:0.1490, loss-lb:0.0818, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:11:33.724] iteration:19973  t-loss:0.1586, loss-lb:0.0823, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:11:33.917] iteration:19974  t-loss:0.1421, loss-lb:0.0733, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:11:34.108] iteration:19975  t-loss:0.1409, loss-lb:0.0743, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:11:34.302] iteration:19976  t-loss:0.1557, loss-lb:0.0838, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:11:34.496] iteration:19977  t-loss:0.1439, loss-lb:0.0811, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:11:34.688] iteration:19978  t-loss:0.1987, loss-lb:0.0795, loss-ulb:0.0596, weight:2.00, lr:0.0004
[12:11:34.880] iteration:19979  t-loss:0.1524, loss-lb:0.0751, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:11:35.074] iteration:19980  t-loss:0.1573, loss-lb:0.0721, loss-ulb:0.0426, weight:2.00, lr:0.0004
[12:11:35.266] iteration:19981  t-loss:0.1471, loss-lb:0.0754, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:11:35.458] iteration:19982  t-loss:0.1503, loss-lb:0.0716, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:11:35.651] iteration:19983  t-loss:0.1385, loss-lb:0.0768, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:11:35.843] iteration:19984  t-loss:0.1345, loss-lb:0.0713, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:11:36.035] iteration:19985  t-loss:0.1466, loss-lb:0.0769, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:11:36.226] iteration:19986  t-loss:0.1412, loss-lb:0.0786, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:11:36.418] iteration:19987  t-loss:0.1542, loss-lb:0.0788, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:11:36.609] iteration:19988  t-loss:0.1554, loss-lb:0.0768, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:11:36.801] iteration:19989  t-loss:0.1403, loss-lb:0.0830, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:11:36.991] iteration:19990  t-loss:0.1458, loss-lb:0.0733, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:11:37.183] iteration:19991  t-loss:0.2054, loss-lb:0.0746, loss-ulb:0.0654, weight:2.00, lr:0.0004
[12:11:37.373] iteration:19992  t-loss:0.1358, loss-lb:0.0740, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:11:37.950] iteration:19993  t-loss:0.1469, loss-lb:0.0759, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:11:38.145] iteration:19994  t-loss:0.1542, loss-lb:0.0829, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:11:38.338] iteration:19995  t-loss:0.1278, loss-lb:0.0715, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:11:38.530] iteration:19996  t-loss:0.1393, loss-lb:0.0778, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:11:38.723] iteration:19997  t-loss:0.1390, loss-lb:0.0752, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:11:38.915] iteration:19998  t-loss:0.1415, loss-lb:0.0754, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:11:39.108] iteration:19999  t-loss:0.1410, loss-lb:0.0755, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:11:39.300] iteration:20000  t-loss:0.1439, loss-lb:0.0764, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:11:39.493] iteration:20001  t-loss:0.1388, loss-lb:0.0760, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:11:39.686] iteration:20002  t-loss:0.1458, loss-lb:0.0855, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:11:39.879] iteration:20003  t-loss:0.1989, loss-lb:0.0850, loss-ulb:0.0570, weight:2.00, lr:0.0004
[12:11:40.071] iteration:20004  t-loss:0.1342, loss-lb:0.0712, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:11:40.264] iteration:20005  t-loss:0.1384, loss-lb:0.0757, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:11:40.457] iteration:20006  t-loss:0.1697, loss-lb:0.0749, loss-ulb:0.0474, weight:2.00, lr:0.0004
[12:11:40.649] iteration:20007  t-loss:0.1680, loss-lb:0.0787, loss-ulb:0.0446, weight:2.00, lr:0.0004
[12:11:40.844] iteration:20008  t-loss:0.1812, loss-lb:0.0722, loss-ulb:0.0545, weight:2.00, lr:0.0004
[12:11:41.037] iteration:20009  t-loss:0.2160, loss-lb:0.0798, loss-ulb:0.0681, weight:2.00, lr:0.0004
[12:11:41.229] iteration:20010  t-loss:0.1403, loss-lb:0.0731, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:11:41.423] iteration:20011  t-loss:0.1746, loss-lb:0.0835, loss-ulb:0.0455, weight:2.00, lr:0.0004
[12:11:41.615] iteration:20012  t-loss:0.1397, loss-lb:0.0721, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:11:41.809] iteration:20013  t-loss:0.1445, loss-lb:0.0779, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:11:42.001] iteration:20014  t-loss:0.1773, loss-lb:0.0811, loss-ulb:0.0481, weight:2.00, lr:0.0004
[12:11:42.193] iteration:20015  t-loss:0.1594, loss-lb:0.0988, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:11:42.387] iteration:20016  t-loss:0.1732, loss-lb:0.0747, loss-ulb:0.0493, weight:2.00, lr:0.0004
[12:11:42.579] iteration:20017  t-loss:0.1576, loss-lb:0.0838, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:11:42.770] iteration:20018  t-loss:0.1389, loss-lb:0.0754, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:11:42.963] iteration:20019  t-loss:0.1309, loss-lb:0.0721, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:11:43.156] iteration:20020  t-loss:0.1527, loss-lb:0.0849, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:11:43.348] iteration:20021  t-loss:0.1436, loss-lb:0.0743, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:11:43.541] iteration:20022  t-loss:0.1396, loss-lb:0.0716, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:11:43.734] iteration:20023  t-loss:0.1669, loss-lb:0.0775, loss-ulb:0.0447, weight:2.00, lr:0.0004
[12:11:43.927] iteration:20024  t-loss:0.1479, loss-lb:0.0804, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:11:44.119] iteration:20025  t-loss:0.1479, loss-lb:0.0849, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:11:44.312] iteration:20026  t-loss:0.1334, loss-lb:0.0691, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:11:44.505] iteration:20027  t-loss:0.1450, loss-lb:0.0835, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:11:44.698] iteration:20028  t-loss:0.1316, loss-lb:0.0768, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:11:44.890] iteration:20029  t-loss:0.1490, loss-lb:0.0753, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:11:45.084] iteration:20030  t-loss:0.1423, loss-lb:0.0763, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:11:45.277] iteration:20031  t-loss:0.1423, loss-lb:0.0753, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:11:45.469] iteration:20032  t-loss:0.1486, loss-lb:0.0855, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:11:45.662] iteration:20033  t-loss:0.1576, loss-lb:0.0862, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:11:45.856] iteration:20034  t-loss:0.1545, loss-lb:0.0818, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:11:46.047] iteration:20035  t-loss:0.1566, loss-lb:0.0807, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:11:46.239] iteration:20036  t-loss:0.1303, loss-lb:0.0723, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:11:46.432] iteration:20037  t-loss:0.1406, loss-lb:0.0718, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:11:46.625] iteration:20038  t-loss:0.1415, loss-lb:0.0774, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:11:46.818] iteration:20039  t-loss:0.1316, loss-lb:0.0715, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:11:47.010] iteration:20040  t-loss:0.1514, loss-lb:0.0725, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:11:47.202] iteration:20041  t-loss:0.1590, loss-lb:0.0944, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:11:47.395] iteration:20042  t-loss:0.1430, loss-lb:0.0830, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:11:47.587] iteration:20043  t-loss:0.1289, loss-lb:0.0694, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:11:47.779] iteration:20044  t-loss:0.1330, loss-lb:0.0763, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:11:47.972] iteration:20045  t-loss:0.1385, loss-lb:0.0687, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:11:48.165] iteration:20046  t-loss:0.1922, loss-lb:0.0761, loss-ulb:0.0580, weight:2.00, lr:0.0004
[12:11:48.358] iteration:20047  t-loss:0.1434, loss-lb:0.0773, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:11:48.551] iteration:20048  t-loss:0.1596, loss-lb:0.0721, loss-ulb:0.0437, weight:2.00, lr:0.0004
[12:11:48.744] iteration:20049  t-loss:0.1707, loss-lb:0.0959, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:11:48.938] iteration:20050  t-loss:0.1369, loss-lb:0.0779, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:11:49.132] iteration:20051  t-loss:0.1514, loss-lb:0.0780, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:11:49.324] iteration:20052  t-loss:0.1488, loss-lb:0.0799, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:11:49.517] iteration:20053  t-loss:0.1808, loss-lb:0.0688, loss-ulb:0.0560, weight:2.00, lr:0.0004
[12:11:49.710] iteration:20054  t-loss:0.1332, loss-lb:0.0778, loss-ulb:0.0277, weight:2.00, lr:0.0004
[12:11:49.903] iteration:20055  t-loss:0.1697, loss-lb:0.0837, loss-ulb:0.0430, weight:2.00, lr:0.0004
[12:11:50.095] iteration:20056  t-loss:0.1623, loss-lb:0.0713, loss-ulb:0.0455, weight:2.00, lr:0.0004
[12:11:50.288] iteration:20057  t-loss:0.1347, loss-lb:0.0746, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:11:50.481] iteration:20058  t-loss:0.1563, loss-lb:0.0798, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:11:50.673] iteration:20059  t-loss:0.1548, loss-lb:0.0832, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:11:50.866] iteration:20060  t-loss:0.1687, loss-lb:0.0789, loss-ulb:0.0449, weight:2.00, lr:0.0004
[12:11:51.060] iteration:20061  t-loss:0.1390, loss-lb:0.0749, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:11:51.254] iteration:20062  t-loss:0.1652, loss-lb:0.0824, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:11:51.445] iteration:20063  t-loss:0.1435, loss-lb:0.0775, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:11:51.637] iteration:20064  t-loss:0.1532, loss-lb:0.0876, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:11:51.831] iteration:20065  t-loss:0.1813, loss-lb:0.0747, loss-ulb:0.0533, weight:2.00, lr:0.0004
[12:11:52.024] iteration:20066  t-loss:0.1507, loss-lb:0.0762, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:11:52.217] iteration:20067  t-loss:0.1345, loss-lb:0.0704, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:11:52.410] iteration:20068  t-loss:0.1441, loss-lb:0.0843, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:11:52.603] iteration:20069  t-loss:0.1628, loss-lb:0.0841, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:11:52.797] iteration:20070  t-loss:0.1689, loss-lb:0.0972, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:11:52.989] iteration:20071  t-loss:0.1364, loss-lb:0.0812, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:11:53.182] iteration:20072  t-loss:0.1550, loss-lb:0.0827, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:11:53.375] iteration:20073  t-loss:0.1461, loss-lb:0.0714, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:11:53.570] iteration:20074  t-loss:0.1455, loss-lb:0.0859, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:11:53.764] iteration:20075  t-loss:0.2463, loss-lb:0.0744, loss-ulb:0.0860, weight:2.00, lr:0.0004
[12:11:53.956] iteration:20076  t-loss:0.1493, loss-lb:0.0745, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:11:54.149] iteration:20077  t-loss:0.1443, loss-lb:0.0784, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:11:54.343] iteration:20078  t-loss:0.1415, loss-lb:0.0758, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:11:54.537] iteration:20079  t-loss:0.1450, loss-lb:0.0788, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:11:54.729] iteration:20080  t-loss:0.1363, loss-lb:0.0718, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:11:54.921] iteration:20081  t-loss:0.1658, loss-lb:0.0885, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:11:55.113] iteration:20082  t-loss:0.1366, loss-lb:0.0731, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:11:55.304] iteration:20083  t-loss:0.1548, loss-lb:0.0772, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:11:55.496] iteration:20084  t-loss:0.1429, loss-lb:0.0804, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:11:55.686] iteration:20085  t-loss:0.1608, loss-lb:0.0780, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:11:55.877] iteration:20086  t-loss:0.1442, loss-lb:0.0763, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:11:56.067] iteration:20087  t-loss:0.1397, loss-lb:0.0755, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:11:56.259] iteration:20088  t-loss:0.1428, loss-lb:0.0738, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:11:56.451] iteration:20089  t-loss:0.1375, loss-lb:0.0757, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:11:56.641] iteration:20090  t-loss:0.1403, loss-lb:0.0804, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:12:09.017]  <<Test>> - Ep:204  - mean_dice/mean_h95 - S:89.77/1.42, Best-S:90.99, T:89.69/1.38, Best-T:90.48
[12:12:09.018]           - AvgLoss(lb/ulb/all):0.0782/0.0364/0.1505
[12:12:09.567] iteration:20091  t-loss:0.1537, loss-lb:0.0783, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:12:09.764] iteration:20092  t-loss:0.1449, loss-lb:0.0836, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:12:09.956] iteration:20093  t-loss:0.1623, loss-lb:0.0743, loss-ulb:0.0440, weight:2.00, lr:0.0004
[12:12:10.147] iteration:20094  t-loss:0.1447, loss-lb:0.0792, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:12:10.340] iteration:20095  t-loss:0.1428, loss-lb:0.0760, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:12:10.534] iteration:20096  t-loss:0.1430, loss-lb:0.0732, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:12:10.727] iteration:20097  t-loss:0.1354, loss-lb:0.0754, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:12:10.918] iteration:20098  t-loss:0.1463, loss-lb:0.0760, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:12:11.110] iteration:20099  t-loss:0.1275, loss-lb:0.0753, loss-ulb:0.0261, weight:2.00, lr:0.0004
[12:12:11.303] iteration:20100  t-loss:0.1488, loss-lb:0.0720, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:12:11.496] iteration:20101  t-loss:0.1435, loss-lb:0.0740, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:12:11.689] iteration:20102  t-loss:0.1381, loss-lb:0.0748, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:12:11.882] iteration:20103  t-loss:0.1555, loss-lb:0.0810, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:12:12.074] iteration:20104  t-loss:0.1423, loss-lb:0.0772, loss-ulb:0.0325, weight:2.00, lr:0.0004
[12:12:12.266] iteration:20105  t-loss:0.1425, loss-lb:0.0728, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:12:12.459] iteration:20106  t-loss:0.1308, loss-lb:0.0723, loss-ulb:0.0293, weight:2.00, lr:0.0004
[12:12:12.650] iteration:20107  t-loss:0.1383, loss-lb:0.0726, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:12:12.842] iteration:20108  t-loss:0.1422, loss-lb:0.0804, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:12:13.035] iteration:20109  t-loss:0.1476, loss-lb:0.0796, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:12:13.226] iteration:20110  t-loss:0.1315, loss-lb:0.0680, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:12:13.419] iteration:20111  t-loss:0.1471, loss-lb:0.0752, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:12:13.612] iteration:20112  t-loss:0.1557, loss-lb:0.0785, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:12:13.804] iteration:20113  t-loss:0.1371, loss-lb:0.0773, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:12:13.995] iteration:20114  t-loss:0.1310, loss-lb:0.0704, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:12:14.189] iteration:20115  t-loss:0.1525, loss-lb:0.0748, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:12:14.380] iteration:20116  t-loss:0.1588, loss-lb:0.0736, loss-ulb:0.0426, weight:2.00, lr:0.0004
[12:12:14.573] iteration:20117  t-loss:0.1408, loss-lb:0.0771, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:12:14.767] iteration:20118  t-loss:0.1433, loss-lb:0.0773, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:12:14.964] iteration:20119  t-loss:0.1499, loss-lb:0.0790, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:12:15.159] iteration:20120  t-loss:0.1590, loss-lb:0.0761, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:12:15.353] iteration:20121  t-loss:0.1366, loss-lb:0.0760, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:12:15.547] iteration:20122  t-loss:0.1305, loss-lb:0.0769, loss-ulb:0.0268, weight:2.00, lr:0.0004
[12:12:15.740] iteration:20123  t-loss:0.1549, loss-lb:0.0712, loss-ulb:0.0419, weight:2.00, lr:0.0004
[12:12:15.931] iteration:20124  t-loss:0.1315, loss-lb:0.0753, loss-ulb:0.0281, weight:2.00, lr:0.0004
[12:12:16.123] iteration:20125  t-loss:0.1236, loss-lb:0.0687, loss-ulb:0.0275, weight:2.00, lr:0.0004
[12:12:16.316] iteration:20126  t-loss:0.1599, loss-lb:0.0791, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:12:16.508] iteration:20127  t-loss:0.1559, loss-lb:0.0782, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:12:16.700] iteration:20128  t-loss:0.1378, loss-lb:0.0779, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:12:16.891] iteration:20129  t-loss:0.1345, loss-lb:0.0747, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:12:17.083] iteration:20130  t-loss:0.1474, loss-lb:0.0760, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:12:17.275] iteration:20131  t-loss:0.1523, loss-lb:0.0809, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:12:17.468] iteration:20132  t-loss:0.2790, loss-lb:0.0859, loss-ulb:0.0965, weight:2.00, lr:0.0004
[12:12:17.661] iteration:20133  t-loss:0.1550, loss-lb:0.0751, loss-ulb:0.0399, weight:2.00, lr:0.0004
[12:12:17.854] iteration:20134  t-loss:0.1624, loss-lb:0.0724, loss-ulb:0.0450, weight:2.00, lr:0.0004
[12:12:18.047] iteration:20135  t-loss:0.1395, loss-lb:0.0718, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:12:18.238] iteration:20136  t-loss:0.1496, loss-lb:0.0783, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:12:18.431] iteration:20137  t-loss:0.1452, loss-lb:0.0685, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:12:18.623] iteration:20138  t-loss:0.1508, loss-lb:0.0723, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:12:18.815] iteration:20139  t-loss:0.1601, loss-lb:0.0785, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:12:19.008] iteration:20140  t-loss:0.1330, loss-lb:0.0706, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:12:19.201] iteration:20141  t-loss:0.1681, loss-lb:0.0747, loss-ulb:0.0467, weight:2.00, lr:0.0004
[12:12:19.393] iteration:20142  t-loss:0.2239, loss-lb:0.0852, loss-ulb:0.0693, weight:2.00, lr:0.0004
[12:12:19.585] iteration:20143  t-loss:0.1421, loss-lb:0.0751, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:12:19.777] iteration:20144  t-loss:0.1375, loss-lb:0.0719, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:12:19.968] iteration:20145  t-loss:0.1366, loss-lb:0.0724, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:12:20.161] iteration:20146  t-loss:0.1405, loss-lb:0.0799, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:12:20.354] iteration:20147  t-loss:0.1385, loss-lb:0.0790, loss-ulb:0.0298, weight:2.00, lr:0.0004
[12:12:20.548] iteration:20148  t-loss:0.1282, loss-lb:0.0724, loss-ulb:0.0279, weight:2.00, lr:0.0004
[12:12:20.740] iteration:20149  t-loss:0.1394, loss-lb:0.0762, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:12:20.932] iteration:20150  t-loss:0.1495, loss-lb:0.0765, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:12:21.124] iteration:20151  t-loss:0.1487, loss-lb:0.0796, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:12:21.315] iteration:20152  t-loss:0.1517, loss-lb:0.0760, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:12:21.507] iteration:20153  t-loss:0.1404, loss-lb:0.0762, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:12:21.700] iteration:20154  t-loss:0.1269, loss-lb:0.0701, loss-ulb:0.0284, weight:2.00, lr:0.0004
[12:12:21.891] iteration:20155  t-loss:0.1486, loss-lb:0.0803, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:12:22.084] iteration:20156  t-loss:0.1491, loss-lb:0.0779, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:12:22.276] iteration:20157  t-loss:0.1547, loss-lb:0.0813, loss-ulb:0.0367, weight:2.00, lr:0.0004
[12:12:22.468] iteration:20158  t-loss:0.1375, loss-lb:0.0719, loss-ulb:0.0328, weight:2.00, lr:0.0004
[12:12:22.660] iteration:20159  t-loss:0.1345, loss-lb:0.0772, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:12:22.851] iteration:20160  t-loss:0.1351, loss-lb:0.0680, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:12:23.043] iteration:20161  t-loss:0.1412, loss-lb:0.0726, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:12:23.236] iteration:20162  t-loss:0.1512, loss-lb:0.0820, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:12:23.427] iteration:20163  t-loss:0.1465, loss-lb:0.0792, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:12:23.619] iteration:20164  t-loss:0.1515, loss-lb:0.0716, loss-ulb:0.0399, weight:2.00, lr:0.0004
[12:12:23.810] iteration:20165  t-loss:0.1621, loss-lb:0.0811, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:12:24.001] iteration:20166  t-loss:0.1411, loss-lb:0.0757, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:12:24.193] iteration:20167  t-loss:0.1609, loss-lb:0.0850, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:12:24.388] iteration:20168  t-loss:0.2982, loss-lb:0.0737, loss-ulb:0.1123, weight:2.00, lr:0.0004
[12:12:24.579] iteration:20169  t-loss:0.1484, loss-lb:0.0809, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:12:24.772] iteration:20170  t-loss:0.1392, loss-lb:0.0702, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:12:24.964] iteration:20171  t-loss:0.1419, loss-lb:0.0679, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:12:25.154] iteration:20172  t-loss:0.1465, loss-lb:0.0780, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:12:25.348] iteration:20173  t-loss:0.2210, loss-lb:0.0774, loss-ulb:0.0718, weight:2.00, lr:0.0004
[12:12:25.542] iteration:20174  t-loss:0.1423, loss-lb:0.0737, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:12:25.737] iteration:20175  t-loss:0.1483, loss-lb:0.0714, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:12:25.934] iteration:20176  t-loss:0.1430, loss-lb:0.0771, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:12:26.130] iteration:20177  t-loss:0.1496, loss-lb:0.0801, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:12:26.323] iteration:20178  t-loss:0.1336, loss-lb:0.0675, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:12:26.516] iteration:20179  t-loss:0.1710, loss-lb:0.0782, loss-ulb:0.0464, weight:2.00, lr:0.0004
[12:12:26.708] iteration:20180  t-loss:0.2103, loss-lb:0.0785, loss-ulb:0.0659, weight:2.00, lr:0.0004
[12:12:26.901] iteration:20181  t-loss:0.1561, loss-lb:0.0783, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:12:27.091] iteration:20182  t-loss:0.1485, loss-lb:0.0809, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:12:27.281] iteration:20183  t-loss:0.1426, loss-lb:0.0749, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:12:27.472] iteration:20184  t-loss:0.1446, loss-lb:0.0787, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:12:27.664] iteration:20185  t-loss:0.1339, loss-lb:0.0738, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:12:27.854] iteration:20186  t-loss:0.1478, loss-lb:0.0767, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:12:28.045] iteration:20187  t-loss:0.1473, loss-lb:0.0715, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:12:28.236] iteration:20188  t-loss:0.1320, loss-lb:0.0777, loss-ulb:0.0272, weight:2.00, lr:0.0004
[12:12:28.841] iteration:20189  t-loss:0.1383, loss-lb:0.0795, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:12:29.037] iteration:20190  t-loss:0.1679, loss-lb:0.0780, loss-ulb:0.0449, weight:2.00, lr:0.0004
[12:12:29.230] iteration:20191  t-loss:0.1567, loss-lb:0.0718, loss-ulb:0.0425, weight:2.00, lr:0.0004
[12:12:29.423] iteration:20192  t-loss:0.1409, loss-lb:0.0802, loss-ulb:0.0303, weight:2.00, lr:0.0004
[12:12:29.614] iteration:20193  t-loss:0.1405, loss-lb:0.0800, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:12:29.806] iteration:20194  t-loss:0.1534, loss-lb:0.0803, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:12:29.997] iteration:20195  t-loss:0.1467, loss-lb:0.0819, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:12:30.189] iteration:20196  t-loss:0.1333, loss-lb:0.0672, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:12:30.381] iteration:20197  t-loss:0.1258, loss-lb:0.0668, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:12:30.573] iteration:20198  t-loss:0.1471, loss-lb:0.0723, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:12:30.765] iteration:20199  t-loss:0.1545, loss-lb:0.0786, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:12:30.958] iteration:20200  t-loss:0.1674, loss-lb:0.0799, loss-ulb:0.0437, weight:2.00, lr:0.0004
[12:12:31.150] iteration:20201  t-loss:0.1355, loss-lb:0.0728, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:12:31.342] iteration:20202  t-loss:0.1493, loss-lb:0.0864, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:12:31.535] iteration:20203  t-loss:0.1506, loss-lb:0.0749, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:12:31.726] iteration:20204  t-loss:0.1448, loss-lb:0.0747, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:12:31.918] iteration:20205  t-loss:0.1530, loss-lb:0.0823, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:12:32.109] iteration:20206  t-loss:0.1478, loss-lb:0.0730, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:12:32.303] iteration:20207  t-loss:0.1282, loss-lb:0.0746, loss-ulb:0.0268, weight:2.00, lr:0.0004
[12:12:32.494] iteration:20208  t-loss:0.1447, loss-lb:0.0754, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:12:32.689] iteration:20209  t-loss:0.1627, loss-lb:0.0831, loss-ulb:0.0398, weight:2.00, lr:0.0004
[12:12:32.882] iteration:20210  t-loss:0.1940, loss-lb:0.0767, loss-ulb:0.0586, weight:2.00, lr:0.0004
[12:12:33.074] iteration:20211  t-loss:0.1470, loss-lb:0.0734, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:12:33.266] iteration:20212  t-loss:0.1394, loss-lb:0.0732, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:12:33.458] iteration:20213  t-loss:0.1412, loss-lb:0.0793, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:12:33.650] iteration:20214  t-loss:0.1430, loss-lb:0.0722, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:12:33.854] iteration:20215  t-loss:0.1464, loss-lb:0.0739, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:12:34.054] iteration:20216  t-loss:0.1421, loss-lb:0.0753, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:12:34.249] iteration:20217  t-loss:0.1371, loss-lb:0.0697, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:12:34.441] iteration:20218  t-loss:0.1394, loss-lb:0.0764, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:12:34.632] iteration:20219  t-loss:0.1473, loss-lb:0.0732, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:12:34.823] iteration:20220  t-loss:0.1630, loss-lb:0.0825, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:12:35.015] iteration:20221  t-loss:0.1469, loss-lb:0.0837, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:12:35.206] iteration:20222  t-loss:0.1432, loss-lb:0.0786, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:12:35.398] iteration:20223  t-loss:0.1396, loss-lb:0.0814, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:12:35.589] iteration:20224  t-loss:0.1392, loss-lb:0.0692, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:12:35.781] iteration:20225  t-loss:0.1712, loss-lb:0.0685, loss-ulb:0.0513, weight:2.00, lr:0.0004
[12:12:35.972] iteration:20226  t-loss:0.1514, loss-lb:0.0790, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:12:36.163] iteration:20227  t-loss:0.1391, loss-lb:0.0755, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:12:36.356] iteration:20228  t-loss:0.1416, loss-lb:0.0745, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:12:36.550] iteration:20229  t-loss:0.1432, loss-lb:0.0818, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:12:36.747] iteration:20230  t-loss:0.1348, loss-lb:0.0747, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:12:36.941] iteration:20231  t-loss:0.1517, loss-lb:0.0761, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:12:37.137] iteration:20232  t-loss:0.1375, loss-lb:0.0749, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:12:37.330] iteration:20233  t-loss:0.1472, loss-lb:0.0721, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:12:37.521] iteration:20234  t-loss:0.1311, loss-lb:0.0720, loss-ulb:0.0296, weight:2.00, lr:0.0004
[12:12:37.714] iteration:20235  t-loss:0.1474, loss-lb:0.0731, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:12:37.907] iteration:20236  t-loss:0.1335, loss-lb:0.0700, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:12:38.099] iteration:20237  t-loss:0.1548, loss-lb:0.0801, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:12:38.291] iteration:20238  t-loss:0.1349, loss-lb:0.0716, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:12:38.483] iteration:20239  t-loss:0.1381, loss-lb:0.0704, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:12:38.677] iteration:20240  t-loss:0.1544, loss-lb:0.0780, loss-ulb:0.0382, weight:2.00, lr:0.0004
[12:12:38.868] iteration:20241  t-loss:0.1289, loss-lb:0.0688, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:12:39.062] iteration:20242  t-loss:0.2208, loss-lb:0.0797, loss-ulb:0.0706, weight:2.00, lr:0.0004
[12:12:39.255] iteration:20243  t-loss:0.1564, loss-lb:0.0712, loss-ulb:0.0426, weight:2.00, lr:0.0004
[12:12:39.447] iteration:20244  t-loss:0.1404, loss-lb:0.0763, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:12:39.641] iteration:20245  t-loss:0.2171, loss-lb:0.0800, loss-ulb:0.0685, weight:2.00, lr:0.0004
[12:12:39.833] iteration:20246  t-loss:0.1418, loss-lb:0.0773, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:12:40.026] iteration:20247  t-loss:0.1465, loss-lb:0.0801, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:12:40.218] iteration:20248  t-loss:0.1695, loss-lb:0.0831, loss-ulb:0.0432, weight:2.00, lr:0.0004
[12:12:40.410] iteration:20249  t-loss:0.1403, loss-lb:0.0722, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:12:40.601] iteration:20250  t-loss:0.1265, loss-lb:0.0686, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:12:40.792] iteration:20251  t-loss:0.1582, loss-lb:0.0784, loss-ulb:0.0399, weight:2.00, lr:0.0004
[12:12:40.985] iteration:20252  t-loss:0.1426, loss-lb:0.0836, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:12:41.176] iteration:20253  t-loss:0.1368, loss-lb:0.0780, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:12:41.368] iteration:20254  t-loss:0.1420, loss-lb:0.0790, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:12:41.561] iteration:20255  t-loss:0.1409, loss-lb:0.0740, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:12:41.752] iteration:20256  t-loss:0.1476, loss-lb:0.0721, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:12:41.945] iteration:20257  t-loss:0.1679, loss-lb:0.0719, loss-ulb:0.0480, weight:2.00, lr:0.0004
[12:12:42.136] iteration:20258  t-loss:0.1387, loss-lb:0.0726, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:12:42.327] iteration:20259  t-loss:0.1407, loss-lb:0.0807, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:12:42.520] iteration:20260  t-loss:0.1485, loss-lb:0.0717, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:12:42.712] iteration:20261  t-loss:0.1647, loss-lb:0.0881, loss-ulb:0.0383, weight:2.00, lr:0.0004
[12:12:42.904] iteration:20262  t-loss:0.1322, loss-lb:0.0739, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:12:43.095] iteration:20263  t-loss:0.1528, loss-lb:0.0755, loss-ulb:0.0386, weight:2.00, lr:0.0004
[12:12:43.287] iteration:20264  t-loss:0.1570, loss-lb:0.0857, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:12:43.480] iteration:20265  t-loss:0.1411, loss-lb:0.0780, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:12:43.672] iteration:20266  t-loss:0.1541, loss-lb:0.0873, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:12:43.863] iteration:20267  t-loss:0.1413, loss-lb:0.0792, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:12:44.055] iteration:20268  t-loss:0.1673, loss-lb:0.0810, loss-ulb:0.0432, weight:2.00, lr:0.0004
[12:12:44.247] iteration:20269  t-loss:0.1223, loss-lb:0.0662, loss-ulb:0.0280, weight:2.00, lr:0.0004
[12:12:44.438] iteration:20270  t-loss:0.1445, loss-lb:0.0765, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:12:44.629] iteration:20271  t-loss:0.1579, loss-lb:0.0843, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:12:44.820] iteration:20272  t-loss:0.1626, loss-lb:0.0750, loss-ulb:0.0438, weight:2.00, lr:0.0004
[12:12:45.013] iteration:20273  t-loss:0.1386, loss-lb:0.0694, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:12:45.206] iteration:20274  t-loss:0.2109, loss-lb:0.0742, loss-ulb:0.0683, weight:2.00, lr:0.0004
[12:12:45.397] iteration:20275  t-loss:0.1476, loss-lb:0.0832, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:12:45.588] iteration:20276  t-loss:0.1347, loss-lb:0.0695, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:12:45.780] iteration:20277  t-loss:0.1445, loss-lb:0.0774, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:12:45.972] iteration:20278  t-loss:0.1691, loss-lb:0.0848, loss-ulb:0.0422, weight:2.00, lr:0.0004
[12:12:46.162] iteration:20279  t-loss:0.1450, loss-lb:0.0806, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:12:46.351] iteration:20280  t-loss:0.1668, loss-lb:0.0756, loss-ulb:0.0456, weight:2.00, lr:0.0004
[12:12:46.541] iteration:20281  t-loss:0.2000, loss-lb:0.0862, loss-ulb:0.0569, weight:2.00, lr:0.0004
[12:12:46.731] iteration:20282  t-loss:0.1446, loss-lb:0.0811, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:12:46.921] iteration:20283  t-loss:0.1701, loss-lb:0.0654, loss-ulb:0.0523, weight:2.00, lr:0.0004
[12:12:47.113] iteration:20284  t-loss:0.1520, loss-lb:0.0770, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:12:47.303] iteration:20285  t-loss:0.1525, loss-lb:0.0737, loss-ulb:0.0394, weight:2.00, lr:0.0004
[12:12:47.495] iteration:20286  t-loss:0.2087, loss-lb:0.0728, loss-ulb:0.0680, weight:2.00, lr:0.0004
[12:12:59.939]  <<Test>> - Ep:206  - mean_dice/mean_h95 - S:89.52/1.99, Best-S:90.99, T:89.64/1.40, Best-T:90.48
[12:12:59.940]           - AvgLoss(lb/ulb/all):0.0764/0.0412/0.1590
[12:13:00.466] iteration:20287  t-loss:0.1538, loss-lb:0.0793, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:13:00.665] iteration:20288  t-loss:0.1356, loss-lb:0.0735, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:13:00.859] iteration:20289  t-loss:0.1520, loss-lb:0.0744, loss-ulb:0.0388, weight:2.00, lr:0.0004
[12:13:01.053] iteration:20290  t-loss:0.1413, loss-lb:0.0815, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:13:01.246] iteration:20291  t-loss:0.1381, loss-lb:0.0798, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:13:01.439] iteration:20292  t-loss:0.1562, loss-lb:0.0836, loss-ulb:0.0363, weight:2.00, lr:0.0004
[12:13:01.634] iteration:20293  t-loss:0.2054, loss-lb:0.0794, loss-ulb:0.0630, weight:2.00, lr:0.0004
[12:13:01.826] iteration:20294  t-loss:0.1526, loss-lb:0.0730, loss-ulb:0.0398, weight:2.00, lr:0.0004
[12:13:02.019] iteration:20295  t-loss:0.1439, loss-lb:0.0816, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:13:02.212] iteration:20296  t-loss:0.1340, loss-lb:0.0731, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:13:02.406] iteration:20297  t-loss:0.1407, loss-lb:0.0724, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:13:02.598] iteration:20298  t-loss:0.1410, loss-lb:0.0716, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:13:02.791] iteration:20299  t-loss:0.1311, loss-lb:0.0709, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:13:02.984] iteration:20300  t-loss:0.1561, loss-lb:0.0761, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:13:03.177] iteration:20301  t-loss:0.1403, loss-lb:0.0770, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:13:03.370] iteration:20302  t-loss:0.1355, loss-lb:0.0686, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:13:03.564] iteration:20303  t-loss:0.2099, loss-lb:0.0953, loss-ulb:0.0573, weight:2.00, lr:0.0004
[12:13:03.757] iteration:20304  t-loss:0.1460, loss-lb:0.0759, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:13:03.951] iteration:20305  t-loss:0.1765, loss-lb:0.0835, loss-ulb:0.0465, weight:2.00, lr:0.0004
[12:13:04.142] iteration:20306  t-loss:0.1424, loss-lb:0.0759, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:13:04.336] iteration:20307  t-loss:0.1638, loss-lb:0.0845, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:13:04.529] iteration:20308  t-loss:0.1438, loss-lb:0.0801, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:13:04.722] iteration:20309  t-loss:0.1383, loss-lb:0.0804, loss-ulb:0.0290, weight:2.00, lr:0.0004
[12:13:04.916] iteration:20310  t-loss:0.1341, loss-lb:0.0706, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:13:05.110] iteration:20311  t-loss:0.2208, loss-lb:0.0767, loss-ulb:0.0721, weight:2.00, lr:0.0004
[12:13:05.303] iteration:20312  t-loss:0.2120, loss-lb:0.0769, loss-ulb:0.0675, weight:2.00, lr:0.0004
[12:13:05.498] iteration:20313  t-loss:0.3442, loss-lb:0.0836, loss-ulb:0.1303, weight:2.00, lr:0.0004
[12:13:05.691] iteration:20314  t-loss:0.1355, loss-lb:0.0719, loss-ulb:0.0318, weight:2.00, lr:0.0004
[12:13:05.884] iteration:20315  t-loss:0.1433, loss-lb:0.0748, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:13:06.076] iteration:20316  t-loss:0.1636, loss-lb:0.0850, loss-ulb:0.0393, weight:2.00, lr:0.0004
[12:13:06.268] iteration:20317  t-loss:0.1534, loss-lb:0.0717, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:13:06.460] iteration:20318  t-loss:0.1303, loss-lb:0.0756, loss-ulb:0.0273, weight:2.00, lr:0.0004
[12:13:06.667] iteration:20319  t-loss:0.1516, loss-lb:0.0770, loss-ulb:0.0373, weight:2.00, lr:0.0004
[12:13:06.867] iteration:20320  t-loss:0.1499, loss-lb:0.0748, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:13:07.062] iteration:20321  t-loss:0.1485, loss-lb:0.0725, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:13:07.255] iteration:20322  t-loss:0.1569, loss-lb:0.0880, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:13:07.447] iteration:20323  t-loss:0.1521, loss-lb:0.0728, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:13:07.640] iteration:20324  t-loss:0.1785, loss-lb:0.0768, loss-ulb:0.0508, weight:2.00, lr:0.0004
[12:13:07.833] iteration:20325  t-loss:0.1436, loss-lb:0.0817, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:13:08.024] iteration:20326  t-loss:0.1694, loss-lb:0.0774, loss-ulb:0.0460, weight:2.00, lr:0.0004
[12:13:08.217] iteration:20327  t-loss:0.1495, loss-lb:0.0758, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:13:08.411] iteration:20328  t-loss:0.1758, loss-lb:0.0748, loss-ulb:0.0505, weight:2.00, lr:0.0004
[12:13:08.604] iteration:20329  t-loss:0.1328, loss-lb:0.0739, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:13:08.798] iteration:20330  t-loss:0.1514, loss-lb:0.0770, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:13:08.990] iteration:20331  t-loss:0.1602, loss-lb:0.0796, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:13:09.182] iteration:20332  t-loss:0.1647, loss-lb:0.0756, loss-ulb:0.0446, weight:2.00, lr:0.0004
[12:13:09.375] iteration:20333  t-loss:0.1236, loss-lb:0.0708, loss-ulb:0.0264, weight:2.00, lr:0.0004
[12:13:09.566] iteration:20334  t-loss:0.1573, loss-lb:0.0757, loss-ulb:0.0408, weight:2.00, lr:0.0004
[12:13:09.760] iteration:20335  t-loss:0.1613, loss-lb:0.0924, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:13:09.954] iteration:20336  t-loss:0.1420, loss-lb:0.0804, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:13:10.146] iteration:20337  t-loss:0.1426, loss-lb:0.0769, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:13:10.338] iteration:20338  t-loss:0.1376, loss-lb:0.0841, loss-ulb:0.0268, weight:2.00, lr:0.0004
[12:13:10.531] iteration:20339  t-loss:0.1385, loss-lb:0.0752, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:13:10.723] iteration:20340  t-loss:0.1749, loss-lb:0.0773, loss-ulb:0.0488, weight:2.00, lr:0.0004
[12:13:10.915] iteration:20341  t-loss:0.1454, loss-lb:0.0731, loss-ulb:0.0361, weight:2.00, lr:0.0004
[12:13:11.107] iteration:20342  t-loss:0.1675, loss-lb:0.0795, loss-ulb:0.0440, weight:2.00, lr:0.0004
[12:13:11.300] iteration:20343  t-loss:0.1477, loss-lb:0.0806, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:13:11.493] iteration:20344  t-loss:0.1385, loss-lb:0.0703, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:13:11.687] iteration:20345  t-loss:0.2008, loss-lb:0.0890, loss-ulb:0.0559, weight:2.00, lr:0.0004
[12:13:11.879] iteration:20346  t-loss:0.1749, loss-lb:0.0823, loss-ulb:0.0463, weight:2.00, lr:0.0004
[12:13:12.072] iteration:20347  t-loss:0.1757, loss-lb:0.0755, loss-ulb:0.0501, weight:2.00, lr:0.0004
[12:13:12.267] iteration:20348  t-loss:0.1520, loss-lb:0.0719, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:13:12.459] iteration:20349  t-loss:0.1457, loss-lb:0.0758, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:13:12.651] iteration:20350  t-loss:0.1429, loss-lb:0.0757, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:13:12.844] iteration:20351  t-loss:0.1513, loss-lb:0.0843, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:13:13.037] iteration:20352  t-loss:0.1564, loss-lb:0.0724, loss-ulb:0.0420, weight:2.00, lr:0.0004
[12:13:13.229] iteration:20353  t-loss:0.1876, loss-lb:0.0848, loss-ulb:0.0514, weight:2.00, lr:0.0004
[12:13:13.422] iteration:20354  t-loss:0.1843, loss-lb:0.0812, loss-ulb:0.0515, weight:2.00, lr:0.0004
[12:13:13.614] iteration:20355  t-loss:0.1398, loss-lb:0.0774, loss-ulb:0.0312, weight:2.00, lr:0.0004
[12:13:13.806] iteration:20356  t-loss:0.1257, loss-lb:0.0667, loss-ulb:0.0295, weight:2.00, lr:0.0004
[12:13:13.999] iteration:20357  t-loss:0.1333, loss-lb:0.0780, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:13:14.191] iteration:20358  t-loss:0.1463, loss-lb:0.0854, loss-ulb:0.0304, weight:2.00, lr:0.0004
[12:13:14.383] iteration:20359  t-loss:0.1886, loss-lb:0.0797, loss-ulb:0.0544, weight:2.00, lr:0.0004
[12:13:14.575] iteration:20360  t-loss:0.1536, loss-lb:0.0783, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:13:14.768] iteration:20361  t-loss:0.1549, loss-lb:0.0806, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:13:14.960] iteration:20362  t-loss:0.1571, loss-lb:0.0832, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:13:15.153] iteration:20363  t-loss:0.1395, loss-lb:0.0761, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:13:15.346] iteration:20364  t-loss:0.1401, loss-lb:0.0757, loss-ulb:0.0322, weight:2.00, lr:0.0004
[12:13:15.539] iteration:20365  t-loss:0.1318, loss-lb:0.0752, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:13:15.731] iteration:20366  t-loss:0.1464, loss-lb:0.0787, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:13:15.924] iteration:20367  t-loss:0.2622, loss-lb:0.0696, loss-ulb:0.0963, weight:2.00, lr:0.0004
[12:13:16.117] iteration:20368  t-loss:0.1877, loss-lb:0.0793, loss-ulb:0.0542, weight:2.00, lr:0.0004
[12:13:16.310] iteration:20369  t-loss:0.1523, loss-lb:0.0882, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:13:16.502] iteration:20370  t-loss:0.1582, loss-lb:0.0715, loss-ulb:0.0433, weight:2.00, lr:0.0004
[12:13:16.695] iteration:20371  t-loss:0.1529, loss-lb:0.0721, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:13:16.888] iteration:20372  t-loss:0.1746, loss-lb:0.0693, loss-ulb:0.0526, weight:2.00, lr:0.0004
[12:13:17.079] iteration:20373  t-loss:0.1709, loss-lb:0.0759, loss-ulb:0.0475, weight:2.00, lr:0.0004
[12:13:17.272] iteration:20374  t-loss:0.1541, loss-lb:0.0774, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:13:17.466] iteration:20375  t-loss:0.2114, loss-lb:0.0868, loss-ulb:0.0623, weight:2.00, lr:0.0004
[12:13:17.658] iteration:20376  t-loss:0.1734, loss-lb:0.0827, loss-ulb:0.0454, weight:2.00, lr:0.0004
[12:13:17.850] iteration:20377  t-loss:0.1644, loss-lb:0.0834, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:13:18.041] iteration:20378  t-loss:0.1545, loss-lb:0.0826, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:13:18.231] iteration:20379  t-loss:0.1629, loss-lb:0.0773, loss-ulb:0.0428, weight:2.00, lr:0.0004
[12:13:18.422] iteration:20380  t-loss:0.1390, loss-lb:0.0805, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:13:18.613] iteration:20381  t-loss:0.1386, loss-lb:0.0804, loss-ulb:0.0291, weight:2.00, lr:0.0004
[12:13:18.804] iteration:20382  t-loss:0.1500, loss-lb:0.0775, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:13:18.994] iteration:20383  t-loss:0.1287, loss-lb:0.0750, loss-ulb:0.0269, weight:2.00, lr:0.0004
[12:13:19.185] iteration:20384  t-loss:0.1778, loss-lb:0.0721, loss-ulb:0.0528, weight:2.00, lr:0.0004
[12:13:19.754] iteration:20385  t-loss:0.2380, loss-lb:0.0785, loss-ulb:0.0797, weight:2.00, lr:0.0004
[12:13:19.948] iteration:20386  t-loss:0.1382, loss-lb:0.0752, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:13:20.142] iteration:20387  t-loss:0.1419, loss-lb:0.0790, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:13:20.335] iteration:20388  t-loss:0.1483, loss-lb:0.0763, loss-ulb:0.0360, weight:2.00, lr:0.0004
[12:13:20.527] iteration:20389  t-loss:0.1456, loss-lb:0.0802, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:13:20.720] iteration:20390  t-loss:0.1575, loss-lb:0.0783, loss-ulb:0.0396, weight:2.00, lr:0.0004
[12:13:20.913] iteration:20391  t-loss:0.1745, loss-lb:0.0737, loss-ulb:0.0504, weight:2.00, lr:0.0004
[12:13:21.107] iteration:20392  t-loss:0.1681, loss-lb:0.0791, loss-ulb:0.0445, weight:2.00, lr:0.0004
[12:13:21.298] iteration:20393  t-loss:0.1566, loss-lb:0.0757, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:13:21.490] iteration:20394  t-loss:0.2014, loss-lb:0.0774, loss-ulb:0.0620, weight:2.00, lr:0.0004
[12:13:21.684] iteration:20395  t-loss:0.1515, loss-lb:0.0822, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:13:21.879] iteration:20396  t-loss:0.1571, loss-lb:0.0754, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:13:22.073] iteration:20397  t-loss:0.2193, loss-lb:0.0760, loss-ulb:0.0716, weight:2.00, lr:0.0004
[12:13:22.267] iteration:20398  t-loss:0.2083, loss-lb:0.0802, loss-ulb:0.0640, weight:2.00, lr:0.0004
[12:13:22.458] iteration:20399  t-loss:0.1439, loss-lb:0.0736, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:13:22.652] iteration:20400  t-loss:0.2382, loss-lb:0.0764, loss-ulb:0.0809, weight:2.00, lr:0.0004
[12:13:22.847] iteration:20401  t-loss:0.1691, loss-lb:0.0752, loss-ulb:0.0470, weight:2.00, lr:0.0004
[12:13:23.040] iteration:20402  t-loss:0.1561, loss-lb:0.0819, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:13:23.232] iteration:20403  t-loss:0.1519, loss-lb:0.0852, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:13:23.424] iteration:20404  t-loss:0.1984, loss-lb:0.0817, loss-ulb:0.0584, weight:2.00, lr:0.0004
[12:13:23.618] iteration:20405  t-loss:0.1510, loss-lb:0.0826, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:13:23.812] iteration:20406  t-loss:0.1647, loss-lb:0.0764, loss-ulb:0.0441, weight:2.00, lr:0.0004
[12:13:24.005] iteration:20407  t-loss:0.1556, loss-lb:0.0827, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:13:24.200] iteration:20408  t-loss:0.1471, loss-lb:0.0771, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:13:24.392] iteration:20409  t-loss:0.1443, loss-lb:0.0812, loss-ulb:0.0315, weight:2.00, lr:0.0004
[12:13:24.586] iteration:20410  t-loss:0.2188, loss-lb:0.1021, loss-ulb:0.0583, weight:2.00, lr:0.0004
[12:13:24.778] iteration:20411  t-loss:0.1568, loss-lb:0.0922, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:13:24.972] iteration:20412  t-loss:0.1515, loss-lb:0.0797, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:13:25.164] iteration:20413  t-loss:0.1582, loss-lb:0.0831, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:13:25.357] iteration:20414  t-loss:0.1694, loss-lb:0.0834, loss-ulb:0.0430, weight:2.00, lr:0.0004
[12:13:25.551] iteration:20415  t-loss:0.1402, loss-lb:0.0803, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:13:25.744] iteration:20416  t-loss:0.1486, loss-lb:0.0825, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:13:25.951] iteration:20417  t-loss:0.1403, loss-lb:0.0763, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:13:26.144] iteration:20418  t-loss:0.1785, loss-lb:0.0774, loss-ulb:0.0505, weight:2.00, lr:0.0004
[12:13:26.337] iteration:20419  t-loss:0.1376, loss-lb:0.0820, loss-ulb:0.0278, weight:2.00, lr:0.0004
[12:13:26.529] iteration:20420  t-loss:0.1541, loss-lb:0.0834, loss-ulb:0.0354, weight:2.00, lr:0.0004
[12:13:26.722] iteration:20421  t-loss:0.1443, loss-lb:0.0772, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:13:26.915] iteration:20422  t-loss:0.1605, loss-lb:0.0768, loss-ulb:0.0419, weight:2.00, lr:0.0004
[12:13:27.107] iteration:20423  t-loss:0.1785, loss-lb:0.0914, loss-ulb:0.0435, weight:2.00, lr:0.0004
[12:13:27.300] iteration:20424  t-loss:0.1507, loss-lb:0.0832, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:13:27.493] iteration:20425  t-loss:0.1620, loss-lb:0.0852, loss-ulb:0.0384, weight:2.00, lr:0.0004
[12:13:27.685] iteration:20426  t-loss:0.1498, loss-lb:0.0827, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:13:27.878] iteration:20427  t-loss:0.1485, loss-lb:0.0794, loss-ulb:0.0346, weight:2.00, lr:0.0004
[12:13:28.071] iteration:20428  t-loss:0.1509, loss-lb:0.0795, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:13:28.265] iteration:20429  t-loss:0.1558, loss-lb:0.0740, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:13:28.459] iteration:20430  t-loss:0.1570, loss-lb:0.0921, loss-ulb:0.0324, weight:2.00, lr:0.0004
[12:13:28.651] iteration:20431  t-loss:0.1466, loss-lb:0.0787, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:13:28.845] iteration:20432  t-loss:0.1657, loss-lb:0.0776, loss-ulb:0.0440, weight:2.00, lr:0.0004
[12:13:29.038] iteration:20433  t-loss:0.1598, loss-lb:0.0893, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:13:29.230] iteration:20434  t-loss:0.1397, loss-lb:0.0731, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:13:29.423] iteration:20435  t-loss:0.1914, loss-lb:0.0816, loss-ulb:0.0549, weight:2.00, lr:0.0004
[12:13:29.616] iteration:20436  t-loss:0.1466, loss-lb:0.0790, loss-ulb:0.0338, weight:2.00, lr:0.0004
[12:13:29.808] iteration:20437  t-loss:0.1463, loss-lb:0.0800, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:13:30.000] iteration:20438  t-loss:0.1704, loss-lb:0.0744, loss-ulb:0.0480, weight:2.00, lr:0.0004
[12:13:30.193] iteration:20439  t-loss:0.2969, loss-lb:0.0804, loss-ulb:0.1082, weight:2.00, lr:0.0004
[12:13:30.388] iteration:20440  t-loss:0.1976, loss-lb:0.0779, loss-ulb:0.0598, weight:2.00, lr:0.0004
[12:13:30.581] iteration:20441  t-loss:0.1481, loss-lb:0.0808, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:13:30.773] iteration:20442  t-loss:0.1471, loss-lb:0.0785, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:13:30.965] iteration:20443  t-loss:0.1496, loss-lb:0.0801, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:13:31.158] iteration:20444  t-loss:0.1380, loss-lb:0.0813, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:13:31.351] iteration:20445  t-loss:0.1417, loss-lb:0.0797, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:13:31.545] iteration:20446  t-loss:0.1522, loss-lb:0.0816, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:13:31.738] iteration:20447  t-loss:0.1571, loss-lb:0.0835, loss-ulb:0.0368, weight:2.00, lr:0.0004
[12:13:31.931] iteration:20448  t-loss:0.1439, loss-lb:0.0772, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:13:32.125] iteration:20449  t-loss:0.1468, loss-lb:0.0807, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:13:32.318] iteration:20450  t-loss:0.1535, loss-lb:0.0807, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:13:32.511] iteration:20451  t-loss:0.2234, loss-lb:0.0797, loss-ulb:0.0718, weight:2.00, lr:0.0004
[12:13:32.703] iteration:20452  t-loss:0.1557, loss-lb:0.0808, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:13:32.894] iteration:20453  t-loss:0.1608, loss-lb:0.0884, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:13:33.088] iteration:20454  t-loss:0.1403, loss-lb:0.0743, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:13:33.281] iteration:20455  t-loss:0.1485, loss-lb:0.0758, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:13:33.473] iteration:20456  t-loss:0.1655, loss-lb:0.0809, loss-ulb:0.0423, weight:2.00, lr:0.0004
[12:13:33.665] iteration:20457  t-loss:0.1416, loss-lb:0.0729, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:13:33.859] iteration:20458  t-loss:0.1487, loss-lb:0.0788, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:13:34.052] iteration:20459  t-loss:0.1771, loss-lb:0.0792, loss-ulb:0.0490, weight:2.00, lr:0.0004
[12:13:34.244] iteration:20460  t-loss:0.1478, loss-lb:0.0812, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:13:34.437] iteration:20461  t-loss:0.1432, loss-lb:0.0768, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:13:34.630] iteration:20462  t-loss:0.1436, loss-lb:0.0835, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:13:34.821] iteration:20463  t-loss:0.1532, loss-lb:0.0790, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:13:35.014] iteration:20464  t-loss:0.1508, loss-lb:0.0829, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:13:35.208] iteration:20465  t-loss:0.1540, loss-lb:0.0730, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:13:35.401] iteration:20466  t-loss:0.2005, loss-lb:0.0826, loss-ulb:0.0590, weight:2.00, lr:0.0004
[12:13:35.593] iteration:20467  t-loss:0.1593, loss-lb:0.0816, loss-ulb:0.0389, weight:2.00, lr:0.0004
[12:13:35.785] iteration:20468  t-loss:0.1344, loss-lb:0.0684, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:13:35.978] iteration:20469  t-loss:0.1418, loss-lb:0.0764, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:13:36.171] iteration:20470  t-loss:0.1500, loss-lb:0.0803, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:13:36.363] iteration:20471  t-loss:0.1460, loss-lb:0.0848, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:13:36.556] iteration:20472  t-loss:0.1655, loss-lb:0.0761, loss-ulb:0.0447, weight:2.00, lr:0.0004
[12:13:36.749] iteration:20473  t-loss:0.1503, loss-lb:0.0745, loss-ulb:0.0379, weight:2.00, lr:0.0004
[12:13:36.942] iteration:20474  t-loss:0.1708, loss-lb:0.0745, loss-ulb:0.0481, weight:2.00, lr:0.0004
[12:13:37.133] iteration:20475  t-loss:0.1448, loss-lb:0.0775, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:13:37.326] iteration:20476  t-loss:0.1399, loss-lb:0.0823, loss-ulb:0.0288, weight:2.00, lr:0.0004
[12:13:37.522] iteration:20477  t-loss:0.1546, loss-lb:0.0803, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:13:37.715] iteration:20478  t-loss:0.1609, loss-lb:0.0830, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:13:37.909] iteration:20479  t-loss:0.1822, loss-lb:0.0704, loss-ulb:0.0559, weight:2.00, lr:0.0004
[12:13:38.100] iteration:20480  t-loss:0.1483, loss-lb:0.0810, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:13:38.293] iteration:20481  t-loss:0.1559, loss-lb:0.0775, loss-ulb:0.0392, weight:2.00, lr:0.0004
[12:13:38.484] iteration:20482  t-loss:0.1486, loss-lb:0.0712, loss-ulb:0.0387, weight:2.00, lr:0.0004
[12:13:50.727]  <<Test>> - Ep:208  - mean_dice/mean_h95 - S:89.81/2.49, Best-S:90.99, T:89.67/1.38, Best-T:90.48
[12:13:50.727]           - AvgLoss(lb/ulb/all):0.0797/0.0389/0.1556
[12:13:51.270] iteration:20483  t-loss:0.1710, loss-lb:0.0778, loss-ulb:0.0466, weight:2.00, lr:0.0004
[12:13:51.470] iteration:20484  t-loss:0.1517, loss-lb:0.0802, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:13:51.663] iteration:20485  t-loss:0.1599, loss-lb:0.0762, loss-ulb:0.0418, weight:2.00, lr:0.0004
[12:13:51.856] iteration:20486  t-loss:0.1622, loss-lb:0.0916, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:13:52.048] iteration:20487  t-loss:0.1595, loss-lb:0.0789, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:13:52.240] iteration:20488  t-loss:0.1630, loss-lb:0.0926, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:13:52.433] iteration:20489  t-loss:0.1358, loss-lb:0.0736, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:13:52.628] iteration:20490  t-loss:0.1815, loss-lb:0.0801, loss-ulb:0.0507, weight:2.00, lr:0.0004
[12:13:52.820] iteration:20491  t-loss:0.1544, loss-lb:0.0723, loss-ulb:0.0410, weight:2.00, lr:0.0004
[12:13:53.014] iteration:20492  t-loss:0.1476, loss-lb:0.0747, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:13:53.207] iteration:20493  t-loss:0.1465, loss-lb:0.0808, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:13:53.400] iteration:20494  t-loss:0.1376, loss-lb:0.0743, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:13:53.594] iteration:20495  t-loss:0.1473, loss-lb:0.0807, loss-ulb:0.0333, weight:2.00, lr:0.0004
[12:13:53.786] iteration:20496  t-loss:0.1451, loss-lb:0.0751, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:13:53.979] iteration:20497  t-loss:0.1672, loss-lb:0.0864, loss-ulb:0.0404, weight:2.00, lr:0.0004
[12:13:54.172] iteration:20498  t-loss:0.1428, loss-lb:0.0718, loss-ulb:0.0355, weight:2.00, lr:0.0004
[12:13:54.364] iteration:20499  t-loss:0.1454, loss-lb:0.0757, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:13:54.557] iteration:20500  t-loss:0.1373, loss-lb:0.0773, loss-ulb:0.0300, weight:2.00, lr:0.0004
[12:13:54.750] iteration:20501  t-loss:0.1520, loss-lb:0.0857, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:13:54.942] iteration:20502  t-loss:0.1358, loss-lb:0.0705, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:13:55.134] iteration:20503  t-loss:0.1571, loss-lb:0.0771, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:13:55.327] iteration:20504  t-loss:0.1488, loss-lb:0.0740, loss-ulb:0.0374, weight:2.00, lr:0.0004
[12:13:55.518] iteration:20505  t-loss:0.1497, loss-lb:0.0807, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:13:55.710] iteration:20506  t-loss:0.1324, loss-lb:0.0726, loss-ulb:0.0299, weight:2.00, lr:0.0004
[12:13:55.904] iteration:20507  t-loss:0.1366, loss-lb:0.0738, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:13:56.098] iteration:20508  t-loss:0.1788, loss-lb:0.0856, loss-ulb:0.0466, weight:2.00, lr:0.0004
[12:13:56.291] iteration:20509  t-loss:0.1694, loss-lb:0.0894, loss-ulb:0.0400, weight:2.00, lr:0.0004
[12:13:56.483] iteration:20510  t-loss:0.1512, loss-lb:0.0700, loss-ulb:0.0406, weight:2.00, lr:0.0004
[12:13:56.675] iteration:20511  t-loss:0.1309, loss-lb:0.0700, loss-ulb:0.0305, weight:2.00, lr:0.0004
[12:13:56.866] iteration:20512  t-loss:0.1653, loss-lb:0.0761, loss-ulb:0.0446, weight:2.00, lr:0.0004
[12:13:57.058] iteration:20513  t-loss:0.1354, loss-lb:0.0784, loss-ulb:0.0285, weight:2.00, lr:0.0004
[12:13:57.250] iteration:20514  t-loss:0.1547, loss-lb:0.0892, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:13:57.441] iteration:20515  t-loss:0.1467, loss-lb:0.0774, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:13:57.632] iteration:20516  t-loss:0.1342, loss-lb:0.0729, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:13:57.825] iteration:20517  t-loss:0.1420, loss-lb:0.0786, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:13:58.017] iteration:20518  t-loss:0.1520, loss-lb:0.0836, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:13:58.208] iteration:20519  t-loss:0.1442, loss-lb:0.0759, loss-ulb:0.0341, weight:2.00, lr:0.0004
[12:13:58.400] iteration:20520  t-loss:0.1442, loss-lb:0.0771, loss-ulb:0.0335, weight:2.00, lr:0.0004
[12:13:58.591] iteration:20521  t-loss:0.1372, loss-lb:0.0851, loss-ulb:0.0260, weight:2.00, lr:0.0004
[12:13:58.783] iteration:20522  t-loss:0.1429, loss-lb:0.0745, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:13:58.977] iteration:20523  t-loss:0.1271, loss-lb:0.0724, loss-ulb:0.0274, weight:2.00, lr:0.0004
[12:13:59.173] iteration:20524  t-loss:0.2178, loss-lb:0.0681, loss-ulb:0.0749, weight:2.00, lr:0.0004
[12:13:59.374] iteration:20525  t-loss:0.1590, loss-lb:0.0820, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:13:59.568] iteration:20526  t-loss:0.1595, loss-lb:0.0814, loss-ulb:0.0390, weight:2.00, lr:0.0004
[12:13:59.761] iteration:20527  t-loss:0.1500, loss-lb:0.0718, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:13:59.954] iteration:20528  t-loss:0.1898, loss-lb:0.0736, loss-ulb:0.0581, weight:2.00, lr:0.0004
[12:14:00.146] iteration:20529  t-loss:0.1466, loss-lb:0.0742, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:14:00.338] iteration:20530  t-loss:0.1468, loss-lb:0.0751, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:14:00.531] iteration:20531  t-loss:0.1590, loss-lb:0.0841, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:14:00.724] iteration:20532  t-loss:0.1403, loss-lb:0.0735, loss-ulb:0.0334, weight:2.00, lr:0.0004
[12:14:00.915] iteration:20533  t-loss:0.1768, loss-lb:0.0777, loss-ulb:0.0496, weight:2.00, lr:0.0004
[12:14:01.107] iteration:20534  t-loss:0.1498, loss-lb:0.0737, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:14:01.300] iteration:20535  t-loss:0.1507, loss-lb:0.0752, loss-ulb:0.0377, weight:2.00, lr:0.0004
[12:14:01.491] iteration:20536  t-loss:0.1339, loss-lb:0.0713, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:14:01.683] iteration:20537  t-loss:0.1553, loss-lb:0.0750, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:14:01.874] iteration:20538  t-loss:0.1443, loss-lb:0.0748, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:14:02.065] iteration:20539  t-loss:0.1511, loss-lb:0.0793, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:14:02.258] iteration:20540  t-loss:0.1385, loss-lb:0.0747, loss-ulb:0.0319, weight:2.00, lr:0.0004
[12:14:02.449] iteration:20541  t-loss:0.1524, loss-lb:0.0806, loss-ulb:0.0359, weight:2.00, lr:0.0004
[12:14:02.641] iteration:20542  t-loss:0.1662, loss-lb:0.0736, loss-ulb:0.0463, weight:2.00, lr:0.0004
[12:14:02.834] iteration:20543  t-loss:0.1388, loss-lb:0.0756, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:14:03.024] iteration:20544  t-loss:0.1221, loss-lb:0.0649, loss-ulb:0.0286, weight:2.00, lr:0.0004
[12:14:03.217] iteration:20545  t-loss:0.1499, loss-lb:0.0769, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:14:03.408] iteration:20546  t-loss:0.1516, loss-lb:0.0861, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:14:03.600] iteration:20547  t-loss:0.1470, loss-lb:0.0785, loss-ulb:0.0343, weight:2.00, lr:0.0004
[12:14:03.794] iteration:20548  t-loss:0.1568, loss-lb:0.0766, loss-ulb:0.0401, weight:2.00, lr:0.0004
[12:14:03.985] iteration:20549  t-loss:0.1347, loss-lb:0.0803, loss-ulb:0.0272, weight:2.00, lr:0.0004
[12:14:04.178] iteration:20550  t-loss:0.2233, loss-lb:0.0751, loss-ulb:0.0741, weight:2.00, lr:0.0004
[12:14:04.371] iteration:20551  t-loss:0.1498, loss-lb:0.0795, loss-ulb:0.0352, weight:2.00, lr:0.0004
[12:14:04.564] iteration:20552  t-loss:0.1701, loss-lb:0.0716, loss-ulb:0.0493, weight:2.00, lr:0.0004
[12:14:04.755] iteration:20553  t-loss:0.1486, loss-lb:0.0759, loss-ulb:0.0364, weight:2.00, lr:0.0004
[12:14:04.948] iteration:20554  t-loss:0.1624, loss-lb:0.0828, loss-ulb:0.0398, weight:2.00, lr:0.0004
[12:14:05.141] iteration:20555  t-loss:0.1346, loss-lb:0.0713, loss-ulb:0.0317, weight:2.00, lr:0.0004
[12:14:05.332] iteration:20556  t-loss:0.1442, loss-lb:0.0809, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:14:05.523] iteration:20557  t-loss:0.1494, loss-lb:0.0754, loss-ulb:0.0370, weight:2.00, lr:0.0004
[12:14:05.715] iteration:20558  t-loss:0.1655, loss-lb:0.1009, loss-ulb:0.0323, weight:2.00, lr:0.0004
[12:14:05.908] iteration:20559  t-loss:0.1459, loss-lb:0.0728, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:14:06.100] iteration:20560  t-loss:0.1397, loss-lb:0.0794, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:14:06.293] iteration:20561  t-loss:0.2201, loss-lb:0.0798, loss-ulb:0.0701, weight:2.00, lr:0.0004
[12:14:06.485] iteration:20562  t-loss:0.1471, loss-lb:0.0729, loss-ulb:0.0371, weight:2.00, lr:0.0004
[12:14:06.677] iteration:20563  t-loss:0.1491, loss-lb:0.0785, loss-ulb:0.0353, weight:2.00, lr:0.0004
[12:14:06.870] iteration:20564  t-loss:0.1420, loss-lb:0.0765, loss-ulb:0.0327, weight:2.00, lr:0.0004
[12:14:07.063] iteration:20565  t-loss:0.1347, loss-lb:0.0782, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:14:07.254] iteration:20566  t-loss:0.1801, loss-lb:0.0759, loss-ulb:0.0521, weight:2.00, lr:0.0004
[12:14:07.445] iteration:20567  t-loss:0.1444, loss-lb:0.0721, loss-ulb:0.0362, weight:2.00, lr:0.0004
[12:14:07.637] iteration:20568  t-loss:0.1214, loss-lb:0.0674, loss-ulb:0.0270, weight:2.00, lr:0.0004
[12:14:07.830] iteration:20569  t-loss:0.1612, loss-lb:0.0841, loss-ulb:0.0385, weight:2.00, lr:0.0004
[12:14:08.021] iteration:20570  t-loss:0.1273, loss-lb:0.0721, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:14:08.212] iteration:20571  t-loss:0.1863, loss-lb:0.0762, loss-ulb:0.0551, weight:2.00, lr:0.0004
[12:14:08.403] iteration:20572  t-loss:0.1486, loss-lb:0.0823, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:14:08.594] iteration:20573  t-loss:0.1467, loss-lb:0.0826, loss-ulb:0.0321, weight:2.00, lr:0.0004
[12:14:08.784] iteration:20574  t-loss:0.1497, loss-lb:0.0800, loss-ulb:0.0348, weight:2.00, lr:0.0004
[12:14:08.974] iteration:20575  t-loss:0.1459, loss-lb:0.0756, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:14:09.163] iteration:20576  t-loss:0.1395, loss-lb:0.0772, loss-ulb:0.0311, weight:2.00, lr:0.0004
[12:14:09.354] iteration:20577  t-loss:0.1387, loss-lb:0.0729, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:14:09.544] iteration:20578  t-loss:0.1616, loss-lb:0.0826, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:14:09.735] iteration:20579  t-loss:0.1388, loss-lb:0.0700, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:14:09.926] iteration:20580  t-loss:0.1494, loss-lb:0.0793, loss-ulb:0.0351, weight:2.00, lr:0.0004
[12:14:10.562] iteration:20581  t-loss:0.1379, loss-lb:0.0759, loss-ulb:0.0310, weight:2.00, lr:0.0004
[12:14:10.757] iteration:20582  t-loss:0.1458, loss-lb:0.0797, loss-ulb:0.0331, weight:2.00, lr:0.0004
[12:14:10.950] iteration:20583  t-loss:0.1436, loss-lb:0.0778, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:14:11.141] iteration:20584  t-loss:0.1479, loss-lb:0.0800, loss-ulb:0.0340, weight:2.00, lr:0.0004
[12:14:11.334] iteration:20585  t-loss:0.1400, loss-lb:0.0761, loss-ulb:0.0320, weight:2.00, lr:0.0004
[12:14:11.526] iteration:20586  t-loss:0.1363, loss-lb:0.0735, loss-ulb:0.0314, weight:2.00, lr:0.0004
[12:14:11.717] iteration:20587  t-loss:0.1404, loss-lb:0.0792, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:14:11.910] iteration:20588  t-loss:0.1291, loss-lb:0.0769, loss-ulb:0.0261, weight:2.00, lr:0.0004
[12:14:12.104] iteration:20589  t-loss:0.1611, loss-lb:0.0711, loss-ulb:0.0450, weight:2.00, lr:0.0004
[12:14:12.310] iteration:20590  t-loss:0.1569, loss-lb:0.0788, loss-ulb:0.0391, weight:2.00, lr:0.0004
[12:14:12.508] iteration:20591  t-loss:0.1333, loss-lb:0.0731, loss-ulb:0.0301, weight:2.00, lr:0.0004
[12:14:12.700] iteration:20592  t-loss:0.1509, loss-lb:0.0772, loss-ulb:0.0369, weight:2.00, lr:0.0004
[12:14:12.891] iteration:20593  t-loss:0.1436, loss-lb:0.0777, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:14:13.084] iteration:20594  t-loss:0.1664, loss-lb:0.0866, loss-ulb:0.0399, weight:2.00, lr:0.0004
[12:14:13.276] iteration:20595  t-loss:0.1335, loss-lb:0.0702, loss-ulb:0.0316, weight:2.00, lr:0.0004
[12:14:13.467] iteration:20596  t-loss:0.1323, loss-lb:0.0709, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:14:13.659] iteration:20597  t-loss:0.1666, loss-lb:0.0839, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:14:13.852] iteration:20598  t-loss:0.1499, loss-lb:0.0738, loss-ulb:0.0380, weight:2.00, lr:0.0004
[12:14:14.043] iteration:20599  t-loss:0.1623, loss-lb:0.0795, loss-ulb:0.0414, weight:2.00, lr:0.0004
[12:14:14.235] iteration:20600  t-loss:0.1324, loss-lb:0.0737, loss-ulb:0.0294, weight:2.00, lr:0.0004
[12:14:14.429] iteration:20601  t-loss:0.1537, loss-lb:0.0720, loss-ulb:0.0409, weight:2.00, lr:0.0004
[12:14:14.621] iteration:20602  t-loss:0.1484, loss-lb:0.0791, loss-ulb:0.0347, weight:2.00, lr:0.0004
[12:14:14.813] iteration:20603  t-loss:0.1906, loss-lb:0.0746, loss-ulb:0.0580, weight:2.00, lr:0.0004
[12:14:15.005] iteration:20604  t-loss:0.1260, loss-lb:0.0677, loss-ulb:0.0292, weight:2.00, lr:0.0004
[12:14:15.197] iteration:20605  t-loss:0.1603, loss-lb:0.0772, loss-ulb:0.0415, weight:2.00, lr:0.0004
[12:14:15.388] iteration:20606  t-loss:0.1482, loss-lb:0.0878, loss-ulb:0.0302, weight:2.00, lr:0.0004
[12:14:15.580] iteration:20607  t-loss:0.1599, loss-lb:0.0789, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:14:15.772] iteration:20608  t-loss:0.1320, loss-lb:0.0703, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:14:15.965] iteration:20609  t-loss:0.2136, loss-lb:0.0767, loss-ulb:0.0685, weight:2.00, lr:0.0004
[12:14:16.157] iteration:20610  t-loss:0.1505, loss-lb:0.0808, loss-ulb:0.0349, weight:2.00, lr:0.0004
[12:14:16.350] iteration:20611  t-loss:0.1408, loss-lb:0.0718, loss-ulb:0.0345, weight:2.00, lr:0.0004
[12:14:16.541] iteration:20612  t-loss:0.1514, loss-lb:0.0782, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:14:16.735] iteration:20613  t-loss:0.1516, loss-lb:0.0726, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:14:16.926] iteration:20614  t-loss:0.1330, loss-lb:0.0678, loss-ulb:0.0326, weight:2.00, lr:0.0004
[12:14:17.119] iteration:20615  t-loss:0.2129, loss-lb:0.0735, loss-ulb:0.0697, weight:2.00, lr:0.0004
[12:14:17.310] iteration:20616  t-loss:0.1476, loss-lb:0.0746, loss-ulb:0.0365, weight:2.00, lr:0.0004
[12:14:17.502] iteration:20617  t-loss:0.1597, loss-lb:0.0847, loss-ulb:0.0375, weight:2.00, lr:0.0004
[12:14:17.694] iteration:20618  t-loss:0.1510, loss-lb:0.0721, loss-ulb:0.0395, weight:2.00, lr:0.0004
[12:14:17.887] iteration:20619  t-loss:0.1370, loss-lb:0.0795, loss-ulb:0.0287, weight:2.00, lr:0.0004
[12:14:18.079] iteration:20620  t-loss:0.1383, loss-lb:0.0708, loss-ulb:0.0337, weight:2.00, lr:0.0004
[12:14:18.271] iteration:20621  t-loss:0.1608, loss-lb:0.0704, loss-ulb:0.0452, weight:2.00, lr:0.0004
[12:14:18.463] iteration:20622  t-loss:0.1338, loss-lb:0.0785, loss-ulb:0.0277, weight:2.00, lr:0.0004
[12:14:18.654] iteration:20623  t-loss:0.1553, loss-lb:0.0889, loss-ulb:0.0332, weight:2.00, lr:0.0004
[12:14:18.847] iteration:20624  t-loss:0.1513, loss-lb:0.0840, loss-ulb:0.0336, weight:2.00, lr:0.0004
[12:14:19.038] iteration:20625  t-loss:0.1516, loss-lb:0.0706, loss-ulb:0.0405, weight:2.00, lr:0.0004
[12:14:19.231] iteration:20626  t-loss:0.1341, loss-lb:0.0746, loss-ulb:0.0297, weight:2.00, lr:0.0004
[12:14:19.422] iteration:20627  t-loss:0.1393, loss-lb:0.0733, loss-ulb:0.0330, weight:2.00, lr:0.0004
[12:14:19.614] iteration:20628  t-loss:0.1358, loss-lb:0.0745, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:14:19.806] iteration:20629  t-loss:0.1750, loss-lb:0.0751, loss-ulb:0.0500, weight:2.00, lr:0.0004
[12:14:19.998] iteration:20630  t-loss:0.1398, loss-lb:0.0787, loss-ulb:0.0306, weight:2.00, lr:0.0004
[12:14:20.190] iteration:20631  t-loss:0.1424, loss-lb:0.0765, loss-ulb:0.0329, weight:2.00, lr:0.0004
[12:14:20.383] iteration:20632  t-loss:0.1401, loss-lb:0.0716, loss-ulb:0.0342, weight:2.00, lr:0.0004
[12:14:20.574] iteration:20633  t-loss:0.1803, loss-lb:0.0827, loss-ulb:0.0488, weight:2.00, lr:0.0004
[12:14:20.766] iteration:20634  t-loss:0.1524, loss-lb:0.0768, loss-ulb:0.0378, weight:2.00, lr:0.0004
[12:14:20.959] iteration:20635  t-loss:0.1469, loss-lb:0.0782, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:14:21.152] iteration:20636  t-loss:0.1372, loss-lb:0.0756, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:14:21.344] iteration:20637  t-loss:0.1546, loss-lb:0.0750, loss-ulb:0.0398, weight:2.00, lr:0.0004
[12:14:21.537] iteration:20638  t-loss:0.1433, loss-lb:0.0733, loss-ulb:0.0350, weight:2.00, lr:0.0004
[12:14:21.730] iteration:20639  t-loss:0.1573, loss-lb:0.0821, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:14:21.922] iteration:20640  t-loss:0.1529, loss-lb:0.0817, loss-ulb:0.0356, weight:2.00, lr:0.0004
[12:14:22.115] iteration:20641  t-loss:0.1380, loss-lb:0.0664, loss-ulb:0.0358, weight:2.00, lr:0.0004
[12:14:22.309] iteration:20642  t-loss:0.2484, loss-lb:0.0751, loss-ulb:0.0867, weight:2.00, lr:0.0004
[12:14:22.501] iteration:20643  t-loss:0.1303, loss-lb:0.0686, loss-ulb:0.0309, weight:2.00, lr:0.0004
[12:14:22.696] iteration:20644  t-loss:0.1291, loss-lb:0.0739, loss-ulb:0.0276, weight:2.00, lr:0.0004
[12:14:22.887] iteration:20645  t-loss:0.1380, loss-lb:0.0754, loss-ulb:0.0313, weight:2.00, lr:0.0004
[12:14:23.080] iteration:20646  t-loss:0.2394, loss-lb:0.0820, loss-ulb:0.0787, weight:2.00, lr:0.0004
[12:14:23.273] iteration:20647  t-loss:0.1431, loss-lb:0.0753, loss-ulb:0.0339, weight:2.00, lr:0.0004
[12:14:23.466] iteration:20648  t-loss:0.1497, loss-lb:0.0745, loss-ulb:0.0376, weight:2.00, lr:0.0004
[12:14:23.658] iteration:20649  t-loss:0.1494, loss-lb:0.0751, loss-ulb:0.0372, weight:2.00, lr:0.0004
[12:14:23.851] iteration:20650  t-loss:0.1415, loss-lb:0.0726, loss-ulb:0.0344, weight:2.00, lr:0.0004
[12:14:24.044] iteration:20651  t-loss:0.1407, loss-lb:0.0793, loss-ulb:0.0307, weight:2.00, lr:0.0004
[12:14:24.236] iteration:20652  t-loss:0.1583, loss-lb:0.0852, loss-ulb:0.0366, weight:2.00, lr:0.0004
[12:14:24.428] iteration:20653  t-loss:0.1437, loss-lb:0.0821, loss-ulb:0.0308, weight:2.00, lr:0.0004
[12:14:24.620] iteration:20654  t-loss:0.1538, loss-lb:0.0731, loss-ulb:0.0403, weight:2.00, lr:0.0004
[12:14:24.813] iteration:20655  t-loss:0.1466, loss-lb:0.0752, loss-ulb:0.0357, weight:2.00, lr:0.0004
[12:14:25.005] iteration:20656  t-loss:0.1301, loss-lb:0.0735, loss-ulb:0.0283, weight:2.00, lr:0.0004
[12:14:25.198] iteration:20657  t-loss:0.1621, loss-lb:0.0736, loss-ulb:0.0442, weight:2.00, lr:0.0004
[12:14:25.392] iteration:20658  t-loss:0.1357, loss-lb:0.0766, loss-ulb:0.0296, weight:2.00, lr:0.0003
[12:14:25.584] iteration:20659  t-loss:0.1353, loss-lb:0.0829, loss-ulb:0.0262, weight:2.00, lr:0.0003
[12:14:25.777] iteration:20660  t-loss:0.1519, loss-lb:0.0762, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:14:25.970] iteration:20661  t-loss:0.1440, loss-lb:0.0732, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:14:26.163] iteration:20662  t-loss:0.1421, loss-lb:0.0768, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:14:26.354] iteration:20663  t-loss:0.1362, loss-lb:0.0774, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:14:26.547] iteration:20664  t-loss:0.1482, loss-lb:0.0717, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:14:26.740] iteration:20665  t-loss:0.1484, loss-lb:0.0786, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:14:26.933] iteration:20666  t-loss:0.1622, loss-lb:0.0734, loss-ulb:0.0444, weight:2.00, lr:0.0003
[12:14:27.127] iteration:20667  t-loss:0.1517, loss-lb:0.0915, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:14:27.319] iteration:20668  t-loss:0.1358, loss-lb:0.0741, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:14:27.512] iteration:20669  t-loss:0.1419, loss-lb:0.0746, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:14:27.705] iteration:20670  t-loss:0.1493, loss-lb:0.0789, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:14:27.896] iteration:20671  t-loss:0.1356, loss-lb:0.0742, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:14:28.087] iteration:20672  t-loss:0.1563, loss-lb:0.0715, loss-ulb:0.0424, weight:2.00, lr:0.0003
[12:14:28.277] iteration:20673  t-loss:0.1499, loss-lb:0.0818, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:14:28.468] iteration:20674  t-loss:0.1608, loss-lb:0.0799, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:14:28.660] iteration:20675  t-loss:0.1388, loss-lb:0.0714, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:14:28.851] iteration:20676  t-loss:0.1650, loss-lb:0.0910, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:14:29.042] iteration:20677  t-loss:0.1600, loss-lb:0.0756, loss-ulb:0.0422, weight:2.00, lr:0.0003
[12:14:29.233] iteration:20678  t-loss:0.1457, loss-lb:0.0751, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:14:41.856]  <<Test>> - Ep:210  - mean_dice/mean_h95 - S:89.81/1.48, Best-S:90.99, T:89.77/1.41, Best-T:90.48
[12:14:41.856]           - AvgLoss(lb/ulb/all):0.0765/0.0352/0.1480
[12:14:42.381] iteration:20679  t-loss:0.1694, loss-lb:0.0740, loss-ulb:0.0477, weight:2.00, lr:0.0003
[12:14:42.576] iteration:20680  t-loss:0.1443, loss-lb:0.0717, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:14:42.770] iteration:20681  t-loss:0.1403, loss-lb:0.0694, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:14:42.965] iteration:20682  t-loss:0.1477, loss-lb:0.0744, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:14:43.158] iteration:20683  t-loss:0.1462, loss-lb:0.0743, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:14:43.350] iteration:20684  t-loss:0.1406, loss-lb:0.0765, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:14:43.543] iteration:20685  t-loss:0.1401, loss-lb:0.0794, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:14:43.736] iteration:20686  t-loss:0.1576, loss-lb:0.0797, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:14:43.929] iteration:20687  t-loss:0.1422, loss-lb:0.0761, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:14:44.122] iteration:20688  t-loss:0.1389, loss-lb:0.0767, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:14:44.316] iteration:20689  t-loss:0.1486, loss-lb:0.0819, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:14:44.508] iteration:20690  t-loss:0.1474, loss-lb:0.0800, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:14:44.702] iteration:20691  t-loss:0.1794, loss-lb:0.0776, loss-ulb:0.0509, weight:2.00, lr:0.0003
[12:14:44.903] iteration:20692  t-loss:0.1513, loss-lb:0.0783, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:14:45.107] iteration:20693  t-loss:0.1321, loss-lb:0.0695, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:14:45.303] iteration:20694  t-loss:0.1399, loss-lb:0.0766, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:14:45.496] iteration:20695  t-loss:0.1312, loss-lb:0.0735, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:14:45.689] iteration:20696  t-loss:0.1501, loss-lb:0.0792, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:14:45.882] iteration:20697  t-loss:0.1570, loss-lb:0.0779, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:14:46.077] iteration:20698  t-loss:0.1796, loss-lb:0.0728, loss-ulb:0.0534, weight:2.00, lr:0.0003
[12:14:46.270] iteration:20699  t-loss:0.1391, loss-lb:0.0755, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:14:46.463] iteration:20700  t-loss:0.1448, loss-lb:0.0822, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:14:46.656] iteration:20701  t-loss:0.1660, loss-lb:0.0725, loss-ulb:0.0467, weight:2.00, lr:0.0003
[12:14:46.850] iteration:20702  t-loss:0.2922, loss-lb:0.0786, loss-ulb:0.1068, weight:2.00, lr:0.0003
[12:14:47.044] iteration:20703  t-loss:0.1384, loss-lb:0.0725, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:14:47.238] iteration:20704  t-loss:0.1435, loss-lb:0.0786, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:14:47.430] iteration:20705  t-loss:0.1446, loss-lb:0.0795, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:14:47.624] iteration:20706  t-loss:0.2102, loss-lb:0.0775, loss-ulb:0.0664, weight:2.00, lr:0.0003
[12:14:47.818] iteration:20707  t-loss:0.1695, loss-lb:0.0701, loss-ulb:0.0497, weight:2.00, lr:0.0003
[12:14:48.011] iteration:20708  t-loss:0.1410, loss-lb:0.0756, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:14:48.205] iteration:20709  t-loss:0.1591, loss-lb:0.0726, loss-ulb:0.0432, weight:2.00, lr:0.0003
[12:14:48.400] iteration:20710  t-loss:0.1506, loss-lb:0.0808, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:14:48.594] iteration:20711  t-loss:0.1512, loss-lb:0.0707, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:14:48.787] iteration:20712  t-loss:0.1344, loss-lb:0.0771, loss-ulb:0.0286, weight:2.00, lr:0.0003
[12:14:48.980] iteration:20713  t-loss:0.1383, loss-lb:0.0772, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:14:49.172] iteration:20714  t-loss:0.1391, loss-lb:0.0767, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:14:49.370] iteration:20715  t-loss:0.1611, loss-lb:0.0732, loss-ulb:0.0440, weight:2.00, lr:0.0003
[12:14:49.564] iteration:20716  t-loss:0.2188, loss-lb:0.0706, loss-ulb:0.0741, weight:2.00, lr:0.0003
[12:14:49.757] iteration:20717  t-loss:0.1460, loss-lb:0.0718, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:14:49.950] iteration:20718  t-loss:0.1304, loss-lb:0.0738, loss-ulb:0.0283, weight:2.00, lr:0.0003
[12:14:50.149] iteration:20719  t-loss:0.1640, loss-lb:0.0830, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:14:50.343] iteration:20720  t-loss:0.3471, loss-lb:0.0776, loss-ulb:0.1347, weight:2.00, lr:0.0003
[12:14:50.536] iteration:20721  t-loss:0.1854, loss-lb:0.0823, loss-ulb:0.0515, weight:2.00, lr:0.0003
[12:14:50.728] iteration:20722  t-loss:0.1653, loss-lb:0.0932, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:14:50.921] iteration:20723  t-loss:0.1499, loss-lb:0.0730, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:14:51.113] iteration:20724  t-loss:0.1444, loss-lb:0.0773, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:14:51.306] iteration:20725  t-loss:0.1682, loss-lb:0.0821, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:14:51.499] iteration:20726  t-loss:0.1595, loss-lb:0.0775, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:14:51.692] iteration:20727  t-loss:0.1437, loss-lb:0.0741, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:14:51.884] iteration:20728  t-loss:0.1474, loss-lb:0.0794, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:14:52.077] iteration:20729  t-loss:0.1534, loss-lb:0.0831, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:14:52.269] iteration:20730  t-loss:0.1605, loss-lb:0.0703, loss-ulb:0.0451, weight:2.00, lr:0.0003
[12:14:52.461] iteration:20731  t-loss:0.1603, loss-lb:0.0778, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:14:52.653] iteration:20732  t-loss:0.1289, loss-lb:0.0747, loss-ulb:0.0271, weight:2.00, lr:0.0003
[12:14:52.846] iteration:20733  t-loss:0.1372, loss-lb:0.0730, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:14:53.038] iteration:20734  t-loss:0.1728, loss-lb:0.0937, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:14:53.231] iteration:20735  t-loss:0.1715, loss-lb:0.0796, loss-ulb:0.0459, weight:2.00, lr:0.0003
[12:14:53.423] iteration:20736  t-loss:0.1467, loss-lb:0.0829, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:14:53.616] iteration:20737  t-loss:0.2041, loss-lb:0.0775, loss-ulb:0.0633, weight:2.00, lr:0.0003
[12:14:53.809] iteration:20738  t-loss:0.1931, loss-lb:0.0827, loss-ulb:0.0552, weight:2.00, lr:0.0003
[12:14:54.002] iteration:20739  t-loss:0.1474, loss-lb:0.0683, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:14:54.195] iteration:20740  t-loss:0.1344, loss-lb:0.0699, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:14:54.388] iteration:20741  t-loss:0.1551, loss-lb:0.0815, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:14:54.581] iteration:20742  t-loss:0.1736, loss-lb:0.0823, loss-ulb:0.0456, weight:2.00, lr:0.0003
[12:14:54.774] iteration:20743  t-loss:0.1386, loss-lb:0.0810, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:14:54.968] iteration:20744  t-loss:0.1623, loss-lb:0.0822, loss-ulb:0.0400, weight:2.00, lr:0.0003
[12:14:55.161] iteration:20745  t-loss:0.1537, loss-lb:0.0816, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:14:55.353] iteration:20746  t-loss:0.1634, loss-lb:0.0774, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:14:55.545] iteration:20747  t-loss:0.1619, loss-lb:0.0890, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:14:55.737] iteration:20748  t-loss:0.1425, loss-lb:0.0731, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:14:55.931] iteration:20749  t-loss:0.1493, loss-lb:0.0788, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:14:56.123] iteration:20750  t-loss:0.1732, loss-lb:0.0893, loss-ulb:0.0419, weight:2.00, lr:0.0003
[12:14:56.316] iteration:20751  t-loss:0.1825, loss-lb:0.0822, loss-ulb:0.0501, weight:2.00, lr:0.0003
[12:14:56.509] iteration:20752  t-loss:0.1409, loss-lb:0.0793, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:14:56.703] iteration:20753  t-loss:0.1914, loss-lb:0.0867, loss-ulb:0.0524, weight:2.00, lr:0.0003
[12:14:56.896] iteration:20754  t-loss:0.2016, loss-lb:0.0843, loss-ulb:0.0586, weight:2.00, lr:0.0003
[12:14:57.088] iteration:20755  t-loss:0.1721, loss-lb:0.1004, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:14:57.281] iteration:20756  t-loss:0.1416, loss-lb:0.0772, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:14:57.473] iteration:20757  t-loss:0.1420, loss-lb:0.0791, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:14:57.665] iteration:20758  t-loss:0.1561, loss-lb:0.0781, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:14:57.858] iteration:20759  t-loss:0.1404, loss-lb:0.0762, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:14:58.052] iteration:20760  t-loss:0.1566, loss-lb:0.0871, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:14:58.247] iteration:20761  t-loss:0.2139, loss-lb:0.0786, loss-ulb:0.0677, weight:2.00, lr:0.0003
[12:14:58.440] iteration:20762  t-loss:0.1555, loss-lb:0.0846, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:14:58.633] iteration:20763  t-loss:0.1423, loss-lb:0.0753, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:14:58.825] iteration:20764  t-loss:0.1643, loss-lb:0.0790, loss-ulb:0.0426, weight:2.00, lr:0.0003
[12:14:59.017] iteration:20765  t-loss:0.1735, loss-lb:0.0875, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:14:59.209] iteration:20766  t-loss:0.1427, loss-lb:0.0762, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:14:59.404] iteration:20767  t-loss:0.1515, loss-lb:0.0794, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:14:59.596] iteration:20768  t-loss:0.1578, loss-lb:0.0792, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:14:59.787] iteration:20769  t-loss:0.1535, loss-lb:0.0839, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:14:59.978] iteration:20770  t-loss:0.1576, loss-lb:0.0802, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:15:00.168] iteration:20771  t-loss:0.1596, loss-lb:0.0773, loss-ulb:0.0411, weight:2.00, lr:0.0003
[12:15:00.359] iteration:20772  t-loss:0.1517, loss-lb:0.0805, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:15:00.550] iteration:20773  t-loss:0.1326, loss-lb:0.0705, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:15:00.741] iteration:20774  t-loss:0.1416, loss-lb:0.0787, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:15:00.932] iteration:20775  t-loss:0.1377, loss-lb:0.0772, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:15:01.122] iteration:20776  t-loss:0.1297, loss-lb:0.0714, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:15:01.725] iteration:20777  t-loss:0.1577, loss-lb:0.0876, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:15:01.921] iteration:20778  t-loss:0.1590, loss-lb:0.0831, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:15:02.114] iteration:20779  t-loss:0.1338, loss-lb:0.0741, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:15:02.307] iteration:20780  t-loss:0.1380, loss-lb:0.0815, loss-ulb:0.0282, weight:2.00, lr:0.0003
[12:15:02.500] iteration:20781  t-loss:0.1562, loss-lb:0.0814, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:15:02.694] iteration:20782  t-loss:0.1436, loss-lb:0.0738, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:15:02.885] iteration:20783  t-loss:0.1382, loss-lb:0.0709, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:15:03.078] iteration:20784  t-loss:0.1500, loss-lb:0.0724, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:15:03.271] iteration:20785  t-loss:0.1491, loss-lb:0.0770, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:15:03.463] iteration:20786  t-loss:0.1308, loss-lb:0.0781, loss-ulb:0.0263, weight:2.00, lr:0.0003
[12:15:03.655] iteration:20787  t-loss:0.1462, loss-lb:0.0785, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:15:03.852] iteration:20788  t-loss:0.1509, loss-lb:0.0774, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:15:04.045] iteration:20789  t-loss:0.1812, loss-lb:0.0789, loss-ulb:0.0512, weight:2.00, lr:0.0003
[12:15:04.238] iteration:20790  t-loss:0.1566, loss-lb:0.0783, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:15:04.430] iteration:20791  t-loss:0.1334, loss-lb:0.0731, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:15:04.623] iteration:20792  t-loss:0.1403, loss-lb:0.0775, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:15:04.816] iteration:20793  t-loss:0.1479, loss-lb:0.0761, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:15:05.009] iteration:20794  t-loss:0.1396, loss-lb:0.0772, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:15:05.202] iteration:20795  t-loss:0.1569, loss-lb:0.0809, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:15:05.394] iteration:20796  t-loss:0.1445, loss-lb:0.0783, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:15:05.587] iteration:20797  t-loss:0.1434, loss-lb:0.0821, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:15:05.778] iteration:20798  t-loss:0.1417, loss-lb:0.0804, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:15:05.972] iteration:20799  t-loss:0.1474, loss-lb:0.0786, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:15:06.164] iteration:20800  t-loss:0.1444, loss-lb:0.0766, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:15:06.358] iteration:20801  t-loss:0.3972, loss-lb:0.0737, loss-ulb:0.1618, weight:2.00, lr:0.0003
[12:15:06.551] iteration:20802  t-loss:0.1683, loss-lb:0.0785, loss-ulb:0.0449, weight:2.00, lr:0.0003
[12:15:06.742] iteration:20803  t-loss:0.1582, loss-lb:0.0871, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:15:06.935] iteration:20804  t-loss:0.1594, loss-lb:0.0742, loss-ulb:0.0426, weight:2.00, lr:0.0003
[12:15:07.127] iteration:20805  t-loss:0.1315, loss-lb:0.0746, loss-ulb:0.0285, weight:2.00, lr:0.0003
[12:15:07.319] iteration:20806  t-loss:0.1512, loss-lb:0.0763, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:15:07.512] iteration:20807  t-loss:0.1882, loss-lb:0.0749, loss-ulb:0.0567, weight:2.00, lr:0.0003
[12:15:07.705] iteration:20808  t-loss:0.1453, loss-lb:0.0772, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:15:07.899] iteration:20809  t-loss:0.1298, loss-lb:0.0705, loss-ulb:0.0297, weight:2.00, lr:0.0003
[12:15:08.092] iteration:20810  t-loss:0.1354, loss-lb:0.0767, loss-ulb:0.0293, weight:2.00, lr:0.0003
[12:15:08.285] iteration:20811  t-loss:0.1445, loss-lb:0.0781, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:15:08.477] iteration:20812  t-loss:0.1430, loss-lb:0.0757, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:15:08.669] iteration:20813  t-loss:0.1463, loss-lb:0.0779, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:15:08.862] iteration:20814  t-loss:0.1263, loss-lb:0.0637, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:15:09.055] iteration:20815  t-loss:0.1534, loss-lb:0.0781, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:15:09.250] iteration:20816  t-loss:0.1386, loss-lb:0.0778, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:15:09.444] iteration:20817  t-loss:0.1486, loss-lb:0.0809, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:15:09.636] iteration:20818  t-loss:0.1557, loss-lb:0.0771, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:15:09.829] iteration:20819  t-loss:0.1408, loss-lb:0.0804, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:15:10.022] iteration:20820  t-loss:0.1516, loss-lb:0.0805, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:15:10.214] iteration:20821  t-loss:0.1380, loss-lb:0.0715, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:15:10.406] iteration:20822  t-loss:0.1415, loss-lb:0.0732, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:15:10.598] iteration:20823  t-loss:0.1439, loss-lb:0.0670, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:15:10.791] iteration:20824  t-loss:0.1476, loss-lb:0.0718, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:15:10.987] iteration:20825  t-loss:0.1595, loss-lb:0.0873, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:15:11.182] iteration:20826  t-loss:0.1402, loss-lb:0.0734, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:15:11.376] iteration:20827  t-loss:0.1693, loss-lb:0.0736, loss-ulb:0.0479, weight:2.00, lr:0.0003
[12:15:11.568] iteration:20828  t-loss:0.1410, loss-lb:0.0810, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:15:11.760] iteration:20829  t-loss:0.1474, loss-lb:0.0785, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:15:11.951] iteration:20830  t-loss:0.1523, loss-lb:0.0761, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:15:12.142] iteration:20831  t-loss:0.1287, loss-lb:0.0725, loss-ulb:0.0281, weight:2.00, lr:0.0003
[12:15:12.334] iteration:20832  t-loss:0.1507, loss-lb:0.0757, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:15:12.527] iteration:20833  t-loss:0.2186, loss-lb:0.0792, loss-ulb:0.0697, weight:2.00, lr:0.0003
[12:15:12.719] iteration:20834  t-loss:0.1491, loss-lb:0.0785, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:15:12.911] iteration:20835  t-loss:0.1393, loss-lb:0.0782, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:15:13.103] iteration:20836  t-loss:0.1465, loss-lb:0.0746, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:15:13.295] iteration:20837  t-loss:0.1407, loss-lb:0.0793, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:15:13.486] iteration:20838  t-loss:0.1479, loss-lb:0.0709, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:15:13.680] iteration:20839  t-loss:0.1556, loss-lb:0.0780, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:15:13.873] iteration:20840  t-loss:0.2347, loss-lb:0.0707, loss-ulb:0.0820, weight:2.00, lr:0.0003
[12:15:14.068] iteration:20841  t-loss:0.1370, loss-lb:0.0793, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:15:14.259] iteration:20842  t-loss:0.1455, loss-lb:0.0730, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:15:14.451] iteration:20843  t-loss:0.1451, loss-lb:0.0718, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:15:14.645] iteration:20844  t-loss:0.1325, loss-lb:0.0758, loss-ulb:0.0284, weight:2.00, lr:0.0003
[12:15:14.838] iteration:20845  t-loss:0.1441, loss-lb:0.0784, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:15:15.032] iteration:20846  t-loss:0.1360, loss-lb:0.0712, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:15:15.224] iteration:20847  t-loss:0.1491, loss-lb:0.0838, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:15:15.417] iteration:20848  t-loss:0.2267, loss-lb:0.0740, loss-ulb:0.0763, weight:2.00, lr:0.0003
[12:15:15.609] iteration:20849  t-loss:0.1306, loss-lb:0.0755, loss-ulb:0.0276, weight:2.00, lr:0.0003
[12:15:15.801] iteration:20850  t-loss:0.1548, loss-lb:0.0804, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:15:15.994] iteration:20851  t-loss:0.1416, loss-lb:0.0704, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:15:16.186] iteration:20852  t-loss:0.1615, loss-lb:0.0841, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:15:16.377] iteration:20853  t-loss:0.1303, loss-lb:0.0691, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:15:16.569] iteration:20854  t-loss:0.1502, loss-lb:0.0799, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:15:16.760] iteration:20855  t-loss:0.1348, loss-lb:0.0753, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:15:16.953] iteration:20856  t-loss:0.1542, loss-lb:0.0824, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:15:17.146] iteration:20857  t-loss:0.1508, loss-lb:0.0785, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:15:17.337] iteration:20858  t-loss:0.1542, loss-lb:0.0764, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:15:17.529] iteration:20859  t-loss:0.1439, loss-lb:0.0772, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:15:17.732] iteration:20860  t-loss:0.1445, loss-lb:0.0757, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:15:17.929] iteration:20861  t-loss:0.1407, loss-lb:0.0781, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:15:18.125] iteration:20862  t-loss:0.1481, loss-lb:0.0711, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:15:18.317] iteration:20863  t-loss:0.1552, loss-lb:0.0778, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:15:18.510] iteration:20864  t-loss:0.3075, loss-lb:0.0730, loss-ulb:0.1172, weight:2.00, lr:0.0003
[12:15:18.703] iteration:20865  t-loss:0.1501, loss-lb:0.0776, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:15:18.895] iteration:20866  t-loss:0.1459, loss-lb:0.0748, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:15:19.085] iteration:20867  t-loss:0.1460, loss-lb:0.0740, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:15:19.276] iteration:20868  t-loss:0.1569, loss-lb:0.0760, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:15:19.465] iteration:20869  t-loss:0.1420, loss-lb:0.0769, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:15:19.656] iteration:20870  t-loss:0.1779, loss-lb:0.0834, loss-ulb:0.0473, weight:2.00, lr:0.0003
[12:15:19.846] iteration:20871  t-loss:0.1297, loss-lb:0.0726, loss-ulb:0.0285, weight:2.00, lr:0.0003
[12:15:20.034] iteration:20872  t-loss:0.1519, loss-lb:0.0781, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:15:20.225] iteration:20873  t-loss:0.1284, loss-lb:0.0697, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:15:20.414] iteration:20874  t-loss:0.1429, loss-lb:0.0813, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:15:32.892]  <<Test>> - Ep:212  - mean_dice/mean_h95 - S:89.88/1.31, Best-S:90.99, T:89.62/1.38, Best-T:90.48
[12:15:32.892]           - AvgLoss(lb/ulb/all):0.0767/0.0394/0.1553
[12:15:33.478] iteration:20875  t-loss:0.1507, loss-lb:0.0750, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:15:33.677] iteration:20876  t-loss:0.1242, loss-lb:0.0673, loss-ulb:0.0284, weight:2.00, lr:0.0003
[12:15:33.869] iteration:20877  t-loss:0.1535, loss-lb:0.0785, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:15:34.062] iteration:20878  t-loss:0.1340, loss-lb:0.0793, loss-ulb:0.0274, weight:2.00, lr:0.0003
[12:15:34.255] iteration:20879  t-loss:0.1558, loss-lb:0.0823, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:15:34.448] iteration:20880  t-loss:0.1429, loss-lb:0.0788, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:15:34.641] iteration:20881  t-loss:0.1459, loss-lb:0.0829, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:15:34.832] iteration:20882  t-loss:0.1533, loss-lb:0.0777, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:15:35.025] iteration:20883  t-loss:0.1416, loss-lb:0.0767, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:15:35.218] iteration:20884  t-loss:0.1583, loss-lb:0.0716, loss-ulb:0.0434, weight:2.00, lr:0.0003
[12:15:35.410] iteration:20885  t-loss:0.1329, loss-lb:0.0713, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:15:35.603] iteration:20886  t-loss:0.1435, loss-lb:0.0752, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:15:35.796] iteration:20887  t-loss:0.1483, loss-lb:0.0755, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:15:35.989] iteration:20888  t-loss:0.1412, loss-lb:0.0745, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:15:36.181] iteration:20889  t-loss:0.1425, loss-lb:0.0772, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:15:36.374] iteration:20890  t-loss:0.2148, loss-lb:0.0780, loss-ulb:0.0684, weight:2.00, lr:0.0003
[12:15:36.567] iteration:20891  t-loss:0.1431, loss-lb:0.0758, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:15:36.760] iteration:20892  t-loss:0.1502, loss-lb:0.0765, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:15:36.953] iteration:20893  t-loss:0.2325, loss-lb:0.0781, loss-ulb:0.0772, weight:2.00, lr:0.0003
[12:15:37.145] iteration:20894  t-loss:0.1349, loss-lb:0.0709, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:15:37.338] iteration:20895  t-loss:0.1343, loss-lb:0.0759, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:15:37.529] iteration:20896  t-loss:0.1429, loss-lb:0.0796, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:15:37.723] iteration:20897  t-loss:0.1784, loss-lb:0.0711, loss-ulb:0.0536, weight:2.00, lr:0.0003
[12:15:37.917] iteration:20898  t-loss:0.1499, loss-lb:0.0766, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:15:38.110] iteration:20899  t-loss:0.1595, loss-lb:0.0820, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:15:38.301] iteration:20900  t-loss:0.1620, loss-lb:0.0790, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:15:38.494] iteration:20901  t-loss:0.1487, loss-lb:0.0760, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:15:38.686] iteration:20902  t-loss:0.1703, loss-lb:0.0725, loss-ulb:0.0489, weight:2.00, lr:0.0003
[12:15:38.880] iteration:20903  t-loss:0.1495, loss-lb:0.0826, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:15:39.071] iteration:20904  t-loss:0.1247, loss-lb:0.0645, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:15:39.264] iteration:20905  t-loss:0.1358, loss-lb:0.0758, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:15:39.459] iteration:20906  t-loss:0.1419, loss-lb:0.0782, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:15:39.651] iteration:20907  t-loss:0.1361, loss-lb:0.0727, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:15:39.845] iteration:20908  t-loss:0.1395, loss-lb:0.0723, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:15:40.037] iteration:20909  t-loss:0.1358, loss-lb:0.0724, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:15:40.231] iteration:20910  t-loss:0.1344, loss-lb:0.0802, loss-ulb:0.0271, weight:2.00, lr:0.0003
[12:15:40.424] iteration:20911  t-loss:0.1590, loss-lb:0.0761, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:15:40.614] iteration:20912  t-loss:0.1565, loss-lb:0.0742, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:15:40.807] iteration:20913  t-loss:0.1405, loss-lb:0.0822, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:15:40.998] iteration:20914  t-loss:0.1497, loss-lb:0.0753, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:15:41.190] iteration:20915  t-loss:0.1383, loss-lb:0.0794, loss-ulb:0.0295, weight:2.00, lr:0.0003
[12:15:41.382] iteration:20916  t-loss:0.1490, loss-lb:0.0752, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:15:41.573] iteration:20917  t-loss:0.1565, loss-lb:0.0861, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:15:41.765] iteration:20918  t-loss:0.1444, loss-lb:0.0755, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:15:41.956] iteration:20919  t-loss:0.1551, loss-lb:0.0714, loss-ulb:0.0418, weight:2.00, lr:0.0003
[12:15:42.148] iteration:20920  t-loss:0.1701, loss-lb:0.0726, loss-ulb:0.0487, weight:2.00, lr:0.0003
[12:15:42.339] iteration:20921  t-loss:0.1375, loss-lb:0.0704, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:15:42.530] iteration:20922  t-loss:0.1641, loss-lb:0.0791, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:15:42.721] iteration:20923  t-loss:0.1385, loss-lb:0.0768, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:15:42.912] iteration:20924  t-loss:0.1449, loss-lb:0.0730, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:15:43.103] iteration:20925  t-loss:0.1427, loss-lb:0.0760, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:15:43.298] iteration:20926  t-loss:0.1449, loss-lb:0.0828, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:15:43.489] iteration:20927  t-loss:0.1406, loss-lb:0.0749, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:15:43.683] iteration:20928  t-loss:0.1750, loss-lb:0.0972, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:15:43.879] iteration:20929  t-loss:0.1369, loss-lb:0.0726, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:15:44.073] iteration:20930  t-loss:0.1307, loss-lb:0.0747, loss-ulb:0.0280, weight:2.00, lr:0.0003
[12:15:44.268] iteration:20931  t-loss:0.1564, loss-lb:0.0912, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:15:44.462] iteration:20932  t-loss:0.1379, loss-lb:0.0709, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:15:44.654] iteration:20933  t-loss:0.1353, loss-lb:0.0726, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:15:44.847] iteration:20934  t-loss:0.1538, loss-lb:0.0794, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:15:45.038] iteration:20935  t-loss:0.1456, loss-lb:0.0776, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:15:45.230] iteration:20936  t-loss:0.1333, loss-lb:0.0724, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:15:45.422] iteration:20937  t-loss:0.1416, loss-lb:0.0756, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:15:45.614] iteration:20938  t-loss:0.1363, loss-lb:0.0765, loss-ulb:0.0299, weight:2.00, lr:0.0003
[12:15:45.806] iteration:20939  t-loss:0.1518, loss-lb:0.0808, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:15:45.998] iteration:20940  t-loss:0.1406, loss-lb:0.0727, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:15:46.190] iteration:20941  t-loss:0.1433, loss-lb:0.0771, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:15:46.381] iteration:20942  t-loss:0.1670, loss-lb:0.0735, loss-ulb:0.0467, weight:2.00, lr:0.0003
[12:15:46.573] iteration:20943  t-loss:0.1341, loss-lb:0.0705, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:15:46.764] iteration:20944  t-loss:0.1493, loss-lb:0.0785, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:15:46.956] iteration:20945  t-loss:0.1472, loss-lb:0.0749, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:15:47.148] iteration:20946  t-loss:0.1613, loss-lb:0.0796, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:15:47.340] iteration:20947  t-loss:0.1342, loss-lb:0.0692, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:15:47.532] iteration:20948  t-loss:0.1472, loss-lb:0.0721, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:15:47.723] iteration:20949  t-loss:0.1391, loss-lb:0.0843, loss-ulb:0.0274, weight:2.00, lr:0.0003
[12:15:47.915] iteration:20950  t-loss:0.1428, loss-lb:0.0753, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:15:48.108] iteration:20951  t-loss:0.1469, loss-lb:0.0796, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:15:48.300] iteration:20952  t-loss:0.1653, loss-lb:0.0730, loss-ulb:0.0462, weight:2.00, lr:0.0003
[12:15:48.492] iteration:20953  t-loss:0.1352, loss-lb:0.0747, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:15:48.686] iteration:20954  t-loss:0.1729, loss-lb:0.0727, loss-ulb:0.0501, weight:2.00, lr:0.0003
[12:15:48.878] iteration:20955  t-loss:0.1391, loss-lb:0.0755, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:15:49.071] iteration:20956  t-loss:0.1346, loss-lb:0.0791, loss-ulb:0.0277, weight:2.00, lr:0.0003
[12:15:49.263] iteration:20957  t-loss:0.1495, loss-lb:0.0790, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:15:49.455] iteration:20958  t-loss:0.1415, loss-lb:0.0760, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:15:49.648] iteration:20959  t-loss:0.1354, loss-lb:0.0736, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:15:49.841] iteration:20960  t-loss:0.2006, loss-lb:0.0678, loss-ulb:0.0664, weight:2.00, lr:0.0003
[12:15:50.033] iteration:20961  t-loss:0.1388, loss-lb:0.0726, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:15:50.226] iteration:20962  t-loss:0.1408, loss-lb:0.0812, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:15:50.423] iteration:20963  t-loss:0.1677, loss-lb:0.0760, loss-ulb:0.0459, weight:2.00, lr:0.0003
[12:15:50.626] iteration:20964  t-loss:0.1718, loss-lb:0.0706, loss-ulb:0.0506, weight:2.00, lr:0.0003
[12:15:50.822] iteration:20965  t-loss:0.1410, loss-lb:0.0755, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:15:51.014] iteration:20966  t-loss:0.1404, loss-lb:0.0754, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:15:51.205] iteration:20967  t-loss:0.1439, loss-lb:0.0812, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:15:51.396] iteration:20968  t-loss:0.1451, loss-lb:0.0828, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:15:51.586] iteration:20969  t-loss:0.1402, loss-lb:0.0740, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:15:51.776] iteration:20970  t-loss:0.1477, loss-lb:0.0790, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:15:51.965] iteration:20971  t-loss:0.1477, loss-lb:0.0773, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:15:52.155] iteration:20972  t-loss:0.1326, loss-lb:0.0708, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:15:52.761] iteration:20973  t-loss:0.1448, loss-lb:0.0826, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:15:52.957] iteration:20974  t-loss:0.1312, loss-lb:0.0692, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:15:53.150] iteration:20975  t-loss:0.1479, loss-lb:0.0720, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:15:53.340] iteration:20976  t-loss:0.1466, loss-lb:0.0735, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:15:53.532] iteration:20977  t-loss:0.1453, loss-lb:0.0791, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:15:53.724] iteration:20978  t-loss:0.2727, loss-lb:0.0802, loss-ulb:0.0962, weight:2.00, lr:0.0003
[12:15:53.916] iteration:20979  t-loss:0.1258, loss-lb:0.0696, loss-ulb:0.0281, weight:2.00, lr:0.0003
[12:15:54.107] iteration:20980  t-loss:0.1373, loss-lb:0.0713, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:15:54.300] iteration:20981  t-loss:0.1459, loss-lb:0.0805, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:15:54.492] iteration:20982  t-loss:0.1438, loss-lb:0.0750, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:15:54.685] iteration:20983  t-loss:0.1358, loss-lb:0.0782, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:15:54.879] iteration:20984  t-loss:0.2151, loss-lb:0.0747, loss-ulb:0.0702, weight:2.00, lr:0.0003
[12:15:55.071] iteration:20985  t-loss:0.1573, loss-lb:0.0864, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:15:55.264] iteration:20986  t-loss:0.1421, loss-lb:0.0739, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:15:55.456] iteration:20987  t-loss:0.1454, loss-lb:0.0767, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:15:55.650] iteration:20988  t-loss:0.1697, loss-lb:0.0646, loss-ulb:0.0525, weight:2.00, lr:0.0003
[12:15:55.841] iteration:20989  t-loss:0.1436, loss-lb:0.0771, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:15:56.034] iteration:20990  t-loss:0.1416, loss-lb:0.0783, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:15:56.225] iteration:20991  t-loss:0.1285, loss-lb:0.0719, loss-ulb:0.0283, weight:2.00, lr:0.0003
[12:15:56.417] iteration:20992  t-loss:0.1482, loss-lb:0.0766, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:15:56.610] iteration:20993  t-loss:0.1496, loss-lb:0.0857, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:15:56.802] iteration:20994  t-loss:0.1533, loss-lb:0.0724, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:15:56.996] iteration:20995  t-loss:0.2200, loss-lb:0.0845, loss-ulb:0.0677, weight:2.00, lr:0.0003
[12:15:57.187] iteration:20996  t-loss:0.1414, loss-lb:0.0761, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:15:57.380] iteration:20997  t-loss:0.1419, loss-lb:0.0759, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:15:57.572] iteration:20998  t-loss:0.1447, loss-lb:0.0697, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:15:57.765] iteration:20999  t-loss:0.1348, loss-lb:0.0706, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:15:57.958] iteration:21000  t-loss:0.1505, loss-lb:0.0740, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:15:58.151] iteration:21001  t-loss:0.1337, loss-lb:0.0732, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:15:58.342] iteration:21002  t-loss:0.1406, loss-lb:0.0793, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:15:58.536] iteration:21003  t-loss:0.1447, loss-lb:0.0797, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:15:58.728] iteration:21004  t-loss:0.1422, loss-lb:0.0703, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:15:58.921] iteration:21005  t-loss:0.1467, loss-lb:0.0699, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:15:59.113] iteration:21006  t-loss:0.1395, loss-lb:0.0742, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:15:59.306] iteration:21007  t-loss:0.1383, loss-lb:0.0735, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:15:59.499] iteration:21008  t-loss:0.1518, loss-lb:0.0781, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:15:59.692] iteration:21009  t-loss:0.1955, loss-lb:0.0821, loss-ulb:0.0567, weight:2.00, lr:0.0003
[12:15:59.885] iteration:21010  t-loss:0.1702, loss-lb:0.0720, loss-ulb:0.0491, weight:2.00, lr:0.0003
[12:16:00.077] iteration:21011  t-loss:0.1493, loss-lb:0.0820, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:16:00.269] iteration:21012  t-loss:0.1798, loss-lb:0.0848, loss-ulb:0.0475, weight:2.00, lr:0.0003
[12:16:00.462] iteration:21013  t-loss:0.1492, loss-lb:0.0764, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:16:00.655] iteration:21014  t-loss:0.1558, loss-lb:0.0731, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:16:00.847] iteration:21015  t-loss:0.1446, loss-lb:0.0733, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:16:01.040] iteration:21016  t-loss:0.1501, loss-lb:0.0741, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:16:01.233] iteration:21017  t-loss:0.1268, loss-lb:0.0663, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:16:01.428] iteration:21018  t-loss:0.2318, loss-lb:0.0815, loss-ulb:0.0752, weight:2.00, lr:0.0003
[12:16:01.620] iteration:21019  t-loss:0.1455, loss-lb:0.0657, loss-ulb:0.0399, weight:2.00, lr:0.0003
[12:16:01.813] iteration:21020  t-loss:0.1324, loss-lb:0.0745, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:16:02.006] iteration:21021  t-loss:0.1445, loss-lb:0.0716, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:16:02.198] iteration:21022  t-loss:0.1414, loss-lb:0.0694, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:16:02.391] iteration:21023  t-loss:0.1436, loss-lb:0.0672, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:16:02.584] iteration:21024  t-loss:0.1495, loss-lb:0.0779, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:16:02.778] iteration:21025  t-loss:0.1654, loss-lb:0.0769, loss-ulb:0.0443, weight:2.00, lr:0.0003
[12:16:02.971] iteration:21026  t-loss:0.1616, loss-lb:0.0840, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:16:03.162] iteration:21027  t-loss:0.1340, loss-lb:0.0764, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:16:03.354] iteration:21028  t-loss:0.1580, loss-lb:0.0845, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:16:03.547] iteration:21029  t-loss:0.1478, loss-lb:0.0827, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:16:03.739] iteration:21030  t-loss:0.1421, loss-lb:0.0700, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:16:03.932] iteration:21031  t-loss:0.1443, loss-lb:0.0736, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:16:04.126] iteration:21032  t-loss:0.2202, loss-lb:0.0722, loss-ulb:0.0740, weight:2.00, lr:0.0003
[12:16:04.319] iteration:21033  t-loss:0.1370, loss-lb:0.0717, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:16:04.511] iteration:21034  t-loss:0.1420, loss-lb:0.0747, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:16:04.703] iteration:21035  t-loss:0.1392, loss-lb:0.0746, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:16:04.896] iteration:21036  t-loss:0.1420, loss-lb:0.0760, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:16:05.088] iteration:21037  t-loss:0.1448, loss-lb:0.0780, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:16:05.280] iteration:21038  t-loss:0.1819, loss-lb:0.0765, loss-ulb:0.0527, weight:2.00, lr:0.0003
[12:16:05.472] iteration:21039  t-loss:0.1413, loss-lb:0.0835, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:16:05.664] iteration:21040  t-loss:0.1570, loss-lb:0.0675, loss-ulb:0.0447, weight:2.00, lr:0.0003
[12:16:05.856] iteration:21041  t-loss:0.1558, loss-lb:0.0803, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:16:06.049] iteration:21042  t-loss:0.1627, loss-lb:0.0730, loss-ulb:0.0449, weight:2.00, lr:0.0003
[12:16:06.243] iteration:21043  t-loss:0.1494, loss-lb:0.0865, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:16:06.435] iteration:21044  t-loss:0.1467, loss-lb:0.0782, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:16:06.628] iteration:21045  t-loss:0.1444, loss-lb:0.0761, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:16:06.822] iteration:21046  t-loss:0.1489, loss-lb:0.0777, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:16:07.014] iteration:21047  t-loss:0.1406, loss-lb:0.0730, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:16:07.206] iteration:21048  t-loss:0.1468, loss-lb:0.0746, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:16:07.399] iteration:21049  t-loss:0.1647, loss-lb:0.0770, loss-ulb:0.0439, weight:2.00, lr:0.0003
[12:16:07.592] iteration:21050  t-loss:0.1221, loss-lb:0.0678, loss-ulb:0.0271, weight:2.00, lr:0.0003
[12:16:07.784] iteration:21051  t-loss:0.1449, loss-lb:0.0765, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:16:07.976] iteration:21052  t-loss:0.1451, loss-lb:0.0777, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:16:08.169] iteration:21053  t-loss:0.1345, loss-lb:0.0759, loss-ulb:0.0293, weight:2.00, lr:0.0003
[12:16:08.362] iteration:21054  t-loss:0.1456, loss-lb:0.0742, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:16:08.554] iteration:21055  t-loss:0.1414, loss-lb:0.0740, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:16:08.747] iteration:21056  t-loss:0.1488, loss-lb:0.0810, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:16:08.941] iteration:21057  t-loss:0.1448, loss-lb:0.0728, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:16:09.133] iteration:21058  t-loss:0.1603, loss-lb:0.0780, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:16:09.326] iteration:21059  t-loss:0.1378, loss-lb:0.0706, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:16:09.518] iteration:21060  t-loss:0.1475, loss-lb:0.0805, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:16:09.711] iteration:21061  t-loss:0.2071, loss-lb:0.0787, loss-ulb:0.0642, weight:2.00, lr:0.0003
[12:16:09.903] iteration:21062  t-loss:0.1450, loss-lb:0.0694, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:16:10.095] iteration:21063  t-loss:0.1454, loss-lb:0.0809, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:16:10.286] iteration:21064  t-loss:0.1418, loss-lb:0.0774, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:16:10.476] iteration:21065  t-loss:0.1471, loss-lb:0.0776, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:16:10.667] iteration:21066  t-loss:0.1522, loss-lb:0.0739, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:16:10.858] iteration:21067  t-loss:0.1347, loss-lb:0.0707, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:16:11.049] iteration:21068  t-loss:0.1537, loss-lb:0.0862, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:16:11.239] iteration:21069  t-loss:0.1437, loss-lb:0.0707, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:16:11.430] iteration:21070  t-loss:0.1401, loss-lb:0.0731, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:16:24.123]  <<Test>> - Ep:214  - mean_dice/mean_h95 - S:89.42/1.39, Best-S:90.99, T:89.69/1.36, Best-T:90.48
[12:16:24.123]           - AvgLoss(lb/ulb/all):0.0757/0.0360/0.1481
[12:16:24.649] iteration:21071  t-loss:0.1357, loss-lb:0.0735, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:16:24.846] iteration:21072  t-loss:0.1949, loss-lb:0.0769, loss-ulb:0.0590, weight:2.00, lr:0.0003
[12:16:25.039] iteration:21073  t-loss:0.1328, loss-lb:0.0705, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:16:25.233] iteration:21074  t-loss:0.1353, loss-lb:0.0774, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:16:25.426] iteration:21075  t-loss:0.1352, loss-lb:0.0751, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:16:25.617] iteration:21076  t-loss:0.1478, loss-lb:0.0724, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:16:25.810] iteration:21077  t-loss:0.1573, loss-lb:0.0826, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:16:26.003] iteration:21078  t-loss:0.1562, loss-lb:0.0743, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:16:26.196] iteration:21079  t-loss:0.1375, loss-lb:0.0726, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:16:26.389] iteration:21080  t-loss:0.1606, loss-lb:0.0700, loss-ulb:0.0453, weight:2.00, lr:0.0003
[12:16:26.582] iteration:21081  t-loss:0.1432, loss-lb:0.0751, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:16:26.776] iteration:21082  t-loss:0.1483, loss-lb:0.0845, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:16:26.969] iteration:21083  t-loss:0.2696, loss-lb:0.0791, loss-ulb:0.0953, weight:2.00, lr:0.0003
[12:16:27.161] iteration:21084  t-loss:0.1481, loss-lb:0.0782, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:16:27.354] iteration:21085  t-loss:0.1382, loss-lb:0.0726, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:16:27.547] iteration:21086  t-loss:0.1324, loss-lb:0.0705, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:16:27.740] iteration:21087  t-loss:0.1374, loss-lb:0.0765, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:16:27.932] iteration:21088  t-loss:0.1590, loss-lb:0.0763, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:16:28.127] iteration:21089  t-loss:0.1593, loss-lb:0.0865, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:16:28.320] iteration:21090  t-loss:0.1499, loss-lb:0.0766, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:16:28.514] iteration:21091  t-loss:0.1361, loss-lb:0.0721, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:16:28.706] iteration:21092  t-loss:0.1329, loss-lb:0.0725, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:16:28.901] iteration:21093  t-loss:0.1552, loss-lb:0.0808, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:16:29.093] iteration:21094  t-loss:0.1333, loss-lb:0.0759, loss-ulb:0.0287, weight:2.00, lr:0.0003
[12:16:29.287] iteration:21095  t-loss:0.1337, loss-lb:0.0695, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:16:29.480] iteration:21096  t-loss:0.1996, loss-lb:0.0813, loss-ulb:0.0592, weight:2.00, lr:0.0003
[12:16:29.675] iteration:21097  t-loss:0.1338, loss-lb:0.0778, loss-ulb:0.0280, weight:2.00, lr:0.0003
[12:16:29.868] iteration:21098  t-loss:0.1501, loss-lb:0.0734, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:16:30.060] iteration:21099  t-loss:0.1372, loss-lb:0.0747, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:16:30.251] iteration:21100  t-loss:0.1434, loss-lb:0.0747, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:16:30.444] iteration:21101  t-loss:0.1582, loss-lb:0.0766, loss-ulb:0.0408, weight:2.00, lr:0.0003
[12:16:30.636] iteration:21102  t-loss:0.1861, loss-lb:0.0797, loss-ulb:0.0532, weight:2.00, lr:0.0003
[12:16:30.828] iteration:21103  t-loss:0.1422, loss-lb:0.0812, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:16:31.019] iteration:21104  t-loss:0.1386, loss-lb:0.0708, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:16:31.210] iteration:21105  t-loss:0.1458, loss-lb:0.0726, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:16:31.403] iteration:21106  t-loss:0.1514, loss-lb:0.0762, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:16:31.595] iteration:21107  t-loss:0.1415, loss-lb:0.0731, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:16:31.786] iteration:21108  t-loss:0.1365, loss-lb:0.0678, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:16:31.980] iteration:21109  t-loss:0.1581, loss-lb:0.0856, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:16:32.173] iteration:21110  t-loss:0.1699, loss-lb:0.0791, loss-ulb:0.0454, weight:2.00, lr:0.0003
[12:16:32.364] iteration:21111  t-loss:0.1354, loss-lb:0.0740, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:16:32.556] iteration:21112  t-loss:0.1463, loss-lb:0.0794, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:16:32.746] iteration:21113  t-loss:0.1650, loss-lb:0.0891, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:16:32.939] iteration:21114  t-loss:0.1375, loss-lb:0.0744, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:16:33.132] iteration:21115  t-loss:0.1524, loss-lb:0.0673, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:16:33.324] iteration:21116  t-loss:0.1416, loss-lb:0.0702, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:16:33.516] iteration:21117  t-loss:0.1440, loss-lb:0.0718, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:16:33.709] iteration:21118  t-loss:0.1487, loss-lb:0.0746, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:16:33.901] iteration:21119  t-loss:0.1488, loss-lb:0.0732, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:16:34.093] iteration:21120  t-loss:0.1509, loss-lb:0.0720, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:16:34.288] iteration:21121  t-loss:0.1430, loss-lb:0.0746, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:16:34.480] iteration:21122  t-loss:0.1500, loss-lb:0.0803, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:16:34.673] iteration:21123  t-loss:0.1557, loss-lb:0.0751, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:16:34.865] iteration:21124  t-loss:0.1639, loss-lb:0.0743, loss-ulb:0.0448, weight:2.00, lr:0.0003
[12:16:35.059] iteration:21125  t-loss:0.1266, loss-lb:0.0678, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:16:35.250] iteration:21126  t-loss:0.1523, loss-lb:0.0732, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:16:35.443] iteration:21127  t-loss:0.1429, loss-lb:0.0827, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:16:35.633] iteration:21128  t-loss:0.1461, loss-lb:0.0767, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:16:35.826] iteration:21129  t-loss:0.1418, loss-lb:0.0767, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:16:36.018] iteration:21130  t-loss:0.1409, loss-lb:0.0751, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:16:36.210] iteration:21131  t-loss:0.1464, loss-lb:0.0741, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:16:36.402] iteration:21132  t-loss:0.1362, loss-lb:0.0761, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:16:36.596] iteration:21133  t-loss:0.1503, loss-lb:0.0796, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:16:36.788] iteration:21134  t-loss:0.1378, loss-lb:0.0757, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:16:36.980] iteration:21135  t-loss:0.1546, loss-lb:0.0691, loss-ulb:0.0428, weight:2.00, lr:0.0003
[12:16:37.170] iteration:21136  t-loss:0.1358, loss-lb:0.0697, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:16:37.364] iteration:21137  t-loss:0.1729, loss-lb:0.0799, loss-ulb:0.0465, weight:2.00, lr:0.0003
[12:16:37.555] iteration:21138  t-loss:0.1260, loss-lb:0.0727, loss-ulb:0.0266, weight:2.00, lr:0.0003
[12:16:37.747] iteration:21139  t-loss:0.1462, loss-lb:0.0725, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:16:37.938] iteration:21140  t-loss:0.1465, loss-lb:0.0751, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:16:38.130] iteration:21141  t-loss:0.1346, loss-lb:0.0727, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:16:38.323] iteration:21142  t-loss:0.1680, loss-lb:0.0795, loss-ulb:0.0442, weight:2.00, lr:0.0003
[12:16:38.517] iteration:21143  t-loss:0.1384, loss-lb:0.0720, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:16:38.708] iteration:21144  t-loss:0.1347, loss-lb:0.0753, loss-ulb:0.0297, weight:2.00, lr:0.0003
[12:16:38.901] iteration:21145  t-loss:0.1314, loss-lb:0.0735, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:16:39.093] iteration:21146  t-loss:0.1401, loss-lb:0.0751, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:16:39.287] iteration:21147  t-loss:0.1364, loss-lb:0.0700, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:16:39.479] iteration:21148  t-loss:0.1550, loss-lb:0.0758, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:16:39.671] iteration:21149  t-loss:0.1357, loss-lb:0.0712, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:16:39.863] iteration:21150  t-loss:0.1455, loss-lb:0.0738, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:16:40.056] iteration:21151  t-loss:0.1236, loss-lb:0.0688, loss-ulb:0.0274, weight:2.00, lr:0.0003
[12:16:40.249] iteration:21152  t-loss:0.1987, loss-lb:0.0824, loss-ulb:0.0581, weight:2.00, lr:0.0003
[12:16:40.440] iteration:21153  t-loss:0.1450, loss-lb:0.0752, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:16:40.632] iteration:21154  t-loss:0.1454, loss-lb:0.0719, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:16:40.824] iteration:21155  t-loss:0.1447, loss-lb:0.0694, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:16:41.014] iteration:21156  t-loss:0.1386, loss-lb:0.0719, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:16:41.207] iteration:21157  t-loss:0.1475, loss-lb:0.0748, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:16:41.399] iteration:21158  t-loss:0.1394, loss-lb:0.0744, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:16:41.592] iteration:21159  t-loss:0.1628, loss-lb:0.0702, loss-ulb:0.0463, weight:2.00, lr:0.0003
[12:16:41.783] iteration:21160  t-loss:0.1404, loss-lb:0.0769, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:16:41.975] iteration:21161  t-loss:0.1378, loss-lb:0.0752, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:16:42.167] iteration:21162  t-loss:0.1439, loss-lb:0.0694, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:16:42.357] iteration:21163  t-loss:0.1405, loss-lb:0.0707, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:16:42.548] iteration:21164  t-loss:0.1441, loss-lb:0.0816, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:16:42.738] iteration:21165  t-loss:0.1475, loss-lb:0.0753, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:16:42.929] iteration:21166  t-loss:0.1413, loss-lb:0.0719, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:16:43.120] iteration:21167  t-loss:0.1658, loss-lb:0.0813, loss-ulb:0.0422, weight:2.00, lr:0.0003
[12:16:43.311] iteration:21168  t-loss:0.1634, loss-lb:0.0855, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:16:43.902] iteration:21169  t-loss:0.1356, loss-lb:0.0766, loss-ulb:0.0295, weight:2.00, lr:0.0003
[12:16:44.108] iteration:21170  t-loss:0.1437, loss-lb:0.0741, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:16:44.301] iteration:21171  t-loss:0.1388, loss-lb:0.0730, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:16:44.495] iteration:21172  t-loss:0.1498, loss-lb:0.0772, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:16:44.692] iteration:21173  t-loss:0.1300, loss-lb:0.0759, loss-ulb:0.0270, weight:2.00, lr:0.0003
[12:16:44.886] iteration:21174  t-loss:0.1396, loss-lb:0.0788, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:16:45.080] iteration:21175  t-loss:0.1422, loss-lb:0.0726, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:16:45.272] iteration:21176  t-loss:0.1429, loss-lb:0.0721, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:16:45.465] iteration:21177  t-loss:0.1471, loss-lb:0.0730, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:16:45.658] iteration:21178  t-loss:0.1488, loss-lb:0.0745, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:16:45.850] iteration:21179  t-loss:0.1373, loss-lb:0.0690, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:16:46.042] iteration:21180  t-loss:0.1544, loss-lb:0.0779, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:16:46.234] iteration:21181  t-loss:0.1436, loss-lb:0.0689, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:16:46.426] iteration:21182  t-loss:0.1487, loss-lb:0.0742, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:16:46.617] iteration:21183  t-loss:0.1415, loss-lb:0.0706, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:16:46.810] iteration:21184  t-loss:0.1458, loss-lb:0.0659, loss-ulb:0.0399, weight:2.00, lr:0.0003
[12:16:47.003] iteration:21185  t-loss:0.2355, loss-lb:0.0795, loss-ulb:0.0780, weight:2.00, lr:0.0003
[12:16:47.196] iteration:21186  t-loss:0.1625, loss-lb:0.0713, loss-ulb:0.0456, weight:2.00, lr:0.0003
[12:16:47.390] iteration:21187  t-loss:0.1540, loss-lb:0.0799, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:16:47.581] iteration:21188  t-loss:0.1465, loss-lb:0.0770, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:16:47.773] iteration:21189  t-loss:0.2229, loss-lb:0.0825, loss-ulb:0.0702, weight:2.00, lr:0.0003
[12:16:47.966] iteration:21190  t-loss:0.2369, loss-lb:0.0774, loss-ulb:0.0797, weight:2.00, lr:0.0003
[12:16:48.158] iteration:21191  t-loss:0.1330, loss-lb:0.0733, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:16:48.350] iteration:21192  t-loss:0.1363, loss-lb:0.0767, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:16:48.541] iteration:21193  t-loss:0.1340, loss-lb:0.0756, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:16:48.733] iteration:21194  t-loss:0.1616, loss-lb:0.0791, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:16:48.927] iteration:21195  t-loss:0.2320, loss-lb:0.0692, loss-ulb:0.0814, weight:2.00, lr:0.0003
[12:16:49.118] iteration:21196  t-loss:0.1662, loss-lb:0.0720, loss-ulb:0.0471, weight:2.00, lr:0.0003
[12:16:49.312] iteration:21197  t-loss:0.1545, loss-lb:0.0759, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:16:49.505] iteration:21198  t-loss:0.1525, loss-lb:0.0834, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:16:49.696] iteration:21199  t-loss:0.1547, loss-lb:0.0737, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:16:49.888] iteration:21200  t-loss:0.1599, loss-lb:0.0768, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:16:50.080] iteration:21201  t-loss:0.1366, loss-lb:0.0643, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:16:50.272] iteration:21202  t-loss:0.1348, loss-lb:0.0678, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:16:50.464] iteration:21203  t-loss:0.1431, loss-lb:0.0754, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:16:50.655] iteration:21204  t-loss:0.1611, loss-lb:0.0775, loss-ulb:0.0418, weight:2.00, lr:0.0003
[12:16:50.849] iteration:21205  t-loss:0.1560, loss-lb:0.0780, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:16:51.041] iteration:21206  t-loss:0.1340, loss-lb:0.0761, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:16:51.234] iteration:21207  t-loss:0.1476, loss-lb:0.0846, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:16:51.426] iteration:21208  t-loss:0.1438, loss-lb:0.0802, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:16:51.618] iteration:21209  t-loss:0.1446, loss-lb:0.0678, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:16:51.809] iteration:21210  t-loss:0.1364, loss-lb:0.0827, loss-ulb:0.0269, weight:2.00, lr:0.0003
[12:16:52.001] iteration:21211  t-loss:0.1648, loss-lb:0.0723, loss-ulb:0.0463, weight:2.00, lr:0.0003
[12:16:52.194] iteration:21212  t-loss:0.1308, loss-lb:0.0717, loss-ulb:0.0296, weight:2.00, lr:0.0003
[12:16:52.386] iteration:21213  t-loss:0.1622, loss-lb:0.0760, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:16:52.577] iteration:21214  t-loss:0.1409, loss-lb:0.0765, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:16:52.769] iteration:21215  t-loss:0.1513, loss-lb:0.0744, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:16:52.960] iteration:21216  t-loss:0.1320, loss-lb:0.0701, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:16:53.151] iteration:21217  t-loss:0.1470, loss-lb:0.0778, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:16:53.344] iteration:21218  t-loss:0.1555, loss-lb:0.0707, loss-ulb:0.0424, weight:2.00, lr:0.0003
[12:16:53.535] iteration:21219  t-loss:0.1401, loss-lb:0.0755, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:16:53.728] iteration:21220  t-loss:0.1382, loss-lb:0.0775, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:16:53.918] iteration:21221  t-loss:0.1514, loss-lb:0.0762, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:16:54.110] iteration:21222  t-loss:0.1404, loss-lb:0.0740, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:16:54.302] iteration:21223  t-loss:0.1423, loss-lb:0.0688, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:16:54.494] iteration:21224  t-loss:0.1336, loss-lb:0.0745, loss-ulb:0.0295, weight:2.00, lr:0.0003
[12:16:54.687] iteration:21225  t-loss:0.1819, loss-lb:0.0884, loss-ulb:0.0468, weight:2.00, lr:0.0003
[12:16:54.878] iteration:21226  t-loss:0.1375, loss-lb:0.0701, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:16:55.070] iteration:21227  t-loss:0.1437, loss-lb:0.0750, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:16:55.264] iteration:21228  t-loss:0.1426, loss-lb:0.0746, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:16:55.458] iteration:21229  t-loss:0.1413, loss-lb:0.0750, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:16:55.656] iteration:21230  t-loss:0.1512, loss-lb:0.0718, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:16:55.850] iteration:21231  t-loss:0.1440, loss-lb:0.0785, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:16:56.056] iteration:21232  t-loss:0.1392, loss-lb:0.0708, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:16:56.254] iteration:21233  t-loss:0.1515, loss-lb:0.0748, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:16:56.450] iteration:21234  t-loss:0.1508, loss-lb:0.0727, loss-ulb:0.0391, weight:2.00, lr:0.0003
[12:16:56.644] iteration:21235  t-loss:0.1477, loss-lb:0.0769, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:16:56.836] iteration:21236  t-loss:0.1480, loss-lb:0.0740, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:16:57.029] iteration:21237  t-loss:0.1425, loss-lb:0.0730, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:16:57.221] iteration:21238  t-loss:0.1427, loss-lb:0.0724, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:16:57.413] iteration:21239  t-loss:0.1434, loss-lb:0.0859, loss-ulb:0.0287, weight:2.00, lr:0.0003
[12:16:57.605] iteration:21240  t-loss:0.1350, loss-lb:0.0686, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:16:57.797] iteration:21241  t-loss:0.1388, loss-lb:0.0757, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:16:57.989] iteration:21242  t-loss:0.1563, loss-lb:0.0779, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:16:58.180] iteration:21243  t-loss:0.1818, loss-lb:0.0717, loss-ulb:0.0550, weight:2.00, lr:0.0003
[12:16:58.372] iteration:21244  t-loss:0.1520, loss-lb:0.0836, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:16:58.565] iteration:21245  t-loss:0.1722, loss-lb:0.0725, loss-ulb:0.0498, weight:2.00, lr:0.0003
[12:16:58.756] iteration:21246  t-loss:0.1419, loss-lb:0.0765, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:16:58.948] iteration:21247  t-loss:0.1512, loss-lb:0.0800, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:16:59.141] iteration:21248  t-loss:0.1531, loss-lb:0.0644, loss-ulb:0.0443, weight:2.00, lr:0.0003
[12:16:59.333] iteration:21249  t-loss:0.1237, loss-lb:0.0653, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:16:59.525] iteration:21250  t-loss:0.1587, loss-lb:0.0865, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:16:59.720] iteration:21251  t-loss:0.1387, loss-lb:0.0703, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:16:59.912] iteration:21252  t-loss:0.1444, loss-lb:0.0749, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:17:00.105] iteration:21253  t-loss:0.1469, loss-lb:0.0766, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:17:00.297] iteration:21254  t-loss:0.1307, loss-lb:0.0706, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:17:00.490] iteration:21255  t-loss:0.1421, loss-lb:0.0784, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:17:00.683] iteration:21256  t-loss:0.1466, loss-lb:0.0705, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:17:00.875] iteration:21257  t-loss:0.1430, loss-lb:0.0814, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:17:01.066] iteration:21258  t-loss:0.1529, loss-lb:0.0762, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:17:01.258] iteration:21259  t-loss:0.1500, loss-lb:0.0730, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:17:01.449] iteration:21260  t-loss:0.1557, loss-lb:0.0817, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:17:01.640] iteration:21261  t-loss:0.1486, loss-lb:0.0841, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:17:01.830] iteration:21262  t-loss:0.1424, loss-lb:0.0808, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:17:02.021] iteration:21263  t-loss:0.1307, loss-lb:0.0723, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:17:02.212] iteration:21264  t-loss:0.1428, loss-lb:0.0756, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:17:02.404] iteration:21265  t-loss:0.1516, loss-lb:0.0679, loss-ulb:0.0418, weight:2.00, lr:0.0003
[12:17:02.594] iteration:21266  t-loss:0.1451, loss-lb:0.0737, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:17:14.870]  <<Test>> - Ep:216  - mean_dice/mean_h95 - S:89.80/1.33, Best-S:90.99, T:89.80/1.34, Best-T:90.48
[12:17:14.871]           - AvgLoss(lb/ulb/all):0.0750/0.0349/0.1449
[12:17:15.415] iteration:21267  t-loss:0.2021, loss-lb:0.0740, loss-ulb:0.0641, weight:2.00, lr:0.0003
[12:17:15.613] iteration:21268  t-loss:0.1578, loss-lb:0.0746, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:17:15.803] iteration:21269  t-loss:0.1535, loss-lb:0.0732, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:17:15.995] iteration:21270  t-loss:0.1555, loss-lb:0.0793, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:17:16.188] iteration:21271  t-loss:0.1295, loss-lb:0.0748, loss-ulb:0.0273, weight:2.00, lr:0.0003
[12:17:16.380] iteration:21272  t-loss:0.1425, loss-lb:0.0779, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:17:16.571] iteration:21273  t-loss:0.1421, loss-lb:0.0751, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:17:16.763] iteration:21274  t-loss:0.1507, loss-lb:0.0723, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:17:16.955] iteration:21275  t-loss:0.1388, loss-lb:0.0763, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:17:17.150] iteration:21276  t-loss:0.1674, loss-lb:0.0720, loss-ulb:0.0477, weight:2.00, lr:0.0003
[12:17:17.345] iteration:21277  t-loss:0.1466, loss-lb:0.0738, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:17:17.541] iteration:21278  t-loss:0.1889, loss-lb:0.0704, loss-ulb:0.0593, weight:2.00, lr:0.0003
[12:17:17.737] iteration:21279  t-loss:0.1537, loss-lb:0.0789, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:17:17.930] iteration:21280  t-loss:0.1458, loss-lb:0.0813, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:17:18.121] iteration:21281  t-loss:0.1320, loss-lb:0.0742, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:17:18.314] iteration:21282  t-loss:0.1361, loss-lb:0.0704, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:17:18.507] iteration:21283  t-loss:0.1425, loss-lb:0.0781, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:17:18.700] iteration:21284  t-loss:0.1447, loss-lb:0.0714, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:17:18.891] iteration:21285  t-loss:0.1441, loss-lb:0.0759, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:17:19.084] iteration:21286  t-loss:0.1364, loss-lb:0.0715, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:17:19.277] iteration:21287  t-loss:0.1272, loss-lb:0.0689, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:17:19.468] iteration:21288  t-loss:0.1380, loss-lb:0.0728, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:17:19.660] iteration:21289  t-loss:0.1413, loss-lb:0.0808, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:17:19.854] iteration:21290  t-loss:0.1588, loss-lb:0.0790, loss-ulb:0.0399, weight:2.00, lr:0.0003
[12:17:20.048] iteration:21291  t-loss:0.1391, loss-lb:0.0745, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:17:20.240] iteration:21292  t-loss:0.1495, loss-lb:0.0691, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:17:20.432] iteration:21293  t-loss:0.2150, loss-lb:0.0750, loss-ulb:0.0700, weight:2.00, lr:0.0003
[12:17:20.626] iteration:21294  t-loss:0.1442, loss-lb:0.0738, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:17:20.819] iteration:21295  t-loss:0.1271, loss-lb:0.0671, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:17:21.011] iteration:21296  t-loss:0.1465, loss-lb:0.0791, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:17:21.200] iteration:21297  t-loss:0.1667, loss-lb:0.0702, loss-ulb:0.0482, weight:2.00, lr:0.0003
[12:17:21.390] iteration:21298  t-loss:0.1471, loss-lb:0.0746, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:17:21.583] iteration:21299  t-loss:0.1518, loss-lb:0.0706, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:17:21.774] iteration:21300  t-loss:0.1375, loss-lb:0.0697, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:17:21.966] iteration:21301  t-loss:0.1495, loss-lb:0.0765, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:17:22.158] iteration:21302  t-loss:0.2123, loss-lb:0.0783, loss-ulb:0.0670, weight:2.00, lr:0.0003
[12:17:22.350] iteration:21303  t-loss:0.1717, loss-lb:0.0864, loss-ulb:0.0427, weight:2.00, lr:0.0003
[12:17:22.542] iteration:21304  t-loss:0.1399, loss-lb:0.0665, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:17:22.733] iteration:21305  t-loss:0.1529, loss-lb:0.0826, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:17:22.926] iteration:21306  t-loss:0.1522, loss-lb:0.0758, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:17:23.117] iteration:21307  t-loss:0.1377, loss-lb:0.0662, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:17:23.309] iteration:21308  t-loss:0.1465, loss-lb:0.0736, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:17:23.501] iteration:21309  t-loss:0.1833, loss-lb:0.0937, loss-ulb:0.0448, weight:2.00, lr:0.0003
[12:17:23.693] iteration:21310  t-loss:0.1575, loss-lb:0.0747, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:17:23.885] iteration:21311  t-loss:0.1374, loss-lb:0.0710, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:17:24.078] iteration:21312  t-loss:0.1473, loss-lb:0.0820, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:17:24.270] iteration:21313  t-loss:0.1900, loss-lb:0.0764, loss-ulb:0.0568, weight:2.00, lr:0.0003
[12:17:24.463] iteration:21314  t-loss:0.1716, loss-lb:0.0787, loss-ulb:0.0465, weight:2.00, lr:0.0003
[12:17:24.654] iteration:21315  t-loss:0.1691, loss-lb:0.0876, loss-ulb:0.0408, weight:2.00, lr:0.0003
[12:17:24.846] iteration:21316  t-loss:0.1345, loss-lb:0.0814, loss-ulb:0.0266, weight:2.00, lr:0.0003
[12:17:25.037] iteration:21317  t-loss:0.1396, loss-lb:0.0772, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:17:25.229] iteration:21318  t-loss:0.1497, loss-lb:0.0817, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:17:25.420] iteration:21319  t-loss:0.1541, loss-lb:0.0793, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:17:25.612] iteration:21320  t-loss:0.1736, loss-lb:0.0823, loss-ulb:0.0457, weight:2.00, lr:0.0003
[12:17:25.802] iteration:21321  t-loss:0.1627, loss-lb:0.0789, loss-ulb:0.0419, weight:2.00, lr:0.0003
[12:17:25.992] iteration:21322  t-loss:0.1567, loss-lb:0.0800, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:17:26.185] iteration:21323  t-loss:0.1770, loss-lb:0.0887, loss-ulb:0.0441, weight:2.00, lr:0.0003
[12:17:26.376] iteration:21324  t-loss:0.1453, loss-lb:0.0787, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:17:26.566] iteration:21325  t-loss:0.1541, loss-lb:0.0837, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:17:26.759] iteration:21326  t-loss:0.1549, loss-lb:0.0774, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:17:26.950] iteration:21327  t-loss:0.2421, loss-lb:0.0806, loss-ulb:0.0807, weight:2.00, lr:0.0003
[12:17:27.142] iteration:21328  t-loss:0.1484, loss-lb:0.0756, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:17:27.332] iteration:21329  t-loss:0.1689, loss-lb:0.0776, loss-ulb:0.0457, weight:2.00, lr:0.0003
[12:17:27.524] iteration:21330  t-loss:0.1494, loss-lb:0.0796, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:17:27.716] iteration:21331  t-loss:0.1777, loss-lb:0.0878, loss-ulb:0.0450, weight:2.00, lr:0.0003
[12:17:27.908] iteration:21332  t-loss:0.1525, loss-lb:0.0748, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:17:28.099] iteration:21333  t-loss:0.1649, loss-lb:0.0875, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:17:28.293] iteration:21334  t-loss:0.1533, loss-lb:0.0780, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:17:28.486] iteration:21335  t-loss:0.1475, loss-lb:0.0791, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:17:28.680] iteration:21336  t-loss:0.1595, loss-lb:0.0771, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:17:28.880] iteration:21337  t-loss:0.2109, loss-lb:0.0777, loss-ulb:0.0666, weight:2.00, lr:0.0003
[12:17:29.080] iteration:21338  t-loss:0.1616, loss-lb:0.0871, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:17:29.273] iteration:21339  t-loss:0.1539, loss-lb:0.0744, loss-ulb:0.0398, weight:2.00, lr:0.0003
[12:17:29.465] iteration:21340  t-loss:0.1456, loss-lb:0.0778, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:17:29.656] iteration:21341  t-loss:0.1353, loss-lb:0.0774, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:17:29.849] iteration:21342  t-loss:0.1470, loss-lb:0.0842, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:17:30.040] iteration:21343  t-loss:0.1488, loss-lb:0.0875, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:17:30.232] iteration:21344  t-loss:0.1645, loss-lb:0.0839, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:17:30.424] iteration:21345  t-loss:0.1834, loss-lb:0.0831, loss-ulb:0.0501, weight:2.00, lr:0.0003
[12:17:30.616] iteration:21346  t-loss:0.1587, loss-lb:0.0771, loss-ulb:0.0408, weight:2.00, lr:0.0003
[12:17:30.808] iteration:21347  t-loss:0.1418, loss-lb:0.0700, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:17:31.000] iteration:21348  t-loss:0.1408, loss-lb:0.0806, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:17:31.192] iteration:21349  t-loss:0.1386, loss-lb:0.0729, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:17:31.385] iteration:21350  t-loss:0.1475, loss-lb:0.0801, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:17:31.577] iteration:21351  t-loss:0.1520, loss-lb:0.0802, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:17:31.769] iteration:21352  t-loss:0.1632, loss-lb:0.0811, loss-ulb:0.0411, weight:2.00, lr:0.0003
[12:17:31.961] iteration:21353  t-loss:0.1450, loss-lb:0.0827, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:17:32.153] iteration:21354  t-loss:0.1380, loss-lb:0.0687, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:17:32.347] iteration:21355  t-loss:0.1433, loss-lb:0.0764, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:17:32.540] iteration:21356  t-loss:0.2493, loss-lb:0.0773, loss-ulb:0.0860, weight:2.00, lr:0.0003
[12:17:32.731] iteration:21357  t-loss:0.1381, loss-lb:0.0834, loss-ulb:0.0274, weight:2.00, lr:0.0003
[12:17:32.922] iteration:21358  t-loss:0.1539, loss-lb:0.0834, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:17:33.113] iteration:21359  t-loss:0.1636, loss-lb:0.0792, loss-ulb:0.0422, weight:2.00, lr:0.0003
[12:17:33.304] iteration:21360  t-loss:0.1565, loss-lb:0.0852, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:17:33.495] iteration:21361  t-loss:0.2664, loss-lb:0.0757, loss-ulb:0.0954, weight:2.00, lr:0.0003
[12:17:33.686] iteration:21362  t-loss:0.1956, loss-lb:0.0830, loss-ulb:0.0563, weight:2.00, lr:0.0003
[12:17:33.878] iteration:21363  t-loss:0.1471, loss-lb:0.0691, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:17:34.068] iteration:21364  t-loss:0.1526, loss-lb:0.0814, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:17:34.654] iteration:21365  t-loss:0.1529, loss-lb:0.0780, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:17:34.849] iteration:21366  t-loss:0.1433, loss-lb:0.0765, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:17:35.042] iteration:21367  t-loss:0.1445, loss-lb:0.0712, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:17:35.236] iteration:21368  t-loss:0.1490, loss-lb:0.0884, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:17:35.429] iteration:21369  t-loss:0.1902, loss-lb:0.0780, loss-ulb:0.0561, weight:2.00, lr:0.0003
[12:17:35.620] iteration:21370  t-loss:0.1357, loss-lb:0.0745, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:17:35.813] iteration:21371  t-loss:0.1452, loss-lb:0.0809, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:17:36.006] iteration:21372  t-loss:0.2455, loss-lb:0.0741, loss-ulb:0.0857, weight:2.00, lr:0.0003
[12:17:36.198] iteration:21373  t-loss:0.1453, loss-lb:0.0820, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:17:36.390] iteration:21374  t-loss:0.1469, loss-lb:0.0784, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:17:36.583] iteration:21375  t-loss:0.1352, loss-lb:0.0754, loss-ulb:0.0299, weight:2.00, lr:0.0003
[12:17:36.777] iteration:21376  t-loss:0.1480, loss-lb:0.0713, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:17:36.969] iteration:21377  t-loss:0.1858, loss-lb:0.0811, loss-ulb:0.0523, weight:2.00, lr:0.0003
[12:17:37.162] iteration:21378  t-loss:0.1439, loss-lb:0.0790, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:17:37.354] iteration:21379  t-loss:0.1749, loss-lb:0.0812, loss-ulb:0.0469, weight:2.00, lr:0.0003
[12:17:37.547] iteration:21380  t-loss:0.1978, loss-lb:0.0753, loss-ulb:0.0612, weight:2.00, lr:0.0003
[12:17:37.739] iteration:21381  t-loss:0.1530, loss-lb:0.0783, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:17:37.931] iteration:21382  t-loss:0.1426, loss-lb:0.0793, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:17:38.124] iteration:21383  t-loss:0.1750, loss-lb:0.0848, loss-ulb:0.0451, weight:2.00, lr:0.0003
[12:17:38.317] iteration:21384  t-loss:0.1580, loss-lb:0.0814, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:17:38.509] iteration:21385  t-loss:0.1513, loss-lb:0.0817, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:17:38.702] iteration:21386  t-loss:0.2118, loss-lb:0.0926, loss-ulb:0.0596, weight:2.00, lr:0.0003
[12:17:38.894] iteration:21387  t-loss:0.1492, loss-lb:0.0727, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:17:39.086] iteration:21388  t-loss:0.1561, loss-lb:0.0717, loss-ulb:0.0422, weight:2.00, lr:0.0003
[12:17:39.279] iteration:21389  t-loss:0.1500, loss-lb:0.0796, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:17:39.471] iteration:21390  t-loss:0.1495, loss-lb:0.0772, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:17:39.664] iteration:21391  t-loss:0.1910, loss-lb:0.0838, loss-ulb:0.0536, weight:2.00, lr:0.0003
[12:17:39.856] iteration:21392  t-loss:0.1591, loss-lb:0.0809, loss-ulb:0.0391, weight:2.00, lr:0.0003
[12:17:40.048] iteration:21393  t-loss:0.1401, loss-lb:0.0725, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:17:40.240] iteration:21394  t-loss:0.1463, loss-lb:0.0776, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:17:40.434] iteration:21395  t-loss:0.1427, loss-lb:0.0742, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:17:40.627] iteration:21396  t-loss:0.1648, loss-lb:0.0738, loss-ulb:0.0455, weight:2.00, lr:0.0003
[12:17:40.818] iteration:21397  t-loss:0.1357, loss-lb:0.0701, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:17:41.011] iteration:21398  t-loss:0.1812, loss-lb:0.0740, loss-ulb:0.0536, weight:2.00, lr:0.0003
[12:17:41.204] iteration:21399  t-loss:0.1377, loss-lb:0.0734, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:17:41.397] iteration:21400  t-loss:0.1551, loss-lb:0.0851, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:17:41.590] iteration:21401  t-loss:0.1399, loss-lb:0.0784, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:17:41.782] iteration:21402  t-loss:0.1805, loss-lb:0.0770, loss-ulb:0.0517, weight:2.00, lr:0.0003
[12:17:41.975] iteration:21403  t-loss:0.1386, loss-lb:0.0793, loss-ulb:0.0296, weight:2.00, lr:0.0003
[12:17:42.167] iteration:21404  t-loss:0.1396, loss-lb:0.0754, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:17:42.360] iteration:21405  t-loss:0.1405, loss-lb:0.0747, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:17:42.552] iteration:21406  t-loss:0.1620, loss-lb:0.0855, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:17:42.745] iteration:21407  t-loss:0.1767, loss-lb:0.0812, loss-ulb:0.0477, weight:2.00, lr:0.0003
[12:17:42.936] iteration:21408  t-loss:0.1425, loss-lb:0.0819, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:17:43.128] iteration:21409  t-loss:0.1528, loss-lb:0.0726, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:17:43.321] iteration:21410  t-loss:0.1515, loss-lb:0.0786, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:17:43.512] iteration:21411  t-loss:0.1474, loss-lb:0.0835, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:17:43.705] iteration:21412  t-loss:0.1486, loss-lb:0.0751, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:17:43.897] iteration:21413  t-loss:0.1651, loss-lb:0.0819, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:17:44.089] iteration:21414  t-loss:0.1368, loss-lb:0.0754, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:17:44.281] iteration:21415  t-loss:0.1482, loss-lb:0.0767, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:17:44.473] iteration:21416  t-loss:0.1448, loss-lb:0.0736, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:17:44.665] iteration:21417  t-loss:0.1303, loss-lb:0.0753, loss-ulb:0.0275, weight:2.00, lr:0.0003
[12:17:44.858] iteration:21418  t-loss:0.1502, loss-lb:0.0705, loss-ulb:0.0398, weight:2.00, lr:0.0003
[12:17:45.050] iteration:21419  t-loss:0.1375, loss-lb:0.0702, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:17:45.242] iteration:21420  t-loss:0.1469, loss-lb:0.0727, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:17:45.434] iteration:21421  t-loss:0.1291, loss-lb:0.0707, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:17:45.626] iteration:21422  t-loss:0.1380, loss-lb:0.0714, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:17:45.819] iteration:21423  t-loss:0.1453, loss-lb:0.0805, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:17:46.011] iteration:21424  t-loss:0.1434, loss-lb:0.0750, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:17:46.204] iteration:21425  t-loss:0.1472, loss-lb:0.0715, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:17:46.397] iteration:21426  t-loss:0.2186, loss-lb:0.0682, loss-ulb:0.0752, weight:2.00, lr:0.0003
[12:17:46.590] iteration:21427  t-loss:0.1509, loss-lb:0.0738, loss-ulb:0.0386, weight:2.00, lr:0.0003
[12:17:46.782] iteration:21428  t-loss:0.1537, loss-lb:0.0779, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:17:46.976] iteration:21429  t-loss:0.1646, loss-lb:0.0804, loss-ulb:0.0421, weight:2.00, lr:0.0003
[12:17:47.169] iteration:21430  t-loss:0.1914, loss-lb:0.0734, loss-ulb:0.0590, weight:2.00, lr:0.0003
[12:17:47.361] iteration:21431  t-loss:0.1451, loss-lb:0.0781, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:17:47.553] iteration:21432  t-loss:0.1607, loss-lb:0.0722, loss-ulb:0.0442, weight:2.00, lr:0.0003
[12:17:47.745] iteration:21433  t-loss:0.1592, loss-lb:0.0803, loss-ulb:0.0394, weight:2.00, lr:0.0003
[12:17:47.937] iteration:21434  t-loss:0.1357, loss-lb:0.0749, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:17:48.130] iteration:21435  t-loss:0.2173, loss-lb:0.0697, loss-ulb:0.0738, weight:2.00, lr:0.0003
[12:17:48.323] iteration:21436  t-loss:0.1520, loss-lb:0.0789, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:17:48.517] iteration:21437  t-loss:0.1393, loss-lb:0.0749, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:17:48.710] iteration:21438  t-loss:0.1368, loss-lb:0.0788, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:17:48.902] iteration:21439  t-loss:0.1377, loss-lb:0.0729, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:17:49.095] iteration:21440  t-loss:0.1414, loss-lb:0.0785, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:17:49.288] iteration:21441  t-loss:0.1858, loss-lb:0.0789, loss-ulb:0.0534, weight:2.00, lr:0.0003
[12:17:49.481] iteration:21442  t-loss:0.1899, loss-lb:0.0792, loss-ulb:0.0553, weight:2.00, lr:0.0003
[12:17:49.673] iteration:21443  t-loss:0.1445, loss-lb:0.0805, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:17:49.866] iteration:21444  t-loss:0.1987, loss-lb:0.0816, loss-ulb:0.0586, weight:2.00, lr:0.0003
[12:17:50.058] iteration:21445  t-loss:0.1918, loss-lb:0.0753, loss-ulb:0.0583, weight:2.00, lr:0.0003
[12:17:50.251] iteration:21446  t-loss:0.1683, loss-lb:0.0796, loss-ulb:0.0444, weight:2.00, lr:0.0003
[12:17:50.443] iteration:21447  t-loss:0.1412, loss-lb:0.0692, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:17:50.636] iteration:21448  t-loss:0.1885, loss-lb:0.0795, loss-ulb:0.0545, weight:2.00, lr:0.0003
[12:17:50.828] iteration:21449  t-loss:0.1583, loss-lb:0.0754, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:17:51.021] iteration:21450  t-loss:0.1664, loss-lb:0.0723, loss-ulb:0.0470, weight:2.00, lr:0.0003
[12:17:51.213] iteration:21451  t-loss:0.1429, loss-lb:0.0740, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:17:51.406] iteration:21452  t-loss:0.1398, loss-lb:0.0735, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:17:51.599] iteration:21453  t-loss:0.1642, loss-lb:0.0877, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:17:51.790] iteration:21454  t-loss:0.1545, loss-lb:0.0874, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:17:51.982] iteration:21455  t-loss:0.1506, loss-lb:0.0826, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:17:52.173] iteration:21456  t-loss:0.1442, loss-lb:0.0805, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:17:52.364] iteration:21457  t-loss:0.1387, loss-lb:0.0761, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:17:52.555] iteration:21458  t-loss:0.1516, loss-lb:0.0792, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:17:52.747] iteration:21459  t-loss:0.1664, loss-lb:0.0829, loss-ulb:0.0417, weight:2.00, lr:0.0003
[12:17:52.937] iteration:21460  t-loss:0.1360, loss-lb:0.0759, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:17:53.128] iteration:21461  t-loss:0.1889, loss-lb:0.0729, loss-ulb:0.0580, weight:2.00, lr:0.0003
[12:17:53.319] iteration:21462  t-loss:0.1500, loss-lb:0.0781, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:18:05.791]  <<Test>> - Ep:218  - mean_dice/mean_h95 - S:89.45/1.41, Best-S:90.99, T:89.63/1.40, Best-T:90.48
[12:18:05.792]           - AvgLoss(lb/ulb/all):0.0773/0.0405/0.1593
[12:18:06.315] iteration:21463  t-loss:0.1450, loss-lb:0.0782, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:18:06.511] iteration:21464  t-loss:0.1515, loss-lb:0.0806, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:18:06.703] iteration:21465  t-loss:0.1446, loss-lb:0.0682, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:18:06.896] iteration:21466  t-loss:0.1432, loss-lb:0.0766, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:18:07.089] iteration:21467  t-loss:0.1391, loss-lb:0.0817, loss-ulb:0.0287, weight:2.00, lr:0.0003
[12:18:07.282] iteration:21468  t-loss:0.1523, loss-lb:0.0810, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:18:07.474] iteration:21469  t-loss:0.1354, loss-lb:0.0745, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:18:07.666] iteration:21470  t-loss:0.1536, loss-lb:0.0733, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:18:07.860] iteration:21471  t-loss:0.1351, loss-lb:0.0731, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:18:08.052] iteration:21472  t-loss:0.1592, loss-lb:0.0763, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:18:08.245] iteration:21473  t-loss:0.1403, loss-lb:0.0792, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:18:08.438] iteration:21474  t-loss:0.1423, loss-lb:0.0736, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:18:08.632] iteration:21475  t-loss:0.1470, loss-lb:0.0814, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:18:08.827] iteration:21476  t-loss:0.1452, loss-lb:0.0788, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:18:09.019] iteration:21477  t-loss:0.1336, loss-lb:0.0707, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:18:09.211] iteration:21478  t-loss:0.1416, loss-lb:0.0742, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:18:09.404] iteration:21479  t-loss:0.1434, loss-lb:0.0805, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:18:09.597] iteration:21480  t-loss:0.1419, loss-lb:0.0798, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:18:09.789] iteration:21481  t-loss:0.1594, loss-lb:0.0919, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:18:09.982] iteration:21482  t-loss:0.1825, loss-lb:0.0733, loss-ulb:0.0546, weight:2.00, lr:0.0003
[12:18:10.175] iteration:21483  t-loss:0.1403, loss-lb:0.0701, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:18:10.368] iteration:21484  t-loss:0.1362, loss-lb:0.0749, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:18:10.561] iteration:21485  t-loss:0.1437, loss-lb:0.0718, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:18:10.754] iteration:21486  t-loss:0.1338, loss-lb:0.0723, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:18:10.947] iteration:21487  t-loss:0.1604, loss-lb:0.0722, loss-ulb:0.0441, weight:2.00, lr:0.0003
[12:18:11.141] iteration:21488  t-loss:0.1568, loss-lb:0.0740, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:18:11.333] iteration:21489  t-loss:0.1420, loss-lb:0.0716, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:18:11.526] iteration:21490  t-loss:0.1372, loss-lb:0.0713, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:18:11.719] iteration:21491  t-loss:0.1358, loss-lb:0.0732, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:18:11.911] iteration:21492  t-loss:0.1628, loss-lb:0.0742, loss-ulb:0.0443, weight:2.00, lr:0.0003
[12:18:12.104] iteration:21493  t-loss:0.1408, loss-lb:0.0706, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:18:12.295] iteration:21494  t-loss:0.1443, loss-lb:0.0778, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:18:12.488] iteration:21495  t-loss:0.1594, loss-lb:0.0698, loss-ulb:0.0448, weight:2.00, lr:0.0003
[12:18:12.680] iteration:21496  t-loss:0.1444, loss-lb:0.0731, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:18:12.874] iteration:21497  t-loss:0.1409, loss-lb:0.0782, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:18:13.066] iteration:21498  t-loss:0.1486, loss-lb:0.0760, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:18:13.259] iteration:21499  t-loss:0.1277, loss-lb:0.0669, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:18:13.451] iteration:21500  t-loss:0.1535, loss-lb:0.0766, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:18:13.643] iteration:21501  t-loss:0.1362, loss-lb:0.0790, loss-ulb:0.0286, weight:2.00, lr:0.0003
[12:18:13.835] iteration:21502  t-loss:0.1247, loss-lb:0.0710, loss-ulb:0.0268, weight:2.00, lr:0.0003
[12:18:14.027] iteration:21503  t-loss:0.1586, loss-lb:0.0795, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:18:14.218] iteration:21504  t-loss:0.1351, loss-lb:0.0752, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:18:14.412] iteration:21505  t-loss:0.1531, loss-lb:0.0748, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:18:14.605] iteration:21506  t-loss:0.1363, loss-lb:0.0760, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:18:14.798] iteration:21507  t-loss:0.1512, loss-lb:0.0721, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:18:14.990] iteration:21508  t-loss:0.1405, loss-lb:0.0725, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:18:15.182] iteration:21509  t-loss:0.1485, loss-lb:0.0751, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:18:15.374] iteration:21510  t-loss:0.1485, loss-lb:0.0690, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:18:15.566] iteration:21511  t-loss:0.2052, loss-lb:0.0820, loss-ulb:0.0616, weight:2.00, lr:0.0003
[12:18:15.762] iteration:21512  t-loss:0.1482, loss-lb:0.0727, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:18:15.955] iteration:21513  t-loss:0.1404, loss-lb:0.0711, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:18:16.147] iteration:21514  t-loss:0.1596, loss-lb:0.0772, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:18:16.340] iteration:21515  t-loss:0.2338, loss-lb:0.0749, loss-ulb:0.0794, weight:2.00, lr:0.0003
[12:18:16.532] iteration:21516  t-loss:0.1573, loss-lb:0.0803, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:18:16.726] iteration:21517  t-loss:0.1988, loss-lb:0.0744, loss-ulb:0.0622, weight:2.00, lr:0.0003
[12:18:16.918] iteration:21518  t-loss:0.1411, loss-lb:0.0767, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:18:17.111] iteration:21519  t-loss:0.2732, loss-lb:0.0848, loss-ulb:0.0942, weight:2.00, lr:0.0003
[12:18:17.303] iteration:21520  t-loss:0.1528, loss-lb:0.0801, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:18:17.496] iteration:21521  t-loss:0.1709, loss-lb:0.0774, loss-ulb:0.0468, weight:2.00, lr:0.0003
[12:18:17.689] iteration:21522  t-loss:0.1535, loss-lb:0.0815, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:18:17.881] iteration:21523  t-loss:0.1368, loss-lb:0.0715, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:18:18.073] iteration:21524  t-loss:0.1453, loss-lb:0.0720, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:18:18.267] iteration:21525  t-loss:0.1521, loss-lb:0.0759, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:18:18.462] iteration:21526  t-loss:0.1715, loss-lb:0.0776, loss-ulb:0.0470, weight:2.00, lr:0.0003
[12:18:18.657] iteration:21527  t-loss:0.1569, loss-lb:0.0783, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:18:18.852] iteration:21528  t-loss:0.1416, loss-lb:0.0752, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:18:19.047] iteration:21529  t-loss:0.1700, loss-lb:0.0809, loss-ulb:0.0446, weight:2.00, lr:0.0003
[12:18:19.240] iteration:21530  t-loss:0.1502, loss-lb:0.0788, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:18:19.433] iteration:21531  t-loss:0.1443, loss-lb:0.0844, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:18:19.626] iteration:21532  t-loss:0.1467, loss-lb:0.0765, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:18:19.817] iteration:21533  t-loss:0.1474, loss-lb:0.0770, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:18:20.009] iteration:21534  t-loss:0.2486, loss-lb:0.0858, loss-ulb:0.0814, weight:2.00, lr:0.0003
[12:18:20.202] iteration:21535  t-loss:0.1433, loss-lb:0.0772, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:18:20.394] iteration:21536  t-loss:0.1666, loss-lb:0.0726, loss-ulb:0.0470, weight:2.00, lr:0.0003
[12:18:20.586] iteration:21537  t-loss:0.1576, loss-lb:0.0743, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:18:20.779] iteration:21538  t-loss:0.1384, loss-lb:0.0808, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:18:20.970] iteration:21539  t-loss:0.1366, loss-lb:0.0708, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:18:21.162] iteration:21540  t-loss:0.1323, loss-lb:0.0741, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:18:21.354] iteration:21541  t-loss:0.1370, loss-lb:0.0704, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:18:21.546] iteration:21542  t-loss:0.1575, loss-lb:0.0789, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:18:21.739] iteration:21543  t-loss:0.1475, loss-lb:0.0804, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:18:21.930] iteration:21544  t-loss:0.1523, loss-lb:0.0850, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:18:22.123] iteration:21545  t-loss:0.1533, loss-lb:0.0786, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:18:22.314] iteration:21546  t-loss:0.1495, loss-lb:0.0739, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:18:22.506] iteration:21547  t-loss:0.1362, loss-lb:0.0708, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:18:22.698] iteration:21548  t-loss:0.1363, loss-lb:0.0753, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:18:22.889] iteration:21549  t-loss:0.1521, loss-lb:0.0762, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:18:23.081] iteration:21550  t-loss:0.1976, loss-lb:0.0681, loss-ulb:0.0647, weight:2.00, lr:0.0003
[12:18:23.274] iteration:21551  t-loss:0.1612, loss-lb:0.0874, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:18:23.466] iteration:21552  t-loss:0.1527, loss-lb:0.0736, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:18:23.656] iteration:21553  t-loss:0.1316, loss-lb:0.0735, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:18:23.848] iteration:21554  t-loss:0.1450, loss-lb:0.0698, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:18:24.039] iteration:21555  t-loss:0.1454, loss-lb:0.0724, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:18:24.229] iteration:21556  t-loss:0.1536, loss-lb:0.0883, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:18:24.420] iteration:21557  t-loss:0.1395, loss-lb:0.0708, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:18:24.611] iteration:21558  t-loss:0.1567, loss-lb:0.0784, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:18:24.801] iteration:21559  t-loss:0.1488, loss-lb:0.0756, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:18:24.992] iteration:21560  t-loss:0.1595, loss-lb:0.0831, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:18:25.584] iteration:21561  t-loss:0.1357, loss-lb:0.0714, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:18:25.777] iteration:21562  t-loss:0.1583, loss-lb:0.0794, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:18:25.970] iteration:21563  t-loss:0.1774, loss-lb:0.0796, loss-ulb:0.0489, weight:2.00, lr:0.0003
[12:18:26.162] iteration:21564  t-loss:0.1576, loss-lb:0.0776, loss-ulb:0.0400, weight:2.00, lr:0.0003
[12:18:26.354] iteration:21565  t-loss:0.1406, loss-lb:0.0764, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:18:26.546] iteration:21566  t-loss:0.1420, loss-lb:0.0745, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:18:26.737] iteration:21567  t-loss:0.1539, loss-lb:0.0826, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:18:26.928] iteration:21568  t-loss:0.1586, loss-lb:0.0746, loss-ulb:0.0420, weight:2.00, lr:0.0003
[12:18:27.119] iteration:21569  t-loss:0.1242, loss-lb:0.0713, loss-ulb:0.0264, weight:2.00, lr:0.0003
[12:18:27.309] iteration:21570  t-loss:0.1306, loss-lb:0.0727, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:18:27.501] iteration:21571  t-loss:0.1475, loss-lb:0.0731, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:18:27.694] iteration:21572  t-loss:0.2004, loss-lb:0.0766, loss-ulb:0.0619, weight:2.00, lr:0.0003
[12:18:27.885] iteration:21573  t-loss:0.1392, loss-lb:0.0704, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:18:28.076] iteration:21574  t-loss:0.1606, loss-lb:0.0789, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:18:28.267] iteration:21575  t-loss:0.1478, loss-lb:0.0755, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:18:28.459] iteration:21576  t-loss:0.1775, loss-lb:0.0799, loss-ulb:0.0488, weight:2.00, lr:0.0003
[12:18:28.651] iteration:21577  t-loss:0.1483, loss-lb:0.0864, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:18:28.842] iteration:21578  t-loss:0.1605, loss-lb:0.0774, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:18:29.035] iteration:21579  t-loss:0.1356, loss-lb:0.0745, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:18:29.229] iteration:21580  t-loss:0.1444, loss-lb:0.0710, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:18:29.426] iteration:21581  t-loss:0.1528, loss-lb:0.0824, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:18:29.622] iteration:21582  t-loss:0.1389, loss-lb:0.0720, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:18:29.816] iteration:21583  t-loss:0.2082, loss-lb:0.0736, loss-ulb:0.0673, weight:2.00, lr:0.0003
[12:18:30.009] iteration:21584  t-loss:0.1502, loss-lb:0.0737, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:18:30.204] iteration:21585  t-loss:0.1461, loss-lb:0.0757, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:18:30.395] iteration:21586  t-loss:0.1529, loss-lb:0.0721, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:18:30.587] iteration:21587  t-loss:0.1543, loss-lb:0.0758, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:18:30.780] iteration:21588  t-loss:0.1538, loss-lb:0.0806, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:18:30.974] iteration:21589  t-loss:0.1414, loss-lb:0.0853, loss-ulb:0.0280, weight:2.00, lr:0.0003
[12:18:31.167] iteration:21590  t-loss:0.1503, loss-lb:0.0799, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:18:31.358] iteration:21591  t-loss:0.1441, loss-lb:0.0747, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:18:31.550] iteration:21592  t-loss:0.1283, loss-lb:0.0702, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:18:31.743] iteration:21593  t-loss:0.1472, loss-lb:0.0774, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:18:31.934] iteration:21594  t-loss:0.1403, loss-lb:0.0756, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:18:32.128] iteration:21595  t-loss:0.1363, loss-lb:0.0769, loss-ulb:0.0297, weight:2.00, lr:0.0003
[12:18:32.321] iteration:21596  t-loss:0.1529, loss-lb:0.0784, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:18:32.512] iteration:21597  t-loss:0.1413, loss-lb:0.0782, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:18:32.706] iteration:21598  t-loss:0.1468, loss-lb:0.0737, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:18:32.898] iteration:21599  t-loss:0.1540, loss-lb:0.0797, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:18:33.090] iteration:21600  t-loss:0.1403, loss-lb:0.0798, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:18:33.282] iteration:21601  t-loss:0.1478, loss-lb:0.0728, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:18:33.474] iteration:21602  t-loss:0.1505, loss-lb:0.0693, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:18:33.665] iteration:21603  t-loss:0.1583, loss-lb:0.0762, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:18:33.858] iteration:21604  t-loss:0.1429, loss-lb:0.0730, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:18:34.050] iteration:21605  t-loss:0.1422, loss-lb:0.0778, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:18:34.243] iteration:21606  t-loss:0.1387, loss-lb:0.0732, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:18:34.445] iteration:21607  t-loss:0.1358, loss-lb:0.0756, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:18:34.643] iteration:21608  t-loss:0.1398, loss-lb:0.0744, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:18:34.834] iteration:21609  t-loss:0.1452, loss-lb:0.0800, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:18:35.027] iteration:21610  t-loss:0.1463, loss-lb:0.0776, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:18:35.219] iteration:21611  t-loss:0.1374, loss-lb:0.0731, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:18:35.411] iteration:21612  t-loss:0.1369, loss-lb:0.0736, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:18:35.604] iteration:21613  t-loss:0.1476, loss-lb:0.0751, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:18:35.796] iteration:21614  t-loss:0.1335, loss-lb:0.0720, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:18:35.989] iteration:21615  t-loss:0.1333, loss-lb:0.0674, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:18:36.182] iteration:21616  t-loss:0.1435, loss-lb:0.0676, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:18:36.373] iteration:21617  t-loss:0.1486, loss-lb:0.0840, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:18:36.565] iteration:21618  t-loss:0.1351, loss-lb:0.0715, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:18:36.758] iteration:21619  t-loss:0.1509, loss-lb:0.0738, loss-ulb:0.0386, weight:2.00, lr:0.0003
[12:18:36.951] iteration:21620  t-loss:0.1402, loss-lb:0.0753, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:18:37.143] iteration:21621  t-loss:0.1328, loss-lb:0.0717, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:18:37.336] iteration:21622  t-loss:0.1943, loss-lb:0.0764, loss-ulb:0.0589, weight:2.00, lr:0.0003
[12:18:37.528] iteration:21623  t-loss:0.1439, loss-lb:0.0774, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:18:37.719] iteration:21624  t-loss:0.1428, loss-lb:0.0846, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:18:37.910] iteration:21625  t-loss:0.1394, loss-lb:0.0756, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:18:38.103] iteration:21626  t-loss:0.1322, loss-lb:0.0707, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:18:38.294] iteration:21627  t-loss:0.1346, loss-lb:0.0697, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:18:38.486] iteration:21628  t-loss:0.1350, loss-lb:0.0696, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:18:38.678] iteration:21629  t-loss:0.1373, loss-lb:0.0693, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:18:38.869] iteration:21630  t-loss:0.1423, loss-lb:0.0693, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:18:39.061] iteration:21631  t-loss:0.1455, loss-lb:0.0756, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:18:39.251] iteration:21632  t-loss:0.1527, loss-lb:0.0779, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:18:39.444] iteration:21633  t-loss:0.1411, loss-lb:0.0739, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:18:39.636] iteration:21634  t-loss:0.1468, loss-lb:0.0800, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:18:39.828] iteration:21635  t-loss:0.1275, loss-lb:0.0680, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:18:40.020] iteration:21636  t-loss:0.1496, loss-lb:0.0815, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:18:40.214] iteration:21637  t-loss:0.1478, loss-lb:0.0728, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:18:40.409] iteration:21638  t-loss:0.1476, loss-lb:0.0752, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:18:40.603] iteration:21639  t-loss:0.1348, loss-lb:0.0791, loss-ulb:0.0279, weight:2.00, lr:0.0003
[12:18:40.799] iteration:21640  t-loss:0.1642, loss-lb:0.0735, loss-ulb:0.0453, weight:2.00, lr:0.0003
[12:18:40.991] iteration:21641  t-loss:0.1341, loss-lb:0.0663, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:18:41.182] iteration:21642  t-loss:0.1488, loss-lb:0.0792, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:18:41.375] iteration:21643  t-loss:0.1672, loss-lb:0.0702, loss-ulb:0.0485, weight:2.00, lr:0.0003
[12:18:41.567] iteration:21644  t-loss:0.1355, loss-lb:0.0691, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:18:41.761] iteration:21645  t-loss:0.1724, loss-lb:0.0720, loss-ulb:0.0502, weight:2.00, lr:0.0003
[12:18:41.950] iteration:21646  t-loss:0.1327, loss-lb:0.0679, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:18:42.138] iteration:21647  t-loss:0.1568, loss-lb:0.0829, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:18:42.330] iteration:21648  t-loss:0.2358, loss-lb:0.0742, loss-ulb:0.0808, weight:2.00, lr:0.0003
[12:18:42.522] iteration:21649  t-loss:0.1531, loss-lb:0.0840, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:18:42.714] iteration:21650  t-loss:0.1612, loss-lb:0.0742, loss-ulb:0.0435, weight:2.00, lr:0.0003
[12:18:42.906] iteration:21651  t-loss:0.1429, loss-lb:0.0720, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:18:43.097] iteration:21652  t-loss:0.2230, loss-lb:0.0759, loss-ulb:0.0735, weight:2.00, lr:0.0003
[12:18:43.287] iteration:21653  t-loss:0.1755, loss-lb:0.0761, loss-ulb:0.0497, weight:2.00, lr:0.0003
[12:18:43.478] iteration:21654  t-loss:0.1511, loss-lb:0.0757, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:18:43.670] iteration:21655  t-loss:0.1449, loss-lb:0.0731, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:18:43.861] iteration:21656  t-loss:0.1551, loss-lb:0.0840, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:18:44.051] iteration:21657  t-loss:0.1364, loss-lb:0.0708, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:18:44.242] iteration:21658  t-loss:0.1586, loss-lb:0.0822, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:18:56.499]  <<Test>> - Ep:220  - mean_dice/mean_h95 - S:89.81/1.34, Best-S:90.99, T:89.72/1.38, Best-T:90.48
[12:18:56.499]           - AvgLoss(lb/ulb/all):0.0753/0.0420/0.1592
[12:18:57.019] iteration:21659  t-loss:0.1581, loss-lb:0.0778, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:18:57.215] iteration:21660  t-loss:0.1471, loss-lb:0.0763, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:18:57.407] iteration:21661  t-loss:0.1341, loss-lb:0.0685, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:18:57.599] iteration:21662  t-loss:0.1508, loss-lb:0.0701, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:18:57.793] iteration:21663  t-loss:0.1701, loss-lb:0.0849, loss-ulb:0.0426, weight:2.00, lr:0.0003
[12:18:57.985] iteration:21664  t-loss:0.1449, loss-lb:0.0782, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:18:58.179] iteration:21665  t-loss:0.1415, loss-lb:0.0752, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:18:58.372] iteration:21666  t-loss:0.1456, loss-lb:0.0719, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:18:58.564] iteration:21667  t-loss:0.1432, loss-lb:0.0751, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:18:58.758] iteration:21668  t-loss:0.1491, loss-lb:0.0800, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:18:58.950] iteration:21669  t-loss:0.1388, loss-lb:0.0738, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:18:59.143] iteration:21670  t-loss:0.1445, loss-lb:0.0724, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:18:59.335] iteration:21671  t-loss:0.1618, loss-lb:0.0756, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:18:59.528] iteration:21672  t-loss:0.1451, loss-lb:0.0813, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:18:59.719] iteration:21673  t-loss:0.1973, loss-lb:0.0721, loss-ulb:0.0626, weight:2.00, lr:0.0003
[12:18:59.911] iteration:21674  t-loss:0.1332, loss-lb:0.0694, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:19:00.104] iteration:21675  t-loss:0.1666, loss-lb:0.0901, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:19:00.296] iteration:21676  t-loss:0.1454, loss-lb:0.0704, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:19:00.487] iteration:21677  t-loss:0.1748, loss-lb:0.0921, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:19:00.678] iteration:21678  t-loss:0.1552, loss-lb:0.0788, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:19:00.869] iteration:21679  t-loss:0.1493, loss-lb:0.0757, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:19:01.061] iteration:21680  t-loss:0.1443, loss-lb:0.0792, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:19:01.253] iteration:21681  t-loss:0.1283, loss-lb:0.0731, loss-ulb:0.0276, weight:2.00, lr:0.0003
[12:19:01.444] iteration:21682  t-loss:0.1443, loss-lb:0.0775, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:19:01.636] iteration:21683  t-loss:0.2277, loss-lb:0.0764, loss-ulb:0.0757, weight:2.00, lr:0.0003
[12:19:01.828] iteration:21684  t-loss:0.1415, loss-lb:0.0772, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:19:02.021] iteration:21685  t-loss:0.1339, loss-lb:0.0692, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:19:02.212] iteration:21686  t-loss:0.1520, loss-lb:0.0842, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:19:02.405] iteration:21687  t-loss:0.1503, loss-lb:0.0831, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:19:02.597] iteration:21688  t-loss:0.1276, loss-lb:0.0728, loss-ulb:0.0274, weight:2.00, lr:0.0003
[12:19:02.788] iteration:21689  t-loss:0.1550, loss-lb:0.0763, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:19:02.981] iteration:21690  t-loss:0.1488, loss-lb:0.0771, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:19:03.173] iteration:21691  t-loss:0.1598, loss-lb:0.0757, loss-ulb:0.0421, weight:2.00, lr:0.0003
[12:19:03.367] iteration:21692  t-loss:0.1507, loss-lb:0.0757, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:19:03.560] iteration:21693  t-loss:0.1395, loss-lb:0.0828, loss-ulb:0.0283, weight:2.00, lr:0.0003
[12:19:03.753] iteration:21694  t-loss:0.1507, loss-lb:0.0855, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:19:03.946] iteration:21695  t-loss:0.1394, loss-lb:0.0736, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:19:04.140] iteration:21696  t-loss:0.1424, loss-lb:0.0760, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:19:04.332] iteration:21697  t-loss:0.1543, loss-lb:0.0702, loss-ulb:0.0420, weight:2.00, lr:0.0003
[12:19:04.524] iteration:21698  t-loss:0.1490, loss-lb:0.0771, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:19:04.718] iteration:21699  t-loss:0.1541, loss-lb:0.0792, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:19:04.911] iteration:21700  t-loss:0.1575, loss-lb:0.0734, loss-ulb:0.0420, weight:2.00, lr:0.0003
[12:19:05.103] iteration:21701  t-loss:0.1633, loss-lb:0.0813, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:19:05.295] iteration:21702  t-loss:0.1445, loss-lb:0.0755, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:19:05.489] iteration:21703  t-loss:0.1819, loss-lb:0.0728, loss-ulb:0.0545, weight:2.00, lr:0.0003
[12:19:05.681] iteration:21704  t-loss:0.1357, loss-lb:0.0714, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:19:05.874] iteration:21705  t-loss:0.1375, loss-lb:0.0708, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:19:06.065] iteration:21706  t-loss:0.1410, loss-lb:0.0675, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:19:06.258] iteration:21707  t-loss:0.1528, loss-lb:0.0840, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:19:06.450] iteration:21708  t-loss:0.1506, loss-lb:0.0779, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:19:06.642] iteration:21709  t-loss:0.1405, loss-lb:0.0673, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:19:06.834] iteration:21710  t-loss:0.1470, loss-lb:0.0763, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:19:07.030] iteration:21711  t-loss:0.1420, loss-lb:0.0775, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:19:07.235] iteration:21712  t-loss:0.1481, loss-lb:0.0767, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:19:07.432] iteration:21713  t-loss:0.1375, loss-lb:0.0731, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:19:07.624] iteration:21714  t-loss:0.1499, loss-lb:0.0775, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:19:07.816] iteration:21715  t-loss:0.1481, loss-lb:0.0809, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:19:08.009] iteration:21716  t-loss:0.1880, loss-lb:0.0707, loss-ulb:0.0587, weight:2.00, lr:0.0003
[12:19:08.201] iteration:21717  t-loss:0.1533, loss-lb:0.0750, loss-ulb:0.0391, weight:2.00, lr:0.0003
[12:19:08.393] iteration:21718  t-loss:0.1411, loss-lb:0.0690, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:19:08.585] iteration:21719  t-loss:0.1471, loss-lb:0.0737, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:19:08.778] iteration:21720  t-loss:0.1406, loss-lb:0.0707, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:19:08.970] iteration:21721  t-loss:0.1610, loss-lb:0.0782, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:19:09.162] iteration:21722  t-loss:0.1482, loss-lb:0.0829, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:19:09.355] iteration:21723  t-loss:0.1409, loss-lb:0.0781, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:19:09.547] iteration:21724  t-loss:0.1557, loss-lb:0.0807, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:19:09.739] iteration:21725  t-loss:0.1369, loss-lb:0.0734, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:19:09.931] iteration:21726  t-loss:0.1704, loss-lb:0.0798, loss-ulb:0.0453, weight:2.00, lr:0.0003
[12:19:10.123] iteration:21727  t-loss:0.1443, loss-lb:0.0733, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:19:10.315] iteration:21728  t-loss:0.1545, loss-lb:0.0715, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:19:10.509] iteration:21729  t-loss:0.1679, loss-lb:0.0778, loss-ulb:0.0451, weight:2.00, lr:0.0003
[12:19:10.701] iteration:21730  t-loss:0.1451, loss-lb:0.0741, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:19:10.894] iteration:21731  t-loss:0.1627, loss-lb:0.0874, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:19:11.087] iteration:21732  t-loss:0.1489, loss-lb:0.0776, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:19:11.280] iteration:21733  t-loss:0.1457, loss-lb:0.0700, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:19:11.471] iteration:21734  t-loss:0.1779, loss-lb:0.0754, loss-ulb:0.0513, weight:2.00, lr:0.0003
[12:19:11.664] iteration:21735  t-loss:0.1622, loss-lb:0.0794, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:19:11.857] iteration:21736  t-loss:0.1411, loss-lb:0.0796, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:19:12.048] iteration:21737  t-loss:0.1394, loss-lb:0.0729, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:19:12.242] iteration:21738  t-loss:0.1496, loss-lb:0.0812, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:19:12.434] iteration:21739  t-loss:0.1425, loss-lb:0.0762, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:19:12.626] iteration:21740  t-loss:0.1509, loss-lb:0.0767, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:19:12.818] iteration:21741  t-loss:0.1568, loss-lb:0.0782, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:19:13.011] iteration:21742  t-loss:0.1318, loss-lb:0.0745, loss-ulb:0.0286, weight:2.00, lr:0.0003
[12:19:13.204] iteration:21743  t-loss:0.1530, loss-lb:0.0783, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:19:13.396] iteration:21744  t-loss:0.1495, loss-lb:0.0737, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:19:13.590] iteration:21745  t-loss:0.1482, loss-lb:0.0734, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:19:13.783] iteration:21746  t-loss:0.1401, loss-lb:0.0691, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:19:13.976] iteration:21747  t-loss:0.1627, loss-lb:0.0800, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:19:14.168] iteration:21748  t-loss:0.1362, loss-lb:0.0758, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:19:14.359] iteration:21749  t-loss:0.1537, loss-lb:0.0880, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:19:14.550] iteration:21750  t-loss:0.1365, loss-lb:0.0748, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:19:14.740] iteration:21751  t-loss:0.1538, loss-lb:0.0868, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:19:14.931] iteration:21752  t-loss:0.1455, loss-lb:0.0697, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:19:15.121] iteration:21753  t-loss:0.1449, loss-lb:0.0730, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:19:15.313] iteration:21754  t-loss:0.2346, loss-lb:0.0780, loss-ulb:0.0783, weight:2.00, lr:0.0003
[12:19:15.504] iteration:21755  t-loss:0.1450, loss-lb:0.0732, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:19:15.695] iteration:21756  t-loss:0.1798, loss-lb:0.0747, loss-ulb:0.0526, weight:2.00, lr:0.0003
[12:19:16.293] iteration:21757  t-loss:0.1632, loss-lb:0.0838, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:19:16.489] iteration:21758  t-loss:0.1529, loss-lb:0.0711, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:19:16.682] iteration:21759  t-loss:0.1487, loss-lb:0.0716, loss-ulb:0.0386, weight:2.00, lr:0.0003
[12:19:16.873] iteration:21760  t-loss:0.1478, loss-lb:0.0748, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:19:17.066] iteration:21761  t-loss:0.1355, loss-lb:0.0766, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:19:17.259] iteration:21762  t-loss:0.1436, loss-lb:0.0775, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:19:17.453] iteration:21763  t-loss:0.1812, loss-lb:0.0769, loss-ulb:0.0522, weight:2.00, lr:0.0003
[12:19:17.644] iteration:21764  t-loss:0.1854, loss-lb:0.0773, loss-ulb:0.0541, weight:2.00, lr:0.0003
[12:19:17.837] iteration:21765  t-loss:0.2157, loss-lb:0.0727, loss-ulb:0.0715, weight:2.00, lr:0.0003
[12:19:18.030] iteration:21766  t-loss:0.1261, loss-lb:0.0738, loss-ulb:0.0261, weight:2.00, lr:0.0003
[12:19:18.222] iteration:21767  t-loss:0.1423, loss-lb:0.0772, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:19:18.415] iteration:21768  t-loss:0.1510, loss-lb:0.0729, loss-ulb:0.0391, weight:2.00, lr:0.0003
[12:19:18.607] iteration:21769  t-loss:0.1332, loss-lb:0.0712, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:19:18.799] iteration:21770  t-loss:0.1423, loss-lb:0.0741, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:19:18.991] iteration:21771  t-loss:0.1577, loss-lb:0.0763, loss-ulb:0.0407, weight:2.00, lr:0.0003
[12:19:19.183] iteration:21772  t-loss:0.1481, loss-lb:0.0747, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:19:19.375] iteration:21773  t-loss:0.1568, loss-lb:0.0853, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:19:19.568] iteration:21774  t-loss:0.1490, loss-lb:0.0791, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:19:19.761] iteration:21775  t-loss:0.1580, loss-lb:0.0795, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:19:19.953] iteration:21776  t-loss:0.1370, loss-lb:0.0725, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:19:20.145] iteration:21777  t-loss:0.1412, loss-lb:0.0718, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:19:20.337] iteration:21778  t-loss:0.1618, loss-lb:0.0832, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:19:20.530] iteration:21779  t-loss:0.1432, loss-lb:0.0750, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:19:20.722] iteration:21780  t-loss:0.2273, loss-lb:0.0729, loss-ulb:0.0772, weight:2.00, lr:0.0003
[12:19:20.914] iteration:21781  t-loss:0.1359, loss-lb:0.0733, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:19:21.108] iteration:21782  t-loss:0.1502, loss-lb:0.0821, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:19:21.301] iteration:21783  t-loss:0.1481, loss-lb:0.0767, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:19:21.493] iteration:21784  t-loss:0.1508, loss-lb:0.0777, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:19:21.686] iteration:21785  t-loss:0.1404, loss-lb:0.0742, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:19:21.879] iteration:21786  t-loss:0.1518, loss-lb:0.0806, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:19:22.071] iteration:21787  t-loss:0.1349, loss-lb:0.0720, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:19:22.264] iteration:21788  t-loss:0.1531, loss-lb:0.0763, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:19:22.457] iteration:21789  t-loss:0.1503, loss-lb:0.0683, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:19:22.649] iteration:21790  t-loss:0.1432, loss-lb:0.0816, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:19:22.841] iteration:21791  t-loss:0.1458, loss-lb:0.0705, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:19:23.033] iteration:21792  t-loss:0.1320, loss-lb:0.0714, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:19:23.225] iteration:21793  t-loss:0.1452, loss-lb:0.0773, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:19:23.416] iteration:21794  t-loss:0.1390, loss-lb:0.0707, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:19:23.610] iteration:21795  t-loss:0.1417, loss-lb:0.0735, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:19:23.803] iteration:21796  t-loss:0.1520, loss-lb:0.0767, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:19:23.995] iteration:21797  t-loss:0.1663, loss-lb:0.0777, loss-ulb:0.0443, weight:2.00, lr:0.0003
[12:19:24.188] iteration:21798  t-loss:0.1632, loss-lb:0.0794, loss-ulb:0.0419, weight:2.00, lr:0.0003
[12:19:24.381] iteration:21799  t-loss:0.1792, loss-lb:0.0746, loss-ulb:0.0523, weight:2.00, lr:0.0003
[12:19:24.574] iteration:21800  t-loss:0.1346, loss-lb:0.0724, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:19:24.767] iteration:21801  t-loss:0.1503, loss-lb:0.0762, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:19:24.960] iteration:21802  t-loss:0.1551, loss-lb:0.0800, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:19:25.152] iteration:21803  t-loss:0.1574, loss-lb:0.0737, loss-ulb:0.0419, weight:2.00, lr:0.0003
[12:19:25.344] iteration:21804  t-loss:0.1440, loss-lb:0.0717, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:19:25.536] iteration:21805  t-loss:0.1436, loss-lb:0.0796, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:19:25.729] iteration:21806  t-loss:0.1570, loss-lb:0.0766, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:19:25.921] iteration:21807  t-loss:0.1455, loss-lb:0.0751, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:19:26.114] iteration:21808  t-loss:0.1549, loss-lb:0.0710, loss-ulb:0.0419, weight:2.00, lr:0.0003
[12:19:26.307] iteration:21809  t-loss:0.1694, loss-lb:0.0699, loss-ulb:0.0498, weight:2.00, lr:0.0003
[12:19:26.500] iteration:21810  t-loss:0.1727, loss-lb:0.0714, loss-ulb:0.0507, weight:2.00, lr:0.0003
[12:19:26.694] iteration:21811  t-loss:0.2108, loss-lb:0.0758, loss-ulb:0.0675, weight:2.00, lr:0.0003
[12:19:26.887] iteration:21812  t-loss:0.1692, loss-lb:0.0848, loss-ulb:0.0422, weight:2.00, lr:0.0003
[12:19:27.079] iteration:21813  t-loss:0.1518, loss-lb:0.0766, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:19:27.271] iteration:21814  t-loss:0.1341, loss-lb:0.0704, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:19:27.465] iteration:21815  t-loss:0.1384, loss-lb:0.0800, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:19:27.657] iteration:21816  t-loss:0.1374, loss-lb:0.0740, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:19:27.850] iteration:21817  t-loss:0.1367, loss-lb:0.0722, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:19:28.043] iteration:21818  t-loss:0.1711, loss-lb:0.0793, loss-ulb:0.0459, weight:2.00, lr:0.0003
[12:19:28.237] iteration:21819  t-loss:0.2258, loss-lb:0.0780, loss-ulb:0.0739, weight:2.00, lr:0.0003
[12:19:28.428] iteration:21820  t-loss:0.1500, loss-lb:0.0868, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:19:28.621] iteration:21821  t-loss:0.1581, loss-lb:0.0849, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:19:28.814] iteration:21822  t-loss:0.1623, loss-lb:0.0772, loss-ulb:0.0426, weight:2.00, lr:0.0003
[12:19:29.005] iteration:21823  t-loss:0.1451, loss-lb:0.0809, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:19:29.198] iteration:21824  t-loss:0.1349, loss-lb:0.0705, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:19:29.391] iteration:21825  t-loss:0.1378, loss-lb:0.0736, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:19:29.585] iteration:21826  t-loss:0.1381, loss-lb:0.0708, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:19:29.777] iteration:21827  t-loss:0.1613, loss-lb:0.0908, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:19:29.969] iteration:21828  t-loss:0.1507, loss-lb:0.0758, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:19:30.162] iteration:21829  t-loss:0.1433, loss-lb:0.0793, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:19:30.353] iteration:21830  t-loss:0.1421, loss-lb:0.0726, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:19:30.546] iteration:21831  t-loss:0.1421, loss-lb:0.0739, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:19:30.740] iteration:21832  t-loss:0.1600, loss-lb:0.0952, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:19:30.933] iteration:21833  t-loss:0.1481, loss-lb:0.0808, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:19:31.125] iteration:21834  t-loss:0.1438, loss-lb:0.0722, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:19:31.318] iteration:21835  t-loss:0.1292, loss-lb:0.0716, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:19:31.511] iteration:21836  t-loss:0.2084, loss-lb:0.0782, loss-ulb:0.0651, weight:2.00, lr:0.0003
[12:19:31.703] iteration:21837  t-loss:0.1333, loss-lb:0.0689, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:19:31.895] iteration:21838  t-loss:0.1429, loss-lb:0.0760, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:19:32.088] iteration:21839  t-loss:0.2468, loss-lb:0.0796, loss-ulb:0.0836, weight:2.00, lr:0.0003
[12:19:32.281] iteration:21840  t-loss:0.1667, loss-lb:0.0759, loss-ulb:0.0454, weight:2.00, lr:0.0003
[12:19:32.473] iteration:21841  t-loss:0.1540, loss-lb:0.0713, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:19:32.666] iteration:21842  t-loss:0.1420, loss-lb:0.0745, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:19:32.858] iteration:21843  t-loss:0.1468, loss-lb:0.0701, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:19:33.051] iteration:21844  t-loss:0.1379, loss-lb:0.0745, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:19:33.244] iteration:21845  t-loss:0.1569, loss-lb:0.0751, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:19:33.436] iteration:21846  t-loss:0.1654, loss-lb:0.0807, loss-ulb:0.0424, weight:2.00, lr:0.0003
[12:19:33.628] iteration:21847  t-loss:0.1453, loss-lb:0.0847, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:19:33.819] iteration:21848  t-loss:0.1528, loss-lb:0.0720, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:19:34.010] iteration:21849  t-loss:0.1565, loss-lb:0.0908, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:19:34.202] iteration:21850  t-loss:0.1363, loss-lb:0.0755, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:19:34.393] iteration:21851  t-loss:0.1557, loss-lb:0.0835, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:19:34.584] iteration:21852  t-loss:0.1517, loss-lb:0.0841, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:19:34.775] iteration:21853  t-loss:0.1504, loss-lb:0.0811, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:19:34.967] iteration:21854  t-loss:0.1472, loss-lb:0.0772, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:19:47.492]  <<Test>> - Ep:222  - mean_dice/mean_h95 - S:90.03/1.32, Best-S:90.99, T:89.80/1.37, Best-T:90.48
[12:19:47.493]           - AvgLoss(lb/ulb/all):0.0765/0.0395/0.1563
[12:19:48.022] iteration:21855  t-loss:0.1375, loss-lb:0.0779, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:19:48.219] iteration:21856  t-loss:0.1422, loss-lb:0.0773, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:19:48.413] iteration:21857  t-loss:0.1374, loss-lb:0.0719, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:19:48.606] iteration:21858  t-loss:0.1376, loss-lb:0.0762, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:19:48.798] iteration:21859  t-loss:0.1499, loss-lb:0.0810, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:19:48.992] iteration:21860  t-loss:0.2337, loss-lb:0.0782, loss-ulb:0.0777, weight:2.00, lr:0.0003
[12:19:49.185] iteration:21861  t-loss:0.1488, loss-lb:0.0907, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:19:49.378] iteration:21862  t-loss:0.1633, loss-lb:0.0760, loss-ulb:0.0436, weight:2.00, lr:0.0003
[12:19:49.570] iteration:21863  t-loss:0.1511, loss-lb:0.0753, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:19:49.764] iteration:21864  t-loss:0.1381, loss-lb:0.0771, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:19:49.957] iteration:21865  t-loss:0.1415, loss-lb:0.0794, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:19:50.150] iteration:21866  t-loss:0.1560, loss-lb:0.0832, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:19:50.342] iteration:21867  t-loss:0.1412, loss-lb:0.0783, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:19:50.535] iteration:21868  t-loss:0.1377, loss-lb:0.0756, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:19:50.729] iteration:21869  t-loss:0.1904, loss-lb:0.0662, loss-ulb:0.0621, weight:2.00, lr:0.0003
[12:19:50.923] iteration:21870  t-loss:0.1710, loss-lb:0.0940, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:19:51.115] iteration:21871  t-loss:0.1351, loss-lb:0.0732, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:19:51.308] iteration:21872  t-loss:0.1530, loss-lb:0.0801, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:19:51.502] iteration:21873  t-loss:0.1423, loss-lb:0.0738, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:19:51.696] iteration:21874  t-loss:0.1404, loss-lb:0.0764, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:19:51.887] iteration:21875  t-loss:0.1705, loss-lb:0.0803, loss-ulb:0.0451, weight:2.00, lr:0.0003
[12:19:52.081] iteration:21876  t-loss:0.1404, loss-lb:0.0776, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:19:52.275] iteration:21877  t-loss:0.1442, loss-lb:0.0835, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:19:52.470] iteration:21878  t-loss:0.1439, loss-lb:0.0785, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:19:52.667] iteration:21879  t-loss:0.1673, loss-lb:0.0771, loss-ulb:0.0451, weight:2.00, lr:0.0003
[12:19:52.859] iteration:21880  t-loss:0.1480, loss-lb:0.0749, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:19:53.051] iteration:21881  t-loss:0.1444, loss-lb:0.0757, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:19:53.242] iteration:21882  t-loss:0.1391, loss-lb:0.0739, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:19:53.436] iteration:21883  t-loss:0.1716, loss-lb:0.0753, loss-ulb:0.0482, weight:2.00, lr:0.0003
[12:19:53.627] iteration:21884  t-loss:0.1530, loss-lb:0.0777, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:19:53.820] iteration:21885  t-loss:0.1739, loss-lb:0.0737, loss-ulb:0.0501, weight:2.00, lr:0.0003
[12:19:54.011] iteration:21886  t-loss:0.1524, loss-lb:0.0714, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:19:54.203] iteration:21887  t-loss:0.1549, loss-lb:0.0757, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:19:54.395] iteration:21888  t-loss:0.2782, loss-lb:0.0760, loss-ulb:0.1011, weight:2.00, lr:0.0003
[12:19:54.588] iteration:21889  t-loss:0.1346, loss-lb:0.0669, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:19:54.780] iteration:21890  t-loss:0.1608, loss-lb:0.0797, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:19:54.972] iteration:21891  t-loss:0.1651, loss-lb:0.0770, loss-ulb:0.0441, weight:2.00, lr:0.0003
[12:19:55.164] iteration:21892  t-loss:0.1524, loss-lb:0.0758, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:19:55.357] iteration:21893  t-loss:0.1582, loss-lb:0.0753, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:19:55.548] iteration:21894  t-loss:0.1550, loss-lb:0.0775, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:19:55.740] iteration:21895  t-loss:0.1905, loss-lb:0.0764, loss-ulb:0.0571, weight:2.00, lr:0.0003
[12:19:55.932] iteration:21896  t-loss:0.1595, loss-lb:0.0789, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:19:56.124] iteration:21897  t-loss:0.1476, loss-lb:0.0728, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:19:56.318] iteration:21898  t-loss:0.1524, loss-lb:0.0823, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:19:56.510] iteration:21899  t-loss:0.1674, loss-lb:0.0713, loss-ulb:0.0481, weight:2.00, lr:0.0003
[12:19:56.701] iteration:21900  t-loss:0.1596, loss-lb:0.0746, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:19:56.894] iteration:21901  t-loss:0.1615, loss-lb:0.0869, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:19:57.086] iteration:21902  t-loss:0.1482, loss-lb:0.0714, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:19:57.278] iteration:21903  t-loss:0.1519, loss-lb:0.0763, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:19:57.471] iteration:21904  t-loss:0.1571, loss-lb:0.0760, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:19:57.662] iteration:21905  t-loss:0.1361, loss-lb:0.0672, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:19:57.854] iteration:21906  t-loss:0.1500, loss-lb:0.0807, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:19:58.045] iteration:21907  t-loss:0.1663, loss-lb:0.0751, loss-ulb:0.0456, weight:2.00, lr:0.0003
[12:19:58.237] iteration:21908  t-loss:0.1988, loss-lb:0.0780, loss-ulb:0.0604, weight:2.00, lr:0.0003
[12:19:58.428] iteration:21909  t-loss:0.1464, loss-lb:0.0766, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:19:58.619] iteration:21910  t-loss:0.1423, loss-lb:0.0716, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:19:58.814] iteration:21911  t-loss:0.1930, loss-lb:0.0789, loss-ulb:0.0570, weight:2.00, lr:0.0003
[12:19:59.006] iteration:21912  t-loss:0.1346, loss-lb:0.0708, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:19:59.198] iteration:21913  t-loss:0.1459, loss-lb:0.0807, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:19:59.391] iteration:21914  t-loss:0.1699, loss-lb:0.0757, loss-ulb:0.0471, weight:2.00, lr:0.0003
[12:19:59.584] iteration:21915  t-loss:0.1711, loss-lb:0.0765, loss-ulb:0.0473, weight:2.00, lr:0.0003
[12:19:59.777] iteration:21916  t-loss:0.1462, loss-lb:0.0744, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:19:59.969] iteration:21917  t-loss:0.1400, loss-lb:0.0683, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:20:00.161] iteration:21918  t-loss:0.1548, loss-lb:0.0753, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:20:00.353] iteration:21919  t-loss:0.1647, loss-lb:0.0759, loss-ulb:0.0444, weight:2.00, lr:0.0003
[12:20:00.544] iteration:21920  t-loss:0.1338, loss-lb:0.0764, loss-ulb:0.0287, weight:2.00, lr:0.0003
[12:20:00.736] iteration:21921  t-loss:0.1481, loss-lb:0.0767, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:20:00.927] iteration:21922  t-loss:0.1487, loss-lb:0.0807, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:20:01.120] iteration:21923  t-loss:0.1726, loss-lb:0.0831, loss-ulb:0.0447, weight:2.00, lr:0.0003
[12:20:01.312] iteration:21924  t-loss:0.1401, loss-lb:0.0759, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:20:01.503] iteration:21925  t-loss:0.1452, loss-lb:0.0687, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:20:01.695] iteration:21926  t-loss:0.1573, loss-lb:0.0814, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:20:01.886] iteration:21927  t-loss:0.1494, loss-lb:0.0801, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:20:02.078] iteration:21928  t-loss:0.1457, loss-lb:0.0768, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:20:02.269] iteration:21929  t-loss:0.1485, loss-lb:0.0701, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:20:02.461] iteration:21930  t-loss:0.1495, loss-lb:0.0878, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:20:02.653] iteration:21931  t-loss:0.1374, loss-lb:0.0690, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:20:02.846] iteration:21932  t-loss:0.1386, loss-lb:0.0852, loss-ulb:0.0267, weight:2.00, lr:0.0003
[12:20:03.038] iteration:21933  t-loss:0.1506, loss-lb:0.0752, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:20:03.233] iteration:21934  t-loss:0.1514, loss-lb:0.0830, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:20:03.427] iteration:21935  t-loss:0.1375, loss-lb:0.0694, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:20:03.623] iteration:21936  t-loss:0.1524, loss-lb:0.0799, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:20:03.816] iteration:21937  t-loss:0.1448, loss-lb:0.0783, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:20:04.007] iteration:21938  t-loss:0.1432, loss-lb:0.0693, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:20:04.199] iteration:21939  t-loss:0.1426, loss-lb:0.0752, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:20:04.392] iteration:21940  t-loss:0.1434, loss-lb:0.0831, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:20:04.584] iteration:21941  t-loss:0.1599, loss-lb:0.0805, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:20:04.777] iteration:21942  t-loss:0.1716, loss-lb:0.0702, loss-ulb:0.0507, weight:2.00, lr:0.0003
[12:20:04.970] iteration:21943  t-loss:0.1462, loss-lb:0.0805, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:20:05.162] iteration:21944  t-loss:0.1435, loss-lb:0.0765, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:20:05.353] iteration:21945  t-loss:0.1381, loss-lb:0.0790, loss-ulb:0.0296, weight:2.00, lr:0.0003
[12:20:05.545] iteration:21946  t-loss:0.1695, loss-lb:0.0746, loss-ulb:0.0474, weight:2.00, lr:0.0003
[12:20:05.735] iteration:21947  t-loss:0.1465, loss-lb:0.0800, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:20:05.927] iteration:21948  t-loss:0.1559, loss-lb:0.0830, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:20:06.118] iteration:21949  t-loss:0.1428, loss-lb:0.0757, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:20:06.308] iteration:21950  t-loss:0.1392, loss-lb:0.0747, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:20:06.498] iteration:21951  t-loss:0.1461, loss-lb:0.0741, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:20:06.689] iteration:21952  t-loss:0.1466, loss-lb:0.0799, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:20:07.274] iteration:21953  t-loss:0.1389, loss-lb:0.0803, loss-ulb:0.0293, weight:2.00, lr:0.0003
[12:20:07.470] iteration:21954  t-loss:0.1520, loss-lb:0.0736, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:20:07.661] iteration:21955  t-loss:0.1379, loss-lb:0.0779, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:20:07.853] iteration:21956  t-loss:0.1424, loss-lb:0.0809, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:20:08.045] iteration:21957  t-loss:0.1468, loss-lb:0.0786, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:20:08.237] iteration:21958  t-loss:0.1569, loss-lb:0.0844, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:20:08.429] iteration:21959  t-loss:0.1298, loss-lb:0.0750, loss-ulb:0.0274, weight:2.00, lr:0.0003
[12:20:08.621] iteration:21960  t-loss:0.1427, loss-lb:0.0817, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:20:08.813] iteration:21961  t-loss:0.1395, loss-lb:0.0742, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:20:09.005] iteration:21962  t-loss:0.1487, loss-lb:0.0706, loss-ulb:0.0391, weight:2.00, lr:0.0003
[12:20:09.198] iteration:21963  t-loss:0.1316, loss-lb:0.0722, loss-ulb:0.0297, weight:2.00, lr:0.0003
[12:20:09.391] iteration:21964  t-loss:0.1449, loss-lb:0.0711, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:20:09.583] iteration:21965  t-loss:0.1472, loss-lb:0.0671, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:20:09.775] iteration:21966  t-loss:0.1445, loss-lb:0.0715, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:20:09.967] iteration:21967  t-loss:0.1506, loss-lb:0.0782, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:20:10.158] iteration:21968  t-loss:0.1309, loss-lb:0.0730, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:20:10.350] iteration:21969  t-loss:0.1434, loss-lb:0.0771, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:20:10.542] iteration:21970  t-loss:0.1453, loss-lb:0.0781, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:20:10.733] iteration:21971  t-loss:0.1572, loss-lb:0.0846, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:20:10.925] iteration:21972  t-loss:0.1471, loss-lb:0.0803, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:20:11.116] iteration:21973  t-loss:0.1707, loss-lb:0.0800, loss-ulb:0.0453, weight:2.00, lr:0.0003
[12:20:11.307] iteration:21974  t-loss:0.1466, loss-lb:0.0732, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:20:11.499] iteration:21975  t-loss:0.1415, loss-lb:0.0752, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:20:11.691] iteration:21976  t-loss:0.1401, loss-lb:0.0713, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:20:11.882] iteration:21977  t-loss:0.1433, loss-lb:0.0730, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:20:12.073] iteration:21978  t-loss:0.1516, loss-lb:0.0772, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:20:12.264] iteration:21979  t-loss:0.1393, loss-lb:0.0793, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:20:12.456] iteration:21980  t-loss:0.1396, loss-lb:0.0710, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:20:12.661] iteration:21981  t-loss:0.1352, loss-lb:0.0720, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:20:12.860] iteration:21982  t-loss:0.1414, loss-lb:0.0771, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:20:13.056] iteration:21983  t-loss:0.1301, loss-lb:0.0713, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:20:13.247] iteration:21984  t-loss:0.1572, loss-lb:0.0762, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:20:13.439] iteration:21985  t-loss:0.1848, loss-lb:0.0787, loss-ulb:0.0531, weight:2.00, lr:0.0003
[12:20:13.632] iteration:21986  t-loss:0.1305, loss-lb:0.0728, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:20:13.826] iteration:21987  t-loss:0.1316, loss-lb:0.0697, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:20:14.019] iteration:21988  t-loss:0.1533, loss-lb:0.0732, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:20:14.213] iteration:21989  t-loss:0.1477, loss-lb:0.0756, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:20:14.411] iteration:21990  t-loss:0.1303, loss-lb:0.0638, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:20:14.603] iteration:21991  t-loss:0.1500, loss-lb:0.0822, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:20:14.803] iteration:21992  t-loss:0.1475, loss-lb:0.0747, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:20:14.996] iteration:21993  t-loss:0.1469, loss-lb:0.0771, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:20:15.189] iteration:21994  t-loss:0.1401, loss-lb:0.0776, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:20:15.380] iteration:21995  t-loss:0.1400, loss-lb:0.0732, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:20:15.573] iteration:21996  t-loss:0.1533, loss-lb:0.0728, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:20:15.766] iteration:21997  t-loss:0.1463, loss-lb:0.0684, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:20:15.957] iteration:21998  t-loss:0.1374, loss-lb:0.0744, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:20:16.150] iteration:21999  t-loss:0.1562, loss-lb:0.0979, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:20:16.342] iteration:22000  t-loss:0.1401, loss-lb:0.0751, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:20:16.534] iteration:22001  t-loss:0.1459, loss-lb:0.0739, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:20:16.726] iteration:22002  t-loss:0.1550, loss-lb:0.0760, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:20:16.918] iteration:22003  t-loss:0.1344, loss-lb:0.0663, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:20:17.110] iteration:22004  t-loss:0.1396, loss-lb:0.0743, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:20:17.301] iteration:22005  t-loss:0.1407, loss-lb:0.0780, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:20:17.494] iteration:22006  t-loss:0.1388, loss-lb:0.0759, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:20:17.685] iteration:22007  t-loss:0.1430, loss-lb:0.0776, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:20:17.877] iteration:22008  t-loss:0.1433, loss-lb:0.0783, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:20:18.069] iteration:22009  t-loss:0.1504, loss-lb:0.0711, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:20:18.260] iteration:22010  t-loss:0.1308, loss-lb:0.0691, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:20:18.453] iteration:22011  t-loss:0.1419, loss-lb:0.0762, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:20:18.646] iteration:22012  t-loss:0.2169, loss-lb:0.0752, loss-ulb:0.0709, weight:2.00, lr:0.0003
[12:20:18.838] iteration:22013  t-loss:0.1507, loss-lb:0.0732, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:20:19.031] iteration:22014  t-loss:0.1476, loss-lb:0.0725, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:20:19.223] iteration:22015  t-loss:0.1316, loss-lb:0.0736, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:20:19.414] iteration:22016  t-loss:0.1951, loss-lb:0.0782, loss-ulb:0.0585, weight:2.00, lr:0.0003
[12:20:19.605] iteration:22017  t-loss:0.1339, loss-lb:0.0739, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:20:19.797] iteration:22018  t-loss:0.1491, loss-lb:0.0768, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:20:19.989] iteration:22019  t-loss:0.1512, loss-lb:0.0804, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:20:20.182] iteration:22020  t-loss:0.1700, loss-lb:0.0845, loss-ulb:0.0428, weight:2.00, lr:0.0003
[12:20:20.375] iteration:22021  t-loss:0.1934, loss-lb:0.0781, loss-ulb:0.0577, weight:2.00, lr:0.0003
[12:20:20.567] iteration:22022  t-loss:0.1591, loss-lb:0.0816, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:20:20.760] iteration:22023  t-loss:0.1689, loss-lb:0.0782, loss-ulb:0.0453, weight:2.00, lr:0.0003
[12:20:20.953] iteration:22024  t-loss:0.1417, loss-lb:0.0839, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:20:21.144] iteration:22025  t-loss:0.1579, loss-lb:0.0752, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:20:21.336] iteration:22026  t-loss:0.1722, loss-lb:0.0954, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:20:21.528] iteration:22027  t-loss:0.1471, loss-lb:0.0800, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:20:21.721] iteration:22028  t-loss:0.1746, loss-lb:0.0787, loss-ulb:0.0480, weight:2.00, lr:0.0003
[12:20:21.913] iteration:22029  t-loss:0.2401, loss-lb:0.0908, loss-ulb:0.0747, weight:2.00, lr:0.0003
[12:20:22.105] iteration:22030  t-loss:0.1584, loss-lb:0.0808, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:20:22.297] iteration:22031  t-loss:0.1682, loss-lb:0.0777, loss-ulb:0.0452, weight:2.00, lr:0.0003
[12:20:22.488] iteration:22032  t-loss:0.1370, loss-lb:0.0697, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:20:22.680] iteration:22033  t-loss:0.1663, loss-lb:0.0816, loss-ulb:0.0424, weight:2.00, lr:0.0003
[12:20:22.871] iteration:22034  t-loss:0.1792, loss-lb:0.0871, loss-ulb:0.0461, weight:2.00, lr:0.0003
[12:20:23.063] iteration:22035  t-loss:0.1563, loss-lb:0.0826, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:20:23.254] iteration:22036  t-loss:0.1698, loss-lb:0.0800, loss-ulb:0.0449, weight:2.00, lr:0.0003
[12:20:23.447] iteration:22037  t-loss:0.1657, loss-lb:0.0760, loss-ulb:0.0449, weight:2.00, lr:0.0003
[12:20:23.638] iteration:22038  t-loss:0.1416, loss-lb:0.0768, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:20:23.829] iteration:22039  t-loss:0.1363, loss-lb:0.0785, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:20:24.020] iteration:22040  t-loss:0.1422, loss-lb:0.0701, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:20:24.212] iteration:22041  t-loss:0.1497, loss-lb:0.0791, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:20:24.406] iteration:22042  t-loss:0.1520, loss-lb:0.0740, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:20:24.594] iteration:22043  t-loss:0.1487, loss-lb:0.0775, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:20:24.785] iteration:22044  t-loss:0.2207, loss-lb:0.0950, loss-ulb:0.0628, weight:2.00, lr:0.0003
[12:20:24.978] iteration:22045  t-loss:0.1739, loss-lb:0.0799, loss-ulb:0.0470, weight:2.00, lr:0.0003
[12:20:25.171] iteration:22046  t-loss:0.1374, loss-lb:0.0777, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:20:25.365] iteration:22047  t-loss:0.1373, loss-lb:0.0730, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:20:25.558] iteration:22048  t-loss:0.2247, loss-lb:0.0716, loss-ulb:0.0766, weight:2.00, lr:0.0003
[12:20:25.749] iteration:22049  t-loss:0.1408, loss-lb:0.0739, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:20:25.940] iteration:22050  t-loss:0.1394, loss-lb:0.0775, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:20:38.112]  <<Test>> - Ep:224  - mean_dice/mean_h95 - S:89.85/1.35, Best-S:90.99, T:89.73/1.60, Best-T:90.48
[12:20:38.112]           - AvgLoss(lb/ulb/all):0.0767/0.0407/0.1594
[12:20:38.633] iteration:22051  t-loss:0.1348, loss-lb:0.0681, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:20:38.829] iteration:22052  t-loss:0.1906, loss-lb:0.0726, loss-ulb:0.0590, weight:2.00, lr:0.0003
[12:20:39.021] iteration:22053  t-loss:0.1400, loss-lb:0.0752, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:20:39.215] iteration:22054  t-loss:0.1714, loss-lb:0.0933, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:20:39.409] iteration:22055  t-loss:0.1652, loss-lb:0.0899, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:20:39.603] iteration:22056  t-loss:0.1438, loss-lb:0.0809, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:20:39.793] iteration:22057  t-loss:0.1551, loss-lb:0.0863, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:20:39.982] iteration:22058  t-loss:0.1721, loss-lb:0.0845, loss-ulb:0.0438, weight:2.00, lr:0.0003
[12:20:40.172] iteration:22059  t-loss:0.1443, loss-lb:0.0795, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:20:40.362] iteration:22060  t-loss:0.1696, loss-lb:0.0710, loss-ulb:0.0493, weight:2.00, lr:0.0003
[12:20:40.551] iteration:22061  t-loss:0.1902, loss-lb:0.0819, loss-ulb:0.0541, weight:2.00, lr:0.0003
[12:20:40.741] iteration:22062  t-loss:0.1718, loss-lb:0.0854, loss-ulb:0.0432, weight:2.00, lr:0.0003
[12:20:40.931] iteration:22063  t-loss:0.1442, loss-lb:0.0721, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:20:41.121] iteration:22064  t-loss:0.1713, loss-lb:0.0745, loss-ulb:0.0484, weight:2.00, lr:0.0003
[12:20:41.310] iteration:22065  t-loss:0.1568, loss-lb:0.0824, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:20:41.501] iteration:22066  t-loss:0.1582, loss-lb:0.0851, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:20:41.691] iteration:22067  t-loss:0.1596, loss-lb:0.0817, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:20:41.881] iteration:22068  t-loss:0.1792, loss-lb:0.0798, loss-ulb:0.0497, weight:2.00, lr:0.0003
[12:20:42.071] iteration:22069  t-loss:0.1471, loss-lb:0.0817, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:20:42.262] iteration:22070  t-loss:0.1409, loss-lb:0.0781, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:20:42.451] iteration:22071  t-loss:0.2622, loss-lb:0.0735, loss-ulb:0.0943, weight:2.00, lr:0.0003
[12:20:42.640] iteration:22072  t-loss:0.1341, loss-lb:0.0797, loss-ulb:0.0272, weight:2.00, lr:0.0003
[12:20:42.829] iteration:22073  t-loss:0.1502, loss-lb:0.0806, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:20:43.018] iteration:22074  t-loss:0.1539, loss-lb:0.0813, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:20:43.207] iteration:22075  t-loss:0.1606, loss-lb:0.0867, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:20:43.396] iteration:22076  t-loss:0.1416, loss-lb:0.0744, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:20:43.585] iteration:22077  t-loss:0.1467, loss-lb:0.0743, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:20:43.773] iteration:22078  t-loss:0.1442, loss-lb:0.0769, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:20:43.963] iteration:22079  t-loss:0.1441, loss-lb:0.0770, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:20:44.153] iteration:22080  t-loss:0.2719, loss-lb:0.0812, loss-ulb:0.0954, weight:2.00, lr:0.0003
[12:20:44.341] iteration:22081  t-loss:0.1455, loss-lb:0.0777, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:20:44.531] iteration:22082  t-loss:0.2018, loss-lb:0.0794, loss-ulb:0.0612, weight:2.00, lr:0.0003
[12:20:44.721] iteration:22083  t-loss:0.1538, loss-lb:0.0761, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:20:44.909] iteration:22084  t-loss:0.1968, loss-lb:0.0769, loss-ulb:0.0599, weight:2.00, lr:0.0003
[12:20:45.100] iteration:22085  t-loss:0.2030, loss-lb:0.0750, loss-ulb:0.0640, weight:2.00, lr:0.0003
[12:20:45.292] iteration:22086  t-loss:0.1498, loss-lb:0.0772, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:20:45.487] iteration:22087  t-loss:0.2411, loss-lb:0.0766, loss-ulb:0.0823, weight:2.00, lr:0.0003
[12:20:45.679] iteration:22088  t-loss:0.1480, loss-lb:0.0761, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:20:45.867] iteration:22089  t-loss:0.1641, loss-lb:0.0929, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:20:46.056] iteration:22090  t-loss:0.1409, loss-lb:0.0704, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:20:46.244] iteration:22091  t-loss:0.1575, loss-lb:0.0828, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:20:46.434] iteration:22092  t-loss:0.1706, loss-lb:0.0798, loss-ulb:0.0454, weight:2.00, lr:0.0003
[12:20:46.623] iteration:22093  t-loss:0.1624, loss-lb:0.0802, loss-ulb:0.0411, weight:2.00, lr:0.0003
[12:20:46.812] iteration:22094  t-loss:0.1422, loss-lb:0.0772, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:20:47.001] iteration:22095  t-loss:0.1586, loss-lb:0.0756, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:20:47.191] iteration:22096  t-loss:0.1415, loss-lb:0.0722, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:20:47.384] iteration:22097  t-loss:0.1448, loss-lb:0.0756, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:20:47.578] iteration:22098  t-loss:0.1431, loss-lb:0.0806, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:20:47.770] iteration:22099  t-loss:0.1640, loss-lb:0.0813, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:20:47.963] iteration:22100  t-loss:0.1363, loss-lb:0.0742, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:20:48.155] iteration:22101  t-loss:0.1554, loss-lb:0.0726, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:20:48.347] iteration:22102  t-loss:0.1546, loss-lb:0.0803, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:20:48.540] iteration:22103  t-loss:0.1456, loss-lb:0.0755, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:20:48.732] iteration:22104  t-loss:0.1448, loss-lb:0.0735, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:20:48.925] iteration:22105  t-loss:0.1429, loss-lb:0.0797, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:20:49.118] iteration:22106  t-loss:0.1440, loss-lb:0.0758, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:20:49.309] iteration:22107  t-loss:0.1435, loss-lb:0.0839, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:20:49.502] iteration:22108  t-loss:0.1657, loss-lb:0.0851, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:20:49.694] iteration:22109  t-loss:0.1742, loss-lb:0.0686, loss-ulb:0.0528, weight:2.00, lr:0.0003
[12:20:49.886] iteration:22110  t-loss:0.1526, loss-lb:0.0825, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:20:50.079] iteration:22111  t-loss:0.1429, loss-lb:0.0748, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:20:50.272] iteration:22112  t-loss:0.1426, loss-lb:0.0744, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:20:50.464] iteration:22113  t-loss:0.1441, loss-lb:0.0760, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:20:50.658] iteration:22114  t-loss:0.2246, loss-lb:0.0710, loss-ulb:0.0768, weight:2.00, lr:0.0003
[12:20:50.852] iteration:22115  t-loss:0.1793, loss-lb:0.0739, loss-ulb:0.0527, weight:2.00, lr:0.0003
[12:20:51.044] iteration:22116  t-loss:0.1461, loss-lb:0.0752, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:20:51.236] iteration:22117  t-loss:0.1281, loss-lb:0.0756, loss-ulb:0.0262, weight:2.00, lr:0.0003
[12:20:51.430] iteration:22118  t-loss:0.1507, loss-lb:0.0820, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:20:51.623] iteration:22119  t-loss:0.1826, loss-lb:0.0692, loss-ulb:0.0567, weight:2.00, lr:0.0003
[12:20:51.815] iteration:22120  t-loss:0.1457, loss-lb:0.0754, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:20:52.008] iteration:22121  t-loss:0.1402, loss-lb:0.0763, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:20:52.200] iteration:22122  t-loss:0.1483, loss-lb:0.0798, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:20:52.392] iteration:22123  t-loss:0.1460, loss-lb:0.0723, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:20:52.585] iteration:22124  t-loss:0.1553, loss-lb:0.0781, loss-ulb:0.0386, weight:2.00, lr:0.0003
[12:20:52.778] iteration:22125  t-loss:0.1514, loss-lb:0.0772, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:20:52.970] iteration:22126  t-loss:0.1366, loss-lb:0.0729, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:20:53.162] iteration:22127  t-loss:0.1685, loss-lb:0.0778, loss-ulb:0.0454, weight:2.00, lr:0.0003
[12:20:53.355] iteration:22128  t-loss:0.1429, loss-lb:0.0771, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:20:53.548] iteration:22129  t-loss:0.1477, loss-lb:0.0798, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:20:53.740] iteration:22130  t-loss:0.1342, loss-lb:0.0758, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:20:53.932] iteration:22131  t-loss:0.1409, loss-lb:0.0780, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:20:54.125] iteration:22132  t-loss:0.1621, loss-lb:0.0785, loss-ulb:0.0418, weight:2.00, lr:0.0003
[12:20:54.317] iteration:22133  t-loss:0.1466, loss-lb:0.0821, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:20:54.509] iteration:22134  t-loss:0.1445, loss-lb:0.0711, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:20:54.702] iteration:22135  t-loss:0.1595, loss-lb:0.0716, loss-ulb:0.0439, weight:2.00, lr:0.0003
[12:20:54.895] iteration:22136  t-loss:0.1359, loss-lb:0.0675, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:20:55.086] iteration:22137  t-loss:0.1594, loss-lb:0.0800, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:20:55.279] iteration:22138  t-loss:0.1323, loss-lb:0.0748, loss-ulb:0.0287, weight:2.00, lr:0.0003
[12:20:55.471] iteration:22139  t-loss:0.1341, loss-lb:0.0755, loss-ulb:0.0293, weight:2.00, lr:0.0003
[12:20:55.663] iteration:22140  t-loss:0.1577, loss-lb:0.0767, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:20:55.855] iteration:22141  t-loss:0.1488, loss-lb:0.0788, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:20:56.045] iteration:22142  t-loss:0.1409, loss-lb:0.0789, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:20:56.237] iteration:22143  t-loss:0.1444, loss-lb:0.0739, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:20:56.428] iteration:22144  t-loss:0.1352, loss-lb:0.0745, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:20:56.620] iteration:22145  t-loss:0.1473, loss-lb:0.0763, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:20:56.811] iteration:22146  t-loss:0.1692, loss-lb:0.0918, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:20:57.002] iteration:22147  t-loss:0.1551, loss-lb:0.0766, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:20:57.194] iteration:22148  t-loss:0.1624, loss-lb:0.0689, loss-ulb:0.0467, weight:2.00, lr:0.0003
[12:20:57.772] iteration:22149  t-loss:0.1583, loss-lb:0.0743, loss-ulb:0.0420, weight:2.00, lr:0.0003
[12:20:57.967] iteration:22150  t-loss:0.1367, loss-lb:0.0743, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:20:58.160] iteration:22151  t-loss:0.1392, loss-lb:0.0744, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:20:58.353] iteration:22152  t-loss:0.1321, loss-lb:0.0739, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:20:58.545] iteration:22153  t-loss:0.1447, loss-lb:0.0805, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:20:58.738] iteration:22154  t-loss:0.1529, loss-lb:0.0752, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:20:58.931] iteration:22155  t-loss:0.1444, loss-lb:0.0816, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:20:59.123] iteration:22156  t-loss:0.1590, loss-lb:0.0727, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:20:59.316] iteration:22157  t-loss:0.3407, loss-lb:0.0663, loss-ulb:0.1372, weight:2.00, lr:0.0003
[12:20:59.509] iteration:22158  t-loss:0.1418, loss-lb:0.0729, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:20:59.700] iteration:22159  t-loss:0.1423, loss-lb:0.0733, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:20:59.893] iteration:22160  t-loss:0.1373, loss-lb:0.0726, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:21:00.086] iteration:22161  t-loss:0.1445, loss-lb:0.0736, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:21:00.278] iteration:22162  t-loss:0.1520, loss-lb:0.0768, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:21:00.470] iteration:22163  t-loss:0.1581, loss-lb:0.0744, loss-ulb:0.0418, weight:2.00, lr:0.0003
[12:21:00.664] iteration:22164  t-loss:0.1320, loss-lb:0.0711, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:21:00.857] iteration:22165  t-loss:0.1547, loss-lb:0.0812, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:21:01.049] iteration:22166  t-loss:0.1763, loss-lb:0.0849, loss-ulb:0.0457, weight:2.00, lr:0.0003
[12:21:01.241] iteration:22167  t-loss:0.1489, loss-lb:0.0733, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:21:01.434] iteration:22168  t-loss:0.1237, loss-lb:0.0683, loss-ulb:0.0277, weight:2.00, lr:0.0003
[12:21:01.627] iteration:22169  t-loss:0.1481, loss-lb:0.0805, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:21:01.819] iteration:22170  t-loss:0.1580, loss-lb:0.0848, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:21:02.012] iteration:22171  t-loss:0.1544, loss-lb:0.0791, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:21:02.205] iteration:22172  t-loss:0.1900, loss-lb:0.0703, loss-ulb:0.0598, weight:2.00, lr:0.0003
[12:21:02.397] iteration:22173  t-loss:0.1312, loss-lb:0.0759, loss-ulb:0.0276, weight:2.00, lr:0.0003
[12:21:02.591] iteration:22174  t-loss:0.1455, loss-lb:0.0756, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:21:02.784] iteration:22175  t-loss:0.1781, loss-lb:0.0769, loss-ulb:0.0506, weight:2.00, lr:0.0003
[12:21:02.977] iteration:22176  t-loss:0.1679, loss-lb:0.0915, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:21:03.170] iteration:22177  t-loss:0.2157, loss-lb:0.0777, loss-ulb:0.0690, weight:2.00, lr:0.0003
[12:21:03.363] iteration:22178  t-loss:0.1608, loss-lb:0.0796, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:21:03.556] iteration:22179  t-loss:0.1446, loss-lb:0.0748, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:03.747] iteration:22180  t-loss:0.1477, loss-lb:0.0688, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:21:03.941] iteration:22181  t-loss:0.1488, loss-lb:0.0790, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:04.134] iteration:22182  t-loss:0.1360, loss-lb:0.0740, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:21:04.327] iteration:22183  t-loss:0.1413, loss-lb:0.0741, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:21:04.520] iteration:22184  t-loss:0.1847, loss-lb:0.0747, loss-ulb:0.0550, weight:2.00, lr:0.0003
[12:21:04.712] iteration:22185  t-loss:0.1596, loss-lb:0.0869, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:21:04.906] iteration:22186  t-loss:0.1262, loss-lb:0.0718, loss-ulb:0.0272, weight:2.00, lr:0.0003
[12:21:05.098] iteration:22187  t-loss:0.1689, loss-lb:0.0835, loss-ulb:0.0427, weight:2.00, lr:0.0003
[12:21:05.291] iteration:22188  t-loss:0.1509, loss-lb:0.0706, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:21:05.484] iteration:22189  t-loss:0.1369, loss-lb:0.0766, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:21:05.677] iteration:22190  t-loss:0.1486, loss-lb:0.0808, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:21:05.869] iteration:22191  t-loss:0.1488, loss-lb:0.0767, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:21:06.062] iteration:22192  t-loss:0.1338, loss-lb:0.0717, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:21:06.255] iteration:22193  t-loss:0.1406, loss-lb:0.0682, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:21:06.447] iteration:22194  t-loss:0.1530, loss-lb:0.0764, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:21:06.639] iteration:22195  t-loss:0.1546, loss-lb:0.0727, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:21:06.831] iteration:22196  t-loss:0.1656, loss-lb:0.0723, loss-ulb:0.0467, weight:2.00, lr:0.0003
[12:21:07.025] iteration:22197  t-loss:0.1538, loss-lb:0.0753, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:21:07.218] iteration:22198  t-loss:0.1509, loss-lb:0.0810, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:07.411] iteration:22199  t-loss:0.1377, loss-lb:0.0703, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:21:07.603] iteration:22200  t-loss:0.1456, loss-lb:0.0762, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:21:07.796] iteration:22201  t-loss:0.1351, loss-lb:0.0727, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:21:07.988] iteration:22202  t-loss:0.1607, loss-lb:0.0786, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:21:08.180] iteration:22203  t-loss:0.1480, loss-lb:0.0776, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:21:08.373] iteration:22204  t-loss:0.1411, loss-lb:0.0766, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:21:08.565] iteration:22205  t-loss:0.1464, loss-lb:0.0835, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:21:08.757] iteration:22206  t-loss:0.1450, loss-lb:0.0745, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:21:08.949] iteration:22207  t-loss:0.1334, loss-lb:0.0696, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:21:09.142] iteration:22208  t-loss:0.1334, loss-lb:0.0766, loss-ulb:0.0284, weight:2.00, lr:0.0003
[12:21:09.336] iteration:22209  t-loss:0.1385, loss-lb:0.0753, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:21:09.529] iteration:22210  t-loss:0.1437, loss-lb:0.0823, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:21:09.721] iteration:22211  t-loss:0.1545, loss-lb:0.0777, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:21:09.914] iteration:22212  t-loss:0.1317, loss-lb:0.0729, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:21:10.107] iteration:22213  t-loss:0.1433, loss-lb:0.0741, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:21:10.299] iteration:22214  t-loss:0.1333, loss-lb:0.0751, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:21:10.493] iteration:22215  t-loss:0.1445, loss-lb:0.0756, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:21:10.686] iteration:22216  t-loss:0.1547, loss-lb:0.0772, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:21:10.879] iteration:22217  t-loss:0.1471, loss-lb:0.0789, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:21:11.070] iteration:22218  t-loss:0.1277, loss-lb:0.0677, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:21:11.263] iteration:22219  t-loss:0.2223, loss-lb:0.0737, loss-ulb:0.0743, weight:2.00, lr:0.0003
[12:21:11.456] iteration:22220  t-loss:0.1495, loss-lb:0.0740, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:21:11.648] iteration:22221  t-loss:0.1834, loss-lb:0.0809, loss-ulb:0.0512, weight:2.00, lr:0.0003
[12:21:11.840] iteration:22222  t-loss:0.1403, loss-lb:0.0726, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:21:12.033] iteration:22223  t-loss:0.1458, loss-lb:0.0745, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:21:12.226] iteration:22224  t-loss:0.2776, loss-lb:0.0842, loss-ulb:0.0967, weight:2.00, lr:0.0003
[12:21:12.419] iteration:22225  t-loss:0.1505, loss-lb:0.0866, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:21:12.612] iteration:22226  t-loss:0.1357, loss-lb:0.0769, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:21:12.804] iteration:22227  t-loss:0.1411, loss-lb:0.0726, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:21:12.999] iteration:22228  t-loss:0.1460, loss-lb:0.0790, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:21:13.191] iteration:22229  t-loss:0.1414, loss-lb:0.0783, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:21:13.384] iteration:22230  t-loss:0.1529, loss-lb:0.0776, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:21:13.576] iteration:22231  t-loss:0.1480, loss-lb:0.0743, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:21:13.769] iteration:22232  t-loss:0.1452, loss-lb:0.0728, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:21:13.962] iteration:22233  t-loss:0.1342, loss-lb:0.0658, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:21:14.154] iteration:22234  t-loss:0.1575, loss-lb:0.0746, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:21:14.347] iteration:22235  t-loss:0.1445, loss-lb:0.0757, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:21:14.539] iteration:22236  t-loss:0.1359, loss-lb:0.0692, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:21:14.734] iteration:22237  t-loss:0.1376, loss-lb:0.0771, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:21:14.927] iteration:22238  t-loss:0.1461, loss-lb:0.0763, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:15.118] iteration:22239  t-loss:0.1456, loss-lb:0.0788, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:21:15.310] iteration:22240  t-loss:0.1518, loss-lb:0.0765, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:21:15.501] iteration:22241  t-loss:0.1239, loss-lb:0.0743, loss-ulb:0.0248, weight:2.00, lr:0.0003
[12:21:15.691] iteration:22242  t-loss:0.1556, loss-lb:0.0851, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:21:15.883] iteration:22243  t-loss:0.1538, loss-lb:0.0810, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:21:16.075] iteration:22244  t-loss:0.1430, loss-lb:0.0769, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:21:16.265] iteration:22245  t-loss:0.1386, loss-lb:0.0744, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:21:16.456] iteration:22246  t-loss:0.1414, loss-lb:0.0736, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:21:29.216]  <<Test>> - Ep:226  - mean_dice/mean_h95 - S:90.03/1.32, Best-S:90.99, T:89.81/1.37, Best-T:90.48
[12:21:29.216]           - AvgLoss(lb/ulb/all):0.0760/0.0343/0.1442
[12:21:29.763] iteration:22247  t-loss:0.1466, loss-lb:0.0751, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:21:29.961] iteration:22248  t-loss:0.1545, loss-lb:0.0772, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:21:30.154] iteration:22249  t-loss:0.1310, loss-lb:0.0696, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:21:30.347] iteration:22250  t-loss:0.1456, loss-lb:0.0758, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:30.539] iteration:22251  t-loss:0.1364, loss-lb:0.0725, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:21:30.732] iteration:22252  t-loss:0.1446, loss-lb:0.0756, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:21:30.925] iteration:22253  t-loss:0.1870, loss-lb:0.0818, loss-ulb:0.0526, weight:2.00, lr:0.0003
[12:21:31.117] iteration:22254  t-loss:0.1399, loss-lb:0.0694, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:21:31.311] iteration:22255  t-loss:0.1510, loss-lb:0.0792, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:21:31.503] iteration:22256  t-loss:0.1411, loss-lb:0.0750, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:21:31.696] iteration:22257  t-loss:0.1510, loss-lb:0.0790, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:21:31.889] iteration:22258  t-loss:0.1289, loss-lb:0.0694, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:21:32.083] iteration:22259  t-loss:0.1516, loss-lb:0.0762, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:21:32.275] iteration:22260  t-loss:0.1465, loss-lb:0.0765, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:21:32.467] iteration:22261  t-loss:0.1468, loss-lb:0.0740, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:21:32.661] iteration:22262  t-loss:0.1416, loss-lb:0.0745, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:21:32.855] iteration:22263  t-loss:0.1474, loss-lb:0.0812, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:21:33.049] iteration:22264  t-loss:0.1416, loss-lb:0.0741, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:21:33.240] iteration:22265  t-loss:0.1355, loss-lb:0.0759, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:21:33.432] iteration:22266  t-loss:0.1412, loss-lb:0.0701, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:21:33.623] iteration:22267  t-loss:0.1423, loss-lb:0.0729, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:21:33.814] iteration:22268  t-loss:0.1451, loss-lb:0.0769, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:21:34.005] iteration:22269  t-loss:0.1467, loss-lb:0.0755, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:21:34.197] iteration:22270  t-loss:0.1367, loss-lb:0.0698, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:21:34.388] iteration:22271  t-loss:0.1394, loss-lb:0.0780, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:21:34.580] iteration:22272  t-loss:0.1487, loss-lb:0.0789, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:34.772] iteration:22273  t-loss:0.1491, loss-lb:0.0760, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:21:34.963] iteration:22274  t-loss:0.1305, loss-lb:0.0664, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:21:35.156] iteration:22275  t-loss:0.1690, loss-lb:0.0773, loss-ulb:0.0458, weight:2.00, lr:0.0003
[12:21:35.348] iteration:22276  t-loss:0.1632, loss-lb:0.0806, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:21:35.539] iteration:22277  t-loss:0.1448, loss-lb:0.0684, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:21:35.731] iteration:22278  t-loss:0.1326, loss-lb:0.0704, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:21:35.922] iteration:22279  t-loss:0.1473, loss-lb:0.0729, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:21:36.113] iteration:22280  t-loss:0.1396, loss-lb:0.0732, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:21:36.305] iteration:22281  t-loss:0.1401, loss-lb:0.0727, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:21:36.499] iteration:22282  t-loss:0.2118, loss-lb:0.0753, loss-ulb:0.0682, weight:2.00, lr:0.0003
[12:21:36.693] iteration:22283  t-loss:0.1889, loss-lb:0.0771, loss-ulb:0.0559, weight:2.00, lr:0.0003
[12:21:36.891] iteration:22284  t-loss:0.1376, loss-lb:0.0685, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:21:37.086] iteration:22285  t-loss:0.1392, loss-lb:0.0742, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:21:37.278] iteration:22286  t-loss:0.1435, loss-lb:0.0702, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:21:37.472] iteration:22287  t-loss:0.1752, loss-lb:0.0669, loss-ulb:0.0542, weight:2.00, lr:0.0003
[12:21:37.665] iteration:22288  t-loss:0.1339, loss-lb:0.0793, loss-ulb:0.0273, weight:2.00, lr:0.0003
[12:21:37.858] iteration:22289  t-loss:0.1552, loss-lb:0.0809, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:21:38.050] iteration:22290  t-loss:0.1417, loss-lb:0.0740, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:21:38.245] iteration:22291  t-loss:0.1359, loss-lb:0.0755, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:21:38.438] iteration:22292  t-loss:0.3268, loss-lb:0.0716, loss-ulb:0.1276, weight:2.00, lr:0.0003
[12:21:38.630] iteration:22293  t-loss:0.1573, loss-lb:0.0745, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:21:38.823] iteration:22294  t-loss:0.2289, loss-lb:0.0872, loss-ulb:0.0708, weight:2.00, lr:0.0003
[12:21:39.017] iteration:22295  t-loss:0.1430, loss-lb:0.0721, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:21:39.210] iteration:22296  t-loss:0.2228, loss-lb:0.0732, loss-ulb:0.0748, weight:2.00, lr:0.0003
[12:21:39.402] iteration:22297  t-loss:0.1458, loss-lb:0.0783, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:21:39.594] iteration:22298  t-loss:0.1593, loss-lb:0.0794, loss-ulb:0.0399, weight:2.00, lr:0.0003
[12:21:39.787] iteration:22299  t-loss:0.1520, loss-lb:0.0772, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:21:39.978] iteration:22300  t-loss:0.1434, loss-lb:0.0694, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:21:40.170] iteration:22301  t-loss:0.1273, loss-lb:0.0671, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:21:40.364] iteration:22302  t-loss:0.1774, loss-lb:0.0857, loss-ulb:0.0458, weight:2.00, lr:0.0003
[12:21:40.556] iteration:22303  t-loss:0.1441, loss-lb:0.0818, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:21:40.748] iteration:22304  t-loss:0.1500, loss-lb:0.0821, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:21:40.940] iteration:22305  t-loss:0.1451, loss-lb:0.0776, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:21:41.131] iteration:22306  t-loss:0.1364, loss-lb:0.0725, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:21:41.323] iteration:22307  t-loss:0.1259, loss-lb:0.0676, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:21:41.515] iteration:22308  t-loss:0.1474, loss-lb:0.0732, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:21:41.707] iteration:22309  t-loss:0.1497, loss-lb:0.0732, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:21:41.899] iteration:22310  t-loss:0.1374, loss-lb:0.0761, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:21:42.091] iteration:22311  t-loss:0.1567, loss-lb:0.0802, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:21:42.283] iteration:22312  t-loss:0.1571, loss-lb:0.0741, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:21:42.474] iteration:22313  t-loss:0.1423, loss-lb:0.0771, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:21:42.666] iteration:22314  t-loss:0.1380, loss-lb:0.0763, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:21:42.857] iteration:22315  t-loss:0.1457, loss-lb:0.0740, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:21:43.050] iteration:22316  t-loss:0.1423, loss-lb:0.0779, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:21:43.242] iteration:22317  t-loss:0.1483, loss-lb:0.0806, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:21:43.434] iteration:22318  t-loss:0.1592, loss-lb:0.0788, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:21:43.628] iteration:22319  t-loss:0.1448, loss-lb:0.0745, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:21:43.821] iteration:22320  t-loss:0.1395, loss-lb:0.0753, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:21:44.013] iteration:22321  t-loss:0.1436, loss-lb:0.0748, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:21:44.205] iteration:22322  t-loss:0.1386, loss-lb:0.0719, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:21:44.398] iteration:22323  t-loss:0.1360, loss-lb:0.0714, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:21:44.590] iteration:22324  t-loss:0.1516, loss-lb:0.0788, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:21:44.781] iteration:22325  t-loss:0.1279, loss-lb:0.0738, loss-ulb:0.0270, weight:2.00, lr:0.0003
[12:21:44.976] iteration:22326  t-loss:0.1461, loss-lb:0.0794, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:21:45.167] iteration:22327  t-loss:0.1340, loss-lb:0.0702, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:21:45.358] iteration:22328  t-loss:0.1449, loss-lb:0.0747, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:21:45.552] iteration:22329  t-loss:0.1553, loss-lb:0.0733, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:21:45.743] iteration:22330  t-loss:0.1415, loss-lb:0.0676, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:21:45.937] iteration:22331  t-loss:0.1485, loss-lb:0.0857, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:21:46.129] iteration:22332  t-loss:0.1934, loss-lb:0.0719, loss-ulb:0.0607, weight:2.00, lr:0.0003
[12:21:46.320] iteration:22333  t-loss:0.1485, loss-lb:0.0752, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:21:46.513] iteration:22334  t-loss:0.1402, loss-lb:0.0675, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:21:46.705] iteration:22335  t-loss:0.1500, loss-lb:0.0857, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:21:46.899] iteration:22336  t-loss:0.1544, loss-lb:0.0681, loss-ulb:0.0432, weight:2.00, lr:0.0003
[12:21:47.090] iteration:22337  t-loss:0.1437, loss-lb:0.0753, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:21:47.281] iteration:22338  t-loss:0.1470, loss-lb:0.0724, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:21:47.472] iteration:22339  t-loss:0.1503, loss-lb:0.0753, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:21:47.666] iteration:22340  t-loss:0.1416, loss-lb:0.0719, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:47.861] iteration:22341  t-loss:0.1386, loss-lb:0.0797, loss-ulb:0.0295, weight:2.00, lr:0.0003
[12:21:48.056] iteration:22342  t-loss:0.1991, loss-lb:0.0685, loss-ulb:0.0653, weight:2.00, lr:0.0003
[12:21:48.247] iteration:22343  t-loss:0.1520, loss-lb:0.0813, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:21:48.438] iteration:22344  t-loss:0.1611, loss-lb:0.0867, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:21:49.022] iteration:22345  t-loss:0.1430, loss-lb:0.0760, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:21:49.216] iteration:22346  t-loss:0.1574, loss-lb:0.0768, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:21:49.407] iteration:22347  t-loss:0.1323, loss-lb:0.0734, loss-ulb:0.0295, weight:2.00, lr:0.0003
[12:21:49.599] iteration:22348  t-loss:0.1557, loss-lb:0.0809, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:21:49.791] iteration:22349  t-loss:0.1436, loss-lb:0.0768, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:21:49.982] iteration:22350  t-loss:0.1594, loss-lb:0.0819, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:21:50.175] iteration:22351  t-loss:0.1626, loss-lb:0.0876, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:21:50.366] iteration:22352  t-loss:0.1642, loss-lb:0.0780, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:21:50.558] iteration:22353  t-loss:0.1463, loss-lb:0.0781, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:21:50.750] iteration:22354  t-loss:0.2270, loss-lb:0.0850, loss-ulb:0.0710, weight:2.00, lr:0.0003
[12:21:50.955] iteration:22355  t-loss:0.2101, loss-lb:0.0773, loss-ulb:0.0664, weight:2.00, lr:0.0003
[12:21:51.154] iteration:22356  t-loss:0.1884, loss-lb:0.1208, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:21:51.351] iteration:22357  t-loss:0.1676, loss-lb:0.0769, loss-ulb:0.0453, weight:2.00, lr:0.0003
[12:21:51.542] iteration:22358  t-loss:0.1558, loss-lb:0.0802, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:21:51.734] iteration:22359  t-loss:0.1544, loss-lb:0.0730, loss-ulb:0.0407, weight:2.00, lr:0.0003
[12:21:51.927] iteration:22360  t-loss:0.1504, loss-lb:0.0788, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:21:52.118] iteration:22361  t-loss:0.1892, loss-lb:0.0881, loss-ulb:0.0506, weight:2.00, lr:0.0003
[12:21:52.311] iteration:22362  t-loss:0.1582, loss-lb:0.0893, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:21:52.502] iteration:22363  t-loss:0.1571, loss-lb:0.0844, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:21:52.694] iteration:22364  t-loss:0.1997, loss-lb:0.0808, loss-ulb:0.0595, weight:2.00, lr:0.0003
[12:21:52.886] iteration:22365  t-loss:0.1508, loss-lb:0.0837, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:21:53.078] iteration:22366  t-loss:0.1582, loss-lb:0.0860, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:21:53.271] iteration:22367  t-loss:0.1593, loss-lb:0.0835, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:21:53.463] iteration:22368  t-loss:0.1379, loss-lb:0.0727, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:21:53.655] iteration:22369  t-loss:0.1479, loss-lb:0.0728, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:21:53.847] iteration:22370  t-loss:0.1797, loss-lb:0.0790, loss-ulb:0.0503, weight:2.00, lr:0.0003
[12:21:54.039] iteration:22371  t-loss:0.1482, loss-lb:0.0814, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:21:54.230] iteration:22372  t-loss:0.1474, loss-lb:0.0753, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:21:54.423] iteration:22373  t-loss:0.2129, loss-lb:0.0813, loss-ulb:0.0658, weight:2.00, lr:0.0003
[12:21:54.616] iteration:22374  t-loss:0.1483, loss-lb:0.0817, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:21:54.809] iteration:22375  t-loss:0.1425, loss-lb:0.0793, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:21:55.000] iteration:22376  t-loss:0.1819, loss-lb:0.0932, loss-ulb:0.0443, weight:2.00, lr:0.0003
[12:21:55.193] iteration:22377  t-loss:0.1394, loss-lb:0.0732, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:21:55.385] iteration:22378  t-loss:0.2017, loss-lb:0.0741, loss-ulb:0.0638, weight:2.00, lr:0.0003
[12:21:55.579] iteration:22379  t-loss:0.1461, loss-lb:0.0775, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:21:55.770] iteration:22380  t-loss:0.1430, loss-lb:0.0750, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:21:55.962] iteration:22381  t-loss:0.1600, loss-lb:0.0822, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:21:56.153] iteration:22382  t-loss:0.1467, loss-lb:0.0770, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:21:56.344] iteration:22383  t-loss:0.1499, loss-lb:0.0844, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:21:56.537] iteration:22384  t-loss:0.1738, loss-lb:0.0771, loss-ulb:0.0483, weight:2.00, lr:0.0003
[12:21:56.728] iteration:22385  t-loss:0.1705, loss-lb:0.0819, loss-ulb:0.0443, weight:2.00, lr:0.0003
[12:21:56.920] iteration:22386  t-loss:0.1765, loss-lb:0.0803, loss-ulb:0.0481, weight:2.00, lr:0.0003
[12:21:57.112] iteration:22387  t-loss:0.1434, loss-lb:0.0812, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:21:57.304] iteration:22388  t-loss:0.1358, loss-lb:0.0750, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:21:57.497] iteration:22389  t-loss:0.1537, loss-lb:0.0742, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:21:57.689] iteration:22390  t-loss:0.2222, loss-lb:0.0751, loss-ulb:0.0736, weight:2.00, lr:0.0003
[12:21:57.880] iteration:22391  t-loss:0.1590, loss-lb:0.0788, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:21:58.072] iteration:22392  t-loss:0.1636, loss-lb:0.0768, loss-ulb:0.0434, weight:2.00, lr:0.0003
[12:21:58.264] iteration:22393  t-loss:0.1572, loss-lb:0.0743, loss-ulb:0.0414, weight:2.00, lr:0.0003
[12:21:58.457] iteration:22394  t-loss:0.1538, loss-lb:0.0836, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:21:58.654] iteration:22395  t-loss:0.1765, loss-lb:0.0754, loss-ulb:0.0506, weight:2.00, lr:0.0003
[12:21:58.848] iteration:22396  t-loss:0.1508, loss-lb:0.0801, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:21:59.043] iteration:22397  t-loss:0.1551, loss-lb:0.0817, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:21:59.236] iteration:22398  t-loss:0.1408, loss-lb:0.0767, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:21:59.427] iteration:22399  t-loss:0.1445, loss-lb:0.0733, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:21:59.620] iteration:22400  t-loss:0.1686, loss-lb:0.0826, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:21:59.811] iteration:22401  t-loss:0.1551, loss-lb:0.0818, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:22:00.003] iteration:22402  t-loss:0.1583, loss-lb:0.0808, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:22:00.195] iteration:22403  t-loss:0.1424, loss-lb:0.0798, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:22:00.388] iteration:22404  t-loss:0.1609, loss-lb:0.0792, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:22:00.579] iteration:22405  t-loss:0.1423, loss-lb:0.0665, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:22:00.772] iteration:22406  t-loss:0.2384, loss-lb:0.0759, loss-ulb:0.0812, weight:2.00, lr:0.0003
[12:22:00.965] iteration:22407  t-loss:0.1461, loss-lb:0.0758, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:22:01.156] iteration:22408  t-loss:0.2147, loss-lb:0.0804, loss-ulb:0.0671, weight:2.00, lr:0.0003
[12:22:01.348] iteration:22409  t-loss:0.1745, loss-lb:0.0769, loss-ulb:0.0488, weight:2.00, lr:0.0003
[12:22:01.540] iteration:22410  t-loss:0.1683, loss-lb:0.0805, loss-ulb:0.0439, weight:2.00, lr:0.0003
[12:22:01.733] iteration:22411  t-loss:0.1546, loss-lb:0.0804, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:22:01.926] iteration:22412  t-loss:0.1808, loss-lb:0.0773, loss-ulb:0.0518, weight:2.00, lr:0.0003
[12:22:02.118] iteration:22413  t-loss:0.1422, loss-lb:0.0785, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:22:02.309] iteration:22414  t-loss:0.1483, loss-lb:0.0842, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:22:02.501] iteration:22415  t-loss:0.1583, loss-lb:0.0767, loss-ulb:0.0408, weight:2.00, lr:0.0003
[12:22:02.693] iteration:22416  t-loss:0.1619, loss-lb:0.0842, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:22:02.885] iteration:22417  t-loss:0.1395, loss-lb:0.0769, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:22:03.078] iteration:22418  t-loss:0.1388, loss-lb:0.0708, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:22:03.269] iteration:22419  t-loss:0.1579, loss-lb:0.0855, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:22:03.461] iteration:22420  t-loss:0.1483, loss-lb:0.0782, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:22:03.654] iteration:22421  t-loss:0.1996, loss-lb:0.0779, loss-ulb:0.0608, weight:2.00, lr:0.0003
[12:22:03.847] iteration:22422  t-loss:0.2322, loss-lb:0.0778, loss-ulb:0.0772, weight:2.00, lr:0.0003
[12:22:04.038] iteration:22423  t-loss:0.1362, loss-lb:0.0756, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:22:04.230] iteration:22424  t-loss:0.1487, loss-lb:0.0840, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:22:04.422] iteration:22425  t-loss:0.1485, loss-lb:0.0778, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:22:04.615] iteration:22426  t-loss:0.1403, loss-lb:0.0773, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:22:04.808] iteration:22427  t-loss:0.1497, loss-lb:0.0734, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:22:05.000] iteration:22428  t-loss:0.1463, loss-lb:0.0712, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:22:05.192] iteration:22429  t-loss:0.1587, loss-lb:0.0776, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:22:05.384] iteration:22430  t-loss:0.1464, loss-lb:0.0798, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:22:05.576] iteration:22431  t-loss:0.1463, loss-lb:0.0807, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:22:05.768] iteration:22432  t-loss:0.1734, loss-lb:0.0784, loss-ulb:0.0475, weight:2.00, lr:0.0003
[12:22:05.959] iteration:22433  t-loss:0.1365, loss-lb:0.0746, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:22:06.152] iteration:22434  t-loss:0.1316, loss-lb:0.0678, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:22:06.343] iteration:22435  t-loss:0.1445, loss-lb:0.0811, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:22:06.535] iteration:22436  t-loss:0.2082, loss-lb:0.0744, loss-ulb:0.0669, weight:2.00, lr:0.0003
[12:22:06.726] iteration:22437  t-loss:0.1898, loss-lb:0.0819, loss-ulb:0.0539, weight:2.00, lr:0.0003
[12:22:06.916] iteration:22438  t-loss:0.1444, loss-lb:0.0707, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:22:07.106] iteration:22439  t-loss:0.1434, loss-lb:0.0745, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:22:07.296] iteration:22440  t-loss:0.1382, loss-lb:0.0781, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:22:07.485] iteration:22441  t-loss:0.1409, loss-lb:0.0708, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:22:07.677] iteration:22442  t-loss:0.1645, loss-lb:0.0757, loss-ulb:0.0444, weight:2.00, lr:0.0003
[12:22:19.569]  <<Test>> - Ep:228  - mean_dice/mean_h95 - S:89.79/1.38, Best-S:90.99, T:89.72/1.36, Best-T:90.48
[12:22:19.569]           - AvgLoss(lb/ulb/all):0.0789/0.0378/0.1518
[12:22:20.096] iteration:22443  t-loss:0.1393, loss-lb:0.0768, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:22:20.296] iteration:22444  t-loss:0.1491, loss-lb:0.0784, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:22:20.490] iteration:22445  t-loss:0.1450, loss-lb:0.0748, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:22:20.684] iteration:22446  t-loss:0.1570, loss-lb:0.0789, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:22:20.876] iteration:22447  t-loss:0.1385, loss-lb:0.0750, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:22:21.070] iteration:22448  t-loss:0.1448, loss-lb:0.0777, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:22:21.263] iteration:22449  t-loss:0.1524, loss-lb:0.0792, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:22:21.456] iteration:22450  t-loss:0.1432, loss-lb:0.0709, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:22:21.650] iteration:22451  t-loss:0.2409, loss-lb:0.0746, loss-ulb:0.0831, weight:2.00, lr:0.0003
[12:22:21.843] iteration:22452  t-loss:0.1376, loss-lb:0.0688, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:22:22.035] iteration:22453  t-loss:0.1379, loss-lb:0.0774, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:22:22.228] iteration:22454  t-loss:0.1503, loss-lb:0.0757, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:22:22.423] iteration:22455  t-loss:0.1482, loss-lb:0.0748, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:22:22.616] iteration:22456  t-loss:0.1414, loss-lb:0.0814, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:22:22.810] iteration:22457  t-loss:0.2738, loss-lb:0.0742, loss-ulb:0.0998, weight:2.00, lr:0.0003
[12:22:23.003] iteration:22458  t-loss:0.1205, loss-lb:0.0675, loss-ulb:0.0265, weight:2.00, lr:0.0003
[12:22:23.197] iteration:22459  t-loss:0.1470, loss-lb:0.0782, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:22:23.390] iteration:22460  t-loss:0.1381, loss-lb:0.0750, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:22:23.583] iteration:22461  t-loss:0.1402, loss-lb:0.0834, loss-ulb:0.0284, weight:2.00, lr:0.0003
[12:22:23.789] iteration:22462  t-loss:0.1619, loss-lb:0.0864, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:22:23.986] iteration:22463  t-loss:0.1614, loss-lb:0.0748, loss-ulb:0.0433, weight:2.00, lr:0.0003
[12:22:24.178] iteration:22464  t-loss:0.1384, loss-lb:0.0773, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:22:24.371] iteration:22465  t-loss:0.1345, loss-lb:0.0704, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:22:24.562] iteration:22466  t-loss:0.1471, loss-lb:0.0721, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:22:24.755] iteration:22467  t-loss:0.1493, loss-lb:0.0801, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:22:24.949] iteration:22468  t-loss:0.1608, loss-lb:0.0797, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:22:25.142] iteration:22469  t-loss:0.1484, loss-lb:0.0650, loss-ulb:0.0417, weight:2.00, lr:0.0003
[12:22:25.333] iteration:22470  t-loss:0.1469, loss-lb:0.0764, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:22:25.526] iteration:22471  t-loss:0.1487, loss-lb:0.0734, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:22:25.719] iteration:22472  t-loss:0.1567, loss-lb:0.0797, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:22:25.911] iteration:22473  t-loss:0.1358, loss-lb:0.0747, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:22:26.104] iteration:22474  t-loss:0.1460, loss-lb:0.0713, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:22:26.297] iteration:22475  t-loss:0.1439, loss-lb:0.0707, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:22:26.489] iteration:22476  t-loss:0.1468, loss-lb:0.0885, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:22:26.681] iteration:22477  t-loss:0.1275, loss-lb:0.0686, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:22:26.874] iteration:22478  t-loss:0.1628, loss-lb:0.0892, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:22:27.067] iteration:22479  t-loss:0.1507, loss-lb:0.0783, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:22:27.258] iteration:22480  t-loss:0.1472, loss-lb:0.0723, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:22:27.451] iteration:22481  t-loss:0.1361, loss-lb:0.0756, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:22:27.644] iteration:22482  t-loss:0.1581, loss-lb:0.0855, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:22:27.835] iteration:22483  t-loss:0.1682, loss-lb:0.0742, loss-ulb:0.0470, weight:2.00, lr:0.0003
[12:22:28.028] iteration:22484  t-loss:0.2141, loss-lb:0.0775, loss-ulb:0.0683, weight:2.00, lr:0.0003
[12:22:28.220] iteration:22485  t-loss:0.1686, loss-lb:0.0756, loss-ulb:0.0465, weight:2.00, lr:0.0003
[12:22:28.412] iteration:22486  t-loss:0.1350, loss-lb:0.0733, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:22:28.604] iteration:22487  t-loss:0.1441, loss-lb:0.0688, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:22:28.796] iteration:22488  t-loss:0.1517, loss-lb:0.0769, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:22:28.988] iteration:22489  t-loss:0.1516, loss-lb:0.0793, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:22:29.181] iteration:22490  t-loss:0.1438, loss-lb:0.0749, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:22:29.373] iteration:22491  t-loss:0.1602, loss-lb:0.0753, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:22:29.566] iteration:22492  t-loss:0.1440, loss-lb:0.0786, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:22:29.758] iteration:22493  t-loss:0.1361, loss-lb:0.0745, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:22:29.950] iteration:22494  t-loss:0.1485, loss-lb:0.0820, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:22:30.142] iteration:22495  t-loss:0.1479, loss-lb:0.0799, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:22:30.334] iteration:22496  t-loss:0.1492, loss-lb:0.0740, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:22:30.528] iteration:22497  t-loss:0.1486, loss-lb:0.0774, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:22:30.720] iteration:22498  t-loss:0.1621, loss-lb:0.0789, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:22:30.913] iteration:22499  t-loss:0.1514, loss-lb:0.0807, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:22:31.106] iteration:22500  t-loss:0.1630, loss-lb:0.0782, loss-ulb:0.0424, weight:2.00, lr:0.0003
[12:22:31.298] iteration:22501  t-loss:0.1653, loss-lb:0.0862, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:22:31.491] iteration:22502  t-loss:0.1504, loss-lb:0.0770, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:22:31.685] iteration:22503  t-loss:0.1428, loss-lb:0.0749, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:22:31.878] iteration:22504  t-loss:0.1526, loss-lb:0.0745, loss-ulb:0.0391, weight:2.00, lr:0.0003
[12:22:32.072] iteration:22505  t-loss:0.1752, loss-lb:0.0743, loss-ulb:0.0505, weight:2.00, lr:0.0003
[12:22:32.264] iteration:22506  t-loss:0.1577, loss-lb:0.0802, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:22:32.456] iteration:22507  t-loss:0.1449, loss-lb:0.0769, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:22:32.649] iteration:22508  t-loss:0.1547, loss-lb:0.0802, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:22:32.842] iteration:22509  t-loss:0.1597, loss-lb:0.0820, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:22:33.035] iteration:22510  t-loss:0.1464, loss-lb:0.0734, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:22:33.227] iteration:22511  t-loss:0.1417, loss-lb:0.0751, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:22:33.420] iteration:22512  t-loss:0.1330, loss-lb:0.0705, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:22:33.611] iteration:22513  t-loss:0.1441, loss-lb:0.0781, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:22:33.804] iteration:22514  t-loss:0.1574, loss-lb:0.0801, loss-ulb:0.0386, weight:2.00, lr:0.0003
[12:22:33.997] iteration:22515  t-loss:0.1251, loss-lb:0.0681, loss-ulb:0.0285, weight:2.00, lr:0.0003
[12:22:34.189] iteration:22516  t-loss:0.1619, loss-lb:0.0698, loss-ulb:0.0461, weight:2.00, lr:0.0003
[12:22:34.381] iteration:22517  t-loss:0.1443, loss-lb:0.0749, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:22:34.574] iteration:22518  t-loss:0.1586, loss-lb:0.0836, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:22:34.767] iteration:22519  t-loss:0.1336, loss-lb:0.0751, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:22:34.959] iteration:22520  t-loss:0.1584, loss-lb:0.0753, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:22:35.151] iteration:22521  t-loss:0.1433, loss-lb:0.0738, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:22:35.344] iteration:22522  t-loss:0.1450, loss-lb:0.0768, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:22:35.537] iteration:22523  t-loss:0.1520, loss-lb:0.0773, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:22:35.729] iteration:22524  t-loss:0.1373, loss-lb:0.0751, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:22:35.921] iteration:22525  t-loss:0.1480, loss-lb:0.0761, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:22:36.112] iteration:22526  t-loss:0.1344, loss-lb:0.0747, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:22:36.304] iteration:22527  t-loss:0.1526, loss-lb:0.0756, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:22:36.498] iteration:22528  t-loss:0.1701, loss-lb:0.0826, loss-ulb:0.0438, weight:2.00, lr:0.0003
[12:22:36.691] iteration:22529  t-loss:0.1380, loss-lb:0.0736, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:22:36.884] iteration:22530  t-loss:0.1507, loss-lb:0.0712, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:22:37.076] iteration:22531  t-loss:0.1321, loss-lb:0.0709, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:22:37.269] iteration:22532  t-loss:0.1444, loss-lb:0.0713, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:22:37.460] iteration:22533  t-loss:0.1410, loss-lb:0.0765, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:22:37.650] iteration:22534  t-loss:0.1549, loss-lb:0.0771, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:22:37.841] iteration:22535  t-loss:0.1354, loss-lb:0.0812, loss-ulb:0.0271, weight:2.00, lr:0.0003
[12:22:38.031] iteration:22536  t-loss:0.1524, loss-lb:0.0849, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:22:38.222] iteration:22537  t-loss:0.1618, loss-lb:0.0745, loss-ulb:0.0437, weight:2.00, lr:0.0003
[12:22:38.412] iteration:22538  t-loss:0.1456, loss-lb:0.0794, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:22:38.603] iteration:22539  t-loss:0.1503, loss-lb:0.0723, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:22:38.794] iteration:22540  t-loss:0.1350, loss-lb:0.0703, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:22:39.425] iteration:22541  t-loss:0.1445, loss-lb:0.0758, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:22:39.622] iteration:22542  t-loss:0.1754, loss-lb:0.0821, loss-ulb:0.0466, weight:2.00, lr:0.0003
[12:22:39.814] iteration:22543  t-loss:0.1449, loss-lb:0.0712, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:22:40.006] iteration:22544  t-loss:0.1413, loss-lb:0.0767, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:22:40.198] iteration:22545  t-loss:0.1401, loss-lb:0.0735, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:22:40.391] iteration:22546  t-loss:0.1524, loss-lb:0.0861, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:22:40.583] iteration:22547  t-loss:0.1474, loss-lb:0.0771, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:22:40.775] iteration:22548  t-loss:0.1550, loss-lb:0.0691, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:22:40.967] iteration:22549  t-loss:0.1354, loss-lb:0.0753, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:22:41.160] iteration:22550  t-loss:0.1403, loss-lb:0.0686, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:22:41.352] iteration:22551  t-loss:0.1463, loss-lb:0.0798, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:22:41.545] iteration:22552  t-loss:0.1512, loss-lb:0.0833, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:22:41.737] iteration:22553  t-loss:0.1908, loss-lb:0.0805, loss-ulb:0.0552, weight:2.00, lr:0.0003
[12:22:41.930] iteration:22554  t-loss:0.1482, loss-lb:0.0815, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:22:42.122] iteration:22555  t-loss:0.1614, loss-lb:0.0822, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:22:42.314] iteration:22556  t-loss:0.1419, loss-lb:0.0684, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:22:42.507] iteration:22557  t-loss:0.1616, loss-lb:0.0759, loss-ulb:0.0428, weight:2.00, lr:0.0003
[12:22:42.700] iteration:22558  t-loss:0.1416, loss-lb:0.0699, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:22:42.893] iteration:22559  t-loss:0.1554, loss-lb:0.0823, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:22:43.085] iteration:22560  t-loss:0.1380, loss-lb:0.0724, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:22:43.278] iteration:22561  t-loss:0.1869, loss-lb:0.0770, loss-ulb:0.0550, weight:2.00, lr:0.0003
[12:22:43.470] iteration:22562  t-loss:0.1369, loss-lb:0.0738, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:22:43.664] iteration:22563  t-loss:0.1459, loss-lb:0.0802, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:22:43.856] iteration:22564  t-loss:0.1421, loss-lb:0.0792, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:22:44.048] iteration:22565  t-loss:0.1469, loss-lb:0.0716, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:22:44.239] iteration:22566  t-loss:0.1415, loss-lb:0.0704, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:22:44.431] iteration:22567  t-loss:0.1372, loss-lb:0.0718, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:22:44.625] iteration:22568  t-loss:0.1401, loss-lb:0.0726, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:22:44.817] iteration:22569  t-loss:0.1476, loss-lb:0.0781, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:22:45.009] iteration:22570  t-loss:0.1402, loss-lb:0.0721, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:22:45.202] iteration:22571  t-loss:0.1436, loss-lb:0.0796, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:22:45.394] iteration:22572  t-loss:0.1447, loss-lb:0.0802, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:22:45.586] iteration:22573  t-loss:0.1470, loss-lb:0.0719, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:22:45.778] iteration:22574  t-loss:0.1308, loss-lb:0.0756, loss-ulb:0.0276, weight:2.00, lr:0.0003
[12:22:45.972] iteration:22575  t-loss:0.1419, loss-lb:0.0731, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:22:46.164] iteration:22576  t-loss:0.1471, loss-lb:0.0814, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:22:46.357] iteration:22577  t-loss:0.1509, loss-lb:0.0754, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:22:46.550] iteration:22578  t-loss:0.1490, loss-lb:0.0666, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:22:46.743] iteration:22579  t-loss:0.1438, loss-lb:0.0803, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:22:46.936] iteration:22580  t-loss:0.1488, loss-lb:0.0729, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:22:47.129] iteration:22581  t-loss:0.1338, loss-lb:0.0679, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:22:47.322] iteration:22582  t-loss:0.1610, loss-lb:0.0810, loss-ulb:0.0400, weight:2.00, lr:0.0003
[12:22:47.514] iteration:22583  t-loss:0.1527, loss-lb:0.0782, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:22:47.706] iteration:22584  t-loss:0.1480, loss-lb:0.0738, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:22:47.899] iteration:22585  t-loss:0.1338, loss-lb:0.0743, loss-ulb:0.0297, weight:2.00, lr:0.0003
[12:22:48.091] iteration:22586  t-loss:0.1603, loss-lb:0.0732, loss-ulb:0.0436, weight:2.00, lr:0.0003
[12:22:48.285] iteration:22587  t-loss:0.1310, loss-lb:0.0681, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:22:48.476] iteration:22588  t-loss:0.1303, loss-lb:0.0678, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:22:48.668] iteration:22589  t-loss:0.1479, loss-lb:0.0799, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:22:48.861] iteration:22590  t-loss:0.1452, loss-lb:0.0718, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:22:49.055] iteration:22591  t-loss:0.1397, loss-lb:0.0742, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:22:49.247] iteration:22592  t-loss:0.1453, loss-lb:0.0731, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:22:49.440] iteration:22593  t-loss:0.1433, loss-lb:0.0805, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:22:49.634] iteration:22594  t-loss:0.2145, loss-lb:0.0730, loss-ulb:0.0708, weight:2.00, lr:0.0003
[12:22:49.827] iteration:22595  t-loss:0.1520, loss-lb:0.0773, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:22:50.021] iteration:22596  t-loss:0.1540, loss-lb:0.0822, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:22:50.214] iteration:22597  t-loss:0.1367, loss-lb:0.0744, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:22:50.410] iteration:22598  t-loss:0.1449, loss-lb:0.0759, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:22:50.603] iteration:22599  t-loss:0.1357, loss-lb:0.0733, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:22:50.796] iteration:22600  t-loss:0.1563, loss-lb:0.0742, loss-ulb:0.0411, weight:2.00, lr:0.0003
[12:22:50.989] iteration:22601  t-loss:0.1603, loss-lb:0.0691, loss-ulb:0.0456, weight:2.00, lr:0.0003
[12:22:51.182] iteration:22602  t-loss:0.1598, loss-lb:0.0700, loss-ulb:0.0449, weight:2.00, lr:0.0003
[12:22:51.374] iteration:22603  t-loss:0.1581, loss-lb:0.0769, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:22:51.569] iteration:22604  t-loss:0.1345, loss-lb:0.0757, loss-ulb:0.0294, weight:2.00, lr:0.0003
[12:22:51.762] iteration:22605  t-loss:0.1605, loss-lb:0.0716, loss-ulb:0.0445, weight:2.00, lr:0.0003
[12:22:51.955] iteration:22606  t-loss:0.2149, loss-lb:0.0790, loss-ulb:0.0680, weight:2.00, lr:0.0003
[12:22:52.148] iteration:22607  t-loss:0.1392, loss-lb:0.0776, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:22:52.341] iteration:22608  t-loss:0.1504, loss-lb:0.0697, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:22:52.533] iteration:22609  t-loss:0.1487, loss-lb:0.0790, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:22:52.725] iteration:22610  t-loss:0.1372, loss-lb:0.0735, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:22:52.918] iteration:22611  t-loss:0.1445, loss-lb:0.0766, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:22:53.111] iteration:22612  t-loss:0.1410, loss-lb:0.0785, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:22:53.303] iteration:22613  t-loss:0.1589, loss-lb:0.0827, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:22:53.495] iteration:22614  t-loss:0.1370, loss-lb:0.0702, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:22:53.688] iteration:22615  t-loss:0.1383, loss-lb:0.0690, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:22:53.880] iteration:22616  t-loss:0.1320, loss-lb:0.0751, loss-ulb:0.0285, weight:2.00, lr:0.0003
[12:22:54.074] iteration:22617  t-loss:0.2005, loss-lb:0.0801, loss-ulb:0.0602, weight:2.00, lr:0.0003
[12:22:54.266] iteration:22618  t-loss:0.1386, loss-lb:0.0683, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:22:54.458] iteration:22619  t-loss:0.1413, loss-lb:0.0745, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:22:54.651] iteration:22620  t-loss:0.1532, loss-lb:0.0795, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:22:54.844] iteration:22621  t-loss:0.1385, loss-lb:0.0707, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:22:55.037] iteration:22622  t-loss:0.1750, loss-lb:0.0802, loss-ulb:0.0474, weight:2.00, lr:0.0003
[12:22:55.229] iteration:22623  t-loss:0.1463, loss-lb:0.0794, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:22:55.421] iteration:22624  t-loss:0.1261, loss-lb:0.0615, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:22:55.615] iteration:22625  t-loss:0.1350, loss-lb:0.0710, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:22:55.808] iteration:22626  t-loss:0.1438, loss-lb:0.0719, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:22:56.000] iteration:22627  t-loss:0.1292, loss-lb:0.0709, loss-ulb:0.0292, weight:2.00, lr:0.0003
[12:22:56.191] iteration:22628  t-loss:0.1511, loss-lb:0.0760, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:22:56.387] iteration:22629  t-loss:0.1337, loss-lb:0.0778, loss-ulb:0.0280, weight:2.00, lr:0.0003
[12:22:56.592] iteration:22630  t-loss:0.1349, loss-lb:0.0718, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:22:56.795] iteration:22631  t-loss:0.1508, loss-lb:0.0824, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:22:56.986] iteration:22632  t-loss:0.1452, loss-lb:0.0781, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:22:57.176] iteration:22633  t-loss:0.1414, loss-lb:0.0724, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:22:57.367] iteration:22634  t-loss:0.1471, loss-lb:0.0761, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:22:57.558] iteration:22635  t-loss:0.1585, loss-lb:0.0762, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:22:57.748] iteration:22636  t-loss:0.1410, loss-lb:0.0728, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:22:57.939] iteration:22637  t-loss:0.1284, loss-lb:0.0647, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:22:58.130] iteration:22638  t-loss:0.1387, loss-lb:0.0750, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:23:11.110]  <<Test>> - Ep:230  - mean_dice/mean_h95 - S:89.89/1.32, Best-S:90.99, T:89.86/1.35, Best-T:90.48
[12:23:11.110]           - AvgLoss(lb/ulb/all):0.0750/0.0344/0.1430
[12:23:11.641] iteration:22639  t-loss:0.1768, loss-lb:0.0840, loss-ulb:0.0464, weight:2.00, lr:0.0003
[12:23:11.841] iteration:22640  t-loss:0.1378, loss-lb:0.0737, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:23:12.035] iteration:22641  t-loss:0.1418, loss-lb:0.0715, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:23:12.228] iteration:22642  t-loss:0.1514, loss-lb:0.0785, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:23:12.421] iteration:22643  t-loss:0.1507, loss-lb:0.0749, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:23:12.615] iteration:22644  t-loss:0.1450, loss-lb:0.0722, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:23:12.807] iteration:22645  t-loss:0.1358, loss-lb:0.0727, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:23:13.000] iteration:22646  t-loss:0.1497, loss-lb:0.0744, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:23:13.194] iteration:22647  t-loss:0.1485, loss-lb:0.0702, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:23:13.386] iteration:22648  t-loss:0.1414, loss-lb:0.0724, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:23:13.578] iteration:22649  t-loss:0.1599, loss-lb:0.0750, loss-ulb:0.0424, weight:2.00, lr:0.0003
[12:23:13.771] iteration:22650  t-loss:0.1504, loss-lb:0.0761, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:23:13.964] iteration:22651  t-loss:0.1458, loss-lb:0.0731, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:23:14.157] iteration:22652  t-loss:0.1404, loss-lb:0.0735, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:23:14.351] iteration:22653  t-loss:0.1353, loss-lb:0.0708, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:23:14.546] iteration:22654  t-loss:0.1456, loss-lb:0.0755, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:23:14.739] iteration:22655  t-loss:0.1478, loss-lb:0.0739, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:23:14.932] iteration:22656  t-loss:0.1510, loss-lb:0.0785, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:23:15.124] iteration:22657  t-loss:0.1498, loss-lb:0.0787, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:23:15.316] iteration:22658  t-loss:0.1559, loss-lb:0.0728, loss-ulb:0.0415, weight:2.00, lr:0.0003
[12:23:15.509] iteration:22659  t-loss:0.1376, loss-lb:0.0755, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:23:15.701] iteration:22660  t-loss:0.1374, loss-lb:0.0691, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:23:15.894] iteration:22661  t-loss:0.1372, loss-lb:0.0688, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:23:16.085] iteration:22662  t-loss:0.1336, loss-lb:0.0658, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:23:16.276] iteration:22663  t-loss:0.1290, loss-lb:0.0690, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:23:16.469] iteration:22664  t-loss:0.1386, loss-lb:0.0781, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:23:16.660] iteration:22665  t-loss:0.1483, loss-lb:0.0702, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:23:16.852] iteration:22666  t-loss:0.1519, loss-lb:0.0841, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:23:17.046] iteration:22667  t-loss:0.1838, loss-lb:0.0801, loss-ulb:0.0519, weight:2.00, lr:0.0003
[12:23:17.238] iteration:22668  t-loss:0.1411, loss-lb:0.0749, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:23:17.430] iteration:22669  t-loss:0.1495, loss-lb:0.0664, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:23:17.623] iteration:22670  t-loss:0.1449, loss-lb:0.0777, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:23:17.815] iteration:22671  t-loss:0.1328, loss-lb:0.0670, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:23:18.007] iteration:22672  t-loss:0.1373, loss-lb:0.0758, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:23:18.199] iteration:22673  t-loss:0.1390, loss-lb:0.0701, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:23:18.391] iteration:22674  t-loss:0.2061, loss-lb:0.0759, loss-ulb:0.0651, weight:2.00, lr:0.0003
[12:23:18.582] iteration:22675  t-loss:0.1595, loss-lb:0.0788, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:23:18.774] iteration:22676  t-loss:0.1501, loss-lb:0.0772, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:23:18.965] iteration:22677  t-loss:0.1600, loss-lb:0.0738, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:23:19.157] iteration:22678  t-loss:0.1631, loss-lb:0.0718, loss-ulb:0.0456, weight:2.00, lr:0.0003
[12:23:19.349] iteration:22679  t-loss:0.1341, loss-lb:0.0720, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:23:19.541] iteration:22680  t-loss:0.1511, loss-lb:0.0807, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:23:19.732] iteration:22681  t-loss:0.1581, loss-lb:0.0809, loss-ulb:0.0386, weight:2.00, lr:0.0003
[12:23:19.923] iteration:22682  t-loss:0.1284, loss-lb:0.0713, loss-ulb:0.0286, weight:2.00, lr:0.0003
[12:23:20.115] iteration:22683  t-loss:0.1514, loss-lb:0.0759, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:23:20.307] iteration:22684  t-loss:0.1401, loss-lb:0.0734, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:23:20.497] iteration:22685  t-loss:0.1670, loss-lb:0.0755, loss-ulb:0.0458, weight:2.00, lr:0.0003
[12:23:20.691] iteration:22686  t-loss:0.1442, loss-lb:0.0748, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:23:20.885] iteration:22687  t-loss:0.1484, loss-lb:0.0795, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:23:21.078] iteration:22688  t-loss:0.1423, loss-lb:0.0812, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:23:21.274] iteration:22689  t-loss:0.1375, loss-lb:0.0689, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:23:21.469] iteration:22690  t-loss:0.1354, loss-lb:0.0731, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:23:21.661] iteration:22691  t-loss:0.1696, loss-lb:0.0733, loss-ulb:0.0481, weight:2.00, lr:0.0003
[12:23:21.854] iteration:22692  t-loss:0.1668, loss-lb:0.0788, loss-ulb:0.0440, weight:2.00, lr:0.0003
[12:23:22.045] iteration:22693  t-loss:0.1482, loss-lb:0.0784, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:23:22.239] iteration:22694  t-loss:0.1743, loss-lb:0.0834, loss-ulb:0.0455, weight:2.00, lr:0.0003
[12:23:22.431] iteration:22695  t-loss:0.1507, loss-lb:0.0797, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:23:22.624] iteration:22696  t-loss:0.1954, loss-lb:0.0687, loss-ulb:0.0634, weight:2.00, lr:0.0003
[12:23:22.815] iteration:22697  t-loss:0.1407, loss-lb:0.0745, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:23:23.008] iteration:22698  t-loss:0.1443, loss-lb:0.0720, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:23:23.201] iteration:22699  t-loss:0.1417, loss-lb:0.0681, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:23:23.393] iteration:22700  t-loss:0.1524, loss-lb:0.0762, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:23:23.584] iteration:22701  t-loss:0.1313, loss-lb:0.0672, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:23:23.776] iteration:22702  t-loss:0.1747, loss-lb:0.0785, loss-ulb:0.0481, weight:2.00, lr:0.0003
[12:23:23.968] iteration:22703  t-loss:0.1500, loss-lb:0.0734, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:23:24.162] iteration:22704  t-loss:0.1752, loss-lb:0.0769, loss-ulb:0.0491, weight:2.00, lr:0.0003
[12:23:24.354] iteration:22705  t-loss:0.1729, loss-lb:0.0810, loss-ulb:0.0460, weight:2.00, lr:0.0003
[12:23:24.547] iteration:22706  t-loss:0.1590, loss-lb:0.0769, loss-ulb:0.0411, weight:2.00, lr:0.0003
[12:23:24.738] iteration:22707  t-loss:0.1506, loss-lb:0.0790, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:23:24.931] iteration:22708  t-loss:0.1450, loss-lb:0.0750, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:23:25.123] iteration:22709  t-loss:0.1485, loss-lb:0.0659, loss-ulb:0.0413, weight:2.00, lr:0.0003
[12:23:25.314] iteration:22710  t-loss:0.1358, loss-lb:0.0753, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:23:25.507] iteration:22711  t-loss:0.1541, loss-lb:0.0820, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:23:25.699] iteration:22712  t-loss:0.1448, loss-lb:0.0766, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:23:25.890] iteration:22713  t-loss:0.1448, loss-lb:0.0742, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:23:26.083] iteration:22714  t-loss:0.1331, loss-lb:0.0704, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:23:26.274] iteration:22715  t-loss:0.1584, loss-lb:0.0798, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:23:26.465] iteration:22716  t-loss:0.1498, loss-lb:0.0728, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:23:26.654] iteration:22717  t-loss:0.1489, loss-lb:0.0822, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:23:26.846] iteration:22718  t-loss:0.1331, loss-lb:0.0779, loss-ulb:0.0276, weight:2.00, lr:0.0003
[12:23:27.036] iteration:22719  t-loss:0.1458, loss-lb:0.0684, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:23:27.228] iteration:22720  t-loss:0.1597, loss-lb:0.0803, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:23:27.421] iteration:22721  t-loss:0.1414, loss-lb:0.0726, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:23:27.614] iteration:22722  t-loss:0.1245, loss-lb:0.0731, loss-ulb:0.0257, weight:2.00, lr:0.0003
[12:23:27.806] iteration:22723  t-loss:0.1464, loss-lb:0.0742, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:23:28.005] iteration:22724  t-loss:0.1397, loss-lb:0.0756, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:23:28.197] iteration:22725  t-loss:0.1435, loss-lb:0.0787, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:23:28.394] iteration:22726  t-loss:0.1725, loss-lb:0.0737, loss-ulb:0.0494, weight:2.00, lr:0.0003
[12:23:28.588] iteration:22727  t-loss:0.1559, loss-lb:0.0869, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:23:28.780] iteration:22728  t-loss:0.1554, loss-lb:0.0752, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:23:28.970] iteration:22729  t-loss:0.1448, loss-lb:0.0756, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:23:29.162] iteration:22730  t-loss:0.1367, loss-lb:0.0752, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:23:29.365] iteration:22731  t-loss:0.1437, loss-lb:0.0706, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:23:29.560] iteration:22732  t-loss:0.1538, loss-lb:0.0742, loss-ulb:0.0398, weight:2.00, lr:0.0003
[12:23:29.751] iteration:22733  t-loss:0.1293, loss-lb:0.0718, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:23:29.941] iteration:22734  t-loss:0.1410, loss-lb:0.0761, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:23:30.131] iteration:22735  t-loss:0.1460, loss-lb:0.0701, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:23:30.321] iteration:22736  t-loss:0.1430, loss-lb:0.0702, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:23:30.897] iteration:22737  t-loss:0.1509, loss-lb:0.0686, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:23:31.091] iteration:22738  t-loss:0.1576, loss-lb:0.0781, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:23:31.282] iteration:22739  t-loss:0.1419, loss-lb:0.0759, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:23:31.476] iteration:22740  t-loss:0.1857, loss-lb:0.0715, loss-ulb:0.0571, weight:2.00, lr:0.0003
[12:23:31.667] iteration:22741  t-loss:0.1465, loss-lb:0.0763, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:23:31.861] iteration:22742  t-loss:0.1466, loss-lb:0.0775, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:23:32.058] iteration:22743  t-loss:0.1431, loss-lb:0.0804, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:23:32.253] iteration:22744  t-loss:0.1515, loss-lb:0.0746, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:23:32.447] iteration:22745  t-loss:0.1486, loss-lb:0.0763, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:23:32.640] iteration:22746  t-loss:0.1703, loss-lb:0.0745, loss-ulb:0.0479, weight:2.00, lr:0.0003
[12:23:32.834] iteration:22747  t-loss:0.1965, loss-lb:0.0785, loss-ulb:0.0590, weight:2.00, lr:0.0003
[12:23:33.027] iteration:22748  t-loss:0.1469, loss-lb:0.0804, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:23:33.220] iteration:22749  t-loss:0.1538, loss-lb:0.0787, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:23:33.411] iteration:22750  t-loss:0.1479, loss-lb:0.0785, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:23:33.603] iteration:22751  t-loss:0.1458, loss-lb:0.0698, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:23:33.796] iteration:22752  t-loss:0.1361, loss-lb:0.0690, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:23:33.989] iteration:22753  t-loss:0.1301, loss-lb:0.0722, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:23:34.181] iteration:22754  t-loss:0.1443, loss-lb:0.0778, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:23:34.372] iteration:22755  t-loss:0.1387, loss-lb:0.0756, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:23:34.565] iteration:22756  t-loss:0.1559, loss-lb:0.0718, loss-ulb:0.0420, weight:2.00, lr:0.0003
[12:23:34.759] iteration:22757  t-loss:0.1456, loss-lb:0.0727, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:23:34.953] iteration:22758  t-loss:0.1306, loss-lb:0.0781, loss-ulb:0.0263, weight:2.00, lr:0.0003
[12:23:35.144] iteration:22759  t-loss:0.1514, loss-lb:0.0751, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:23:35.336] iteration:22760  t-loss:0.1395, loss-lb:0.0727, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:23:35.529] iteration:22761  t-loss:0.1465, loss-lb:0.0722, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:23:35.721] iteration:22762  t-loss:0.1493, loss-lb:0.0825, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:23:35.913] iteration:22763  t-loss:0.1481, loss-lb:0.0726, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:23:36.105] iteration:22764  t-loss:0.1384, loss-lb:0.0710, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:23:36.297] iteration:22765  t-loss:0.1436, loss-lb:0.0713, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:23:36.489] iteration:22766  t-loss:0.1498, loss-lb:0.0772, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:23:36.682] iteration:22767  t-loss:0.1489, loss-lb:0.0745, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:23:36.875] iteration:22768  t-loss:0.2310, loss-lb:0.0757, loss-ulb:0.0776, weight:2.00, lr:0.0003
[12:23:37.068] iteration:22769  t-loss:0.1494, loss-lb:0.0726, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:23:37.260] iteration:22770  t-loss:0.1505, loss-lb:0.0710, loss-ulb:0.0398, weight:2.00, lr:0.0003
[12:23:37.453] iteration:22771  t-loss:0.1326, loss-lb:0.0695, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:23:37.645] iteration:22772  t-loss:0.1507, loss-lb:0.0758, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:23:37.837] iteration:22773  t-loss:0.1444, loss-lb:0.0804, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:23:38.035] iteration:22774  t-loss:0.1655, loss-lb:0.0780, loss-ulb:0.0437, weight:2.00, lr:0.0003
[12:23:38.228] iteration:22775  t-loss:0.1522, loss-lb:0.0814, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:23:38.421] iteration:22776  t-loss:0.1406, loss-lb:0.0763, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:23:38.612] iteration:22777  t-loss:0.1418, loss-lb:0.0756, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:23:38.805] iteration:22778  t-loss:0.1559, loss-lb:0.0838, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:23:38.997] iteration:22779  t-loss:0.1537, loss-lb:0.0768, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:23:39.189] iteration:22780  t-loss:0.1330, loss-lb:0.0649, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:23:39.381] iteration:22781  t-loss:0.1400, loss-lb:0.0694, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:23:39.574] iteration:22782  t-loss:0.1382, loss-lb:0.0725, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:23:39.766] iteration:22783  t-loss:0.1378, loss-lb:0.0753, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:23:39.958] iteration:22784  t-loss:0.1626, loss-lb:0.0722, loss-ulb:0.0452, weight:2.00, lr:0.0003
[12:23:40.149] iteration:22785  t-loss:0.1430, loss-lb:0.0739, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:23:40.340] iteration:22786  t-loss:0.1472, loss-lb:0.0825, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:23:40.532] iteration:22787  t-loss:0.1611, loss-lb:0.0719, loss-ulb:0.0446, weight:2.00, lr:0.0003
[12:23:40.724] iteration:22788  t-loss:0.1378, loss-lb:0.0696, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:23:40.917] iteration:22789  t-loss:0.1423, loss-lb:0.0803, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:23:41.108] iteration:22790  t-loss:0.1513, loss-lb:0.0749, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:23:41.299] iteration:22791  t-loss:0.1336, loss-lb:0.0718, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:23:41.492] iteration:22792  t-loss:0.2249, loss-lb:0.0677, loss-ulb:0.0786, weight:2.00, lr:0.0003
[12:23:41.683] iteration:22793  t-loss:0.1333, loss-lb:0.0714, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:23:41.876] iteration:22794  t-loss:0.1370, loss-lb:0.0703, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:23:42.067] iteration:22795  t-loss:0.1603, loss-lb:0.0730, loss-ulb:0.0436, weight:2.00, lr:0.0003
[12:23:42.259] iteration:22796  t-loss:0.1434, loss-lb:0.0772, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:23:42.451] iteration:22797  t-loss:0.1503, loss-lb:0.0698, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:23:42.645] iteration:22798  t-loss:0.1366, loss-lb:0.0736, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:23:42.838] iteration:22799  t-loss:0.1413, loss-lb:0.0737, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:23:43.030] iteration:22800  t-loss:0.1549, loss-lb:0.0794, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:23:43.222] iteration:22801  t-loss:0.1495, loss-lb:0.0752, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:23:43.415] iteration:22802  t-loss:0.1405, loss-lb:0.0722, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:23:43.607] iteration:22803  t-loss:0.1489, loss-lb:0.0820, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:23:43.800] iteration:22804  t-loss:0.1696, loss-lb:0.0847, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:23:43.993] iteration:22805  t-loss:0.2174, loss-lb:0.0717, loss-ulb:0.0728, weight:2.00, lr:0.0003
[12:23:44.186] iteration:22806  t-loss:0.1334, loss-lb:0.0694, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:23:44.379] iteration:22807  t-loss:0.1415, loss-lb:0.0701, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:23:44.571] iteration:22808  t-loss:0.1554, loss-lb:0.0807, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:23:44.764] iteration:22809  t-loss:0.1674, loss-lb:0.0750, loss-ulb:0.0462, weight:2.00, lr:0.0003
[12:23:44.958] iteration:22810  t-loss:0.1392, loss-lb:0.0697, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:23:45.150] iteration:22811  t-loss:0.1501, loss-lb:0.0778, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:23:45.343] iteration:22812  t-loss:0.1637, loss-lb:0.0867, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:23:45.535] iteration:22813  t-loss:0.1508, loss-lb:0.0803, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:23:45.729] iteration:22814  t-loss:0.1424, loss-lb:0.0706, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:23:45.921] iteration:22815  t-loss:0.1385, loss-lb:0.0748, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:23:46.114] iteration:22816  t-loss:0.1568, loss-lb:0.0664, loss-ulb:0.0452, weight:2.00, lr:0.0003
[12:23:46.306] iteration:22817  t-loss:0.1236, loss-lb:0.0661, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:23:46.498] iteration:22818  t-loss:0.1460, loss-lb:0.0764, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:23:46.696] iteration:22819  t-loss:0.1510, loss-lb:0.0766, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:23:46.888] iteration:22820  t-loss:0.1434, loss-lb:0.0733, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:23:47.081] iteration:22821  t-loss:0.1470, loss-lb:0.0714, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:23:47.273] iteration:22822  t-loss:0.1395, loss-lb:0.0680, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:23:47.465] iteration:22823  t-loss:0.1543, loss-lb:0.0801, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:23:47.659] iteration:22824  t-loss:0.1574, loss-lb:0.0715, loss-ulb:0.0429, weight:2.00, lr:0.0003
[12:23:47.853] iteration:22825  t-loss:0.1571, loss-lb:0.0776, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:23:48.045] iteration:22826  t-loss:0.1549, loss-lb:0.0832, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:23:48.236] iteration:22827  t-loss:0.1456, loss-lb:0.0783, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:23:48.427] iteration:22828  t-loss:0.1456, loss-lb:0.0744, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:23:48.620] iteration:22829  t-loss:0.1460, loss-lb:0.0776, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:23:48.811] iteration:22830  t-loss:0.1421, loss-lb:0.0761, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:23:49.001] iteration:22831  t-loss:0.1386, loss-lb:0.0730, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:23:49.193] iteration:22832  t-loss:0.1433, loss-lb:0.0834, loss-ulb:0.0299, weight:2.00, lr:0.0003
[12:23:49.385] iteration:22833  t-loss:0.1430, loss-lb:0.0692, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:23:49.575] iteration:22834  t-loss:0.1555, loss-lb:0.0789, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:24:01.590]  <<Test>> - Ep:232  - mean_dice/mean_h95 - S:89.83/1.31, Best-S:90.99, T:89.76/1.36, Best-T:90.48
[12:24:01.590]           - AvgLoss(lb/ulb/all):0.0749/0.0358/0.1465
[12:24:02.203] iteration:22835  t-loss:0.1356, loss-lb:0.0720, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:24:02.399] iteration:22836  t-loss:0.1459, loss-lb:0.0771, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:24:02.592] iteration:22837  t-loss:0.1284, loss-lb:0.0679, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:24:02.785] iteration:22838  t-loss:0.1401, loss-lb:0.0747, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:24:02.977] iteration:22839  t-loss:0.1405, loss-lb:0.0693, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:24:03.169] iteration:22840  t-loss:0.1472, loss-lb:0.0721, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:24:03.363] iteration:22841  t-loss:0.1497, loss-lb:0.0809, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:24:03.555] iteration:22842  t-loss:0.1476, loss-lb:0.0790, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:24:03.748] iteration:22843  t-loss:0.1875, loss-lb:0.0810, loss-ulb:0.0533, weight:2.00, lr:0.0003
[12:24:03.941] iteration:22844  t-loss:0.1333, loss-lb:0.0714, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:24:04.134] iteration:22845  t-loss:0.1435, loss-lb:0.0817, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:24:04.327] iteration:22846  t-loss:0.1411, loss-lb:0.0695, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:24:04.519] iteration:22847  t-loss:0.1301, loss-lb:0.0659, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:24:04.713] iteration:22848  t-loss:0.1657, loss-lb:0.0724, loss-ulb:0.0466, weight:2.00, lr:0.0003
[12:24:04.907] iteration:22849  t-loss:0.1523, loss-lb:0.0763, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:24:05.100] iteration:22850  t-loss:0.1418, loss-lb:0.0723, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:24:05.292] iteration:22851  t-loss:0.1469, loss-lb:0.0736, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:24:05.485] iteration:22852  t-loss:0.1650, loss-lb:0.0800, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:24:05.678] iteration:22853  t-loss:0.1382, loss-lb:0.0753, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:24:05.869] iteration:22854  t-loss:0.1402, loss-lb:0.0693, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:24:06.061] iteration:22855  t-loss:0.1430, loss-lb:0.0701, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:24:06.254] iteration:22856  t-loss:0.1467, loss-lb:0.0726, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:24:06.446] iteration:22857  t-loss:0.1455, loss-lb:0.0747, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:24:06.639] iteration:22858  t-loss:0.1402, loss-lb:0.0746, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:24:06.831] iteration:22859  t-loss:0.1776, loss-lb:0.0671, loss-ulb:0.0552, weight:2.00, lr:0.0003
[12:24:07.022] iteration:22860  t-loss:0.1620, loss-lb:0.0804, loss-ulb:0.0408, weight:2.00, lr:0.0003
[12:24:07.215] iteration:22861  t-loss:0.1470, loss-lb:0.0858, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:24:07.408] iteration:22862  t-loss:0.1391, loss-lb:0.0768, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:24:07.602] iteration:22863  t-loss:0.1435, loss-lb:0.0635, loss-ulb:0.0400, weight:2.00, lr:0.0003
[12:24:07.794] iteration:22864  t-loss:0.1417, loss-lb:0.0699, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:24:07.987] iteration:22865  t-loss:0.1517, loss-lb:0.0793, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:24:08.179] iteration:22866  t-loss:0.1601, loss-lb:0.0835, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:24:08.371] iteration:22867  t-loss:0.1351, loss-lb:0.0664, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:24:08.564] iteration:22868  t-loss:0.1452, loss-lb:0.0698, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:24:08.757] iteration:22869  t-loss:0.1405, loss-lb:0.0747, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:24:08.950] iteration:22870  t-loss:0.1486, loss-lb:0.0789, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:24:09.142] iteration:22871  t-loss:0.1527, loss-lb:0.0817, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:24:09.334] iteration:22872  t-loss:0.1639, loss-lb:0.0789, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:24:09.527] iteration:22873  t-loss:0.1278, loss-lb:0.0707, loss-ulb:0.0285, weight:2.00, lr:0.0003
[12:24:09.720] iteration:22874  t-loss:0.1366, loss-lb:0.0717, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:24:09.912] iteration:22875  t-loss:0.1585, loss-lb:0.0779, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:24:10.105] iteration:22876  t-loss:0.1406, loss-lb:0.0760, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:24:10.298] iteration:22877  t-loss:0.1500, loss-lb:0.0707, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:24:10.490] iteration:22878  t-loss:0.1352, loss-lb:0.0680, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:24:10.683] iteration:22879  t-loss:0.1583, loss-lb:0.0661, loss-ulb:0.0461, weight:2.00, lr:0.0003
[12:24:10.875] iteration:22880  t-loss:0.1512, loss-lb:0.0691, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:24:11.068] iteration:22881  t-loss:0.1368, loss-lb:0.0704, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:24:11.260] iteration:22882  t-loss:0.1507, loss-lb:0.0733, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:24:11.452] iteration:22883  t-loss:0.1603, loss-lb:0.0803, loss-ulb:0.0400, weight:2.00, lr:0.0003
[12:24:11.645] iteration:22884  t-loss:0.1614, loss-lb:0.0893, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:24:11.837] iteration:22885  t-loss:0.1492, loss-lb:0.0691, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:24:12.028] iteration:22886  t-loss:0.1423, loss-lb:0.0758, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:24:12.222] iteration:22887  t-loss:0.1596, loss-lb:0.0733, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:24:12.413] iteration:22888  t-loss:0.1364, loss-lb:0.0695, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:24:12.605] iteration:22889  t-loss:0.1503, loss-lb:0.0713, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:24:12.798] iteration:22890  t-loss:0.1318, loss-lb:0.0744, loss-ulb:0.0287, weight:2.00, lr:0.0003
[12:24:12.991] iteration:22891  t-loss:0.1348, loss-lb:0.0688, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:24:13.184] iteration:22892  t-loss:0.1429, loss-lb:0.0677, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:24:13.377] iteration:22893  t-loss:0.1419, loss-lb:0.0771, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:24:13.570] iteration:22894  t-loss:0.1509, loss-lb:0.0786, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:24:13.764] iteration:22895  t-loss:0.1485, loss-lb:0.0732, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:24:13.958] iteration:22896  t-loss:0.1412, loss-lb:0.0730, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:24:14.149] iteration:22897  t-loss:0.1419, loss-lb:0.0706, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:24:14.342] iteration:22898  t-loss:0.1460, loss-lb:0.0693, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:24:14.535] iteration:22899  t-loss:0.1397, loss-lb:0.0722, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:24:14.727] iteration:22900  t-loss:0.1390, loss-lb:0.0750, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:24:14.920] iteration:22901  t-loss:0.1640, loss-lb:0.0789, loss-ulb:0.0426, weight:2.00, lr:0.0003
[12:24:15.113] iteration:22902  t-loss:0.1406, loss-lb:0.0720, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:24:15.307] iteration:22903  t-loss:0.1657, loss-lb:0.0710, loss-ulb:0.0473, weight:2.00, lr:0.0003
[12:24:15.500] iteration:22904  t-loss:0.1802, loss-lb:0.0694, loss-ulb:0.0554, weight:2.00, lr:0.0003
[12:24:15.693] iteration:22905  t-loss:0.2015, loss-lb:0.0781, loss-ulb:0.0617, weight:2.00, lr:0.0003
[12:24:15.886] iteration:22906  t-loss:0.1926, loss-lb:0.0823, loss-ulb:0.0551, weight:2.00, lr:0.0003
[12:24:16.078] iteration:22907  t-loss:0.1523, loss-lb:0.0753, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:24:16.271] iteration:22908  t-loss:0.1441, loss-lb:0.0745, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:24:16.463] iteration:22909  t-loss:0.1368, loss-lb:0.0703, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:24:16.656] iteration:22910  t-loss:0.1410, loss-lb:0.0729, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:24:16.849] iteration:22911  t-loss:0.1518, loss-lb:0.0756, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:24:17.041] iteration:22912  t-loss:0.1365, loss-lb:0.0658, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:24:17.233] iteration:22913  t-loss:0.1378, loss-lb:0.0717, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:24:17.425] iteration:22914  t-loss:0.1475, loss-lb:0.0743, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:24:17.619] iteration:22915  t-loss:0.1427, loss-lb:0.0652, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:24:17.810] iteration:22916  t-loss:0.1326, loss-lb:0.0755, loss-ulb:0.0285, weight:2.00, lr:0.0003
[12:24:18.003] iteration:22917  t-loss:0.1497, loss-lb:0.0745, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:24:18.195] iteration:22918  t-loss:0.1359, loss-lb:0.0666, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:24:18.387] iteration:22919  t-loss:0.1493, loss-lb:0.0741, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:24:18.579] iteration:22920  t-loss:0.1453, loss-lb:0.0741, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:24:18.772] iteration:22921  t-loss:0.1407, loss-lb:0.0780, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:24:18.965] iteration:22922  t-loss:0.1433, loss-lb:0.0698, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:24:19.157] iteration:22923  t-loss:0.1465, loss-lb:0.0770, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:24:19.350] iteration:22924  t-loss:0.1328, loss-lb:0.0731, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:24:19.542] iteration:22925  t-loss:0.1338, loss-lb:0.0697, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:24:19.732] iteration:22926  t-loss:0.1463, loss-lb:0.0745, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:24:19.923] iteration:22927  t-loss:0.1550, loss-lb:0.0700, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:24:20.114] iteration:22928  t-loss:0.1468, loss-lb:0.0770, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:24:20.305] iteration:22929  t-loss:0.1482, loss-lb:0.0780, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:24:20.497] iteration:22930  t-loss:0.1318, loss-lb:0.0707, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:24:20.688] iteration:22931  t-loss:0.1319, loss-lb:0.0710, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:24:20.880] iteration:22932  t-loss:0.1595, loss-lb:0.0889, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:24:21.496] iteration:22933  t-loss:0.1628, loss-lb:0.0707, loss-ulb:0.0460, weight:2.00, lr:0.0003
[12:24:21.693] iteration:22934  t-loss:0.1394, loss-lb:0.0722, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:24:21.884] iteration:22935  t-loss:0.1442, loss-lb:0.0794, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:24:22.077] iteration:22936  t-loss:0.1615, loss-lb:0.0870, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:24:22.269] iteration:22937  t-loss:0.1372, loss-lb:0.0759, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:24:22.463] iteration:22938  t-loss:0.1477, loss-lb:0.0714, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:24:22.655] iteration:22939  t-loss:0.1827, loss-lb:0.0807, loss-ulb:0.0510, weight:2.00, lr:0.0003
[12:24:22.847] iteration:22940  t-loss:0.1398, loss-lb:0.0711, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:24:23.039] iteration:22941  t-loss:0.1329, loss-lb:0.0684, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:24:23.232] iteration:22942  t-loss:0.1442, loss-lb:0.0693, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:24:23.425] iteration:22943  t-loss:0.1516, loss-lb:0.0746, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:24:23.618] iteration:22944  t-loss:0.1380, loss-lb:0.0780, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:24:23.810] iteration:22945  t-loss:0.1336, loss-lb:0.0685, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:24:24.003] iteration:22946  t-loss:0.1469, loss-lb:0.0777, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:24:24.195] iteration:22947  t-loss:0.1437, loss-lb:0.0698, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:24:24.388] iteration:22948  t-loss:0.1358, loss-lb:0.0672, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:24:24.580] iteration:22949  t-loss:0.1515, loss-lb:0.0790, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:24:24.772] iteration:22950  t-loss:0.1383, loss-lb:0.0772, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:24:24.964] iteration:22951  t-loss:0.1443, loss-lb:0.0706, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:24:25.157] iteration:22952  t-loss:0.1403, loss-lb:0.0714, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:24:25.349] iteration:22953  t-loss:0.1346, loss-lb:0.0710, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:24:25.541] iteration:22954  t-loss:0.1400, loss-lb:0.0728, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:24:25.733] iteration:22955  t-loss:0.1553, loss-lb:0.0773, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:24:25.924] iteration:22956  t-loss:0.1303, loss-lb:0.0637, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:24:26.116] iteration:22957  t-loss:0.1483, loss-lb:0.0661, loss-ulb:0.0411, weight:2.00, lr:0.0003
[12:24:26.310] iteration:22958  t-loss:0.1445, loss-lb:0.0692, loss-ulb:0.0377, weight:2.00, lr:0.0003
[12:24:26.502] iteration:22959  t-loss:0.1501, loss-lb:0.0784, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:24:26.693] iteration:22960  t-loss:0.1521, loss-lb:0.0752, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:24:26.886] iteration:22961  t-loss:0.1421, loss-lb:0.0777, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:24:27.079] iteration:22962  t-loss:0.1461, loss-lb:0.0794, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:24:27.273] iteration:22963  t-loss:0.1290, loss-lb:0.0682, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:24:27.465] iteration:22964  t-loss:0.1562, loss-lb:0.0855, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:24:27.659] iteration:22965  t-loss:0.1436, loss-lb:0.0670, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:24:27.851] iteration:22966  t-loss:0.1323, loss-lb:0.0680, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:24:28.048] iteration:22967  t-loss:0.1351, loss-lb:0.0679, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:24:28.240] iteration:22968  t-loss:0.1294, loss-lb:0.0737, loss-ulb:0.0279, weight:2.00, lr:0.0003
[12:24:28.433] iteration:22969  t-loss:0.1437, loss-lb:0.0694, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:24:28.626] iteration:22970  t-loss:0.1332, loss-lb:0.0708, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:24:28.820] iteration:22971  t-loss:0.1384, loss-lb:0.0771, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:24:29.011] iteration:22972  t-loss:0.1404, loss-lb:0.0763, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:24:29.204] iteration:22973  t-loss:0.1432, loss-lb:0.0752, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:24:29.396] iteration:22974  t-loss:0.1543, loss-lb:0.0803, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:24:29.589] iteration:22975  t-loss:0.1759, loss-lb:0.0740, loss-ulb:0.0510, weight:2.00, lr:0.0003
[12:24:29.782] iteration:22976  t-loss:0.1427, loss-lb:0.0651, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:24:29.974] iteration:22977  t-loss:0.1352, loss-lb:0.0715, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:24:30.167] iteration:22978  t-loss:0.1482, loss-lb:0.0742, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:24:30.359] iteration:22979  t-loss:0.1436, loss-lb:0.0681, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:24:30.552] iteration:22980  t-loss:0.1459, loss-lb:0.0722, loss-ulb:0.0369, weight:2.00, lr:0.0003
[12:24:30.746] iteration:22981  t-loss:0.1413, loss-lb:0.0696, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:24:30.938] iteration:22982  t-loss:0.1340, loss-lb:0.0730, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:24:31.131] iteration:22983  t-loss:0.1491, loss-lb:0.0712, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:24:31.324] iteration:22984  t-loss:0.1325, loss-lb:0.0688, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:24:31.516] iteration:22985  t-loss:0.1330, loss-lb:0.0754, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:24:31.709] iteration:22986  t-loss:0.1746, loss-lb:0.0783, loss-ulb:0.0481, weight:2.00, lr:0.0003
[12:24:31.902] iteration:22987  t-loss:0.1452, loss-lb:0.0727, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:24:32.095] iteration:22988  t-loss:0.1547, loss-lb:0.0796, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:24:32.287] iteration:22989  t-loss:0.1570, loss-lb:0.0776, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:24:32.480] iteration:22990  t-loss:0.1647, loss-lb:0.0759, loss-ulb:0.0444, weight:2.00, lr:0.0003
[12:24:32.671] iteration:22991  t-loss:0.1484, loss-lb:0.0723, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:24:32.864] iteration:22992  t-loss:0.1377, loss-lb:0.0682, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:24:33.058] iteration:22993  t-loss:0.1373, loss-lb:0.0739, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:24:33.258] iteration:22994  t-loss:0.1349, loss-lb:0.0715, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:24:33.452] iteration:22995  t-loss:0.1318, loss-lb:0.0713, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:24:33.644] iteration:22996  t-loss:0.1470, loss-lb:0.0744, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:24:33.838] iteration:22997  t-loss:0.1488, loss-lb:0.0776, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:24:34.030] iteration:22998  t-loss:0.1537, loss-lb:0.0726, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:24:34.221] iteration:22999  t-loss:0.1396, loss-lb:0.0711, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:24:34.413] iteration:23000  t-loss:0.1445, loss-lb:0.0743, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:24:34.605] iteration:23001  t-loss:0.1572, loss-lb:0.0729, loss-ulb:0.0422, weight:2.00, lr:0.0003
[12:24:34.811] iteration:23002  t-loss:0.1784, loss-lb:0.0752, loss-ulb:0.0516, weight:2.00, lr:0.0003
[12:24:35.008] iteration:23003  t-loss:0.1491, loss-lb:0.0714, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:24:35.204] iteration:23004  t-loss:0.1559, loss-lb:0.0753, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:24:35.395] iteration:23005  t-loss:0.1432, loss-lb:0.0756, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:24:35.587] iteration:23006  t-loss:0.1404, loss-lb:0.0712, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:24:35.778] iteration:23007  t-loss:0.1432, loss-lb:0.0724, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:24:35.971] iteration:23008  t-loss:0.2264, loss-lb:0.0791, loss-ulb:0.0737, weight:2.00, lr:0.0003
[12:24:36.163] iteration:23009  t-loss:0.1351, loss-lb:0.0720, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:24:36.356] iteration:23010  t-loss:0.1523, loss-lb:0.0727, loss-ulb:0.0398, weight:2.00, lr:0.0003
[12:24:36.549] iteration:23011  t-loss:0.1374, loss-lb:0.0693, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:24:36.741] iteration:23012  t-loss:0.1425, loss-lb:0.0737, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:24:36.934] iteration:23013  t-loss:0.1548, loss-lb:0.0730, loss-ulb:0.0409, weight:2.00, lr:0.0003
[12:24:37.125] iteration:23014  t-loss:0.1386, loss-lb:0.0771, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:24:37.318] iteration:23015  t-loss:0.1337, loss-lb:0.0731, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:24:37.509] iteration:23016  t-loss:0.1313, loss-lb:0.0698, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:24:37.701] iteration:23017  t-loss:0.1544, loss-lb:0.0750, loss-ulb:0.0397, weight:2.00, lr:0.0003
[12:24:37.893] iteration:23018  t-loss:0.1248, loss-lb:0.0643, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:24:38.084] iteration:23019  t-loss:0.1419, loss-lb:0.0756, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:24:38.277] iteration:23020  t-loss:0.1433, loss-lb:0.0739, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:24:38.468] iteration:23021  t-loss:0.1477, loss-lb:0.0746, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:24:38.660] iteration:23022  t-loss:0.1421, loss-lb:0.0726, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:24:38.851] iteration:23023  t-loss:0.1455, loss-lb:0.0725, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:24:39.043] iteration:23024  t-loss:0.1531, loss-lb:0.0687, loss-ulb:0.0422, weight:2.00, lr:0.0003
[12:24:39.233] iteration:23025  t-loss:0.1565, loss-lb:0.0719, loss-ulb:0.0423, weight:2.00, lr:0.0003
[12:24:39.424] iteration:23026  t-loss:0.1419, loss-lb:0.0751, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:24:39.614] iteration:23027  t-loss:0.1428, loss-lb:0.0695, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:24:39.805] iteration:23028  t-loss:0.1306, loss-lb:0.0714, loss-ulb:0.0296, weight:2.00, lr:0.0003
[12:24:39.998] iteration:23029  t-loss:0.1364, loss-lb:0.0712, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:24:40.189] iteration:23030  t-loss:0.1503, loss-lb:0.0762, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:24:52.985]  <<Test>> - Ep:234  - mean_dice/mean_h95 - S:89.68/1.37, Best-S:90.99, T:89.74/1.34, Best-T:90.48
[12:24:52.985]           - AvgLoss(lb/ulb/all):0.0732/0.0350/0.1425
[12:24:53.507] iteration:23031  t-loss:0.1478, loss-lb:0.0709, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:24:53.703] iteration:23032  t-loss:0.1470, loss-lb:0.0754, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:24:53.895] iteration:23033  t-loss:0.1480, loss-lb:0.0642, loss-ulb:0.0419, weight:2.00, lr:0.0003
[12:24:54.086] iteration:23034  t-loss:0.1637, loss-lb:0.0765, loss-ulb:0.0436, weight:2.00, lr:0.0003
[12:24:54.278] iteration:23035  t-loss:0.1431, loss-lb:0.0823, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:24:54.470] iteration:23036  t-loss:0.1454, loss-lb:0.0708, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:24:54.662] iteration:23037  t-loss:0.1378, loss-lb:0.0769, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:24:54.857] iteration:23038  t-loss:0.1435, loss-lb:0.0673, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:24:55.053] iteration:23039  t-loss:0.1393, loss-lb:0.0710, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:24:55.248] iteration:23040  t-loss:0.1326, loss-lb:0.0678, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:24:55.445] iteration:23041  t-loss:0.1865, loss-lb:0.0729, loss-ulb:0.0568, weight:2.00, lr:0.0003
[12:24:55.640] iteration:23042  t-loss:0.1337, loss-lb:0.0689, loss-ulb:0.0324, weight:2.00, lr:0.0003
[12:24:55.835] iteration:23043  t-loss:0.1403, loss-lb:0.0729, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:24:56.029] iteration:23044  t-loss:0.1455, loss-lb:0.0766, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:24:56.221] iteration:23045  t-loss:0.1470, loss-lb:0.0771, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:24:56.413] iteration:23046  t-loss:0.1307, loss-lb:0.0727, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:24:56.606] iteration:23047  t-loss:0.1487, loss-lb:0.0731, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:24:56.800] iteration:23048  t-loss:0.1562, loss-lb:0.0747, loss-ulb:0.0407, weight:2.00, lr:0.0003
[12:24:56.992] iteration:23049  t-loss:0.1345, loss-lb:0.0777, loss-ulb:0.0284, weight:2.00, lr:0.0003
[12:24:57.184] iteration:23050  t-loss:0.1490, loss-lb:0.0688, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:24:57.377] iteration:23051  t-loss:0.1337, loss-lb:0.0697, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:24:57.569] iteration:23052  t-loss:0.1424, loss-lb:0.0747, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:24:57.762] iteration:23053  t-loss:0.1334, loss-lb:0.0725, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:24:57.953] iteration:23054  t-loss:0.1341, loss-lb:0.0724, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:24:58.146] iteration:23055  t-loss:0.1363, loss-lb:0.0718, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:24:58.338] iteration:23056  t-loss:0.1471, loss-lb:0.0767, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:24:58.529] iteration:23057  t-loss:0.1450, loss-lb:0.0701, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:24:58.722] iteration:23058  t-loss:0.1427, loss-lb:0.0752, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:24:58.915] iteration:23059  t-loss:0.1521, loss-lb:0.0715, loss-ulb:0.0403, weight:2.00, lr:0.0003
[12:24:59.106] iteration:23060  t-loss:0.1520, loss-lb:0.0752, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:24:59.300] iteration:23061  t-loss:0.1621, loss-lb:0.0696, loss-ulb:0.0462, weight:2.00, lr:0.0003
[12:24:59.492] iteration:23062  t-loss:0.1465, loss-lb:0.0815, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:24:59.685] iteration:23063  t-loss:0.1520, loss-lb:0.0789, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:24:59.878] iteration:23064  t-loss:0.1285, loss-lb:0.0658, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:25:00.070] iteration:23065  t-loss:0.1541, loss-lb:0.0707, loss-ulb:0.0417, weight:2.00, lr:0.0003
[12:25:00.262] iteration:23066  t-loss:0.1491, loss-lb:0.0814, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:25:00.455] iteration:23067  t-loss:0.1509, loss-lb:0.0777, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:25:00.648] iteration:23068  t-loss:0.1559, loss-lb:0.0649, loss-ulb:0.0455, weight:2.00, lr:0.0003
[12:25:00.840] iteration:23069  t-loss:0.1481, loss-lb:0.0789, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:25:01.033] iteration:23070  t-loss:0.1562, loss-lb:0.0779, loss-ulb:0.0391, weight:2.00, lr:0.0003
[12:25:01.224] iteration:23071  t-loss:0.1558, loss-lb:0.0748, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:25:01.417] iteration:23072  t-loss:0.1391, loss-lb:0.0782, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:25:01.608] iteration:23073  t-loss:0.1282, loss-lb:0.0743, loss-ulb:0.0270, weight:2.00, lr:0.0003
[12:25:01.800] iteration:23074  t-loss:0.1347, loss-lb:0.0752, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:25:01.992] iteration:23075  t-loss:0.1464, loss-lb:0.0699, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:25:02.185] iteration:23076  t-loss:0.2015, loss-lb:0.0701, loss-ulb:0.0657, weight:2.00, lr:0.0003
[12:25:02.376] iteration:23077  t-loss:0.1444, loss-lb:0.0710, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:25:02.569] iteration:23078  t-loss:0.1378, loss-lb:0.0654, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:25:02.761] iteration:23079  t-loss:0.1604, loss-lb:0.0793, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:25:02.954] iteration:23080  t-loss:0.1437, loss-lb:0.0745, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:25:03.146] iteration:23081  t-loss:0.1522, loss-lb:0.0714, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:25:03.337] iteration:23082  t-loss:0.1508, loss-lb:0.0855, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:25:03.527] iteration:23083  t-loss:0.1512, loss-lb:0.0765, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:25:03.719] iteration:23084  t-loss:0.1453, loss-lb:0.0667, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:25:03.910] iteration:23085  t-loss:0.1425, loss-lb:0.0718, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:25:04.102] iteration:23086  t-loss:0.1493, loss-lb:0.0766, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:25:04.293] iteration:23087  t-loss:0.1468, loss-lb:0.0762, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:25:04.484] iteration:23088  t-loss:0.1339, loss-lb:0.0682, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:25:04.676] iteration:23089  t-loss:0.1380, loss-lb:0.0711, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:25:04.867] iteration:23090  t-loss:0.1472, loss-lb:0.0758, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:25:05.059] iteration:23091  t-loss:0.1432, loss-lb:0.0722, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:25:05.250] iteration:23092  t-loss:0.1450, loss-lb:0.0720, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:25:05.441] iteration:23093  t-loss:0.1340, loss-lb:0.0742, loss-ulb:0.0299, weight:2.00, lr:0.0003
[12:25:05.635] iteration:23094  t-loss:0.1361, loss-lb:0.0715, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:25:05.831] iteration:23095  t-loss:0.2050, loss-lb:0.0811, loss-ulb:0.0620, weight:2.00, lr:0.0003
[12:25:06.029] iteration:23096  t-loss:0.1335, loss-lb:0.0780, loss-ulb:0.0278, weight:2.00, lr:0.0003
[12:25:06.223] iteration:23097  t-loss:0.1357, loss-lb:0.0717, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:25:06.417] iteration:23098  t-loss:0.1517, loss-lb:0.0718, loss-ulb:0.0400, weight:2.00, lr:0.0003
[12:25:06.609] iteration:23099  t-loss:0.1612, loss-lb:0.0772, loss-ulb:0.0420, weight:2.00, lr:0.0003
[12:25:06.802] iteration:23100  t-loss:0.2308, loss-lb:0.0687, loss-ulb:0.0811, weight:2.00, lr:0.0003
[12:25:06.995] iteration:23101  t-loss:0.1644, loss-lb:0.0749, loss-ulb:0.0447, weight:2.00, lr:0.0003
[12:25:07.188] iteration:23102  t-loss:0.1357, loss-lb:0.0722, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:25:07.379] iteration:23103  t-loss:0.1419, loss-lb:0.0669, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:25:07.584] iteration:23104  t-loss:0.1522, loss-lb:0.0734, loss-ulb:0.0394, weight:2.00, lr:0.0003
[12:25:07.781] iteration:23105  t-loss:0.1447, loss-lb:0.0760, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:25:07.977] iteration:23106  t-loss:0.2009, loss-lb:0.0815, loss-ulb:0.0597, weight:2.00, lr:0.0003
[12:25:08.169] iteration:23107  t-loss:0.1440, loss-lb:0.0726, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:25:08.361] iteration:23108  t-loss:0.1345, loss-lb:0.0772, loss-ulb:0.0286, weight:2.00, lr:0.0003
[12:25:08.553] iteration:23109  t-loss:0.1460, loss-lb:0.0673, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:25:08.745] iteration:23110  t-loss:0.1427, loss-lb:0.0771, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:25:08.939] iteration:23111  t-loss:0.1516, loss-lb:0.0711, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:25:09.131] iteration:23112  t-loss:0.4377, loss-lb:0.0738, loss-ulb:0.1819, weight:2.00, lr:0.0003
[12:25:09.323] iteration:23113  t-loss:0.1503, loss-lb:0.0737, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:25:09.515] iteration:23114  t-loss:0.1450, loss-lb:0.0742, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:25:09.706] iteration:23115  t-loss:0.1336, loss-lb:0.0713, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:25:09.898] iteration:23116  t-loss:0.1313, loss-lb:0.0699, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:25:10.091] iteration:23117  t-loss:0.1347, loss-lb:0.0745, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:25:10.283] iteration:23118  t-loss:0.1320, loss-lb:0.0708, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:25:10.475] iteration:23119  t-loss:0.1482, loss-lb:0.0738, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:25:10.668] iteration:23120  t-loss:0.1940, loss-lb:0.0790, loss-ulb:0.0575, weight:2.00, lr:0.0003
[12:25:10.860] iteration:23121  t-loss:0.1369, loss-lb:0.0735, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:25:11.050] iteration:23122  t-loss:0.1498, loss-lb:0.0770, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:25:11.241] iteration:23123  t-loss:0.1456, loss-lb:0.0723, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:25:11.432] iteration:23124  t-loss:0.1736, loss-lb:0.0844, loss-ulb:0.0446, weight:2.00, lr:0.0003
[12:25:11.622] iteration:23125  t-loss:0.1435, loss-lb:0.0704, loss-ulb:0.0366, weight:2.00, lr:0.0003
[12:25:11.813] iteration:23126  t-loss:0.1785, loss-lb:0.0766, loss-ulb:0.0510, weight:2.00, lr:0.0003
[12:25:12.003] iteration:23127  t-loss:0.1345, loss-lb:0.0699, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:25:12.194] iteration:23128  t-loss:0.1423, loss-lb:0.0706, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:25:12.798] iteration:23129  t-loss:0.1657, loss-lb:0.0770, loss-ulb:0.0443, weight:2.00, lr:0.0003
[12:25:12.993] iteration:23130  t-loss:0.1632, loss-lb:0.0773, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:25:13.185] iteration:23131  t-loss:0.1360, loss-lb:0.0741, loss-ulb:0.0310, weight:2.00, lr:0.0003
[12:25:13.377] iteration:23132  t-loss:0.1482, loss-lb:0.0758, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:25:13.569] iteration:23133  t-loss:0.1440, loss-lb:0.0800, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:25:13.761] iteration:23134  t-loss:0.1433, loss-lb:0.0719, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:25:13.953] iteration:23135  t-loss:0.1412, loss-lb:0.0721, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:25:14.145] iteration:23136  t-loss:0.1440, loss-lb:0.0730, loss-ulb:0.0355, weight:2.00, lr:0.0003
[12:25:14.336] iteration:23137  t-loss:0.1353, loss-lb:0.0737, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:25:14.527] iteration:23138  t-loss:0.1314, loss-lb:0.0658, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:25:14.719] iteration:23139  t-loss:0.1374, loss-lb:0.0749, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:25:14.910] iteration:23140  t-loss:0.1447, loss-lb:0.0761, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:25:15.103] iteration:23141  t-loss:0.1404, loss-lb:0.0736, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:25:15.295] iteration:23142  t-loss:0.1505, loss-lb:0.0731, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:25:15.486] iteration:23143  t-loss:0.1391, loss-lb:0.0700, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:25:15.678] iteration:23144  t-loss:0.1479, loss-lb:0.0695, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:25:15.870] iteration:23145  t-loss:0.1588, loss-lb:0.0800, loss-ulb:0.0394, weight:2.00, lr:0.0003
[12:25:16.062] iteration:23146  t-loss:0.1690, loss-lb:0.0767, loss-ulb:0.0461, weight:2.00, lr:0.0003
[12:25:16.255] iteration:23147  t-loss:0.1481, loss-lb:0.0876, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:25:16.448] iteration:23148  t-loss:0.1459, loss-lb:0.0703, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:25:16.640] iteration:23149  t-loss:0.1470, loss-lb:0.0720, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:25:16.833] iteration:23150  t-loss:0.1432, loss-lb:0.0787, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:25:17.026] iteration:23151  t-loss:0.1428, loss-lb:0.0737, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:25:17.219] iteration:23152  t-loss:0.1424, loss-lb:0.0727, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:25:17.410] iteration:23153  t-loss:0.1315, loss-lb:0.0710, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:25:17.604] iteration:23154  t-loss:0.1471, loss-lb:0.0810, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:25:17.796] iteration:23155  t-loss:0.1388, loss-lb:0.0750, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:25:17.989] iteration:23156  t-loss:0.1399, loss-lb:0.0735, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:25:18.183] iteration:23157  t-loss:0.1536, loss-lb:0.0752, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:25:18.375] iteration:23158  t-loss:0.1415, loss-lb:0.0790, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:25:18.567] iteration:23159  t-loss:0.1583, loss-lb:0.0720, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:25:18.760] iteration:23160  t-loss:0.1327, loss-lb:0.0688, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:25:18.953] iteration:23161  t-loss:0.1293, loss-lb:0.0637, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:25:19.145] iteration:23162  t-loss:0.1308, loss-lb:0.0708, loss-ulb:0.0300, weight:2.00, lr:0.0003
[12:25:19.338] iteration:23163  t-loss:0.1444, loss-lb:0.0667, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:25:19.532] iteration:23164  t-loss:0.2472, loss-lb:0.0802, loss-ulb:0.0835, weight:2.00, lr:0.0003
[12:25:19.724] iteration:23165  t-loss:0.1480, loss-lb:0.0786, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:25:19.917] iteration:23166  t-loss:0.1526, loss-lb:0.0665, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:25:20.111] iteration:23167  t-loss:0.1664, loss-lb:0.0727, loss-ulb:0.0468, weight:2.00, lr:0.0003
[12:25:20.304] iteration:23168  t-loss:0.1414, loss-lb:0.0740, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:25:20.496] iteration:23169  t-loss:0.1458, loss-lb:0.0791, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:25:20.689] iteration:23170  t-loss:0.1526, loss-lb:0.0798, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:25:20.881] iteration:23171  t-loss:0.1573, loss-lb:0.0703, loss-ulb:0.0435, weight:2.00, lr:0.0003
[12:25:21.076] iteration:23172  t-loss:0.1442, loss-lb:0.0700, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:25:21.269] iteration:23173  t-loss:0.1288, loss-lb:0.0669, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:25:21.461] iteration:23174  t-loss:0.1622, loss-lb:0.0708, loss-ulb:0.0457, weight:2.00, lr:0.0003
[12:25:21.654] iteration:23175  t-loss:0.1447, loss-lb:0.0742, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:25:21.847] iteration:23176  t-loss:0.1302, loss-lb:0.0665, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:25:22.040] iteration:23177  t-loss:0.1558, loss-lb:0.0833, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:25:22.232] iteration:23178  t-loss:0.1453, loss-lb:0.0737, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:25:22.425] iteration:23179  t-loss:0.2058, loss-lb:0.0693, loss-ulb:0.0682, weight:2.00, lr:0.0003
[12:25:22.617] iteration:23180  t-loss:0.1415, loss-lb:0.0745, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:25:22.810] iteration:23181  t-loss:0.1381, loss-lb:0.0718, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:25:23.002] iteration:23182  t-loss:0.1423, loss-lb:0.0709, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:25:23.194] iteration:23183  t-loss:0.1362, loss-lb:0.0698, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:25:23.388] iteration:23184  t-loss:0.1472, loss-lb:0.0743, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:25:23.581] iteration:23185  t-loss:0.1429, loss-lb:0.0756, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:25:23.773] iteration:23186  t-loss:0.1467, loss-lb:0.0711, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:25:23.965] iteration:23187  t-loss:0.1385, loss-lb:0.0700, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:25:24.158] iteration:23188  t-loss:0.1485, loss-lb:0.0813, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:25:24.351] iteration:23189  t-loss:0.1469, loss-lb:0.0774, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:25:24.545] iteration:23190  t-loss:0.1414, loss-lb:0.0747, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:25:24.737] iteration:23191  t-loss:0.1330, loss-lb:0.0659, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:25:24.930] iteration:23192  t-loss:0.1429, loss-lb:0.0733, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:25:25.123] iteration:23193  t-loss:0.1407, loss-lb:0.0701, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:25:25.315] iteration:23194  t-loss:0.1421, loss-lb:0.0729, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:25:25.508] iteration:23195  t-loss:0.1377, loss-lb:0.0710, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:25:25.701] iteration:23196  t-loss:0.1500, loss-lb:0.0677, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:25:25.895] iteration:23197  t-loss:0.1374, loss-lb:0.0708, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:25:26.088] iteration:23198  t-loss:0.2390, loss-lb:0.0813, loss-ulb:0.0788, weight:2.00, lr:0.0003
[12:25:26.280] iteration:23199  t-loss:0.1630, loss-lb:0.0761, loss-ulb:0.0435, weight:2.00, lr:0.0003
[12:25:26.473] iteration:23200  t-loss:0.1525, loss-lb:0.0722, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:25:26.666] iteration:23201  t-loss:0.1385, loss-lb:0.0682, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:25:26.859] iteration:23202  t-loss:0.1342, loss-lb:0.0757, loss-ulb:0.0293, weight:2.00, lr:0.0003
[12:25:27.051] iteration:23203  t-loss:0.1692, loss-lb:0.0739, loss-ulb:0.0476, weight:2.00, lr:0.0003
[12:25:27.244] iteration:23204  t-loss:0.1375, loss-lb:0.0715, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:25:27.437] iteration:23205  t-loss:0.1840, loss-lb:0.0721, loss-ulb:0.0559, weight:2.00, lr:0.0003
[12:25:27.629] iteration:23206  t-loss:0.1439, loss-lb:0.0776, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:25:27.821] iteration:23207  t-loss:0.1483, loss-lb:0.0793, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:25:28.014] iteration:23208  t-loss:0.1282, loss-lb:0.0686, loss-ulb:0.0298, weight:2.00, lr:0.0003
[12:25:28.206] iteration:23209  t-loss:0.1485, loss-lb:0.0661, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:25:28.399] iteration:23210  t-loss:0.1594, loss-lb:0.0876, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:25:28.591] iteration:23211  t-loss:0.1439, loss-lb:0.0754, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:25:28.786] iteration:23212  t-loss:0.1494, loss-lb:0.0731, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:25:28.980] iteration:23213  t-loss:0.1542, loss-lb:0.0762, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:25:29.172] iteration:23214  t-loss:0.1441, loss-lb:0.0729, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:25:29.364] iteration:23215  t-loss:0.1346, loss-lb:0.0672, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:25:29.558] iteration:23216  t-loss:0.2156, loss-lb:0.0707, loss-ulb:0.0724, weight:2.00, lr:0.0003
[12:25:29.751] iteration:23217  t-loss:0.1515, loss-lb:0.0752, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:25:29.944] iteration:23218  t-loss:0.1444, loss-lb:0.0732, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:25:30.135] iteration:23219  t-loss:0.1513, loss-lb:0.0736, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:25:30.326] iteration:23220  t-loss:0.1313, loss-lb:0.0689, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:25:30.516] iteration:23221  t-loss:0.1278, loss-lb:0.0670, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:25:30.707] iteration:23222  t-loss:0.1863, loss-lb:0.0803, loss-ulb:0.0530, weight:2.00, lr:0.0003
[12:25:30.900] iteration:23223  t-loss:0.1558, loss-lb:0.0801, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:25:31.091] iteration:23224  t-loss:0.2122, loss-lb:0.0707, loss-ulb:0.0707, weight:2.00, lr:0.0003
[12:25:31.282] iteration:23225  t-loss:0.1493, loss-lb:0.0747, loss-ulb:0.0373, weight:2.00, lr:0.0003
[12:25:31.473] iteration:23226  t-loss:0.1320, loss-lb:0.0712, loss-ulb:0.0304, weight:2.00, lr:0.0003
[12:25:43.466]  <<Test>> - Ep:236  - mean_dice/mean_h95 - S:89.87/1.33, Best-S:90.99, T:89.85/1.34, Best-T:90.48
[12:25:43.466]           - AvgLoss(lb/ulb/all):0.0735/0.0399/0.1534
[12:25:43.993] iteration:23227  t-loss:0.1348, loss-lb:0.0665, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:25:44.193] iteration:23228  t-loss:0.1408, loss-lb:0.0794, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:25:44.386] iteration:23229  t-loss:0.1397, loss-lb:0.0722, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:25:44.578] iteration:23230  t-loss:0.1587, loss-lb:0.0725, loss-ulb:0.0431, weight:2.00, lr:0.0003
[12:25:44.771] iteration:23231  t-loss:0.1485, loss-lb:0.0851, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:25:44.964] iteration:23232  t-loss:0.1434, loss-lb:0.0747, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:25:45.157] iteration:23233  t-loss:0.1401, loss-lb:0.0733, loss-ulb:0.0334, weight:2.00, lr:0.0003
[12:25:45.350] iteration:23234  t-loss:0.1550, loss-lb:0.0807, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:25:45.543] iteration:23235  t-loss:0.1366, loss-lb:0.0720, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:25:45.736] iteration:23236  t-loss:0.1260, loss-lb:0.0678, loss-ulb:0.0291, weight:2.00, lr:0.0003
[12:25:45.929] iteration:23237  t-loss:0.1509, loss-lb:0.0741, loss-ulb:0.0384, weight:2.00, lr:0.0003
[12:25:46.122] iteration:23238  t-loss:0.1404, loss-lb:0.0757, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:25:46.314] iteration:23239  t-loss:0.1554, loss-lb:0.0722, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:25:46.507] iteration:23240  t-loss:0.1533, loss-lb:0.0720, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:25:46.700] iteration:23241  t-loss:0.1662, loss-lb:0.0742, loss-ulb:0.0460, weight:2.00, lr:0.0003
[12:25:46.894] iteration:23242  t-loss:0.1392, loss-lb:0.0707, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:25:47.087] iteration:23243  t-loss:0.1561, loss-lb:0.0772, loss-ulb:0.0394, weight:2.00, lr:0.0003
[12:25:47.281] iteration:23244  t-loss:0.1366, loss-lb:0.0765, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:25:47.475] iteration:23245  t-loss:0.1851, loss-lb:0.0840, loss-ulb:0.0505, weight:2.00, lr:0.0003
[12:25:47.668] iteration:23246  t-loss:0.1831, loss-lb:0.0776, loss-ulb:0.0528, weight:2.00, lr:0.0003
[12:25:47.860] iteration:23247  t-loss:0.1394, loss-lb:0.0683, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:25:48.053] iteration:23248  t-loss:0.1570, loss-lb:0.0806, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:25:48.246] iteration:23249  t-loss:0.1410, loss-lb:0.0670, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:25:48.437] iteration:23250  t-loss:0.1587, loss-lb:0.0677, loss-ulb:0.0455, weight:2.00, lr:0.0003
[12:25:48.630] iteration:23251  t-loss:0.1432, loss-lb:0.0714, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:25:48.823] iteration:23252  t-loss:0.1651, loss-lb:0.0848, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:25:49.015] iteration:23253  t-loss:0.1547, loss-lb:0.0748, loss-ulb:0.0399, weight:2.00, lr:0.0003
[12:25:49.207] iteration:23254  t-loss:0.1414, loss-lb:0.0784, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:25:49.400] iteration:23255  t-loss:0.1425, loss-lb:0.0737, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:25:49.594] iteration:23256  t-loss:0.1383, loss-lb:0.0723, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:25:49.787] iteration:23257  t-loss:0.1313, loss-lb:0.0659, loss-ulb:0.0327, weight:2.00, lr:0.0003
[12:25:49.979] iteration:23258  t-loss:0.1511, loss-lb:0.0794, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:25:50.171] iteration:23259  t-loss:0.1365, loss-lb:0.0706, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:25:50.363] iteration:23260  t-loss:0.1468, loss-lb:0.0704, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:25:50.556] iteration:23261  t-loss:0.1440, loss-lb:0.0673, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:25:50.748] iteration:23262  t-loss:0.1591, loss-lb:0.0805, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:25:50.942] iteration:23263  t-loss:0.1335, loss-lb:0.0764, loss-ulb:0.0285, weight:2.00, lr:0.0003
[12:25:51.135] iteration:23264  t-loss:0.1321, loss-lb:0.0717, loss-ulb:0.0302, weight:2.00, lr:0.0003
[12:25:51.327] iteration:23265  t-loss:0.1539, loss-lb:0.0724, loss-ulb:0.0408, weight:2.00, lr:0.0003
[12:25:51.519] iteration:23266  t-loss:0.1462, loss-lb:0.0767, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:25:51.711] iteration:23267  t-loss:0.1592, loss-lb:0.0717, loss-ulb:0.0437, weight:2.00, lr:0.0003
[12:25:51.903] iteration:23268  t-loss:0.1426, loss-lb:0.0738, loss-ulb:0.0344, weight:2.00, lr:0.0003
[12:25:52.095] iteration:23269  t-loss:0.1466, loss-lb:0.0742, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:25:52.288] iteration:23270  t-loss:0.1490, loss-lb:0.0702, loss-ulb:0.0394, weight:2.00, lr:0.0003
[12:25:52.482] iteration:23271  t-loss:0.1509, loss-lb:0.0698, loss-ulb:0.0406, weight:2.00, lr:0.0003
[12:25:52.675] iteration:23272  t-loss:0.1548, loss-lb:0.0694, loss-ulb:0.0427, weight:2.00, lr:0.0003
[12:25:52.867] iteration:23273  t-loss:0.1437, loss-lb:0.0675, loss-ulb:0.0381, weight:2.00, lr:0.0003
[12:25:53.061] iteration:23274  t-loss:0.1340, loss-lb:0.0670, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:25:53.252] iteration:23275  t-loss:0.1648, loss-lb:0.0816, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:25:53.444] iteration:23276  t-loss:0.1375, loss-lb:0.0655, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:25:53.637] iteration:23277  t-loss:0.1500, loss-lb:0.0720, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:25:53.830] iteration:23278  t-loss:0.1625, loss-lb:0.0756, loss-ulb:0.0434, weight:2.00, lr:0.0003
[12:25:54.023] iteration:23279  t-loss:0.1408, loss-lb:0.0714, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:25:54.216] iteration:23280  t-loss:0.1552, loss-lb:0.0744, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:25:54.408] iteration:23281  t-loss:0.1454, loss-lb:0.0764, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:25:54.601] iteration:23282  t-loss:0.1676, loss-lb:0.0781, loss-ulb:0.0448, weight:2.00, lr:0.0003
[12:25:54.793] iteration:23283  t-loss:0.1418, loss-lb:0.0745, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:25:54.985] iteration:23284  t-loss:0.1466, loss-lb:0.0723, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:25:55.178] iteration:23285  t-loss:0.1444, loss-lb:0.0719, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:25:55.370] iteration:23286  t-loss:0.1355, loss-lb:0.0725, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:25:55.564] iteration:23287  t-loss:0.1424, loss-lb:0.0762, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:25:55.755] iteration:23288  t-loss:0.1328, loss-lb:0.0725, loss-ulb:0.0301, weight:2.00, lr:0.0003
[12:25:55.947] iteration:23289  t-loss:0.1416, loss-lb:0.0775, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:25:56.140] iteration:23290  t-loss:0.1309, loss-lb:0.0732, loss-ulb:0.0288, weight:2.00, lr:0.0003
[12:25:56.333] iteration:23291  t-loss:0.1322, loss-lb:0.0680, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:25:56.525] iteration:23292  t-loss:0.1497, loss-lb:0.0793, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:25:56.719] iteration:23293  t-loss:0.1366, loss-lb:0.0752, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:25:56.912] iteration:23294  t-loss:0.1919, loss-lb:0.0752, loss-ulb:0.0583, weight:2.00, lr:0.0003
[12:25:57.104] iteration:23295  t-loss:0.1531, loss-lb:0.0797, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:25:57.296] iteration:23296  t-loss:0.1297, loss-lb:0.0665, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:25:57.489] iteration:23297  t-loss:0.1361, loss-lb:0.0742, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:25:57.682] iteration:23298  t-loss:0.1474, loss-lb:0.0757, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:25:57.873] iteration:23299  t-loss:0.1562, loss-lb:0.0856, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:25:58.065] iteration:23300  t-loss:0.1355, loss-lb:0.0675, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:25:58.259] iteration:23301  t-loss:0.1615, loss-lb:0.0732, loss-ulb:0.0442, weight:2.00, lr:0.0003
[12:25:58.451] iteration:23302  t-loss:0.1453, loss-lb:0.0742, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:25:58.644] iteration:23303  t-loss:0.1477, loss-lb:0.0719, loss-ulb:0.0379, weight:2.00, lr:0.0003
[12:25:58.836] iteration:23304  t-loss:0.1339, loss-lb:0.0693, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:25:59.028] iteration:23305  t-loss:0.1505, loss-lb:0.0745, loss-ulb:0.0380, weight:2.00, lr:0.0003
[12:25:59.220] iteration:23306  t-loss:0.1412, loss-lb:0.0732, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:25:59.413] iteration:23307  t-loss:0.1383, loss-lb:0.0732, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:25:59.605] iteration:23308  t-loss:0.1430, loss-lb:0.0773, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:25:59.798] iteration:23309  t-loss:0.1419, loss-lb:0.0723, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:25:59.991] iteration:23310  t-loss:0.1612, loss-lb:0.0747, loss-ulb:0.0432, weight:2.00, lr:0.0003
[12:26:00.184] iteration:23311  t-loss:0.1432, loss-lb:0.0735, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:26:00.378] iteration:23312  t-loss:0.1631, loss-lb:0.0646, loss-ulb:0.0492, weight:2.00, lr:0.0003
[12:26:00.570] iteration:23313  t-loss:0.1355, loss-lb:0.0691, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:26:00.762] iteration:23314  t-loss:0.1330, loss-lb:0.0687, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:26:00.955] iteration:23315  t-loss:0.1518, loss-lb:0.0747, loss-ulb:0.0386, weight:2.00, lr:0.0003
[12:26:01.147] iteration:23316  t-loss:0.1282, loss-lb:0.0673, loss-ulb:0.0305, weight:2.00, lr:0.0003
[12:26:01.338] iteration:23317  t-loss:0.1389, loss-lb:0.0693, loss-ulb:0.0348, weight:2.00, lr:0.0003
[12:26:01.530] iteration:23318  t-loss:0.1486, loss-lb:0.0848, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:26:01.721] iteration:23319  t-loss:0.2306, loss-lb:0.0727, loss-ulb:0.0790, weight:2.00, lr:0.0003
[12:26:01.912] iteration:23320  t-loss:0.1454, loss-lb:0.0740, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:26:02.103] iteration:23321  t-loss:0.1676, loss-lb:0.0680, loss-ulb:0.0498, weight:2.00, lr:0.0003
[12:26:02.295] iteration:23322  t-loss:0.1489, loss-lb:0.0799, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:26:02.485] iteration:23323  t-loss:0.1298, loss-lb:0.0674, loss-ulb:0.0312, weight:2.00, lr:0.0003
[12:26:02.676] iteration:23324  t-loss:0.1661, loss-lb:0.0700, loss-ulb:0.0480, weight:2.00, lr:0.0003
[12:26:03.256] iteration:23325  t-loss:0.1454, loss-lb:0.0779, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:26:03.451] iteration:23326  t-loss:0.1339, loss-lb:0.0706, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:26:03.644] iteration:23327  t-loss:0.1381, loss-lb:0.0715, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:26:03.837] iteration:23328  t-loss:0.1402, loss-lb:0.0735, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:26:04.030] iteration:23329  t-loss:0.1476, loss-lb:0.0846, loss-ulb:0.0315, weight:2.00, lr:0.0003
[12:26:04.221] iteration:23330  t-loss:0.1430, loss-lb:0.0710, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:04.414] iteration:23331  t-loss:0.1382, loss-lb:0.0735, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:26:04.607] iteration:23332  t-loss:0.1392, loss-lb:0.0656, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:26:04.799] iteration:23333  t-loss:0.1363, loss-lb:0.0744, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:26:04.991] iteration:23334  t-loss:0.1472, loss-lb:0.0677, loss-ulb:0.0398, weight:2.00, lr:0.0003
[12:26:05.185] iteration:23335  t-loss:0.1370, loss-lb:0.0700, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:26:05.378] iteration:23336  t-loss:0.1391, loss-lb:0.0701, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:26:05.571] iteration:23337  t-loss:0.2754, loss-lb:0.0723, loss-ulb:0.1016, weight:2.00, lr:0.0003
[12:26:05.764] iteration:23338  t-loss:0.1393, loss-lb:0.0692, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:26:05.958] iteration:23339  t-loss:0.1937, loss-lb:0.0725, loss-ulb:0.0606, weight:2.00, lr:0.0003
[12:26:06.151] iteration:23340  t-loss:0.1935, loss-lb:0.0676, loss-ulb:0.0629, weight:2.00, lr:0.0003
[12:26:06.343] iteration:23341  t-loss:0.1360, loss-lb:0.0720, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:26:06.534] iteration:23342  t-loss:0.1565, loss-lb:0.0814, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:26:06.726] iteration:23343  t-loss:0.1861, loss-lb:0.0790, loss-ulb:0.0535, weight:2.00, lr:0.0003
[12:26:06.920] iteration:23344  t-loss:0.1407, loss-lb:0.0772, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:26:07.117] iteration:23345  t-loss:0.1673, loss-lb:0.0773, loss-ulb:0.0450, weight:2.00, lr:0.0003
[12:26:07.311] iteration:23346  t-loss:0.1464, loss-lb:0.0857, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:26:07.504] iteration:23347  t-loss:0.1658, loss-lb:0.0731, loss-ulb:0.0464, weight:2.00, lr:0.0003
[12:26:07.697] iteration:23348  t-loss:0.1456, loss-lb:0.0731, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:26:07.888] iteration:23349  t-loss:0.1255, loss-lb:0.0660, loss-ulb:0.0297, weight:2.00, lr:0.0003
[12:26:08.080] iteration:23350  t-loss:0.1478, loss-lb:0.0779, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:26:08.272] iteration:23351  t-loss:0.1341, loss-lb:0.0699, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:26:08.465] iteration:23352  t-loss:0.1430, loss-lb:0.0746, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:26:08.658] iteration:23353  t-loss:0.1413, loss-lb:0.0736, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:26:08.850] iteration:23354  t-loss:0.1521, loss-lb:0.0675, loss-ulb:0.0423, weight:2.00, lr:0.0003
[12:26:09.041] iteration:23355  t-loss:0.1316, loss-lb:0.0682, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:26:09.233] iteration:23356  t-loss:0.1452, loss-lb:0.0774, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:26:09.427] iteration:23357  t-loss:0.1443, loss-lb:0.0720, loss-ulb:0.0362, weight:2.00, lr:0.0003
[12:26:09.619] iteration:23358  t-loss:0.1369, loss-lb:0.0732, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:26:09.811] iteration:23359  t-loss:0.1526, loss-lb:0.0692, loss-ulb:0.0417, weight:2.00, lr:0.0003
[12:26:10.003] iteration:23360  t-loss:0.1356, loss-lb:0.0733, loss-ulb:0.0311, weight:2.00, lr:0.0003
[12:26:10.194] iteration:23361  t-loss:0.1322, loss-lb:0.0707, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:26:10.387] iteration:23362  t-loss:0.1567, loss-lb:0.0752, loss-ulb:0.0407, weight:2.00, lr:0.0003
[12:26:10.578] iteration:23363  t-loss:0.1411, loss-lb:0.0700, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:26:10.770] iteration:23364  t-loss:0.1424, loss-lb:0.0746, loss-ulb:0.0339, weight:2.00, lr:0.0003
[12:26:10.962] iteration:23365  t-loss:0.1427, loss-lb:0.0730, loss-ulb:0.0349, weight:2.00, lr:0.0003
[12:26:11.155] iteration:23366  t-loss:0.1771, loss-lb:0.0921, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:26:11.347] iteration:23367  t-loss:0.1361, loss-lb:0.0711, loss-ulb:0.0325, weight:2.00, lr:0.0003
[12:26:11.539] iteration:23368  t-loss:0.1982, loss-lb:0.0836, loss-ulb:0.0573, weight:2.00, lr:0.0003
[12:26:11.731] iteration:23369  t-loss:0.1522, loss-lb:0.0673, loss-ulb:0.0424, weight:2.00, lr:0.0003
[12:26:11.923] iteration:23370  t-loss:0.1432, loss-lb:0.0697, loss-ulb:0.0367, weight:2.00, lr:0.0003
[12:26:12.115] iteration:23371  t-loss:0.1380, loss-lb:0.0650, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:26:12.309] iteration:23372  t-loss:0.1487, loss-lb:0.0696, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:26:12.500] iteration:23373  t-loss:0.1952, loss-lb:0.1013, loss-ulb:0.0469, weight:2.00, lr:0.0003
[12:26:12.693] iteration:23374  t-loss:0.1368, loss-lb:0.0736, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:26:12.884] iteration:23375  t-loss:0.1324, loss-lb:0.0678, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:26:13.087] iteration:23376  t-loss:0.1385, loss-lb:0.0758, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:26:13.284] iteration:23377  t-loss:0.1573, loss-lb:0.0852, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:13.479] iteration:23378  t-loss:0.1337, loss-lb:0.0703, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:26:13.671] iteration:23379  t-loss:0.1376, loss-lb:0.0714, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:26:13.864] iteration:23380  t-loss:0.1460, loss-lb:0.0766, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:26:14.056] iteration:23381  t-loss:0.1571, loss-lb:0.0801, loss-ulb:0.0385, weight:2.00, lr:0.0003
[12:26:14.248] iteration:23382  t-loss:0.1588, loss-lb:0.0664, loss-ulb:0.0462, weight:2.00, lr:0.0003
[12:26:14.441] iteration:23383  t-loss:0.1395, loss-lb:0.0756, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:26:14.634] iteration:23384  t-loss:0.1397, loss-lb:0.0800, loss-ulb:0.0299, weight:2.00, lr:0.0003
[12:26:14.825] iteration:23385  t-loss:0.1493, loss-lb:0.0702, loss-ulb:0.0396, weight:2.00, lr:0.0003
[12:26:15.017] iteration:23386  t-loss:0.1374, loss-lb:0.0712, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:26:15.210] iteration:23387  t-loss:0.1674, loss-lb:0.0763, loss-ulb:0.0455, weight:2.00, lr:0.0003
[12:26:15.401] iteration:23388  t-loss:0.1523, loss-lb:0.0738, loss-ulb:0.0393, weight:2.00, lr:0.0003
[12:26:15.593] iteration:23389  t-loss:0.1442, loss-lb:0.0702, loss-ulb:0.0370, weight:2.00, lr:0.0003
[12:26:15.785] iteration:23390  t-loss:0.2512, loss-lb:0.0706, loss-ulb:0.0903, weight:2.00, lr:0.0003
[12:26:15.977] iteration:23391  t-loss:0.1586, loss-lb:0.0748, loss-ulb:0.0419, weight:2.00, lr:0.0003
[12:26:16.169] iteration:23392  t-loss:0.1522, loss-lb:0.0746, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:26:16.360] iteration:23393  t-loss:0.1675, loss-lb:0.0851, loss-ulb:0.0412, weight:2.00, lr:0.0003
[12:26:16.551] iteration:23394  t-loss:0.1429, loss-lb:0.0792, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:26:16.743] iteration:23395  t-loss:0.1453, loss-lb:0.0739, loss-ulb:0.0357, weight:2.00, lr:0.0003
[12:26:16.934] iteration:23396  t-loss:0.1653, loss-lb:0.0804, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:26:17.126] iteration:23397  t-loss:0.1454, loss-lb:0.0702, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:26:17.317] iteration:23398  t-loss:0.1364, loss-lb:0.0752, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:26:17.509] iteration:23399  t-loss:0.1750, loss-lb:0.0780, loss-ulb:0.0485, weight:2.00, lr:0.0003
[12:26:17.703] iteration:23400  t-loss:0.2232, loss-lb:0.0760, loss-ulb:0.0736, weight:2.00, lr:0.0003
[12:26:17.897] iteration:23401  t-loss:0.1446, loss-lb:0.0704, loss-ulb:0.0371, weight:2.00, lr:0.0003
[12:26:18.093] iteration:23402  t-loss:0.1425, loss-lb:0.0706, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:18.289] iteration:23403  t-loss:0.1376, loss-lb:0.0683, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:26:18.484] iteration:23404  t-loss:0.1365, loss-lb:0.0752, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:26:18.677] iteration:23405  t-loss:0.1276, loss-lb:0.0685, loss-ulb:0.0295, weight:2.00, lr:0.0003
[12:26:18.869] iteration:23406  t-loss:0.1476, loss-lb:0.0756, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:19.061] iteration:23407  t-loss:0.1577, loss-lb:0.0787, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:26:19.253] iteration:23408  t-loss:0.1745, loss-lb:0.0722, loss-ulb:0.0511, weight:2.00, lr:0.0003
[12:26:19.445] iteration:23409  t-loss:0.1436, loss-lb:0.0742, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:26:19.637] iteration:23410  t-loss:0.1592, loss-lb:0.0791, loss-ulb:0.0400, weight:2.00, lr:0.0003
[12:26:19.830] iteration:23411  t-loss:0.1431, loss-lb:0.0815, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:26:20.022] iteration:23412  t-loss:0.1318, loss-lb:0.0704, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:26:20.214] iteration:23413  t-loss:0.1500, loss-lb:0.0725, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:26:20.406] iteration:23414  t-loss:0.1340, loss-lb:0.0693, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:26:20.598] iteration:23415  t-loss:0.1660, loss-lb:0.0768, loss-ulb:0.0446, weight:2.00, lr:0.0003
[12:26:20.788] iteration:23416  t-loss:0.1623, loss-lb:0.0818, loss-ulb:0.0402, weight:2.00, lr:0.0003
[12:26:20.980] iteration:23417  t-loss:0.1552, loss-lb:0.0786, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:26:21.171] iteration:23418  t-loss:0.1287, loss-lb:0.0734, loss-ulb:0.0277, weight:2.00, lr:0.0003
[12:26:21.363] iteration:23419  t-loss:0.1323, loss-lb:0.0684, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:26:21.554] iteration:23420  t-loss:0.1511, loss-lb:0.0806, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:26:21.745] iteration:23421  t-loss:0.1524, loss-lb:0.0749, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:26:21.936] iteration:23422  t-loss:0.1397, loss-lb:0.0694, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:26:34.776]  <<Test>> - Ep:238  - mean_dice/mean_h95 - S:90.11/1.31, Best-S:90.99, T:89.74/1.35, Best-T:90.48
[12:26:34.776]           - AvgLoss(lb/ulb/all):0.0742/0.0360/0.1465
[12:26:35.315] iteration:23423  t-loss:0.1481, loss-lb:0.0841, loss-ulb:0.0320, weight:2.00, lr:0.0003
[12:26:35.513] iteration:23424  t-loss:0.1408, loss-lb:0.0732, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:26:35.705] iteration:23425  t-loss:0.1449, loss-lb:0.0760, loss-ulb:0.0345, weight:2.00, lr:0.0003
[12:26:35.899] iteration:23426  t-loss:0.1497, loss-lb:0.0731, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:26:36.092] iteration:23427  t-loss:0.1543, loss-lb:0.0795, loss-ulb:0.0374, weight:2.00, lr:0.0003
[12:26:36.283] iteration:23428  t-loss:0.1490, loss-lb:0.0738, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:26:36.475] iteration:23429  t-loss:0.1530, loss-lb:0.0778, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:26:36.668] iteration:23430  t-loss:0.1433, loss-lb:0.0711, loss-ulb:0.0361, weight:2.00, lr:0.0003
[12:26:36.860] iteration:23431  t-loss:0.1330, loss-lb:0.0678, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:26:37.052] iteration:23432  t-loss:0.1403, loss-lb:0.0700, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:26:37.246] iteration:23433  t-loss:0.2311, loss-lb:0.0709, loss-ulb:0.0801, weight:2.00, lr:0.0003
[12:26:37.438] iteration:23434  t-loss:0.1422, loss-lb:0.0751, loss-ulb:0.0335, weight:2.00, lr:0.0003
[12:26:37.630] iteration:23435  t-loss:0.1312, loss-lb:0.0667, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:26:37.822] iteration:23436  t-loss:0.1467, loss-lb:0.0775, loss-ulb:0.0346, weight:2.00, lr:0.0003
[12:26:38.014] iteration:23437  t-loss:0.1479, loss-lb:0.0742, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:26:38.206] iteration:23438  t-loss:0.1321, loss-lb:0.0656, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:26:38.397] iteration:23439  t-loss:0.1488, loss-lb:0.0772, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:26:38.590] iteration:23440  t-loss:0.1476, loss-lb:0.0732, loss-ulb:0.0372, weight:2.00, lr:0.0003
[12:26:38.781] iteration:23441  t-loss:0.1449, loss-lb:0.0755, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:26:38.973] iteration:23442  t-loss:0.1578, loss-lb:0.0787, loss-ulb:0.0395, weight:2.00, lr:0.0003
[12:26:39.165] iteration:23443  t-loss:0.1529, loss-lb:0.0801, loss-ulb:0.0364, weight:2.00, lr:0.0003
[12:26:39.357] iteration:23444  t-loss:0.1537, loss-lb:0.0760, loss-ulb:0.0388, weight:2.00, lr:0.0003
[12:26:39.550] iteration:23445  t-loss:0.1406, loss-lb:0.0772, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:26:39.745] iteration:23446  t-loss:0.1514, loss-lb:0.0707, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:26:39.942] iteration:23447  t-loss:0.1406, loss-lb:0.0800, loss-ulb:0.0303, weight:2.00, lr:0.0003
[12:26:40.139] iteration:23448  t-loss:0.1397, loss-lb:0.0696, loss-ulb:0.0351, weight:2.00, lr:0.0003
[12:26:40.333] iteration:23449  t-loss:0.1338, loss-lb:0.0699, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:26:40.526] iteration:23450  t-loss:0.1515, loss-lb:0.0779, loss-ulb:0.0368, weight:2.00, lr:0.0003
[12:26:40.719] iteration:23451  t-loss:0.1338, loss-lb:0.0702, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:26:40.910] iteration:23452  t-loss:0.1422, loss-lb:0.0757, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:26:41.103] iteration:23453  t-loss:0.1861, loss-lb:0.0747, loss-ulb:0.0557, weight:2.00, lr:0.0003
[12:26:41.295] iteration:23454  t-loss:0.1395, loss-lb:0.0752, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:26:41.487] iteration:23455  t-loss:0.1297, loss-lb:0.0665, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:26:41.680] iteration:23456  t-loss:0.1322, loss-lb:0.0694, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:26:41.872] iteration:23457  t-loss:0.1332, loss-lb:0.0688, loss-ulb:0.0322, weight:2.00, lr:0.0003
[12:26:42.065] iteration:23458  t-loss:0.1257, loss-lb:0.0666, loss-ulb:0.0295, weight:2.00, lr:0.0003
[12:26:42.257] iteration:23459  t-loss:0.1324, loss-lb:0.0731, loss-ulb:0.0296, weight:2.00, lr:0.0003
[12:26:42.449] iteration:23460  t-loss:0.1402, loss-lb:0.0682, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:42.642] iteration:23461  t-loss:0.1440, loss-lb:0.0755, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:26:42.835] iteration:23462  t-loss:0.1967, loss-lb:0.0756, loss-ulb:0.0605, weight:2.00, lr:0.0003
[12:26:43.027] iteration:23463  t-loss:0.1718, loss-lb:0.0713, loss-ulb:0.0503, weight:2.00, lr:0.0003
[12:26:43.220] iteration:23464  t-loss:0.2580, loss-lb:0.0781, loss-ulb:0.0900, weight:2.00, lr:0.0003
[12:26:43.411] iteration:23465  t-loss:0.1488, loss-lb:0.0773, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:26:43.604] iteration:23466  t-loss:0.1371, loss-lb:0.0753, loss-ulb:0.0309, weight:2.00, lr:0.0003
[12:26:43.796] iteration:23467  t-loss:0.1330, loss-lb:0.0718, loss-ulb:0.0306, weight:2.00, lr:0.0003
[12:26:43.987] iteration:23468  t-loss:0.1403, loss-lb:0.0686, loss-ulb:0.0359, weight:2.00, lr:0.0003
[12:26:44.180] iteration:23469  t-loss:0.1345, loss-lb:0.0687, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:26:44.373] iteration:23470  t-loss:0.1572, loss-lb:0.0690, loss-ulb:0.0441, weight:2.00, lr:0.0003
[12:26:44.566] iteration:23471  t-loss:0.1514, loss-lb:0.0747, loss-ulb:0.0383, weight:2.00, lr:0.0003
[12:26:44.757] iteration:23472  t-loss:0.1557, loss-lb:0.0882, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:26:44.950] iteration:23473  t-loss:0.1388, loss-lb:0.0724, loss-ulb:0.0332, weight:2.00, lr:0.0003
[12:26:45.141] iteration:23474  t-loss:0.1358, loss-lb:0.0696, loss-ulb:0.0331, weight:2.00, lr:0.0003
[12:26:45.333] iteration:23475  t-loss:0.1390, loss-lb:0.0674, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:26:45.526] iteration:23476  t-loss:0.1579, loss-lb:0.0763, loss-ulb:0.0408, weight:2.00, lr:0.0003
[12:26:45.717] iteration:23477  t-loss:0.1416, loss-lb:0.0733, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:26:45.923] iteration:23478  t-loss:0.1512, loss-lb:0.0737, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:26:46.120] iteration:23479  t-loss:0.1449, loss-lb:0.0729, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:46.315] iteration:23480  t-loss:0.2251, loss-lb:0.0760, loss-ulb:0.0746, weight:2.00, lr:0.0003
[12:26:46.506] iteration:23481  t-loss:0.1583, loss-lb:0.0683, loss-ulb:0.0450, weight:2.00, lr:0.0003
[12:26:46.699] iteration:23482  t-loss:0.1541, loss-lb:0.0728, loss-ulb:0.0407, weight:2.00, lr:0.0003
[12:26:46.890] iteration:23483  t-loss:0.1302, loss-lb:0.0717, loss-ulb:0.0293, weight:2.00, lr:0.0003
[12:26:47.083] iteration:23484  t-loss:0.1337, loss-lb:0.0706, loss-ulb:0.0316, weight:2.00, lr:0.0003
[12:26:47.275] iteration:23485  t-loss:0.1421, loss-lb:0.0664, loss-ulb:0.0378, weight:2.00, lr:0.0003
[12:26:47.467] iteration:23486  t-loss:0.1352, loss-lb:0.0672, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:26:47.658] iteration:23487  t-loss:0.1716, loss-lb:0.0867, loss-ulb:0.0425, weight:2.00, lr:0.0003
[12:26:47.850] iteration:23488  t-loss:0.1495, loss-lb:0.0848, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:26:48.043] iteration:23489  t-loss:0.1441, loss-lb:0.0825, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:26:48.234] iteration:23490  t-loss:0.1559, loss-lb:0.0698, loss-ulb:0.0430, weight:2.00, lr:0.0003
[12:26:48.426] iteration:23491  t-loss:0.1396, loss-lb:0.0665, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:26:48.617] iteration:23492  t-loss:0.1423, loss-lb:0.0741, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:26:48.808] iteration:23493  t-loss:0.1305, loss-lb:0.0680, loss-ulb:0.0313, weight:2.00, lr:0.0003
[12:26:49.000] iteration:23494  t-loss:0.1343, loss-lb:0.0728, loss-ulb:0.0308, weight:2.00, lr:0.0003
[12:26:49.192] iteration:23495  t-loss:0.1280, loss-lb:0.0714, loss-ulb:0.0283, weight:2.00, lr:0.0003
[12:26:49.383] iteration:23496  t-loss:0.1519, loss-lb:0.0740, loss-ulb:0.0389, weight:2.00, lr:0.0003
[12:26:49.575] iteration:23497  t-loss:0.1581, loss-lb:0.0778, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:26:49.766] iteration:23498  t-loss:0.1428, loss-lb:0.0782, loss-ulb:0.0323, weight:2.00, lr:0.0003
[12:26:49.958] iteration:23499  t-loss:0.1437, loss-lb:0.0770, loss-ulb:0.0333, weight:2.00, lr:0.0003
[12:26:50.149] iteration:23500  t-loss:0.1367, loss-lb:0.0691, loss-ulb:0.0338, weight:2.00, lr:0.0003
[12:26:50.342] iteration:23501  t-loss:0.1825, loss-lb:0.0750, loss-ulb:0.0538, weight:2.00, lr:0.0003
[12:26:50.534] iteration:23502  t-loss:0.1543, loss-lb:0.0861, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:26:50.727] iteration:23503  t-loss:0.1229, loss-lb:0.0651, loss-ulb:0.0289, weight:2.00, lr:0.0003
[12:26:50.920] iteration:23504  t-loss:0.1469, loss-lb:0.0776, loss-ulb:0.0347, weight:2.00, lr:0.0003
[12:26:51.113] iteration:23505  t-loss:0.1988, loss-lb:0.0732, loss-ulb:0.0628, weight:2.00, lr:0.0003
[12:26:51.305] iteration:23506  t-loss:0.1533, loss-lb:0.0700, loss-ulb:0.0416, weight:2.00, lr:0.0003
[12:26:51.498] iteration:23507  t-loss:0.1317, loss-lb:0.0682, loss-ulb:0.0317, weight:2.00, lr:0.0003
[12:26:51.690] iteration:23508  t-loss:0.1405, loss-lb:0.0685, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:51.882] iteration:23509  t-loss:0.1519, loss-lb:0.0738, loss-ulb:0.0390, weight:2.00, lr:0.0003
[12:26:52.075] iteration:23510  t-loss:0.1390, loss-lb:0.0659, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:26:52.268] iteration:23511  t-loss:0.1520, loss-lb:0.0868, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:26:52.460] iteration:23512  t-loss:0.1549, loss-lb:0.0738, loss-ulb:0.0405, weight:2.00, lr:0.0003
[12:26:52.652] iteration:23513  t-loss:0.1540, loss-lb:0.0819, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:52.844] iteration:23514  t-loss:0.1677, loss-lb:0.0754, loss-ulb:0.0461, weight:2.00, lr:0.0003
[12:26:53.035] iteration:23515  t-loss:0.1393, loss-lb:0.0755, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:26:53.226] iteration:23516  t-loss:0.1528, loss-lb:0.0754, loss-ulb:0.0387, weight:2.00, lr:0.0003
[12:26:53.416] iteration:23517  t-loss:0.1373, loss-lb:0.0721, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:26:53.607] iteration:23518  t-loss:0.1760, loss-lb:0.0788, loss-ulb:0.0486, weight:2.00, lr:0.0003
[12:26:53.799] iteration:23519  t-loss:0.1356, loss-lb:0.0698, loss-ulb:0.0329, weight:2.00, lr:0.0003
[12:26:53.990] iteration:23520  t-loss:0.1567, loss-lb:0.0668, loss-ulb:0.0449, weight:2.00, lr:0.0003
[12:26:54.581] iteration:23521  t-loss:0.1563, loss-lb:0.0728, loss-ulb:0.0418, weight:2.00, lr:0.0003
[12:26:54.777] iteration:23522  t-loss:0.1588, loss-lb:0.0769, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:26:54.971] iteration:23523  t-loss:0.1295, loss-lb:0.0743, loss-ulb:0.0276, weight:2.00, lr:0.0003
[12:26:55.164] iteration:23524  t-loss:0.1870, loss-lb:0.0764, loss-ulb:0.0553, weight:2.00, lr:0.0003
[12:26:55.357] iteration:23525  t-loss:0.1451, loss-lb:0.0809, loss-ulb:0.0321, weight:2.00, lr:0.0003
[12:26:55.550] iteration:23526  t-loss:0.1423, loss-lb:0.0788, loss-ulb:0.0318, weight:2.00, lr:0.0003
[12:26:55.743] iteration:23527  t-loss:0.1496, loss-lb:0.0732, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:26:55.936] iteration:23528  t-loss:0.1449, loss-lb:0.0686, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:26:56.128] iteration:23529  t-loss:0.1457, loss-lb:0.0737, loss-ulb:0.0360, weight:2.00, lr:0.0003
[12:26:56.319] iteration:23530  t-loss:0.1332, loss-lb:0.0648, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:26:56.512] iteration:23531  t-loss:0.1400, loss-lb:0.0772, loss-ulb:0.0314, weight:2.00, lr:0.0003
[12:26:56.705] iteration:23532  t-loss:0.1437, loss-lb:0.0725, loss-ulb:0.0356, weight:2.00, lr:0.0003
[12:26:56.898] iteration:23533  t-loss:0.1368, loss-lb:0.0652, loss-ulb:0.0358, weight:2.00, lr:0.0003
[12:26:57.090] iteration:23534  t-loss:0.1466, loss-lb:0.0809, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:26:57.282] iteration:23535  t-loss:0.1380, loss-lb:0.0801, loss-ulb:0.0290, weight:2.00, lr:0.0003
[12:26:57.475] iteration:23536  t-loss:0.1322, loss-lb:0.0766, loss-ulb:0.0278, weight:2.00, lr:0.0003
[12:26:57.667] iteration:23537  t-loss:0.1576, loss-lb:0.0757, loss-ulb:0.0410, weight:2.00, lr:0.0003
[12:26:57.860] iteration:23538  t-loss:0.1470, loss-lb:0.0789, loss-ulb:0.0340, weight:2.00, lr:0.0003
[12:26:58.052] iteration:23539  t-loss:0.1392, loss-lb:0.0777, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:26:58.244] iteration:23540  t-loss:0.1487, loss-lb:0.0734, loss-ulb:0.0376, weight:2.00, lr:0.0003
[12:26:58.435] iteration:23541  t-loss:0.1399, loss-lb:0.0725, loss-ulb:0.0337, weight:2.00, lr:0.0003
[12:26:58.630] iteration:23542  t-loss:0.1393, loss-lb:0.0710, loss-ulb:0.0342, weight:2.00, lr:0.0003
[12:26:58.822] iteration:23543  t-loss:0.1500, loss-lb:0.0827, loss-ulb:0.0336, weight:2.00, lr:0.0003
[12:26:59.014] iteration:23544  t-loss:0.1746, loss-lb:0.0712, loss-ulb:0.0517, weight:2.00, lr:0.0003
[12:26:59.206] iteration:23545  t-loss:0.1421, loss-lb:0.0691, loss-ulb:0.0365, weight:2.00, lr:0.0003
[12:26:59.399] iteration:23546  t-loss:0.1395, loss-lb:0.0713, loss-ulb:0.0341, weight:2.00, lr:0.0003
[12:26:59.591] iteration:23547  t-loss:0.1700, loss-lb:0.0736, loss-ulb:0.0482, weight:2.00, lr:0.0003
[12:26:59.784] iteration:23548  t-loss:0.1624, loss-lb:0.0920, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:26:59.978] iteration:23549  t-loss:0.1410, loss-lb:0.0710, loss-ulb:0.0350, weight:2.00, lr:0.0003
[12:27:00.171] iteration:23550  t-loss:0.1911, loss-lb:0.0757, loss-ulb:0.0577, weight:2.00, lr:0.0003
[12:27:00.363] iteration:23551  t-loss:0.1488, loss-lb:0.0680, loss-ulb:0.0404, weight:2.00, lr:0.0003
[12:27:00.556] iteration:23552  t-loss:0.1456, loss-lb:0.0805, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:27:00.751] iteration:23553  t-loss:0.1427, loss-lb:0.0677, loss-ulb:0.0375, weight:2.00, lr:0.0003
[12:27:00.944] iteration:23554  t-loss:0.1434, loss-lb:0.0707, loss-ulb:0.0363, weight:2.00, lr:0.0003
[12:27:01.137] iteration:23555  t-loss:0.1441, loss-lb:0.0827, loss-ulb:0.0307, weight:2.00, lr:0.0003
[12:27:01.329] iteration:23556  t-loss:0.1447, loss-lb:0.0788, loss-ulb:0.0330, weight:2.00, lr:0.0003
[12:27:01.522] iteration:23557  t-loss:0.1521, loss-lb:0.0733, loss-ulb:0.0394, weight:2.00, lr:0.0003
[12:27:01.714] iteration:23558  t-loss:0.1610, loss-lb:0.0796, loss-ulb:0.0407, weight:2.00, lr:0.0003
[12:27:01.906] iteration:23559  t-loss:0.1497, loss-lb:0.0695, loss-ulb:0.0401, weight:2.00, lr:0.0003
[12:27:02.099] iteration:23560  t-loss:0.1371, loss-lb:0.0732, loss-ulb:0.0319, weight:2.00, lr:0.0003
[12:27:02.292] iteration:23561  t-loss:0.1521, loss-lb:0.0812, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:27:02.485] iteration:23562  t-loss:0.1437, loss-lb:0.0730, loss-ulb:0.0353, weight:2.00, lr:0.0003
[12:27:02.678] iteration:23563  t-loss:0.1514, loss-lb:0.0810, loss-ulb:0.0352, weight:2.00, lr:0.0003
[12:27:02.870] iteration:23564  t-loss:0.1453, loss-lb:0.0689, loss-ulb:0.0382, weight:2.00, lr:0.0003
[12:27:03.063] iteration:23565  t-loss:0.1470, loss-lb:0.0673, loss-ulb:0.0398, weight:2.00, lr:0.0003
[12:27:03.256] iteration:23566  t-loss:0.1505, loss-lb:0.0721, loss-ulb:0.0392, weight:2.00, lr:0.0003
[12:27:03.448] iteration:23567  t-loss:0.1423, loss-lb:0.0737, loss-ulb:0.0343, weight:2.00, lr:0.0003
[12:27:03.640] iteration:23568  t-loss:0.1342, loss-lb:0.0690, loss-ulb:0.0326, weight:2.00, lr:0.0003
[12:27:03.833] iteration:23569  t-loss:0.1568, loss-lb:0.0662, loss-ulb:0.0453, weight:2.00, lr:0.0003
[12:27:04.025] iteration:23570  t-loss:0.1374, loss-lb:0.0719, loss-ulb:0.0328, weight:2.00, lr:0.0003
[12:27:04.217] iteration:23571  t-loss:0.1401, loss-lb:0.0693, loss-ulb:0.0354, weight:2.00, lr:0.0003
[12:27:04.410] iteration:23572  t-loss:0.1538, loss-lb:0.0836, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:27:04.603] iteration:23573  t-loss:0.1423, loss-lb:0.0715, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:27:04.794] iteration:23574  t-loss:0.1406, loss-lb:0.0720, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:27:04.987] iteration:23575  t-loss:0.1364, loss-lb:0.0694, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:27:05.180] iteration:23576  t-loss:0.1976, loss-lb:0.0745, loss-ulb:0.0616, weight:2.00, lr:0.0002
[12:27:05.374] iteration:23577  t-loss:0.1672, loss-lb:0.0822, loss-ulb:0.0425, weight:2.00, lr:0.0002
[12:27:05.567] iteration:23578  t-loss:0.1359, loss-lb:0.0774, loss-ulb:0.0293, weight:2.00, lr:0.0002
[12:27:05.759] iteration:23579  t-loss:0.1298, loss-lb:0.0731, loss-ulb:0.0284, weight:2.00, lr:0.0002
[12:27:05.951] iteration:23580  t-loss:0.1502, loss-lb:0.0722, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:27:06.144] iteration:23581  t-loss:0.1395, loss-lb:0.0679, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:27:06.337] iteration:23582  t-loss:0.1337, loss-lb:0.0656, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:27:06.529] iteration:23583  t-loss:0.1678, loss-lb:0.0737, loss-ulb:0.0470, weight:2.00, lr:0.0002
[12:27:06.723] iteration:23584  t-loss:0.1267, loss-lb:0.0716, loss-ulb:0.0275, weight:2.00, lr:0.0002
[12:27:06.915] iteration:23585  t-loss:0.1367, loss-lb:0.0731, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:27:07.107] iteration:23586  t-loss:0.1391, loss-lb:0.0756, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:27:07.300] iteration:23587  t-loss:0.1500, loss-lb:0.0745, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:27:07.493] iteration:23588  t-loss:0.1454, loss-lb:0.0747, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:27:07.685] iteration:23589  t-loss:0.1529, loss-lb:0.0775, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:27:07.877] iteration:23590  t-loss:0.1538, loss-lb:0.0811, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:27:08.069] iteration:23591  t-loss:0.1462, loss-lb:0.0748, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:27:08.261] iteration:23592  t-loss:0.1778, loss-lb:0.0696, loss-ulb:0.0541, weight:2.00, lr:0.0002
[12:27:08.454] iteration:23593  t-loss:0.1400, loss-lb:0.0752, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:27:08.646] iteration:23594  t-loss:0.1281, loss-lb:0.0708, loss-ulb:0.0287, weight:2.00, lr:0.0002
[12:27:08.840] iteration:23595  t-loss:0.1316, loss-lb:0.0683, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:27:09.032] iteration:23596  t-loss:0.1473, loss-lb:0.0736, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:27:09.224] iteration:23597  t-loss:0.1525, loss-lb:0.0751, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:27:09.417] iteration:23598  t-loss:0.1527, loss-lb:0.0745, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:27:09.609] iteration:23599  t-loss:0.1454, loss-lb:0.0720, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:27:09.802] iteration:23600  t-loss:0.1464, loss-lb:0.0701, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:27:09.995] iteration:23601  t-loss:0.1340, loss-lb:0.0669, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:27:10.187] iteration:23602  t-loss:0.1555, loss-lb:0.0756, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:27:10.380] iteration:23603  t-loss:0.1538, loss-lb:0.0749, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:27:10.574] iteration:23604  t-loss:0.1542, loss-lb:0.0759, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:27:10.767] iteration:23605  t-loss:0.1328, loss-lb:0.0648, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:27:10.959] iteration:23606  t-loss:0.1404, loss-lb:0.0689, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:27:11.151] iteration:23607  t-loss:0.1416, loss-lb:0.0747, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:27:11.344] iteration:23608  t-loss:0.1462, loss-lb:0.0762, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:27:11.539] iteration:23609  t-loss:0.1546, loss-lb:0.0709, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:27:11.731] iteration:23610  t-loss:0.1385, loss-lb:0.0720, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:27:11.925] iteration:23611  t-loss:0.1797, loss-lb:0.0788, loss-ulb:0.0505, weight:2.00, lr:0.0002
[12:27:12.116] iteration:23612  t-loss:0.1606, loss-lb:0.0820, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:27:12.308] iteration:23613  t-loss:0.1296, loss-lb:0.0729, loss-ulb:0.0284, weight:2.00, lr:0.0002
[12:27:12.498] iteration:23614  t-loss:0.1409, loss-lb:0.0705, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:27:12.689] iteration:23615  t-loss:0.1291, loss-lb:0.0653, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:27:12.881] iteration:23616  t-loss:0.1370, loss-lb:0.0740, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:27:13.072] iteration:23617  t-loss:0.1478, loss-lb:0.0776, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:27:13.263] iteration:23618  t-loss:0.1477, loss-lb:0.0718, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:27:25.194]  <<Test>> - Ep:240  - mean_dice/mean_h95 - S:89.67/1.51, Best-S:90.99, T:89.88/1.37, Best-T:90.48
[12:27:25.194]           - AvgLoss(lb/ulb/all):0.0738/0.0365/0.1458
[12:27:25.720] iteration:23619  t-loss:0.1483, loss-lb:0.0712, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:27:25.917] iteration:23620  t-loss:0.1320, loss-lb:0.0639, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:27:26.111] iteration:23621  t-loss:0.1367, loss-lb:0.0702, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:27:26.305] iteration:23622  t-loss:0.1460, loss-lb:0.0760, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:27:26.496] iteration:23623  t-loss:0.1407, loss-lb:0.0733, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:27:26.690] iteration:23624  t-loss:0.1424, loss-lb:0.0716, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:27:26.883] iteration:23625  t-loss:0.1374, loss-lb:0.0710, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:27:27.075] iteration:23626  t-loss:0.1534, loss-lb:0.0727, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:27:27.267] iteration:23627  t-loss:0.1539, loss-lb:0.0736, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:27:27.460] iteration:23628  t-loss:0.1501, loss-lb:0.0719, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:27:27.654] iteration:23629  t-loss:0.1475, loss-lb:0.0816, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:27:27.846] iteration:23630  t-loss:0.1360, loss-lb:0.0686, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:27:28.039] iteration:23631  t-loss:0.1362, loss-lb:0.0709, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:27:28.233] iteration:23632  t-loss:0.2136, loss-lb:0.0832, loss-ulb:0.0652, weight:2.00, lr:0.0002
[12:27:28.427] iteration:23633  t-loss:0.1822, loss-lb:0.0698, loss-ulb:0.0562, weight:2.00, lr:0.0002
[12:27:28.619] iteration:23634  t-loss:0.1389, loss-lb:0.0729, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:27:28.812] iteration:23635  t-loss:0.1510, loss-lb:0.0831, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:27:29.006] iteration:23636  t-loss:0.1395, loss-lb:0.0750, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:27:29.199] iteration:23637  t-loss:0.1492, loss-lb:0.0851, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:27:29.392] iteration:23638  t-loss:0.1535, loss-lb:0.0764, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:27:29.585] iteration:23639  t-loss:0.1270, loss-lb:0.0666, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:27:29.777] iteration:23640  t-loss:0.1433, loss-lb:0.0730, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:27:29.970] iteration:23641  t-loss:0.1720, loss-lb:0.0688, loss-ulb:0.0516, weight:2.00, lr:0.0002
[12:27:30.162] iteration:23642  t-loss:0.1431, loss-lb:0.0685, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:27:30.354] iteration:23643  t-loss:0.1288, loss-lb:0.0645, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:27:30.547] iteration:23644  t-loss:0.1520, loss-lb:0.0737, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:27:30.739] iteration:23645  t-loss:0.1462, loss-lb:0.0773, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:27:30.931] iteration:23646  t-loss:0.1303, loss-lb:0.0627, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:27:31.125] iteration:23647  t-loss:0.1702, loss-lb:0.0768, loss-ulb:0.0467, weight:2.00, lr:0.0002
[12:27:31.316] iteration:23648  t-loss:0.1706, loss-lb:0.0847, loss-ulb:0.0429, weight:2.00, lr:0.0002
[12:27:31.510] iteration:23649  t-loss:0.1433, loss-lb:0.0713, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:27:31.701] iteration:23650  t-loss:0.1464, loss-lb:0.0763, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:27:31.894] iteration:23651  t-loss:0.1372, loss-lb:0.0687, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:27:32.086] iteration:23652  t-loss:0.1367, loss-lb:0.0712, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:27:32.278] iteration:23653  t-loss:0.1565, loss-lb:0.0754, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:27:32.471] iteration:23654  t-loss:0.1450, loss-lb:0.0739, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:27:32.663] iteration:23655  t-loss:0.1423, loss-lb:0.0736, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:27:32.856] iteration:23656  t-loss:0.3037, loss-lb:0.0704, loss-ulb:0.1167, weight:2.00, lr:0.0002
[12:27:33.048] iteration:23657  t-loss:0.1515, loss-lb:0.0771, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:27:33.240] iteration:23658  t-loss:0.1358, loss-lb:0.0687, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:27:33.433] iteration:23659  t-loss:0.1749, loss-lb:0.0732, loss-ulb:0.0508, weight:2.00, lr:0.0002
[12:27:33.625] iteration:23660  t-loss:0.1961, loss-lb:0.0845, loss-ulb:0.0558, weight:2.00, lr:0.0002
[12:27:33.817] iteration:23661  t-loss:0.1509, loss-lb:0.0798, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:27:34.010] iteration:23662  t-loss:0.1446, loss-lb:0.0711, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:27:34.204] iteration:23663  t-loss:0.1774, loss-lb:0.0716, loss-ulb:0.0529, weight:2.00, lr:0.0002
[12:27:34.395] iteration:23664  t-loss:0.1388, loss-lb:0.0737, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:27:34.588] iteration:23665  t-loss:0.1541, loss-lb:0.0728, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:27:34.780] iteration:23666  t-loss:0.1519, loss-lb:0.0737, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:27:34.972] iteration:23667  t-loss:0.1438, loss-lb:0.0730, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:27:35.164] iteration:23668  t-loss:0.1368, loss-lb:0.0683, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:27:35.357] iteration:23669  t-loss:0.1415, loss-lb:0.0756, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:27:35.549] iteration:23670  t-loss:0.1446, loss-lb:0.0706, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:27:35.742] iteration:23671  t-loss:0.1471, loss-lb:0.0734, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:27:35.935] iteration:23672  t-loss:0.1583, loss-lb:0.0720, loss-ulb:0.0432, weight:2.00, lr:0.0002
[12:27:36.127] iteration:23673  t-loss:0.1464, loss-lb:0.0745, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:27:36.319] iteration:23674  t-loss:0.1530, loss-lb:0.0713, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:27:36.511] iteration:23675  t-loss:0.1360, loss-lb:0.0778, loss-ulb:0.0291, weight:2.00, lr:0.0002
[12:27:36.703] iteration:23676  t-loss:0.1465, loss-lb:0.0708, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:27:36.895] iteration:23677  t-loss:0.1454, loss-lb:0.0725, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:27:37.088] iteration:23678  t-loss:0.1434, loss-lb:0.0777, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:27:37.280] iteration:23679  t-loss:0.1319, loss-lb:0.0641, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:27:37.473] iteration:23680  t-loss:0.1326, loss-lb:0.0709, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:27:37.665] iteration:23681  t-loss:0.1294, loss-lb:0.0672, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:27:37.858] iteration:23682  t-loss:0.1663, loss-lb:0.0812, loss-ulb:0.0425, weight:2.00, lr:0.0002
[12:27:38.050] iteration:23683  t-loss:0.1451, loss-lb:0.0762, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:27:38.242] iteration:23684  t-loss:0.1422, loss-lb:0.0727, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:27:38.435] iteration:23685  t-loss:0.1366, loss-lb:0.0767, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:27:38.628] iteration:23686  t-loss:0.1828, loss-lb:0.0710, loss-ulb:0.0559, weight:2.00, lr:0.0002
[12:27:38.822] iteration:23687  t-loss:0.1392, loss-lb:0.0736, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:27:39.015] iteration:23688  t-loss:0.1323, loss-lb:0.0680, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:27:39.208] iteration:23689  t-loss:0.1351, loss-lb:0.0715, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:27:39.402] iteration:23690  t-loss:0.1465, loss-lb:0.0687, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:27:39.595] iteration:23691  t-loss:0.1475, loss-lb:0.0743, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:27:39.787] iteration:23692  t-loss:0.1389, loss-lb:0.0700, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:27:39.980] iteration:23693  t-loss:0.1506, loss-lb:0.0734, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:27:40.172] iteration:23694  t-loss:0.1475, loss-lb:0.0795, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:27:40.364] iteration:23695  t-loss:0.1510, loss-lb:0.0813, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:27:40.558] iteration:23696  t-loss:0.1464, loss-lb:0.0676, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:27:40.753] iteration:23697  t-loss:0.1511, loss-lb:0.0799, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:27:40.950] iteration:23698  t-loss:0.1740, loss-lb:0.0823, loss-ulb:0.0459, weight:2.00, lr:0.0002
[12:27:41.144] iteration:23699  t-loss:0.1489, loss-lb:0.0697, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:27:41.337] iteration:23700  t-loss:0.1406, loss-lb:0.0718, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:27:41.531] iteration:23701  t-loss:0.1344, loss-lb:0.0742, loss-ulb:0.0301, weight:2.00, lr:0.0002
[12:27:41.722] iteration:23702  t-loss:0.1423, loss-lb:0.0738, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:27:41.915] iteration:23703  t-loss:0.1314, loss-lb:0.0685, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:27:42.108] iteration:23704  t-loss:0.1432, loss-lb:0.0693, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:27:42.299] iteration:23705  t-loss:0.1453, loss-lb:0.0769, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:27:42.492] iteration:23706  t-loss:0.2091, loss-lb:0.0743, loss-ulb:0.0674, weight:2.00, lr:0.0002
[12:27:42.686] iteration:23707  t-loss:0.1321, loss-lb:0.0753, loss-ulb:0.0284, weight:2.00, lr:0.0002
[12:27:42.880] iteration:23708  t-loss:0.1492, loss-lb:0.0698, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:27:43.071] iteration:23709  t-loss:0.1343, loss-lb:0.0678, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:27:43.262] iteration:23710  t-loss:0.1779, loss-lb:0.0717, loss-ulb:0.0531, weight:2.00, lr:0.0002
[12:27:43.453] iteration:23711  t-loss:0.1540, loss-lb:0.0735, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:27:43.644] iteration:23712  t-loss:0.1558, loss-lb:0.0754, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:27:43.835] iteration:23713  t-loss:0.1514, loss-lb:0.0753, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:27:44.026] iteration:23714  t-loss:0.1434, loss-lb:0.0773, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:27:44.216] iteration:23715  t-loss:0.1484, loss-lb:0.0700, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:27:44.407] iteration:23716  t-loss:0.1446, loss-lb:0.0735, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:27:45.000] iteration:23717  t-loss:0.1603, loss-lb:0.0778, loss-ulb:0.0413, weight:2.00, lr:0.0002
[12:27:45.195] iteration:23718  t-loss:0.1411, loss-lb:0.0728, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:27:45.389] iteration:23719  t-loss:0.2228, loss-lb:0.0726, loss-ulb:0.0751, weight:2.00, lr:0.0002
[12:27:45.581] iteration:23720  t-loss:0.1377, loss-lb:0.0708, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:27:45.772] iteration:23721  t-loss:0.1350, loss-lb:0.0701, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:27:45.965] iteration:23722  t-loss:0.1488, loss-lb:0.0765, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:27:46.158] iteration:23723  t-loss:0.1373, loss-lb:0.0746, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:27:46.351] iteration:23724  t-loss:0.1450, loss-lb:0.0813, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:27:46.542] iteration:23725  t-loss:0.1274, loss-lb:0.0649, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:27:46.735] iteration:23726  t-loss:0.1473, loss-lb:0.0704, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:27:46.927] iteration:23727  t-loss:0.1661, loss-lb:0.0767, loss-ulb:0.0447, weight:2.00, lr:0.0002
[12:27:47.118] iteration:23728  t-loss:0.1449, loss-lb:0.0731, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:27:47.310] iteration:23729  t-loss:0.1507, loss-lb:0.0831, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:27:47.502] iteration:23730  t-loss:0.1365, loss-lb:0.0643, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:27:47.695] iteration:23731  t-loss:0.1548, loss-lb:0.0787, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:27:47.887] iteration:23732  t-loss:0.1585, loss-lb:0.0766, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:27:48.078] iteration:23733  t-loss:0.1399, loss-lb:0.0781, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:27:48.270] iteration:23734  t-loss:0.1423, loss-lb:0.0725, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:27:48.463] iteration:23735  t-loss:0.2119, loss-lb:0.0769, loss-ulb:0.0675, weight:2.00, lr:0.0002
[12:27:48.655] iteration:23736  t-loss:0.1315, loss-lb:0.0680, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:27:48.847] iteration:23737  t-loss:0.1648, loss-lb:0.0760, loss-ulb:0.0444, weight:2.00, lr:0.0002
[12:27:49.038] iteration:23738  t-loss:0.1642, loss-lb:0.0743, loss-ulb:0.0450, weight:2.00, lr:0.0002
[12:27:49.229] iteration:23739  t-loss:0.1454, loss-lb:0.0784, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:27:49.421] iteration:23740  t-loss:0.1447, loss-lb:0.0749, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:27:49.613] iteration:23741  t-loss:0.1501, loss-lb:0.0708, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:27:49.806] iteration:23742  t-loss:0.2663, loss-lb:0.0736, loss-ulb:0.0963, weight:2.00, lr:0.0002
[12:27:49.997] iteration:23743  t-loss:0.1597, loss-lb:0.0799, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:27:50.189] iteration:23744  t-loss:0.1605, loss-lb:0.0826, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:27:50.380] iteration:23745  t-loss:0.1440, loss-lb:0.0699, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:27:50.571] iteration:23746  t-loss:0.1657, loss-lb:0.0969, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:27:50.764] iteration:23747  t-loss:0.1676, loss-lb:0.0820, loss-ulb:0.0428, weight:2.00, lr:0.0002
[12:27:50.955] iteration:23748  t-loss:0.1557, loss-lb:0.0745, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:27:51.147] iteration:23749  t-loss:0.1559, loss-lb:0.0723, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:27:51.354] iteration:23750  t-loss:0.2174, loss-lb:0.0756, loss-ulb:0.0709, weight:2.00, lr:0.0002
[12:27:51.557] iteration:23751  t-loss:0.1590, loss-lb:0.0725, loss-ulb:0.0433, weight:2.00, lr:0.0002
[12:27:51.757] iteration:23752  t-loss:0.1421, loss-lb:0.0766, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:27:51.951] iteration:23753  t-loss:0.1498, loss-lb:0.0795, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:27:52.155] iteration:23754  t-loss:0.1367, loss-lb:0.0747, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:27:52.347] iteration:23755  t-loss:0.1457, loss-lb:0.0740, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:27:52.539] iteration:23756  t-loss:0.1550, loss-lb:0.0791, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:27:52.732] iteration:23757  t-loss:0.1463, loss-lb:0.0781, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:27:52.931] iteration:23758  t-loss:0.1512, loss-lb:0.0813, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:27:53.124] iteration:23759  t-loss:0.1593, loss-lb:0.0846, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:27:53.315] iteration:23760  t-loss:0.1481, loss-lb:0.0750, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:27:53.507] iteration:23761  t-loss:0.1506, loss-lb:0.0717, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:27:53.706] iteration:23762  t-loss:0.1331, loss-lb:0.0713, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:27:53.897] iteration:23763  t-loss:0.1456, loss-lb:0.0786, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:27:54.090] iteration:23764  t-loss:0.1415, loss-lb:0.0720, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:27:54.281] iteration:23765  t-loss:0.1836, loss-lb:0.0788, loss-ulb:0.0524, weight:2.00, lr:0.0002
[12:27:54.481] iteration:23766  t-loss:0.1674, loss-lb:0.0794, loss-ulb:0.0440, weight:2.00, lr:0.0002
[12:27:54.674] iteration:23767  t-loss:0.1448, loss-lb:0.0714, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:27:54.866] iteration:23768  t-loss:0.1939, loss-lb:0.0800, loss-ulb:0.0570, weight:2.00, lr:0.0002
[12:27:55.058] iteration:23769  t-loss:0.1724, loss-lb:0.0713, loss-ulb:0.0505, weight:2.00, lr:0.0002
[12:27:55.259] iteration:23770  t-loss:0.2506, loss-lb:0.0690, loss-ulb:0.0908, weight:2.00, lr:0.0002
[12:27:55.451] iteration:23771  t-loss:0.1321, loss-lb:0.0711, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:27:55.644] iteration:23772  t-loss:0.1530, loss-lb:0.0813, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:27:55.837] iteration:23773  t-loss:0.1702, loss-lb:0.0844, loss-ulb:0.0429, weight:2.00, lr:0.0002
[12:27:56.037] iteration:23774  t-loss:0.1414, loss-lb:0.0745, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:27:56.229] iteration:23775  t-loss:0.1508, loss-lb:0.0800, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:27:56.422] iteration:23776  t-loss:0.1525, loss-lb:0.0814, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:27:56.614] iteration:23777  t-loss:0.1317, loss-lb:0.0736, loss-ulb:0.0291, weight:2.00, lr:0.0002
[12:27:56.807] iteration:23778  t-loss:0.1366, loss-lb:0.0684, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:27:56.999] iteration:23779  t-loss:0.1419, loss-lb:0.0754, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:27:57.190] iteration:23780  t-loss:0.1621, loss-lb:0.0791, loss-ulb:0.0415, weight:2.00, lr:0.0002
[12:27:57.383] iteration:23781  t-loss:0.1533, loss-lb:0.0765, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:27:57.576] iteration:23782  t-loss:0.1432, loss-lb:0.0716, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:27:57.770] iteration:23783  t-loss:0.1532, loss-lb:0.0765, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:27:57.961] iteration:23784  t-loss:0.1431, loss-lb:0.0767, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:27:58.152] iteration:23785  t-loss:0.1486, loss-lb:0.0776, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:27:58.344] iteration:23786  t-loss:0.1364, loss-lb:0.0680, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:27:58.536] iteration:23787  t-loss:0.1509, loss-lb:0.0835, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:27:58.727] iteration:23788  t-loss:0.1511, loss-lb:0.0728, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:27:58.920] iteration:23789  t-loss:0.1385, loss-lb:0.0738, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:27:59.114] iteration:23790  t-loss:0.1508, loss-lb:0.0807, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:27:59.305] iteration:23791  t-loss:0.1703, loss-lb:0.0825, loss-ulb:0.0439, weight:2.00, lr:0.0002
[12:27:59.497] iteration:23792  t-loss:0.1445, loss-lb:0.0751, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:27:59.689] iteration:23793  t-loss:0.1378, loss-lb:0.0669, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:27:59.880] iteration:23794  t-loss:0.1471, loss-lb:0.0761, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:28:00.071] iteration:23795  t-loss:0.1545, loss-lb:0.0823, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:28:00.264] iteration:23796  t-loss:0.1421, loss-lb:0.0698, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:28:00.454] iteration:23797  t-loss:0.1396, loss-lb:0.0705, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:28:00.645] iteration:23798  t-loss:0.1482, loss-lb:0.0739, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:28:00.838] iteration:23799  t-loss:0.1541, loss-lb:0.0776, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:28:01.029] iteration:23800  t-loss:0.1630, loss-lb:0.0711, loss-ulb:0.0460, weight:2.00, lr:0.0002
[12:28:01.222] iteration:23801  t-loss:0.1418, loss-lb:0.0714, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:28:01.414] iteration:23802  t-loss:0.1467, loss-lb:0.0680, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:28:01.605] iteration:23803  t-loss:0.1491, loss-lb:0.0853, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:28:01.797] iteration:23804  t-loss:0.2868, loss-lb:0.0865, loss-ulb:0.1002, weight:2.00, lr:0.0002
[12:28:01.989] iteration:23805  t-loss:0.1435, loss-lb:0.0777, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:28:02.181] iteration:23806  t-loss:0.1383, loss-lb:0.0726, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:28:02.374] iteration:23807  t-loss:0.1406, loss-lb:0.0768, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:28:02.568] iteration:23808  t-loss:0.1697, loss-lb:0.0880, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:28:02.762] iteration:23809  t-loss:0.1616, loss-lb:0.0707, loss-ulb:0.0454, weight:2.00, lr:0.0002
[12:28:02.954] iteration:23810  t-loss:0.1563, loss-lb:0.0761, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:28:03.147] iteration:23811  t-loss:0.1466, loss-lb:0.0729, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:28:03.339] iteration:23812  t-loss:0.1366, loss-lb:0.0785, loss-ulb:0.0290, weight:2.00, lr:0.0002
[12:28:03.529] iteration:23813  t-loss:0.1468, loss-lb:0.0716, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:28:03.719] iteration:23814  t-loss:0.1730, loss-lb:0.0761, loss-ulb:0.0485, weight:2.00, lr:0.0002
[12:28:16.478]  <<Test>> - Ep:242  - mean_dice/mean_h95 - S:89.46/1.51, Best-S:90.99, T:89.61/1.57, Best-T:90.48
[12:28:16.478]           - AvgLoss(lb/ulb/all):0.0758/0.0405/0.1570
[12:28:17.021] iteration:23815  t-loss:0.1293, loss-lb:0.0720, loss-ulb:0.0287, weight:2.00, lr:0.0002
[12:28:17.219] iteration:23816  t-loss:0.1464, loss-lb:0.0706, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:28:17.412] iteration:23817  t-loss:0.1379, loss-lb:0.0687, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:28:17.606] iteration:23818  t-loss:0.1683, loss-lb:0.0746, loss-ulb:0.0469, weight:2.00, lr:0.0002
[12:28:17.799] iteration:23819  t-loss:0.1539, loss-lb:0.0900, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:28:17.991] iteration:23820  t-loss:0.1520, loss-lb:0.0783, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:28:18.184] iteration:23821  t-loss:0.1407, loss-lb:0.0775, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:28:18.377] iteration:23822  t-loss:0.1411, loss-lb:0.0758, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:28:18.570] iteration:23823  t-loss:0.1341, loss-lb:0.0669, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:28:18.762] iteration:23824  t-loss:0.1484, loss-lb:0.0734, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:28:18.955] iteration:23825  t-loss:0.1471, loss-lb:0.0761, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:28:19.148] iteration:23826  t-loss:0.1571, loss-lb:0.0731, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:28:19.340] iteration:23827  t-loss:0.1476, loss-lb:0.0702, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:28:19.532] iteration:23828  t-loss:0.1408, loss-lb:0.0688, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:28:19.725] iteration:23829  t-loss:0.1560, loss-lb:0.0667, loss-ulb:0.0447, weight:2.00, lr:0.0002
[12:28:19.918] iteration:23830  t-loss:0.1485, loss-lb:0.0750, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:28:20.111] iteration:23831  t-loss:0.1556, loss-lb:0.0738, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:28:20.303] iteration:23832  t-loss:0.1528, loss-lb:0.0856, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:28:20.497] iteration:23833  t-loss:0.1471, loss-lb:0.0825, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:28:20.689] iteration:23834  t-loss:0.1569, loss-lb:0.0791, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:28:20.886] iteration:23835  t-loss:0.1391, loss-lb:0.0768, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:28:21.078] iteration:23836  t-loss:0.1490, loss-lb:0.0840, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:28:21.271] iteration:23837  t-loss:0.1998, loss-lb:0.0752, loss-ulb:0.0623, weight:2.00, lr:0.0002
[12:28:21.464] iteration:23838  t-loss:0.1289, loss-lb:0.0677, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:28:21.657] iteration:23839  t-loss:0.1383, loss-lb:0.0682, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:28:21.847] iteration:23840  t-loss:0.1586, loss-lb:0.0787, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:28:22.039] iteration:23841  t-loss:0.1334, loss-lb:0.0745, loss-ulb:0.0294, weight:2.00, lr:0.0002
[12:28:22.230] iteration:23842  t-loss:0.1533, loss-lb:0.0824, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:28:22.422] iteration:23843  t-loss:0.1392, loss-lb:0.0715, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:28:22.614] iteration:23844  t-loss:0.1686, loss-lb:0.0841, loss-ulb:0.0422, weight:2.00, lr:0.0002
[12:28:22.805] iteration:23845  t-loss:0.1447, loss-lb:0.0733, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:28:22.998] iteration:23846  t-loss:0.1464, loss-lb:0.0718, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:28:23.189] iteration:23847  t-loss:0.1353, loss-lb:0.0707, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:28:23.381] iteration:23848  t-loss:0.1400, loss-lb:0.0705, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:28:23.573] iteration:23849  t-loss:0.1412, loss-lb:0.0686, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:28:23.764] iteration:23850  t-loss:0.1537, loss-lb:0.0834, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:28:23.957] iteration:23851  t-loss:0.2060, loss-lb:0.0761, loss-ulb:0.0650, weight:2.00, lr:0.0002
[12:28:24.162] iteration:23852  t-loss:0.1443, loss-lb:0.0715, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:28:24.361] iteration:23853  t-loss:0.1434, loss-lb:0.0823, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:28:24.556] iteration:23854  t-loss:0.1623, loss-lb:0.0717, loss-ulb:0.0453, weight:2.00, lr:0.0002
[12:28:24.749] iteration:23855  t-loss:0.1520, loss-lb:0.0752, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:28:24.942] iteration:23856  t-loss:0.2387, loss-lb:0.0839, loss-ulb:0.0774, weight:2.00, lr:0.0002
[12:28:25.135] iteration:23857  t-loss:0.1422, loss-lb:0.0760, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:28:25.326] iteration:23858  t-loss:0.1362, loss-lb:0.0719, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:28:25.519] iteration:23859  t-loss:0.1332, loss-lb:0.0693, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:28:25.712] iteration:23860  t-loss:0.1413, loss-lb:0.0744, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:28:25.906] iteration:23861  t-loss:0.1603, loss-lb:0.0672, loss-ulb:0.0466, weight:2.00, lr:0.0002
[12:28:26.099] iteration:23862  t-loss:0.1498, loss-lb:0.0718, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:28:26.291] iteration:23863  t-loss:0.1624, loss-lb:0.0791, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:28:26.484] iteration:23864  t-loss:0.1905, loss-lb:0.0920, loss-ulb:0.0493, weight:2.00, lr:0.0002
[12:28:26.677] iteration:23865  t-loss:0.2604, loss-lb:0.0693, loss-ulb:0.0956, weight:2.00, lr:0.0002
[12:28:26.870] iteration:23866  t-loss:0.1392, loss-lb:0.0710, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:28:27.062] iteration:23867  t-loss:0.1644, loss-lb:0.0858, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:28:27.255] iteration:23868  t-loss:0.1408, loss-lb:0.0807, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:28:27.448] iteration:23869  t-loss:0.1374, loss-lb:0.0689, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:28:27.641] iteration:23870  t-loss:0.1529, loss-lb:0.0757, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:28:27.834] iteration:23871  t-loss:0.2188, loss-lb:0.0790, loss-ulb:0.0699, weight:2.00, lr:0.0002
[12:28:28.026] iteration:23872  t-loss:0.1847, loss-lb:0.0678, loss-ulb:0.0585, weight:2.00, lr:0.0002
[12:28:28.219] iteration:23873  t-loss:0.1530, loss-lb:0.0800, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:28:28.412] iteration:23874  t-loss:0.1555, loss-lb:0.0728, loss-ulb:0.0414, weight:2.00, lr:0.0002
[12:28:28.604] iteration:23875  t-loss:0.1586, loss-lb:0.0745, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:28:28.798] iteration:23876  t-loss:0.1767, loss-lb:0.0786, loss-ulb:0.0490, weight:2.00, lr:0.0002
[12:28:28.990] iteration:23877  t-loss:0.1337, loss-lb:0.0762, loss-ulb:0.0287, weight:2.00, lr:0.0002
[12:28:29.182] iteration:23878  t-loss:0.1585, loss-lb:0.0812, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:28:29.375] iteration:23879  t-loss:0.1593, loss-lb:0.0692, loss-ulb:0.0451, weight:2.00, lr:0.0002
[12:28:29.568] iteration:23880  t-loss:0.1481, loss-lb:0.0774, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:28:29.761] iteration:23881  t-loss:0.1526, loss-lb:0.0766, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:28:29.953] iteration:23882  t-loss:0.1475, loss-lb:0.0735, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:28:30.145] iteration:23883  t-loss:0.1480, loss-lb:0.0819, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:28:30.338] iteration:23884  t-loss:0.1427, loss-lb:0.0720, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:28:30.531] iteration:23885  t-loss:0.1608, loss-lb:0.0762, loss-ulb:0.0423, weight:2.00, lr:0.0002
[12:28:30.723] iteration:23886  t-loss:0.1369, loss-lb:0.0735, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:28:30.916] iteration:23887  t-loss:0.1503, loss-lb:0.0762, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:28:31.109] iteration:23888  t-loss:0.1501, loss-lb:0.0828, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:28:31.301] iteration:23889  t-loss:0.1350, loss-lb:0.0742, loss-ulb:0.0304, weight:2.00, lr:0.0002
[12:28:31.493] iteration:23890  t-loss:0.1518, loss-lb:0.0785, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:28:31.686] iteration:23891  t-loss:0.1438, loss-lb:0.0699, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:28:31.879] iteration:23892  t-loss:0.1387, loss-lb:0.0728, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:28:32.070] iteration:23893  t-loss:0.1580, loss-lb:0.0739, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:28:32.264] iteration:23894  t-loss:0.1473, loss-lb:0.0876, loss-ulb:0.0299, weight:2.00, lr:0.0002
[12:28:32.457] iteration:23895  t-loss:0.1295, loss-lb:0.0653, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:28:32.650] iteration:23896  t-loss:0.1541, loss-lb:0.0809, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:28:32.842] iteration:23897  t-loss:0.1467, loss-lb:0.0742, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:28:33.034] iteration:23898  t-loss:0.1682, loss-lb:0.0767, loss-ulb:0.0458, weight:2.00, lr:0.0002
[12:28:33.226] iteration:23899  t-loss:0.1524, loss-lb:0.0726, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:28:33.419] iteration:23900  t-loss:0.1390, loss-lb:0.0703, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:28:33.612] iteration:23901  t-loss:0.1650, loss-lb:0.0780, loss-ulb:0.0435, weight:2.00, lr:0.0002
[12:28:33.805] iteration:23902  t-loss:0.2184, loss-lb:0.0725, loss-ulb:0.0729, weight:2.00, lr:0.0002
[12:28:33.998] iteration:23903  t-loss:0.1446, loss-lb:0.0784, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:28:34.190] iteration:23904  t-loss:0.1593, loss-lb:0.0739, loss-ulb:0.0427, weight:2.00, lr:0.0002
[12:28:34.382] iteration:23905  t-loss:0.1511, loss-lb:0.0736, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:28:34.572] iteration:23906  t-loss:0.1555, loss-lb:0.0806, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:28:34.763] iteration:23907  t-loss:0.1673, loss-lb:0.0758, loss-ulb:0.0457, weight:2.00, lr:0.0002
[12:28:34.953] iteration:23908  t-loss:0.1486, loss-lb:0.0718, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:28:35.144] iteration:23909  t-loss:0.1472, loss-lb:0.0705, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:28:35.334] iteration:23910  t-loss:0.1528, loss-lb:0.0745, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:28:35.524] iteration:23911  t-loss:0.1464, loss-lb:0.0816, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:28:35.714] iteration:23912  t-loss:0.1613, loss-lb:0.0699, loss-ulb:0.0457, weight:2.00, lr:0.0002
[12:28:36.302] iteration:23913  t-loss:0.1476, loss-lb:0.0832, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:28:36.497] iteration:23914  t-loss:0.1682, loss-lb:0.0735, loss-ulb:0.0473, weight:2.00, lr:0.0002
[12:28:36.690] iteration:23915  t-loss:0.1305, loss-lb:0.0689, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:28:36.881] iteration:23916  t-loss:0.1494, loss-lb:0.0799, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:28:37.074] iteration:23917  t-loss:0.1373, loss-lb:0.0776, loss-ulb:0.0298, weight:2.00, lr:0.0002
[12:28:37.266] iteration:23918  t-loss:0.1385, loss-lb:0.0736, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:28:37.460] iteration:23919  t-loss:0.1357, loss-lb:0.0719, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:28:37.653] iteration:23920  t-loss:0.1814, loss-lb:0.0739, loss-ulb:0.0538, weight:2.00, lr:0.0002
[12:28:37.846] iteration:23921  t-loss:0.1459, loss-lb:0.0687, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:28:38.039] iteration:23922  t-loss:0.1561, loss-lb:0.0739, loss-ulb:0.0411, weight:2.00, lr:0.0002
[12:28:38.231] iteration:23923  t-loss:0.1474, loss-lb:0.0762, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:28:38.425] iteration:23924  t-loss:0.1349, loss-lb:0.0721, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:28:38.618] iteration:23925  t-loss:0.1950, loss-lb:0.0780, loss-ulb:0.0585, weight:2.00, lr:0.0002
[12:28:38.811] iteration:23926  t-loss:0.1946, loss-lb:0.0740, loss-ulb:0.0603, weight:2.00, lr:0.0002
[12:28:39.003] iteration:23927  t-loss:0.1413, loss-lb:0.0690, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:28:39.195] iteration:23928  t-loss:0.1424, loss-lb:0.0657, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:28:39.388] iteration:23929  t-loss:0.1700, loss-lb:0.0822, loss-ulb:0.0439, weight:2.00, lr:0.0002
[12:28:39.582] iteration:23930  t-loss:0.1475, loss-lb:0.0718, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:28:39.773] iteration:23931  t-loss:0.1574, loss-lb:0.0859, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:28:39.966] iteration:23932  t-loss:0.1507, loss-lb:0.0717, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:28:40.159] iteration:23933  t-loss:0.1619, loss-lb:0.0719, loss-ulb:0.0450, weight:2.00, lr:0.0002
[12:28:40.351] iteration:23934  t-loss:0.1505, loss-lb:0.0722, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:28:40.543] iteration:23935  t-loss:0.1736, loss-lb:0.0700, loss-ulb:0.0518, weight:2.00, lr:0.0002
[12:28:40.736] iteration:23936  t-loss:0.1451, loss-lb:0.0765, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:28:40.930] iteration:23937  t-loss:0.1460, loss-lb:0.0812, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:28:41.125] iteration:23938  t-loss:0.2195, loss-lb:0.0729, loss-ulb:0.0733, weight:2.00, lr:0.0002
[12:28:41.316] iteration:23939  t-loss:0.1347, loss-lb:0.0696, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:28:41.510] iteration:23940  t-loss:0.1412, loss-lb:0.0707, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:28:41.703] iteration:23941  t-loss:0.1341, loss-lb:0.0713, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:28:41.895] iteration:23942  t-loss:0.1449, loss-lb:0.0706, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:28:42.088] iteration:23943  t-loss:0.1538, loss-lb:0.0726, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:28:42.281] iteration:23944  t-loss:0.1903, loss-lb:0.0723, loss-ulb:0.0590, weight:2.00, lr:0.0002
[12:28:42.474] iteration:23945  t-loss:0.1321, loss-lb:0.0682, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:28:42.665] iteration:23946  t-loss:0.1357, loss-lb:0.0715, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:28:42.858] iteration:23947  t-loss:0.1397, loss-lb:0.0707, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:28:43.050] iteration:23948  t-loss:0.1394, loss-lb:0.0764, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:28:43.242] iteration:23949  t-loss:0.1447, loss-lb:0.0717, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:28:43.434] iteration:23950  t-loss:0.1303, loss-lb:0.0625, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:28:43.627] iteration:23951  t-loss:0.1520, loss-lb:0.0780, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:28:43.819] iteration:23952  t-loss:0.1425, loss-lb:0.0700, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:28:44.012] iteration:23953  t-loss:0.1744, loss-lb:0.0757, loss-ulb:0.0494, weight:2.00, lr:0.0002
[12:28:44.205] iteration:23954  t-loss:0.1519, loss-lb:0.0804, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:28:44.398] iteration:23955  t-loss:0.1624, loss-lb:0.0823, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:28:44.591] iteration:23956  t-loss:0.1346, loss-lb:0.0717, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:28:44.784] iteration:23957  t-loss:0.1451, loss-lb:0.0684, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:28:44.976] iteration:23958  t-loss:0.1477, loss-lb:0.0737, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:28:45.169] iteration:23959  t-loss:0.1358, loss-lb:0.0690, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:28:45.360] iteration:23960  t-loss:0.1432, loss-lb:0.0676, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:28:45.552] iteration:23961  t-loss:0.1650, loss-lb:0.0819, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:28:45.744] iteration:23962  t-loss:0.1359, loss-lb:0.0684, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:28:45.938] iteration:23963  t-loss:0.1328, loss-lb:0.0675, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:28:46.130] iteration:23964  t-loss:0.1580, loss-lb:0.0806, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:28:46.322] iteration:23965  t-loss:0.1479, loss-lb:0.0823, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:28:46.515] iteration:23966  t-loss:0.1584, loss-lb:0.0735, loss-ulb:0.0424, weight:2.00, lr:0.0002
[12:28:46.708] iteration:23967  t-loss:0.1391, loss-lb:0.0721, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:28:46.899] iteration:23968  t-loss:0.1348, loss-lb:0.0692, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:28:47.092] iteration:23969  t-loss:0.1303, loss-lb:0.0707, loss-ulb:0.0298, weight:2.00, lr:0.0002
[12:28:47.286] iteration:23970  t-loss:0.1291, loss-lb:0.0675, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:28:47.478] iteration:23971  t-loss:0.1635, loss-lb:0.0752, loss-ulb:0.0442, weight:2.00, lr:0.0002
[12:28:47.670] iteration:23972  t-loss:0.1484, loss-lb:0.0742, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:28:47.864] iteration:23973  t-loss:0.1640, loss-lb:0.0713, loss-ulb:0.0464, weight:2.00, lr:0.0002
[12:28:48.056] iteration:23974  t-loss:0.1506, loss-lb:0.0706, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:28:48.248] iteration:23975  t-loss:0.1284, loss-lb:0.0695, loss-ulb:0.0295, weight:2.00, lr:0.0002
[12:28:48.440] iteration:23976  t-loss:0.1325, loss-lb:0.0751, loss-ulb:0.0287, weight:2.00, lr:0.0002
[12:28:48.633] iteration:23977  t-loss:0.1673, loss-lb:0.0747, loss-ulb:0.0463, weight:2.00, lr:0.0002
[12:28:48.825] iteration:23978  t-loss:0.1598, loss-lb:0.0791, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:28:49.018] iteration:23979  t-loss:0.1427, loss-lb:0.0713, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:28:49.212] iteration:23980  t-loss:0.1384, loss-lb:0.0723, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:28:49.404] iteration:23981  t-loss:0.1415, loss-lb:0.0725, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:28:49.596] iteration:23982  t-loss:0.1332, loss-lb:0.0671, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:28:49.789] iteration:23983  t-loss:0.1477, loss-lb:0.0772, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:28:49.981] iteration:23984  t-loss:0.1399, loss-lb:0.0664, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:28:50.173] iteration:23985  t-loss:0.1386, loss-lb:0.0704, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:28:50.367] iteration:23986  t-loss:0.3068, loss-lb:0.0741, loss-ulb:0.1163, weight:2.00, lr:0.0002
[12:28:50.560] iteration:23987  t-loss:0.1478, loss-lb:0.0698, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:28:50.752] iteration:23988  t-loss:0.1589, loss-lb:0.0811, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:28:50.944] iteration:23989  t-loss:0.1282, loss-lb:0.0711, loss-ulb:0.0286, weight:2.00, lr:0.0002
[12:28:51.136] iteration:23990  t-loss:0.1511, loss-lb:0.0784, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:28:51.329] iteration:23991  t-loss:0.1546, loss-lb:0.0804, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:28:51.521] iteration:23992  t-loss:0.1388, loss-lb:0.0730, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:28:51.713] iteration:23993  t-loss:0.1387, loss-lb:0.0715, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:28:51.907] iteration:23994  t-loss:0.1847, loss-lb:0.0816, loss-ulb:0.0515, weight:2.00, lr:0.0002
[12:28:52.099] iteration:23995  t-loss:0.1460, loss-lb:0.0725, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:28:52.292] iteration:23996  t-loss:0.1465, loss-lb:0.0671, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:28:52.484] iteration:23997  t-loss:0.1386, loss-lb:0.0711, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:28:52.676] iteration:23998  t-loss:0.1256, loss-lb:0.0685, loss-ulb:0.0285, weight:2.00, lr:0.0002
[12:28:52.868] iteration:23999  t-loss:0.1346, loss-lb:0.0767, loss-ulb:0.0290, weight:2.00, lr:0.0002
[12:28:53.062] iteration:24000  t-loss:0.2509, loss-lb:0.0697, loss-ulb:0.0906, weight:2.00, lr:0.0002
[12:28:53.254] iteration:24001  t-loss:0.1560, loss-lb:0.0717, loss-ulb:0.0421, weight:2.00, lr:0.0002
[12:28:53.447] iteration:24002  t-loss:0.1401, loss-lb:0.0704, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:28:53.638] iteration:24003  t-loss:0.1514, loss-lb:0.0765, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:28:53.829] iteration:24004  t-loss:0.1338, loss-lb:0.0772, loss-ulb:0.0283, weight:2.00, lr:0.0002
[12:28:54.020] iteration:24005  t-loss:0.1506, loss-lb:0.0652, loss-ulb:0.0427, weight:2.00, lr:0.0002
[12:28:54.211] iteration:24006  t-loss:0.1364, loss-lb:0.0762, loss-ulb:0.0301, weight:2.00, lr:0.0002
[12:28:54.402] iteration:24007  t-loss:0.1428, loss-lb:0.0689, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:28:54.592] iteration:24008  t-loss:0.1446, loss-lb:0.0746, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:28:54.783] iteration:24009  t-loss:0.1411, loss-lb:0.0694, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:28:54.977] iteration:24010  t-loss:0.1485, loss-lb:0.0766, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:29:06.971]  <<Test>> - Ep:244  - mean_dice/mean_h95 - S:89.86/1.32, Best-S:90.99, T:89.68/1.33, Best-T:90.48
[12:29:06.971]           - AvgLoss(lb/ulb/all):0.0732/0.0386/0.1502
[12:29:07.492] iteration:24011  t-loss:0.1503, loss-lb:0.0877, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:29:07.687] iteration:24012  t-loss:0.1481, loss-lb:0.0730, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:29:07.881] iteration:24013  t-loss:0.1395, loss-lb:0.0751, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:29:08.073] iteration:24014  t-loss:0.1569, loss-lb:0.0748, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:29:08.266] iteration:24015  t-loss:0.1372, loss-lb:0.0714, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:29:08.460] iteration:24016  t-loss:0.1783, loss-lb:0.0781, loss-ulb:0.0501, weight:2.00, lr:0.0002
[12:29:08.653] iteration:24017  t-loss:0.1715, loss-lb:0.0709, loss-ulb:0.0503, weight:2.00, lr:0.0002
[12:29:08.847] iteration:24018  t-loss:0.2000, loss-lb:0.0728, loss-ulb:0.0636, weight:2.00, lr:0.0002
[12:29:09.041] iteration:24019  t-loss:0.1397, loss-lb:0.0720, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:29:09.234] iteration:24020  t-loss:0.1577, loss-lb:0.0693, loss-ulb:0.0442, weight:2.00, lr:0.0002
[12:29:09.427] iteration:24021  t-loss:0.1555, loss-lb:0.0699, loss-ulb:0.0428, weight:2.00, lr:0.0002
[12:29:09.620] iteration:24022  t-loss:0.1418, loss-lb:0.0703, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:29:09.814] iteration:24023  t-loss:0.1526, loss-lb:0.0661, loss-ulb:0.0432, weight:2.00, lr:0.0002
[12:29:10.007] iteration:24024  t-loss:0.1413, loss-lb:0.0704, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:29:10.200] iteration:24025  t-loss:0.1596, loss-lb:0.0722, loss-ulb:0.0437, weight:2.00, lr:0.0002
[12:29:10.391] iteration:24026  t-loss:0.1438, loss-lb:0.0657, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:29:10.584] iteration:24027  t-loss:0.1526, loss-lb:0.0740, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:29:10.776] iteration:24028  t-loss:0.1435, loss-lb:0.0725, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:29:10.969] iteration:24029  t-loss:0.1396, loss-lb:0.0738, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:29:11.161] iteration:24030  t-loss:0.1386, loss-lb:0.0726, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:29:11.355] iteration:24031  t-loss:0.1427, loss-lb:0.0727, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:29:11.548] iteration:24032  t-loss:0.1555, loss-lb:0.0877, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:29:11.741] iteration:24033  t-loss:0.3065, loss-lb:0.0784, loss-ulb:0.1141, weight:2.00, lr:0.0002
[12:29:11.934] iteration:24034  t-loss:0.1578, loss-lb:0.0714, loss-ulb:0.0432, weight:2.00, lr:0.0002
[12:29:12.127] iteration:24035  t-loss:0.1378, loss-lb:0.0727, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:29:12.318] iteration:24036  t-loss:0.1544, loss-lb:0.0789, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:29:12.510] iteration:24037  t-loss:0.1426, loss-lb:0.0757, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:29:12.704] iteration:24038  t-loss:0.1346, loss-lb:0.0663, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:29:12.895] iteration:24039  t-loss:0.1451, loss-lb:0.0773, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:29:13.088] iteration:24040  t-loss:0.2265, loss-lb:0.0811, loss-ulb:0.0727, weight:2.00, lr:0.0002
[12:29:13.281] iteration:24041  t-loss:0.1348, loss-lb:0.0675, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:29:13.474] iteration:24042  t-loss:0.1550, loss-lb:0.0746, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:29:13.666] iteration:24043  t-loss:0.1516, loss-lb:0.0716, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:29:13.860] iteration:24044  t-loss:0.1447, loss-lb:0.0714, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:29:14.053] iteration:24045  t-loss:0.1787, loss-lb:0.0749, loss-ulb:0.0519, weight:2.00, lr:0.0002
[12:29:14.244] iteration:24046  t-loss:0.1465, loss-lb:0.0631, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:29:14.438] iteration:24047  t-loss:0.1486, loss-lb:0.0760, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:29:14.632] iteration:24048  t-loss:0.1299, loss-lb:0.0676, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:29:14.830] iteration:24049  t-loss:0.1441, loss-lb:0.0725, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:29:15.025] iteration:24050  t-loss:0.2045, loss-lb:0.0723, loss-ulb:0.0661, weight:2.00, lr:0.0002
[12:29:15.218] iteration:24051  t-loss:0.1582, loss-lb:0.0795, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:29:15.411] iteration:24052  t-loss:0.1387, loss-lb:0.0744, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:29:15.603] iteration:24053  t-loss:0.1586, loss-lb:0.0785, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:29:15.796] iteration:24054  t-loss:0.1393, loss-lb:0.0712, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:29:15.989] iteration:24055  t-loss:0.1396, loss-lb:0.0644, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:29:16.182] iteration:24056  t-loss:0.1429, loss-lb:0.0761, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:29:16.375] iteration:24057  t-loss:0.1647, loss-lb:0.0670, loss-ulb:0.0489, weight:2.00, lr:0.0002
[12:29:16.566] iteration:24058  t-loss:0.1442, loss-lb:0.0752, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:29:16.758] iteration:24059  t-loss:0.1486, loss-lb:0.0788, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:29:16.949] iteration:24060  t-loss:0.1364, loss-lb:0.0678, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:29:17.141] iteration:24061  t-loss:0.1382, loss-lb:0.0647, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:29:17.333] iteration:24062  t-loss:0.1425, loss-lb:0.0704, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:29:17.525] iteration:24063  t-loss:0.1455, loss-lb:0.0786, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:29:17.717] iteration:24064  t-loss:0.1327, loss-lb:0.0757, loss-ulb:0.0285, weight:2.00, lr:0.0002
[12:29:17.909] iteration:24065  t-loss:0.1452, loss-lb:0.0776, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:29:18.100] iteration:24066  t-loss:0.1469, loss-lb:0.0763, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:29:18.291] iteration:24067  t-loss:0.1431, loss-lb:0.0779, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:29:18.483] iteration:24068  t-loss:0.1347, loss-lb:0.0733, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:29:18.675] iteration:24069  t-loss:0.1459, loss-lb:0.0709, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:29:18.867] iteration:24070  t-loss:0.1405, loss-lb:0.0732, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:29:19.060] iteration:24071  t-loss:0.1378, loss-lb:0.0685, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:29:19.252] iteration:24072  t-loss:0.1380, loss-lb:0.0636, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:29:19.444] iteration:24073  t-loss:0.1315, loss-lb:0.0669, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:29:19.637] iteration:24074  t-loss:0.1501, loss-lb:0.0751, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:29:19.829] iteration:24075  t-loss:0.1552, loss-lb:0.0847, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:29:20.021] iteration:24076  t-loss:0.1346, loss-lb:0.0807, loss-ulb:0.0269, weight:2.00, lr:0.0002
[12:29:20.213] iteration:24077  t-loss:0.1496, loss-lb:0.0828, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:29:20.405] iteration:24078  t-loss:0.1442, loss-lb:0.0709, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:29:20.597] iteration:24079  t-loss:0.1380, loss-lb:0.0782, loss-ulb:0.0299, weight:2.00, lr:0.0002
[12:29:20.789] iteration:24080  t-loss:0.1463, loss-lb:0.0780, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:29:20.980] iteration:24081  t-loss:0.1455, loss-lb:0.0737, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:29:21.173] iteration:24082  t-loss:0.1230, loss-lb:0.0690, loss-ulb:0.0270, weight:2.00, lr:0.0002
[12:29:21.366] iteration:24083  t-loss:0.1676, loss-lb:0.0735, loss-ulb:0.0470, weight:2.00, lr:0.0002
[12:29:21.558] iteration:24084  t-loss:0.1395, loss-lb:0.0756, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:29:21.749] iteration:24085  t-loss:0.1539, loss-lb:0.0729, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:29:21.941] iteration:24086  t-loss:0.1340, loss-lb:0.0718, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:29:22.136] iteration:24087  t-loss:0.1322, loss-lb:0.0656, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:29:22.327] iteration:24088  t-loss:0.1391, loss-lb:0.0702, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:29:22.520] iteration:24089  t-loss:0.1387, loss-lb:0.0706, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:29:22.712] iteration:24090  t-loss:0.1477, loss-lb:0.0743, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:29:22.903] iteration:24091  t-loss:0.1391, loss-lb:0.0666, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:29:23.094] iteration:24092  t-loss:0.1337, loss-lb:0.0704, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:29:23.286] iteration:24093  t-loss:0.1641, loss-lb:0.0687, loss-ulb:0.0477, weight:2.00, lr:0.0002
[12:29:23.477] iteration:24094  t-loss:0.1398, loss-lb:0.0715, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:29:23.669] iteration:24095  t-loss:0.1340, loss-lb:0.0662, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:29:23.860] iteration:24096  t-loss:0.1424, loss-lb:0.0713, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:29:24.053] iteration:24097  t-loss:0.1708, loss-lb:0.0802, loss-ulb:0.0453, weight:2.00, lr:0.0002
[12:29:24.244] iteration:24098  t-loss:0.1370, loss-lb:0.0699, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:29:24.435] iteration:24099  t-loss:0.1460, loss-lb:0.0844, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:29:24.628] iteration:24100  t-loss:0.1465, loss-lb:0.0725, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:29:24.819] iteration:24101  t-loss:0.2151, loss-lb:0.0659, loss-ulb:0.0746, weight:2.00, lr:0.0002
[12:29:25.010] iteration:24102  t-loss:0.1388, loss-lb:0.0729, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:29:25.201] iteration:24103  t-loss:0.1559, loss-lb:0.0777, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:29:25.392] iteration:24104  t-loss:0.1600, loss-lb:0.0743, loss-ulb:0.0428, weight:2.00, lr:0.0002
[12:29:25.588] iteration:24105  t-loss:0.1295, loss-lb:0.0608, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:29:25.784] iteration:24106  t-loss:0.1694, loss-lb:0.0764, loss-ulb:0.0465, weight:2.00, lr:0.0002
[12:29:25.977] iteration:24107  t-loss:0.1282, loss-lb:0.0670, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:29:26.169] iteration:24108  t-loss:0.1602, loss-lb:0.0717, loss-ulb:0.0443, weight:2.00, lr:0.0002
[12:29:26.751] iteration:24109  t-loss:0.1365, loss-lb:0.0706, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:29:26.947] iteration:24110  t-loss:0.1518, loss-lb:0.0729, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:29:27.141] iteration:24111  t-loss:0.1432, loss-lb:0.0690, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:29:27.333] iteration:24112  t-loss:0.1569, loss-lb:0.0883, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:29:27.525] iteration:24113  t-loss:0.1396, loss-lb:0.0800, loss-ulb:0.0298, weight:2.00, lr:0.0002
[12:29:27.718] iteration:24114  t-loss:0.1354, loss-lb:0.0672, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:29:27.910] iteration:24115  t-loss:0.1369, loss-lb:0.0694, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:29:28.101] iteration:24116  t-loss:0.1609, loss-lb:0.0739, loss-ulb:0.0435, weight:2.00, lr:0.0002
[12:29:28.295] iteration:24117  t-loss:0.1647, loss-lb:0.0771, loss-ulb:0.0438, weight:2.00, lr:0.0002
[12:29:28.487] iteration:24118  t-loss:0.1453, loss-lb:0.0704, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:29:28.679] iteration:24119  t-loss:0.3140, loss-lb:0.0687, loss-ulb:0.1226, weight:2.00, lr:0.0002
[12:29:28.871] iteration:24120  t-loss:0.1496, loss-lb:0.0818, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:29:29.064] iteration:24121  t-loss:0.1604, loss-lb:0.0749, loss-ulb:0.0427, weight:2.00, lr:0.0002
[12:29:29.256] iteration:24122  t-loss:0.1356, loss-lb:0.0709, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:29:29.447] iteration:24123  t-loss:0.1382, loss-lb:0.0739, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:29:29.648] iteration:24124  t-loss:0.1325, loss-lb:0.0651, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:29:29.851] iteration:24125  t-loss:0.1385, loss-lb:0.0741, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:29:30.046] iteration:24126  t-loss:0.1516, loss-lb:0.0765, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:29:30.239] iteration:24127  t-loss:0.1405, loss-lb:0.0785, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:29:30.432] iteration:24128  t-loss:0.1420, loss-lb:0.0696, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:29:30.625] iteration:24129  t-loss:0.1490, loss-lb:0.0766, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:29:30.816] iteration:24130  t-loss:0.1520, loss-lb:0.0773, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:29:31.008] iteration:24131  t-loss:0.1450, loss-lb:0.0684, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:29:31.200] iteration:24132  t-loss:0.1375, loss-lb:0.0644, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:29:31.392] iteration:24133  t-loss:0.1560, loss-lb:0.0810, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:29:31.584] iteration:24134  t-loss:0.1641, loss-lb:0.0737, loss-ulb:0.0452, weight:2.00, lr:0.0002
[12:29:31.784] iteration:24135  t-loss:0.1947, loss-lb:0.0730, loss-ulb:0.0608, weight:2.00, lr:0.0002
[12:29:31.977] iteration:24136  t-loss:0.1504, loss-lb:0.0739, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:29:32.169] iteration:24137  t-loss:0.1377, loss-lb:0.0728, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:29:32.362] iteration:24138  t-loss:0.1478, loss-lb:0.0785, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:29:32.554] iteration:24139  t-loss:0.1458, loss-lb:0.0700, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:29:32.746] iteration:24140  t-loss:0.1516, loss-lb:0.0759, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:29:32.937] iteration:24141  t-loss:0.1403, loss-lb:0.0743, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:29:33.128] iteration:24142  t-loss:0.1934, loss-lb:0.0682, loss-ulb:0.0626, weight:2.00, lr:0.0002
[12:29:33.322] iteration:24143  t-loss:0.1462, loss-lb:0.0754, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:29:33.514] iteration:24144  t-loss:0.1391, loss-lb:0.0768, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:29:33.705] iteration:24145  t-loss:0.1357, loss-lb:0.0710, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:29:33.896] iteration:24146  t-loss:0.1330, loss-lb:0.0692, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:29:34.087] iteration:24147  t-loss:0.1337, loss-lb:0.0689, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:29:34.278] iteration:24148  t-loss:0.1434, loss-lb:0.0817, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:29:34.468] iteration:24149  t-loss:0.1444, loss-lb:0.0719, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:29:34.660] iteration:24150  t-loss:0.1431, loss-lb:0.0752, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:29:34.851] iteration:24151  t-loss:0.1391, loss-lb:0.0715, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:29:35.043] iteration:24152  t-loss:0.1395, loss-lb:0.0692, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:29:35.235] iteration:24153  t-loss:0.1357, loss-lb:0.0729, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:29:35.426] iteration:24154  t-loss:0.1350, loss-lb:0.0703, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:29:35.618] iteration:24155  t-loss:0.1419, loss-lb:0.0700, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:29:35.809] iteration:24156  t-loss:0.1466, loss-lb:0.0684, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:29:35.999] iteration:24157  t-loss:0.1614, loss-lb:0.0741, loss-ulb:0.0437, weight:2.00, lr:0.0002
[12:29:36.192] iteration:24158  t-loss:0.1372, loss-lb:0.0661, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:29:36.386] iteration:24159  t-loss:0.1330, loss-lb:0.0708, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:29:36.583] iteration:24160  t-loss:0.1489, loss-lb:0.0693, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:29:36.779] iteration:24161  t-loss:0.1509, loss-lb:0.0769, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:29:36.972] iteration:24162  t-loss:0.1394, loss-lb:0.0781, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:29:37.163] iteration:24163  t-loss:0.1291, loss-lb:0.0638, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:29:37.356] iteration:24164  t-loss:0.1860, loss-lb:0.0804, loss-ulb:0.0528, weight:2.00, lr:0.0002
[12:29:37.549] iteration:24165  t-loss:0.1467, loss-lb:0.0758, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:29:37.740] iteration:24166  t-loss:0.1346, loss-lb:0.0713, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:29:37.932] iteration:24167  t-loss:0.1384, loss-lb:0.0709, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:29:38.125] iteration:24168  t-loss:0.1699, loss-lb:0.0764, loss-ulb:0.0467, weight:2.00, lr:0.0002
[12:29:38.318] iteration:24169  t-loss:0.1369, loss-lb:0.0686, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:29:38.511] iteration:24170  t-loss:0.1405, loss-lb:0.0744, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:29:38.706] iteration:24171  t-loss:0.1542, loss-lb:0.0699, loss-ulb:0.0422, weight:2.00, lr:0.0002
[12:29:38.898] iteration:24172  t-loss:0.1315, loss-lb:0.0680, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:29:39.091] iteration:24173  t-loss:0.1885, loss-lb:0.0810, loss-ulb:0.0538, weight:2.00, lr:0.0002
[12:29:39.283] iteration:24174  t-loss:0.1518, loss-lb:0.0849, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:29:39.475] iteration:24175  t-loss:0.1729, loss-lb:0.0759, loss-ulb:0.0485, weight:2.00, lr:0.0002
[12:29:39.668] iteration:24176  t-loss:0.1539, loss-lb:0.0672, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:29:39.859] iteration:24177  t-loss:0.1378, loss-lb:0.0725, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:29:40.052] iteration:24178  t-loss:0.1612, loss-lb:0.0730, loss-ulb:0.0441, weight:2.00, lr:0.0002
[12:29:40.246] iteration:24179  t-loss:0.2057, loss-lb:0.0735, loss-ulb:0.0661, weight:2.00, lr:0.0002
[12:29:40.438] iteration:24180  t-loss:0.1453, loss-lb:0.0712, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:29:40.630] iteration:24181  t-loss:0.1361, loss-lb:0.0724, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:29:40.822] iteration:24182  t-loss:0.1393, loss-lb:0.0747, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:29:41.014] iteration:24183  t-loss:0.1364, loss-lb:0.0711, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:29:41.207] iteration:24184  t-loss:0.1401, loss-lb:0.0755, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:29:41.399] iteration:24185  t-loss:0.1434, loss-lb:0.0741, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:29:41.591] iteration:24186  t-loss:0.1544, loss-lb:0.0772, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:29:41.783] iteration:24187  t-loss:0.1363, loss-lb:0.0727, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:29:41.975] iteration:24188  t-loss:0.1373, loss-lb:0.0711, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:29:42.168] iteration:24189  t-loss:0.1302, loss-lb:0.0661, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:29:42.359] iteration:24190  t-loss:0.1405, loss-lb:0.0696, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:29:42.551] iteration:24191  t-loss:0.1514, loss-lb:0.0740, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:29:42.743] iteration:24192  t-loss:0.1314, loss-lb:0.0673, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:29:42.936] iteration:24193  t-loss:0.1641, loss-lb:0.0716, loss-ulb:0.0462, weight:2.00, lr:0.0002
[12:29:43.129] iteration:24194  t-loss:0.1362, loss-lb:0.0667, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:29:43.321] iteration:24195  t-loss:0.1550, loss-lb:0.0761, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:29:43.512] iteration:24196  t-loss:0.1443, loss-lb:0.0764, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:29:43.705] iteration:24197  t-loss:0.1378, loss-lb:0.0726, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:29:43.897] iteration:24198  t-loss:0.1430, loss-lb:0.0710, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:29:44.090] iteration:24199  t-loss:0.1638, loss-lb:0.0788, loss-ulb:0.0425, weight:2.00, lr:0.0002
[12:29:44.280] iteration:24200  t-loss:0.1461, loss-lb:0.0725, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:29:44.471] iteration:24201  t-loss:0.1469, loss-lb:0.0769, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:29:44.660] iteration:24202  t-loss:0.1641, loss-lb:0.0759, loss-ulb:0.0441, weight:2.00, lr:0.0002
[12:29:44.850] iteration:24203  t-loss:0.1334, loss-lb:0.0692, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:29:45.040] iteration:24204  t-loss:0.1610, loss-lb:0.0759, loss-ulb:0.0425, weight:2.00, lr:0.0002
[12:29:45.230] iteration:24205  t-loss:0.1390, loss-lb:0.0696, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:29:45.420] iteration:24206  t-loss:0.2058, loss-lb:0.0684, loss-ulb:0.0687, weight:2.00, lr:0.0002
[12:29:58.109]  <<Test>> - Ep:246  - mean_dice/mean_h95 - S:90.00/1.33, Best-S:90.99, T:89.91/1.29, Best-T:90.48
[12:29:58.109]           - AvgLoss(lb/ulb/all):0.0730/0.0381/0.1484
[12:29:58.673] iteration:24207  t-loss:0.1610, loss-lb:0.0727, loss-ulb:0.0441, weight:2.00, lr:0.0002
[12:29:58.870] iteration:24208  t-loss:0.1366, loss-lb:0.0682, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:29:59.065] iteration:24209  t-loss:0.1651, loss-lb:0.0755, loss-ulb:0.0448, weight:2.00, lr:0.0002
[12:29:59.260] iteration:24210  t-loss:0.1767, loss-lb:0.0779, loss-ulb:0.0494, weight:2.00, lr:0.0002
[12:29:59.454] iteration:24211  t-loss:0.1527, loss-lb:0.0813, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:29:59.649] iteration:24212  t-loss:0.1443, loss-lb:0.0733, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:29:59.843] iteration:24213  t-loss:0.1460, loss-lb:0.0754, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:30:00.039] iteration:24214  t-loss:0.2122, loss-lb:0.0652, loss-ulb:0.0735, weight:2.00, lr:0.0002
[12:30:00.233] iteration:24215  t-loss:0.1412, loss-lb:0.0694, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:30:00.426] iteration:24216  t-loss:0.1475, loss-lb:0.0687, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:30:00.618] iteration:24217  t-loss:0.1436, loss-lb:0.0687, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:30:00.811] iteration:24218  t-loss:0.1528, loss-lb:0.0842, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:30:01.006] iteration:24219  t-loss:0.1435, loss-lb:0.0823, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:30:01.200] iteration:24220  t-loss:0.1565, loss-lb:0.0772, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:30:01.392] iteration:24221  t-loss:0.1339, loss-lb:0.0675, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:30:01.586] iteration:24222  t-loss:0.1349, loss-lb:0.0689, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:30:01.779] iteration:24223  t-loss:0.1490, loss-lb:0.0769, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:30:01.970] iteration:24224  t-loss:0.1354, loss-lb:0.0690, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:30:02.163] iteration:24225  t-loss:0.1395, loss-lb:0.0679, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:30:02.356] iteration:24226  t-loss:0.1508, loss-lb:0.0747, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:30:02.563] iteration:24227  t-loss:0.1701, loss-lb:0.0754, loss-ulb:0.0474, weight:2.00, lr:0.0002
[12:30:02.761] iteration:24228  t-loss:0.1409, loss-lb:0.0781, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:30:02.954] iteration:24229  t-loss:0.1322, loss-lb:0.0735, loss-ulb:0.0294, weight:2.00, lr:0.0002
[12:30:03.147] iteration:24230  t-loss:0.1425, loss-lb:0.0694, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:30:03.340] iteration:24231  t-loss:0.1555, loss-lb:0.0708, loss-ulb:0.0424, weight:2.00, lr:0.0002
[12:30:03.532] iteration:24232  t-loss:0.1384, loss-lb:0.0690, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:30:03.725] iteration:24233  t-loss:0.1454, loss-lb:0.0725, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:30:03.918] iteration:24234  t-loss:0.1507, loss-lb:0.0763, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:30:04.110] iteration:24235  t-loss:0.1413, loss-lb:0.0691, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:30:04.303] iteration:24236  t-loss:0.1375, loss-lb:0.0696, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:30:04.496] iteration:24237  t-loss:0.1557, loss-lb:0.0694, loss-ulb:0.0432, weight:2.00, lr:0.0002
[12:30:04.687] iteration:24238  t-loss:0.1570, loss-lb:0.0775, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:30:04.880] iteration:24239  t-loss:0.1444, loss-lb:0.0696, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:30:05.073] iteration:24240  t-loss:0.1382, loss-lb:0.0743, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:30:05.266] iteration:24241  t-loss:0.1508, loss-lb:0.0732, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:30:05.460] iteration:24242  t-loss:0.1422, loss-lb:0.0689, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:30:05.652] iteration:24243  t-loss:0.1516, loss-lb:0.0740, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:30:05.845] iteration:24244  t-loss:0.1881, loss-lb:0.0717, loss-ulb:0.0582, weight:2.00, lr:0.0002
[12:30:06.037] iteration:24245  t-loss:0.1389, loss-lb:0.0688, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:30:06.230] iteration:24246  t-loss:0.1440, loss-lb:0.0774, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:30:06.422] iteration:24247  t-loss:0.1751, loss-lb:0.0751, loss-ulb:0.0500, weight:2.00, lr:0.0002
[12:30:06.616] iteration:24248  t-loss:0.1696, loss-lb:0.0797, loss-ulb:0.0449, weight:2.00, lr:0.0002
[12:30:06.809] iteration:24249  t-loss:0.1380, loss-lb:0.0736, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:30:07.003] iteration:24250  t-loss:0.1682, loss-lb:0.0715, loss-ulb:0.0484, weight:2.00, lr:0.0002
[12:30:07.196] iteration:24251  t-loss:0.1311, loss-lb:0.0674, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:30:07.388] iteration:24252  t-loss:0.1365, loss-lb:0.0678, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:30:07.581] iteration:24253  t-loss:0.2598, loss-lb:0.0671, loss-ulb:0.0963, weight:2.00, lr:0.0002
[12:30:07.774] iteration:24254  t-loss:0.1384, loss-lb:0.0687, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:30:07.965] iteration:24255  t-loss:0.1555, loss-lb:0.0804, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:30:08.159] iteration:24256  t-loss:0.1425, loss-lb:0.0730, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:30:08.351] iteration:24257  t-loss:0.1383, loss-lb:0.0724, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:30:08.543] iteration:24258  t-loss:0.1290, loss-lb:0.0720, loss-ulb:0.0285, weight:2.00, lr:0.0002
[12:30:08.735] iteration:24259  t-loss:0.1428, loss-lb:0.0743, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:30:08.928] iteration:24260  t-loss:0.2048, loss-lb:0.0717, loss-ulb:0.0666, weight:2.00, lr:0.0002
[12:30:09.120] iteration:24261  t-loss:0.1362, loss-lb:0.0744, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:30:09.312] iteration:24262  t-loss:0.1434, loss-lb:0.0759, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:30:09.505] iteration:24263  t-loss:0.1569, loss-lb:0.0767, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:30:09.699] iteration:24264  t-loss:0.1426, loss-lb:0.0709, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:30:09.892] iteration:24265  t-loss:0.1634, loss-lb:0.0748, loss-ulb:0.0443, weight:2.00, lr:0.0002
[12:30:10.083] iteration:24266  t-loss:0.1496, loss-lb:0.0740, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:30:10.277] iteration:24267  t-loss:0.1344, loss-lb:0.0670, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:30:10.470] iteration:24268  t-loss:0.1354, loss-lb:0.0695, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:30:10.662] iteration:24269  t-loss:0.1409, loss-lb:0.0687, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:30:10.855] iteration:24270  t-loss:0.1474, loss-lb:0.0803, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:30:11.049] iteration:24271  t-loss:0.1562, loss-lb:0.0820, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:30:11.242] iteration:24272  t-loss:0.1418, loss-lb:0.0757, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:30:11.434] iteration:24273  t-loss:0.1477, loss-lb:0.0721, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:30:11.627] iteration:24274  t-loss:0.1451, loss-lb:0.0714, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:30:11.820] iteration:24275  t-loss:0.1442, loss-lb:0.0782, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:30:12.014] iteration:24276  t-loss:0.1312, loss-lb:0.0684, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:30:12.206] iteration:24277  t-loss:0.1440, loss-lb:0.0649, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:30:12.399] iteration:24278  t-loss:0.1482, loss-lb:0.0737, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:30:12.591] iteration:24279  t-loss:0.1631, loss-lb:0.0824, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:30:12.783] iteration:24280  t-loss:0.1491, loss-lb:0.0754, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:30:12.976] iteration:24281  t-loss:0.1833, loss-lb:0.0797, loss-ulb:0.0518, weight:2.00, lr:0.0002
[12:30:13.169] iteration:24282  t-loss:0.1601, loss-lb:0.0815, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:30:13.361] iteration:24283  t-loss:0.1959, loss-lb:0.0721, loss-ulb:0.0619, weight:2.00, lr:0.0002
[12:30:13.554] iteration:24284  t-loss:0.1347, loss-lb:0.0699, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:30:13.746] iteration:24285  t-loss:0.1362, loss-lb:0.0695, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:30:13.940] iteration:24286  t-loss:0.1835, loss-lb:0.0786, loss-ulb:0.0525, weight:2.00, lr:0.0002
[12:30:14.133] iteration:24287  t-loss:0.1521, loss-lb:0.0736, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:30:14.325] iteration:24288  t-loss:0.1818, loss-lb:0.0772, loss-ulb:0.0523, weight:2.00, lr:0.0002
[12:30:14.517] iteration:24289  t-loss:0.1549, loss-lb:0.0680, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:30:14.709] iteration:24290  t-loss:0.1443, loss-lb:0.0751, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:30:14.902] iteration:24291  t-loss:0.1670, loss-lb:0.0727, loss-ulb:0.0471, weight:2.00, lr:0.0002
[12:30:15.094] iteration:24292  t-loss:0.1519, loss-lb:0.0745, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:30:15.286] iteration:24293  t-loss:0.1599, loss-lb:0.0808, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:30:15.480] iteration:24294  t-loss:0.1458, loss-lb:0.0776, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:30:15.672] iteration:24295  t-loss:0.1431, loss-lb:0.0753, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:30:15.864] iteration:24296  t-loss:0.1511, loss-lb:0.0745, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:30:16.056] iteration:24297  t-loss:0.1426, loss-lb:0.0745, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:30:16.246] iteration:24298  t-loss:0.1461, loss-lb:0.0765, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:30:16.437] iteration:24299  t-loss:0.1579, loss-lb:0.0746, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:30:16.628] iteration:24300  t-loss:0.2019, loss-lb:0.0823, loss-ulb:0.0598, weight:2.00, lr:0.0002
[12:30:16.819] iteration:24301  t-loss:0.1457, loss-lb:0.0709, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:30:17.009] iteration:24302  t-loss:0.1537, loss-lb:0.0858, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:30:17.200] iteration:24303  t-loss:0.1388, loss-lb:0.0663, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:30:17.390] iteration:24304  t-loss:0.1591, loss-lb:0.0773, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:30:17.993] iteration:24305  t-loss:0.1437, loss-lb:0.0793, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:30:18.191] iteration:24306  t-loss:0.1703, loss-lb:0.0852, loss-ulb:0.0425, weight:2.00, lr:0.0002
[12:30:18.384] iteration:24307  t-loss:0.1686, loss-lb:0.0724, loss-ulb:0.0481, weight:2.00, lr:0.0002
[12:30:18.575] iteration:24308  t-loss:0.1466, loss-lb:0.0745, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:30:18.769] iteration:24309  t-loss:0.1382, loss-lb:0.0757, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:30:18.961] iteration:24310  t-loss:0.1472, loss-lb:0.0690, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:30:19.152] iteration:24311  t-loss:0.1408, loss-lb:0.0782, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:30:19.345] iteration:24312  t-loss:0.1476, loss-lb:0.0761, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:30:19.538] iteration:24313  t-loss:0.1411, loss-lb:0.0734, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:30:19.731] iteration:24314  t-loss:0.1405, loss-lb:0.0719, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:30:19.925] iteration:24315  t-loss:0.1381, loss-lb:0.0706, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:30:20.118] iteration:24316  t-loss:0.1580, loss-lb:0.0726, loss-ulb:0.0427, weight:2.00, lr:0.0002
[12:30:20.311] iteration:24317  t-loss:0.1718, loss-lb:0.0701, loss-ulb:0.0508, weight:2.00, lr:0.0002
[12:30:20.504] iteration:24318  t-loss:0.1403, loss-lb:0.0694, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:30:20.697] iteration:24319  t-loss:0.1440, loss-lb:0.0751, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:30:20.889] iteration:24320  t-loss:0.1378, loss-lb:0.0711, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:30:21.082] iteration:24321  t-loss:0.1486, loss-lb:0.0754, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:30:21.274] iteration:24322  t-loss:0.1534, loss-lb:0.0856, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:30:21.468] iteration:24323  t-loss:0.1296, loss-lb:0.0781, loss-ulb:0.0258, weight:2.00, lr:0.0002
[12:30:21.661] iteration:24324  t-loss:0.1432, loss-lb:0.0716, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:30:21.854] iteration:24325  t-loss:0.1492, loss-lb:0.0771, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:30:22.046] iteration:24326  t-loss:0.1685, loss-lb:0.0882, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:30:22.239] iteration:24327  t-loss:0.1403, loss-lb:0.0715, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:30:22.431] iteration:24328  t-loss:0.1385, loss-lb:0.0731, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:30:22.624] iteration:24329  t-loss:0.1417, loss-lb:0.0685, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:30:22.817] iteration:24330  t-loss:0.1660, loss-lb:0.0790, loss-ulb:0.0435, weight:2.00, lr:0.0002
[12:30:23.009] iteration:24331  t-loss:0.1453, loss-lb:0.0773, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:30:23.201] iteration:24332  t-loss:0.1525, loss-lb:0.0862, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:30:23.396] iteration:24333  t-loss:0.1693, loss-lb:0.0739, loss-ulb:0.0477, weight:2.00, lr:0.0002
[12:30:23.588] iteration:24334  t-loss:0.1445, loss-lb:0.0694, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:30:23.780] iteration:24335  t-loss:0.1528, loss-lb:0.0716, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:30:23.973] iteration:24336  t-loss:0.1469, loss-lb:0.0818, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:30:24.166] iteration:24337  t-loss:0.2315, loss-lb:0.0665, loss-ulb:0.0825, weight:2.00, lr:0.0002
[12:30:24.359] iteration:24338  t-loss:0.1462, loss-lb:0.0655, loss-ulb:0.0404, weight:2.00, lr:0.0002
[12:30:24.553] iteration:24339  t-loss:0.1480, loss-lb:0.0720, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:30:24.747] iteration:24340  t-loss:0.1488, loss-lb:0.0730, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:30:24.939] iteration:24341  t-loss:0.1350, loss-lb:0.0733, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:30:25.131] iteration:24342  t-loss:0.1390, loss-lb:0.0736, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:30:25.324] iteration:24343  t-loss:0.1375, loss-lb:0.0740, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:30:25.516] iteration:24344  t-loss:0.1524, loss-lb:0.0829, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:30:25.708] iteration:24345  t-loss:0.1398, loss-lb:0.0717, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:30:25.902] iteration:24346  t-loss:0.1413, loss-lb:0.0718, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:30:26.094] iteration:24347  t-loss:0.1588, loss-lb:0.0724, loss-ulb:0.0432, weight:2.00, lr:0.0002
[12:30:26.286] iteration:24348  t-loss:0.1406, loss-lb:0.0679, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:30:26.480] iteration:24349  t-loss:0.1442, loss-lb:0.0703, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:30:26.673] iteration:24350  t-loss:0.1373, loss-lb:0.0717, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:30:26.865] iteration:24351  t-loss:0.1364, loss-lb:0.0691, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:30:27.058] iteration:24352  t-loss:0.2234, loss-lb:0.0696, loss-ulb:0.0769, weight:2.00, lr:0.0002
[12:30:27.251] iteration:24353  t-loss:0.1479, loss-lb:0.0748, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:30:27.445] iteration:24354  t-loss:0.1422, loss-lb:0.0689, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:30:27.637] iteration:24355  t-loss:0.1440, loss-lb:0.0704, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:30:27.829] iteration:24356  t-loss:0.1367, loss-lb:0.0720, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:30:28.023] iteration:24357  t-loss:0.1612, loss-lb:0.0772, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:30:28.215] iteration:24358  t-loss:0.1450, loss-lb:0.0709, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:30:28.407] iteration:24359  t-loss:0.1683, loss-lb:0.0685, loss-ulb:0.0499, weight:2.00, lr:0.0002
[12:30:28.600] iteration:24360  t-loss:0.1521, loss-lb:0.0726, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:30:28.792] iteration:24361  t-loss:0.1564, loss-lb:0.0853, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:30:28.986] iteration:24362  t-loss:0.1596, loss-lb:0.0719, loss-ulb:0.0438, weight:2.00, lr:0.0002
[12:30:29.178] iteration:24363  t-loss:0.1608, loss-lb:0.0708, loss-ulb:0.0450, weight:2.00, lr:0.0002
[12:30:29.372] iteration:24364  t-loss:0.1369, loss-lb:0.0697, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:30:29.564] iteration:24365  t-loss:0.1445, loss-lb:0.0670, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:30:29.756] iteration:24366  t-loss:0.1448, loss-lb:0.0697, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:30:29.949] iteration:24367  t-loss:0.1423, loss-lb:0.0775, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:30:30.142] iteration:24368  t-loss:0.1448, loss-lb:0.0733, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:30:30.333] iteration:24369  t-loss:0.1539, loss-lb:0.0837, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:30:30.525] iteration:24370  t-loss:0.1334, loss-lb:0.0668, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:30:30.719] iteration:24371  t-loss:0.2101, loss-lb:0.0814, loss-ulb:0.0644, weight:2.00, lr:0.0002
[12:30:30.912] iteration:24372  t-loss:0.1421, loss-lb:0.0727, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:30:31.104] iteration:24373  t-loss:0.1613, loss-lb:0.0716, loss-ulb:0.0449, weight:2.00, lr:0.0002
[12:30:31.297] iteration:24374  t-loss:0.1491, loss-lb:0.0714, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:30:31.490] iteration:24375  t-loss:0.1362, loss-lb:0.0687, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:30:31.682] iteration:24376  t-loss:0.1565, loss-lb:0.0788, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:30:31.875] iteration:24377  t-loss:0.1539, loss-lb:0.0786, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:30:32.066] iteration:24378  t-loss:0.1447, loss-lb:0.0731, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:30:32.259] iteration:24379  t-loss:0.1379, loss-lb:0.0720, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:30:32.451] iteration:24380  t-loss:0.1456, loss-lb:0.0759, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:30:32.643] iteration:24381  t-loss:0.1467, loss-lb:0.0801, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:30:32.836] iteration:24382  t-loss:0.1311, loss-lb:0.0672, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:30:33.028] iteration:24383  t-loss:0.1319, loss-lb:0.0733, loss-ulb:0.0293, weight:2.00, lr:0.0002
[12:30:33.222] iteration:24384  t-loss:0.1454, loss-lb:0.0739, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:30:33.414] iteration:24385  t-loss:0.1373, loss-lb:0.0681, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:30:33.606] iteration:24386  t-loss:0.1328, loss-lb:0.0725, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:30:33.800] iteration:24387  t-loss:0.1461, loss-lb:0.0706, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:30:33.993] iteration:24388  t-loss:0.1944, loss-lb:0.0670, loss-ulb:0.0637, weight:2.00, lr:0.0002
[12:30:34.187] iteration:24389  t-loss:0.1366, loss-lb:0.0733, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:30:34.380] iteration:24390  t-loss:0.1470, loss-lb:0.0778, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:30:34.573] iteration:24391  t-loss:0.1471, loss-lb:0.0753, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:30:34.765] iteration:24392  t-loss:0.1400, loss-lb:0.0673, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:30:34.957] iteration:24393  t-loss:0.1396, loss-lb:0.0761, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:30:35.153] iteration:24394  t-loss:0.1681, loss-lb:0.0752, loss-ulb:0.0464, weight:2.00, lr:0.0002
[12:30:35.357] iteration:24395  t-loss:0.1377, loss-lb:0.0705, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:30:35.554] iteration:24396  t-loss:0.1790, loss-lb:0.0842, loss-ulb:0.0474, weight:2.00, lr:0.0002
[12:30:35.745] iteration:24397  t-loss:0.1455, loss-lb:0.0743, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:30:35.937] iteration:24398  t-loss:0.1830, loss-lb:0.0795, loss-ulb:0.0517, weight:2.00, lr:0.0002
[12:30:36.128] iteration:24399  t-loss:0.1391, loss-lb:0.0755, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:30:36.319] iteration:24400  t-loss:0.1430, loss-lb:0.0731, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:30:36.510] iteration:24401  t-loss:0.1218, loss-lb:0.0599, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:30:36.701] iteration:24402  t-loss:0.1382, loss-lb:0.0729, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:30:49.200]  <<Test>> - Ep:248  - mean_dice/mean_h95 - S:89.86/1.29, Best-S:90.99, T:89.68/1.33, Best-T:90.48
[12:30:49.200]           - AvgLoss(lb/ulb/all):0.0737/0.0373/0.1477
[12:30:49.800] iteration:24403  t-loss:0.1439, loss-lb:0.0766, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:30:49.998] iteration:24404  t-loss:0.1624, loss-lb:0.0761, loss-ulb:0.0432, weight:2.00, lr:0.0002
[12:30:50.191] iteration:24405  t-loss:0.1954, loss-lb:0.0751, loss-ulb:0.0602, weight:2.00, lr:0.0002
[12:30:50.384] iteration:24406  t-loss:0.1354, loss-lb:0.0707, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:30:50.576] iteration:24407  t-loss:0.1414, loss-lb:0.0723, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:30:50.769] iteration:24408  t-loss:0.1643, loss-lb:0.0777, loss-ulb:0.0433, weight:2.00, lr:0.0002
[12:30:50.963] iteration:24409  t-loss:0.1248, loss-lb:0.0694, loss-ulb:0.0277, weight:2.00, lr:0.0002
[12:30:51.155] iteration:24410  t-loss:0.1474, loss-lb:0.0736, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:30:51.347] iteration:24411  t-loss:0.1420, loss-lb:0.0718, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:30:51.540] iteration:24412  t-loss:0.1367, loss-lb:0.0700, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:30:51.733] iteration:24413  t-loss:0.1364, loss-lb:0.0680, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:30:51.925] iteration:24414  t-loss:0.1504, loss-lb:0.0739, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:30:52.118] iteration:24415  t-loss:0.1826, loss-lb:0.0775, loss-ulb:0.0526, weight:2.00, lr:0.0002
[12:30:52.311] iteration:24416  t-loss:0.1413, loss-lb:0.0738, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:30:52.504] iteration:24417  t-loss:0.1275, loss-lb:0.0657, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:30:52.695] iteration:24418  t-loss:0.1488, loss-lb:0.0751, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:30:52.888] iteration:24419  t-loss:0.1332, loss-lb:0.0738, loss-ulb:0.0297, weight:2.00, lr:0.0002
[12:30:53.080] iteration:24420  t-loss:0.1731, loss-lb:0.0772, loss-ulb:0.0480, weight:2.00, lr:0.0002
[12:30:53.273] iteration:24421  t-loss:0.1454, loss-lb:0.0702, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:30:53.465] iteration:24422  t-loss:0.1395, loss-lb:0.0680, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:30:53.656] iteration:24423  t-loss:0.1458, loss-lb:0.0746, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:30:53.848] iteration:24424  t-loss:0.1552, loss-lb:0.0753, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:30:54.040] iteration:24425  t-loss:0.1452, loss-lb:0.0755, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:30:54.231] iteration:24426  t-loss:0.1409, loss-lb:0.0733, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:30:54.424] iteration:24427  t-loss:0.2484, loss-lb:0.0819, loss-ulb:0.0833, weight:2.00, lr:0.0002
[12:30:54.616] iteration:24428  t-loss:0.1797, loss-lb:0.0702, loss-ulb:0.0547, weight:2.00, lr:0.0002
[12:30:54.808] iteration:24429  t-loss:0.1575, loss-lb:0.0843, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:30:54.999] iteration:24430  t-loss:0.1496, loss-lb:0.0775, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:30:55.191] iteration:24431  t-loss:0.1380, loss-lb:0.0686, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:30:55.384] iteration:24432  t-loss:0.2205, loss-lb:0.0806, loss-ulb:0.0699, weight:2.00, lr:0.0002
[12:30:55.576] iteration:24433  t-loss:0.1439, loss-lb:0.0683, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:30:55.768] iteration:24434  t-loss:0.1462, loss-lb:0.0715, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:30:55.960] iteration:24435  t-loss:0.1519, loss-lb:0.0777, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:30:56.151] iteration:24436  t-loss:0.1388, loss-lb:0.0717, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:30:56.344] iteration:24437  t-loss:0.1926, loss-lb:0.0696, loss-ulb:0.0615, weight:2.00, lr:0.0002
[12:30:56.536] iteration:24438  t-loss:0.1519, loss-lb:0.0718, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:30:56.729] iteration:24439  t-loss:0.1456, loss-lb:0.0760, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:30:56.920] iteration:24440  t-loss:0.1439, loss-lb:0.0753, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:30:57.114] iteration:24441  t-loss:0.1520, loss-lb:0.0800, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:30:57.306] iteration:24442  t-loss:0.1630, loss-lb:0.0784, loss-ulb:0.0423, weight:2.00, lr:0.0002
[12:30:57.498] iteration:24443  t-loss:0.1380, loss-lb:0.0726, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:30:57.689] iteration:24444  t-loss:0.1835, loss-lb:0.0867, loss-ulb:0.0484, weight:2.00, lr:0.0002
[12:30:57.880] iteration:24445  t-loss:0.1590, loss-lb:0.0825, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:30:58.071] iteration:24446  t-loss:0.1447, loss-lb:0.0731, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:30:58.263] iteration:24447  t-loss:0.1649, loss-lb:0.0719, loss-ulb:0.0465, weight:2.00, lr:0.0002
[12:30:58.455] iteration:24448  t-loss:0.1341, loss-lb:0.0652, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:30:58.647] iteration:24449  t-loss:0.1456, loss-lb:0.0707, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:30:58.838] iteration:24450  t-loss:0.1752, loss-lb:0.0764, loss-ulb:0.0494, weight:2.00, lr:0.0002
[12:30:59.031] iteration:24451  t-loss:0.2240, loss-lb:0.0781, loss-ulb:0.0730, weight:2.00, lr:0.0002
[12:30:59.222] iteration:24452  t-loss:0.1553, loss-lb:0.0714, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:30:59.413] iteration:24453  t-loss:0.1493, loss-lb:0.0730, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:30:59.605] iteration:24454  t-loss:0.1666, loss-lb:0.0781, loss-ulb:0.0443, weight:2.00, lr:0.0002
[12:30:59.797] iteration:24455  t-loss:0.1429, loss-lb:0.0775, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:30:59.991] iteration:24456  t-loss:0.1830, loss-lb:0.0749, loss-ulb:0.0541, weight:2.00, lr:0.0002
[12:31:00.188] iteration:24457  t-loss:0.1585, loss-lb:0.0716, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:31:00.382] iteration:24458  t-loss:0.1610, loss-lb:0.0789, loss-ulb:0.0411, weight:2.00, lr:0.0002
[12:31:00.576] iteration:24459  t-loss:0.1362, loss-lb:0.0751, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:31:00.769] iteration:24460  t-loss:0.1496, loss-lb:0.0855, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:31:00.963] iteration:24461  t-loss:0.1827, loss-lb:0.0731, loss-ulb:0.0548, weight:2.00, lr:0.0002
[12:31:01.155] iteration:24462  t-loss:0.1510, loss-lb:0.0863, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:31:01.347] iteration:24463  t-loss:0.1547, loss-lb:0.0757, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:31:01.540] iteration:24464  t-loss:0.1435, loss-lb:0.0729, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:31:01.733] iteration:24465  t-loss:0.1476, loss-lb:0.0762, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:31:01.925] iteration:24466  t-loss:0.1653, loss-lb:0.0786, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:31:02.117] iteration:24467  t-loss:0.2059, loss-lb:0.0731, loss-ulb:0.0664, weight:2.00, lr:0.0002
[12:31:02.309] iteration:24468  t-loss:0.1518, loss-lb:0.0729, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:31:02.500] iteration:24469  t-loss:0.1412, loss-lb:0.0727, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:31:02.693] iteration:24470  t-loss:0.1758, loss-lb:0.0748, loss-ulb:0.0505, weight:2.00, lr:0.0002
[12:31:02.885] iteration:24471  t-loss:0.1439, loss-lb:0.0744, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:31:03.077] iteration:24472  t-loss:0.1454, loss-lb:0.0779, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:31:03.270] iteration:24473  t-loss:0.1437, loss-lb:0.0782, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:31:03.462] iteration:24474  t-loss:0.1665, loss-lb:0.1012, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:31:03.654] iteration:24475  t-loss:0.1827, loss-lb:0.0762, loss-ulb:0.0532, weight:2.00, lr:0.0002
[12:31:03.845] iteration:24476  t-loss:0.1422, loss-lb:0.0683, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:31:04.038] iteration:24477  t-loss:0.1517, loss-lb:0.0746, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:31:04.230] iteration:24478  t-loss:0.1633, loss-lb:0.0797, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:31:04.423] iteration:24479  t-loss:0.1509, loss-lb:0.0732, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:31:04.614] iteration:24480  t-loss:0.1324, loss-lb:0.0759, loss-ulb:0.0282, weight:2.00, lr:0.0002
[12:31:04.805] iteration:24481  t-loss:0.1510, loss-lb:0.0797, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:31:04.999] iteration:24482  t-loss:0.1401, loss-lb:0.0712, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:31:05.191] iteration:24483  t-loss:0.1550, loss-lb:0.0706, loss-ulb:0.0422, weight:2.00, lr:0.0002
[12:31:05.383] iteration:24484  t-loss:0.1512, loss-lb:0.0832, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:31:05.577] iteration:24485  t-loss:0.1624, loss-lb:0.0694, loss-ulb:0.0465, weight:2.00, lr:0.0002
[12:31:05.769] iteration:24486  t-loss:0.1335, loss-lb:0.0701, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:31:05.962] iteration:24487  t-loss:0.1453, loss-lb:0.0765, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:31:06.154] iteration:24488  t-loss:0.1367, loss-lb:0.0659, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:31:06.346] iteration:24489  t-loss:0.1416, loss-lb:0.0749, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:31:06.538] iteration:24490  t-loss:0.1469, loss-lb:0.0751, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:31:06.730] iteration:24491  t-loss:0.1466, loss-lb:0.0812, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:31:06.923] iteration:24492  t-loss:0.1498, loss-lb:0.0726, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:31:07.115] iteration:24493  t-loss:0.1521, loss-lb:0.0760, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:31:07.307] iteration:24494  t-loss:0.1501, loss-lb:0.0794, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:31:07.499] iteration:24495  t-loss:0.1598, loss-lb:0.0768, loss-ulb:0.0415, weight:2.00, lr:0.0002
[12:31:07.689] iteration:24496  t-loss:0.1595, loss-lb:0.0764, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:31:07.880] iteration:24497  t-loss:0.1400, loss-lb:0.0746, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:31:08.083] iteration:24498  t-loss:0.1341, loss-lb:0.0720, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:31:08.278] iteration:24499  t-loss:0.1356, loss-lb:0.0695, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:31:08.468] iteration:24500  t-loss:0.1450, loss-lb:0.0704, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:31:09.046] iteration:24501  t-loss:0.1512, loss-lb:0.0818, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:31:09.241] iteration:24502  t-loss:0.1524, loss-lb:0.0782, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:31:09.433] iteration:24503  t-loss:0.1411, loss-lb:0.0663, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:31:09.625] iteration:24504  t-loss:0.1384, loss-lb:0.0787, loss-ulb:0.0299, weight:2.00, lr:0.0002
[12:31:09.816] iteration:24505  t-loss:0.1499, loss-lb:0.0757, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:31:10.008] iteration:24506  t-loss:0.1460, loss-lb:0.0759, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:31:10.199] iteration:24507  t-loss:0.1498, loss-lb:0.0734, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:31:10.390] iteration:24508  t-loss:0.1644, loss-lb:0.0643, loss-ulb:0.0501, weight:2.00, lr:0.0002
[12:31:10.583] iteration:24509  t-loss:0.1338, loss-lb:0.0693, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:31:10.776] iteration:24510  t-loss:0.1372, loss-lb:0.0625, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:31:10.973] iteration:24511  t-loss:0.1458, loss-lb:0.0723, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:31:11.169] iteration:24512  t-loss:0.1437, loss-lb:0.0749, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:31:11.361] iteration:24513  t-loss:0.1360, loss-lb:0.0703, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:31:11.553] iteration:24514  t-loss:0.1475, loss-lb:0.0811, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:31:11.747] iteration:24515  t-loss:0.1396, loss-lb:0.0713, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:31:11.938] iteration:24516  t-loss:0.1366, loss-lb:0.0660, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:31:12.130] iteration:24517  t-loss:0.1605, loss-lb:0.0746, loss-ulb:0.0429, weight:2.00, lr:0.0002
[12:31:12.322] iteration:24518  t-loss:0.1504, loss-lb:0.0822, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:31:12.513] iteration:24519  t-loss:0.1248, loss-lb:0.0725, loss-ulb:0.0262, weight:2.00, lr:0.0002
[12:31:12.705] iteration:24520  t-loss:0.1476, loss-lb:0.0773, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:31:12.898] iteration:24521  t-loss:0.1400, loss-lb:0.0703, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:31:13.089] iteration:24522  t-loss:0.1365, loss-lb:0.0710, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:31:13.282] iteration:24523  t-loss:0.1684, loss-lb:0.0741, loss-ulb:0.0471, weight:2.00, lr:0.0002
[12:31:13.474] iteration:24524  t-loss:0.1288, loss-lb:0.0647, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:31:13.666] iteration:24525  t-loss:0.1450, loss-lb:0.0741, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:31:13.858] iteration:24526  t-loss:0.1534, loss-lb:0.0701, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:31:14.051] iteration:24527  t-loss:0.2847, loss-lb:0.0756, loss-ulb:0.1045, weight:2.00, lr:0.0002
[12:31:14.245] iteration:24528  t-loss:0.1778, loss-lb:0.0744, loss-ulb:0.0517, weight:2.00, lr:0.0002
[12:31:14.436] iteration:24529  t-loss:0.1474, loss-lb:0.0792, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:31:14.627] iteration:24530  t-loss:0.1621, loss-lb:0.0757, loss-ulb:0.0432, weight:2.00, lr:0.0002
[12:31:14.820] iteration:24531  t-loss:0.1442, loss-lb:0.0685, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:31:15.011] iteration:24532  t-loss:0.1467, loss-lb:0.0712, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:31:15.205] iteration:24533  t-loss:0.1395, loss-lb:0.0667, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:31:15.397] iteration:24534  t-loss:0.1442, loss-lb:0.0669, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:31:15.590] iteration:24535  t-loss:0.1348, loss-lb:0.0758, loss-ulb:0.0295, weight:2.00, lr:0.0002
[12:31:15.782] iteration:24536  t-loss:0.1406, loss-lb:0.0728, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:31:15.974] iteration:24537  t-loss:0.1750, loss-lb:0.0912, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:31:16.174] iteration:24538  t-loss:0.1541, loss-lb:0.0751, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:31:16.366] iteration:24539  t-loss:0.1480, loss-lb:0.0749, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:31:16.559] iteration:24540  t-loss:0.1411, loss-lb:0.0719, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:31:16.751] iteration:24541  t-loss:0.2972, loss-lb:0.0691, loss-ulb:0.1141, weight:2.00, lr:0.0002
[12:31:16.951] iteration:24542  t-loss:0.1861, loss-lb:0.0754, loss-ulb:0.0553, weight:2.00, lr:0.0002
[12:31:17.144] iteration:24543  t-loss:0.1467, loss-lb:0.0806, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:31:17.336] iteration:24544  t-loss:0.1449, loss-lb:0.0776, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:31:17.529] iteration:24545  t-loss:0.1488, loss-lb:0.0696, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:31:17.728] iteration:24546  t-loss:0.1433, loss-lb:0.0740, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:31:17.920] iteration:24547  t-loss:0.1476, loss-lb:0.0736, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:31:18.112] iteration:24548  t-loss:0.1682, loss-lb:0.0718, loss-ulb:0.0482, weight:2.00, lr:0.0002
[12:31:18.304] iteration:24549  t-loss:0.1484, loss-lb:0.0733, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:31:18.504] iteration:24550  t-loss:0.1561, loss-lb:0.0765, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:31:18.696] iteration:24551  t-loss:0.1364, loss-lb:0.0680, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:31:18.888] iteration:24552  t-loss:0.1754, loss-lb:0.0724, loss-ulb:0.0515, weight:2.00, lr:0.0002
[12:31:19.079] iteration:24553  t-loss:0.1423, loss-lb:0.0734, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:31:19.279] iteration:24554  t-loss:0.1551, loss-lb:0.0717, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:31:19.471] iteration:24555  t-loss:0.1413, loss-lb:0.0659, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:31:19.663] iteration:24556  t-loss:0.1471, loss-lb:0.0774, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:31:19.854] iteration:24557  t-loss:0.1627, loss-lb:0.0819, loss-ulb:0.0404, weight:2.00, lr:0.0002
[12:31:20.054] iteration:24558  t-loss:0.1367, loss-lb:0.0723, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:31:20.246] iteration:24559  t-loss:0.2372, loss-lb:0.0714, loss-ulb:0.0829, weight:2.00, lr:0.0002
[12:31:20.438] iteration:24560  t-loss:0.1435, loss-lb:0.0674, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:31:20.629] iteration:24561  t-loss:0.1499, loss-lb:0.0660, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:31:20.835] iteration:24562  t-loss:0.1440, loss-lb:0.0689, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:31:21.027] iteration:24563  t-loss:0.1611, loss-lb:0.0845, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:31:21.219] iteration:24564  t-loss:0.1661, loss-lb:0.0682, loss-ulb:0.0490, weight:2.00, lr:0.0002
[12:31:21.411] iteration:24565  t-loss:0.1835, loss-lb:0.0792, loss-ulb:0.0521, weight:2.00, lr:0.0002
[12:31:21.605] iteration:24566  t-loss:0.1463, loss-lb:0.0732, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:31:21.800] iteration:24567  t-loss:0.1373, loss-lb:0.0727, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:31:21.995] iteration:24568  t-loss:0.1441, loss-lb:0.0793, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:31:22.192] iteration:24569  t-loss:0.1475, loss-lb:0.0790, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:31:22.384] iteration:24570  t-loss:0.1308, loss-lb:0.0682, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:31:22.578] iteration:24571  t-loss:0.1589, loss-lb:0.0778, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:31:22.770] iteration:24572  t-loss:0.1588, loss-lb:0.0734, loss-ulb:0.0427, weight:2.00, lr:0.0002
[12:31:22.961] iteration:24573  t-loss:0.1422, loss-lb:0.0718, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:31:23.154] iteration:24574  t-loss:0.1397, loss-lb:0.0734, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:31:23.347] iteration:24575  t-loss:0.1527, loss-lb:0.0755, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:31:23.538] iteration:24576  t-loss:0.1549, loss-lb:0.0776, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:31:23.731] iteration:24577  t-loss:0.1714, loss-lb:0.0738, loss-ulb:0.0488, weight:2.00, lr:0.0002
[12:31:23.923] iteration:24578  t-loss:0.1478, loss-lb:0.0707, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:31:24.114] iteration:24579  t-loss:0.1366, loss-lb:0.0675, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:31:24.306] iteration:24580  t-loss:0.1345, loss-lb:0.0637, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:31:24.498] iteration:24581  t-loss:0.1295, loss-lb:0.0636, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:31:24.689] iteration:24582  t-loss:0.1368, loss-lb:0.0764, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:31:24.881] iteration:24583  t-loss:0.1362, loss-lb:0.0709, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:31:25.073] iteration:24584  t-loss:0.1427, loss-lb:0.0715, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:31:25.264] iteration:24585  t-loss:0.1333, loss-lb:0.0643, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:31:25.457] iteration:24586  t-loss:0.1436, loss-lb:0.0701, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:31:25.648] iteration:24587  t-loss:0.1297, loss-lb:0.0678, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:31:25.840] iteration:24588  t-loss:0.1453, loss-lb:0.0695, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:31:26.033] iteration:24589  t-loss:0.1724, loss-lb:0.0806, loss-ulb:0.0459, weight:2.00, lr:0.0002
[12:31:26.225] iteration:24590  t-loss:0.1500, loss-lb:0.0779, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:31:26.416] iteration:24591  t-loss:0.1323, loss-lb:0.0651, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:31:26.606] iteration:24592  t-loss:0.1488, loss-lb:0.0819, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:31:26.797] iteration:24593  t-loss:0.1301, loss-lb:0.0670, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:31:26.988] iteration:24594  t-loss:0.1347, loss-lb:0.0696, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:31:27.178] iteration:24595  t-loss:0.1421, loss-lb:0.0783, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:31:27.371] iteration:24596  t-loss:0.1438, loss-lb:0.0735, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:31:27.561] iteration:24597  t-loss:0.1314, loss-lb:0.0648, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:31:27.752] iteration:24598  t-loss:0.1476, loss-lb:0.0723, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:31:39.579]  <<Test>> - Ep:250  - mean_dice/mean_h95 - S:89.96/1.31, Best-S:90.99, T:89.72/1.33, Best-T:90.48
[12:31:39.580]           - AvgLoss(lb/ulb/all):0.0729/0.0346/0.1401
[12:31:40.107] iteration:24599  t-loss:0.1537, loss-lb:0.0769, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:31:40.305] iteration:24600  t-loss:0.1627, loss-lb:0.0743, loss-ulb:0.0442, weight:2.00, lr:0.0002
[12:31:40.498] iteration:24601  t-loss:0.1402, loss-lb:0.0695, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:31:40.694] iteration:24602  t-loss:0.1454, loss-lb:0.0752, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:31:40.900] iteration:24603  t-loss:0.1435, loss-lb:0.0755, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:31:41.097] iteration:24604  t-loss:0.1544, loss-lb:0.0766, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:31:41.292] iteration:24605  t-loss:0.1417, loss-lb:0.0732, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:31:41.486] iteration:24606  t-loss:0.1436, loss-lb:0.0755, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:31:41.679] iteration:24607  t-loss:0.1315, loss-lb:0.0672, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:31:41.872] iteration:24608  t-loss:0.1296, loss-lb:0.0621, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:31:42.065] iteration:24609  t-loss:0.1788, loss-lb:0.0715, loss-ulb:0.0536, weight:2.00, lr:0.0002
[12:31:42.258] iteration:24610  t-loss:0.1355, loss-lb:0.0733, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:31:42.450] iteration:24611  t-loss:0.1336, loss-lb:0.0672, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:31:42.643] iteration:24612  t-loss:0.1752, loss-lb:0.0768, loss-ulb:0.0492, weight:2.00, lr:0.0002
[12:31:42.835] iteration:24613  t-loss:0.1510, loss-lb:0.0749, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:31:43.028] iteration:24614  t-loss:0.1461, loss-lb:0.0688, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:31:43.220] iteration:24615  t-loss:0.1519, loss-lb:0.0748, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:31:43.412] iteration:24616  t-loss:0.1805, loss-lb:0.0777, loss-ulb:0.0514, weight:2.00, lr:0.0002
[12:31:43.605] iteration:24617  t-loss:0.1471, loss-lb:0.0802, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:31:43.797] iteration:24618  t-loss:0.1363, loss-lb:0.0720, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:31:43.990] iteration:24619  t-loss:0.1407, loss-lb:0.0708, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:31:44.183] iteration:24620  t-loss:0.1455, loss-lb:0.0732, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:31:44.377] iteration:24621  t-loss:0.1423, loss-lb:0.0733, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:31:44.569] iteration:24622  t-loss:0.1319, loss-lb:0.0673, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:31:44.761] iteration:24623  t-loss:0.1493, loss-lb:0.0736, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:31:44.955] iteration:24624  t-loss:0.1327, loss-lb:0.0675, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:31:45.147] iteration:24625  t-loss:0.1446, loss-lb:0.0710, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:31:45.339] iteration:24626  t-loss:0.1383, loss-lb:0.0766, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:31:45.533] iteration:24627  t-loss:0.2120, loss-lb:0.0758, loss-ulb:0.0681, weight:2.00, lr:0.0002
[12:31:45.726] iteration:24628  t-loss:0.1394, loss-lb:0.0713, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:31:45.919] iteration:24629  t-loss:0.1343, loss-lb:0.0692, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:31:46.110] iteration:24630  t-loss:0.1580, loss-lb:0.0907, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:31:46.303] iteration:24631  t-loss:0.1342, loss-lb:0.0739, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:31:46.497] iteration:24632  t-loss:0.1237, loss-lb:0.0648, loss-ulb:0.0295, weight:2.00, lr:0.0002
[12:31:46.691] iteration:24633  t-loss:0.1464, loss-lb:0.0678, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:31:46.882] iteration:24634  t-loss:0.1372, loss-lb:0.0705, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:31:47.075] iteration:24635  t-loss:0.1635, loss-lb:0.0751, loss-ulb:0.0442, weight:2.00, lr:0.0002
[12:31:47.269] iteration:24636  t-loss:0.1416, loss-lb:0.0709, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:31:47.462] iteration:24637  t-loss:0.1543, loss-lb:0.0746, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:31:47.654] iteration:24638  t-loss:0.1500, loss-lb:0.0818, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:31:47.847] iteration:24639  t-loss:0.1587, loss-lb:0.0708, loss-ulb:0.0440, weight:2.00, lr:0.0002
[12:31:48.041] iteration:24640  t-loss:0.1495, loss-lb:0.0741, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:31:48.234] iteration:24641  t-loss:0.1543, loss-lb:0.0729, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:31:48.425] iteration:24642  t-loss:0.1421, loss-lb:0.0672, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:31:48.618] iteration:24643  t-loss:0.1576, loss-lb:0.0708, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:31:48.811] iteration:24644  t-loss:0.1616, loss-lb:0.0707, loss-ulb:0.0455, weight:2.00, lr:0.0002
[12:31:49.003] iteration:24645  t-loss:0.1786, loss-lb:0.0686, loss-ulb:0.0550, weight:2.00, lr:0.0002
[12:31:49.196] iteration:24646  t-loss:0.1443, loss-lb:0.0686, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:31:49.388] iteration:24647  t-loss:0.1634, loss-lb:0.0852, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:31:49.581] iteration:24648  t-loss:0.1410, loss-lb:0.0783, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:31:49.773] iteration:24649  t-loss:0.1507, loss-lb:0.0790, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:31:49.965] iteration:24650  t-loss:0.1324, loss-lb:0.0716, loss-ulb:0.0304, weight:2.00, lr:0.0002
[12:31:50.158] iteration:24651  t-loss:0.1876, loss-lb:0.0760, loss-ulb:0.0558, weight:2.00, lr:0.0002
[12:31:50.349] iteration:24652  t-loss:0.1491, loss-lb:0.0693, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:31:50.542] iteration:24653  t-loss:0.1389, loss-lb:0.0643, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:31:50.735] iteration:24654  t-loss:0.1531, loss-lb:0.0759, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:31:50.927] iteration:24655  t-loss:0.1537, loss-lb:0.0788, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:31:51.120] iteration:24656  t-loss:0.1419, loss-lb:0.0715, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:31:51.313] iteration:24657  t-loss:0.1340, loss-lb:0.0735, loss-ulb:0.0303, weight:2.00, lr:0.0002
[12:31:51.506] iteration:24658  t-loss:0.1501, loss-lb:0.0848, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:31:51.698] iteration:24659  t-loss:0.1556, loss-lb:0.0671, loss-ulb:0.0443, weight:2.00, lr:0.0002
[12:31:51.890] iteration:24660  t-loss:0.1396, loss-lb:0.0746, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:31:52.083] iteration:24661  t-loss:0.1466, loss-lb:0.0753, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:31:52.276] iteration:24662  t-loss:0.1355, loss-lb:0.0705, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:31:52.469] iteration:24663  t-loss:0.1351, loss-lb:0.0691, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:31:52.661] iteration:24664  t-loss:0.1375, loss-lb:0.0708, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:31:52.853] iteration:24665  t-loss:0.1402, loss-lb:0.0697, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:31:53.046] iteration:24666  t-loss:0.1525, loss-lb:0.0803, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:31:53.238] iteration:24667  t-loss:0.1544, loss-lb:0.0720, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:31:53.430] iteration:24668  t-loss:0.1399, loss-lb:0.0729, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:31:53.622] iteration:24669  t-loss:0.1993, loss-lb:0.0756, loss-ulb:0.0619, weight:2.00, lr:0.0002
[12:31:53.816] iteration:24670  t-loss:0.1563, loss-lb:0.0758, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:31:54.008] iteration:24671  t-loss:0.1462, loss-lb:0.0791, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:31:54.200] iteration:24672  t-loss:0.2267, loss-lb:0.0768, loss-ulb:0.0749, weight:2.00, lr:0.0002
[12:31:54.394] iteration:24673  t-loss:0.2651, loss-lb:0.0788, loss-ulb:0.0932, weight:2.00, lr:0.0002
[12:31:54.587] iteration:24674  t-loss:0.1489, loss-lb:0.0723, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:31:54.780] iteration:24675  t-loss:0.1410, loss-lb:0.0689, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:31:54.973] iteration:24676  t-loss:0.1427, loss-lb:0.0757, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:31:55.165] iteration:24677  t-loss:0.1534, loss-lb:0.0774, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:31:55.359] iteration:24678  t-loss:0.1778, loss-lb:0.0745, loss-ulb:0.0517, weight:2.00, lr:0.0002
[12:31:55.551] iteration:24679  t-loss:0.1475, loss-lb:0.0711, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:31:55.743] iteration:24680  t-loss:0.1553, loss-lb:0.0703, loss-ulb:0.0425, weight:2.00, lr:0.0002
[12:31:55.936] iteration:24681  t-loss:0.1429, loss-lb:0.0778, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:31:56.129] iteration:24682  t-loss:0.1450, loss-lb:0.0768, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:31:56.322] iteration:24683  t-loss:0.1426, loss-lb:0.0654, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:31:56.514] iteration:24684  t-loss:0.1261, loss-lb:0.0662, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:31:56.707] iteration:24685  t-loss:0.1380, loss-lb:0.0780, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:31:56.900] iteration:24686  t-loss:0.1477, loss-lb:0.0698, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:31:57.092] iteration:24687  t-loss:0.1485, loss-lb:0.0780, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:31:57.285] iteration:24688  t-loss:0.1577, loss-lb:0.0759, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:31:57.477] iteration:24689  t-loss:0.1582, loss-lb:0.0762, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:31:57.668] iteration:24690  t-loss:0.1377, loss-lb:0.0730, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:31:57.858] iteration:24691  t-loss:0.1581, loss-lb:0.0749, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:31:58.048] iteration:24692  t-loss:0.1462, loss-lb:0.0773, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:31:58.239] iteration:24693  t-loss:0.1332, loss-lb:0.0712, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:31:58.429] iteration:24694  t-loss:0.1500, loss-lb:0.0781, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:31:58.621] iteration:24695  t-loss:0.1582, loss-lb:0.0768, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:31:58.811] iteration:24696  t-loss:0.1419, loss-lb:0.0738, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:31:59.394] iteration:24697  t-loss:0.1905, loss-lb:0.0728, loss-ulb:0.0588, weight:2.00, lr:0.0002
[12:31:59.589] iteration:24698  t-loss:0.1357, loss-lb:0.0679, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:31:59.782] iteration:24699  t-loss:0.1604, loss-lb:0.0768, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:31:59.975] iteration:24700  t-loss:0.1863, loss-lb:0.0742, loss-ulb:0.0561, weight:2.00, lr:0.0002
[12:32:00.167] iteration:24701  t-loss:0.1809, loss-lb:0.0689, loss-ulb:0.0560, weight:2.00, lr:0.0002
[12:32:00.360] iteration:24702  t-loss:0.1402, loss-lb:0.0710, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:32:00.553] iteration:24703  t-loss:0.1586, loss-lb:0.0767, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:32:00.746] iteration:24704  t-loss:0.2337, loss-lb:0.0722, loss-ulb:0.0807, weight:2.00, lr:0.0002
[12:32:00.938] iteration:24705  t-loss:0.1556, loss-lb:0.0784, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:32:01.131] iteration:24706  t-loss:0.1458, loss-lb:0.0706, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:32:01.324] iteration:24707  t-loss:0.1607, loss-lb:0.0707, loss-ulb:0.0450, weight:2.00, lr:0.0002
[12:32:01.515] iteration:24708  t-loss:0.1477, loss-lb:0.0777, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:32:01.708] iteration:24709  t-loss:0.1798, loss-lb:0.0740, loss-ulb:0.0529, weight:2.00, lr:0.0002
[12:32:01.901] iteration:24710  t-loss:0.1567, loss-lb:0.0748, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:32:02.094] iteration:24711  t-loss:0.1403, loss-lb:0.0705, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:32:02.287] iteration:24712  t-loss:0.2554, loss-lb:0.0723, loss-ulb:0.0915, weight:2.00, lr:0.0002
[12:32:02.481] iteration:24713  t-loss:0.1978, loss-lb:0.0754, loss-ulb:0.0612, weight:2.00, lr:0.0002
[12:32:02.674] iteration:24714  t-loss:0.1382, loss-lb:0.0745, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:32:02.866] iteration:24715  t-loss:0.1463, loss-lb:0.0821, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:32:03.060] iteration:24716  t-loss:0.1412, loss-lb:0.0692, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:32:03.252] iteration:24717  t-loss:0.1409, loss-lb:0.0749, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:32:03.445] iteration:24718  t-loss:0.1285, loss-lb:0.0697, loss-ulb:0.0294, weight:2.00, lr:0.0002
[12:32:03.637] iteration:24719  t-loss:0.1483, loss-lb:0.0778, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:32:03.829] iteration:24720  t-loss:0.1319, loss-lb:0.0724, loss-ulb:0.0297, weight:2.00, lr:0.0002
[12:32:04.022] iteration:24721  t-loss:0.1444, loss-lb:0.0721, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:32:04.215] iteration:24722  t-loss:0.1705, loss-lb:0.0716, loss-ulb:0.0494, weight:2.00, lr:0.0002
[12:32:04.407] iteration:24723  t-loss:0.1274, loss-lb:0.0644, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:32:04.600] iteration:24724  t-loss:0.1496, loss-lb:0.0699, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:32:04.794] iteration:24725  t-loss:0.1445, loss-lb:0.0773, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:32:04.986] iteration:24726  t-loss:0.1561, loss-lb:0.0724, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:32:05.178] iteration:24727  t-loss:0.1410, loss-lb:0.0722, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:32:05.371] iteration:24728  t-loss:0.1385, loss-lb:0.0718, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:32:05.564] iteration:24729  t-loss:0.1477, loss-lb:0.0718, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:32:05.756] iteration:24730  t-loss:0.1464, loss-lb:0.0728, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:32:05.950] iteration:24731  t-loss:0.1607, loss-lb:0.0683, loss-ulb:0.0462, weight:2.00, lr:0.0002
[12:32:06.142] iteration:24732  t-loss:0.1423, loss-lb:0.0736, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:32:06.335] iteration:24733  t-loss:0.1453, loss-lb:0.0787, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:32:06.528] iteration:24734  t-loss:0.1761, loss-lb:0.0781, loss-ulb:0.0490, weight:2.00, lr:0.0002
[12:32:06.721] iteration:24735  t-loss:0.1450, loss-lb:0.0809, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:32:06.914] iteration:24736  t-loss:0.1333, loss-lb:0.0697, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:32:07.107] iteration:24737  t-loss:0.1350, loss-lb:0.0640, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:32:07.300] iteration:24738  t-loss:0.1357, loss-lb:0.0698, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:32:07.494] iteration:24739  t-loss:0.2482, loss-lb:0.0785, loss-ulb:0.0848, weight:2.00, lr:0.0002
[12:32:07.686] iteration:24740  t-loss:0.1433, loss-lb:0.0716, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:32:07.879] iteration:24741  t-loss:0.1474, loss-lb:0.0697, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:32:08.071] iteration:24742  t-loss:0.1379, loss-lb:0.0656, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:32:08.263] iteration:24743  t-loss:0.1589, loss-lb:0.0721, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:32:08.458] iteration:24744  t-loss:0.1368, loss-lb:0.0708, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:32:08.651] iteration:24745  t-loss:0.1419, loss-lb:0.0705, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:32:08.843] iteration:24746  t-loss:0.1313, loss-lb:0.0680, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:32:09.036] iteration:24747  t-loss:0.1293, loss-lb:0.0717, loss-ulb:0.0288, weight:2.00, lr:0.0002
[12:32:09.229] iteration:24748  t-loss:0.1460, loss-lb:0.0737, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:32:09.421] iteration:24749  t-loss:0.1569, loss-lb:0.0812, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:32:09.612] iteration:24750  t-loss:0.1388, loss-lb:0.0707, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:32:09.805] iteration:24751  t-loss:0.1528, loss-lb:0.0785, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:32:09.998] iteration:24752  t-loss:0.1369, loss-lb:0.0749, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:32:10.190] iteration:24753  t-loss:0.1351, loss-lb:0.0728, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:32:10.384] iteration:24754  t-loss:0.1458, loss-lb:0.0694, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:32:10.577] iteration:24755  t-loss:0.1278, loss-lb:0.0650, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:32:10.769] iteration:24756  t-loss:0.1516, loss-lb:0.0703, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:32:10.962] iteration:24757  t-loss:0.1377, loss-lb:0.0688, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:32:11.154] iteration:24758  t-loss:0.1449, loss-lb:0.0749, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:32:11.347] iteration:24759  t-loss:0.1712, loss-lb:0.0744, loss-ulb:0.0484, weight:2.00, lr:0.0002
[12:32:11.540] iteration:24760  t-loss:0.1388, loss-lb:0.0763, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:32:11.734] iteration:24761  t-loss:0.1706, loss-lb:0.0737, loss-ulb:0.0485, weight:2.00, lr:0.0002
[12:32:11.926] iteration:24762  t-loss:0.1340, loss-lb:0.0675, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:32:12.119] iteration:24763  t-loss:0.1542, loss-lb:0.0853, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:32:12.312] iteration:24764  t-loss:0.1401, loss-lb:0.0729, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:32:12.506] iteration:24765  t-loss:0.1592, loss-lb:0.0700, loss-ulb:0.0446, weight:2.00, lr:0.0002
[12:32:12.700] iteration:24766  t-loss:0.1366, loss-lb:0.0660, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:32:12.892] iteration:24767  t-loss:0.1395, loss-lb:0.0720, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:32:13.084] iteration:24768  t-loss:0.1324, loss-lb:0.0715, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:32:13.277] iteration:24769  t-loss:0.1381, loss-lb:0.0726, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:32:13.479] iteration:24770  t-loss:0.2481, loss-lb:0.0788, loss-ulb:0.0847, weight:2.00, lr:0.0002
[12:32:13.682] iteration:24771  t-loss:0.1392, loss-lb:0.0707, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:32:13.879] iteration:24772  t-loss:0.1465, loss-lb:0.0709, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:32:14.072] iteration:24773  t-loss:0.1601, loss-lb:0.0814, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:32:14.264] iteration:24774  t-loss:0.1397, loss-lb:0.0704, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:32:14.455] iteration:24775  t-loss:0.1421, loss-lb:0.0705, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:32:14.648] iteration:24776  t-loss:0.1494, loss-lb:0.0742, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:32:14.841] iteration:24777  t-loss:0.1502, loss-lb:0.0772, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:32:15.034] iteration:24778  t-loss:0.1444, loss-lb:0.0735, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:32:15.226] iteration:24779  t-loss:0.1489, loss-lb:0.0715, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:32:15.418] iteration:24780  t-loss:0.1377, loss-lb:0.0712, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:32:15.611] iteration:24781  t-loss:0.1320, loss-lb:0.0722, loss-ulb:0.0299, weight:2.00, lr:0.0002
[12:32:15.802] iteration:24782  t-loss:0.1286, loss-lb:0.0612, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:32:15.995] iteration:24783  t-loss:0.1530, loss-lb:0.0716, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:32:16.188] iteration:24784  t-loss:0.1357, loss-lb:0.0720, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:32:16.381] iteration:24785  t-loss:0.1394, loss-lb:0.0698, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:32:16.573] iteration:24786  t-loss:0.1535, loss-lb:0.0726, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:32:16.765] iteration:24787  t-loss:0.1408, loss-lb:0.0846, loss-ulb:0.0281, weight:2.00, lr:0.0002
[12:32:16.957] iteration:24788  t-loss:0.1426, loss-lb:0.0700, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:32:17.147] iteration:24789  t-loss:0.1602, loss-lb:0.0711, loss-ulb:0.0445, weight:2.00, lr:0.0002
[12:32:17.340] iteration:24790  t-loss:0.1449, loss-lb:0.0712, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:32:17.530] iteration:24791  t-loss:0.1520, loss-lb:0.0723, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:32:17.722] iteration:24792  t-loss:0.2028, loss-lb:0.0711, loss-ulb:0.0658, weight:2.00, lr:0.0002
[12:32:17.913] iteration:24793  t-loss:0.1427, loss-lb:0.0749, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:32:18.104] iteration:24794  t-loss:0.1404, loss-lb:0.0674, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:32:30.936]  <<Test>> - Ep:252  - mean_dice/mean_h95 - S:90.03/1.32, Best-S:90.99, T:89.80/1.36, Best-T:90.48
[12:32:30.936]           - AvgLoss(lb/ulb/all):0.0726/0.0375/0.1471
[12:32:31.440] iteration:24795  t-loss:0.1428, loss-lb:0.0726, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:32:31.637] iteration:24796  t-loss:0.1421, loss-lb:0.0747, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:32:31.830] iteration:24797  t-loss:0.1510, loss-lb:0.0643, loss-ulb:0.0433, weight:2.00, lr:0.0002
[12:32:32.021] iteration:24798  t-loss:0.1492, loss-lb:0.0745, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:32:32.214] iteration:24799  t-loss:0.1339, loss-lb:0.0734, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:32:32.406] iteration:24800  t-loss:0.1525, loss-lb:0.0755, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:32:32.597] iteration:24801  t-loss:0.1437, loss-lb:0.0686, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:32:32.789] iteration:24802  t-loss:0.1359, loss-lb:0.0668, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:32:32.981] iteration:24803  t-loss:0.1439, loss-lb:0.0765, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:32:33.174] iteration:24804  t-loss:0.1474, loss-lb:0.0739, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:32:33.367] iteration:24805  t-loss:0.1373, loss-lb:0.0729, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:32:33.562] iteration:24806  t-loss:0.1370, loss-lb:0.0714, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:32:33.759] iteration:24807  t-loss:0.1524, loss-lb:0.0714, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:32:33.954] iteration:24808  t-loss:0.1486, loss-lb:0.0715, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:32:34.150] iteration:24809  t-loss:0.1511, loss-lb:0.0736, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:32:34.344] iteration:24810  t-loss:0.1422, loss-lb:0.0662, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:32:34.538] iteration:24811  t-loss:0.2981, loss-lb:0.0792, loss-ulb:0.1094, weight:2.00, lr:0.0002
[12:32:34.731] iteration:24812  t-loss:0.1496, loss-lb:0.0810, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:32:34.924] iteration:24813  t-loss:0.1580, loss-lb:0.0766, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:32:35.117] iteration:24814  t-loss:0.1473, loss-lb:0.0707, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:32:35.310] iteration:24815  t-loss:0.1506, loss-lb:0.0724, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:32:35.503] iteration:24816  t-loss:0.1676, loss-lb:0.0758, loss-ulb:0.0459, weight:2.00, lr:0.0002
[12:32:35.695] iteration:24817  t-loss:0.1381, loss-lb:0.0694, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:32:35.888] iteration:24818  t-loss:0.1608, loss-lb:0.0685, loss-ulb:0.0462, weight:2.00, lr:0.0002
[12:32:36.081] iteration:24819  t-loss:0.1552, loss-lb:0.0722, loss-ulb:0.0415, weight:2.00, lr:0.0002
[12:32:36.272] iteration:24820  t-loss:0.1419, loss-lb:0.0745, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:32:36.465] iteration:24821  t-loss:0.1504, loss-lb:0.0737, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:32:36.657] iteration:24822  t-loss:0.1585, loss-lb:0.0731, loss-ulb:0.0427, weight:2.00, lr:0.0002
[12:32:36.850] iteration:24823  t-loss:0.1419, loss-lb:0.0760, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:32:37.043] iteration:24824  t-loss:0.1378, loss-lb:0.0736, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:32:37.236] iteration:24825  t-loss:0.1614, loss-lb:0.0704, loss-ulb:0.0455, weight:2.00, lr:0.0002
[12:32:37.428] iteration:24826  t-loss:0.1417, loss-lb:0.0696, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:32:37.621] iteration:24827  t-loss:0.1417, loss-lb:0.0727, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:32:37.813] iteration:24828  t-loss:0.1380, loss-lb:0.0727, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:32:38.005] iteration:24829  t-loss:0.1473, loss-lb:0.0736, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:32:38.199] iteration:24830  t-loss:0.1503, loss-lb:0.0787, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:32:38.390] iteration:24831  t-loss:0.1474, loss-lb:0.0653, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:32:38.582] iteration:24832  t-loss:0.1218, loss-lb:0.0679, loss-ulb:0.0269, weight:2.00, lr:0.0002
[12:32:38.774] iteration:24833  t-loss:0.1402, loss-lb:0.0752, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:32:38.965] iteration:24834  t-loss:0.1419, loss-lb:0.0663, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:32:39.157] iteration:24835  t-loss:0.1504, loss-lb:0.0742, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:32:39.349] iteration:24836  t-loss:0.1541, loss-lb:0.0795, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:32:39.541] iteration:24837  t-loss:0.1442, loss-lb:0.0738, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:32:39.734] iteration:24838  t-loss:0.2128, loss-lb:0.0762, loss-ulb:0.0683, weight:2.00, lr:0.0002
[12:32:39.925] iteration:24839  t-loss:0.1456, loss-lb:0.0714, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:32:40.117] iteration:24840  t-loss:0.1487, loss-lb:0.0785, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:32:40.310] iteration:24841  t-loss:0.1971, loss-lb:0.0657, loss-ulb:0.0657, weight:2.00, lr:0.0002
[12:32:40.502] iteration:24842  t-loss:0.1513, loss-lb:0.0776, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:32:40.695] iteration:24843  t-loss:0.1516, loss-lb:0.0815, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:32:40.887] iteration:24844  t-loss:0.1386, loss-lb:0.0723, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:32:41.078] iteration:24845  t-loss:0.1511, loss-lb:0.0750, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:32:41.270] iteration:24846  t-loss:0.1385, loss-lb:0.0684, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:32:41.465] iteration:24847  t-loss:0.1476, loss-lb:0.0739, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:32:41.655] iteration:24848  t-loss:0.1501, loss-lb:0.0683, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:32:41.847] iteration:24849  t-loss:0.1512, loss-lb:0.0796, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:32:42.038] iteration:24850  t-loss:0.1424, loss-lb:0.0708, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:32:42.230] iteration:24851  t-loss:0.1479, loss-lb:0.0829, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:32:42.422] iteration:24852  t-loss:0.1518, loss-lb:0.0713, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:32:42.613] iteration:24853  t-loss:0.1616, loss-lb:0.0785, loss-ulb:0.0415, weight:2.00, lr:0.0002
[12:32:42.805] iteration:24854  t-loss:0.1404, loss-lb:0.0674, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:32:42.997] iteration:24855  t-loss:0.1382, loss-lb:0.0654, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:32:43.188] iteration:24856  t-loss:0.1322, loss-lb:0.0666, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:32:43.379] iteration:24857  t-loss:0.1502, loss-lb:0.0771, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:32:43.571] iteration:24858  t-loss:0.1304, loss-lb:0.0736, loss-ulb:0.0284, weight:2.00, lr:0.0002
[12:32:43.763] iteration:24859  t-loss:0.1894, loss-lb:0.0872, loss-ulb:0.0511, weight:2.00, lr:0.0002
[12:32:43.956] iteration:24860  t-loss:0.2165, loss-lb:0.0681, loss-ulb:0.0742, weight:2.00, lr:0.0002
[12:32:44.147] iteration:24861  t-loss:0.1319, loss-lb:0.0722, loss-ulb:0.0298, weight:2.00, lr:0.0002
[12:32:44.341] iteration:24862  t-loss:0.1566, loss-lb:0.0726, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:32:44.536] iteration:24863  t-loss:0.1318, loss-lb:0.0684, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:32:44.731] iteration:24864  t-loss:0.1537, loss-lb:0.0758, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:32:44.925] iteration:24865  t-loss:0.1452, loss-lb:0.0737, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:32:45.117] iteration:24866  t-loss:0.1370, loss-lb:0.0720, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:32:45.310] iteration:24867  t-loss:0.2285, loss-lb:0.0822, loss-ulb:0.0731, weight:2.00, lr:0.0002
[12:32:45.502] iteration:24868  t-loss:0.1444, loss-lb:0.0770, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:32:45.694] iteration:24869  t-loss:0.1393, loss-lb:0.0700, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:32:45.886] iteration:24870  t-loss:0.1422, loss-lb:0.0721, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:32:46.077] iteration:24871  t-loss:0.1508, loss-lb:0.0744, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:32:46.285] iteration:24872  t-loss:0.1684, loss-lb:0.0746, loss-ulb:0.0469, weight:2.00, lr:0.0002
[12:32:46.484] iteration:24873  t-loss:0.1345, loss-lb:0.0679, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:32:46.681] iteration:24874  t-loss:0.1457, loss-lb:0.0744, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:32:46.874] iteration:24875  t-loss:0.1281, loss-lb:0.0689, loss-ulb:0.0296, weight:2.00, lr:0.0002
[12:32:47.066] iteration:24876  t-loss:0.1325, loss-lb:0.0714, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:32:47.260] iteration:24877  t-loss:0.1443, loss-lb:0.0738, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:32:47.451] iteration:24878  t-loss:0.1402, loss-lb:0.0721, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:32:47.646] iteration:24879  t-loss:0.1439, loss-lb:0.0728, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:32:47.838] iteration:24880  t-loss:0.1301, loss-lb:0.0647, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:32:48.030] iteration:24881  t-loss:0.1414, loss-lb:0.0705, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:32:48.223] iteration:24882  t-loss:0.1806, loss-lb:0.0704, loss-ulb:0.0551, weight:2.00, lr:0.0002
[12:32:48.415] iteration:24883  t-loss:0.1709, loss-lb:0.0814, loss-ulb:0.0448, weight:2.00, lr:0.0002
[12:32:48.608] iteration:24884  t-loss:0.1429, loss-lb:0.0717, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:32:48.800] iteration:24885  t-loss:0.1293, loss-lb:0.0695, loss-ulb:0.0299, weight:2.00, lr:0.0002
[12:32:48.991] iteration:24886  t-loss:0.1483, loss-lb:0.0718, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:32:49.183] iteration:24887  t-loss:0.1320, loss-lb:0.0678, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:32:49.374] iteration:24888  t-loss:0.1481, loss-lb:0.0725, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:32:49.565] iteration:24889  t-loss:0.1245, loss-lb:0.0681, loss-ulb:0.0282, weight:2.00, lr:0.0002
[12:32:49.755] iteration:24890  t-loss:0.1550, loss-lb:0.0735, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:32:49.946] iteration:24891  t-loss:0.1328, loss-lb:0.0647, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:32:50.138] iteration:24892  t-loss:0.1780, loss-lb:0.0716, loss-ulb:0.0532, weight:2.00, lr:0.0002
[12:32:50.714] iteration:24893  t-loss:0.1447, loss-lb:0.0745, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:32:50.916] iteration:24894  t-loss:0.1353, loss-lb:0.0731, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:32:51.109] iteration:24895  t-loss:0.1370, loss-lb:0.0683, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:32:51.301] iteration:24896  t-loss:0.1501, loss-lb:0.0722, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:32:51.493] iteration:24897  t-loss:0.1393, loss-lb:0.0705, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:32:51.692] iteration:24898  t-loss:0.1353, loss-lb:0.0740, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:32:51.884] iteration:24899  t-loss:0.1315, loss-lb:0.0678, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:32:52.077] iteration:24900  t-loss:0.1842, loss-lb:0.0920, loss-ulb:0.0461, weight:2.00, lr:0.0002
[12:32:52.270] iteration:24901  t-loss:0.1709, loss-lb:0.0685, loss-ulb:0.0512, weight:2.00, lr:0.0002
[12:32:52.470] iteration:24902  t-loss:0.1324, loss-lb:0.0648, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:32:52.662] iteration:24903  t-loss:0.1613, loss-lb:0.0823, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:32:52.855] iteration:24904  t-loss:0.1409, loss-lb:0.0771, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:32:53.047] iteration:24905  t-loss:0.1578, loss-lb:0.0703, loss-ulb:0.0438, weight:2.00, lr:0.0002
[12:32:53.247] iteration:24906  t-loss:0.1373, loss-lb:0.0713, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:32:53.439] iteration:24907  t-loss:0.1419, loss-lb:0.0726, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:32:53.631] iteration:24908  t-loss:0.1560, loss-lb:0.0751, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:32:53.823] iteration:24909  t-loss:0.1558, loss-lb:0.0716, loss-ulb:0.0421, weight:2.00, lr:0.0002
[12:32:54.023] iteration:24910  t-loss:0.1444, loss-lb:0.0680, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:32:54.215] iteration:24911  t-loss:0.1512, loss-lb:0.0841, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:32:54.408] iteration:24912  t-loss:0.1986, loss-lb:0.0752, loss-ulb:0.0617, weight:2.00, lr:0.0002
[12:32:54.599] iteration:24913  t-loss:0.1356, loss-lb:0.0747, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:32:54.798] iteration:24914  t-loss:0.1377, loss-lb:0.0715, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:32:54.990] iteration:24915  t-loss:0.1398, loss-lb:0.0732, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:32:55.183] iteration:24916  t-loss:0.1625, loss-lb:0.0709, loss-ulb:0.0458, weight:2.00, lr:0.0002
[12:32:55.378] iteration:24917  t-loss:0.1497, loss-lb:0.0686, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:32:55.586] iteration:24918  t-loss:0.1676, loss-lb:0.0780, loss-ulb:0.0448, weight:2.00, lr:0.0002
[12:32:55.780] iteration:24919  t-loss:0.1819, loss-lb:0.0679, loss-ulb:0.0570, weight:2.00, lr:0.0002
[12:32:55.974] iteration:24920  t-loss:0.1627, loss-lb:0.0688, loss-ulb:0.0470, weight:2.00, lr:0.0002
[12:32:56.167] iteration:24921  t-loss:0.1494, loss-lb:0.0765, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:32:56.368] iteration:24922  t-loss:0.1807, loss-lb:0.0801, loss-ulb:0.0503, weight:2.00, lr:0.0002
[12:32:56.560] iteration:24923  t-loss:0.1961, loss-lb:0.0823, loss-ulb:0.0569, weight:2.00, lr:0.0002
[12:32:56.753] iteration:24924  t-loss:0.1449, loss-lb:0.0768, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:32:56.945] iteration:24925  t-loss:0.1444, loss-lb:0.0694, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:32:57.145] iteration:24926  t-loss:0.1255, loss-lb:0.0648, loss-ulb:0.0304, weight:2.00, lr:0.0002
[12:32:57.337] iteration:24927  t-loss:0.1371, loss-lb:0.0704, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:32:57.530] iteration:24928  t-loss:0.1360, loss-lb:0.0711, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:32:57.724] iteration:24929  t-loss:0.1686, loss-lb:0.0781, loss-ulb:0.0452, weight:2.00, lr:0.0002
[12:32:57.918] iteration:24930  t-loss:0.1430, loss-lb:0.0705, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:32:58.110] iteration:24931  t-loss:0.1501, loss-lb:0.0759, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:32:58.302] iteration:24932  t-loss:0.1560, loss-lb:0.0797, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:32:58.495] iteration:24933  t-loss:0.1509, loss-lb:0.0703, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:32:58.687] iteration:24934  t-loss:0.1445, loss-lb:0.0687, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:32:58.879] iteration:24935  t-loss:0.1556, loss-lb:0.0747, loss-ulb:0.0404, weight:2.00, lr:0.0002
[12:32:59.071] iteration:24936  t-loss:0.1358, loss-lb:0.0698, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:32:59.264] iteration:24937  t-loss:0.1444, loss-lb:0.0705, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:32:59.456] iteration:24938  t-loss:0.1510, loss-lb:0.0694, loss-ulb:0.0408, weight:2.00, lr:0.0002
[12:32:59.648] iteration:24939  t-loss:0.1480, loss-lb:0.0702, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:32:59.841] iteration:24940  t-loss:0.1552, loss-lb:0.0746, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:33:00.034] iteration:24941  t-loss:0.1507, loss-lb:0.0738, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:33:00.226] iteration:24942  t-loss:0.1421, loss-lb:0.0729, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:33:00.418] iteration:24943  t-loss:0.1541, loss-lb:0.0694, loss-ulb:0.0423, weight:2.00, lr:0.0002
[12:33:00.609] iteration:24944  t-loss:0.1357, loss-lb:0.0721, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:33:00.802] iteration:24945  t-loss:0.1452, loss-lb:0.0729, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:33:00.995] iteration:24946  t-loss:0.1426, loss-lb:0.0674, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:33:01.187] iteration:24947  t-loss:0.1435, loss-lb:0.0760, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:33:01.380] iteration:24948  t-loss:0.1309, loss-lb:0.0695, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:33:01.572] iteration:24949  t-loss:0.1580, loss-lb:0.0857, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:33:01.763] iteration:24950  t-loss:0.1354, loss-lb:0.0678, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:33:01.955] iteration:24951  t-loss:0.1296, loss-lb:0.0658, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:33:02.147] iteration:24952  t-loss:0.1381, loss-lb:0.0742, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:33:02.340] iteration:24953  t-loss:0.1326, loss-lb:0.0676, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:33:02.533] iteration:24954  t-loss:0.1417, loss-lb:0.0675, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:33:02.725] iteration:24955  t-loss:0.1495, loss-lb:0.0761, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:33:02.917] iteration:24956  t-loss:0.1631, loss-lb:0.0758, loss-ulb:0.0437, weight:2.00, lr:0.0002
[12:33:03.108] iteration:24957  t-loss:0.1405, loss-lb:0.0765, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:33:03.301] iteration:24958  t-loss:0.1557, loss-lb:0.0777, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:33:03.492] iteration:24959  t-loss:0.1418, loss-lb:0.0755, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:33:03.684] iteration:24960  t-loss:0.1443, loss-lb:0.0670, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:33:03.875] iteration:24961  t-loss:0.1552, loss-lb:0.0820, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:33:04.066] iteration:24962  t-loss:0.1408, loss-lb:0.0743, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:33:04.258] iteration:24963  t-loss:0.1624, loss-lb:0.0757, loss-ulb:0.0433, weight:2.00, lr:0.0002
[12:33:04.449] iteration:24964  t-loss:0.1444, loss-lb:0.0694, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:33:04.641] iteration:24965  t-loss:0.1394, loss-lb:0.0722, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:33:04.833] iteration:24966  t-loss:0.1489, loss-lb:0.0835, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:33:05.025] iteration:24967  t-loss:0.1768, loss-lb:0.0658, loss-ulb:0.0555, weight:2.00, lr:0.0002
[12:33:05.216] iteration:24968  t-loss:0.1394, loss-lb:0.0711, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:33:05.407] iteration:24969  t-loss:0.1451, loss-lb:0.0704, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:33:05.599] iteration:24970  t-loss:0.1311, loss-lb:0.0652, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:33:05.790] iteration:24971  t-loss:0.1560, loss-lb:0.0841, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:33:05.985] iteration:24972  t-loss:0.1883, loss-lb:0.0801, loss-ulb:0.0541, weight:2.00, lr:0.0002
[12:33:06.177] iteration:24973  t-loss:0.2078, loss-lb:0.0656, loss-ulb:0.0711, weight:2.00, lr:0.0002
[12:33:06.371] iteration:24974  t-loss:0.1747, loss-lb:0.0750, loss-ulb:0.0498, weight:2.00, lr:0.0002
[12:33:06.564] iteration:24975  t-loss:0.1495, loss-lb:0.0728, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:33:06.757] iteration:24976  t-loss:0.2809, loss-lb:0.0665, loss-ulb:0.1072, weight:2.00, lr:0.0002
[12:33:06.950] iteration:24977  t-loss:0.1502, loss-lb:0.0774, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:33:07.143] iteration:24978  t-loss:0.1331, loss-lb:0.0665, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:33:07.336] iteration:24979  t-loss:0.1401, loss-lb:0.0738, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:33:07.529] iteration:24980  t-loss:0.1453, loss-lb:0.0719, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:33:07.723] iteration:24981  t-loss:0.1373, loss-lb:0.0701, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:33:07.917] iteration:24982  t-loss:0.1339, loss-lb:0.0686, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:33:08.108] iteration:24983  t-loss:0.1546, loss-lb:0.0794, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:33:08.298] iteration:24984  t-loss:0.1632, loss-lb:0.0791, loss-ulb:0.0421, weight:2.00, lr:0.0002
[12:33:08.489] iteration:24985  t-loss:0.1451, loss-lb:0.0703, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:33:08.680] iteration:24986  t-loss:0.1435, loss-lb:0.0672, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:33:08.872] iteration:24987  t-loss:0.1344, loss-lb:0.0661, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:33:09.062] iteration:24988  t-loss:0.1478, loss-lb:0.0769, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:33:09.254] iteration:24989  t-loss:0.1337, loss-lb:0.0655, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:33:09.445] iteration:24990  t-loss:0.1450, loss-lb:0.0692, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:33:21.470]  <<Test>> - Ep:254  - mean_dice/mean_h95 - S:90.06/1.33, Best-S:90.99, T:89.74/1.36, Best-T:90.48
[12:33:21.470]           - AvgLoss(lb/ulb/all):0.0728/0.0430/0.1582
[12:33:21.999] iteration:24991  t-loss:0.1353, loss-lb:0.0687, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:33:22.194] iteration:24992  t-loss:0.1647, loss-lb:0.0740, loss-ulb:0.0454, weight:2.00, lr:0.0002
[12:33:22.386] iteration:24993  t-loss:0.1640, loss-lb:0.0816, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:33:22.580] iteration:24994  t-loss:0.1396, loss-lb:0.0735, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:33:22.774] iteration:24995  t-loss:0.1443, loss-lb:0.0744, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:33:22.968] iteration:24996  t-loss:0.1419, loss-lb:0.0718, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:33:23.161] iteration:24997  t-loss:0.1344, loss-lb:0.0707, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:33:23.354] iteration:24998  t-loss:0.1612, loss-lb:0.0684, loss-ulb:0.0464, weight:2.00, lr:0.0002
[12:33:23.546] iteration:24999  t-loss:0.1311, loss-lb:0.0653, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:33:23.740] iteration:25000  t-loss:0.1430, loss-lb:0.0718, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:33:23.933] iteration:25001  t-loss:0.1450, loss-lb:0.0740, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:33:24.127] iteration:25002  t-loss:0.1331, loss-lb:0.0730, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:33:24.319] iteration:25003  t-loss:0.1495, loss-lb:0.0742, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:33:24.511] iteration:25004  t-loss:0.1363, loss-lb:0.0749, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:33:24.704] iteration:25005  t-loss:0.1403, loss-lb:0.0665, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:33:24.897] iteration:25006  t-loss:0.1363, loss-lb:0.0709, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:33:25.089] iteration:25007  t-loss:0.1432, loss-lb:0.0711, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:33:25.282] iteration:25008  t-loss:0.1317, loss-lb:0.0678, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:33:25.474] iteration:25009  t-loss:0.1432, loss-lb:0.0817, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:33:25.666] iteration:25010  t-loss:0.1391, loss-lb:0.0685, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:33:25.859] iteration:25011  t-loss:0.1549, loss-lb:0.0735, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:33:26.051] iteration:25012  t-loss:0.1485, loss-lb:0.0750, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:33:26.244] iteration:25013  t-loss:0.1804, loss-lb:0.0725, loss-ulb:0.0539, weight:2.00, lr:0.0002
[12:33:26.438] iteration:25014  t-loss:0.1760, loss-lb:0.0652, loss-ulb:0.0554, weight:2.00, lr:0.0002
[12:33:26.630] iteration:25015  t-loss:0.1490, loss-lb:0.0768, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:33:26.822] iteration:25016  t-loss:0.1474, loss-lb:0.0759, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:33:27.016] iteration:25017  t-loss:0.1398, loss-lb:0.0673, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:33:27.208] iteration:25018  t-loss:0.1419, loss-lb:0.0734, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:33:27.401] iteration:25019  t-loss:0.1863, loss-lb:0.0714, loss-ulb:0.0575, weight:2.00, lr:0.0002
[12:33:27.595] iteration:25020  t-loss:0.2054, loss-lb:0.0815, loss-ulb:0.0619, weight:2.00, lr:0.0002
[12:33:27.787] iteration:25021  t-loss:0.1502, loss-lb:0.0789, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:33:27.980] iteration:25022  t-loss:0.1939, loss-lb:0.0721, loss-ulb:0.0609, weight:2.00, lr:0.0002
[12:33:28.173] iteration:25023  t-loss:0.1375, loss-lb:0.0712, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:33:28.366] iteration:25024  t-loss:0.1352, loss-lb:0.0626, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:33:28.558] iteration:25025  t-loss:0.1386, loss-lb:0.0724, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:33:28.751] iteration:25026  t-loss:0.1793, loss-lb:0.0780, loss-ulb:0.0507, weight:2.00, lr:0.0002
[12:33:28.944] iteration:25027  t-loss:0.1517, loss-lb:0.0776, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:33:29.136] iteration:25028  t-loss:0.1462, loss-lb:0.0756, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:33:29.328] iteration:25029  t-loss:0.1453, loss-lb:0.0756, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:33:29.522] iteration:25030  t-loss:0.2052, loss-lb:0.0750, loss-ulb:0.0651, weight:2.00, lr:0.0002
[12:33:29.716] iteration:25031  t-loss:0.1481, loss-lb:0.0708, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:33:29.908] iteration:25032  t-loss:0.1418, loss-lb:0.0700, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:33:30.101] iteration:25033  t-loss:0.1417, loss-lb:0.0732, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:33:30.293] iteration:25034  t-loss:0.1297, loss-lb:0.0704, loss-ulb:0.0297, weight:2.00, lr:0.0002
[12:33:30.485] iteration:25035  t-loss:0.1330, loss-lb:0.0669, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:33:30.677] iteration:25036  t-loss:0.1424, loss-lb:0.0704, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:33:30.870] iteration:25037  t-loss:0.1469, loss-lb:0.0704, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:33:31.063] iteration:25038  t-loss:0.1684, loss-lb:0.0758, loss-ulb:0.0463, weight:2.00, lr:0.0002
[12:33:31.255] iteration:25039  t-loss:0.1421, loss-lb:0.0665, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:33:31.447] iteration:25040  t-loss:0.1558, loss-lb:0.0763, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:33:31.641] iteration:25041  t-loss:0.1424, loss-lb:0.0679, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:33:31.834] iteration:25042  t-loss:0.1585, loss-lb:0.0881, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:33:32.026] iteration:25043  t-loss:0.1335, loss-lb:0.0698, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:33:32.218] iteration:25044  t-loss:0.1450, loss-lb:0.0669, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:33:32.411] iteration:25045  t-loss:0.1609, loss-lb:0.0706, loss-ulb:0.0452, weight:2.00, lr:0.0002
[12:33:32.604] iteration:25046  t-loss:0.1430, loss-lb:0.0737, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:33:32.797] iteration:25047  t-loss:0.1445, loss-lb:0.0784, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:33:32.990] iteration:25048  t-loss:0.1508, loss-lb:0.0734, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:33:33.183] iteration:25049  t-loss:0.1256, loss-lb:0.0651, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:33:33.375] iteration:25050  t-loss:0.1337, loss-lb:0.0744, loss-ulb:0.0297, weight:2.00, lr:0.0002
[12:33:33.568] iteration:25051  t-loss:0.1323, loss-lb:0.0641, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:33:33.761] iteration:25052  t-loss:0.1352, loss-lb:0.0723, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:33:33.954] iteration:25053  t-loss:0.1507, loss-lb:0.0789, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:33:34.146] iteration:25054  t-loss:0.1461, loss-lb:0.0728, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:33:34.338] iteration:25055  t-loss:0.1464, loss-lb:0.0741, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:33:34.532] iteration:25056  t-loss:0.1494, loss-lb:0.0723, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:33:34.724] iteration:25057  t-loss:0.1523, loss-lb:0.0762, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:33:34.916] iteration:25058  t-loss:0.1485, loss-lb:0.0675, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:33:35.110] iteration:25059  t-loss:0.1470, loss-lb:0.0723, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:33:35.304] iteration:25060  t-loss:0.1445, loss-lb:0.0723, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:33:35.496] iteration:25061  t-loss:0.1422, loss-lb:0.0738, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:33:35.689] iteration:25062  t-loss:0.1290, loss-lb:0.0715, loss-ulb:0.0288, weight:2.00, lr:0.0002
[12:33:35.882] iteration:25063  t-loss:0.1419, loss-lb:0.0756, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:33:36.074] iteration:25064  t-loss:0.1340, loss-lb:0.0741, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:33:36.267] iteration:25065  t-loss:0.1344, loss-lb:0.0664, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:33:36.460] iteration:25066  t-loss:0.1442, loss-lb:0.0711, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:33:36.652] iteration:25067  t-loss:0.1462, loss-lb:0.0662, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:33:36.844] iteration:25068  t-loss:0.1398, loss-lb:0.0776, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:33:37.036] iteration:25069  t-loss:0.1397, loss-lb:0.0709, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:33:37.230] iteration:25070  t-loss:0.1435, loss-lb:0.0719, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:33:37.421] iteration:25071  t-loss:0.1351, loss-lb:0.0711, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:33:37.614] iteration:25072  t-loss:0.2037, loss-lb:0.0718, loss-ulb:0.0659, weight:2.00, lr:0.0002
[12:33:37.815] iteration:25073  t-loss:0.1374, loss-lb:0.0683, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:33:38.006] iteration:25074  t-loss:0.1425, loss-lb:0.0746, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:33:38.198] iteration:25075  t-loss:0.1419, loss-lb:0.0690, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:33:38.392] iteration:25076  t-loss:0.1394, loss-lb:0.0730, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:33:38.591] iteration:25077  t-loss:0.1434, loss-lb:0.0714, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:33:38.784] iteration:25078  t-loss:0.1411, loss-lb:0.0735, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:33:38.977] iteration:25079  t-loss:0.1493, loss-lb:0.0786, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:33:39.170] iteration:25080  t-loss:0.2490, loss-lb:0.0682, loss-ulb:0.0904, weight:2.00, lr:0.0002
[12:33:39.362] iteration:25081  t-loss:0.1686, loss-lb:0.0715, loss-ulb:0.0486, weight:2.00, lr:0.0002
[12:33:39.553] iteration:25082  t-loss:0.1521, loss-lb:0.0812, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:33:39.743] iteration:25083  t-loss:0.1383, loss-lb:0.0734, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:33:39.934] iteration:25084  t-loss:0.1339, loss-lb:0.0723, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:33:40.125] iteration:25085  t-loss:0.1417, loss-lb:0.0708, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:33:40.316] iteration:25086  t-loss:0.1497, loss-lb:0.0771, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:33:40.506] iteration:25087  t-loss:0.1340, loss-lb:0.0691, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:33:40.697] iteration:25088  t-loss:0.1440, loss-lb:0.0697, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:33:41.277] iteration:25089  t-loss:0.1546, loss-lb:0.0856, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:33:41.472] iteration:25090  t-loss:0.1448, loss-lb:0.0735, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:33:41.665] iteration:25091  t-loss:0.1432, loss-lb:0.0683, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:33:41.859] iteration:25092  t-loss:0.1344, loss-lb:0.0713, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:33:42.051] iteration:25093  t-loss:0.1368, loss-lb:0.0735, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:33:42.243] iteration:25094  t-loss:0.1340, loss-lb:0.0754, loss-ulb:0.0293, weight:2.00, lr:0.0002
[12:33:42.436] iteration:25095  t-loss:0.1468, loss-lb:0.0712, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:33:42.629] iteration:25096  t-loss:0.1463, loss-lb:0.0779, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:33:42.823] iteration:25097  t-loss:0.1344, loss-lb:0.0702, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:33:43.015] iteration:25098  t-loss:0.1603, loss-lb:0.0769, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:33:43.208] iteration:25099  t-loss:0.1425, loss-lb:0.0686, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:33:43.401] iteration:25100  t-loss:0.1488, loss-lb:0.0787, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:33:43.594] iteration:25101  t-loss:0.1321, loss-lb:0.0696, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:33:43.786] iteration:25102  t-loss:0.1382, loss-lb:0.0722, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:33:43.979] iteration:25103  t-loss:0.1360, loss-lb:0.0679, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:33:44.172] iteration:25104  t-loss:0.1344, loss-lb:0.0692, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:33:44.364] iteration:25105  t-loss:0.1384, loss-lb:0.0733, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:33:44.557] iteration:25106  t-loss:0.1613, loss-lb:0.0771, loss-ulb:0.0421, weight:2.00, lr:0.0002
[12:33:44.750] iteration:25107  t-loss:0.1420, loss-lb:0.0717, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:33:44.941] iteration:25108  t-loss:0.1550, loss-lb:0.0819, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:33:45.134] iteration:25109  t-loss:0.1396, loss-lb:0.0682, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:33:45.327] iteration:25110  t-loss:0.1435, loss-lb:0.0730, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:33:45.520] iteration:25111  t-loss:0.1316, loss-lb:0.0690, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:33:45.712] iteration:25112  t-loss:0.1305, loss-lb:0.0704, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:33:45.905] iteration:25113  t-loss:0.1481, loss-lb:0.0764, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:33:46.098] iteration:25114  t-loss:0.1446, loss-lb:0.0743, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:33:46.290] iteration:25115  t-loss:0.1475, loss-lb:0.0706, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:33:46.482] iteration:25116  t-loss:0.1324, loss-lb:0.0680, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:33:46.676] iteration:25117  t-loss:0.2542, loss-lb:0.0722, loss-ulb:0.0910, weight:2.00, lr:0.0002
[12:33:46.869] iteration:25118  t-loss:0.1445, loss-lb:0.0666, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:33:47.062] iteration:25119  t-loss:0.1472, loss-lb:0.0705, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:33:47.255] iteration:25120  t-loss:0.1373, loss-lb:0.0706, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:33:47.448] iteration:25121  t-loss:0.1559, loss-lb:0.0686, loss-ulb:0.0437, weight:2.00, lr:0.0002
[12:33:47.641] iteration:25122  t-loss:0.1468, loss-lb:0.0756, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:33:47.834] iteration:25123  t-loss:0.1471, loss-lb:0.0829, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:33:48.026] iteration:25124  t-loss:0.1517, loss-lb:0.0712, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:33:48.219] iteration:25125  t-loss:0.1323, loss-lb:0.0695, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:33:48.413] iteration:25126  t-loss:0.1335, loss-lb:0.0688, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:33:48.605] iteration:25127  t-loss:0.1544, loss-lb:0.0768, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:33:48.797] iteration:25128  t-loss:0.1472, loss-lb:0.0672, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:33:48.989] iteration:25129  t-loss:0.1516, loss-lb:0.0778, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:33:49.182] iteration:25130  t-loss:0.1577, loss-lb:0.0728, loss-ulb:0.0424, weight:2.00, lr:0.0002
[12:33:49.375] iteration:25131  t-loss:0.1405, loss-lb:0.0742, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:33:49.568] iteration:25132  t-loss:0.2088, loss-lb:0.0703, loss-ulb:0.0692, weight:2.00, lr:0.0002
[12:33:49.761] iteration:25133  t-loss:0.1322, loss-lb:0.0673, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:33:49.953] iteration:25134  t-loss:0.1402, loss-lb:0.0710, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:33:50.146] iteration:25135  t-loss:0.1274, loss-lb:0.0690, loss-ulb:0.0292, weight:2.00, lr:0.0002
[12:33:50.339] iteration:25136  t-loss:0.1478, loss-lb:0.0630, loss-ulb:0.0424, weight:2.00, lr:0.0002
[12:33:50.531] iteration:25137  t-loss:0.1503, loss-lb:0.0766, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:33:50.723] iteration:25138  t-loss:0.1553, loss-lb:0.0716, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:33:50.915] iteration:25139  t-loss:0.1359, loss-lb:0.0663, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:33:51.107] iteration:25140  t-loss:0.1542, loss-lb:0.0756, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:33:51.301] iteration:25141  t-loss:0.1406, loss-lb:0.0746, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:33:51.494] iteration:25142  t-loss:0.1491, loss-lb:0.0697, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:33:51.686] iteration:25143  t-loss:0.1342, loss-lb:0.0696, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:33:51.878] iteration:25144  t-loss:0.1460, loss-lb:0.0688, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:33:52.071] iteration:25145  t-loss:0.1518, loss-lb:0.0780, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:33:52.264] iteration:25146  t-loss:0.1368, loss-lb:0.0695, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:33:52.456] iteration:25147  t-loss:0.1470, loss-lb:0.0769, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:33:52.649] iteration:25148  t-loss:0.1321, loss-lb:0.0650, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:33:52.843] iteration:25149  t-loss:0.1275, loss-lb:0.0702, loss-ulb:0.0286, weight:2.00, lr:0.0002
[12:33:53.046] iteration:25150  t-loss:0.1214, loss-lb:0.0679, loss-ulb:0.0267, weight:2.00, lr:0.0002
[12:33:53.242] iteration:25151  t-loss:0.1366, loss-lb:0.0657, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:33:53.434] iteration:25152  t-loss:0.1438, loss-lb:0.0740, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:33:53.627] iteration:25153  t-loss:0.1412, loss-lb:0.0723, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:33:53.821] iteration:25154  t-loss:0.1300, loss-lb:0.0723, loss-ulb:0.0288, weight:2.00, lr:0.0002
[12:33:54.013] iteration:25155  t-loss:0.1817, loss-lb:0.0765, loss-ulb:0.0526, weight:2.00, lr:0.0002
[12:33:54.205] iteration:25156  t-loss:0.1492, loss-lb:0.0704, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:33:54.397] iteration:25157  t-loss:0.1456, loss-lb:0.0752, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:33:54.590] iteration:25158  t-loss:0.1418, loss-lb:0.0647, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:33:54.783] iteration:25159  t-loss:0.1263, loss-lb:0.0731, loss-ulb:0.0266, weight:2.00, lr:0.0002
[12:33:54.975] iteration:25160  t-loss:0.1386, loss-lb:0.0690, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:33:55.167] iteration:25161  t-loss:0.1301, loss-lb:0.0701, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:33:55.360] iteration:25162  t-loss:0.1393, loss-lb:0.0691, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:33:55.552] iteration:25163  t-loss:0.1467, loss-lb:0.0757, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:33:55.744] iteration:25164  t-loss:0.1502, loss-lb:0.0784, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:33:55.938] iteration:25165  t-loss:0.1693, loss-lb:0.0723, loss-ulb:0.0485, weight:2.00, lr:0.0002
[12:33:56.130] iteration:25166  t-loss:0.1362, loss-lb:0.0685, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:33:56.323] iteration:25167  t-loss:0.1383, loss-lb:0.0721, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:33:56.519] iteration:25168  t-loss:0.2909, loss-lb:0.0730, loss-ulb:0.1089, weight:2.00, lr:0.0002
[12:33:56.713] iteration:25169  t-loss:0.1504, loss-lb:0.0773, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:33:56.906] iteration:25170  t-loss:0.1566, loss-lb:0.0755, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:33:57.099] iteration:25171  t-loss:0.1422, loss-lb:0.0667, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:33:57.292] iteration:25172  t-loss:0.1423, loss-lb:0.0691, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:33:57.484] iteration:25173  t-loss:0.1314, loss-lb:0.0675, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:33:57.676] iteration:25174  t-loss:0.1434, loss-lb:0.0645, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:33:57.868] iteration:25175  t-loss:0.1363, loss-lb:0.0653, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:33:58.060] iteration:25176  t-loss:0.1405, loss-lb:0.0728, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:33:58.252] iteration:25177  t-loss:0.1458, loss-lb:0.0681, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:33:58.444] iteration:25178  t-loss:0.1454, loss-lb:0.0690, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:33:58.636] iteration:25179  t-loss:0.2714, loss-lb:0.0813, loss-ulb:0.0950, weight:2.00, lr:0.0002
[12:33:58.827] iteration:25180  t-loss:0.1539, loss-lb:0.0729, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:33:59.018] iteration:25181  t-loss:0.1782, loss-lb:0.0729, loss-ulb:0.0526, weight:2.00, lr:0.0002
[12:33:59.209] iteration:25182  t-loss:0.1574, loss-lb:0.0783, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:33:59.399] iteration:25183  t-loss:0.1356, loss-lb:0.0691, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:33:59.589] iteration:25184  t-loss:0.1504, loss-lb:0.0772, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:33:59.781] iteration:25185  t-loss:0.1409, loss-lb:0.0710, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:33:59.971] iteration:25186  t-loss:0.1659, loss-lb:0.0712, loss-ulb:0.0473, weight:2.00, lr:0.0002
[12:34:12.972]  <<Test>> - Ep:256  - mean_dice/mean_h95 - S:89.75/1.35, Best-S:90.99, T:89.75/1.36, Best-T:90.48
[12:34:12.972]           - AvgLoss(lb/ulb/all):0.0720/0.0446/0.1609
[12:34:13.522] iteration:25187  t-loss:0.1516, loss-lb:0.0723, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:34:13.720] iteration:25188  t-loss:0.1335, loss-lb:0.0719, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:34:13.913] iteration:25189  t-loss:0.1386, loss-lb:0.0717, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:34:14.106] iteration:25190  t-loss:0.1429, loss-lb:0.0794, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:34:14.299] iteration:25191  t-loss:0.1366, loss-lb:0.0755, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:34:14.491] iteration:25192  t-loss:0.1503, loss-lb:0.0744, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:34:14.684] iteration:25193  t-loss:0.1386, loss-lb:0.0726, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:34:14.876] iteration:25194  t-loss:0.1425, loss-lb:0.0711, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:34:15.069] iteration:25195  t-loss:0.1550, loss-lb:0.0599, loss-ulb:0.0476, weight:2.00, lr:0.0002
[12:34:15.262] iteration:25196  t-loss:0.1294, loss-lb:0.0674, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:34:15.453] iteration:25197  t-loss:0.1414, loss-lb:0.0728, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:34:15.646] iteration:25198  t-loss:0.1309, loss-lb:0.0688, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:34:15.839] iteration:25199  t-loss:0.1459, loss-lb:0.0754, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:34:16.032] iteration:25200  t-loss:0.1252, loss-lb:0.0630, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:34:16.224] iteration:25201  t-loss:0.1433, loss-lb:0.0712, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:34:16.416] iteration:25202  t-loss:0.1517, loss-lb:0.0755, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:34:16.607] iteration:25203  t-loss:0.1542, loss-lb:0.0761, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:34:16.796] iteration:25204  t-loss:0.1552, loss-lb:0.0735, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:34:16.987] iteration:25205  t-loss:0.1335, loss-lb:0.0710, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:34:17.178] iteration:25206  t-loss:0.1511, loss-lb:0.0706, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:34:17.367] iteration:25207  t-loss:0.1565, loss-lb:0.0773, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:34:17.558] iteration:25208  t-loss:0.1569, loss-lb:0.0757, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:34:17.750] iteration:25209  t-loss:0.1524, loss-lb:0.0757, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:34:17.942] iteration:25210  t-loss:0.1396, loss-lb:0.0715, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:34:18.137] iteration:25211  t-loss:0.1504, loss-lb:0.0727, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:34:18.333] iteration:25212  t-loss:0.1813, loss-lb:0.0767, loss-ulb:0.0523, weight:2.00, lr:0.0002
[12:34:18.530] iteration:25213  t-loss:0.1481, loss-lb:0.0697, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:34:18.722] iteration:25214  t-loss:0.1554, loss-lb:0.0758, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:34:18.912] iteration:25215  t-loss:0.1459, loss-lb:0.0764, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:34:19.101] iteration:25216  t-loss:0.1510, loss-lb:0.0766, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:34:19.289] iteration:25217  t-loss:0.1429, loss-lb:0.0755, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:34:19.478] iteration:25218  t-loss:0.1359, loss-lb:0.0681, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:34:19.667] iteration:25219  t-loss:0.1323, loss-lb:0.0678, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:34:19.856] iteration:25220  t-loss:0.1257, loss-lb:0.0656, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:34:20.047] iteration:25221  t-loss:0.1511, loss-lb:0.0718, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:34:20.236] iteration:25222  t-loss:0.1501, loss-lb:0.0713, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:34:20.435] iteration:25223  t-loss:0.1570, loss-lb:0.0669, loss-ulb:0.0450, weight:2.00, lr:0.0002
[12:34:20.627] iteration:25224  t-loss:0.1524, loss-lb:0.0749, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:34:20.831] iteration:25225  t-loss:0.1434, loss-lb:0.0773, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:34:21.020] iteration:25226  t-loss:0.1462, loss-lb:0.0724, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:34:21.208] iteration:25227  t-loss:0.1396, loss-lb:0.0691, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:34:21.399] iteration:25228  t-loss:0.1510, loss-lb:0.0725, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:34:21.588] iteration:25229  t-loss:0.1463, loss-lb:0.0744, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:34:21.779] iteration:25230  t-loss:0.1397, loss-lb:0.0715, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:34:21.968] iteration:25231  t-loss:0.1509, loss-lb:0.0720, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:34:22.156] iteration:25232  t-loss:0.1334, loss-lb:0.0671, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:34:22.344] iteration:25233  t-loss:0.1475, loss-lb:0.0730, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:34:22.533] iteration:25234  t-loss:0.1440, loss-lb:0.0616, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:34:22.722] iteration:25235  t-loss:0.1403, loss-lb:0.0729, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:34:23.060] iteration:25236  t-loss:0.1308, loss-lb:0.0640, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:34:23.249] iteration:25237  t-loss:0.1402, loss-lb:0.0774, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:34:23.438] iteration:25238  t-loss:0.2213, loss-lb:0.0747, loss-ulb:0.0733, weight:2.00, lr:0.0002
[12:34:23.627] iteration:25239  t-loss:0.1657, loss-lb:0.0734, loss-ulb:0.0462, weight:2.00, lr:0.0002
[12:34:23.816] iteration:25240  t-loss:0.1388, loss-lb:0.0738, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:34:24.004] iteration:25241  t-loss:0.1349, loss-lb:0.0674, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:34:24.192] iteration:25242  t-loss:0.1669, loss-lb:0.0735, loss-ulb:0.0467, weight:2.00, lr:0.0002
[12:34:24.382] iteration:25243  t-loss:0.1537, loss-lb:0.0843, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:34:24.571] iteration:25244  t-loss:0.1525, loss-lb:0.0725, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:34:24.760] iteration:25245  t-loss:0.1359, loss-lb:0.0715, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:34:24.949] iteration:25246  t-loss:0.1401, loss-lb:0.0717, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:34:25.137] iteration:25247  t-loss:0.1424, loss-lb:0.0712, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:34:25.326] iteration:25248  t-loss:0.1357, loss-lb:0.0680, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:34:25.516] iteration:25249  t-loss:0.1428, loss-lb:0.0725, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:34:25.712] iteration:25250  t-loss:0.1987, loss-lb:0.0699, loss-ulb:0.0644, weight:2.00, lr:0.0002
[12:34:25.903] iteration:25251  t-loss:0.1518, loss-lb:0.0687, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:34:26.093] iteration:25252  t-loss:0.1444, loss-lb:0.0694, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:34:26.282] iteration:25253  t-loss:0.1530, loss-lb:0.0710, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:34:26.470] iteration:25254  t-loss:0.1350, loss-lb:0.0725, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:34:26.660] iteration:25255  t-loss:0.1628, loss-lb:0.0809, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:34:26.848] iteration:25256  t-loss:0.1364, loss-lb:0.0693, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:34:27.036] iteration:25257  t-loss:0.1452, loss-lb:0.0747, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:34:27.224] iteration:25258  t-loss:0.1479, loss-lb:0.0718, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:34:27.413] iteration:25259  t-loss:0.1382, loss-lb:0.0737, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:34:27.602] iteration:25260  t-loss:0.1661, loss-lb:0.0816, loss-ulb:0.0423, weight:2.00, lr:0.0002
[12:34:27.790] iteration:25261  t-loss:0.1792, loss-lb:0.0754, loss-ulb:0.0519, weight:2.00, lr:0.0002
[12:34:27.977] iteration:25262  t-loss:0.1482, loss-lb:0.0781, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:34:28.165] iteration:25263  t-loss:0.1504, loss-lb:0.0703, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:34:28.354] iteration:25264  t-loss:0.1424, loss-lb:0.0678, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:34:28.542] iteration:25265  t-loss:0.1354, loss-lb:0.0673, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:34:28.730] iteration:25266  t-loss:0.1412, loss-lb:0.0707, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:34:28.918] iteration:25267  t-loss:0.1499, loss-lb:0.0684, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:34:29.108] iteration:25268  t-loss:0.1568, loss-lb:0.0836, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:34:29.298] iteration:25269  t-loss:0.1429, loss-lb:0.0704, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:34:29.490] iteration:25270  t-loss:0.1365, loss-lb:0.0664, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:34:29.695] iteration:25271  t-loss:0.1437, loss-lb:0.0687, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:34:29.889] iteration:25272  t-loss:0.1500, loss-lb:0.0685, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:34:30.084] iteration:25273  t-loss:0.1556, loss-lb:0.0717, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:34:30.277] iteration:25274  t-loss:0.1470, loss-lb:0.0710, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:34:30.471] iteration:25275  t-loss:0.1626, loss-lb:0.0714, loss-ulb:0.0456, weight:2.00, lr:0.0002
[12:34:30.663] iteration:25276  t-loss:0.1407, loss-lb:0.0747, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:34:30.855] iteration:25277  t-loss:0.1688, loss-lb:0.0743, loss-ulb:0.0472, weight:2.00, lr:0.0002
[12:34:31.048] iteration:25278  t-loss:0.1360, loss-lb:0.0694, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:34:31.238] iteration:25279  t-loss:0.1300, loss-lb:0.0682, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:34:31.432] iteration:25280  t-loss:0.2668, loss-lb:0.0810, loss-ulb:0.0929, weight:2.00, lr:0.0002
[12:34:31.626] iteration:25281  t-loss:0.1362, loss-lb:0.0758, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:34:31.820] iteration:25282  t-loss:0.1411, loss-lb:0.0779, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:34:32.013] iteration:25283  t-loss:0.1432, loss-lb:0.0681, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:34:32.204] iteration:25284  t-loss:0.1441, loss-lb:0.0709, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:34:32.800] iteration:25285  t-loss:0.1375, loss-lb:0.0719, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:34:32.996] iteration:25286  t-loss:0.1366, loss-lb:0.0671, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:34:33.188] iteration:25287  t-loss:0.1252, loss-lb:0.0686, loss-ulb:0.0283, weight:2.00, lr:0.0002
[12:34:33.380] iteration:25288  t-loss:0.1583, loss-lb:0.0777, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:34:33.573] iteration:25289  t-loss:0.1474, loss-lb:0.0806, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:34:33.766] iteration:25290  t-loss:0.1378, loss-lb:0.0723, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:34:33.958] iteration:25291  t-loss:0.1299, loss-lb:0.0694, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:34:34.150] iteration:25292  t-loss:0.1342, loss-lb:0.0716, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:34:34.344] iteration:25293  t-loss:0.1422, loss-lb:0.0717, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:34:34.535] iteration:25294  t-loss:0.1317, loss-lb:0.0611, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:34:34.727] iteration:25295  t-loss:0.1508, loss-lb:0.0781, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:34:34.920] iteration:25296  t-loss:0.1346, loss-lb:0.0650, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:34:35.113] iteration:25297  t-loss:0.1737, loss-lb:0.0704, loss-ulb:0.0516, weight:2.00, lr:0.0002
[12:34:35.305] iteration:25298  t-loss:0.1374, loss-lb:0.0709, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:34:35.515] iteration:25299  t-loss:0.2080, loss-lb:0.0666, loss-ulb:0.0707, weight:2.00, lr:0.0002
[12:34:35.707] iteration:25300  t-loss:0.1540, loss-lb:0.0680, loss-ulb:0.0430, weight:2.00, lr:0.0002
[12:34:35.900] iteration:25301  t-loss:0.1597, loss-lb:0.0779, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:34:36.093] iteration:25302  t-loss:0.1665, loss-lb:0.0696, loss-ulb:0.0485, weight:2.00, lr:0.0002
[12:34:36.286] iteration:25303  t-loss:0.1587, loss-lb:0.0809, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:34:36.478] iteration:25304  t-loss:0.1489, loss-lb:0.0683, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:34:36.671] iteration:25305  t-loss:0.1362, loss-lb:0.0697, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:34:36.867] iteration:25306  t-loss:0.1516, loss-lb:0.0759, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:34:37.059] iteration:25307  t-loss:0.1592, loss-lb:0.0723, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:34:37.251] iteration:25308  t-loss:0.1740, loss-lb:0.0767, loss-ulb:0.0486, weight:2.00, lr:0.0002
[12:34:37.443] iteration:25309  t-loss:0.1479, loss-lb:0.0784, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:34:37.636] iteration:25310  t-loss:0.1484, loss-lb:0.0803, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:34:37.828] iteration:25311  t-loss:0.1422, loss-lb:0.0699, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:34:38.020] iteration:25312  t-loss:0.1445, loss-lb:0.0704, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:34:38.211] iteration:25313  t-loss:0.1405, loss-lb:0.0720, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:34:38.404] iteration:25314  t-loss:0.1449, loss-lb:0.0766, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:34:38.596] iteration:25315  t-loss:0.1483, loss-lb:0.0737, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:34:38.790] iteration:25316  t-loss:0.1370, loss-lb:0.0681, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:34:38.982] iteration:25317  t-loss:0.1474, loss-lb:0.0680, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:34:39.174] iteration:25318  t-loss:0.1339, loss-lb:0.0635, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:34:39.366] iteration:25319  t-loss:0.1369, loss-lb:0.0691, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:34:39.558] iteration:25320  t-loss:0.1382, loss-lb:0.0740, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:34:39.752] iteration:25321  t-loss:0.1496, loss-lb:0.0776, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:34:39.945] iteration:25322  t-loss:0.1335, loss-lb:0.0666, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:34:40.137] iteration:25323  t-loss:0.1457, loss-lb:0.0771, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:34:40.330] iteration:25324  t-loss:0.1378, loss-lb:0.0661, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:34:40.523] iteration:25325  t-loss:0.1462, loss-lb:0.0676, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:34:40.716] iteration:25326  t-loss:0.1520, loss-lb:0.0748, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:34:40.910] iteration:25327  t-loss:0.1542, loss-lb:0.0790, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:34:41.103] iteration:25328  t-loss:0.1373, loss-lb:0.0689, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:34:41.296] iteration:25329  t-loss:0.1397, loss-lb:0.0654, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:34:41.490] iteration:25330  t-loss:0.1673, loss-lb:0.0701, loss-ulb:0.0486, weight:2.00, lr:0.0002
[12:34:41.683] iteration:25331  t-loss:0.1392, loss-lb:0.0693, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:34:41.877] iteration:25332  t-loss:0.1363, loss-lb:0.0705, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:34:42.070] iteration:25333  t-loss:0.1390, loss-lb:0.0734, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:34:42.262] iteration:25334  t-loss:0.1355, loss-lb:0.0738, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:34:42.454] iteration:25335  t-loss:0.1202, loss-lb:0.0638, loss-ulb:0.0282, weight:2.00, lr:0.0002
[12:34:42.646] iteration:25336  t-loss:0.1363, loss-lb:0.0654, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:34:42.841] iteration:25337  t-loss:0.1550, loss-lb:0.0722, loss-ulb:0.0414, weight:2.00, lr:0.0002
[12:34:43.034] iteration:25338  t-loss:0.1427, loss-lb:0.0641, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:34:43.229] iteration:25339  t-loss:0.1389, loss-lb:0.0685, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:34:43.421] iteration:25340  t-loss:0.1393, loss-lb:0.0764, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:34:43.614] iteration:25341  t-loss:0.1433, loss-lb:0.0800, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:34:43.808] iteration:25342  t-loss:0.1319, loss-lb:0.0706, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:34:44.005] iteration:25343  t-loss:0.1386, loss-lb:0.0619, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:34:44.200] iteration:25344  t-loss:0.1973, loss-lb:0.0726, loss-ulb:0.0624, weight:2.00, lr:0.0002
[12:34:44.396] iteration:25345  t-loss:0.1407, loss-lb:0.0707, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:34:44.592] iteration:25346  t-loss:0.1355, loss-lb:0.0747, loss-ulb:0.0304, weight:2.00, lr:0.0002
[12:34:44.789] iteration:25347  t-loss:0.1574, loss-lb:0.0718, loss-ulb:0.0428, weight:2.00, lr:0.0002
[12:34:44.985] iteration:25348  t-loss:0.1384, loss-lb:0.0713, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:34:45.178] iteration:25349  t-loss:0.1494, loss-lb:0.0721, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:34:45.371] iteration:25350  t-loss:0.1483, loss-lb:0.0706, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:34:45.563] iteration:25351  t-loss:0.1625, loss-lb:0.0725, loss-ulb:0.0450, weight:2.00, lr:0.0002
[12:34:45.756] iteration:25352  t-loss:0.1385, loss-lb:0.0686, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:34:45.950] iteration:25353  t-loss:0.1358, loss-lb:0.0683, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:34:46.142] iteration:25354  t-loss:0.1429, loss-lb:0.0726, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:34:46.335] iteration:25355  t-loss:0.1469, loss-lb:0.0690, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:34:46.528] iteration:25356  t-loss:0.1438, loss-lb:0.0708, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:34:46.720] iteration:25357  t-loss:0.1528, loss-lb:0.0807, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:34:46.913] iteration:25358  t-loss:0.1356, loss-lb:0.0706, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:34:47.106] iteration:25359  t-loss:0.1579, loss-lb:0.0708, loss-ulb:0.0436, weight:2.00, lr:0.0002
[12:34:47.299] iteration:25360  t-loss:0.1290, loss-lb:0.0699, loss-ulb:0.0295, weight:2.00, lr:0.0002
[12:34:47.491] iteration:25361  t-loss:0.1332, loss-lb:0.0710, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:34:47.684] iteration:25362  t-loss:0.1407, loss-lb:0.0755, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:34:47.877] iteration:25363  t-loss:0.1442, loss-lb:0.0724, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:34:48.070] iteration:25364  t-loss:0.1402, loss-lb:0.0739, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:34:48.263] iteration:25365  t-loss:0.1266, loss-lb:0.0671, loss-ulb:0.0298, weight:2.00, lr:0.0002
[12:34:48.457] iteration:25366  t-loss:0.1464, loss-lb:0.0779, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:34:48.651] iteration:25367  t-loss:0.1524, loss-lb:0.0732, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:34:48.844] iteration:25368  t-loss:0.1605, loss-lb:0.0672, loss-ulb:0.0467, weight:2.00, lr:0.0002
[12:34:49.040] iteration:25369  t-loss:0.1428, loss-lb:0.0731, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:34:49.234] iteration:25370  t-loss:0.1450, loss-lb:0.0662, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:34:49.427] iteration:25371  t-loss:0.1412, loss-lb:0.0669, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:34:49.620] iteration:25372  t-loss:0.1384, loss-lb:0.0745, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:34:49.814] iteration:25373  t-loss:0.1728, loss-lb:0.0730, loss-ulb:0.0499, weight:2.00, lr:0.0002
[12:34:50.007] iteration:25374  t-loss:0.1416, loss-lb:0.0673, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:34:50.200] iteration:25375  t-loss:0.1361, loss-lb:0.0738, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:34:50.391] iteration:25376  t-loss:0.1501, loss-lb:0.0746, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:34:50.583] iteration:25377  t-loss:0.2180, loss-lb:0.0781, loss-ulb:0.0700, weight:2.00, lr:0.0002
[12:34:50.774] iteration:25378  t-loss:0.1489, loss-lb:0.0710, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:34:50.966] iteration:25379  t-loss:0.1430, loss-lb:0.0652, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:34:51.157] iteration:25380  t-loss:0.1514, loss-lb:0.0749, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:34:51.348] iteration:25381  t-loss:0.1442, loss-lb:0.0667, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:34:51.540] iteration:25382  t-loss:0.1364, loss-lb:0.0687, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:35:03.967]  <<Test>> - Ep:258  - mean_dice/mean_h95 - S:89.70/1.34, Best-S:90.99, T:89.62/1.39, Best-T:90.48
[12:35:03.967]           - AvgLoss(lb/ulb/all):0.0714/0.0389/0.1490
[12:35:04.518] iteration:25383  t-loss:0.2022, loss-lb:0.0782, loss-ulb:0.0620, weight:2.00, lr:0.0002
[12:35:04.714] iteration:25384  t-loss:0.1604, loss-lb:0.0716, loss-ulb:0.0444, weight:2.00, lr:0.0002
[12:35:04.907] iteration:25385  t-loss:0.1384, loss-lb:0.0677, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:35:05.099] iteration:25386  t-loss:0.1583, loss-lb:0.0795, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:35:05.293] iteration:25387  t-loss:0.1429, loss-lb:0.0751, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:35:05.487] iteration:25388  t-loss:0.1431, loss-lb:0.0740, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:35:05.679] iteration:25389  t-loss:0.1435, loss-lb:0.0838, loss-ulb:0.0298, weight:2.00, lr:0.0002
[12:35:05.871] iteration:25390  t-loss:0.1430, loss-lb:0.0649, loss-ulb:0.0390, weight:2.00, lr:0.0002
[12:35:06.065] iteration:25391  t-loss:0.1364, loss-lb:0.0664, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:35:06.258] iteration:25392  t-loss:0.1268, loss-lb:0.0632, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:35:06.451] iteration:25393  t-loss:0.1283, loss-lb:0.0633, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:35:06.644] iteration:25394  t-loss:0.1434, loss-lb:0.0807, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:35:06.838] iteration:25395  t-loss:0.1818, loss-lb:0.0695, loss-ulb:0.0562, weight:2.00, lr:0.0002
[12:35:07.032] iteration:25396  t-loss:0.1369, loss-lb:0.0637, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:35:07.226] iteration:25397  t-loss:0.1380, loss-lb:0.0714, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:35:07.418] iteration:25398  t-loss:0.1337, loss-lb:0.0698, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:35:07.610] iteration:25399  t-loss:0.1451, loss-lb:0.0733, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:35:07.804] iteration:25400  t-loss:0.1430, loss-lb:0.0722, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:35:07.998] iteration:25401  t-loss:0.1579, loss-lb:0.0801, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:35:08.191] iteration:25402  t-loss:0.1411, loss-lb:0.0781, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:35:08.382] iteration:25403  t-loss:0.1392, loss-lb:0.0751, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:35:08.575] iteration:25404  t-loss:0.1295, loss-lb:0.0711, loss-ulb:0.0292, weight:2.00, lr:0.0002
[12:35:08.768] iteration:25405  t-loss:0.1381, loss-lb:0.0750, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:35:08.960] iteration:25406  t-loss:0.1334, loss-lb:0.0681, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:35:09.152] iteration:25407  t-loss:0.1338, loss-lb:0.0652, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:35:09.344] iteration:25408  t-loss:0.1609, loss-lb:0.0744, loss-ulb:0.0433, weight:2.00, lr:0.0002
[12:35:09.537] iteration:25409  t-loss:0.1507, loss-lb:0.0770, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:35:09.729] iteration:25410  t-loss:0.1335, loss-lb:0.0721, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:35:09.923] iteration:25411  t-loss:0.1666, loss-lb:0.0702, loss-ulb:0.0482, weight:2.00, lr:0.0002
[12:35:10.114] iteration:25412  t-loss:0.1373, loss-lb:0.0703, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:35:10.306] iteration:25413  t-loss:0.1389, loss-lb:0.0678, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:35:10.500] iteration:25414  t-loss:0.1467, loss-lb:0.0760, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:35:10.692] iteration:25415  t-loss:0.1415, loss-lb:0.0741, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:35:10.884] iteration:25416  t-loss:0.1457, loss-lb:0.0691, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:35:11.076] iteration:25417  t-loss:0.1671, loss-lb:0.0720, loss-ulb:0.0475, weight:2.00, lr:0.0002
[12:35:11.268] iteration:25418  t-loss:0.1499, loss-lb:0.0733, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:35:11.460] iteration:25419  t-loss:0.1372, loss-lb:0.0694, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:35:11.653] iteration:25420  t-loss:0.1346, loss-lb:0.0720, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:35:11.847] iteration:25421  t-loss:0.1389, loss-lb:0.0755, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:35:12.041] iteration:25422  t-loss:0.1440, loss-lb:0.0705, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:35:12.233] iteration:25423  t-loss:0.1449, loss-lb:0.0780, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:35:12.425] iteration:25424  t-loss:0.1566, loss-lb:0.0754, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:35:12.617] iteration:25425  t-loss:0.1564, loss-lb:0.0773, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:35:12.809] iteration:25426  t-loss:0.1410, loss-lb:0.0618, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:35:13.002] iteration:25427  t-loss:0.1400, loss-lb:0.0657, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:35:13.195] iteration:25428  t-loss:0.1414, loss-lb:0.0721, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:35:13.387] iteration:25429  t-loss:0.1421, loss-lb:0.0726, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:35:13.580] iteration:25430  t-loss:0.1767, loss-lb:0.0676, loss-ulb:0.0546, weight:2.00, lr:0.0002
[12:35:13.773] iteration:25431  t-loss:0.1481, loss-lb:0.0782, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:35:13.964] iteration:25432  t-loss:0.1369, loss-lb:0.0762, loss-ulb:0.0303, weight:2.00, lr:0.0002
[12:35:14.157] iteration:25433  t-loss:0.1527, loss-lb:0.0690, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:35:14.349] iteration:25434  t-loss:0.1399, loss-lb:0.0737, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:35:14.541] iteration:25435  t-loss:0.1325, loss-lb:0.0688, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:35:14.735] iteration:25436  t-loss:0.1229, loss-lb:0.0622, loss-ulb:0.0303, weight:2.00, lr:0.0002
[12:35:14.928] iteration:25437  t-loss:0.2365, loss-lb:0.0763, loss-ulb:0.0801, weight:2.00, lr:0.0002
[12:35:15.121] iteration:25438  t-loss:0.1443, loss-lb:0.0705, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:35:15.312] iteration:25439  t-loss:0.2002, loss-lb:0.0746, loss-ulb:0.0628, weight:2.00, lr:0.0002
[12:35:15.505] iteration:25440  t-loss:0.1335, loss-lb:0.0712, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:35:15.698] iteration:25441  t-loss:0.1439, loss-lb:0.0727, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:35:15.891] iteration:25442  t-loss:0.1355, loss-lb:0.0756, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:35:16.083] iteration:25443  t-loss:0.1355, loss-lb:0.0655, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:35:16.276] iteration:25444  t-loss:0.1413, loss-lb:0.0675, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:35:16.469] iteration:25445  t-loss:0.1423, loss-lb:0.0734, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:35:16.661] iteration:25446  t-loss:0.1275, loss-lb:0.0652, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:35:16.853] iteration:25447  t-loss:0.1721, loss-lb:0.0949, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:35:17.045] iteration:25448  t-loss:0.1422, loss-lb:0.0660, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:35:17.238] iteration:25449  t-loss:0.1460, loss-lb:0.0725, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:35:17.430] iteration:25450  t-loss:0.1389, loss-lb:0.0752, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:35:17.623] iteration:25451  t-loss:0.1536, loss-lb:0.0732, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:35:17.814] iteration:25452  t-loss:0.1694, loss-lb:0.0807, loss-ulb:0.0444, weight:2.00, lr:0.0002
[12:35:18.006] iteration:25453  t-loss:0.1662, loss-lb:0.0754, loss-ulb:0.0454, weight:2.00, lr:0.0002
[12:35:18.199] iteration:25454  t-loss:0.1311, loss-lb:0.0695, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:35:18.392] iteration:25455  t-loss:0.1427, loss-lb:0.0727, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:35:18.583] iteration:25456  t-loss:0.1408, loss-lb:0.0745, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:35:18.776] iteration:25457  t-loss:0.1241, loss-lb:0.0672, loss-ulb:0.0285, weight:2.00, lr:0.0002
[12:35:18.969] iteration:25458  t-loss:0.1483, loss-lb:0.0833, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:35:19.163] iteration:25459  t-loss:0.2489, loss-lb:0.0724, loss-ulb:0.0882, weight:2.00, lr:0.0002
[12:35:19.355] iteration:25460  t-loss:0.1479, loss-lb:0.0718, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:35:19.547] iteration:25461  t-loss:0.1368, loss-lb:0.0671, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:35:19.740] iteration:25462  t-loss:0.1494, loss-lb:0.0765, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:35:19.933] iteration:25463  t-loss:0.1559, loss-lb:0.0686, loss-ulb:0.0437, weight:2.00, lr:0.0002
[12:35:20.124] iteration:25464  t-loss:0.1385, loss-lb:0.0732, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:35:20.318] iteration:25465  t-loss:0.1635, loss-lb:0.0829, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:35:20.511] iteration:25466  t-loss:0.1280, loss-lb:0.0693, loss-ulb:0.0294, weight:2.00, lr:0.0002
[12:35:20.704] iteration:25467  t-loss:0.1397, loss-lb:0.0769, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:35:20.897] iteration:25468  t-loss:0.1333, loss-lb:0.0601, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:35:21.089] iteration:25469  t-loss:0.1404, loss-lb:0.0705, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:35:21.281] iteration:25470  t-loss:0.1485, loss-lb:0.0736, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:35:21.473] iteration:25471  t-loss:0.1408, loss-lb:0.0716, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:35:21.666] iteration:25472  t-loss:0.1474, loss-lb:0.0719, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:35:21.857] iteration:25473  t-loss:0.1583, loss-lb:0.0759, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:35:22.049] iteration:25474  t-loss:0.1633, loss-lb:0.0743, loss-ulb:0.0445, weight:2.00, lr:0.0002
[12:35:22.239] iteration:25475  t-loss:0.1403, loss-lb:0.0683, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:35:22.431] iteration:25476  t-loss:0.1578, loss-lb:0.0744, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:35:22.621] iteration:25477  t-loss:0.1391, loss-lb:0.0684, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:35:22.811] iteration:25478  t-loss:0.1458, loss-lb:0.0789, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:35:23.002] iteration:25479  t-loss:0.1433, loss-lb:0.0785, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:35:23.193] iteration:25480  t-loss:0.1573, loss-lb:0.0742, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:35:23.816] iteration:25481  t-loss:0.1461, loss-lb:0.0677, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:35:24.011] iteration:25482  t-loss:0.1356, loss-lb:0.0661, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:35:24.204] iteration:25483  t-loss:0.1326, loss-lb:0.0675, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:35:24.397] iteration:25484  t-loss:0.1582, loss-lb:0.0860, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:35:24.589] iteration:25485  t-loss:0.1356, loss-lb:0.0762, loss-ulb:0.0297, weight:2.00, lr:0.0002
[12:35:24.782] iteration:25486  t-loss:0.1439, loss-lb:0.0714, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:35:24.975] iteration:25487  t-loss:0.1618, loss-lb:0.0752, loss-ulb:0.0433, weight:2.00, lr:0.0002
[12:35:25.168] iteration:25488  t-loss:0.1333, loss-lb:0.0694, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:35:25.360] iteration:25489  t-loss:0.1365, loss-lb:0.0657, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:35:25.552] iteration:25490  t-loss:0.1449, loss-lb:0.0730, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:35:25.746] iteration:25491  t-loss:0.1588, loss-lb:0.0720, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:35:25.938] iteration:25492  t-loss:0.1526, loss-lb:0.0795, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:35:26.130] iteration:25493  t-loss:0.1435, loss-lb:0.0650, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:35:26.322] iteration:25494  t-loss:0.1303, loss-lb:0.0731, loss-ulb:0.0286, weight:2.00, lr:0.0002
[12:35:26.515] iteration:25495  t-loss:0.1409, loss-lb:0.0658, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:35:26.707] iteration:25496  t-loss:0.1463, loss-lb:0.0722, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:35:26.901] iteration:25497  t-loss:0.1565, loss-lb:0.0792, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:35:27.094] iteration:25498  t-loss:0.1438, loss-lb:0.0739, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:35:27.286] iteration:25499  t-loss:0.1425, loss-lb:0.0710, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:35:27.478] iteration:25500  t-loss:0.1406, loss-lb:0.0726, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:35:27.671] iteration:25501  t-loss:0.1386, loss-lb:0.0668, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:35:27.864] iteration:25502  t-loss:0.1387, loss-lb:0.0734, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:35:28.057] iteration:25503  t-loss:0.1350, loss-lb:0.0758, loss-ulb:0.0296, weight:2.00, lr:0.0002
[12:35:28.249] iteration:25504  t-loss:0.1342, loss-lb:0.0687, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:35:28.441] iteration:25505  t-loss:0.1455, loss-lb:0.0694, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:35:28.633] iteration:25506  t-loss:0.1312, loss-lb:0.0723, loss-ulb:0.0295, weight:2.00, lr:0.0002
[12:35:28.825] iteration:25507  t-loss:0.1350, loss-lb:0.0700, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:35:29.018] iteration:25508  t-loss:0.1442, loss-lb:0.0692, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:35:29.209] iteration:25509  t-loss:0.1341, loss-lb:0.0653, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:35:29.401] iteration:25510  t-loss:0.1496, loss-lb:0.0678, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:35:29.595] iteration:25511  t-loss:0.2207, loss-lb:0.0682, loss-ulb:0.0762, weight:2.00, lr:0.0002
[12:35:29.789] iteration:25512  t-loss:0.2957, loss-lb:0.0712, loss-ulb:0.1122, weight:2.00, lr:0.0002
[12:35:29.980] iteration:25513  t-loss:0.1350, loss-lb:0.0676, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:35:30.174] iteration:25514  t-loss:0.1301, loss-lb:0.0710, loss-ulb:0.0296, weight:2.00, lr:0.0002
[12:35:30.370] iteration:25515  t-loss:0.2335, loss-lb:0.0673, loss-ulb:0.0831, weight:2.00, lr:0.0002
[12:35:30.566] iteration:25516  t-loss:0.1495, loss-lb:0.0726, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:35:30.760] iteration:25517  t-loss:0.1435, loss-lb:0.0721, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:35:30.953] iteration:25518  t-loss:0.1343, loss-lb:0.0721, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:35:31.159] iteration:25519  t-loss:0.1381, loss-lb:0.0683, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:35:31.358] iteration:25520  t-loss:0.1508, loss-lb:0.0762, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:35:31.556] iteration:25521  t-loss:0.1649, loss-lb:0.0774, loss-ulb:0.0438, weight:2.00, lr:0.0002
[12:35:31.748] iteration:25522  t-loss:0.1347, loss-lb:0.0676, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:35:31.939] iteration:25523  t-loss:0.1351, loss-lb:0.0708, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:35:32.132] iteration:25524  t-loss:0.1291, loss-lb:0.0663, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:35:32.324] iteration:25525  t-loss:0.1406, loss-lb:0.0694, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:35:32.517] iteration:25526  t-loss:0.1417, loss-lb:0.0763, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:35:32.708] iteration:25527  t-loss:0.1462, loss-lb:0.0686, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:35:32.900] iteration:25528  t-loss:0.1298, loss-lb:0.0645, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:35:33.091] iteration:25529  t-loss:0.1381, loss-lb:0.0702, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:35:33.284] iteration:25530  t-loss:0.1341, loss-lb:0.0687, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:35:33.477] iteration:25531  t-loss:0.1350, loss-lb:0.0685, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:35:33.668] iteration:25532  t-loss:0.1462, loss-lb:0.0717, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:35:33.859] iteration:25533  t-loss:0.1416, loss-lb:0.0793, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:35:34.052] iteration:25534  t-loss:0.1419, loss-lb:0.0673, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:35:34.244] iteration:25535  t-loss:0.1449, loss-lb:0.0731, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:35:34.437] iteration:25536  t-loss:0.1473, loss-lb:0.0705, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:35:34.629] iteration:25537  t-loss:0.1462, loss-lb:0.0733, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:35:34.822] iteration:25538  t-loss:0.1337, loss-lb:0.0671, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:35:35.015] iteration:25539  t-loss:0.1472, loss-lb:0.0728, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:35:35.206] iteration:25540  t-loss:0.1960, loss-lb:0.1123, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:35:35.399] iteration:25541  t-loss:0.1288, loss-lb:0.0695, loss-ulb:0.0297, weight:2.00, lr:0.0002
[12:35:35.593] iteration:25542  t-loss:0.1520, loss-lb:0.0704, loss-ulb:0.0408, weight:2.00, lr:0.0002
[12:35:35.788] iteration:25543  t-loss:0.1500, loss-lb:0.0707, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:35:35.979] iteration:25544  t-loss:0.1422, loss-lb:0.0748, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:35:36.171] iteration:25545  t-loss:0.1506, loss-lb:0.0799, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:35:36.364] iteration:25546  t-loss:0.1379, loss-lb:0.0748, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:35:36.555] iteration:25547  t-loss:0.1547, loss-lb:0.0744, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:35:36.747] iteration:25548  t-loss:0.1452, loss-lb:0.0725, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:35:36.939] iteration:25549  t-loss:0.1561, loss-lb:0.0750, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:35:37.131] iteration:25550  t-loss:0.1303, loss-lb:0.0688, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:35:37.323] iteration:25551  t-loss:0.1481, loss-lb:0.0729, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:35:37.516] iteration:25552  t-loss:0.1470, loss-lb:0.0761, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:35:37.709] iteration:25553  t-loss:0.1375, loss-lb:0.0737, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:35:37.902] iteration:25554  t-loss:0.2447, loss-lb:0.0761, loss-ulb:0.0843, weight:2.00, lr:0.0002
[12:35:38.094] iteration:25555  t-loss:0.1321, loss-lb:0.0662, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:35:38.287] iteration:25556  t-loss:0.1671, loss-lb:0.0786, loss-ulb:0.0443, weight:2.00, lr:0.0002
[12:35:38.478] iteration:25557  t-loss:0.1389, loss-lb:0.0689, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:35:38.670] iteration:25558  t-loss:0.1481, loss-lb:0.0713, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:35:38.861] iteration:25559  t-loss:0.1406, loss-lb:0.0715, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:35:39.053] iteration:25560  t-loss:0.1716, loss-lb:0.0717, loss-ulb:0.0500, weight:2.00, lr:0.0002
[12:35:39.245] iteration:25561  t-loss:0.1462, loss-lb:0.0665, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:35:39.436] iteration:25562  t-loss:0.1440, loss-lb:0.0710, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:35:39.627] iteration:25563  t-loss:0.1405, loss-lb:0.0745, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:35:39.818] iteration:25564  t-loss:0.1493, loss-lb:0.0747, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:35:40.009] iteration:25565  t-loss:0.1440, loss-lb:0.0707, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:35:40.201] iteration:25566  t-loss:0.1574, loss-lb:0.0759, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:35:40.393] iteration:25567  t-loss:0.1957, loss-lb:0.0742, loss-ulb:0.0607, weight:2.00, lr:0.0002
[12:35:40.585] iteration:25568  t-loss:0.1397, loss-lb:0.0754, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:35:40.777] iteration:25569  t-loss:0.1412, loss-lb:0.0735, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:35:40.969] iteration:25570  t-loss:0.1344, loss-lb:0.0697, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:35:41.162] iteration:25571  t-loss:0.1515, loss-lb:0.0774, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:35:41.356] iteration:25572  t-loss:0.1339, loss-lb:0.0715, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:35:41.551] iteration:25573  t-loss:0.1587, loss-lb:0.0686, loss-ulb:0.0451, weight:2.00, lr:0.0002
[12:35:41.746] iteration:25574  t-loss:0.1551, loss-lb:0.0778, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:35:41.938] iteration:25575  t-loss:0.1934, loss-lb:0.0789, loss-ulb:0.0573, weight:2.00, lr:0.0002
[12:35:42.130] iteration:25576  t-loss:0.1351, loss-lb:0.0735, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:35:42.321] iteration:25577  t-loss:0.1441, loss-lb:0.0699, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:35:42.513] iteration:25578  t-loss:0.1617, loss-lb:0.0757, loss-ulb:0.0430, weight:2.00, lr:0.0002
[12:35:55.262]  <<Test>> - Ep:260  - mean_dice/mean_h95 - S:89.67/1.35, Best-S:90.99, T:89.65/1.38, Best-T:90.48
[12:35:55.263]           - AvgLoss(lb/ulb/all):0.0723/0.0394/0.1519
[12:35:55.782] iteration:25579  t-loss:0.1688, loss-lb:0.0764, loss-ulb:0.0462, weight:2.00, lr:0.0002
[12:35:55.981] iteration:25580  t-loss:0.1419, loss-lb:0.0683, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:35:56.174] iteration:25581  t-loss:0.1332, loss-lb:0.0642, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:35:56.367] iteration:25582  t-loss:0.1563, loss-lb:0.0756, loss-ulb:0.0404, weight:2.00, lr:0.0002
[12:35:56.560] iteration:25583  t-loss:0.1443, loss-lb:0.0798, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:35:56.751] iteration:25584  t-loss:0.1547, loss-lb:0.0721, loss-ulb:0.0413, weight:2.00, lr:0.0002
[12:35:56.944] iteration:25585  t-loss:0.1331, loss-lb:0.0712, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:35:57.138] iteration:25586  t-loss:0.1966, loss-lb:0.0748, loss-ulb:0.0609, weight:2.00, lr:0.0002
[12:35:57.334] iteration:25587  t-loss:0.1308, loss-lb:0.0648, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:35:57.527] iteration:25588  t-loss:0.1409, loss-lb:0.0694, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:35:57.719] iteration:25589  t-loss:0.1338, loss-lb:0.0694, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:35:57.912] iteration:25590  t-loss:0.1483, loss-lb:0.0734, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:35:58.104] iteration:25591  t-loss:0.1544, loss-lb:0.0683, loss-ulb:0.0430, weight:2.00, lr:0.0002
[12:35:58.297] iteration:25592  t-loss:0.1675, loss-lb:0.0765, loss-ulb:0.0455, weight:2.00, lr:0.0002
[12:35:58.490] iteration:25593  t-loss:0.2191, loss-lb:0.0744, loss-ulb:0.0723, weight:2.00, lr:0.0002
[12:35:58.682] iteration:25594  t-loss:0.1330, loss-lb:0.0665, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:35:58.875] iteration:25595  t-loss:0.2493, loss-lb:0.0726, loss-ulb:0.0884, weight:2.00, lr:0.0002
[12:35:59.067] iteration:25596  t-loss:0.1400, loss-lb:0.0753, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:35:59.259] iteration:25597  t-loss:0.1536, loss-lb:0.0796, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:35:59.451] iteration:25598  t-loss:0.1479, loss-lb:0.0731, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:35:59.643] iteration:25599  t-loss:0.1528, loss-lb:0.0695, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:35:59.834] iteration:25600  t-loss:0.1320, loss-lb:0.0709, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:36:00.026] iteration:25601  t-loss:0.1549, loss-lb:0.0725, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:36:00.218] iteration:25602  t-loss:0.1468, loss-lb:0.0730, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:36:00.409] iteration:25603  t-loss:0.1604, loss-lb:0.0799, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:36:00.601] iteration:25604  t-loss:0.1520, loss-lb:0.0766, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:36:00.792] iteration:25605  t-loss:0.1496, loss-lb:0.0708, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:36:00.984] iteration:25606  t-loss:0.1474, loss-lb:0.0755, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:36:01.175] iteration:25607  t-loss:0.1355, loss-lb:0.0645, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:36:01.367] iteration:25608  t-loss:0.1873, loss-lb:0.0668, loss-ulb:0.0602, weight:2.00, lr:0.0002
[12:36:01.558] iteration:25609  t-loss:0.1383, loss-lb:0.0737, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:36:01.750] iteration:25610  t-loss:0.1554, loss-lb:0.0767, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:36:01.942] iteration:25611  t-loss:0.1438, loss-lb:0.0640, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:36:02.133] iteration:25612  t-loss:0.1339, loss-lb:0.0663, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:36:02.325] iteration:25613  t-loss:0.1428, loss-lb:0.0734, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:36:02.517] iteration:25614  t-loss:0.1463, loss-lb:0.0745, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:36:02.709] iteration:25615  t-loss:0.1483, loss-lb:0.0705, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:36:02.902] iteration:25616  t-loss:0.1342, loss-lb:0.0651, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:03.097] iteration:25617  t-loss:0.1479, loss-lb:0.0766, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:36:03.292] iteration:25618  t-loss:0.1300, loss-lb:0.0659, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:36:03.485] iteration:25619  t-loss:0.1468, loss-lb:0.0706, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:36:03.679] iteration:25620  t-loss:0.1504, loss-lb:0.0794, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:36:03.878] iteration:25621  t-loss:0.1352, loss-lb:0.0683, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:36:04.081] iteration:25622  t-loss:0.1309, loss-lb:0.0677, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:36:04.279] iteration:25623  t-loss:0.1433, loss-lb:0.0677, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:36:04.470] iteration:25624  t-loss:0.1471, loss-lb:0.0700, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:36:04.659] iteration:25625  t-loss:0.1474, loss-lb:0.0738, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:36:04.850] iteration:25626  t-loss:0.1520, loss-lb:0.0746, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:36:05.043] iteration:25627  t-loss:0.1561, loss-lb:0.0719, loss-ulb:0.0421, weight:2.00, lr:0.0002
[12:36:05.235] iteration:25628  t-loss:0.1877, loss-lb:0.0662, loss-ulb:0.0608, weight:2.00, lr:0.0002
[12:36:05.427] iteration:25629  t-loss:0.1360, loss-lb:0.0662, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:36:05.619] iteration:25630  t-loss:0.1565, loss-lb:0.0699, loss-ulb:0.0433, weight:2.00, lr:0.0002
[12:36:05.812] iteration:25631  t-loss:0.1413, loss-lb:0.0775, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:36:06.004] iteration:25632  t-loss:0.1258, loss-lb:0.0636, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:36:06.196] iteration:25633  t-loss:0.1475, loss-lb:0.0768, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:36:06.389] iteration:25634  t-loss:0.1308, loss-lb:0.0765, loss-ulb:0.0272, weight:2.00, lr:0.0002
[12:36:06.581] iteration:25635  t-loss:0.1648, loss-lb:0.0758, loss-ulb:0.0445, weight:2.00, lr:0.0002
[12:36:06.773] iteration:25636  t-loss:0.1293, loss-lb:0.0690, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:36:06.965] iteration:25637  t-loss:0.1438, loss-lb:0.0693, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:36:07.156] iteration:25638  t-loss:0.1421, loss-lb:0.0732, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:07.348] iteration:25639  t-loss:0.1300, loss-lb:0.0672, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:36:07.541] iteration:25640  t-loss:0.1286, loss-lb:0.0700, loss-ulb:0.0293, weight:2.00, lr:0.0002
[12:36:07.733] iteration:25641  t-loss:0.1423, loss-lb:0.0759, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:36:07.925] iteration:25642  t-loss:0.1356, loss-lb:0.0660, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:36:08.117] iteration:25643  t-loss:0.1467, loss-lb:0.0736, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:36:08.310] iteration:25644  t-loss:0.2156, loss-lb:0.0785, loss-ulb:0.0685, weight:2.00, lr:0.0002
[12:36:08.502] iteration:25645  t-loss:0.1448, loss-lb:0.0753, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:36:08.694] iteration:25646  t-loss:0.1348, loss-lb:0.0708, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:36:08.886] iteration:25647  t-loss:0.2196, loss-lb:0.0717, loss-ulb:0.0739, weight:2.00, lr:0.0002
[12:36:09.078] iteration:25648  t-loss:0.1393, loss-lb:0.0798, loss-ulb:0.0298, weight:2.00, lr:0.0002
[12:36:09.269] iteration:25649  t-loss:0.1458, loss-lb:0.0687, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:36:09.461] iteration:25650  t-loss:0.1412, loss-lb:0.0783, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:36:09.654] iteration:25651  t-loss:0.1344, loss-lb:0.0700, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:36:09.845] iteration:25652  t-loss:0.1379, loss-lb:0.0648, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:36:10.037] iteration:25653  t-loss:0.1312, loss-lb:0.0681, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:36:10.229] iteration:25654  t-loss:0.1558, loss-lb:0.0722, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:36:10.420] iteration:25655  t-loss:0.1522, loss-lb:0.0771, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:36:10.612] iteration:25656  t-loss:0.1335, loss-lb:0.0669, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:36:10.804] iteration:25657  t-loss:0.1441, loss-lb:0.0751, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:10.997] iteration:25658  t-loss:0.1652, loss-lb:0.0784, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:36:11.188] iteration:25659  t-loss:0.1325, loss-lb:0.0638, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:36:11.380] iteration:25660  t-loss:0.1444, loss-lb:0.0766, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:36:11.571] iteration:25661  t-loss:0.1372, loss-lb:0.0663, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:36:11.762] iteration:25662  t-loss:0.1500, loss-lb:0.0709, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:36:11.953] iteration:25663  t-loss:0.1370, loss-lb:0.0650, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:36:12.144] iteration:25664  t-loss:0.1349, loss-lb:0.0665, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:36:12.335] iteration:25665  t-loss:0.1492, loss-lb:0.0774, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:36:12.527] iteration:25666  t-loss:0.1513, loss-lb:0.0736, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:36:12.718] iteration:25667  t-loss:0.1487, loss-lb:0.0771, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:36:12.910] iteration:25668  t-loss:0.1514, loss-lb:0.0720, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:36:13.101] iteration:25669  t-loss:0.1382, loss-lb:0.0734, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:36:13.292] iteration:25670  t-loss:0.1497, loss-lb:0.0698, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:36:13.482] iteration:25671  t-loss:0.1544, loss-lb:0.0726, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:36:13.672] iteration:25672  t-loss:0.1435, loss-lb:0.0750, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:36:13.863] iteration:25673  t-loss:0.1467, loss-lb:0.0710, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:36:14.053] iteration:25674  t-loss:0.1578, loss-lb:0.0773, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:36:14.244] iteration:25675  t-loss:0.1481, loss-lb:0.0717, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:36:14.433] iteration:25676  t-loss:0.1573, loss-lb:0.0711, loss-ulb:0.0431, weight:2.00, lr:0.0002
[12:36:15.025] iteration:25677  t-loss:0.1498, loss-lb:0.0725, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:36:15.222] iteration:25678  t-loss:0.1491, loss-lb:0.0716, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:36:15.415] iteration:25679  t-loss:0.1412, loss-lb:0.0711, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:36:15.608] iteration:25680  t-loss:0.1427, loss-lb:0.0724, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:36:15.800] iteration:25681  t-loss:0.1494, loss-lb:0.0741, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:36:15.993] iteration:25682  t-loss:0.1354, loss-lb:0.0705, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:36:16.184] iteration:25683  t-loss:0.1341, loss-lb:0.0703, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:36:16.377] iteration:25684  t-loss:0.1394, loss-lb:0.0707, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:36:16.569] iteration:25685  t-loss:0.1385, loss-lb:0.0675, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:36:16.762] iteration:25686  t-loss:0.1391, loss-lb:0.0666, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:36:16.954] iteration:25687  t-loss:0.1530, loss-lb:0.0691, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:36:17.147] iteration:25688  t-loss:0.1400, loss-lb:0.0665, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:36:17.339] iteration:25689  t-loss:0.1492, loss-lb:0.0729, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:36:17.531] iteration:25690  t-loss:0.1313, loss-lb:0.0660, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:36:17.724] iteration:25691  t-loss:0.1417, loss-lb:0.0670, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:36:17.917] iteration:25692  t-loss:0.1338, loss-lb:0.0708, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:36:18.109] iteration:25693  t-loss:0.1547, loss-lb:0.0782, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:36:18.301] iteration:25694  t-loss:0.1627, loss-lb:0.0729, loss-ulb:0.0449, weight:2.00, lr:0.0002
[12:36:18.493] iteration:25695  t-loss:0.1423, loss-lb:0.0735, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:36:18.685] iteration:25696  t-loss:0.1343, loss-lb:0.0676, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:36:18.877] iteration:25697  t-loss:0.1451, loss-lb:0.0708, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:36:19.069] iteration:25698  t-loss:0.1467, loss-lb:0.0747, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:36:19.262] iteration:25699  t-loss:0.1430, loss-lb:0.0738, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:36:19.454] iteration:25700  t-loss:0.1268, loss-lb:0.0648, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:36:19.646] iteration:25701  t-loss:0.1487, loss-lb:0.0722, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:36:19.840] iteration:25702  t-loss:0.1474, loss-lb:0.0718, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:36:20.032] iteration:25703  t-loss:0.1500, loss-lb:0.0762, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:36:20.227] iteration:25704  t-loss:0.1945, loss-lb:0.0694, loss-ulb:0.0626, weight:2.00, lr:0.0002
[12:36:20.419] iteration:25705  t-loss:0.1315, loss-lb:0.0676, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:36:20.613] iteration:25706  t-loss:0.1720, loss-lb:0.0741, loss-ulb:0.0490, weight:2.00, lr:0.0002
[12:36:20.805] iteration:25707  t-loss:0.1472, loss-lb:0.0676, loss-ulb:0.0398, weight:2.00, lr:0.0002
[12:36:20.997] iteration:25708  t-loss:0.1369, loss-lb:0.0720, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:36:21.190] iteration:25709  t-loss:0.1320, loss-lb:0.0684, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:36:21.382] iteration:25710  t-loss:0.1388, loss-lb:0.0711, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:36:21.575] iteration:25711  t-loss:0.1350, loss-lb:0.0677, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:36:21.768] iteration:25712  t-loss:0.1430, loss-lb:0.0703, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:36:21.961] iteration:25713  t-loss:0.1502, loss-lb:0.0744, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:36:22.153] iteration:25714  t-loss:0.2016, loss-lb:0.0667, loss-ulb:0.0674, weight:2.00, lr:0.0002
[12:36:22.346] iteration:25715  t-loss:0.1334, loss-lb:0.0679, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:36:22.540] iteration:25716  t-loss:0.1540, loss-lb:0.0851, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:22.732] iteration:25717  t-loss:0.1739, loss-lb:0.0892, loss-ulb:0.0424, weight:2.00, lr:0.0002
[12:36:22.924] iteration:25718  t-loss:0.1563, loss-lb:0.0810, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:36:23.117] iteration:25719  t-loss:0.1746, loss-lb:0.0798, loss-ulb:0.0474, weight:2.00, lr:0.0002
[12:36:23.311] iteration:25720  t-loss:0.1840, loss-lb:0.0651, loss-ulb:0.0595, weight:2.00, lr:0.0002
[12:36:23.503] iteration:25721  t-loss:0.1412, loss-lb:0.0669, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:36:23.699] iteration:25722  t-loss:0.1473, loss-lb:0.0757, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:36:23.891] iteration:25723  t-loss:0.1231, loss-lb:0.0706, loss-ulb:0.0263, weight:2.00, lr:0.0002
[12:36:24.084] iteration:25724  t-loss:0.1513, loss-lb:0.0745, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:36:24.275] iteration:25725  t-loss:0.1498, loss-lb:0.0828, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:36:24.467] iteration:25726  t-loss:0.1439, loss-lb:0.0720, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:36:24.659] iteration:25727  t-loss:0.1412, loss-lb:0.0671, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:36:24.851] iteration:25728  t-loss:0.1340, loss-lb:0.0686, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:36:25.043] iteration:25729  t-loss:0.1448, loss-lb:0.0716, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:36:25.236] iteration:25730  t-loss:0.1526, loss-lb:0.0671, loss-ulb:0.0428, weight:2.00, lr:0.0002
[12:36:25.428] iteration:25731  t-loss:0.1349, loss-lb:0.0656, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:36:25.620] iteration:25732  t-loss:0.1352, loss-lb:0.0682, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:36:25.813] iteration:25733  t-loss:0.1396, loss-lb:0.0755, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:36:26.008] iteration:25734  t-loss:0.1827, loss-lb:0.0684, loss-ulb:0.0572, weight:2.00, lr:0.0002
[12:36:26.200] iteration:25735  t-loss:0.1415, loss-lb:0.0753, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:36:26.393] iteration:25736  t-loss:0.1331, loss-lb:0.0698, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:36:26.586] iteration:25737  t-loss:0.1417, loss-lb:0.0656, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:36:26.778] iteration:25738  t-loss:0.1402, loss-lb:0.0684, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:36:26.970] iteration:25739  t-loss:0.1485, loss-lb:0.0760, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:36:27.163] iteration:25740  t-loss:0.1301, loss-lb:0.0671, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:36:27.355] iteration:25741  t-loss:0.1430, loss-lb:0.0738, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:36:27.547] iteration:25742  t-loss:0.1534, loss-lb:0.0654, loss-ulb:0.0440, weight:2.00, lr:0.0002
[12:36:27.739] iteration:25743  t-loss:0.1395, loss-lb:0.0681, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:36:27.932] iteration:25744  t-loss:0.1540, loss-lb:0.0702, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:36:28.124] iteration:25745  t-loss:0.1470, loss-lb:0.0728, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:36:28.316] iteration:25746  t-loss:0.1423, loss-lb:0.0687, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:36:28.509] iteration:25747  t-loss:0.1384, loss-lb:0.0690, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:36:28.702] iteration:25748  t-loss:0.1415, loss-lb:0.0779, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:36:28.894] iteration:25749  t-loss:0.1499, loss-lb:0.0728, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:36:29.087] iteration:25750  t-loss:0.1403, loss-lb:0.0713, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:29.280] iteration:25751  t-loss:0.1196, loss-lb:0.0623, loss-ulb:0.0286, weight:2.00, lr:0.0002
[12:36:29.473] iteration:25752  t-loss:0.1412, loss-lb:0.0733, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:36:29.666] iteration:25753  t-loss:0.1321, loss-lb:0.0685, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:36:29.859] iteration:25754  t-loss:0.1490, loss-lb:0.0672, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:36:30.050] iteration:25755  t-loss:0.1417, loss-lb:0.0749, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:36:30.243] iteration:25756  t-loss:0.1246, loss-lb:0.0653, loss-ulb:0.0297, weight:2.00, lr:0.0002
[12:36:30.436] iteration:25757  t-loss:0.1884, loss-lb:0.0664, loss-ulb:0.0610, weight:2.00, lr:0.0002
[12:36:30.629] iteration:25758  t-loss:0.1438, loss-lb:0.0734, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:36:30.821] iteration:25759  t-loss:0.1460, loss-lb:0.0714, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:36:31.015] iteration:25760  t-loss:0.1401, loss-lb:0.0585, loss-ulb:0.0408, weight:2.00, lr:0.0002
[12:36:31.207] iteration:25761  t-loss:0.1411, loss-lb:0.0720, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:31.401] iteration:25762  t-loss:0.1703, loss-lb:0.0683, loss-ulb:0.0510, weight:2.00, lr:0.0002
[12:36:31.595] iteration:25763  t-loss:0.1600, loss-lb:0.0792, loss-ulb:0.0404, weight:2.00, lr:0.0002
[12:36:31.788] iteration:25764  t-loss:0.1307, loss-lb:0.0674, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:36:31.980] iteration:25765  t-loss:0.1474, loss-lb:0.0724, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:36:32.172] iteration:25766  t-loss:0.1462, loss-lb:0.0736, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:36:32.364] iteration:25767  t-loss:0.1412, loss-lb:0.0736, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:36:32.554] iteration:25768  t-loss:0.1346, loss-lb:0.0736, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:36:32.745] iteration:25769  t-loss:0.1516, loss-lb:0.0744, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:36:32.936] iteration:25770  t-loss:0.1411, loss-lb:0.0719, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:36:33.127] iteration:25771  t-loss:0.1332, loss-lb:0.0699, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:36:33.317] iteration:25772  t-loss:0.1372, loss-lb:0.0761, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:36:33.507] iteration:25773  t-loss:0.1398, loss-lb:0.0700, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:36:33.697] iteration:25774  t-loss:0.1348, loss-lb:0.0674, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:36:45.712]  <<Test>> - Ep:262  - mean_dice/mean_h95 - S:89.71/1.37, Best-S:90.99, T:89.67/1.37, Best-T:90.48
[12:36:45.713]           - AvgLoss(lb/ulb/all):0.0711/0.0369/0.1447
[12:36:46.241] iteration:25775  t-loss:0.1625, loss-lb:0.0770, loss-ulb:0.0427, weight:2.00, lr:0.0002
[12:36:46.439] iteration:25776  t-loss:0.1514, loss-lb:0.0671, loss-ulb:0.0422, weight:2.00, lr:0.0002
[12:36:46.632] iteration:25777  t-loss:0.1457, loss-lb:0.0725, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:36:46.826] iteration:25778  t-loss:0.1534, loss-lb:0.0780, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:36:47.023] iteration:25779  t-loss:0.2145, loss-lb:0.0774, loss-ulb:0.0685, weight:2.00, lr:0.0002
[12:36:47.215] iteration:25780  t-loss:0.1417, loss-lb:0.0812, loss-ulb:0.0303, weight:2.00, lr:0.0002
[12:36:47.408] iteration:25781  t-loss:0.1356, loss-lb:0.0686, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:36:47.601] iteration:25782  t-loss:0.1353, loss-lb:0.0679, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:36:47.794] iteration:25783  t-loss:0.1285, loss-lb:0.0651, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:36:47.987] iteration:25784  t-loss:0.1304, loss-lb:0.0650, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:36:48.181] iteration:25785  t-loss:0.1795, loss-lb:0.0736, loss-ulb:0.0530, weight:2.00, lr:0.0002
[12:36:48.375] iteration:25786  t-loss:0.1308, loss-lb:0.0642, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:36:48.568] iteration:25787  t-loss:0.1517, loss-lb:0.0751, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:36:48.761] iteration:25788  t-loss:0.1330, loss-lb:0.0709, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:36:48.952] iteration:25789  t-loss:0.1385, loss-lb:0.0669, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:36:49.146] iteration:25790  t-loss:0.1528, loss-lb:0.0688, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:36:49.340] iteration:25791  t-loss:0.1667, loss-lb:0.0702, loss-ulb:0.0483, weight:2.00, lr:0.0002
[12:36:49.533] iteration:25792  t-loss:0.1392, loss-lb:0.0767, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:36:49.725] iteration:25793  t-loss:0.1484, loss-lb:0.0752, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:36:49.918] iteration:25794  t-loss:0.2017, loss-lb:0.0665, loss-ulb:0.0676, weight:2.00, lr:0.0002
[12:36:50.111] iteration:25795  t-loss:0.1789, loss-lb:0.0715, loss-ulb:0.0537, weight:2.00, lr:0.0002
[12:36:50.304] iteration:25796  t-loss:0.1587, loss-lb:0.0845, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:36:50.496] iteration:25797  t-loss:0.1317, loss-lb:0.0678, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:36:50.688] iteration:25798  t-loss:0.1275, loss-lb:0.0685, loss-ulb:0.0295, weight:2.00, lr:0.0002
[12:36:50.882] iteration:25799  t-loss:0.1548, loss-lb:0.0705, loss-ulb:0.0421, weight:2.00, lr:0.0002
[12:36:51.076] iteration:25800  t-loss:0.2361, loss-lb:0.0691, loss-ulb:0.0835, weight:2.00, lr:0.0002
[12:36:51.268] iteration:25801  t-loss:0.1394, loss-lb:0.0692, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:36:51.461] iteration:25802  t-loss:0.1569, loss-lb:0.0728, loss-ulb:0.0421, weight:2.00, lr:0.0002
[12:36:51.654] iteration:25803  t-loss:0.1409, loss-lb:0.0719, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:51.846] iteration:25804  t-loss:0.1523, loss-lb:0.0738, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:36:52.038] iteration:25805  t-loss:0.1767, loss-lb:0.0708, loss-ulb:0.0529, weight:2.00, lr:0.0002
[12:36:52.232] iteration:25806  t-loss:0.1697, loss-lb:0.0737, loss-ulb:0.0480, weight:2.00, lr:0.0002
[12:36:52.426] iteration:25807  t-loss:0.1533, loss-lb:0.0757, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:36:52.618] iteration:25808  t-loss:0.1469, loss-lb:0.0735, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:36:52.810] iteration:25809  t-loss:0.1367, loss-lb:0.0759, loss-ulb:0.0304, weight:2.00, lr:0.0002
[12:36:53.002] iteration:25810  t-loss:0.1402, loss-lb:0.0705, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:36:53.195] iteration:25811  t-loss:0.1411, loss-lb:0.0708, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:36:53.388] iteration:25812  t-loss:0.1415, loss-lb:0.0640, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:36:53.581] iteration:25813  t-loss:0.1542, loss-lb:0.0778, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:36:53.774] iteration:25814  t-loss:0.1405, loss-lb:0.0752, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:36:53.966] iteration:25815  t-loss:0.1412, loss-lb:0.0688, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:36:54.158] iteration:25816  t-loss:0.1448, loss-lb:0.0809, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:36:54.350] iteration:25817  t-loss:0.1505, loss-lb:0.0722, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:36:54.543] iteration:25818  t-loss:0.1549, loss-lb:0.0711, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:36:54.735] iteration:25819  t-loss:0.1374, loss-lb:0.0660, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:36:54.927] iteration:25820  t-loss:0.1353, loss-lb:0.0669, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:36:55.119] iteration:25821  t-loss:0.1379, loss-lb:0.0665, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:36:55.311] iteration:25822  t-loss:0.1506, loss-lb:0.0706, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:36:55.504] iteration:25823  t-loss:0.1454, loss-lb:0.0781, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:36:55.697] iteration:25824  t-loss:0.1498, loss-lb:0.0767, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:36:55.890] iteration:25825  t-loss:0.1542, loss-lb:0.0731, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:36:56.083] iteration:25826  t-loss:0.1531, loss-lb:0.0644, loss-ulb:0.0444, weight:2.00, lr:0.0002
[12:36:56.275] iteration:25827  t-loss:0.1479, loss-lb:0.0779, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:36:56.468] iteration:25828  t-loss:0.1417, loss-lb:0.0727, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:36:56.659] iteration:25829  t-loss:0.1274, loss-lb:0.0664, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:36:56.852] iteration:25830  t-loss:0.1364, loss-lb:0.0703, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:36:57.045] iteration:25831  t-loss:0.1593, loss-lb:0.0759, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:36:57.239] iteration:25832  t-loss:0.1535, loss-lb:0.0716, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:36:57.431] iteration:25833  t-loss:0.1399, loss-lb:0.0706, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:36:57.624] iteration:25834  t-loss:0.1480, loss-lb:0.0763, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:36:57.817] iteration:25835  t-loss:0.1420, loss-lb:0.0690, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:36:58.010] iteration:25836  t-loss:0.1292, loss-lb:0.0651, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:36:58.201] iteration:25837  t-loss:0.1397, loss-lb:0.0652, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:36:58.393] iteration:25838  t-loss:0.1349, loss-lb:0.0688, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:36:58.587] iteration:25839  t-loss:0.1541, loss-lb:0.0700, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:36:58.778] iteration:25840  t-loss:0.1525, loss-lb:0.0803, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:36:58.971] iteration:25841  t-loss:0.1419, loss-lb:0.0742, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:36:59.164] iteration:25842  t-loss:0.2541, loss-lb:0.0763, loss-ulb:0.0889, weight:2.00, lr:0.0002
[12:36:59.355] iteration:25843  t-loss:0.1494, loss-lb:0.0697, loss-ulb:0.0399, weight:2.00, lr:0.0002
[12:36:59.549] iteration:25844  t-loss:0.1654, loss-lb:0.0735, loss-ulb:0.0460, weight:2.00, lr:0.0002
[12:36:59.741] iteration:25845  t-loss:0.1530, loss-lb:0.0690, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:36:59.933] iteration:25846  t-loss:0.1533, loss-lb:0.0769, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:37:00.126] iteration:25847  t-loss:0.1417, loss-lb:0.0756, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:37:00.319] iteration:25848  t-loss:0.1493, loss-lb:0.0734, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:37:00.510] iteration:25849  t-loss:0.1445, loss-lb:0.0727, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:37:00.703] iteration:25850  t-loss:0.1463, loss-lb:0.0769, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:37:00.896] iteration:25851  t-loss:0.1336, loss-lb:0.0656, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:37:01.087] iteration:25852  t-loss:0.1316, loss-lb:0.0672, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:37:01.280] iteration:25853  t-loss:0.1270, loss-lb:0.0689, loss-ulb:0.0291, weight:2.00, lr:0.0002
[12:37:01.472] iteration:25854  t-loss:0.1554, loss-lb:0.0717, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:37:01.665] iteration:25855  t-loss:0.1584, loss-lb:0.0752, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:37:01.857] iteration:25856  t-loss:0.1497, loss-lb:0.0735, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:37:02.049] iteration:25857  t-loss:0.1364, loss-lb:0.0695, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:37:02.243] iteration:25858  t-loss:0.1554, loss-lb:0.0673, loss-ulb:0.0441, weight:2.00, lr:0.0002
[12:37:02.434] iteration:25859  t-loss:0.1475, loss-lb:0.0718, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:37:02.627] iteration:25860  t-loss:0.1388, loss-lb:0.0675, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:37:02.818] iteration:25861  t-loss:0.1501, loss-lb:0.0791, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:37:03.010] iteration:25862  t-loss:0.1486, loss-lb:0.0704, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:37:03.203] iteration:25863  t-loss:0.1402, loss-lb:0.0763, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:37:03.396] iteration:25864  t-loss:0.1372, loss-lb:0.0676, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:37:03.587] iteration:25865  t-loss:0.1561, loss-lb:0.0744, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:37:03.778] iteration:25866  t-loss:0.1599, loss-lb:0.0711, loss-ulb:0.0444, weight:2.00, lr:0.0002
[12:37:03.969] iteration:25867  t-loss:0.1401, loss-lb:0.0678, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:37:04.161] iteration:25868  t-loss:0.1942, loss-lb:0.0833, loss-ulb:0.0555, weight:2.00, lr:0.0002
[12:37:04.356] iteration:25869  t-loss:0.1286, loss-lb:0.0660, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:37:04.551] iteration:25870  t-loss:0.1516, loss-lb:0.0648, loss-ulb:0.0434, weight:2.00, lr:0.0002
[12:37:04.745] iteration:25871  t-loss:0.1478, loss-lb:0.0728, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:37:04.936] iteration:25872  t-loss:0.1383, loss-lb:0.0662, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:37:05.522] iteration:25873  t-loss:0.1308, loss-lb:0.0668, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:37:05.716] iteration:25874  t-loss:0.1384, loss-lb:0.0649, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:37:05.908] iteration:25875  t-loss:0.1326, loss-lb:0.0720, loss-ulb:0.0303, weight:2.00, lr:0.0002
[12:37:06.101] iteration:25876  t-loss:0.1433, loss-lb:0.0781, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:37:06.293] iteration:25877  t-loss:0.1537, loss-lb:0.0763, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:37:06.485] iteration:25878  t-loss:0.1612, loss-lb:0.0890, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:37:06.677] iteration:25879  t-loss:0.1454, loss-lb:0.0745, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:37:06.868] iteration:25880  t-loss:0.1477, loss-lb:0.0776, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:37:07.060] iteration:25881  t-loss:0.1255, loss-lb:0.0646, loss-ulb:0.0304, weight:2.00, lr:0.0002
[12:37:07.251] iteration:25882  t-loss:0.1309, loss-lb:0.0670, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:37:07.443] iteration:25883  t-loss:0.1453, loss-lb:0.0676, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:37:07.635] iteration:25884  t-loss:0.1505, loss-lb:0.0723, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:37:07.829] iteration:25885  t-loss:0.1373, loss-lb:0.0676, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:37:08.020] iteration:25886  t-loss:0.1586, loss-lb:0.0782, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:37:08.211] iteration:25887  t-loss:0.1385, loss-lb:0.0686, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:37:08.402] iteration:25888  t-loss:0.1418, loss-lb:0.0766, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:37:08.594] iteration:25889  t-loss:0.1615, loss-lb:0.0780, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:37:08.786] iteration:25890  t-loss:0.1431, loss-lb:0.0729, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:37:08.978] iteration:25891  t-loss:0.1302, loss-lb:0.0748, loss-ulb:0.0277, weight:2.00, lr:0.0002
[12:37:09.169] iteration:25892  t-loss:0.1539, loss-lb:0.0819, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:37:09.361] iteration:25893  t-loss:0.1563, loss-lb:0.0740, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:37:09.554] iteration:25894  t-loss:0.1304, loss-lb:0.0668, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:37:09.745] iteration:25895  t-loss:0.1540, loss-lb:0.0765, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:37:09.936] iteration:25896  t-loss:0.1464, loss-lb:0.0679, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:37:10.129] iteration:25897  t-loss:0.1465, loss-lb:0.0702, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:37:10.322] iteration:25898  t-loss:0.1660, loss-lb:0.0678, loss-ulb:0.0491, weight:2.00, lr:0.0002
[12:37:10.518] iteration:25899  t-loss:0.1362, loss-lb:0.0684, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:37:10.713] iteration:25900  t-loss:0.1529, loss-lb:0.0747, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:37:10.907] iteration:25901  t-loss:0.1409, loss-lb:0.0726, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:37:11.099] iteration:25902  t-loss:0.1378, loss-lb:0.0728, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:37:11.293] iteration:25903  t-loss:0.2104, loss-lb:0.0602, loss-ulb:0.0751, weight:2.00, lr:0.0002
[12:37:11.484] iteration:25904  t-loss:0.1430, loss-lb:0.0739, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:37:11.678] iteration:25905  t-loss:0.1269, loss-lb:0.0657, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:37:11.870] iteration:25906  t-loss:0.1436, loss-lb:0.0705, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:37:12.062] iteration:25907  t-loss:0.1404, loss-lb:0.0718, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:37:12.253] iteration:25908  t-loss:0.1506, loss-lb:0.0798, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:37:12.445] iteration:25909  t-loss:0.1618, loss-lb:0.0814, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:37:12.637] iteration:25910  t-loss:0.1413, loss-lb:0.0727, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:37:12.828] iteration:25911  t-loss:0.1787, loss-lb:0.0698, loss-ulb:0.0544, weight:2.00, lr:0.0002
[12:37:13.021] iteration:25912  t-loss:0.2097, loss-lb:0.0637, loss-ulb:0.0730, weight:2.00, lr:0.0002
[12:37:13.212] iteration:25913  t-loss:0.1367, loss-lb:0.0733, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:37:13.404] iteration:25914  t-loss:0.1454, loss-lb:0.0730, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:37:13.596] iteration:25915  t-loss:0.1432, loss-lb:0.0700, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:37:13.787] iteration:25916  t-loss:0.1367, loss-lb:0.0666, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:37:13.979] iteration:25917  t-loss:0.1579, loss-lb:0.0661, loss-ulb:0.0459, weight:2.00, lr:0.0002
[12:37:14.171] iteration:25918  t-loss:0.1503, loss-lb:0.0701, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:37:14.362] iteration:25919  t-loss:0.1340, loss-lb:0.0645, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:37:14.554] iteration:25920  t-loss:0.1385, loss-lb:0.0676, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:37:14.745] iteration:25921  t-loss:0.1767, loss-lb:0.0743, loss-ulb:0.0512, weight:2.00, lr:0.0002
[12:37:14.939] iteration:25922  t-loss:0.1542, loss-lb:0.0714, loss-ulb:0.0414, weight:2.00, lr:0.0002
[12:37:15.135] iteration:25923  t-loss:0.1397, loss-lb:0.0683, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:37:15.329] iteration:25924  t-loss:0.1594, loss-lb:0.0733, loss-ulb:0.0431, weight:2.00, lr:0.0002
[12:37:15.524] iteration:25925  t-loss:0.1462, loss-lb:0.0730, loss-ulb:0.0366, weight:2.00, lr:0.0002
[12:37:15.716] iteration:25926  t-loss:0.1280, loss-lb:0.0623, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:37:15.907] iteration:25927  t-loss:0.1389, loss-lb:0.0700, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:37:16.099] iteration:25928  t-loss:0.1602, loss-lb:0.0861, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:37:16.292] iteration:25929  t-loss:0.1546, loss-lb:0.0859, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:37:16.484] iteration:25930  t-loss:0.1406, loss-lb:0.0635, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:37:16.676] iteration:25931  t-loss:0.1482, loss-lb:0.0732, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:37:16.869] iteration:25932  t-loss:0.1489, loss-lb:0.0762, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:37:17.061] iteration:25933  t-loss:0.1419, loss-lb:0.0682, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:37:17.253] iteration:25934  t-loss:0.1510, loss-lb:0.0664, loss-ulb:0.0423, weight:2.00, lr:0.0002
[12:37:17.446] iteration:25935  t-loss:0.1369, loss-lb:0.0640, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:37:17.638] iteration:25936  t-loss:0.1351, loss-lb:0.0730, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:37:17.829] iteration:25937  t-loss:0.1406, loss-lb:0.0779, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:37:18.021] iteration:25938  t-loss:0.1484, loss-lb:0.0789, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:37:18.212] iteration:25939  t-loss:0.1441, loss-lb:0.0725, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:37:18.404] iteration:25940  t-loss:0.1360, loss-lb:0.0663, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:37:18.596] iteration:25941  t-loss:0.1573, loss-lb:0.0715, loss-ulb:0.0429, weight:2.00, lr:0.0002
[12:37:18.790] iteration:25942  t-loss:0.2788, loss-lb:0.0668, loss-ulb:0.1060, weight:2.00, lr:0.0002
[12:37:18.983] iteration:25943  t-loss:0.1417, loss-lb:0.0680, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:37:19.174] iteration:25944  t-loss:0.1562, loss-lb:0.0740, loss-ulb:0.0411, weight:2.00, lr:0.0002
[12:37:19.368] iteration:25945  t-loss:0.2339, loss-lb:0.0705, loss-ulb:0.0817, weight:2.00, lr:0.0002
[12:37:19.559] iteration:25946  t-loss:0.1445, loss-lb:0.0734, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:37:19.751] iteration:25947  t-loss:0.1301, loss-lb:0.0642, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:37:19.943] iteration:25948  t-loss:0.1467, loss-lb:0.0773, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:37:20.134] iteration:25949  t-loss:0.1358, loss-lb:0.0675, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:37:20.330] iteration:25950  t-loss:0.1608, loss-lb:0.0781, loss-ulb:0.0413, weight:2.00, lr:0.0002
[12:37:20.522] iteration:25951  t-loss:0.1393, loss-lb:0.0748, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:37:20.714] iteration:25952  t-loss:0.1369, loss-lb:0.0662, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:37:20.906] iteration:25953  t-loss:0.1471, loss-lb:0.0688, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:37:21.098] iteration:25954  t-loss:0.1501, loss-lb:0.0793, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:37:21.290] iteration:25955  t-loss:0.1444, loss-lb:0.0656, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:37:21.482] iteration:25956  t-loss:0.1781, loss-lb:0.0691, loss-ulb:0.0545, weight:2.00, lr:0.0002
[12:37:21.675] iteration:25957  t-loss:0.1384, loss-lb:0.0715, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:37:21.866] iteration:25958  t-loss:0.1381, loss-lb:0.0687, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:37:22.059] iteration:25959  t-loss:0.1490, loss-lb:0.0740, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:37:22.252] iteration:25960  t-loss:0.1346, loss-lb:0.0671, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:37:22.445] iteration:25961  t-loss:0.1773, loss-lb:0.0772, loss-ulb:0.0501, weight:2.00, lr:0.0002
[12:37:22.637] iteration:25962  t-loss:0.1453, loss-lb:0.0740, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:37:22.829] iteration:25963  t-loss:0.1582, loss-lb:0.0744, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:37:23.021] iteration:25964  t-loss:0.3133, loss-lb:0.0744, loss-ulb:0.1195, weight:2.00, lr:0.0002
[12:37:23.211] iteration:25965  t-loss:0.1380, loss-lb:0.0674, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:37:23.401] iteration:25966  t-loss:0.1442, loss-lb:0.0700, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:37:23.590] iteration:25967  t-loss:0.1431, loss-lb:0.0722, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:37:23.779] iteration:25968  t-loss:0.1407, loss-lb:0.0702, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:37:23.970] iteration:25969  t-loss:0.1592, loss-lb:0.0662, loss-ulb:0.0465, weight:2.00, lr:0.0002
[12:37:24.161] iteration:25970  t-loss:0.2431, loss-lb:0.0825, loss-ulb:0.0803, weight:2.00, lr:0.0002
[12:37:37.301]  <<Test>> - Ep:264  - mean_dice/mean_h95 - S:89.30/1.90, Best-S:90.99, T:89.49/1.44, Best-T:90.48
[12:37:37.301]           - AvgLoss(lb/ulb/all):0.0717/0.0446/0.1609
[12:37:37.880] iteration:25971  t-loss:0.1564, loss-lb:0.0670, loss-ulb:0.0447, weight:2.00, lr:0.0002
[12:37:38.077] iteration:25972  t-loss:0.1389, loss-lb:0.0785, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:37:38.269] iteration:25973  t-loss:0.1456, loss-lb:0.0738, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:37:38.462] iteration:25974  t-loss:0.1404, loss-lb:0.0711, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:37:38.657] iteration:25975  t-loss:0.1435, loss-lb:0.0749, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:37:38.848] iteration:25976  t-loss:0.1594, loss-lb:0.0902, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:37:39.042] iteration:25977  t-loss:0.1717, loss-lb:0.0650, loss-ulb:0.0534, weight:2.00, lr:0.0002
[12:37:39.235] iteration:25978  t-loss:0.1910, loss-lb:0.0884, loss-ulb:0.0513, weight:2.00, lr:0.0002
[12:37:39.428] iteration:25979  t-loss:0.1475, loss-lb:0.0724, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:37:39.620] iteration:25980  t-loss:0.1368, loss-lb:0.0685, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:37:39.813] iteration:25981  t-loss:0.1420, loss-lb:0.0733, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:37:40.005] iteration:25982  t-loss:0.1507, loss-lb:0.0756, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:37:40.197] iteration:25983  t-loss:0.1596, loss-lb:0.0757, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:37:40.390] iteration:25984  t-loss:0.1459, loss-lb:0.0714, loss-ulb:0.0373, weight:2.00, lr:0.0002
[12:37:40.583] iteration:25985  t-loss:0.1473, loss-lb:0.0696, loss-ulb:0.0388, weight:2.00, lr:0.0002
[12:37:40.776] iteration:25986  t-loss:0.1505, loss-lb:0.0700, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:37:40.968] iteration:25987  t-loss:0.1428, loss-lb:0.0732, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:37:41.159] iteration:25988  t-loss:0.1666, loss-lb:0.0804, loss-ulb:0.0431, weight:2.00, lr:0.0002
[12:37:41.352] iteration:25989  t-loss:0.1568, loss-lb:0.0764, loss-ulb:0.0402, weight:2.00, lr:0.0002
[12:37:41.543] iteration:25990  t-loss:0.1423, loss-lb:0.0740, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:37:41.735] iteration:25991  t-loss:0.1346, loss-lb:0.0724, loss-ulb:0.0311, weight:2.00, lr:0.0002
[12:37:41.928] iteration:25992  t-loss:0.1336, loss-lb:0.0665, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:37:42.120] iteration:25993  t-loss:0.1375, loss-lb:0.0739, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:37:42.312] iteration:25994  t-loss:0.1402, loss-lb:0.0732, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:37:42.503] iteration:25995  t-loss:0.1635, loss-lb:0.0787, loss-ulb:0.0424, weight:2.00, lr:0.0002
[12:37:42.696] iteration:25996  t-loss:0.1464, loss-lb:0.0677, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:37:42.888] iteration:25997  t-loss:0.1399, loss-lb:0.0693, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:37:43.081] iteration:25998  t-loss:0.1717, loss-lb:0.0727, loss-ulb:0.0495, weight:2.00, lr:0.0002
[12:37:43.287] iteration:25999  t-loss:0.1358, loss-lb:0.0683, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:37:43.485] iteration:26000  t-loss:0.1602, loss-lb:0.0802, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:37:43.679] iteration:26001  t-loss:0.1585, loss-lb:0.0712, loss-ulb:0.0436, weight:2.00, lr:0.0002
[12:37:43.873] iteration:26002  t-loss:0.1430, loss-lb:0.0738, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:37:44.065] iteration:26003  t-loss:0.1570, loss-lb:0.0635, loss-ulb:0.0467, weight:2.00, lr:0.0002
[12:37:44.256] iteration:26004  t-loss:0.1314, loss-lb:0.0648, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:37:44.449] iteration:26005  t-loss:0.1543, loss-lb:0.0773, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:37:44.641] iteration:26006  t-loss:0.1442, loss-lb:0.0785, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:37:44.832] iteration:26007  t-loss:0.1610, loss-lb:0.0700, loss-ulb:0.0455, weight:2.00, lr:0.0002
[12:37:45.025] iteration:26008  t-loss:0.1422, loss-lb:0.0721, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:37:45.217] iteration:26009  t-loss:0.1483, loss-lb:0.0782, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:37:45.408] iteration:26010  t-loss:0.1310, loss-lb:0.0697, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:37:45.600] iteration:26011  t-loss:0.1492, loss-lb:0.0654, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:37:45.792] iteration:26012  t-loss:0.1498, loss-lb:0.0669, loss-ulb:0.0414, weight:2.00, lr:0.0002
[12:37:45.984] iteration:26013  t-loss:0.1615, loss-lb:0.0705, loss-ulb:0.0455, weight:2.00, lr:0.0002
[12:37:46.176] iteration:26014  t-loss:0.1279, loss-lb:0.0662, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:37:46.367] iteration:26015  t-loss:0.1361, loss-lb:0.0675, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:37:46.559] iteration:26016  t-loss:0.1474, loss-lb:0.0711, loss-ulb:0.0382, weight:2.00, lr:0.0002
[12:37:46.750] iteration:26017  t-loss:0.1449, loss-lb:0.0660, loss-ulb:0.0395, weight:2.00, lr:0.0002
[12:37:46.941] iteration:26018  t-loss:0.1404, loss-lb:0.0679, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:37:47.134] iteration:26019  t-loss:0.1525, loss-lb:0.0717, loss-ulb:0.0404, weight:2.00, lr:0.0002
[12:37:47.325] iteration:26020  t-loss:0.1393, loss-lb:0.0706, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:37:47.517] iteration:26021  t-loss:0.1435, loss-lb:0.0695, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:37:47.709] iteration:26022  t-loss:0.1481, loss-lb:0.0725, loss-ulb:0.0378, weight:2.00, lr:0.0002
[12:37:47.901] iteration:26023  t-loss:0.1466, loss-lb:0.0756, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:37:48.094] iteration:26024  t-loss:0.1409, loss-lb:0.0745, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:37:48.286] iteration:26025  t-loss:0.1349, loss-lb:0.0669, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:37:48.478] iteration:26026  t-loss:0.1514, loss-lb:0.0780, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:37:48.670] iteration:26027  t-loss:0.1449, loss-lb:0.0762, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:37:48.863] iteration:26028  t-loss:0.1321, loss-lb:0.0711, loss-ulb:0.0305, weight:2.00, lr:0.0002
[12:37:49.054] iteration:26029  t-loss:0.1472, loss-lb:0.0762, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:37:49.246] iteration:26030  t-loss:0.1368, loss-lb:0.0700, loss-ulb:0.0334, weight:2.00, lr:0.0002
[12:37:49.440] iteration:26031  t-loss:0.1352, loss-lb:0.0661, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:37:49.633] iteration:26032  t-loss:0.1599, loss-lb:0.0710, loss-ulb:0.0444, weight:2.00, lr:0.0002
[12:37:49.825] iteration:26033  t-loss:0.1487, loss-lb:0.0745, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:37:50.017] iteration:26034  t-loss:0.1295, loss-lb:0.0654, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:37:50.210] iteration:26035  t-loss:0.1656, loss-lb:0.0754, loss-ulb:0.0451, weight:2.00, lr:0.0002
[12:37:50.402] iteration:26036  t-loss:0.1512, loss-lb:0.0668, loss-ulb:0.0422, weight:2.00, lr:0.0002
[12:37:50.594] iteration:26037  t-loss:0.1434, loss-lb:0.0722, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:37:50.787] iteration:26038  t-loss:0.1417, loss-lb:0.0701, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:37:50.979] iteration:26039  t-loss:0.1473, loss-lb:0.0698, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:37:51.171] iteration:26040  t-loss:0.1260, loss-lb:0.0657, loss-ulb:0.0302, weight:2.00, lr:0.0002
[12:37:51.363] iteration:26041  t-loss:0.1481, loss-lb:0.0826, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:37:51.555] iteration:26042  t-loss:0.1324, loss-lb:0.0684, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:37:51.748] iteration:26043  t-loss:0.1327, loss-lb:0.0654, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:37:51.941] iteration:26044  t-loss:0.2212, loss-lb:0.0764, loss-ulb:0.0724, weight:2.00, lr:0.0002
[12:37:52.133] iteration:26045  t-loss:0.1540, loss-lb:0.0724, loss-ulb:0.0408, weight:2.00, lr:0.0002
[12:37:52.325] iteration:26046  t-loss:0.1541, loss-lb:0.0783, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:37:52.518] iteration:26047  t-loss:0.1685, loss-lb:0.0669, loss-ulb:0.0508, weight:2.00, lr:0.0002
[12:37:52.711] iteration:26048  t-loss:0.1319, loss-lb:0.0682, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:37:52.903] iteration:26049  t-loss:0.1495, loss-lb:0.0744, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:37:53.095] iteration:26050  t-loss:0.1458, loss-lb:0.0800, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:37:53.288] iteration:26051  t-loss:0.1482, loss-lb:0.0691, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:37:53.480] iteration:26052  t-loss:0.1391, loss-lb:0.0714, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:37:53.672] iteration:26053  t-loss:0.1455, loss-lb:0.0765, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:37:53.865] iteration:26054  t-loss:0.1470, loss-lb:0.0736, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:37:54.058] iteration:26055  t-loss:0.1352, loss-lb:0.0692, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:37:54.250] iteration:26056  t-loss:0.1344, loss-lb:0.0648, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:37:54.444] iteration:26057  t-loss:0.1964, loss-lb:0.0755, loss-ulb:0.0604, weight:2.00, lr:0.0002
[12:37:54.636] iteration:26058  t-loss:0.1300, loss-lb:0.0676, loss-ulb:0.0312, weight:2.00, lr:0.0002
[12:37:54.829] iteration:26059  t-loss:0.1378, loss-lb:0.0731, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:37:55.021] iteration:26060  t-loss:0.1267, loss-lb:0.0634, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:37:55.213] iteration:26061  t-loss:0.1481, loss-lb:0.0756, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:37:55.403] iteration:26062  t-loss:0.1468, loss-lb:0.0781, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:37:55.595] iteration:26063  t-loss:0.1630, loss-lb:0.0785, loss-ulb:0.0423, weight:2.00, lr:0.0002
[12:37:55.785] iteration:26064  t-loss:0.1449, loss-lb:0.0689, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:37:55.976] iteration:26065  t-loss:0.1437, loss-lb:0.0669, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:37:56.168] iteration:26066  t-loss:0.1366, loss-lb:0.0680, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:37:56.358] iteration:26067  t-loss:0.1289, loss-lb:0.0649, loss-ulb:0.0320, weight:2.00, lr:0.0002
[12:37:56.549] iteration:26068  t-loss:0.1367, loss-lb:0.0700, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:37:57.142] iteration:26069  t-loss:0.1397, loss-lb:0.0723, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:37:57.338] iteration:26070  t-loss:0.1414, loss-lb:0.0723, loss-ulb:0.0345, weight:2.00, lr:0.0002
[12:37:57.531] iteration:26071  t-loss:0.1596, loss-lb:0.0784, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:37:57.724] iteration:26072  t-loss:0.1574, loss-lb:0.0764, loss-ulb:0.0405, weight:2.00, lr:0.0002
[12:37:57.917] iteration:26073  t-loss:0.1360, loss-lb:0.0679, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:37:58.110] iteration:26074  t-loss:0.1364, loss-lb:0.0694, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:37:58.304] iteration:26075  t-loss:0.1408, loss-lb:0.0730, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:37:58.501] iteration:26076  t-loss:0.1522, loss-lb:0.0689, loss-ulb:0.0416, weight:2.00, lr:0.0002
[12:37:58.693] iteration:26077  t-loss:0.1463, loss-lb:0.0713, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:37:58.887] iteration:26078  t-loss:0.1399, loss-lb:0.0690, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:37:59.080] iteration:26079  t-loss:0.1295, loss-lb:0.0643, loss-ulb:0.0326, weight:2.00, lr:0.0002
[12:37:59.273] iteration:26080  t-loss:0.1854, loss-lb:0.0741, loss-ulb:0.0557, weight:2.00, lr:0.0002
[12:37:59.467] iteration:26081  t-loss:0.1842, loss-lb:0.0725, loss-ulb:0.0559, weight:2.00, lr:0.0002
[12:37:59.660] iteration:26082  t-loss:0.1620, loss-lb:0.0661, loss-ulb:0.0479, weight:2.00, lr:0.0002
[12:37:59.853] iteration:26083  t-loss:0.1321, loss-lb:0.0657, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:38:00.046] iteration:26084  t-loss:0.1406, loss-lb:0.0700, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:38:00.240] iteration:26085  t-loss:0.1566, loss-lb:0.0743, loss-ulb:0.0411, weight:2.00, lr:0.0002
[12:38:00.435] iteration:26086  t-loss:0.1476, loss-lb:0.0782, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:38:00.629] iteration:26087  t-loss:0.1531, loss-lb:0.0845, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:38:00.822] iteration:26088  t-loss:0.1442, loss-lb:0.0783, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:38:01.015] iteration:26089  t-loss:0.1391, loss-lb:0.0649, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:38:01.208] iteration:26090  t-loss:0.1355, loss-lb:0.0694, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:38:01.400] iteration:26091  t-loss:0.1439, loss-lb:0.0691, loss-ulb:0.0374, weight:2.00, lr:0.0002
[12:38:01.592] iteration:26092  t-loss:0.1498, loss-lb:0.0746, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:38:01.785] iteration:26093  t-loss:0.1437, loss-lb:0.0767, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:38:01.977] iteration:26094  t-loss:0.1551, loss-lb:0.0801, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:38:02.172] iteration:26095  t-loss:0.1902, loss-lb:0.0686, loss-ulb:0.0608, weight:2.00, lr:0.0002
[12:38:02.366] iteration:26096  t-loss:0.1342, loss-lb:0.0698, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:38:02.558] iteration:26097  t-loss:0.1377, loss-lb:0.0706, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:38:02.752] iteration:26098  t-loss:0.1558, loss-lb:0.0763, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:38:02.946] iteration:26099  t-loss:0.1352, loss-lb:0.0679, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:38:03.139] iteration:26100  t-loss:0.1472, loss-lb:0.0730, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:38:03.334] iteration:26101  t-loss:0.1407, loss-lb:0.0712, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:38:03.527] iteration:26102  t-loss:0.1226, loss-lb:0.0650, loss-ulb:0.0288, weight:2.00, lr:0.0002
[12:38:03.720] iteration:26103  t-loss:0.1448, loss-lb:0.0686, loss-ulb:0.0381, weight:2.00, lr:0.0002
[12:38:03.913] iteration:26104  t-loss:0.1501, loss-lb:0.0744, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:38:04.106] iteration:26105  t-loss:0.1608, loss-lb:0.0711, loss-ulb:0.0449, weight:2.00, lr:0.0002
[12:38:04.298] iteration:26106  t-loss:0.1320, loss-lb:0.0618, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:04.492] iteration:26107  t-loss:0.1547, loss-lb:0.0745, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:38:04.686] iteration:26108  t-loss:0.1386, loss-lb:0.0772, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:38:04.879] iteration:26109  t-loss:0.1436, loss-lb:0.0765, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:38:05.071] iteration:26110  t-loss:0.1367, loss-lb:0.0661, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:38:05.265] iteration:26111  t-loss:0.1572, loss-lb:0.0757, loss-ulb:0.0407, weight:2.00, lr:0.0002
[12:38:05.458] iteration:26112  t-loss:0.1434, loss-lb:0.0791, loss-ulb:0.0321, weight:2.00, lr:0.0002
[12:38:05.651] iteration:26113  t-loss:0.1395, loss-lb:0.0656, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:38:05.846] iteration:26114  t-loss:0.1759, loss-lb:0.0749, loss-ulb:0.0505, weight:2.00, lr:0.0002
[12:38:06.039] iteration:26115  t-loss:0.1383, loss-lb:0.0680, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:38:06.231] iteration:26116  t-loss:0.1348, loss-lb:0.0667, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:38:06.424] iteration:26117  t-loss:0.1897, loss-lb:0.0741, loss-ulb:0.0578, weight:2.00, lr:0.0002
[12:38:06.618] iteration:26118  t-loss:0.1520, loss-lb:0.0728, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:38:06.810] iteration:26119  t-loss:0.1526, loss-lb:0.0666, loss-ulb:0.0430, weight:2.00, lr:0.0002
[12:38:07.005] iteration:26120  t-loss:0.1754, loss-lb:0.0793, loss-ulb:0.0480, weight:2.00, lr:0.0002
[12:38:07.198] iteration:26121  t-loss:0.1443, loss-lb:0.0751, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:38:07.391] iteration:26122  t-loss:0.1453, loss-lb:0.0688, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:38:07.584] iteration:26123  t-loss:0.1450, loss-lb:0.0643, loss-ulb:0.0403, weight:2.00, lr:0.0002
[12:38:07.777] iteration:26124  t-loss:0.1516, loss-lb:0.0834, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:38:07.970] iteration:26125  t-loss:0.1438, loss-lb:0.0789, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:38:08.165] iteration:26126  t-loss:0.1671, loss-lb:0.0739, loss-ulb:0.0466, weight:2.00, lr:0.0002
[12:38:08.356] iteration:26127  t-loss:0.1403, loss-lb:0.0731, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:38:08.549] iteration:26128  t-loss:0.1483, loss-lb:0.0730, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:38:08.743] iteration:26129  t-loss:0.1388, loss-lb:0.0689, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:38:08.936] iteration:26130  t-loss:0.1371, loss-lb:0.0688, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:38:09.129] iteration:26131  t-loss:0.1371, loss-lb:0.0697, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:38:09.322] iteration:26132  t-loss:0.1465, loss-lb:0.0769, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:38:09.514] iteration:26133  t-loss:0.1434, loss-lb:0.0742, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:38:09.708] iteration:26134  t-loss:0.1383, loss-lb:0.0645, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:38:09.901] iteration:26135  t-loss:0.1378, loss-lb:0.0652, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:38:10.094] iteration:26136  t-loss:0.1519, loss-lb:0.0720, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:38:10.287] iteration:26137  t-loss:0.1332, loss-lb:0.0706, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:38:10.481] iteration:26138  t-loss:0.1394, loss-lb:0.0695, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:38:10.673] iteration:26139  t-loss:0.1450, loss-lb:0.0696, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:38:10.866] iteration:26140  t-loss:0.1382, loss-lb:0.0705, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:38:11.058] iteration:26141  t-loss:0.1274, loss-lb:0.0715, loss-ulb:0.0280, weight:2.00, lr:0.0002
[12:38:11.251] iteration:26142  t-loss:0.1332, loss-lb:0.0699, loss-ulb:0.0316, weight:2.00, lr:0.0002
[12:38:11.444] iteration:26143  t-loss:0.1372, loss-lb:0.0712, loss-ulb:0.0330, weight:2.00, lr:0.0002
[12:38:11.637] iteration:26144  t-loss:0.1384, loss-lb:0.0676, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:38:11.829] iteration:26145  t-loss:0.1348, loss-lb:0.0728, loss-ulb:0.0310, weight:2.00, lr:0.0002
[12:38:12.022] iteration:26146  t-loss:0.1373, loss-lb:0.0719, loss-ulb:0.0327, weight:2.00, lr:0.0002
[12:38:12.215] iteration:26147  t-loss:0.1497, loss-lb:0.0783, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:38:12.408] iteration:26148  t-loss:0.1395, loss-lb:0.0766, loss-ulb:0.0314, weight:2.00, lr:0.0002
[12:38:12.600] iteration:26149  t-loss:0.1462, loss-lb:0.0655, loss-ulb:0.0404, weight:2.00, lr:0.0002
[12:38:12.793] iteration:26150  t-loss:0.1524, loss-lb:0.0803, loss-ulb:0.0360, weight:2.00, lr:0.0002
[12:38:12.986] iteration:26151  t-loss:0.1510, loss-lb:0.0671, loss-ulb:0.0420, weight:2.00, lr:0.0002
[12:38:13.178] iteration:26152  t-loss:0.1411, loss-lb:0.0709, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:13.371] iteration:26153  t-loss:0.1447, loss-lb:0.0710, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:38:13.565] iteration:26154  t-loss:0.1487, loss-lb:0.0670, loss-ulb:0.0409, weight:2.00, lr:0.0002
[12:38:13.758] iteration:26155  t-loss:0.1349, loss-lb:0.0734, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:38:13.950] iteration:26156  t-loss:0.1393, loss-lb:0.0683, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:38:14.143] iteration:26157  t-loss:0.1411, loss-lb:0.0705, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:38:14.336] iteration:26158  t-loss:0.1386, loss-lb:0.0678, loss-ulb:0.0354, weight:2.00, lr:0.0002
[12:38:14.528] iteration:26159  t-loss:0.1617, loss-lb:0.0765, loss-ulb:0.0426, weight:2.00, lr:0.0002
[12:38:14.719] iteration:26160  t-loss:0.1438, loss-lb:0.0790, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:38:14.911] iteration:26161  t-loss:0.1317, loss-lb:0.0683, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:38:15.102] iteration:26162  t-loss:0.1454, loss-lb:0.0753, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:38:15.293] iteration:26163  t-loss:0.1473, loss-lb:0.0629, loss-ulb:0.0422, weight:2.00, lr:0.0002
[12:38:15.484] iteration:26164  t-loss:0.1428, loss-lb:0.0733, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:38:15.675] iteration:26165  t-loss:0.1653, loss-lb:0.0654, loss-ulb:0.0500, weight:2.00, lr:0.0002
[12:38:15.866] iteration:26166  t-loss:0.1402, loss-lb:0.0673, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:38:27.705]  <<Test>> - Ep:266  - mean_dice/mean_h95 - S:89.97/1.29, Best-S:90.99, T:89.58/1.39, Best-T:90.48
[12:38:27.705]           - AvgLoss(lb/ulb/all):0.0716/0.0370/0.1453
[12:38:28.231] iteration:26167  t-loss:0.1452, loss-lb:0.0724, loss-ulb:0.0364, weight:2.00, lr:0.0002
[12:38:28.429] iteration:26168  t-loss:0.1394, loss-lb:0.0703, loss-ulb:0.0346, weight:2.00, lr:0.0002
[12:38:28.622] iteration:26169  t-loss:0.1455, loss-lb:0.0696, loss-ulb:0.0379, weight:2.00, lr:0.0002
[12:38:28.816] iteration:26170  t-loss:0.1395, loss-lb:0.0718, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:38:29.009] iteration:26171  t-loss:0.1389, loss-lb:0.0740, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:38:29.201] iteration:26172  t-loss:0.1447, loss-lb:0.0763, loss-ulb:0.0342, weight:2.00, lr:0.0002
[12:38:29.394] iteration:26173  t-loss:0.1299, loss-lb:0.0685, loss-ulb:0.0307, weight:2.00, lr:0.0002
[12:38:29.587] iteration:26174  t-loss:0.1446, loss-lb:0.0706, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:38:29.781] iteration:26175  t-loss:0.1423, loss-lb:0.0649, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:38:29.974] iteration:26176  t-loss:0.1450, loss-lb:0.0737, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:38:30.167] iteration:26177  t-loss:0.1477, loss-lb:0.0682, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:38:30.361] iteration:26178  t-loss:0.1329, loss-lb:0.0723, loss-ulb:0.0303, weight:2.00, lr:0.0002
[12:38:30.555] iteration:26179  t-loss:0.1370, loss-lb:0.0675, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:38:30.748] iteration:26180  t-loss:0.1584, loss-lb:0.0760, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:38:30.940] iteration:26181  t-loss:0.1366, loss-lb:0.0664, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:31.133] iteration:26182  t-loss:0.1646, loss-lb:0.0810, loss-ulb:0.0418, weight:2.00, lr:0.0002
[12:38:31.326] iteration:26183  t-loss:0.1453, loss-lb:0.0790, loss-ulb:0.0331, weight:2.00, lr:0.0002
[12:38:31.520] iteration:26184  t-loss:0.2510, loss-lb:0.0733, loss-ulb:0.0889, weight:2.00, lr:0.0002
[12:38:31.714] iteration:26185  t-loss:0.1641, loss-lb:0.0726, loss-ulb:0.0458, weight:2.00, lr:0.0002
[12:38:31.906] iteration:26186  t-loss:0.1342, loss-lb:0.0663, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:38:32.100] iteration:26187  t-loss:0.1292, loss-lb:0.0642, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:38:32.293] iteration:26188  t-loss:0.1434, loss-lb:0.0733, loss-ulb:0.0350, weight:2.00, lr:0.0002
[12:38:32.484] iteration:26189  t-loss:0.1478, loss-lb:0.0700, loss-ulb:0.0389, weight:2.00, lr:0.0002
[12:38:32.677] iteration:26190  t-loss:0.1474, loss-lb:0.0702, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:38:32.869] iteration:26191  t-loss:0.1268, loss-lb:0.0692, loss-ulb:0.0288, weight:2.00, lr:0.0002
[12:38:33.061] iteration:26192  t-loss:0.1561, loss-lb:0.0648, loss-ulb:0.0456, weight:2.00, lr:0.0002
[12:38:33.254] iteration:26193  t-loss:0.1486, loss-lb:0.0720, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:38:33.446] iteration:26194  t-loss:0.1430, loss-lb:0.0688, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:38:33.639] iteration:26195  t-loss:0.1374, loss-lb:0.0731, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:38:33.833] iteration:26196  t-loss:0.1399, loss-lb:0.0734, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:38:34.026] iteration:26197  t-loss:0.1937, loss-lb:0.0771, loss-ulb:0.0583, weight:2.00, lr:0.0002
[12:38:34.219] iteration:26198  t-loss:0.1389, loss-lb:0.0707, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:38:34.412] iteration:26199  t-loss:0.1296, loss-lb:0.0639, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:38:34.605] iteration:26200  t-loss:0.1490, loss-lb:0.0652, loss-ulb:0.0419, weight:2.00, lr:0.0002
[12:38:34.797] iteration:26201  t-loss:0.1518, loss-lb:0.0795, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:38:34.990] iteration:26202  t-loss:0.1468, loss-lb:0.0666, loss-ulb:0.0401, weight:2.00, lr:0.0002
[12:38:35.182] iteration:26203  t-loss:0.1529, loss-lb:0.0835, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:38:35.376] iteration:26204  t-loss:0.1345, loss-lb:0.0668, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:38:35.567] iteration:26205  t-loss:0.1357, loss-lb:0.0707, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:38:35.760] iteration:26206  t-loss:0.1464, loss-lb:0.0752, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:38:35.953] iteration:26207  t-loss:0.1924, loss-lb:0.0665, loss-ulb:0.0629, weight:2.00, lr:0.0002
[12:38:36.147] iteration:26208  t-loss:0.1866, loss-lb:0.0709, loss-ulb:0.0578, weight:2.00, lr:0.0002
[12:38:36.339] iteration:26209  t-loss:0.1511, loss-lb:0.0798, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:38:36.532] iteration:26210  t-loss:0.1517, loss-lb:0.0693, loss-ulb:0.0412, weight:2.00, lr:0.0002
[12:38:36.726] iteration:26211  t-loss:0.1532, loss-lb:0.0596, loss-ulb:0.0468, weight:2.00, lr:0.0002
[12:38:36.919] iteration:26212  t-loss:0.2446, loss-lb:0.0743, loss-ulb:0.0851, weight:2.00, lr:0.0002
[12:38:37.112] iteration:26213  t-loss:0.1710, loss-lb:0.0680, loss-ulb:0.0515, weight:2.00, lr:0.0002
[12:38:37.304] iteration:26214  t-loss:0.1368, loss-lb:0.0656, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:38:37.498] iteration:26215  t-loss:0.2137, loss-lb:0.0857, loss-ulb:0.0640, weight:2.00, lr:0.0002
[12:38:37.690] iteration:26216  t-loss:0.1713, loss-lb:0.0686, loss-ulb:0.0513, weight:2.00, lr:0.0002
[12:38:37.882] iteration:26217  t-loss:0.1380, loss-lb:0.0675, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:38:38.076] iteration:26218  t-loss:0.1419, loss-lb:0.0646, loss-ulb:0.0386, weight:2.00, lr:0.0002
[12:38:38.272] iteration:26219  t-loss:0.1574, loss-lb:0.0723, loss-ulb:0.0425, weight:2.00, lr:0.0002
[12:38:38.466] iteration:26220  t-loss:0.1487, loss-lb:0.0668, loss-ulb:0.0410, weight:2.00, lr:0.0002
[12:38:38.660] iteration:26221  t-loss:0.1353, loss-lb:0.0707, loss-ulb:0.0323, weight:2.00, lr:0.0002
[12:38:38.855] iteration:26222  t-loss:0.1421, loss-lb:0.0786, loss-ulb:0.0317, weight:2.00, lr:0.0002
[12:38:39.048] iteration:26223  t-loss:0.2500, loss-lb:0.0783, loss-ulb:0.0859, weight:2.00, lr:0.0002
[12:38:39.241] iteration:26224  t-loss:0.1265, loss-lb:0.0692, loss-ulb:0.0286, weight:2.00, lr:0.0002
[12:38:39.432] iteration:26225  t-loss:0.1347, loss-lb:0.0681, loss-ulb:0.0333, weight:2.00, lr:0.0002
[12:38:39.624] iteration:26226  t-loss:0.1506, loss-lb:0.0720, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:38:39.816] iteration:26227  t-loss:0.1466, loss-lb:0.0736, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:38:40.007] iteration:26228  t-loss:0.1354, loss-lb:0.0644, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:38:40.200] iteration:26229  t-loss:0.1330, loss-lb:0.0705, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:38:40.392] iteration:26230  t-loss:0.1404, loss-lb:0.0754, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:38:40.584] iteration:26231  t-loss:0.1369, loss-lb:0.0726, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:38:40.776] iteration:26232  t-loss:0.1664, loss-lb:0.0718, loss-ulb:0.0473, weight:2.00, lr:0.0002
[12:38:40.968] iteration:26233  t-loss:0.1617, loss-lb:0.0720, loss-ulb:0.0449, weight:2.00, lr:0.0002
[12:38:41.159] iteration:26234  t-loss:0.1517, loss-lb:0.0752, loss-ulb:0.0383, weight:2.00, lr:0.0002
[12:38:41.351] iteration:26235  t-loss:0.1372, loss-lb:0.0715, loss-ulb:0.0329, weight:2.00, lr:0.0002
[12:38:41.545] iteration:26236  t-loss:0.1570, loss-lb:0.0758, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:38:41.746] iteration:26237  t-loss:0.1347, loss-lb:0.0721, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:38:41.939] iteration:26238  t-loss:0.1446, loss-lb:0.0702, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:38:42.132] iteration:26239  t-loss:0.1474, loss-lb:0.0721, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:38:42.324] iteration:26240  t-loss:0.1378, loss-lb:0.0680, loss-ulb:0.0349, weight:2.00, lr:0.0002
[12:38:42.524] iteration:26241  t-loss:0.1384, loss-lb:0.0674, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:38:42.717] iteration:26242  t-loss:0.1432, loss-lb:0.0760, loss-ulb:0.0336, weight:2.00, lr:0.0002
[12:38:42.908] iteration:26243  t-loss:0.1374, loss-lb:0.0663, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:38:43.100] iteration:26244  t-loss:0.1438, loss-lb:0.0695, loss-ulb:0.0371, weight:2.00, lr:0.0002
[12:38:43.299] iteration:26245  t-loss:0.1673, loss-lb:0.0750, loss-ulb:0.0461, weight:2.00, lr:0.0002
[12:38:43.492] iteration:26246  t-loss:0.1709, loss-lb:0.0767, loss-ulb:0.0471, weight:2.00, lr:0.0002
[12:38:43.685] iteration:26247  t-loss:0.1480, loss-lb:0.0691, loss-ulb:0.0394, weight:2.00, lr:0.0002
[12:38:43.878] iteration:26248  t-loss:0.1720, loss-lb:0.0764, loss-ulb:0.0478, weight:2.00, lr:0.0002
[12:38:44.075] iteration:26249  t-loss:0.1423, loss-lb:0.0674, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:38:44.266] iteration:26250  t-loss:0.1363, loss-lb:0.0645, loss-ulb:0.0359, weight:2.00, lr:0.0002
[12:38:44.459] iteration:26251  t-loss:0.1415, loss-lb:0.0712, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:44.652] iteration:26252  t-loss:0.1587, loss-lb:0.0625, loss-ulb:0.0481, weight:2.00, lr:0.0002
[12:38:44.851] iteration:26253  t-loss:0.1421, loss-lb:0.0744, loss-ulb:0.0338, weight:2.00, lr:0.0002
[12:38:45.043] iteration:26254  t-loss:0.1439, loss-lb:0.0736, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:45.237] iteration:26255  t-loss:0.1497, loss-lb:0.0696, loss-ulb:0.0400, weight:2.00, lr:0.0002
[12:38:45.429] iteration:26256  t-loss:0.1350, loss-lb:0.0649, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:45.620] iteration:26257  t-loss:0.1318, loss-lb:0.0707, loss-ulb:0.0306, weight:2.00, lr:0.0002
[12:38:45.813] iteration:26258  t-loss:0.1910, loss-lb:0.0767, loss-ulb:0.0571, weight:2.00, lr:0.0002
[12:38:46.003] iteration:26259  t-loss:0.1485, loss-lb:0.0731, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:38:46.193] iteration:26260  t-loss:0.1650, loss-lb:0.0673, loss-ulb:0.0488, weight:2.00, lr:0.0002
[12:38:46.383] iteration:26261  t-loss:0.1430, loss-lb:0.0695, loss-ulb:0.0367, weight:2.00, lr:0.0002
[12:38:46.572] iteration:26262  t-loss:0.1410, loss-lb:0.0713, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:38:46.762] iteration:26263  t-loss:0.1605, loss-lb:0.0724, loss-ulb:0.0441, weight:2.00, lr:0.0002
[12:38:46.951] iteration:26264  t-loss:0.1438, loss-lb:0.0688, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:38:47.535] iteration:26265  t-loss:0.1416, loss-lb:0.0702, loss-ulb:0.0357, weight:2.00, lr:0.0002
[12:38:47.731] iteration:26266  t-loss:0.1561, loss-lb:0.0767, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:38:47.923] iteration:26267  t-loss:0.1327, loss-lb:0.0727, loss-ulb:0.0300, weight:2.00, lr:0.0002
[12:38:48.114] iteration:26268  t-loss:0.1479, loss-lb:0.0767, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:38:48.306] iteration:26269  t-loss:0.1467, loss-lb:0.0713, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:38:48.497] iteration:26270  t-loss:0.1431, loss-lb:0.0691, loss-ulb:0.0370, weight:2.00, lr:0.0002
[12:38:48.698] iteration:26271  t-loss:0.1482, loss-lb:0.0779, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:48.910] iteration:26272  t-loss:0.1553, loss-lb:0.0724, loss-ulb:0.0415, weight:2.00, lr:0.0002
[12:38:49.108] iteration:26273  t-loss:0.1454, loss-lb:0.0683, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:38:49.303] iteration:26274  t-loss:0.1327, loss-lb:0.0690, loss-ulb:0.0318, weight:2.00, lr:0.0002
[12:38:49.497] iteration:26275  t-loss:0.1393, loss-lb:0.0710, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:38:49.691] iteration:26276  t-loss:0.1392, loss-lb:0.0712, loss-ulb:0.0340, weight:2.00, lr:0.0002
[12:38:49.883] iteration:26277  t-loss:0.1506, loss-lb:0.0712, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:38:50.075] iteration:26278  t-loss:0.1433, loss-lb:0.0718, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:38:50.268] iteration:26279  t-loss:0.1347, loss-lb:0.0661, loss-ulb:0.0343, weight:2.00, lr:0.0002
[12:38:50.460] iteration:26280  t-loss:0.1695, loss-lb:0.0755, loss-ulb:0.0470, weight:2.00, lr:0.0002
[12:38:50.654] iteration:26281  t-loss:0.1499, loss-lb:0.0792, loss-ulb:0.0353, weight:2.00, lr:0.0002
[12:38:50.846] iteration:26282  t-loss:0.1382, loss-lb:0.0751, loss-ulb:0.0315, weight:2.00, lr:0.0002
[12:38:51.038] iteration:26283  t-loss:0.1382, loss-lb:0.0737, loss-ulb:0.0322, weight:2.00, lr:0.0002
[12:38:51.230] iteration:26284  t-loss:0.1441, loss-lb:0.0674, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:38:51.423] iteration:26285  t-loss:0.1437, loss-lb:0.0733, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:38:51.615] iteration:26286  t-loss:0.1369, loss-lb:0.0680, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:38:51.807] iteration:26287  t-loss:0.1522, loss-lb:0.0739, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:38:51.999] iteration:26288  t-loss:0.1301, loss-lb:0.0686, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:38:52.192] iteration:26289  t-loss:0.1403, loss-lb:0.0746, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:38:52.384] iteration:26290  t-loss:0.1396, loss-lb:0.0652, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:38:52.576] iteration:26291  t-loss:0.1496, loss-lb:0.0709, loss-ulb:0.0393, weight:2.00, lr:0.0002
[12:38:52.768] iteration:26292  t-loss:0.1625, loss-lb:0.0778, loss-ulb:0.0423, weight:2.00, lr:0.0002
[12:38:52.965] iteration:26293  t-loss:0.1371, loss-lb:0.0755, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:38:53.157] iteration:26294  t-loss:0.1471, loss-lb:0.0678, loss-ulb:0.0396, weight:2.00, lr:0.0002
[12:38:53.350] iteration:26295  t-loss:0.1321, loss-lb:0.0643, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:38:53.542] iteration:26296  t-loss:0.1339, loss-lb:0.0731, loss-ulb:0.0304, weight:2.00, lr:0.0002
[12:38:53.734] iteration:26297  t-loss:0.1433, loss-lb:0.0652, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:38:53.927] iteration:26298  t-loss:0.1498, loss-lb:0.0785, loss-ulb:0.0356, weight:2.00, lr:0.0002
[12:38:54.121] iteration:26299  t-loss:0.1830, loss-lb:0.0699, loss-ulb:0.0566, weight:2.00, lr:0.0002
[12:38:54.313] iteration:26300  t-loss:0.1436, loss-lb:0.0719, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:38:54.505] iteration:26301  t-loss:0.1376, loss-lb:0.0760, loss-ulb:0.0308, weight:2.00, lr:0.0002
[12:38:54.698] iteration:26302  t-loss:0.1357, loss-lb:0.0687, loss-ulb:0.0335, weight:2.00, lr:0.0002
[12:38:54.889] iteration:26303  t-loss:0.1476, loss-lb:0.0793, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:38:55.082] iteration:26304  t-loss:0.1462, loss-lb:0.0718, loss-ulb:0.0372, weight:2.00, lr:0.0002
[12:38:55.273] iteration:26305  t-loss:0.1465, loss-lb:0.0728, loss-ulb:0.0369, weight:2.00, lr:0.0002
[12:38:55.465] iteration:26306  t-loss:0.1430, loss-lb:0.0749, loss-ulb:0.0341, weight:2.00, lr:0.0002
[12:38:55.657] iteration:26307  t-loss:0.1530, loss-lb:0.0777, loss-ulb:0.0376, weight:2.00, lr:0.0002
[12:38:55.849] iteration:26308  t-loss:0.1370, loss-lb:0.0634, loss-ulb:0.0368, weight:2.00, lr:0.0002
[12:38:56.041] iteration:26309  t-loss:0.1493, loss-lb:0.0665, loss-ulb:0.0414, weight:2.00, lr:0.0002
[12:38:56.234] iteration:26310  t-loss:0.1443, loss-lb:0.0660, loss-ulb:0.0392, weight:2.00, lr:0.0002
[12:38:56.426] iteration:26311  t-loss:0.1420, loss-lb:0.0718, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:38:56.618] iteration:26312  t-loss:0.1448, loss-lb:0.0688, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:38:56.810] iteration:26313  t-loss:0.1521, loss-lb:0.0766, loss-ulb:0.0377, weight:2.00, lr:0.0002
[12:38:57.003] iteration:26314  t-loss:0.1428, loss-lb:0.0739, loss-ulb:0.0344, weight:2.00, lr:0.0002
[12:38:57.194] iteration:26315  t-loss:0.1883, loss-lb:0.0986, loss-ulb:0.0449, weight:2.00, lr:0.0002
[12:38:57.385] iteration:26316  t-loss:0.1352, loss-lb:0.0734, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:38:57.578] iteration:26317  t-loss:0.1404, loss-lb:0.0695, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:38:57.769] iteration:26318  t-loss:0.1383, loss-lb:0.0678, loss-ulb:0.0352, weight:2.00, lr:0.0002
[12:38:57.960] iteration:26319  t-loss:0.1301, loss-lb:0.0644, loss-ulb:0.0328, weight:2.00, lr:0.0002
[12:38:58.151] iteration:26320  t-loss:0.1382, loss-lb:0.0718, loss-ulb:0.0332, weight:2.00, lr:0.0002
[12:38:58.343] iteration:26321  t-loss:0.1378, loss-lb:0.0682, loss-ulb:0.0348, weight:2.00, lr:0.0002
[12:38:58.535] iteration:26322  t-loss:0.1511, loss-lb:0.0785, loss-ulb:0.0363, weight:2.00, lr:0.0002
[12:38:58.726] iteration:26323  t-loss:0.1480, loss-lb:0.0706, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:38:58.918] iteration:26324  t-loss:0.1409, loss-lb:0.0684, loss-ulb:0.0362, weight:2.00, lr:0.0002
[12:38:59.110] iteration:26325  t-loss:0.1426, loss-lb:0.0656, loss-ulb:0.0385, weight:2.00, lr:0.0002
[12:38:59.303] iteration:26326  t-loss:0.1438, loss-lb:0.0708, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:38:59.495] iteration:26327  t-loss:0.1618, loss-lb:0.0837, loss-ulb:0.0391, weight:2.00, lr:0.0002
[12:38:59.689] iteration:26328  t-loss:0.1366, loss-lb:0.0739, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:38:59.883] iteration:26329  t-loss:0.2218, loss-lb:0.0668, loss-ulb:0.0775, weight:2.00, lr:0.0002
[12:39:00.078] iteration:26330  t-loss:0.1452, loss-lb:0.0685, loss-ulb:0.0384, weight:2.00, lr:0.0002
[12:39:00.272] iteration:26331  t-loss:0.1392, loss-lb:0.0698, loss-ulb:0.0347, weight:2.00, lr:0.0002
[12:39:00.465] iteration:26332  t-loss:0.1380, loss-lb:0.0706, loss-ulb:0.0337, weight:2.00, lr:0.0002
[12:39:00.658] iteration:26333  t-loss:0.1753, loss-lb:0.0693, loss-ulb:0.0530, weight:2.00, lr:0.0002
[12:39:00.851] iteration:26334  t-loss:0.1429, loss-lb:0.0706, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:39:01.042] iteration:26335  t-loss:0.1303, loss-lb:0.0715, loss-ulb:0.0294, weight:2.00, lr:0.0002
[12:39:01.234] iteration:26336  t-loss:0.1403, loss-lb:0.0776, loss-ulb:0.0313, weight:2.00, lr:0.0002
[12:39:01.426] iteration:26337  t-loss:0.1488, loss-lb:0.0694, loss-ulb:0.0397, weight:2.00, lr:0.0002
[12:39:01.617] iteration:26338  t-loss:0.1424, loss-lb:0.0776, loss-ulb:0.0324, weight:2.00, lr:0.0002
[12:39:01.810] iteration:26339  t-loss:0.1482, loss-lb:0.0707, loss-ulb:0.0387, weight:2.00, lr:0.0002
[12:39:02.002] iteration:26340  t-loss:0.1460, loss-lb:0.0781, loss-ulb:0.0339, weight:2.00, lr:0.0002
[12:39:02.193] iteration:26341  t-loss:0.1439, loss-lb:0.0738, loss-ulb:0.0351, weight:2.00, lr:0.0002
[12:39:02.385] iteration:26342  t-loss:0.1471, loss-lb:0.0721, loss-ulb:0.0375, weight:2.00, lr:0.0002
[12:39:02.577] iteration:26343  t-loss:0.1411, loss-lb:0.0696, loss-ulb:0.0358, weight:2.00, lr:0.0002
[12:39:02.769] iteration:26344  t-loss:0.1530, loss-lb:0.0718, loss-ulb:0.0406, weight:2.00, lr:0.0002
[12:39:02.961] iteration:26345  t-loss:0.1293, loss-lb:0.0656, loss-ulb:0.0319, weight:2.00, lr:0.0002
[12:39:03.153] iteration:26346  t-loss:0.1462, loss-lb:0.0740, loss-ulb:0.0361, weight:2.00, lr:0.0002
[12:39:03.346] iteration:26347  t-loss:0.1234, loss-lb:0.0652, loss-ulb:0.0291, weight:2.00, lr:0.0002
[12:39:03.537] iteration:26348  t-loss:0.1479, loss-lb:0.0719, loss-ulb:0.0380, weight:2.00, lr:0.0002
[12:39:03.729] iteration:26349  t-loss:0.1432, loss-lb:0.0702, loss-ulb:0.0365, weight:2.00, lr:0.0002
[12:39:03.921] iteration:26350  t-loss:0.1289, loss-lb:0.0639, loss-ulb:0.0325, weight:2.00, lr:0.0002
[12:39:04.114] iteration:26351  t-loss:0.1572, loss-lb:0.0729, loss-ulb:0.0422, weight:2.00, lr:0.0002
[12:39:04.307] iteration:26352  t-loss:0.1733, loss-lb:0.0692, loss-ulb:0.0521, weight:2.00, lr:0.0002
[12:39:04.501] iteration:26353  t-loss:0.1387, loss-lb:0.0677, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:39:04.693] iteration:26354  t-loss:0.1488, loss-lb:0.0655, loss-ulb:0.0417, weight:2.00, lr:0.0002
[12:39:04.885] iteration:26355  t-loss:0.1531, loss-lb:0.0821, loss-ulb:0.0355, weight:2.00, lr:0.0002
[12:39:05.075] iteration:26356  t-loss:0.1332, loss-lb:0.0715, loss-ulb:0.0309, weight:2.00, lr:0.0002
[12:39:05.266] iteration:26357  t-loss:0.1492, loss-lb:0.0737, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:39:05.459] iteration:26358  t-loss:0.1926, loss-lb:0.0777, loss-ulb:0.0575, weight:2.00, lr:0.0001
[12:39:05.649] iteration:26359  t-loss:0.1398, loss-lb:0.0672, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:39:05.841] iteration:26360  t-loss:0.1548, loss-lb:0.0722, loss-ulb:0.0413, weight:2.00, lr:0.0001
[12:39:06.031] iteration:26361  t-loss:0.1372, loss-lb:0.0664, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:39:06.223] iteration:26362  t-loss:0.1495, loss-lb:0.0770, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:39:19.273]  <<Test>> - Ep:268  - mean_dice/mean_h95 - S:89.62/1.39, Best-S:90.99, T:89.62/1.39, Best-T:90.48
[12:39:19.273]           - AvgLoss(lb/ulb/all):0.0718/0.0381/0.1470
[12:39:19.815] iteration:26363  t-loss:0.1512, loss-lb:0.0709, loss-ulb:0.0402, weight:2.00, lr:0.0001
[12:39:20.012] iteration:26364  t-loss:0.1422, loss-lb:0.0796, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:39:20.203] iteration:26365  t-loss:0.1286, loss-lb:0.0638, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:39:20.397] iteration:26366  t-loss:0.1434, loss-lb:0.0735, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:39:20.589] iteration:26367  t-loss:0.1436, loss-lb:0.0693, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:39:20.782] iteration:26368  t-loss:0.1432, loss-lb:0.0796, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:39:20.973] iteration:26369  t-loss:0.1411, loss-lb:0.0752, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:39:21.165] iteration:26370  t-loss:0.1703, loss-lb:0.0758, loss-ulb:0.0472, weight:2.00, lr:0.0001
[12:39:21.357] iteration:26371  t-loss:0.1523, loss-lb:0.0723, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:39:21.564] iteration:26372  t-loss:0.1390, loss-lb:0.0672, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:39:21.765] iteration:26373  t-loss:0.1571, loss-lb:0.0663, loss-ulb:0.0454, weight:2.00, lr:0.0001
[12:39:21.963] iteration:26374  t-loss:0.1487, loss-lb:0.0702, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:39:22.156] iteration:26375  t-loss:0.1484, loss-lb:0.0718, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:39:22.350] iteration:26376  t-loss:0.1547, loss-lb:0.0712, loss-ulb:0.0417, weight:2.00, lr:0.0001
[12:39:22.544] iteration:26377  t-loss:0.1619, loss-lb:0.0697, loss-ulb:0.0461, weight:2.00, lr:0.0001
[12:39:22.736] iteration:26378  t-loss:0.1318, loss-lb:0.0647, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:39:22.929] iteration:26379  t-loss:0.1442, loss-lb:0.0773, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:39:23.123] iteration:26380  t-loss:0.1387, loss-lb:0.0692, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:39:23.316] iteration:26381  t-loss:0.1511, loss-lb:0.0816, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:39:23.508] iteration:26382  t-loss:0.1478, loss-lb:0.0718, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:39:23.700] iteration:26383  t-loss:0.1457, loss-lb:0.0699, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:39:23.893] iteration:26384  t-loss:0.1668, loss-lb:0.0791, loss-ulb:0.0439, weight:2.00, lr:0.0001
[12:39:24.086] iteration:26385  t-loss:0.1829, loss-lb:0.0719, loss-ulb:0.0555, weight:2.00, lr:0.0001
[12:39:24.279] iteration:26386  t-loss:0.1455, loss-lb:0.0702, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:39:24.470] iteration:26387  t-loss:0.1445, loss-lb:0.0723, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:39:24.663] iteration:26388  t-loss:0.1397, loss-lb:0.0681, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:39:24.856] iteration:26389  t-loss:0.1603, loss-lb:0.0808, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:39:25.048] iteration:26390  t-loss:0.1449, loss-lb:0.0728, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:39:25.242] iteration:26391  t-loss:0.1374, loss-lb:0.0673, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:39:25.435] iteration:26392  t-loss:0.1705, loss-lb:0.0780, loss-ulb:0.0463, weight:2.00, lr:0.0001
[12:39:25.628] iteration:26393  t-loss:0.1429, loss-lb:0.0677, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:39:25.820] iteration:26394  t-loss:0.1383, loss-lb:0.0706, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:39:26.013] iteration:26395  t-loss:0.1437, loss-lb:0.0683, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:39:26.205] iteration:26396  t-loss:0.1393, loss-lb:0.0715, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:39:26.399] iteration:26397  t-loss:0.1385, loss-lb:0.0687, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:39:26.590] iteration:26398  t-loss:0.1442, loss-lb:0.0745, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:39:26.783] iteration:26399  t-loss:0.1437, loss-lb:0.0693, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:39:26.976] iteration:26400  t-loss:0.1484, loss-lb:0.0706, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:39:27.169] iteration:26401  t-loss:0.1300, loss-lb:0.0683, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:39:27.361] iteration:26402  t-loss:0.1370, loss-lb:0.0740, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:39:27.553] iteration:26403  t-loss:0.1497, loss-lb:0.0692, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:39:27.745] iteration:26404  t-loss:0.1455, loss-lb:0.0776, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:39:27.938] iteration:26405  t-loss:0.1533, loss-lb:0.0735, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:39:28.131] iteration:26406  t-loss:0.1274, loss-lb:0.0696, loss-ulb:0.0289, weight:2.00, lr:0.0001
[12:39:28.324] iteration:26407  t-loss:0.1327, loss-lb:0.0725, loss-ulb:0.0301, weight:2.00, lr:0.0001
[12:39:28.515] iteration:26408  t-loss:0.1387, loss-lb:0.0693, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:39:28.709] iteration:26409  t-loss:0.1420, loss-lb:0.0702, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:39:28.903] iteration:26410  t-loss:0.1304, loss-lb:0.0652, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:39:29.095] iteration:26411  t-loss:0.1937, loss-lb:0.0754, loss-ulb:0.0592, weight:2.00, lr:0.0001
[12:39:29.288] iteration:26412  t-loss:0.1757, loss-lb:0.0736, loss-ulb:0.0510, weight:2.00, lr:0.0001
[12:39:29.481] iteration:26413  t-loss:0.1372, loss-lb:0.0690, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:39:29.673] iteration:26414  t-loss:0.1464, loss-lb:0.0772, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:39:29.865] iteration:26415  t-loss:0.1414, loss-lb:0.0743, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:39:30.058] iteration:26416  t-loss:0.1418, loss-lb:0.0672, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:39:30.250] iteration:26417  t-loss:0.1496, loss-lb:0.0736, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:39:30.442] iteration:26418  t-loss:0.1439, loss-lb:0.0678, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:39:30.635] iteration:26419  t-loss:0.1476, loss-lb:0.0706, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:39:30.827] iteration:26420  t-loss:0.1239, loss-lb:0.0668, loss-ulb:0.0286, weight:2.00, lr:0.0001
[12:39:31.019] iteration:26421  t-loss:0.1620, loss-lb:0.0762, loss-ulb:0.0429, weight:2.00, lr:0.0001
[12:39:31.211] iteration:26422  t-loss:0.1550, loss-lb:0.0654, loss-ulb:0.0448, weight:2.00, lr:0.0001
[12:39:31.404] iteration:26423  t-loss:0.1380, loss-lb:0.0684, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:39:31.595] iteration:26424  t-loss:0.1364, loss-lb:0.0650, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:39:31.787] iteration:26425  t-loss:0.1414, loss-lb:0.0743, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:39:31.979] iteration:26426  t-loss:0.1479, loss-lb:0.0771, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:39:32.171] iteration:26427  t-loss:0.1492, loss-lb:0.0740, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:39:32.364] iteration:26428  t-loss:0.1554, loss-lb:0.0734, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:39:32.556] iteration:26429  t-loss:0.1412, loss-lb:0.0755, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:39:32.750] iteration:26430  t-loss:0.1382, loss-lb:0.0691, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:39:32.942] iteration:26431  t-loss:0.1477, loss-lb:0.0793, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:39:33.134] iteration:26432  t-loss:0.1339, loss-lb:0.0676, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:39:33.326] iteration:26433  t-loss:0.1347, loss-lb:0.0702, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:39:33.519] iteration:26434  t-loss:0.1388, loss-lb:0.0722, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:39:33.711] iteration:26435  t-loss:0.1357, loss-lb:0.0679, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:39:33.903] iteration:26436  t-loss:0.1399, loss-lb:0.0719, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:39:34.096] iteration:26437  t-loss:0.1378, loss-lb:0.0708, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:39:34.289] iteration:26438  t-loss:0.1495, loss-lb:0.0821, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:39:34.482] iteration:26439  t-loss:0.1331, loss-lb:0.0726, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:39:34.674] iteration:26440  t-loss:0.1418, loss-lb:0.0679, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:39:34.866] iteration:26441  t-loss:0.1363, loss-lb:0.0719, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:39:35.060] iteration:26442  t-loss:0.1394, loss-lb:0.0692, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:39:35.252] iteration:26443  t-loss:0.1309, loss-lb:0.0662, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:39:35.446] iteration:26444  t-loss:0.1788, loss-lb:0.0728, loss-ulb:0.0530, weight:2.00, lr:0.0001
[12:39:35.638] iteration:26445  t-loss:0.1319, loss-lb:0.0656, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:39:35.831] iteration:26446  t-loss:0.1267, loss-lb:0.0675, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:39:36.023] iteration:26447  t-loss:0.1492, loss-lb:0.0645, loss-ulb:0.0424, weight:2.00, lr:0.0001
[12:39:36.215] iteration:26448  t-loss:0.1419, loss-lb:0.0664, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:39:36.408] iteration:26449  t-loss:0.1310, loss-lb:0.0727, loss-ulb:0.0291, weight:2.00, lr:0.0001
[12:39:36.600] iteration:26450  t-loss:0.1490, loss-lb:0.0696, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:39:36.794] iteration:26451  t-loss:0.1383, loss-lb:0.0734, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:39:36.986] iteration:26452  t-loss:0.1468, loss-lb:0.0673, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:39:37.178] iteration:26453  t-loss:0.1387, loss-lb:0.0656, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:39:37.368] iteration:26454  t-loss:0.1295, loss-lb:0.0695, loss-ulb:0.0300, weight:2.00, lr:0.0001
[12:39:37.559] iteration:26455  t-loss:0.1579, loss-lb:0.0755, loss-ulb:0.0412, weight:2.00, lr:0.0001
[12:39:37.750] iteration:26456  t-loss:0.1291, loss-lb:0.0670, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:39:37.941] iteration:26457  t-loss:0.1416, loss-lb:0.0720, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:39:38.131] iteration:26458  t-loss:0.1482, loss-lb:0.0697, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:39:38.322] iteration:26459  t-loss:0.1316, loss-lb:0.0646, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:39:38.513] iteration:26460  t-loss:0.1374, loss-lb:0.0672, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:39:39.113] iteration:26461  t-loss:0.1418, loss-lb:0.0668, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:39:39.310] iteration:26462  t-loss:0.1543, loss-lb:0.0766, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:39:39.502] iteration:26463  t-loss:0.2028, loss-lb:0.0718, loss-ulb:0.0655, weight:2.00, lr:0.0001
[12:39:39.697] iteration:26464  t-loss:0.1542, loss-lb:0.0780, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:39:39.890] iteration:26465  t-loss:0.1541, loss-lb:0.0707, loss-ulb:0.0417, weight:2.00, lr:0.0001
[12:39:40.083] iteration:26466  t-loss:0.1340, loss-lb:0.0679, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:39:40.275] iteration:26467  t-loss:0.1420, loss-lb:0.0714, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:39:40.467] iteration:26468  t-loss:0.1392, loss-lb:0.0648, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:39:40.659] iteration:26469  t-loss:0.1403, loss-lb:0.0683, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:39:40.853] iteration:26470  t-loss:0.1546, loss-lb:0.0793, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:39:41.044] iteration:26471  t-loss:0.1487, loss-lb:0.0699, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:39:41.237] iteration:26472  t-loss:0.1491, loss-lb:0.0757, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:39:41.431] iteration:26473  t-loss:0.1529, loss-lb:0.0714, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:39:41.623] iteration:26474  t-loss:0.1383, loss-lb:0.0706, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:39:41.816] iteration:26475  t-loss:0.1528, loss-lb:0.0735, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:39:42.008] iteration:26476  t-loss:0.1456, loss-lb:0.0781, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:39:42.201] iteration:26477  t-loss:0.1616, loss-lb:0.0750, loss-ulb:0.0433, weight:2.00, lr:0.0001
[12:39:42.394] iteration:26478  t-loss:0.1853, loss-lb:0.0738, loss-ulb:0.0558, weight:2.00, lr:0.0001
[12:39:42.587] iteration:26479  t-loss:0.1491, loss-lb:0.0688, loss-ulb:0.0402, weight:2.00, lr:0.0001
[12:39:42.779] iteration:26480  t-loss:0.1497, loss-lb:0.0695, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:39:42.973] iteration:26481  t-loss:0.2031, loss-lb:0.0682, loss-ulb:0.0675, weight:2.00, lr:0.0001
[12:39:43.167] iteration:26482  t-loss:0.1353, loss-lb:0.0665, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:39:43.358] iteration:26483  t-loss:0.1473, loss-lb:0.0792, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:39:43.551] iteration:26484  t-loss:0.1429, loss-lb:0.0768, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:39:43.745] iteration:26485  t-loss:0.2649, loss-lb:0.0664, loss-ulb:0.0992, weight:2.00, lr:0.0001
[12:39:43.938] iteration:26486  t-loss:0.1497, loss-lb:0.0740, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:39:44.130] iteration:26487  t-loss:0.1856, loss-lb:0.0651, loss-ulb:0.0603, weight:2.00, lr:0.0001
[12:39:44.323] iteration:26488  t-loss:0.1490, loss-lb:0.0774, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:39:44.517] iteration:26489  t-loss:0.1699, loss-lb:0.0674, loss-ulb:0.0513, weight:2.00, lr:0.0001
[12:39:44.710] iteration:26490  t-loss:0.1401, loss-lb:0.0690, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:39:44.901] iteration:26491  t-loss:0.1414, loss-lb:0.0755, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:39:45.094] iteration:26492  t-loss:0.1482, loss-lb:0.0714, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:39:45.287] iteration:26493  t-loss:0.1401, loss-lb:0.0649, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:39:45.479] iteration:26494  t-loss:0.1377, loss-lb:0.0680, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:39:45.671] iteration:26495  t-loss:0.1424, loss-lb:0.0745, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:39:45.864] iteration:26496  t-loss:0.1546, loss-lb:0.0709, loss-ulb:0.0418, weight:2.00, lr:0.0001
[12:39:46.056] iteration:26497  t-loss:0.1467, loss-lb:0.0772, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:39:46.248] iteration:26498  t-loss:0.1401, loss-lb:0.0713, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:39:46.441] iteration:26499  t-loss:0.1420, loss-lb:0.0658, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:39:46.633] iteration:26500  t-loss:0.1448, loss-lb:0.0764, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:39:46.826] iteration:26501  t-loss:0.1551, loss-lb:0.0672, loss-ulb:0.0440, weight:2.00, lr:0.0001
[12:39:47.018] iteration:26502  t-loss:0.1609, loss-lb:0.0762, loss-ulb:0.0424, weight:2.00, lr:0.0001
[12:39:47.211] iteration:26503  t-loss:0.1437, loss-lb:0.0747, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:39:47.403] iteration:26504  t-loss:0.1407, loss-lb:0.0708, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:39:47.596] iteration:26505  t-loss:0.1279, loss-lb:0.0685, loss-ulb:0.0297, weight:2.00, lr:0.0001
[12:39:47.789] iteration:26506  t-loss:0.1716, loss-lb:0.0656, loss-ulb:0.0530, weight:2.00, lr:0.0001
[12:39:47.981] iteration:26507  t-loss:0.1458, loss-lb:0.0629, loss-ulb:0.0415, weight:2.00, lr:0.0001
[12:39:48.174] iteration:26508  t-loss:0.1385, loss-lb:0.0671, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:39:48.366] iteration:26509  t-loss:0.1495, loss-lb:0.0762, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:39:48.559] iteration:26510  t-loss:0.1465, loss-lb:0.0675, loss-ulb:0.0395, weight:2.00, lr:0.0001
[12:39:48.751] iteration:26511  t-loss:0.2114, loss-lb:0.0782, loss-ulb:0.0666, weight:2.00, lr:0.0001
[12:39:48.943] iteration:26512  t-loss:0.1452, loss-lb:0.0810, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:39:49.135] iteration:26513  t-loss:0.1471, loss-lb:0.0725, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:39:49.328] iteration:26514  t-loss:0.1896, loss-lb:0.0702, loss-ulb:0.0597, weight:2.00, lr:0.0001
[12:39:49.521] iteration:26515  t-loss:0.1929, loss-lb:0.0795, loss-ulb:0.0567, weight:2.00, lr:0.0001
[12:39:49.714] iteration:26516  t-loss:0.1416, loss-lb:0.0693, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:39:49.906] iteration:26517  t-loss:0.1330, loss-lb:0.0706, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:39:50.098] iteration:26518  t-loss:0.1312, loss-lb:0.0660, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:39:50.291] iteration:26519  t-loss:0.1453, loss-lb:0.0688, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:39:50.483] iteration:26520  t-loss:0.1474, loss-lb:0.0680, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:39:50.677] iteration:26521  t-loss:0.2060, loss-lb:0.0673, loss-ulb:0.0694, weight:2.00, lr:0.0001
[12:39:50.870] iteration:26522  t-loss:0.1414, loss-lb:0.0702, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:39:51.063] iteration:26523  t-loss:0.1504, loss-lb:0.0731, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:39:51.256] iteration:26524  t-loss:0.1497, loss-lb:0.0790, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:39:51.449] iteration:26525  t-loss:0.1447, loss-lb:0.0736, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:39:51.640] iteration:26526  t-loss:0.1420, loss-lb:0.0727, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:39:51.833] iteration:26527  t-loss:0.1398, loss-lb:0.0723, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:39:52.025] iteration:26528  t-loss:0.1403, loss-lb:0.0730, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:39:52.217] iteration:26529  t-loss:0.1390, loss-lb:0.0713, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:39:52.409] iteration:26530  t-loss:0.1482, loss-lb:0.0902, loss-ulb:0.0290, weight:2.00, lr:0.0001
[12:39:52.603] iteration:26531  t-loss:0.1632, loss-lb:0.0738, loss-ulb:0.0447, weight:2.00, lr:0.0001
[12:39:52.795] iteration:26532  t-loss:0.1526, loss-lb:0.0730, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:39:52.987] iteration:26533  t-loss:0.1467, loss-lb:0.0717, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:39:53.180] iteration:26534  t-loss:0.2266, loss-lb:0.0723, loss-ulb:0.0772, weight:2.00, lr:0.0001
[12:39:53.374] iteration:26535  t-loss:0.1405, loss-lb:0.0704, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:39:53.567] iteration:26536  t-loss:0.1411, loss-lb:0.0680, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:39:53.759] iteration:26537  t-loss:0.1358, loss-lb:0.0686, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:39:53.952] iteration:26538  t-loss:0.1411, loss-lb:0.0655, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:39:54.144] iteration:26539  t-loss:0.1331, loss-lb:0.0756, loss-ulb:0.0288, weight:2.00, lr:0.0001
[12:39:54.351] iteration:26540  t-loss:0.1367, loss-lb:0.0725, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:39:54.550] iteration:26541  t-loss:0.1470, loss-lb:0.0705, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:39:54.743] iteration:26542  t-loss:0.1670, loss-lb:0.0719, loss-ulb:0.0476, weight:2.00, lr:0.0001
[12:39:54.936] iteration:26543  t-loss:0.1663, loss-lb:0.0706, loss-ulb:0.0479, weight:2.00, lr:0.0001
[12:39:55.127] iteration:26544  t-loss:0.1417, loss-lb:0.0672, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:39:55.320] iteration:26545  t-loss:0.1419, loss-lb:0.0746, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:39:55.512] iteration:26546  t-loss:0.1354, loss-lb:0.0613, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:39:55.704] iteration:26547  t-loss:0.1374, loss-lb:0.0710, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:39:55.896] iteration:26548  t-loss:0.1450, loss-lb:0.0697, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:39:56.089] iteration:26549  t-loss:0.1450, loss-lb:0.0800, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:39:56.282] iteration:26550  t-loss:0.1658, loss-lb:0.0701, loss-ulb:0.0479, weight:2.00, lr:0.0001
[12:39:56.474] iteration:26551  t-loss:0.1346, loss-lb:0.0657, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:39:56.665] iteration:26552  t-loss:0.1468, loss-lb:0.0690, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:39:56.856] iteration:26553  t-loss:0.1373, loss-lb:0.0718, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:39:57.046] iteration:26554  t-loss:0.1407, loss-lb:0.0718, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:39:57.237] iteration:26555  t-loss:0.1411, loss-lb:0.0679, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:39:57.429] iteration:26556  t-loss:0.1603, loss-lb:0.0932, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:39:57.620] iteration:26557  t-loss:0.1366, loss-lb:0.0678, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:39:57.812] iteration:26558  t-loss:0.2181, loss-lb:0.0721, loss-ulb:0.0730, weight:2.00, lr:0.0001
[12:40:09.701]  <<Test>> - Ep:270  - mean_dice/mean_h95 - S:89.99/1.29, Best-S:90.99, T:89.54/1.37, Best-T:90.48
[12:40:09.701]           - AvgLoss(lb/ulb/all):0.0717/0.0386/0.1489
[12:40:10.228] iteration:26559  t-loss:0.1315, loss-lb:0.0658, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:40:10.425] iteration:26560  t-loss:0.1438, loss-lb:0.0675, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:40:10.619] iteration:26561  t-loss:0.1317, loss-lb:0.0672, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:40:10.812] iteration:26562  t-loss:0.1445, loss-lb:0.0711, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:40:11.004] iteration:26563  t-loss:0.1514, loss-lb:0.0792, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:40:11.197] iteration:26564  t-loss:0.1380, loss-lb:0.0735, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:40:11.391] iteration:26565  t-loss:0.1457, loss-lb:0.0731, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:40:11.583] iteration:26566  t-loss:0.1439, loss-lb:0.0719, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:40:11.779] iteration:26567  t-loss:0.1372, loss-lb:0.0673, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:40:11.975] iteration:26568  t-loss:0.1411, loss-lb:0.0709, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:40:12.170] iteration:26569  t-loss:0.1411, loss-lb:0.0779, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:40:12.367] iteration:26570  t-loss:0.1496, loss-lb:0.0731, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:40:12.561] iteration:26571  t-loss:0.1419, loss-lb:0.0748, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:40:12.753] iteration:26572  t-loss:0.1577, loss-lb:0.0716, loss-ulb:0.0431, weight:2.00, lr:0.0001
[12:40:12.946] iteration:26573  t-loss:0.1517, loss-lb:0.0655, loss-ulb:0.0431, weight:2.00, lr:0.0001
[12:40:13.139] iteration:26574  t-loss:0.1414, loss-lb:0.0643, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:40:13.332] iteration:26575  t-loss:0.1578, loss-lb:0.0702, loss-ulb:0.0438, weight:2.00, lr:0.0001
[12:40:13.525] iteration:26576  t-loss:0.1368, loss-lb:0.0734, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:40:13.716] iteration:26577  t-loss:0.1452, loss-lb:0.0711, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:40:13.909] iteration:26578  t-loss:0.1633, loss-lb:0.0818, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:40:14.102] iteration:26579  t-loss:0.1399, loss-lb:0.0714, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:40:14.293] iteration:26580  t-loss:0.1570, loss-lb:0.0783, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:40:14.486] iteration:26581  t-loss:0.1661, loss-lb:0.0720, loss-ulb:0.0471, weight:2.00, lr:0.0001
[12:40:14.678] iteration:26582  t-loss:0.1434, loss-lb:0.0718, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:40:14.871] iteration:26583  t-loss:0.1524, loss-lb:0.0707, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:40:15.063] iteration:26584  t-loss:0.1499, loss-lb:0.0762, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:40:15.256] iteration:26585  t-loss:0.1462, loss-lb:0.0766, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:40:15.447] iteration:26586  t-loss:0.1385, loss-lb:0.0719, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:40:15.639] iteration:26587  t-loss:0.1402, loss-lb:0.0730, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:40:15.832] iteration:26588  t-loss:0.1660, loss-lb:0.0697, loss-ulb:0.0481, weight:2.00, lr:0.0001
[12:40:16.024] iteration:26589  t-loss:0.1386, loss-lb:0.0711, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:40:16.216] iteration:26590  t-loss:0.1418, loss-lb:0.0706, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:40:16.409] iteration:26591  t-loss:0.1397, loss-lb:0.0638, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:40:16.600] iteration:26592  t-loss:0.1334, loss-lb:0.0642, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:40:16.792] iteration:26593  t-loss:0.1320, loss-lb:0.0670, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:40:16.984] iteration:26594  t-loss:0.1442, loss-lb:0.0688, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:40:17.176] iteration:26595  t-loss:0.1366, loss-lb:0.0681, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:40:17.368] iteration:26596  t-loss:0.1373, loss-lb:0.0636, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:40:17.560] iteration:26597  t-loss:0.1841, loss-lb:0.0750, loss-ulb:0.0545, weight:2.00, lr:0.0001
[12:40:17.752] iteration:26598  t-loss:0.1455, loss-lb:0.0728, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:40:17.944] iteration:26599  t-loss:0.1536, loss-lb:0.0733, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:40:18.135] iteration:26600  t-loss:0.1714, loss-lb:0.0741, loss-ulb:0.0486, weight:2.00, lr:0.0001
[12:40:18.327] iteration:26601  t-loss:0.1527, loss-lb:0.0752, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:40:18.519] iteration:26602  t-loss:0.1990, loss-lb:0.0672, loss-ulb:0.0659, weight:2.00, lr:0.0001
[12:40:18.711] iteration:26603  t-loss:0.1452, loss-lb:0.0653, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:40:18.903] iteration:26604  t-loss:0.1581, loss-lb:0.0763, loss-ulb:0.0409, weight:2.00, lr:0.0001
[12:40:19.096] iteration:26605  t-loss:0.1642, loss-lb:0.0633, loss-ulb:0.0505, weight:2.00, lr:0.0001
[12:40:19.288] iteration:26606  t-loss:0.2658, loss-lb:0.0599, loss-ulb:0.1030, weight:2.00, lr:0.0001
[12:40:19.479] iteration:26607  t-loss:0.1483, loss-lb:0.0821, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:40:19.672] iteration:26608  t-loss:0.1388, loss-lb:0.0664, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:40:19.863] iteration:26609  t-loss:0.1388, loss-lb:0.0654, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:40:20.054] iteration:26610  t-loss:0.1490, loss-lb:0.0759, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:40:20.245] iteration:26611  t-loss:0.1522, loss-lb:0.0732, loss-ulb:0.0395, weight:2.00, lr:0.0001
[12:40:20.437] iteration:26612  t-loss:0.1346, loss-lb:0.0709, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:40:20.628] iteration:26613  t-loss:0.1393, loss-lb:0.0732, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:40:20.820] iteration:26614  t-loss:0.1489, loss-lb:0.0716, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:40:21.012] iteration:26615  t-loss:0.1384, loss-lb:0.0720, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:40:21.203] iteration:26616  t-loss:0.1457, loss-lb:0.0714, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:40:21.394] iteration:26617  t-loss:0.1323, loss-lb:0.0638, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:40:21.586] iteration:26618  t-loss:0.1482, loss-lb:0.0707, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:40:21.777] iteration:26619  t-loss:0.1291, loss-lb:0.0669, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:40:21.969] iteration:26620  t-loss:0.1427, loss-lb:0.0750, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:40:22.160] iteration:26621  t-loss:0.1404, loss-lb:0.0707, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:40:22.353] iteration:26622  t-loss:0.1367, loss-lb:0.0681, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:40:22.545] iteration:26623  t-loss:0.1442, loss-lb:0.0723, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:40:22.741] iteration:26624  t-loss:0.1394, loss-lb:0.0698, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:40:22.938] iteration:26625  t-loss:0.1371, loss-lb:0.0741, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:40:23.131] iteration:26626  t-loss:0.1512, loss-lb:0.0671, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:40:23.324] iteration:26627  t-loss:0.1316, loss-lb:0.0690, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:40:23.516] iteration:26628  t-loss:0.1443, loss-lb:0.0766, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:40:23.708] iteration:26629  t-loss:0.1388, loss-lb:0.0745, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:40:23.901] iteration:26630  t-loss:0.1484, loss-lb:0.0738, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:40:24.093] iteration:26631  t-loss:0.1339, loss-lb:0.0724, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:40:24.285] iteration:26632  t-loss:0.1456, loss-lb:0.0729, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:40:24.478] iteration:26633  t-loss:0.1546, loss-lb:0.0666, loss-ulb:0.0440, weight:2.00, lr:0.0001
[12:40:24.669] iteration:26634  t-loss:0.1442, loss-lb:0.0713, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:40:24.861] iteration:26635  t-loss:0.1461, loss-lb:0.0736, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:40:25.053] iteration:26636  t-loss:0.1723, loss-lb:0.0668, loss-ulb:0.0527, weight:2.00, lr:0.0001
[12:40:25.245] iteration:26637  t-loss:0.1268, loss-lb:0.0658, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:40:25.437] iteration:26638  t-loss:0.1403, loss-lb:0.0673, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:40:25.630] iteration:26639  t-loss:0.1558, loss-lb:0.0804, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:40:25.823] iteration:26640  t-loss:0.1385, loss-lb:0.0745, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:40:26.014] iteration:26641  t-loss:0.1380, loss-lb:0.0706, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:40:26.206] iteration:26642  t-loss:0.1464, loss-lb:0.0700, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:40:26.398] iteration:26643  t-loss:0.2428, loss-lb:0.0716, loss-ulb:0.0856, weight:2.00, lr:0.0001
[12:40:26.589] iteration:26644  t-loss:0.1663, loss-lb:0.0659, loss-ulb:0.0502, weight:2.00, lr:0.0001
[12:40:26.781] iteration:26645  t-loss:0.1402, loss-lb:0.0687, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:40:26.973] iteration:26646  t-loss:0.1617, loss-lb:0.0668, loss-ulb:0.0475, weight:2.00, lr:0.0001
[12:40:27.178] iteration:26647  t-loss:0.1441, loss-lb:0.0707, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:40:27.376] iteration:26648  t-loss:0.1307, loss-lb:0.0629, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:40:27.568] iteration:26649  t-loss:0.1450, loss-lb:0.0824, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:40:27.759] iteration:26650  t-loss:0.1452, loss-lb:0.0841, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:40:27.950] iteration:26651  t-loss:0.1441, loss-lb:0.0729, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:40:28.141] iteration:26652  t-loss:0.1590, loss-lb:0.0700, loss-ulb:0.0445, weight:2.00, lr:0.0001
[12:40:28.333] iteration:26653  t-loss:0.1861, loss-lb:0.0639, loss-ulb:0.0611, weight:2.00, lr:0.0001
[12:40:28.523] iteration:26654  t-loss:0.1382, loss-lb:0.0681, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:40:28.715] iteration:26655  t-loss:0.1385, loss-lb:0.0599, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:40:28.905] iteration:26656  t-loss:0.1365, loss-lb:0.0676, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:40:29.500] iteration:26657  t-loss:0.1553, loss-lb:0.0742, loss-ulb:0.0405, weight:2.00, lr:0.0001
[12:40:29.695] iteration:26658  t-loss:0.1558, loss-lb:0.0698, loss-ulb:0.0430, weight:2.00, lr:0.0001
[12:40:29.887] iteration:26659  t-loss:0.1418, loss-lb:0.0698, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:40:30.079] iteration:26660  t-loss:0.1379, loss-lb:0.0688, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:40:30.272] iteration:26661  t-loss:0.1489, loss-lb:0.0778, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:40:30.465] iteration:26662  t-loss:0.1560, loss-lb:0.0853, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:40:30.657] iteration:26663  t-loss:0.1454, loss-lb:0.0718, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:40:30.848] iteration:26664  t-loss:0.1550, loss-lb:0.0733, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:40:31.040] iteration:26665  t-loss:0.1480, loss-lb:0.0712, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:40:31.231] iteration:26666  t-loss:0.1436, loss-lb:0.0756, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:40:31.423] iteration:26667  t-loss:0.1395, loss-lb:0.0659, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:40:31.615] iteration:26668  t-loss:0.1415, loss-lb:0.0745, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:40:31.806] iteration:26669  t-loss:0.1816, loss-lb:0.0723, loss-ulb:0.0547, weight:2.00, lr:0.0001
[12:40:31.997] iteration:26670  t-loss:0.1862, loss-lb:0.0707, loss-ulb:0.0578, weight:2.00, lr:0.0001
[12:40:32.189] iteration:26671  t-loss:0.1386, loss-lb:0.0705, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:40:32.381] iteration:26672  t-loss:0.1361, loss-lb:0.0730, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:40:32.573] iteration:26673  t-loss:0.1432, loss-lb:0.0760, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:40:32.764] iteration:26674  t-loss:0.1450, loss-lb:0.0729, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:40:32.956] iteration:26675  t-loss:0.1374, loss-lb:0.0716, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:40:33.148] iteration:26676  t-loss:0.1545, loss-lb:0.0718, loss-ulb:0.0413, weight:2.00, lr:0.0001
[12:40:33.340] iteration:26677  t-loss:0.1496, loss-lb:0.0673, loss-ulb:0.0412, weight:2.00, lr:0.0001
[12:40:33.533] iteration:26678  t-loss:0.1460, loss-lb:0.0705, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:40:33.728] iteration:26679  t-loss:0.1396, loss-lb:0.0670, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:40:33.925] iteration:26680  t-loss:0.1387, loss-lb:0.0687, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:40:34.120] iteration:26681  t-loss:0.1447, loss-lb:0.0708, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:40:34.313] iteration:26682  t-loss:0.1541, loss-lb:0.0787, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:40:34.505] iteration:26683  t-loss:0.1475, loss-lb:0.0753, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:40:34.699] iteration:26684  t-loss:0.1443, loss-lb:0.0718, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:40:34.891] iteration:26685  t-loss:0.1410, loss-lb:0.0649, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:40:35.082] iteration:26686  t-loss:0.1443, loss-lb:0.0732, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:40:35.274] iteration:26687  t-loss:0.1509, loss-lb:0.0708, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:40:35.467] iteration:26688  t-loss:0.1514, loss-lb:0.0734, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:40:35.658] iteration:26689  t-loss:0.1309, loss-lb:0.0683, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:40:35.851] iteration:26690  t-loss:0.1528, loss-lb:0.0696, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:40:36.045] iteration:26691  t-loss:0.1487, loss-lb:0.0708, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:40:36.237] iteration:26692  t-loss:0.1381, loss-lb:0.0685, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:40:36.429] iteration:26693  t-loss:0.1464, loss-lb:0.0723, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:40:36.621] iteration:26694  t-loss:0.1522, loss-lb:0.0739, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:40:36.815] iteration:26695  t-loss:0.1801, loss-lb:0.0733, loss-ulb:0.0534, weight:2.00, lr:0.0001
[12:40:37.007] iteration:26696  t-loss:0.1323, loss-lb:0.0667, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:40:37.199] iteration:26697  t-loss:0.1404, loss-lb:0.0704, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:40:37.391] iteration:26698  t-loss:0.1591, loss-lb:0.0778, loss-ulb:0.0406, weight:2.00, lr:0.0001
[12:40:37.582] iteration:26699  t-loss:0.1685, loss-lb:0.0819, loss-ulb:0.0433, weight:2.00, lr:0.0001
[12:40:37.774] iteration:26700  t-loss:0.1322, loss-lb:0.0641, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:40:37.966] iteration:26701  t-loss:0.1439, loss-lb:0.0623, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:40:38.161] iteration:26702  t-loss:0.1380, loss-lb:0.0664, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:40:38.353] iteration:26703  t-loss:0.1511, loss-lb:0.0670, loss-ulb:0.0421, weight:2.00, lr:0.0001
[12:40:38.546] iteration:26704  t-loss:0.1416, loss-lb:0.0738, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:40:38.738] iteration:26705  t-loss:0.1369, loss-lb:0.0708, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:40:38.929] iteration:26706  t-loss:0.1304, loss-lb:0.0669, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:40:39.123] iteration:26707  t-loss:0.1321, loss-lb:0.0700, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:40:39.315] iteration:26708  t-loss:0.1397, loss-lb:0.0712, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:40:39.507] iteration:26709  t-loss:0.1409, loss-lb:0.0778, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:40:39.700] iteration:26710  t-loss:0.1418, loss-lb:0.0669, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:40:39.892] iteration:26711  t-loss:0.1351, loss-lb:0.0686, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:40:40.084] iteration:26712  t-loss:0.1486, loss-lb:0.0710, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:40:40.277] iteration:26713  t-loss:0.1452, loss-lb:0.0747, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:40:40.468] iteration:26714  t-loss:0.1416, loss-lb:0.0670, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:40:40.661] iteration:26715  t-loss:0.1338, loss-lb:0.0677, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:40:40.853] iteration:26716  t-loss:0.1404, loss-lb:0.0692, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:40:41.044] iteration:26717  t-loss:0.1336, loss-lb:0.0645, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:40:41.236] iteration:26718  t-loss:0.1330, loss-lb:0.0686, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:40:41.428] iteration:26719  t-loss:0.1337, loss-lb:0.0725, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:40:41.621] iteration:26720  t-loss:0.1689, loss-lb:0.0758, loss-ulb:0.0465, weight:2.00, lr:0.0001
[12:40:41.813] iteration:26721  t-loss:0.1416, loss-lb:0.0778, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:40:42.004] iteration:26722  t-loss:0.1402, loss-lb:0.0670, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:40:42.195] iteration:26723  t-loss:0.1357, loss-lb:0.0716, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:40:42.387] iteration:26724  t-loss:0.1562, loss-lb:0.0686, loss-ulb:0.0438, weight:2.00, lr:0.0001
[12:40:42.578] iteration:26725  t-loss:0.1410, loss-lb:0.0762, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:40:42.770] iteration:26726  t-loss:0.1340, loss-lb:0.0729, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:40:42.961] iteration:26727  t-loss:0.1407, loss-lb:0.0678, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:40:43.152] iteration:26728  t-loss:0.1487, loss-lb:0.0750, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:40:43.345] iteration:26729  t-loss:0.1407, loss-lb:0.0715, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:40:43.538] iteration:26730  t-loss:0.1412, loss-lb:0.0720, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:40:43.735] iteration:26731  t-loss:0.1987, loss-lb:0.0660, loss-ulb:0.0663, weight:2.00, lr:0.0001
[12:40:43.927] iteration:26732  t-loss:0.1471, loss-lb:0.0683, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:40:44.118] iteration:26733  t-loss:0.1282, loss-lb:0.0604, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:40:44.310] iteration:26734  t-loss:0.1497, loss-lb:0.0734, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:40:44.503] iteration:26735  t-loss:0.1572, loss-lb:0.0697, loss-ulb:0.0438, weight:2.00, lr:0.0001
[12:40:44.696] iteration:26736  t-loss:0.1652, loss-lb:0.0766, loss-ulb:0.0443, weight:2.00, lr:0.0001
[12:40:44.893] iteration:26737  t-loss:0.1501, loss-lb:0.0762, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:40:45.087] iteration:26738  t-loss:0.1452, loss-lb:0.0756, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:40:45.279] iteration:26739  t-loss:0.1290, loss-lb:0.0658, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:40:45.470] iteration:26740  t-loss:0.1367, loss-lb:0.0673, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:40:45.662] iteration:26741  t-loss:0.1286, loss-lb:0.0660, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:40:45.854] iteration:26742  t-loss:0.1330, loss-lb:0.0665, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:40:46.046] iteration:26743  t-loss:0.1373, loss-lb:0.0766, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:40:46.238] iteration:26744  t-loss:0.1274, loss-lb:0.0647, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:40:46.430] iteration:26745  t-loss:0.1458, loss-lb:0.0704, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:40:46.621] iteration:26746  t-loss:0.1392, loss-lb:0.0676, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:40:46.813] iteration:26747  t-loss:0.1452, loss-lb:0.0675, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:40:47.004] iteration:26748  t-loss:0.1378, loss-lb:0.0754, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:40:47.195] iteration:26749  t-loss:0.1354, loss-lb:0.0732, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:40:47.387] iteration:26750  t-loss:0.1592, loss-lb:0.0730, loss-ulb:0.0431, weight:2.00, lr:0.0001
[12:40:47.578] iteration:26751  t-loss:0.1510, loss-lb:0.0719, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:40:47.768] iteration:26752  t-loss:0.1823, loss-lb:0.0897, loss-ulb:0.0463, weight:2.00, lr:0.0001
[12:40:47.960] iteration:26753  t-loss:0.1508, loss-lb:0.0693, loss-ulb:0.0407, weight:2.00, lr:0.0001
[12:40:48.150] iteration:26754  t-loss:0.1386, loss-lb:0.0687, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:41:00.873]  <<Test>> - Ep:272  - mean_dice/mean_h95 - S:89.50/1.41, Best-S:90.99, T:89.47/1.41, Best-T:90.48
[12:41:00.874]           - AvgLoss(lb/ulb/all):0.0712/0.0366/0.1448
[12:41:01.405] iteration:26755  t-loss:0.1350, loss-lb:0.0674, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:41:01.602] iteration:26756  t-loss:0.1429, loss-lb:0.0729, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:41:01.794] iteration:26757  t-loss:0.1283, loss-lb:0.0655, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:41:01.988] iteration:26758  t-loss:0.1712, loss-lb:0.0717, loss-ulb:0.0497, weight:2.00, lr:0.0001
[12:41:02.182] iteration:26759  t-loss:0.1540, loss-lb:0.0734, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:41:02.376] iteration:26760  t-loss:0.1525, loss-lb:0.0657, loss-ulb:0.0434, weight:2.00, lr:0.0001
[12:41:02.568] iteration:26761  t-loss:0.1404, loss-lb:0.0753, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:41:02.763] iteration:26762  t-loss:0.1466, loss-lb:0.0738, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:41:02.955] iteration:26763  t-loss:0.1474, loss-lb:0.0672, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:41:03.149] iteration:26764  t-loss:0.1410, loss-lb:0.0713, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:41:03.343] iteration:26765  t-loss:0.1348, loss-lb:0.0729, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:41:03.535] iteration:26766  t-loss:0.1241, loss-lb:0.0688, loss-ulb:0.0277, weight:2.00, lr:0.0001
[12:41:03.729] iteration:26767  t-loss:0.1490, loss-lb:0.0718, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:41:03.922] iteration:26768  t-loss:0.1513, loss-lb:0.0726, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:41:04.115] iteration:26769  t-loss:0.1408, loss-lb:0.0639, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:41:04.308] iteration:26770  t-loss:0.1392, loss-lb:0.0690, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:41:04.502] iteration:26771  t-loss:0.1537, loss-lb:0.0731, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:41:04.695] iteration:26772  t-loss:0.1470, loss-lb:0.0741, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:41:04.887] iteration:26773  t-loss:0.1346, loss-lb:0.0739, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:41:05.080] iteration:26774  t-loss:0.1334, loss-lb:0.0684, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:41:05.273] iteration:26775  t-loss:0.1554, loss-lb:0.0737, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:41:05.465] iteration:26776  t-loss:0.1507, loss-lb:0.0793, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:41:05.657] iteration:26777  t-loss:0.1391, loss-lb:0.0718, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:41:05.850] iteration:26778  t-loss:0.1376, loss-lb:0.0701, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:41:06.043] iteration:26779  t-loss:0.1395, loss-lb:0.0717, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:41:06.238] iteration:26780  t-loss:0.2108, loss-lb:0.0730, loss-ulb:0.0689, weight:2.00, lr:0.0001
[12:41:06.430] iteration:26781  t-loss:0.1427, loss-lb:0.0700, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:41:06.621] iteration:26782  t-loss:0.1346, loss-lb:0.0671, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:41:06.814] iteration:26783  t-loss:0.1448, loss-lb:0.0674, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:41:07.007] iteration:26784  t-loss:0.1430, loss-lb:0.0728, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:41:07.198] iteration:26785  t-loss:0.1514, loss-lb:0.0675, loss-ulb:0.0419, weight:2.00, lr:0.0001
[12:41:07.391] iteration:26786  t-loss:0.1562, loss-lb:0.0702, loss-ulb:0.0430, weight:2.00, lr:0.0001
[12:41:07.584] iteration:26787  t-loss:0.1465, loss-lb:0.0707, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:41:07.777] iteration:26788  t-loss:0.1340, loss-lb:0.0717, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:41:07.969] iteration:26789  t-loss:0.1362, loss-lb:0.0702, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:41:08.162] iteration:26790  t-loss:0.1718, loss-lb:0.0754, loss-ulb:0.0482, weight:2.00, lr:0.0001
[12:41:08.354] iteration:26791  t-loss:0.1579, loss-lb:0.0754, loss-ulb:0.0412, weight:2.00, lr:0.0001
[12:41:08.547] iteration:26792  t-loss:0.1370, loss-lb:0.0645, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:41:08.741] iteration:26793  t-loss:0.1539, loss-lb:0.0724, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:41:08.933] iteration:26794  t-loss:0.1320, loss-lb:0.0705, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:41:09.127] iteration:26795  t-loss:0.1384, loss-lb:0.0724, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:41:09.319] iteration:26796  t-loss:0.1397, loss-lb:0.0670, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:41:09.511] iteration:26797  t-loss:0.1494, loss-lb:0.0726, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:41:09.704] iteration:26798  t-loss:0.1404, loss-lb:0.0682, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:41:09.897] iteration:26799  t-loss:0.1370, loss-lb:0.0711, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:41:10.089] iteration:26800  t-loss:0.1356, loss-lb:0.0692, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:41:10.282] iteration:26801  t-loss:0.1478, loss-lb:0.0672, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:41:10.474] iteration:26802  t-loss:0.1435, loss-lb:0.0683, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:41:10.667] iteration:26803  t-loss:0.1653, loss-lb:0.0691, loss-ulb:0.0481, weight:2.00, lr:0.0001
[12:41:10.859] iteration:26804  t-loss:0.1400, loss-lb:0.0667, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:41:11.051] iteration:26805  t-loss:0.1378, loss-lb:0.0656, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:41:11.244] iteration:26806  t-loss:0.1428, loss-lb:0.0811, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:41:11.436] iteration:26807  t-loss:0.1399, loss-lb:0.0764, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:41:11.628] iteration:26808  t-loss:0.1332, loss-lb:0.0632, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:41:11.821] iteration:26809  t-loss:0.1397, loss-lb:0.0674, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:41:12.014] iteration:26810  t-loss:0.1472, loss-lb:0.0766, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:41:12.207] iteration:26811  t-loss:0.1648, loss-lb:0.0814, loss-ulb:0.0417, weight:2.00, lr:0.0001
[12:41:12.399] iteration:26812  t-loss:0.1478, loss-lb:0.0699, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:41:12.591] iteration:26813  t-loss:0.1340, loss-lb:0.0674, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:41:12.782] iteration:26814  t-loss:0.1346, loss-lb:0.0693, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:41:12.974] iteration:26815  t-loss:0.1447, loss-lb:0.0705, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:41:13.168] iteration:26816  t-loss:0.1407, loss-lb:0.0690, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:41:13.360] iteration:26817  t-loss:0.1267, loss-lb:0.0654, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:41:13.553] iteration:26818  t-loss:0.1623, loss-lb:0.0749, loss-ulb:0.0437, weight:2.00, lr:0.0001
[12:41:13.746] iteration:26819  t-loss:0.1564, loss-lb:0.0898, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:41:13.938] iteration:26820  t-loss:0.1358, loss-lb:0.0701, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:41:14.131] iteration:26821  t-loss:0.1397, loss-lb:0.0691, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:41:14.324] iteration:26822  t-loss:0.1285, loss-lb:0.0680, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:41:14.515] iteration:26823  t-loss:0.1422, loss-lb:0.0710, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:41:14.708] iteration:26824  t-loss:0.1342, loss-lb:0.0678, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:41:14.901] iteration:26825  t-loss:0.1785, loss-lb:0.0773, loss-ulb:0.0506, weight:2.00, lr:0.0001
[12:41:15.093] iteration:26826  t-loss:0.1299, loss-lb:0.0698, loss-ulb:0.0301, weight:2.00, lr:0.0001
[12:41:15.285] iteration:26827  t-loss:0.1405, loss-lb:0.0688, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:41:15.478] iteration:26828  t-loss:0.1282, loss-lb:0.0708, loss-ulb:0.0287, weight:2.00, lr:0.0001
[12:41:15.669] iteration:26829  t-loss:0.1467, loss-lb:0.0717, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:41:15.862] iteration:26830  t-loss:0.1439, loss-lb:0.0682, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:41:16.055] iteration:26831  t-loss:0.1355, loss-lb:0.0688, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:41:16.246] iteration:26832  t-loss:0.1444, loss-lb:0.0670, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:41:16.440] iteration:26833  t-loss:0.1343, loss-lb:0.0669, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:41:16.632] iteration:26834  t-loss:0.1339, loss-lb:0.0662, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:41:16.824] iteration:26835  t-loss:0.1319, loss-lb:0.0706, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:41:17.016] iteration:26836  t-loss:0.1395, loss-lb:0.0684, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:41:17.208] iteration:26837  t-loss:0.1361, loss-lb:0.0650, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:41:17.401] iteration:26838  t-loss:0.1715, loss-lb:0.0682, loss-ulb:0.0516, weight:2.00, lr:0.0001
[12:41:17.593] iteration:26839  t-loss:0.1315, loss-lb:0.0696, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:41:17.787] iteration:26840  t-loss:0.1233, loss-lb:0.0638, loss-ulb:0.0298, weight:2.00, lr:0.0001
[12:41:17.981] iteration:26841  t-loss:0.1351, loss-lb:0.0696, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:41:18.174] iteration:26842  t-loss:0.1511, loss-lb:0.0764, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:41:18.367] iteration:26843  t-loss:0.1563, loss-lb:0.0718, loss-ulb:0.0422, weight:2.00, lr:0.0001
[12:41:18.559] iteration:26844  t-loss:0.1522, loss-lb:0.0763, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:41:18.751] iteration:26845  t-loss:0.1385, loss-lb:0.0750, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:41:18.942] iteration:26846  t-loss:0.1449, loss-lb:0.0655, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:41:19.132] iteration:26847  t-loss:0.1480, loss-lb:0.0636, loss-ulb:0.0422, weight:2.00, lr:0.0001
[12:41:19.323] iteration:26848  t-loss:0.1541, loss-lb:0.0760, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:41:19.513] iteration:26849  t-loss:0.1293, loss-lb:0.0654, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:41:19.705] iteration:26850  t-loss:0.1361, loss-lb:0.0702, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:41:19.896] iteration:26851  t-loss:0.1471, loss-lb:0.0658, loss-ulb:0.0407, weight:2.00, lr:0.0001
[12:41:20.086] iteration:26852  t-loss:0.1388, loss-lb:0.0705, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:41:20.645] iteration:26853  t-loss:0.1458, loss-lb:0.0729, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:41:20.841] iteration:26854  t-loss:0.1472, loss-lb:0.0769, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:41:21.034] iteration:26855  t-loss:0.1442, loss-lb:0.0679, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:41:21.226] iteration:26856  t-loss:0.1572, loss-lb:0.0748, loss-ulb:0.0412, weight:2.00, lr:0.0001
[12:41:21.418] iteration:26857  t-loss:0.1538, loss-lb:0.0739, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:41:21.610] iteration:26858  t-loss:0.1311, loss-lb:0.0681, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:41:21.803] iteration:26859  t-loss:0.1437, loss-lb:0.0698, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:41:21.997] iteration:26860  t-loss:0.1395, loss-lb:0.0725, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:41:22.188] iteration:26861  t-loss:0.1288, loss-lb:0.0647, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:41:22.381] iteration:26862  t-loss:0.1586, loss-lb:0.0634, loss-ulb:0.0476, weight:2.00, lr:0.0001
[12:41:22.574] iteration:26863  t-loss:0.1436, loss-lb:0.0662, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:41:22.765] iteration:26864  t-loss:0.1340, loss-lb:0.0713, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:41:22.958] iteration:26865  t-loss:0.1616, loss-lb:0.0846, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:41:23.150] iteration:26866  t-loss:0.1658, loss-lb:0.0599, loss-ulb:0.0529, weight:2.00, lr:0.0001
[12:41:23.343] iteration:26867  t-loss:0.1562, loss-lb:0.0688, loss-ulb:0.0437, weight:2.00, lr:0.0001
[12:41:23.535] iteration:26868  t-loss:0.1377, loss-lb:0.0685, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:41:23.727] iteration:26869  t-loss:0.1415, loss-lb:0.0676, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:41:23.921] iteration:26870  t-loss:0.1598, loss-lb:0.0764, loss-ulb:0.0417, weight:2.00, lr:0.0001
[12:41:24.114] iteration:26871  t-loss:0.1396, loss-lb:0.0679, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:41:24.307] iteration:26872  t-loss:0.1579, loss-lb:0.0724, loss-ulb:0.0428, weight:2.00, lr:0.0001
[12:41:24.500] iteration:26873  t-loss:0.1495, loss-lb:0.0711, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:41:24.692] iteration:26874  t-loss:0.1494, loss-lb:0.0743, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:41:24.885] iteration:26875  t-loss:0.1425, loss-lb:0.0741, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:41:25.077] iteration:26876  t-loss:0.1322, loss-lb:0.0694, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:41:25.272] iteration:26877  t-loss:0.1368, loss-lb:0.0679, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:41:25.472] iteration:26878  t-loss:0.1517, loss-lb:0.0752, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:41:25.665] iteration:26879  t-loss:0.1546, loss-lb:0.0705, loss-ulb:0.0421, weight:2.00, lr:0.0001
[12:41:25.857] iteration:26880  t-loss:0.1678, loss-lb:0.0769, loss-ulb:0.0455, weight:2.00, lr:0.0001
[12:41:26.049] iteration:26881  t-loss:0.1439, loss-lb:0.0687, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:41:26.249] iteration:26882  t-loss:0.1476, loss-lb:0.0711, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:41:26.441] iteration:26883  t-loss:0.1384, loss-lb:0.0654, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:41:26.633] iteration:26884  t-loss:0.1257, loss-lb:0.0669, loss-ulb:0.0294, weight:2.00, lr:0.0001
[12:41:26.826] iteration:26885  t-loss:0.1532, loss-lb:0.0666, loss-ulb:0.0433, weight:2.00, lr:0.0001
[12:41:27.026] iteration:26886  t-loss:0.1330, loss-lb:0.0677, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:41:27.219] iteration:26887  t-loss:0.1318, loss-lb:0.0679, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:41:27.413] iteration:26888  t-loss:0.1918, loss-lb:0.0776, loss-ulb:0.0571, weight:2.00, lr:0.0001
[12:41:27.606] iteration:26889  t-loss:0.1751, loss-lb:0.0698, loss-ulb:0.0527, weight:2.00, lr:0.0001
[12:41:27.799] iteration:26890  t-loss:0.1526, loss-lb:0.0853, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:41:27.992] iteration:26891  t-loss:0.1486, loss-lb:0.0802, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:41:28.184] iteration:26892  t-loss:0.1473, loss-lb:0.0710, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:41:28.377] iteration:26893  t-loss:0.1319, loss-lb:0.0698, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:41:28.570] iteration:26894  t-loss:0.1291, loss-lb:0.0693, loss-ulb:0.0299, weight:2.00, lr:0.0001
[12:41:28.764] iteration:26895  t-loss:0.1360, loss-lb:0.0632, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:41:28.955] iteration:26896  t-loss:0.1330, loss-lb:0.0671, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:41:29.148] iteration:26897  t-loss:0.1348, loss-lb:0.0679, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:41:29.341] iteration:26898  t-loss:0.1432, loss-lb:0.0653, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:41:29.533] iteration:26899  t-loss:0.1462, loss-lb:0.0743, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:41:29.725] iteration:26900  t-loss:0.1422, loss-lb:0.0716, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:41:29.918] iteration:26901  t-loss:0.1419, loss-lb:0.0680, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:41:30.111] iteration:26902  t-loss:0.1361, loss-lb:0.0654, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:41:30.302] iteration:26903  t-loss:0.1393, loss-lb:0.0713, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:41:30.495] iteration:26904  t-loss:0.1782, loss-lb:0.0670, loss-ulb:0.0556, weight:2.00, lr:0.0001
[12:41:30.688] iteration:26905  t-loss:0.1449, loss-lb:0.0757, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:41:30.881] iteration:26906  t-loss:0.1333, loss-lb:0.0718, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:41:31.073] iteration:26907  t-loss:0.1345, loss-lb:0.0658, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:41:31.266] iteration:26908  t-loss:0.1490, loss-lb:0.0804, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:41:31.459] iteration:26909  t-loss:0.1599, loss-lb:0.0705, loss-ulb:0.0447, weight:2.00, lr:0.0001
[12:41:31.653] iteration:26910  t-loss:0.1424, loss-lb:0.0675, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:41:31.845] iteration:26911  t-loss:0.1455, loss-lb:0.0770, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:41:32.038] iteration:26912  t-loss:0.1309, loss-lb:0.0664, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:41:32.230] iteration:26913  t-loss:0.1401, loss-lb:0.0664, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:41:32.424] iteration:26914  t-loss:0.1321, loss-lb:0.0682, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:41:32.629] iteration:26915  t-loss:0.1406, loss-lb:0.0750, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:41:32.829] iteration:26916  t-loss:0.1426, loss-lb:0.0687, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:41:33.026] iteration:26917  t-loss:0.1535, loss-lb:0.0635, loss-ulb:0.0450, weight:2.00, lr:0.0001
[12:41:33.218] iteration:26918  t-loss:0.1456, loss-lb:0.0744, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:41:33.412] iteration:26919  t-loss:0.1764, loss-lb:0.0788, loss-ulb:0.0488, weight:2.00, lr:0.0001
[12:41:33.603] iteration:26920  t-loss:0.1312, loss-lb:0.0686, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:41:33.798] iteration:26921  t-loss:0.1401, loss-lb:0.0691, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:41:33.991] iteration:26922  t-loss:0.1289, loss-lb:0.0669, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:41:34.183] iteration:26923  t-loss:0.1414, loss-lb:0.0701, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:41:34.375] iteration:26924  t-loss:0.1406, loss-lb:0.0708, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:41:34.569] iteration:26925  t-loss:0.1550, loss-lb:0.0698, loss-ulb:0.0426, weight:2.00, lr:0.0001
[12:41:34.761] iteration:26926  t-loss:0.1384, loss-lb:0.0656, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:41:34.955] iteration:26927  t-loss:0.1405, loss-lb:0.0705, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:41:35.146] iteration:26928  t-loss:0.1600, loss-lb:0.0820, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:41:35.339] iteration:26929  t-loss:0.1397, loss-lb:0.0685, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:41:35.533] iteration:26930  t-loss:0.1533, loss-lb:0.0673, loss-ulb:0.0430, weight:2.00, lr:0.0001
[12:41:35.725] iteration:26931  t-loss:0.1385, loss-lb:0.0700, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:41:35.918] iteration:26932  t-loss:0.1321, loss-lb:0.0660, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:41:36.111] iteration:26933  t-loss:0.1367, loss-lb:0.0689, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:41:36.304] iteration:26934  t-loss:0.1535, loss-lb:0.0810, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:41:36.496] iteration:26935  t-loss:0.1363, loss-lb:0.0693, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:41:36.688] iteration:26936  t-loss:0.1510, loss-lb:0.0670, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:41:36.882] iteration:26937  t-loss:0.1344, loss-lb:0.0675, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:41:37.074] iteration:26938  t-loss:0.1276, loss-lb:0.0646, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:41:37.268] iteration:26939  t-loss:0.1477, loss-lb:0.0644, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:41:37.460] iteration:26940  t-loss:0.1511, loss-lb:0.0743, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:41:37.653] iteration:26941  t-loss:0.1285, loss-lb:0.0636, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:41:37.846] iteration:26942  t-loss:0.1420, loss-lb:0.0739, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:41:38.037] iteration:26943  t-loss:0.1505, loss-lb:0.0746, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:41:38.229] iteration:26944  t-loss:0.1489, loss-lb:0.0743, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:41:38.420] iteration:26945  t-loss:0.1400, loss-lb:0.0659, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:41:38.612] iteration:26946  t-loss:0.1514, loss-lb:0.0689, loss-ulb:0.0413, weight:2.00, lr:0.0001
[12:41:38.804] iteration:26947  t-loss:0.1543, loss-lb:0.0656, loss-ulb:0.0444, weight:2.00, lr:0.0001
[12:41:38.996] iteration:26948  t-loss:0.1386, loss-lb:0.0688, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:41:39.187] iteration:26949  t-loss:0.1603, loss-lb:0.0672, loss-ulb:0.0466, weight:2.00, lr:0.0001
[12:41:39.378] iteration:26950  t-loss:0.1383, loss-lb:0.0632, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:41:51.492]  <<Test>> - Ep:274  - mean_dice/mean_h95 - S:89.68/1.36, Best-S:90.99, T:89.62/1.37, Best-T:90.48
[12:41:51.493]           - AvgLoss(lb/ulb/all):0.0702/0.0371/0.1431
[12:41:52.015] iteration:26951  t-loss:0.1432, loss-lb:0.0687, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:41:52.213] iteration:26952  t-loss:0.1427, loss-lb:0.0702, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:41:52.405] iteration:26953  t-loss:0.1356, loss-lb:0.0677, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:41:52.597] iteration:26954  t-loss:0.1407, loss-lb:0.0685, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:41:52.790] iteration:26955  t-loss:0.1508, loss-lb:0.0690, loss-ulb:0.0409, weight:2.00, lr:0.0001
[12:41:52.983] iteration:26956  t-loss:0.1428, loss-lb:0.0750, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:41:53.174] iteration:26957  t-loss:0.1480, loss-lb:0.0729, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:41:53.366] iteration:26958  t-loss:0.1404, loss-lb:0.0744, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:41:53.560] iteration:26959  t-loss:0.1421, loss-lb:0.0676, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:41:53.753] iteration:26960  t-loss:0.1504, loss-lb:0.0758, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:41:53.943] iteration:26961  t-loss:0.1379, loss-lb:0.0713, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:41:54.135] iteration:26962  t-loss:0.1242, loss-lb:0.0619, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:41:54.327] iteration:26963  t-loss:0.1376, loss-lb:0.0707, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:41:54.518] iteration:26964  t-loss:0.1516, loss-lb:0.0763, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:41:54.710] iteration:26965  t-loss:0.1372, loss-lb:0.0681, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:41:54.901] iteration:26966  t-loss:0.1467, loss-lb:0.0658, loss-ulb:0.0404, weight:2.00, lr:0.0001
[12:41:55.094] iteration:26967  t-loss:0.1526, loss-lb:0.0832, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:41:55.285] iteration:26968  t-loss:0.1483, loss-lb:0.0721, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:41:55.474] iteration:26969  t-loss:0.1709, loss-lb:0.0723, loss-ulb:0.0493, weight:2.00, lr:0.0001
[12:41:55.666] iteration:26970  t-loss:0.1455, loss-lb:0.0674, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:41:55.857] iteration:26971  t-loss:0.1402, loss-lb:0.0666, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:41:56.050] iteration:26972  t-loss:0.1475, loss-lb:0.0737, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:41:56.240] iteration:26973  t-loss:0.1469, loss-lb:0.0840, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:41:56.435] iteration:26974  t-loss:0.1305, loss-lb:0.0678, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:41:56.631] iteration:26975  t-loss:0.1393, loss-lb:0.0652, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:41:56.825] iteration:26976  t-loss:0.1494, loss-lb:0.0706, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:41:57.019] iteration:26977  t-loss:0.1272, loss-lb:0.0713, loss-ulb:0.0280, weight:2.00, lr:0.0001
[12:41:57.214] iteration:26978  t-loss:0.1403, loss-lb:0.0779, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:41:57.408] iteration:26979  t-loss:0.1465, loss-lb:0.0736, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:41:57.599] iteration:26980  t-loss:0.1422, loss-lb:0.0715, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:41:57.790] iteration:26981  t-loss:0.1399, loss-lb:0.0653, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:41:57.980] iteration:26982  t-loss:0.1440, loss-lb:0.0713, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:41:58.173] iteration:26983  t-loss:0.1289, loss-lb:0.0686, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:41:58.365] iteration:26984  t-loss:0.1448, loss-lb:0.0666, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:41:58.557] iteration:26985  t-loss:0.1439, loss-lb:0.0684, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:41:58.748] iteration:26986  t-loss:0.1506, loss-lb:0.0756, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:41:58.940] iteration:26987  t-loss:0.1538, loss-lb:0.0740, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:41:59.132] iteration:26988  t-loss:0.1376, loss-lb:0.0646, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:41:59.323] iteration:26989  t-loss:0.1351, loss-lb:0.0702, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:41:59.517] iteration:26990  t-loss:0.1635, loss-lb:0.0715, loss-ulb:0.0460, weight:2.00, lr:0.0001
[12:41:59.709] iteration:26991  t-loss:0.1258, loss-lb:0.0659, loss-ulb:0.0300, weight:2.00, lr:0.0001
[12:41:59.901] iteration:26992  t-loss:0.1867, loss-lb:0.0781, loss-ulb:0.0543, weight:2.00, lr:0.0001
[12:42:00.093] iteration:26993  t-loss:0.1402, loss-lb:0.0783, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:42:00.285] iteration:26994  t-loss:0.1315, loss-lb:0.0671, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:42:00.480] iteration:26995  t-loss:0.2007, loss-lb:0.0605, loss-ulb:0.0701, weight:2.00, lr:0.0001
[12:42:00.672] iteration:26996  t-loss:0.1617, loss-lb:0.0730, loss-ulb:0.0444, weight:2.00, lr:0.0001
[12:42:00.863] iteration:26997  t-loss:0.1282, loss-lb:0.0658, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:42:01.055] iteration:26998  t-loss:0.1518, loss-lb:0.0648, loss-ulb:0.0435, weight:2.00, lr:0.0001
[12:42:01.248] iteration:26999  t-loss:0.1631, loss-lb:0.0718, loss-ulb:0.0456, weight:2.00, lr:0.0001
[12:42:01.440] iteration:27000  t-loss:0.1293, loss-lb:0.0702, loss-ulb:0.0295, weight:2.00, lr:0.0001
[12:42:01.632] iteration:27001  t-loss:0.1446, loss-lb:0.0699, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:42:01.824] iteration:27002  t-loss:0.1368, loss-lb:0.0675, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:42:02.016] iteration:27003  t-loss:0.1692, loss-lb:0.0822, loss-ulb:0.0435, weight:2.00, lr:0.0001
[12:42:02.207] iteration:27004  t-loss:0.1279, loss-lb:0.0667, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:42:02.398] iteration:27005  t-loss:0.1330, loss-lb:0.0674, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:42:02.590] iteration:27006  t-loss:0.1504, loss-lb:0.0784, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:42:02.782] iteration:27007  t-loss:0.1348, loss-lb:0.0687, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:42:02.974] iteration:27008  t-loss:0.1359, loss-lb:0.0717, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:42:03.163] iteration:27009  t-loss:0.1318, loss-lb:0.0688, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:42:03.356] iteration:27010  t-loss:0.1421, loss-lb:0.0768, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:42:03.548] iteration:27011  t-loss:0.1451, loss-lb:0.0788, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:42:03.741] iteration:27012  t-loss:0.1452, loss-lb:0.0787, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:42:03.931] iteration:27013  t-loss:0.1454, loss-lb:0.0763, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:42:04.124] iteration:27014  t-loss:0.1360, loss-lb:0.0656, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:42:04.317] iteration:27015  t-loss:0.1415, loss-lb:0.0676, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:42:04.509] iteration:27016  t-loss:0.1454, loss-lb:0.0723, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:42:04.699] iteration:27017  t-loss:0.1468, loss-lb:0.0765, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:42:04.892] iteration:27018  t-loss:0.1398, loss-lb:0.0682, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:42:05.084] iteration:27019  t-loss:0.1792, loss-lb:0.0719, loss-ulb:0.0537, weight:2.00, lr:0.0001
[12:42:05.277] iteration:27020  t-loss:0.1518, loss-lb:0.0741, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:42:05.477] iteration:27021  t-loss:0.1314, loss-lb:0.0680, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:42:05.677] iteration:27022  t-loss:0.1444, loss-lb:0.0720, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:42:05.872] iteration:27023  t-loss:0.1450, loss-lb:0.0715, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:42:06.062] iteration:27024  t-loss:0.1442, loss-lb:0.0666, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:42:06.254] iteration:27025  t-loss:0.1921, loss-lb:0.0698, loss-ulb:0.0612, weight:2.00, lr:0.0001
[12:42:06.446] iteration:27026  t-loss:0.1433, loss-lb:0.0782, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:42:06.637] iteration:27027  t-loss:0.1329, loss-lb:0.0665, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:42:06.829] iteration:27028  t-loss:0.1523, loss-lb:0.0717, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:42:07.019] iteration:27029  t-loss:0.1395, loss-lb:0.0704, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:42:07.210] iteration:27030  t-loss:0.1536, loss-lb:0.0736, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:42:07.404] iteration:27031  t-loss:0.1258, loss-lb:0.0646, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:42:07.601] iteration:27032  t-loss:0.1393, loss-lb:0.0707, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:42:07.794] iteration:27033  t-loss:0.1391, loss-lb:0.0683, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:42:07.987] iteration:27034  t-loss:0.1492, loss-lb:0.0728, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:42:08.180] iteration:27035  t-loss:0.1377, loss-lb:0.0700, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:42:08.373] iteration:27036  t-loss:0.1396, loss-lb:0.0670, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:42:08.564] iteration:27037  t-loss:0.1471, loss-lb:0.0710, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:42:08.755] iteration:27038  t-loss:0.1383, loss-lb:0.0654, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:42:08.946] iteration:27039  t-loss:0.1419, loss-lb:0.0729, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:42:09.140] iteration:27040  t-loss:0.1321, loss-lb:0.0653, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:42:09.332] iteration:27041  t-loss:0.1536, loss-lb:0.0787, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:42:09.521] iteration:27042  t-loss:0.1394, loss-lb:0.0736, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:42:09.712] iteration:27043  t-loss:0.1553, loss-lb:0.0717, loss-ulb:0.0418, weight:2.00, lr:0.0001
[12:42:09.902] iteration:27044  t-loss:0.1397, loss-lb:0.0723, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:42:10.093] iteration:27045  t-loss:0.1302, loss-lb:0.0628, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:42:10.283] iteration:27046  t-loss:0.1288, loss-lb:0.0686, loss-ulb:0.0301, weight:2.00, lr:0.0001
[12:42:10.473] iteration:27047  t-loss:0.1390, loss-lb:0.0687, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:10.663] iteration:27048  t-loss:0.1422, loss-lb:0.0723, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:42:11.246] iteration:27049  t-loss:0.1386, loss-lb:0.0676, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:42:11.442] iteration:27050  t-loss:0.1452, loss-lb:0.0704, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:42:11.635] iteration:27051  t-loss:0.1291, loss-lb:0.0637, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:42:11.827] iteration:27052  t-loss:0.1504, loss-lb:0.0686, loss-ulb:0.0409, weight:2.00, lr:0.0001
[12:42:12.018] iteration:27053  t-loss:0.1454, loss-lb:0.0752, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:12.210] iteration:27054  t-loss:0.1404, loss-lb:0.0699, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:42:12.402] iteration:27055  t-loss:0.1418, loss-lb:0.0684, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:42:12.594] iteration:27056  t-loss:0.1323, loss-lb:0.0708, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:42:12.786] iteration:27057  t-loss:0.1463, loss-lb:0.0701, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:42:12.978] iteration:27058  t-loss:0.1427, loss-lb:0.0635, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:42:13.170] iteration:27059  t-loss:0.1292, loss-lb:0.0720, loss-ulb:0.0286, weight:2.00, lr:0.0001
[12:42:13.363] iteration:27060  t-loss:0.1390, loss-lb:0.0715, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:42:13.554] iteration:27061  t-loss:0.1364, loss-lb:0.0676, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:42:13.746] iteration:27062  t-loss:0.1489, loss-lb:0.0691, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:42:13.938] iteration:27063  t-loss:0.1494, loss-lb:0.0708, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:42:14.130] iteration:27064  t-loss:0.1393, loss-lb:0.0714, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:42:14.321] iteration:27065  t-loss:0.1545, loss-lb:0.0693, loss-ulb:0.0426, weight:2.00, lr:0.0001
[12:42:14.514] iteration:27066  t-loss:0.1353, loss-lb:0.0703, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:42:14.704] iteration:27067  t-loss:0.1720, loss-lb:0.0718, loss-ulb:0.0501, weight:2.00, lr:0.0001
[12:42:14.896] iteration:27068  t-loss:0.1543, loss-lb:0.0715, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:42:15.087] iteration:27069  t-loss:0.1387, loss-lb:0.0684, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:15.280] iteration:27070  t-loss:0.1373, loss-lb:0.0751, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:42:15.472] iteration:27071  t-loss:0.1345, loss-lb:0.0687, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:42:15.664] iteration:27072  t-loss:0.1360, loss-lb:0.0699, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:42:15.855] iteration:27073  t-loss:0.1604, loss-lb:0.0676, loss-ulb:0.0464, weight:2.00, lr:0.0001
[12:42:16.046] iteration:27074  t-loss:0.1392, loss-lb:0.0761, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:42:16.237] iteration:27075  t-loss:0.1478, loss-lb:0.0655, loss-ulb:0.0411, weight:2.00, lr:0.0001
[12:42:16.429] iteration:27076  t-loss:0.1576, loss-lb:0.0730, loss-ulb:0.0423, weight:2.00, lr:0.0001
[12:42:16.629] iteration:27077  t-loss:0.1403, loss-lb:0.0693, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:42:16.822] iteration:27078  t-loss:0.1667, loss-lb:0.0836, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:42:17.013] iteration:27079  t-loss:0.1309, loss-lb:0.0667, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:42:17.205] iteration:27080  t-loss:0.1482, loss-lb:0.0724, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:42:17.397] iteration:27081  t-loss:0.1479, loss-lb:0.0679, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:42:17.588] iteration:27082  t-loss:0.1279, loss-lb:0.0672, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:42:17.781] iteration:27083  t-loss:0.1348, loss-lb:0.0651, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:42:17.974] iteration:27084  t-loss:0.1496, loss-lb:0.0671, loss-ulb:0.0412, weight:2.00, lr:0.0001
[12:42:18.167] iteration:27085  t-loss:0.1486, loss-lb:0.0729, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:42:18.362] iteration:27086  t-loss:0.1252, loss-lb:0.0661, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:42:18.557] iteration:27087  t-loss:0.1497, loss-lb:0.0785, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:42:18.751] iteration:27088  t-loss:0.1383, loss-lb:0.0692, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:42:18.944] iteration:27089  t-loss:0.1371, loss-lb:0.0676, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:42:19.138] iteration:27090  t-loss:0.1614, loss-lb:0.0772, loss-ulb:0.0421, weight:2.00, lr:0.0001
[12:42:19.329] iteration:27091  t-loss:0.1258, loss-lb:0.0686, loss-ulb:0.0286, weight:2.00, lr:0.0001
[12:42:19.521] iteration:27092  t-loss:0.1417, loss-lb:0.0703, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:42:19.714] iteration:27093  t-loss:0.1246, loss-lb:0.0657, loss-ulb:0.0294, weight:2.00, lr:0.0001
[12:42:19.905] iteration:27094  t-loss:0.1614, loss-lb:0.0799, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:42:20.098] iteration:27095  t-loss:0.1333, loss-lb:0.0647, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:42:20.290] iteration:27096  t-loss:0.1414, loss-lb:0.0702, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:42:20.484] iteration:27097  t-loss:0.1964, loss-lb:0.0751, loss-ulb:0.0607, weight:2.00, lr:0.0001
[12:42:20.676] iteration:27098  t-loss:0.1386, loss-lb:0.0702, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:42:20.868] iteration:27099  t-loss:0.1366, loss-lb:0.0637, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:42:21.061] iteration:27100  t-loss:0.1415, loss-lb:0.0717, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:42:21.254] iteration:27101  t-loss:0.1420, loss-lb:0.0755, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:42:21.446] iteration:27102  t-loss:0.1599, loss-lb:0.0678, loss-ulb:0.0461, weight:2.00, lr:0.0001
[12:42:21.638] iteration:27103  t-loss:0.1456, loss-lb:0.0685, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:42:21.830] iteration:27104  t-loss:0.1436, loss-lb:0.0761, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:42:22.023] iteration:27105  t-loss:0.1559, loss-lb:0.0694, loss-ulb:0.0433, weight:2.00, lr:0.0001
[12:42:22.216] iteration:27106  t-loss:0.1368, loss-lb:0.0666, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:22.407] iteration:27107  t-loss:0.1383, loss-lb:0.0739, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:42:22.599] iteration:27108  t-loss:0.1418, loss-lb:0.0758, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:42:22.791] iteration:27109  t-loss:0.1399, loss-lb:0.0686, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:42:22.985] iteration:27110  t-loss:0.1359, loss-lb:0.0679, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:42:23.176] iteration:27111  t-loss:0.1302, loss-lb:0.0659, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:42:23.369] iteration:27112  t-loss:0.1404, loss-lb:0.0682, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:42:23.561] iteration:27113  t-loss:0.1491, loss-lb:0.0759, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:42:23.753] iteration:27114  t-loss:0.1314, loss-lb:0.0640, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:42:23.946] iteration:27115  t-loss:0.1479, loss-lb:0.0723, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:42:24.139] iteration:27116  t-loss:0.1499, loss-lb:0.0723, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:42:24.331] iteration:27117  t-loss:0.1538, loss-lb:0.0693, loss-ulb:0.0422, weight:2.00, lr:0.0001
[12:42:24.523] iteration:27118  t-loss:0.1401, loss-lb:0.0715, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:42:24.715] iteration:27119  t-loss:0.1503, loss-lb:0.0774, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:42:24.908] iteration:27120  t-loss:0.1468, loss-lb:0.0696, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:42:25.099] iteration:27121  t-loss:0.1493, loss-lb:0.0728, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:42:25.292] iteration:27122  t-loss:0.1410, loss-lb:0.0728, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:42:25.485] iteration:27123  t-loss:0.1440, loss-lb:0.0714, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:42:25.677] iteration:27124  t-loss:0.1525, loss-lb:0.0753, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:42:25.869] iteration:27125  t-loss:0.1241, loss-lb:0.0666, loss-ulb:0.0288, weight:2.00, lr:0.0001
[12:42:26.061] iteration:27126  t-loss:0.1347, loss-lb:0.0641, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:42:26.254] iteration:27127  t-loss:0.1269, loss-lb:0.0622, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:42:26.445] iteration:27128  t-loss:0.1527, loss-lb:0.0707, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:42:26.637] iteration:27129  t-loss:0.1451, loss-lb:0.0776, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:42:26.828] iteration:27130  t-loss:0.1666, loss-lb:0.0666, loss-ulb:0.0500, weight:2.00, lr:0.0001
[12:42:27.020] iteration:27131  t-loss:0.1497, loss-lb:0.0676, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:42:27.212] iteration:27132  t-loss:0.1409, loss-lb:0.0683, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:42:27.403] iteration:27133  t-loss:0.1327, loss-lb:0.0663, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:42:27.595] iteration:27134  t-loss:0.2066, loss-lb:0.0621, loss-ulb:0.0723, weight:2.00, lr:0.0001
[12:42:27.786] iteration:27135  t-loss:0.1509, loss-lb:0.0742, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:42:27.978] iteration:27136  t-loss:0.1602, loss-lb:0.0693, loss-ulb:0.0455, weight:2.00, lr:0.0001
[12:42:28.172] iteration:27137  t-loss:0.1386, loss-lb:0.0692, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:42:28.364] iteration:27138  t-loss:0.1558, loss-lb:0.0816, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:42:28.555] iteration:27139  t-loss:0.1365, loss-lb:0.0688, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:42:28.746] iteration:27140  t-loss:0.1435, loss-lb:0.0706, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:42:28.937] iteration:27141  t-loss:0.1386, loss-lb:0.0709, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:42:29.128] iteration:27142  t-loss:0.1431, loss-lb:0.0760, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:42:29.318] iteration:27143  t-loss:0.1361, loss-lb:0.0698, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:42:29.509] iteration:27144  t-loss:0.1457, loss-lb:0.0694, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:42:29.701] iteration:27145  t-loss:0.1454, loss-lb:0.0672, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:42:29.892] iteration:27146  t-loss:0.1371, loss-lb:0.0714, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:42:42.469]  <<Test>> - Ep:276  - mean_dice/mean_h95 - S:89.59/1.36, Best-S:90.99, T:89.55/1.40, Best-T:90.48
[12:42:42.469]           - AvgLoss(lb/ulb/all):0.0703/0.0388/0.1476
[12:42:42.996] iteration:27147  t-loss:0.1394, loss-lb:0.0748, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:42:43.193] iteration:27148  t-loss:0.1429, loss-lb:0.0671, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:42:43.386] iteration:27149  t-loss:0.1266, loss-lb:0.0620, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:42:43.578] iteration:27150  t-loss:0.1351, loss-lb:0.0756, loss-ulb:0.0297, weight:2.00, lr:0.0001
[12:42:43.773] iteration:27151  t-loss:0.1299, loss-lb:0.0677, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:42:43.966] iteration:27152  t-loss:0.1341, loss-lb:0.0674, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:42:44.160] iteration:27153  t-loss:0.1870, loss-lb:0.0750, loss-ulb:0.0560, weight:2.00, lr:0.0001
[12:42:44.355] iteration:27154  t-loss:0.1352, loss-lb:0.0666, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:42:44.548] iteration:27155  t-loss:0.1298, loss-lb:0.0640, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:42:44.740] iteration:27156  t-loss:0.1334, loss-lb:0.0663, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:42:44.934] iteration:27157  t-loss:0.1364, loss-lb:0.0767, loss-ulb:0.0299, weight:2.00, lr:0.0001
[12:42:45.128] iteration:27158  t-loss:0.1465, loss-lb:0.0725, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:42:45.321] iteration:27159  t-loss:0.1434, loss-lb:0.0780, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:42:45.514] iteration:27160  t-loss:0.1380, loss-lb:0.0687, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:42:45.707] iteration:27161  t-loss:0.1452, loss-lb:0.0661, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:42:45.900] iteration:27162  t-loss:0.1416, loss-lb:0.0650, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:42:46.094] iteration:27163  t-loss:0.1425, loss-lb:0.0706, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:42:46.288] iteration:27164  t-loss:0.2335, loss-lb:0.0846, loss-ulb:0.0744, weight:2.00, lr:0.0001
[12:42:46.480] iteration:27165  t-loss:0.1371, loss-lb:0.0724, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:42:46.672] iteration:27166  t-loss:0.1440, loss-lb:0.0697, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:42:46.865] iteration:27167  t-loss:0.1464, loss-lb:0.0714, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:42:47.057] iteration:27168  t-loss:0.1297, loss-lb:0.0678, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:42:47.250] iteration:27169  t-loss:0.1979, loss-lb:0.0692, loss-ulb:0.0644, weight:2.00, lr:0.0001
[12:42:47.443] iteration:27170  t-loss:0.1381, loss-lb:0.0654, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:42:47.636] iteration:27171  t-loss:0.1369, loss-lb:0.0709, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:42:47.828] iteration:27172  t-loss:0.1503, loss-lb:0.0750, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:42:48.021] iteration:27173  t-loss:0.1385, loss-lb:0.0668, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:42:48.214] iteration:27174  t-loss:0.1396, loss-lb:0.0693, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:48.407] iteration:27175  t-loss:0.1592, loss-lb:0.0793, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:42:48.600] iteration:27176  t-loss:0.1478, loss-lb:0.0738, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:42:48.792] iteration:27177  t-loss:0.1448, loss-lb:0.0706, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:42:48.985] iteration:27178  t-loss:0.1376, loss-lb:0.0723, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:42:49.177] iteration:27179  t-loss:0.1384, loss-lb:0.0714, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:42:49.370] iteration:27180  t-loss:0.1324, loss-lb:0.0672, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:42:49.563] iteration:27181  t-loss:0.1365, loss-lb:0.0681, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:42:49.755] iteration:27182  t-loss:0.1553, loss-lb:0.0736, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:42:49.947] iteration:27183  t-loss:0.1436, loss-lb:0.0782, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:42:50.140] iteration:27184  t-loss:0.1372, loss-lb:0.0671, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:50.333] iteration:27185  t-loss:0.1803, loss-lb:0.0724, loss-ulb:0.0540, weight:2.00, lr:0.0001
[12:42:50.526] iteration:27186  t-loss:0.1346, loss-lb:0.0644, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:50.719] iteration:27187  t-loss:0.1519, loss-lb:0.0651, loss-ulb:0.0434, weight:2.00, lr:0.0001
[12:42:50.911] iteration:27188  t-loss:0.1413, loss-lb:0.0718, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:42:51.104] iteration:27189  t-loss:0.1457, loss-lb:0.0730, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:42:51.297] iteration:27190  t-loss:0.1380, loss-lb:0.0639, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:42:51.490] iteration:27191  t-loss:0.1383, loss-lb:0.0683, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:42:51.683] iteration:27192  t-loss:0.1451, loss-lb:0.0668, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:42:51.878] iteration:27193  t-loss:0.1592, loss-lb:0.0630, loss-ulb:0.0481, weight:2.00, lr:0.0001
[12:42:52.070] iteration:27194  t-loss:0.2118, loss-lb:0.0581, loss-ulb:0.0769, weight:2.00, lr:0.0001
[12:42:52.271] iteration:27195  t-loss:0.1343, loss-lb:0.0739, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:42:52.463] iteration:27196  t-loss:0.1439, loss-lb:0.0682, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:42:52.655] iteration:27197  t-loss:0.1380, loss-lb:0.0655, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:42:52.848] iteration:27198  t-loss:0.1453, loss-lb:0.0785, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:42:53.047] iteration:27199  t-loss:0.1516, loss-lb:0.0764, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:42:53.239] iteration:27200  t-loss:0.1401, loss-lb:0.0725, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:42:53.433] iteration:27201  t-loss:0.1386, loss-lb:0.0658, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:42:53.626] iteration:27202  t-loss:0.1458, loss-lb:0.0825, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:42:53.825] iteration:27203  t-loss:0.1448, loss-lb:0.0750, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:42:54.020] iteration:27204  t-loss:0.1337, loss-lb:0.0716, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:42:54.212] iteration:27205  t-loss:0.1277, loss-lb:0.0674, loss-ulb:0.0301, weight:2.00, lr:0.0001
[12:42:54.404] iteration:27206  t-loss:0.1464, loss-lb:0.0690, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:42:54.597] iteration:27207  t-loss:0.1340, loss-lb:0.0634, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:42:54.789] iteration:27208  t-loss:0.1412, loss-lb:0.0630, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:42:54.982] iteration:27209  t-loss:0.1483, loss-lb:0.0714, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:42:55.175] iteration:27210  t-loss:0.1345, loss-lb:0.0684, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:42:55.366] iteration:27211  t-loss:0.1781, loss-lb:0.0705, loss-ulb:0.0538, weight:2.00, lr:0.0001
[12:42:55.559] iteration:27212  t-loss:0.1423, loss-lb:0.0672, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:42:55.751] iteration:27213  t-loss:0.1433, loss-lb:0.0727, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:42:55.943] iteration:27214  t-loss:0.2066, loss-lb:0.0711, loss-ulb:0.0677, weight:2.00, lr:0.0001
[12:42:56.136] iteration:27215  t-loss:0.1315, loss-lb:0.0639, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:42:56.330] iteration:27216  t-loss:0.1408, loss-lb:0.0705, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:42:56.523] iteration:27217  t-loss:0.1426, loss-lb:0.0698, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:42:56.717] iteration:27218  t-loss:0.1254, loss-lb:0.0703, loss-ulb:0.0276, weight:2.00, lr:0.0001
[12:42:56.910] iteration:27219  t-loss:0.1407, loss-lb:0.0742, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:42:57.101] iteration:27220  t-loss:0.1291, loss-lb:0.0684, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:42:57.295] iteration:27221  t-loss:0.1469, loss-lb:0.0664, loss-ulb:0.0402, weight:2.00, lr:0.0001
[12:42:57.486] iteration:27222  t-loss:0.1300, loss-lb:0.0715, loss-ulb:0.0292, weight:2.00, lr:0.0001
[12:42:57.678] iteration:27223  t-loss:0.1383, loss-lb:0.0752, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:42:57.871] iteration:27224  t-loss:0.1276, loss-lb:0.0635, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:42:58.063] iteration:27225  t-loss:0.1467, loss-lb:0.0758, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:42:58.255] iteration:27226  t-loss:0.1459, loss-lb:0.0769, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:42:58.448] iteration:27227  t-loss:0.1399, loss-lb:0.0695, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:42:58.641] iteration:27228  t-loss:0.1509, loss-lb:0.0797, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:42:58.833] iteration:27229  t-loss:0.1457, loss-lb:0.0739, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:42:59.025] iteration:27230  t-loss:0.1375, loss-lb:0.0623, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:42:59.218] iteration:27231  t-loss:0.1431, loss-lb:0.0688, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:42:59.410] iteration:27232  t-loss:0.1403, loss-lb:0.0629, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:42:59.604] iteration:27233  t-loss:0.1664, loss-lb:0.0733, loss-ulb:0.0466, weight:2.00, lr:0.0001
[12:42:59.796] iteration:27234  t-loss:0.1356, loss-lb:0.0618, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:42:59.989] iteration:27235  t-loss:0.1349, loss-lb:0.0681, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:43:00.181] iteration:27236  t-loss:0.1353, loss-lb:0.0674, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:43:00.373] iteration:27237  t-loss:0.1472, loss-lb:0.0703, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:43:00.564] iteration:27238  t-loss:0.1952, loss-lb:0.0818, loss-ulb:0.0567, weight:2.00, lr:0.0001
[12:43:00.754] iteration:27239  t-loss:0.1372, loss-lb:0.0648, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:43:00.945] iteration:27240  t-loss:0.1498, loss-lb:0.0727, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:43:01.137] iteration:27241  t-loss:0.1340, loss-lb:0.0643, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:43:01.328] iteration:27242  t-loss:0.1712, loss-lb:0.0851, loss-ulb:0.0430, weight:2.00, lr:0.0001
[12:43:01.518] iteration:27243  t-loss:0.1373, loss-lb:0.0646, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:43:01.710] iteration:27244  t-loss:0.1430, loss-lb:0.0742, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:43:02.317] iteration:27245  t-loss:0.1365, loss-lb:0.0733, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:43:02.514] iteration:27246  t-loss:0.1686, loss-lb:0.0769, loss-ulb:0.0459, weight:2.00, lr:0.0001
[12:43:02.707] iteration:27247  t-loss:0.1341, loss-lb:0.0686, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:43:02.900] iteration:27248  t-loss:0.1603, loss-lb:0.0726, loss-ulb:0.0438, weight:2.00, lr:0.0001
[12:43:03.092] iteration:27249  t-loss:0.1327, loss-lb:0.0698, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:43:03.284] iteration:27250  t-loss:0.1456, loss-lb:0.0758, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:43:03.478] iteration:27251  t-loss:0.1695, loss-lb:0.0668, loss-ulb:0.0514, weight:2.00, lr:0.0001
[12:43:03.670] iteration:27252  t-loss:0.1321, loss-lb:0.0715, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:43:03.863] iteration:27253  t-loss:0.1398, loss-lb:0.0664, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:43:04.054] iteration:27254  t-loss:0.1368, loss-lb:0.0692, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:43:04.246] iteration:27255  t-loss:0.1379, loss-lb:0.0695, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:43:04.439] iteration:27256  t-loss:0.1495, loss-lb:0.0739, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:43:04.632] iteration:27257  t-loss:0.1324, loss-lb:0.0647, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:43:04.824] iteration:27258  t-loss:0.1433, loss-lb:0.0680, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:43:05.016] iteration:27259  t-loss:0.1295, loss-lb:0.0584, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:43:05.210] iteration:27260  t-loss:0.1755, loss-lb:0.0709, loss-ulb:0.0523, weight:2.00, lr:0.0001
[12:43:05.402] iteration:27261  t-loss:0.1440, loss-lb:0.0693, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:43:05.595] iteration:27262  t-loss:0.1410, loss-lb:0.0751, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:43:05.788] iteration:27263  t-loss:0.1601, loss-lb:0.0729, loss-ulb:0.0436, weight:2.00, lr:0.0001
[12:43:05.981] iteration:27264  t-loss:0.1467, loss-lb:0.0687, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:43:06.173] iteration:27265  t-loss:0.1422, loss-lb:0.0690, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:43:06.366] iteration:27266  t-loss:0.1523, loss-lb:0.0811, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:43:06.558] iteration:27267  t-loss:0.1464, loss-lb:0.0740, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:43:06.750] iteration:27268  t-loss:0.1557, loss-lb:0.0731, loss-ulb:0.0413, weight:2.00, lr:0.0001
[12:43:06.942] iteration:27269  t-loss:0.1509, loss-lb:0.0689, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:43:07.135] iteration:27270  t-loss:0.1406, loss-lb:0.0683, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:43:07.329] iteration:27271  t-loss:0.1432, loss-lb:0.0727, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:43:07.521] iteration:27272  t-loss:0.1346, loss-lb:0.0678, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:43:07.714] iteration:27273  t-loss:0.1385, loss-lb:0.0681, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:43:07.907] iteration:27274  t-loss:0.1557, loss-lb:0.0700, loss-ulb:0.0428, weight:2.00, lr:0.0001
[12:43:08.101] iteration:27275  t-loss:0.1366, loss-lb:0.0651, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:43:08.294] iteration:27276  t-loss:0.1700, loss-lb:0.0750, loss-ulb:0.0475, weight:2.00, lr:0.0001
[12:43:08.487] iteration:27277  t-loss:0.1496, loss-lb:0.0697, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:43:08.681] iteration:27278  t-loss:0.1364, loss-lb:0.0680, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:43:08.874] iteration:27279  t-loss:0.1436, loss-lb:0.0672, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:43:09.066] iteration:27280  t-loss:0.1370, loss-lb:0.0670, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:43:09.259] iteration:27281  t-loss:0.1297, loss-lb:0.0641, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:43:09.452] iteration:27282  t-loss:0.1277, loss-lb:0.0647, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:43:09.646] iteration:27283  t-loss:0.1483, loss-lb:0.0706, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:43:09.838] iteration:27284  t-loss:0.1344, loss-lb:0.0689, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:43:10.030] iteration:27285  t-loss:0.1474, loss-lb:0.0767, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:43:10.222] iteration:27286  t-loss:0.1428, loss-lb:0.0737, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:43:10.415] iteration:27287  t-loss:0.1449, loss-lb:0.0752, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:43:10.607] iteration:27288  t-loss:0.1418, loss-lb:0.0701, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:43:10.802] iteration:27289  t-loss:0.1392, loss-lb:0.0622, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:43:11.007] iteration:27290  t-loss:0.1379, loss-lb:0.0736, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:43:11.207] iteration:27291  t-loss:0.1389, loss-lb:0.0697, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:43:11.401] iteration:27292  t-loss:0.1587, loss-lb:0.0713, loss-ulb:0.0437, weight:2.00, lr:0.0001
[12:43:11.593] iteration:27293  t-loss:0.1515, loss-lb:0.0676, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:43:11.785] iteration:27294  t-loss:0.1631, loss-lb:0.0712, loss-ulb:0.0460, weight:2.00, lr:0.0001
[12:43:11.977] iteration:27295  t-loss:0.1352, loss-lb:0.0706, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:43:12.169] iteration:27296  t-loss:0.1392, loss-lb:0.0701, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:43:12.363] iteration:27297  t-loss:0.1882, loss-lb:0.0767, loss-ulb:0.0557, weight:2.00, lr:0.0001
[12:43:12.555] iteration:27298  t-loss:0.1391, loss-lb:0.0652, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:43:12.748] iteration:27299  t-loss:0.1297, loss-lb:0.0657, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:43:12.941] iteration:27300  t-loss:0.1357, loss-lb:0.0705, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:43:13.133] iteration:27301  t-loss:0.1290, loss-lb:0.0699, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:43:13.326] iteration:27302  t-loss:0.1246, loss-lb:0.0655, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:43:13.519] iteration:27303  t-loss:0.1305, loss-lb:0.0680, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:43:13.711] iteration:27304  t-loss:0.1504, loss-lb:0.0756, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:43:13.905] iteration:27305  t-loss:0.1411, loss-lb:0.0655, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:43:14.098] iteration:27306  t-loss:0.1342, loss-lb:0.0707, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:43:14.290] iteration:27307  t-loss:0.1395, loss-lb:0.0746, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:43:14.482] iteration:27308  t-loss:0.1420, loss-lb:0.0720, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:43:14.674] iteration:27309  t-loss:0.1453, loss-lb:0.0755, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:43:14.867] iteration:27310  t-loss:0.1379, loss-lb:0.0686, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:43:15.060] iteration:27311  t-loss:0.1351, loss-lb:0.0728, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:43:15.252] iteration:27312  t-loss:0.1388, loss-lb:0.0639, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:43:15.444] iteration:27313  t-loss:0.1433, loss-lb:0.0691, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:43:15.637] iteration:27314  t-loss:0.1406, loss-lb:0.0709, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:43:15.830] iteration:27315  t-loss:0.1495, loss-lb:0.0684, loss-ulb:0.0405, weight:2.00, lr:0.0001
[12:43:16.022] iteration:27316  t-loss:0.1432, loss-lb:0.0713, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:43:16.214] iteration:27317  t-loss:0.1731, loss-lb:0.0815, loss-ulb:0.0458, weight:2.00, lr:0.0001
[12:43:16.408] iteration:27318  t-loss:0.1411, loss-lb:0.0698, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:43:16.602] iteration:27319  t-loss:0.1564, loss-lb:0.0722, loss-ulb:0.0421, weight:2.00, lr:0.0001
[12:43:16.794] iteration:27320  t-loss:0.1299, loss-lb:0.0676, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:43:16.987] iteration:27321  t-loss:0.1401, loss-lb:0.0709, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:43:17.179] iteration:27322  t-loss:0.1364, loss-lb:0.0645, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:43:17.371] iteration:27323  t-loss:0.1340, loss-lb:0.0697, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:43:17.565] iteration:27324  t-loss:0.1381, loss-lb:0.0766, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:43:17.757] iteration:27325  t-loss:0.1389, loss-lb:0.0645, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:43:17.950] iteration:27326  t-loss:0.1404, loss-lb:0.0699, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:43:18.144] iteration:27327  t-loss:0.1399, loss-lb:0.0747, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:43:18.337] iteration:27328  t-loss:0.2133, loss-lb:0.0695, loss-ulb:0.0719, weight:2.00, lr:0.0001
[12:43:18.530] iteration:27329  t-loss:0.1468, loss-lb:0.0670, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:43:18.723] iteration:27330  t-loss:0.1272, loss-lb:0.0581, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:43:18.917] iteration:27331  t-loss:0.1419, loss-lb:0.0733, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:43:19.108] iteration:27332  t-loss:0.1260, loss-lb:0.0655, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:43:19.301] iteration:27333  t-loss:0.1515, loss-lb:0.0764, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:43:19.495] iteration:27334  t-loss:0.1367, loss-lb:0.0709, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:43:19.689] iteration:27335  t-loss:0.1607, loss-lb:0.0768, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:43:19.885] iteration:27336  t-loss:0.1461, loss-lb:0.0746, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:43:20.078] iteration:27337  t-loss:0.1377, loss-lb:0.0644, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:43:20.269] iteration:27338  t-loss:0.1467, loss-lb:0.0740, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:43:20.461] iteration:27339  t-loss:0.1253, loss-lb:0.0620, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:43:20.651] iteration:27340  t-loss:0.1654, loss-lb:0.0765, loss-ulb:0.0444, weight:2.00, lr:0.0001
[12:43:20.841] iteration:27341  t-loss:0.1437, loss-lb:0.0696, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:43:21.031] iteration:27342  t-loss:0.1427, loss-lb:0.0690, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:43:33.042]  <<Test>> - Ep:278  - mean_dice/mean_h95 - S:90.06/1.29, Best-S:90.99, T:89.73/1.35, Best-T:90.48
[12:43:33.042]           - AvgLoss(lb/ulb/all):0.0702/0.0375/0.1452
[12:43:33.577] iteration:27343  t-loss:0.1417, loss-lb:0.0664, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:43:33.774] iteration:27344  t-loss:0.1465, loss-lb:0.0708, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:43:33.974] iteration:27345  t-loss:0.1308, loss-lb:0.0680, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:43:34.165] iteration:27346  t-loss:0.1478, loss-lb:0.0666, loss-ulb:0.0406, weight:2.00, lr:0.0001
[12:43:34.359] iteration:27347  t-loss:0.1817, loss-lb:0.0723, loss-ulb:0.0547, weight:2.00, lr:0.0001
[12:43:34.554] iteration:27348  t-loss:0.1406, loss-lb:0.0732, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:43:34.747] iteration:27349  t-loss:0.1476, loss-lb:0.0709, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:43:34.944] iteration:27350  t-loss:0.1333, loss-lb:0.0607, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:43:35.136] iteration:27351  t-loss:0.1512, loss-lb:0.0728, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:43:35.330] iteration:27352  t-loss:0.1835, loss-lb:0.0655, loss-ulb:0.0590, weight:2.00, lr:0.0001
[12:43:35.526] iteration:27353  t-loss:0.1686, loss-lb:0.0740, loss-ulb:0.0473, weight:2.00, lr:0.0001
[12:43:35.720] iteration:27354  t-loss:0.1360, loss-lb:0.0720, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:43:35.915] iteration:27355  t-loss:0.1389, loss-lb:0.0667, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:43:36.108] iteration:27356  t-loss:0.1521, loss-lb:0.0625, loss-ulb:0.0448, weight:2.00, lr:0.0001
[12:43:36.300] iteration:27357  t-loss:0.1342, loss-lb:0.0735, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:43:36.493] iteration:27358  t-loss:0.1431, loss-lb:0.0742, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:43:36.687] iteration:27359  t-loss:0.1389, loss-lb:0.0717, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:43:36.886] iteration:27360  t-loss:0.1546, loss-lb:0.0696, loss-ulb:0.0425, weight:2.00, lr:0.0001
[12:43:37.081] iteration:27361  t-loss:0.1378, loss-lb:0.0739, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:43:37.274] iteration:27362  t-loss:0.1474, loss-lb:0.0707, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:43:37.469] iteration:27363  t-loss:0.1528, loss-lb:0.0692, loss-ulb:0.0418, weight:2.00, lr:0.0001
[12:43:37.661] iteration:27364  t-loss:0.1449, loss-lb:0.0829, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:43:37.858] iteration:27365  t-loss:0.1405, loss-lb:0.0763, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:43:38.050] iteration:27366  t-loss:0.1557, loss-lb:0.0829, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:43:38.243] iteration:27367  t-loss:0.1282, loss-lb:0.0659, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:43:38.440] iteration:27368  t-loss:0.1629, loss-lb:0.0747, loss-ulb:0.0441, weight:2.00, lr:0.0001
[12:43:38.631] iteration:27369  t-loss:0.1501, loss-lb:0.0712, loss-ulb:0.0395, weight:2.00, lr:0.0001
[12:43:38.823] iteration:27370  t-loss:0.1573, loss-lb:0.0693, loss-ulb:0.0440, weight:2.00, lr:0.0001
[12:43:39.015] iteration:27371  t-loss:0.1412, loss-lb:0.0728, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:43:39.207] iteration:27372  t-loss:0.1497, loss-lb:0.0744, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:43:39.399] iteration:27373  t-loss:0.1496, loss-lb:0.0639, loss-ulb:0.0428, weight:2.00, lr:0.0001
[12:43:39.590] iteration:27374  t-loss:0.1370, loss-lb:0.0722, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:43:39.783] iteration:27375  t-loss:0.1453, loss-lb:0.0664, loss-ulb:0.0395, weight:2.00, lr:0.0001
[12:43:39.975] iteration:27376  t-loss:0.1802, loss-lb:0.0674, loss-ulb:0.0564, weight:2.00, lr:0.0001
[12:43:40.166] iteration:27377  t-loss:0.1392, loss-lb:0.0672, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:43:40.358] iteration:27378  t-loss:0.1353, loss-lb:0.0703, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:43:40.549] iteration:27379  t-loss:0.1373, loss-lb:0.0723, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:43:40.741] iteration:27380  t-loss:0.1316, loss-lb:0.0662, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:43:40.932] iteration:27381  t-loss:0.1266, loss-lb:0.0629, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:43:41.125] iteration:27382  t-loss:0.1491, loss-lb:0.0723, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:43:41.318] iteration:27383  t-loss:0.1461, loss-lb:0.0695, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:43:41.511] iteration:27384  t-loss:0.1333, loss-lb:0.0697, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:43:41.707] iteration:27385  t-loss:0.1482, loss-lb:0.0709, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:43:41.901] iteration:27386  t-loss:0.1440, loss-lb:0.0709, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:43:42.095] iteration:27387  t-loss:0.1392, loss-lb:0.0676, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:43:42.288] iteration:27388  t-loss:0.1341, loss-lb:0.0678, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:43:42.479] iteration:27389  t-loss:0.1484, loss-lb:0.0695, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:43:42.670] iteration:27390  t-loss:0.1321, loss-lb:0.0659, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:43:42.864] iteration:27391  t-loss:0.1613, loss-lb:0.0694, loss-ulb:0.0459, weight:2.00, lr:0.0001
[12:43:43.058] iteration:27392  t-loss:0.1926, loss-lb:0.0786, loss-ulb:0.0570, weight:2.00, lr:0.0001
[12:43:43.249] iteration:27393  t-loss:0.1409, loss-lb:0.0627, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:43:43.441] iteration:27394  t-loss:0.1614, loss-lb:0.0785, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:43:43.636] iteration:27395  t-loss:0.1515, loss-lb:0.0699, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:43:43.840] iteration:27396  t-loss:0.1318, loss-lb:0.0651, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:43:44.037] iteration:27397  t-loss:0.1401, loss-lb:0.0768, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:43:44.229] iteration:27398  t-loss:0.1449, loss-lb:0.0684, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:43:44.422] iteration:27399  t-loss:0.1409, loss-lb:0.0772, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:43:44.614] iteration:27400  t-loss:0.1391, loss-lb:0.0673, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:43:44.805] iteration:27401  t-loss:0.1324, loss-lb:0.0659, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:43:44.997] iteration:27402  t-loss:0.1401, loss-lb:0.0686, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:43:45.189] iteration:27403  t-loss:0.1351, loss-lb:0.0655, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:43:45.382] iteration:27404  t-loss:0.1316, loss-lb:0.0626, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:43:45.574] iteration:27405  t-loss:0.2000, loss-lb:0.0716, loss-ulb:0.0642, weight:2.00, lr:0.0001
[12:43:45.766] iteration:27406  t-loss:0.1406, loss-lb:0.0793, loss-ulb:0.0307, weight:2.00, lr:0.0001
[12:43:45.958] iteration:27407  t-loss:0.1677, loss-lb:0.0716, loss-ulb:0.0481, weight:2.00, lr:0.0001
[12:43:46.150] iteration:27408  t-loss:0.1561, loss-lb:0.0766, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:43:46.341] iteration:27409  t-loss:0.1517, loss-lb:0.0725, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:43:46.533] iteration:27410  t-loss:0.1404, loss-lb:0.0665, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:43:46.725] iteration:27411  t-loss:0.1392, loss-lb:0.0734, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:43:46.917] iteration:27412  t-loss:0.1350, loss-lb:0.0616, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:43:47.108] iteration:27413  t-loss:0.1457, loss-lb:0.0723, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:43:47.300] iteration:27414  t-loss:0.1273, loss-lb:0.0696, loss-ulb:0.0289, weight:2.00, lr:0.0001
[12:43:47.492] iteration:27415  t-loss:0.1378, loss-lb:0.0704, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:43:47.684] iteration:27416  t-loss:0.1342, loss-lb:0.0737, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:43:47.876] iteration:27417  t-loss:0.1434, loss-lb:0.0699, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:43:48.068] iteration:27418  t-loss:0.1478, loss-lb:0.0800, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:43:48.260] iteration:27419  t-loss:0.1639, loss-lb:0.0704, loss-ulb:0.0468, weight:2.00, lr:0.0001
[12:43:48.452] iteration:27420  t-loss:0.1460, loss-lb:0.0673, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:43:48.644] iteration:27421  t-loss:0.1340, loss-lb:0.0666, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:43:48.837] iteration:27422  t-loss:0.1398, loss-lb:0.0659, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:43:49.029] iteration:27423  t-loss:0.1294, loss-lb:0.0657, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:43:49.219] iteration:27424  t-loss:0.1321, loss-lb:0.0724, loss-ulb:0.0299, weight:2.00, lr:0.0001
[12:43:49.412] iteration:27425  t-loss:0.1295, loss-lb:0.0654, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:43:49.603] iteration:27426  t-loss:0.1516, loss-lb:0.0751, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:43:49.795] iteration:27427  t-loss:0.1437, loss-lb:0.0669, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:43:49.986] iteration:27428  t-loss:0.1391, loss-lb:0.0649, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:43:50.177] iteration:27429  t-loss:0.1357, loss-lb:0.0719, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:43:50.369] iteration:27430  t-loss:0.1313, loss-lb:0.0660, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:43:50.560] iteration:27431  t-loss:0.1469, loss-lb:0.0747, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:43:50.753] iteration:27432  t-loss:0.1402, loss-lb:0.0675, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:43:50.944] iteration:27433  t-loss:0.1498, loss-lb:0.0745, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:43:51.133] iteration:27434  t-loss:0.1606, loss-lb:0.0700, loss-ulb:0.0453, weight:2.00, lr:0.0001
[12:43:51.323] iteration:27435  t-loss:0.1317, loss-lb:0.0664, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:43:51.513] iteration:27436  t-loss:0.1920, loss-lb:0.0752, loss-ulb:0.0584, weight:2.00, lr:0.0001
[12:43:51.702] iteration:27437  t-loss:0.1453, loss-lb:0.0720, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:43:51.893] iteration:27438  t-loss:0.1532, loss-lb:0.0740, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:43:52.084] iteration:27439  t-loss:0.1356, loss-lb:0.0660, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:43:52.276] iteration:27440  t-loss:0.1562, loss-lb:0.0684, loss-ulb:0.0439, weight:2.00, lr:0.0001
[12:43:52.872] iteration:27441  t-loss:0.1364, loss-lb:0.0698, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:43:53.069] iteration:27442  t-loss:0.1441, loss-lb:0.0711, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:43:53.262] iteration:27443  t-loss:0.1287, loss-lb:0.0661, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:43:53.454] iteration:27444  t-loss:0.1420, loss-lb:0.0750, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:43:53.647] iteration:27445  t-loss:0.1455, loss-lb:0.0702, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:43:53.839] iteration:27446  t-loss:0.1431, loss-lb:0.0702, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:43:54.031] iteration:27447  t-loss:0.1406, loss-lb:0.0726, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:43:54.223] iteration:27448  t-loss:0.1356, loss-lb:0.0694, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:43:54.411] iteration:27449  t-loss:0.1430, loss-lb:0.0689, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:43:54.603] iteration:27450  t-loss:0.1489, loss-lb:0.0705, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:43:54.796] iteration:27451  t-loss:0.1955, loss-lb:0.0700, loss-ulb:0.0628, weight:2.00, lr:0.0001
[12:43:54.991] iteration:27452  t-loss:0.1444, loss-lb:0.0689, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:43:55.184] iteration:27453  t-loss:0.1468, loss-lb:0.0731, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:43:55.375] iteration:27454  t-loss:0.1472, loss-lb:0.0693, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:43:55.567] iteration:27455  t-loss:0.1242, loss-lb:0.0609, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:43:55.759] iteration:27456  t-loss:0.1339, loss-lb:0.0705, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:43:55.951] iteration:27457  t-loss:0.1349, loss-lb:0.0757, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:43:56.143] iteration:27458  t-loss:0.1526, loss-lb:0.0742, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:43:56.335] iteration:27459  t-loss:0.1432, loss-lb:0.0755, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:43:56.526] iteration:27460  t-loss:0.1315, loss-lb:0.0666, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:43:56.719] iteration:27461  t-loss:0.1314, loss-lb:0.0676, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:43:56.910] iteration:27462  t-loss:0.1380, loss-lb:0.0737, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:43:57.102] iteration:27463  t-loss:0.1463, loss-lb:0.0706, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:43:57.294] iteration:27464  t-loss:0.1322, loss-lb:0.0704, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:43:57.487] iteration:27465  t-loss:0.1355, loss-lb:0.0670, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:43:57.680] iteration:27466  t-loss:0.1294, loss-lb:0.0698, loss-ulb:0.0298, weight:2.00, lr:0.0001
[12:43:57.871] iteration:27467  t-loss:0.1319, loss-lb:0.0633, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:43:58.064] iteration:27468  t-loss:0.1480, loss-lb:0.0785, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:43:58.255] iteration:27469  t-loss:0.1432, loss-lb:0.0701, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:43:58.448] iteration:27470  t-loss:0.1481, loss-lb:0.0719, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:43:58.640] iteration:27471  t-loss:0.1324, loss-lb:0.0652, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:43:58.833] iteration:27472  t-loss:0.1475, loss-lb:0.0688, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:43:59.025] iteration:27473  t-loss:0.1486, loss-lb:0.0721, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:43:59.217] iteration:27474  t-loss:0.1366, loss-lb:0.0685, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:43:59.410] iteration:27475  t-loss:0.1380, loss-lb:0.0721, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:43:59.602] iteration:27476  t-loss:0.1372, loss-lb:0.0703, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:43:59.794] iteration:27477  t-loss:0.1551, loss-lb:0.0749, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:43:59.987] iteration:27478  t-loss:0.2224, loss-lb:0.0740, loss-ulb:0.0742, weight:2.00, lr:0.0001
[12:44:00.179] iteration:27479  t-loss:0.1435, loss-lb:0.0708, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:44:00.372] iteration:27480  t-loss:0.1361, loss-lb:0.0639, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:44:00.564] iteration:27481  t-loss:0.1429, loss-lb:0.0667, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:44:00.758] iteration:27482  t-loss:0.1481, loss-lb:0.0682, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:44:00.950] iteration:27483  t-loss:0.1448, loss-lb:0.0698, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:44:01.141] iteration:27484  t-loss:0.1386, loss-lb:0.0703, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:44:01.333] iteration:27485  t-loss:0.1312, loss-lb:0.0638, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:44:01.525] iteration:27486  t-loss:0.1478, loss-lb:0.0665, loss-ulb:0.0407, weight:2.00, lr:0.0001
[12:44:01.718] iteration:27487  t-loss:0.1668, loss-lb:0.0721, loss-ulb:0.0474, weight:2.00, lr:0.0001
[12:44:01.909] iteration:27488  t-loss:0.1444, loss-lb:0.0647, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:44:02.101] iteration:27489  t-loss:0.1460, loss-lb:0.0739, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:44:02.292] iteration:27490  t-loss:0.1506, loss-lb:0.0674, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:44:02.483] iteration:27491  t-loss:0.1324, loss-lb:0.0705, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:44:02.676] iteration:27492  t-loss:0.1655, loss-lb:0.0715, loss-ulb:0.0470, weight:2.00, lr:0.0001
[12:44:02.867] iteration:27493  t-loss:0.1340, loss-lb:0.0718, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:44:03.060] iteration:27494  t-loss:0.1296, loss-lb:0.0626, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:44:03.252] iteration:27495  t-loss:0.1540, loss-lb:0.0701, loss-ulb:0.0419, weight:2.00, lr:0.0001
[12:44:03.445] iteration:27496  t-loss:0.1750, loss-lb:0.0674, loss-ulb:0.0538, weight:2.00, lr:0.0001
[12:44:03.638] iteration:27497  t-loss:0.1419, loss-lb:0.0698, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:44:03.830] iteration:27498  t-loss:0.1372, loss-lb:0.0727, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:44:04.023] iteration:27499  t-loss:0.1272, loss-lb:0.0626, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:44:04.215] iteration:27500  t-loss:0.1425, loss-lb:0.0667, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:44:04.408] iteration:27501  t-loss:0.1565, loss-lb:0.0682, loss-ulb:0.0442, weight:2.00, lr:0.0001
[12:44:04.600] iteration:27502  t-loss:0.1459, loss-lb:0.0749, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:44:04.793] iteration:27503  t-loss:0.1416, loss-lb:0.0733, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:44:04.986] iteration:27504  t-loss:0.1709, loss-lb:0.0700, loss-ulb:0.0505, weight:2.00, lr:0.0001
[12:44:05.177] iteration:27505  t-loss:0.1402, loss-lb:0.0716, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:44:05.370] iteration:27506  t-loss:0.1436, loss-lb:0.0682, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:44:05.562] iteration:27507  t-loss:0.1459, loss-lb:0.0740, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:44:05.754] iteration:27508  t-loss:0.1359, loss-lb:0.0665, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:44:05.945] iteration:27509  t-loss:0.1411, loss-lb:0.0678, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:44:06.138] iteration:27510  t-loss:0.1296, loss-lb:0.0626, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:44:06.333] iteration:27511  t-loss:0.1751, loss-lb:0.0721, loss-ulb:0.0515, weight:2.00, lr:0.0001
[12:44:06.525] iteration:27512  t-loss:0.1379, loss-lb:0.0716, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:44:06.717] iteration:27513  t-loss:0.1320, loss-lb:0.0701, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:44:06.909] iteration:27514  t-loss:0.1663, loss-lb:0.0745, loss-ulb:0.0459, weight:2.00, lr:0.0001
[12:44:07.103] iteration:27515  t-loss:0.1312, loss-lb:0.0688, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:44:07.296] iteration:27516  t-loss:0.1350, loss-lb:0.0742, loss-ulb:0.0304, weight:2.00, lr:0.0001
[12:44:07.489] iteration:27517  t-loss:0.1901, loss-lb:0.0768, loss-ulb:0.0567, weight:2.00, lr:0.0001
[12:44:07.681] iteration:27518  t-loss:0.1473, loss-lb:0.0738, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:44:07.873] iteration:27519  t-loss:0.2321, loss-lb:0.0681, loss-ulb:0.0820, weight:2.00, lr:0.0001
[12:44:08.065] iteration:27520  t-loss:0.1595, loss-lb:0.0745, loss-ulb:0.0425, weight:2.00, lr:0.0001
[12:44:08.258] iteration:27521  t-loss:0.1502, loss-lb:0.0683, loss-ulb:0.0409, weight:2.00, lr:0.0001
[12:44:08.449] iteration:27522  t-loss:0.1422, loss-lb:0.0728, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:44:08.641] iteration:27523  t-loss:0.1409, loss-lb:0.0660, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:44:08.834] iteration:27524  t-loss:0.1392, loss-lb:0.0657, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:44:09.025] iteration:27525  t-loss:0.1461, loss-lb:0.0709, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:44:09.218] iteration:27526  t-loss:0.1393, loss-lb:0.0706, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:44:09.411] iteration:27527  t-loss:0.1430, loss-lb:0.0727, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:44:09.603] iteration:27528  t-loss:0.1472, loss-lb:0.0705, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:44:09.796] iteration:27529  t-loss:0.1636, loss-lb:0.0702, loss-ulb:0.0467, weight:2.00, lr:0.0001
[12:44:09.988] iteration:27530  t-loss:0.1500, loss-lb:0.0659, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:44:10.179] iteration:27531  t-loss:0.1509, loss-lb:0.0725, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:44:10.370] iteration:27532  t-loss:0.1375, loss-lb:0.0701, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:44:10.562] iteration:27533  t-loss:0.1400, loss-lb:0.0695, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:44:10.753] iteration:27534  t-loss:0.1461, loss-lb:0.0725, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:44:10.944] iteration:27535  t-loss:0.1347, loss-lb:0.0615, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:44:11.134] iteration:27536  t-loss:0.1417, loss-lb:0.0752, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:44:11.325] iteration:27537  t-loss:0.1469, loss-lb:0.0714, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:44:11.516] iteration:27538  t-loss:0.1341, loss-lb:0.0683, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:44:23.933]  <<Test>> - Ep:280  - mean_dice/mean_h95 - S:89.54/2.64, Best-S:90.99, T:89.65/1.38, Best-T:90.48
[12:44:23.933]           - AvgLoss(lb/ulb/all):0.0700/0.0397/0.1493
[12:44:24.455] iteration:27539  t-loss:0.1502, loss-lb:0.0737, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:44:24.653] iteration:27540  t-loss:0.1633, loss-lb:0.0702, loss-ulb:0.0465, weight:2.00, lr:0.0001
[12:44:24.847] iteration:27541  t-loss:0.1565, loss-lb:0.0711, loss-ulb:0.0427, weight:2.00, lr:0.0001
[12:44:25.042] iteration:27542  t-loss:0.1398, loss-lb:0.0718, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:44:25.234] iteration:27543  t-loss:0.1467, loss-lb:0.0756, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:44:25.427] iteration:27544  t-loss:0.1365, loss-lb:0.0683, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:44:25.621] iteration:27545  t-loss:0.1431, loss-lb:0.0772, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:44:25.814] iteration:27546  t-loss:0.1413, loss-lb:0.0719, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:44:26.006] iteration:27547  t-loss:0.1418, loss-lb:0.0740, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:44:26.199] iteration:27548  t-loss:0.1409, loss-lb:0.0667, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:44:26.394] iteration:27549  t-loss:0.1372, loss-lb:0.0657, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:44:26.587] iteration:27550  t-loss:0.1610, loss-lb:0.0712, loss-ulb:0.0449, weight:2.00, lr:0.0001
[12:44:26.781] iteration:27551  t-loss:0.1314, loss-lb:0.0669, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:44:26.974] iteration:27552  t-loss:0.1433, loss-lb:0.0734, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:44:27.167] iteration:27553  t-loss:0.1398, loss-lb:0.0723, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:44:27.360] iteration:27554  t-loss:0.1455, loss-lb:0.0624, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:44:27.552] iteration:27555  t-loss:0.1507, loss-lb:0.0741, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:44:27.745] iteration:27556  t-loss:0.1409, loss-lb:0.0706, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:44:27.938] iteration:27557  t-loss:0.1634, loss-lb:0.0664, loss-ulb:0.0485, weight:2.00, lr:0.0001
[12:44:28.131] iteration:27558  t-loss:0.1344, loss-lb:0.0725, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:44:28.325] iteration:27559  t-loss:0.1425, loss-lb:0.0730, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:44:28.519] iteration:27560  t-loss:0.1452, loss-lb:0.0786, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:44:28.711] iteration:27561  t-loss:0.1437, loss-lb:0.0763, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:44:28.904] iteration:27562  t-loss:0.1378, loss-lb:0.0705, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:44:29.096] iteration:27563  t-loss:0.1367, loss-lb:0.0635, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:44:29.290] iteration:27564  t-loss:0.2114, loss-lb:0.0721, loss-ulb:0.0696, weight:2.00, lr:0.0001
[12:44:29.483] iteration:27565  t-loss:0.1429, loss-lb:0.0659, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:44:29.675] iteration:27566  t-loss:0.1425, loss-lb:0.0690, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:44:29.868] iteration:27567  t-loss:0.1471, loss-lb:0.0712, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:44:30.061] iteration:27568  t-loss:0.1710, loss-lb:0.0794, loss-ulb:0.0458, weight:2.00, lr:0.0001
[12:44:30.253] iteration:27569  t-loss:0.1345, loss-lb:0.0677, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:44:30.446] iteration:27570  t-loss:0.1554, loss-lb:0.0752, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:44:30.639] iteration:27571  t-loss:0.1467, loss-lb:0.0672, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:44:30.831] iteration:27572  t-loss:0.1312, loss-lb:0.0626, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:44:31.024] iteration:27573  t-loss:0.1421, loss-lb:0.0679, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:44:31.217] iteration:27574  t-loss:0.1418, loss-lb:0.0767, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:44:31.410] iteration:27575  t-loss:0.1449, loss-lb:0.0701, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:44:31.601] iteration:27576  t-loss:0.1407, loss-lb:0.0608, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:44:31.793] iteration:27577  t-loss:0.1492, loss-lb:0.0703, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:44:31.986] iteration:27578  t-loss:0.1518, loss-lb:0.0765, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:44:32.179] iteration:27579  t-loss:0.1458, loss-lb:0.0657, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:44:32.372] iteration:27580  t-loss:0.1402, loss-lb:0.0687, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:44:32.565] iteration:27581  t-loss:0.1699, loss-lb:0.0703, loss-ulb:0.0498, weight:2.00, lr:0.0001
[12:44:32.758] iteration:27582  t-loss:0.1478, loss-lb:0.0667, loss-ulb:0.0406, weight:2.00, lr:0.0001
[12:44:32.951] iteration:27583  t-loss:0.1547, loss-lb:0.0716, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:44:33.142] iteration:27584  t-loss:0.1392, loss-lb:0.0707, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:44:33.335] iteration:27585  t-loss:0.1289, loss-lb:0.0673, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:44:33.527] iteration:27586  t-loss:0.1341, loss-lb:0.0615, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:44:33.719] iteration:27587  t-loss:0.1507, loss-lb:0.0739, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:44:33.912] iteration:27588  t-loss:0.1362, loss-lb:0.0637, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:44:34.105] iteration:27589  t-loss:0.1465, loss-lb:0.0689, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:44:34.298] iteration:27590  t-loss:0.1340, loss-lb:0.0728, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:44:34.490] iteration:27591  t-loss:0.1317, loss-lb:0.0694, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:44:34.683] iteration:27592  t-loss:0.1587, loss-lb:0.0758, loss-ulb:0.0415, weight:2.00, lr:0.0001
[12:44:34.874] iteration:27593  t-loss:0.1395, loss-lb:0.0725, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:44:35.068] iteration:27594  t-loss:0.1435, loss-lb:0.0695, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:44:35.262] iteration:27595  t-loss:0.1824, loss-lb:0.0801, loss-ulb:0.0512, weight:2.00, lr:0.0001
[12:44:35.455] iteration:27596  t-loss:0.1336, loss-lb:0.0682, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:44:35.647] iteration:27597  t-loss:0.1464, loss-lb:0.0757, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:44:35.840] iteration:27598  t-loss:0.2257, loss-lb:0.0724, loss-ulb:0.0767, weight:2.00, lr:0.0001
[12:44:36.032] iteration:27599  t-loss:0.1413, loss-lb:0.0677, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:44:36.225] iteration:27600  t-loss:0.1326, loss-lb:0.0707, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:44:36.417] iteration:27601  t-loss:0.1375, loss-lb:0.0692, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:44:36.608] iteration:27602  t-loss:0.1355, loss-lb:0.0668, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:44:36.801] iteration:27603  t-loss:0.1427, loss-lb:0.0714, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:44:36.993] iteration:27604  t-loss:0.1340, loss-lb:0.0682, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:44:37.185] iteration:27605  t-loss:0.1412, loss-lb:0.0730, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:44:37.377] iteration:27606  t-loss:0.1385, loss-lb:0.0664, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:44:37.570] iteration:27607  t-loss:0.1275, loss-lb:0.0707, loss-ulb:0.0284, weight:2.00, lr:0.0001
[12:44:37.762] iteration:27608  t-loss:0.1335, loss-lb:0.0689, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:44:37.954] iteration:27609  t-loss:0.1371, loss-lb:0.0738, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:44:38.147] iteration:27610  t-loss:0.1326, loss-lb:0.0678, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:44:38.338] iteration:27611  t-loss:0.1421, loss-lb:0.0691, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:44:38.531] iteration:27612  t-loss:0.1717, loss-lb:0.0725, loss-ulb:0.0496, weight:2.00, lr:0.0001
[12:44:38.724] iteration:27613  t-loss:0.1371, loss-lb:0.0646, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:44:38.917] iteration:27614  t-loss:0.1491, loss-lb:0.0716, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:44:39.109] iteration:27615  t-loss:0.1346, loss-lb:0.0651, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:44:39.302] iteration:27616  t-loss:0.1334, loss-lb:0.0674, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:44:39.494] iteration:27617  t-loss:0.1343, loss-lb:0.0698, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:44:39.687] iteration:27618  t-loss:0.1440, loss-lb:0.0691, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:44:39.879] iteration:27619  t-loss:0.1387, loss-lb:0.0704, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:44:40.072] iteration:27620  t-loss:0.1440, loss-lb:0.0741, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:44:40.265] iteration:27621  t-loss:0.1452, loss-lb:0.0737, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:44:40.458] iteration:27622  t-loss:0.1396, loss-lb:0.0621, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:44:40.651] iteration:27623  t-loss:0.2100, loss-lb:0.0685, loss-ulb:0.0707, weight:2.00, lr:0.0001
[12:44:40.843] iteration:27624  t-loss:0.1268, loss-lb:0.0616, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:44:41.035] iteration:27625  t-loss:0.1476, loss-lb:0.0730, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:44:41.227] iteration:27626  t-loss:0.1280, loss-lb:0.0639, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:44:41.420] iteration:27627  t-loss:0.1414, loss-lb:0.0687, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:44:41.611] iteration:27628  t-loss:0.1389, loss-lb:0.0711, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:44:41.803] iteration:27629  t-loss:0.1368, loss-lb:0.0696, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:44:41.995] iteration:27630  t-loss:0.1832, loss-lb:0.0724, loss-ulb:0.0554, weight:2.00, lr:0.0001
[12:44:42.186] iteration:27631  t-loss:0.1349, loss-lb:0.0660, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:44:42.377] iteration:27632  t-loss:0.1509, loss-lb:0.0747, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:44:42.568] iteration:27633  t-loss:0.1385, loss-lb:0.0688, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:44:42.758] iteration:27634  t-loss:0.1414, loss-lb:0.0725, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:44:42.948] iteration:27635  t-loss:0.1333, loss-lb:0.0639, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:44:43.139] iteration:27636  t-loss:0.1464, loss-lb:0.0720, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:44:43.735] iteration:27637  t-loss:0.1244, loss-lb:0.0690, loss-ulb:0.0277, weight:2.00, lr:0.0001
[12:44:43.932] iteration:27638  t-loss:0.1304, loss-lb:0.0675, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:44:44.126] iteration:27639  t-loss:0.1356, loss-lb:0.0650, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:44:44.319] iteration:27640  t-loss:0.1313, loss-lb:0.0688, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:44:44.510] iteration:27641  t-loss:0.1353, loss-lb:0.0721, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:44:44.703] iteration:27642  t-loss:0.1336, loss-lb:0.0704, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:44:44.895] iteration:27643  t-loss:0.1463, loss-lb:0.0770, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:44:45.087] iteration:27644  t-loss:0.1803, loss-lb:0.0681, loss-ulb:0.0561, weight:2.00, lr:0.0001
[12:44:45.279] iteration:27645  t-loss:0.1282, loss-lb:0.0681, loss-ulb:0.0300, weight:2.00, lr:0.0001
[12:44:45.475] iteration:27646  t-loss:0.1386, loss-lb:0.0656, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:44:45.668] iteration:27647  t-loss:0.1453, loss-lb:0.0712, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:44:45.860] iteration:27648  t-loss:0.1373, loss-lb:0.0703, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:44:46.053] iteration:27649  t-loss:0.1391, loss-lb:0.0719, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:44:46.246] iteration:27650  t-loss:0.1416, loss-lb:0.0675, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:44:46.438] iteration:27651  t-loss:0.1510, loss-lb:0.0721, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:44:46.630] iteration:27652  t-loss:0.1331, loss-lb:0.0680, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:44:46.823] iteration:27653  t-loss:0.1342, loss-lb:0.0700, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:44:47.015] iteration:27654  t-loss:0.1409, loss-lb:0.0698, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:44:47.207] iteration:27655  t-loss:0.1505, loss-lb:0.0747, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:44:47.401] iteration:27656  t-loss:0.1406, loss-lb:0.0638, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:44:47.593] iteration:27657  t-loss:0.1448, loss-lb:0.0712, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:44:47.785] iteration:27658  t-loss:0.1425, loss-lb:0.0725, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:44:47.978] iteration:27659  t-loss:0.2043, loss-lb:0.0680, loss-ulb:0.0682, weight:2.00, lr:0.0001
[12:44:48.170] iteration:27660  t-loss:0.1389, loss-lb:0.0650, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:44:48.363] iteration:27661  t-loss:0.1382, loss-lb:0.0626, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:44:48.555] iteration:27662  t-loss:0.1465, loss-lb:0.0765, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:44:48.747] iteration:27663  t-loss:0.1394, loss-lb:0.0734, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:44:48.940] iteration:27664  t-loss:0.1338, loss-lb:0.0693, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:44:49.134] iteration:27665  t-loss:0.1554, loss-lb:0.0694, loss-ulb:0.0430, weight:2.00, lr:0.0001
[12:44:49.340] iteration:27666  t-loss:0.1403, loss-lb:0.0725, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:44:49.539] iteration:27667  t-loss:0.1366, loss-lb:0.0666, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:44:49.731] iteration:27668  t-loss:0.1443, loss-lb:0.0657, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:44:49.924] iteration:27669  t-loss:0.1429, loss-lb:0.0722, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:44:50.116] iteration:27670  t-loss:0.1280, loss-lb:0.0630, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:44:50.308] iteration:27671  t-loss:0.1294, loss-lb:0.0625, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:44:50.501] iteration:27672  t-loss:0.1481, loss-lb:0.0703, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:44:50.694] iteration:27673  t-loss:0.1337, loss-lb:0.0671, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:44:50.886] iteration:27674  t-loss:0.1546, loss-lb:0.0706, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:44:51.079] iteration:27675  t-loss:0.1352, loss-lb:0.0673, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:44:51.272] iteration:27676  t-loss:0.1774, loss-lb:0.0710, loss-ulb:0.0532, weight:2.00, lr:0.0001
[12:44:51.466] iteration:27677  t-loss:0.2526, loss-lb:0.0684, loss-ulb:0.0921, weight:2.00, lr:0.0001
[12:44:51.658] iteration:27678  t-loss:0.1503, loss-lb:0.0770, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:44:51.850] iteration:27679  t-loss:0.1447, loss-lb:0.0750, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:44:52.042] iteration:27680  t-loss:0.1299, loss-lb:0.0699, loss-ulb:0.0300, weight:2.00, lr:0.0001
[12:44:52.235] iteration:27681  t-loss:0.1417, loss-lb:0.0654, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:44:52.427] iteration:27682  t-loss:0.1517, loss-lb:0.0624, loss-ulb:0.0447, weight:2.00, lr:0.0001
[12:44:52.619] iteration:27683  t-loss:0.1454, loss-lb:0.0718, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:44:52.811] iteration:27684  t-loss:0.1533, loss-lb:0.0718, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:44:53.003] iteration:27685  t-loss:0.1338, loss-lb:0.0684, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:44:53.195] iteration:27686  t-loss:0.1345, loss-lb:0.0702, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:44:53.386] iteration:27687  t-loss:0.1385, loss-lb:0.0653, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:44:53.579] iteration:27688  t-loss:0.1442, loss-lb:0.0745, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:44:53.775] iteration:27689  t-loss:0.1363, loss-lb:0.0699, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:44:53.970] iteration:27690  t-loss:0.1413, loss-lb:0.0626, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:44:54.167] iteration:27691  t-loss:0.1282, loss-lb:0.0655, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:44:54.361] iteration:27692  t-loss:0.1816, loss-lb:0.0698, loss-ulb:0.0559, weight:2.00, lr:0.0001
[12:44:54.553] iteration:27693  t-loss:0.1601, loss-lb:0.0846, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:44:54.745] iteration:27694  t-loss:0.1325, loss-lb:0.0698, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:44:54.938] iteration:27695  t-loss:0.1569, loss-lb:0.0684, loss-ulb:0.0443, weight:2.00, lr:0.0001
[12:44:55.131] iteration:27696  t-loss:0.1385, loss-lb:0.0685, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:44:55.325] iteration:27697  t-loss:0.1358, loss-lb:0.0654, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:44:55.517] iteration:27698  t-loss:0.1574, loss-lb:0.0695, loss-ulb:0.0439, weight:2.00, lr:0.0001
[12:44:55.709] iteration:27699  t-loss:0.1393, loss-lb:0.0761, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:44:55.901] iteration:27700  t-loss:0.1470, loss-lb:0.0710, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:44:56.094] iteration:27701  t-loss:0.1444, loss-lb:0.0699, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:44:56.286] iteration:27702  t-loss:0.1522, loss-lb:0.0650, loss-ulb:0.0436, weight:2.00, lr:0.0001
[12:44:56.479] iteration:27703  t-loss:0.1264, loss-lb:0.0714, loss-ulb:0.0275, weight:2.00, lr:0.0001
[12:44:56.672] iteration:27704  t-loss:0.1222, loss-lb:0.0680, loss-ulb:0.0271, weight:2.00, lr:0.0001
[12:44:56.864] iteration:27705  t-loss:0.1542, loss-lb:0.0681, loss-ulb:0.0430, weight:2.00, lr:0.0001
[12:44:57.057] iteration:27706  t-loss:0.2146, loss-lb:0.0699, loss-ulb:0.0723, weight:2.00, lr:0.0001
[12:44:57.248] iteration:27707  t-loss:0.1481, loss-lb:0.0778, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:44:57.440] iteration:27708  t-loss:0.1322, loss-lb:0.0686, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:44:57.633] iteration:27709  t-loss:0.1362, loss-lb:0.0673, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:44:57.825] iteration:27710  t-loss:0.1374, loss-lb:0.0717, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:44:58.019] iteration:27711  t-loss:0.2102, loss-lb:0.0660, loss-ulb:0.0721, weight:2.00, lr:0.0001
[12:44:58.210] iteration:27712  t-loss:0.1400, loss-lb:0.0725, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:44:58.402] iteration:27713  t-loss:0.1514, loss-lb:0.0702, loss-ulb:0.0406, weight:2.00, lr:0.0001
[12:44:58.594] iteration:27714  t-loss:0.1358, loss-lb:0.0685, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:44:58.786] iteration:27715  t-loss:0.1453, loss-lb:0.0714, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:44:58.979] iteration:27716  t-loss:0.1536, loss-lb:0.0716, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:44:59.171] iteration:27717  t-loss:0.1274, loss-lb:0.0641, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:44:59.362] iteration:27718  t-loss:0.1403, loss-lb:0.0716, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:44:59.555] iteration:27719  t-loss:0.1479, loss-lb:0.0723, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:44:59.746] iteration:27720  t-loss:0.1370, loss-lb:0.0697, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:44:59.938] iteration:27721  t-loss:0.1481, loss-lb:0.0717, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:45:00.131] iteration:27722  t-loss:0.1316, loss-lb:0.0602, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:45:00.324] iteration:27723  t-loss:0.1472, loss-lb:0.0716, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:45:00.517] iteration:27724  t-loss:0.1441, loss-lb:0.0700, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:45:00.709] iteration:27725  t-loss:0.1546, loss-lb:0.0696, loss-ulb:0.0425, weight:2.00, lr:0.0001
[12:45:00.902] iteration:27726  t-loss:0.1564, loss-lb:0.0757, loss-ulb:0.0404, weight:2.00, lr:0.0001
[12:45:01.094] iteration:27727  t-loss:0.1929, loss-lb:0.0713, loss-ulb:0.0608, weight:2.00, lr:0.0001
[12:45:01.286] iteration:27728  t-loss:0.1762, loss-lb:0.0722, loss-ulb:0.0520, weight:2.00, lr:0.0001
[12:45:01.477] iteration:27729  t-loss:0.1464, loss-lb:0.0666, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:45:01.667] iteration:27730  t-loss:0.1662, loss-lb:0.0776, loss-ulb:0.0443, weight:2.00, lr:0.0001
[12:45:01.857] iteration:27731  t-loss:0.1348, loss-lb:0.0670, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:45:02.048] iteration:27732  t-loss:0.1482, loss-lb:0.0704, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:45:02.237] iteration:27733  t-loss:0.1359, loss-lb:0.0645, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:45:02.427] iteration:27734  t-loss:0.1469, loss-lb:0.0692, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:45:14.587]  <<Test>> - Ep:282  - mean_dice/mean_h95 - S:89.68/1.38, Best-S:90.99, T:89.59/1.45, Best-T:90.48
[12:45:14.587]           - AvgLoss(lb/ulb/all):0.0696/0.0396/0.1491
[12:45:15.130] iteration:27735  t-loss:0.1324, loss-lb:0.0654, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:45:15.332] iteration:27736  t-loss:0.1290, loss-lb:0.0626, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:45:15.527] iteration:27737  t-loss:0.1370, loss-lb:0.0639, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:45:15.726] iteration:27738  t-loss:0.1710, loss-lb:0.0717, loss-ulb:0.0496, weight:2.00, lr:0.0001
[12:45:15.922] iteration:27739  t-loss:0.1340, loss-lb:0.0730, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:45:16.117] iteration:27740  t-loss:0.1468, loss-lb:0.0808, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:45:16.312] iteration:27741  t-loss:0.1505, loss-lb:0.0672, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:45:16.503] iteration:27742  t-loss:0.1345, loss-lb:0.0696, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:45:16.696] iteration:27743  t-loss:0.1538, loss-lb:0.0670, loss-ulb:0.0434, weight:2.00, lr:0.0001
[12:45:16.889] iteration:27744  t-loss:0.1477, loss-lb:0.0666, loss-ulb:0.0405, weight:2.00, lr:0.0001
[12:45:17.082] iteration:27745  t-loss:0.1493, loss-lb:0.0699, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:45:17.274] iteration:27746  t-loss:0.1389, loss-lb:0.0680, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:45:17.467] iteration:27747  t-loss:0.1318, loss-lb:0.0676, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:45:17.659] iteration:27748  t-loss:0.1323, loss-lb:0.0658, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:45:17.851] iteration:27749  t-loss:0.1449, loss-lb:0.0729, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:45:18.044] iteration:27750  t-loss:0.1202, loss-lb:0.0657, loss-ulb:0.0272, weight:2.00, lr:0.0001
[12:45:18.238] iteration:27751  t-loss:0.1774, loss-lb:0.0760, loss-ulb:0.0507, weight:2.00, lr:0.0001
[12:45:18.431] iteration:27752  t-loss:0.1479, loss-lb:0.0720, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:45:18.624] iteration:27753  t-loss:0.1386, loss-lb:0.0736, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:45:18.817] iteration:27754  t-loss:0.1449, loss-lb:0.0716, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:45:19.010] iteration:27755  t-loss:0.1353, loss-lb:0.0643, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:45:19.202] iteration:27756  t-loss:0.1304, loss-lb:0.0685, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:45:19.394] iteration:27757  t-loss:0.1279, loss-lb:0.0627, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:45:19.595] iteration:27758  t-loss:0.1347, loss-lb:0.0684, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:45:19.787] iteration:27759  t-loss:0.1421, loss-lb:0.0760, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:45:19.978] iteration:27760  t-loss:0.1524, loss-lb:0.0708, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:45:20.171] iteration:27761  t-loss:0.2064, loss-lb:0.0698, loss-ulb:0.0683, weight:2.00, lr:0.0001
[12:45:20.368] iteration:27762  t-loss:0.1549, loss-lb:0.0728, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:45:20.562] iteration:27763  t-loss:0.1440, loss-lb:0.0704, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:45:20.754] iteration:27764  t-loss:0.1413, loss-lb:0.0700, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:45:20.945] iteration:27765  t-loss:0.1514, loss-lb:0.0659, loss-ulb:0.0428, weight:2.00, lr:0.0001
[12:45:21.137] iteration:27766  t-loss:0.1402, loss-lb:0.0812, loss-ulb:0.0295, weight:2.00, lr:0.0001
[12:45:21.329] iteration:27767  t-loss:0.1326, loss-lb:0.0684, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:45:21.520] iteration:27768  t-loss:0.1254, loss-lb:0.0619, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:45:21.714] iteration:27769  t-loss:0.1410, loss-lb:0.0717, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:45:21.907] iteration:27770  t-loss:0.1574, loss-lb:0.0750, loss-ulb:0.0412, weight:2.00, lr:0.0001
[12:45:22.112] iteration:27771  t-loss:0.1526, loss-lb:0.0771, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:45:22.309] iteration:27772  t-loss:0.1401, loss-lb:0.0596, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:45:22.502] iteration:27773  t-loss:0.1301, loss-lb:0.0711, loss-ulb:0.0295, weight:2.00, lr:0.0001
[12:45:22.695] iteration:27774  t-loss:0.1383, loss-lb:0.0672, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:45:22.888] iteration:27775  t-loss:0.1866, loss-lb:0.0654, loss-ulb:0.0606, weight:2.00, lr:0.0001
[12:45:23.080] iteration:27776  t-loss:0.1677, loss-lb:0.0743, loss-ulb:0.0467, weight:2.00, lr:0.0001
[12:45:23.274] iteration:27777  t-loss:0.1422, loss-lb:0.0771, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:45:23.467] iteration:27778  t-loss:0.1347, loss-lb:0.0685, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:45:23.658] iteration:27779  t-loss:0.1610, loss-lb:0.0774, loss-ulb:0.0418, weight:2.00, lr:0.0001
[12:45:23.853] iteration:27780  t-loss:0.1825, loss-lb:0.0652, loss-ulb:0.0586, weight:2.00, lr:0.0001
[12:45:24.044] iteration:27781  t-loss:0.1450, loss-lb:0.0729, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:45:24.235] iteration:27782  t-loss:0.1484, loss-lb:0.0655, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:45:24.426] iteration:27783  t-loss:0.1475, loss-lb:0.0702, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:45:24.617] iteration:27784  t-loss:0.1422, loss-lb:0.0710, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:45:24.808] iteration:27785  t-loss:0.1332, loss-lb:0.0697, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:45:25.000] iteration:27786  t-loss:0.1448, loss-lb:0.0738, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:45:25.193] iteration:27787  t-loss:0.1559, loss-lb:0.0709, loss-ulb:0.0425, weight:2.00, lr:0.0001
[12:45:25.383] iteration:27788  t-loss:0.1697, loss-lb:0.0743, loss-ulb:0.0477, weight:2.00, lr:0.0001
[12:45:25.575] iteration:27789  t-loss:0.1506, loss-lb:0.0642, loss-ulb:0.0432, weight:2.00, lr:0.0001
[12:45:25.766] iteration:27790  t-loss:0.1562, loss-lb:0.0713, loss-ulb:0.0424, weight:2.00, lr:0.0001
[12:45:25.959] iteration:27791  t-loss:0.1434, loss-lb:0.0673, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:45:26.152] iteration:27792  t-loss:0.1334, loss-lb:0.0630, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:45:26.345] iteration:27793  t-loss:0.1302, loss-lb:0.0700, loss-ulb:0.0301, weight:2.00, lr:0.0001
[12:45:26.540] iteration:27794  t-loss:0.1558, loss-lb:0.0689, loss-ulb:0.0434, weight:2.00, lr:0.0001
[12:45:26.732] iteration:27795  t-loss:0.1360, loss-lb:0.0684, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:45:26.926] iteration:27796  t-loss:0.1334, loss-lb:0.0727, loss-ulb:0.0304, weight:2.00, lr:0.0001
[12:45:27.119] iteration:27797  t-loss:0.1366, loss-lb:0.0641, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:45:27.311] iteration:27798  t-loss:0.1356, loss-lb:0.0715, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:45:27.504] iteration:27799  t-loss:0.1375, loss-lb:0.0721, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:45:27.696] iteration:27800  t-loss:0.1480, loss-lb:0.0762, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:45:27.889] iteration:27801  t-loss:0.1370, loss-lb:0.0757, loss-ulb:0.0307, weight:2.00, lr:0.0001
[12:45:28.080] iteration:27802  t-loss:0.1449, loss-lb:0.0729, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:45:28.285] iteration:27803  t-loss:0.1692, loss-lb:0.0778, loss-ulb:0.0457, weight:2.00, lr:0.0001
[12:45:28.477] iteration:27804  t-loss:0.1379, loss-lb:0.0692, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:45:28.668] iteration:27805  t-loss:0.1310, loss-lb:0.0709, loss-ulb:0.0300, weight:2.00, lr:0.0001
[12:45:28.860] iteration:27806  t-loss:0.1487, loss-lb:0.0732, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:45:29.051] iteration:27807  t-loss:0.1427, loss-lb:0.0668, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:45:29.244] iteration:27808  t-loss:0.1497, loss-lb:0.0808, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:45:29.436] iteration:27809  t-loss:0.1228, loss-lb:0.0622, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:45:29.628] iteration:27810  t-loss:0.1464, loss-lb:0.0776, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:45:29.819] iteration:27811  t-loss:0.1346, loss-lb:0.0678, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:45:30.012] iteration:27812  t-loss:0.1426, loss-lb:0.0681, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:45:30.205] iteration:27813  t-loss:0.1488, loss-lb:0.0683, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:45:30.397] iteration:27814  t-loss:0.1445, loss-lb:0.0683, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:45:30.589] iteration:27815  t-loss:0.1358, loss-lb:0.0664, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:45:30.781] iteration:27816  t-loss:0.1507, loss-lb:0.0707, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:45:30.973] iteration:27817  t-loss:0.1391, loss-lb:0.0683, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:45:31.165] iteration:27818  t-loss:0.1458, loss-lb:0.0679, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:45:31.358] iteration:27819  t-loss:0.1501, loss-lb:0.0747, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:45:31.550] iteration:27820  t-loss:0.1421, loss-lb:0.0775, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:45:31.742] iteration:27821  t-loss:0.1219, loss-lb:0.0672, loss-ulb:0.0274, weight:2.00, lr:0.0001
[12:45:31.935] iteration:27822  t-loss:0.1223, loss-lb:0.0600, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:45:32.128] iteration:27823  t-loss:0.1492, loss-lb:0.0740, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:45:32.320] iteration:27824  t-loss:0.1451, loss-lb:0.0705, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:45:32.512] iteration:27825  t-loss:0.1466, loss-lb:0.0716, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:45:32.703] iteration:27826  t-loss:0.1450, loss-lb:0.0768, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:45:32.894] iteration:27827  t-loss:0.1460, loss-lb:0.0774, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:45:33.085] iteration:27828  t-loss:0.1510, loss-lb:0.0666, loss-ulb:0.0422, weight:2.00, lr:0.0001
[12:45:33.275] iteration:27829  t-loss:0.1323, loss-lb:0.0648, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:45:33.466] iteration:27830  t-loss:0.1517, loss-lb:0.0738, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:45:33.658] iteration:27831  t-loss:0.2022, loss-lb:0.0693, loss-ulb:0.0665, weight:2.00, lr:0.0001
[12:45:33.847] iteration:27832  t-loss:0.1342, loss-lb:0.0702, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:45:34.442] iteration:27833  t-loss:0.1707, loss-lb:0.0698, loss-ulb:0.0504, weight:2.00, lr:0.0001
[12:45:34.636] iteration:27834  t-loss:0.1462, loss-lb:0.0780, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:45:34.828] iteration:27835  t-loss:0.1410, loss-lb:0.0661, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:45:35.021] iteration:27836  t-loss:0.1403, loss-lb:0.0728, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:45:35.212] iteration:27837  t-loss:0.1333, loss-lb:0.0718, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:45:35.403] iteration:27838  t-loss:0.1422, loss-lb:0.0704, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:45:35.595] iteration:27839  t-loss:0.1302, loss-lb:0.0692, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:45:35.786] iteration:27840  t-loss:0.1431, loss-lb:0.0717, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:45:35.979] iteration:27841  t-loss:0.1731, loss-lb:0.0667, loss-ulb:0.0532, weight:2.00, lr:0.0001
[12:45:36.171] iteration:27842  t-loss:0.2424, loss-lb:0.0669, loss-ulb:0.0877, weight:2.00, lr:0.0001
[12:45:36.363] iteration:27843  t-loss:0.1355, loss-lb:0.0676, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:45:36.555] iteration:27844  t-loss:0.1508, loss-lb:0.0674, loss-ulb:0.0417, weight:2.00, lr:0.0001
[12:45:36.747] iteration:27845  t-loss:0.1377, loss-lb:0.0766, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:45:36.958] iteration:27846  t-loss:0.1318, loss-lb:0.0715, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:45:37.155] iteration:27847  t-loss:0.2302, loss-lb:0.0686, loss-ulb:0.0808, weight:2.00, lr:0.0001
[12:45:37.348] iteration:27848  t-loss:0.1409, loss-lb:0.0661, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:45:37.541] iteration:27849  t-loss:0.1352, loss-lb:0.0675, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:45:37.733] iteration:27850  t-loss:0.1539, loss-lb:0.0687, loss-ulb:0.0426, weight:2.00, lr:0.0001
[12:45:37.927] iteration:27851  t-loss:0.1445, loss-lb:0.0673, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:45:38.119] iteration:27852  t-loss:0.1456, loss-lb:0.0753, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:45:38.313] iteration:27853  t-loss:0.1339, loss-lb:0.0756, loss-ulb:0.0292, weight:2.00, lr:0.0001
[12:45:38.506] iteration:27854  t-loss:0.1393, loss-lb:0.0701, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:45:38.699] iteration:27855  t-loss:0.1401, loss-lb:0.0678, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:45:38.891] iteration:27856  t-loss:0.1437, loss-lb:0.0678, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:45:39.083] iteration:27857  t-loss:0.1562, loss-lb:0.0817, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:45:39.277] iteration:27858  t-loss:0.1502, loss-lb:0.0772, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:45:39.470] iteration:27859  t-loss:0.1453, loss-lb:0.0725, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:45:39.662] iteration:27860  t-loss:0.1489, loss-lb:0.0670, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:45:39.854] iteration:27861  t-loss:0.1378, loss-lb:0.0635, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:45:40.047] iteration:27862  t-loss:0.1402, loss-lb:0.0682, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:45:40.240] iteration:27863  t-loss:0.1294, loss-lb:0.0654, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:45:40.433] iteration:27864  t-loss:0.1544, loss-lb:0.0692, loss-ulb:0.0426, weight:2.00, lr:0.0001
[12:45:40.625] iteration:27865  t-loss:0.1565, loss-lb:0.0723, loss-ulb:0.0421, weight:2.00, lr:0.0001
[12:45:40.818] iteration:27866  t-loss:0.1302, loss-lb:0.0616, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:45:41.010] iteration:27867  t-loss:0.1417, loss-lb:0.0647, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:45:41.202] iteration:27868  t-loss:0.1411, loss-lb:0.0684, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:45:41.396] iteration:27869  t-loss:0.1433, loss-lb:0.0735, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:45:41.589] iteration:27870  t-loss:0.1457, loss-lb:0.0712, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:45:41.781] iteration:27871  t-loss:0.1411, loss-lb:0.0755, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:45:41.973] iteration:27872  t-loss:0.1465, loss-lb:0.0699, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:45:42.165] iteration:27873  t-loss:0.1465, loss-lb:0.0668, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:45:42.357] iteration:27874  t-loss:0.1477, loss-lb:0.0758, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:45:42.551] iteration:27875  t-loss:0.1468, loss-lb:0.0700, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:45:42.743] iteration:27876  t-loss:0.1173, loss-lb:0.0590, loss-ulb:0.0291, weight:2.00, lr:0.0001
[12:45:42.935] iteration:27877  t-loss:0.1418, loss-lb:0.0712, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:45:43.128] iteration:27878  t-loss:0.1383, loss-lb:0.0662, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:45:43.320] iteration:27879  t-loss:0.1369, loss-lb:0.0670, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:45:43.513] iteration:27880  t-loss:0.1571, loss-lb:0.0720, loss-ulb:0.0425, weight:2.00, lr:0.0001
[12:45:43.705] iteration:27881  t-loss:0.1373, loss-lb:0.0690, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:45:43.899] iteration:27882  t-loss:0.1433, loss-lb:0.0677, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:45:44.092] iteration:27883  t-loss:0.1327, loss-lb:0.0695, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:45:44.284] iteration:27884  t-loss:0.1341, loss-lb:0.0709, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:45:44.478] iteration:27885  t-loss:0.1368, loss-lb:0.0685, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:45:44.671] iteration:27886  t-loss:0.1523, loss-lb:0.0730, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:45:44.863] iteration:27887  t-loss:0.1307, loss-lb:0.0728, loss-ulb:0.0290, weight:2.00, lr:0.0001
[12:45:45.055] iteration:27888  t-loss:0.1297, loss-lb:0.0660, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:45:45.248] iteration:27889  t-loss:0.1360, loss-lb:0.0718, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:45:45.440] iteration:27890  t-loss:0.1388, loss-lb:0.0649, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:45:45.631] iteration:27891  t-loss:0.1292, loss-lb:0.0674, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:45:45.824] iteration:27892  t-loss:0.1724, loss-lb:0.0714, loss-ulb:0.0505, weight:2.00, lr:0.0001
[12:45:46.017] iteration:27893  t-loss:0.1562, loss-lb:0.0792, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:45:46.209] iteration:27894  t-loss:0.1292, loss-lb:0.0611, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:45:46.401] iteration:27895  t-loss:0.1245, loss-lb:0.0670, loss-ulb:0.0287, weight:2.00, lr:0.0001
[12:45:46.594] iteration:27896  t-loss:0.1306, loss-lb:0.0666, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:45:46.787] iteration:27897  t-loss:0.1535, loss-lb:0.0762, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:45:46.980] iteration:27898  t-loss:0.1528, loss-lb:0.0705, loss-ulb:0.0412, weight:2.00, lr:0.0001
[12:45:47.172] iteration:27899  t-loss:0.1457, loss-lb:0.0786, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:45:47.365] iteration:27900  t-loss:0.1435, loss-lb:0.0652, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:45:47.559] iteration:27901  t-loss:0.1392, loss-lb:0.0724, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:45:47.751] iteration:27902  t-loss:0.1380, loss-lb:0.0658, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:45:47.943] iteration:27903  t-loss:0.1495, loss-lb:0.0753, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:45:48.135] iteration:27904  t-loss:0.1481, loss-lb:0.0756, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:45:48.328] iteration:27905  t-loss:0.1585, loss-lb:0.0798, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:45:48.520] iteration:27906  t-loss:0.1475, loss-lb:0.0711, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:45:48.713] iteration:27907  t-loss:0.1500, loss-lb:0.0643, loss-ulb:0.0428, weight:2.00, lr:0.0001
[12:45:48.906] iteration:27908  t-loss:0.1454, loss-lb:0.0709, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:45:49.099] iteration:27909  t-loss:0.1406, loss-lb:0.0674, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:45:49.292] iteration:27910  t-loss:0.1357, loss-lb:0.0671, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:45:49.485] iteration:27911  t-loss:0.1388, loss-lb:0.0701, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:45:49.677] iteration:27912  t-loss:0.1390, loss-lb:0.0636, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:45:49.870] iteration:27913  t-loss:0.1328, loss-lb:0.0645, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:45:50.063] iteration:27914  t-loss:0.1397, loss-lb:0.0687, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:45:50.256] iteration:27915  t-loss:0.1370, loss-lb:0.0697, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:45:50.449] iteration:27916  t-loss:0.1424, loss-lb:0.0699, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:45:50.643] iteration:27917  t-loss:0.1442, loss-lb:0.0726, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:45:50.835] iteration:27918  t-loss:0.1377, loss-lb:0.0615, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:45:51.028] iteration:27919  t-loss:0.1568, loss-lb:0.0748, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:45:51.220] iteration:27920  t-loss:0.1353, loss-lb:0.0642, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:45:51.413] iteration:27921  t-loss:0.1467, loss-lb:0.0682, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:45:51.606] iteration:27922  t-loss:0.1451, loss-lb:0.0771, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:45:51.797] iteration:27923  t-loss:0.1595, loss-lb:0.0755, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:45:51.989] iteration:27924  t-loss:0.1453, loss-lb:0.0772, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:45:52.179] iteration:27925  t-loss:0.1304, loss-lb:0.0646, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:45:52.370] iteration:27926  t-loss:0.1488, loss-lb:0.0765, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:45:52.561] iteration:27927  t-loss:0.1332, loss-lb:0.0704, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:45:52.752] iteration:27928  t-loss:0.1450, loss-lb:0.0709, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:45:52.944] iteration:27929  t-loss:0.1409, loss-lb:0.0640, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:45:53.134] iteration:27930  t-loss:0.1345, loss-lb:0.0685, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:46:05.831]  <<Test>> - Ep:284  - mean_dice/mean_h95 - S:89.85/1.36, Best-S:90.99, T:89.61/1.40, Best-T:90.48
[12:46:05.831]           - AvgLoss(lb/ulb/all):0.0699/0.0360/0.1417
[12:46:06.360] iteration:27931  t-loss:0.1343, loss-lb:0.0726, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:46:06.559] iteration:27932  t-loss:0.1478, loss-lb:0.0735, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:46:06.751] iteration:27933  t-loss:0.1356, loss-lb:0.0675, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:46:06.943] iteration:27934  t-loss:0.1375, loss-lb:0.0679, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:46:07.136] iteration:27935  t-loss:0.1329, loss-lb:0.0673, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:46:07.329] iteration:27936  t-loss:0.1467, loss-lb:0.0697, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:46:07.523] iteration:27937  t-loss:0.1337, loss-lb:0.0634, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:46:07.715] iteration:27938  t-loss:0.1640, loss-lb:0.0671, loss-ulb:0.0484, weight:2.00, lr:0.0001
[12:46:07.908] iteration:27939  t-loss:0.1557, loss-lb:0.0737, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:46:08.101] iteration:27940  t-loss:0.1537, loss-lb:0.0715, loss-ulb:0.0411, weight:2.00, lr:0.0001
[12:46:08.294] iteration:27941  t-loss:0.1401, loss-lb:0.0704, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:46:08.487] iteration:27942  t-loss:0.1388, loss-lb:0.0660, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:46:08.682] iteration:27943  t-loss:0.1428, loss-lb:0.0722, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:46:08.875] iteration:27944  t-loss:0.1473, loss-lb:0.0728, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:46:09.068] iteration:27945  t-loss:0.1350, loss-lb:0.0641, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:46:09.261] iteration:27946  t-loss:0.1457, loss-lb:0.0692, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:46:09.455] iteration:27947  t-loss:0.1585, loss-lb:0.0723, loss-ulb:0.0431, weight:2.00, lr:0.0001
[12:46:09.648] iteration:27948  t-loss:0.1423, loss-lb:0.0736, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:46:09.842] iteration:27949  t-loss:0.1429, loss-lb:0.0705, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:46:10.034] iteration:27950  t-loss:0.1304, loss-lb:0.0661, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:46:10.228] iteration:27951  t-loss:0.1658, loss-lb:0.0759, loss-ulb:0.0450, weight:2.00, lr:0.0001
[12:46:10.422] iteration:27952  t-loss:0.1486, loss-lb:0.0691, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:46:10.615] iteration:27953  t-loss:0.1478, loss-lb:0.0742, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:46:10.807] iteration:27954  t-loss:0.1363, loss-lb:0.0772, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:46:10.999] iteration:27955  t-loss:0.1416, loss-lb:0.0714, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:46:11.192] iteration:27956  t-loss:0.1370, loss-lb:0.0723, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:46:11.384] iteration:27957  t-loss:0.1351, loss-lb:0.0637, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:46:11.576] iteration:27958  t-loss:0.1285, loss-lb:0.0626, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:46:11.770] iteration:27959  t-loss:0.1977, loss-lb:0.0745, loss-ulb:0.0616, weight:2.00, lr:0.0001
[12:46:11.963] iteration:27960  t-loss:0.1382, loss-lb:0.0788, loss-ulb:0.0297, weight:2.00, lr:0.0001
[12:46:12.155] iteration:27961  t-loss:0.1309, loss-lb:0.0613, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:46:12.348] iteration:27962  t-loss:0.1267, loss-lb:0.0655, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:46:12.541] iteration:27963  t-loss:0.3809, loss-lb:0.0668, loss-ulb:0.1571, weight:2.00, lr:0.0001
[12:46:12.734] iteration:27964  t-loss:0.1356, loss-lb:0.0689, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:46:12.926] iteration:27965  t-loss:0.1403, loss-lb:0.0671, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:46:13.120] iteration:27966  t-loss:0.1639, loss-lb:0.0744, loss-ulb:0.0447, weight:2.00, lr:0.0001
[12:46:13.312] iteration:27967  t-loss:0.1472, loss-lb:0.0796, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:46:13.504] iteration:27968  t-loss:0.1365, loss-lb:0.0653, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:46:13.696] iteration:27969  t-loss:0.1395, loss-lb:0.0702, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:46:13.889] iteration:27970  t-loss:0.1260, loss-lb:0.0672, loss-ulb:0.0294, weight:2.00, lr:0.0001
[12:46:14.081] iteration:27971  t-loss:0.1370, loss-lb:0.0704, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:46:14.274] iteration:27972  t-loss:0.1538, loss-lb:0.0706, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:46:14.467] iteration:27973  t-loss:0.1505, loss-lb:0.0757, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:46:14.660] iteration:27974  t-loss:0.1294, loss-lb:0.0640, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:46:14.853] iteration:27975  t-loss:0.1320, loss-lb:0.0645, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:46:15.047] iteration:27976  t-loss:0.1288, loss-lb:0.0635, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:46:15.240] iteration:27977  t-loss:0.1266, loss-lb:0.0626, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:46:15.433] iteration:27978  t-loss:0.1435, loss-lb:0.0648, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:46:15.625] iteration:27979  t-loss:0.1464, loss-lb:0.0797, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:46:15.817] iteration:27980  t-loss:0.1455, loss-lb:0.0769, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:46:16.010] iteration:27981  t-loss:0.1590, loss-lb:0.0660, loss-ulb:0.0465, weight:2.00, lr:0.0001
[12:46:16.203] iteration:27982  t-loss:0.1469, loss-lb:0.0760, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:46:16.396] iteration:27983  t-loss:0.1346, loss-lb:0.0677, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:46:16.587] iteration:27984  t-loss:0.1312, loss-lb:0.0656, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:46:16.779] iteration:27985  t-loss:0.1339, loss-lb:0.0658, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:46:16.973] iteration:27986  t-loss:0.1957, loss-lb:0.0708, loss-ulb:0.0624, weight:2.00, lr:0.0001
[12:46:17.164] iteration:27987  t-loss:0.1642, loss-lb:0.0801, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:46:17.358] iteration:27988  t-loss:0.2020, loss-lb:0.0751, loss-ulb:0.0634, weight:2.00, lr:0.0001
[12:46:17.551] iteration:27989  t-loss:0.1411, loss-lb:0.0701, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:46:17.743] iteration:27990  t-loss:0.1507, loss-lb:0.0706, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:46:17.935] iteration:27991  t-loss:0.1264, loss-lb:0.0631, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:46:18.127] iteration:27992  t-loss:0.1189, loss-lb:0.0598, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:46:18.320] iteration:27993  t-loss:0.1348, loss-lb:0.0673, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:46:18.512] iteration:27994  t-loss:0.1376, loss-lb:0.0679, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:46:18.705] iteration:27995  t-loss:0.1412, loss-lb:0.0746, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:46:18.896] iteration:27996  t-loss:0.1412, loss-lb:0.0640, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:46:19.088] iteration:27997  t-loss:0.1390, loss-lb:0.0700, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:46:19.281] iteration:27998  t-loss:0.1533, loss-lb:0.0723, loss-ulb:0.0405, weight:2.00, lr:0.0001
[12:46:19.475] iteration:27999  t-loss:0.1261, loss-lb:0.0674, loss-ulb:0.0294, weight:2.00, lr:0.0001
[12:46:19.667] iteration:28000  t-loss:0.1363, loss-lb:0.0622, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:46:19.860] iteration:28001  t-loss:0.1502, loss-lb:0.0800, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:46:20.053] iteration:28002  t-loss:0.1636, loss-lb:0.0744, loss-ulb:0.0446, weight:2.00, lr:0.0001
[12:46:20.245] iteration:28003  t-loss:0.1389, loss-lb:0.0666, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:46:20.438] iteration:28004  t-loss:0.1563, loss-lb:0.0808, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:46:20.631] iteration:28005  t-loss:0.1453, loss-lb:0.0661, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:46:20.824] iteration:28006  t-loss:0.1446, loss-lb:0.0639, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:46:21.017] iteration:28007  t-loss:0.1246, loss-lb:0.0631, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:46:21.210] iteration:28008  t-loss:0.1352, loss-lb:0.0714, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:46:21.403] iteration:28009  t-loss:0.3001, loss-lb:0.0743, loss-ulb:0.1129, weight:2.00, lr:0.0001
[12:46:21.595] iteration:28010  t-loss:0.1403, loss-lb:0.0728, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:46:21.787] iteration:28011  t-loss:0.1242, loss-lb:0.0646, loss-ulb:0.0298, weight:2.00, lr:0.0001
[12:46:21.980] iteration:28012  t-loss:0.1680, loss-lb:0.0788, loss-ulb:0.0446, weight:2.00, lr:0.0001
[12:46:22.174] iteration:28013  t-loss:0.2421, loss-lb:0.0691, loss-ulb:0.0865, weight:2.00, lr:0.0001
[12:46:22.366] iteration:28014  t-loss:0.1339, loss-lb:0.0658, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:46:22.558] iteration:28015  t-loss:0.1440, loss-lb:0.0702, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:46:22.750] iteration:28016  t-loss:0.1370, loss-lb:0.0652, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:46:22.942] iteration:28017  t-loss:0.1314, loss-lb:0.0667, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:46:23.135] iteration:28018  t-loss:0.1382, loss-lb:0.0741, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:46:23.328] iteration:28019  t-loss:0.1429, loss-lb:0.0705, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:46:23.522] iteration:28020  t-loss:0.1391, loss-lb:0.0664, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:46:23.714] iteration:28021  t-loss:0.1317, loss-lb:0.0656, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:46:23.905] iteration:28022  t-loss:0.1694, loss-lb:0.0731, loss-ulb:0.0482, weight:2.00, lr:0.0001
[12:46:24.095] iteration:28023  t-loss:0.1299, loss-lb:0.0685, loss-ulb:0.0307, weight:2.00, lr:0.0001
[12:46:24.286] iteration:28024  t-loss:0.1501, loss-lb:0.0636, loss-ulb:0.0432, weight:2.00, lr:0.0001
[12:46:24.476] iteration:28025  t-loss:0.1292, loss-lb:0.0656, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:46:24.667] iteration:28026  t-loss:0.1367, loss-lb:0.0759, loss-ulb:0.0304, weight:2.00, lr:0.0001
[12:46:24.858] iteration:28027  t-loss:0.1418, loss-lb:0.0660, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:46:25.049] iteration:28028  t-loss:0.1422, loss-lb:0.0740, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:46:25.630] iteration:28029  t-loss:0.1340, loss-lb:0.0681, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:46:25.830] iteration:28030  t-loss:0.1313, loss-lb:0.0677, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:46:26.023] iteration:28031  t-loss:0.1309, loss-lb:0.0662, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:46:26.214] iteration:28032  t-loss:0.1462, loss-lb:0.0753, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:46:26.407] iteration:28033  t-loss:0.1428, loss-lb:0.0749, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:46:26.600] iteration:28034  t-loss:0.1522, loss-lb:0.0757, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:46:26.793] iteration:28035  t-loss:0.1559, loss-lb:0.0717, loss-ulb:0.0421, weight:2.00, lr:0.0001
[12:46:26.986] iteration:28036  t-loss:0.2220, loss-lb:0.0650, loss-ulb:0.0785, weight:2.00, lr:0.0001
[12:46:27.179] iteration:28037  t-loss:0.1193, loss-lb:0.0590, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:46:27.372] iteration:28038  t-loss:0.1459, loss-lb:0.0642, loss-ulb:0.0409, weight:2.00, lr:0.0001
[12:46:27.577] iteration:28039  t-loss:0.1398, loss-lb:0.0648, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:46:27.774] iteration:28040  t-loss:0.1333, loss-lb:0.0748, loss-ulb:0.0293, weight:2.00, lr:0.0001
[12:46:27.970] iteration:28041  t-loss:0.1597, loss-lb:0.0709, loss-ulb:0.0444, weight:2.00, lr:0.0001
[12:46:28.163] iteration:28042  t-loss:0.1419, loss-lb:0.0697, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:46:28.355] iteration:28043  t-loss:0.1310, loss-lb:0.0613, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:46:28.547] iteration:28044  t-loss:0.1343, loss-lb:0.0693, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:46:28.739] iteration:28045  t-loss:0.1556, loss-lb:0.0716, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:46:28.931] iteration:28046  t-loss:0.1448, loss-lb:0.0708, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:46:29.123] iteration:28047  t-loss:0.1482, loss-lb:0.0785, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:46:29.315] iteration:28048  t-loss:0.1456, loss-lb:0.0664, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:46:29.507] iteration:28049  t-loss:0.1324, loss-lb:0.0673, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:46:29.699] iteration:28050  t-loss:0.1358, loss-lb:0.0657, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:46:29.892] iteration:28051  t-loss:0.1391, loss-lb:0.0732, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:46:30.083] iteration:28052  t-loss:0.1390, loss-lb:0.0680, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:46:30.275] iteration:28053  t-loss:0.1433, loss-lb:0.0710, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:46:30.466] iteration:28054  t-loss:0.1359, loss-lb:0.0667, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:46:30.659] iteration:28055  t-loss:0.1482, loss-lb:0.0728, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:46:30.850] iteration:28056  t-loss:0.1421, loss-lb:0.0742, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:46:31.042] iteration:28057  t-loss:0.1315, loss-lb:0.0657, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:46:31.234] iteration:28058  t-loss:0.1363, loss-lb:0.0649, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:46:31.426] iteration:28059  t-loss:0.1472, loss-lb:0.0642, loss-ulb:0.0415, weight:2.00, lr:0.0001
[12:46:31.617] iteration:28060  t-loss:0.1402, loss-lb:0.0688, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:46:31.810] iteration:28061  t-loss:0.1442, loss-lb:0.0691, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:46:32.002] iteration:28062  t-loss:0.1407, loss-lb:0.0660, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:46:32.194] iteration:28063  t-loss:0.1337, loss-lb:0.0696, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:46:32.386] iteration:28064  t-loss:0.1386, loss-lb:0.0672, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:46:32.579] iteration:28065  t-loss:0.1352, loss-lb:0.0772, loss-ulb:0.0290, weight:2.00, lr:0.0001
[12:46:32.771] iteration:28066  t-loss:0.1409, loss-lb:0.0759, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:46:32.963] iteration:28067  t-loss:0.1715, loss-lb:0.0715, loss-ulb:0.0500, weight:2.00, lr:0.0001
[12:46:33.155] iteration:28068  t-loss:0.1323, loss-lb:0.0664, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:46:33.347] iteration:28069  t-loss:0.1343, loss-lb:0.0678, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:46:33.540] iteration:28070  t-loss:0.1571, loss-lb:0.0779, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:46:33.732] iteration:28071  t-loss:0.1332, loss-lb:0.0700, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:46:33.924] iteration:28072  t-loss:0.1455, loss-lb:0.0662, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:46:34.118] iteration:28073  t-loss:0.1155, loss-lb:0.0580, loss-ulb:0.0287, weight:2.00, lr:0.0001
[12:46:34.310] iteration:28074  t-loss:0.1425, loss-lb:0.0683, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:46:34.501] iteration:28075  t-loss:0.1351, loss-lb:0.0624, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:46:34.693] iteration:28076  t-loss:0.1322, loss-lb:0.0665, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:46:34.885] iteration:28077  t-loss:0.1455, loss-lb:0.0713, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:46:35.078] iteration:28078  t-loss:0.1382, loss-lb:0.0680, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:46:35.270] iteration:28079  t-loss:0.1424, loss-lb:0.0691, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:46:35.461] iteration:28080  t-loss:0.1400, loss-lb:0.0673, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:46:35.653] iteration:28081  t-loss:0.1417, loss-lb:0.0694, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:46:35.846] iteration:28082  t-loss:0.1653, loss-lb:0.0732, loss-ulb:0.0460, weight:2.00, lr:0.0001
[12:46:36.037] iteration:28083  t-loss:0.1346, loss-lb:0.0612, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:46:36.228] iteration:28084  t-loss:0.1455, loss-lb:0.0766, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:46:36.419] iteration:28085  t-loss:0.1629, loss-lb:0.0965, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:46:36.612] iteration:28086  t-loss:0.1456, loss-lb:0.0695, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:46:36.802] iteration:28087  t-loss:0.1345, loss-lb:0.0702, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:46:36.993] iteration:28088  t-loss:0.1322, loss-lb:0.0689, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:46:37.185] iteration:28089  t-loss:0.1407, loss-lb:0.0634, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:46:37.377] iteration:28090  t-loss:0.1560, loss-lb:0.0738, loss-ulb:0.0411, weight:2.00, lr:0.0001
[12:46:37.569] iteration:28091  t-loss:0.1353, loss-lb:0.0634, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:46:37.760] iteration:28092  t-loss:0.1449, loss-lb:0.0718, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:46:37.952] iteration:28093  t-loss:0.1560, loss-lb:0.0731, loss-ulb:0.0415, weight:2.00, lr:0.0001
[12:46:38.146] iteration:28094  t-loss:0.1399, loss-lb:0.0723, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:46:38.339] iteration:28095  t-loss:0.1474, loss-lb:0.0707, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:46:38.535] iteration:28096  t-loss:0.1284, loss-lb:0.0643, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:46:38.730] iteration:28097  t-loss:0.1392, loss-lb:0.0692, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:46:38.923] iteration:28098  t-loss:0.1338, loss-lb:0.0670, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:46:39.117] iteration:28099  t-loss:0.1295, loss-lb:0.0729, loss-ulb:0.0283, weight:2.00, lr:0.0001
[12:46:39.308] iteration:28100  t-loss:0.1342, loss-lb:0.0731, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:46:39.500] iteration:28101  t-loss:0.1287, loss-lb:0.0699, loss-ulb:0.0294, weight:2.00, lr:0.0001
[12:46:39.692] iteration:28102  t-loss:0.1308, loss-lb:0.0677, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:46:39.884] iteration:28103  t-loss:0.1301, loss-lb:0.0661, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:46:40.077] iteration:28104  t-loss:0.1481, loss-lb:0.0802, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:46:40.269] iteration:28105  t-loss:0.1343, loss-lb:0.0688, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:46:40.461] iteration:28106  t-loss:0.1288, loss-lb:0.0668, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:46:40.652] iteration:28107  t-loss:0.1413, loss-lb:0.0688, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:46:40.844] iteration:28108  t-loss:0.1300, loss-lb:0.0651, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:46:41.035] iteration:28109  t-loss:0.1448, loss-lb:0.0631, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:46:41.227] iteration:28110  t-loss:0.1364, loss-lb:0.0748, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:46:41.419] iteration:28111  t-loss:0.1495, loss-lb:0.0666, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:46:41.611] iteration:28112  t-loss:0.1386, loss-lb:0.0659, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:46:41.803] iteration:28113  t-loss:0.1432, loss-lb:0.0703, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:46:41.995] iteration:28114  t-loss:0.1417, loss-lb:0.0688, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:46:42.186] iteration:28115  t-loss:0.1492, loss-lb:0.0712, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:46:42.378] iteration:28116  t-loss:0.1396, loss-lb:0.0727, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:46:42.571] iteration:28117  t-loss:0.2020, loss-lb:0.0713, loss-ulb:0.0653, weight:2.00, lr:0.0001
[12:46:42.763] iteration:28118  t-loss:0.1504, loss-lb:0.0707, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:46:42.955] iteration:28119  t-loss:0.1347, loss-lb:0.0716, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:46:43.146] iteration:28120  t-loss:0.1309, loss-lb:0.0724, loss-ulb:0.0293, weight:2.00, lr:0.0001
[12:46:43.338] iteration:28121  t-loss:0.2277, loss-lb:0.0698, loss-ulb:0.0790, weight:2.00, lr:0.0001
[12:46:43.529] iteration:28122  t-loss:0.1425, loss-lb:0.0783, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:46:43.719] iteration:28123  t-loss:0.1318, loss-lb:0.0667, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:46:43.911] iteration:28124  t-loss:0.1513, loss-lb:0.0657, loss-ulb:0.0428, weight:2.00, lr:0.0001
[12:46:44.101] iteration:28125  t-loss:0.1308, loss-lb:0.0662, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:46:44.293] iteration:28126  t-loss:0.1450, loss-lb:0.0656, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:46:56.388]  <<Test>> - Ep:286  - mean_dice/mean_h95 - S:89.86/1.33, Best-S:90.99, T:89.62/1.38, Best-T:90.48
[12:46:56.388]           - AvgLoss(lb/ulb/all):0.0695/0.0394/0.1481
[12:46:56.936] iteration:28127  t-loss:0.1462, loss-lb:0.0710, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:46:57.132] iteration:28128  t-loss:0.1467, loss-lb:0.0756, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:46:57.325] iteration:28129  t-loss:0.1395, loss-lb:0.0673, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:46:57.518] iteration:28130  t-loss:0.1383, loss-lb:0.0716, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:46:57.709] iteration:28131  t-loss:0.1420, loss-lb:0.0734, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:46:57.902] iteration:28132  t-loss:0.1381, loss-lb:0.0747, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:46:58.095] iteration:28133  t-loss:0.1348, loss-lb:0.0671, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:46:58.286] iteration:28134  t-loss:0.1500, loss-lb:0.0610, loss-ulb:0.0445, weight:2.00, lr:0.0001
[12:46:58.480] iteration:28135  t-loss:0.1365, loss-lb:0.0699, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:46:58.671] iteration:28136  t-loss:0.1269, loss-lb:0.0671, loss-ulb:0.0299, weight:2.00, lr:0.0001
[12:46:58.862] iteration:28137  t-loss:0.1424, loss-lb:0.0673, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:46:59.055] iteration:28138  t-loss:0.1484, loss-lb:0.0725, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:46:59.247] iteration:28139  t-loss:0.1948, loss-lb:0.0700, loss-ulb:0.0624, weight:2.00, lr:0.0001
[12:46:59.438] iteration:28140  t-loss:0.1431, loss-lb:0.0707, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:46:59.631] iteration:28141  t-loss:0.1307, loss-lb:0.0661, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:46:59.824] iteration:28142  t-loss:0.1399, loss-lb:0.0704, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:47:00.017] iteration:28143  t-loss:0.1500, loss-lb:0.0705, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:47:00.218] iteration:28144  t-loss:0.1473, loss-lb:0.0779, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:47:00.442] iteration:28145  t-loss:0.1360, loss-lb:0.0742, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:47:00.642] iteration:28146  t-loss:0.1465, loss-lb:0.0688, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:47:00.837] iteration:28147  t-loss:0.1379, loss-lb:0.0679, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:47:01.030] iteration:28148  t-loss:0.1328, loss-lb:0.0702, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:47:01.225] iteration:28149  t-loss:0.1727, loss-lb:0.0699, loss-ulb:0.0514, weight:2.00, lr:0.0001
[12:47:01.417] iteration:28150  t-loss:0.1516, loss-lb:0.0795, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:47:01.611] iteration:28151  t-loss:0.1483, loss-lb:0.0722, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:47:01.804] iteration:28152  t-loss:0.1615, loss-lb:0.0769, loss-ulb:0.0423, weight:2.00, lr:0.0001
[12:47:01.998] iteration:28153  t-loss:0.1386, loss-lb:0.0677, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:47:02.190] iteration:28154  t-loss:0.1408, loss-lb:0.0634, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:47:02.383] iteration:28155  t-loss:0.1398, loss-lb:0.0686, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:47:02.576] iteration:28156  t-loss:0.1482, loss-lb:0.0717, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:47:02.771] iteration:28157  t-loss:0.1400, loss-lb:0.0648, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:47:02.964] iteration:28158  t-loss:0.1420, loss-lb:0.0727, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:47:03.156] iteration:28159  t-loss:0.1383, loss-lb:0.0667, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:47:03.348] iteration:28160  t-loss:0.1283, loss-lb:0.0617, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:47:03.542] iteration:28161  t-loss:0.1773, loss-lb:0.0743, loss-ulb:0.0515, weight:2.00, lr:0.0001
[12:47:03.733] iteration:28162  t-loss:0.1389, loss-lb:0.0702, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:47:03.926] iteration:28163  t-loss:0.1424, loss-lb:0.0778, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:47:04.119] iteration:28164  t-loss:0.1452, loss-lb:0.0668, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:47:04.312] iteration:28165  t-loss:0.1452, loss-lb:0.0718, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:47:04.504] iteration:28166  t-loss:0.1412, loss-lb:0.0649, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:47:04.697] iteration:28167  t-loss:0.1310, loss-lb:0.0644, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:47:04.888] iteration:28168  t-loss:0.1454, loss-lb:0.0708, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:47:05.080] iteration:28169  t-loss:0.1533, loss-lb:0.0702, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:47:05.273] iteration:28170  t-loss:0.1427, loss-lb:0.0692, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:47:05.465] iteration:28171  t-loss:0.1645, loss-lb:0.0697, loss-ulb:0.0474, weight:2.00, lr:0.0001
[12:47:05.657] iteration:28172  t-loss:0.1478, loss-lb:0.0686, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:47:05.850] iteration:28173  t-loss:0.1270, loss-lb:0.0650, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:47:06.042] iteration:28174  t-loss:0.1363, loss-lb:0.0640, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:47:06.233] iteration:28175  t-loss:0.1419, loss-lb:0.0694, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:47:06.425] iteration:28176  t-loss:0.1306, loss-lb:0.0698, loss-ulb:0.0304, weight:2.00, lr:0.0001
[12:47:06.619] iteration:28177  t-loss:0.1365, loss-lb:0.0672, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:47:06.812] iteration:28178  t-loss:0.1619, loss-lb:0.0742, loss-ulb:0.0439, weight:2.00, lr:0.0001
[12:47:07.004] iteration:28179  t-loss:0.1592, loss-lb:0.0732, loss-ulb:0.0430, weight:2.00, lr:0.0001
[12:47:07.195] iteration:28180  t-loss:0.1730, loss-lb:0.0654, loss-ulb:0.0538, weight:2.00, lr:0.0001
[12:47:07.387] iteration:28181  t-loss:0.1467, loss-lb:0.0748, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:47:07.579] iteration:28182  t-loss:0.1602, loss-lb:0.0692, loss-ulb:0.0455, weight:2.00, lr:0.0001
[12:47:07.771] iteration:28183  t-loss:0.1568, loss-lb:0.0719, loss-ulb:0.0425, weight:2.00, lr:0.0001
[12:47:07.963] iteration:28184  t-loss:0.1298, loss-lb:0.0647, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:47:08.156] iteration:28185  t-loss:0.1424, loss-lb:0.0686, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:47:08.348] iteration:28186  t-loss:0.1422, loss-lb:0.0688, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:47:08.539] iteration:28187  t-loss:0.1312, loss-lb:0.0642, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:08.731] iteration:28188  t-loss:0.1376, loss-lb:0.0694, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:47:08.922] iteration:28189  t-loss:0.1406, loss-lb:0.0733, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:47:09.114] iteration:28190  t-loss:0.1530, loss-lb:0.0702, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:47:09.306] iteration:28191  t-loss:0.1583, loss-lb:0.0742, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:47:09.497] iteration:28192  t-loss:0.1379, loss-lb:0.0685, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:47:09.689] iteration:28193  t-loss:0.1322, loss-lb:0.0727, loss-ulb:0.0297, weight:2.00, lr:0.0001
[12:47:09.881] iteration:28194  t-loss:0.1278, loss-lb:0.0663, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:47:10.072] iteration:28195  t-loss:0.1329, loss-lb:0.0686, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:47:10.264] iteration:28196  t-loss:0.1829, loss-lb:0.0664, loss-ulb:0.0582, weight:2.00, lr:0.0001
[12:47:10.457] iteration:28197  t-loss:0.1370, loss-lb:0.0678, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:47:10.647] iteration:28198  t-loss:0.1399, loss-lb:0.0710, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:47:10.840] iteration:28199  t-loss:0.1358, loss-lb:0.0701, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:47:11.033] iteration:28200  t-loss:0.1335, loss-lb:0.0667, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:47:11.225] iteration:28201  t-loss:0.1312, loss-lb:0.0627, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:47:11.418] iteration:28202  t-loss:0.1452, loss-lb:0.0735, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:47:11.610] iteration:28203  t-loss:0.1327, loss-lb:0.0619, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:47:11.803] iteration:28204  t-loss:0.1440, loss-lb:0.0742, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:47:11.995] iteration:28205  t-loss:0.1727, loss-lb:0.0717, loss-ulb:0.0505, weight:2.00, lr:0.0001
[12:47:12.189] iteration:28206  t-loss:0.1402, loss-lb:0.0679, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:47:12.382] iteration:28207  t-loss:0.1497, loss-lb:0.0698, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:47:12.576] iteration:28208  t-loss:0.1838, loss-lb:0.0743, loss-ulb:0.0547, weight:2.00, lr:0.0001
[12:47:12.768] iteration:28209  t-loss:0.1424, loss-lb:0.0660, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:47:12.961] iteration:28210  t-loss:0.1408, loss-lb:0.0644, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:47:13.154] iteration:28211  t-loss:0.1347, loss-lb:0.0652, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:47:13.346] iteration:28212  t-loss:0.1281, loss-lb:0.0641, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:47:13.538] iteration:28213  t-loss:0.1393, loss-lb:0.0717, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:47:13.732] iteration:28214  t-loss:0.1512, loss-lb:0.0691, loss-ulb:0.0411, weight:2.00, lr:0.0001
[12:47:13.924] iteration:28215  t-loss:0.1539, loss-lb:0.0710, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:47:14.117] iteration:28216  t-loss:0.1488, loss-lb:0.0699, loss-ulb:0.0394, weight:2.00, lr:0.0001
[12:47:14.308] iteration:28217  t-loss:0.1365, loss-lb:0.0761, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:47:14.500] iteration:28218  t-loss:0.1445, loss-lb:0.0734, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:47:14.691] iteration:28219  t-loss:0.1357, loss-lb:0.0687, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:14.883] iteration:28220  t-loss:0.1370, loss-lb:0.0701, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:15.074] iteration:28221  t-loss:0.1397, loss-lb:0.0646, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:47:15.265] iteration:28222  t-loss:0.1433, loss-lb:0.0751, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:47:15.457] iteration:28223  t-loss:0.1444, loss-lb:0.0675, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:47:15.648] iteration:28224  t-loss:0.1395, loss-lb:0.0668, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:47:16.249] iteration:28225  t-loss:0.1446, loss-lb:0.0761, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:47:16.446] iteration:28226  t-loss:0.1425, loss-lb:0.0729, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:47:16.638] iteration:28227  t-loss:0.1392, loss-lb:0.0690, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:47:16.831] iteration:28228  t-loss:0.1420, loss-lb:0.0730, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:47:17.023] iteration:28229  t-loss:0.1387, loss-lb:0.0798, loss-ulb:0.0295, weight:2.00, lr:0.0001
[12:47:17.215] iteration:28230  t-loss:0.1328, loss-lb:0.0653, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:47:17.408] iteration:28231  t-loss:0.1368, loss-lb:0.0742, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:47:17.601] iteration:28232  t-loss:0.1279, loss-lb:0.0653, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:47:17.793] iteration:28233  t-loss:0.1467, loss-lb:0.0635, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:47:17.986] iteration:28234  t-loss:0.1404, loss-lb:0.0624, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:47:18.178] iteration:28235  t-loss:0.1433, loss-lb:0.0648, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:47:18.370] iteration:28236  t-loss:0.1357, loss-lb:0.0646, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:47:18.562] iteration:28237  t-loss:0.1470, loss-lb:0.0755, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:47:18.755] iteration:28238  t-loss:0.1513, loss-lb:0.0682, loss-ulb:0.0415, weight:2.00, lr:0.0001
[12:47:18.948] iteration:28239  t-loss:0.1646, loss-lb:0.0668, loss-ulb:0.0489, weight:2.00, lr:0.0001
[12:47:19.142] iteration:28240  t-loss:0.2112, loss-lb:0.0702, loss-ulb:0.0705, weight:2.00, lr:0.0001
[12:47:19.335] iteration:28241  t-loss:0.1428, loss-lb:0.0677, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:47:19.529] iteration:28242  t-loss:0.2124, loss-lb:0.0745, loss-ulb:0.0689, weight:2.00, lr:0.0001
[12:47:19.721] iteration:28243  t-loss:0.1444, loss-lb:0.0724, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:47:19.923] iteration:28244  t-loss:0.1451, loss-lb:0.0656, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:47:20.115] iteration:28245  t-loss:0.1458, loss-lb:0.0678, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:47:20.314] iteration:28246  t-loss:0.1560, loss-lb:0.0780, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:47:20.507] iteration:28247  t-loss:0.1415, loss-lb:0.0634, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:47:20.699] iteration:28248  t-loss:0.1487, loss-lb:0.0684, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:47:20.891] iteration:28249  t-loss:0.1762, loss-lb:0.0724, loss-ulb:0.0519, weight:2.00, lr:0.0001
[12:47:21.090] iteration:28250  t-loss:0.1666, loss-lb:0.0839, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:47:21.284] iteration:28251  t-loss:0.1368, loss-lb:0.0747, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:47:21.477] iteration:28252  t-loss:0.1792, loss-lb:0.0867, loss-ulb:0.0462, weight:2.00, lr:0.0001
[12:47:21.669] iteration:28253  t-loss:0.1344, loss-lb:0.0644, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:47:21.870] iteration:28254  t-loss:0.1509, loss-lb:0.0733, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:47:22.062] iteration:28255  t-loss:0.1391, loss-lb:0.0666, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:47:22.254] iteration:28256  t-loss:0.1326, loss-lb:0.0618, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:47:22.447] iteration:28257  t-loss:0.1335, loss-lb:0.0686, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:47:22.647] iteration:28258  t-loss:0.1321, loss-lb:0.0607, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:47:22.841] iteration:28259  t-loss:0.1325, loss-lb:0.0689, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:47:23.034] iteration:28260  t-loss:0.1292, loss-lb:0.0662, loss-ulb:0.0315, weight:2.00, lr:0.0001
[12:47:23.228] iteration:28261  t-loss:0.1555, loss-lb:0.0754, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:47:23.419] iteration:28262  t-loss:0.1393, loss-lb:0.0703, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:47:23.611] iteration:28263  t-loss:0.1423, loss-lb:0.0664, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:47:23.804] iteration:28264  t-loss:0.1267, loss-lb:0.0650, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:47:23.997] iteration:28265  t-loss:0.1332, loss-lb:0.0701, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:47:24.189] iteration:28266  t-loss:0.1365, loss-lb:0.0710, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:47:24.382] iteration:28267  t-loss:0.1272, loss-lb:0.0690, loss-ulb:0.0291, weight:2.00, lr:0.0001
[12:47:24.575] iteration:28268  t-loss:0.1401, loss-lb:0.0710, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:47:24.768] iteration:28269  t-loss:0.1437, loss-lb:0.0677, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:47:24.960] iteration:28270  t-loss:0.1640, loss-lb:0.0726, loss-ulb:0.0457, weight:2.00, lr:0.0001
[12:47:25.154] iteration:28271  t-loss:0.1420, loss-lb:0.0739, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:47:25.347] iteration:28272  t-loss:0.2660, loss-lb:0.0676, loss-ulb:0.0992, weight:2.00, lr:0.0001
[12:47:25.540] iteration:28273  t-loss:0.1498, loss-lb:0.0696, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:47:25.733] iteration:28274  t-loss:0.1504, loss-lb:0.0642, loss-ulb:0.0431, weight:2.00, lr:0.0001
[12:47:25.926] iteration:28275  t-loss:0.1392, loss-lb:0.0720, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:47:26.118] iteration:28276  t-loss:0.1359, loss-lb:0.0717, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:47:26.310] iteration:28277  t-loss:0.1470, loss-lb:0.0664, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:47:26.502] iteration:28278  t-loss:0.1475, loss-lb:0.0674, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:47:26.695] iteration:28279  t-loss:0.1336, loss-lb:0.0651, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:47:26.888] iteration:28280  t-loss:0.1445, loss-lb:0.0701, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:47:27.081] iteration:28281  t-loss:0.1358, loss-lb:0.0720, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:47:27.272] iteration:28282  t-loss:0.1424, loss-lb:0.0715, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:47:27.465] iteration:28283  t-loss:0.1470, loss-lb:0.0734, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:47:27.659] iteration:28284  t-loss:0.1304, loss-lb:0.0659, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:47:27.851] iteration:28285  t-loss:0.1349, loss-lb:0.0651, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:47:28.044] iteration:28286  t-loss:0.1260, loss-lb:0.0650, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:47:28.236] iteration:28287  t-loss:0.1439, loss-lb:0.0683, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:47:28.427] iteration:28288  t-loss:0.1481, loss-lb:0.0673, loss-ulb:0.0404, weight:2.00, lr:0.0001
[12:47:28.620] iteration:28289  t-loss:0.1482, loss-lb:0.0791, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:47:28.814] iteration:28290  t-loss:0.1432, loss-lb:0.0702, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:47:29.007] iteration:28291  t-loss:0.1426, loss-lb:0.0709, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:47:29.199] iteration:28292  t-loss:0.1289, loss-lb:0.0635, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:47:29.391] iteration:28293  t-loss:0.1269, loss-lb:0.0691, loss-ulb:0.0289, weight:2.00, lr:0.0001
[12:47:29.584] iteration:28294  t-loss:0.1302, loss-lb:0.0630, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:47:29.777] iteration:28295  t-loss:0.1526, loss-lb:0.0676, loss-ulb:0.0425, weight:2.00, lr:0.0001
[12:47:29.969] iteration:28296  t-loss:0.1351, loss-lb:0.0697, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:47:30.162] iteration:28297  t-loss:0.1405, loss-lb:0.0756, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:47:30.354] iteration:28298  t-loss:0.1336, loss-lb:0.0663, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:47:30.546] iteration:28299  t-loss:0.1479, loss-lb:0.0751, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:47:30.739] iteration:28300  t-loss:0.1323, loss-lb:0.0654, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:30.932] iteration:28301  t-loss:0.1437, loss-lb:0.0702, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:47:31.124] iteration:28302  t-loss:0.1409, loss-lb:0.0706, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:47:31.316] iteration:28303  t-loss:0.1465, loss-lb:0.0748, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:47:31.509] iteration:28304  t-loss:0.2467, loss-lb:0.0687, loss-ulb:0.0890, weight:2.00, lr:0.0001
[12:47:31.701] iteration:28305  t-loss:0.1341, loss-lb:0.0670, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:31.894] iteration:28306  t-loss:0.1886, loss-lb:0.0691, loss-ulb:0.0598, weight:2.00, lr:0.0001
[12:47:32.087] iteration:28307  t-loss:0.1409, loss-lb:0.0750, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:47:32.279] iteration:28308  t-loss:0.1463, loss-lb:0.0646, loss-ulb:0.0409, weight:2.00, lr:0.0001
[12:47:32.472] iteration:28309  t-loss:0.1960, loss-lb:0.0639, loss-ulb:0.0661, weight:2.00, lr:0.0001
[12:47:32.664] iteration:28310  t-loss:0.1443, loss-lb:0.0670, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:47:32.858] iteration:28311  t-loss:0.1363, loss-lb:0.0701, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:47:33.065] iteration:28312  t-loss:0.1382, loss-lb:0.0720, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:47:33.266] iteration:28313  t-loss:0.1949, loss-lb:0.0731, loss-ulb:0.0609, weight:2.00, lr:0.0001
[12:47:33.460] iteration:28314  t-loss:0.1458, loss-lb:0.0685, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:47:33.651] iteration:28315  t-loss:0.1438, loss-lb:0.0678, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:47:33.843] iteration:28316  t-loss:0.1386, loss-lb:0.0640, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:47:34.035] iteration:28317  t-loss:0.1837, loss-lb:0.0787, loss-ulb:0.0525, weight:2.00, lr:0.0001
[12:47:34.226] iteration:28318  t-loss:0.1413, loss-lb:0.0642, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:47:34.417] iteration:28319  t-loss:0.1404, loss-lb:0.0660, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:47:34.608] iteration:28320  t-loss:0.2244, loss-lb:0.0795, loss-ulb:0.0724, weight:2.00, lr:0.0001
[12:47:34.799] iteration:28321  t-loss:0.1384, loss-lb:0.0675, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:47:34.990] iteration:28322  t-loss:0.1574, loss-lb:0.0710, loss-ulb:0.0432, weight:2.00, lr:0.0001
[12:47:47.493]  <<Test>> - Ep:288  - mean_dice/mean_h95 - S:89.75/1.36, Best-S:90.99, T:89.62/1.38, Best-T:90.48
[12:47:47.494]           - AvgLoss(lb/ulb/all):0.0696/0.0458/0.1613
[12:47:48.025] iteration:28323  t-loss:0.1321, loss-lb:0.0670, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:47:48.222] iteration:28324  t-loss:0.1548, loss-lb:0.0715, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:47:48.414] iteration:28325  t-loss:0.1328, loss-lb:0.0638, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:47:48.607] iteration:28326  t-loss:0.1402, loss-lb:0.0700, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:47:48.799] iteration:28327  t-loss:0.1455, loss-lb:0.0774, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:47:48.991] iteration:28328  t-loss:0.1307, loss-lb:0.0725, loss-ulb:0.0291, weight:2.00, lr:0.0001
[12:47:49.182] iteration:28329  t-loss:0.1337, loss-lb:0.0676, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:47:49.375] iteration:28330  t-loss:0.1431, loss-lb:0.0700, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:47:49.568] iteration:28331  t-loss:0.2116, loss-lb:0.0614, loss-ulb:0.0751, weight:2.00, lr:0.0001
[12:47:49.762] iteration:28332  t-loss:0.1379, loss-lb:0.0642, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:47:49.954] iteration:28333  t-loss:0.1388, loss-lb:0.0641, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:47:50.146] iteration:28334  t-loss:0.1461, loss-lb:0.0712, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:47:50.339] iteration:28335  t-loss:0.1255, loss-lb:0.0678, loss-ulb:0.0289, weight:2.00, lr:0.0001
[12:47:50.532] iteration:28336  t-loss:0.1464, loss-lb:0.0754, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:47:50.724] iteration:28337  t-loss:0.1313, loss-lb:0.0679, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:47:50.916] iteration:28338  t-loss:0.1332, loss-lb:0.0690, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:47:51.109] iteration:28339  t-loss:0.2417, loss-lb:0.0717, loss-ulb:0.0850, weight:2.00, lr:0.0001
[12:47:51.301] iteration:28340  t-loss:0.1367, loss-lb:0.0768, loss-ulb:0.0299, weight:2.00, lr:0.0001
[12:47:51.494] iteration:28341  t-loss:0.1577, loss-lb:0.0782, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:47:51.686] iteration:28342  t-loss:0.1283, loss-lb:0.0613, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:51.878] iteration:28343  t-loss:0.1396, loss-lb:0.0654, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:47:52.070] iteration:28344  t-loss:0.1437, loss-lb:0.0712, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:47:52.261] iteration:28345  t-loss:0.1405, loss-lb:0.0691, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:47:52.453] iteration:28346  t-loss:0.1356, loss-lb:0.0666, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:47:52.645] iteration:28347  t-loss:0.1275, loss-lb:0.0659, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:47:52.836] iteration:28348  t-loss:0.1403, loss-lb:0.0734, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:53.028] iteration:28349  t-loss:0.1466, loss-lb:0.0788, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:47:53.221] iteration:28350  t-loss:0.1644, loss-lb:0.0643, loss-ulb:0.0501, weight:2.00, lr:0.0001
[12:47:53.412] iteration:28351  t-loss:0.1307, loss-lb:0.0675, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:47:53.605] iteration:28352  t-loss:0.1420, loss-lb:0.0773, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:47:53.798] iteration:28353  t-loss:0.1572, loss-lb:0.0690, loss-ulb:0.0441, weight:2.00, lr:0.0001
[12:47:53.992] iteration:28354  t-loss:0.1352, loss-lb:0.0678, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:47:54.185] iteration:28355  t-loss:0.1473, loss-lb:0.0651, loss-ulb:0.0411, weight:2.00, lr:0.0001
[12:47:54.377] iteration:28356  t-loss:0.1336, loss-lb:0.0670, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:47:54.569] iteration:28357  t-loss:0.1404, loss-lb:0.0703, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:47:54.762] iteration:28358  t-loss:0.1433, loss-lb:0.0697, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:47:54.954] iteration:28359  t-loss:0.1354, loss-lb:0.0668, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:47:55.146] iteration:28360  t-loss:0.1367, loss-lb:0.0681, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:47:55.338] iteration:28361  t-loss:0.1377, loss-lb:0.0711, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:47:55.530] iteration:28362  t-loss:0.1527, loss-lb:0.0674, loss-ulb:0.0426, weight:2.00, lr:0.0001
[12:47:55.722] iteration:28363  t-loss:0.1437, loss-lb:0.0755, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:47:55.915] iteration:28364  t-loss:0.1575, loss-lb:0.0743, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:47:56.107] iteration:28365  t-loss:0.1392, loss-lb:0.0729, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:47:56.299] iteration:28366  t-loss:0.1346, loss-lb:0.0689, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:47:56.492] iteration:28367  t-loss:0.3240, loss-lb:0.0644, loss-ulb:0.1298, weight:2.00, lr:0.0001
[12:47:56.686] iteration:28368  t-loss:0.1472, loss-lb:0.0604, loss-ulb:0.0434, weight:2.00, lr:0.0001
[12:47:56.878] iteration:28369  t-loss:0.1257, loss-lb:0.0614, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:47:57.071] iteration:28370  t-loss:0.2169, loss-lb:0.0710, loss-ulb:0.0729, weight:2.00, lr:0.0001
[12:47:57.264] iteration:28371  t-loss:0.1650, loss-lb:0.0797, loss-ulb:0.0427, weight:2.00, lr:0.0001
[12:47:57.456] iteration:28372  t-loss:0.1354, loss-lb:0.0684, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:47:57.647] iteration:28373  t-loss:0.1323, loss-lb:0.0612, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:47:57.840] iteration:28374  t-loss:0.1323, loss-lb:0.0687, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:47:58.033] iteration:28375  t-loss:0.1455, loss-lb:0.0766, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:47:58.226] iteration:28376  t-loss:0.1713, loss-lb:0.0729, loss-ulb:0.0492, weight:2.00, lr:0.0001
[12:47:58.418] iteration:28377  t-loss:0.1360, loss-lb:0.0700, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:47:58.611] iteration:28378  t-loss:0.1462, loss-lb:0.0717, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:47:58.804] iteration:28379  t-loss:0.1414, loss-lb:0.0710, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:47:58.995] iteration:28380  t-loss:0.1397, loss-lb:0.0725, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:47:59.189] iteration:28381  t-loss:0.1612, loss-lb:0.0696, loss-ulb:0.0458, weight:2.00, lr:0.0001
[12:47:59.382] iteration:28382  t-loss:0.1455, loss-lb:0.0640, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:47:59.575] iteration:28383  t-loss:0.1406, loss-lb:0.0677, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:47:59.767] iteration:28384  t-loss:0.1645, loss-lb:0.0665, loss-ulb:0.0490, weight:2.00, lr:0.0001
[12:47:59.960] iteration:28385  t-loss:0.1463, loss-lb:0.0694, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:48:00.153] iteration:28386  t-loss:0.1378, loss-lb:0.0733, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:48:00.345] iteration:28387  t-loss:0.1402, loss-lb:0.0716, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:48:00.537] iteration:28388  t-loss:0.1334, loss-lb:0.0653, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:48:00.731] iteration:28389  t-loss:0.1658, loss-lb:0.0716, loss-ulb:0.0471, weight:2.00, lr:0.0001
[12:48:00.923] iteration:28390  t-loss:0.1361, loss-lb:0.0681, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:48:01.114] iteration:28391  t-loss:0.1554, loss-lb:0.0710, loss-ulb:0.0422, weight:2.00, lr:0.0001
[12:48:01.308] iteration:28392  t-loss:0.1416, loss-lb:0.0645, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:48:01.502] iteration:28393  t-loss:0.1462, loss-lb:0.0652, loss-ulb:0.0405, weight:2.00, lr:0.0001
[12:48:01.699] iteration:28394  t-loss:0.2053, loss-lb:0.0745, loss-ulb:0.0654, weight:2.00, lr:0.0001
[12:48:01.893] iteration:28395  t-loss:0.1497, loss-lb:0.0678, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:48:02.086] iteration:28396  t-loss:0.1471, loss-lb:0.0675, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:48:02.279] iteration:28397  t-loss:0.2863, loss-lb:0.0667, loss-ulb:0.1098, weight:2.00, lr:0.0001
[12:48:02.471] iteration:28398  t-loss:0.1383, loss-lb:0.0704, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:48:02.664] iteration:28399  t-loss:0.1648, loss-lb:0.0688, loss-ulb:0.0480, weight:2.00, lr:0.0001
[12:48:02.856] iteration:28400  t-loss:0.1338, loss-lb:0.0669, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:48:03.049] iteration:28401  t-loss:0.1443, loss-lb:0.0673, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:48:03.241] iteration:28402  t-loss:0.1630, loss-lb:0.0720, loss-ulb:0.0455, weight:2.00, lr:0.0001
[12:48:03.432] iteration:28403  t-loss:0.1188, loss-lb:0.0633, loss-ulb:0.0278, weight:2.00, lr:0.0001
[12:48:03.625] iteration:28404  t-loss:0.1391, loss-lb:0.0668, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:48:03.816] iteration:28405  t-loss:0.1594, loss-lb:0.0729, loss-ulb:0.0432, weight:2.00, lr:0.0001
[12:48:04.008] iteration:28406  t-loss:0.1750, loss-lb:0.0728, loss-ulb:0.0511, weight:2.00, lr:0.0001
[12:48:04.201] iteration:28407  t-loss:0.1462, loss-lb:0.0640, loss-ulb:0.0411, weight:2.00, lr:0.0001
[12:48:04.393] iteration:28408  t-loss:0.1584, loss-lb:0.0613, loss-ulb:0.0485, weight:2.00, lr:0.0001
[12:48:04.585] iteration:28409  t-loss:0.1499, loss-lb:0.0728, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:48:04.778] iteration:28410  t-loss:0.1499, loss-lb:0.0699, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:48:04.971] iteration:28411  t-loss:0.1727, loss-lb:0.0672, loss-ulb:0.0527, weight:2.00, lr:0.0001
[12:48:05.163] iteration:28412  t-loss:0.1390, loss-lb:0.0715, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:48:05.354] iteration:28413  t-loss:0.1374, loss-lb:0.0693, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:48:05.545] iteration:28414  t-loss:0.1461, loss-lb:0.0689, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:48:05.736] iteration:28415  t-loss:0.1426, loss-lb:0.0677, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:48:05.939] iteration:28416  t-loss:0.1780, loss-lb:0.0837, loss-ulb:0.0471, weight:2.00, lr:0.0001
[12:48:06.135] iteration:28417  t-loss:0.1403, loss-lb:0.0619, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:48:06.327] iteration:28418  t-loss:0.1479, loss-lb:0.0765, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:48:06.518] iteration:28419  t-loss:0.1397, loss-lb:0.0675, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:48:06.709] iteration:28420  t-loss:0.1446, loss-lb:0.0718, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:48:07.280] iteration:28421  t-loss:0.1448, loss-lb:0.0736, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:48:07.475] iteration:28422  t-loss:0.1457, loss-lb:0.0768, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:48:07.667] iteration:28423  t-loss:0.1477, loss-lb:0.0669, loss-ulb:0.0404, weight:2.00, lr:0.0001
[12:48:07.859] iteration:28424  t-loss:0.1291, loss-lb:0.0686, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:48:08.051] iteration:28425  t-loss:0.1469, loss-lb:0.0688, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:48:08.243] iteration:28426  t-loss:0.1481, loss-lb:0.0735, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:48:08.434] iteration:28427  t-loss:0.1301, loss-lb:0.0617, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:48:08.625] iteration:28428  t-loss:0.1502, loss-lb:0.0731, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:48:08.818] iteration:28429  t-loss:0.1271, loss-lb:0.0612, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:48:09.010] iteration:28430  t-loss:0.1463, loss-lb:0.0622, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:48:09.202] iteration:28431  t-loss:0.1473, loss-lb:0.0703, loss-ulb:0.0385, weight:2.00, lr:0.0001
[12:48:09.394] iteration:28432  t-loss:0.1247, loss-lb:0.0662, loss-ulb:0.0293, weight:2.00, lr:0.0001
[12:48:09.586] iteration:28433  t-loss:0.1384, loss-lb:0.0664, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:48:09.778] iteration:28434  t-loss:0.1364, loss-lb:0.0678, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:48:09.969] iteration:28435  t-loss:0.1296, loss-lb:0.0638, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:48:10.161] iteration:28436  t-loss:0.1335, loss-lb:0.0663, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:48:10.353] iteration:28437  t-loss:0.1509, loss-lb:0.0813, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:48:10.543] iteration:28438  t-loss:0.1452, loss-lb:0.0695, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:48:10.735] iteration:28439  t-loss:0.1420, loss-lb:0.0729, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:48:10.927] iteration:28440  t-loss:0.1671, loss-lb:0.0649, loss-ulb:0.0511, weight:2.00, lr:0.0001
[12:48:11.119] iteration:28441  t-loss:0.1430, loss-lb:0.0714, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:48:11.310] iteration:28442  t-loss:0.1521, loss-lb:0.0823, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:48:11.502] iteration:28443  t-loss:0.1349, loss-lb:0.0705, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:48:11.693] iteration:28444  t-loss:0.1286, loss-lb:0.0612, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:48:11.884] iteration:28445  t-loss:0.1474, loss-lb:0.0710, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:48:12.076] iteration:28446  t-loss:0.1335, loss-lb:0.0667, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:48:12.269] iteration:28447  t-loss:0.1380, loss-lb:0.0655, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:48:12.463] iteration:28448  t-loss:0.1434, loss-lb:0.0737, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:48:12.662] iteration:28449  t-loss:0.1506, loss-lb:0.0738, loss-ulb:0.0384, weight:2.00, lr:0.0001
[12:48:12.856] iteration:28450  t-loss:0.1491, loss-lb:0.0756, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:48:13.051] iteration:28451  t-loss:0.1492, loss-lb:0.0695, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:48:13.245] iteration:28452  t-loss:0.1335, loss-lb:0.0671, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:48:13.436] iteration:28453  t-loss:0.1408, loss-lb:0.0680, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:48:13.629] iteration:28454  t-loss:0.1597, loss-lb:0.0631, loss-ulb:0.0483, weight:2.00, lr:0.0001
[12:48:13.821] iteration:28455  t-loss:0.1309, loss-lb:0.0671, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:48:14.013] iteration:28456  t-loss:0.1476, loss-lb:0.0789, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:48:14.205] iteration:28457  t-loss:0.1688, loss-lb:0.0724, loss-ulb:0.0482, weight:2.00, lr:0.0001
[12:48:14.396] iteration:28458  t-loss:0.1228, loss-lb:0.0643, loss-ulb:0.0292, weight:2.00, lr:0.0001
[12:48:14.589] iteration:28459  t-loss:0.1390, loss-lb:0.0711, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:48:14.781] iteration:28460  t-loss:0.1338, loss-lb:0.0721, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:48:14.973] iteration:28461  t-loss:0.1446, loss-lb:0.0680, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:48:15.166] iteration:28462  t-loss:0.1523, loss-lb:0.0746, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:48:15.358] iteration:28463  t-loss:0.1351, loss-lb:0.0694, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:48:15.552] iteration:28464  t-loss:0.1380, loss-lb:0.0666, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:48:15.743] iteration:28465  t-loss:0.1432, loss-lb:0.0645, loss-ulb:0.0393, weight:2.00, lr:0.0001
[12:48:15.935] iteration:28466  t-loss:0.1287, loss-lb:0.0582, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:48:16.126] iteration:28467  t-loss:0.1404, loss-lb:0.0684, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:48:16.318] iteration:28468  t-loss:0.1430, loss-lb:0.0711, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:48:16.511] iteration:28469  t-loss:0.1388, loss-lb:0.0713, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:48:16.704] iteration:28470  t-loss:0.1404, loss-lb:0.0657, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:48:16.896] iteration:28471  t-loss:0.1456, loss-lb:0.0646, loss-ulb:0.0405, weight:2.00, lr:0.0001
[12:48:17.087] iteration:28472  t-loss:0.1360, loss-lb:0.0652, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:48:17.278] iteration:28473  t-loss:0.1429, loss-lb:0.0756, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:48:17.471] iteration:28474  t-loss:0.1193, loss-lb:0.0655, loss-ulb:0.0269, weight:2.00, lr:0.0001
[12:48:17.663] iteration:28475  t-loss:0.1515, loss-lb:0.0817, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:48:17.856] iteration:28476  t-loss:0.1520, loss-lb:0.0747, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:48:18.049] iteration:28477  t-loss:0.1460, loss-lb:0.0712, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:48:18.241] iteration:28478  t-loss:0.1378, loss-lb:0.0714, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:48:18.433] iteration:28479  t-loss:0.1617, loss-lb:0.0718, loss-ulb:0.0449, weight:2.00, lr:0.0001
[12:48:18.625] iteration:28480  t-loss:0.1298, loss-lb:0.0652, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:48:18.818] iteration:28481  t-loss:0.1894, loss-lb:0.0614, loss-ulb:0.0640, weight:2.00, lr:0.0001
[12:48:19.011] iteration:28482  t-loss:0.1525, loss-lb:0.0651, loss-ulb:0.0437, weight:2.00, lr:0.0001
[12:48:19.202] iteration:28483  t-loss:0.1311, loss-lb:0.0587, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:48:19.396] iteration:28484  t-loss:0.1519, loss-lb:0.0714, loss-ulb:0.0402, weight:2.00, lr:0.0001
[12:48:19.588] iteration:28485  t-loss:0.1406, loss-lb:0.0758, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:48:19.780] iteration:28486  t-loss:0.1361, loss-lb:0.0711, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:48:19.971] iteration:28487  t-loss:0.1384, loss-lb:0.0732, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:48:20.164] iteration:28488  t-loss:0.1367, loss-lb:0.0675, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:48:20.356] iteration:28489  t-loss:0.1300, loss-lb:0.0660, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:48:20.548] iteration:28490  t-loss:0.1192, loss-lb:0.0610, loss-ulb:0.0291, weight:2.00, lr:0.0001
[12:48:20.740] iteration:28491  t-loss:0.1931, loss-lb:0.0623, loss-ulb:0.0654, weight:2.00, lr:0.0001
[12:48:20.931] iteration:28492  t-loss:0.1432, loss-lb:0.0680, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:48:21.123] iteration:28493  t-loss:0.1451, loss-lb:0.0757, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:48:21.315] iteration:28494  t-loss:0.1605, loss-lb:0.0753, loss-ulb:0.0426, weight:2.00, lr:0.0001
[12:48:21.506] iteration:28495  t-loss:0.1435, loss-lb:0.0683, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:48:21.697] iteration:28496  t-loss:0.1427, loss-lb:0.0756, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:48:21.890] iteration:28497  t-loss:0.1400, loss-lb:0.0684, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:48:22.081] iteration:28498  t-loss:0.1583, loss-lb:0.0748, loss-ulb:0.0417, weight:2.00, lr:0.0001
[12:48:22.273] iteration:28499  t-loss:0.1344, loss-lb:0.0712, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:48:22.463] iteration:28500  t-loss:0.1410, loss-lb:0.0683, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:48:22.654] iteration:28501  t-loss:0.1450, loss-lb:0.0674, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:48:22.846] iteration:28502  t-loss:0.1324, loss-lb:0.0669, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:48:23.038] iteration:28503  t-loss:0.1364, loss-lb:0.0703, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:48:23.233] iteration:28504  t-loss:0.1338, loss-lb:0.0631, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:48:23.429] iteration:28505  t-loss:0.1440, loss-lb:0.0677, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:48:23.623] iteration:28506  t-loss:0.1365, loss-lb:0.0675, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:48:23.819] iteration:28507  t-loss:0.1342, loss-lb:0.0682, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:48:24.013] iteration:28508  t-loss:0.1282, loss-lb:0.0645, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:48:24.206] iteration:28509  t-loss:0.1397, loss-lb:0.0705, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:48:24.398] iteration:28510  t-loss:0.1395, loss-lb:0.0689, loss-ulb:0.0353, weight:2.00, lr:0.0001
[12:48:24.590] iteration:28511  t-loss:0.1334, loss-lb:0.0693, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:48:24.781] iteration:28512  t-loss:0.1388, loss-lb:0.0730, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:48:24.971] iteration:28513  t-loss:0.1466, loss-lb:0.0663, loss-ulb:0.0402, weight:2.00, lr:0.0001
[12:48:25.161] iteration:28514  t-loss:0.1355, loss-lb:0.0707, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:48:25.352] iteration:28515  t-loss:0.1376, loss-lb:0.0649, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:48:25.542] iteration:28516  t-loss:0.1453, loss-lb:0.0760, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:48:25.732] iteration:28517  t-loss:0.1354, loss-lb:0.0644, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:48:25.923] iteration:28518  t-loss:0.1448, loss-lb:0.0728, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:48:37.878]  <<Test>> - Ep:290  - mean_dice/mean_h95 - S:89.80/1.35, Best-S:90.99, T:89.67/1.34, Best-T:90.48
[12:48:37.879]           - AvgLoss(lb/ulb/all):0.0692/0.0348/0.1381
[12:48:38.413] iteration:28519  t-loss:0.1307, loss-lb:0.0657, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:48:38.624] iteration:28520  t-loss:0.1452, loss-lb:0.0653, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:48:38.837] iteration:28521  t-loss:0.1329, loss-lb:0.0667, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:48:39.055] iteration:28522  t-loss:0.1371, loss-lb:0.0718, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:48:39.249] iteration:28523  t-loss:0.1401, loss-lb:0.0690, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:48:39.442] iteration:28524  t-loss:0.1449, loss-lb:0.0693, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:48:39.634] iteration:28525  t-loss:0.1441, loss-lb:0.0757, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:48:39.827] iteration:28526  t-loss:0.1544, loss-lb:0.0708, loss-ulb:0.0418, weight:2.00, lr:0.0001
[12:48:40.019] iteration:28527  t-loss:0.1230, loss-lb:0.0648, loss-ulb:0.0291, weight:2.00, lr:0.0001
[12:48:40.212] iteration:28528  t-loss:0.1351, loss-lb:0.0641, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:48:40.404] iteration:28529  t-loss:0.1269, loss-lb:0.0704, loss-ulb:0.0283, weight:2.00, lr:0.0001
[12:48:40.598] iteration:28530  t-loss:0.1398, loss-lb:0.0709, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:48:40.793] iteration:28531  t-loss:0.1462, loss-lb:0.0696, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:48:40.985] iteration:28532  t-loss:0.1540, loss-lb:0.0707, loss-ulb:0.0416, weight:2.00, lr:0.0001
[12:48:41.178] iteration:28533  t-loss:0.1672, loss-lb:0.0770, loss-ulb:0.0451, weight:2.00, lr:0.0001
[12:48:41.380] iteration:28534  t-loss:0.1269, loss-lb:0.0647, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:48:41.573] iteration:28535  t-loss:0.1522, loss-lb:0.0721, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:48:41.765] iteration:28536  t-loss:0.1275, loss-lb:0.0691, loss-ulb:0.0292, weight:2.00, lr:0.0001
[12:48:41.959] iteration:28537  t-loss:0.1298, loss-lb:0.0670, loss-ulb:0.0314, weight:2.00, lr:0.0001
[12:48:42.159] iteration:28538  t-loss:0.1352, loss-lb:0.0694, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:48:42.351] iteration:28539  t-loss:0.1452, loss-lb:0.0721, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:48:42.543] iteration:28540  t-loss:0.1453, loss-lb:0.0766, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:48:42.734] iteration:28541  t-loss:0.1489, loss-lb:0.0717, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:48:42.934] iteration:28542  t-loss:0.1378, loss-lb:0.0696, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:48:43.126] iteration:28543  t-loss:0.1557, loss-lb:0.0682, loss-ulb:0.0438, weight:2.00, lr:0.0001
[12:48:43.319] iteration:28544  t-loss:0.1432, loss-lb:0.0695, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:48:43.510] iteration:28545  t-loss:0.1355, loss-lb:0.0685, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:48:43.708] iteration:28546  t-loss:0.1422, loss-lb:0.0672, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:48:43.901] iteration:28547  t-loss:0.1324, loss-lb:0.0609, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:48:44.091] iteration:28548  t-loss:0.1418, loss-lb:0.0729, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:48:44.284] iteration:28549  t-loss:0.1275, loss-lb:0.0726, loss-ulb:0.0274, weight:2.00, lr:0.0001
[12:48:44.476] iteration:28550  t-loss:0.1435, loss-lb:0.0687, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:48:44.667] iteration:28551  t-loss:0.1532, loss-lb:0.0648, loss-ulb:0.0442, weight:2.00, lr:0.0001
[12:48:44.858] iteration:28552  t-loss:0.1532, loss-lb:0.0694, loss-ulb:0.0419, weight:2.00, lr:0.0001
[12:48:45.051] iteration:28553  t-loss:0.1371, loss-lb:0.0670, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:48:45.243] iteration:28554  t-loss:0.1388, loss-lb:0.0728, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:48:45.436] iteration:28555  t-loss:0.1491, loss-lb:0.0716, loss-ulb:0.0387, weight:2.00, lr:0.0001
[12:48:45.627] iteration:28556  t-loss:0.1284, loss-lb:0.0666, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:48:45.826] iteration:28557  t-loss:0.1638, loss-lb:0.0760, loss-ulb:0.0439, weight:2.00, lr:0.0001
[12:48:46.020] iteration:28558  t-loss:0.1591, loss-lb:0.0682, loss-ulb:0.0455, weight:2.00, lr:0.0001
[12:48:46.213] iteration:28559  t-loss:0.1403, loss-lb:0.0673, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:48:46.404] iteration:28560  t-loss:0.1537, loss-lb:0.0782, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:48:46.598] iteration:28561  t-loss:0.2046, loss-lb:0.0728, loss-ulb:0.0659, weight:2.00, lr:0.0001
[12:48:46.790] iteration:28562  t-loss:0.1285, loss-lb:0.0673, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:48:46.983] iteration:28563  t-loss:0.1341, loss-lb:0.0621, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:48:47.175] iteration:28564  t-loss:0.1620, loss-lb:0.0653, loss-ulb:0.0484, weight:2.00, lr:0.0001
[12:48:47.368] iteration:28565  t-loss:0.1357, loss-lb:0.0702, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:48:47.560] iteration:28566  t-loss:0.1510, loss-lb:0.0651, loss-ulb:0.0429, weight:2.00, lr:0.0001
[12:48:47.752] iteration:28567  t-loss:0.1469, loss-lb:0.0779, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:48:47.944] iteration:28568  t-loss:0.1391, loss-lb:0.0665, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:48:48.138] iteration:28569  t-loss:0.1388, loss-lb:0.0675, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:48:48.330] iteration:28570  t-loss:0.1346, loss-lb:0.0694, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:48:48.522] iteration:28571  t-loss:0.1343, loss-lb:0.0677, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:48:48.715] iteration:28572  t-loss:0.1624, loss-lb:0.0680, loss-ulb:0.0472, weight:2.00, lr:0.0001
[12:48:48.909] iteration:28573  t-loss:0.1409, loss-lb:0.0695, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:48:49.101] iteration:28574  t-loss:0.1359, loss-lb:0.0735, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:48:49.292] iteration:28575  t-loss:0.1511, loss-lb:0.0704, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:48:49.485] iteration:28576  t-loss:0.1952, loss-lb:0.0776, loss-ulb:0.0588, weight:2.00, lr:0.0001
[12:48:49.678] iteration:28577  t-loss:0.1635, loss-lb:0.0854, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:48:49.870] iteration:28578  t-loss:0.1390, loss-lb:0.0663, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:48:50.063] iteration:28579  t-loss:0.1306, loss-lb:0.0629, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:48:50.256] iteration:28580  t-loss:0.1431, loss-lb:0.0615, loss-ulb:0.0408, weight:2.00, lr:0.0001
[12:48:50.448] iteration:28581  t-loss:0.1360, loss-lb:0.0651, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:48:50.641] iteration:28582  t-loss:0.1309, loss-lb:0.0668, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:48:50.834] iteration:28583  t-loss:0.1521, loss-lb:0.0743, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:48:51.025] iteration:28584  t-loss:0.1431, loss-lb:0.0709, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:48:51.219] iteration:28585  t-loss:0.1346, loss-lb:0.0660, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:48:51.411] iteration:28586  t-loss:0.1498, loss-lb:0.0752, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:48:51.604] iteration:28587  t-loss:0.1966, loss-lb:0.0752, loss-ulb:0.0607, weight:2.00, lr:0.0001
[12:48:51.796] iteration:28588  t-loss:0.1391, loss-lb:0.0635, loss-ulb:0.0378, weight:2.00, lr:0.0001
[12:48:51.991] iteration:28589  t-loss:0.1665, loss-lb:0.0685, loss-ulb:0.0490, weight:2.00, lr:0.0001
[12:48:52.185] iteration:28590  t-loss:0.1842, loss-lb:0.0663, loss-ulb:0.0589, weight:2.00, lr:0.0001
[12:48:52.379] iteration:28591  t-loss:0.1338, loss-lb:0.0735, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:48:52.571] iteration:28592  t-loss:0.1770, loss-lb:0.0690, loss-ulb:0.0540, weight:2.00, lr:0.0001
[12:48:52.764] iteration:28593  t-loss:0.1413, loss-lb:0.0705, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:48:52.957] iteration:28594  t-loss:0.1417, loss-lb:0.0717, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:48:53.150] iteration:28595  t-loss:0.1385, loss-lb:0.0660, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:48:53.342] iteration:28596  t-loss:0.1412, loss-lb:0.0660, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:48:53.536] iteration:28597  t-loss:0.1446, loss-lb:0.0643, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:48:53.728] iteration:28598  t-loss:0.1450, loss-lb:0.0622, loss-ulb:0.0414, weight:2.00, lr:0.0001
[12:48:53.921] iteration:28599  t-loss:0.1365, loss-lb:0.0716, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:48:54.114] iteration:28600  t-loss:0.1423, loss-lb:0.0752, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:48:54.307] iteration:28601  t-loss:0.1312, loss-lb:0.0655, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:48:54.500] iteration:28602  t-loss:0.1540, loss-lb:0.0674, loss-ulb:0.0433, weight:2.00, lr:0.0001
[12:48:54.693] iteration:28603  t-loss:0.1330, loss-lb:0.0673, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:48:54.884] iteration:28604  t-loss:0.1475, loss-lb:0.0634, loss-ulb:0.0421, weight:2.00, lr:0.0001
[12:48:55.078] iteration:28605  t-loss:0.2439, loss-lb:0.0733, loss-ulb:0.0853, weight:2.00, lr:0.0001
[12:48:55.271] iteration:28606  t-loss:0.1383, loss-lb:0.0639, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:48:55.465] iteration:28607  t-loss:0.1608, loss-lb:0.0750, loss-ulb:0.0429, weight:2.00, lr:0.0001
[12:48:55.658] iteration:28608  t-loss:0.1554, loss-lb:0.0699, loss-ulb:0.0428, weight:2.00, lr:0.0001
[12:48:55.850] iteration:28609  t-loss:0.1406, loss-lb:0.0780, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:48:56.041] iteration:28610  t-loss:0.1438, loss-lb:0.0749, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:48:56.234] iteration:28611  t-loss:0.1436, loss-lb:0.0763, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:48:56.425] iteration:28612  t-loss:0.1391, loss-lb:0.0694, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:48:56.617] iteration:28613  t-loss:0.1370, loss-lb:0.0764, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:48:56.807] iteration:28614  t-loss:0.1379, loss-lb:0.0657, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:48:56.998] iteration:28615  t-loss:0.1391, loss-lb:0.0624, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:48:57.188] iteration:28616  t-loss:0.1639, loss-lb:0.0696, loss-ulb:0.0472, weight:2.00, lr:0.0001
[12:48:57.781] iteration:28617  t-loss:0.1411, loss-lb:0.0689, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:48:57.975] iteration:28618  t-loss:0.1359, loss-lb:0.0722, loss-ulb:0.0319, weight:2.00, lr:0.0001
[12:48:58.167] iteration:28619  t-loss:0.1512, loss-lb:0.0648, loss-ulb:0.0432, weight:2.00, lr:0.0001
[12:48:58.360] iteration:28620  t-loss:0.1543, loss-lb:0.0791, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:48:58.553] iteration:28621  t-loss:0.1399, loss-lb:0.0661, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:48:58.746] iteration:28622  t-loss:0.1329, loss-lb:0.0671, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:48:58.938] iteration:28623  t-loss:0.1542, loss-lb:0.0702, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:48:59.131] iteration:28624  t-loss:0.1483, loss-lb:0.0683, loss-ulb:0.0400, weight:2.00, lr:0.0001
[12:48:59.323] iteration:28625  t-loss:0.1292, loss-lb:0.0625, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:48:59.515] iteration:28626  t-loss:0.1362, loss-lb:0.0751, loss-ulb:0.0306, weight:2.00, lr:0.0001
[12:48:59.708] iteration:28627  t-loss:0.1378, loss-lb:0.0687, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:48:59.900] iteration:28628  t-loss:0.1348, loss-lb:0.0703, loss-ulb:0.0322, weight:2.00, lr:0.0001
[12:49:00.092] iteration:28629  t-loss:0.1407, loss-lb:0.0649, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:49:00.285] iteration:28630  t-loss:0.1419, loss-lb:0.0691, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:49:00.477] iteration:28631  t-loss:0.1349, loss-lb:0.0646, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:49:00.671] iteration:28632  t-loss:0.2137, loss-lb:0.0664, loss-ulb:0.0736, weight:2.00, lr:0.0001
[12:49:00.862] iteration:28633  t-loss:0.1406, loss-lb:0.0698, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:49:01.056] iteration:28634  t-loss:0.2509, loss-lb:0.0714, loss-ulb:0.0898, weight:2.00, lr:0.0001
[12:49:01.248] iteration:28635  t-loss:0.1366, loss-lb:0.0694, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:49:01.441] iteration:28636  t-loss:0.2254, loss-lb:0.0694, loss-ulb:0.0780, weight:2.00, lr:0.0001
[12:49:01.634] iteration:28637  t-loss:0.1893, loss-lb:0.0748, loss-ulb:0.0572, weight:2.00, lr:0.0001
[12:49:01.826] iteration:28638  t-loss:0.1407, loss-lb:0.0698, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:49:02.019] iteration:28639  t-loss:0.1312, loss-lb:0.0640, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:49:02.213] iteration:28640  t-loss:0.1885, loss-lb:0.0718, loss-ulb:0.0583, weight:2.00, lr:0.0001
[12:49:02.406] iteration:28641  t-loss:0.1483, loss-lb:0.0646, loss-ulb:0.0418, weight:2.00, lr:0.0001
[12:49:02.599] iteration:28642  t-loss:0.1586, loss-lb:0.0743, loss-ulb:0.0422, weight:2.00, lr:0.0001
[12:49:02.791] iteration:28643  t-loss:0.1277, loss-lb:0.0679, loss-ulb:0.0299, weight:2.00, lr:0.0001
[12:49:02.983] iteration:28644  t-loss:0.1299, loss-lb:0.0620, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:49:03.176] iteration:28645  t-loss:0.1435, loss-lb:0.0762, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:49:03.368] iteration:28646  t-loss:0.1456, loss-lb:0.0693, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:49:03.561] iteration:28647  t-loss:0.1332, loss-lb:0.0657, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:49:03.754] iteration:28648  t-loss:0.1411, loss-lb:0.0719, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:49:03.947] iteration:28649  t-loss:0.1330, loss-lb:0.0650, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:49:04.140] iteration:28650  t-loss:0.1349, loss-lb:0.0621, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:49:04.334] iteration:28651  t-loss:0.1491, loss-lb:0.0736, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:49:04.526] iteration:28652  t-loss:0.1465, loss-lb:0.0790, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:49:04.719] iteration:28653  t-loss:0.1370, loss-lb:0.0671, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:49:04.911] iteration:28654  t-loss:0.1255, loss-lb:0.0619, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:49:05.104] iteration:28655  t-loss:0.1471, loss-lb:0.0731, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:49:05.295] iteration:28656  t-loss:0.1382, loss-lb:0.0729, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:49:05.487] iteration:28657  t-loss:0.1339, loss-lb:0.0607, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:49:05.680] iteration:28658  t-loss:0.1449, loss-lb:0.0702, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:49:05.873] iteration:28659  t-loss:0.1316, loss-lb:0.0656, loss-ulb:0.0330, weight:2.00, lr:0.0001
[12:49:06.065] iteration:28660  t-loss:0.1354, loss-lb:0.0663, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:49:06.259] iteration:28661  t-loss:0.1254, loss-lb:0.0648, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:49:06.452] iteration:28662  t-loss:0.1410, loss-lb:0.0719, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:49:06.644] iteration:28663  t-loss:0.1435, loss-lb:0.0641, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:49:06.836] iteration:28664  t-loss:0.1506, loss-lb:0.0608, loss-ulb:0.0449, weight:2.00, lr:0.0001
[12:49:07.029] iteration:28665  t-loss:0.1349, loss-lb:0.0661, loss-ulb:0.0344, weight:2.00, lr:0.0001
[12:49:07.221] iteration:28666  t-loss:0.1469, loss-lb:0.0730, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:49:07.413] iteration:28667  t-loss:0.1289, loss-lb:0.0675, loss-ulb:0.0307, weight:2.00, lr:0.0001
[12:49:07.606] iteration:28668  t-loss:0.1369, loss-lb:0.0677, loss-ulb:0.0346, weight:2.00, lr:0.0001
[12:49:07.798] iteration:28669  t-loss:0.1485, loss-lb:0.0750, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:49:07.990] iteration:28670  t-loss:0.1512, loss-lb:0.0729, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:49:08.183] iteration:28671  t-loss:0.1329, loss-lb:0.0708, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:49:08.374] iteration:28672  t-loss:0.1378, loss-lb:0.0754, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:49:08.568] iteration:28673  t-loss:0.1552, loss-lb:0.0689, loss-ulb:0.0432, weight:2.00, lr:0.0001
[12:49:08.761] iteration:28674  t-loss:0.1680, loss-lb:0.0792, loss-ulb:0.0444, weight:2.00, lr:0.0001
[12:49:08.953] iteration:28675  t-loss:0.1294, loss-lb:0.0689, loss-ulb:0.0302, weight:2.00, lr:0.0001
[12:49:09.145] iteration:28676  t-loss:0.2353, loss-lb:0.0714, loss-ulb:0.0819, weight:2.00, lr:0.0001
[12:49:09.338] iteration:28677  t-loss:0.1394, loss-lb:0.0681, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:49:09.532] iteration:28678  t-loss:0.1447, loss-lb:0.0608, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:49:09.724] iteration:28679  t-loss:0.1424, loss-lb:0.0726, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:49:09.916] iteration:28680  t-loss:0.1343, loss-lb:0.0703, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:49:10.109] iteration:28681  t-loss:0.1427, loss-lb:0.0714, loss-ulb:0.0357, weight:2.00, lr:0.0001
[12:49:10.302] iteration:28682  t-loss:0.1394, loss-lb:0.0669, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:49:10.495] iteration:28683  t-loss:0.1397, loss-lb:0.0724, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:49:10.687] iteration:28684  t-loss:0.1327, loss-lb:0.0655, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:49:10.879] iteration:28685  t-loss:0.1418, loss-lb:0.0687, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:49:11.071] iteration:28686  t-loss:0.1264, loss-lb:0.0645, loss-ulb:0.0310, weight:2.00, lr:0.0001
[12:49:11.264] iteration:28687  t-loss:0.1343, loss-lb:0.0692, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:49:11.468] iteration:28688  t-loss:0.1515, loss-lb:0.0750, loss-ulb:0.0383, weight:2.00, lr:0.0001
[12:49:11.666] iteration:28689  t-loss:0.1242, loss-lb:0.0636, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:49:11.859] iteration:28690  t-loss:0.1485, loss-lb:0.0687, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:49:12.051] iteration:28691  t-loss:0.1370, loss-lb:0.0661, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:49:12.242] iteration:28692  t-loss:0.1591, loss-lb:0.0777, loss-ulb:0.0407, weight:2.00, lr:0.0001
[12:49:12.435] iteration:28693  t-loss:0.1389, loss-lb:0.0709, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:49:12.627] iteration:28694  t-loss:0.1402, loss-lb:0.0665, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:49:12.819] iteration:28695  t-loss:0.1439, loss-lb:0.0703, loss-ulb:0.0368, weight:2.00, lr:0.0001
[12:49:13.011] iteration:28696  t-loss:0.1333, loss-lb:0.0683, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:49:13.203] iteration:28697  t-loss:0.1451, loss-lb:0.0672, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:49:13.395] iteration:28698  t-loss:0.1392, loss-lb:0.0660, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:49:13.587] iteration:28699  t-loss:0.1536, loss-lb:0.0644, loss-ulb:0.0446, weight:2.00, lr:0.0001
[12:49:13.779] iteration:28700  t-loss:0.1457, loss-lb:0.0757, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:49:13.972] iteration:28701  t-loss:0.1734, loss-lb:0.0674, loss-ulb:0.0530, weight:2.00, lr:0.0001
[12:49:14.164] iteration:28702  t-loss:0.1876, loss-lb:0.0637, loss-ulb:0.0619, weight:2.00, lr:0.0001
[12:49:14.357] iteration:28703  t-loss:0.1495, loss-lb:0.0733, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:49:14.550] iteration:28704  t-loss:0.1754, loss-lb:0.0649, loss-ulb:0.0553, weight:2.00, lr:0.0001
[12:49:14.744] iteration:28705  t-loss:0.1756, loss-lb:0.0751, loss-ulb:0.0502, weight:2.00, lr:0.0001
[12:49:14.936] iteration:28706  t-loss:0.1351, loss-lb:0.0635, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:49:15.128] iteration:28707  t-loss:0.1389, loss-lb:0.0731, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:49:15.318] iteration:28708  t-loss:0.1467, loss-lb:0.0707, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:49:15.510] iteration:28709  t-loss:0.1374, loss-lb:0.0691, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:49:15.701] iteration:28710  t-loss:0.1498, loss-lb:0.0770, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:49:15.891] iteration:28711  t-loss:0.1367, loss-lb:0.0698, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:49:16.083] iteration:28712  t-loss:0.2090, loss-lb:0.0710, loss-ulb:0.0690, weight:2.00, lr:0.0001
[12:49:16.274] iteration:28713  t-loss:0.1813, loss-lb:0.0672, loss-ulb:0.0571, weight:2.00, lr:0.0001
[12:49:16.465] iteration:28714  t-loss:0.1372, loss-lb:0.0669, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:49:29.005]  <<Test>> - Ep:292  - mean_dice/mean_h95 - S:89.79/1.34, Best-S:90.99, T:89.63/1.37, Best-T:90.48
[12:49:29.006]           - AvgLoss(lb/ulb/all):0.0691/0.0427/0.1547
[12:49:29.537] iteration:28715  t-loss:0.1333, loss-lb:0.0707, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:49:29.736] iteration:28716  t-loss:0.1386, loss-lb:0.0754, loss-ulb:0.0316, weight:2.00, lr:0.0001
[12:49:29.929] iteration:28717  t-loss:0.1464, loss-lb:0.0654, loss-ulb:0.0405, weight:2.00, lr:0.0001
[12:49:30.124] iteration:28718  t-loss:0.1521, loss-lb:0.0827, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:49:30.317] iteration:28719  t-loss:0.1347, loss-lb:0.0706, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:49:30.509] iteration:28720  t-loss:0.1344, loss-lb:0.0702, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:49:30.703] iteration:28721  t-loss:0.1200, loss-lb:0.0634, loss-ulb:0.0283, weight:2.00, lr:0.0001
[12:49:30.896] iteration:28722  t-loss:0.1296, loss-lb:0.0671, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:49:31.089] iteration:28723  t-loss:0.1440, loss-lb:0.0675, loss-ulb:0.0382, weight:2.00, lr:0.0001
[12:49:31.282] iteration:28724  t-loss:0.1328, loss-lb:0.0654, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:49:31.475] iteration:28725  t-loss:0.1407, loss-lb:0.0667, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:49:31.668] iteration:28726  t-loss:0.1307, loss-lb:0.0684, loss-ulb:0.0312, weight:2.00, lr:0.0001
[12:49:31.862] iteration:28727  t-loss:0.1545, loss-lb:0.0727, loss-ulb:0.0409, weight:2.00, lr:0.0001
[12:49:32.055] iteration:28728  t-loss:0.1305, loss-lb:0.0689, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:49:32.248] iteration:28729  t-loss:0.1549, loss-lb:0.0665, loss-ulb:0.0442, weight:2.00, lr:0.0001
[12:49:32.443] iteration:28730  t-loss:0.1361, loss-lb:0.0662, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:49:32.636] iteration:28731  t-loss:0.1551, loss-lb:0.0790, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:49:32.830] iteration:28732  t-loss:0.1503, loss-lb:0.0773, loss-ulb:0.0365, weight:2.00, lr:0.0001
[12:49:33.024] iteration:28733  t-loss:0.1548, loss-lb:0.0744, loss-ulb:0.0402, weight:2.00, lr:0.0001
[12:49:33.216] iteration:28734  t-loss:0.1473, loss-lb:0.0670, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:49:33.409] iteration:28735  t-loss:0.1368, loss-lb:0.0696, loss-ulb:0.0336, weight:2.00, lr:0.0001
[12:49:33.602] iteration:28736  t-loss:0.1524, loss-lb:0.0732, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:49:33.796] iteration:28737  t-loss:0.1336, loss-lb:0.0671, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:49:33.989] iteration:28738  t-loss:0.1455, loss-lb:0.0677, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:49:34.182] iteration:28739  t-loss:0.1422, loss-lb:0.0701, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:49:34.376] iteration:28740  t-loss:0.1816, loss-lb:0.0688, loss-ulb:0.0564, weight:2.00, lr:0.0001
[12:49:34.569] iteration:28741  t-loss:0.1415, loss-lb:0.0654, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:49:34.761] iteration:28742  t-loss:0.1340, loss-lb:0.0687, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:49:34.954] iteration:28743  t-loss:0.1310, loss-lb:0.0615, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:49:35.146] iteration:28744  t-loss:0.1591, loss-lb:0.0753, loss-ulb:0.0419, weight:2.00, lr:0.0001
[12:49:35.339] iteration:28745  t-loss:0.1740, loss-lb:0.0686, loss-ulb:0.0527, weight:2.00, lr:0.0001
[12:49:35.533] iteration:28746  t-loss:0.1362, loss-lb:0.0650, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:49:35.725] iteration:28747  t-loss:0.1550, loss-lb:0.0713, loss-ulb:0.0418, weight:2.00, lr:0.0001
[12:49:35.919] iteration:28748  t-loss:0.1569, loss-lb:0.0691, loss-ulb:0.0439, weight:2.00, lr:0.0001
[12:49:36.112] iteration:28749  t-loss:0.1328, loss-lb:0.0689, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:49:36.305] iteration:28750  t-loss:0.1581, loss-lb:0.0855, loss-ulb:0.0363, weight:2.00, lr:0.0001
[12:49:36.498] iteration:28751  t-loss:0.1506, loss-lb:0.0714, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:49:36.689] iteration:28752  t-loss:0.1320, loss-lb:0.0604, loss-ulb:0.0358, weight:2.00, lr:0.0001
[12:49:36.882] iteration:28753  t-loss:0.1313, loss-lb:0.0687, loss-ulb:0.0313, weight:2.00, lr:0.0001
[12:49:37.075] iteration:28754  t-loss:0.1390, loss-lb:0.0666, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:49:37.268] iteration:28755  t-loss:0.1277, loss-lb:0.0626, loss-ulb:0.0326, weight:2.00, lr:0.0001
[12:49:37.461] iteration:28756  t-loss:0.1559, loss-lb:0.0730, loss-ulb:0.0415, weight:2.00, lr:0.0001
[12:49:37.654] iteration:28757  t-loss:0.1565, loss-lb:0.0713, loss-ulb:0.0426, weight:2.00, lr:0.0001
[12:49:37.852] iteration:28758  t-loss:0.1317, loss-lb:0.0667, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:49:38.044] iteration:28759  t-loss:0.1460, loss-lb:0.0750, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:49:38.236] iteration:28760  t-loss:0.1491, loss-lb:0.0632, loss-ulb:0.0429, weight:2.00, lr:0.0001
[12:49:38.428] iteration:28761  t-loss:0.1241, loss-lb:0.0649, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:49:38.628] iteration:28762  t-loss:0.1452, loss-lb:0.0731, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:49:38.821] iteration:28763  t-loss:0.1736, loss-lb:0.0742, loss-ulb:0.0497, weight:2.00, lr:0.0001
[12:49:39.014] iteration:28764  t-loss:0.1360, loss-lb:0.0705, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:49:39.206] iteration:28765  t-loss:0.1392, loss-lb:0.0709, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:49:39.405] iteration:28766  t-loss:0.1393, loss-lb:0.0653, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:49:39.597] iteration:28767  t-loss:0.1319, loss-lb:0.0701, loss-ulb:0.0309, weight:2.00, lr:0.0001
[12:49:39.788] iteration:28768  t-loss:0.1529, loss-lb:0.0691, loss-ulb:0.0419, weight:2.00, lr:0.0001
[12:49:39.982] iteration:28769  t-loss:0.1420, loss-lb:0.0734, loss-ulb:0.0343, weight:2.00, lr:0.0001
[12:49:40.182] iteration:28770  t-loss:0.1336, loss-lb:0.0638, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:49:40.373] iteration:28771  t-loss:0.1537, loss-lb:0.0754, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:49:40.565] iteration:28772  t-loss:0.1478, loss-lb:0.0702, loss-ulb:0.0388, weight:2.00, lr:0.0001
[12:49:40.757] iteration:28773  t-loss:0.1376, loss-lb:0.0686, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:49:40.958] iteration:28774  t-loss:0.1485, loss-lb:0.0644, loss-ulb:0.0420, weight:2.00, lr:0.0001
[12:49:41.152] iteration:28775  t-loss:0.1307, loss-lb:0.0643, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:49:41.343] iteration:28776  t-loss:0.1354, loss-lb:0.0622, loss-ulb:0.0366, weight:2.00, lr:0.0001
[12:49:41.535] iteration:28777  t-loss:0.1404, loss-lb:0.0738, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:49:41.734] iteration:28778  t-loss:0.1302, loss-lb:0.0695, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:49:41.926] iteration:28779  t-loss:0.1459, loss-lb:0.0681, loss-ulb:0.0389, weight:2.00, lr:0.0001
[12:49:42.119] iteration:28780  t-loss:0.1387, loss-lb:0.0717, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:49:42.311] iteration:28781  t-loss:0.1799, loss-lb:0.0762, loss-ulb:0.0518, weight:2.00, lr:0.0001
[12:49:42.511] iteration:28782  t-loss:0.1325, loss-lb:0.0677, loss-ulb:0.0324, weight:2.00, lr:0.0001
[12:49:42.704] iteration:28783  t-loss:0.1430, loss-lb:0.0718, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:49:42.896] iteration:28784  t-loss:0.1628, loss-lb:0.0654, loss-ulb:0.0487, weight:2.00, lr:0.0001
[12:49:43.088] iteration:28785  t-loss:0.1981, loss-lb:0.0810, loss-ulb:0.0585, weight:2.00, lr:0.0001
[12:49:43.280] iteration:28786  t-loss:0.1601, loss-lb:0.0668, loss-ulb:0.0467, weight:2.00, lr:0.0001
[12:49:43.472] iteration:28787  t-loss:0.1728, loss-lb:0.0719, loss-ulb:0.0505, weight:2.00, lr:0.0001
[12:49:43.664] iteration:28788  t-loss:0.1346, loss-lb:0.0677, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:49:43.855] iteration:28789  t-loss:0.1487, loss-lb:0.0680, loss-ulb:0.0403, weight:2.00, lr:0.0001
[12:49:44.047] iteration:28790  t-loss:0.1314, loss-lb:0.0699, loss-ulb:0.0308, weight:2.00, lr:0.0001
[12:49:44.251] iteration:28791  t-loss:0.1917, loss-lb:0.0714, loss-ulb:0.0602, weight:2.00, lr:0.0001
[12:49:44.449] iteration:28792  t-loss:0.1371, loss-lb:0.0681, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:49:44.641] iteration:28793  t-loss:0.1410, loss-lb:0.0663, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:49:44.833] iteration:28794  t-loss:0.1405, loss-lb:0.0740, loss-ulb:0.0332, weight:2.00, lr:0.0001
[12:49:45.024] iteration:28795  t-loss:0.1367, loss-lb:0.0642, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:49:45.215] iteration:28796  t-loss:0.1429, loss-lb:0.0702, loss-ulb:0.0364, weight:2.00, lr:0.0001
[12:49:45.407] iteration:28797  t-loss:0.1402, loss-lb:0.0648, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:49:45.599] iteration:28798  t-loss:0.1648, loss-lb:0.0617, loss-ulb:0.0515, weight:2.00, lr:0.0001
[12:49:45.791] iteration:28799  t-loss:0.1362, loss-lb:0.0709, loss-ulb:0.0327, weight:2.00, lr:0.0001
[12:49:45.982] iteration:28800  t-loss:0.1362, loss-lb:0.0701, loss-ulb:0.0331, weight:2.00, lr:0.0001
[12:49:46.175] iteration:28801  t-loss:0.1345, loss-lb:0.0632, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:49:46.370] iteration:28802  t-loss:0.1735, loss-lb:0.0637, loss-ulb:0.0549, weight:2.00, lr:0.0001
[12:49:46.565] iteration:28803  t-loss:0.1459, loss-lb:0.0718, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:49:46.764] iteration:28804  t-loss:0.1430, loss-lb:0.0669, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:49:46.958] iteration:28805  t-loss:0.1451, loss-lb:0.0717, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:49:47.151] iteration:28806  t-loss:0.1267, loss-lb:0.0626, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:49:47.342] iteration:28807  t-loss:0.1484, loss-lb:0.0733, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:49:47.532] iteration:28808  t-loss:0.1384, loss-lb:0.0675, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:49:47.722] iteration:28809  t-loss:0.1257, loss-lb:0.0664, loss-ulb:0.0296, weight:2.00, lr:0.0001
[12:49:47.913] iteration:28810  t-loss:0.1517, loss-lb:0.0774, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:49:48.104] iteration:28811  t-loss:0.1307, loss-lb:0.0609, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:49:48.295] iteration:28812  t-loss:0.1570, loss-lb:0.0663, loss-ulb:0.0454, weight:2.00, lr:0.0001
[12:49:48.868] iteration:28813  t-loss:0.1422, loss-lb:0.0731, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:49:49.062] iteration:28814  t-loss:0.1494, loss-lb:0.0782, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:49:49.255] iteration:28815  t-loss:0.1437, loss-lb:0.0646, loss-ulb:0.0395, weight:2.00, lr:0.0001
[12:49:49.447] iteration:28816  t-loss:0.1331, loss-lb:0.0674, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:49:49.640] iteration:28817  t-loss:0.1444, loss-lb:0.0747, loss-ulb:0.0348, weight:2.00, lr:0.0001
[12:49:49.831] iteration:28818  t-loss:0.1697, loss-lb:0.0713, loss-ulb:0.0492, weight:2.00, lr:0.0001
[12:49:50.023] iteration:28819  t-loss:0.1355, loss-lb:0.0647, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:49:50.215] iteration:28820  t-loss:0.1496, loss-lb:0.0677, loss-ulb:0.0410, weight:2.00, lr:0.0001
[12:49:50.407] iteration:28821  t-loss:0.1355, loss-lb:0.0665, loss-ulb:0.0345, weight:2.00, lr:0.0001
[12:49:50.599] iteration:28822  t-loss:0.1340, loss-lb:0.0674, loss-ulb:0.0333, weight:2.00, lr:0.0001
[12:49:50.790] iteration:28823  t-loss:0.1376, loss-lb:0.0604, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:49:50.983] iteration:28824  t-loss:0.1394, loss-lb:0.0694, loss-ulb:0.0350, weight:2.00, lr:0.0001
[12:49:51.175] iteration:28825  t-loss:0.1512, loss-lb:0.0632, loss-ulb:0.0440, weight:2.00, lr:0.0001
[12:49:51.366] iteration:28826  t-loss:0.1342, loss-lb:0.0659, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:49:51.559] iteration:28827  t-loss:0.1549, loss-lb:0.0702, loss-ulb:0.0424, weight:2.00, lr:0.0001
[12:49:51.750] iteration:28828  t-loss:0.1382, loss-lb:0.0658, loss-ulb:0.0362, weight:2.00, lr:0.0001
[12:49:51.943] iteration:28829  t-loss:0.1558, loss-lb:0.0824, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:49:52.134] iteration:28830  t-loss:0.1345, loss-lb:0.0776, loss-ulb:0.0284, weight:2.00, lr:0.0001
[12:49:52.326] iteration:28831  t-loss:0.1454, loss-lb:0.0753, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:49:52.518] iteration:28832  t-loss:0.1417, loss-lb:0.0705, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:49:52.711] iteration:28833  t-loss:0.1391, loss-lb:0.0683, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:49:52.903] iteration:28834  t-loss:0.1564, loss-lb:0.0691, loss-ulb:0.0436, weight:2.00, lr:0.0001
[12:49:53.096] iteration:28835  t-loss:0.1415, loss-lb:0.0668, loss-ulb:0.0373, weight:2.00, lr:0.0001
[12:49:53.288] iteration:28836  t-loss:0.1389, loss-lb:0.0671, loss-ulb:0.0359, weight:2.00, lr:0.0001
[12:49:53.480] iteration:28837  t-loss:0.1459, loss-lb:0.0710, loss-ulb:0.0374, weight:2.00, lr:0.0001
[12:49:53.672] iteration:28838  t-loss:0.1386, loss-lb:0.0716, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:49:53.864] iteration:28839  t-loss:0.1357, loss-lb:0.0617, loss-ulb:0.0370, weight:2.00, lr:0.0001
[12:49:54.058] iteration:28840  t-loss:0.1491, loss-lb:0.0688, loss-ulb:0.0402, weight:2.00, lr:0.0001
[12:49:54.251] iteration:28841  t-loss:0.1518, loss-lb:0.0720, loss-ulb:0.0399, weight:2.00, lr:0.0001
[12:49:54.442] iteration:28842  t-loss:0.1468, loss-lb:0.0786, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:49:54.633] iteration:28843  t-loss:0.1481, loss-lb:0.0678, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:49:54.828] iteration:28844  t-loss:0.1213, loss-lb:0.0628, loss-ulb:0.0292, weight:2.00, lr:0.0001
[12:49:55.020] iteration:28845  t-loss:0.1425, loss-lb:0.0675, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:49:55.213] iteration:28846  t-loss:0.1856, loss-lb:0.0573, loss-ulb:0.0642, weight:2.00, lr:0.0001
[12:49:55.405] iteration:28847  t-loss:0.1282, loss-lb:0.0626, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:49:55.597] iteration:28848  t-loss:0.1458, loss-lb:0.0686, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:49:55.788] iteration:28849  t-loss:0.1572, loss-lb:0.0726, loss-ulb:0.0423, weight:2.00, lr:0.0001
[12:49:55.980] iteration:28850  t-loss:0.1428, loss-lb:0.0634, loss-ulb:0.0397, weight:2.00, lr:0.0001
[12:49:56.171] iteration:28851  t-loss:0.1417, loss-lb:0.0749, loss-ulb:0.0334, weight:2.00, lr:0.0001
[12:49:56.363] iteration:28852  t-loss:0.1393, loss-lb:0.0711, loss-ulb:0.0341, weight:2.00, lr:0.0001
[12:49:56.553] iteration:28853  t-loss:0.1381, loss-lb:0.0636, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:49:56.745] iteration:28854  t-loss:0.1526, loss-lb:0.0791, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:49:56.937] iteration:28855  t-loss:0.1394, loss-lb:0.0761, loss-ulb:0.0317, weight:2.00, lr:0.0001
[12:49:57.128] iteration:28856  t-loss:0.1512, loss-lb:0.0792, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:49:57.321] iteration:28857  t-loss:0.1316, loss-lb:0.0607, loss-ulb:0.0355, weight:2.00, lr:0.0001
[12:49:57.516] iteration:28858  t-loss:0.1446, loss-lb:0.0687, loss-ulb:0.0379, weight:2.00, lr:0.0001
[12:49:57.713] iteration:28859  t-loss:0.1270, loss-lb:0.0592, loss-ulb:0.0339, weight:2.00, lr:0.0001
[12:49:57.908] iteration:28860  t-loss:0.1399, loss-lb:0.0655, loss-ulb:0.0372, weight:2.00, lr:0.0001
[12:49:58.102] iteration:28861  t-loss:0.1463, loss-lb:0.0726, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:49:58.295] iteration:28862  t-loss:0.1551, loss-lb:0.0679, loss-ulb:0.0436, weight:2.00, lr:0.0001
[12:49:58.487] iteration:28863  t-loss:0.2014, loss-lb:0.0673, loss-ulb:0.0671, weight:2.00, lr:0.0001
[12:49:58.679] iteration:28864  t-loss:0.1502, loss-lb:0.0730, loss-ulb:0.0386, weight:2.00, lr:0.0001
[12:49:58.872] iteration:28865  t-loss:0.1295, loss-lb:0.0715, loss-ulb:0.0290, weight:2.00, lr:0.0001
[12:49:59.064] iteration:28866  t-loss:0.1292, loss-lb:0.0615, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:49:59.257] iteration:28867  t-loss:0.1551, loss-lb:0.0704, loss-ulb:0.0424, weight:2.00, lr:0.0001
[12:49:59.448] iteration:28868  t-loss:0.1357, loss-lb:0.0760, loss-ulb:0.0299, weight:2.00, lr:0.0001
[12:49:59.640] iteration:28869  t-loss:0.1332, loss-lb:0.0655, loss-ulb:0.0338, weight:2.00, lr:0.0001
[12:49:59.833] iteration:28870  t-loss:0.1538, loss-lb:0.0700, loss-ulb:0.0419, weight:2.00, lr:0.0001
[12:50:00.025] iteration:28871  t-loss:0.1383, loss-lb:0.0685, loss-ulb:0.0349, weight:2.00, lr:0.0001
[12:50:00.217] iteration:28872  t-loss:0.1498, loss-lb:0.0713, loss-ulb:0.0392, weight:2.00, lr:0.0001
[12:50:00.408] iteration:28873  t-loss:0.1380, loss-lb:0.0637, loss-ulb:0.0371, weight:2.00, lr:0.0001
[12:50:00.601] iteration:28874  t-loss:0.1446, loss-lb:0.0725, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:50:00.793] iteration:28875  t-loss:0.1333, loss-lb:0.0683, loss-ulb:0.0325, weight:2.00, lr:0.0001
[12:50:00.986] iteration:28876  t-loss:0.1747, loss-lb:0.0645, loss-ulb:0.0551, weight:2.00, lr:0.0001
[12:50:01.178] iteration:28877  t-loss:0.1463, loss-lb:0.0667, loss-ulb:0.0398, weight:2.00, lr:0.0001
[12:50:01.370] iteration:28878  t-loss:0.1271, loss-lb:0.0670, loss-ulb:0.0301, weight:2.00, lr:0.0001
[12:50:01.563] iteration:28879  t-loss:0.1396, loss-lb:0.0749, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:50:01.756] iteration:28880  t-loss:0.1371, loss-lb:0.0697, loss-ulb:0.0337, weight:2.00, lr:0.0001
[12:50:01.947] iteration:28881  t-loss:0.1499, loss-lb:0.0737, loss-ulb:0.0381, weight:2.00, lr:0.0001
[12:50:02.140] iteration:28882  t-loss:0.1283, loss-lb:0.0675, loss-ulb:0.0304, weight:2.00, lr:0.0001
[12:50:02.332] iteration:28883  t-loss:0.1384, loss-lb:0.0634, loss-ulb:0.0375, weight:2.00, lr:0.0001
[12:50:02.524] iteration:28884  t-loss:0.1312, loss-lb:0.0754, loss-ulb:0.0279, weight:2.00, lr:0.0001
[12:50:02.717] iteration:28885  t-loss:0.1258, loss-lb:0.0706, loss-ulb:0.0276, weight:2.00, lr:0.0001
[12:50:02.909] iteration:28886  t-loss:0.1321, loss-lb:0.0666, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:50:03.101] iteration:28887  t-loss:0.1539, loss-lb:0.0787, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:50:03.293] iteration:28888  t-loss:0.1438, loss-lb:0.0636, loss-ulb:0.0401, weight:2.00, lr:0.0001
[12:50:03.485] iteration:28889  t-loss:0.1515, loss-lb:0.0733, loss-ulb:0.0391, weight:2.00, lr:0.0001
[12:50:03.677] iteration:28890  t-loss:0.1469, loss-lb:0.0655, loss-ulb:0.0407, weight:2.00, lr:0.0001
[12:50:03.869] iteration:28891  t-loss:0.1342, loss-lb:0.0700, loss-ulb:0.0321, weight:2.00, lr:0.0001
[12:50:04.062] iteration:28892  t-loss:0.1503, loss-lb:0.0670, loss-ulb:0.0417, weight:2.00, lr:0.0001
[12:50:04.253] iteration:28893  t-loss:0.1393, loss-lb:0.0688, loss-ulb:0.0352, weight:2.00, lr:0.0001
[12:50:04.445] iteration:28894  t-loss:0.1359, loss-lb:0.0737, loss-ulb:0.0311, weight:2.00, lr:0.0001
[12:50:04.637] iteration:28895  t-loss:0.1274, loss-lb:0.0635, loss-ulb:0.0320, weight:2.00, lr:0.0001
[12:50:04.829] iteration:28896  t-loss:0.1298, loss-lb:0.0688, loss-ulb:0.0305, weight:2.00, lr:0.0001
[12:50:05.021] iteration:28897  t-loss:0.1388, loss-lb:0.0628, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:50:05.214] iteration:28898  t-loss:0.1444, loss-lb:0.0684, loss-ulb:0.0380, weight:2.00, lr:0.0001
[12:50:05.406] iteration:28899  t-loss:0.1345, loss-lb:0.0699, loss-ulb:0.0323, weight:2.00, lr:0.0001
[12:50:05.597] iteration:28900  t-loss:0.1287, loss-lb:0.0632, loss-ulb:0.0328, weight:2.00, lr:0.0001
[12:50:05.791] iteration:28901  t-loss:0.1689, loss-lb:0.0687, loss-ulb:0.0501, weight:2.00, lr:0.0001
[12:50:05.982] iteration:28902  t-loss:0.1429, loss-lb:0.0676, loss-ulb:0.0377, weight:2.00, lr:0.0001
[12:50:06.173] iteration:28903  t-loss:0.1590, loss-lb:0.0723, loss-ulb:0.0434, weight:2.00, lr:0.0001
[12:50:06.365] iteration:28904  t-loss:0.1427, loss-lb:0.0689, loss-ulb:0.0369, weight:2.00, lr:0.0001
[12:50:06.555] iteration:28905  t-loss:0.1343, loss-lb:0.0707, loss-ulb:0.0318, weight:2.00, lr:0.0001
[12:50:06.744] iteration:28906  t-loss:0.1505, loss-lb:0.0683, loss-ulb:0.0411, weight:2.00, lr:0.0001
[12:50:06.934] iteration:28907  t-loss:0.1392, loss-lb:0.0671, loss-ulb:0.0360, weight:2.00, lr:0.0001
[12:50:07.123] iteration:28908  t-loss:0.1699, loss-lb:0.0725, loss-ulb:0.0487, weight:2.00, lr:0.0001
[12:50:07.313] iteration:28909  t-loss:0.1571, loss-lb:0.0668, loss-ulb:0.0452, weight:2.00, lr:0.0001
[12:50:07.503] iteration:28910  t-loss:0.1467, loss-lb:0.0675, loss-ulb:0.0396, weight:2.00, lr:0.0001
[12:50:19.903]  <<Test>> - Ep:294  - mean_dice/mean_h95 - S:89.83/1.34, Best-S:90.99, T:89.70/1.36, Best-T:90.48
[12:50:19.903]           - AvgLoss(lb/ulb/all):0.0690/0.0377/0.1437
[12:50:20.445] iteration:28911  t-loss:0.1366, loss-lb:0.0708, loss-ulb:0.0329, weight:2.00, lr:0.0001
[12:50:20.643] iteration:28912  t-loss:0.1378, loss-lb:0.0708, loss-ulb:0.0335, weight:2.00, lr:0.0001
[12:50:20.836] iteration:28913  t-loss:0.1421, loss-lb:0.0700, loss-ulb:0.0361, weight:2.00, lr:0.0001
[12:50:21.029] iteration:28914  t-loss:0.1498, loss-lb:0.0763, loss-ulb:0.0367, weight:2.00, lr:0.0001
[12:50:21.222] iteration:28915  t-loss:0.1423, loss-lb:0.0743, loss-ulb:0.0340, weight:2.00, lr:0.0001
[12:50:21.415] iteration:28916  t-loss:0.1353, loss-lb:0.0641, loss-ulb:0.0356, weight:2.00, lr:0.0001
[12:50:21.609] iteration:28917  t-loss:0.1455, loss-lb:0.0762, loss-ulb:0.0347, weight:2.00, lr:0.0001
[12:50:21.803] iteration:28918  t-loss:0.1367, loss-lb:0.0616, loss-ulb:0.0376, weight:2.00, lr:0.0001
[12:50:21.996] iteration:28919  t-loss:0.1332, loss-lb:0.0629, loss-ulb:0.0351, weight:2.00, lr:0.0001
[12:50:22.189] iteration:28920  t-loss:0.1244, loss-lb:0.0660, loss-ulb:0.0292, weight:2.00, lr:0.0001
[12:50:22.382] iteration:28921  t-loss:0.1401, loss-lb:0.0718, loss-ulb:0.0342, weight:2.00, lr:0.0001
[12:50:22.576] iteration:28922  t-loss:0.1547, loss-lb:0.0661, loss-ulb:0.0443, weight:2.00, lr:0.0001
[12:50:22.768] iteration:28923  t-loss:0.1381, loss-lb:0.0673, loss-ulb:0.0354, weight:2.00, lr:0.0001
[12:50:22.961] iteration:28924  t-loss:0.1280, loss-lb:0.0674, loss-ulb:0.0303, weight:2.00, lr:0.0001
[12:50:23.154] iteration:28925  t-loss:0.1403, loss-lb:0.0622, loss-ulb:0.0390, weight:2.00, lr:0.0001
[12:50:23.347] iteration:28926  t-loss:0.1394, loss-lb:0.0646, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:50:23.541] iteration:28927  t-loss:0.1591, loss-lb:0.0704, loss-ulb:0.0444, weight:2.00, lr:0.0000
[12:50:23.735] iteration:28928  t-loss:0.1701, loss-lb:0.0751, loss-ulb:0.0475, weight:2.00, lr:0.0000
[12:50:23.927] iteration:28929  t-loss:0.1427, loss-lb:0.0718, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:50:24.120] iteration:28930  t-loss:0.1506, loss-lb:0.0722, loss-ulb:0.0392, weight:2.00, lr:0.0000
[12:50:24.313] iteration:28931  t-loss:0.1675, loss-lb:0.0743, loss-ulb:0.0466, weight:2.00, lr:0.0000
[12:50:24.506] iteration:28932  t-loss:0.1683, loss-lb:0.0788, loss-ulb:0.0447, weight:2.00, lr:0.0000
[12:50:24.699] iteration:28933  t-loss:0.1437, loss-lb:0.0719, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:50:24.891] iteration:28934  t-loss:0.1361, loss-lb:0.0597, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:50:25.084] iteration:28935  t-loss:0.1310, loss-lb:0.0688, loss-ulb:0.0311, weight:2.00, lr:0.0000
[12:50:25.277] iteration:28936  t-loss:0.2523, loss-lb:0.0782, loss-ulb:0.0871, weight:2.00, lr:0.0000
[12:50:25.469] iteration:28937  t-loss:0.1442, loss-lb:0.0652, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:50:25.660] iteration:28938  t-loss:0.1436, loss-lb:0.0744, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:50:25.853] iteration:28939  t-loss:0.1369, loss-lb:0.0659, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:50:26.044] iteration:28940  t-loss:0.1669, loss-lb:0.0754, loss-ulb:0.0457, weight:2.00, lr:0.0000
[12:50:26.237] iteration:28941  t-loss:0.1385, loss-lb:0.0667, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:50:26.429] iteration:28942  t-loss:0.1378, loss-lb:0.0687, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:50:26.621] iteration:28943  t-loss:0.1474, loss-lb:0.0699, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:50:26.813] iteration:28944  t-loss:0.1251, loss-lb:0.0639, loss-ulb:0.0306, weight:2.00, lr:0.0000
[12:50:27.007] iteration:28945  t-loss:0.1570, loss-lb:0.0638, loss-ulb:0.0466, weight:2.00, lr:0.0000
[12:50:27.202] iteration:28946  t-loss:0.1584, loss-lb:0.0839, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:50:27.395] iteration:28947  t-loss:0.1456, loss-lb:0.0739, loss-ulb:0.0358, weight:2.00, lr:0.0000
[12:50:27.586] iteration:28948  t-loss:0.1452, loss-lb:0.0601, loss-ulb:0.0425, weight:2.00, lr:0.0000
[12:50:27.779] iteration:28949  t-loss:0.1414, loss-lb:0.0745, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:50:27.971] iteration:28950  t-loss:0.1282, loss-lb:0.0674, loss-ulb:0.0304, weight:2.00, lr:0.0000
[12:50:28.163] iteration:28951  t-loss:0.1461, loss-lb:0.0658, loss-ulb:0.0401, weight:2.00, lr:0.0000
[12:50:28.356] iteration:28952  t-loss:0.1732, loss-lb:0.0743, loss-ulb:0.0494, weight:2.00, lr:0.0000
[12:50:28.550] iteration:28953  t-loss:0.1968, loss-lb:0.0697, loss-ulb:0.0636, weight:2.00, lr:0.0000
[12:50:28.742] iteration:28954  t-loss:0.1333, loss-lb:0.0640, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:50:28.934] iteration:28955  t-loss:0.1385, loss-lb:0.0645, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:50:29.126] iteration:28956  t-loss:0.1434, loss-lb:0.0694, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:50:29.320] iteration:28957  t-loss:0.1252, loss-lb:0.0625, loss-ulb:0.0314, weight:2.00, lr:0.0000
[12:50:29.513] iteration:28958  t-loss:0.1377, loss-lb:0.0685, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:50:29.705] iteration:28959  t-loss:0.1668, loss-lb:0.0725, loss-ulb:0.0472, weight:2.00, lr:0.0000
[12:50:29.898] iteration:28960  t-loss:0.1366, loss-lb:0.0717, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:50:30.090] iteration:28961  t-loss:0.1473, loss-lb:0.0659, loss-ulb:0.0407, weight:2.00, lr:0.0000
[12:50:30.283] iteration:28962  t-loss:0.1641, loss-lb:0.0694, loss-ulb:0.0474, weight:2.00, lr:0.0000
[12:50:30.476] iteration:28963  t-loss:0.1561, loss-lb:0.0719, loss-ulb:0.0421, weight:2.00, lr:0.0000
[12:50:30.669] iteration:28964  t-loss:0.1327, loss-lb:0.0685, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:50:30.861] iteration:28965  t-loss:0.1458, loss-lb:0.0698, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:50:31.053] iteration:28966  t-loss:0.1379, loss-lb:0.0704, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:50:31.247] iteration:28967  t-loss:0.1371, loss-lb:0.0735, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:50:31.441] iteration:28968  t-loss:0.1589, loss-lb:0.0695, loss-ulb:0.0447, weight:2.00, lr:0.0000
[12:50:31.633] iteration:28969  t-loss:0.1479, loss-lb:0.0716, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:50:31.824] iteration:28970  t-loss:0.1393, loss-lb:0.0646, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:50:32.017] iteration:28971  t-loss:0.1337, loss-lb:0.0612, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:50:32.210] iteration:28972  t-loss:0.1411, loss-lb:0.0604, loss-ulb:0.0403, weight:2.00, lr:0.0000
[12:50:32.403] iteration:28973  t-loss:0.1632, loss-lb:0.0716, loss-ulb:0.0458, weight:2.00, lr:0.0000
[12:50:32.595] iteration:28974  t-loss:0.1399, loss-lb:0.0715, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:50:32.788] iteration:28975  t-loss:0.1394, loss-lb:0.0730, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:50:32.980] iteration:28976  t-loss:0.1525, loss-lb:0.0707, loss-ulb:0.0409, weight:2.00, lr:0.0000
[12:50:33.173] iteration:28977  t-loss:0.1890, loss-lb:0.0742, loss-ulb:0.0574, weight:2.00, lr:0.0000
[12:50:33.366] iteration:28978  t-loss:0.1339, loss-lb:0.0667, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:50:33.557] iteration:28979  t-loss:0.1230, loss-lb:0.0651, loss-ulb:0.0289, weight:2.00, lr:0.0000
[12:50:33.750] iteration:28980  t-loss:0.1432, loss-lb:0.0642, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:50:33.943] iteration:28981  t-loss:0.1381, loss-lb:0.0740, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:50:34.136] iteration:28982  t-loss:0.1538, loss-lb:0.0734, loss-ulb:0.0402, weight:2.00, lr:0.0000
[12:50:34.328] iteration:28983  t-loss:0.1485, loss-lb:0.0757, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:50:34.521] iteration:28984  t-loss:0.1474, loss-lb:0.0684, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:50:34.714] iteration:28985  t-loss:0.1730, loss-lb:0.0630, loss-ulb:0.0550, weight:2.00, lr:0.0000
[12:50:34.905] iteration:28986  t-loss:0.1378, loss-lb:0.0697, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:50:35.097] iteration:28987  t-loss:0.1305, loss-lb:0.0683, loss-ulb:0.0311, weight:2.00, lr:0.0000
[12:50:35.289] iteration:28988  t-loss:0.1286, loss-lb:0.0651, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:50:35.480] iteration:28989  t-loss:0.1399, loss-lb:0.0723, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:50:35.673] iteration:28990  t-loss:0.1445, loss-lb:0.0750, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:50:35.866] iteration:28991  t-loss:0.1367, loss-lb:0.0652, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:50:36.058] iteration:28992  t-loss:0.1463, loss-lb:0.0722, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:50:36.251] iteration:28993  t-loss:0.1489, loss-lb:0.0663, loss-ulb:0.0413, weight:2.00, lr:0.0000
[12:50:36.445] iteration:28994  t-loss:0.1419, loss-lb:0.0668, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:50:36.637] iteration:28995  t-loss:0.1417, loss-lb:0.0657, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:50:36.829] iteration:28996  t-loss:0.1262, loss-lb:0.0637, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:50:37.023] iteration:28997  t-loss:0.1377, loss-lb:0.0770, loss-ulb:0.0303, weight:2.00, lr:0.0000
[12:50:37.216] iteration:28998  t-loss:0.1439, loss-lb:0.0643, loss-ulb:0.0398, weight:2.00, lr:0.0000
[12:50:37.409] iteration:28999  t-loss:0.1374, loss-lb:0.0728, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:50:37.602] iteration:29000  t-loss:0.1550, loss-lb:0.0627, loss-ulb:0.0461, weight:2.00, lr:0.0000
[12:50:37.794] iteration:29001  t-loss:0.1592, loss-lb:0.0671, loss-ulb:0.0460, weight:2.00, lr:0.0000
[12:50:37.987] iteration:29002  t-loss:0.1439, loss-lb:0.0699, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:50:38.176] iteration:29003  t-loss:0.1320, loss-lb:0.0655, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:50:38.367] iteration:29004  t-loss:0.1400, loss-lb:0.0719, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:50:38.557] iteration:29005  t-loss:0.1349, loss-lb:0.0650, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:50:38.748] iteration:29006  t-loss:0.1404, loss-lb:0.0703, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:50:38.938] iteration:29007  t-loss:0.1460, loss-lb:0.0663, loss-ulb:0.0398, weight:2.00, lr:0.0000
[12:50:39.130] iteration:29008  t-loss:0.1426, loss-lb:0.0684, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:50:39.711] iteration:29009  t-loss:0.1338, loss-lb:0.0637, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:50:39.906] iteration:29010  t-loss:0.1429, loss-lb:0.0728, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:50:40.098] iteration:29011  t-loss:0.1323, loss-lb:0.0640, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:50:40.291] iteration:29012  t-loss:0.1478, loss-lb:0.0715, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:50:40.485] iteration:29013  t-loss:0.1305, loss-lb:0.0736, loss-ulb:0.0284, weight:2.00, lr:0.0000
[12:50:40.677] iteration:29014  t-loss:0.1465, loss-lb:0.0694, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:50:40.869] iteration:29015  t-loss:0.1389, loss-lb:0.0671, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:50:41.062] iteration:29016  t-loss:0.1450, loss-lb:0.0714, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:50:41.254] iteration:29017  t-loss:0.1332, loss-lb:0.0636, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:50:41.446] iteration:29018  t-loss:0.1291, loss-lb:0.0668, loss-ulb:0.0312, weight:2.00, lr:0.0000
[12:50:41.639] iteration:29019  t-loss:0.1594, loss-lb:0.0784, loss-ulb:0.0405, weight:2.00, lr:0.0000
[12:50:41.832] iteration:29020  t-loss:0.1520, loss-lb:0.0679, loss-ulb:0.0420, weight:2.00, lr:0.0000
[12:50:42.024] iteration:29021  t-loss:0.1809, loss-lb:0.0747, loss-ulb:0.0531, weight:2.00, lr:0.0000
[12:50:42.216] iteration:29022  t-loss:0.1430, loss-lb:0.0753, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:50:42.408] iteration:29023  t-loss:0.1283, loss-lb:0.0688, loss-ulb:0.0297, weight:2.00, lr:0.0000
[12:50:42.601] iteration:29024  t-loss:0.1254, loss-lb:0.0575, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:50:42.793] iteration:29025  t-loss:0.1458, loss-lb:0.0716, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:50:42.986] iteration:29026  t-loss:0.1538, loss-lb:0.0707, loss-ulb:0.0416, weight:2.00, lr:0.0000
[12:50:43.179] iteration:29027  t-loss:0.1645, loss-lb:0.0686, loss-ulb:0.0479, weight:2.00, lr:0.0000
[12:50:43.371] iteration:29028  t-loss:0.1328, loss-lb:0.0637, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:50:43.564] iteration:29029  t-loss:0.1592, loss-lb:0.0777, loss-ulb:0.0407, weight:2.00, lr:0.0000
[12:50:43.756] iteration:29030  t-loss:0.1451, loss-lb:0.0662, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:50:43.950] iteration:29031  t-loss:0.1491, loss-lb:0.0675, loss-ulb:0.0408, weight:2.00, lr:0.0000
[12:50:44.143] iteration:29032  t-loss:0.1308, loss-lb:0.0669, loss-ulb:0.0320, weight:2.00, lr:0.0000
[12:50:44.335] iteration:29033  t-loss:0.1395, loss-lb:0.0688, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:50:44.527] iteration:29034  t-loss:0.1534, loss-lb:0.0805, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:50:44.719] iteration:29035  t-loss:0.1415, loss-lb:0.0716, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:50:44.911] iteration:29036  t-loss:0.1443, loss-lb:0.0684, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:50:45.104] iteration:29037  t-loss:0.1313, loss-lb:0.0660, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:50:45.296] iteration:29038  t-loss:0.1425, loss-lb:0.0699, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:50:45.489] iteration:29039  t-loss:0.1365, loss-lb:0.0692, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:50:45.683] iteration:29040  t-loss:0.1560, loss-lb:0.0728, loss-ulb:0.0416, weight:2.00, lr:0.0000
[12:50:45.874] iteration:29041  t-loss:0.1455, loss-lb:0.0645, loss-ulb:0.0405, weight:2.00, lr:0.0000
[12:50:46.066] iteration:29042  t-loss:0.1223, loss-lb:0.0642, loss-ulb:0.0290, weight:2.00, lr:0.0000
[12:50:46.260] iteration:29043  t-loss:0.1324, loss-lb:0.0683, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:50:46.452] iteration:29044  t-loss:0.1389, loss-lb:0.0688, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:50:46.644] iteration:29045  t-loss:0.1436, loss-lb:0.0693, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:50:46.836] iteration:29046  t-loss:0.1257, loss-lb:0.0654, loss-ulb:0.0302, weight:2.00, lr:0.0000
[12:50:47.028] iteration:29047  t-loss:0.1442, loss-lb:0.0758, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:50:47.220] iteration:29048  t-loss:0.1404, loss-lb:0.0639, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:50:47.413] iteration:29049  t-loss:0.1280, loss-lb:0.0664, loss-ulb:0.0308, weight:2.00, lr:0.0000
[12:50:47.607] iteration:29050  t-loss:0.1669, loss-lb:0.0713, loss-ulb:0.0478, weight:2.00, lr:0.0000
[12:50:47.799] iteration:29051  t-loss:0.1538, loss-lb:0.0707, loss-ulb:0.0416, weight:2.00, lr:0.0000
[12:50:47.991] iteration:29052  t-loss:0.1344, loss-lb:0.0701, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:50:48.183] iteration:29053  t-loss:0.1369, loss-lb:0.0643, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:50:48.375] iteration:29054  t-loss:0.1370, loss-lb:0.0718, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:50:48.568] iteration:29055  t-loss:0.1399, loss-lb:0.0688, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:50:48.760] iteration:29056  t-loss:0.1468, loss-lb:0.0631, loss-ulb:0.0418, weight:2.00, lr:0.0000
[12:50:48.954] iteration:29057  t-loss:0.2600, loss-lb:0.0722, loss-ulb:0.0939, weight:2.00, lr:0.0000
[12:50:49.147] iteration:29058  t-loss:0.1685, loss-lb:0.0792, loss-ulb:0.0447, weight:2.00, lr:0.0000
[12:50:49.339] iteration:29059  t-loss:0.1428, loss-lb:0.0685, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:50:49.532] iteration:29060  t-loss:0.1431, loss-lb:0.0692, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:50:49.736] iteration:29061  t-loss:0.1528, loss-lb:0.0659, loss-ulb:0.0434, weight:2.00, lr:0.0000
[12:50:49.936] iteration:29062  t-loss:0.1476, loss-lb:0.0666, loss-ulb:0.0405, weight:2.00, lr:0.0000
[12:50:50.130] iteration:29063  t-loss:0.1808, loss-lb:0.0692, loss-ulb:0.0558, weight:2.00, lr:0.0000
[12:50:50.324] iteration:29064  t-loss:0.2098, loss-lb:0.0704, loss-ulb:0.0697, weight:2.00, lr:0.0000
[12:50:50.516] iteration:29065  t-loss:0.1555, loss-lb:0.0811, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:50:50.709] iteration:29066  t-loss:0.1462, loss-lb:0.0773, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:50:50.901] iteration:29067  t-loss:0.1319, loss-lb:0.0619, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:50:51.095] iteration:29068  t-loss:0.1642, loss-lb:0.0665, loss-ulb:0.0488, weight:2.00, lr:0.0000
[12:50:51.287] iteration:29069  t-loss:0.1429, loss-lb:0.0667, loss-ulb:0.0381, weight:2.00, lr:0.0000
[12:50:51.480] iteration:29070  t-loss:0.1394, loss-lb:0.0655, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:50:51.673] iteration:29071  t-loss:0.1404, loss-lb:0.0667, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:50:51.865] iteration:29072  t-loss:0.1374, loss-lb:0.0705, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:50:52.057] iteration:29073  t-loss:0.1402, loss-lb:0.0689, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:50:52.250] iteration:29074  t-loss:0.1454, loss-lb:0.0693, loss-ulb:0.0381, weight:2.00, lr:0.0000
[12:50:52.443] iteration:29075  t-loss:0.1371, loss-lb:0.0676, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:50:52.635] iteration:29076  t-loss:0.1340, loss-lb:0.0684, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:50:52.827] iteration:29077  t-loss:0.1504, loss-lb:0.0701, loss-ulb:0.0401, weight:2.00, lr:0.0000
[12:50:53.019] iteration:29078  t-loss:0.1329, loss-lb:0.0695, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:50:53.212] iteration:29079  t-loss:0.1459, loss-lb:0.0713, loss-ulb:0.0373, weight:2.00, lr:0.0000
[12:50:53.404] iteration:29080  t-loss:0.1450, loss-lb:0.0643, loss-ulb:0.0404, weight:2.00, lr:0.0000
[12:50:53.596] iteration:29081  t-loss:0.1215, loss-lb:0.0622, loss-ulb:0.0297, weight:2.00, lr:0.0000
[12:50:53.789] iteration:29082  t-loss:0.1284, loss-lb:0.0660, loss-ulb:0.0312, weight:2.00, lr:0.0000
[12:50:53.982] iteration:29083  t-loss:0.1275, loss-lb:0.0642, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:50:54.174] iteration:29084  t-loss:0.1785, loss-lb:0.0686, loss-ulb:0.0549, weight:2.00, lr:0.0000
[12:50:54.367] iteration:29085  t-loss:0.1257, loss-lb:0.0669, loss-ulb:0.0294, weight:2.00, lr:0.0000
[12:50:54.561] iteration:29086  t-loss:0.1400, loss-lb:0.0682, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:50:54.755] iteration:29087  t-loss:0.2313, loss-lb:0.0764, loss-ulb:0.0775, weight:2.00, lr:0.0000
[12:50:54.947] iteration:29088  t-loss:0.1463, loss-lb:0.0714, loss-ulb:0.0375, weight:2.00, lr:0.0000
[12:50:55.140] iteration:29089  t-loss:0.1551, loss-lb:0.0610, loss-ulb:0.0470, weight:2.00, lr:0.0000
[12:50:55.333] iteration:29090  t-loss:0.1414, loss-lb:0.0799, loss-ulb:0.0308, weight:2.00, lr:0.0000
[12:50:55.526] iteration:29091  t-loss:0.1890, loss-lb:0.0698, loss-ulb:0.0596, weight:2.00, lr:0.0000
[12:50:55.718] iteration:29092  t-loss:0.1431, loss-lb:0.0665, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:50:55.912] iteration:29093  t-loss:0.1467, loss-lb:0.0687, loss-ulb:0.0390, weight:2.00, lr:0.0000
[12:50:56.105] iteration:29094  t-loss:0.1298, loss-lb:0.0641, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:50:56.298] iteration:29095  t-loss:0.1356, loss-lb:0.0677, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:50:56.491] iteration:29096  t-loss:0.1273, loss-lb:0.0620, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:50:56.684] iteration:29097  t-loss:0.1457, loss-lb:0.0738, loss-ulb:0.0360, weight:2.00, lr:0.0000
[12:50:56.876] iteration:29098  t-loss:0.1515, loss-lb:0.0752, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:50:57.067] iteration:29099  t-loss:0.1330, loss-lb:0.0646, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:50:57.260] iteration:29100  t-loss:0.1615, loss-lb:0.0704, loss-ulb:0.0455, weight:2.00, lr:0.0000
[12:50:57.449] iteration:29101  t-loss:0.1551, loss-lb:0.0643, loss-ulb:0.0454, weight:2.00, lr:0.0000
[12:50:57.641] iteration:29102  t-loss:0.1439, loss-lb:0.0681, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:50:57.832] iteration:29103  t-loss:0.1499, loss-lb:0.0754, loss-ulb:0.0373, weight:2.00, lr:0.0000
[12:50:58.023] iteration:29104  t-loss:0.2241, loss-lb:0.0702, loss-ulb:0.0769, weight:2.00, lr:0.0000
[12:50:58.214] iteration:29105  t-loss:0.1380, loss-lb:0.0661, loss-ulb:0.0360, weight:2.00, lr:0.0000
[12:50:58.404] iteration:29106  t-loss:0.1352, loss-lb:0.0678, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:51:11.318]  <<Test>> - Ep:296  - mean_dice/mean_h95 - S:89.70/1.40, Best-S:90.99, T:89.64/1.37, Best-T:90.48
[12:51:11.318]           - AvgLoss(lb/ulb/all):0.0690/0.0425/0.1542
[12:51:11.847] iteration:29107  t-loss:0.1407, loss-lb:0.0706, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:51:12.049] iteration:29108  t-loss:0.1332, loss-lb:0.0668, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:51:12.243] iteration:29109  t-loss:0.1276, loss-lb:0.0619, loss-ulb:0.0329, weight:2.00, lr:0.0000
[12:51:12.435] iteration:29110  t-loss:0.1399, loss-lb:0.0754, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:51:12.635] iteration:29111  t-loss:0.1315, loss-lb:0.0658, loss-ulb:0.0329, weight:2.00, lr:0.0000
[12:51:12.827] iteration:29112  t-loss:0.1538, loss-lb:0.0710, loss-ulb:0.0414, weight:2.00, lr:0.0000
[12:51:13.020] iteration:29113  t-loss:0.1293, loss-lb:0.0664, loss-ulb:0.0315, weight:2.00, lr:0.0000
[12:51:13.213] iteration:29114  t-loss:0.1383, loss-lb:0.0668, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:51:13.412] iteration:29115  t-loss:0.1296, loss-lb:0.0659, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:51:13.605] iteration:29116  t-loss:0.1324, loss-lb:0.0644, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:51:13.798] iteration:29117  t-loss:0.1374, loss-lb:0.0658, loss-ulb:0.0358, weight:2.00, lr:0.0000
[12:51:13.990] iteration:29118  t-loss:0.2230, loss-lb:0.0676, loss-ulb:0.0777, weight:2.00, lr:0.0000
[12:51:14.190] iteration:29119  t-loss:0.1518, loss-lb:0.0672, loss-ulb:0.0423, weight:2.00, lr:0.0000
[12:51:14.382] iteration:29120  t-loss:0.1268, loss-lb:0.0627, loss-ulb:0.0320, weight:2.00, lr:0.0000
[12:51:14.574] iteration:29121  t-loss:0.1440, loss-lb:0.0698, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:51:14.768] iteration:29122  t-loss:0.1371, loss-lb:0.0653, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:51:14.967] iteration:29123  t-loss:0.1429, loss-lb:0.0636, loss-ulb:0.0396, weight:2.00, lr:0.0000
[12:51:15.160] iteration:29124  t-loss:0.1459, loss-lb:0.0703, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:51:15.353] iteration:29125  t-loss:0.1659, loss-lb:0.0737, loss-ulb:0.0461, weight:2.00, lr:0.0000
[12:51:15.545] iteration:29126  t-loss:0.1395, loss-lb:0.0727, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:51:15.746] iteration:29127  t-loss:0.1482, loss-lb:0.0775, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:51:15.938] iteration:29128  t-loss:0.1407, loss-lb:0.0727, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:51:16.130] iteration:29129  t-loss:0.1419, loss-lb:0.0730, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:51:16.325] iteration:29130  t-loss:0.1473, loss-lb:0.0716, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:51:16.525] iteration:29131  t-loss:0.1479, loss-lb:0.0713, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:51:16.718] iteration:29132  t-loss:0.1515, loss-lb:0.0803, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:51:16.910] iteration:29133  t-loss:0.1290, loss-lb:0.0683, loss-ulb:0.0303, weight:2.00, lr:0.0000
[12:51:17.102] iteration:29134  t-loss:0.1461, loss-lb:0.0602, loss-ulb:0.0429, weight:2.00, lr:0.0000
[12:51:17.303] iteration:29135  t-loss:0.1353, loss-lb:0.0694, loss-ulb:0.0329, weight:2.00, lr:0.0000
[12:51:17.494] iteration:29136  t-loss:0.1527, loss-lb:0.0717, loss-ulb:0.0405, weight:2.00, lr:0.0000
[12:51:17.685] iteration:29137  t-loss:0.1419, loss-lb:0.0653, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:51:17.877] iteration:29138  t-loss:0.1464, loss-lb:0.0720, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:51:18.076] iteration:29139  t-loss:0.1424, loss-lb:0.0717, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:51:18.267] iteration:29140  t-loss:0.1249, loss-lb:0.0630, loss-ulb:0.0310, weight:2.00, lr:0.0000
[12:51:18.459] iteration:29141  t-loss:0.1329, loss-lb:0.0701, loss-ulb:0.0314, weight:2.00, lr:0.0000
[12:51:18.651] iteration:29142  t-loss:0.1412, loss-lb:0.0661, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:51:18.849] iteration:29143  t-loss:0.1526, loss-lb:0.0702, loss-ulb:0.0412, weight:2.00, lr:0.0000
[12:51:19.040] iteration:29144  t-loss:0.1317, loss-lb:0.0667, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:51:19.231] iteration:29145  t-loss:0.1335, loss-lb:0.0678, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:51:19.422] iteration:29146  t-loss:0.1404, loss-lb:0.0651, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:51:19.622] iteration:29147  t-loss:0.1409, loss-lb:0.0672, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:51:19.813] iteration:29148  t-loss:0.1546, loss-lb:0.0749, loss-ulb:0.0399, weight:2.00, lr:0.0000
[12:51:20.005] iteration:29149  t-loss:0.1599, loss-lb:0.0710, loss-ulb:0.0444, weight:2.00, lr:0.0000
[12:51:20.199] iteration:29150  t-loss:0.1385, loss-lb:0.0699, loss-ulb:0.0343, weight:2.00, lr:0.0000
[12:51:20.402] iteration:29151  t-loss:0.1303, loss-lb:0.0649, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:51:20.596] iteration:29152  t-loss:0.1284, loss-lb:0.0686, loss-ulb:0.0299, weight:2.00, lr:0.0000
[12:51:20.790] iteration:29153  t-loss:0.1411, loss-lb:0.0678, loss-ulb:0.0366, weight:2.00, lr:0.0000
[12:51:20.982] iteration:29154  t-loss:0.1339, loss-lb:0.0634, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:51:21.183] iteration:29155  t-loss:0.1495, loss-lb:0.0736, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:51:21.375] iteration:29156  t-loss:0.1389, loss-lb:0.0667, loss-ulb:0.0361, weight:2.00, lr:0.0000
[12:51:21.567] iteration:29157  t-loss:0.1252, loss-lb:0.0599, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:51:21.762] iteration:29158  t-loss:0.2311, loss-lb:0.0755, loss-ulb:0.0778, weight:2.00, lr:0.0000
[12:51:21.954] iteration:29159  t-loss:0.3025, loss-lb:0.0828, loss-ulb:0.1099, weight:2.00, lr:0.0000
[12:51:22.145] iteration:29160  t-loss:0.1424, loss-lb:0.0696, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:51:22.337] iteration:29161  t-loss:0.1247, loss-lb:0.0676, loss-ulb:0.0285, weight:2.00, lr:0.0000
[12:51:22.541] iteration:29162  t-loss:0.1481, loss-lb:0.0706, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:51:22.741] iteration:29163  t-loss:0.2147, loss-lb:0.0709, loss-ulb:0.0719, weight:2.00, lr:0.0000
[12:51:22.934] iteration:29164  t-loss:0.1334, loss-lb:0.0654, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:51:23.127] iteration:29165  t-loss:0.1325, loss-lb:0.0665, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:51:23.318] iteration:29166  t-loss:0.1297, loss-lb:0.0629, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:51:23.510] iteration:29167  t-loss:0.1582, loss-lb:0.0652, loss-ulb:0.0465, weight:2.00, lr:0.0000
[12:51:23.703] iteration:29168  t-loss:0.1420, loss-lb:0.0662, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:51:23.894] iteration:29169  t-loss:0.1445, loss-lb:0.0663, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:51:24.086] iteration:29170  t-loss:0.1454, loss-lb:0.0741, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:51:24.279] iteration:29171  t-loss:0.1468, loss-lb:0.0718, loss-ulb:0.0375, weight:2.00, lr:0.0000
[12:51:24.471] iteration:29172  t-loss:0.1609, loss-lb:0.0735, loss-ulb:0.0437, weight:2.00, lr:0.0000
[12:51:24.664] iteration:29173  t-loss:0.2020, loss-lb:0.0760, loss-ulb:0.0630, weight:2.00, lr:0.0000
[12:51:24.856] iteration:29174  t-loss:0.1355, loss-lb:0.0661, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:51:25.050] iteration:29175  t-loss:0.1442, loss-lb:0.0672, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:51:25.240] iteration:29176  t-loss:0.1353, loss-lb:0.0593, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:51:25.432] iteration:29177  t-loss:0.1467, loss-lb:0.0630, loss-ulb:0.0419, weight:2.00, lr:0.0000
[12:51:25.625] iteration:29178  t-loss:0.1410, loss-lb:0.0654, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:51:25.816] iteration:29179  t-loss:0.1379, loss-lb:0.0718, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:51:26.010] iteration:29180  t-loss:0.2111, loss-lb:0.0745, loss-ulb:0.0683, weight:2.00, lr:0.0000
[12:51:26.201] iteration:29181  t-loss:0.1413, loss-lb:0.0718, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:51:26.393] iteration:29182  t-loss:0.1432, loss-lb:0.0696, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:51:26.587] iteration:29183  t-loss:0.1737, loss-lb:0.0734, loss-ulb:0.0501, weight:2.00, lr:0.0000
[12:51:26.778] iteration:29184  t-loss:0.1720, loss-lb:0.0670, loss-ulb:0.0525, weight:2.00, lr:0.0000
[12:51:26.970] iteration:29185  t-loss:0.1385, loss-lb:0.0699, loss-ulb:0.0343, weight:2.00, lr:0.0000
[12:51:27.169] iteration:29186  t-loss:0.1787, loss-lb:0.0724, loss-ulb:0.0531, weight:2.00, lr:0.0000
[12:51:27.361] iteration:29187  t-loss:0.1470, loss-lb:0.0668, loss-ulb:0.0401, weight:2.00, lr:0.0000
[12:51:27.551] iteration:29188  t-loss:0.1377, loss-lb:0.0672, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:51:27.743] iteration:29189  t-loss:0.1264, loss-lb:0.0607, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:51:27.935] iteration:29190  t-loss:0.1487, loss-lb:0.0683, loss-ulb:0.0402, weight:2.00, lr:0.0000
[12:51:28.134] iteration:29191  t-loss:0.1408, loss-lb:0.0674, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:51:28.326] iteration:29192  t-loss:0.1362, loss-lb:0.0702, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:51:28.518] iteration:29193  t-loss:0.1501, loss-lb:0.0715, loss-ulb:0.0393, weight:2.00, lr:0.0000
[12:51:28.709] iteration:29194  t-loss:0.1429, loss-lb:0.0705, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:51:28.902] iteration:29195  t-loss:0.1867, loss-lb:0.0762, loss-ulb:0.0553, weight:2.00, lr:0.0000
[12:51:29.094] iteration:29196  t-loss:0.1414, loss-lb:0.0681, loss-ulb:0.0366, weight:2.00, lr:0.0000
[12:51:29.285] iteration:29197  t-loss:0.1488, loss-lb:0.0725, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:51:29.476] iteration:29198  t-loss:0.1418, loss-lb:0.0745, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:51:29.667] iteration:29199  t-loss:0.1674, loss-lb:0.0705, loss-ulb:0.0485, weight:2.00, lr:0.0000
[12:51:29.857] iteration:29200  t-loss:0.1281, loss-lb:0.0683, loss-ulb:0.0299, weight:2.00, lr:0.0000
[12:51:30.048] iteration:29201  t-loss:0.1402, loss-lb:0.0725, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:51:30.237] iteration:29202  t-loss:0.1384, loss-lb:0.0688, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:51:30.427] iteration:29203  t-loss:0.1476, loss-lb:0.0694, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:51:30.617] iteration:29204  t-loss:0.1264, loss-lb:0.0678, loss-ulb:0.0293, weight:2.00, lr:0.0000
[12:51:31.189] iteration:29205  t-loss:0.1432, loss-lb:0.0725, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:51:31.386] iteration:29206  t-loss:0.1485, loss-lb:0.0717, loss-ulb:0.0384, weight:2.00, lr:0.0000
[12:51:31.581] iteration:29207  t-loss:0.1456, loss-lb:0.0615, loss-ulb:0.0420, weight:2.00, lr:0.0000
[12:51:31.776] iteration:29208  t-loss:0.1482, loss-lb:0.0744, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:51:31.969] iteration:29209  t-loss:0.1285, loss-lb:0.0637, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:51:32.160] iteration:29210  t-loss:0.1463, loss-lb:0.0726, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:51:32.352] iteration:29211  t-loss:0.1298, loss-lb:0.0659, loss-ulb:0.0319, weight:2.00, lr:0.0000
[12:51:32.544] iteration:29212  t-loss:0.1661, loss-lb:0.0686, loss-ulb:0.0488, weight:2.00, lr:0.0000
[12:51:32.737] iteration:29213  t-loss:0.1513, loss-lb:0.0631, loss-ulb:0.0441, weight:2.00, lr:0.0000
[12:51:32.930] iteration:29214  t-loss:0.1397, loss-lb:0.0710, loss-ulb:0.0343, weight:2.00, lr:0.0000
[12:51:33.122] iteration:29215  t-loss:0.1429, loss-lb:0.0716, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:51:33.312] iteration:29216  t-loss:0.1331, loss-lb:0.0721, loss-ulb:0.0305, weight:2.00, lr:0.0000
[12:51:33.504] iteration:29217  t-loss:0.1265, loss-lb:0.0634, loss-ulb:0.0315, weight:2.00, lr:0.0000
[12:51:33.693] iteration:29218  t-loss:0.1359, loss-lb:0.0647, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:51:33.886] iteration:29219  t-loss:0.1386, loss-lb:0.0662, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:51:34.077] iteration:29220  t-loss:0.1417, loss-lb:0.0638, loss-ulb:0.0389, weight:2.00, lr:0.0000
[12:51:34.277] iteration:29221  t-loss:0.1887, loss-lb:0.0746, loss-ulb:0.0570, weight:2.00, lr:0.0000
[12:51:34.468] iteration:29222  t-loss:0.1442, loss-lb:0.0764, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:51:34.660] iteration:29223  t-loss:0.1365, loss-lb:0.0757, loss-ulb:0.0304, weight:2.00, lr:0.0000
[12:51:34.859] iteration:29224  t-loss:0.1517, loss-lb:0.0768, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:51:35.050] iteration:29225  t-loss:0.1381, loss-lb:0.0667, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:51:35.243] iteration:29226  t-loss:0.1453, loss-lb:0.0715, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:51:35.439] iteration:29227  t-loss:0.1904, loss-lb:0.0684, loss-ulb:0.0610, weight:2.00, lr:0.0000
[12:51:35.632] iteration:29228  t-loss:0.1378, loss-lb:0.0735, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:51:35.828] iteration:29229  t-loss:0.1474, loss-lb:0.0674, loss-ulb:0.0400, weight:2.00, lr:0.0000
[12:51:36.020] iteration:29230  t-loss:0.1585, loss-lb:0.0694, loss-ulb:0.0446, weight:2.00, lr:0.0000
[12:51:36.220] iteration:29231  t-loss:0.1364, loss-lb:0.0668, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:51:36.412] iteration:29232  t-loss:0.1332, loss-lb:0.0636, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:51:36.606] iteration:29233  t-loss:0.1306, loss-lb:0.0671, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:51:36.806] iteration:29234  t-loss:0.1499, loss-lb:0.0744, loss-ulb:0.0377, weight:2.00, lr:0.0000
[12:51:36.999] iteration:29235  t-loss:0.1502, loss-lb:0.0695, loss-ulb:0.0404, weight:2.00, lr:0.0000
[12:51:37.190] iteration:29236  t-loss:0.1348, loss-lb:0.0682, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:51:37.389] iteration:29237  t-loss:0.1442, loss-lb:0.0667, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:51:37.581] iteration:29238  t-loss:0.1410, loss-lb:0.0697, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:51:37.773] iteration:29239  t-loss:0.1475, loss-lb:0.0725, loss-ulb:0.0375, weight:2.00, lr:0.0000
[12:51:37.965] iteration:29240  t-loss:0.1315, loss-lb:0.0667, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:51:38.158] iteration:29241  t-loss:0.1408, loss-lb:0.0730, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:51:38.354] iteration:29242  t-loss:0.1339, loss-lb:0.0706, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:51:38.545] iteration:29243  t-loss:0.1490, loss-lb:0.0712, loss-ulb:0.0389, weight:2.00, lr:0.0000
[12:51:38.735] iteration:29244  t-loss:0.1326, loss-lb:0.0657, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:51:38.926] iteration:29245  t-loss:0.1445, loss-lb:0.0698, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:51:39.118] iteration:29246  t-loss:0.1544, loss-lb:0.0764, loss-ulb:0.0390, weight:2.00, lr:0.0000
[12:51:39.311] iteration:29247  t-loss:0.1398, loss-lb:0.0721, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:51:39.502] iteration:29248  t-loss:0.1386, loss-lb:0.0653, loss-ulb:0.0366, weight:2.00, lr:0.0000
[12:51:39.694] iteration:29249  t-loss:0.1598, loss-lb:0.0627, loss-ulb:0.0485, weight:2.00, lr:0.0000
[12:51:39.886] iteration:29250  t-loss:0.1505, loss-lb:0.0664, loss-ulb:0.0421, weight:2.00, lr:0.0000
[12:51:40.078] iteration:29251  t-loss:0.1687, loss-lb:0.0654, loss-ulb:0.0517, weight:2.00, lr:0.0000
[12:51:40.270] iteration:29252  t-loss:0.1496, loss-lb:0.0666, loss-ulb:0.0415, weight:2.00, lr:0.0000
[12:51:40.462] iteration:29253  t-loss:0.1696, loss-lb:0.0789, loss-ulb:0.0454, weight:2.00, lr:0.0000
[12:51:40.654] iteration:29254  t-loss:0.1301, loss-lb:0.0630, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:51:40.846] iteration:29255  t-loss:0.1302, loss-lb:0.0656, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:51:41.038] iteration:29256  t-loss:0.1442, loss-lb:0.0714, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:51:41.229] iteration:29257  t-loss:0.1505, loss-lb:0.0707, loss-ulb:0.0399, weight:2.00, lr:0.0000
[12:51:41.421] iteration:29258  t-loss:0.1360, loss-lb:0.0655, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:51:41.613] iteration:29259  t-loss:0.1264, loss-lb:0.0634, loss-ulb:0.0315, weight:2.00, lr:0.0000
[12:51:41.804] iteration:29260  t-loss:0.1398, loss-lb:0.0762, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:51:41.999] iteration:29261  t-loss:0.1443, loss-lb:0.0750, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:51:42.195] iteration:29262  t-loss:0.1485, loss-lb:0.0684, loss-ulb:0.0400, weight:2.00, lr:0.0000
[12:51:42.389] iteration:29263  t-loss:0.1334, loss-lb:0.0637, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:51:42.584] iteration:29264  t-loss:0.1592, loss-lb:0.0696, loss-ulb:0.0448, weight:2.00, lr:0.0000
[12:51:42.777] iteration:29265  t-loss:0.1242, loss-lb:0.0607, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:51:42.969] iteration:29266  t-loss:0.1351, loss-lb:0.0637, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:51:43.162] iteration:29267  t-loss:0.1389, loss-lb:0.0762, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:51:43.354] iteration:29268  t-loss:0.1410, loss-lb:0.0736, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:51:43.545] iteration:29269  t-loss:0.1319, loss-lb:0.0667, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:51:43.738] iteration:29270  t-loss:0.1465, loss-lb:0.0708, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:51:43.931] iteration:29271  t-loss:0.1386, loss-lb:0.0688, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:51:44.122] iteration:29272  t-loss:0.1393, loss-lb:0.0708, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:51:44.314] iteration:29273  t-loss:0.1364, loss-lb:0.0722, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:51:44.507] iteration:29274  t-loss:0.1555, loss-lb:0.0682, loss-ulb:0.0437, weight:2.00, lr:0.0000
[12:51:44.699] iteration:29275  t-loss:0.1376, loss-lb:0.0707, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:51:44.891] iteration:29276  t-loss:0.1546, loss-lb:0.0785, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:51:45.083] iteration:29277  t-loss:0.1288, loss-lb:0.0628, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:51:45.275] iteration:29278  t-loss:0.1337, loss-lb:0.0655, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:51:45.468] iteration:29279  t-loss:0.1486, loss-lb:0.0667, loss-ulb:0.0410, weight:2.00, lr:0.0000
[12:51:45.660] iteration:29280  t-loss:0.1418, loss-lb:0.0707, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:51:45.853] iteration:29281  t-loss:0.1569, loss-lb:0.0737, loss-ulb:0.0416, weight:2.00, lr:0.0000
[12:51:46.045] iteration:29282  t-loss:0.1385, loss-lb:0.0681, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:51:46.236] iteration:29283  t-loss:0.1329, loss-lb:0.0657, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:51:46.430] iteration:29284  t-loss:0.1302, loss-lb:0.0664, loss-ulb:0.0319, weight:2.00, lr:0.0000
[12:51:46.622] iteration:29285  t-loss:0.1499, loss-lb:0.0632, loss-ulb:0.0433, weight:2.00, lr:0.0000
[12:51:46.814] iteration:29286  t-loss:0.1627, loss-lb:0.0769, loss-ulb:0.0429, weight:2.00, lr:0.0000
[12:51:47.007] iteration:29287  t-loss:0.1349, loss-lb:0.0651, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:51:47.199] iteration:29288  t-loss:0.1494, loss-lb:0.0760, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:51:47.390] iteration:29289  t-loss:0.1276, loss-lb:0.0702, loss-ulb:0.0287, weight:2.00, lr:0.0000
[12:51:47.583] iteration:29290  t-loss:0.1424, loss-lb:0.0655, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:51:47.777] iteration:29291  t-loss:0.1466, loss-lb:0.0756, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:51:47.968] iteration:29292  t-loss:0.1375, loss-lb:0.0677, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:51:48.161] iteration:29293  t-loss:0.1442, loss-lb:0.0730, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:51:48.354] iteration:29294  t-loss:0.1470, loss-lb:0.0713, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:51:48.545] iteration:29295  t-loss:0.1415, loss-lb:0.0635, loss-ulb:0.0390, weight:2.00, lr:0.0000
[12:51:48.738] iteration:29296  t-loss:0.1524, loss-lb:0.0874, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:51:48.929] iteration:29297  t-loss:0.1331, loss-lb:0.0654, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:51:49.119] iteration:29298  t-loss:0.1537, loss-lb:0.0714, loss-ulb:0.0412, weight:2.00, lr:0.0000
[12:51:49.312] iteration:29299  t-loss:0.1289, loss-lb:0.0682, loss-ulb:0.0304, weight:2.00, lr:0.0000
[12:51:49.502] iteration:29300  t-loss:0.1560, loss-lb:0.0717, loss-ulb:0.0421, weight:2.00, lr:0.0000
[12:51:49.694] iteration:29301  t-loss:0.1462, loss-lb:0.0657, loss-ulb:0.0402, weight:2.00, lr:0.0000
[12:51:49.885] iteration:29302  t-loss:0.1796, loss-lb:0.0682, loss-ulb:0.0557, weight:2.00, lr:0.0000
[12:52:01.803]  <<Test>> - Ep:298  - mean_dice/mean_h95 - S:89.88/1.33, Best-S:90.99, T:89.64/1.39, Best-T:90.48
[12:52:01.803]           - AvgLoss(lb/ulb/all):0.0693/0.0375/0.1448
[12:52:02.346] iteration:29303  t-loss:0.1559, loss-lb:0.0667, loss-ulb:0.0446, weight:2.00, lr:0.0000
[12:52:02.543] iteration:29304  t-loss:0.1310, loss-lb:0.0656, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:52:02.736] iteration:29305  t-loss:0.1467, loss-lb:0.0660, loss-ulb:0.0403, weight:2.00, lr:0.0000
[12:52:02.929] iteration:29306  t-loss:0.1356, loss-lb:0.0703, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:52:03.122] iteration:29307  t-loss:0.1322, loss-lb:0.0658, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:52:03.315] iteration:29308  t-loss:0.1424, loss-lb:0.0674, loss-ulb:0.0375, weight:2.00, lr:0.0000
[12:52:03.508] iteration:29309  t-loss:0.1386, loss-lb:0.0697, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:52:03.701] iteration:29310  t-loss:0.1344, loss-lb:0.0638, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:52:03.894] iteration:29311  t-loss:0.1340, loss-lb:0.0697, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:52:04.087] iteration:29312  t-loss:0.2308, loss-lb:0.0671, loss-ulb:0.0819, weight:2.00, lr:0.0000
[12:52:04.280] iteration:29313  t-loss:0.1397, loss-lb:0.0696, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:52:04.473] iteration:29314  t-loss:0.1606, loss-lb:0.0778, loss-ulb:0.0414, weight:2.00, lr:0.0000
[12:52:04.667] iteration:29315  t-loss:0.1598, loss-lb:0.0686, loss-ulb:0.0456, weight:2.00, lr:0.0000
[12:52:04.860] iteration:29316  t-loss:0.1301, loss-lb:0.0638, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:52:05.053] iteration:29317  t-loss:0.1361, loss-lb:0.0662, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:52:05.247] iteration:29318  t-loss:0.1405, loss-lb:0.0714, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:52:05.441] iteration:29319  t-loss:0.1432, loss-lb:0.0692, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:52:05.634] iteration:29320  t-loss:0.1413, loss-lb:0.0705, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:52:05.827] iteration:29321  t-loss:0.1466, loss-lb:0.0730, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:52:06.019] iteration:29322  t-loss:0.1488, loss-lb:0.0707, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:52:06.212] iteration:29323  t-loss:0.1478, loss-lb:0.0705, loss-ulb:0.0386, weight:2.00, lr:0.0000
[12:52:06.406] iteration:29324  t-loss:0.1326, loss-lb:0.0648, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:52:06.598] iteration:29325  t-loss:0.1284, loss-lb:0.0691, loss-ulb:0.0297, weight:2.00, lr:0.0000
[12:52:06.791] iteration:29326  t-loss:0.1331, loss-lb:0.0693, loss-ulb:0.0319, weight:2.00, lr:0.0000
[12:52:06.984] iteration:29327  t-loss:0.1697, loss-lb:0.0716, loss-ulb:0.0491, weight:2.00, lr:0.0000
[12:52:07.177] iteration:29328  t-loss:0.1693, loss-lb:0.0696, loss-ulb:0.0498, weight:2.00, lr:0.0000
[12:52:07.368] iteration:29329  t-loss:0.1316, loss-lb:0.0668, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:52:07.561] iteration:29330  t-loss:0.1373, loss-lb:0.0638, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:52:07.754] iteration:29331  t-loss:0.1409, loss-lb:0.0683, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:52:07.946] iteration:29332  t-loss:0.1335, loss-lb:0.0729, loss-ulb:0.0303, weight:2.00, lr:0.0000
[12:52:08.138] iteration:29333  t-loss:0.1509, loss-lb:0.0636, loss-ulb:0.0436, weight:2.00, lr:0.0000
[12:52:08.332] iteration:29334  t-loss:0.1357, loss-lb:0.0703, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:52:08.526] iteration:29335  t-loss:0.2234, loss-lb:0.0710, loss-ulb:0.0762, weight:2.00, lr:0.0000
[12:52:08.719] iteration:29336  t-loss:0.1478, loss-lb:0.0730, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:52:08.911] iteration:29337  t-loss:0.1258, loss-lb:0.0645, loss-ulb:0.0307, weight:2.00, lr:0.0000
[12:52:09.104] iteration:29338  t-loss:0.1850, loss-lb:0.0720, loss-ulb:0.0565, weight:2.00, lr:0.0000
[12:52:09.296] iteration:29339  t-loss:0.1422, loss-lb:0.0684, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:52:09.489] iteration:29340  t-loss:0.1379, loss-lb:0.0695, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:52:09.681] iteration:29341  t-loss:0.1341, loss-lb:0.0700, loss-ulb:0.0320, weight:2.00, lr:0.0000
[12:52:09.874] iteration:29342  t-loss:0.1469, loss-lb:0.0690, loss-ulb:0.0389, weight:2.00, lr:0.0000
[12:52:10.066] iteration:29343  t-loss:0.1385, loss-lb:0.0681, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:10.259] iteration:29344  t-loss:0.1675, loss-lb:0.0751, loss-ulb:0.0462, weight:2.00, lr:0.0000
[12:52:10.452] iteration:29345  t-loss:0.1346, loss-lb:0.0642, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:10.645] iteration:29346  t-loss:0.1376, loss-lb:0.0682, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:52:10.837] iteration:29347  t-loss:0.1286, loss-lb:0.0630, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:52:11.029] iteration:29348  t-loss:0.1337, loss-lb:0.0706, loss-ulb:0.0316, weight:2.00, lr:0.0000
[12:52:11.222] iteration:29349  t-loss:0.1384, loss-lb:0.0684, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:52:11.415] iteration:29350  t-loss:0.1634, loss-lb:0.0681, loss-ulb:0.0477, weight:2.00, lr:0.0000
[12:52:11.607] iteration:29351  t-loss:0.1520, loss-lb:0.0811, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:52:11.799] iteration:29352  t-loss:0.1395, loss-lb:0.0655, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:52:11.991] iteration:29353  t-loss:0.1344, loss-lb:0.0629, loss-ulb:0.0358, weight:2.00, lr:0.0000
[12:52:12.183] iteration:29354  t-loss:0.1279, loss-lb:0.0683, loss-ulb:0.0298, weight:2.00, lr:0.0000
[12:52:12.376] iteration:29355  t-loss:0.1542, loss-lb:0.0755, loss-ulb:0.0394, weight:2.00, lr:0.0000
[12:52:12.569] iteration:29356  t-loss:0.1403, loss-lb:0.0687, loss-ulb:0.0358, weight:2.00, lr:0.0000
[12:52:12.761] iteration:29357  t-loss:0.1361, loss-lb:0.0611, loss-ulb:0.0375, weight:2.00, lr:0.0000
[12:52:12.954] iteration:29358  t-loss:0.1353, loss-lb:0.0793, loss-ulb:0.0280, weight:2.00, lr:0.0000
[12:52:13.146] iteration:29359  t-loss:0.1448, loss-lb:0.0641, loss-ulb:0.0404, weight:2.00, lr:0.0000
[12:52:13.339] iteration:29360  t-loss:0.1366, loss-lb:0.0670, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:52:13.531] iteration:29361  t-loss:0.1340, loss-lb:0.0670, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:52:13.724] iteration:29362  t-loss:0.1350, loss-lb:0.0663, loss-ulb:0.0343, weight:2.00, lr:0.0000
[12:52:13.917] iteration:29363  t-loss:0.1361, loss-lb:0.0624, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:52:14.109] iteration:29364  t-loss:0.1367, loss-lb:0.0691, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:52:14.302] iteration:29365  t-loss:0.1395, loss-lb:0.0657, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:52:14.496] iteration:29366  t-loss:0.1600, loss-lb:0.0702, loss-ulb:0.0449, weight:2.00, lr:0.0000
[12:52:14.689] iteration:29367  t-loss:0.1411, loss-lb:0.0791, loss-ulb:0.0310, weight:2.00, lr:0.0000
[12:52:14.882] iteration:29368  t-loss:0.1509, loss-lb:0.0699, loss-ulb:0.0405, weight:2.00, lr:0.0000
[12:52:15.075] iteration:29369  t-loss:0.1390, loss-lb:0.0668, loss-ulb:0.0361, weight:2.00, lr:0.0000
[12:52:15.268] iteration:29370  t-loss:0.1393, loss-lb:0.0680, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:52:15.463] iteration:29371  t-loss:0.1496, loss-lb:0.0709, loss-ulb:0.0393, weight:2.00, lr:0.0000
[12:52:15.658] iteration:29372  t-loss:0.1423, loss-lb:0.0696, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:52:15.851] iteration:29373  t-loss:0.1399, loss-lb:0.0636, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:52:16.045] iteration:29374  t-loss:0.1288, loss-lb:0.0644, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:52:16.238] iteration:29375  t-loss:0.1435, loss-lb:0.0707, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:52:16.430] iteration:29376  t-loss:0.1386, loss-lb:0.0696, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:52:16.622] iteration:29377  t-loss:0.1326, loss-lb:0.0615, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:52:16.815] iteration:29378  t-loss:0.1372, loss-lb:0.0741, loss-ulb:0.0316, weight:2.00, lr:0.0000
[12:52:17.007] iteration:29379  t-loss:0.1388, loss-lb:0.0681, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:52:17.199] iteration:29380  t-loss:0.1483, loss-lb:0.0692, loss-ulb:0.0396, weight:2.00, lr:0.0000
[12:52:17.391] iteration:29381  t-loss:0.1370, loss-lb:0.0681, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:52:17.584] iteration:29382  t-loss:0.2675, loss-lb:0.0701, loss-ulb:0.0987, weight:2.00, lr:0.0000
[12:52:17.778] iteration:29383  t-loss:0.1363, loss-lb:0.0639, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:52:17.971] iteration:29384  t-loss:0.1615, loss-lb:0.0731, loss-ulb:0.0442, weight:2.00, lr:0.0000
[12:52:18.164] iteration:29385  t-loss:0.1579, loss-lb:0.0632, loss-ulb:0.0473, weight:2.00, lr:0.0000
[12:52:18.356] iteration:29386  t-loss:0.1680, loss-lb:0.0681, loss-ulb:0.0500, weight:2.00, lr:0.0000
[12:52:18.550] iteration:29387  t-loss:0.1325, loss-lb:0.0682, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:52:18.742] iteration:29388  t-loss:0.1438, loss-lb:0.0697, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:52:18.935] iteration:29389  t-loss:0.1394, loss-lb:0.0733, loss-ulb:0.0331, weight:2.00, lr:0.0000
[12:52:19.128] iteration:29390  t-loss:0.1423, loss-lb:0.0717, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:52:19.320] iteration:29391  t-loss:0.1324, loss-lb:0.0678, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:52:19.511] iteration:29392  t-loss:0.1246, loss-lb:0.0648, loss-ulb:0.0299, weight:2.00, lr:0.0000
[12:52:19.703] iteration:29393  t-loss:0.1324, loss-lb:0.0640, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:52:19.894] iteration:29394  t-loss:0.1523, loss-lb:0.0710, loss-ulb:0.0406, weight:2.00, lr:0.0000
[12:52:20.087] iteration:29395  t-loss:0.2180, loss-lb:0.0649, loss-ulb:0.0766, weight:2.00, lr:0.0000
[12:52:20.277] iteration:29396  t-loss:0.1395, loss-lb:0.0741, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:52:20.469] iteration:29397  t-loss:0.1339, loss-lb:0.0635, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:20.659] iteration:29398  t-loss:0.1446, loss-lb:0.0692, loss-ulb:0.0377, weight:2.00, lr:0.0000
[12:52:20.850] iteration:29399  t-loss:0.1382, loss-lb:0.0715, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:52:21.042] iteration:29400  t-loss:0.1450, loss-lb:0.0692, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:52:21.630] iteration:29401  t-loss:0.1635, loss-lb:0.0769, loss-ulb:0.0433, weight:2.00, lr:0.0000
[12:52:21.826] iteration:29402  t-loss:0.1409, loss-lb:0.0705, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:22.018] iteration:29403  t-loss:0.1258, loss-lb:0.0597, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:52:22.211] iteration:29404  t-loss:0.1427, loss-lb:0.0772, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:52:22.404] iteration:29405  t-loss:0.1537, loss-lb:0.0716, loss-ulb:0.0410, weight:2.00, lr:0.0000
[12:52:22.597] iteration:29406  t-loss:0.1291, loss-lb:0.0676, loss-ulb:0.0308, weight:2.00, lr:0.0000
[12:52:22.789] iteration:29407  t-loss:0.1408, loss-lb:0.0783, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:52:22.981] iteration:29408  t-loss:0.1455, loss-lb:0.0698, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:52:23.173] iteration:29409  t-loss:0.1214, loss-lb:0.0670, loss-ulb:0.0272, weight:2.00, lr:0.0000
[12:52:23.365] iteration:29410  t-loss:0.1432, loss-lb:0.0683, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:52:23.558] iteration:29411  t-loss:0.2747, loss-lb:0.0676, loss-ulb:0.1036, weight:2.00, lr:0.0000
[12:52:23.751] iteration:29412  t-loss:0.1329, loss-lb:0.0657, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:52:23.943] iteration:29413  t-loss:0.1596, loss-lb:0.0740, loss-ulb:0.0428, weight:2.00, lr:0.0000
[12:52:24.135] iteration:29414  t-loss:0.2103, loss-lb:0.0644, loss-ulb:0.0729, weight:2.00, lr:0.0000
[12:52:24.328] iteration:29415  t-loss:0.1333, loss-lb:0.0607, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:52:24.521] iteration:29416  t-loss:0.1356, loss-lb:0.0697, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:52:24.714] iteration:29417  t-loss:0.1511, loss-lb:0.0693, loss-ulb:0.0409, weight:2.00, lr:0.0000
[12:52:24.906] iteration:29418  t-loss:0.1382, loss-lb:0.0675, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:52:25.099] iteration:29419  t-loss:0.1411, loss-lb:0.0727, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:52:25.290] iteration:29420  t-loss:0.1371, loss-lb:0.0668, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:25.482] iteration:29421  t-loss:0.1301, loss-lb:0.0663, loss-ulb:0.0319, weight:2.00, lr:0.0000
[12:52:25.675] iteration:29422  t-loss:0.1394, loss-lb:0.0708, loss-ulb:0.0343, weight:2.00, lr:0.0000
[12:52:25.867] iteration:29423  t-loss:0.1568, loss-lb:0.0806, loss-ulb:0.0381, weight:2.00, lr:0.0000
[12:52:26.059] iteration:29424  t-loss:0.1532, loss-lb:0.0658, loss-ulb:0.0437, weight:2.00, lr:0.0000
[12:52:26.252] iteration:29425  t-loss:0.1314, loss-lb:0.0647, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:52:26.444] iteration:29426  t-loss:0.1422, loss-lb:0.0673, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:52:26.637] iteration:29427  t-loss:0.2917, loss-lb:0.0671, loss-ulb:0.1123, weight:2.00, lr:0.0000
[12:52:26.830] iteration:29428  t-loss:0.1368, loss-lb:0.0673, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:52:27.022] iteration:29429  t-loss:0.1376, loss-lb:0.0699, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:52:27.214] iteration:29430  t-loss:0.1426, loss-lb:0.0722, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:27.408] iteration:29431  t-loss:0.1614, loss-lb:0.0698, loss-ulb:0.0458, weight:2.00, lr:0.0000
[12:52:27.600] iteration:29432  t-loss:0.1461, loss-lb:0.0679, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:52:27.793] iteration:29433  t-loss:0.1302, loss-lb:0.0624, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:52:28.000] iteration:29434  t-loss:0.1341, loss-lb:0.0695, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:52:28.201] iteration:29435  t-loss:0.1331, loss-lb:0.0597, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:52:28.397] iteration:29436  t-loss:0.1423, loss-lb:0.0729, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:52:28.590] iteration:29437  t-loss:0.1349, loss-lb:0.0714, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:52:28.782] iteration:29438  t-loss:0.1562, loss-lb:0.0697, loss-ulb:0.0433, weight:2.00, lr:0.0000
[12:52:28.975] iteration:29439  t-loss:0.1439, loss-lb:0.0701, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:52:29.167] iteration:29440  t-loss:0.1350, loss-lb:0.0652, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:52:29.359] iteration:29441  t-loss:0.1565, loss-lb:0.0706, loss-ulb:0.0429, weight:2.00, lr:0.0000
[12:52:29.553] iteration:29442  t-loss:0.1453, loss-lb:0.0719, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:52:29.746] iteration:29443  t-loss:0.1796, loss-lb:0.0736, loss-ulb:0.0530, weight:2.00, lr:0.0000
[12:52:29.939] iteration:29444  t-loss:0.1274, loss-lb:0.0648, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:52:30.132] iteration:29445  t-loss:0.1347, loss-lb:0.0612, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:52:30.323] iteration:29446  t-loss:0.1237, loss-lb:0.0615, loss-ulb:0.0311, weight:2.00, lr:0.0000
[12:52:30.516] iteration:29447  t-loss:0.1363, loss-lb:0.0659, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:30.709] iteration:29448  t-loss:0.1545, loss-lb:0.0694, loss-ulb:0.0425, weight:2.00, lr:0.0000
[12:52:30.901] iteration:29449  t-loss:0.1280, loss-lb:0.0669, loss-ulb:0.0306, weight:2.00, lr:0.0000
[12:52:31.093] iteration:29450  t-loss:0.1328, loss-lb:0.0625, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:52:31.287] iteration:29451  t-loss:0.1403, loss-lb:0.0704, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:52:31.479] iteration:29452  t-loss:0.1538, loss-lb:0.0688, loss-ulb:0.0425, weight:2.00, lr:0.0000
[12:52:31.671] iteration:29453  t-loss:0.1448, loss-lb:0.0710, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:52:31.864] iteration:29454  t-loss:0.1415, loss-lb:0.0622, loss-ulb:0.0397, weight:2.00, lr:0.0000
[12:52:32.057] iteration:29455  t-loss:0.1488, loss-lb:0.0701, loss-ulb:0.0394, weight:2.00, lr:0.0000
[12:52:32.249] iteration:29456  t-loss:0.1243, loss-lb:0.0628, loss-ulb:0.0307, weight:2.00, lr:0.0000
[12:52:32.442] iteration:29457  t-loss:0.1365, loss-lb:0.0714, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:52:32.635] iteration:29458  t-loss:0.1463, loss-lb:0.0672, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:52:32.829] iteration:29459  t-loss:0.1376, loss-lb:0.0670, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:52:33.022] iteration:29460  t-loss:0.1660, loss-lb:0.0701, loss-ulb:0.0480, weight:2.00, lr:0.0000
[12:52:33.214] iteration:29461  t-loss:0.1291, loss-lb:0.0644, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:52:33.408] iteration:29462  t-loss:0.1582, loss-lb:0.0665, loss-ulb:0.0458, weight:2.00, lr:0.0000
[12:52:33.601] iteration:29463  t-loss:0.1346, loss-lb:0.0697, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:52:33.793] iteration:29464  t-loss:0.1499, loss-lb:0.0661, loss-ulb:0.0419, weight:2.00, lr:0.0000
[12:52:33.986] iteration:29465  t-loss:0.1500, loss-lb:0.0736, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:52:34.179] iteration:29466  t-loss:0.1465, loss-lb:0.0683, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:52:34.373] iteration:29467  t-loss:0.1518, loss-lb:0.0728, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:52:34.565] iteration:29468  t-loss:0.1387, loss-lb:0.0674, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:52:34.757] iteration:29469  t-loss:0.1319, loss-lb:0.0660, loss-ulb:0.0329, weight:2.00, lr:0.0000
[12:52:34.949] iteration:29470  t-loss:0.1332, loss-lb:0.0663, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:52:35.141] iteration:29471  t-loss:0.1526, loss-lb:0.0708, loss-ulb:0.0409, weight:2.00, lr:0.0000
[12:52:35.334] iteration:29472  t-loss:0.1396, loss-lb:0.0713, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:52:35.526] iteration:29473  t-loss:0.1480, loss-lb:0.0681, loss-ulb:0.0399, weight:2.00, lr:0.0000
[12:52:35.718] iteration:29474  t-loss:0.1298, loss-lb:0.0678, loss-ulb:0.0310, weight:2.00, lr:0.0000
[12:52:35.910] iteration:29475  t-loss:0.1424, loss-lb:0.0683, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:52:36.104] iteration:29476  t-loss:0.1507, loss-lb:0.0776, loss-ulb:0.0365, weight:2.00, lr:0.0000
[12:52:36.295] iteration:29477  t-loss:0.1434, loss-lb:0.0630, loss-ulb:0.0402, weight:2.00, lr:0.0000
[12:52:36.487] iteration:29478  t-loss:0.1298, loss-lb:0.0604, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:52:36.680] iteration:29479  t-loss:0.1345, loss-lb:0.0720, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:52:36.874] iteration:29480  t-loss:0.1657, loss-lb:0.0713, loss-ulb:0.0472, weight:2.00, lr:0.0000
[12:52:37.066] iteration:29481  t-loss:0.2129, loss-lb:0.0662, loss-ulb:0.0734, weight:2.00, lr:0.0000
[12:52:37.259] iteration:29482  t-loss:0.1416, loss-lb:0.0731, loss-ulb:0.0343, weight:2.00, lr:0.0000
[12:52:37.452] iteration:29483  t-loss:0.1375, loss-lb:0.0637, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:52:37.647] iteration:29484  t-loss:0.1337, loss-lb:0.0673, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:52:37.839] iteration:29485  t-loss:0.1438, loss-lb:0.0755, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:52:38.031] iteration:29486  t-loss:0.1246, loss-lb:0.0634, loss-ulb:0.0306, weight:2.00, lr:0.0000
[12:52:38.225] iteration:29487  t-loss:0.1436, loss-lb:0.0745, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:52:38.417] iteration:29488  t-loss:0.1343, loss-lb:0.0653, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:52:38.612] iteration:29489  t-loss:0.1356, loss-lb:0.0705, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:52:38.805] iteration:29490  t-loss:0.1438, loss-lb:0.0705, loss-ulb:0.0366, weight:2.00, lr:0.0000
[12:52:38.998] iteration:29491  t-loss:0.1410, loss-lb:0.0667, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:52:39.191] iteration:29492  t-loss:0.1441, loss-lb:0.0731, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:52:39.381] iteration:29493  t-loss:0.1355, loss-lb:0.0630, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:52:39.573] iteration:29494  t-loss:0.1485, loss-lb:0.0754, loss-ulb:0.0365, weight:2.00, lr:0.0000
[12:52:39.764] iteration:29495  t-loss:0.1411, loss-lb:0.0679, loss-ulb:0.0366, weight:2.00, lr:0.0000
[12:52:39.955] iteration:29496  t-loss:0.1418, loss-lb:0.0714, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:52:40.146] iteration:29497  t-loss:0.1381, loss-lb:0.0658, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:52:40.336] iteration:29498  t-loss:0.1631, loss-lb:0.0664, loss-ulb:0.0484, weight:2.00, lr:0.0000
[12:52:53.392]  <<Test>> - Ep:300  - mean_dice/mean_h95 - S:89.90/1.32, Best-S:90.99, T:89.63/1.37, Best-T:90.48
[12:52:53.393]           - AvgLoss(lb/ulb/all):0.0685/0.0380/0.1452
[12:52:53.972] iteration:29499  t-loss:0.1486, loss-lb:0.0733, loss-ulb:0.0377, weight:2.00, lr:0.0000
[12:52:54.170] iteration:29500  t-loss:0.1416, loss-lb:0.0634, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:52:54.362] iteration:29501  t-loss:0.1338, loss-lb:0.0687, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:52:54.555] iteration:29502  t-loss:0.2117, loss-lb:0.0773, loss-ulb:0.0672, weight:2.00, lr:0.0000
[12:52:54.747] iteration:29503  t-loss:0.1405, loss-lb:0.0734, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:52:54.938] iteration:29504  t-loss:0.1345, loss-lb:0.0656, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:52:55.131] iteration:29505  t-loss:0.1302, loss-lb:0.0655, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:52:55.322] iteration:29506  t-loss:0.1364, loss-lb:0.0649, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:52:55.514] iteration:29507  t-loss:0.1406, loss-lb:0.0712, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:52:55.705] iteration:29508  t-loss:0.1461, loss-lb:0.0678, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:52:55.897] iteration:29509  t-loss:0.1411, loss-lb:0.0626, loss-ulb:0.0393, weight:2.00, lr:0.0000
[12:52:56.090] iteration:29510  t-loss:0.1460, loss-lb:0.0713, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:52:56.281] iteration:29511  t-loss:0.1504, loss-lb:0.0654, loss-ulb:0.0425, weight:2.00, lr:0.0000
[12:52:56.472] iteration:29512  t-loss:0.1529, loss-lb:0.0759, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:52:56.663] iteration:29513  t-loss:0.1423, loss-lb:0.0685, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:52:56.855] iteration:29514  t-loss:0.1302, loss-lb:0.0661, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:52:57.047] iteration:29515  t-loss:0.1703, loss-lb:0.0976, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:52:57.239] iteration:29516  t-loss:0.1291, loss-lb:0.0629, loss-ulb:0.0331, weight:2.00, lr:0.0000
[12:52:57.431] iteration:29517  t-loss:0.1493, loss-lb:0.0748, loss-ulb:0.0373, weight:2.00, lr:0.0000
[12:52:57.623] iteration:29518  t-loss:0.1480, loss-lb:0.0721, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:52:57.814] iteration:29519  t-loss:0.1429, loss-lb:0.0722, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:52:58.005] iteration:29520  t-loss:0.1410, loss-lb:0.0662, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:52:58.197] iteration:29521  t-loss:0.1463, loss-lb:0.0717, loss-ulb:0.0373, weight:2.00, lr:0.0000
[12:52:58.388] iteration:29522  t-loss:0.1479, loss-lb:0.0734, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:52:58.580] iteration:29523  t-loss:0.1321, loss-lb:0.0651, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:52:58.770] iteration:29524  t-loss:0.1440, loss-lb:0.0675, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:52:58.962] iteration:29525  t-loss:0.1431, loss-lb:0.0670, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:52:59.154] iteration:29526  t-loss:0.1449, loss-lb:0.0679, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:52:59.345] iteration:29527  t-loss:0.1361, loss-lb:0.0696, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:52:59.537] iteration:29528  t-loss:0.1429, loss-lb:0.0758, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:52:59.728] iteration:29529  t-loss:0.1435, loss-lb:0.0709, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:52:59.919] iteration:29530  t-loss:0.1340, loss-lb:0.0638, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:53:00.112] iteration:29531  t-loss:0.2453, loss-lb:0.0750, loss-ulb:0.0851, weight:2.00, lr:0.0000
[12:53:00.303] iteration:29532  t-loss:0.1313, loss-lb:0.0647, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:53:00.495] iteration:29533  t-loss:0.1312, loss-lb:0.0678, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:53:00.691] iteration:29534  t-loss:0.1271, loss-lb:0.0675, loss-ulb:0.0298, weight:2.00, lr:0.0000
[12:53:00.895] iteration:29535  t-loss:0.1446, loss-lb:0.0675, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:53:01.092] iteration:29536  t-loss:0.1426, loss-lb:0.0688, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:53:01.284] iteration:29537  t-loss:0.1382, loss-lb:0.0631, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:53:01.477] iteration:29538  t-loss:0.1434, loss-lb:0.0667, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:53:01.667] iteration:29539  t-loss:0.1451, loss-lb:0.0680, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:53:01.859] iteration:29540  t-loss:0.1490, loss-lb:0.0727, loss-ulb:0.0381, weight:2.00, lr:0.0000
[12:53:02.051] iteration:29541  t-loss:0.1478, loss-lb:0.0720, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:53:02.242] iteration:29542  t-loss:0.1402, loss-lb:0.0651, loss-ulb:0.0375, weight:2.00, lr:0.0000
[12:53:02.434] iteration:29543  t-loss:0.1392, loss-lb:0.0651, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:53:02.625] iteration:29544  t-loss:0.1279, loss-lb:0.0667, loss-ulb:0.0306, weight:2.00, lr:0.0000
[12:53:02.818] iteration:29545  t-loss:0.1441, loss-lb:0.0628, loss-ulb:0.0406, weight:2.00, lr:0.0000
[12:53:03.010] iteration:29546  t-loss:0.1527, loss-lb:0.0664, loss-ulb:0.0432, weight:2.00, lr:0.0000
[12:53:03.202] iteration:29547  t-loss:0.1513, loss-lb:0.0745, loss-ulb:0.0384, weight:2.00, lr:0.0000
[12:53:03.394] iteration:29548  t-loss:0.1411, loss-lb:0.0659, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:53:03.586] iteration:29549  t-loss:0.1366, loss-lb:0.0661, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:53:03.777] iteration:29550  t-loss:0.1532, loss-lb:0.0777, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:53:03.970] iteration:29551  t-loss:0.1254, loss-lb:0.0623, loss-ulb:0.0316, weight:2.00, lr:0.0000
[12:53:04.161] iteration:29552  t-loss:0.1564, loss-lb:0.0674, loss-ulb:0.0445, weight:2.00, lr:0.0000
[12:53:04.356] iteration:29553  t-loss:0.1398, loss-lb:0.0677, loss-ulb:0.0360, weight:2.00, lr:0.0000
[12:53:04.552] iteration:29554  t-loss:0.1392, loss-lb:0.0749, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:53:04.745] iteration:29555  t-loss:0.1503, loss-lb:0.0713, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:53:04.941] iteration:29556  t-loss:0.1453, loss-lb:0.0685, loss-ulb:0.0384, weight:2.00, lr:0.0000
[12:53:05.134] iteration:29557  t-loss:0.1692, loss-lb:0.0632, loss-ulb:0.0530, weight:2.00, lr:0.0000
[12:53:05.328] iteration:29558  t-loss:0.1341, loss-lb:0.0662, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:53:05.521] iteration:29559  t-loss:0.1383, loss-lb:0.0623, loss-ulb:0.0380, weight:2.00, lr:0.0000
[12:53:05.712] iteration:29560  t-loss:0.1282, loss-lb:0.0646, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:53:05.905] iteration:29561  t-loss:0.1327, loss-lb:0.0664, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:53:06.097] iteration:29562  t-loss:0.1448, loss-lb:0.0692, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:53:06.289] iteration:29563  t-loss:0.1754, loss-lb:0.0814, loss-ulb:0.0470, weight:2.00, lr:0.0000
[12:53:06.481] iteration:29564  t-loss:0.1414, loss-lb:0.0627, loss-ulb:0.0393, weight:2.00, lr:0.0000
[12:53:06.673] iteration:29565  t-loss:0.1388, loss-lb:0.0705, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:53:06.865] iteration:29566  t-loss:0.1356, loss-lb:0.0689, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:53:07.057] iteration:29567  t-loss:0.1596, loss-lb:0.0745, loss-ulb:0.0426, weight:2.00, lr:0.0000
[12:53:07.248] iteration:29568  t-loss:0.1306, loss-lb:0.0634, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:53:07.440] iteration:29569  t-loss:0.1295, loss-lb:0.0671, loss-ulb:0.0312, weight:2.00, lr:0.0000
[12:53:07.633] iteration:29570  t-loss:0.1367, loss-lb:0.0703, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:53:07.825] iteration:29571  t-loss:0.1486, loss-lb:0.0694, loss-ulb:0.0396, weight:2.00, lr:0.0000
[12:53:08.018] iteration:29572  t-loss:0.1973, loss-lb:0.0738, loss-ulb:0.0617, weight:2.00, lr:0.0000
[12:53:08.210] iteration:29573  t-loss:0.1540, loss-lb:0.0636, loss-ulb:0.0452, weight:2.00, lr:0.0000
[12:53:08.403] iteration:29574  t-loss:0.1232, loss-lb:0.0643, loss-ulb:0.0294, weight:2.00, lr:0.0000
[12:53:08.594] iteration:29575  t-loss:0.1510, loss-lb:0.0790, loss-ulb:0.0360, weight:2.00, lr:0.0000
[12:53:08.786] iteration:29576  t-loss:0.1491, loss-lb:0.0656, loss-ulb:0.0417, weight:2.00, lr:0.0000
[12:53:08.978] iteration:29577  t-loss:0.1320, loss-lb:0.0684, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:53:09.171] iteration:29578  t-loss:0.1335, loss-lb:0.0746, loss-ulb:0.0295, weight:2.00, lr:0.0000
[12:53:09.362] iteration:29579  t-loss:0.1333, loss-lb:0.0589, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:53:09.555] iteration:29580  t-loss:0.1530, loss-lb:0.0841, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:53:09.746] iteration:29581  t-loss:0.1614, loss-lb:0.0654, loss-ulb:0.0480, weight:2.00, lr:0.0000
[12:53:09.937] iteration:29582  t-loss:0.1323, loss-lb:0.0688, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:53:10.129] iteration:29583  t-loss:0.1539, loss-lb:0.0658, loss-ulb:0.0440, weight:2.00, lr:0.0000
[12:53:10.322] iteration:29584  t-loss:0.1904, loss-lb:0.0666, loss-ulb:0.0619, weight:2.00, lr:0.0000
[12:53:10.514] iteration:29585  t-loss:0.1429, loss-lb:0.0738, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:53:10.707] iteration:29586  t-loss:0.1379, loss-lb:0.0636, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:53:10.898] iteration:29587  t-loss:0.1519, loss-lb:0.0782, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:53:11.091] iteration:29588  t-loss:0.1370, loss-lb:0.0664, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:53:11.283] iteration:29589  t-loss:0.1290, loss-lb:0.0642, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:53:11.474] iteration:29590  t-loss:0.1387, loss-lb:0.0695, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:53:11.665] iteration:29591  t-loss:0.1374, loss-lb:0.0663, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:53:11.856] iteration:29592  t-loss:0.1311, loss-lb:0.0684, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:53:12.048] iteration:29593  t-loss:0.1331, loss-lb:0.0708, loss-ulb:0.0312, weight:2.00, lr:0.0000
[12:53:12.238] iteration:29594  t-loss:0.1514, loss-lb:0.0772, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:53:12.428] iteration:29595  t-loss:0.1350, loss-lb:0.0638, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:53:12.619] iteration:29596  t-loss:0.1373, loss-lb:0.0674, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:53:13.205] iteration:29597  t-loss:0.1451, loss-lb:0.0755, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:53:13.398] iteration:29598  t-loss:0.1357, loss-lb:0.0689, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:53:13.591] iteration:29599  t-loss:0.1287, loss-lb:0.0643, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:53:13.783] iteration:29600  t-loss:0.1297, loss-lb:0.0647, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:53:13.974] iteration:29601  t-loss:0.1364, loss-lb:0.0726, loss-ulb:0.0319, weight:2.00, lr:0.0000
[12:53:14.165] iteration:29602  t-loss:0.1305, loss-lb:0.0645, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:53:14.357] iteration:29603  t-loss:0.1677, loss-lb:0.0681, loss-ulb:0.0498, weight:2.00, lr:0.0000
[12:53:14.548] iteration:29604  t-loss:0.1391, loss-lb:0.0646, loss-ulb:0.0373, weight:2.00, lr:0.0000
[12:53:14.740] iteration:29605  t-loss:0.1427, loss-lb:0.0687, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:53:14.931] iteration:29606  t-loss:0.1515, loss-lb:0.0710, loss-ulb:0.0403, weight:2.00, lr:0.0000
[12:53:15.125] iteration:29607  t-loss:0.1365, loss-lb:0.0647, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:53:15.321] iteration:29608  t-loss:0.1389, loss-lb:0.0715, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:53:15.518] iteration:29609  t-loss:0.2033, loss-lb:0.0704, loss-ulb:0.0664, weight:2.00, lr:0.0000
[12:53:15.713] iteration:29610  t-loss:0.1305, loss-lb:0.0714, loss-ulb:0.0295, weight:2.00, lr:0.0000
[12:53:15.906] iteration:29611  t-loss:0.1253, loss-lb:0.0639, loss-ulb:0.0307, weight:2.00, lr:0.0000
[12:53:16.098] iteration:29612  t-loss:0.1344, loss-lb:0.0638, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:53:16.290] iteration:29613  t-loss:0.1310, loss-lb:0.0666, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:53:16.482] iteration:29614  t-loss:0.1478, loss-lb:0.0719, loss-ulb:0.0379, weight:2.00, lr:0.0000
[12:53:16.675] iteration:29615  t-loss:0.1313, loss-lb:0.0683, loss-ulb:0.0315, weight:2.00, lr:0.0000
[12:53:16.866] iteration:29616  t-loss:0.1417, loss-lb:0.0682, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:53:17.058] iteration:29617  t-loss:0.1295, loss-lb:0.0620, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:53:17.250] iteration:29618  t-loss:0.1535, loss-lb:0.0747, loss-ulb:0.0394, weight:2.00, lr:0.0000
[12:53:17.441] iteration:29619  t-loss:0.1399, loss-lb:0.0674, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:53:17.633] iteration:29620  t-loss:0.1372, loss-lb:0.0727, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:53:17.827] iteration:29621  t-loss:0.1316, loss-lb:0.0644, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:53:18.020] iteration:29622  t-loss:0.1515, loss-lb:0.0699, loss-ulb:0.0408, weight:2.00, lr:0.0000
[12:53:18.211] iteration:29623  t-loss:0.1363, loss-lb:0.0627, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:53:18.403] iteration:29624  t-loss:0.1440, loss-lb:0.0645, loss-ulb:0.0398, weight:2.00, lr:0.0000
[12:53:18.596] iteration:29625  t-loss:0.1466, loss-lb:0.0612, loss-ulb:0.0427, weight:2.00, lr:0.0000
[12:53:18.788] iteration:29626  t-loss:0.1365, loss-lb:0.0675, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:53:18.980] iteration:29627  t-loss:0.1422, loss-lb:0.0720, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:53:19.174] iteration:29628  t-loss:0.1489, loss-lb:0.0772, loss-ulb:0.0358, weight:2.00, lr:0.0000
[12:53:19.366] iteration:29629  t-loss:0.2358, loss-lb:0.0717, loss-ulb:0.0820, weight:2.00, lr:0.0000
[12:53:19.558] iteration:29630  t-loss:0.1329, loss-lb:0.0681, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:53:19.751] iteration:29631  t-loss:0.1346, loss-lb:0.0675, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:53:19.945] iteration:29632  t-loss:0.1530, loss-lb:0.0778, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:53:20.137] iteration:29633  t-loss:0.1473, loss-lb:0.0722, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:53:20.330] iteration:29634  t-loss:0.2045, loss-lb:0.0632, loss-ulb:0.0706, weight:2.00, lr:0.0000
[12:53:20.522] iteration:29635  t-loss:0.1304, loss-lb:0.0658, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:53:20.715] iteration:29636  t-loss:0.1338, loss-lb:0.0704, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:53:20.906] iteration:29637  t-loss:0.1485, loss-lb:0.0683, loss-ulb:0.0401, weight:2.00, lr:0.0000
[12:53:21.098] iteration:29638  t-loss:0.1497, loss-lb:0.0656, loss-ulb:0.0420, weight:2.00, lr:0.0000
[12:53:21.291] iteration:29639  t-loss:0.1645, loss-lb:0.0684, loss-ulb:0.0481, weight:2.00, lr:0.0000
[12:53:21.483] iteration:29640  t-loss:0.1220, loss-lb:0.0616, loss-ulb:0.0302, weight:2.00, lr:0.0000
[12:53:21.676] iteration:29641  t-loss:0.1368, loss-lb:0.0638, loss-ulb:0.0365, weight:2.00, lr:0.0000
[12:53:21.869] iteration:29642  t-loss:0.1432, loss-lb:0.0689, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:53:22.060] iteration:29643  t-loss:0.1261, loss-lb:0.0619, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:53:22.253] iteration:29644  t-loss:0.1645, loss-lb:0.0661, loss-ulb:0.0492, weight:2.00, lr:0.0000
[12:53:22.446] iteration:29645  t-loss:0.1417, loss-lb:0.0644, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:53:22.639] iteration:29646  t-loss:0.1627, loss-lb:0.0666, loss-ulb:0.0480, weight:2.00, lr:0.0000
[12:53:22.831] iteration:29647  t-loss:0.1463, loss-lb:0.0649, loss-ulb:0.0407, weight:2.00, lr:0.0000
[12:53:23.023] iteration:29648  t-loss:0.1541, loss-lb:0.0702, loss-ulb:0.0419, weight:2.00, lr:0.0000
[12:53:23.216] iteration:29649  t-loss:0.2105, loss-lb:0.0742, loss-ulb:0.0682, weight:2.00, lr:0.0000
[12:53:23.408] iteration:29650  t-loss:0.1594, loss-lb:0.0745, loss-ulb:0.0424, weight:2.00, lr:0.0000
[12:53:23.600] iteration:29651  t-loss:0.1367, loss-lb:0.0659, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:53:23.793] iteration:29652  t-loss:0.1784, loss-lb:0.0702, loss-ulb:0.0541, weight:2.00, lr:0.0000
[12:53:23.985] iteration:29653  t-loss:0.1456, loss-lb:0.0746, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:53:24.176] iteration:29654  t-loss:0.1771, loss-lb:0.0660, loss-ulb:0.0555, weight:2.00, lr:0.0000
[12:53:24.368] iteration:29655  t-loss:0.1238, loss-lb:0.0650, loss-ulb:0.0294, weight:2.00, lr:0.0000
[12:53:24.560] iteration:29656  t-loss:0.1421, loss-lb:0.0744, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:53:24.752] iteration:29657  t-loss:0.1261, loss-lb:0.0612, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:53:24.944] iteration:29658  t-loss:0.1295, loss-lb:0.0620, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:53:25.135] iteration:29659  t-loss:0.1499, loss-lb:0.0831, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:53:25.326] iteration:29660  t-loss:0.1458, loss-lb:0.0685, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:53:25.518] iteration:29661  t-loss:0.1321, loss-lb:0.0648, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:53:25.709] iteration:29662  t-loss:0.1379, loss-lb:0.0668, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:53:25.902] iteration:29663  t-loss:0.1413, loss-lb:0.0708, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:53:26.094] iteration:29664  t-loss:0.1488, loss-lb:0.0706, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:53:26.286] iteration:29665  t-loss:0.1338, loss-lb:0.0688, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:53:26.478] iteration:29666  t-loss:0.1255, loss-lb:0.0584, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:53:26.671] iteration:29667  t-loss:0.1349, loss-lb:0.0651, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:53:26.864] iteration:29668  t-loss:0.1649, loss-lb:0.0664, loss-ulb:0.0493, weight:2.00, lr:0.0000
[12:53:27.056] iteration:29669  t-loss:0.1530, loss-lb:0.0731, loss-ulb:0.0399, weight:2.00, lr:0.0000
[12:53:27.249] iteration:29670  t-loss:0.1288, loss-lb:0.0687, loss-ulb:0.0300, weight:2.00, lr:0.0000
[12:53:27.442] iteration:29671  t-loss:0.1374, loss-lb:0.0752, loss-ulb:0.0311, weight:2.00, lr:0.0000
[12:53:27.634] iteration:29672  t-loss:0.1442, loss-lb:0.0761, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:53:27.827] iteration:29673  t-loss:0.1435, loss-lb:0.0670, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:53:28.020] iteration:29674  t-loss:0.1602, loss-lb:0.0692, loss-ulb:0.0455, weight:2.00, lr:0.0000
[12:53:28.213] iteration:29675  t-loss:0.1484, loss-lb:0.0700, loss-ulb:0.0392, weight:2.00, lr:0.0000
[12:53:28.406] iteration:29676  t-loss:0.1399, loss-lb:0.0678, loss-ulb:0.0360, weight:2.00, lr:0.0000
[12:53:28.598] iteration:29677  t-loss:0.1459, loss-lb:0.0669, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:53:28.791] iteration:29678  t-loss:0.1563, loss-lb:0.0742, loss-ulb:0.0411, weight:2.00, lr:0.0000
[12:53:28.983] iteration:29679  t-loss:0.1394, loss-lb:0.0684, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:53:29.175] iteration:29680  t-loss:0.1467, loss-lb:0.0701, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:53:29.368] iteration:29681  t-loss:0.1267, loss-lb:0.0609, loss-ulb:0.0329, weight:2.00, lr:0.0000
[12:53:29.561] iteration:29682  t-loss:0.1613, loss-lb:0.0624, loss-ulb:0.0494, weight:2.00, lr:0.0000
[12:53:29.753] iteration:29683  t-loss:0.1453, loss-lb:0.0804, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:53:29.946] iteration:29684  t-loss:0.1230, loss-lb:0.0644, loss-ulb:0.0293, weight:2.00, lr:0.0000
[12:53:30.139] iteration:29685  t-loss:0.1492, loss-lb:0.0715, loss-ulb:0.0389, weight:2.00, lr:0.0000
[12:53:30.331] iteration:29686  t-loss:0.1393, loss-lb:0.0701, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:53:30.523] iteration:29687  t-loss:0.1850, loss-lb:0.0663, loss-ulb:0.0594, weight:2.00, lr:0.0000
[12:53:30.715] iteration:29688  t-loss:0.1545, loss-lb:0.0749, loss-ulb:0.0398, weight:2.00, lr:0.0000
[12:53:30.906] iteration:29689  t-loss:0.1362, loss-lb:0.0673, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:53:31.097] iteration:29690  t-loss:0.1640, loss-lb:0.0710, loss-ulb:0.0465, weight:2.00, lr:0.0000
[12:53:31.288] iteration:29691  t-loss:0.1344, loss-lb:0.0702, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:53:31.479] iteration:29692  t-loss:0.1500, loss-lb:0.0829, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:53:31.670] iteration:29693  t-loss:0.1438, loss-lb:0.0613, loss-ulb:0.0412, weight:2.00, lr:0.0000
[12:53:31.860] iteration:29694  t-loss:0.1324, loss-lb:0.0683, loss-ulb:0.0320, weight:2.00, lr:0.0000
[12:53:43.769]  <<Test>> - Ep:302  - mean_dice/mean_h95 - S:89.84/1.35, Best-S:90.99, T:89.66/1.37, Best-T:90.48
[12:53:43.769]           - AvgLoss(lb/ulb/all):0.0685/0.0383/0.1461
[12:53:44.333] iteration:29695  t-loss:0.1620, loss-lb:0.0699, loss-ulb:0.0461, weight:2.00, lr:0.0000
[12:53:44.529] iteration:29696  t-loss:0.1357, loss-lb:0.0732, loss-ulb:0.0312, weight:2.00, lr:0.0000
[12:53:44.722] iteration:29697  t-loss:0.1331, loss-lb:0.0613, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:53:44.916] iteration:29698  t-loss:0.1424, loss-lb:0.0752, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:53:45.108] iteration:29699  t-loss:0.1541, loss-lb:0.0767, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:53:45.301] iteration:29700  t-loss:0.1468, loss-lb:0.0670, loss-ulb:0.0399, weight:2.00, lr:0.0000
[12:53:45.493] iteration:29701  t-loss:0.1413, loss-lb:0.0744, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:53:45.686] iteration:29702  t-loss:0.1473, loss-lb:0.0605, loss-ulb:0.0434, weight:2.00, lr:0.0000
[12:53:45.880] iteration:29703  t-loss:0.1569, loss-lb:0.0664, loss-ulb:0.0453, weight:2.00, lr:0.0000
[12:53:46.073] iteration:29704  t-loss:0.1440, loss-lb:0.0664, loss-ulb:0.0388, weight:2.00, lr:0.0000
[12:53:46.267] iteration:29705  t-loss:0.1452, loss-lb:0.0678, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:53:46.460] iteration:29706  t-loss:0.1390, loss-lb:0.0687, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:53:46.653] iteration:29707  t-loss:0.1605, loss-lb:0.0780, loss-ulb:0.0413, weight:2.00, lr:0.0000
[12:53:46.846] iteration:29708  t-loss:0.1299, loss-lb:0.0679, loss-ulb:0.0310, weight:2.00, lr:0.0000
[12:53:47.040] iteration:29709  t-loss:0.1365, loss-lb:0.0651, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:53:47.232] iteration:29710  t-loss:0.1353, loss-lb:0.0626, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:53:47.425] iteration:29711  t-loss:0.1461, loss-lb:0.0743, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:53:47.618] iteration:29712  t-loss:0.1466, loss-lb:0.0710, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:53:47.812] iteration:29713  t-loss:0.1435, loss-lb:0.0737, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:53:48.004] iteration:29714  t-loss:0.1293, loss-lb:0.0672, loss-ulb:0.0310, weight:2.00, lr:0.0000
[12:53:48.197] iteration:29715  t-loss:0.1383, loss-lb:0.0689, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:53:48.392] iteration:29716  t-loss:0.1351, loss-lb:0.0696, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:53:48.586] iteration:29717  t-loss:0.1353, loss-lb:0.0676, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:53:48.781] iteration:29718  t-loss:0.1411, loss-lb:0.0728, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:53:48.973] iteration:29719  t-loss:0.1336, loss-lb:0.0677, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:53:49.166] iteration:29720  t-loss:0.1578, loss-lb:0.0728, loss-ulb:0.0425, weight:2.00, lr:0.0000
[12:53:49.358] iteration:29721  t-loss:0.1332, loss-lb:0.0682, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:53:49.551] iteration:29722  t-loss:0.1513, loss-lb:0.0719, loss-ulb:0.0397, weight:2.00, lr:0.0000
[12:53:49.743] iteration:29723  t-loss:0.1359, loss-lb:0.0627, loss-ulb:0.0366, weight:2.00, lr:0.0000
[12:53:49.935] iteration:29724  t-loss:0.1526, loss-lb:0.0696, loss-ulb:0.0415, weight:2.00, lr:0.0000
[12:53:50.127] iteration:29725  t-loss:0.1372, loss-lb:0.0617, loss-ulb:0.0377, weight:2.00, lr:0.0000
[12:53:50.321] iteration:29726  t-loss:0.1420, loss-lb:0.0692, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:53:50.513] iteration:29727  t-loss:0.1395, loss-lb:0.0643, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:53:50.706] iteration:29728  t-loss:0.1346, loss-lb:0.0665, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:53:50.898] iteration:29729  t-loss:0.1469, loss-lb:0.0682, loss-ulb:0.0394, weight:2.00, lr:0.0000
[12:53:51.092] iteration:29730  t-loss:0.2043, loss-lb:0.0743, loss-ulb:0.0650, weight:2.00, lr:0.0000
[12:53:51.284] iteration:29731  t-loss:0.1238, loss-lb:0.0658, loss-ulb:0.0290, weight:2.00, lr:0.0000
[12:53:51.476] iteration:29732  t-loss:0.1435, loss-lb:0.0691, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:53:51.669] iteration:29733  t-loss:0.1378, loss-lb:0.0704, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:53:51.861] iteration:29734  t-loss:0.1427, loss-lb:0.0688, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:53:52.053] iteration:29735  t-loss:0.1506, loss-lb:0.0692, loss-ulb:0.0407, weight:2.00, lr:0.0000
[12:53:52.247] iteration:29736  t-loss:0.1460, loss-lb:0.0748, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:53:52.440] iteration:29737  t-loss:0.1410, loss-lb:0.0654, loss-ulb:0.0378, weight:2.00, lr:0.0000
[12:53:52.633] iteration:29738  t-loss:0.1328, loss-lb:0.0633, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:53:52.827] iteration:29739  t-loss:0.1396, loss-lb:0.0613, loss-ulb:0.0392, weight:2.00, lr:0.0000
[12:53:53.020] iteration:29740  t-loss:0.1346, loss-lb:0.0676, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:53:53.212] iteration:29741  t-loss:0.1410, loss-lb:0.0655, loss-ulb:0.0377, weight:2.00, lr:0.0000
[12:53:53.405] iteration:29742  t-loss:0.1418, loss-lb:0.0670, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:53:53.598] iteration:29743  t-loss:0.1456, loss-lb:0.0692, loss-ulb:0.0382, weight:2.00, lr:0.0000
[12:53:53.791] iteration:29744  t-loss:0.1369, loss-lb:0.0703, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:53:53.983] iteration:29745  t-loss:0.1378, loss-lb:0.0685, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:53:54.175] iteration:29746  t-loss:0.1440, loss-lb:0.0730, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:53:54.367] iteration:29747  t-loss:0.1724, loss-lb:0.0686, loss-ulb:0.0519, weight:2.00, lr:0.0000
[12:53:54.560] iteration:29748  t-loss:0.1375, loss-lb:0.0652, loss-ulb:0.0361, weight:2.00, lr:0.0000
[12:53:54.752] iteration:29749  t-loss:0.1284, loss-lb:0.0659, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:53:54.944] iteration:29750  t-loss:0.1359, loss-lb:0.0738, loss-ulb:0.0310, weight:2.00, lr:0.0000
[12:53:55.137] iteration:29751  t-loss:0.1501, loss-lb:0.0775, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:53:55.330] iteration:29752  t-loss:0.1323, loss-lb:0.0658, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:53:55.523] iteration:29753  t-loss:0.1542, loss-lb:0.0643, loss-ulb:0.0450, weight:2.00, lr:0.0000
[12:53:55.716] iteration:29754  t-loss:0.1481, loss-lb:0.0735, loss-ulb:0.0373, weight:2.00, lr:0.0000
[12:53:55.909] iteration:29755  t-loss:0.1477, loss-lb:0.0660, loss-ulb:0.0408, weight:2.00, lr:0.0000
[12:53:56.102] iteration:29756  t-loss:0.1328, loss-lb:0.0675, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:53:56.296] iteration:29757  t-loss:0.1344, loss-lb:0.0704, loss-ulb:0.0320, weight:2.00, lr:0.0000
[12:53:56.490] iteration:29758  t-loss:0.1300, loss-lb:0.0654, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:53:56.684] iteration:29759  t-loss:0.1342, loss-lb:0.0634, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:53:56.876] iteration:29760  t-loss:0.1608, loss-lb:0.0678, loss-ulb:0.0465, weight:2.00, lr:0.0000
[12:53:57.068] iteration:29761  t-loss:0.1443, loss-lb:0.0760, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:53:57.263] iteration:29762  t-loss:0.1395, loss-lb:0.0670, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:53:57.457] iteration:29763  t-loss:0.1239, loss-lb:0.0614, loss-ulb:0.0312, weight:2.00, lr:0.0000
[12:53:57.649] iteration:29764  t-loss:0.1389, loss-lb:0.0690, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:53:57.841] iteration:29765  t-loss:0.1704, loss-lb:0.0737, loss-ulb:0.0483, weight:2.00, lr:0.0000
[12:53:58.034] iteration:29766  t-loss:0.1375, loss-lb:0.0683, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:53:58.227] iteration:29767  t-loss:0.1514, loss-lb:0.0769, loss-ulb:0.0372, weight:2.00, lr:0.0000
[12:53:58.419] iteration:29768  t-loss:0.1410, loss-lb:0.0735, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:53:58.611] iteration:29769  t-loss:0.1333, loss-lb:0.0637, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:53:58.804] iteration:29770  t-loss:0.1459, loss-lb:0.0762, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:53:58.996] iteration:29771  t-loss:0.1381, loss-lb:0.0656, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:53:59.188] iteration:29772  t-loss:0.1355, loss-lb:0.0655, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:53:59.381] iteration:29773  t-loss:0.1435, loss-lb:0.0673, loss-ulb:0.0381, weight:2.00, lr:0.0000
[12:53:59.575] iteration:29774  t-loss:0.1324, loss-lb:0.0592, loss-ulb:0.0366, weight:2.00, lr:0.0000
[12:53:59.766] iteration:29775  t-loss:0.1354, loss-lb:0.0624, loss-ulb:0.0365, weight:2.00, lr:0.0000
[12:53:59.960] iteration:29776  t-loss:0.1571, loss-lb:0.0841, loss-ulb:0.0365, weight:2.00, lr:0.0000
[12:54:00.152] iteration:29777  t-loss:0.1308, loss-lb:0.0694, loss-ulb:0.0307, weight:2.00, lr:0.0000
[12:54:00.345] iteration:29778  t-loss:0.1454, loss-lb:0.0688, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:54:00.538] iteration:29779  t-loss:0.1411, loss-lb:0.0669, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:54:00.730] iteration:29780  t-loss:0.1394, loss-lb:0.0717, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:54:00.922] iteration:29781  t-loss:0.1385, loss-lb:0.0715, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:54:01.115] iteration:29782  t-loss:0.1291, loss-lb:0.0651, loss-ulb:0.0320, weight:2.00, lr:0.0000
[12:54:01.308] iteration:29783  t-loss:0.1406, loss-lb:0.0728, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:54:01.501] iteration:29784  t-loss:0.1402, loss-lb:0.0628, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:54:01.693] iteration:29785  t-loss:0.1340, loss-lb:0.0681, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:54:01.884] iteration:29786  t-loss:0.1517, loss-lb:0.0741, loss-ulb:0.0388, weight:2.00, lr:0.0000
[12:54:02.074] iteration:29787  t-loss:0.1634, loss-lb:0.0695, loss-ulb:0.0470, weight:2.00, lr:0.0000
[12:54:02.265] iteration:29788  t-loss:0.1401, loss-lb:0.0700, loss-ulb:0.0350, weight:2.00, lr:0.0000
[12:54:02.456] iteration:29789  t-loss:0.1306, loss-lb:0.0671, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:54:02.648] iteration:29790  t-loss:0.1284, loss-lb:0.0639, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:54:02.838] iteration:29791  t-loss:0.1324, loss-lb:0.0639, loss-ulb:0.0343, weight:2.00, lr:0.0000
[12:54:03.030] iteration:29792  t-loss:0.1300, loss-lb:0.0629, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:54:03.647] iteration:29793  t-loss:0.1380, loss-lb:0.0673, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:54:03.843] iteration:29794  t-loss:0.1377, loss-lb:0.0731, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:54:04.036] iteration:29795  t-loss:0.1398, loss-lb:0.0671, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:54:04.228] iteration:29796  t-loss:0.1495, loss-lb:0.0760, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:54:04.420] iteration:29797  t-loss:0.1524, loss-lb:0.0665, loss-ulb:0.0430, weight:2.00, lr:0.0000
[12:54:04.613] iteration:29798  t-loss:0.1291, loss-lb:0.0689, loss-ulb:0.0301, weight:2.00, lr:0.0000
[12:54:04.805] iteration:29799  t-loss:0.1468, loss-lb:0.0673, loss-ulb:0.0397, weight:2.00, lr:0.0000
[12:54:04.997] iteration:29800  t-loss:0.1418, loss-lb:0.0677, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:54:05.190] iteration:29801  t-loss:0.1405, loss-lb:0.0686, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:54:05.381] iteration:29802  t-loss:0.1334, loss-lb:0.0605, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:54:05.575] iteration:29803  t-loss:0.1605, loss-lb:0.0667, loss-ulb:0.0469, weight:2.00, lr:0.0000
[12:54:05.768] iteration:29804  t-loss:0.1490, loss-lb:0.0711, loss-ulb:0.0389, weight:2.00, lr:0.0000
[12:54:05.961] iteration:29805  t-loss:0.1492, loss-lb:0.0681, loss-ulb:0.0405, weight:2.00, lr:0.0000
[12:54:06.156] iteration:29806  t-loss:0.1675, loss-lb:0.0645, loss-ulb:0.0515, weight:2.00, lr:0.0000
[12:54:06.363] iteration:29807  t-loss:0.1418, loss-lb:0.0695, loss-ulb:0.0361, weight:2.00, lr:0.0000
[12:54:06.563] iteration:29808  t-loss:0.1432, loss-lb:0.0722, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:54:06.757] iteration:29809  t-loss:0.1504, loss-lb:0.0774, loss-ulb:0.0365, weight:2.00, lr:0.0000
[12:54:06.951] iteration:29810  t-loss:0.1479, loss-lb:0.0709, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:54:07.144] iteration:29811  t-loss:0.1516, loss-lb:0.0710, loss-ulb:0.0403, weight:2.00, lr:0.0000
[12:54:07.336] iteration:29812  t-loss:0.1429, loss-lb:0.0641, loss-ulb:0.0394, weight:2.00, lr:0.0000
[12:54:07.528] iteration:29813  t-loss:0.1301, loss-lb:0.0664, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:54:07.721] iteration:29814  t-loss:0.1402, loss-lb:0.0697, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:54:07.913] iteration:29815  t-loss:0.1322, loss-lb:0.0661, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:54:08.106] iteration:29816  t-loss:0.1285, loss-lb:0.0617, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:54:08.299] iteration:29817  t-loss:0.1292, loss-lb:0.0663, loss-ulb:0.0314, weight:2.00, lr:0.0000
[12:54:08.493] iteration:29818  t-loss:0.1328, loss-lb:0.0686, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:54:08.685] iteration:29819  t-loss:0.2161, loss-lb:0.0729, loss-ulb:0.0716, weight:2.00, lr:0.0000
[12:54:08.878] iteration:29820  t-loss:0.1537, loss-lb:0.0682, loss-ulb:0.0427, weight:2.00, lr:0.0000
[12:54:09.071] iteration:29821  t-loss:0.1370, loss-lb:0.0725, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:54:09.265] iteration:29822  t-loss:0.1354, loss-lb:0.0686, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:54:09.457] iteration:29823  t-loss:0.1394, loss-lb:0.0655, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:54:09.650] iteration:29824  t-loss:0.1391, loss-lb:0.0690, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:54:09.843] iteration:29825  t-loss:0.1298, loss-lb:0.0639, loss-ulb:0.0329, weight:2.00, lr:0.0000
[12:54:10.037] iteration:29826  t-loss:0.1335, loss-lb:0.0638, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:54:10.231] iteration:29827  t-loss:0.1542, loss-lb:0.0754, loss-ulb:0.0394, weight:2.00, lr:0.0000
[12:54:10.423] iteration:29828  t-loss:0.1497, loss-lb:0.0695, loss-ulb:0.0401, weight:2.00, lr:0.0000
[12:54:10.615] iteration:29829  t-loss:0.1333, loss-lb:0.0650, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:54:10.807] iteration:29830  t-loss:0.1284, loss-lb:0.0656, loss-ulb:0.0314, weight:2.00, lr:0.0000
[12:54:11.000] iteration:29831  t-loss:0.1447, loss-lb:0.0728, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:54:11.193] iteration:29832  t-loss:0.1368, loss-lb:0.0637, loss-ulb:0.0365, weight:2.00, lr:0.0000
[12:54:11.386] iteration:29833  t-loss:0.1398, loss-lb:0.0702, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:54:11.579] iteration:29834  t-loss:0.1637, loss-lb:0.0763, loss-ulb:0.0437, weight:2.00, lr:0.0000
[12:54:11.771] iteration:29835  t-loss:0.1455, loss-lb:0.0688, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:54:11.963] iteration:29836  t-loss:0.1363, loss-lb:0.0627, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:54:12.157] iteration:29837  t-loss:0.1419, loss-lb:0.0692, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:54:12.349] iteration:29838  t-loss:0.1397, loss-lb:0.0754, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:54:12.541] iteration:29839  t-loss:0.1240, loss-lb:0.0636, loss-ulb:0.0302, weight:2.00, lr:0.0000
[12:54:12.734] iteration:29840  t-loss:0.1379, loss-lb:0.0655, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:54:12.927] iteration:29841  t-loss:0.1465, loss-lb:0.0660, loss-ulb:0.0403, weight:2.00, lr:0.0000
[12:54:13.119] iteration:29842  t-loss:0.1364, loss-lb:0.0693, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:54:13.312] iteration:29843  t-loss:0.1503, loss-lb:0.0692, loss-ulb:0.0406, weight:2.00, lr:0.0000
[12:54:13.504] iteration:29844  t-loss:0.1439, loss-lb:0.0692, loss-ulb:0.0373, weight:2.00, lr:0.0000
[12:54:13.698] iteration:29845  t-loss:0.1382, loss-lb:0.0736, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:54:13.890] iteration:29846  t-loss:0.1771, loss-lb:0.0664, loss-ulb:0.0554, weight:2.00, lr:0.0000
[12:54:14.083] iteration:29847  t-loss:0.1375, loss-lb:0.0733, loss-ulb:0.0321, weight:2.00, lr:0.0000
[12:54:14.276] iteration:29848  t-loss:0.1542, loss-lb:0.0638, loss-ulb:0.0452, weight:2.00, lr:0.0000
[12:54:14.470] iteration:29849  t-loss:0.1497, loss-lb:0.0778, loss-ulb:0.0360, weight:2.00, lr:0.0000
[12:54:14.662] iteration:29850  t-loss:0.1283, loss-lb:0.0589, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:54:14.855] iteration:29851  t-loss:0.1456, loss-lb:0.0805, loss-ulb:0.0325, weight:2.00, lr:0.0000
[12:54:15.047] iteration:29852  t-loss:0.1591, loss-lb:0.0768, loss-ulb:0.0411, weight:2.00, lr:0.0000
[12:54:15.239] iteration:29853  t-loss:0.1272, loss-lb:0.0642, loss-ulb:0.0315, weight:2.00, lr:0.0000
[12:54:15.432] iteration:29854  t-loss:0.1399, loss-lb:0.0705, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:54:15.625] iteration:29855  t-loss:0.1367, loss-lb:0.0707, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:54:15.820] iteration:29856  t-loss:0.1259, loss-lb:0.0639, loss-ulb:0.0310, weight:2.00, lr:0.0000
[12:54:16.015] iteration:29857  t-loss:0.1432, loss-lb:0.0684, loss-ulb:0.0374, weight:2.00, lr:0.0000
[12:54:16.211] iteration:29858  t-loss:0.1414, loss-lb:0.0663, loss-ulb:0.0376, weight:2.00, lr:0.0000
[12:54:16.406] iteration:29859  t-loss:0.1557, loss-lb:0.0664, loss-ulb:0.0446, weight:2.00, lr:0.0000
[12:54:16.598] iteration:29860  t-loss:0.1400, loss-lb:0.0685, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:54:16.790] iteration:29861  t-loss:0.1343, loss-lb:0.0699, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:54:16.982] iteration:29862  t-loss:0.1605, loss-lb:0.0684, loss-ulb:0.0461, weight:2.00, lr:0.0000
[12:54:17.176] iteration:29863  t-loss:0.1443, loss-lb:0.0653, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:54:17.370] iteration:29864  t-loss:0.1350, loss-lb:0.0688, loss-ulb:0.0331, weight:2.00, lr:0.0000
[12:54:17.562] iteration:29865  t-loss:0.1353, loss-lb:0.0683, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:54:17.754] iteration:29866  t-loss:0.2338, loss-lb:0.0675, loss-ulb:0.0832, weight:2.00, lr:0.0000
[12:54:17.947] iteration:29867  t-loss:0.1329, loss-lb:0.0672, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:54:18.140] iteration:29868  t-loss:0.1450, loss-lb:0.0758, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:54:18.332] iteration:29869  t-loss:0.1364, loss-lb:0.0639, loss-ulb:0.0363, weight:2.00, lr:0.0000
[12:54:18.523] iteration:29870  t-loss:0.1365, loss-lb:0.0714, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:54:18.718] iteration:29871  t-loss:0.1344, loss-lb:0.0691, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:54:18.910] iteration:29872  t-loss:0.1441, loss-lb:0.0734, loss-ulb:0.0353, weight:2.00, lr:0.0000
[12:54:19.102] iteration:29873  t-loss:0.1309, loss-lb:0.0720, loss-ulb:0.0294, weight:2.00, lr:0.0000
[12:54:19.295] iteration:29874  t-loss:0.1401, loss-lb:0.0700, loss-ulb:0.0351, weight:2.00, lr:0.0000
[12:54:19.487] iteration:29875  t-loss:0.1261, loss-lb:0.0635, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:54:19.680] iteration:29876  t-loss:0.1422, loss-lb:0.0621, loss-ulb:0.0400, weight:2.00, lr:0.0000
[12:54:19.873] iteration:29877  t-loss:0.1284, loss-lb:0.0612, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:54:20.065] iteration:29878  t-loss:0.1275, loss-lb:0.0650, loss-ulb:0.0313, weight:2.00, lr:0.0000
[12:54:20.257] iteration:29879  t-loss:0.1413, loss-lb:0.0702, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:54:20.449] iteration:29880  t-loss:0.1369, loss-lb:0.0653, loss-ulb:0.0358, weight:2.00, lr:0.0000
[12:54:20.643] iteration:29881  t-loss:0.1559, loss-lb:0.0770, loss-ulb:0.0394, weight:2.00, lr:0.0000
[12:54:20.834] iteration:29882  t-loss:0.1495, loss-lb:0.0704, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:54:21.027] iteration:29883  t-loss:0.1442, loss-lb:0.0704, loss-ulb:0.0369, weight:2.00, lr:0.0000
[12:54:21.219] iteration:29884  t-loss:0.1437, loss-lb:0.0636, loss-ulb:0.0400, weight:2.00, lr:0.0000
[12:54:21.410] iteration:29885  t-loss:0.1406, loss-lb:0.0701, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:54:21.600] iteration:29886  t-loss:0.1597, loss-lb:0.0697, loss-ulb:0.0450, weight:2.00, lr:0.0000
[12:54:21.791] iteration:29887  t-loss:0.1336, loss-lb:0.0657, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:54:21.980] iteration:29888  t-loss:0.1264, loss-lb:0.0712, loss-ulb:0.0276, weight:2.00, lr:0.0000
[12:54:22.171] iteration:29889  t-loss:0.1843, loss-lb:0.0632, loss-ulb:0.0605, weight:2.00, lr:0.0000
[12:54:22.364] iteration:29890  t-loss:0.1344, loss-lb:0.0647, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:54:35.270]  <<Test>> - Ep:304  - mean_dice/mean_h95 - S:89.83/1.34, Best-S:90.99, T:89.65/1.36, Best-T:90.48
[12:54:35.270]           - AvgLoss(lb/ulb/all):0.0685/0.0367/0.1412
[12:54:35.806] iteration:29891  t-loss:0.1380, loss-lb:0.0594, loss-ulb:0.0393, weight:2.00, lr:0.0000
[12:54:36.000] iteration:29892  t-loss:0.1315, loss-lb:0.0676, loss-ulb:0.0319, weight:2.00, lr:0.0000
[12:54:36.192] iteration:29893  t-loss:0.1301, loss-lb:0.0657, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:54:36.383] iteration:29894  t-loss:0.1377, loss-lb:0.0706, loss-ulb:0.0335, weight:2.00, lr:0.0000
[12:54:36.575] iteration:29895  t-loss:0.1248, loss-lb:0.0662, loss-ulb:0.0293, weight:2.00, lr:0.0000
[12:54:36.766] iteration:29896  t-loss:0.1304, loss-lb:0.0651, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:54:36.957] iteration:29897  t-loss:0.1491, loss-lb:0.0722, loss-ulb:0.0385, weight:2.00, lr:0.0000
[12:54:37.148] iteration:29898  t-loss:0.1964, loss-lb:0.0699, loss-ulb:0.0633, weight:2.00, lr:0.0000
[12:54:37.339] iteration:29899  t-loss:0.1513, loss-lb:0.0700, loss-ulb:0.0406, weight:2.00, lr:0.0000
[12:54:37.532] iteration:29900  t-loss:0.1555, loss-lb:0.0662, loss-ulb:0.0447, weight:2.00, lr:0.0000
[12:54:37.726] iteration:29901  t-loss:0.1348, loss-lb:0.0644, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:54:37.918] iteration:29902  t-loss:0.1291, loss-lb:0.0674, loss-ulb:0.0308, weight:2.00, lr:0.0000
[12:54:38.108] iteration:29903  t-loss:0.1366, loss-lb:0.0726, loss-ulb:0.0320, weight:2.00, lr:0.0000
[12:54:38.298] iteration:29904  t-loss:0.1311, loss-lb:0.0665, loss-ulb:0.0323, weight:2.00, lr:0.0000
[12:54:38.488] iteration:29905  t-loss:0.1290, loss-lb:0.0635, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:54:38.676] iteration:29906  t-loss:0.1384, loss-lb:0.0706, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:54:38.864] iteration:29907  t-loss:0.1450, loss-lb:0.0784, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:54:39.059] iteration:29908  t-loss:0.1672, loss-lb:0.0715, loss-ulb:0.0478, weight:2.00, lr:0.0000
[12:54:39.253] iteration:29909  t-loss:0.1362, loss-lb:0.0671, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:54:39.443] iteration:29910  t-loss:0.1499, loss-lb:0.0698, loss-ulb:0.0400, weight:2.00, lr:0.0000
[12:54:39.633] iteration:29911  t-loss:0.1680, loss-lb:0.0681, loss-ulb:0.0499, weight:2.00, lr:0.0000
[12:54:39.821] iteration:29912  t-loss:0.1383, loss-lb:0.0700, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:54:40.009] iteration:29913  t-loss:0.1328, loss-lb:0.0722, loss-ulb:0.0303, weight:2.00, lr:0.0000
[12:54:40.198] iteration:29914  t-loss:0.1283, loss-lb:0.0634, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:54:40.387] iteration:29915  t-loss:0.1377, loss-lb:0.0664, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:54:40.575] iteration:29916  t-loss:0.1356, loss-lb:0.0723, loss-ulb:0.0317, weight:2.00, lr:0.0000
[12:54:40.764] iteration:29917  t-loss:0.1364, loss-lb:0.0711, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:54:40.952] iteration:29918  t-loss:0.2429, loss-lb:0.0713, loss-ulb:0.0858, weight:2.00, lr:0.0000
[12:54:41.141] iteration:29919  t-loss:0.1357, loss-lb:0.0582, loss-ulb:0.0387, weight:2.00, lr:0.0000
[12:54:41.330] iteration:29920  t-loss:0.1336, loss-lb:0.0732, loss-ulb:0.0302, weight:2.00, lr:0.0000
[12:54:41.518] iteration:29921  t-loss:0.1302, loss-lb:0.0627, loss-ulb:0.0338, weight:2.00, lr:0.0000
[12:54:41.707] iteration:29922  t-loss:0.1344, loss-lb:0.0672, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:54:41.895] iteration:29923  t-loss:0.1527, loss-lb:0.0733, loss-ulb:0.0397, weight:2.00, lr:0.0000
[12:54:42.083] iteration:29924  t-loss:0.1321, loss-lb:0.0669, loss-ulb:0.0326, weight:2.00, lr:0.0000
[12:54:42.271] iteration:29925  t-loss:0.1325, loss-lb:0.0615, loss-ulb:0.0355, weight:2.00, lr:0.0000
[12:54:42.459] iteration:29926  t-loss:0.1448, loss-lb:0.0764, loss-ulb:0.0342, weight:2.00, lr:0.0000
[12:54:42.648] iteration:29927  t-loss:0.1313, loss-lb:0.0708, loss-ulb:0.0302, weight:2.00, lr:0.0000
[12:54:42.838] iteration:29928  t-loss:0.1310, loss-lb:0.0643, loss-ulb:0.0333, weight:2.00, lr:0.0000
[12:54:43.028] iteration:29929  t-loss:0.1362, loss-lb:0.0628, loss-ulb:0.0367, weight:2.00, lr:0.0000
[12:54:43.217] iteration:29930  t-loss:0.1627, loss-lb:0.0744, loss-ulb:0.0441, weight:2.00, lr:0.0000
[12:54:43.405] iteration:29931  t-loss:0.1351, loss-lb:0.0687, loss-ulb:0.0332, weight:2.00, lr:0.0000
[12:54:43.594] iteration:29932  t-loss:0.1515, loss-lb:0.0796, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:54:43.783] iteration:29933  t-loss:0.1669, loss-lb:0.0742, loss-ulb:0.0464, weight:2.00, lr:0.0000
[12:54:43.970] iteration:29934  t-loss:0.1379, loss-lb:0.0705, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:54:44.159] iteration:29935  t-loss:0.1349, loss-lb:0.0635, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:54:44.348] iteration:29936  t-loss:0.1401, loss-lb:0.0703, loss-ulb:0.0349, weight:2.00, lr:0.0000
[12:54:44.536] iteration:29937  t-loss:0.1447, loss-lb:0.0638, loss-ulb:0.0404, weight:2.00, lr:0.0000
[12:54:44.725] iteration:29938  t-loss:0.1283, loss-lb:0.0645, loss-ulb:0.0319, weight:2.00, lr:0.0000
[12:54:44.913] iteration:29939  t-loss:0.1542, loss-lb:0.0692, loss-ulb:0.0425, weight:2.00, lr:0.0000
[12:54:45.102] iteration:29940  t-loss:0.1380, loss-lb:0.0626, loss-ulb:0.0377, weight:2.00, lr:0.0000
[12:54:45.291] iteration:29941  t-loss:0.1381, loss-lb:0.0658, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:54:45.479] iteration:29942  t-loss:0.1474, loss-lb:0.0724, loss-ulb:0.0375, weight:2.00, lr:0.0000
[12:54:45.669] iteration:29943  t-loss:0.1357, loss-lb:0.0733, loss-ulb:0.0312, weight:2.00, lr:0.0000
[12:54:45.856] iteration:29944  t-loss:0.1501, loss-lb:0.0670, loss-ulb:0.0415, weight:2.00, lr:0.0000
[12:54:46.046] iteration:29945  t-loss:0.1272, loss-lb:0.0645, loss-ulb:0.0314, weight:2.00, lr:0.0000
[12:54:46.234] iteration:29946  t-loss:0.1433, loss-lb:0.0765, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:54:46.422] iteration:29947  t-loss:0.1443, loss-lb:0.0755, loss-ulb:0.0344, weight:2.00, lr:0.0000
[12:54:46.610] iteration:29948  t-loss:0.1426, loss-lb:0.0636, loss-ulb:0.0395, weight:2.00, lr:0.0000
[12:54:46.798] iteration:29949  t-loss:0.1401, loss-lb:0.0610, loss-ulb:0.0396, weight:2.00, lr:0.0000
[12:54:46.987] iteration:29950  t-loss:0.1418, loss-lb:0.0715, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:54:47.175] iteration:29951  t-loss:0.1355, loss-lb:0.0578, loss-ulb:0.0389, weight:2.00, lr:0.0000
[12:54:47.363] iteration:29952  t-loss:0.1386, loss-lb:0.0723, loss-ulb:0.0331, weight:2.00, lr:0.0000
[12:54:47.551] iteration:29953  t-loss:0.1308, loss-lb:0.0629, loss-ulb:0.0340, weight:2.00, lr:0.0000
[12:54:47.740] iteration:29954  t-loss:0.1494, loss-lb:0.0728, loss-ulb:0.0383, weight:2.00, lr:0.0000
[12:54:47.928] iteration:29955  t-loss:0.1426, loss-lb:0.0683, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:54:48.116] iteration:29956  t-loss:0.1492, loss-lb:0.0749, loss-ulb:0.0371, weight:2.00, lr:0.0000
[12:54:48.304] iteration:29957  t-loss:0.1401, loss-lb:0.0741, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:54:48.493] iteration:29958  t-loss:0.1432, loss-lb:0.0708, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:54:48.683] iteration:29959  t-loss:0.1285, loss-lb:0.0689, loss-ulb:0.0298, weight:2.00, lr:0.0000
[12:54:48.876] iteration:29960  t-loss:0.1282, loss-lb:0.0635, loss-ulb:0.0324, weight:2.00, lr:0.0000
[12:54:49.066] iteration:29961  t-loss:0.1539, loss-lb:0.0720, loss-ulb:0.0409, weight:2.00, lr:0.0000
[12:54:49.257] iteration:29962  t-loss:0.1352, loss-lb:0.0669, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:54:49.447] iteration:29963  t-loss:0.1392, loss-lb:0.0719, loss-ulb:0.0337, weight:2.00, lr:0.0000
[12:54:49.635] iteration:29964  t-loss:0.1409, loss-lb:0.0626, loss-ulb:0.0391, weight:2.00, lr:0.0000
[12:54:49.824] iteration:29965  t-loss:0.1418, loss-lb:0.0650, loss-ulb:0.0384, weight:2.00, lr:0.0000
[12:54:50.012] iteration:29966  t-loss:0.1404, loss-lb:0.0695, loss-ulb:0.0354, weight:2.00, lr:0.0000
[12:54:50.201] iteration:29967  t-loss:0.1383, loss-lb:0.0689, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:54:50.389] iteration:29968  t-loss:0.1449, loss-lb:0.0696, loss-ulb:0.0377, weight:2.00, lr:0.0000
[12:54:50.577] iteration:29969  t-loss:0.1449, loss-lb:0.0725, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:54:50.766] iteration:29970  t-loss:0.1439, loss-lb:0.0698, loss-ulb:0.0370, weight:2.00, lr:0.0000
[12:54:50.955] iteration:29971  t-loss:0.1327, loss-lb:0.0649, loss-ulb:0.0339, weight:2.00, lr:0.0000
[12:54:51.145] iteration:29972  t-loss:0.1614, loss-lb:0.0665, loss-ulb:0.0474, weight:2.00, lr:0.0000
[12:54:51.334] iteration:29973  t-loss:0.1364, loss-lb:0.0672, loss-ulb:0.0346, weight:2.00, lr:0.0000
[12:54:51.522] iteration:29974  t-loss:0.1434, loss-lb:0.0710, loss-ulb:0.0362, weight:2.00, lr:0.0000
[12:54:51.712] iteration:29975  t-loss:0.1498, loss-lb:0.0610, loss-ulb:0.0444, weight:2.00, lr:0.0000
[12:54:51.901] iteration:29976  t-loss:0.1297, loss-lb:0.0607, loss-ulb:0.0345, weight:2.00, lr:0.0000
[12:54:52.089] iteration:29977  t-loss:0.1356, loss-lb:0.0696, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:54:52.278] iteration:29978  t-loss:0.1393, loss-lb:0.0681, loss-ulb:0.0356, weight:2.00, lr:0.0000
[12:54:52.468] iteration:29979  t-loss:0.1405, loss-lb:0.0688, loss-ulb:0.0359, weight:2.00, lr:0.0000
[12:54:52.658] iteration:29980  t-loss:0.1380, loss-lb:0.0724, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:54:52.847] iteration:29981  t-loss:0.1339, loss-lb:0.0677, loss-ulb:0.0331, weight:2.00, lr:0.0000
[12:54:53.035] iteration:29982  t-loss:0.1318, loss-lb:0.0635, loss-ulb:0.0341, weight:2.00, lr:0.0000
[12:54:53.222] iteration:29983  t-loss:0.1429, loss-lb:0.0693, loss-ulb:0.0368, weight:2.00, lr:0.0000
[12:54:53.409] iteration:29984  t-loss:0.1411, loss-lb:0.0697, loss-ulb:0.0357, weight:2.00, lr:0.0000
[12:54:53.597] iteration:29985  t-loss:0.1357, loss-lb:0.0663, loss-ulb:0.0347, weight:2.00, lr:0.0000
[12:54:53.784] iteration:29986  t-loss:0.1411, loss-lb:0.0743, loss-ulb:0.0334, weight:2.00, lr:0.0000
[12:54:53.972] iteration:29987  t-loss:0.1497, loss-lb:0.0678, loss-ulb:0.0410, weight:2.00, lr:0.0000
[12:54:54.160] iteration:29988  t-loss:0.2108, loss-lb:0.0692, loss-ulb:0.0708, weight:2.00, lr:0.0000
[12:54:54.758] iteration:29989  t-loss:0.1332, loss-lb:0.0678, loss-ulb:0.0327, weight:2.00, lr:0.0000
[12:54:54.953] iteration:29990  t-loss:0.1388, loss-lb:0.0716, loss-ulb:0.0336, weight:2.00, lr:0.0000
[12:54:55.153] iteration:29991  t-loss:0.1229, loss-lb:0.0585, loss-ulb:0.0322, weight:2.00, lr:0.0000
[12:54:55.346] iteration:29992  t-loss:0.1464, loss-lb:0.0736, loss-ulb:0.0364, weight:2.00, lr:0.0000
[12:54:55.539] iteration:29993  t-loss:0.1485, loss-lb:0.0645, loss-ulb:0.0420, weight:2.00, lr:0.0000
[12:54:55.732] iteration:29994  t-loss:0.1375, loss-lb:0.0672, loss-ulb:0.0352, weight:2.00, lr:0.0000
[12:54:55.924] iteration:29995  t-loss:0.1293, loss-lb:0.0677, loss-ulb:0.0308, weight:2.00, lr:0.0000
[12:54:56.116] iteration:29996  t-loss:0.1305, loss-lb:0.0644, loss-ulb:0.0330, weight:2.00, lr:0.0000
[12:54:56.307] iteration:29997  t-loss:0.1381, loss-lb:0.0686, loss-ulb:0.0348, weight:2.00, lr:0.0000
[12:54:56.500] iteration:29998  t-loss:0.1321, loss-lb:0.0665, loss-ulb:0.0328, weight:2.00, lr:0.0000
[12:54:56.691] iteration:29999  t-loss:0.1531, loss-lb:0.0705, loss-ulb:0.0413, weight:2.00, lr:0.0000
[12:54:56.883] iteration:30000  t-loss:0.1384, loss-lb:0.0749, loss-ulb:0.0318, weight:2.00, lr:0.0000
[12:55:08.765]  <<Test>> - Ep:306  - mean_dice/mean_h95 - S:89.85/1.35, Best-S:90.99, T:89.65/1.36, Best-T:90.48
[12:55:08.766]           - AvgLoss(lb/ulb/all):0.0680/0.0347/0.1374
