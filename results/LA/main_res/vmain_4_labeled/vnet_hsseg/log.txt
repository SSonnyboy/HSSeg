[23:07:00.511] {'base_lr': 0.001,
 'batch_size': 4,
 'cfg': 'config_3d_la_aut.yml',
 'consistency': 2.0,
 'consistency_rampup': 40,
 'deterministic': 1,
 'ema_decay': 0.99,
 'exp': 'omega_test/v_hist_weight_0.5',
 'gamma': 0.05,
 'gpu_id': 2,
 'hist_weight': 0.5,
 'labeled_bs': 2,
 'labeled_num': 4,
 'loss_type': 'rnkc',
 'max_iterations': 15000,
 'max_samples': 80,
 'model': 'vnet_hsseg',
 'num_classes': 2,
 'patch_size': [112, 112, 80],
 'poly': True,
 'res_path': './results/LA',
 'root_path': '/home/chenyu/SSMIS/data/LA',
 'save_interval_epoch': 1000000,
 'seed': 2025,
 'stage_k': 4,
 'test_interval_ep': 4,
 'test_interval_iter': 200,
 'threshold': 0.75,
 'train_mode': 6,
 'workers': 4}
[23:07:02.476] 38 iterations per epoch
[23:07:04.833] iteration:1  t-loss:0.5524, loss-lb:0.5524, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:05.062] iteration:2  t-loss:0.4690, loss-lb:0.4690, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:05.269] iteration:3  t-loss:0.4329, loss-lb:0.4329, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:05.480] iteration:4  t-loss:0.3627, loss-lb:0.3627, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:05.697] iteration:5  t-loss:0.4793, loss-lb:0.4793, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:05.909] iteration:6  t-loss:0.3774, loss-lb:0.3774, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:06.167] iteration:7  t-loss:0.3475, loss-lb:0.3475, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:06.408] iteration:8  t-loss:0.3848, loss-lb:0.3848, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:06.647] iteration:9  t-loss:0.3636, loss-lb:0.3636, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:06.891] iteration:10  t-loss:0.3258, loss-lb:0.3258, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:07.132] iteration:11  t-loss:0.3320, loss-lb:0.3320, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:07.361] iteration:12  t-loss:0.3551, loss-lb:0.3551, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:07.617] iteration:13  t-loss:0.3757, loss-lb:0.3757, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:07.856] iteration:14  t-loss:0.2763, loss-lb:0.2763, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:08.086] iteration:15  t-loss:0.3054, loss-lb:0.3054, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:08.327] iteration:16  t-loss:0.2756, loss-lb:0.2756, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:08.552] iteration:17  t-loss:0.2489, loss-lb:0.2489, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:08.769] iteration:18  t-loss:0.2549, loss-lb:0.2549, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:08.981] iteration:19  t-loss:0.4576, loss-lb:0.4576, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:09.193] iteration:20  t-loss:0.2998, loss-lb:0.2998, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:09.410] iteration:21  t-loss:0.3664, loss-lb:0.3664, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:09.631] iteration:22  t-loss:0.2532, loss-lb:0.2532, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:09.840] iteration:23  t-loss:0.3006, loss-lb:0.3006, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:10.051] iteration:24  t-loss:0.3101, loss-lb:0.3101, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:10.270] iteration:25  t-loss:0.3094, loss-lb:0.3094, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:10.496] iteration:26  t-loss:0.2583, loss-lb:0.2583, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:10.734] iteration:27  t-loss:0.2934, loss-lb:0.2934, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:10.975] iteration:28  t-loss:0.2722, loss-lb:0.2722, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:11.231] iteration:29  t-loss:0.3219, loss-lb:0.3219, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:11.456] iteration:30  t-loss:0.2635, loss-lb:0.2635, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:11.695] iteration:31  t-loss:0.3052, loss-lb:0.3052, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:11.927] iteration:32  t-loss:0.2617, loss-lb:0.2617, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:12.138] iteration:33  t-loss:0.2803, loss-lb:0.2803, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:12.333] iteration:34  t-loss:0.2833, loss-lb:0.2833, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:12.526] iteration:35  t-loss:0.2581, loss-lb:0.2581, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:12.724] iteration:36  t-loss:0.2584, loss-lb:0.2584, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:12.922] iteration:37  t-loss:0.2689, loss-lb:0.2689, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:07:13.115] iteration:38  t-loss:0.2945, loss-lb:0.2945, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:11.733] iteration 38 : dice_score: 0.591448 best_dice: 0.591400
[23:08:11.733]  <<Test>> - Ep:0  - Dice-S/T:59.14/59.14, Best-S:59.14, Best-T:59.14
[23:08:11.733]           - AvgLoss(lb/ulb/all):0.33/0.00/0.30
[23:08:12.728] iteration:39  t-loss:0.2727, loss-lb:0.2727, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:12.950] iteration:40  t-loss:0.2511, loss-lb:0.2511, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:13.178] iteration:41  t-loss:0.2534, loss-lb:0.2534, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:13.404] iteration:42  t-loss:0.2574, loss-lb:0.2574, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:13.625] iteration:43  t-loss:0.2302, loss-lb:0.2302, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:13.840] iteration:44  t-loss:0.3050, loss-lb:0.3050, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:14.053] iteration:45  t-loss:0.2341, loss-lb:0.2341, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:14.268] iteration:46  t-loss:0.2714, loss-lb:0.2714, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:14.482] iteration:47  t-loss:0.2839, loss-lb:0.2839, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:14.685] iteration:48  t-loss:0.2216, loss-lb:0.2216, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:14.882] iteration:49  t-loss:0.1954, loss-lb:0.1954, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:15.081] iteration:50  t-loss:0.2182, loss-lb:0.2182, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:15.281] iteration:51  t-loss:0.2251, loss-lb:0.2251, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:15.483] iteration:52  t-loss:0.1935, loss-lb:0.1935, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:15.682] iteration:53  t-loss:0.2174, loss-lb:0.2174, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:15.885] iteration:54  t-loss:0.2305, loss-lb:0.2305, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:16.086] iteration:55  t-loss:0.1959, loss-lb:0.1959, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:16.283] iteration:56  t-loss:0.1643, loss-lb:0.1643, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:16.478] iteration:57  t-loss:0.2274, loss-lb:0.2274, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:16.675] iteration:58  t-loss:0.2563, loss-lb:0.2563, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:16.878] iteration:59  t-loss:0.3121, loss-lb:0.3121, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:17.076] iteration:60  t-loss:0.2459, loss-lb:0.2459, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:17.276] iteration:61  t-loss:0.3287, loss-lb:0.3287, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:17.479] iteration:62  t-loss:0.2051, loss-lb:0.2051, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:17.684] iteration:63  t-loss:0.2313, loss-lb:0.2313, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:17.888] iteration:64  t-loss:0.2190, loss-lb:0.2190, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:18.083] iteration:65  t-loss:0.2131, loss-lb:0.2131, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:18.279] iteration:66  t-loss:0.2156, loss-lb:0.2156, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:18.480] iteration:67  t-loss:0.2147, loss-lb:0.2147, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:18.676] iteration:68  t-loss:0.2692, loss-lb:0.2692, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:18.872] iteration:69  t-loss:0.2603, loss-lb:0.2603, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:19.067] iteration:70  t-loss:0.2621, loss-lb:0.2621, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:19.257] iteration:71  t-loss:0.2486, loss-lb:0.2486, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:19.445] iteration:72  t-loss:0.2121, loss-lb:0.2121, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:19.634] iteration:73  t-loss:0.2880, loss-lb:0.2880, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:19.821] iteration:74  t-loss:0.1831, loss-lb:0.1831, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:20.011] iteration:75  t-loss:0.2698, loss-lb:0.2698, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:20.199] iteration:76  t-loss:0.2051, loss-lb:0.2051, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:21.254] iteration:77  t-loss:0.2396, loss-lb:0.2396, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:21.483] iteration:78  t-loss:0.2040, loss-lb:0.2040, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:21.707] iteration:79  t-loss:0.2859, loss-lb:0.2859, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:21.933] iteration:80  t-loss:0.2161, loss-lb:0.2161, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:22.153] iteration:81  t-loss:0.2585, loss-lb:0.2585, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:22.364] iteration:82  t-loss:0.1713, loss-lb:0.1713, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:22.570] iteration:83  t-loss:0.2735, loss-lb:0.2735, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:22.780] iteration:84  t-loss:0.1881, loss-lb:0.1881, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:22.984] iteration:85  t-loss:0.2537, loss-lb:0.2537, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:23.178] iteration:86  t-loss:0.2615, loss-lb:0.2615, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:23.371] iteration:87  t-loss:0.1879, loss-lb:0.1879, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:23.571] iteration:88  t-loss:0.1981, loss-lb:0.1981, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:23.769] iteration:89  t-loss:0.2265, loss-lb:0.2265, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:23.968] iteration:90  t-loss:0.2561, loss-lb:0.2561, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:24.170] iteration:91  t-loss:0.2980, loss-lb:0.2980, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:24.368] iteration:92  t-loss:0.1491, loss-lb:0.1491, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:24.562] iteration:93  t-loss:0.2382, loss-lb:0.2382, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:24.760] iteration:94  t-loss:0.1908, loss-lb:0.1908, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:24.962] iteration:95  t-loss:0.2237, loss-lb:0.2237, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:25.162] iteration:96  t-loss:0.1710, loss-lb:0.1710, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:25.361] iteration:97  t-loss:0.1517, loss-lb:0.1517, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:25.564] iteration:98  t-loss:0.2136, loss-lb:0.2136, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:25.766] iteration:99  t-loss:0.2928, loss-lb:0.2928, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:25.970] iteration:100  t-loss:0.1742, loss-lb:0.1742, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:26.168] iteration:101  t-loss:0.1714, loss-lb:0.1714, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:26.367] iteration:102  t-loss:0.1578, loss-lb:0.1578, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:26.563] iteration:103  t-loss:0.1307, loss-lb:0.1307, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:26.765] iteration:104  t-loss:0.2658, loss-lb:0.2658, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:26.969] iteration:105  t-loss:0.1637, loss-lb:0.1637, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:27.168] iteration:106  t-loss:0.1719, loss-lb:0.1719, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:27.371] iteration:107  t-loss:0.2201, loss-lb:0.2201, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:27.572] iteration:108  t-loss:0.2402, loss-lb:0.2402, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:27.765] iteration:109  t-loss:0.1400, loss-lb:0.1400, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:27.962] iteration:110  t-loss:0.1639, loss-lb:0.1639, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:28.154] iteration:111  t-loss:0.1625, loss-lb:0.1625, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:28.345] iteration:112  t-loss:0.1789, loss-lb:0.1789, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:28.538] iteration:113  t-loss:0.1699, loss-lb:0.1699, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:28.731] iteration:114  t-loss:0.1614, loss-lb:0.1614, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:29.604] iteration:115  t-loss:0.1959, loss-lb:0.1959, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:29.812] iteration:116  t-loss:0.2198, loss-lb:0.2198, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:30.020] iteration:117  t-loss:0.1330, loss-lb:0.1330, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:30.244] iteration:118  t-loss:0.2253, loss-lb:0.2253, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:30.491] iteration:119  t-loss:0.3226, loss-lb:0.3226, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:30.792] iteration:120  t-loss:0.2565, loss-lb:0.2565, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:31.100] iteration:121  t-loss:0.1768, loss-lb:0.1768, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:31.429] iteration:122  t-loss:0.1753, loss-lb:0.1753, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:31.727] iteration:123  t-loss:0.2067, loss-lb:0.2067, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:32.024] iteration:124  t-loss:0.2166, loss-lb:0.2166, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:32.302] iteration:125  t-loss:0.1650, loss-lb:0.1650, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:32.545] iteration:126  t-loss:0.1742, loss-lb:0.1742, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:32.807] iteration:127  t-loss:0.1636, loss-lb:0.1636, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:33.074] iteration:128  t-loss:0.2303, loss-lb:0.2303, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:33.362] iteration:129  t-loss:0.1758, loss-lb:0.1758, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:33.646] iteration:130  t-loss:0.1672, loss-lb:0.1672, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:33.924] iteration:131  t-loss:0.1776, loss-lb:0.1776, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:34.197] iteration:132  t-loss:0.2172, loss-lb:0.2172, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:34.467] iteration:133  t-loss:0.1775, loss-lb:0.1775, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:34.751] iteration:134  t-loss:0.2639, loss-lb:0.2639, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:35.011] iteration:135  t-loss:0.2230, loss-lb:0.2230, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:35.264] iteration:136  t-loss:0.1503, loss-lb:0.1503, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:35.520] iteration:137  t-loss:0.2141, loss-lb:0.2141, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:35.774] iteration:138  t-loss:0.1565, loss-lb:0.1565, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:36.032] iteration:139  t-loss:0.1374, loss-lb:0.1374, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:36.282] iteration:140  t-loss:0.1711, loss-lb:0.1711, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:36.546] iteration:141  t-loss:0.2303, loss-lb:0.2303, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:36.840] iteration:142  t-loss:0.1424, loss-lb:0.1424, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:37.105] iteration:143  t-loss:0.1566, loss-lb:0.1566, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:37.395] iteration:144  t-loss:0.2095, loss-lb:0.2095, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:37.671] iteration:145  t-loss:0.2166, loss-lb:0.2166, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:37.945] iteration:146  t-loss:0.1298, loss-lb:0.1298, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:38.210] iteration:147  t-loss:0.1136, loss-lb:0.1136, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:38.451] iteration:148  t-loss:0.2014, loss-lb:0.2014, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:38.697] iteration:149  t-loss:0.1837, loss-lb:0.1837, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:38.936] iteration:150  t-loss:0.2097, loss-lb:0.2097, loss-ulb:0.0000, weight:0.01, lr:0.0010
[23:08:39.141] iteration:151  t-loss:0.2311, loss-lb:0.2311, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:39.374] iteration:152  t-loss:0.2634, loss-lb:0.2634, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:40.514] iteration:153  t-loss:0.2081, loss-lb:0.2081, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:40.732] iteration:154  t-loss:0.2365, loss-lb:0.2365, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:40.929] iteration:155  t-loss:0.1387, loss-lb:0.1387, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:41.133] iteration:156  t-loss:0.2070, loss-lb:0.2070, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:41.338] iteration:157  t-loss:0.1625, loss-lb:0.1625, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:41.549] iteration:158  t-loss:0.2031, loss-lb:0.2031, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:41.766] iteration:159  t-loss:0.1494, loss-lb:0.1494, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:41.998] iteration:160  t-loss:0.1839, loss-lb:0.1839, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:42.242] iteration:161  t-loss:0.1252, loss-lb:0.1252, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:42.489] iteration:162  t-loss:0.2425, loss-lb:0.2425, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:42.738] iteration:163  t-loss:0.1348, loss-lb:0.1348, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:43.013] iteration:164  t-loss:0.1402, loss-lb:0.1402, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:43.272] iteration:165  t-loss:0.1325, loss-lb:0.1325, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:43.538] iteration:166  t-loss:0.1865, loss-lb:0.1865, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:43.831] iteration:167  t-loss:0.1790, loss-lb:0.1790, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:44.078] iteration:168  t-loss:0.1594, loss-lb:0.1594, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:44.350] iteration:169  t-loss:0.2251, loss-lb:0.2251, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:44.623] iteration:170  t-loss:0.1659, loss-lb:0.1659, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:44.921] iteration:171  t-loss:0.2036, loss-lb:0.2036, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:45.188] iteration:172  t-loss:0.1078, loss-lb:0.1078, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:45.474] iteration:173  t-loss:0.1972, loss-lb:0.1972, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:45.747] iteration:174  t-loss:0.1303, loss-lb:0.1303, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:46.047] iteration:175  t-loss:0.1843, loss-lb:0.1843, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:46.315] iteration:176  t-loss:0.1486, loss-lb:0.1486, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:46.599] iteration:177  t-loss:0.1790, loss-lb:0.1790, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:46.846] iteration:178  t-loss:0.1282, loss-lb:0.1282, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:47.105] iteration:179  t-loss:0.1730, loss-lb:0.1730, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:47.375] iteration:180  t-loss:0.1341, loss-lb:0.1341, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:47.638] iteration:181  t-loss:0.1780, loss-lb:0.1780, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:47.905] iteration:182  t-loss:0.1722, loss-lb:0.1722, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:48.160] iteration:183  t-loss:0.1491, loss-lb:0.1491, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:48.386] iteration:184  t-loss:0.2074, loss-lb:0.2074, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:48.625] iteration:185  t-loss:0.2027, loss-lb:0.2027, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:48.855] iteration:186  t-loss:0.1227, loss-lb:0.1227, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:49.062] iteration:187  t-loss:0.1761, loss-lb:0.1761, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:49.269] iteration:188  t-loss:0.1209, loss-lb:0.1209, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:49.477] iteration:189  t-loss:0.2258, loss-lb:0.2258, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:08:49.683] iteration:190  t-loss:0.1701, loss-lb:0.1701, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:52.946] iteration 190 : dice_score: 0.627224 best_dice: 0.627200
[23:09:52.947]  <<Test>> - Ep:4  - Dice-S/T:54.87/62.72, Best-S:59.14, Best-T:62.72
[23:09:52.947]           - AvgLoss(lb/ulb/all):0.17/0.00/0.17
[23:09:53.956] iteration:191  t-loss:0.1633, loss-lb:0.1633, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:54.172] iteration:192  t-loss:0.1892, loss-lb:0.1892, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:54.380] iteration:193  t-loss:0.1692, loss-lb:0.1692, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:54.601] iteration:194  t-loss:0.1711, loss-lb:0.1711, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:54.817] iteration:195  t-loss:0.1455, loss-lb:0.1455, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:55.037] iteration:196  t-loss:0.1913, loss-lb:0.1913, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:55.264] iteration:197  t-loss:0.1588, loss-lb:0.1588, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:55.491] iteration:198  t-loss:0.1539, loss-lb:0.1539, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:55.696] iteration:199  t-loss:0.1495, loss-lb:0.1495, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:55.916] iteration:200  t-loss:0.1945, loss-lb:0.1945, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:56.126] iteration:201  t-loss:0.1454, loss-lb:0.1454, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:56.340] iteration:202  t-loss:0.1959, loss-lb:0.1959, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:56.547] iteration:203  t-loss:0.1630, loss-lb:0.1630, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:56.752] iteration:204  t-loss:0.1684, loss-lb:0.1684, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:56.956] iteration:205  t-loss:0.1864, loss-lb:0.1864, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:57.155] iteration:206  t-loss:0.1293, loss-lb:0.1293, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:57.367] iteration:207  t-loss:0.1712, loss-lb:0.1712, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:57.570] iteration:208  t-loss:0.1820, loss-lb:0.1820, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:57.773] iteration:209  t-loss:0.1107, loss-lb:0.1107, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:57.974] iteration:210  t-loss:0.2553, loss-lb:0.2553, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:58.180] iteration:211  t-loss:0.1492, loss-lb:0.1492, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:58.382] iteration:212  t-loss:0.1110, loss-lb:0.1110, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:58.587] iteration:213  t-loss:0.1208, loss-lb:0.1208, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:58.789] iteration:214  t-loss:0.1570, loss-lb:0.1570, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:58.995] iteration:215  t-loss:0.2027, loss-lb:0.2027, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:59.200] iteration:216  t-loss:0.1189, loss-lb:0.1189, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:59.400] iteration:217  t-loss:0.2004, loss-lb:0.2004, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:59.605] iteration:218  t-loss:0.1290, loss-lb:0.1290, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:09:59.804] iteration:219  t-loss:0.1631, loss-lb:0.1631, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:00.009] iteration:220  t-loss:0.2191, loss-lb:0.2191, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:00.213] iteration:221  t-loss:0.1880, loss-lb:0.1880, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:00.412] iteration:222  t-loss:0.1407, loss-lb:0.1407, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:00.607] iteration:223  t-loss:0.1715, loss-lb:0.1715, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:00.803] iteration:224  t-loss:0.1372, loss-lb:0.1372, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:00.996] iteration:225  t-loss:0.1465, loss-lb:0.1465, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:01.193] iteration:226  t-loss:0.1963, loss-lb:0.1963, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:01.388] iteration:227  t-loss:0.1770, loss-lb:0.1770, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:01.580] iteration:228  t-loss:0.1116, loss-lb:0.1116, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:02.492] iteration:229  t-loss:0.1429, loss-lb:0.1429, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:02.693] iteration:230  t-loss:0.1092, loss-lb:0.1092, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:02.896] iteration:231  t-loss:0.1360, loss-lb:0.1360, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:03.102] iteration:232  t-loss:0.1613, loss-lb:0.1613, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:03.303] iteration:233  t-loss:0.1225, loss-lb:0.1225, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:03.508] iteration:234  t-loss:0.1269, loss-lb:0.1269, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:03.725] iteration:235  t-loss:0.1721, loss-lb:0.1721, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:03.947] iteration:236  t-loss:0.1117, loss-lb:0.1117, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:04.167] iteration:237  t-loss:0.1256, loss-lb:0.1256, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:04.382] iteration:238  t-loss:0.1554, loss-lb:0.1554, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:04.593] iteration:239  t-loss:0.1971, loss-lb:0.1971, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:04.795] iteration:240  t-loss:0.1313, loss-lb:0.1313, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:04.999] iteration:241  t-loss:0.1455, loss-lb:0.1455, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:05.200] iteration:242  t-loss:0.1309, loss-lb:0.1309, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:05.407] iteration:243  t-loss:0.1609, loss-lb:0.1609, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:05.615] iteration:244  t-loss:0.2211, loss-lb:0.2211, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:05.816] iteration:245  t-loss:0.1368, loss-lb:0.1368, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:06.016] iteration:246  t-loss:0.2017, loss-lb:0.2017, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:06.220] iteration:247  t-loss:0.0982, loss-lb:0.0982, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:06.425] iteration:248  t-loss:0.1793, loss-lb:0.1793, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:06.628] iteration:249  t-loss:0.0878, loss-lb:0.0878, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:06.829] iteration:250  t-loss:0.1099, loss-lb:0.1099, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:07.035] iteration:251  t-loss:0.1482, loss-lb:0.1482, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:07.236] iteration:252  t-loss:0.1747, loss-lb:0.1747, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:07.439] iteration:253  t-loss:0.1839, loss-lb:0.1839, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:07.638] iteration:254  t-loss:0.1109, loss-lb:0.1109, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:07.840] iteration:255  t-loss:0.1093, loss-lb:0.1093, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:08.041] iteration:256  t-loss:0.1436, loss-lb:0.1436, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:08.245] iteration:257  t-loss:0.0986, loss-lb:0.0986, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:08.450] iteration:258  t-loss:0.1676, loss-lb:0.1676, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:08.653] iteration:259  t-loss:0.1830, loss-lb:0.1830, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:08.856] iteration:260  t-loss:0.1148, loss-lb:0.1148, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:09.057] iteration:261  t-loss:0.1575, loss-lb:0.1575, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:09.256] iteration:262  t-loss:0.1600, loss-lb:0.1600, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:09.455] iteration:263  t-loss:0.2023, loss-lb:0.2023, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:09.656] iteration:264  t-loss:0.1085, loss-lb:0.1085, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:09.853] iteration:265  t-loss:0.1694, loss-lb:0.1694, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:10.049] iteration:266  t-loss:0.1163, loss-lb:0.1163, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:11.056] iteration:267  t-loss:0.1377, loss-lb:0.1377, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:11.266] iteration:268  t-loss:0.1274, loss-lb:0.1274, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:11.463] iteration:269  t-loss:0.1304, loss-lb:0.1304, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:11.671] iteration:270  t-loss:0.1274, loss-lb:0.1274, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:11.884] iteration:271  t-loss:0.1028, loss-lb:0.1028, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:12.089] iteration:272  t-loss:0.1410, loss-lb:0.1410, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:12.327] iteration:273  t-loss:0.0967, loss-lb:0.0967, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:12.559] iteration:274  t-loss:0.1294, loss-lb:0.1294, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:12.779] iteration:275  t-loss:0.1240, loss-lb:0.1240, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:13.028] iteration:276  t-loss:0.1074, loss-lb:0.1074, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:13.251] iteration:277  t-loss:0.0835, loss-lb:0.0835, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:13.493] iteration:278  t-loss:0.0932, loss-lb:0.0932, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:13.700] iteration:279  t-loss:0.0966, loss-lb:0.0966, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:13.936] iteration:280  t-loss:0.1244, loss-lb:0.1244, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:14.168] iteration:281  t-loss:0.1629, loss-lb:0.1629, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:14.375] iteration:282  t-loss:0.0809, loss-lb:0.0809, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:14.591] iteration:283  t-loss:0.1644, loss-lb:0.1644, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:14.792] iteration:284  t-loss:0.0732, loss-lb:0.0732, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:15.000] iteration:285  t-loss:0.1041, loss-lb:0.1041, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:15.216] iteration:286  t-loss:0.1525, loss-lb:0.1525, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:15.422] iteration:287  t-loss:0.1068, loss-lb:0.1068, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:15.629] iteration:288  t-loss:0.1397, loss-lb:0.1397, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:15.834] iteration:289  t-loss:0.2237, loss-lb:0.2237, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:16.045] iteration:290  t-loss:0.1398, loss-lb:0.1398, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:16.245] iteration:291  t-loss:0.1096, loss-lb:0.1096, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:16.444] iteration:292  t-loss:0.1004, loss-lb:0.1004, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:16.648] iteration:293  t-loss:0.1308, loss-lb:0.1308, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:16.850] iteration:294  t-loss:0.2290, loss-lb:0.2290, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:17.051] iteration:295  t-loss:0.0803, loss-lb:0.0803, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:17.254] iteration:296  t-loss:0.1325, loss-lb:0.1325, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:17.461] iteration:297  t-loss:0.0961, loss-lb:0.0961, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:17.660] iteration:298  t-loss:0.0818, loss-lb:0.0818, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:17.855] iteration:299  t-loss:0.2654, loss-lb:0.2654, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:18.049] iteration:300  t-loss:0.0924, loss-lb:0.0924, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:18.243] iteration:301  t-loss:0.0661, loss-lb:0.0661, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:18.442] iteration:302  t-loss:0.2126, loss-lb:0.2126, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:18.636] iteration:303  t-loss:0.1744, loss-lb:0.1744, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:18.834] iteration:304  t-loss:0.1894, loss-lb:0.1894, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:19.759] iteration:305  t-loss:0.1775, loss-lb:0.1775, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:19.967] iteration:306  t-loss:0.1335, loss-lb:0.1335, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:20.167] iteration:307  t-loss:0.1078, loss-lb:0.1078, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:20.373] iteration:308  t-loss:0.1146, loss-lb:0.1146, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:20.576] iteration:309  t-loss:0.2045, loss-lb:0.2045, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:20.787] iteration:310  t-loss:0.0949, loss-lb:0.0949, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:21.011] iteration:311  t-loss:0.1044, loss-lb:0.1044, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:21.227] iteration:312  t-loss:0.1070, loss-lb:0.1070, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:21.436] iteration:313  t-loss:0.0947, loss-lb:0.0947, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:21.648] iteration:314  t-loss:0.1313, loss-lb:0.1313, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:21.864] iteration:315  t-loss:0.1226, loss-lb:0.1226, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:22.077] iteration:316  t-loss:0.2021, loss-lb:0.2021, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:22.286] iteration:317  t-loss:0.0798, loss-lb:0.0798, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:22.492] iteration:318  t-loss:0.1357, loss-lb:0.1357, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:22.694] iteration:319  t-loss:0.1022, loss-lb:0.1022, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:22.899] iteration:320  t-loss:0.1478, loss-lb:0.1478, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:23.105] iteration:321  t-loss:0.0925, loss-lb:0.0925, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:23.307] iteration:322  t-loss:0.0990, loss-lb:0.0990, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:23.511] iteration:323  t-loss:0.0815, loss-lb:0.0815, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:23.710] iteration:324  t-loss:0.1098, loss-lb:0.1098, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:23.913] iteration:325  t-loss:0.2104, loss-lb:0.2104, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:24.117] iteration:326  t-loss:0.0593, loss-lb:0.0593, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:24.328] iteration:327  t-loss:0.1594, loss-lb:0.1594, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:24.524] iteration:328  t-loss:0.0927, loss-lb:0.0927, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:24.730] iteration:329  t-loss:0.0860, loss-lb:0.0860, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:24.935] iteration:330  t-loss:0.0888, loss-lb:0.0888, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:25.130] iteration:331  t-loss:0.1230, loss-lb:0.1230, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:25.348] iteration:332  t-loss:0.0699, loss-lb:0.0699, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:25.576] iteration:333  t-loss:0.1398, loss-lb:0.1398, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:25.831] iteration:334  t-loss:0.1596, loss-lb:0.1596, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:26.087] iteration:335  t-loss:0.1310, loss-lb:0.1310, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:26.324] iteration:336  t-loss:0.1213, loss-lb:0.1213, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:26.545] iteration:337  t-loss:0.0725, loss-lb:0.0725, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:26.761] iteration:338  t-loss:0.1379, loss-lb:0.1379, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:26.972] iteration:339  t-loss:0.1569, loss-lb:0.1569, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:27.188] iteration:340  t-loss:0.0971, loss-lb:0.0971, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:27.384] iteration:341  t-loss:0.1021, loss-lb:0.1021, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:10:27.578] iteration:342  t-loss:0.0694, loss-lb:0.0694, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:31.892] iteration 342 : dice_score: 0.651129 best_dice: 0.651100
[23:11:31.892]  <<Test>> - Ep:8  - Dice-S/T:45.91/65.11, Best-S:59.14, Best-T:65.11
[23:11:31.893]           - AvgLoss(lb/ulb/all):0.12/0.00/0.11
[23:11:32.882] iteration:343  t-loss:0.1021, loss-lb:0.1021, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:33.092] iteration:344  t-loss:0.1051, loss-lb:0.1051, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:33.296] iteration:345  t-loss:0.1647, loss-lb:0.1647, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:33.506] iteration:346  t-loss:0.1117, loss-lb:0.1117, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:33.723] iteration:347  t-loss:0.1251, loss-lb:0.1251, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:33.940] iteration:348  t-loss:0.1099, loss-lb:0.1099, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:34.159] iteration:349  t-loss:0.1737, loss-lb:0.1737, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:34.375] iteration:350  t-loss:0.1141, loss-lb:0.1141, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:34.580] iteration:351  t-loss:0.1136, loss-lb:0.1136, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:34.784] iteration:352  t-loss:0.1180, loss-lb:0.1180, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:34.989] iteration:353  t-loss:0.0869, loss-lb:0.0869, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:35.198] iteration:354  t-loss:0.1221, loss-lb:0.1221, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:35.400] iteration:355  t-loss:0.1571, loss-lb:0.1571, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:35.597] iteration:356  t-loss:0.0788, loss-lb:0.0788, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:35.802] iteration:357  t-loss:0.0825, loss-lb:0.0825, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:36.013] iteration:358  t-loss:0.2388, loss-lb:0.2388, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:36.220] iteration:359  t-loss:0.1844, loss-lb:0.1844, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:36.419] iteration:360  t-loss:0.1274, loss-lb:0.1274, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:36.619] iteration:361  t-loss:0.1416, loss-lb:0.1416, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:36.823] iteration:362  t-loss:0.1501, loss-lb:0.1501, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:37.025] iteration:363  t-loss:0.1279, loss-lb:0.1279, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:37.228] iteration:364  t-loss:0.1209, loss-lb:0.1209, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:37.441] iteration:365  t-loss:0.1531, loss-lb:0.1531, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:37.650] iteration:366  t-loss:0.1339, loss-lb:0.1339, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:37.849] iteration:367  t-loss:0.1492, loss-lb:0.1492, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:38.056] iteration:368  t-loss:0.1050, loss-lb:0.1050, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:38.265] iteration:369  t-loss:0.0906, loss-lb:0.0906, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:38.468] iteration:370  t-loss:0.1352, loss-lb:0.1352, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:38.672] iteration:371  t-loss:0.1463, loss-lb:0.1463, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:38.875] iteration:372  t-loss:0.1559, loss-lb:0.1559, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:39.069] iteration:373  t-loss:0.0861, loss-lb:0.0861, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:39.262] iteration:374  t-loss:0.0760, loss-lb:0.0760, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:39.461] iteration:375  t-loss:0.1294, loss-lb:0.1294, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:39.656] iteration:376  t-loss:0.1211, loss-lb:0.1211, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:39.852] iteration:377  t-loss:0.0978, loss-lb:0.0978, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:40.048] iteration:378  t-loss:0.2383, loss-lb:0.2383, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:40.241] iteration:379  t-loss:0.1242, loss-lb:0.1242, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:40.434] iteration:380  t-loss:0.1589, loss-lb:0.1589, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:41.383] iteration:381  t-loss:0.0705, loss-lb:0.0705, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:41.581] iteration:382  t-loss:0.1430, loss-lb:0.1430, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:41.778] iteration:383  t-loss:0.1913, loss-lb:0.1913, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:41.983] iteration:384  t-loss:0.1374, loss-lb:0.1374, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:42.191] iteration:385  t-loss:0.1669, loss-lb:0.1669, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:42.406] iteration:386  t-loss:0.1000, loss-lb:0.1000, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:42.616] iteration:387  t-loss:0.1052, loss-lb:0.1052, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:42.833] iteration:388  t-loss:0.0782, loss-lb:0.0782, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:43.043] iteration:389  t-loss:0.0743, loss-lb:0.0743, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:43.254] iteration:390  t-loss:0.0911, loss-lb:0.0911, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:43.458] iteration:391  t-loss:0.1244, loss-lb:0.1244, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:43.669] iteration:392  t-loss:0.1425, loss-lb:0.1425, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:43.878] iteration:393  t-loss:0.1495, loss-lb:0.1495, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:44.090] iteration:394  t-loss:0.1362, loss-lb:0.1362, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:44.296] iteration:395  t-loss:0.1531, loss-lb:0.1531, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:44.501] iteration:396  t-loss:0.1854, loss-lb:0.1854, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:44.722] iteration:397  t-loss:0.1270, loss-lb:0.1270, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:44.930] iteration:398  t-loss:0.1278, loss-lb:0.1278, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:45.130] iteration:399  t-loss:0.1272, loss-lb:0.1272, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:45.338] iteration:400  t-loss:0.1381, loss-lb:0.1381, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:45.547] iteration:401  t-loss:0.1261, loss-lb:0.1261, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:45.761] iteration:402  t-loss:0.1237, loss-lb:0.1237, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:45.969] iteration:403  t-loss:0.1735, loss-lb:0.1735, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:46.175] iteration:404  t-loss:0.1540, loss-lb:0.1540, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:46.379] iteration:405  t-loss:0.1292, loss-lb:0.1292, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:46.591] iteration:406  t-loss:0.1304, loss-lb:0.1304, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:46.789] iteration:407  t-loss:0.0730, loss-lb:0.0730, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:46.989] iteration:408  t-loss:0.1533, loss-lb:0.1533, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:47.194] iteration:409  t-loss:0.1293, loss-lb:0.1293, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:47.399] iteration:410  t-loss:0.0938, loss-lb:0.0938, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:47.601] iteration:411  t-loss:0.1036, loss-lb:0.1036, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:47.802] iteration:412  t-loss:0.1436, loss-lb:0.1436, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:48.000] iteration:413  t-loss:0.1708, loss-lb:0.1708, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:48.197] iteration:414  t-loss:0.1334, loss-lb:0.1334, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:48.390] iteration:415  t-loss:0.1216, loss-lb:0.1216, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:48.586] iteration:416  t-loss:0.1223, loss-lb:0.1223, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:48.776] iteration:417  t-loss:0.1059, loss-lb:0.1059, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:48.967] iteration:418  t-loss:0.1379, loss-lb:0.1379, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:49.933] iteration:419  t-loss:0.0835, loss-lb:0.0835, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:50.135] iteration:420  t-loss:0.0923, loss-lb:0.0923, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:50.333] iteration:421  t-loss:0.1580, loss-lb:0.1580, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:50.543] iteration:422  t-loss:0.0861, loss-lb:0.0861, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:50.747] iteration:423  t-loss:0.2225, loss-lb:0.2225, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:50.962] iteration:424  t-loss:0.1270, loss-lb:0.1270, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:51.182] iteration:425  t-loss:0.0625, loss-lb:0.0625, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:51.387] iteration:426  t-loss:0.1156, loss-lb:0.1156, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:51.597] iteration:427  t-loss:0.1120, loss-lb:0.1120, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:51.806] iteration:428  t-loss:0.0853, loss-lb:0.0853, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:52.008] iteration:429  t-loss:0.1298, loss-lb:0.1298, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:52.212] iteration:430  t-loss:0.0597, loss-lb:0.0597, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:52.414] iteration:431  t-loss:0.0790, loss-lb:0.0790, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:52.618] iteration:432  t-loss:0.1220, loss-lb:0.1220, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:52.821] iteration:433  t-loss:0.0740, loss-lb:0.0740, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:53.022] iteration:434  t-loss:0.0774, loss-lb:0.0774, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:53.220] iteration:435  t-loss:0.0968, loss-lb:0.0968, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:53.419] iteration:436  t-loss:0.1109, loss-lb:0.1109, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:53.628] iteration:437  t-loss:0.1784, loss-lb:0.1784, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:53.830] iteration:438  t-loss:0.0878, loss-lb:0.0878, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:54.034] iteration:439  t-loss:0.0747, loss-lb:0.0747, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:54.240] iteration:440  t-loss:0.0954, loss-lb:0.0954, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:54.440] iteration:441  t-loss:0.1272, loss-lb:0.1272, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:54.642] iteration:442  t-loss:0.0700, loss-lb:0.0700, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:54.844] iteration:443  t-loss:0.1102, loss-lb:0.1102, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:55.053] iteration:444  t-loss:0.0632, loss-lb:0.0632, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:55.257] iteration:445  t-loss:0.0713, loss-lb:0.0713, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:55.455] iteration:446  t-loss:0.1420, loss-lb:0.1420, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:55.655] iteration:447  t-loss:0.0777, loss-lb:0.0777, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:55.854] iteration:448  t-loss:0.1142, loss-lb:0.1142, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:56.054] iteration:449  t-loss:0.0702, loss-lb:0.0702, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:56.250] iteration:450  t-loss:0.1266, loss-lb:0.1266, loss-ulb:0.0000, weight:0.02, lr:0.0010
[23:11:56.447] iteration:451  t-loss:0.0680, loss-lb:0.0680, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:56.644] iteration:452  t-loss:0.1545, loss-lb:0.1545, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:56.837] iteration:453  t-loss:0.0622, loss-lb:0.0622, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:57.030] iteration:454  t-loss:0.0730, loss-lb:0.0730, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:57.226] iteration:455  t-loss:0.2467, loss-lb:0.2467, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:57.417] iteration:456  t-loss:0.0702, loss-lb:0.0702, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:58.345] iteration:457  t-loss:0.1637, loss-lb:0.1637, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:58.554] iteration:458  t-loss:0.0595, loss-lb:0.0595, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:58.753] iteration:459  t-loss:0.0741, loss-lb:0.0741, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:58.963] iteration:460  t-loss:0.1282, loss-lb:0.1282, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:59.175] iteration:461  t-loss:0.1276, loss-lb:0.1276, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:59.376] iteration:462  t-loss:0.0801, loss-lb:0.0801, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:59.598] iteration:463  t-loss:0.0939, loss-lb:0.0939, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:11:59.825] iteration:464  t-loss:0.0558, loss-lb:0.0558, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:00.039] iteration:465  t-loss:0.1088, loss-lb:0.1088, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:00.276] iteration:466  t-loss:0.0905, loss-lb:0.0905, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:00.497] iteration:467  t-loss:0.0884, loss-lb:0.0884, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:00.722] iteration:468  t-loss:0.1079, loss-lb:0.1079, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:00.952] iteration:469  t-loss:0.1283, loss-lb:0.1283, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:01.166] iteration:470  t-loss:0.1240, loss-lb:0.1240, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:01.386] iteration:471  t-loss:0.1630, loss-lb:0.1630, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:01.599] iteration:472  t-loss:0.0811, loss-lb:0.0811, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:01.810] iteration:473  t-loss:0.2248, loss-lb:0.2248, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:02.022] iteration:474  t-loss:0.0844, loss-lb:0.0844, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:02.222] iteration:475  t-loss:0.0972, loss-lb:0.0972, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:02.432] iteration:476  t-loss:0.0665, loss-lb:0.0665, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:02.639] iteration:477  t-loss:0.1731, loss-lb:0.1731, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:02.845] iteration:478  t-loss:0.0851, loss-lb:0.0851, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:03.058] iteration:479  t-loss:0.0672, loss-lb:0.0672, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:03.267] iteration:480  t-loss:0.1651, loss-lb:0.1651, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:03.472] iteration:481  t-loss:0.0772, loss-lb:0.0772, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:03.682] iteration:482  t-loss:0.1178, loss-lb:0.1178, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:03.888] iteration:483  t-loss:0.2101, loss-lb:0.2101, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:04.086] iteration:484  t-loss:0.0592, loss-lb:0.0592, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:04.292] iteration:485  t-loss:0.1834, loss-lb:0.1834, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:04.494] iteration:486  t-loss:0.0563, loss-lb:0.0563, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:04.701] iteration:487  t-loss:0.1601, loss-lb:0.1601, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:04.900] iteration:488  t-loss:0.0984, loss-lb:0.0984, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:05.098] iteration:489  t-loss:0.1225, loss-lb:0.1225, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:05.294] iteration:490  t-loss:0.0877, loss-lb:0.0877, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:05.497] iteration:491  t-loss:0.1771, loss-lb:0.1771, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:05.692] iteration:492  t-loss:0.2143, loss-lb:0.2143, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:05.892] iteration:493  t-loss:0.1183, loss-lb:0.1183, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:12:06.086] iteration:494  t-loss:0.0772, loss-lb:0.0772, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:12.044] iteration 494 : dice_score: 0.705141 best_dice: 0.705100
[23:13:12.045]  <<Test>> - Ep:12  - Dice-S/T:61.59/70.51, Best-S:61.59, Best-T:70.51
[23:13:12.045]           - AvgLoss(lb/ulb/all):0.12/0.00/0.12
[23:13:12.884] iteration:495  t-loss:0.0806, loss-lb:0.0806, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:13.101] iteration:496  t-loss:0.1126, loss-lb:0.1126, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:13.320] iteration:497  t-loss:0.0789, loss-lb:0.0789, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:13.527] iteration:498  t-loss:0.0833, loss-lb:0.0833, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:13.748] iteration:499  t-loss:0.1571, loss-lb:0.1571, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:13.965] iteration:500  t-loss:0.0967, loss-lb:0.0967, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:14.191] iteration:501  t-loss:0.0871, loss-lb:0.0871, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:14.407] iteration:502  t-loss:0.1199, loss-lb:0.1199, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:14.612] iteration:503  t-loss:0.0677, loss-lb:0.0677, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:14.827] iteration:504  t-loss:0.0818, loss-lb:0.0818, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:15.038] iteration:505  t-loss:0.0840, loss-lb:0.0840, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:15.248] iteration:506  t-loss:0.0650, loss-lb:0.0650, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:15.449] iteration:507  t-loss:0.1610, loss-lb:0.1610, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:15.657] iteration:508  t-loss:0.1491, loss-lb:0.1491, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:15.857] iteration:509  t-loss:0.0803, loss-lb:0.0803, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:16.054] iteration:510  t-loss:0.0678, loss-lb:0.0678, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:16.253] iteration:511  t-loss:0.0636, loss-lb:0.0636, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:16.463] iteration:512  t-loss:0.1515, loss-lb:0.1515, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:16.663] iteration:513  t-loss:0.1217, loss-lb:0.1217, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:16.866] iteration:514  t-loss:0.1117, loss-lb:0.1117, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:17.065] iteration:515  t-loss:0.1043, loss-lb:0.1043, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:17.264] iteration:516  t-loss:0.0828, loss-lb:0.0828, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:17.467] iteration:517  t-loss:0.1470, loss-lb:0.1470, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:17.669] iteration:518  t-loss:0.0930, loss-lb:0.0930, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:17.869] iteration:519  t-loss:0.1323, loss-lb:0.1323, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:18.080] iteration:520  t-loss:0.1349, loss-lb:0.1349, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:18.282] iteration:521  t-loss:0.0860, loss-lb:0.0860, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:18.486] iteration:522  t-loss:0.1365, loss-lb:0.1365, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:18.680] iteration:523  t-loss:0.0745, loss-lb:0.0745, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:18.886] iteration:524  t-loss:0.1155, loss-lb:0.1155, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:19.090] iteration:525  t-loss:0.1259, loss-lb:0.1259, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:19.289] iteration:526  t-loss:0.1010, loss-lb:0.1010, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:19.485] iteration:527  t-loss:0.0757, loss-lb:0.0757, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:19.682] iteration:528  t-loss:0.1013, loss-lb:0.1013, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:19.878] iteration:529  t-loss:0.0764, loss-lb:0.0764, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:20.075] iteration:530  t-loss:0.1140, loss-lb:0.1140, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:20.267] iteration:531  t-loss:0.0686, loss-lb:0.0686, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:20.462] iteration:532  t-loss:0.0939, loss-lb:0.0939, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:21.266] iteration:533  t-loss:0.0652, loss-lb:0.0652, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:21.469] iteration:534  t-loss:0.1622, loss-lb:0.1622, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:21.676] iteration:535  t-loss:0.1208, loss-lb:0.1208, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:21.885] iteration:536  t-loss:0.0776, loss-lb:0.0776, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:22.082] iteration:537  t-loss:0.0743, loss-lb:0.0743, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:22.292] iteration:538  t-loss:0.1952, loss-lb:0.1952, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:22.512] iteration:539  t-loss:0.1209, loss-lb:0.1209, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:22.725] iteration:540  t-loss:0.0609, loss-lb:0.0609, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:22.952] iteration:541  t-loss:0.0948, loss-lb:0.0948, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:23.167] iteration:542  t-loss:0.1096, loss-lb:0.1096, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:23.379] iteration:543  t-loss:0.1239, loss-lb:0.1239, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:23.587] iteration:544  t-loss:0.0981, loss-lb:0.0981, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:23.785] iteration:545  t-loss:0.1210, loss-lb:0.1210, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:23.989] iteration:546  t-loss:0.0873, loss-lb:0.0873, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:24.186] iteration:547  t-loss:0.0757, loss-lb:0.0757, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:24.397] iteration:548  t-loss:0.1086, loss-lb:0.1086, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:24.597] iteration:549  t-loss:0.0675, loss-lb:0.0675, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:24.793] iteration:550  t-loss:0.0844, loss-lb:0.0844, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:24.995] iteration:551  t-loss:0.0753, loss-lb:0.0753, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:25.205] iteration:552  t-loss:0.0737, loss-lb:0.0737, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:25.412] iteration:553  t-loss:0.1017, loss-lb:0.1017, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:25.606] iteration:554  t-loss:0.0794, loss-lb:0.0794, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:25.803] iteration:555  t-loss:0.0797, loss-lb:0.0797, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:26.006] iteration:556  t-loss:0.0945, loss-lb:0.0945, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:26.204] iteration:557  t-loss:0.1197, loss-lb:0.1197, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:26.406] iteration:558  t-loss:0.0597, loss-lb:0.0597, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:26.605] iteration:559  t-loss:0.0777, loss-lb:0.0777, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:26.807] iteration:560  t-loss:0.1549, loss-lb:0.1549, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:27.003] iteration:561  t-loss:0.0751, loss-lb:0.0751, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:27.204] iteration:562  t-loss:0.1946, loss-lb:0.1946, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:27.406] iteration:563  t-loss:0.1050, loss-lb:0.1050, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:27.601] iteration:564  t-loss:0.0946, loss-lb:0.0946, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:27.794] iteration:565  t-loss:0.0886, loss-lb:0.0886, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:27.986] iteration:566  t-loss:0.0655, loss-lb:0.0655, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:28.186] iteration:567  t-loss:0.1288, loss-lb:0.1288, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:28.381] iteration:568  t-loss:0.0922, loss-lb:0.0922, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:28.576] iteration:569  t-loss:0.0926, loss-lb:0.0926, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:28.770] iteration:570  t-loss:0.0916, loss-lb:0.0916, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:29.720] iteration:571  t-loss:0.0769, loss-lb:0.0769, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:29.924] iteration:572  t-loss:0.1482, loss-lb:0.1482, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:30.132] iteration:573  t-loss:0.0789, loss-lb:0.0789, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:30.334] iteration:574  t-loss:0.0624, loss-lb:0.0624, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:30.544] iteration:575  t-loss:0.0721, loss-lb:0.0721, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:30.755] iteration:576  t-loss:0.0906, loss-lb:0.0906, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:30.968] iteration:577  t-loss:0.0687, loss-lb:0.0687, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:31.193] iteration:578  t-loss:0.1601, loss-lb:0.1601, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:31.405] iteration:579  t-loss:0.0712, loss-lb:0.0712, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:31.611] iteration:580  t-loss:0.0804, loss-lb:0.0804, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:31.821] iteration:581  t-loss:0.0567, loss-lb:0.0567, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:32.026] iteration:582  t-loss:0.0859, loss-lb:0.0859, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:32.228] iteration:583  t-loss:0.0615, loss-lb:0.0615, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:32.429] iteration:584  t-loss:0.0681, loss-lb:0.0681, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:32.647] iteration:585  t-loss:0.1252, loss-lb:0.1252, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:32.850] iteration:586  t-loss:0.1241, loss-lb:0.1241, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:33.058] iteration:587  t-loss:0.1472, loss-lb:0.1472, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:33.257] iteration:588  t-loss:0.0813, loss-lb:0.0813, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:33.456] iteration:589  t-loss:0.0619, loss-lb:0.0619, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:33.666] iteration:590  t-loss:0.1059, loss-lb:0.1059, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:33.878] iteration:591  t-loss:0.0850, loss-lb:0.0850, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:34.084] iteration:592  t-loss:0.0799, loss-lb:0.0799, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:34.293] iteration:593  t-loss:0.1418, loss-lb:0.1418, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:34.495] iteration:594  t-loss:0.0871, loss-lb:0.0871, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:34.696] iteration:595  t-loss:0.0617, loss-lb:0.0617, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:34.901] iteration:596  t-loss:0.1645, loss-lb:0.1645, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:35.107] iteration:597  t-loss:0.1107, loss-lb:0.1107, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:35.311] iteration:598  t-loss:0.0695, loss-lb:0.0695, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:35.511] iteration:599  t-loss:0.0910, loss-lb:0.0910, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:35.724] iteration:600  t-loss:0.1486, loss-lb:0.1486, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:35.919] iteration:601  t-loss:0.0856, loss-lb:0.0856, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:36.116] iteration:602  t-loss:0.0769, loss-lb:0.0769, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:36.313] iteration:603  t-loss:0.0910, loss-lb:0.0910, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:36.508] iteration:604  t-loss:0.1080, loss-lb:0.1080, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:36.705] iteration:605  t-loss:0.0514, loss-lb:0.0514, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:36.901] iteration:606  t-loss:0.1975, loss-lb:0.1975, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:37.096] iteration:607  t-loss:0.1301, loss-lb:0.1301, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:37.292] iteration:608  t-loss:0.0721, loss-lb:0.0721, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:38.105] iteration:609  t-loss:0.1022, loss-lb:0.1022, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:38.306] iteration:610  t-loss:0.0600, loss-lb:0.0600, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:38.505] iteration:611  t-loss:0.0589, loss-lb:0.0589, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:38.705] iteration:612  t-loss:0.0997, loss-lb:0.0997, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:38.903] iteration:613  t-loss:0.0779, loss-lb:0.0779, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:39.103] iteration:614  t-loss:0.0747, loss-lb:0.0747, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:39.300] iteration:615  t-loss:0.0652, loss-lb:0.0652, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:39.498] iteration:616  t-loss:0.1064, loss-lb:0.1064, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:39.700] iteration:617  t-loss:0.0449, loss-lb:0.0449, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:39.898] iteration:618  t-loss:0.0687, loss-lb:0.0687, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:40.096] iteration:619  t-loss:0.0800, loss-lb:0.0800, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:40.297] iteration:620  t-loss:0.0821, loss-lb:0.0821, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:40.499] iteration:621  t-loss:0.1083, loss-lb:0.1083, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:40.701] iteration:622  t-loss:0.1413, loss-lb:0.1413, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:40.900] iteration:623  t-loss:0.0519, loss-lb:0.0519, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:41.101] iteration:624  t-loss:0.1270, loss-lb:0.1270, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:41.304] iteration:625  t-loss:0.0591, loss-lb:0.0591, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:41.505] iteration:626  t-loss:0.0985, loss-lb:0.0985, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:41.704] iteration:627  t-loss:0.1627, loss-lb:0.1627, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:41.904] iteration:628  t-loss:0.0810, loss-lb:0.0810, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:42.109] iteration:629  t-loss:0.0722, loss-lb:0.0722, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:42.304] iteration:630  t-loss:0.0727, loss-lb:0.0727, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:42.503] iteration:631  t-loss:0.0583, loss-lb:0.0583, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:42.703] iteration:632  t-loss:0.0537, loss-lb:0.0537, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:42.912] iteration:633  t-loss:0.0845, loss-lb:0.0845, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:43.108] iteration:634  t-loss:0.0668, loss-lb:0.0668, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:43.305] iteration:635  t-loss:0.0690, loss-lb:0.0690, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:43.506] iteration:636  t-loss:0.0874, loss-lb:0.0874, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:43.718] iteration:637  t-loss:0.0548, loss-lb:0.0548, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:43.922] iteration:638  t-loss:0.0684, loss-lb:0.0684, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:44.123] iteration:639  t-loss:0.0910, loss-lb:0.0910, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:44.324] iteration:640  t-loss:0.0713, loss-lb:0.0713, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:44.524] iteration:641  t-loss:0.0651, loss-lb:0.0651, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:44.719] iteration:642  t-loss:0.0535, loss-lb:0.0535, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:44.916] iteration:643  t-loss:0.0617, loss-lb:0.0617, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:45.118] iteration:644  t-loss:0.1245, loss-lb:0.1245, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:45.320] iteration:645  t-loss:0.0834, loss-lb:0.0834, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:13:45.515] iteration:646  t-loss:0.1336, loss-lb:0.1336, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:54.322] iteration 646 : dice_score: 0.719743 best_dice: 0.719700
[23:14:54.323]  <<Test>> - Ep:16  - Dice-S/T:58.46/71.97, Best-S:61.59, Best-T:71.97
[23:14:54.323]           - AvgLoss(lb/ulb/all):0.08/0.00/0.08
[23:14:55.328] iteration:647  t-loss:0.1478, loss-lb:0.1478, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:55.539] iteration:648  t-loss:0.0531, loss-lb:0.0531, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:55.742] iteration:649  t-loss:0.1684, loss-lb:0.1684, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:55.948] iteration:650  t-loss:0.0756, loss-lb:0.0756, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:56.151] iteration:651  t-loss:0.0767, loss-lb:0.0767, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:56.352] iteration:652  t-loss:0.1008, loss-lb:0.1008, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:56.550] iteration:653  t-loss:0.0910, loss-lb:0.0910, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:56.750] iteration:654  t-loss:0.0861, loss-lb:0.0861, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:56.947] iteration:655  t-loss:0.0627, loss-lb:0.0627, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:57.147] iteration:656  t-loss:0.0463, loss-lb:0.0463, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:57.344] iteration:657  t-loss:0.0836, loss-lb:0.0836, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:57.558] iteration:658  t-loss:0.1063, loss-lb:0.1063, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:57.771] iteration:659  t-loss:0.1198, loss-lb:0.1198, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:57.992] iteration:660  t-loss:0.0937, loss-lb:0.0937, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:58.217] iteration:661  t-loss:0.0866, loss-lb:0.0866, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:58.432] iteration:662  t-loss:0.0873, loss-lb:0.0873, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:58.670] iteration:663  t-loss:0.0872, loss-lb:0.0872, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:58.906] iteration:664  t-loss:0.1821, loss-lb:0.1821, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:59.139] iteration:665  t-loss:0.2093, loss-lb:0.2093, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:59.345] iteration:666  t-loss:0.0544, loss-lb:0.0544, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:59.571] iteration:667  t-loss:0.1385, loss-lb:0.1385, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:14:59.786] iteration:668  t-loss:0.0741, loss-lb:0.0741, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:00.006] iteration:669  t-loss:0.1109, loss-lb:0.1109, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:00.215] iteration:670  t-loss:0.0984, loss-lb:0.0984, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:00.437] iteration:671  t-loss:0.1006, loss-lb:0.1006, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:00.647] iteration:672  t-loss:0.0997, loss-lb:0.0997, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:00.861] iteration:673  t-loss:0.1173, loss-lb:0.1173, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:01.078] iteration:674  t-loss:0.1181, loss-lb:0.1181, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:01.287] iteration:675  t-loss:0.0906, loss-lb:0.0906, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:01.492] iteration:676  t-loss:0.1305, loss-lb:0.1305, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:01.697] iteration:677  t-loss:0.1247, loss-lb:0.1247, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:01.898] iteration:678  t-loss:0.0502, loss-lb:0.0502, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:02.090] iteration:679  t-loss:0.0679, loss-lb:0.0679, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:02.287] iteration:680  t-loss:0.0673, loss-lb:0.0673, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:02.486] iteration:681  t-loss:0.0595, loss-lb:0.0595, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:02.682] iteration:682  t-loss:0.1191, loss-lb:0.1191, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:02.874] iteration:683  t-loss:0.0733, loss-lb:0.0733, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:03.069] iteration:684  t-loss:0.1267, loss-lb:0.1267, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:04.135] iteration:685  t-loss:0.0687, loss-lb:0.0687, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:04.358] iteration:686  t-loss:0.0589, loss-lb:0.0589, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:04.590] iteration:687  t-loss:0.1656, loss-lb:0.1656, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:04.809] iteration:688  t-loss:0.0761, loss-lb:0.0761, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:05.025] iteration:689  t-loss:0.0620, loss-lb:0.0620, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:05.233] iteration:690  t-loss:0.1015, loss-lb:0.1015, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:05.431] iteration:691  t-loss:0.0716, loss-lb:0.0716, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:05.626] iteration:692  t-loss:0.0549, loss-lb:0.0549, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:05.824] iteration:693  t-loss:0.0974, loss-lb:0.0974, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:06.018] iteration:694  t-loss:0.0923, loss-lb:0.0923, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:06.215] iteration:695  t-loss:0.0618, loss-lb:0.0618, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:06.414] iteration:696  t-loss:0.1066, loss-lb:0.1066, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:06.624] iteration:697  t-loss:0.0657, loss-lb:0.0657, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:06.837] iteration:698  t-loss:0.1192, loss-lb:0.1192, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:07.049] iteration:699  t-loss:0.0485, loss-lb:0.0485, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:07.263] iteration:700  t-loss:0.0908, loss-lb:0.0908, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:07.481] iteration:701  t-loss:0.0721, loss-lb:0.0721, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:07.701] iteration:702  t-loss:0.0822, loss-lb:0.0822, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:07.905] iteration:703  t-loss:0.0580, loss-lb:0.0580, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:08.120] iteration:704  t-loss:0.1089, loss-lb:0.1089, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:08.332] iteration:705  t-loss:0.1265, loss-lb:0.1265, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:08.545] iteration:706  t-loss:0.0531, loss-lb:0.0531, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:08.752] iteration:707  t-loss:0.0842, loss-lb:0.0842, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:08.960] iteration:708  t-loss:0.0972, loss-lb:0.0972, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:09.158] iteration:709  t-loss:0.0695, loss-lb:0.0695, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:09.369] iteration:710  t-loss:0.1149, loss-lb:0.1149, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:09.577] iteration:711  t-loss:0.0813, loss-lb:0.0813, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:09.790] iteration:712  t-loss:0.1288, loss-lb:0.1288, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:09.993] iteration:713  t-loss:0.0461, loss-lb:0.0461, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:10.199] iteration:714  t-loss:0.0741, loss-lb:0.0741, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:10.396] iteration:715  t-loss:0.0546, loss-lb:0.0546, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:10.595] iteration:716  t-loss:0.0760, loss-lb:0.0760, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:10.793] iteration:717  t-loss:0.0948, loss-lb:0.0948, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:10.992] iteration:718  t-loss:0.0959, loss-lb:0.0959, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:11.188] iteration:719  t-loss:0.1111, loss-lb:0.1111, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:11.387] iteration:720  t-loss:0.1016, loss-lb:0.1016, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:11.587] iteration:721  t-loss:0.0607, loss-lb:0.0607, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:11.781] iteration:722  t-loss:0.0885, loss-lb:0.0885, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:13.014] iteration:723  t-loss:0.0972, loss-lb:0.0972, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:13.225] iteration:724  t-loss:0.0759, loss-lb:0.0759, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:13.434] iteration:725  t-loss:0.0439, loss-lb:0.0439, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:13.634] iteration:726  t-loss:0.0669, loss-lb:0.0669, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:13.839] iteration:727  t-loss:0.0474, loss-lb:0.0474, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:14.039] iteration:728  t-loss:0.1545, loss-lb:0.1545, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:14.241] iteration:729  t-loss:0.2428, loss-lb:0.2428, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:14.439] iteration:730  t-loss:0.0702, loss-lb:0.0702, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:14.639] iteration:731  t-loss:0.1283, loss-lb:0.1283, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:14.831] iteration:732  t-loss:0.1235, loss-lb:0.1235, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:15.028] iteration:733  t-loss:0.0622, loss-lb:0.0622, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:15.230] iteration:734  t-loss:0.0759, loss-lb:0.0759, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:15.439] iteration:735  t-loss:0.0667, loss-lb:0.0667, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:15.659] iteration:736  t-loss:0.0778, loss-lb:0.0778, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:15.889] iteration:737  t-loss:0.0863, loss-lb:0.0863, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:16.093] iteration:738  t-loss:0.0501, loss-lb:0.0501, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:16.307] iteration:739  t-loss:0.0623, loss-lb:0.0623, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:16.520] iteration:740  t-loss:0.1523, loss-lb:0.1523, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:16.728] iteration:741  t-loss:0.0538, loss-lb:0.0538, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:16.926] iteration:742  t-loss:0.1073, loss-lb:0.1073, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:17.129] iteration:743  t-loss:0.0850, loss-lb:0.0850, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:17.332] iteration:744  t-loss:0.1039, loss-lb:0.1039, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:17.531] iteration:745  t-loss:0.1235, loss-lb:0.1235, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:17.738] iteration:746  t-loss:0.0850, loss-lb:0.0850, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:17.943] iteration:747  t-loss:0.0997, loss-lb:0.0997, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:18.155] iteration:748  t-loss:0.0966, loss-lb:0.0966, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:18.354] iteration:749  t-loss:0.0765, loss-lb:0.0765, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:18.567] iteration:750  t-loss:0.0532, loss-lb:0.0532, loss-ulb:0.0000, weight:0.03, lr:0.0010
[23:15:18.771] iteration:751  t-loss:0.1002, loss-lb:0.1002, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:18.974] iteration:752  t-loss:0.1050, loss-lb:0.1050, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:19.169] iteration:753  t-loss:0.0599, loss-lb:0.0599, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:19.364] iteration:754  t-loss:0.0691, loss-lb:0.0691, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:19.559] iteration:755  t-loss:0.0689, loss-lb:0.0689, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:19.750] iteration:756  t-loss:0.0780, loss-lb:0.0780, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:19.942] iteration:757  t-loss:0.0767, loss-lb:0.0767, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:20.138] iteration:758  t-loss:0.0510, loss-lb:0.0510, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:20.338] iteration:759  t-loss:0.2365, loss-lb:0.2365, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:20.536] iteration:760  t-loss:0.1061, loss-lb:0.1061, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:21.684] iteration:761  t-loss:0.1293, loss-lb:0.1293, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:21.897] iteration:762  t-loss:0.2849, loss-lb:0.2849, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:22.106] iteration:763  t-loss:0.2989, loss-lb:0.2989, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:22.311] iteration:764  t-loss:0.1041, loss-lb:0.1041, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:22.517] iteration:765  t-loss:0.1707, loss-lb:0.1707, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:22.716] iteration:766  t-loss:0.0790, loss-lb:0.0790, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:22.912] iteration:767  t-loss:0.1201, loss-lb:0.1201, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:23.111] iteration:768  t-loss:0.1494, loss-lb:0.1494, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:23.307] iteration:769  t-loss:0.1092, loss-lb:0.1092, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:23.501] iteration:770  t-loss:0.0818, loss-lb:0.0818, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:23.695] iteration:771  t-loss:0.1185, loss-lb:0.1185, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:23.898] iteration:772  t-loss:0.1215, loss-lb:0.1215, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:24.112] iteration:773  t-loss:0.1095, loss-lb:0.1095, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:24.328] iteration:774  t-loss:0.1296, loss-lb:0.1296, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:24.551] iteration:775  t-loss:0.1073, loss-lb:0.1073, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:24.779] iteration:776  t-loss:0.0742, loss-lb:0.0742, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:25.003] iteration:777  t-loss:0.1251, loss-lb:0.1251, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:25.216] iteration:778  t-loss:0.0754, loss-lb:0.0754, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:25.431] iteration:779  t-loss:0.1757, loss-lb:0.1757, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:25.646] iteration:780  t-loss:0.0544, loss-lb:0.0544, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:25.855] iteration:781  t-loss:0.0701, loss-lb:0.0701, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:26.063] iteration:782  t-loss:0.0849, loss-lb:0.0849, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:26.279] iteration:783  t-loss:0.1323, loss-lb:0.1323, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:26.489] iteration:784  t-loss:0.0676, loss-lb:0.0676, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:26.692] iteration:785  t-loss:0.1023, loss-lb:0.1023, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:26.893] iteration:786  t-loss:0.0600, loss-lb:0.0600, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:27.089] iteration:787  t-loss:0.0580, loss-lb:0.0580, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:27.301] iteration:788  t-loss:0.2062, loss-lb:0.2062, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:27.503] iteration:789  t-loss:0.0810, loss-lb:0.0810, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:27.706] iteration:790  t-loss:0.0852, loss-lb:0.0852, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:27.902] iteration:791  t-loss:0.0809, loss-lb:0.0809, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:28.101] iteration:792  t-loss:0.1422, loss-lb:0.1422, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:28.293] iteration:793  t-loss:0.0639, loss-lb:0.0639, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:28.490] iteration:794  t-loss:0.0946, loss-lb:0.0946, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:28.685] iteration:795  t-loss:0.0719, loss-lb:0.0719, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:28.883] iteration:796  t-loss:0.1007, loss-lb:0.1007, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:29.081] iteration:797  t-loss:0.1024, loss-lb:0.1024, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:15:29.276] iteration:798  t-loss:0.0699, loss-lb:0.0699, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:35.970] iteration 798 : dice_score: 0.718822 best_dice: 0.719700
[23:16:35.970]  <<Test>> - Ep:20  - Dice-S/T:55.94/71.88, Best-S:61.59, Best-T:71.97
[23:16:35.970]           - AvgLoss(lb/ulb/all):0.11/0.00/0.10
[23:16:37.237] iteration:799  t-loss:0.0631, loss-lb:0.0631, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:37.471] iteration:800  t-loss:0.1463, loss-lb:0.1463, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:37.695] iteration:801  t-loss:0.1016, loss-lb:0.1016, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:37.916] iteration:802  t-loss:0.1212, loss-lb:0.1212, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:38.131] iteration:803  t-loss:0.0765, loss-lb:0.0765, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:38.335] iteration:804  t-loss:0.0719, loss-lb:0.0719, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:38.536] iteration:805  t-loss:0.0512, loss-lb:0.0512, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:38.732] iteration:806  t-loss:0.1011, loss-lb:0.1011, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:38.936] iteration:807  t-loss:0.1728, loss-lb:0.1728, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:39.133] iteration:808  t-loss:0.0437, loss-lb:0.0437, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:39.348] iteration:809  t-loss:0.0954, loss-lb:0.0954, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:39.562] iteration:810  t-loss:0.1313, loss-lb:0.1313, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:39.768] iteration:811  t-loss:0.1195, loss-lb:0.1195, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:39.967] iteration:812  t-loss:0.0720, loss-lb:0.0720, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:40.180] iteration:813  t-loss:0.0718, loss-lb:0.0718, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:40.385] iteration:814  t-loss:0.1014, loss-lb:0.1014, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:40.585] iteration:815  t-loss:0.0881, loss-lb:0.0881, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:40.786] iteration:816  t-loss:0.0922, loss-lb:0.0922, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:40.984] iteration:817  t-loss:0.1590, loss-lb:0.1590, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:41.181] iteration:818  t-loss:0.0782, loss-lb:0.0782, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:41.383] iteration:819  t-loss:0.0704, loss-lb:0.0704, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:41.586] iteration:820  t-loss:0.0502, loss-lb:0.0502, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:41.805] iteration:821  t-loss:0.0592, loss-lb:0.0592, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:42.026] iteration:822  t-loss:0.0574, loss-lb:0.0574, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:42.234] iteration:823  t-loss:0.0737, loss-lb:0.0737, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:42.441] iteration:824  t-loss:0.0594, loss-lb:0.0594, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:42.649] iteration:825  t-loss:0.0415, loss-lb:0.0415, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:42.868] iteration:826  t-loss:0.1742, loss-lb:0.1742, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:43.068] iteration:827  t-loss:0.0509, loss-lb:0.0509, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:43.274] iteration:828  t-loss:0.1442, loss-lb:0.1442, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:43.470] iteration:829  t-loss:0.1030, loss-lb:0.1030, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:43.670] iteration:830  t-loss:0.0842, loss-lb:0.0842, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:43.861] iteration:831  t-loss:0.0551, loss-lb:0.0551, loss-ulb:0.0000, weight:0.04, lr:0.0010
[23:16:44.055] iteration:832  t-loss:0.0847, loss-lb:0.0847, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:44.253] iteration:833  t-loss:0.0533, loss-lb:0.0533, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:44.449] iteration:834  t-loss:0.0905, loss-lb:0.0905, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:44.645] iteration:835  t-loss:0.0559, loss-lb:0.0559, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:44.846] iteration:836  t-loss:0.0957, loss-lb:0.0957, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:45.901] iteration:837  t-loss:0.0521, loss-lb:0.0521, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:46.116] iteration:838  t-loss:0.0758, loss-lb:0.0758, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:46.339] iteration:839  t-loss:0.0587, loss-lb:0.0587, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:46.556] iteration:840  t-loss:0.0595, loss-lb:0.0595, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:46.792] iteration:841  t-loss:0.2040, loss-lb:0.2040, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:47.001] iteration:842  t-loss:0.0612, loss-lb:0.0612, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:47.217] iteration:843  t-loss:0.0667, loss-lb:0.0667, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:47.435] iteration:844  t-loss:0.1300, loss-lb:0.1300, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:47.648] iteration:845  t-loss:0.1113, loss-lb:0.1113, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:47.862] iteration:846  t-loss:0.0982, loss-lb:0.0982, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:48.063] iteration:847  t-loss:0.0441, loss-lb:0.0441, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:48.271] iteration:848  t-loss:0.0544, loss-lb:0.0544, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:48.469] iteration:849  t-loss:0.0653, loss-lb:0.0653, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:48.665] iteration:850  t-loss:0.1095, loss-lb:0.1095, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:48.861] iteration:851  t-loss:0.0478, loss-lb:0.0478, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:49.055] iteration:852  t-loss:0.0434, loss-lb:0.0434, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:49.244] iteration:853  t-loss:0.0525, loss-lb:0.0525, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:49.434] iteration:854  t-loss:0.0690, loss-lb:0.0690, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:49.635] iteration:855  t-loss:0.0590, loss-lb:0.0590, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:49.833] iteration:856  t-loss:0.0947, loss-lb:0.0947, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:50.028] iteration:857  t-loss:0.0647, loss-lb:0.0647, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:50.228] iteration:858  t-loss:0.0740, loss-lb:0.0740, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:50.439] iteration:859  t-loss:0.0493, loss-lb:0.0493, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:50.659] iteration:860  t-loss:0.0524, loss-lb:0.0524, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:50.862] iteration:861  t-loss:0.0530, loss-lb:0.0530, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:51.077] iteration:862  t-loss:0.0520, loss-lb:0.0520, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:51.290] iteration:863  t-loss:0.0504, loss-lb:0.0504, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:51.515] iteration:864  t-loss:0.1451, loss-lb:0.1451, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:51.719] iteration:865  t-loss:0.1374, loss-lb:0.1374, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:51.929] iteration:866  t-loss:0.0538, loss-lb:0.0538, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:52.148] iteration:867  t-loss:0.0933, loss-lb:0.0933, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:52.348] iteration:868  t-loss:0.0492, loss-lb:0.0492, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:52.548] iteration:869  t-loss:0.0814, loss-lb:0.0814, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:52.746] iteration:870  t-loss:0.0818, loss-lb:0.0818, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:52.939] iteration:871  t-loss:0.0823, loss-lb:0.0823, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:53.135] iteration:872  t-loss:0.1340, loss-lb:0.1340, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:53.335] iteration:873  t-loss:0.1013, loss-lb:0.1013, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:53.531] iteration:874  t-loss:0.0780, loss-lb:0.0780, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:54.776] iteration:875  t-loss:0.0507, loss-lb:0.0507, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:54.996] iteration:876  t-loss:0.0926, loss-lb:0.0926, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:55.202] iteration:877  t-loss:0.0479, loss-lb:0.0479, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:55.419] iteration:878  t-loss:0.1280, loss-lb:0.1280, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:55.615] iteration:879  t-loss:0.1079, loss-lb:0.1079, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:55.810] iteration:880  t-loss:0.0673, loss-lb:0.0673, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:56.011] iteration:881  t-loss:0.0474, loss-lb:0.0474, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:56.214] iteration:882  t-loss:0.1033, loss-lb:0.1033, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:56.417] iteration:883  t-loss:0.0483, loss-lb:0.0483, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:56.621] iteration:884  t-loss:0.1316, loss-lb:0.1316, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:56.820] iteration:885  t-loss:0.0819, loss-lb:0.0819, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:57.016] iteration:886  t-loss:0.0781, loss-lb:0.0781, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:57.208] iteration:887  t-loss:0.0401, loss-lb:0.0401, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:57.401] iteration:888  t-loss:0.0693, loss-lb:0.0693, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:57.604] iteration:889  t-loss:0.0821, loss-lb:0.0821, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:57.800] iteration:890  t-loss:0.0708, loss-lb:0.0708, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:57.994] iteration:891  t-loss:0.1590, loss-lb:0.1590, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:58.186] iteration:892  t-loss:0.0692, loss-lb:0.0692, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:58.382] iteration:893  t-loss:0.0830, loss-lb:0.0830, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:58.580] iteration:894  t-loss:0.0838, loss-lb:0.0838, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:58.789] iteration:895  t-loss:0.1109, loss-lb:0.1109, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:59.005] iteration:896  t-loss:0.0726, loss-lb:0.0726, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:59.234] iteration:897  t-loss:0.0775, loss-lb:0.0775, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:59.459] iteration:898  t-loss:0.1182, loss-lb:0.1182, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:59.663] iteration:899  t-loss:0.0487, loss-lb:0.0487, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:16:59.885] iteration:900  t-loss:0.0527, loss-lb:0.0527, loss-ulb:0.0000, weight:0.04, lr:0.0009
[23:17:00.105] iteration:901  t-loss:0.0997, loss-lb:0.0997, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:00.320] iteration:902  t-loss:0.1368, loss-lb:0.1368, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:00.531] iteration:903  t-loss:0.0991, loss-lb:0.0991, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:00.740] iteration:904  t-loss:0.0580, loss-lb:0.0580, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:00.942] iteration:905  t-loss:0.0491, loss-lb:0.0491, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:01.142] iteration:906  t-loss:0.0770, loss-lb:0.0770, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:01.336] iteration:907  t-loss:0.0880, loss-lb:0.0880, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:01.531] iteration:908  t-loss:0.1501, loss-lb:0.1501, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:01.727] iteration:909  t-loss:0.0743, loss-lb:0.0743, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:01.925] iteration:910  t-loss:0.1027, loss-lb:0.1027, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:02.121] iteration:911  t-loss:0.0489, loss-lb:0.0489, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:02.317] iteration:912  t-loss:0.0379, loss-lb:0.0379, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:03.387] iteration:913  t-loss:0.0563, loss-lb:0.0563, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:03.596] iteration:914  t-loss:0.0394, loss-lb:0.0394, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:03.799] iteration:915  t-loss:0.0433, loss-lb:0.0433, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:04.013] iteration:916  t-loss:0.0710, loss-lb:0.0710, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:04.220] iteration:917  t-loss:0.0598, loss-lb:0.0598, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:04.432] iteration:918  t-loss:0.1301, loss-lb:0.1301, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:04.636] iteration:919  t-loss:0.1353, loss-lb:0.1353, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:04.835] iteration:920  t-loss:0.1284, loss-lb:0.1284, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:05.041] iteration:921  t-loss:0.0882, loss-lb:0.0882, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:05.242] iteration:922  t-loss:0.0704, loss-lb:0.0704, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:05.444] iteration:923  t-loss:0.0651, loss-lb:0.0651, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:05.647] iteration:924  t-loss:0.1254, loss-lb:0.1254, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:05.845] iteration:925  t-loss:0.0765, loss-lb:0.0765, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:06.043] iteration:926  t-loss:0.0836, loss-lb:0.0836, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:06.241] iteration:927  t-loss:0.1128, loss-lb:0.1128, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:06.435] iteration:928  t-loss:0.1331, loss-lb:0.1331, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:06.633] iteration:929  t-loss:0.0519, loss-lb:0.0519, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:06.831] iteration:930  t-loss:0.0526, loss-lb:0.0526, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:07.027] iteration:931  t-loss:0.0439, loss-lb:0.0439, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:07.222] iteration:932  t-loss:0.0635, loss-lb:0.0635, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:07.423] iteration:933  t-loss:0.1000, loss-lb:0.1000, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:07.630] iteration:934  t-loss:0.0436, loss-lb:0.0436, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:07.846] iteration:935  t-loss:0.0796, loss-lb:0.0796, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:08.048] iteration:936  t-loss:0.0629, loss-lb:0.0629, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:08.250] iteration:937  t-loss:0.0436, loss-lb:0.0436, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:08.451] iteration:938  t-loss:0.0913, loss-lb:0.0913, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:08.664] iteration:939  t-loss:0.1244, loss-lb:0.1244, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:08.868] iteration:940  t-loss:0.0565, loss-lb:0.0565, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:09.072] iteration:941  t-loss:0.0745, loss-lb:0.0745, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:09.274] iteration:942  t-loss:0.0508, loss-lb:0.0508, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:09.473] iteration:943  t-loss:0.0633, loss-lb:0.0633, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:09.668] iteration:944  t-loss:0.0543, loss-lb:0.0543, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:09.867] iteration:945  t-loss:0.0653, loss-lb:0.0653, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:10.064] iteration:946  t-loss:0.0674, loss-lb:0.0674, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:10.261] iteration:947  t-loss:0.0651, loss-lb:0.0651, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:10.454] iteration:948  t-loss:0.1464, loss-lb:0.1464, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:10.656] iteration:949  t-loss:0.0689, loss-lb:0.0689, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:17:10.852] iteration:950  t-loss:0.0888, loss-lb:0.0888, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:14.176] iteration 950 : dice_score: 0.642364 best_dice: 0.719700
[23:18:14.176]  <<Test>> - Ep:24  - Dice-S/T:55.88/64.24, Best-S:61.59, Best-T:71.97
[23:18:14.176]           - AvgLoss(lb/ulb/all):0.08/0.00/0.07
[23:18:15.496] iteration:951  t-loss:0.1289, loss-lb:0.1289, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:15.729] iteration:952  t-loss:0.0495, loss-lb:0.0495, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:15.994] iteration:953  t-loss:0.0726, loss-lb:0.0726, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:16.243] iteration:954  t-loss:0.0431, loss-lb:0.0431, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:16.486] iteration:955  t-loss:0.0561, loss-lb:0.0561, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:16.722] iteration:956  t-loss:0.0759, loss-lb:0.0759, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:16.975] iteration:957  t-loss:0.1036, loss-lb:0.1036, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:17.198] iteration:958  t-loss:0.0677, loss-lb:0.0677, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:17.450] iteration:959  t-loss:0.0664, loss-lb:0.0664, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:17.690] iteration:960  t-loss:0.0656, loss-lb:0.0656, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:17.924] iteration:961  t-loss:0.0614, loss-lb:0.0614, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:18.154] iteration:962  t-loss:0.1019, loss-lb:0.1019, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:18.377] iteration:963  t-loss:0.1730, loss-lb:0.1730, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:18.598] iteration:964  t-loss:0.0421, loss-lb:0.0421, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:18.830] iteration:965  t-loss:0.1081, loss-lb:0.1081, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:19.056] iteration:966  t-loss:0.0754, loss-lb:0.0754, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:19.284] iteration:967  t-loss:0.0882, loss-lb:0.0882, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:19.495] iteration:968  t-loss:0.1087, loss-lb:0.1087, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:19.691] iteration:969  t-loss:0.0491, loss-lb:0.0491, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:19.900] iteration:970  t-loss:0.0752, loss-lb:0.0752, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:20.122] iteration:971  t-loss:0.0521, loss-lb:0.0521, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:20.332] iteration:972  t-loss:0.0701, loss-lb:0.0701, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:20.535] iteration:973  t-loss:0.0644, loss-lb:0.0644, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:20.742] iteration:974  t-loss:0.0928, loss-lb:0.0928, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:20.949] iteration:975  t-loss:0.0404, loss-lb:0.0404, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:21.159] iteration:976  t-loss:0.0477, loss-lb:0.0477, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:21.363] iteration:977  t-loss:0.0459, loss-lb:0.0459, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:21.570] iteration:978  t-loss:0.0539, loss-lb:0.0539, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:21.772] iteration:979  t-loss:0.0453, loss-lb:0.0453, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:21.978] iteration:980  t-loss:0.0701, loss-lb:0.0701, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:22.176] iteration:981  t-loss:0.0598, loss-lb:0.0598, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:22.382] iteration:982  t-loss:0.0355, loss-lb:0.0355, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:22.579] iteration:983  t-loss:0.0371, loss-lb:0.0371, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:22.775] iteration:984  t-loss:0.1250, loss-lb:0.1250, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:22.969] iteration:985  t-loss:0.0493, loss-lb:0.0493, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:23.164] iteration:986  t-loss:0.0508, loss-lb:0.0508, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:23.359] iteration:987  t-loss:0.0492, loss-lb:0.0492, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:23.553] iteration:988  t-loss:0.0358, loss-lb:0.0358, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:25.222] iteration:989  t-loss:0.0419, loss-lb:0.0419, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:25.469] iteration:990  t-loss:0.1470, loss-lb:0.1470, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:25.712] iteration:991  t-loss:0.1048, loss-lb:0.1048, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:25.966] iteration:992  t-loss:0.0883, loss-lb:0.0883, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:26.205] iteration:993  t-loss:0.1324, loss-lb:0.1324, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:26.468] iteration:994  t-loss:0.0612, loss-lb:0.0612, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:26.696] iteration:995  t-loss:0.0358, loss-lb:0.0358, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:26.931] iteration:996  t-loss:0.0591, loss-lb:0.0591, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:27.164] iteration:997  t-loss:0.0693, loss-lb:0.0693, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:27.407] iteration:998  t-loss:0.0917, loss-lb:0.0917, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:27.627] iteration:999  t-loss:0.0595, loss-lb:0.0595, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:27.848] iteration:1000  t-loss:0.1053, loss-lb:0.1053, loss-ulb:0.0000, weight:0.05, lr:0.0009
[23:18:28.652] iteration:1001  t-loss:0.0787, loss-lb:0.0777, loss-ulb:0.0170, weight:0.05, lr:0.0009
[23:18:29.036] iteration:1002  t-loss:0.0642, loss-lb:0.0622, loss-ulb:0.0380, weight:0.05, lr:0.0009
[23:18:29.412] iteration:1003  t-loss:0.0690, loss-lb:0.0659, loss-ulb:0.0575, weight:0.05, lr:0.0009
[23:18:29.798] iteration:1004  t-loss:0.0553, loss-lb:0.0520, loss-ulb:0.0596, weight:0.05, lr:0.0009
[23:18:30.186] iteration:1005  t-loss:0.1243, loss-lb:0.1227, loss-ulb:0.0288, weight:0.05, lr:0.0009
[23:18:30.571] iteration:1006  t-loss:0.0669, loss-lb:0.0664, loss-ulb:0.0088, weight:0.05, lr:0.0009
[23:18:30.953] iteration:1007  t-loss:0.0956, loss-lb:0.0914, loss-ulb:0.0780, weight:0.05, lr:0.0009
[23:18:31.331] iteration:1008  t-loss:0.0893, loss-lb:0.0888, loss-ulb:0.0098, weight:0.05, lr:0.0009
[23:18:31.705] iteration:1009  t-loss:0.1085, loss-lb:0.1072, loss-ulb:0.0233, weight:0.05, lr:0.0009
[23:18:32.090] iteration:1010  t-loss:0.0871, loss-lb:0.0850, loss-ulb:0.0383, weight:0.05, lr:0.0009
[23:18:32.463] iteration:1011  t-loss:0.0544, loss-lb:0.0534, loss-ulb:0.0190, weight:0.05, lr:0.0009
[23:18:32.833] iteration:1012  t-loss:0.0495, loss-lb:0.0478, loss-ulb:0.0309, weight:0.05, lr:0.0009
[23:18:33.217] iteration:1013  t-loss:0.0460, loss-lb:0.0450, loss-ulb:0.0189, weight:0.05, lr:0.0009
[23:18:33.604] iteration:1014  t-loss:0.0611, loss-lb:0.0591, loss-ulb:0.0362, weight:0.05, lr:0.0009
[23:18:33.996] iteration:1015  t-loss:0.0935, loss-lb:0.0929, loss-ulb:0.0125, weight:0.05, lr:0.0009
[23:18:34.381] iteration:1016  t-loss:0.0424, loss-lb:0.0411, loss-ulb:0.0256, weight:0.05, lr:0.0009
[23:18:34.759] iteration:1017  t-loss:0.0714, loss-lb:0.0694, loss-ulb:0.0368, weight:0.05, lr:0.0009
[23:18:35.139] iteration:1018  t-loss:0.0671, loss-lb:0.0650, loss-ulb:0.0401, weight:0.05, lr:0.0009
[23:18:35.516] iteration:1019  t-loss:0.0816, loss-lb:0.0801, loss-ulb:0.0270, weight:0.05, lr:0.0009
[23:18:35.888] iteration:1020  t-loss:0.0947, loss-lb:0.0922, loss-ulb:0.0464, weight:0.05, lr:0.0009
[23:18:36.263] iteration:1021  t-loss:0.0673, loss-lb:0.0657, loss-ulb:0.0302, weight:0.05, lr:0.0009
[23:18:36.635] iteration:1022  t-loss:0.1499, loss-lb:0.1485, loss-ulb:0.0266, weight:0.05, lr:0.0009
[23:18:37.002] iteration:1023  t-loss:0.0804, loss-lb:0.0792, loss-ulb:0.0234, weight:0.05, lr:0.0009
[23:18:37.372] iteration:1024  t-loss:0.0615, loss-lb:0.0613, loss-ulb:0.0042, weight:0.05, lr:0.0009
[23:18:37.741] iteration:1025  t-loss:0.0935, loss-lb:0.0905, loss-ulb:0.0549, weight:0.05, lr:0.0009
[23:18:38.112] iteration:1026  t-loss:0.0412, loss-lb:0.0400, loss-ulb:0.0233, weight:0.05, lr:0.0009
[23:18:39.179] iteration:1027  t-loss:0.0939, loss-lb:0.0933, loss-ulb:0.0102, weight:0.05, lr:0.0009
[23:18:39.568] iteration:1028  t-loss:0.0909, loss-lb:0.0902, loss-ulb:0.0136, weight:0.05, lr:0.0009
[23:18:39.944] iteration:1029  t-loss:0.0795, loss-lb:0.0750, loss-ulb:0.0833, weight:0.05, lr:0.0009
[23:18:40.320] iteration:1030  t-loss:0.1079, loss-lb:0.1073, loss-ulb:0.0110, weight:0.05, lr:0.0009
[23:18:40.698] iteration:1031  t-loss:0.0767, loss-lb:0.0733, loss-ulb:0.0641, weight:0.05, lr:0.0009
[23:18:41.074] iteration:1032  t-loss:0.0988, loss-lb:0.0984, loss-ulb:0.0078, weight:0.05, lr:0.0009
[23:18:41.452] iteration:1033  t-loss:0.0675, loss-lb:0.0661, loss-ulb:0.0258, weight:0.05, lr:0.0009
[23:18:41.828] iteration:1034  t-loss:0.1165, loss-lb:0.1149, loss-ulb:0.0291, weight:0.05, lr:0.0009
[23:18:42.209] iteration:1035  t-loss:0.0778, loss-lb:0.0761, loss-ulb:0.0303, weight:0.05, lr:0.0009
[23:18:42.584] iteration:1036  t-loss:0.0546, loss-lb:0.0521, loss-ulb:0.0472, weight:0.05, lr:0.0009
[23:18:42.953] iteration:1037  t-loss:0.0600, loss-lb:0.0554, loss-ulb:0.0850, weight:0.05, lr:0.0009
[23:18:43.324] iteration:1038  t-loss:0.1880, loss-lb:0.1856, loss-ulb:0.0437, weight:0.05, lr:0.0009
[23:18:43.696] iteration:1039  t-loss:0.1330, loss-lb:0.1321, loss-ulb:0.0162, weight:0.05, lr:0.0009
[23:18:44.068] iteration:1040  t-loss:0.0760, loss-lb:0.0725, loss-ulb:0.0660, weight:0.05, lr:0.0009
[23:18:44.440] iteration:1041  t-loss:0.0542, loss-lb:0.0530, loss-ulb:0.0217, weight:0.05, lr:0.0009
[23:18:44.813] iteration:1042  t-loss:0.0526, loss-lb:0.0510, loss-ulb:0.0288, weight:0.05, lr:0.0009
[23:18:45.183] iteration:1043  t-loss:0.0398, loss-lb:0.0391, loss-ulb:0.0129, weight:0.05, lr:0.0009
[23:18:45.558] iteration:1044  t-loss:0.1158, loss-lb:0.1145, loss-ulb:0.0231, weight:0.05, lr:0.0009
[23:18:45.932] iteration:1045  t-loss:0.0890, loss-lb:0.0883, loss-ulb:0.0122, weight:0.05, lr:0.0009
[23:18:46.317] iteration:1046  t-loss:0.0933, loss-lb:0.0919, loss-ulb:0.0259, weight:0.05, lr:0.0009
[23:18:46.712] iteration:1047  t-loss:0.0413, loss-lb:0.0408, loss-ulb:0.0090, weight:0.05, lr:0.0009
[23:18:47.094] iteration:1048  t-loss:0.0459, loss-lb:0.0455, loss-ulb:0.0089, weight:0.05, lr:0.0009
[23:18:47.473] iteration:1049  t-loss:0.0705, loss-lb:0.0699, loss-ulb:0.0103, weight:0.05, lr:0.0009
[23:18:47.849] iteration:1050  t-loss:0.0502, loss-lb:0.0484, loss-ulb:0.0338, weight:0.05, lr:0.0009
[23:18:48.219] iteration:1051  t-loss:0.0469, loss-lb:0.0430, loss-ulb:0.0590, weight:0.07, lr:0.0009
[23:18:48.598] iteration:1052  t-loss:0.0585, loss-lb:0.0574, loss-ulb:0.0163, weight:0.07, lr:0.0009
[23:18:48.973] iteration:1053  t-loss:0.0459, loss-lb:0.0444, loss-ulb:0.0221, weight:0.07, lr:0.0009
[23:18:49.344] iteration:1054  t-loss:0.0540, loss-lb:0.0480, loss-ulb:0.0904, weight:0.07, lr:0.0009
[23:18:49.716] iteration:1055  t-loss:0.0807, loss-lb:0.0780, loss-ulb:0.0414, weight:0.07, lr:0.0009
[23:18:50.095] iteration:1056  t-loss:0.0537, loss-lb:0.0525, loss-ulb:0.0188, weight:0.07, lr:0.0009
[23:18:50.469] iteration:1057  t-loss:0.0663, loss-lb:0.0640, loss-ulb:0.0356, weight:0.07, lr:0.0009
[23:18:50.840] iteration:1058  t-loss:0.1151, loss-lb:0.1124, loss-ulb:0.0412, weight:0.07, lr:0.0009
[23:18:51.215] iteration:1059  t-loss:0.1043, loss-lb:0.1037, loss-ulb:0.0093, weight:0.07, lr:0.0009
[23:18:51.592] iteration:1060  t-loss:0.0672, loss-lb:0.0644, loss-ulb:0.0410, weight:0.07, lr:0.0009
[23:18:51.963] iteration:1061  t-loss:0.0936, loss-lb:0.0909, loss-ulb:0.0395, weight:0.07, lr:0.0009
[23:18:52.336] iteration:1062  t-loss:0.0952, loss-lb:0.0930, loss-ulb:0.0322, weight:0.07, lr:0.0009
[23:18:52.707] iteration:1063  t-loss:0.0577, loss-lb:0.0508, loss-ulb:0.1040, weight:0.07, lr:0.0009
[23:18:53.081] iteration:1064  t-loss:0.0971, loss-lb:0.0935, loss-ulb:0.0535, weight:0.07, lr:0.0009
[23:18:54.412] iteration:1065  t-loss:0.0626, loss-lb:0.0620, loss-ulb:0.0088, weight:0.07, lr:0.0009
[23:18:54.796] iteration:1066  t-loss:0.0980, loss-lb:0.0972, loss-ulb:0.0119, weight:0.07, lr:0.0009
[23:18:55.169] iteration:1067  t-loss:0.1074, loss-lb:0.1070, loss-ulb:0.0052, weight:0.07, lr:0.0009
[23:18:55.543] iteration:1068  t-loss:0.0391, loss-lb:0.0378, loss-ulb:0.0206, weight:0.07, lr:0.0009
[23:18:55.916] iteration:1069  t-loss:0.0415, loss-lb:0.0361, loss-ulb:0.0821, weight:0.07, lr:0.0009
[23:18:56.296] iteration:1070  t-loss:0.0675, loss-lb:0.0650, loss-ulb:0.0383, weight:0.07, lr:0.0009
[23:18:56.675] iteration:1071  t-loss:0.0849, loss-lb:0.0834, loss-ulb:0.0221, weight:0.07, lr:0.0009
[23:18:57.052] iteration:1072  t-loss:0.0787, loss-lb:0.0776, loss-ulb:0.0167, weight:0.07, lr:0.0009
[23:18:57.427] iteration:1073  t-loss:0.0414, loss-lb:0.0409, loss-ulb:0.0071, weight:0.07, lr:0.0009
[23:18:57.802] iteration:1074  t-loss:0.0460, loss-lb:0.0435, loss-ulb:0.0363, weight:0.07, lr:0.0009
[23:18:58.174] iteration:1075  t-loss:0.0480, loss-lb:0.0473, loss-ulb:0.0104, weight:0.07, lr:0.0009
[23:18:58.549] iteration:1076  t-loss:0.0933, loss-lb:0.0912, loss-ulb:0.0323, weight:0.07, lr:0.0009
[23:18:58.922] iteration:1077  t-loss:0.0457, loss-lb:0.0436, loss-ulb:0.0310, weight:0.07, lr:0.0009
[23:18:59.296] iteration:1078  t-loss:0.0696, loss-lb:0.0681, loss-ulb:0.0225, weight:0.07, lr:0.0009
[23:18:59.668] iteration:1079  t-loss:0.0463, loss-lb:0.0455, loss-ulb:0.0117, weight:0.07, lr:0.0009
[23:19:00.042] iteration:1080  t-loss:0.0476, loss-lb:0.0465, loss-ulb:0.0169, weight:0.07, lr:0.0009
[23:19:00.414] iteration:1081  t-loss:0.0454, loss-lb:0.0444, loss-ulb:0.0153, weight:0.07, lr:0.0009
[23:19:00.783] iteration:1082  t-loss:0.0489, loss-lb:0.0477, loss-ulb:0.0179, weight:0.07, lr:0.0009
[23:19:01.156] iteration:1083  t-loss:0.0372, loss-lb:0.0356, loss-ulb:0.0240, weight:0.07, lr:0.0009
[23:19:01.541] iteration:1084  t-loss:0.0601, loss-lb:0.0592, loss-ulb:0.0143, weight:0.07, lr:0.0009
[23:19:01.939] iteration:1085  t-loss:0.0619, loss-lb:0.0608, loss-ulb:0.0175, weight:0.07, lr:0.0009
[23:19:02.336] iteration:1086  t-loss:0.0751, loss-lb:0.0732, loss-ulb:0.0282, weight:0.07, lr:0.0009
[23:19:02.715] iteration:1087  t-loss:0.0509, loss-lb:0.0497, loss-ulb:0.0181, weight:0.07, lr:0.0009
[23:19:03.090] iteration:1088  t-loss:0.0790, loss-lb:0.0688, loss-ulb:0.1536, weight:0.07, lr:0.0009
[23:19:03.463] iteration:1089  t-loss:0.0795, loss-lb:0.0781, loss-ulb:0.0207, weight:0.07, lr:0.0009
[23:19:03.840] iteration:1090  t-loss:0.0892, loss-lb:0.0880, loss-ulb:0.0182, weight:0.07, lr:0.0009
[23:19:04.219] iteration:1091  t-loss:0.1056, loss-lb:0.1045, loss-ulb:0.0173, weight:0.07, lr:0.0009
[23:19:04.596] iteration:1092  t-loss:0.0341, loss-lb:0.0330, loss-ulb:0.0168, weight:0.07, lr:0.0009
[23:19:04.969] iteration:1093  t-loss:0.1273, loss-lb:0.1270, loss-ulb:0.0051, weight:0.07, lr:0.0009
[23:19:05.345] iteration:1094  t-loss:0.0541, loss-lb:0.0523, loss-ulb:0.0261, weight:0.07, lr:0.0009
[23:19:05.719] iteration:1095  t-loss:0.0757, loss-lb:0.0749, loss-ulb:0.0118, weight:0.07, lr:0.0009
[23:19:06.092] iteration:1096  t-loss:0.0534, loss-lb:0.0521, loss-ulb:0.0195, weight:0.07, lr:0.0009
[23:19:06.466] iteration:1097  t-loss:0.0729, loss-lb:0.0707, loss-ulb:0.0320, weight:0.07, lr:0.0009
[23:19:06.835] iteration:1098  t-loss:0.1153, loss-lb:0.1149, loss-ulb:0.0059, weight:0.07, lr:0.0009
[23:19:07.209] iteration:1099  t-loss:0.0408, loss-lb:0.0404, loss-ulb:0.0052, weight:0.07, lr:0.0009
[23:19:07.585] iteration:1100  t-loss:0.0991, loss-lb:0.0989, loss-ulb:0.0034, weight:0.07, lr:0.0009
[23:19:07.958] iteration:1101  t-loss:0.0461, loss-lb:0.0436, loss-ulb:0.0380, weight:0.07, lr:0.0009
[23:19:08.330] iteration:1102  t-loss:0.0754, loss-lb:0.0749, loss-ulb:0.0064, weight:0.07, lr:0.0009
[23:20:11.310] iteration 1102 : dice_score: 0.611111 best_dice: 0.719700
[23:20:11.310]  <<Test>> - Ep:28  - Dice-S/T:65.55/61.11, Best-S:65.55, Best-T:71.97
[23:20:11.311]           - AvgLoss(lb/ulb/all):0.07/0.02/0.07
[23:20:12.657] iteration:1103  t-loss:0.0362, loss-lb:0.0357, loss-ulb:0.0064, weight:0.07, lr:0.0009
[23:20:13.047] iteration:1104  t-loss:0.0530, loss-lb:0.0457, loss-ulb:0.1106, weight:0.07, lr:0.0009
[23:20:13.424] iteration:1105  t-loss:0.0620, loss-lb:0.0575, loss-ulb:0.0668, weight:0.07, lr:0.0009
[23:20:13.802] iteration:1106  t-loss:0.0836, loss-lb:0.0787, loss-ulb:0.0736, weight:0.07, lr:0.0009
[23:20:14.176] iteration:1107  t-loss:0.0456, loss-lb:0.0449, loss-ulb:0.0118, weight:0.07, lr:0.0009
[23:20:14.556] iteration:1108  t-loss:0.1985, loss-lb:0.1973, loss-ulb:0.0173, weight:0.07, lr:0.0009
[23:20:14.945] iteration:1109  t-loss:0.0693, loss-lb:0.0665, loss-ulb:0.0419, weight:0.07, lr:0.0009
[23:20:15.331] iteration:1110  t-loss:0.0841, loss-lb:0.0825, loss-ulb:0.0242, weight:0.07, lr:0.0009
[23:20:15.713] iteration:1111  t-loss:0.0437, loss-lb:0.0419, loss-ulb:0.0275, weight:0.07, lr:0.0009
[23:20:16.124] iteration:1112  t-loss:0.0897, loss-lb:0.0878, loss-ulb:0.0288, weight:0.07, lr:0.0009
[23:20:16.515] iteration:1113  t-loss:0.0731, loss-lb:0.0726, loss-ulb:0.0075, weight:0.07, lr:0.0009
[23:20:16.893] iteration:1114  t-loss:0.0803, loss-lb:0.0794, loss-ulb:0.0131, weight:0.07, lr:0.0009
[23:20:17.268] iteration:1115  t-loss:0.0768, loss-lb:0.0765, loss-ulb:0.0049, weight:0.07, lr:0.0009
[23:20:17.644] iteration:1116  t-loss:0.0567, loss-lb:0.0551, loss-ulb:0.0248, weight:0.07, lr:0.0009
[23:20:18.022] iteration:1117  t-loss:0.0405, loss-lb:0.0400, loss-ulb:0.0074, weight:0.07, lr:0.0009
[23:20:18.400] iteration:1118  t-loss:0.0831, loss-lb:0.0824, loss-ulb:0.0097, weight:0.07, lr:0.0009
[23:20:18.774] iteration:1119  t-loss:0.0426, loss-lb:0.0410, loss-ulb:0.0244, weight:0.07, lr:0.0009
[23:20:19.157] iteration:1120  t-loss:0.0706, loss-lb:0.0694, loss-ulb:0.0169, weight:0.07, lr:0.0009
[23:20:19.536] iteration:1121  t-loss:0.1128, loss-lb:0.1110, loss-ulb:0.0264, weight:0.07, lr:0.0009
[23:20:19.909] iteration:1122  t-loss:0.0501, loss-lb:0.0476, loss-ulb:0.0384, weight:0.07, lr:0.0009
[23:20:20.300] iteration:1123  t-loss:0.0800, loss-lb:0.0786, loss-ulb:0.0217, weight:0.07, lr:0.0009
[23:20:20.709] iteration:1124  t-loss:0.0387, loss-lb:0.0370, loss-ulb:0.0247, weight:0.07, lr:0.0009
[23:20:21.115] iteration:1125  t-loss:0.1158, loss-lb:0.1126, loss-ulb:0.0488, weight:0.07, lr:0.0009
[23:20:21.500] iteration:1126  t-loss:0.0346, loss-lb:0.0332, loss-ulb:0.0210, weight:0.07, lr:0.0009
[23:20:21.873] iteration:1127  t-loss:0.0551, loss-lb:0.0537, loss-ulb:0.0215, weight:0.07, lr:0.0009
[23:20:22.245] iteration:1128  t-loss:0.0394, loss-lb:0.0378, loss-ulb:0.0244, weight:0.07, lr:0.0009
[23:20:22.619] iteration:1129  t-loss:0.0646, loss-lb:0.0621, loss-ulb:0.0375, weight:0.07, lr:0.0009
[23:20:22.992] iteration:1130  t-loss:0.0723, loss-lb:0.0718, loss-ulb:0.0073, weight:0.07, lr:0.0009
[23:20:23.366] iteration:1131  t-loss:0.0695, loss-lb:0.0683, loss-ulb:0.0181, weight:0.07, lr:0.0009
[23:20:23.743] iteration:1132  t-loss:0.0430, loss-lb:0.0417, loss-ulb:0.0189, weight:0.07, lr:0.0009
[23:20:24.114] iteration:1133  t-loss:0.1282, loss-lb:0.1266, loss-ulb:0.0241, weight:0.07, lr:0.0009
[23:20:24.488] iteration:1134  t-loss:0.0953, loss-lb:0.0937, loss-ulb:0.0243, weight:0.07, lr:0.0009
[23:20:24.861] iteration:1135  t-loss:0.0563, loss-lb:0.0558, loss-ulb:0.0073, weight:0.07, lr:0.0009
[23:20:25.235] iteration:1136  t-loss:0.0545, loss-lb:0.0535, loss-ulb:0.0152, weight:0.07, lr:0.0009
[23:20:25.608] iteration:1137  t-loss:0.0714, loss-lb:0.0699, loss-ulb:0.0220, weight:0.07, lr:0.0009
[23:20:25.979] iteration:1138  t-loss:0.0903, loss-lb:0.0891, loss-ulb:0.0192, weight:0.07, lr:0.0009
[23:20:26.347] iteration:1139  t-loss:0.0693, loss-lb:0.0649, loss-ulb:0.0653, weight:0.07, lr:0.0009
[23:20:26.723] iteration:1140  t-loss:0.0917, loss-lb:0.0876, loss-ulb:0.0618, weight:0.07, lr:0.0009
[23:20:28.296] iteration:1141  t-loss:0.0461, loss-lb:0.0448, loss-ulb:0.0198, weight:0.07, lr:0.0009
[23:20:28.681] iteration:1142  t-loss:0.0715, loss-lb:0.0695, loss-ulb:0.0299, weight:0.07, lr:0.0009
[23:20:29.054] iteration:1143  t-loss:0.0388, loss-lb:0.0378, loss-ulb:0.0150, weight:0.07, lr:0.0009
[23:20:29.435] iteration:1144  t-loss:0.1014, loss-lb:0.1000, loss-ulb:0.0206, weight:0.07, lr:0.0009
[23:20:29.810] iteration:1145  t-loss:0.0551, loss-lb:0.0514, loss-ulb:0.0564, weight:0.07, lr:0.0009
[23:20:30.188] iteration:1146  t-loss:0.0741, loss-lb:0.0730, loss-ulb:0.0161, weight:0.07, lr:0.0009
[23:20:30.569] iteration:1147  t-loss:0.0813, loss-lb:0.0807, loss-ulb:0.0091, weight:0.07, lr:0.0009
[23:20:30.943] iteration:1148  t-loss:0.0538, loss-lb:0.0531, loss-ulb:0.0101, weight:0.07, lr:0.0009
[23:20:31.321] iteration:1149  t-loss:0.0736, loss-lb:0.0708, loss-ulb:0.0425, weight:0.07, lr:0.0009
[23:20:31.696] iteration:1150  t-loss:0.0533, loss-lb:0.0496, loss-ulb:0.0555, weight:0.07, lr:0.0009
[23:20:32.069] iteration:1151  t-loss:0.0881, loss-lb:0.0877, loss-ulb:0.0055, weight:0.07, lr:0.0009
[23:20:32.440] iteration:1152  t-loss:0.1337, loss-lb:0.1332, loss-ulb:0.0075, weight:0.07, lr:0.0009
[23:20:32.817] iteration:1153  t-loss:0.0811, loss-lb:0.0796, loss-ulb:0.0224, weight:0.07, lr:0.0009
[23:20:33.193] iteration:1154  t-loss:0.0574, loss-lb:0.0559, loss-ulb:0.0232, weight:0.07, lr:0.0009
[23:20:33.568] iteration:1155  t-loss:0.1744, loss-lb:0.1726, loss-ulb:0.0265, weight:0.07, lr:0.0009
[23:20:33.937] iteration:1156  t-loss:0.0964, loss-lb:0.0951, loss-ulb:0.0196, weight:0.07, lr:0.0009
[23:20:34.315] iteration:1157  t-loss:0.1014, loss-lb:0.0998, loss-ulb:0.0239, weight:0.07, lr:0.0009
[23:20:34.684] iteration:1158  t-loss:0.0522, loss-lb:0.0493, loss-ulb:0.0440, weight:0.07, lr:0.0009
[23:20:35.056] iteration:1159  t-loss:0.0692, loss-lb:0.0674, loss-ulb:0.0275, weight:0.07, lr:0.0009
[23:20:35.445] iteration:1160  t-loss:0.0746, loss-lb:0.0726, loss-ulb:0.0304, weight:0.07, lr:0.0009
[23:20:35.856] iteration:1161  t-loss:0.0671, loss-lb:0.0663, loss-ulb:0.0107, weight:0.07, lr:0.0009
[23:20:36.247] iteration:1162  t-loss:0.0344, loss-lb:0.0336, loss-ulb:0.0120, weight:0.07, lr:0.0009
[23:20:36.628] iteration:1163  t-loss:0.0434, loss-lb:0.0425, loss-ulb:0.0130, weight:0.07, lr:0.0009
[23:20:37.009] iteration:1164  t-loss:0.0669, loss-lb:0.0661, loss-ulb:0.0107, weight:0.07, lr:0.0009
[23:20:37.389] iteration:1165  t-loss:0.0661, loss-lb:0.0653, loss-ulb:0.0128, weight:0.07, lr:0.0009
[23:20:37.767] iteration:1166  t-loss:0.0554, loss-lb:0.0545, loss-ulb:0.0147, weight:0.07, lr:0.0009
[23:20:38.141] iteration:1167  t-loss:0.0885, loss-lb:0.0877, loss-ulb:0.0125, weight:0.07, lr:0.0009
[23:20:38.516] iteration:1168  t-loss:0.0945, loss-lb:0.0932, loss-ulb:0.0198, weight:0.07, lr:0.0009
[23:20:38.888] iteration:1169  t-loss:0.0357, loss-lb:0.0352, loss-ulb:0.0075, weight:0.07, lr:0.0009
[23:20:39.265] iteration:1170  t-loss:0.1318, loss-lb:0.1306, loss-ulb:0.0183, weight:0.07, lr:0.0009
[23:20:39.635] iteration:1171  t-loss:0.0403, loss-lb:0.0398, loss-ulb:0.0076, weight:0.07, lr:0.0009
[23:20:40.005] iteration:1172  t-loss:0.0552, loss-lb:0.0544, loss-ulb:0.0108, weight:0.07, lr:0.0009
[23:20:40.380] iteration:1173  t-loss:0.1387, loss-lb:0.1373, loss-ulb:0.0214, weight:0.07, lr:0.0009
[23:20:40.753] iteration:1174  t-loss:0.1180, loss-lb:0.1170, loss-ulb:0.0150, weight:0.07, lr:0.0009
[23:20:41.124] iteration:1175  t-loss:0.0833, loss-lb:0.0807, loss-ulb:0.0401, weight:0.07, lr:0.0009
[23:20:41.497] iteration:1176  t-loss:0.0539, loss-lb:0.0518, loss-ulb:0.0311, weight:0.07, lr:0.0009
[23:20:41.870] iteration:1177  t-loss:0.0815, loss-lb:0.0813, loss-ulb:0.0040, weight:0.07, lr:0.0009
[23:20:42.239] iteration:1178  t-loss:0.1101, loss-lb:0.1085, loss-ulb:0.0249, weight:0.07, lr:0.0009
[23:20:43.353] iteration:1179  t-loss:0.0547, loss-lb:0.0514, loss-ulb:0.0497, weight:0.07, lr:0.0009
[23:20:43.736] iteration:1180  t-loss:0.0451, loss-lb:0.0433, loss-ulb:0.0269, weight:0.07, lr:0.0009
[23:20:44.114] iteration:1181  t-loss:0.0507, loss-lb:0.0495, loss-ulb:0.0178, weight:0.07, lr:0.0009
[23:20:44.494] iteration:1182  t-loss:0.0604, loss-lb:0.0596, loss-ulb:0.0115, weight:0.07, lr:0.0009
[23:20:44.870] iteration:1183  t-loss:0.0534, loss-lb:0.0511, loss-ulb:0.0357, weight:0.07, lr:0.0009
[23:20:45.242] iteration:1184  t-loss:0.0536, loss-lb:0.0524, loss-ulb:0.0181, weight:0.07, lr:0.0009
[23:20:45.620] iteration:1185  t-loss:0.0724, loss-lb:0.0706, loss-ulb:0.0273, weight:0.07, lr:0.0009
[23:20:45.998] iteration:1186  t-loss:0.0460, loss-lb:0.0445, loss-ulb:0.0238, weight:0.07, lr:0.0009
[23:20:46.381] iteration:1187  t-loss:0.1613, loss-lb:0.1598, loss-ulb:0.0238, weight:0.07, lr:0.0009
[23:20:46.762] iteration:1188  t-loss:0.0338, loss-lb:0.0286, loss-ulb:0.0777, weight:0.07, lr:0.0009
[23:20:47.134] iteration:1189  t-loss:0.0676, loss-lb:0.0673, loss-ulb:0.0046, weight:0.07, lr:0.0009
[23:20:47.509] iteration:1190  t-loss:0.1080, loss-lb:0.1076, loss-ulb:0.0056, weight:0.07, lr:0.0009
[23:20:47.869] iteration:1191  t-loss:0.0631, loss-lb:0.0618, loss-ulb:0.0198, weight:0.07, lr:0.0009
[23:20:48.243] iteration:1192  t-loss:0.0400, loss-lb:0.0384, loss-ulb:0.0247, weight:0.07, lr:0.0009
[23:20:48.612] iteration:1193  t-loss:0.0538, loss-lb:0.0520, loss-ulb:0.0275, weight:0.07, lr:0.0009
[23:20:48.989] iteration:1194  t-loss:0.0969, loss-lb:0.0967, loss-ulb:0.0026, weight:0.07, lr:0.0009
[23:20:49.361] iteration:1195  t-loss:0.0578, loss-lb:0.0561, loss-ulb:0.0255, weight:0.07, lr:0.0009
[23:20:49.732] iteration:1196  t-loss:0.0429, loss-lb:0.0421, loss-ulb:0.0125, weight:0.07, lr:0.0009
[23:20:50.104] iteration:1197  t-loss:0.0413, loss-lb:0.0390, loss-ulb:0.0354, weight:0.07, lr:0.0009
[23:20:50.487] iteration:1198  t-loss:0.0511, loss-lb:0.0503, loss-ulb:0.0129, weight:0.07, lr:0.0009
[23:20:50.880] iteration:1199  t-loss:0.0887, loss-lb:0.0882, loss-ulb:0.0073, weight:0.07, lr:0.0009
[23:20:51.275] iteration:1200  t-loss:0.0521, loss-lb:0.0506, loss-ulb:0.0219, weight:0.07, lr:0.0009
[23:20:51.659] iteration:1201  t-loss:0.0720, loss-lb:0.0687, loss-ulb:0.0396, weight:0.08, lr:0.0009
[23:20:52.037] iteration:1202  t-loss:0.0330, loss-lb:0.0301, loss-ulb:0.0352, weight:0.08, lr:0.0009
[23:20:52.409] iteration:1203  t-loss:0.0613, loss-lb:0.0608, loss-ulb:0.0059, weight:0.08, lr:0.0009
[23:20:52.781] iteration:1204  t-loss:0.0424, loss-lb:0.0376, loss-ulb:0.0586, weight:0.08, lr:0.0009
[23:20:53.160] iteration:1205  t-loss:0.0701, loss-lb:0.0624, loss-ulb:0.0943, weight:0.08, lr:0.0009
[23:20:53.535] iteration:1206  t-loss:0.0999, loss-lb:0.0975, loss-ulb:0.0289, weight:0.08, lr:0.0009
[23:20:53.911] iteration:1207  t-loss:0.0440, loss-lb:0.0436, loss-ulb:0.0043, weight:0.08, lr:0.0009
[23:20:54.288] iteration:1208  t-loss:0.0674, loss-lb:0.0655, loss-ulb:0.0233, weight:0.08, lr:0.0009
[23:20:54.669] iteration:1209  t-loss:0.0731, loss-lb:0.0710, loss-ulb:0.0258, weight:0.08, lr:0.0009
[23:20:55.039] iteration:1210  t-loss:0.0714, loss-lb:0.0697, loss-ulb:0.0203, weight:0.08, lr:0.0009
[23:20:55.410] iteration:1211  t-loss:0.0395, loss-lb:0.0384, loss-ulb:0.0145, weight:0.08, lr:0.0009
[23:20:55.786] iteration:1212  t-loss:0.0585, loss-lb:0.0543, loss-ulb:0.0515, weight:0.08, lr:0.0009
[23:20:56.159] iteration:1213  t-loss:0.0450, loss-lb:0.0430, loss-ulb:0.0238, weight:0.08, lr:0.0009
[23:20:56.533] iteration:1214  t-loss:0.0438, loss-lb:0.0427, loss-ulb:0.0129, weight:0.08, lr:0.0009
[23:20:56.908] iteration:1215  t-loss:0.1054, loss-lb:0.1048, loss-ulb:0.0085, weight:0.08, lr:0.0009
[23:20:57.284] iteration:1216  t-loss:0.0766, loss-lb:0.0743, loss-ulb:0.0288, weight:0.08, lr:0.0009
[23:20:58.422] iteration:1217  t-loss:0.0485, loss-lb:0.0464, loss-ulb:0.0258, weight:0.08, lr:0.0009
[23:20:58.811] iteration:1218  t-loss:0.0467, loss-lb:0.0395, loss-ulb:0.0894, weight:0.08, lr:0.0009
[23:20:59.189] iteration:1219  t-loss:0.0782, loss-lb:0.0761, loss-ulb:0.0261, weight:0.08, lr:0.0009
[23:20:59.559] iteration:1220  t-loss:0.0433, loss-lb:0.0420, loss-ulb:0.0164, weight:0.08, lr:0.0009
[23:20:59.936] iteration:1221  t-loss:0.0475, loss-lb:0.0456, loss-ulb:0.0235, weight:0.08, lr:0.0009
[23:21:00.310] iteration:1222  t-loss:0.0576, loss-lb:0.0556, loss-ulb:0.0244, weight:0.08, lr:0.0009
[23:21:00.685] iteration:1223  t-loss:0.0784, loss-lb:0.0781, loss-ulb:0.0033, weight:0.08, lr:0.0009
[23:21:01.061] iteration:1224  t-loss:0.0665, loss-lb:0.0582, loss-ulb:0.1026, weight:0.08, lr:0.0009
[23:21:01.440] iteration:1225  t-loss:0.0718, loss-lb:0.0676, loss-ulb:0.0515, weight:0.08, lr:0.0009
[23:21:01.814] iteration:1226  t-loss:0.0545, loss-lb:0.0521, loss-ulb:0.0292, weight:0.08, lr:0.0009
[23:21:02.189] iteration:1227  t-loss:0.0402, loss-lb:0.0391, loss-ulb:0.0137, weight:0.08, lr:0.0009
[23:21:02.569] iteration:1228  t-loss:0.1165, loss-lb:0.1147, loss-ulb:0.0224, weight:0.08, lr:0.0009
[23:21:02.941] iteration:1229  t-loss:0.0431, loss-lb:0.0417, loss-ulb:0.0166, weight:0.08, lr:0.0009
[23:21:03.311] iteration:1230  t-loss:0.0351, loss-lb:0.0348, loss-ulb:0.0045, weight:0.08, lr:0.0009
[23:21:03.687] iteration:1231  t-loss:0.0586, loss-lb:0.0557, loss-ulb:0.0345, weight:0.08, lr:0.0009
[23:21:04.061] iteration:1232  t-loss:0.0452, loss-lb:0.0424, loss-ulb:0.0334, weight:0.08, lr:0.0009
[23:21:04.432] iteration:1233  t-loss:0.0468, loss-lb:0.0437, loss-ulb:0.0381, weight:0.08, lr:0.0009
[23:21:04.805] iteration:1234  t-loss:0.0801, loss-lb:0.0755, loss-ulb:0.0568, weight:0.08, lr:0.0009
[23:21:05.175] iteration:1235  t-loss:0.0476, loss-lb:0.0417, loss-ulb:0.0722, weight:0.08, lr:0.0009
[23:21:05.559] iteration:1236  t-loss:0.0431, loss-lb:0.0413, loss-ulb:0.0227, weight:0.08, lr:0.0009
[23:21:05.955] iteration:1237  t-loss:0.0445, loss-lb:0.0427, loss-ulb:0.0218, weight:0.08, lr:0.0009
[23:21:06.353] iteration:1238  t-loss:0.0598, loss-lb:0.0583, loss-ulb:0.0174, weight:0.08, lr:0.0009
[23:21:06.734] iteration:1239  t-loss:0.0834, loss-lb:0.0791, loss-ulb:0.0528, weight:0.08, lr:0.0009
[23:21:07.107] iteration:1240  t-loss:0.0345, loss-lb:0.0316, loss-ulb:0.0355, weight:0.08, lr:0.0009
[23:21:07.483] iteration:1241  t-loss:0.1059, loss-lb:0.1041, loss-ulb:0.0214, weight:0.08, lr:0.0009
[23:21:07.859] iteration:1242  t-loss:0.0445, loss-lb:0.0432, loss-ulb:0.0160, weight:0.08, lr:0.0009
[23:21:08.236] iteration:1243  t-loss:0.0453, loss-lb:0.0446, loss-ulb:0.0082, weight:0.08, lr:0.0009
[23:21:08.614] iteration:1244  t-loss:0.0618, loss-lb:0.0593, loss-ulb:0.0310, weight:0.08, lr:0.0009
[23:21:08.994] iteration:1245  t-loss:0.0806, loss-lb:0.0787, loss-ulb:0.0231, weight:0.08, lr:0.0009
[23:21:09.368] iteration:1246  t-loss:0.0401, loss-lb:0.0395, loss-ulb:0.0077, weight:0.08, lr:0.0009
[23:21:09.742] iteration:1247  t-loss:0.0652, loss-lb:0.0642, loss-ulb:0.0119, weight:0.08, lr:0.0009
[23:21:10.117] iteration:1248  t-loss:0.0756, loss-lb:0.0721, loss-ulb:0.0434, weight:0.08, lr:0.0009
[23:21:10.491] iteration:1249  t-loss:0.1194, loss-lb:0.1138, loss-ulb:0.0686, weight:0.08, lr:0.0009
[23:21:10.863] iteration:1250  t-loss:0.0326, loss-lb:0.0306, loss-ulb:0.0243, weight:0.08, lr:0.0009
[23:21:11.232] iteration:1251  t-loss:0.0497, loss-lb:0.0466, loss-ulb:0.0379, weight:0.08, lr:0.0009
[23:21:11.605] iteration:1252  t-loss:0.0831, loss-lb:0.0765, loss-ulb:0.0808, weight:0.08, lr:0.0009
[23:21:11.977] iteration:1253  t-loss:0.0730, loss-lb:0.0668, loss-ulb:0.0761, weight:0.08, lr:0.0009
[23:21:12.353] iteration:1254  t-loss:0.0758, loss-lb:0.0742, loss-ulb:0.0203, weight:0.08, lr:0.0009
[23:22:12.831] iteration 1254 : dice_score: 0.660121 best_dice: 0.719700
[23:22:12.831]  <<Test>> - Ep:32  - Dice-S/T:57.98/66.01, Best-S:65.55, Best-T:71.97
[23:22:12.831]           - AvgLoss(lb/ulb/all):0.06/0.03/0.06
[23:22:14.017] iteration:1255  t-loss:0.1076, loss-lb:0.1062, loss-ulb:0.0170, weight:0.08, lr:0.0009
[23:22:14.410] iteration:1256  t-loss:0.0929, loss-lb:0.0910, loss-ulb:0.0234, weight:0.08, lr:0.0009
[23:22:14.794] iteration:1257  t-loss:0.0370, loss-lb:0.0357, loss-ulb:0.0154, weight:0.08, lr:0.0009
[23:22:15.192] iteration:1258  t-loss:0.0738, loss-lb:0.0736, loss-ulb:0.0030, weight:0.08, lr:0.0009
[23:22:15.569] iteration:1259  t-loss:0.0482, loss-lb:0.0456, loss-ulb:0.0318, weight:0.08, lr:0.0009
[23:22:15.940] iteration:1260  t-loss:0.0377, loss-lb:0.0318, loss-ulb:0.0724, weight:0.08, lr:0.0009
[23:22:16.315] iteration:1261  t-loss:0.0422, loss-lb:0.0416, loss-ulb:0.0064, weight:0.08, lr:0.0009
[23:22:16.696] iteration:1262  t-loss:0.0484, loss-lb:0.0460, loss-ulb:0.0299, weight:0.08, lr:0.0009
[23:22:17.070] iteration:1263  t-loss:0.0344, loss-lb:0.0322, loss-ulb:0.0273, weight:0.08, lr:0.0009
[23:22:17.447] iteration:1264  t-loss:0.0407, loss-lb:0.0404, loss-ulb:0.0029, weight:0.08, lr:0.0009
[23:22:17.829] iteration:1265  t-loss:0.1053, loss-lb:0.1035, loss-ulb:0.0213, weight:0.08, lr:0.0009
[23:22:18.202] iteration:1266  t-loss:0.0438, loss-lb:0.0436, loss-ulb:0.0026, weight:0.08, lr:0.0009
[23:22:18.576] iteration:1267  t-loss:0.0423, loss-lb:0.0409, loss-ulb:0.0162, weight:0.08, lr:0.0009
[23:22:18.952] iteration:1268  t-loss:0.0423, loss-lb:0.0410, loss-ulb:0.0154, weight:0.08, lr:0.0009
[23:22:19.345] iteration:1269  t-loss:0.0817, loss-lb:0.0803, loss-ulb:0.0175, weight:0.08, lr:0.0009
[23:22:19.728] iteration:1270  t-loss:0.0352, loss-lb:0.0346, loss-ulb:0.0063, weight:0.08, lr:0.0009
[23:22:20.109] iteration:1271  t-loss:0.0905, loss-lb:0.0883, loss-ulb:0.0264, weight:0.08, lr:0.0009
[23:22:20.485] iteration:1272  t-loss:0.0936, loss-lb:0.0920, loss-ulb:0.0204, weight:0.08, lr:0.0009
[23:22:20.872] iteration:1273  t-loss:0.0389, loss-lb:0.0368, loss-ulb:0.0252, weight:0.08, lr:0.0009
[23:22:21.252] iteration:1274  t-loss:0.0353, loss-lb:0.0328, loss-ulb:0.0305, weight:0.08, lr:0.0009
[23:22:21.628] iteration:1275  t-loss:0.0495, loss-lb:0.0480, loss-ulb:0.0187, weight:0.08, lr:0.0009
[23:22:22.008] iteration:1276  t-loss:0.0717, loss-lb:0.0677, loss-ulb:0.0483, weight:0.08, lr:0.0009
[23:22:22.383] iteration:1277  t-loss:0.0752, loss-lb:0.0732, loss-ulb:0.0248, weight:0.08, lr:0.0009
[23:22:22.777] iteration:1278  t-loss:0.0357, loss-lb:0.0329, loss-ulb:0.0344, weight:0.08, lr:0.0009
[23:22:23.169] iteration:1279  t-loss:0.0932, loss-lb:0.0892, loss-ulb:0.0497, weight:0.08, lr:0.0009
[23:22:23.556] iteration:1280  t-loss:0.0584, loss-lb:0.0563, loss-ulb:0.0258, weight:0.08, lr:0.0009
[23:22:23.947] iteration:1281  t-loss:0.1330, loss-lb:0.1322, loss-ulb:0.0100, weight:0.08, lr:0.0009
[23:22:24.326] iteration:1282  t-loss:0.0370, loss-lb:0.0348, loss-ulb:0.0278, weight:0.08, lr:0.0009
[23:22:24.699] iteration:1283  t-loss:0.0469, loss-lb:0.0464, loss-ulb:0.0052, weight:0.08, lr:0.0009
[23:22:25.078] iteration:1284  t-loss:0.0755, loss-lb:0.0739, loss-ulb:0.0204, weight:0.08, lr:0.0009
[23:22:25.469] iteration:1285  t-loss:0.0493, loss-lb:0.0488, loss-ulb:0.0060, weight:0.08, lr:0.0009
[23:22:25.843] iteration:1286  t-loss:0.0533, loss-lb:0.0488, loss-ulb:0.0554, weight:0.08, lr:0.0009
[23:22:26.217] iteration:1287  t-loss:0.0438, loss-lb:0.0418, loss-ulb:0.0245, weight:0.08, lr:0.0009
[23:22:26.589] iteration:1288  t-loss:0.0516, loss-lb:0.0484, loss-ulb:0.0388, weight:0.08, lr:0.0009
[23:22:26.965] iteration:1289  t-loss:0.0332, loss-lb:0.0300, loss-ulb:0.0389, weight:0.08, lr:0.0009
[23:22:27.335] iteration:1290  t-loss:0.0499, loss-lb:0.0492, loss-ulb:0.0079, weight:0.08, lr:0.0009
[23:22:27.705] iteration:1291  t-loss:0.0562, loss-lb:0.0559, loss-ulb:0.0043, weight:0.08, lr:0.0009
[23:22:28.075] iteration:1292  t-loss:0.1004, loss-lb:0.0998, loss-ulb:0.0066, weight:0.08, lr:0.0009
[23:22:29.315] iteration:1293  t-loss:0.0678, loss-lb:0.0658, loss-ulb:0.0250, weight:0.08, lr:0.0009
[23:22:29.705] iteration:1294  t-loss:0.0382, loss-lb:0.0371, loss-ulb:0.0139, weight:0.08, lr:0.0009
[23:22:30.089] iteration:1295  t-loss:0.0822, loss-lb:0.0794, loss-ulb:0.0349, weight:0.08, lr:0.0009
[23:22:30.472] iteration:1296  t-loss:0.0350, loss-lb:0.0327, loss-ulb:0.0283, weight:0.08, lr:0.0009
[23:22:30.853] iteration:1297  t-loss:0.0366, loss-lb:0.0350, loss-ulb:0.0195, weight:0.08, lr:0.0009
[23:22:31.237] iteration:1298  t-loss:0.0660, loss-lb:0.0638, loss-ulb:0.0272, weight:0.08, lr:0.0009
[23:22:31.625] iteration:1299  t-loss:0.1027, loss-lb:0.0993, loss-ulb:0.0424, weight:0.08, lr:0.0009
[23:22:32.010] iteration:1300  t-loss:0.0286, loss-lb:0.0254, loss-ulb:0.0396, weight:0.08, lr:0.0009
[23:22:32.389] iteration:1301  t-loss:0.0839, loss-lb:0.0814, loss-ulb:0.0307, weight:0.08, lr:0.0009
[23:22:32.765] iteration:1302  t-loss:0.0811, loss-lb:0.0807, loss-ulb:0.0048, weight:0.08, lr:0.0009
[23:22:33.144] iteration:1303  t-loss:0.0565, loss-lb:0.0521, loss-ulb:0.0541, weight:0.08, lr:0.0009
[23:22:33.518] iteration:1304  t-loss:0.0544, loss-lb:0.0512, loss-ulb:0.0397, weight:0.08, lr:0.0009
[23:22:33.892] iteration:1305  t-loss:0.0376, loss-lb:0.0356, loss-ulb:0.0256, weight:0.08, lr:0.0009
[23:22:34.271] iteration:1306  t-loss:0.0690, loss-lb:0.0681, loss-ulb:0.0112, weight:0.08, lr:0.0009
[23:22:34.649] iteration:1307  t-loss:0.0571, loss-lb:0.0554, loss-ulb:0.0208, weight:0.08, lr:0.0009
[23:22:35.026] iteration:1308  t-loss:0.0679, loss-lb:0.0673, loss-ulb:0.0071, weight:0.08, lr:0.0009
[23:22:35.398] iteration:1309  t-loss:0.0452, loss-lb:0.0449, loss-ulb:0.0039, weight:0.08, lr:0.0009
[23:22:35.777] iteration:1310  t-loss:0.0413, loss-lb:0.0407, loss-ulb:0.0073, weight:0.08, lr:0.0009
[23:22:36.161] iteration:1311  t-loss:0.0548, loss-lb:0.0541, loss-ulb:0.0081, weight:0.08, lr:0.0009
[23:22:36.533] iteration:1312  t-loss:0.0799, loss-lb:0.0778, loss-ulb:0.0256, weight:0.08, lr:0.0009
[23:22:36.905] iteration:1313  t-loss:0.0613, loss-lb:0.0602, loss-ulb:0.0136, weight:0.08, lr:0.0009
[23:22:37.284] iteration:1314  t-loss:0.0941, loss-lb:0.0916, loss-ulb:0.0304, weight:0.08, lr:0.0009
[23:22:37.663] iteration:1315  t-loss:0.1066, loss-lb:0.1040, loss-ulb:0.0318, weight:0.08, lr:0.0009
[23:22:38.051] iteration:1316  t-loss:0.0583, loss-lb:0.0564, loss-ulb:0.0231, weight:0.08, lr:0.0009
[23:22:38.438] iteration:1317  t-loss:0.1027, loss-lb:0.0959, loss-ulb:0.0834, weight:0.08, lr:0.0009
[23:22:38.828] iteration:1318  t-loss:0.0590, loss-lb:0.0577, loss-ulb:0.0152, weight:0.08, lr:0.0009
[23:22:39.216] iteration:1319  t-loss:0.0863, loss-lb:0.0843, loss-ulb:0.0241, weight:0.08, lr:0.0009
[23:22:39.585] iteration:1320  t-loss:0.0496, loss-lb:0.0491, loss-ulb:0.0064, weight:0.08, lr:0.0009
[23:22:39.970] iteration:1321  t-loss:0.0941, loss-lb:0.0929, loss-ulb:0.0147, weight:0.08, lr:0.0009
[23:22:40.351] iteration:1322  t-loss:0.0869, loss-lb:0.0858, loss-ulb:0.0134, weight:0.08, lr:0.0009
[23:22:40.728] iteration:1323  t-loss:0.0425, loss-lb:0.0421, loss-ulb:0.0046, weight:0.08, lr:0.0009
[23:22:41.097] iteration:1324  t-loss:0.0940, loss-lb:0.0913, loss-ulb:0.0338, weight:0.08, lr:0.0009
[23:22:41.471] iteration:1325  t-loss:0.0577, loss-lb:0.0528, loss-ulb:0.0604, weight:0.08, lr:0.0009
[23:22:41.847] iteration:1326  t-loss:0.1261, loss-lb:0.1224, loss-ulb:0.0453, weight:0.08, lr:0.0009
[23:22:42.222] iteration:1327  t-loss:0.0929, loss-lb:0.0909, loss-ulb:0.0250, weight:0.08, lr:0.0009
[23:22:42.590] iteration:1328  t-loss:0.0828, loss-lb:0.0812, loss-ulb:0.0199, weight:0.08, lr:0.0009
[23:22:42.959] iteration:1329  t-loss:0.0578, loss-lb:0.0560, loss-ulb:0.0229, weight:0.08, lr:0.0009
[23:22:43.327] iteration:1330  t-loss:0.0453, loss-lb:0.0439, loss-ulb:0.0176, weight:0.08, lr:0.0009
[23:22:44.684] iteration:1331  t-loss:0.0532, loss-lb:0.0494, loss-ulb:0.0455, weight:0.08, lr:0.0009
[23:22:45.066] iteration:1332  t-loss:0.1281, loss-lb:0.1272, loss-ulb:0.0115, weight:0.08, lr:0.0009
[23:22:45.457] iteration:1333  t-loss:0.0690, loss-lb:0.0649, loss-ulb:0.0502, weight:0.08, lr:0.0009
[23:22:45.834] iteration:1334  t-loss:0.1046, loss-lb:0.1013, loss-ulb:0.0403, weight:0.08, lr:0.0009
[23:22:46.209] iteration:1335  t-loss:0.1045, loss-lb:0.1026, loss-ulb:0.0233, weight:0.08, lr:0.0009
[23:22:46.588] iteration:1336  t-loss:0.0761, loss-lb:0.0744, loss-ulb:0.0210, weight:0.08, lr:0.0009
[23:22:46.967] iteration:1337  t-loss:0.0602, loss-lb:0.0583, loss-ulb:0.0233, weight:0.08, lr:0.0009
[23:22:47.344] iteration:1338  t-loss:0.0672, loss-lb:0.0654, loss-ulb:0.0221, weight:0.08, lr:0.0009
[23:22:47.726] iteration:1339  t-loss:0.1275, loss-lb:0.1270, loss-ulb:0.0069, weight:0.08, lr:0.0009
[23:22:48.099] iteration:1340  t-loss:0.0665, loss-lb:0.0649, loss-ulb:0.0185, weight:0.08, lr:0.0009
[23:22:48.477] iteration:1341  t-loss:0.0719, loss-lb:0.0684, loss-ulb:0.0424, weight:0.08, lr:0.0009
[23:22:48.849] iteration:1342  t-loss:0.0951, loss-lb:0.0924, loss-ulb:0.0330, weight:0.08, lr:0.0009
[23:22:49.227] iteration:1343  t-loss:0.0860, loss-lb:0.0820, loss-ulb:0.0495, weight:0.08, lr:0.0009
[23:22:49.601] iteration:1344  t-loss:0.0355, loss-lb:0.0346, loss-ulb:0.0117, weight:0.08, lr:0.0009
[23:22:49.973] iteration:1345  t-loss:0.0428, loss-lb:0.0412, loss-ulb:0.0200, weight:0.08, lr:0.0009
[23:22:50.349] iteration:1346  t-loss:0.1264, loss-lb:0.1240, loss-ulb:0.0295, weight:0.08, lr:0.0009
[23:22:50.725] iteration:1347  t-loss:0.1281, loss-lb:0.1274, loss-ulb:0.0091, weight:0.08, lr:0.0009
[23:22:51.100] iteration:1348  t-loss:0.0804, loss-lb:0.0800, loss-ulb:0.0057, weight:0.08, lr:0.0009
[23:22:51.477] iteration:1349  t-loss:0.0728, loss-lb:0.0693, loss-ulb:0.0422, weight:0.08, lr:0.0009
[23:22:51.852] iteration:1350  t-loss:0.1232, loss-lb:0.1215, loss-ulb:0.0209, weight:0.08, lr:0.0009
[23:22:52.225] iteration:1351  t-loss:0.0959, loss-lb:0.0947, loss-ulb:0.0120, weight:0.10, lr:0.0009
[23:22:52.599] iteration:1352  t-loss:0.0758, loss-lb:0.0751, loss-ulb:0.0070, weight:0.10, lr:0.0009
[23:22:52.988] iteration:1353  t-loss:0.0609, loss-lb:0.0591, loss-ulb:0.0186, weight:0.10, lr:0.0009
[23:22:53.384] iteration:1354  t-loss:0.0779, loss-lb:0.0739, loss-ulb:0.0396, weight:0.10, lr:0.0009
[23:22:53.783] iteration:1355  t-loss:0.0901, loss-lb:0.0879, loss-ulb:0.0216, weight:0.10, lr:0.0009
[23:22:54.165] iteration:1356  t-loss:0.0482, loss-lb:0.0439, loss-ulb:0.0431, weight:0.10, lr:0.0009
[23:22:54.538] iteration:1357  t-loss:0.0509, loss-lb:0.0435, loss-ulb:0.0741, weight:0.10, lr:0.0009
[23:22:54.911] iteration:1358  t-loss:0.0575, loss-lb:0.0553, loss-ulb:0.0214, weight:0.10, lr:0.0009
[23:22:55.286] iteration:1359  t-loss:0.0429, loss-lb:0.0403, loss-ulb:0.0269, weight:0.10, lr:0.0009
[23:22:55.661] iteration:1360  t-loss:0.1045, loss-lb:0.1007, loss-ulb:0.0381, weight:0.10, lr:0.0009
[23:22:56.032] iteration:1361  t-loss:0.0759, loss-lb:0.0746, loss-ulb:0.0123, weight:0.10, lr:0.0009
[23:22:56.405] iteration:1362  t-loss:0.0934, loss-lb:0.0867, loss-ulb:0.0677, weight:0.10, lr:0.0009
[23:22:56.778] iteration:1363  t-loss:0.0678, loss-lb:0.0650, loss-ulb:0.0290, weight:0.10, lr:0.0009
[23:22:57.150] iteration:1364  t-loss:0.0624, loss-lb:0.0593, loss-ulb:0.0304, weight:0.10, lr:0.0009
[23:22:57.519] iteration:1365  t-loss:0.0983, loss-lb:0.0972, loss-ulb:0.0112, weight:0.10, lr:0.0009
[23:22:57.892] iteration:1366  t-loss:0.0856, loss-lb:0.0848, loss-ulb:0.0082, weight:0.10, lr:0.0009
[23:22:58.264] iteration:1367  t-loss:0.1329, loss-lb:0.1310, loss-ulb:0.0195, weight:0.10, lr:0.0009
[23:22:58.632] iteration:1368  t-loss:0.0439, loss-lb:0.0425, loss-ulb:0.0147, weight:0.10, lr:0.0009
[23:22:59.795] iteration:1369  t-loss:0.0840, loss-lb:0.0802, loss-ulb:0.0384, weight:0.10, lr:0.0009
[23:23:00.173] iteration:1370  t-loss:0.0492, loss-lb:0.0479, loss-ulb:0.0124, weight:0.10, lr:0.0009
[23:23:00.551] iteration:1371  t-loss:0.1683, loss-lb:0.1679, loss-ulb:0.0034, weight:0.10, lr:0.0009
[23:23:00.929] iteration:1372  t-loss:0.0611, loss-lb:0.0596, loss-ulb:0.0149, weight:0.10, lr:0.0009
[23:23:01.306] iteration:1373  t-loss:0.0542, loss-lb:0.0527, loss-ulb:0.0148, weight:0.10, lr:0.0009
[23:23:01.679] iteration:1374  t-loss:0.0533, loss-lb:0.0483, loss-ulb:0.0498, weight:0.10, lr:0.0009
[23:23:02.056] iteration:1375  t-loss:0.0754, loss-lb:0.0746, loss-ulb:0.0079, weight:0.10, lr:0.0009
[23:23:02.435] iteration:1376  t-loss:0.0499, loss-lb:0.0468, loss-ulb:0.0312, weight:0.10, lr:0.0009
[23:23:02.812] iteration:1377  t-loss:0.0715, loss-lb:0.0696, loss-ulb:0.0184, weight:0.10, lr:0.0009
[23:23:03.185] iteration:1378  t-loss:0.1244, loss-lb:0.1225, loss-ulb:0.0189, weight:0.10, lr:0.0009
[23:23:03.562] iteration:1379  t-loss:0.0388, loss-lb:0.0360, loss-ulb:0.0280, weight:0.10, lr:0.0009
[23:23:03.940] iteration:1380  t-loss:0.0671, loss-lb:0.0646, loss-ulb:0.0247, weight:0.10, lr:0.0009
[23:23:04.322] iteration:1381  t-loss:0.1262, loss-lb:0.1247, loss-ulb:0.0152, weight:0.10, lr:0.0009
[23:23:04.700] iteration:1382  t-loss:0.0784, loss-lb:0.0777, loss-ulb:0.0065, weight:0.10, lr:0.0009
[23:23:05.071] iteration:1383  t-loss:0.0763, loss-lb:0.0757, loss-ulb:0.0060, weight:0.10, lr:0.0009
[23:23:05.442] iteration:1384  t-loss:0.0579, loss-lb:0.0516, loss-ulb:0.0639, weight:0.10, lr:0.0009
[23:23:05.815] iteration:1385  t-loss:0.0951, loss-lb:0.0910, loss-ulb:0.0412, weight:0.10, lr:0.0009
[23:23:06.186] iteration:1386  t-loss:0.0739, loss-lb:0.0717, loss-ulb:0.0224, weight:0.10, lr:0.0009
[23:23:06.560] iteration:1387  t-loss:0.0603, loss-lb:0.0582, loss-ulb:0.0211, weight:0.10, lr:0.0009
[23:23:06.933] iteration:1388  t-loss:0.0663, loss-lb:0.0636, loss-ulb:0.0270, weight:0.10, lr:0.0009
[23:23:07.309] iteration:1389  t-loss:0.0621, loss-lb:0.0596, loss-ulb:0.0250, weight:0.10, lr:0.0009
[23:23:07.680] iteration:1390  t-loss:0.0753, loss-lb:0.0725, loss-ulb:0.0276, weight:0.10, lr:0.0009
[23:23:08.054] iteration:1391  t-loss:0.0402, loss-lb:0.0393, loss-ulb:0.0094, weight:0.10, lr:0.0009
[23:23:08.454] iteration:1392  t-loss:0.0447, loss-lb:0.0435, loss-ulb:0.0113, weight:0.10, lr:0.0009
[23:23:08.846] iteration:1393  t-loss:0.0858, loss-lb:0.0845, loss-ulb:0.0133, weight:0.10, lr:0.0009
[23:23:09.226] iteration:1394  t-loss:0.0685, loss-lb:0.0656, loss-ulb:0.0288, weight:0.10, lr:0.0009
[23:23:09.605] iteration:1395  t-loss:0.0641, loss-lb:0.0607, loss-ulb:0.0343, weight:0.10, lr:0.0009
[23:23:09.978] iteration:1396  t-loss:0.0857, loss-lb:0.0836, loss-ulb:0.0212, weight:0.10, lr:0.0009
[23:23:10.352] iteration:1397  t-loss:0.0409, loss-lb:0.0382, loss-ulb:0.0267, weight:0.10, lr:0.0009
[23:23:10.729] iteration:1398  t-loss:0.0783, loss-lb:0.0732, loss-ulb:0.0516, weight:0.10, lr:0.0009
[23:23:11.100] iteration:1399  t-loss:0.0776, loss-lb:0.0738, loss-ulb:0.0383, weight:0.10, lr:0.0009
[23:23:11.474] iteration:1400  t-loss:0.0639, loss-lb:0.0623, loss-ulb:0.0163, weight:0.10, lr:0.0009
[23:23:11.852] iteration:1401  t-loss:0.0761, loss-lb:0.0620, loss-ulb:0.1419, weight:0.10, lr:0.0009
[23:23:12.228] iteration:1402  t-loss:0.1122, loss-lb:0.1113, loss-ulb:0.0086, weight:0.10, lr:0.0009
[23:23:12.604] iteration:1403  t-loss:0.0733, loss-lb:0.0717, loss-ulb:0.0158, weight:0.10, lr:0.0009
[23:23:12.973] iteration:1404  t-loss:0.0451, loss-lb:0.0442, loss-ulb:0.0099, weight:0.10, lr:0.0009
[23:23:13.345] iteration:1405  t-loss:0.0758, loss-lb:0.0664, loss-ulb:0.0953, weight:0.10, lr:0.0009
[23:23:13.720] iteration:1406  t-loss:0.0368, loss-lb:0.0349, loss-ulb:0.0200, weight:0.10, lr:0.0009
[23:24:12.248] iteration 1406 : dice_score: 0.695105 best_dice: 0.719700
[23:24:12.248]  <<Test>> - Ep:36  - Dice-S/T:66.85/69.51, Best-S:66.85, Best-T:71.97
[23:24:12.249]           - AvgLoss(lb/ulb/all):0.07/0.03/0.07
[23:24:13.374] iteration:1407  t-loss:0.0733, loss-lb:0.0713, loss-ulb:0.0205, weight:0.10, lr:0.0009
[23:24:13.827] iteration:1408  t-loss:0.0405, loss-lb:0.0375, loss-ulb:0.0295, weight:0.10, lr:0.0009
[23:24:14.211] iteration:1409  t-loss:0.1067, loss-lb:0.0997, loss-ulb:0.0711, weight:0.10, lr:0.0009
[23:24:14.593] iteration:1410  t-loss:0.0320, loss-lb:0.0318, loss-ulb:0.0017, weight:0.10, lr:0.0009
[23:24:14.970] iteration:1411  t-loss:0.0340, loss-lb:0.0325, loss-ulb:0.0146, weight:0.10, lr:0.0009
[23:24:15.353] iteration:1412  t-loss:0.1545, loss-lb:0.1492, loss-ulb:0.0536, weight:0.10, lr:0.0009
[23:24:15.729] iteration:1413  t-loss:0.1142, loss-lb:0.1126, loss-ulb:0.0161, weight:0.10, lr:0.0009
[23:24:16.107] iteration:1414  t-loss:0.0383, loss-lb:0.0370, loss-ulb:0.0126, weight:0.10, lr:0.0009
[23:24:16.490] iteration:1415  t-loss:0.0642, loss-lb:0.0626, loss-ulb:0.0160, weight:0.10, lr:0.0009
[23:24:16.869] iteration:1416  t-loss:0.0425, loss-lb:0.0389, loss-ulb:0.0367, weight:0.10, lr:0.0009
[23:24:17.249] iteration:1417  t-loss:0.0877, loss-lb:0.0731, loss-ulb:0.1466, weight:0.10, lr:0.0009
[23:24:17.624] iteration:1418  t-loss:0.0586, loss-lb:0.0579, loss-ulb:0.0075, weight:0.10, lr:0.0009
[23:24:18.000] iteration:1419  t-loss:0.0427, loss-lb:0.0418, loss-ulb:0.0090, weight:0.10, lr:0.0009
[23:24:18.383] iteration:1420  t-loss:0.0909, loss-lb:0.0890, loss-ulb:0.0187, weight:0.10, lr:0.0009
[23:24:18.762] iteration:1421  t-loss:0.0742, loss-lb:0.0667, loss-ulb:0.0755, weight:0.10, lr:0.0009
[23:24:19.156] iteration:1422  t-loss:0.0660, loss-lb:0.0640, loss-ulb:0.0201, weight:0.10, lr:0.0009
[23:24:19.535] iteration:1423  t-loss:0.0773, loss-lb:0.0758, loss-ulb:0.0150, weight:0.10, lr:0.0009
[23:24:19.914] iteration:1424  t-loss:0.0432, loss-lb:0.0417, loss-ulb:0.0152, weight:0.10, lr:0.0009
[23:24:20.293] iteration:1425  t-loss:0.0490, loss-lb:0.0468, loss-ulb:0.0229, weight:0.10, lr:0.0009
[23:24:20.663] iteration:1426  t-loss:0.0461, loss-lb:0.0437, loss-ulb:0.0243, weight:0.10, lr:0.0009
[23:24:21.042] iteration:1427  t-loss:0.1176, loss-lb:0.1154, loss-ulb:0.0222, weight:0.10, lr:0.0009
[23:24:21.417] iteration:1428  t-loss:0.0651, loss-lb:0.0642, loss-ulb:0.0083, weight:0.10, lr:0.0009
[23:24:21.788] iteration:1429  t-loss:0.0396, loss-lb:0.0368, loss-ulb:0.0281, weight:0.10, lr:0.0009
[23:24:22.168] iteration:1430  t-loss:0.0372, loss-lb:0.0345, loss-ulb:0.0275, weight:0.10, lr:0.0009
[23:24:22.544] iteration:1431  t-loss:0.0941, loss-lb:0.0922, loss-ulb:0.0198, weight:0.10, lr:0.0009
[23:24:22.951] iteration:1432  t-loss:0.0894, loss-lb:0.0869, loss-ulb:0.0250, weight:0.10, lr:0.0009
[23:24:23.382] iteration:1433  t-loss:0.0440, loss-lb:0.0430, loss-ulb:0.0103, weight:0.10, lr:0.0009
[23:24:23.790] iteration:1434  t-loss:0.0514, loss-lb:0.0506, loss-ulb:0.0078, weight:0.10, lr:0.0009
[23:24:24.207] iteration:1435  t-loss:0.1083, loss-lb:0.1066, loss-ulb:0.0166, weight:0.10, lr:0.0009
[23:24:24.614] iteration:1436  t-loss:0.0325, loss-lb:0.0318, loss-ulb:0.0071, weight:0.10, lr:0.0009
[23:24:25.003] iteration:1437  t-loss:0.0714, loss-lb:0.0691, loss-ulb:0.0230, weight:0.10, lr:0.0009
[23:24:25.377] iteration:1438  t-loss:0.0589, loss-lb:0.0570, loss-ulb:0.0196, weight:0.10, lr:0.0009
[23:24:25.747] iteration:1439  t-loss:0.0676, loss-lb:0.0644, loss-ulb:0.0331, weight:0.10, lr:0.0009
[23:24:26.121] iteration:1440  t-loss:0.0404, loss-lb:0.0373, loss-ulb:0.0309, weight:0.10, lr:0.0009
[23:24:26.490] iteration:1441  t-loss:0.0482, loss-lb:0.0434, loss-ulb:0.0485, weight:0.10, lr:0.0009
[23:24:26.864] iteration:1442  t-loss:0.0675, loss-lb:0.0653, loss-ulb:0.0224, weight:0.10, lr:0.0009
[23:24:27.234] iteration:1443  t-loss:0.0405, loss-lb:0.0384, loss-ulb:0.0209, weight:0.10, lr:0.0009
[23:24:27.608] iteration:1444  t-loss:0.0655, loss-lb:0.0609, loss-ulb:0.0464, weight:0.10, lr:0.0009
[23:24:28.870] iteration:1445  t-loss:0.0801, loss-lb:0.0773, loss-ulb:0.0287, weight:0.10, lr:0.0009
[23:24:29.297] iteration:1446  t-loss:0.0754, loss-lb:0.0703, loss-ulb:0.0507, weight:0.10, lr:0.0009
[23:24:29.707] iteration:1447  t-loss:0.0713, loss-lb:0.0702, loss-ulb:0.0116, weight:0.10, lr:0.0009
[23:24:30.095] iteration:1448  t-loss:0.0932, loss-lb:0.0910, loss-ulb:0.0212, weight:0.10, lr:0.0009
[23:24:30.479] iteration:1449  t-loss:0.0755, loss-lb:0.0720, loss-ulb:0.0355, weight:0.10, lr:0.0009
[23:24:30.860] iteration:1450  t-loss:0.0553, loss-lb:0.0527, loss-ulb:0.0265, weight:0.10, lr:0.0009
[23:24:31.238] iteration:1451  t-loss:0.0357, loss-lb:0.0335, loss-ulb:0.0214, weight:0.10, lr:0.0009
[23:24:31.621] iteration:1452  t-loss:0.0997, loss-lb:0.0990, loss-ulb:0.0061, weight:0.10, lr:0.0009
[23:24:31.999] iteration:1453  t-loss:0.0469, loss-lb:0.0432, loss-ulb:0.0366, weight:0.10, lr:0.0009
[23:24:32.376] iteration:1454  t-loss:0.0606, loss-lb:0.0603, loss-ulb:0.0035, weight:0.10, lr:0.0009
[23:24:32.757] iteration:1455  t-loss:0.0713, loss-lb:0.0710, loss-ulb:0.0038, weight:0.10, lr:0.0009
[23:24:33.135] iteration:1456  t-loss:0.0777, loss-lb:0.0760, loss-ulb:0.0172, weight:0.10, lr:0.0009
[23:24:33.508] iteration:1457  t-loss:0.0590, loss-lb:0.0570, loss-ulb:0.0202, weight:0.10, lr:0.0009
[23:24:33.888] iteration:1458  t-loss:0.0261, loss-lb:0.0219, loss-ulb:0.0425, weight:0.10, lr:0.0009
[23:24:34.263] iteration:1459  t-loss:0.0451, loss-lb:0.0426, loss-ulb:0.0246, weight:0.10, lr:0.0009
[23:24:34.639] iteration:1460  t-loss:0.0746, loss-lb:0.0724, loss-ulb:0.0226, weight:0.10, lr:0.0009
[23:24:35.023] iteration:1461  t-loss:0.0712, loss-lb:0.0695, loss-ulb:0.0176, weight:0.10, lr:0.0009
[23:24:35.402] iteration:1462  t-loss:0.0694, loss-lb:0.0684, loss-ulb:0.0101, weight:0.10, lr:0.0009
[23:24:35.778] iteration:1463  t-loss:0.0327, loss-lb:0.0299, loss-ulb:0.0276, weight:0.10, lr:0.0009
[23:24:36.154] iteration:1464  t-loss:0.0505, loss-lb:0.0467, loss-ulb:0.0392, weight:0.10, lr:0.0009
[23:24:36.526] iteration:1465  t-loss:0.0323, loss-lb:0.0314, loss-ulb:0.0089, weight:0.10, lr:0.0009
[23:24:36.904] iteration:1466  t-loss:0.0546, loss-lb:0.0523, loss-ulb:0.0231, weight:0.10, lr:0.0009
[23:24:37.276] iteration:1467  t-loss:0.1097, loss-lb:0.1095, loss-ulb:0.0016, weight:0.10, lr:0.0009
[23:24:37.653] iteration:1468  t-loss:0.0614, loss-lb:0.0598, loss-ulb:0.0156, weight:0.10, lr:0.0009
[23:24:38.025] iteration:1469  t-loss:0.0778, loss-lb:0.0750, loss-ulb:0.0276, weight:0.10, lr:0.0009
[23:24:38.416] iteration:1470  t-loss:0.0801, loss-lb:0.0773, loss-ulb:0.0279, weight:0.10, lr:0.0009
[23:24:38.825] iteration:1471  t-loss:0.0543, loss-lb:0.0519, loss-ulb:0.0243, weight:0.10, lr:0.0009
[23:24:39.220] iteration:1472  t-loss:0.0537, loss-lb:0.0444, loss-ulb:0.0931, weight:0.10, lr:0.0009
[23:24:39.605] iteration:1473  t-loss:0.0868, loss-lb:0.0773, loss-ulb:0.0954, weight:0.10, lr:0.0009
[23:24:39.992] iteration:1474  t-loss:0.1167, loss-lb:0.1154, loss-ulb:0.0136, weight:0.10, lr:0.0009
[23:24:40.374] iteration:1475  t-loss:0.0500, loss-lb:0.0458, loss-ulb:0.0426, weight:0.10, lr:0.0009
[23:24:40.748] iteration:1476  t-loss:0.1350, loss-lb:0.1334, loss-ulb:0.0168, weight:0.10, lr:0.0009
[23:24:41.118] iteration:1477  t-loss:0.0439, loss-lb:0.0375, loss-ulb:0.0638, weight:0.10, lr:0.0009
[23:24:41.487] iteration:1478  t-loss:0.0469, loss-lb:0.0420, loss-ulb:0.0499, weight:0.10, lr:0.0009
[23:24:41.859] iteration:1479  t-loss:0.0581, loss-lb:0.0570, loss-ulb:0.0117, weight:0.10, lr:0.0009
[23:24:42.230] iteration:1480  t-loss:0.0583, loss-lb:0.0548, loss-ulb:0.0344, weight:0.10, lr:0.0009
[23:24:42.603] iteration:1481  t-loss:0.0886, loss-lb:0.0759, loss-ulb:0.1273, weight:0.10, lr:0.0009
[23:24:42.971] iteration:1482  t-loss:0.1288, loss-lb:0.1167, loss-ulb:0.1222, weight:0.10, lr:0.0009
[23:24:44.358] iteration:1483  t-loss:0.0711, loss-lb:0.0691, loss-ulb:0.0199, weight:0.10, lr:0.0009
[23:24:44.758] iteration:1484  t-loss:0.0733, loss-lb:0.0707, loss-ulb:0.0262, weight:0.10, lr:0.0009
[23:24:45.136] iteration:1485  t-loss:0.0798, loss-lb:0.0789, loss-ulb:0.0096, weight:0.10, lr:0.0009
[23:24:45.515] iteration:1486  t-loss:0.0377, loss-lb:0.0357, loss-ulb:0.0204, weight:0.10, lr:0.0009
[23:24:45.893] iteration:1487  t-loss:0.0443, loss-lb:0.0408, loss-ulb:0.0353, weight:0.10, lr:0.0009
[23:24:46.266] iteration:1488  t-loss:0.0348, loss-lb:0.0309, loss-ulb:0.0398, weight:0.10, lr:0.0009
[23:24:46.643] iteration:1489  t-loss:0.0947, loss-lb:0.0901, loss-ulb:0.0459, weight:0.10, lr:0.0009
[23:24:47.018] iteration:1490  t-loss:0.0344, loss-lb:0.0309, loss-ulb:0.0350, weight:0.10, lr:0.0009
[23:24:47.391] iteration:1491  t-loss:0.0354, loss-lb:0.0347, loss-ulb:0.0063, weight:0.10, lr:0.0009
[23:24:47.766] iteration:1492  t-loss:0.0940, loss-lb:0.0935, loss-ulb:0.0048, weight:0.10, lr:0.0009
[23:24:48.146] iteration:1493  t-loss:0.0632, loss-lb:0.0608, loss-ulb:0.0246, weight:0.10, lr:0.0009
[23:24:48.522] iteration:1494  t-loss:0.0541, loss-lb:0.0534, loss-ulb:0.0069, weight:0.10, lr:0.0009
[23:24:48.902] iteration:1495  t-loss:0.0809, loss-lb:0.0792, loss-ulb:0.0163, weight:0.10, lr:0.0009
[23:24:49.284] iteration:1496  t-loss:0.0388, loss-lb:0.0355, loss-ulb:0.0329, weight:0.10, lr:0.0009
[23:24:49.662] iteration:1497  t-loss:0.0297, loss-lb:0.0281, loss-ulb:0.0154, weight:0.10, lr:0.0009
[23:24:50.035] iteration:1498  t-loss:0.0648, loss-lb:0.0642, loss-ulb:0.0058, weight:0.10, lr:0.0009
[23:24:50.410] iteration:1499  t-loss:0.0756, loss-lb:0.0751, loss-ulb:0.0045, weight:0.10, lr:0.0009
[23:24:50.779] iteration:1500  t-loss:0.0430, loss-lb:0.0411, loss-ulb:0.0190, weight:0.10, lr:0.0009
[23:24:51.152] iteration:1501  t-loss:0.0328, loss-lb:0.0296, loss-ulb:0.0274, weight:0.12, lr:0.0009
[23:24:51.526] iteration:1502  t-loss:0.1110, loss-lb:0.1104, loss-ulb:0.0052, weight:0.12, lr:0.0009
[23:24:51.899] iteration:1503  t-loss:0.0326, loss-lb:0.0311, loss-ulb:0.0126, weight:0.12, lr:0.0009
[23:24:52.271] iteration:1504  t-loss:0.1125, loss-lb:0.1111, loss-ulb:0.0120, weight:0.12, lr:0.0009
[23:24:52.640] iteration:1505  t-loss:0.0452, loss-lb:0.0417, loss-ulb:0.0291, weight:0.12, lr:0.0009
[23:24:53.015] iteration:1506  t-loss:0.0377, loss-lb:0.0344, loss-ulb:0.0278, weight:0.12, lr:0.0009
[23:24:53.391] iteration:1507  t-loss:0.0386, loss-lb:0.0350, loss-ulb:0.0302, weight:0.12, lr:0.0009
[23:24:53.778] iteration:1508  t-loss:0.0442, loss-lb:0.0410, loss-ulb:0.0266, weight:0.12, lr:0.0009
[23:24:54.179] iteration:1509  t-loss:0.0762, loss-lb:0.0734, loss-ulb:0.0231, weight:0.12, lr:0.0009
[23:24:54.584] iteration:1510  t-loss:0.0580, loss-lb:0.0563, loss-ulb:0.0141, weight:0.12, lr:0.0009
[23:24:54.967] iteration:1511  t-loss:0.0736, loss-lb:0.0716, loss-ulb:0.0171, weight:0.12, lr:0.0009
[23:24:55.348] iteration:1512  t-loss:0.0530, loss-lb:0.0511, loss-ulb:0.0161, weight:0.12, lr:0.0009
[23:24:55.736] iteration:1513  t-loss:0.0549, loss-lb:0.0546, loss-ulb:0.0028, weight:0.12, lr:0.0009
[23:24:56.114] iteration:1514  t-loss:0.1235, loss-lb:0.1198, loss-ulb:0.0304, weight:0.12, lr:0.0009
[23:24:56.484] iteration:1515  t-loss:0.0341, loss-lb:0.0267, loss-ulb:0.0614, weight:0.12, lr:0.0009
[23:24:56.856] iteration:1516  t-loss:0.0973, loss-lb:0.0936, loss-ulb:0.0302, weight:0.12, lr:0.0009
[23:24:57.226] iteration:1517  t-loss:0.1168, loss-lb:0.1157, loss-ulb:0.0095, weight:0.12, lr:0.0009
[23:24:57.598] iteration:1518  t-loss:0.0485, loss-lb:0.0411, loss-ulb:0.0609, weight:0.12, lr:0.0009
[23:24:57.968] iteration:1519  t-loss:0.1007, loss-lb:0.0983, loss-ulb:0.0198, weight:0.12, lr:0.0009
[23:24:58.341] iteration:1520  t-loss:0.0703, loss-lb:0.0682, loss-ulb:0.0172, weight:0.12, lr:0.0009
[23:24:59.535] iteration:1521  t-loss:0.0778, loss-lb:0.0746, loss-ulb:0.0269, weight:0.12, lr:0.0009
[23:24:59.947] iteration:1522  t-loss:0.0805, loss-lb:0.0781, loss-ulb:0.0202, weight:0.12, lr:0.0009
[23:25:00.330] iteration:1523  t-loss:0.0701, loss-lb:0.0644, loss-ulb:0.0472, weight:0.12, lr:0.0009
[23:25:00.709] iteration:1524  t-loss:0.0810, loss-lb:0.0798, loss-ulb:0.0096, weight:0.12, lr:0.0009
[23:25:01.083] iteration:1525  t-loss:0.0342, loss-lb:0.0333, loss-ulb:0.0078, weight:0.12, lr:0.0009
[23:25:01.459] iteration:1526  t-loss:0.0527, loss-lb:0.0458, loss-ulb:0.0575, weight:0.12, lr:0.0009
[23:25:01.832] iteration:1527  t-loss:0.0495, loss-lb:0.0462, loss-ulb:0.0274, weight:0.12, lr:0.0009
[23:25:02.207] iteration:1528  t-loss:0.0682, loss-lb:0.0517, loss-ulb:0.1373, weight:0.12, lr:0.0009
[23:25:02.583] iteration:1529  t-loss:0.0393, loss-lb:0.0336, loss-ulb:0.0476, weight:0.12, lr:0.0009
[23:25:02.962] iteration:1530  t-loss:0.0875, loss-lb:0.0867, loss-ulb:0.0064, weight:0.12, lr:0.0009
[23:25:03.340] iteration:1531  t-loss:0.0671, loss-lb:0.0647, loss-ulb:0.0203, weight:0.12, lr:0.0009
[23:25:03.717] iteration:1532  t-loss:0.0404, loss-lb:0.0388, loss-ulb:0.0133, weight:0.12, lr:0.0009
[23:25:04.090] iteration:1533  t-loss:0.0724, loss-lb:0.0715, loss-ulb:0.0074, weight:0.12, lr:0.0009
[23:25:04.473] iteration:1534  t-loss:0.0526, loss-lb:0.0512, loss-ulb:0.0114, weight:0.12, lr:0.0009
[23:25:04.849] iteration:1535  t-loss:0.0484, loss-lb:0.0434, loss-ulb:0.0418, weight:0.12, lr:0.0009
[23:25:05.236] iteration:1536  t-loss:0.0903, loss-lb:0.0865, loss-ulb:0.0311, weight:0.12, lr:0.0009
[23:25:05.617] iteration:1537  t-loss:0.0810, loss-lb:0.0786, loss-ulb:0.0199, weight:0.12, lr:0.0009
[23:25:05.988] iteration:1538  t-loss:0.1158, loss-lb:0.1143, loss-ulb:0.0125, weight:0.12, lr:0.0009
[23:25:06.356] iteration:1539  t-loss:0.0513, loss-lb:0.0425, loss-ulb:0.0733, weight:0.12, lr:0.0009
[23:25:06.731] iteration:1540  t-loss:0.0595, loss-lb:0.0564, loss-ulb:0.0253, weight:0.12, lr:0.0009
[23:25:07.104] iteration:1541  t-loss:0.0372, loss-lb:0.0351, loss-ulb:0.0169, weight:0.12, lr:0.0009
[23:25:07.478] iteration:1542  t-loss:0.0381, loss-lb:0.0368, loss-ulb:0.0106, weight:0.12, lr:0.0009
[23:25:07.846] iteration:1543  t-loss:0.0402, loss-lb:0.0378, loss-ulb:0.0202, weight:0.12, lr:0.0009
[23:25:08.216] iteration:1544  t-loss:0.0366, loss-lb:0.0356, loss-ulb:0.0082, weight:0.12, lr:0.0009
[23:25:08.588] iteration:1545  t-loss:0.0397, loss-lb:0.0359, loss-ulb:0.0311, weight:0.12, lr:0.0009
[23:25:08.974] iteration:1546  t-loss:0.0426, loss-lb:0.0362, loss-ulb:0.0536, weight:0.12, lr:0.0009
[23:25:09.376] iteration:1547  t-loss:0.0779, loss-lb:0.0754, loss-ulb:0.0212, weight:0.12, lr:0.0009
[23:25:09.778] iteration:1548  t-loss:0.0801, loss-lb:0.0784, loss-ulb:0.0143, weight:0.12, lr:0.0009
[23:25:10.153] iteration:1549  t-loss:0.0348, loss-lb:0.0322, loss-ulb:0.0222, weight:0.12, lr:0.0009
[23:25:10.528] iteration:1550  t-loss:0.0899, loss-lb:0.0881, loss-ulb:0.0148, weight:0.12, lr:0.0009
[23:25:10.900] iteration:1551  t-loss:0.0413, loss-lb:0.0408, loss-ulb:0.0038, weight:0.12, lr:0.0009
[23:25:11.274] iteration:1552  t-loss:0.0968, loss-lb:0.0926, loss-ulb:0.0347, weight:0.12, lr:0.0009
[23:25:11.649] iteration:1553  t-loss:0.0498, loss-lb:0.0491, loss-ulb:0.0064, weight:0.12, lr:0.0009
[23:25:12.022] iteration:1554  t-loss:0.0465, loss-lb:0.0434, loss-ulb:0.0255, weight:0.12, lr:0.0009
[23:25:12.394] iteration:1555  t-loss:0.0339, loss-lb:0.0332, loss-ulb:0.0056, weight:0.12, lr:0.0009
[23:25:12.764] iteration:1556  t-loss:0.0466, loss-lb:0.0456, loss-ulb:0.0088, weight:0.12, lr:0.0009
[23:25:13.137] iteration:1557  t-loss:0.0572, loss-lb:0.0535, loss-ulb:0.0304, weight:0.12, lr:0.0009
[23:25:13.510] iteration:1558  t-loss:0.0480, loss-lb:0.0437, loss-ulb:0.0356, weight:0.12, lr:0.0009
[23:26:10.423] iteration 1558 : dice_score: 0.648083 best_dice: 0.719700
[23:26:10.423]  <<Test>> - Ep:40  - Dice-S/T:60.00/64.81, Best-S:66.85, Best-T:71.97
[23:26:10.423]           - AvgLoss(lb/ulb/all):0.06/0.02/0.05
[23:26:11.575] iteration:1559  t-loss:0.0422, loss-lb:0.0407, loss-ulb:0.0126, weight:0.12, lr:0.0009
[23:26:11.972] iteration:1560  t-loss:0.1176, loss-lb:0.1156, loss-ulb:0.0163, weight:0.12, lr:0.0009
[23:26:12.355] iteration:1561  t-loss:0.0744, loss-lb:0.0724, loss-ulb:0.0164, weight:0.12, lr:0.0009
[23:26:12.739] iteration:1562  t-loss:0.0539, loss-lb:0.0509, loss-ulb:0.0248, weight:0.12, lr:0.0009
[23:26:13.116] iteration:1563  t-loss:0.0448, loss-lb:0.0443, loss-ulb:0.0038, weight:0.12, lr:0.0009
[23:26:13.493] iteration:1564  t-loss:0.0409, loss-lb:0.0399, loss-ulb:0.0079, weight:0.12, lr:0.0009
[23:26:13.868] iteration:1565  t-loss:0.0343, loss-lb:0.0324, loss-ulb:0.0158, weight:0.12, lr:0.0009
[23:26:14.250] iteration:1566  t-loss:0.0488, loss-lb:0.0482, loss-ulb:0.0050, weight:0.12, lr:0.0009
[23:26:14.624] iteration:1567  t-loss:0.0303, loss-lb:0.0299, loss-ulb:0.0032, weight:0.12, lr:0.0009
[23:26:15.002] iteration:1568  t-loss:0.0516, loss-lb:0.0505, loss-ulb:0.0095, weight:0.12, lr:0.0009
[23:26:15.382] iteration:1569  t-loss:0.0661, loss-lb:0.0648, loss-ulb:0.0108, weight:0.12, lr:0.0009
[23:26:15.764] iteration:1570  t-loss:0.1085, loss-lb:0.1004, loss-ulb:0.0677, weight:0.12, lr:0.0009
[23:26:16.142] iteration:1571  t-loss:0.0735, loss-lb:0.0702, loss-ulb:0.0272, weight:0.12, lr:0.0009
[23:26:16.518] iteration:1572  t-loss:0.0460, loss-lb:0.0431, loss-ulb:0.0243, weight:0.12, lr:0.0009
[23:26:16.899] iteration:1573  t-loss:0.0918, loss-lb:0.0890, loss-ulb:0.0230, weight:0.12, lr:0.0009
[23:26:17.276] iteration:1574  t-loss:0.0430, loss-lb:0.0409, loss-ulb:0.0172, weight:0.12, lr:0.0009
[23:26:17.651] iteration:1575  t-loss:0.0493, loss-lb:0.0396, loss-ulb:0.0809, weight:0.12, lr:0.0009
[23:26:18.024] iteration:1576  t-loss:0.0368, loss-lb:0.0359, loss-ulb:0.0073, weight:0.12, lr:0.0009
[23:26:18.399] iteration:1577  t-loss:0.0424, loss-lb:0.0368, loss-ulb:0.0466, weight:0.12, lr:0.0009
[23:26:18.777] iteration:1578  t-loss:0.0713, loss-lb:0.0668, loss-ulb:0.0376, weight:0.12, lr:0.0009
[23:26:19.154] iteration:1579  t-loss:0.1238, loss-lb:0.1214, loss-ulb:0.0202, weight:0.12, lr:0.0009
[23:26:19.532] iteration:1580  t-loss:0.0295, loss-lb:0.0267, loss-ulb:0.0239, weight:0.12, lr:0.0009
[23:26:19.912] iteration:1581  t-loss:0.0664, loss-lb:0.0643, loss-ulb:0.0175, weight:0.12, lr:0.0009
[23:26:20.286] iteration:1582  t-loss:0.0341, loss-lb:0.0326, loss-ulb:0.0123, weight:0.12, lr:0.0009
[23:26:20.664] iteration:1583  t-loss:0.0701, loss-lb:0.0654, loss-ulb:0.0396, weight:0.12, lr:0.0009
[23:26:21.044] iteration:1584  t-loss:0.1441, loss-lb:0.1416, loss-ulb:0.0206, weight:0.12, lr:0.0009
[23:26:21.423] iteration:1585  t-loss:0.0821, loss-lb:0.0784, loss-ulb:0.0309, weight:0.12, lr:0.0009
[23:26:21.804] iteration:1586  t-loss:0.0325, loss-lb:0.0305, loss-ulb:0.0166, weight:0.12, lr:0.0009
[23:26:22.194] iteration:1587  t-loss:0.0541, loss-lb:0.0501, loss-ulb:0.0331, weight:0.12, lr:0.0009
[23:26:22.587] iteration:1588  t-loss:0.0339, loss-lb:0.0333, loss-ulb:0.0053, weight:0.12, lr:0.0009
[23:26:22.961] iteration:1589  t-loss:0.0718, loss-lb:0.0711, loss-ulb:0.0061, weight:0.12, lr:0.0009
[23:26:23.335] iteration:1590  t-loss:0.0611, loss-lb:0.0591, loss-ulb:0.0166, weight:0.12, lr:0.0009
[23:26:23.723] iteration:1591  t-loss:0.0328, loss-lb:0.0309, loss-ulb:0.0160, weight:0.12, lr:0.0009
[23:26:24.106] iteration:1592  t-loss:0.1103, loss-lb:0.1097, loss-ulb:0.0047, weight:0.12, lr:0.0009
[23:26:24.480] iteration:1593  t-loss:0.0821, loss-lb:0.0812, loss-ulb:0.0072, weight:0.12, lr:0.0009
[23:26:24.855] iteration:1594  t-loss:0.0480, loss-lb:0.0446, loss-ulb:0.0280, weight:0.12, lr:0.0009
[23:26:25.229] iteration:1595  t-loss:0.0317, loss-lb:0.0313, loss-ulb:0.0030, weight:0.12, lr:0.0009
[23:26:25.601] iteration:1596  t-loss:0.0757, loss-lb:0.0745, loss-ulb:0.0099, weight:0.12, lr:0.0009
[23:26:27.112] iteration:1597  t-loss:0.0306, loss-lb:0.0237, loss-ulb:0.0571, weight:0.12, lr:0.0009
[23:26:27.509] iteration:1598  t-loss:0.0603, loss-lb:0.0576, loss-ulb:0.0226, weight:0.12, lr:0.0009
[23:26:27.893] iteration:1599  t-loss:0.0382, loss-lb:0.0377, loss-ulb:0.0042, weight:0.12, lr:0.0009
[23:26:28.296] iteration:1600  t-loss:0.0384, loss-lb:0.0374, loss-ulb:0.0083, weight:0.12, lr:0.0009
[23:26:28.691] iteration:1601  t-loss:0.0797, loss-lb:0.0763, loss-ulb:0.0285, weight:0.12, lr:0.0009
[23:26:29.070] iteration:1602  t-loss:0.0880, loss-lb:0.0777, loss-ulb:0.0855, weight:0.12, lr:0.0009
[23:26:29.458] iteration:1603  t-loss:0.0874, loss-lb:0.0861, loss-ulb:0.0106, weight:0.12, lr:0.0009
[23:26:29.841] iteration:1604  t-loss:0.0576, loss-lb:0.0571, loss-ulb:0.0042, weight:0.12, lr:0.0009
[23:26:30.228] iteration:1605  t-loss:0.0672, loss-lb:0.0644, loss-ulb:0.0233, weight:0.12, lr:0.0009
[23:26:30.615] iteration:1606  t-loss:0.0462, loss-lb:0.0408, loss-ulb:0.0451, weight:0.12, lr:0.0009
[23:26:30.999] iteration:1607  t-loss:0.0379, loss-lb:0.0344, loss-ulb:0.0295, weight:0.12, lr:0.0009
[23:26:31.374] iteration:1608  t-loss:0.0496, loss-lb:0.0483, loss-ulb:0.0108, weight:0.12, lr:0.0009
[23:26:31.751] iteration:1609  t-loss:0.0347, loss-lb:0.0325, loss-ulb:0.0181, weight:0.12, lr:0.0009
[23:26:32.118] iteration:1610  t-loss:0.0393, loss-lb:0.0293, loss-ulb:0.0838, weight:0.12, lr:0.0009
[23:26:32.497] iteration:1611  t-loss:0.0454, loss-lb:0.0394, loss-ulb:0.0503, weight:0.12, lr:0.0009
[23:26:32.884] iteration:1612  t-loss:0.0361, loss-lb:0.0345, loss-ulb:0.0134, weight:0.12, lr:0.0009
[23:26:33.269] iteration:1613  t-loss:0.0521, loss-lb:0.0493, loss-ulb:0.0236, weight:0.12, lr:0.0009
[23:26:33.659] iteration:1614  t-loss:0.0763, loss-lb:0.0743, loss-ulb:0.0162, weight:0.12, lr:0.0009
[23:26:34.036] iteration:1615  t-loss:0.0289, loss-lb:0.0285, loss-ulb:0.0034, weight:0.12, lr:0.0009
[23:26:34.408] iteration:1616  t-loss:0.0337, loss-lb:0.0321, loss-ulb:0.0135, weight:0.12, lr:0.0009
[23:26:34.781] iteration:1617  t-loss:0.0544, loss-lb:0.0522, loss-ulb:0.0185, weight:0.12, lr:0.0009
[23:26:35.153] iteration:1618  t-loss:0.0746, loss-lb:0.0735, loss-ulb:0.0091, weight:0.12, lr:0.0009
[23:26:35.525] iteration:1619  t-loss:0.0345, loss-lb:0.0326, loss-ulb:0.0161, weight:0.12, lr:0.0009
[23:26:35.904] iteration:1620  t-loss:0.0493, loss-lb:0.0478, loss-ulb:0.0125, weight:0.12, lr:0.0009
[23:26:36.280] iteration:1621  t-loss:0.0323, loss-lb:0.0285, loss-ulb:0.0310, weight:0.12, lr:0.0009
[23:26:36.657] iteration:1622  t-loss:0.0998, loss-lb:0.0966, loss-ulb:0.0266, weight:0.12, lr:0.0009
[23:26:37.051] iteration:1623  t-loss:0.0316, loss-lb:0.0300, loss-ulb:0.0128, weight:0.12, lr:0.0009
[23:26:37.481] iteration:1624  t-loss:0.0794, loss-lb:0.0771, loss-ulb:0.0192, weight:0.12, lr:0.0009
[23:26:37.902] iteration:1625  t-loss:0.0588, loss-lb:0.0568, loss-ulb:0.0164, weight:0.12, lr:0.0009
[23:26:38.291] iteration:1626  t-loss:0.0871, loss-lb:0.0850, loss-ulb:0.0172, weight:0.12, lr:0.0009
[23:26:38.667] iteration:1627  t-loss:0.0619, loss-lb:0.0563, loss-ulb:0.0466, weight:0.12, lr:0.0009
[23:26:39.040] iteration:1628  t-loss:0.0780, loss-lb:0.0764, loss-ulb:0.0133, weight:0.12, lr:0.0009
[23:26:39.417] iteration:1629  t-loss:0.0611, loss-lb:0.0555, loss-ulb:0.0463, weight:0.12, lr:0.0009
[23:26:39.793] iteration:1630  t-loss:0.0341, loss-lb:0.0332, loss-ulb:0.0080, weight:0.12, lr:0.0009
[23:26:40.154] iteration:1631  t-loss:0.0687, loss-lb:0.0676, loss-ulb:0.0089, weight:0.12, lr:0.0009
[23:26:40.528] iteration:1632  t-loss:0.0822, loss-lb:0.0807, loss-ulb:0.0127, weight:0.12, lr:0.0009
[23:26:40.903] iteration:1633  t-loss:0.0530, loss-lb:0.0487, loss-ulb:0.0358, weight:0.12, lr:0.0009
[23:26:41.275] iteration:1634  t-loss:0.0438, loss-lb:0.0295, loss-ulb:0.1188, weight:0.12, lr:0.0009
[23:26:42.906] iteration:1635  t-loss:0.0388, loss-lb:0.0364, loss-ulb:0.0201, weight:0.12, lr:0.0009
[23:26:43.317] iteration:1636  t-loss:0.0351, loss-lb:0.0343, loss-ulb:0.0072, weight:0.12, lr:0.0009
[23:26:43.740] iteration:1637  t-loss:0.0366, loss-lb:0.0350, loss-ulb:0.0138, weight:0.12, lr:0.0009
[23:26:44.149] iteration:1638  t-loss:0.0407, loss-lb:0.0391, loss-ulb:0.0135, weight:0.12, lr:0.0009
[23:26:44.549] iteration:1639  t-loss:0.0392, loss-lb:0.0338, loss-ulb:0.0445, weight:0.12, lr:0.0009
[23:26:44.935] iteration:1640  t-loss:0.1061, loss-lb:0.1031, loss-ulb:0.0248, weight:0.12, lr:0.0009
[23:26:45.319] iteration:1641  t-loss:0.0439, loss-lb:0.0401, loss-ulb:0.0318, weight:0.12, lr:0.0009
[23:26:45.702] iteration:1642  t-loss:0.0622, loss-lb:0.0611, loss-ulb:0.0094, weight:0.12, lr:0.0009
[23:26:46.078] iteration:1643  t-loss:0.0719, loss-lb:0.0713, loss-ulb:0.0053, weight:0.12, lr:0.0009
[23:26:46.466] iteration:1644  t-loss:0.0369, loss-lb:0.0342, loss-ulb:0.0227, weight:0.12, lr:0.0009
[23:26:46.856] iteration:1645  t-loss:0.0321, loss-lb:0.0287, loss-ulb:0.0281, weight:0.12, lr:0.0009
[23:26:47.231] iteration:1646  t-loss:0.0487, loss-lb:0.0451, loss-ulb:0.0303, weight:0.12, lr:0.0009
[23:26:47.604] iteration:1647  t-loss:0.0801, loss-lb:0.0766, loss-ulb:0.0286, weight:0.12, lr:0.0009
[23:26:47.982] iteration:1648  t-loss:0.0513, loss-lb:0.0485, loss-ulb:0.0231, weight:0.12, lr:0.0009
[23:26:48.366] iteration:1649  t-loss:0.1069, loss-lb:0.1063, loss-ulb:0.0049, weight:0.12, lr:0.0009
[23:26:48.750] iteration:1650  t-loss:0.0491, loss-lb:0.0471, loss-ulb:0.0160, weight:0.12, lr:0.0009
[23:26:49.132] iteration:1651  t-loss:0.0388, loss-lb:0.0344, loss-ulb:0.0301, weight:0.14, lr:0.0009
[23:26:49.512] iteration:1652  t-loss:0.0267, loss-lb:0.0242, loss-ulb:0.0176, weight:0.14, lr:0.0009
[23:26:49.888] iteration:1653  t-loss:0.0361, loss-lb:0.0314, loss-ulb:0.0320, weight:0.14, lr:0.0009
[23:26:50.268] iteration:1654  t-loss:0.0358, loss-lb:0.0332, loss-ulb:0.0178, weight:0.14, lr:0.0009
[23:26:50.641] iteration:1655  t-loss:0.0361, loss-lb:0.0336, loss-ulb:0.0174, weight:0.14, lr:0.0009
[23:26:51.018] iteration:1656  t-loss:0.0619, loss-lb:0.0603, loss-ulb:0.0115, weight:0.14, lr:0.0009
[23:26:51.402] iteration:1657  t-loss:0.0695, loss-lb:0.0675, loss-ulb:0.0136, weight:0.14, lr:0.0009
[23:26:51.780] iteration:1658  t-loss:0.0459, loss-lb:0.0428, loss-ulb:0.0218, weight:0.14, lr:0.0009
[23:26:52.153] iteration:1659  t-loss:0.0385, loss-lb:0.0377, loss-ulb:0.0055, weight:0.14, lr:0.0009
[23:26:52.525] iteration:1660  t-loss:0.0357, loss-lb:0.0354, loss-ulb:0.0018, weight:0.14, lr:0.0009
[23:26:52.925] iteration:1661  t-loss:0.0420, loss-lb:0.0387, loss-ulb:0.0230, weight:0.14, lr:0.0009
[23:26:53.329] iteration:1662  t-loss:0.0345, loss-lb:0.0286, loss-ulb:0.0407, weight:0.14, lr:0.0009
[23:26:53.719] iteration:1663  t-loss:0.0535, loss-lb:0.0481, loss-ulb:0.0377, weight:0.14, lr:0.0009
[23:26:54.105] iteration:1664  t-loss:0.0413, loss-lb:0.0366, loss-ulb:0.0325, weight:0.14, lr:0.0009
[23:26:54.487] iteration:1665  t-loss:0.0740, loss-lb:0.0712, loss-ulb:0.0197, weight:0.14, lr:0.0009
[23:26:54.859] iteration:1666  t-loss:0.0609, loss-lb:0.0595, loss-ulb:0.0102, weight:0.14, lr:0.0009
[23:26:55.234] iteration:1667  t-loss:0.0800, loss-lb:0.0796, loss-ulb:0.0029, weight:0.14, lr:0.0009
[23:26:55.605] iteration:1668  t-loss:0.0362, loss-lb:0.0357, loss-ulb:0.0033, weight:0.14, lr:0.0009
[23:26:55.979] iteration:1669  t-loss:0.0374, loss-lb:0.0356, loss-ulb:0.0128, weight:0.14, lr:0.0009
[23:26:56.352] iteration:1670  t-loss:0.0595, loss-lb:0.0508, loss-ulb:0.0604, weight:0.14, lr:0.0009
[23:26:56.722] iteration:1671  t-loss:0.0293, loss-lb:0.0278, loss-ulb:0.0109, weight:0.14, lr:0.0009
[23:26:57.095] iteration:1672  t-loss:0.0390, loss-lb:0.0353, loss-ulb:0.0258, weight:0.14, lr:0.0009
[23:26:58.272] iteration:1673  t-loss:0.0297, loss-lb:0.0268, loss-ulb:0.0200, weight:0.14, lr:0.0009
[23:26:58.672] iteration:1674  t-loss:0.0648, loss-lb:0.0612, loss-ulb:0.0250, weight:0.14, lr:0.0009
[23:26:59.092] iteration:1675  t-loss:0.0433, loss-lb:0.0422, loss-ulb:0.0078, weight:0.14, lr:0.0009
[23:26:59.503] iteration:1676  t-loss:0.0630, loss-lb:0.0572, loss-ulb:0.0401, weight:0.14, lr:0.0009
[23:26:59.883] iteration:1677  t-loss:0.0462, loss-lb:0.0445, loss-ulb:0.0113, weight:0.14, lr:0.0009
[23:27:00.272] iteration:1678  t-loss:0.0578, loss-lb:0.0550, loss-ulb:0.0201, weight:0.14, lr:0.0009
[23:27:00.659] iteration:1679  t-loss:0.0385, loss-lb:0.0362, loss-ulb:0.0158, weight:0.14, lr:0.0009
[23:27:01.036] iteration:1680  t-loss:0.0374, loss-lb:0.0312, loss-ulb:0.0428, weight:0.14, lr:0.0009
[23:27:01.410] iteration:1681  t-loss:0.0254, loss-lb:0.0243, loss-ulb:0.0081, weight:0.14, lr:0.0009
[23:27:01.790] iteration:1682  t-loss:0.1260, loss-lb:0.1252, loss-ulb:0.0058, weight:0.14, lr:0.0009
[23:27:02.166] iteration:1683  t-loss:0.0555, loss-lb:0.0540, loss-ulb:0.0104, weight:0.14, lr:0.0009
[23:27:02.541] iteration:1684  t-loss:0.0583, loss-lb:0.0579, loss-ulb:0.0032, weight:0.14, lr:0.0009
[23:27:02.919] iteration:1685  t-loss:0.0606, loss-lb:0.0583, loss-ulb:0.0156, weight:0.14, lr:0.0009
[23:27:03.303] iteration:1686  t-loss:0.0706, loss-lb:0.0692, loss-ulb:0.0095, weight:0.14, lr:0.0009
[23:27:03.680] iteration:1687  t-loss:0.0594, loss-lb:0.0516, loss-ulb:0.0545, weight:0.14, lr:0.0009
[23:27:04.056] iteration:1688  t-loss:0.0244, loss-lb:0.0235, loss-ulb:0.0062, weight:0.14, lr:0.0009
[23:27:04.433] iteration:1689  t-loss:0.0619, loss-lb:0.0602, loss-ulb:0.0111, weight:0.14, lr:0.0009
[23:27:04.814] iteration:1690  t-loss:0.0579, loss-lb:0.0537, loss-ulb:0.0292, weight:0.14, lr:0.0009
[23:27:05.201] iteration:1691  t-loss:0.0625, loss-lb:0.0606, loss-ulb:0.0133, weight:0.14, lr:0.0009
[23:27:05.569] iteration:1692  t-loss:0.0390, loss-lb:0.0381, loss-ulb:0.0065, weight:0.14, lr:0.0009
[23:27:05.945] iteration:1693  t-loss:0.0255, loss-lb:0.0229, loss-ulb:0.0182, weight:0.14, lr:0.0009
[23:27:06.317] iteration:1694  t-loss:0.0420, loss-lb:0.0402, loss-ulb:0.0120, weight:0.14, lr:0.0009
[23:27:06.688] iteration:1695  t-loss:0.0634, loss-lb:0.0619, loss-ulb:0.0102, weight:0.14, lr:0.0009
[23:27:07.065] iteration:1696  t-loss:0.0722, loss-lb:0.0682, loss-ulb:0.0277, weight:0.14, lr:0.0009
[23:27:07.441] iteration:1697  t-loss:0.0698, loss-lb:0.0684, loss-ulb:0.0103, weight:0.14, lr:0.0009
[23:27:07.827] iteration:1698  t-loss:0.0781, loss-lb:0.0768, loss-ulb:0.0086, weight:0.14, lr:0.0009
[23:27:08.217] iteration:1699  t-loss:0.0340, loss-lb:0.0305, loss-ulb:0.0245, weight:0.14, lr:0.0009
[23:27:08.617] iteration:1700  t-loss:0.0390, loss-lb:0.0357, loss-ulb:0.0224, weight:0.14, lr:0.0009
[23:27:09.025] iteration:1701  t-loss:0.0460, loss-lb:0.0424, loss-ulb:0.0253, weight:0.14, lr:0.0009
[23:27:09.407] iteration:1702  t-loss:0.0635, loss-lb:0.0447, loss-ulb:0.1304, weight:0.14, lr:0.0009
[23:27:09.788] iteration:1703  t-loss:0.0801, loss-lb:0.0772, loss-ulb:0.0203, weight:0.14, lr:0.0009
[23:27:10.160] iteration:1704  t-loss:0.0433, loss-lb:0.0393, loss-ulb:0.0276, weight:0.14, lr:0.0009
[23:27:10.529] iteration:1705  t-loss:0.0358, loss-lb:0.0328, loss-ulb:0.0205, weight:0.14, lr:0.0009
[23:27:10.898] iteration:1706  t-loss:0.0638, loss-lb:0.0568, loss-ulb:0.0487, weight:0.14, lr:0.0009
[23:27:11.268] iteration:1707  t-loss:0.0396, loss-lb:0.0394, loss-ulb:0.0019, weight:0.14, lr:0.0009
[23:27:11.638] iteration:1708  t-loss:0.0281, loss-lb:0.0238, loss-ulb:0.0299, weight:0.14, lr:0.0009
[23:27:12.008] iteration:1709  t-loss:0.0655, loss-lb:0.0632, loss-ulb:0.0156, weight:0.14, lr:0.0009
[23:27:12.382] iteration:1710  t-loss:0.0639, loss-lb:0.0615, loss-ulb:0.0169, weight:0.14, lr:0.0009
[23:28:10.301] iteration 1710 : dice_score: 0.670599 best_dice: 0.719700
[23:28:10.301]  <<Test>> - Ep:44  - Dice-S/T:57.11/67.06, Best-S:66.85, Best-T:71.97
[23:28:10.301]           - AvgLoss(lb/ulb/all):0.05/0.02/0.05
[23:28:11.367] iteration:1711  t-loss:0.0322, loss-lb:0.0278, loss-ulb:0.0305, weight:0.14, lr:0.0009
[23:28:11.767] iteration:1712  t-loss:0.0462, loss-lb:0.0413, loss-ulb:0.0338, weight:0.14, lr:0.0009
[23:28:12.144] iteration:1713  t-loss:0.0361, loss-lb:0.0347, loss-ulb:0.0096, weight:0.14, lr:0.0009
[23:28:12.527] iteration:1714  t-loss:0.0562, loss-lb:0.0544, loss-ulb:0.0124, weight:0.14, lr:0.0009
[23:28:12.907] iteration:1715  t-loss:0.0425, loss-lb:0.0404, loss-ulb:0.0144, weight:0.14, lr:0.0009
[23:28:13.284] iteration:1716  t-loss:0.0453, loss-lb:0.0444, loss-ulb:0.0060, weight:0.14, lr:0.0009
[23:28:13.659] iteration:1717  t-loss:0.1033, loss-lb:0.1005, loss-ulb:0.0197, weight:0.14, lr:0.0009
[23:28:14.037] iteration:1718  t-loss:0.0520, loss-lb:0.0505, loss-ulb:0.0104, weight:0.14, lr:0.0009
[23:28:14.415] iteration:1719  t-loss:0.0338, loss-lb:0.0303, loss-ulb:0.0243, weight:0.14, lr:0.0009
[23:28:14.792] iteration:1720  t-loss:0.0601, loss-lb:0.0596, loss-ulb:0.0030, weight:0.14, lr:0.0009
[23:28:15.170] iteration:1721  t-loss:0.1225, loss-lb:0.1220, loss-ulb:0.0041, weight:0.14, lr:0.0009
[23:28:15.545] iteration:1722  t-loss:0.0344, loss-lb:0.0308, loss-ulb:0.0250, weight:0.14, lr:0.0009
[23:28:15.925] iteration:1723  t-loss:0.0348, loss-lb:0.0323, loss-ulb:0.0172, weight:0.14, lr:0.0009
[23:28:16.303] iteration:1724  t-loss:0.0450, loss-lb:0.0420, loss-ulb:0.0209, weight:0.14, lr:0.0009
[23:28:16.682] iteration:1725  t-loss:0.0763, loss-lb:0.0697, loss-ulb:0.0458, weight:0.14, lr:0.0009
[23:28:17.061] iteration:1726  t-loss:0.0417, loss-lb:0.0394, loss-ulb:0.0159, weight:0.14, lr:0.0009
[23:28:17.439] iteration:1727  t-loss:0.0324, loss-lb:0.0303, loss-ulb:0.0139, weight:0.14, lr:0.0009
[23:28:17.816] iteration:1728  t-loss:0.0499, loss-lb:0.0483, loss-ulb:0.0108, weight:0.14, lr:0.0009
[23:28:18.194] iteration:1729  t-loss:0.0704, loss-lb:0.0688, loss-ulb:0.0115, weight:0.14, lr:0.0009
[23:28:18.575] iteration:1730  t-loss:0.0683, loss-lb:0.0649, loss-ulb:0.0231, weight:0.14, lr:0.0009
[23:28:18.952] iteration:1731  t-loss:0.0918, loss-lb:0.0806, loss-ulb:0.0774, weight:0.14, lr:0.0009
[23:28:19.332] iteration:1732  t-loss:0.0857, loss-lb:0.0837, loss-ulb:0.0144, weight:0.14, lr:0.0009
[23:28:19.706] iteration:1733  t-loss:0.0544, loss-lb:0.0540, loss-ulb:0.0030, weight:0.14, lr:0.0009
[23:28:20.080] iteration:1734  t-loss:0.0355, loss-lb:0.0321, loss-ulb:0.0235, weight:0.14, lr:0.0009
[23:28:20.460] iteration:1735  t-loss:0.0354, loss-lb:0.0343, loss-ulb:0.0076, weight:0.14, lr:0.0009
[23:28:20.837] iteration:1736  t-loss:0.0774, loss-lb:0.0719, loss-ulb:0.0380, weight:0.14, lr:0.0009
[23:28:21.224] iteration:1737  t-loss:0.0688, loss-lb:0.0674, loss-ulb:0.0101, weight:0.14, lr:0.0009
[23:28:21.629] iteration:1738  t-loss:0.0611, loss-lb:0.0586, loss-ulb:0.0175, weight:0.14, lr:0.0009
[23:28:22.043] iteration:1739  t-loss:0.0842, loss-lb:0.0820, loss-ulb:0.0151, weight:0.14, lr:0.0009
[23:28:22.422] iteration:1740  t-loss:0.0400, loss-lb:0.0308, loss-ulb:0.0637, weight:0.14, lr:0.0009
[23:28:22.795] iteration:1741  t-loss:0.0381, loss-lb:0.0360, loss-ulb:0.0142, weight:0.14, lr:0.0009
[23:28:23.169] iteration:1742  t-loss:0.0710, loss-lb:0.0693, loss-ulb:0.0117, weight:0.14, lr:0.0009
[23:28:23.539] iteration:1743  t-loss:0.0680, loss-lb:0.0621, loss-ulb:0.0408, weight:0.14, lr:0.0009
[23:28:23.912] iteration:1744  t-loss:0.0573, loss-lb:0.0545, loss-ulb:0.0198, weight:0.14, lr:0.0009
[23:28:24.287] iteration:1745  t-loss:0.0403, loss-lb:0.0366, loss-ulb:0.0251, weight:0.14, lr:0.0009
[23:28:24.661] iteration:1746  t-loss:0.0302, loss-lb:0.0277, loss-ulb:0.0170, weight:0.14, lr:0.0009
[23:28:25.040] iteration:1747  t-loss:0.0611, loss-lb:0.0565, loss-ulb:0.0314, weight:0.14, lr:0.0009
[23:28:25.421] iteration:1748  t-loss:0.0379, loss-lb:0.0340, loss-ulb:0.0267, weight:0.14, lr:0.0009
[23:28:26.582] iteration:1749  t-loss:0.0641, loss-lb:0.0607, loss-ulb:0.0235, weight:0.14, lr:0.0009
[23:28:26.983] iteration:1750  t-loss:0.0346, loss-lb:0.0331, loss-ulb:0.0102, weight:0.14, lr:0.0009
[23:28:27.363] iteration:1751  t-loss:0.0704, loss-lb:0.0677, loss-ulb:0.0183, weight:0.14, lr:0.0009
[23:28:27.734] iteration:1752  t-loss:0.0336, loss-lb:0.0302, loss-ulb:0.0239, weight:0.14, lr:0.0009
[23:28:28.109] iteration:1753  t-loss:0.0317, loss-lb:0.0264, loss-ulb:0.0369, weight:0.14, lr:0.0009
[23:28:28.492] iteration:1754  t-loss:0.0943, loss-lb:0.0926, loss-ulb:0.0118, weight:0.14, lr:0.0009
[23:28:28.868] iteration:1755  t-loss:0.0893, loss-lb:0.0828, loss-ulb:0.0445, weight:0.14, lr:0.0009
[23:28:29.253] iteration:1756  t-loss:0.0360, loss-lb:0.0315, loss-ulb:0.0306, weight:0.14, lr:0.0009
[23:28:29.632] iteration:1757  t-loss:0.0864, loss-lb:0.0826, loss-ulb:0.0266, weight:0.14, lr:0.0009
[23:28:30.008] iteration:1758  t-loss:0.0336, loss-lb:0.0323, loss-ulb:0.0092, weight:0.14, lr:0.0009
[23:28:30.385] iteration:1759  t-loss:0.0388, loss-lb:0.0333, loss-ulb:0.0381, weight:0.14, lr:0.0009
[23:28:30.766] iteration:1760  t-loss:0.1148, loss-lb:0.1138, loss-ulb:0.0072, weight:0.14, lr:0.0009
[23:28:31.141] iteration:1761  t-loss:0.0303, loss-lb:0.0291, loss-ulb:0.0079, weight:0.14, lr:0.0009
[23:28:31.521] iteration:1762  t-loss:0.0787, loss-lb:0.0772, loss-ulb:0.0103, weight:0.14, lr:0.0009
[23:28:31.898] iteration:1763  t-loss:0.0370, loss-lb:0.0351, loss-ulb:0.0137, weight:0.14, lr:0.0009
[23:28:32.274] iteration:1764  t-loss:0.0722, loss-lb:0.0702, loss-ulb:0.0136, weight:0.14, lr:0.0009
[23:28:32.655] iteration:1765  t-loss:0.0302, loss-lb:0.0298, loss-ulb:0.0030, weight:0.14, lr:0.0009
[23:28:33.028] iteration:1766  t-loss:0.0532, loss-lb:0.0470, loss-ulb:0.0433, weight:0.14, lr:0.0009
[23:28:33.400] iteration:1767  t-loss:0.0296, loss-lb:0.0271, loss-ulb:0.0176, weight:0.14, lr:0.0009
[23:28:33.775] iteration:1768  t-loss:0.0771, loss-lb:0.0735, loss-ulb:0.0251, weight:0.14, lr:0.0009
[23:28:34.150] iteration:1769  t-loss:0.0356, loss-lb:0.0321, loss-ulb:0.0248, weight:0.14, lr:0.0009
[23:28:34.526] iteration:1770  t-loss:0.0449, loss-lb:0.0429, loss-ulb:0.0140, weight:0.14, lr:0.0009
[23:28:34.902] iteration:1771  t-loss:0.0543, loss-lb:0.0534, loss-ulb:0.0065, weight:0.14, lr:0.0009
[23:28:35.279] iteration:1772  t-loss:0.0696, loss-lb:0.0659, loss-ulb:0.0259, weight:0.14, lr:0.0009
[23:28:35.656] iteration:1773  t-loss:0.0369, loss-lb:0.0335, loss-ulb:0.0238, weight:0.14, lr:0.0009
[23:28:36.042] iteration:1774  t-loss:0.0293, loss-lb:0.0255, loss-ulb:0.0259, weight:0.14, lr:0.0009
[23:28:36.434] iteration:1775  t-loss:0.0910, loss-lb:0.0899, loss-ulb:0.0071, weight:0.14, lr:0.0009
[23:28:36.851] iteration:1776  t-loss:0.0864, loss-lb:0.0829, loss-ulb:0.0242, weight:0.14, lr:0.0009
[23:28:37.252] iteration:1777  t-loss:0.0886, loss-lb:0.0852, loss-ulb:0.0237, weight:0.14, lr:0.0009
[23:28:37.634] iteration:1778  t-loss:0.0364, loss-lb:0.0341, loss-ulb:0.0155, weight:0.14, lr:0.0009
[23:28:38.015] iteration:1779  t-loss:0.0507, loss-lb:0.0483, loss-ulb:0.0162, weight:0.14, lr:0.0009
[23:28:38.390] iteration:1780  t-loss:0.0723, loss-lb:0.0713, loss-ulb:0.0071, weight:0.14, lr:0.0009
[23:28:38.764] iteration:1781  t-loss:0.0742, loss-lb:0.0711, loss-ulb:0.0213, weight:0.14, lr:0.0009
[23:28:39.138] iteration:1782  t-loss:0.0398, loss-lb:0.0329, loss-ulb:0.0478, weight:0.14, lr:0.0009
[23:28:39.517] iteration:1783  t-loss:0.0936, loss-lb:0.0910, loss-ulb:0.0174, weight:0.14, lr:0.0009
[23:28:39.889] iteration:1784  t-loss:0.0693, loss-lb:0.0490, loss-ulb:0.1409, weight:0.14, lr:0.0009
[23:28:40.266] iteration:1785  t-loss:0.0594, loss-lb:0.0529, loss-ulb:0.0454, weight:0.14, lr:0.0009
[23:28:40.643] iteration:1786  t-loss:0.0485, loss-lb:0.0459, loss-ulb:0.0182, weight:0.14, lr:0.0009
[23:28:41.916] iteration:1787  t-loss:0.0450, loss-lb:0.0430, loss-ulb:0.0140, weight:0.14, lr:0.0009
[23:28:42.394] iteration:1788  t-loss:0.0470, loss-lb:0.0419, loss-ulb:0.0351, weight:0.14, lr:0.0009
[23:28:42.805] iteration:1789  t-loss:0.0625, loss-lb:0.0489, loss-ulb:0.0942, weight:0.14, lr:0.0009
[23:28:43.184] iteration:1790  t-loss:0.0452, loss-lb:0.0430, loss-ulb:0.0153, weight:0.14, lr:0.0009
[23:28:43.560] iteration:1791  t-loss:0.0440, loss-lb:0.0418, loss-ulb:0.0150, weight:0.14, lr:0.0009
[23:28:43.947] iteration:1792  t-loss:0.0320, loss-lb:0.0297, loss-ulb:0.0156, weight:0.14, lr:0.0009
[23:28:44.326] iteration:1793  t-loss:0.0456, loss-lb:0.0432, loss-ulb:0.0166, weight:0.14, lr:0.0009
[23:28:44.703] iteration:1794  t-loss:0.0718, loss-lb:0.0704, loss-ulb:0.0104, weight:0.14, lr:0.0009
[23:28:45.074] iteration:1795  t-loss:0.0355, loss-lb:0.0302, loss-ulb:0.0368, weight:0.14, lr:0.0009
[23:28:45.452] iteration:1796  t-loss:0.0452, loss-lb:0.0428, loss-ulb:0.0167, weight:0.14, lr:0.0009
[23:28:45.829] iteration:1797  t-loss:0.0321, loss-lb:0.0290, loss-ulb:0.0212, weight:0.14, lr:0.0009
[23:28:46.203] iteration:1798  t-loss:0.1448, loss-lb:0.1428, loss-ulb:0.0140, weight:0.14, lr:0.0009
[23:28:46.579] iteration:1799  t-loss:0.0441, loss-lb:0.0382, loss-ulb:0.0408, weight:0.14, lr:0.0009
[23:28:46.962] iteration:1800  t-loss:0.0500, loss-lb:0.0490, loss-ulb:0.0069, weight:0.14, lr:0.0009
[23:28:47.343] iteration:1801  t-loss:0.0675, loss-lb:0.0610, loss-ulb:0.0379, weight:0.17, lr:0.0009
[23:28:47.720] iteration:1802  t-loss:0.0600, loss-lb:0.0560, loss-ulb:0.0229, weight:0.17, lr:0.0009
[23:28:48.098] iteration:1803  t-loss:0.0578, loss-lb:0.0546, loss-ulb:0.0183, weight:0.17, lr:0.0009
[23:28:48.474] iteration:1804  t-loss:0.0394, loss-lb:0.0351, loss-ulb:0.0253, weight:0.17, lr:0.0009
[23:28:48.845] iteration:1805  t-loss:0.0924, loss-lb:0.0912, loss-ulb:0.0070, weight:0.17, lr:0.0009
[23:28:49.215] iteration:1806  t-loss:0.0362, loss-lb:0.0291, loss-ulb:0.0410, weight:0.17, lr:0.0009
[23:28:49.589] iteration:1807  t-loss:0.0601, loss-lb:0.0592, loss-ulb:0.0050, weight:0.17, lr:0.0009
[23:28:49.962] iteration:1808  t-loss:0.0697, loss-lb:0.0561, loss-ulb:0.0789, weight:0.17, lr:0.0009
[23:28:50.333] iteration:1809  t-loss:0.0392, loss-lb:0.0379, loss-ulb:0.0076, weight:0.17, lr:0.0009
[23:28:50.708] iteration:1810  t-loss:0.0805, loss-lb:0.0785, loss-ulb:0.0115, weight:0.17, lr:0.0009
[23:28:51.080] iteration:1811  t-loss:0.0356, loss-lb:0.0283, loss-ulb:0.0423, weight:0.17, lr:0.0009
[23:28:51.468] iteration:1812  t-loss:0.0626, loss-lb:0.0606, loss-ulb:0.0115, weight:0.17, lr:0.0009
[23:28:51.867] iteration:1813  t-loss:0.1061, loss-lb:0.0987, loss-ulb:0.0431, weight:0.17, lr:0.0009
[23:28:52.282] iteration:1814  t-loss:0.0317, loss-lb:0.0306, loss-ulb:0.0065, weight:0.17, lr:0.0009
[23:28:52.678] iteration:1815  t-loss:0.0615, loss-lb:0.0609, loss-ulb:0.0032, weight:0.17, lr:0.0009
[23:28:53.074] iteration:1816  t-loss:0.0395, loss-lb:0.0362, loss-ulb:0.0196, weight:0.17, lr:0.0009
[23:28:53.446] iteration:1817  t-loss:0.0327, loss-lb:0.0322, loss-ulb:0.0028, weight:0.17, lr:0.0009
[23:28:53.818] iteration:1818  t-loss:0.0611, loss-lb:0.0606, loss-ulb:0.0027, weight:0.17, lr:0.0009
[23:28:54.191] iteration:1819  t-loss:0.0428, loss-lb:0.0408, loss-ulb:0.0118, weight:0.17, lr:0.0009
[23:28:54.563] iteration:1820  t-loss:0.0348, loss-lb:0.0288, loss-ulb:0.0352, weight:0.17, lr:0.0009
[23:28:54.937] iteration:1821  t-loss:0.0426, loss-lb:0.0374, loss-ulb:0.0298, weight:0.17, lr:0.0009
[23:28:55.307] iteration:1822  t-loss:0.0452, loss-lb:0.0414, loss-ulb:0.0224, weight:0.17, lr:0.0009
[23:28:55.677] iteration:1823  t-loss:0.0412, loss-lb:0.0357, loss-ulb:0.0321, weight:0.17, lr:0.0009
[23:28:56.058] iteration:1824  t-loss:0.0596, loss-lb:0.0568, loss-ulb:0.0164, weight:0.17, lr:0.0009
[23:28:57.210] iteration:1825  t-loss:0.0719, loss-lb:0.0695, loss-ulb:0.0139, weight:0.17, lr:0.0009
[23:28:57.630] iteration:1826  t-loss:0.0589, loss-lb:0.0562, loss-ulb:0.0156, weight:0.17, lr:0.0009
[23:28:58.059] iteration:1827  t-loss:0.0376, loss-lb:0.0335, loss-ulb:0.0238, weight:0.17, lr:0.0009
[23:28:58.475] iteration:1828  t-loss:0.0750, loss-lb:0.0724, loss-ulb:0.0153, weight:0.17, lr:0.0009
[23:28:58.864] iteration:1829  t-loss:0.0421, loss-lb:0.0352, loss-ulb:0.0400, weight:0.17, lr:0.0009
[23:28:59.250] iteration:1830  t-loss:0.0658, loss-lb:0.0652, loss-ulb:0.0031, weight:0.17, lr:0.0009
[23:28:59.631] iteration:1831  t-loss:0.0251, loss-lb:0.0239, loss-ulb:0.0067, weight:0.17, lr:0.0009
[23:29:00.007] iteration:1832  t-loss:0.0351, loss-lb:0.0323, loss-ulb:0.0162, weight:0.17, lr:0.0009
[23:29:00.385] iteration:1833  t-loss:0.0423, loss-lb:0.0416, loss-ulb:0.0038, weight:0.17, lr:0.0009
[23:29:00.763] iteration:1834  t-loss:0.0302, loss-lb:0.0248, loss-ulb:0.0314, weight:0.17, lr:0.0009
[23:29:01.149] iteration:1835  t-loss:0.0566, loss-lb:0.0499, loss-ulb:0.0385, weight:0.17, lr:0.0009
[23:29:01.519] iteration:1836  t-loss:0.0353, loss-lb:0.0324, loss-ulb:0.0165, weight:0.17, lr:0.0009
[23:29:01.899] iteration:1837  t-loss:0.0561, loss-lb:0.0542, loss-ulb:0.0106, weight:0.17, lr:0.0009
[23:29:02.282] iteration:1838  t-loss:0.0310, loss-lb:0.0294, loss-ulb:0.0095, weight:0.17, lr:0.0009
[23:29:02.662] iteration:1839  t-loss:0.0861, loss-lb:0.0838, loss-ulb:0.0136, weight:0.17, lr:0.0009
[23:29:03.033] iteration:1840  t-loss:0.0349, loss-lb:0.0336, loss-ulb:0.0074, weight:0.17, lr:0.0009
[23:29:03.415] iteration:1841  t-loss:0.0800, loss-lb:0.0771, loss-ulb:0.0172, weight:0.17, lr:0.0009
[23:29:03.789] iteration:1842  t-loss:0.0439, loss-lb:0.0330, loss-ulb:0.0631, weight:0.17, lr:0.0009
[23:29:04.162] iteration:1843  t-loss:0.0444, loss-lb:0.0428, loss-ulb:0.0091, weight:0.17, lr:0.0009
[23:29:04.531] iteration:1844  t-loss:0.0403, loss-lb:0.0398, loss-ulb:0.0026, weight:0.17, lr:0.0009
[23:29:04.913] iteration:1845  t-loss:0.0936, loss-lb:0.0894, loss-ulb:0.0239, weight:0.17, lr:0.0009
[23:29:05.285] iteration:1846  t-loss:0.0304, loss-lb:0.0296, loss-ulb:0.0044, weight:0.17, lr:0.0009
[23:29:05.658] iteration:1847  t-loss:0.0881, loss-lb:0.0853, loss-ulb:0.0165, weight:0.17, lr:0.0009
[23:29:06.030] iteration:1848  t-loss:0.0744, loss-lb:0.0740, loss-ulb:0.0026, weight:0.17, lr:0.0009
[23:29:06.409] iteration:1849  t-loss:0.0537, loss-lb:0.0527, loss-ulb:0.0061, weight:0.17, lr:0.0009
[23:29:06.790] iteration:1850  t-loss:0.0623, loss-lb:0.0575, loss-ulb:0.0276, weight:0.17, lr:0.0009
[23:29:07.167] iteration:1851  t-loss:0.0669, loss-lb:0.0604, loss-ulb:0.0379, weight:0.17, lr:0.0009
[23:29:07.554] iteration:1852  t-loss:0.0265, loss-lb:0.0251, loss-ulb:0.0078, weight:0.17, lr:0.0009
[23:29:07.949] iteration:1853  t-loss:0.0890, loss-lb:0.0839, loss-ulb:0.0295, weight:0.17, lr:0.0009
[23:29:08.362] iteration:1854  t-loss:0.0488, loss-lb:0.0467, loss-ulb:0.0122, weight:0.17, lr:0.0009
[23:29:08.754] iteration:1855  t-loss:0.0627, loss-lb:0.0586, loss-ulb:0.0236, weight:0.17, lr:0.0009
[23:29:09.128] iteration:1856  t-loss:0.0587, loss-lb:0.0519, loss-ulb:0.0395, weight:0.17, lr:0.0009
[23:29:09.498] iteration:1857  t-loss:0.0380, loss-lb:0.0294, loss-ulb:0.0501, weight:0.17, lr:0.0009
[23:29:09.871] iteration:1858  t-loss:0.0355, loss-lb:0.0329, loss-ulb:0.0153, weight:0.17, lr:0.0009
[23:29:10.240] iteration:1859  t-loss:0.0716, loss-lb:0.0689, loss-ulb:0.0153, weight:0.17, lr:0.0009
[23:29:10.612] iteration:1860  t-loss:0.0390, loss-lb:0.0374, loss-ulb:0.0088, weight:0.17, lr:0.0009
[23:29:10.989] iteration:1861  t-loss:0.0762, loss-lb:0.0732, loss-ulb:0.0174, weight:0.17, lr:0.0009
[23:29:11.369] iteration:1862  t-loss:0.0578, loss-lb:0.0575, loss-ulb:0.0022, weight:0.17, lr:0.0009
[23:30:10.682] iteration 1862 : dice_score: 0.624413 best_dice: 0.719700
[23:30:10.682]  <<Test>> - Ep:48  - Dice-S/T:52.43/62.44, Best-S:66.85, Best-T:71.97
[23:30:10.682]           - AvgLoss(lb/ulb/all):0.05/0.02/0.06
[23:30:11.994] iteration:1863  t-loss:0.0328, loss-lb:0.0303, loss-ulb:0.0146, weight:0.17, lr:0.0009
[23:30:12.375] iteration:1864  t-loss:0.0981, loss-lb:0.0952, loss-ulb:0.0164, weight:0.17, lr:0.0009
[23:30:12.746] iteration:1865  t-loss:0.0345, loss-lb:0.0301, loss-ulb:0.0256, weight:0.17, lr:0.0009
[23:30:13.121] iteration:1866  t-loss:0.0716, loss-lb:0.0629, loss-ulb:0.0505, weight:0.17, lr:0.0009
[23:30:13.494] iteration:1867  t-loss:0.0497, loss-lb:0.0483, loss-ulb:0.0080, weight:0.17, lr:0.0009
[23:30:13.870] iteration:1868  t-loss:0.0700, loss-lb:0.0682, loss-ulb:0.0100, weight:0.17, lr:0.0009
[23:30:14.251] iteration:1869  t-loss:0.0666, loss-lb:0.0625, loss-ulb:0.0233, weight:0.17, lr:0.0009
[23:30:14.631] iteration:1870  t-loss:0.0378, loss-lb:0.0339, loss-ulb:0.0225, weight:0.17, lr:0.0009
[23:30:15.006] iteration:1871  t-loss:0.0626, loss-lb:0.0603, loss-ulb:0.0136, weight:0.17, lr:0.0009
[23:30:15.384] iteration:1872  t-loss:0.0268, loss-lb:0.0261, loss-ulb:0.0040, weight:0.17, lr:0.0009
[23:30:15.760] iteration:1873  t-loss:0.0603, loss-lb:0.0592, loss-ulb:0.0063, weight:0.17, lr:0.0009
[23:30:16.138] iteration:1874  t-loss:0.0814, loss-lb:0.0766, loss-ulb:0.0281, weight:0.17, lr:0.0009
[23:30:16.512] iteration:1875  t-loss:0.0635, loss-lb:0.0609, loss-ulb:0.0152, weight:0.17, lr:0.0009
[23:30:16.887] iteration:1876  t-loss:0.0736, loss-lb:0.0715, loss-ulb:0.0121, weight:0.17, lr:0.0009
[23:30:17.266] iteration:1877  t-loss:0.0346, loss-lb:0.0280, loss-ulb:0.0380, weight:0.17, lr:0.0009
[23:30:17.645] iteration:1878  t-loss:0.0838, loss-lb:0.0769, loss-ulb:0.0401, weight:0.17, lr:0.0009
[23:30:18.022] iteration:1879  t-loss:0.0312, loss-lb:0.0293, loss-ulb:0.0113, weight:0.17, lr:0.0009
[23:30:18.396] iteration:1880  t-loss:0.0369, loss-lb:0.0343, loss-ulb:0.0151, weight:0.17, lr:0.0009
[23:30:18.778] iteration:1881  t-loss:0.0739, loss-lb:0.0661, loss-ulb:0.0452, weight:0.17, lr:0.0009
[23:30:19.154] iteration:1882  t-loss:0.0546, loss-lb:0.0527, loss-ulb:0.0112, weight:0.17, lr:0.0009
[23:30:19.529] iteration:1883  t-loss:0.0330, loss-lb:0.0317, loss-ulb:0.0073, weight:0.17, lr:0.0009
[23:30:19.912] iteration:1884  t-loss:0.0329, loss-lb:0.0309, loss-ulb:0.0117, weight:0.17, lr:0.0009
[23:30:20.302] iteration:1885  t-loss:0.0794, loss-lb:0.0782, loss-ulb:0.0070, weight:0.17, lr:0.0009
[23:30:20.685] iteration:1886  t-loss:0.0424, loss-lb:0.0388, loss-ulb:0.0206, weight:0.17, lr:0.0009
[23:30:21.065] iteration:1887  t-loss:0.0310, loss-lb:0.0294, loss-ulb:0.0091, weight:0.17, lr:0.0009
[23:30:21.444] iteration:1888  t-loss:0.0618, loss-lb:0.0574, loss-ulb:0.0256, weight:0.17, lr:0.0009
[23:30:21.819] iteration:1889  t-loss:0.0353, loss-lb:0.0335, loss-ulb:0.0104, weight:0.17, lr:0.0009
[23:30:22.197] iteration:1890  t-loss:0.0536, loss-lb:0.0498, loss-ulb:0.0222, weight:0.17, lr:0.0009
[23:30:22.569] iteration:1891  t-loss:0.0429, loss-lb:0.0409, loss-ulb:0.0119, weight:0.17, lr:0.0009
[23:30:22.945] iteration:1892  t-loss:0.0246, loss-lb:0.0234, loss-ulb:0.0071, weight:0.17, lr:0.0009
[23:30:23.318] iteration:1893  t-loss:0.0589, loss-lb:0.0557, loss-ulb:0.0186, weight:0.17, lr:0.0009
[23:30:23.691] iteration:1894  t-loss:0.0299, loss-lb:0.0260, loss-ulb:0.0231, weight:0.17, lr:0.0009
[23:30:24.064] iteration:1895  t-loss:0.0712, loss-lb:0.0665, loss-ulb:0.0274, weight:0.17, lr:0.0009
[23:30:24.438] iteration:1896  t-loss:0.0688, loss-lb:0.0647, loss-ulb:0.0238, weight:0.17, lr:0.0009
[23:30:24.814] iteration:1897  t-loss:0.0554, loss-lb:0.0498, loss-ulb:0.0323, weight:0.17, lr:0.0009
[23:30:25.190] iteration:1898  t-loss:0.0327, loss-lb:0.0300, loss-ulb:0.0157, weight:0.17, lr:0.0009
[23:30:25.564] iteration:1899  t-loss:0.0610, loss-lb:0.0601, loss-ulb:0.0055, weight:0.17, lr:0.0009
[23:30:25.939] iteration:1900  t-loss:0.0561, loss-lb:0.0544, loss-ulb:0.0095, weight:0.17, lr:0.0009
[23:30:27.120] iteration:1901  t-loss:0.0254, loss-lb:0.0244, loss-ulb:0.0056, weight:0.17, lr:0.0009
[23:30:27.516] iteration:1902  t-loss:0.0923, loss-lb:0.0886, loss-ulb:0.0210, weight:0.17, lr:0.0009
[23:30:27.892] iteration:1903  t-loss:0.0388, loss-lb:0.0356, loss-ulb:0.0188, weight:0.17, lr:0.0009
[23:30:28.277] iteration:1904  t-loss:0.0501, loss-lb:0.0477, loss-ulb:0.0142, weight:0.17, lr:0.0009
[23:30:28.651] iteration:1905  t-loss:0.0264, loss-lb:0.0256, loss-ulb:0.0050, weight:0.17, lr:0.0009
[23:30:29.027] iteration:1906  t-loss:0.0750, loss-lb:0.0697, loss-ulb:0.0308, weight:0.17, lr:0.0009
[23:30:29.402] iteration:1907  t-loss:0.0333, loss-lb:0.0226, loss-ulb:0.0622, weight:0.17, lr:0.0009
[23:30:29.774] iteration:1908  t-loss:0.0362, loss-lb:0.0330, loss-ulb:0.0183, weight:0.17, lr:0.0009
[23:30:30.153] iteration:1909  t-loss:0.0389, loss-lb:0.0330, loss-ulb:0.0341, weight:0.17, lr:0.0009
[23:30:30.525] iteration:1910  t-loss:0.0275, loss-lb:0.0253, loss-ulb:0.0122, weight:0.17, lr:0.0009
[23:30:30.900] iteration:1911  t-loss:0.0273, loss-lb:0.0242, loss-ulb:0.0179, weight:0.17, lr:0.0009
[23:30:31.281] iteration:1912  t-loss:0.0636, loss-lb:0.0614, loss-ulb:0.0126, weight:0.17, lr:0.0009
[23:30:31.658] iteration:1913  t-loss:0.0863, loss-lb:0.0854, loss-ulb:0.0050, weight:0.17, lr:0.0009
[23:30:32.032] iteration:1914  t-loss:0.0592, loss-lb:0.0578, loss-ulb:0.0079, weight:0.17, lr:0.0009
[23:30:32.407] iteration:1915  t-loss:0.0461, loss-lb:0.0413, loss-ulb:0.0274, weight:0.17, lr:0.0009
[23:30:32.782] iteration:1916  t-loss:0.0695, loss-lb:0.0644, loss-ulb:0.0299, weight:0.17, lr:0.0009
[23:30:33.157] iteration:1917  t-loss:0.0669, loss-lb:0.0661, loss-ulb:0.0050, weight:0.17, lr:0.0009
[23:30:33.535] iteration:1918  t-loss:0.0493, loss-lb:0.0450, loss-ulb:0.0250, weight:0.17, lr:0.0009
[23:30:33.914] iteration:1919  t-loss:0.0346, loss-lb:0.0305, loss-ulb:0.0234, weight:0.17, lr:0.0009
[23:30:34.289] iteration:1920  t-loss:0.0361, loss-lb:0.0335, loss-ulb:0.0151, weight:0.17, lr:0.0009
[23:30:34.660] iteration:1921  t-loss:0.0744, loss-lb:0.0697, loss-ulb:0.0271, weight:0.17, lr:0.0009
[23:30:35.049] iteration:1922  t-loss:0.0661, loss-lb:0.0579, loss-ulb:0.0474, weight:0.17, lr:0.0009
[23:30:35.467] iteration:1923  t-loss:0.0729, loss-lb:0.0719, loss-ulb:0.0061, weight:0.17, lr:0.0009
[23:30:35.861] iteration:1924  t-loss:0.1064, loss-lb:0.1026, loss-ulb:0.0220, weight:0.17, lr:0.0009
[23:30:36.239] iteration:1925  t-loss:0.0298, loss-lb:0.0245, loss-ulb:0.0310, weight:0.17, lr:0.0009
[23:30:36.619] iteration:1926  t-loss:0.0811, loss-lb:0.0799, loss-ulb:0.0073, weight:0.17, lr:0.0009
[23:30:36.998] iteration:1927  t-loss:0.0984, loss-lb:0.0975, loss-ulb:0.0055, weight:0.17, lr:0.0009
[23:30:37.373] iteration:1928  t-loss:0.0379, loss-lb:0.0347, loss-ulb:0.0186, weight:0.17, lr:0.0009
[23:30:37.749] iteration:1929  t-loss:0.0409, loss-lb:0.0398, loss-ulb:0.0066, weight:0.17, lr:0.0009
[23:30:38.128] iteration:1930  t-loss:0.0750, loss-lb:0.0625, loss-ulb:0.0725, weight:0.17, lr:0.0009
[23:30:38.499] iteration:1931  t-loss:0.0423, loss-lb:0.0392, loss-ulb:0.0175, weight:0.17, lr:0.0009
[23:30:38.871] iteration:1932  t-loss:0.0290, loss-lb:0.0285, loss-ulb:0.0030, weight:0.17, lr:0.0009
[23:30:39.244] iteration:1933  t-loss:0.0453, loss-lb:0.0416, loss-ulb:0.0211, weight:0.17, lr:0.0009
[23:30:39.623] iteration:1934  t-loss:0.0875, loss-lb:0.0867, loss-ulb:0.0047, weight:0.17, lr:0.0009
[23:30:39.998] iteration:1935  t-loss:0.0420, loss-lb:0.0400, loss-ulb:0.0114, weight:0.17, lr:0.0009
[23:30:40.373] iteration:1936  t-loss:0.0382, loss-lb:0.0371, loss-ulb:0.0068, weight:0.17, lr:0.0009
[23:30:40.744] iteration:1937  t-loss:0.0439, loss-lb:0.0417, loss-ulb:0.0128, weight:0.17, lr:0.0009
[23:30:41.120] iteration:1938  t-loss:0.0712, loss-lb:0.0639, loss-ulb:0.0428, weight:0.17, lr:0.0009
[23:30:42.462] iteration:1939  t-loss:0.0408, loss-lb:0.0393, loss-ulb:0.0090, weight:0.17, lr:0.0009
[23:30:42.845] iteration:1940  t-loss:0.1504, loss-lb:0.1490, loss-ulb:0.0084, weight:0.17, lr:0.0009
[23:30:43.219] iteration:1941  t-loss:0.0488, loss-lb:0.0411, loss-ulb:0.0446, weight:0.17, lr:0.0009
[23:30:43.597] iteration:1942  t-loss:0.0305, loss-lb:0.0283, loss-ulb:0.0125, weight:0.17, lr:0.0009
[23:30:43.979] iteration:1943  t-loss:0.0682, loss-lb:0.0643, loss-ulb:0.0227, weight:0.17, lr:0.0009
[23:30:44.354] iteration:1944  t-loss:0.0428, loss-lb:0.0389, loss-ulb:0.0228, weight:0.17, lr:0.0009
[23:30:44.738] iteration:1945  t-loss:0.0457, loss-lb:0.0392, loss-ulb:0.0381, weight:0.17, lr:0.0009
[23:30:45.115] iteration:1946  t-loss:0.0387, loss-lb:0.0324, loss-ulb:0.0361, weight:0.17, lr:0.0009
[23:30:45.497] iteration:1947  t-loss:0.0536, loss-lb:0.0514, loss-ulb:0.0133, weight:0.17, lr:0.0009
[23:30:45.872] iteration:1948  t-loss:0.0377, loss-lb:0.0370, loss-ulb:0.0044, weight:0.17, lr:0.0009
[23:30:46.250] iteration:1949  t-loss:0.0368, loss-lb:0.0295, loss-ulb:0.0421, weight:0.17, lr:0.0009
[23:30:46.624] iteration:1950  t-loss:0.0406, loss-lb:0.0391, loss-ulb:0.0087, weight:0.17, lr:0.0009
[23:30:46.993] iteration:1951  t-loss:0.0631, loss-lb:0.0281, loss-ulb:0.1709, weight:0.20, lr:0.0009
[23:30:47.365] iteration:1952  t-loss:0.0452, loss-lb:0.0433, loss-ulb:0.0094, weight:0.20, lr:0.0009
[23:30:47.736] iteration:1953  t-loss:0.0446, loss-lb:0.0427, loss-ulb:0.0093, weight:0.20, lr:0.0009
[23:30:48.105] iteration:1954  t-loss:0.0567, loss-lb:0.0377, loss-ulb:0.0927, weight:0.20, lr:0.0009
[23:30:48.479] iteration:1955  t-loss:0.0404, loss-lb:0.0333, loss-ulb:0.0343, weight:0.20, lr:0.0009
[23:30:48.852] iteration:1956  t-loss:0.0629, loss-lb:0.0613, loss-ulb:0.0079, weight:0.20, lr:0.0009
[23:30:49.223] iteration:1957  t-loss:0.0268, loss-lb:0.0248, loss-ulb:0.0101, weight:0.20, lr:0.0009
[23:30:49.594] iteration:1958  t-loss:0.0314, loss-lb:0.0255, loss-ulb:0.0286, weight:0.20, lr:0.0009
[23:30:49.977] iteration:1959  t-loss:0.0671, loss-lb:0.0653, loss-ulb:0.0089, weight:0.20, lr:0.0009
[23:30:50.369] iteration:1960  t-loss:0.0430, loss-lb:0.0356, loss-ulb:0.0360, weight:0.20, lr:0.0009
[23:30:50.765] iteration:1961  t-loss:0.0391, loss-lb:0.0366, loss-ulb:0.0122, weight:0.20, lr:0.0009
[23:30:51.171] iteration:1962  t-loss:0.0255, loss-lb:0.0231, loss-ulb:0.0117, weight:0.20, lr:0.0009
[23:30:51.588] iteration:1963  t-loss:0.0417, loss-lb:0.0410, loss-ulb:0.0034, weight:0.20, lr:0.0009
[23:30:52.006] iteration:1964  t-loss:0.0398, loss-lb:0.0364, loss-ulb:0.0171, weight:0.20, lr:0.0009
[23:30:52.398] iteration:1965  t-loss:0.0301, loss-lb:0.0247, loss-ulb:0.0263, weight:0.20, lr:0.0009
[23:30:52.776] iteration:1966  t-loss:0.0443, loss-lb:0.0340, loss-ulb:0.0501, weight:0.20, lr:0.0009
[23:30:53.152] iteration:1967  t-loss:0.0512, loss-lb:0.0499, loss-ulb:0.0067, weight:0.20, lr:0.0009
[23:30:53.529] iteration:1968  t-loss:0.0791, loss-lb:0.0696, loss-ulb:0.0462, weight:0.20, lr:0.0009
[23:30:53.904] iteration:1969  t-loss:0.0300, loss-lb:0.0270, loss-ulb:0.0149, weight:0.20, lr:0.0009
[23:30:54.282] iteration:1970  t-loss:0.0403, loss-lb:0.0355, loss-ulb:0.0235, weight:0.20, lr:0.0009
[23:30:54.658] iteration:1971  t-loss:0.1195, loss-lb:0.1107, loss-ulb:0.0428, weight:0.20, lr:0.0009
[23:30:55.033] iteration:1972  t-loss:0.0245, loss-lb:0.0240, loss-ulb:0.0024, weight:0.20, lr:0.0009
[23:30:55.408] iteration:1973  t-loss:0.0348, loss-lb:0.0304, loss-ulb:0.0216, weight:0.20, lr:0.0009
[23:30:55.781] iteration:1974  t-loss:0.0386, loss-lb:0.0353, loss-ulb:0.0161, weight:0.20, lr:0.0009
[23:30:56.157] iteration:1975  t-loss:0.0421, loss-lb:0.0407, loss-ulb:0.0064, weight:0.20, lr:0.0009
[23:30:56.553] iteration:1976  t-loss:0.0664, loss-lb:0.0622, loss-ulb:0.0205, weight:0.20, lr:0.0009
[23:30:58.303] iteration:1977  t-loss:0.0302, loss-lb:0.0278, loss-ulb:0.0119, weight:0.20, lr:0.0009
[23:30:58.690] iteration:1978  t-loss:0.0519, loss-lb:0.0513, loss-ulb:0.0030, weight:0.20, lr:0.0009
[23:30:59.077] iteration:1979  t-loss:0.0403, loss-lb:0.0330, loss-ulb:0.0355, weight:0.20, lr:0.0009
[23:30:59.455] iteration:1980  t-loss:0.0458, loss-lb:0.0373, loss-ulb:0.0411, weight:0.20, lr:0.0009
[23:30:59.840] iteration:1981  t-loss:0.0577, loss-lb:0.0504, loss-ulb:0.0355, weight:0.20, lr:0.0009
[23:31:00.217] iteration:1982  t-loss:0.0344, loss-lb:0.0325, loss-ulb:0.0092, weight:0.20, lr:0.0009
[23:31:00.591] iteration:1983  t-loss:0.0538, loss-lb:0.0440, loss-ulb:0.0479, weight:0.20, lr:0.0009
[23:31:00.968] iteration:1984  t-loss:0.0340, loss-lb:0.0260, loss-ulb:0.0393, weight:0.20, lr:0.0009
[23:31:01.337] iteration:1985  t-loss:0.0467, loss-lb:0.0301, loss-ulb:0.0812, weight:0.20, lr:0.0009
[23:31:01.725] iteration:1986  t-loss:0.0544, loss-lb:0.0506, loss-ulb:0.0183, weight:0.20, lr:0.0009
[23:31:02.111] iteration:1987  t-loss:0.0462, loss-lb:0.0372, loss-ulb:0.0442, weight:0.20, lr:0.0009
[23:31:02.490] iteration:1988  t-loss:0.0621, loss-lb:0.0562, loss-ulb:0.0286, weight:0.20, lr:0.0009
[23:31:02.860] iteration:1989  t-loss:0.0292, loss-lb:0.0280, loss-ulb:0.0055, weight:0.20, lr:0.0009
[23:31:03.234] iteration:1990  t-loss:0.0974, loss-lb:0.0934, loss-ulb:0.0196, weight:0.20, lr:0.0009
[23:31:03.608] iteration:1991  t-loss:0.0633, loss-lb:0.0602, loss-ulb:0.0150, weight:0.20, lr:0.0009
[23:31:03.978] iteration:1992  t-loss:0.1528, loss-lb:0.1513, loss-ulb:0.0072, weight:0.20, lr:0.0009
[23:31:04.347] iteration:1993  t-loss:0.0470, loss-lb:0.0401, loss-ulb:0.0335, weight:0.20, lr:0.0009
[23:31:04.717] iteration:1994  t-loss:0.1041, loss-lb:0.0981, loss-ulb:0.0294, weight:0.20, lr:0.0009
[23:31:05.092] iteration:1995  t-loss:0.0882, loss-lb:0.0842, loss-ulb:0.0198, weight:0.20, lr:0.0009
[23:31:05.464] iteration:1996  t-loss:0.0465, loss-lb:0.0408, loss-ulb:0.0278, weight:0.20, lr:0.0009
[23:31:05.848] iteration:1997  t-loss:0.0519, loss-lb:0.0468, loss-ulb:0.0249, weight:0.20, lr:0.0009
[23:31:06.252] iteration:1998  t-loss:0.1134, loss-lb:0.1103, loss-ulb:0.0151, weight:0.20, lr:0.0009
[23:31:06.664] iteration:1999  t-loss:0.0422, loss-lb:0.0303, loss-ulb:0.0580, weight:0.20, lr:0.0009
[23:31:07.068] iteration:2000  t-loss:0.0686, loss-lb:0.0607, loss-ulb:0.0385, weight:0.20, lr:0.0009
[23:31:07.454] iteration:2001  t-loss:0.0573, loss-lb:0.0485, loss-ulb:0.0432, weight:0.20, lr:0.0009
[23:31:07.825] iteration:2002  t-loss:0.0407, loss-lb:0.0350, loss-ulb:0.0282, weight:0.20, lr:0.0009
[23:31:08.195] iteration:2003  t-loss:0.1003, loss-lb:0.0929, loss-ulb:0.0358, weight:0.20, lr:0.0009
[23:31:08.573] iteration:2004  t-loss:0.1001, loss-lb:0.0950, loss-ulb:0.0252, weight:0.20, lr:0.0009
[23:31:08.947] iteration:2005  t-loss:0.0841, loss-lb:0.0826, loss-ulb:0.0075, weight:0.20, lr:0.0009
[23:31:09.322] iteration:2006  t-loss:0.0646, loss-lb:0.0603, loss-ulb:0.0206, weight:0.20, lr:0.0009
[23:31:09.696] iteration:2007  t-loss:0.0685, loss-lb:0.0637, loss-ulb:0.0235, weight:0.20, lr:0.0009
[23:31:10.064] iteration:2008  t-loss:0.0651, loss-lb:0.0582, loss-ulb:0.0337, weight:0.20, lr:0.0009
[23:31:10.430] iteration:2009  t-loss:0.0447, loss-lb:0.0410, loss-ulb:0.0178, weight:0.20, lr:0.0009
[23:31:10.799] iteration:2010  t-loss:0.0793, loss-lb:0.0716, loss-ulb:0.0376, weight:0.20, lr:0.0009
[23:31:11.163] iteration:2011  t-loss:0.0379, loss-lb:0.0326, loss-ulb:0.0258, weight:0.20, lr:0.0009
[23:31:11.535] iteration:2012  t-loss:0.0974, loss-lb:0.0956, loss-ulb:0.0089, weight:0.20, lr:0.0009
[23:31:11.914] iteration:2013  t-loss:0.0650, loss-lb:0.0586, loss-ulb:0.0314, weight:0.20, lr:0.0009
[23:31:12.285] iteration:2014  t-loss:0.0612, loss-lb:0.0551, loss-ulb:0.0297, weight:0.20, lr:0.0009
[23:32:17.664] iteration 2014 : dice_score: 0.726681 best_dice: 0.726700
[23:32:17.664]  <<Test>> - Ep:52  - Dice-S/T:71.14/72.67, Best-S:71.14, Best-T:72.67
[23:32:17.664]           - AvgLoss(lb/ulb/all):0.06/0.03/0.07
[23:32:19.064] iteration:2015  t-loss:0.0361, loss-lb:0.0336, loss-ulb:0.0122, weight:0.20, lr:0.0009
[23:32:19.443] iteration:2016  t-loss:0.0361, loss-lb:0.0351, loss-ulb:0.0049, weight:0.20, lr:0.0009
[23:32:19.825] iteration:2017  t-loss:0.0627, loss-lb:0.0610, loss-ulb:0.0083, weight:0.20, lr:0.0009
[23:32:20.202] iteration:2018  t-loss:0.0605, loss-lb:0.0445, loss-ulb:0.0781, weight:0.20, lr:0.0009
[23:32:20.583] iteration:2019  t-loss:0.0908, loss-lb:0.0896, loss-ulb:0.0056, weight:0.20, lr:0.0009
[23:32:20.976] iteration:2020  t-loss:0.0652, loss-lb:0.0623, loss-ulb:0.0142, weight:0.20, lr:0.0009
[23:32:21.353] iteration:2021  t-loss:0.0370, loss-lb:0.0348, loss-ulb:0.0107, weight:0.20, lr:0.0009
[23:32:21.734] iteration:2022  t-loss:0.0631, loss-lb:0.0530, loss-ulb:0.0491, weight:0.20, lr:0.0009
[23:32:22.110] iteration:2023  t-loss:0.0532, loss-lb:0.0467, loss-ulb:0.0314, weight:0.20, lr:0.0009
[23:32:22.490] iteration:2024  t-loss:0.0388, loss-lb:0.0343, loss-ulb:0.0218, weight:0.20, lr:0.0009
[23:32:22.869] iteration:2025  t-loss:0.0333, loss-lb:0.0260, loss-ulb:0.0359, weight:0.20, lr:0.0009
[23:32:23.254] iteration:2026  t-loss:0.0803, loss-lb:0.0728, loss-ulb:0.0370, weight:0.20, lr:0.0009
[23:32:23.638] iteration:2027  t-loss:0.0625, loss-lb:0.0617, loss-ulb:0.0038, weight:0.20, lr:0.0009
[23:32:24.018] iteration:2028  t-loss:0.0906, loss-lb:0.0830, loss-ulb:0.0369, weight:0.20, lr:0.0009
[23:32:24.405] iteration:2029  t-loss:0.0953, loss-lb:0.0912, loss-ulb:0.0203, weight:0.20, lr:0.0009
[23:32:24.784] iteration:2030  t-loss:0.0313, loss-lb:0.0306, loss-ulb:0.0036, weight:0.20, lr:0.0009
[23:32:25.172] iteration:2031  t-loss:0.0292, loss-lb:0.0257, loss-ulb:0.0172, weight:0.20, lr:0.0009
[23:32:25.554] iteration:2032  t-loss:0.0434, loss-lb:0.0419, loss-ulb:0.0074, weight:0.20, lr:0.0009
[23:32:25.934] iteration:2033  t-loss:0.0310, loss-lb:0.0281, loss-ulb:0.0140, weight:0.20, lr:0.0009
[23:32:26.316] iteration:2034  t-loss:0.0659, loss-lb:0.0585, loss-ulb:0.0358, weight:0.20, lr:0.0009
[23:32:26.696] iteration:2035  t-loss:0.0406, loss-lb:0.0349, loss-ulb:0.0279, weight:0.20, lr:0.0009
[23:32:27.068] iteration:2036  t-loss:0.0292, loss-lb:0.0262, loss-ulb:0.0145, weight:0.20, lr:0.0009
[23:32:27.453] iteration:2037  t-loss:0.0336, loss-lb:0.0301, loss-ulb:0.0172, weight:0.20, lr:0.0009
[23:32:27.841] iteration:2038  t-loss:0.0409, loss-lb:0.0395, loss-ulb:0.0067, weight:0.20, lr:0.0009
[23:32:28.234] iteration:2039  t-loss:0.0289, loss-lb:0.0270, loss-ulb:0.0091, weight:0.20, lr:0.0009
[23:32:28.622] iteration:2040  t-loss:0.0827, loss-lb:0.0775, loss-ulb:0.0251, weight:0.20, lr:0.0009
[23:32:28.998] iteration:2041  t-loss:0.0348, loss-lb:0.0321, loss-ulb:0.0131, weight:0.20, lr:0.0009
[23:32:29.376] iteration:2042  t-loss:0.0355, loss-lb:0.0344, loss-ulb:0.0055, weight:0.20, lr:0.0009
[23:32:29.753] iteration:2043  t-loss:0.0370, loss-lb:0.0338, loss-ulb:0.0159, weight:0.20, lr:0.0009
[23:32:30.127] iteration:2044  t-loss:0.0351, loss-lb:0.0334, loss-ulb:0.0079, weight:0.20, lr:0.0009
[23:32:30.506] iteration:2045  t-loss:0.0445, loss-lb:0.0420, loss-ulb:0.0121, weight:0.20, lr:0.0009
[23:32:30.879] iteration:2046  t-loss:0.0547, loss-lb:0.0532, loss-ulb:0.0071, weight:0.20, lr:0.0009
[23:32:31.254] iteration:2047  t-loss:0.0350, loss-lb:0.0308, loss-ulb:0.0202, weight:0.20, lr:0.0009
[23:32:31.634] iteration:2048  t-loss:0.0663, loss-lb:0.0615, loss-ulb:0.0237, weight:0.20, lr:0.0009
[23:32:32.010] iteration:2049  t-loss:0.0397, loss-lb:0.0366, loss-ulb:0.0152, weight:0.20, lr:0.0009
[23:32:32.384] iteration:2050  t-loss:0.0577, loss-lb:0.0534, loss-ulb:0.0209, weight:0.20, lr:0.0009
[23:32:32.763] iteration:2051  t-loss:0.0876, loss-lb:0.0824, loss-ulb:0.0254, weight:0.20, lr:0.0009
[23:32:33.138] iteration:2052  t-loss:0.0532, loss-lb:0.0484, loss-ulb:0.0235, weight:0.20, lr:0.0009
[23:32:34.457] iteration:2053  t-loss:0.0373, loss-lb:0.0244, loss-ulb:0.0630, weight:0.20, lr:0.0009
[23:32:34.843] iteration:2054  t-loss:0.0429, loss-lb:0.0424, loss-ulb:0.0025, weight:0.20, lr:0.0009
[23:32:35.225] iteration:2055  t-loss:0.0607, loss-lb:0.0569, loss-ulb:0.0186, weight:0.20, lr:0.0009
[23:32:35.608] iteration:2056  t-loss:0.0385, loss-lb:0.0336, loss-ulb:0.0240, weight:0.20, lr:0.0009
[23:32:35.993] iteration:2057  t-loss:0.0401, loss-lb:0.0387, loss-ulb:0.0067, weight:0.20, lr:0.0009
[23:32:36.371] iteration:2058  t-loss:0.0326, loss-lb:0.0314, loss-ulb:0.0060, weight:0.20, lr:0.0009
[23:32:36.751] iteration:2059  t-loss:0.0271, loss-lb:0.0235, loss-ulb:0.0179, weight:0.20, lr:0.0009
[23:32:37.132] iteration:2060  t-loss:0.0864, loss-lb:0.0852, loss-ulb:0.0058, weight:0.20, lr:0.0009
[23:32:37.508] iteration:2061  t-loss:0.0267, loss-lb:0.0256, loss-ulb:0.0051, weight:0.20, lr:0.0009
[23:32:37.886] iteration:2062  t-loss:0.0401, loss-lb:0.0348, loss-ulb:0.0260, weight:0.20, lr:0.0009
[23:32:38.261] iteration:2063  t-loss:0.0465, loss-lb:0.0420, loss-ulb:0.0216, weight:0.20, lr:0.0009
[23:32:38.636] iteration:2064  t-loss:0.0492, loss-lb:0.0477, loss-ulb:0.0074, weight:0.20, lr:0.0009
[23:32:39.011] iteration:2065  t-loss:0.0302, loss-lb:0.0282, loss-ulb:0.0100, weight:0.20, lr:0.0009
[23:32:39.389] iteration:2066  t-loss:0.0331, loss-lb:0.0290, loss-ulb:0.0199, weight:0.20, lr:0.0009
[23:32:39.763] iteration:2067  t-loss:0.0556, loss-lb:0.0375, loss-ulb:0.0882, weight:0.20, lr:0.0009
[23:32:40.144] iteration:2068  t-loss:0.0616, loss-lb:0.0590, loss-ulb:0.0129, weight:0.20, lr:0.0009
[23:32:40.519] iteration:2069  t-loss:0.0444, loss-lb:0.0391, loss-ulb:0.0260, weight:0.20, lr:0.0009
[23:32:40.897] iteration:2070  t-loss:0.0369, loss-lb:0.0302, loss-ulb:0.0327, weight:0.20, lr:0.0009
[23:32:41.272] iteration:2071  t-loss:0.0890, loss-lb:0.0846, loss-ulb:0.0219, weight:0.20, lr:0.0009
[23:32:41.650] iteration:2072  t-loss:0.0357, loss-lb:0.0315, loss-ulb:0.0205, weight:0.20, lr:0.0009
[23:32:42.027] iteration:2073  t-loss:0.0283, loss-lb:0.0274, loss-ulb:0.0043, weight:0.20, lr:0.0009
[23:32:42.406] iteration:2074  t-loss:0.0279, loss-lb:0.0262, loss-ulb:0.0085, weight:0.20, lr:0.0009
[23:32:42.804] iteration:2075  t-loss:0.0768, loss-lb:0.0614, loss-ulb:0.0751, weight:0.20, lr:0.0009
[23:32:43.222] iteration:2076  t-loss:0.0518, loss-lb:0.0451, loss-ulb:0.0329, weight:0.20, lr:0.0009
[23:32:43.617] iteration:2077  t-loss:0.0662, loss-lb:0.0535, loss-ulb:0.0619, weight:0.20, lr:0.0009
[23:32:43.997] iteration:2078  t-loss:0.0373, loss-lb:0.0323, loss-ulb:0.0247, weight:0.20, lr:0.0009
[23:32:44.378] iteration:2079  t-loss:0.0573, loss-lb:0.0511, loss-ulb:0.0301, weight:0.20, lr:0.0009
[23:32:44.749] iteration:2080  t-loss:0.0408, loss-lb:0.0401, loss-ulb:0.0037, weight:0.20, lr:0.0009
[23:32:45.127] iteration:2081  t-loss:0.0374, loss-lb:0.0364, loss-ulb:0.0045, weight:0.20, lr:0.0009
[23:32:45.508] iteration:2082  t-loss:0.0583, loss-lb:0.0517, loss-ulb:0.0322, weight:0.20, lr:0.0009
[23:32:45.877] iteration:2083  t-loss:0.0352, loss-lb:0.0275, loss-ulb:0.0376, weight:0.20, lr:0.0009
[23:32:46.253] iteration:2084  t-loss:0.0363, loss-lb:0.0360, loss-ulb:0.0011, weight:0.20, lr:0.0009
[23:32:46.631] iteration:2085  t-loss:0.0857, loss-lb:0.0811, loss-ulb:0.0225, weight:0.20, lr:0.0009
[23:32:47.005] iteration:2086  t-loss:0.0344, loss-lb:0.0307, loss-ulb:0.0180, weight:0.20, lr:0.0009
[23:32:47.381] iteration:2087  t-loss:0.0782, loss-lb:0.0770, loss-ulb:0.0055, weight:0.20, lr:0.0009
[23:32:47.760] iteration:2088  t-loss:0.0612, loss-lb:0.0574, loss-ulb:0.0183, weight:0.20, lr:0.0009
[23:32:48.136] iteration:2089  t-loss:0.0321, loss-lb:0.0275, loss-ulb:0.0228, weight:0.20, lr:0.0009
[23:32:48.512] iteration:2090  t-loss:0.0593, loss-lb:0.0531, loss-ulb:0.0304, weight:0.20, lr:0.0009
[23:32:49.755] iteration:2091  t-loss:0.0981, loss-lb:0.0973, loss-ulb:0.0036, weight:0.20, lr:0.0009
[23:32:50.151] iteration:2092  t-loss:0.0272, loss-lb:0.0236, loss-ulb:0.0178, weight:0.20, lr:0.0009
[23:32:50.533] iteration:2093  t-loss:0.0369, loss-lb:0.0300, loss-ulb:0.0337, weight:0.20, lr:0.0009
[23:32:50.918] iteration:2094  t-loss:0.0318, loss-lb:0.0287, loss-ulb:0.0147, weight:0.20, lr:0.0009
[23:32:51.304] iteration:2095  t-loss:0.0560, loss-lb:0.0526, loss-ulb:0.0163, weight:0.20, lr:0.0009
[23:32:51.689] iteration:2096  t-loss:0.0637, loss-lb:0.0607, loss-ulb:0.0145, weight:0.20, lr:0.0009
[23:32:52.068] iteration:2097  t-loss:0.0719, loss-lb:0.0640, loss-ulb:0.0383, weight:0.20, lr:0.0009
[23:32:52.447] iteration:2098  t-loss:0.0660, loss-lb:0.0614, loss-ulb:0.0226, weight:0.20, lr:0.0009
[23:32:52.826] iteration:2099  t-loss:0.0396, loss-lb:0.0389, loss-ulb:0.0038, weight:0.20, lr:0.0009
[23:32:53.202] iteration:2100  t-loss:0.0361, loss-lb:0.0337, loss-ulb:0.0117, weight:0.20, lr:0.0009
[23:32:53.577] iteration:2101  t-loss:0.0440, loss-lb:0.0419, loss-ulb:0.0086, weight:0.24, lr:0.0009
[23:32:53.958] iteration:2102  t-loss:0.0467, loss-lb:0.0349, loss-ulb:0.0488, weight:0.24, lr:0.0009
[23:32:54.332] iteration:2103  t-loss:0.1160, loss-lb:0.1132, loss-ulb:0.0118, weight:0.24, lr:0.0009
[23:32:54.709] iteration:2104  t-loss:0.0598, loss-lb:0.0554, loss-ulb:0.0184, weight:0.24, lr:0.0009
[23:32:55.086] iteration:2105  t-loss:0.0273, loss-lb:0.0262, loss-ulb:0.0047, weight:0.24, lr:0.0009
[23:32:55.458] iteration:2106  t-loss:0.0379, loss-lb:0.0273, loss-ulb:0.0438, weight:0.24, lr:0.0009
[23:32:55.837] iteration:2107  t-loss:0.0596, loss-lb:0.0543, loss-ulb:0.0217, weight:0.24, lr:0.0009
[23:32:56.210] iteration:2108  t-loss:0.0297, loss-lb:0.0285, loss-ulb:0.0049, weight:0.24, lr:0.0009
[23:32:56.589] iteration:2109  t-loss:0.0502, loss-lb:0.0446, loss-ulb:0.0235, weight:0.24, lr:0.0009
[23:32:56.966] iteration:2110  t-loss:0.0641, loss-lb:0.0612, loss-ulb:0.0121, weight:0.24, lr:0.0009
[23:32:57.354] iteration:2111  t-loss:0.1239, loss-lb:0.1205, loss-ulb:0.0143, weight:0.24, lr:0.0009
[23:32:57.734] iteration:2112  t-loss:0.0458, loss-lb:0.0435, loss-ulb:0.0095, weight:0.24, lr:0.0009
[23:32:58.143] iteration:2113  t-loss:0.0411, loss-lb:0.0352, loss-ulb:0.0247, weight:0.24, lr:0.0009
[23:32:58.536] iteration:2114  t-loss:0.0373, loss-lb:0.0307, loss-ulb:0.0271, weight:0.24, lr:0.0009
[23:32:58.938] iteration:2115  t-loss:0.0682, loss-lb:0.0584, loss-ulb:0.0408, weight:0.24, lr:0.0009
[23:32:59.332] iteration:2116  t-loss:0.0800, loss-lb:0.0763, loss-ulb:0.0153, weight:0.24, lr:0.0009
[23:32:59.709] iteration:2117  t-loss:0.0643, loss-lb:0.0633, loss-ulb:0.0040, weight:0.24, lr:0.0009
[23:33:00.083] iteration:2118  t-loss:0.0400, loss-lb:0.0380, loss-ulb:0.0086, weight:0.24, lr:0.0009
[23:33:00.468] iteration:2119  t-loss:0.0720, loss-lb:0.0684, loss-ulb:0.0148, weight:0.24, lr:0.0009
[23:33:00.845] iteration:2120  t-loss:0.0469, loss-lb:0.0392, loss-ulb:0.0315, weight:0.24, lr:0.0009
[23:33:01.220] iteration:2121  t-loss:0.0347, loss-lb:0.0318, loss-ulb:0.0123, weight:0.24, lr:0.0009
[23:33:01.590] iteration:2122  t-loss:0.0545, loss-lb:0.0461, loss-ulb:0.0347, weight:0.24, lr:0.0009
[23:33:01.960] iteration:2123  t-loss:0.0404, loss-lb:0.0304, loss-ulb:0.0416, weight:0.24, lr:0.0009
[23:33:02.340] iteration:2124  t-loss:0.0588, loss-lb:0.0562, loss-ulb:0.0106, weight:0.24, lr:0.0009
[23:33:02.711] iteration:2125  t-loss:0.0549, loss-lb:0.0464, loss-ulb:0.0352, weight:0.24, lr:0.0009
[23:33:03.082] iteration:2126  t-loss:0.0648, loss-lb:0.0605, loss-ulb:0.0181, weight:0.24, lr:0.0009
[23:33:03.458] iteration:2127  t-loss:0.0522, loss-lb:0.0488, loss-ulb:0.0142, weight:0.24, lr:0.0009
[23:33:03.821] iteration:2128  t-loss:0.0272, loss-lb:0.0222, loss-ulb:0.0207, weight:0.24, lr:0.0009
[23:33:05.353] iteration:2129  t-loss:0.0310, loss-lb:0.0263, loss-ulb:0.0194, weight:0.24, lr:0.0009
[23:33:05.743] iteration:2130  t-loss:0.0402, loss-lb:0.0349, loss-ulb:0.0217, weight:0.24, lr:0.0009
[23:33:06.125] iteration:2131  t-loss:0.0645, loss-lb:0.0563, loss-ulb:0.0337, weight:0.24, lr:0.0009
[23:33:06.504] iteration:2132  t-loss:0.0499, loss-lb:0.0480, loss-ulb:0.0081, weight:0.24, lr:0.0009
[23:33:06.893] iteration:2133  t-loss:0.0580, loss-lb:0.0513, loss-ulb:0.0277, weight:0.24, lr:0.0009
[23:33:07.283] iteration:2134  t-loss:0.0574, loss-lb:0.0552, loss-ulb:0.0090, weight:0.24, lr:0.0009
[23:33:07.664] iteration:2135  t-loss:0.0641, loss-lb:0.0627, loss-ulb:0.0057, weight:0.24, lr:0.0009
[23:33:08.035] iteration:2136  t-loss:0.0682, loss-lb:0.0324, loss-ulb:0.1482, weight:0.24, lr:0.0009
[23:33:08.412] iteration:2137  t-loss:0.0354, loss-lb:0.0286, loss-ulb:0.0283, weight:0.24, lr:0.0009
[23:33:08.787] iteration:2138  t-loss:0.0785, loss-lb:0.0496, loss-ulb:0.1196, weight:0.24, lr:0.0009
[23:33:09.167] iteration:2139  t-loss:0.0721, loss-lb:0.0664, loss-ulb:0.0235, weight:0.24, lr:0.0009
[23:33:09.539] iteration:2140  t-loss:0.0544, loss-lb:0.0519, loss-ulb:0.0100, weight:0.24, lr:0.0009
[23:33:09.924] iteration:2141  t-loss:0.1121, loss-lb:0.1093, loss-ulb:0.0114, weight:0.24, lr:0.0009
[23:33:10.294] iteration:2142  t-loss:0.0281, loss-lb:0.0263, loss-ulb:0.0076, weight:0.24, lr:0.0009
[23:33:10.674] iteration:2143  t-loss:0.0704, loss-lb:0.0695, loss-ulb:0.0034, weight:0.24, lr:0.0009
[23:33:11.049] iteration:2144  t-loss:0.0361, loss-lb:0.0312, loss-ulb:0.0202, weight:0.24, lr:0.0009
[23:33:11.426] iteration:2145  t-loss:0.0492, loss-lb:0.0481, loss-ulb:0.0047, weight:0.24, lr:0.0009
[23:33:11.798] iteration:2146  t-loss:0.0342, loss-lb:0.0328, loss-ulb:0.0056, weight:0.24, lr:0.0009
[23:33:12.175] iteration:2147  t-loss:0.0626, loss-lb:0.0590, loss-ulb:0.0148, weight:0.24, lr:0.0009
[23:33:12.554] iteration:2148  t-loss:0.0389, loss-lb:0.0357, loss-ulb:0.0133, weight:0.24, lr:0.0009
[23:33:12.946] iteration:2149  t-loss:0.0371, loss-lb:0.0344, loss-ulb:0.0111, weight:0.24, lr:0.0009
[23:33:13.339] iteration:2150  t-loss:0.0454, loss-lb:0.0436, loss-ulb:0.0075, weight:0.24, lr:0.0009
[23:33:13.739] iteration:2151  t-loss:0.0834, loss-lb:0.0782, loss-ulb:0.0217, weight:0.24, lr:0.0009
[23:33:14.155] iteration:2152  t-loss:0.0487, loss-lb:0.0435, loss-ulb:0.0215, weight:0.24, lr:0.0009
[23:33:14.593] iteration:2153  t-loss:0.0835, loss-lb:0.0798, loss-ulb:0.0150, weight:0.24, lr:0.0009
[23:33:14.993] iteration:2154  t-loss:0.0266, loss-lb:0.0239, loss-ulb:0.0109, weight:0.24, lr:0.0009
[23:33:15.386] iteration:2155  t-loss:0.0830, loss-lb:0.0798, loss-ulb:0.0132, weight:0.24, lr:0.0009
[23:33:15.773] iteration:2156  t-loss:0.0714, loss-lb:0.0671, loss-ulb:0.0178, weight:0.24, lr:0.0009
[23:33:16.154] iteration:2157  t-loss:0.0468, loss-lb:0.0403, loss-ulb:0.0269, weight:0.24, lr:0.0009
[23:33:16.537] iteration:2158  t-loss:0.0382, loss-lb:0.0296, loss-ulb:0.0355, weight:0.24, lr:0.0009
[23:33:16.908] iteration:2159  t-loss:0.0396, loss-lb:0.0307, loss-ulb:0.0368, weight:0.24, lr:0.0009
[23:33:17.283] iteration:2160  t-loss:0.0647, loss-lb:0.0581, loss-ulb:0.0275, weight:0.24, lr:0.0009
[23:33:17.657] iteration:2161  t-loss:0.0646, loss-lb:0.0639, loss-ulb:0.0026, weight:0.24, lr:0.0009
[23:33:18.030] iteration:2162  t-loss:0.0474, loss-lb:0.0462, loss-ulb:0.0052, weight:0.24, lr:0.0009
[23:33:18.404] iteration:2163  t-loss:0.0372, loss-lb:0.0334, loss-ulb:0.0158, weight:0.24, lr:0.0009
[23:33:18.780] iteration:2164  t-loss:0.0395, loss-lb:0.0330, loss-ulb:0.0269, weight:0.24, lr:0.0009
[23:33:19.160] iteration:2165  t-loss:0.0412, loss-lb:0.0356, loss-ulb:0.0235, weight:0.24, lr:0.0009
[23:33:19.541] iteration:2166  t-loss:0.0635, loss-lb:0.0572, loss-ulb:0.0259, weight:0.24, lr:0.0009
[23:34:23.031] iteration 2166 : dice_score: 0.722388 best_dice: 0.726700
[23:34:23.031]  <<Test>> - Ep:56  - Dice-S/T:61.06/72.24, Best-S:71.14, Best-T:72.67
[23:34:23.031]           - AvgLoss(lb/ulb/all):0.05/0.02/0.05
[23:34:24.279] iteration:2167  t-loss:0.0853, loss-lb:0.0819, loss-ulb:0.0139, weight:0.24, lr:0.0009
[23:34:24.668] iteration:2168  t-loss:0.0422, loss-lb:0.0350, loss-ulb:0.0297, weight:0.24, lr:0.0009
[23:34:25.050] iteration:2169  t-loss:0.0375, loss-lb:0.0327, loss-ulb:0.0198, weight:0.24, lr:0.0009
[23:34:25.425] iteration:2170  t-loss:0.0262, loss-lb:0.0247, loss-ulb:0.0061, weight:0.24, lr:0.0009
[23:34:25.809] iteration:2171  t-loss:0.0746, loss-lb:0.0706, loss-ulb:0.0168, weight:0.24, lr:0.0009
[23:34:26.188] iteration:2172  t-loss:0.0649, loss-lb:0.0633, loss-ulb:0.0066, weight:0.24, lr:0.0009
[23:34:26.562] iteration:2173  t-loss:0.0405, loss-lb:0.0369, loss-ulb:0.0151, weight:0.24, lr:0.0009
[23:34:26.946] iteration:2174  t-loss:0.0264, loss-lb:0.0233, loss-ulb:0.0129, weight:0.24, lr:0.0009
[23:34:27.327] iteration:2175  t-loss:0.0573, loss-lb:0.0551, loss-ulb:0.0093, weight:0.24, lr:0.0009
[23:34:27.710] iteration:2176  t-loss:0.0530, loss-lb:0.0487, loss-ulb:0.0180, weight:0.24, lr:0.0009
[23:34:28.095] iteration:2177  t-loss:0.0643, loss-lb:0.0629, loss-ulb:0.0059, weight:0.24, lr:0.0009
[23:34:28.476] iteration:2178  t-loss:0.0613, loss-lb:0.0603, loss-ulb:0.0041, weight:0.24, lr:0.0009
[23:34:28.858] iteration:2179  t-loss:0.0613, loss-lb:0.0548, loss-ulb:0.0268, weight:0.24, lr:0.0009
[23:34:29.239] iteration:2180  t-loss:0.0627, loss-lb:0.0570, loss-ulb:0.0236, weight:0.24, lr:0.0009
[23:34:29.620] iteration:2181  t-loss:0.0503, loss-lb:0.0496, loss-ulb:0.0031, weight:0.24, lr:0.0009
[23:34:29.998] iteration:2182  t-loss:0.0243, loss-lb:0.0215, loss-ulb:0.0117, weight:0.24, lr:0.0009
[23:34:30.382] iteration:2183  t-loss:0.0374, loss-lb:0.0352, loss-ulb:0.0092, weight:0.24, lr:0.0009
[23:34:30.763] iteration:2184  t-loss:0.0495, loss-lb:0.0455, loss-ulb:0.0164, weight:0.24, lr:0.0009
[23:34:31.144] iteration:2185  t-loss:0.0338, loss-lb:0.0289, loss-ulb:0.0202, weight:0.24, lr:0.0009
[23:34:31.522] iteration:2186  t-loss:0.0309, loss-lb:0.0298, loss-ulb:0.0047, weight:0.24, lr:0.0009
[23:34:31.908] iteration:2187  t-loss:0.0829, loss-lb:0.0729, loss-ulb:0.0412, weight:0.24, lr:0.0009
[23:34:32.297] iteration:2188  t-loss:0.0506, loss-lb:0.0467, loss-ulb:0.0164, weight:0.24, lr:0.0009
[23:34:32.678] iteration:2189  t-loss:0.0308, loss-lb:0.0300, loss-ulb:0.0035, weight:0.24, lr:0.0009
[23:34:33.073] iteration:2190  t-loss:0.0642, loss-lb:0.0585, loss-ulb:0.0238, weight:0.24, lr:0.0009
[23:34:33.462] iteration:2191  t-loss:0.0623, loss-lb:0.0535, loss-ulb:0.0362, weight:0.24, lr:0.0009
[23:34:33.848] iteration:2192  t-loss:0.0540, loss-lb:0.0508, loss-ulb:0.0131, weight:0.24, lr:0.0009
[23:34:34.235] iteration:2193  t-loss:0.1076, loss-lb:0.0973, loss-ulb:0.0426, weight:0.24, lr:0.0009
[23:34:34.610] iteration:2194  t-loss:0.0516, loss-lb:0.0505, loss-ulb:0.0045, weight:0.24, lr:0.0009
[23:34:34.996] iteration:2195  t-loss:0.0606, loss-lb:0.0542, loss-ulb:0.0262, weight:0.24, lr:0.0009
[23:34:35.382] iteration:2196  t-loss:0.0468, loss-lb:0.0370, loss-ulb:0.0406, weight:0.24, lr:0.0009
[23:34:35.756] iteration:2197  t-loss:0.0616, loss-lb:0.0589, loss-ulb:0.0112, weight:0.24, lr:0.0009
[23:34:36.129] iteration:2198  t-loss:0.0348, loss-lb:0.0312, loss-ulb:0.0150, weight:0.24, lr:0.0009
[23:34:36.506] iteration:2199  t-loss:0.0622, loss-lb:0.0564, loss-ulb:0.0237, weight:0.24, lr:0.0009
[23:34:36.881] iteration:2200  t-loss:0.0588, loss-lb:0.0557, loss-ulb:0.0128, weight:0.24, lr:0.0009
[23:34:37.254] iteration:2201  t-loss:0.0853, loss-lb:0.0832, loss-ulb:0.0091, weight:0.24, lr:0.0009
[23:34:37.627] iteration:2202  t-loss:0.0325, loss-lb:0.0268, loss-ulb:0.0234, weight:0.24, lr:0.0009
[23:34:38.003] iteration:2203  t-loss:0.0607, loss-lb:0.0592, loss-ulb:0.0064, weight:0.24, lr:0.0009
[23:34:38.381] iteration:2204  t-loss:0.0688, loss-lb:0.0655, loss-ulb:0.0137, weight:0.24, lr:0.0009
[23:34:39.605] iteration:2205  t-loss:0.1359, loss-lb:0.1352, loss-ulb:0.0026, weight:0.24, lr:0.0009
[23:34:39.993] iteration:2206  t-loss:0.0635, loss-lb:0.0568, loss-ulb:0.0277, weight:0.24, lr:0.0009
[23:34:40.379] iteration:2207  t-loss:0.0959, loss-lb:0.0843, loss-ulb:0.0483, weight:0.24, lr:0.0009
[23:34:40.753] iteration:2208  t-loss:0.0623, loss-lb:0.0602, loss-ulb:0.0084, weight:0.24, lr:0.0009
[23:34:41.126] iteration:2209  t-loss:0.0420, loss-lb:0.0367, loss-ulb:0.0220, weight:0.24, lr:0.0009
[23:34:41.503] iteration:2210  t-loss:0.0633, loss-lb:0.0604, loss-ulb:0.0120, weight:0.24, lr:0.0009
[23:34:41.885] iteration:2211  t-loss:0.0656, loss-lb:0.0585, loss-ulb:0.0293, weight:0.24, lr:0.0009
[23:34:42.257] iteration:2212  t-loss:0.0312, loss-lb:0.0289, loss-ulb:0.0095, weight:0.24, lr:0.0009
[23:34:42.632] iteration:2213  t-loss:0.0597, loss-lb:0.0551, loss-ulb:0.0190, weight:0.24, lr:0.0009
[23:34:43.019] iteration:2214  t-loss:0.0944, loss-lb:0.0899, loss-ulb:0.0184, weight:0.24, lr:0.0009
[23:34:43.397] iteration:2215  t-loss:0.0734, loss-lb:0.0612, loss-ulb:0.0505, weight:0.24, lr:0.0009
[23:34:43.770] iteration:2216  t-loss:0.0701, loss-lb:0.0655, loss-ulb:0.0191, weight:0.24, lr:0.0009
[23:34:44.144] iteration:2217  t-loss:0.0337, loss-lb:0.0274, loss-ulb:0.0261, weight:0.24, lr:0.0009
[23:34:44.523] iteration:2218  t-loss:0.0800, loss-lb:0.0763, loss-ulb:0.0155, weight:0.24, lr:0.0009
[23:34:44.899] iteration:2219  t-loss:0.0323, loss-lb:0.0279, loss-ulb:0.0183, weight:0.24, lr:0.0009
[23:34:45.274] iteration:2220  t-loss:0.0555, loss-lb:0.0544, loss-ulb:0.0044, weight:0.24, lr:0.0009
[23:34:45.651] iteration:2221  t-loss:0.0353, loss-lb:0.0294, loss-ulb:0.0246, weight:0.24, lr:0.0009
[23:34:46.025] iteration:2222  t-loss:0.0387, loss-lb:0.0337, loss-ulb:0.0207, weight:0.24, lr:0.0009
[23:34:46.401] iteration:2223  t-loss:0.0294, loss-lb:0.0248, loss-ulb:0.0191, weight:0.24, lr:0.0009
[23:34:46.780] iteration:2224  t-loss:0.0376, loss-lb:0.0343, loss-ulb:0.0134, weight:0.24, lr:0.0009
[23:34:47.160] iteration:2225  t-loss:0.0604, loss-lb:0.0551, loss-ulb:0.0221, weight:0.24, lr:0.0009
[23:34:47.538] iteration:2226  t-loss:0.0492, loss-lb:0.0465, loss-ulb:0.0113, weight:0.24, lr:0.0009
[23:34:47.920] iteration:2227  t-loss:0.0879, loss-lb:0.0858, loss-ulb:0.0087, weight:0.24, lr:0.0009
[23:34:48.323] iteration:2228  t-loss:0.0602, loss-lb:0.0564, loss-ulb:0.0156, weight:0.24, lr:0.0009
[23:34:48.734] iteration:2229  t-loss:0.0474, loss-lb:0.0421, loss-ulb:0.0219, weight:0.24, lr:0.0009
[23:34:49.140] iteration:2230  t-loss:0.0637, loss-lb:0.0613, loss-ulb:0.0097, weight:0.24, lr:0.0009
[23:34:49.556] iteration:2231  t-loss:0.0298, loss-lb:0.0238, loss-ulb:0.0250, weight:0.24, lr:0.0009
[23:34:49.943] iteration:2232  t-loss:0.0397, loss-lb:0.0304, loss-ulb:0.0382, weight:0.24, lr:0.0009
[23:34:50.328] iteration:2233  t-loss:0.0283, loss-lb:0.0238, loss-ulb:0.0186, weight:0.24, lr:0.0009
[23:34:50.711] iteration:2234  t-loss:0.0564, loss-lb:0.0515, loss-ulb:0.0202, weight:0.24, lr:0.0009
[23:34:51.101] iteration:2235  t-loss:0.0431, loss-lb:0.0375, loss-ulb:0.0232, weight:0.24, lr:0.0009
[23:34:51.476] iteration:2236  t-loss:0.0369, loss-lb:0.0328, loss-ulb:0.0167, weight:0.24, lr:0.0009
[23:34:51.852] iteration:2237  t-loss:0.0771, loss-lb:0.0739, loss-ulb:0.0133, weight:0.24, lr:0.0009
[23:34:52.230] iteration:2238  t-loss:0.0288, loss-lb:0.0244, loss-ulb:0.0182, weight:0.24, lr:0.0009
[23:34:52.606] iteration:2239  t-loss:0.0286, loss-lb:0.0240, loss-ulb:0.0190, weight:0.24, lr:0.0009
[23:34:52.980] iteration:2240  t-loss:0.0545, loss-lb:0.0504, loss-ulb:0.0167, weight:0.24, lr:0.0009
[23:34:53.354] iteration:2241  t-loss:0.0299, loss-lb:0.0284, loss-ulb:0.0061, weight:0.24, lr:0.0009
[23:34:53.734] iteration:2242  t-loss:0.0584, loss-lb:0.0530, loss-ulb:0.0219, weight:0.24, lr:0.0009
[23:34:54.887] iteration:2243  t-loss:0.0756, loss-lb:0.0752, loss-ulb:0.0018, weight:0.24, lr:0.0009
[23:34:55.292] iteration:2244  t-loss:0.0488, loss-lb:0.0483, loss-ulb:0.0021, weight:0.24, lr:0.0009
[23:34:55.684] iteration:2245  t-loss:0.0610, loss-lb:0.0588, loss-ulb:0.0090, weight:0.24, lr:0.0009
[23:34:56.065] iteration:2246  t-loss:0.0300, loss-lb:0.0242, loss-ulb:0.0240, weight:0.24, lr:0.0009
[23:34:56.447] iteration:2247  t-loss:0.0391, loss-lb:0.0352, loss-ulb:0.0158, weight:0.24, lr:0.0009
[23:34:56.828] iteration:2248  t-loss:0.0333, loss-lb:0.0283, loss-ulb:0.0208, weight:0.24, lr:0.0009
[23:34:57.208] iteration:2249  t-loss:0.0537, loss-lb:0.0448, loss-ulb:0.0369, weight:0.24, lr:0.0009
[23:34:57.586] iteration:2250  t-loss:0.0917, loss-lb:0.0906, loss-ulb:0.0048, weight:0.24, lr:0.0009
[23:34:57.965] iteration:2251  t-loss:0.0227, loss-lb:0.0199, loss-ulb:0.0098, weight:0.28, lr:0.0009
[23:34:58.344] iteration:2252  t-loss:0.0341, loss-lb:0.0333, loss-ulb:0.0028, weight:0.28, lr:0.0009
[23:34:58.728] iteration:2253  t-loss:0.0640, loss-lb:0.0619, loss-ulb:0.0072, weight:0.28, lr:0.0009
[23:34:59.108] iteration:2254  t-loss:0.0554, loss-lb:0.0530, loss-ulb:0.0085, weight:0.28, lr:0.0009
[23:34:59.486] iteration:2255  t-loss:0.0354, loss-lb:0.0300, loss-ulb:0.0189, weight:0.28, lr:0.0009
[23:34:59.866] iteration:2256  t-loss:0.0351, loss-lb:0.0336, loss-ulb:0.0053, weight:0.28, lr:0.0009
[23:35:00.243] iteration:2257  t-loss:0.0692, loss-lb:0.0636, loss-ulb:0.0199, weight:0.28, lr:0.0009
[23:35:00.619] iteration:2258  t-loss:0.0376, loss-lb:0.0319, loss-ulb:0.0201, weight:0.28, lr:0.0009
[23:35:00.993] iteration:2259  t-loss:0.0576, loss-lb:0.0532, loss-ulb:0.0157, weight:0.28, lr:0.0009
[23:35:01.370] iteration:2260  t-loss:0.0479, loss-lb:0.0424, loss-ulb:0.0197, weight:0.28, lr:0.0009
[23:35:01.747] iteration:2261  t-loss:0.0368, loss-lb:0.0339, loss-ulb:0.0103, weight:0.28, lr:0.0009
[23:35:02.125] iteration:2262  t-loss:0.0480, loss-lb:0.0469, loss-ulb:0.0036, weight:0.28, lr:0.0009
[23:35:02.496] iteration:2263  t-loss:0.0380, loss-lb:0.0271, loss-ulb:0.0385, weight:0.28, lr:0.0009
[23:35:02.868] iteration:2264  t-loss:0.0559, loss-lb:0.0283, loss-ulb:0.0973, weight:0.28, lr:0.0009
[23:35:03.242] iteration:2265  t-loss:0.0342, loss-lb:0.0302, loss-ulb:0.0140, weight:0.28, lr:0.0009
[23:35:03.633] iteration:2266  t-loss:0.0254, loss-lb:0.0239, loss-ulb:0.0052, weight:0.28, lr:0.0009
[23:35:04.031] iteration:2267  t-loss:0.0337, loss-lb:0.0315, loss-ulb:0.0076, weight:0.28, lr:0.0009
[23:35:04.418] iteration:2268  t-loss:0.0235, loss-lb:0.0200, loss-ulb:0.0124, weight:0.28, lr:0.0009
[23:35:04.802] iteration:2269  t-loss:0.0522, loss-lb:0.0475, loss-ulb:0.0166, weight:0.28, lr:0.0009
[23:35:05.178] iteration:2270  t-loss:0.0307, loss-lb:0.0261, loss-ulb:0.0162, weight:0.28, lr:0.0009
[23:35:05.562] iteration:2271  t-loss:0.0550, loss-lb:0.0491, loss-ulb:0.0209, weight:0.28, lr:0.0009
[23:35:05.945] iteration:2272  t-loss:0.0654, loss-lb:0.0527, loss-ulb:0.0447, weight:0.28, lr:0.0009
[23:35:06.320] iteration:2273  t-loss:0.0426, loss-lb:0.0306, loss-ulb:0.0423, weight:0.28, lr:0.0009
[23:35:06.706] iteration:2274  t-loss:0.0466, loss-lb:0.0426, loss-ulb:0.0142, weight:0.28, lr:0.0009
[23:35:07.090] iteration:2275  t-loss:0.0728, loss-lb:0.0679, loss-ulb:0.0173, weight:0.28, lr:0.0009
[23:35:07.463] iteration:2276  t-loss:0.0677, loss-lb:0.0631, loss-ulb:0.0164, weight:0.28, lr:0.0009
[23:35:07.836] iteration:2277  t-loss:0.0421, loss-lb:0.0317, loss-ulb:0.0367, weight:0.28, lr:0.0009
[23:35:08.209] iteration:2278  t-loss:0.0333, loss-lb:0.0268, loss-ulb:0.0230, weight:0.28, lr:0.0009
[23:35:08.583] iteration:2279  t-loss:0.0455, loss-lb:0.0415, loss-ulb:0.0141, weight:0.28, lr:0.0009
[23:35:08.960] iteration:2280  t-loss:0.0522, loss-lb:0.0513, loss-ulb:0.0032, weight:0.28, lr:0.0009
[23:35:10.248] iteration:2281  t-loss:0.0365, loss-lb:0.0224, loss-ulb:0.0496, weight:0.28, lr:0.0009
[23:35:10.653] iteration:2282  t-loss:0.0887, loss-lb:0.0855, loss-ulb:0.0112, weight:0.28, lr:0.0009
[23:35:11.041] iteration:2283  t-loss:0.0806, loss-lb:0.0774, loss-ulb:0.0111, weight:0.28, lr:0.0009
[23:35:11.427] iteration:2284  t-loss:0.0646, loss-lb:0.0605, loss-ulb:0.0145, weight:0.28, lr:0.0009
[23:35:11.827] iteration:2285  t-loss:0.0692, loss-lb:0.0639, loss-ulb:0.0189, weight:0.28, lr:0.0009
[23:35:12.206] iteration:2286  t-loss:0.0613, loss-lb:0.0552, loss-ulb:0.0213, weight:0.28, lr:0.0009
[23:35:12.609] iteration:2287  t-loss:0.0310, loss-lb:0.0258, loss-ulb:0.0183, weight:0.28, lr:0.0009
[23:35:12.990] iteration:2288  t-loss:0.0796, loss-lb:0.0741, loss-ulb:0.0192, weight:0.28, lr:0.0009
[23:35:13.368] iteration:2289  t-loss:0.0356, loss-lb:0.0285, loss-ulb:0.0250, weight:0.28, lr:0.0009
[23:35:13.751] iteration:2290  t-loss:0.0830, loss-lb:0.0808, loss-ulb:0.0079, weight:0.28, lr:0.0009
[23:35:14.141] iteration:2291  t-loss:0.1035, loss-lb:0.1001, loss-ulb:0.0122, weight:0.28, lr:0.0009
[23:35:14.524] iteration:2292  t-loss:0.0596, loss-lb:0.0568, loss-ulb:0.0099, weight:0.28, lr:0.0009
[23:35:14.906] iteration:2293  t-loss:0.0505, loss-lb:0.0461, loss-ulb:0.0154, weight:0.28, lr:0.0009
[23:35:15.285] iteration:2294  t-loss:0.0382, loss-lb:0.0205, loss-ulb:0.0624, weight:0.28, lr:0.0009
[23:35:15.664] iteration:2295  t-loss:0.0424, loss-lb:0.0377, loss-ulb:0.0167, weight:0.28, lr:0.0009
[23:35:16.039] iteration:2296  t-loss:0.0656, loss-lb:0.0584, loss-ulb:0.0255, weight:0.28, lr:0.0009
[23:35:16.411] iteration:2297  t-loss:0.0354, loss-lb:0.0343, loss-ulb:0.0039, weight:0.28, lr:0.0009
[23:35:16.786] iteration:2298  t-loss:0.0421, loss-lb:0.0316, loss-ulb:0.0371, weight:0.28, lr:0.0009
[23:35:17.159] iteration:2299  t-loss:0.0688, loss-lb:0.0655, loss-ulb:0.0115, weight:0.28, lr:0.0009
[23:35:17.538] iteration:2300  t-loss:0.0511, loss-lb:0.0488, loss-ulb:0.0082, weight:0.28, lr:0.0009
[23:35:17.912] iteration:2301  t-loss:0.0510, loss-lb:0.0447, loss-ulb:0.0221, weight:0.28, lr:0.0009
[23:35:18.289] iteration:2302  t-loss:0.0267, loss-lb:0.0213, loss-ulb:0.0192, weight:0.28, lr:0.0009
[23:35:18.676] iteration:2303  t-loss:0.0603, loss-lb:0.0560, loss-ulb:0.0151, weight:0.28, lr:0.0009
[23:35:19.094] iteration:2304  t-loss:0.0523, loss-lb:0.0482, loss-ulb:0.0145, weight:0.28, lr:0.0009
[23:35:19.495] iteration:2305  t-loss:0.0319, loss-lb:0.0267, loss-ulb:0.0183, weight:0.28, lr:0.0009
[23:35:19.881] iteration:2306  t-loss:0.0443, loss-lb:0.0379, loss-ulb:0.0225, weight:0.28, lr:0.0009
[23:35:20.264] iteration:2307  t-loss:0.0312, loss-lb:0.0285, loss-ulb:0.0097, weight:0.28, lr:0.0009
[23:35:20.672] iteration:2308  t-loss:0.0592, loss-lb:0.0543, loss-ulb:0.0171, weight:0.28, lr:0.0009
[23:35:21.048] iteration:2309  t-loss:0.0546, loss-lb:0.0492, loss-ulb:0.0191, weight:0.28, lr:0.0009
[23:35:21.440] iteration:2310  t-loss:0.0406, loss-lb:0.0386, loss-ulb:0.0072, weight:0.28, lr:0.0009
[23:35:21.833] iteration:2311  t-loss:0.0605, loss-lb:0.0560, loss-ulb:0.0160, weight:0.28, lr:0.0009
[23:35:22.208] iteration:2312  t-loss:0.0457, loss-lb:0.0414, loss-ulb:0.0150, weight:0.28, lr:0.0009
[23:35:22.585] iteration:2313  t-loss:0.0274, loss-lb:0.0255, loss-ulb:0.0067, weight:0.28, lr:0.0009
[23:35:22.959] iteration:2314  t-loss:0.0605, loss-lb:0.0591, loss-ulb:0.0048, weight:0.28, lr:0.0009
[23:35:23.333] iteration:2315  t-loss:0.0812, loss-lb:0.0769, loss-ulb:0.0149, weight:0.28, lr:0.0009
[23:35:23.703] iteration:2316  t-loss:0.0672, loss-lb:0.0585, loss-ulb:0.0308, weight:0.28, lr:0.0009
[23:35:24.080] iteration:2317  t-loss:0.0538, loss-lb:0.0453, loss-ulb:0.0299, weight:0.28, lr:0.0009
[23:35:24.451] iteration:2318  t-loss:0.0960, loss-lb:0.0951, loss-ulb:0.0032, weight:0.28, lr:0.0009
[23:36:25.899] iteration 2318 : dice_score: 0.712230 best_dice: 0.726700
[23:36:25.899]  <<Test>> - Ep:60  - Dice-S/T:67.00/71.22, Best-S:71.14, Best-T:72.67
[23:36:25.899]           - AvgLoss(lb/ulb/all):0.05/0.02/0.05
[23:36:27.145] iteration:2319  t-loss:0.0759, loss-lb:0.0692, loss-ulb:0.0236, weight:0.28, lr:0.0009
[23:36:27.545] iteration:2320  t-loss:0.0834, loss-lb:0.0819, loss-ulb:0.0055, weight:0.28, lr:0.0009
[23:36:27.925] iteration:2321  t-loss:0.0310, loss-lb:0.0294, loss-ulb:0.0055, weight:0.28, lr:0.0009
[23:36:28.306] iteration:2322  t-loss:0.0327, loss-lb:0.0296, loss-ulb:0.0110, weight:0.28, lr:0.0009
[23:36:28.683] iteration:2323  t-loss:0.0736, loss-lb:0.0593, loss-ulb:0.0506, weight:0.28, lr:0.0009
[23:36:29.060] iteration:2324  t-loss:0.0750, loss-lb:0.0719, loss-ulb:0.0109, weight:0.28, lr:0.0009
[23:36:29.438] iteration:2325  t-loss:0.0370, loss-lb:0.0341, loss-ulb:0.0102, weight:0.28, lr:0.0009
[23:36:29.822] iteration:2326  t-loss:0.0626, loss-lb:0.0563, loss-ulb:0.0220, weight:0.28, lr:0.0009
[23:36:30.201] iteration:2327  t-loss:0.0654, loss-lb:0.0471, loss-ulb:0.0645, weight:0.28, lr:0.0009
[23:36:30.580] iteration:2328  t-loss:0.0399, loss-lb:0.0391, loss-ulb:0.0029, weight:0.28, lr:0.0009
[23:36:30.959] iteration:2329  t-loss:0.0559, loss-lb:0.0538, loss-ulb:0.0074, weight:0.28, lr:0.0009
[23:36:31.341] iteration:2330  t-loss:0.0418, loss-lb:0.0380, loss-ulb:0.0133, weight:0.28, lr:0.0009
[23:36:31.723] iteration:2331  t-loss:0.0428, loss-lb:0.0280, loss-ulb:0.0522, weight:0.28, lr:0.0009
[23:36:32.101] iteration:2332  t-loss:0.0350, loss-lb:0.0241, loss-ulb:0.0387, weight:0.28, lr:0.0009
[23:36:32.485] iteration:2333  t-loss:0.0624, loss-lb:0.0560, loss-ulb:0.0226, weight:0.28, lr:0.0009
[23:36:32.863] iteration:2334  t-loss:0.0327, loss-lb:0.0259, loss-ulb:0.0241, weight:0.28, lr:0.0009
[23:36:33.244] iteration:2335  t-loss:0.0347, loss-lb:0.0313, loss-ulb:0.0122, weight:0.28, lr:0.0009
[23:36:33.618] iteration:2336  t-loss:0.0272, loss-lb:0.0246, loss-ulb:0.0090, weight:0.28, lr:0.0009
[23:36:33.995] iteration:2337  t-loss:0.0683, loss-lb:0.0632, loss-ulb:0.0179, weight:0.28, lr:0.0009
[23:36:34.377] iteration:2338  t-loss:0.0262, loss-lb:0.0242, loss-ulb:0.0072, weight:0.28, lr:0.0009
[23:36:34.759] iteration:2339  t-loss:0.0288, loss-lb:0.0237, loss-ulb:0.0179, weight:0.28, lr:0.0009
[23:36:35.147] iteration:2340  t-loss:0.0472, loss-lb:0.0388, loss-ulb:0.0293, weight:0.28, lr:0.0009
[23:36:35.536] iteration:2341  t-loss:0.0279, loss-lb:0.0238, loss-ulb:0.0144, weight:0.28, lr:0.0009
[23:36:35.926] iteration:2342  t-loss:0.0412, loss-lb:0.0375, loss-ulb:0.0131, weight:0.28, lr:0.0009
[23:36:36.322] iteration:2343  t-loss:0.0536, loss-lb:0.0515, loss-ulb:0.0074, weight:0.28, lr:0.0009
[23:36:36.706] iteration:2344  t-loss:0.0346, loss-lb:0.0317, loss-ulb:0.0102, weight:0.28, lr:0.0009
[23:36:37.091] iteration:2345  t-loss:0.0335, loss-lb:0.0287, loss-ulb:0.0169, weight:0.28, lr:0.0009
[23:36:37.481] iteration:2346  t-loss:0.0357, loss-lb:0.0315, loss-ulb:0.0148, weight:0.28, lr:0.0009
[23:36:37.873] iteration:2347  t-loss:0.1162, loss-lb:0.1090, loss-ulb:0.0256, weight:0.28, lr:0.0009
[23:36:38.252] iteration:2348  t-loss:0.0328, loss-lb:0.0299, loss-ulb:0.0104, weight:0.28, lr:0.0009
[23:36:38.634] iteration:2349  t-loss:0.0528, loss-lb:0.0509, loss-ulb:0.0067, weight:0.28, lr:0.0009
[23:36:39.011] iteration:2350  t-loss:0.0549, loss-lb:0.0526, loss-ulb:0.0080, weight:0.28, lr:0.0009
[23:36:39.386] iteration:2351  t-loss:0.0711, loss-lb:0.0699, loss-ulb:0.0043, weight:0.28, lr:0.0009
[23:36:39.763] iteration:2352  t-loss:0.0453, loss-lb:0.0387, loss-ulb:0.0234, weight:0.28, lr:0.0009
[23:36:40.143] iteration:2353  t-loss:0.0536, loss-lb:0.0441, loss-ulb:0.0335, weight:0.28, lr:0.0009
[23:36:40.519] iteration:2354  t-loss:0.0748, loss-lb:0.0675, loss-ulb:0.0259, weight:0.28, lr:0.0009
[23:36:40.897] iteration:2355  t-loss:0.0877, loss-lb:0.0814, loss-ulb:0.0219, weight:0.28, lr:0.0009
[23:36:41.268] iteration:2356  t-loss:0.0248, loss-lb:0.0231, loss-ulb:0.0059, weight:0.28, lr:0.0009
[23:36:42.429] iteration:2357  t-loss:0.0628, loss-lb:0.0594, loss-ulb:0.0118, weight:0.28, lr:0.0009
[23:36:42.840] iteration:2358  t-loss:0.0573, loss-lb:0.0523, loss-ulb:0.0177, weight:0.28, lr:0.0009
[23:36:43.230] iteration:2359  t-loss:0.0582, loss-lb:0.0542, loss-ulb:0.0141, weight:0.28, lr:0.0009
[23:36:43.601] iteration:2360  t-loss:0.0403, loss-lb:0.0349, loss-ulb:0.0190, weight:0.28, lr:0.0009
[23:36:43.981] iteration:2361  t-loss:0.0472, loss-lb:0.0405, loss-ulb:0.0236, weight:0.28, lr:0.0009
[23:36:44.363] iteration:2362  t-loss:0.0644, loss-lb:0.0610, loss-ulb:0.0120, weight:0.28, lr:0.0009
[23:36:44.739] iteration:2363  t-loss:0.0591, loss-lb:0.0545, loss-ulb:0.0162, weight:0.28, lr:0.0009
[23:36:45.117] iteration:2364  t-loss:0.0653, loss-lb:0.0549, loss-ulb:0.0367, weight:0.28, lr:0.0009
[23:36:45.498] iteration:2365  t-loss:0.0319, loss-lb:0.0244, loss-ulb:0.0266, weight:0.28, lr:0.0009
[23:36:45.880] iteration:2366  t-loss:0.0425, loss-lb:0.0408, loss-ulb:0.0063, weight:0.28, lr:0.0009
[23:36:46.261] iteration:2367  t-loss:0.0451, loss-lb:0.0379, loss-ulb:0.0252, weight:0.28, lr:0.0009
[23:36:46.635] iteration:2368  t-loss:0.0344, loss-lb:0.0309, loss-ulb:0.0124, weight:0.28, lr:0.0009
[23:36:47.007] iteration:2369  t-loss:0.0288, loss-lb:0.0263, loss-ulb:0.0086, weight:0.28, lr:0.0009
[23:36:47.386] iteration:2370  t-loss:0.0590, loss-lb:0.0480, loss-ulb:0.0389, weight:0.28, lr:0.0009
[23:36:47.764] iteration:2371  t-loss:0.0306, loss-lb:0.0272, loss-ulb:0.0120, weight:0.28, lr:0.0009
[23:36:48.137] iteration:2372  t-loss:0.0670, loss-lb:0.0622, loss-ulb:0.0168, weight:0.28, lr:0.0009
[23:36:48.515] iteration:2373  t-loss:0.1130, loss-lb:0.1089, loss-ulb:0.0145, weight:0.28, lr:0.0009
[23:36:48.897] iteration:2374  t-loss:0.0636, loss-lb:0.0534, loss-ulb:0.0360, weight:0.28, lr:0.0009
[23:36:49.278] iteration:2375  t-loss:0.0585, loss-lb:0.0546, loss-ulb:0.0139, weight:0.28, lr:0.0009
[23:36:49.654] iteration:2376  t-loss:0.0391, loss-lb:0.0253, loss-ulb:0.0487, weight:0.28, lr:0.0009
[23:36:50.032] iteration:2377  t-loss:0.0345, loss-lb:0.0282, loss-ulb:0.0222, weight:0.28, lr:0.0009
[23:36:50.422] iteration:2378  t-loss:0.0740, loss-lb:0.0706, loss-ulb:0.0120, weight:0.28, lr:0.0009
[23:36:50.830] iteration:2379  t-loss:0.0473, loss-lb:0.0428, loss-ulb:0.0160, weight:0.28, lr:0.0009
[23:36:51.223] iteration:2380  t-loss:0.0454, loss-lb:0.0410, loss-ulb:0.0155, weight:0.28, lr:0.0009
[23:36:51.607] iteration:2381  t-loss:0.0377, loss-lb:0.0287, loss-ulb:0.0317, weight:0.28, lr:0.0009
[23:36:51.981] iteration:2382  t-loss:0.0318, loss-lb:0.0286, loss-ulb:0.0113, weight:0.28, lr:0.0009
[23:36:52.365] iteration:2383  t-loss:0.0655, loss-lb:0.0585, loss-ulb:0.0247, weight:0.28, lr:0.0009
[23:36:52.746] iteration:2384  t-loss:0.0357, loss-lb:0.0347, loss-ulb:0.0038, weight:0.28, lr:0.0009
[23:36:53.126] iteration:2385  t-loss:0.0271, loss-lb:0.0255, loss-ulb:0.0055, weight:0.28, lr:0.0009
[23:36:53.507] iteration:2386  t-loss:0.0525, loss-lb:0.0457, loss-ulb:0.0239, weight:0.28, lr:0.0009
[23:36:53.881] iteration:2387  t-loss:0.0338, loss-lb:0.0310, loss-ulb:0.0098, weight:0.28, lr:0.0009
[23:36:54.255] iteration:2388  t-loss:0.0700, loss-lb:0.0646, loss-ulb:0.0190, weight:0.28, lr:0.0009
[23:36:54.634] iteration:2389  t-loss:0.0520, loss-lb:0.0483, loss-ulb:0.0131, weight:0.28, lr:0.0009
[23:36:55.004] iteration:2390  t-loss:0.0348, loss-lb:0.0318, loss-ulb:0.0107, weight:0.28, lr:0.0009
[23:36:55.381] iteration:2391  t-loss:0.0333, loss-lb:0.0228, loss-ulb:0.0368, weight:0.28, lr:0.0009
[23:36:55.760] iteration:2392  t-loss:0.0342, loss-lb:0.0247, loss-ulb:0.0335, weight:0.28, lr:0.0009
[23:36:56.140] iteration:2393  t-loss:0.0650, loss-lb:0.0570, loss-ulb:0.0282, weight:0.28, lr:0.0009
[23:36:56.515] iteration:2394  t-loss:0.0609, loss-lb:0.0494, loss-ulb:0.0405, weight:0.28, lr:0.0009
[23:36:57.782] iteration:2395  t-loss:0.0536, loss-lb:0.0504, loss-ulb:0.0112, weight:0.28, lr:0.0009
[23:36:58.182] iteration:2396  t-loss:0.0390, loss-lb:0.0349, loss-ulb:0.0145, weight:0.28, lr:0.0009
[23:36:58.582] iteration:2397  t-loss:0.0328, loss-lb:0.0302, loss-ulb:0.0093, weight:0.28, lr:0.0009
[23:36:58.960] iteration:2398  t-loss:0.0935, loss-lb:0.0914, loss-ulb:0.0073, weight:0.28, lr:0.0009
[23:36:59.344] iteration:2399  t-loss:0.0661, loss-lb:0.0583, loss-ulb:0.0276, weight:0.28, lr:0.0009
[23:36:59.724] iteration:2400  t-loss:0.0515, loss-lb:0.0469, loss-ulb:0.0160, weight:0.28, lr:0.0009
[23:37:00.107] iteration:2401  t-loss:0.0800, loss-lb:0.0792, loss-ulb:0.0024, weight:0.33, lr:0.0009
[23:37:00.481] iteration:2402  t-loss:0.0306, loss-lb:0.0223, loss-ulb:0.0252, weight:0.33, lr:0.0009
[23:37:00.867] iteration:2403  t-loss:0.0874, loss-lb:0.0826, loss-ulb:0.0145, weight:0.33, lr:0.0009
[23:37:01.246] iteration:2404  t-loss:0.0671, loss-lb:0.0644, loss-ulb:0.0082, weight:0.33, lr:0.0009
[23:37:01.628] iteration:2405  t-loss:0.0636, loss-lb:0.0570, loss-ulb:0.0201, weight:0.33, lr:0.0009
[23:37:02.006] iteration:2406  t-loss:0.0469, loss-lb:0.0341, loss-ulb:0.0388, weight:0.33, lr:0.0009
[23:37:02.385] iteration:2407  t-loss:0.0725, loss-lb:0.0607, loss-ulb:0.0355, weight:0.33, lr:0.0009
[23:37:02.761] iteration:2408  t-loss:0.0989, loss-lb:0.0948, loss-ulb:0.0124, weight:0.33, lr:0.0009
[23:37:03.135] iteration:2409  t-loss:0.0423, loss-lb:0.0392, loss-ulb:0.0095, weight:0.33, lr:0.0009
[23:37:03.511] iteration:2410  t-loss:0.1043, loss-lb:0.0961, loss-ulb:0.0249, weight:0.33, lr:0.0009
[23:37:03.888] iteration:2411  t-loss:0.0644, loss-lb:0.0605, loss-ulb:0.0117, weight:0.33, lr:0.0009
[23:37:04.266] iteration:2412  t-loss:0.0394, loss-lb:0.0303, loss-ulb:0.0273, weight:0.33, lr:0.0009
[23:37:04.642] iteration:2413  t-loss:0.0376, loss-lb:0.0320, loss-ulb:0.0170, weight:0.33, lr:0.0009
[23:37:05.016] iteration:2414  t-loss:0.0612, loss-lb:0.0574, loss-ulb:0.0115, weight:0.33, lr:0.0009
[23:37:05.397] iteration:2415  t-loss:0.0477, loss-lb:0.0382, loss-ulb:0.0288, weight:0.33, lr:0.0009
[23:37:05.791] iteration:2416  t-loss:0.0409, loss-lb:0.0392, loss-ulb:0.0052, weight:0.33, lr:0.0009
[23:37:06.196] iteration:2417  t-loss:0.1072, loss-lb:0.0953, loss-ulb:0.0357, weight:0.33, lr:0.0009
[23:37:06.596] iteration:2418  t-loss:0.0965, loss-lb:0.0890, loss-ulb:0.0229, weight:0.33, lr:0.0009
[23:37:06.994] iteration:2419  t-loss:0.0960, loss-lb:0.0817, loss-ulb:0.0433, weight:0.33, lr:0.0009
[23:37:07.379] iteration:2420  t-loss:0.0438, loss-lb:0.0309, loss-ulb:0.0389, weight:0.33, lr:0.0009
[23:37:07.754] iteration:2421  t-loss:0.0628, loss-lb:0.0484, loss-ulb:0.0435, weight:0.33, lr:0.0009
[23:37:08.132] iteration:2422  t-loss:0.0648, loss-lb:0.0602, loss-ulb:0.0141, weight:0.33, lr:0.0009
[23:37:08.525] iteration:2423  t-loss:0.0664, loss-lb:0.0587, loss-ulb:0.0232, weight:0.33, lr:0.0009
[23:37:08.906] iteration:2424  t-loss:0.0525, loss-lb:0.0340, loss-ulb:0.0558, weight:0.33, lr:0.0009
[23:37:09.296] iteration:2425  t-loss:0.1246, loss-lb:0.1196, loss-ulb:0.0150, weight:0.33, lr:0.0009
[23:37:09.672] iteration:2426  t-loss:0.0760, loss-lb:0.0735, loss-ulb:0.0075, weight:0.33, lr:0.0009
[23:37:10.051] iteration:2427  t-loss:0.1480, loss-lb:0.1377, loss-ulb:0.0310, weight:0.33, lr:0.0009
[23:37:10.426] iteration:2428  t-loss:0.1061, loss-lb:0.0851, loss-ulb:0.0635, weight:0.33, lr:0.0009
[23:37:10.797] iteration:2429  t-loss:0.0612, loss-lb:0.0405, loss-ulb:0.0624, weight:0.33, lr:0.0009
[23:37:11.173] iteration:2430  t-loss:0.0600, loss-lb:0.0515, loss-ulb:0.0258, weight:0.33, lr:0.0009
[23:37:11.550] iteration:2431  t-loss:0.0818, loss-lb:0.0802, loss-ulb:0.0050, weight:0.33, lr:0.0009
[23:37:11.922] iteration:2432  t-loss:0.0508, loss-lb:0.0460, loss-ulb:0.0146, weight:0.33, lr:0.0009
[23:37:13.609] iteration:2433  t-loss:0.1124, loss-lb:0.1095, loss-ulb:0.0089, weight:0.33, lr:0.0009
[23:37:14.015] iteration:2434  t-loss:0.1110, loss-lb:0.0933, loss-ulb:0.0536, weight:0.33, lr:0.0009
[23:37:14.426] iteration:2435  t-loss:0.1132, loss-lb:0.1089, loss-ulb:0.0128, weight:0.33, lr:0.0009
[23:37:14.810] iteration:2436  t-loss:0.1020, loss-lb:0.0916, loss-ulb:0.0316, weight:0.33, lr:0.0009
[23:37:15.186] iteration:2437  t-loss:0.0656, loss-lb:0.0614, loss-ulb:0.0127, weight:0.33, lr:0.0009
[23:37:15.566] iteration:2438  t-loss:0.0575, loss-lb:0.0411, loss-ulb:0.0497, weight:0.33, lr:0.0009
[23:37:15.942] iteration:2439  t-loss:0.0647, loss-lb:0.0572, loss-ulb:0.0227, weight:0.33, lr:0.0009
[23:37:16.322] iteration:2440  t-loss:0.0931, loss-lb:0.0889, loss-ulb:0.0129, weight:0.33, lr:0.0009
[23:37:16.701] iteration:2441  t-loss:0.1148, loss-lb:0.1079, loss-ulb:0.0209, weight:0.33, lr:0.0009
[23:37:17.081] iteration:2442  t-loss:0.0687, loss-lb:0.0553, loss-ulb:0.0405, weight:0.33, lr:0.0009
[23:37:17.456] iteration:2443  t-loss:0.0348, loss-lb:0.0332, loss-ulb:0.0049, weight:0.33, lr:0.0009
[23:37:17.832] iteration:2444  t-loss:0.1094, loss-lb:0.1023, loss-ulb:0.0215, weight:0.33, lr:0.0009
[23:37:18.206] iteration:2445  t-loss:0.2134, loss-lb:0.2062, loss-ulb:0.0217, weight:0.33, lr:0.0009
[23:37:18.582] iteration:2446  t-loss:0.0579, loss-lb:0.0548, loss-ulb:0.0095, weight:0.33, lr:0.0009
[23:37:18.960] iteration:2447  t-loss:0.0872, loss-lb:0.0833, loss-ulb:0.0117, weight:0.33, lr:0.0009
[23:37:19.339] iteration:2448  t-loss:0.0962, loss-lb:0.0833, loss-ulb:0.0390, weight:0.33, lr:0.0009
[23:37:19.713] iteration:2449  t-loss:0.0668, loss-lb:0.0471, loss-ulb:0.0595, weight:0.33, lr:0.0009
[23:37:20.091] iteration:2450  t-loss:0.0714, loss-lb:0.0653, loss-ulb:0.0187, weight:0.33, lr:0.0009
[23:37:20.466] iteration:2451  t-loss:0.0484, loss-lb:0.0377, loss-ulb:0.0323, weight:0.33, lr:0.0009
[23:37:20.849] iteration:2452  t-loss:0.0629, loss-lb:0.0497, loss-ulb:0.0400, weight:0.33, lr:0.0009
[23:37:21.256] iteration:2453  t-loss:0.0500, loss-lb:0.0341, loss-ulb:0.0482, weight:0.33, lr:0.0009
[23:37:21.660] iteration:2454  t-loss:0.0779, loss-lb:0.0659, loss-ulb:0.0364, weight:0.33, lr:0.0009
[23:37:22.069] iteration:2455  t-loss:0.0470, loss-lb:0.0418, loss-ulb:0.0158, weight:0.33, lr:0.0009
[23:37:22.492] iteration:2456  t-loss:0.0984, loss-lb:0.0927, loss-ulb:0.0173, weight:0.33, lr:0.0009
[23:37:22.880] iteration:2457  t-loss:0.1167, loss-lb:0.1017, loss-ulb:0.0452, weight:0.33, lr:0.0009
[23:37:23.266] iteration:2458  t-loss:0.0357, loss-lb:0.0295, loss-ulb:0.0189, weight:0.33, lr:0.0009
[23:37:23.646] iteration:2459  t-loss:0.0377, loss-lb:0.0347, loss-ulb:0.0092, weight:0.33, lr:0.0009
[23:37:24.023] iteration:2460  t-loss:0.0969, loss-lb:0.0874, loss-ulb:0.0287, weight:0.33, lr:0.0009
[23:37:24.405] iteration:2461  t-loss:0.0531, loss-lb:0.0429, loss-ulb:0.0309, weight:0.33, lr:0.0009
[23:37:24.794] iteration:2462  t-loss:0.0664, loss-lb:0.0592, loss-ulb:0.0218, weight:0.33, lr:0.0009
[23:37:25.167] iteration:2463  t-loss:0.0862, loss-lb:0.0774, loss-ulb:0.0267, weight:0.33, lr:0.0009
[23:37:25.545] iteration:2464  t-loss:0.0683, loss-lb:0.0631, loss-ulb:0.0157, weight:0.33, lr:0.0009
[23:37:25.916] iteration:2465  t-loss:0.0357, loss-lb:0.0309, loss-ulb:0.0146, weight:0.33, lr:0.0009
[23:37:26.288] iteration:2466  t-loss:0.0740, loss-lb:0.0724, loss-ulb:0.0049, weight:0.33, lr:0.0009
[23:37:26.663] iteration:2467  t-loss:0.0558, loss-lb:0.0474, loss-ulb:0.0254, weight:0.33, lr:0.0009
[23:37:27.034] iteration:2468  t-loss:0.0463, loss-lb:0.0405, loss-ulb:0.0174, weight:0.33, lr:0.0009
[23:37:27.404] iteration:2469  t-loss:0.0591, loss-lb:0.0571, loss-ulb:0.0060, weight:0.33, lr:0.0009
[23:37:27.775] iteration:2470  t-loss:0.0567, loss-lb:0.0531, loss-ulb:0.0107, weight:0.33, lr:0.0009
[23:38:30.438] iteration 2470 : dice_score: 0.725124 best_dice: 0.726700
[23:38:30.438]  <<Test>> - Ep:64  - Dice-S/T:69.75/72.51, Best-S:71.14, Best-T:72.67
[23:38:30.438]           - AvgLoss(lb/ulb/all):0.07/0.02/0.06
[23:38:31.526] iteration:2471  t-loss:0.0773, loss-lb:0.0659, loss-ulb:0.0342, weight:0.33, lr:0.0009
[23:38:31.920] iteration:2472  t-loss:0.0875, loss-lb:0.0785, loss-ulb:0.0274, weight:0.33, lr:0.0009
[23:38:32.301] iteration:2473  t-loss:0.0627, loss-lb:0.0581, loss-ulb:0.0138, weight:0.33, lr:0.0009
[23:38:32.676] iteration:2474  t-loss:0.0842, loss-lb:0.0825, loss-ulb:0.0050, weight:0.33, lr:0.0009
[23:38:33.060] iteration:2475  t-loss:0.0872, loss-lb:0.0813, loss-ulb:0.0177, weight:0.33, lr:0.0009
[23:38:33.443] iteration:2476  t-loss:0.0438, loss-lb:0.0401, loss-ulb:0.0112, weight:0.33, lr:0.0009
[23:38:33.821] iteration:2477  t-loss:0.0610, loss-lb:0.0582, loss-ulb:0.0087, weight:0.33, lr:0.0009
[23:38:34.201] iteration:2478  t-loss:0.0530, loss-lb:0.0486, loss-ulb:0.0132, weight:0.33, lr:0.0009
[23:38:34.582] iteration:2479  t-loss:0.0310, loss-lb:0.0240, loss-ulb:0.0211, weight:0.33, lr:0.0009
[23:38:34.962] iteration:2480  t-loss:0.0439, loss-lb:0.0360, loss-ulb:0.0238, weight:0.33, lr:0.0008
[23:38:35.343] iteration:2481  t-loss:0.0457, loss-lb:0.0407, loss-ulb:0.0153, weight:0.33, lr:0.0008
[23:38:35.731] iteration:2482  t-loss:0.0605, loss-lb:0.0549, loss-ulb:0.0169, weight:0.33, lr:0.0008
[23:38:36.114] iteration:2483  t-loss:0.0344, loss-lb:0.0323, loss-ulb:0.0066, weight:0.33, lr:0.0008
[23:38:36.508] iteration:2484  t-loss:0.1017, loss-lb:0.0917, loss-ulb:0.0301, weight:0.33, lr:0.0008
[23:38:36.886] iteration:2485  t-loss:0.0461, loss-lb:0.0379, loss-ulb:0.0247, weight:0.33, lr:0.0008
[23:38:37.267] iteration:2486  t-loss:0.0885, loss-lb:0.0764, loss-ulb:0.0369, weight:0.33, lr:0.0008
[23:38:37.657] iteration:2487  t-loss:0.0658, loss-lb:0.0622, loss-ulb:0.0110, weight:0.33, lr:0.0008
[23:38:38.021] iteration:2488  t-loss:0.0388, loss-lb:0.0293, loss-ulb:0.0287, weight:0.33, lr:0.0008
[23:38:38.403] iteration:2489  t-loss:0.0356, loss-lb:0.0299, loss-ulb:0.0171, weight:0.33, lr:0.0008
[23:38:38.790] iteration:2490  t-loss:0.0890, loss-lb:0.0763, loss-ulb:0.0385, weight:0.33, lr:0.0008
[23:38:39.169] iteration:2491  t-loss:0.0882, loss-lb:0.0842, loss-ulb:0.0121, weight:0.33, lr:0.0008
[23:38:39.547] iteration:2492  t-loss:0.0395, loss-lb:0.0337, loss-ulb:0.0178, weight:0.33, lr:0.0008
[23:38:39.931] iteration:2493  t-loss:0.0792, loss-lb:0.0757, loss-ulb:0.0105, weight:0.33, lr:0.0008
[23:38:40.311] iteration:2494  t-loss:0.0509, loss-lb:0.0297, loss-ulb:0.0640, weight:0.33, lr:0.0008
[23:38:40.715] iteration:2495  t-loss:0.1517, loss-lb:0.1485, loss-ulb:0.0099, weight:0.33, lr:0.0008
[23:38:41.096] iteration:2496  t-loss:0.0416, loss-lb:0.0281, loss-ulb:0.0408, weight:0.33, lr:0.0008
[23:38:41.472] iteration:2497  t-loss:0.0527, loss-lb:0.0434, loss-ulb:0.0280, weight:0.33, lr:0.0008
[23:38:41.848] iteration:2498  t-loss:0.0343, loss-lb:0.0328, loss-ulb:0.0046, weight:0.33, lr:0.0008
[23:38:42.229] iteration:2499  t-loss:0.0431, loss-lb:0.0348, loss-ulb:0.0252, weight:0.33, lr:0.0008
[23:38:42.606] iteration:2500  t-loss:0.0509, loss-lb:0.0483, loss-ulb:0.0080, weight:0.33, lr:0.0008
[23:38:42.980] iteration:2501  t-loss:0.1272, loss-lb:0.1187, loss-ulb:0.0256, weight:0.33, lr:0.0008
[23:38:43.351] iteration:2502  t-loss:0.0875, loss-lb:0.0850, loss-ulb:0.0075, weight:0.33, lr:0.0008
[23:38:43.723] iteration:2503  t-loss:0.0424, loss-lb:0.0335, loss-ulb:0.0269, weight:0.33, lr:0.0008
[23:38:44.100] iteration:2504  t-loss:0.0489, loss-lb:0.0383, loss-ulb:0.0320, weight:0.33, lr:0.0008
[23:38:44.474] iteration:2505  t-loss:0.0444, loss-lb:0.0393, loss-ulb:0.0152, weight:0.33, lr:0.0008
[23:38:44.847] iteration:2506  t-loss:0.0316, loss-lb:0.0300, loss-ulb:0.0047, weight:0.33, lr:0.0008
[23:38:45.220] iteration:2507  t-loss:0.0375, loss-lb:0.0326, loss-ulb:0.0148, weight:0.33, lr:0.0008
[23:38:45.596] iteration:2508  t-loss:0.0533, loss-lb:0.0509, loss-ulb:0.0072, weight:0.33, lr:0.0008
[23:38:46.812] iteration:2509  t-loss:0.0566, loss-lb:0.0498, loss-ulb:0.0205, weight:0.33, lr:0.0008
[23:38:47.229] iteration:2510  t-loss:0.0950, loss-lb:0.0910, loss-ulb:0.0121, weight:0.33, lr:0.0008
[23:38:47.618] iteration:2511  t-loss:0.0555, loss-lb:0.0508, loss-ulb:0.0141, weight:0.33, lr:0.0008
[23:38:47.998] iteration:2512  t-loss:0.0561, loss-lb:0.0482, loss-ulb:0.0241, weight:0.33, lr:0.0008
[23:38:48.379] iteration:2513  t-loss:0.0593, loss-lb:0.0564, loss-ulb:0.0088, weight:0.33, lr:0.0008
[23:38:48.759] iteration:2514  t-loss:0.0530, loss-lb:0.0521, loss-ulb:0.0025, weight:0.33, lr:0.0008
[23:38:49.141] iteration:2515  t-loss:0.0748, loss-lb:0.0722, loss-ulb:0.0077, weight:0.33, lr:0.0008
[23:38:49.526] iteration:2516  t-loss:0.0326, loss-lb:0.0279, loss-ulb:0.0142, weight:0.33, lr:0.0008
[23:38:49.903] iteration:2517  t-loss:0.0449, loss-lb:0.0402, loss-ulb:0.0144, weight:0.33, lr:0.0008
[23:38:50.279] iteration:2518  t-loss:0.0377, loss-lb:0.0248, loss-ulb:0.0388, weight:0.33, lr:0.0008
[23:38:50.666] iteration:2519  t-loss:0.0785, loss-lb:0.0750, loss-ulb:0.0105, weight:0.33, lr:0.0008
[23:38:51.054] iteration:2520  t-loss:0.0710, loss-lb:0.0568, loss-ulb:0.0431, weight:0.33, lr:0.0008
[23:38:51.432] iteration:2521  t-loss:0.0359, loss-lb:0.0270, loss-ulb:0.0271, weight:0.33, lr:0.0008
[23:38:51.813] iteration:2522  t-loss:0.0772, loss-lb:0.0652, loss-ulb:0.0363, weight:0.33, lr:0.0008
[23:38:52.189] iteration:2523  t-loss:0.0599, loss-lb:0.0566, loss-ulb:0.0098, weight:0.33, lr:0.0008
[23:38:52.569] iteration:2524  t-loss:0.0498, loss-lb:0.0391, loss-ulb:0.0322, weight:0.33, lr:0.0008
[23:38:52.951] iteration:2525  t-loss:0.0476, loss-lb:0.0448, loss-ulb:0.0085, weight:0.33, lr:0.0008
[23:38:53.328] iteration:2526  t-loss:0.0824, loss-lb:0.0748, loss-ulb:0.0229, weight:0.33, lr:0.0008
[23:38:53.703] iteration:2527  t-loss:0.0362, loss-lb:0.0320, loss-ulb:0.0128, weight:0.33, lr:0.0008
[23:38:54.081] iteration:2528  t-loss:0.0586, loss-lb:0.0577, loss-ulb:0.0030, weight:0.33, lr:0.0008
[23:38:54.456] iteration:2529  t-loss:0.0504, loss-lb:0.0451, loss-ulb:0.0161, weight:0.33, lr:0.0008
[23:38:54.832] iteration:2530  t-loss:0.0762, loss-lb:0.0658, loss-ulb:0.0316, weight:0.33, lr:0.0008
[23:38:55.217] iteration:2531  t-loss:0.0693, loss-lb:0.0665, loss-ulb:0.0085, weight:0.33, lr:0.0008
[23:38:55.620] iteration:2532  t-loss:0.0387, loss-lb:0.0336, loss-ulb:0.0153, weight:0.33, lr:0.0008
[23:38:56.020] iteration:2533  t-loss:0.0276, loss-lb:0.0263, loss-ulb:0.0039, weight:0.33, lr:0.0008
[23:38:56.414] iteration:2534  t-loss:0.0687, loss-lb:0.0665, loss-ulb:0.0067, weight:0.33, lr:0.0008
[23:38:56.799] iteration:2535  t-loss:0.0656, loss-lb:0.0584, loss-ulb:0.0218, weight:0.33, lr:0.0008
[23:38:57.182] iteration:2536  t-loss:0.0654, loss-lb:0.0633, loss-ulb:0.0064, weight:0.33, lr:0.0008
[23:38:57.559] iteration:2537  t-loss:0.0349, loss-lb:0.0335, loss-ulb:0.0043, weight:0.33, lr:0.0008
[23:38:57.941] iteration:2538  t-loss:0.0655, loss-lb:0.0590, loss-ulb:0.0195, weight:0.33, lr:0.0008
[23:38:58.317] iteration:2539  t-loss:0.0395, loss-lb:0.0361, loss-ulb:0.0102, weight:0.33, lr:0.0008
[23:38:58.691] iteration:2540  t-loss:0.0539, loss-lb:0.0534, loss-ulb:0.0017, weight:0.33, lr:0.0008
[23:38:59.068] iteration:2541  t-loss:0.0750, loss-lb:0.0706, loss-ulb:0.0133, weight:0.33, lr:0.0008
[23:38:59.445] iteration:2542  t-loss:0.0550, loss-lb:0.0506, loss-ulb:0.0135, weight:0.33, lr:0.0008
[23:38:59.822] iteration:2543  t-loss:0.0391, loss-lb:0.0328, loss-ulb:0.0190, weight:0.33, lr:0.0008
[23:39:00.197] iteration:2544  t-loss:0.0355, loss-lb:0.0282, loss-ulb:0.0221, weight:0.33, lr:0.0008
[23:39:00.576] iteration:2545  t-loss:0.1101, loss-lb:0.1029, loss-ulb:0.0218, weight:0.33, lr:0.0008
[23:39:00.951] iteration:2546  t-loss:0.0322, loss-lb:0.0307, loss-ulb:0.0045, weight:0.33, lr:0.0008
[23:39:02.378] iteration:2547  t-loss:0.0813, loss-lb:0.0703, loss-ulb:0.0332, weight:0.33, lr:0.0008
[23:39:02.767] iteration:2548  t-loss:0.0365, loss-lb:0.0249, loss-ulb:0.0351, weight:0.33, lr:0.0008
[23:39:03.149] iteration:2549  t-loss:0.0415, loss-lb:0.0310, loss-ulb:0.0317, weight:0.33, lr:0.0008
[23:39:03.529] iteration:2550  t-loss:0.0374, loss-lb:0.0336, loss-ulb:0.0114, weight:0.33, lr:0.0008
[23:39:03.910] iteration:2551  t-loss:0.0268, loss-lb:0.0260, loss-ulb:0.0021, weight:0.38, lr:0.0008
[23:39:04.295] iteration:2552  t-loss:0.0859, loss-lb:0.0807, loss-ulb:0.0135, weight:0.38, lr:0.0008
[23:39:04.682] iteration:2553  t-loss:0.0660, loss-lb:0.0564, loss-ulb:0.0252, weight:0.38, lr:0.0008
[23:39:05.069] iteration:2554  t-loss:0.0885, loss-lb:0.0761, loss-ulb:0.0326, weight:0.38, lr:0.0008
[23:39:05.446] iteration:2555  t-loss:0.0249, loss-lb:0.0227, loss-ulb:0.0057, weight:0.38, lr:0.0008
[23:39:05.820] iteration:2556  t-loss:0.0620, loss-lb:0.0588, loss-ulb:0.0084, weight:0.38, lr:0.0008
[23:39:06.204] iteration:2557  t-loss:0.0475, loss-lb:0.0416, loss-ulb:0.0155, weight:0.38, lr:0.0008
[23:39:06.584] iteration:2558  t-loss:0.0492, loss-lb:0.0377, loss-ulb:0.0299, weight:0.38, lr:0.0008
[23:39:06.965] iteration:2559  t-loss:0.0457, loss-lb:0.0411, loss-ulb:0.0119, weight:0.38, lr:0.0008
[23:39:07.349] iteration:2560  t-loss:0.0773, loss-lb:0.0690, loss-ulb:0.0217, weight:0.38, lr:0.0008
[23:39:07.720] iteration:2561  t-loss:0.0377, loss-lb:0.0366, loss-ulb:0.0030, weight:0.38, lr:0.0008
[23:39:08.098] iteration:2562  t-loss:0.0673, loss-lb:0.0653, loss-ulb:0.0051, weight:0.38, lr:0.0008
[23:39:08.474] iteration:2563  t-loss:0.0789, loss-lb:0.0737, loss-ulb:0.0137, weight:0.38, lr:0.0008
[23:39:08.851] iteration:2564  t-loss:0.0432, loss-lb:0.0423, loss-ulb:0.0023, weight:0.38, lr:0.0008
[23:39:09.225] iteration:2565  t-loss:0.0467, loss-lb:0.0352, loss-ulb:0.0302, weight:0.38, lr:0.0008
[23:39:09.602] iteration:2566  t-loss:0.0415, loss-lb:0.0328, loss-ulb:0.0227, weight:0.38, lr:0.0008
[23:39:09.977] iteration:2567  t-loss:0.0413, loss-lb:0.0380, loss-ulb:0.0087, weight:0.38, lr:0.0008
[23:39:10.350] iteration:2568  t-loss:0.0910, loss-lb:0.0897, loss-ulb:0.0035, weight:0.38, lr:0.0008
[23:39:10.746] iteration:2569  t-loss:0.0460, loss-lb:0.0337, loss-ulb:0.0321, weight:0.38, lr:0.0008
[23:39:11.158] iteration:2570  t-loss:0.0298, loss-lb:0.0247, loss-ulb:0.0131, weight:0.38, lr:0.0008
[23:39:11.565] iteration:2571  t-loss:0.0639, loss-lb:0.0534, loss-ulb:0.0273, weight:0.38, lr:0.0008
[23:39:11.952] iteration:2572  t-loss:0.0418, loss-lb:0.0342, loss-ulb:0.0200, weight:0.38, lr:0.0008
[23:39:12.329] iteration:2573  t-loss:0.0391, loss-lb:0.0329, loss-ulb:0.0163, weight:0.38, lr:0.0008
[23:39:12.709] iteration:2574  t-loss:0.0569, loss-lb:0.0536, loss-ulb:0.0086, weight:0.38, lr:0.0008
[23:39:13.085] iteration:2575  t-loss:0.0363, loss-lb:0.0326, loss-ulb:0.0096, weight:0.38, lr:0.0008
[23:39:13.470] iteration:2576  t-loss:0.0550, loss-lb:0.0479, loss-ulb:0.0184, weight:0.38, lr:0.0008
[23:39:13.842] iteration:2577  t-loss:0.0742, loss-lb:0.0690, loss-ulb:0.0136, weight:0.38, lr:0.0008
[23:39:14.216] iteration:2578  t-loss:0.0556, loss-lb:0.0517, loss-ulb:0.0104, weight:0.38, lr:0.0008
[23:39:14.588] iteration:2579  t-loss:0.0360, loss-lb:0.0253, loss-ulb:0.0279, weight:0.38, lr:0.0008
[23:39:14.966] iteration:2580  t-loss:0.0930, loss-lb:0.0896, loss-ulb:0.0088, weight:0.38, lr:0.0008
[23:39:15.339] iteration:2581  t-loss:0.0286, loss-lb:0.0230, loss-ulb:0.0147, weight:0.38, lr:0.0008
[23:39:15.717] iteration:2582  t-loss:0.0858, loss-lb:0.0844, loss-ulb:0.0037, weight:0.38, lr:0.0008
[23:39:16.093] iteration:2583  t-loss:0.0954, loss-lb:0.0753, loss-ulb:0.0525, weight:0.38, lr:0.0008
[23:39:16.470] iteration:2584  t-loss:0.0415, loss-lb:0.0391, loss-ulb:0.0062, weight:0.38, lr:0.0008
[23:39:17.674] iteration:2585  t-loss:0.0300, loss-lb:0.0264, loss-ulb:0.0094, weight:0.38, lr:0.0008
[23:39:18.072] iteration:2586  t-loss:0.0505, loss-lb:0.0469, loss-ulb:0.0096, weight:0.38, lr:0.0008
[23:39:18.458] iteration:2587  t-loss:0.0615, loss-lb:0.0592, loss-ulb:0.0059, weight:0.38, lr:0.0008
[23:39:18.838] iteration:2588  t-loss:0.0424, loss-lb:0.0261, loss-ulb:0.0423, weight:0.38, lr:0.0008
[23:39:19.218] iteration:2589  t-loss:0.0622, loss-lb:0.0564, loss-ulb:0.0152, weight:0.38, lr:0.0008
[23:39:19.597] iteration:2590  t-loss:0.0724, loss-lb:0.0713, loss-ulb:0.0028, weight:0.38, lr:0.0008
[23:39:19.975] iteration:2591  t-loss:0.0703, loss-lb:0.0609, loss-ulb:0.0246, weight:0.38, lr:0.0008
[23:39:20.360] iteration:2592  t-loss:0.0758, loss-lb:0.0669, loss-ulb:0.0232, weight:0.38, lr:0.0008
[23:39:20.736] iteration:2593  t-loss:0.0725, loss-lb:0.0609, loss-ulb:0.0302, weight:0.38, lr:0.0008
[23:39:21.119] iteration:2594  t-loss:0.0533, loss-lb:0.0450, loss-ulb:0.0216, weight:0.38, lr:0.0008
[23:39:21.494] iteration:2595  t-loss:0.0308, loss-lb:0.0268, loss-ulb:0.0103, weight:0.38, lr:0.0008
[23:39:21.873] iteration:2596  t-loss:0.0288, loss-lb:0.0274, loss-ulb:0.0036, weight:0.38, lr:0.0008
[23:39:22.247] iteration:2597  t-loss:0.0806, loss-lb:0.0763, loss-ulb:0.0113, weight:0.38, lr:0.0008
[23:39:22.624] iteration:2598  t-loss:0.0406, loss-lb:0.0308, loss-ulb:0.0255, weight:0.38, lr:0.0008
[23:39:22.999] iteration:2599  t-loss:0.0341, loss-lb:0.0264, loss-ulb:0.0202, weight:0.38, lr:0.0008
[23:39:23.374] iteration:2600  t-loss:0.0917, loss-lb:0.0903, loss-ulb:0.0036, weight:0.38, lr:0.0008
[23:39:23.751] iteration:2601  t-loss:0.0526, loss-lb:0.0478, loss-ulb:0.0124, weight:0.38, lr:0.0008
[23:39:24.125] iteration:2602  t-loss:0.0439, loss-lb:0.0283, loss-ulb:0.0406, weight:0.38, lr:0.0008
[23:39:24.501] iteration:2603  t-loss:0.0462, loss-lb:0.0340, loss-ulb:0.0319, weight:0.38, lr:0.0008
[23:39:24.871] iteration:2604  t-loss:0.0659, loss-lb:0.0553, loss-ulb:0.0277, weight:0.38, lr:0.0008
[23:39:25.243] iteration:2605  t-loss:0.0513, loss-lb:0.0381, loss-ulb:0.0344, weight:0.38, lr:0.0008
[23:39:25.618] iteration:2606  t-loss:0.0547, loss-lb:0.0477, loss-ulb:0.0182, weight:0.38, lr:0.0008
[23:39:25.995] iteration:2607  t-loss:0.0652, loss-lb:0.0548, loss-ulb:0.0273, weight:0.38, lr:0.0008
[23:39:26.390] iteration:2608  t-loss:0.0617, loss-lb:0.0502, loss-ulb:0.0300, weight:0.38, lr:0.0008
[23:39:26.784] iteration:2609  t-loss:0.0766, loss-lb:0.0663, loss-ulb:0.0271, weight:0.38, lr:0.0008
[23:39:27.176] iteration:2610  t-loss:0.0378, loss-lb:0.0308, loss-ulb:0.0180, weight:0.38, lr:0.0008
[23:39:27.552] iteration:2611  t-loss:0.0621, loss-lb:0.0599, loss-ulb:0.0058, weight:0.38, lr:0.0008
[23:39:27.929] iteration:2612  t-loss:0.0424, loss-lb:0.0397, loss-ulb:0.0072, weight:0.38, lr:0.0008
[23:39:28.306] iteration:2613  t-loss:0.0610, loss-lb:0.0542, loss-ulb:0.0177, weight:0.38, lr:0.0008
[23:39:28.698] iteration:2614  t-loss:0.0928, loss-lb:0.0878, loss-ulb:0.0131, weight:0.38, lr:0.0008
[23:39:29.087] iteration:2615  t-loss:0.0385, loss-lb:0.0318, loss-ulb:0.0174, weight:0.38, lr:0.0008
[23:39:29.468] iteration:2616  t-loss:0.0265, loss-lb:0.0242, loss-ulb:0.0060, weight:0.38, lr:0.0008
[23:39:29.840] iteration:2617  t-loss:0.0429, loss-lb:0.0325, loss-ulb:0.0271, weight:0.38, lr:0.0008
[23:39:30.214] iteration:2618  t-loss:0.0850, loss-lb:0.0796, loss-ulb:0.0141, weight:0.38, lr:0.0008
[23:39:30.587] iteration:2619  t-loss:0.0675, loss-lb:0.0635, loss-ulb:0.0105, weight:0.38, lr:0.0008
[23:39:30.957] iteration:2620  t-loss:0.0574, loss-lb:0.0338, loss-ulb:0.0614, weight:0.38, lr:0.0008
[23:39:31.329] iteration:2621  t-loss:0.0343, loss-lb:0.0256, loss-ulb:0.0226, weight:0.38, lr:0.0008
[23:39:31.701] iteration:2622  t-loss:0.0444, loss-lb:0.0402, loss-ulb:0.0111, weight:0.38, lr:0.0008
[23:40:35.209] iteration 2622 : dice_score: 0.747496 best_dice: 0.747500
[23:40:35.210]  <<Test>> - Ep:68  - Dice-S/T:71.84/74.75, Best-S:71.84, Best-T:74.75
[23:40:35.210]           - AvgLoss(lb/ulb/all):0.05/0.02/0.06
[23:40:36.538] iteration:2623  t-loss:0.0319, loss-lb:0.0269, loss-ulb:0.0133, weight:0.38, lr:0.0008
[23:40:36.919] iteration:2624  t-loss:0.0410, loss-lb:0.0370, loss-ulb:0.0103, weight:0.38, lr:0.0008
[23:40:37.297] iteration:2625  t-loss:0.0277, loss-lb:0.0254, loss-ulb:0.0061, weight:0.38, lr:0.0008
[23:40:37.681] iteration:2626  t-loss:0.0820, loss-lb:0.0676, loss-ulb:0.0376, weight:0.38, lr:0.0008
[23:40:38.057] iteration:2627  t-loss:0.0269, loss-lb:0.0259, loss-ulb:0.0027, weight:0.38, lr:0.0008
[23:40:38.438] iteration:2628  t-loss:0.0470, loss-lb:0.0325, loss-ulb:0.0377, weight:0.38, lr:0.0008
[23:40:38.816] iteration:2629  t-loss:0.0317, loss-lb:0.0234, loss-ulb:0.0217, weight:0.38, lr:0.0008
[23:40:39.191] iteration:2630  t-loss:0.0479, loss-lb:0.0435, loss-ulb:0.0115, weight:0.38, lr:0.0008
[23:40:39.568] iteration:2631  t-loss:0.0438, loss-lb:0.0320, loss-ulb:0.0309, weight:0.38, lr:0.0008
[23:40:39.954] iteration:2632  t-loss:0.0410, loss-lb:0.0356, loss-ulb:0.0142, weight:0.38, lr:0.0008
[23:40:40.334] iteration:2633  t-loss:0.0851, loss-lb:0.0771, loss-ulb:0.0208, weight:0.38, lr:0.0008
[23:40:40.714] iteration:2634  t-loss:0.0516, loss-lb:0.0450, loss-ulb:0.0171, weight:0.38, lr:0.0008
[23:40:41.094] iteration:2635  t-loss:0.0308, loss-lb:0.0279, loss-ulb:0.0077, weight:0.38, lr:0.0008
[23:40:41.477] iteration:2636  t-loss:0.0521, loss-lb:0.0488, loss-ulb:0.0087, weight:0.38, lr:0.0008
[23:40:41.860] iteration:2637  t-loss:0.0318, loss-lb:0.0301, loss-ulb:0.0044, weight:0.38, lr:0.0008
[23:40:42.241] iteration:2638  t-loss:0.0964, loss-lb:0.0748, loss-ulb:0.0564, weight:0.38, lr:0.0008
[23:40:42.616] iteration:2639  t-loss:0.0670, loss-lb:0.0616, loss-ulb:0.0139, weight:0.38, lr:0.0008
[23:40:42.989] iteration:2640  t-loss:0.0310, loss-lb:0.0232, loss-ulb:0.0205, weight:0.38, lr:0.0008
[23:40:43.370] iteration:2641  t-loss:0.0487, loss-lb:0.0398, loss-ulb:0.0231, weight:0.38, lr:0.0008
[23:40:43.745] iteration:2642  t-loss:0.0916, loss-lb:0.0822, loss-ulb:0.0245, weight:0.38, lr:0.0008
[23:40:44.132] iteration:2643  t-loss:0.1085, loss-lb:0.0941, loss-ulb:0.0375, weight:0.38, lr:0.0008
[23:40:44.536] iteration:2644  t-loss:0.0982, loss-lb:0.0800, loss-ulb:0.0475, weight:0.38, lr:0.0008
[23:40:44.940] iteration:2645  t-loss:0.1296, loss-lb:0.1199, loss-ulb:0.0253, weight:0.38, lr:0.0008
[23:40:45.328] iteration:2646  t-loss:0.0526, loss-lb:0.0446, loss-ulb:0.0207, weight:0.38, lr:0.0008
[23:40:45.702] iteration:2647  t-loss:0.0366, loss-lb:0.0322, loss-ulb:0.0113, weight:0.38, lr:0.0008
[23:40:46.088] iteration:2648  t-loss:0.0623, loss-lb:0.0557, loss-ulb:0.0171, weight:0.38, lr:0.0008
[23:40:46.470] iteration:2649  t-loss:0.0473, loss-lb:0.0427, loss-ulb:0.0119, weight:0.38, lr:0.0008
[23:40:46.849] iteration:2650  t-loss:0.0629, loss-lb:0.0521, loss-ulb:0.0283, weight:0.38, lr:0.0008
[23:40:47.224] iteration:2651  t-loss:0.0703, loss-lb:0.0567, loss-ulb:0.0357, weight:0.38, lr:0.0008
[23:40:47.598] iteration:2652  t-loss:0.0414, loss-lb:0.0344, loss-ulb:0.0184, weight:0.38, lr:0.0008
[23:40:47.973] iteration:2653  t-loss:0.0415, loss-lb:0.0330, loss-ulb:0.0221, weight:0.38, lr:0.0008
[23:40:48.345] iteration:2654  t-loss:0.0542, loss-lb:0.0466, loss-ulb:0.0199, weight:0.38, lr:0.0008
[23:40:48.715] iteration:2655  t-loss:0.0518, loss-lb:0.0254, loss-ulb:0.0689, weight:0.38, lr:0.0008
[23:40:49.087] iteration:2656  t-loss:0.0514, loss-lb:0.0342, loss-ulb:0.0451, weight:0.38, lr:0.0008
[23:40:49.463] iteration:2657  t-loss:0.0486, loss-lb:0.0448, loss-ulb:0.0100, weight:0.38, lr:0.0008
[23:40:49.839] iteration:2658  t-loss:0.0481, loss-lb:0.0382, loss-ulb:0.0259, weight:0.38, lr:0.0008
[23:40:50.219] iteration:2659  t-loss:0.0253, loss-lb:0.0214, loss-ulb:0.0101, weight:0.38, lr:0.0008
[23:40:50.593] iteration:2660  t-loss:0.0360, loss-lb:0.0252, loss-ulb:0.0280, weight:0.38, lr:0.0008
[23:40:51.862] iteration:2661  t-loss:0.0316, loss-lb:0.0272, loss-ulb:0.0115, weight:0.38, lr:0.0008
[23:40:52.258] iteration:2662  t-loss:0.0942, loss-lb:0.0872, loss-ulb:0.0183, weight:0.38, lr:0.0008
[23:40:52.648] iteration:2663  t-loss:0.0624, loss-lb:0.0607, loss-ulb:0.0043, weight:0.38, lr:0.0008
[23:40:53.031] iteration:2664  t-loss:0.0697, loss-lb:0.0631, loss-ulb:0.0172, weight:0.38, lr:0.0008
[23:40:53.412] iteration:2665  t-loss:0.0458, loss-lb:0.0320, loss-ulb:0.0361, weight:0.38, lr:0.0008
[23:40:53.791] iteration:2666  t-loss:0.0392, loss-lb:0.0349, loss-ulb:0.0111, weight:0.38, lr:0.0008
[23:40:54.168] iteration:2667  t-loss:0.0609, loss-lb:0.0554, loss-ulb:0.0144, weight:0.38, lr:0.0008
[23:40:54.551] iteration:2668  t-loss:0.0618, loss-lb:0.0469, loss-ulb:0.0390, weight:0.38, lr:0.0008
[23:40:54.938] iteration:2669  t-loss:0.0478, loss-lb:0.0342, loss-ulb:0.0355, weight:0.38, lr:0.0008
[23:40:55.317] iteration:2670  t-loss:0.0910, loss-lb:0.0822, loss-ulb:0.0230, weight:0.38, lr:0.0008
[23:40:55.702] iteration:2671  t-loss:0.0642, loss-lb:0.0574, loss-ulb:0.0177, weight:0.38, lr:0.0008
[23:40:56.079] iteration:2672  t-loss:0.0318, loss-lb:0.0257, loss-ulb:0.0159, weight:0.38, lr:0.0008
[23:40:56.458] iteration:2673  t-loss:0.0611, loss-lb:0.0589, loss-ulb:0.0058, weight:0.38, lr:0.0008
[23:40:56.832] iteration:2674  t-loss:0.0393, loss-lb:0.0354, loss-ulb:0.0101, weight:0.38, lr:0.0008
[23:40:57.208] iteration:2675  t-loss:0.0635, loss-lb:0.0610, loss-ulb:0.0063, weight:0.38, lr:0.0008
[23:40:57.582] iteration:2676  t-loss:0.0867, loss-lb:0.0741, loss-ulb:0.0330, weight:0.38, lr:0.0008
[23:40:57.958] iteration:2677  t-loss:0.0728, loss-lb:0.0633, loss-ulb:0.0249, weight:0.38, lr:0.0008
[23:40:58.332] iteration:2678  t-loss:0.0783, loss-lb:0.0590, loss-ulb:0.0504, weight:0.38, lr:0.0008
[23:40:58.706] iteration:2679  t-loss:0.0375, loss-lb:0.0304, loss-ulb:0.0186, weight:0.38, lr:0.0008
[23:40:59.079] iteration:2680  t-loss:0.0283, loss-lb:0.0244, loss-ulb:0.0100, weight:0.38, lr:0.0008
[23:40:59.462] iteration:2681  t-loss:0.0823, loss-lb:0.0765, loss-ulb:0.0152, weight:0.38, lr:0.0008
[23:40:59.856] iteration:2682  t-loss:0.0733, loss-lb:0.0666, loss-ulb:0.0174, weight:0.38, lr:0.0008
[23:41:00.246] iteration:2683  t-loss:0.0503, loss-lb:0.0478, loss-ulb:0.0066, weight:0.38, lr:0.0008
[23:41:00.630] iteration:2684  t-loss:0.0460, loss-lb:0.0431, loss-ulb:0.0076, weight:0.38, lr:0.0008
[23:41:01.001] iteration:2685  t-loss:0.0267, loss-lb:0.0227, loss-ulb:0.0105, weight:0.38, lr:0.0008
[23:41:01.363] iteration:2686  t-loss:0.0373, loss-lb:0.0356, loss-ulb:0.0046, weight:0.38, lr:0.0008
[23:41:01.741] iteration:2687  t-loss:0.0307, loss-lb:0.0290, loss-ulb:0.0042, weight:0.38, lr:0.0008
[23:41:02.121] iteration:2688  t-loss:0.0341, loss-lb:0.0325, loss-ulb:0.0041, weight:0.38, lr:0.0008
[23:41:02.496] iteration:2689  t-loss:0.0537, loss-lb:0.0432, loss-ulb:0.0274, weight:0.38, lr:0.0008
[23:41:02.879] iteration:2690  t-loss:0.0898, loss-lb:0.0866, loss-ulb:0.0084, weight:0.38, lr:0.0008
[23:41:03.255] iteration:2691  t-loss:0.0504, loss-lb:0.0473, loss-ulb:0.0081, weight:0.38, lr:0.0008
[23:41:03.632] iteration:2692  t-loss:0.0698, loss-lb:0.0627, loss-ulb:0.0185, weight:0.38, lr:0.0008
[23:41:04.007] iteration:2693  t-loss:0.0766, loss-lb:0.0743, loss-ulb:0.0058, weight:0.38, lr:0.0008
[23:41:04.382] iteration:2694  t-loss:0.0412, loss-lb:0.0363, loss-ulb:0.0127, weight:0.38, lr:0.0008
[23:41:04.758] iteration:2695  t-loss:0.0764, loss-lb:0.0560, loss-ulb:0.0534, weight:0.38, lr:0.0008
[23:41:05.135] iteration:2696  t-loss:0.0393, loss-lb:0.0248, loss-ulb:0.0378, weight:0.38, lr:0.0008
[23:41:05.515] iteration:2697  t-loss:0.0494, loss-lb:0.0430, loss-ulb:0.0165, weight:0.38, lr:0.0008
[23:41:05.889] iteration:2698  t-loss:0.0304, loss-lb:0.0291, loss-ulb:0.0033, weight:0.38, lr:0.0008
[23:41:07.273] iteration:2699  t-loss:0.0299, loss-lb:0.0252, loss-ulb:0.0125, weight:0.38, lr:0.0008
[23:41:07.655] iteration:2700  t-loss:0.0379, loss-lb:0.0259, loss-ulb:0.0314, weight:0.38, lr:0.0008
[23:41:08.036] iteration:2701  t-loss:0.0285, loss-lb:0.0207, loss-ulb:0.0177, weight:0.44, lr:0.0008
[23:41:08.418] iteration:2702  t-loss:0.0602, loss-lb:0.0515, loss-ulb:0.0197, weight:0.44, lr:0.0008
[23:41:08.800] iteration:2703  t-loss:0.0403, loss-lb:0.0219, loss-ulb:0.0419, weight:0.44, lr:0.0008
[23:41:09.184] iteration:2704  t-loss:0.0836, loss-lb:0.0690, loss-ulb:0.0331, weight:0.44, lr:0.0008
[23:41:09.560] iteration:2705  t-loss:0.0332, loss-lb:0.0299, loss-ulb:0.0076, weight:0.44, lr:0.0008
[23:41:09.944] iteration:2706  t-loss:0.0370, loss-lb:0.0252, loss-ulb:0.0267, weight:0.44, lr:0.0008
[23:41:10.322] iteration:2707  t-loss:0.0383, loss-lb:0.0349, loss-ulb:0.0076, weight:0.44, lr:0.0008
[23:41:10.703] iteration:2708  t-loss:0.0476, loss-lb:0.0426, loss-ulb:0.0113, weight:0.44, lr:0.0008
[23:41:11.100] iteration:2709  t-loss:0.0364, loss-lb:0.0246, loss-ulb:0.0268, weight:0.44, lr:0.0008
[23:41:11.478] iteration:2710  t-loss:0.0650, loss-lb:0.0555, loss-ulb:0.0215, weight:0.44, lr:0.0008
[23:41:11.851] iteration:2711  t-loss:0.0327, loss-lb:0.0262, loss-ulb:0.0147, weight:0.44, lr:0.0008
[23:41:12.231] iteration:2712  t-loss:0.0441, loss-lb:0.0286, loss-ulb:0.0351, weight:0.44, lr:0.0008
[23:41:12.612] iteration:2713  t-loss:0.0763, loss-lb:0.0713, loss-ulb:0.0113, weight:0.44, lr:0.0008
[23:41:12.990] iteration:2714  t-loss:0.0392, loss-lb:0.0303, loss-ulb:0.0202, weight:0.44, lr:0.0008
[23:41:13.367] iteration:2715  t-loss:0.0359, loss-lb:0.0274, loss-ulb:0.0191, weight:0.44, lr:0.0008
[23:41:13.746] iteration:2716  t-loss:0.0620, loss-lb:0.0567, loss-ulb:0.0122, weight:0.44, lr:0.0008
[23:41:14.133] iteration:2717  t-loss:0.0264, loss-lb:0.0210, loss-ulb:0.0121, weight:0.44, lr:0.0008
[23:41:14.511] iteration:2718  t-loss:0.0419, loss-lb:0.0321, loss-ulb:0.0225, weight:0.44, lr:0.0008
[23:41:14.904] iteration:2719  t-loss:0.0276, loss-lb:0.0216, loss-ulb:0.0137, weight:0.44, lr:0.0008
[23:41:15.313] iteration:2720  t-loss:0.0549, loss-lb:0.0380, loss-ulb:0.0384, weight:0.44, lr:0.0008
[23:41:15.719] iteration:2721  t-loss:0.0994, loss-lb:0.0660, loss-ulb:0.0758, weight:0.44, lr:0.0008
[23:41:16.106] iteration:2722  t-loss:0.0311, loss-lb:0.0285, loss-ulb:0.0060, weight:0.44, lr:0.0008
[23:41:16.488] iteration:2723  t-loss:0.0698, loss-lb:0.0685, loss-ulb:0.0029, weight:0.44, lr:0.0008
[23:41:16.869] iteration:2724  t-loss:0.0312, loss-lb:0.0264, loss-ulb:0.0109, weight:0.44, lr:0.0008
[23:41:17.257] iteration:2725  t-loss:0.0248, loss-lb:0.0221, loss-ulb:0.0063, weight:0.44, lr:0.0008
[23:41:17.636] iteration:2726  t-loss:0.0389, loss-lb:0.0371, loss-ulb:0.0040, weight:0.44, lr:0.0008
[23:41:18.010] iteration:2727  t-loss:0.0457, loss-lb:0.0319, loss-ulb:0.0312, weight:0.44, lr:0.0008
[23:41:18.409] iteration:2728  t-loss:0.0335, loss-lb:0.0239, loss-ulb:0.0219, weight:0.44, lr:0.0008
[23:41:18.799] iteration:2729  t-loss:0.0439, loss-lb:0.0296, loss-ulb:0.0323, weight:0.44, lr:0.0008
[23:41:19.181] iteration:2730  t-loss:0.0594, loss-lb:0.0487, loss-ulb:0.0244, weight:0.44, lr:0.0008
[23:41:19.561] iteration:2731  t-loss:0.0317, loss-lb:0.0297, loss-ulb:0.0044, weight:0.44, lr:0.0008
[23:41:19.944] iteration:2732  t-loss:0.0691, loss-lb:0.0638, loss-ulb:0.0121, weight:0.44, lr:0.0008
[23:41:20.325] iteration:2733  t-loss:0.0745, loss-lb:0.0659, loss-ulb:0.0195, weight:0.44, lr:0.0008
[23:41:20.700] iteration:2734  t-loss:0.0439, loss-lb:0.0245, loss-ulb:0.0440, weight:0.44, lr:0.0008
[23:41:21.081] iteration:2735  t-loss:0.0434, loss-lb:0.0375, loss-ulb:0.0134, weight:0.44, lr:0.0008
[23:41:21.460] iteration:2736  t-loss:0.0596, loss-lb:0.0534, loss-ulb:0.0141, weight:0.44, lr:0.0008
[23:41:22.735] iteration:2737  t-loss:0.0447, loss-lb:0.0425, loss-ulb:0.0050, weight:0.44, lr:0.0008
[23:41:23.149] iteration:2738  t-loss:0.0354, loss-lb:0.0306, loss-ulb:0.0108, weight:0.44, lr:0.0008
[23:41:23.561] iteration:2739  t-loss:0.0849, loss-lb:0.0833, loss-ulb:0.0037, weight:0.44, lr:0.0008
[23:41:23.958] iteration:2740  t-loss:0.0254, loss-lb:0.0238, loss-ulb:0.0036, weight:0.44, lr:0.0008
[23:41:24.337] iteration:2741  t-loss:0.1174, loss-lb:0.1024, loss-ulb:0.0342, weight:0.44, lr:0.0008
[23:41:24.707] iteration:2742  t-loss:0.0477, loss-lb:0.0454, loss-ulb:0.0053, weight:0.44, lr:0.0008
[23:41:25.083] iteration:2743  t-loss:0.0512, loss-lb:0.0464, loss-ulb:0.0108, weight:0.44, lr:0.0008
[23:41:25.455] iteration:2744  t-loss:0.0429, loss-lb:0.0257, loss-ulb:0.0389, weight:0.44, lr:0.0008
[23:41:25.838] iteration:2745  t-loss:0.0403, loss-lb:0.0301, loss-ulb:0.0233, weight:0.44, lr:0.0008
[23:41:26.222] iteration:2746  t-loss:0.0634, loss-lb:0.0516, loss-ulb:0.0267, weight:0.44, lr:0.0008
[23:41:26.602] iteration:2747  t-loss:0.0582, loss-lb:0.0560, loss-ulb:0.0049, weight:0.44, lr:0.0008
[23:41:26.982] iteration:2748  t-loss:0.0318, loss-lb:0.0253, loss-ulb:0.0147, weight:0.44, lr:0.0008
[23:41:27.359] iteration:2749  t-loss:0.0265, loss-lb:0.0206, loss-ulb:0.0132, weight:0.44, lr:0.0008
[23:41:27.734] iteration:2750  t-loss:0.0591, loss-lb:0.0532, loss-ulb:0.0134, weight:0.44, lr:0.0008
[23:41:28.110] iteration:2751  t-loss:0.0447, loss-lb:0.0375, loss-ulb:0.0163, weight:0.44, lr:0.0008
[23:41:28.486] iteration:2752  t-loss:0.0324, loss-lb:0.0264, loss-ulb:0.0135, weight:0.44, lr:0.0008
[23:41:28.870] iteration:2753  t-loss:0.0717, loss-lb:0.0671, loss-ulb:0.0103, weight:0.44, lr:0.0008
[23:41:29.244] iteration:2754  t-loss:0.0270, loss-lb:0.0242, loss-ulb:0.0064, weight:0.44, lr:0.0008
[23:41:29.617] iteration:2755  t-loss:0.0698, loss-lb:0.0646, loss-ulb:0.0119, weight:0.44, lr:0.0008
[23:41:29.992] iteration:2756  t-loss:0.0279, loss-lb:0.0237, loss-ulb:0.0096, weight:0.44, lr:0.0008
[23:41:30.377] iteration:2757  t-loss:0.0526, loss-lb:0.0410, loss-ulb:0.0263, weight:0.44, lr:0.0008
[23:41:30.778] iteration:2758  t-loss:0.0734, loss-lb:0.0705, loss-ulb:0.0064, weight:0.44, lr:0.0008
[23:41:31.175] iteration:2759  t-loss:0.0611, loss-lb:0.0484, loss-ulb:0.0288, weight:0.44, lr:0.0008
[23:41:31.568] iteration:2760  t-loss:0.0575, loss-lb:0.0527, loss-ulb:0.0108, weight:0.44, lr:0.0008
[23:41:31.956] iteration:2761  t-loss:0.0361, loss-lb:0.0233, loss-ulb:0.0291, weight:0.44, lr:0.0008
[23:41:32.333] iteration:2762  t-loss:0.0382, loss-lb:0.0294, loss-ulb:0.0198, weight:0.44, lr:0.0008
[23:41:32.714] iteration:2763  t-loss:0.1057, loss-lb:0.0955, loss-ulb:0.0230, weight:0.44, lr:0.0008
[23:41:33.091] iteration:2764  t-loss:0.0401, loss-lb:0.0248, loss-ulb:0.0348, weight:0.44, lr:0.0008
[23:41:33.466] iteration:2765  t-loss:0.0271, loss-lb:0.0258, loss-ulb:0.0029, weight:0.44, lr:0.0008
[23:41:33.851] iteration:2766  t-loss:0.0499, loss-lb:0.0460, loss-ulb:0.0088, weight:0.44, lr:0.0008
[23:41:34.223] iteration:2767  t-loss:0.0404, loss-lb:0.0341, loss-ulb:0.0143, weight:0.44, lr:0.0008
[23:41:34.599] iteration:2768  t-loss:0.0503, loss-lb:0.0433, loss-ulb:0.0159, weight:0.44, lr:0.0008
[23:41:34.976] iteration:2769  t-loss:0.0278, loss-lb:0.0251, loss-ulb:0.0061, weight:0.44, lr:0.0008
[23:41:35.348] iteration:2770  t-loss:0.0344, loss-lb:0.0239, loss-ulb:0.0239, weight:0.44, lr:0.0008
[23:41:35.719] iteration:2771  t-loss:0.0820, loss-lb:0.0804, loss-ulb:0.0036, weight:0.44, lr:0.0008
[23:41:36.092] iteration:2772  t-loss:0.0616, loss-lb:0.0597, loss-ulb:0.0043, weight:0.44, lr:0.0008
[23:41:36.463] iteration:2773  t-loss:0.0290, loss-lb:0.0283, loss-ulb:0.0016, weight:0.44, lr:0.0008
[23:41:36.836] iteration:2774  t-loss:0.1044, loss-lb:0.0963, loss-ulb:0.0184, weight:0.44, lr:0.0008
[23:42:41.961] iteration 2774 : dice_score: 0.730602 best_dice: 0.747500
[23:42:41.962]  <<Test>> - Ep:72  - Dice-S/T:72.32/73.06, Best-S:72.32, Best-T:74.75
[23:42:41.962]           - AvgLoss(lb/ulb/all):0.05/0.02/0.05
[23:42:43.106] iteration:2775  t-loss:0.0379, loss-lb:0.0314, loss-ulb:0.0146, weight:0.44, lr:0.0008
[23:42:43.487] iteration:2776  t-loss:0.0604, loss-lb:0.0504, loss-ulb:0.0228, weight:0.44, lr:0.0008
[23:42:43.868] iteration:2777  t-loss:0.0476, loss-lb:0.0349, loss-ulb:0.0289, weight:0.44, lr:0.0008
[23:42:44.247] iteration:2778  t-loss:0.0420, loss-lb:0.0411, loss-ulb:0.0021, weight:0.44, lr:0.0008
[23:42:44.627] iteration:2779  t-loss:0.0344, loss-lb:0.0322, loss-ulb:0.0050, weight:0.44, lr:0.0008
[23:42:45.012] iteration:2780  t-loss:0.0391, loss-lb:0.0323, loss-ulb:0.0156, weight:0.44, lr:0.0008
[23:42:45.393] iteration:2781  t-loss:0.0379, loss-lb:0.0353, loss-ulb:0.0060, weight:0.44, lr:0.0008
[23:42:45.769] iteration:2782  t-loss:0.0245, loss-lb:0.0223, loss-ulb:0.0049, weight:0.44, lr:0.0008
[23:42:46.148] iteration:2783  t-loss:0.0401, loss-lb:0.0381, loss-ulb:0.0046, weight:0.44, lr:0.0008
[23:42:46.532] iteration:2784  t-loss:0.0356, loss-lb:0.0285, loss-ulb:0.0162, weight:0.44, lr:0.0008
[23:42:46.917] iteration:2785  t-loss:0.0361, loss-lb:0.0332, loss-ulb:0.0067, weight:0.44, lr:0.0008
[23:42:47.293] iteration:2786  t-loss:0.0433, loss-lb:0.0304, loss-ulb:0.0293, weight:0.44, lr:0.0008
[23:42:47.677] iteration:2787  t-loss:0.0527, loss-lb:0.0498, loss-ulb:0.0067, weight:0.44, lr:0.0008
[23:42:48.058] iteration:2788  t-loss:0.0559, loss-lb:0.0537, loss-ulb:0.0052, weight:0.44, lr:0.0008
[23:42:48.438] iteration:2789  t-loss:0.0381, loss-lb:0.0283, loss-ulb:0.0223, weight:0.44, lr:0.0008
[23:42:48.814] iteration:2790  t-loss:0.0264, loss-lb:0.0198, loss-ulb:0.0150, weight:0.44, lr:0.0008
[23:42:49.188] iteration:2791  t-loss:0.0405, loss-lb:0.0235, loss-ulb:0.0385, weight:0.44, lr:0.0008
[23:42:49.569] iteration:2792  t-loss:0.0554, loss-lb:0.0408, loss-ulb:0.0330, weight:0.44, lr:0.0008
[23:42:49.956] iteration:2793  t-loss:0.0313, loss-lb:0.0296, loss-ulb:0.0040, weight:0.44, lr:0.0008
[23:42:50.359] iteration:2794  t-loss:0.0300, loss-lb:0.0187, loss-ulb:0.0255, weight:0.44, lr:0.0008
[23:42:50.752] iteration:2795  t-loss:0.0278, loss-lb:0.0268, loss-ulb:0.0022, weight:0.44, lr:0.0008
[23:42:51.132] iteration:2796  t-loss:0.0713, loss-lb:0.0631, loss-ulb:0.0186, weight:0.44, lr:0.0008
[23:42:51.511] iteration:2797  t-loss:0.0347, loss-lb:0.0250, loss-ulb:0.0220, weight:0.44, lr:0.0008
[23:42:51.886] iteration:2798  t-loss:0.0266, loss-lb:0.0259, loss-ulb:0.0016, weight:0.44, lr:0.0008
[23:42:52.270] iteration:2799  t-loss:0.1024, loss-lb:0.0938, loss-ulb:0.0193, weight:0.44, lr:0.0008
[23:42:52.647] iteration:2800  t-loss:0.0426, loss-lb:0.0305, loss-ulb:0.0273, weight:0.44, lr:0.0008
[23:42:53.033] iteration:2801  t-loss:0.0513, loss-lb:0.0477, loss-ulb:0.0081, weight:0.44, lr:0.0008
[23:42:53.413] iteration:2802  t-loss:0.0435, loss-lb:0.0421, loss-ulb:0.0032, weight:0.44, lr:0.0008
[23:42:53.788] iteration:2803  t-loss:0.0268, loss-lb:0.0261, loss-ulb:0.0016, weight:0.44, lr:0.0008
[23:42:54.163] iteration:2804  t-loss:0.0384, loss-lb:0.0345, loss-ulb:0.0089, weight:0.44, lr:0.0008
[23:42:54.540] iteration:2805  t-loss:0.0430, loss-lb:0.0387, loss-ulb:0.0099, weight:0.44, lr:0.0008
[23:42:54.918] iteration:2806  t-loss:0.0571, loss-lb:0.0553, loss-ulb:0.0040, weight:0.44, lr:0.0008
[23:42:55.298] iteration:2807  t-loss:0.0505, loss-lb:0.0392, loss-ulb:0.0257, weight:0.44, lr:0.0008
[23:42:55.673] iteration:2808  t-loss:0.0345, loss-lb:0.0301, loss-ulb:0.0100, weight:0.44, lr:0.0008
[23:42:56.048] iteration:2809  t-loss:0.0622, loss-lb:0.0570, loss-ulb:0.0119, weight:0.44, lr:0.0008
[23:42:56.422] iteration:2810  t-loss:0.0248, loss-lb:0.0220, loss-ulb:0.0064, weight:0.44, lr:0.0008
[23:42:56.799] iteration:2811  t-loss:0.0311, loss-lb:0.0262, loss-ulb:0.0110, weight:0.44, lr:0.0008
[23:42:57.178] iteration:2812  t-loss:0.0656, loss-lb:0.0516, loss-ulb:0.0318, weight:0.44, lr:0.0008
[23:42:58.468] iteration:2813  t-loss:0.0298, loss-lb:0.0285, loss-ulb:0.0030, weight:0.44, lr:0.0008
[23:42:58.857] iteration:2814  t-loss:0.0223, loss-lb:0.0183, loss-ulb:0.0092, weight:0.44, lr:0.0008
[23:42:59.244] iteration:2815  t-loss:0.0531, loss-lb:0.0483, loss-ulb:0.0109, weight:0.44, lr:0.0008
[23:42:59.643] iteration:2816  t-loss:0.0667, loss-lb:0.0569, loss-ulb:0.0221, weight:0.44, lr:0.0008
[23:43:00.031] iteration:2817  t-loss:0.0397, loss-lb:0.0279, loss-ulb:0.0268, weight:0.44, lr:0.0008
[23:43:00.405] iteration:2818  t-loss:0.0349, loss-lb:0.0228, loss-ulb:0.0275, weight:0.44, lr:0.0008
[23:43:00.785] iteration:2819  t-loss:0.0853, loss-lb:0.0761, loss-ulb:0.0208, weight:0.44, lr:0.0008
[23:43:01.166] iteration:2820  t-loss:0.0327, loss-lb:0.0238, loss-ulb:0.0202, weight:0.44, lr:0.0008
[23:43:01.544] iteration:2821  t-loss:0.0452, loss-lb:0.0354, loss-ulb:0.0222, weight:0.44, lr:0.0008
[23:43:01.922] iteration:2822  t-loss:0.0468, loss-lb:0.0438, loss-ulb:0.0067, weight:0.44, lr:0.0008
[23:43:02.298] iteration:2823  t-loss:0.0386, loss-lb:0.0281, loss-ulb:0.0239, weight:0.44, lr:0.0008
[23:43:02.672] iteration:2824  t-loss:0.0316, loss-lb:0.0227, loss-ulb:0.0201, weight:0.44, lr:0.0008
[23:43:03.046] iteration:2825  t-loss:0.0504, loss-lb:0.0411, loss-ulb:0.0210, weight:0.44, lr:0.0008
[23:43:03.423] iteration:2826  t-loss:0.0762, loss-lb:0.0600, loss-ulb:0.0367, weight:0.44, lr:0.0008
[23:43:03.799] iteration:2827  t-loss:0.0358, loss-lb:0.0327, loss-ulb:0.0071, weight:0.44, lr:0.0008
[23:43:04.176] iteration:2828  t-loss:0.0583, loss-lb:0.0515, loss-ulb:0.0155, weight:0.44, lr:0.0008
[23:43:04.554] iteration:2829  t-loss:0.0360, loss-lb:0.0348, loss-ulb:0.0027, weight:0.44, lr:0.0008
[23:43:04.933] iteration:2830  t-loss:0.0813, loss-lb:0.0753, loss-ulb:0.0136, weight:0.44, lr:0.0008
[23:43:05.323] iteration:2831  t-loss:0.0334, loss-lb:0.0250, loss-ulb:0.0191, weight:0.44, lr:0.0008
[23:43:05.720] iteration:2832  t-loss:0.0598, loss-lb:0.0517, loss-ulb:0.0184, weight:0.44, lr:0.0008
[23:43:06.106] iteration:2833  t-loss:0.0551, loss-lb:0.0536, loss-ulb:0.0034, weight:0.44, lr:0.0008
[23:43:06.487] iteration:2834  t-loss:0.0351, loss-lb:0.0309, loss-ulb:0.0096, weight:0.44, lr:0.0008
[23:43:06.863] iteration:2835  t-loss:0.0363, loss-lb:0.0348, loss-ulb:0.0035, weight:0.44, lr:0.0008
[23:43:07.237] iteration:2836  t-loss:0.0270, loss-lb:0.0258, loss-ulb:0.0029, weight:0.44, lr:0.0008
[23:43:07.619] iteration:2837  t-loss:0.0520, loss-lb:0.0498, loss-ulb:0.0051, weight:0.44, lr:0.0008
[23:43:07.998] iteration:2838  t-loss:0.0776, loss-lb:0.0639, loss-ulb:0.0310, weight:0.44, lr:0.0008
[23:43:08.381] iteration:2839  t-loss:0.0277, loss-lb:0.0223, loss-ulb:0.0124, weight:0.44, lr:0.0008
[23:43:08.764] iteration:2840  t-loss:0.0581, loss-lb:0.0464, loss-ulb:0.0267, weight:0.44, lr:0.0008
[23:43:09.146] iteration:2841  t-loss:0.0288, loss-lb:0.0252, loss-ulb:0.0080, weight:0.44, lr:0.0008
[23:43:09.527] iteration:2842  t-loss:0.0752, loss-lb:0.0667, loss-ulb:0.0194, weight:0.44, lr:0.0008
[23:43:09.907] iteration:2843  t-loss:0.0964, loss-lb:0.0842, loss-ulb:0.0278, weight:0.44, lr:0.0008
[23:43:10.281] iteration:2844  t-loss:0.0333, loss-lb:0.0322, loss-ulb:0.0026, weight:0.44, lr:0.0008
[23:43:10.654] iteration:2845  t-loss:0.0344, loss-lb:0.0283, loss-ulb:0.0139, weight:0.44, lr:0.0008
[23:43:11.029] iteration:2846  t-loss:0.0681, loss-lb:0.0651, loss-ulb:0.0070, weight:0.44, lr:0.0008
[23:43:11.409] iteration:2847  t-loss:0.0784, loss-lb:0.0713, loss-ulb:0.0159, weight:0.44, lr:0.0008
[23:43:11.786] iteration:2848  t-loss:0.0316, loss-lb:0.0274, loss-ulb:0.0095, weight:0.44, lr:0.0008
[23:43:12.166] iteration:2849  t-loss:0.0639, loss-lb:0.0560, loss-ulb:0.0178, weight:0.44, lr:0.0008
[23:43:12.544] iteration:2850  t-loss:0.0536, loss-lb:0.0523, loss-ulb:0.0030, weight:0.44, lr:0.0008
[23:43:13.807] iteration:2851  t-loss:0.0723, loss-lb:0.0568, loss-ulb:0.0307, weight:0.50, lr:0.0008
[23:43:14.208] iteration:2852  t-loss:0.0426, loss-lb:0.0356, loss-ulb:0.0139, weight:0.50, lr:0.0008
[23:43:14.586] iteration:2853  t-loss:0.0431, loss-lb:0.0334, loss-ulb:0.0193, weight:0.50, lr:0.0008
[23:43:14.966] iteration:2854  t-loss:0.0521, loss-lb:0.0472, loss-ulb:0.0098, weight:0.50, lr:0.0008
[23:43:15.345] iteration:2855  t-loss:0.0392, loss-lb:0.0336, loss-ulb:0.0110, weight:0.50, lr:0.0008
[23:43:15.724] iteration:2856  t-loss:0.0648, loss-lb:0.0507, loss-ulb:0.0280, weight:0.50, lr:0.0008
[23:43:16.104] iteration:2857  t-loss:0.0354, loss-lb:0.0345, loss-ulb:0.0020, weight:0.50, lr:0.0008
[23:43:16.480] iteration:2858  t-loss:0.0404, loss-lb:0.0264, loss-ulb:0.0277, weight:0.50, lr:0.0008
[23:43:16.861] iteration:2859  t-loss:0.0456, loss-lb:0.0354, loss-ulb:0.0203, weight:0.50, lr:0.0008
[23:43:17.242] iteration:2860  t-loss:0.0838, loss-lb:0.0511, loss-ulb:0.0648, weight:0.50, lr:0.0008
[23:43:17.620] iteration:2861  t-loss:0.0605, loss-lb:0.0447, loss-ulb:0.0315, weight:0.50, lr:0.0008
[23:43:18.001] iteration:2862  t-loss:0.0648, loss-lb:0.0558, loss-ulb:0.0179, weight:0.50, lr:0.0008
[23:43:18.381] iteration:2863  t-loss:0.0621, loss-lb:0.0609, loss-ulb:0.0023, weight:0.50, lr:0.0008
[23:43:18.760] iteration:2864  t-loss:0.0666, loss-lb:0.0555, loss-ulb:0.0220, weight:0.50, lr:0.0008
[23:43:19.139] iteration:2865  t-loss:0.0629, loss-lb:0.0439, loss-ulb:0.0378, weight:0.50, lr:0.0008
[23:43:19.517] iteration:2866  t-loss:0.0574, loss-lb:0.0543, loss-ulb:0.0061, weight:0.50, lr:0.0008
[23:43:19.896] iteration:2867  t-loss:0.0405, loss-lb:0.0264, loss-ulb:0.0280, weight:0.50, lr:0.0008
[23:43:20.272] iteration:2868  t-loss:0.0876, loss-lb:0.0250, loss-ulb:0.1242, weight:0.50, lr:0.0008
[23:43:20.670] iteration:2869  t-loss:0.0680, loss-lb:0.0566, loss-ulb:0.0227, weight:0.50, lr:0.0008
[23:43:21.084] iteration:2870  t-loss:0.0396, loss-lb:0.0340, loss-ulb:0.0112, weight:0.50, lr:0.0008
[23:43:21.477] iteration:2871  t-loss:0.0318, loss-lb:0.0285, loss-ulb:0.0065, weight:0.50, lr:0.0008
[23:43:21.863] iteration:2872  t-loss:0.0387, loss-lb:0.0304, loss-ulb:0.0165, weight:0.50, lr:0.0008
[23:43:22.248] iteration:2873  t-loss:0.0576, loss-lb:0.0488, loss-ulb:0.0175, weight:0.50, lr:0.0008
[23:43:22.629] iteration:2874  t-loss:0.0691, loss-lb:0.0621, loss-ulb:0.0139, weight:0.50, lr:0.0008
[23:43:23.009] iteration:2875  t-loss:0.0410, loss-lb:0.0287, loss-ulb:0.0243, weight:0.50, lr:0.0008
[23:43:23.389] iteration:2876  t-loss:0.0314, loss-lb:0.0262, loss-ulb:0.0104, weight:0.50, lr:0.0008
[23:43:23.768] iteration:2877  t-loss:0.0421, loss-lb:0.0280, loss-ulb:0.0280, weight:0.50, lr:0.0008
[23:43:24.150] iteration:2878  t-loss:0.0380, loss-lb:0.0361, loss-ulb:0.0037, weight:0.50, lr:0.0008
[23:43:24.526] iteration:2879  t-loss:0.0274, loss-lb:0.0250, loss-ulb:0.0048, weight:0.50, lr:0.0008
[23:43:24.909] iteration:2880  t-loss:0.0635, loss-lb:0.0513, loss-ulb:0.0242, weight:0.50, lr:0.0008
[23:43:25.282] iteration:2881  t-loss:0.0403, loss-lb:0.0383, loss-ulb:0.0041, weight:0.50, lr:0.0008
[23:43:25.656] iteration:2882  t-loss:0.0566, loss-lb:0.0550, loss-ulb:0.0033, weight:0.50, lr:0.0008
[23:43:26.033] iteration:2883  t-loss:0.0468, loss-lb:0.0442, loss-ulb:0.0052, weight:0.50, lr:0.0008
[23:43:26.410] iteration:2884  t-loss:0.1299, loss-lb:0.1216, loss-ulb:0.0165, weight:0.50, lr:0.0008
[23:43:26.790] iteration:2885  t-loss:0.0493, loss-lb:0.0465, loss-ulb:0.0055, weight:0.50, lr:0.0008
[23:43:27.163] iteration:2886  t-loss:0.0475, loss-lb:0.0419, loss-ulb:0.0111, weight:0.50, lr:0.0008
[23:43:27.538] iteration:2887  t-loss:0.0501, loss-lb:0.0295, loss-ulb:0.0409, weight:0.50, lr:0.0008
[23:43:27.915] iteration:2888  t-loss:0.0400, loss-lb:0.0356, loss-ulb:0.0087, weight:0.50, lr:0.0008
[23:43:29.573] iteration:2889  t-loss:0.0452, loss-lb:0.0356, loss-ulb:0.0190, weight:0.50, lr:0.0008
[23:43:29.961] iteration:2890  t-loss:0.0644, loss-lb:0.0548, loss-ulb:0.0190, weight:0.50, lr:0.0008
[23:43:30.350] iteration:2891  t-loss:0.0345, loss-lb:0.0285, loss-ulb:0.0119, weight:0.50, lr:0.0008
[23:43:30.728] iteration:2892  t-loss:0.0378, loss-lb:0.0338, loss-ulb:0.0081, weight:0.50, lr:0.0008
[23:43:31.107] iteration:2893  t-loss:0.0264, loss-lb:0.0215, loss-ulb:0.0096, weight:0.50, lr:0.0008
[23:43:31.488] iteration:2894  t-loss:0.0822, loss-lb:0.0619, loss-ulb:0.0402, weight:0.50, lr:0.0008
[23:43:31.869] iteration:2895  t-loss:0.0945, loss-lb:0.0737, loss-ulb:0.0412, weight:0.50, lr:0.0008
[23:43:32.251] iteration:2896  t-loss:0.0746, loss-lb:0.0679, loss-ulb:0.0133, weight:0.50, lr:0.0008
[23:43:32.625] iteration:2897  t-loss:0.0370, loss-lb:0.0351, loss-ulb:0.0038, weight:0.50, lr:0.0008
[23:43:32.998] iteration:2898  t-loss:0.0658, loss-lb:0.0350, loss-ulb:0.0610, weight:0.50, lr:0.0008
[23:43:33.379] iteration:2899  t-loss:0.0601, loss-lb:0.0563, loss-ulb:0.0075, weight:0.50, lr:0.0008
[23:43:33.754] iteration:2900  t-loss:0.0341, loss-lb:0.0316, loss-ulb:0.0050, weight:0.50, lr:0.0008
[23:43:34.129] iteration:2901  t-loss:0.0462, loss-lb:0.0431, loss-ulb:0.0063, weight:0.50, lr:0.0008
[23:43:34.501] iteration:2902  t-loss:0.0504, loss-lb:0.0257, loss-ulb:0.0491, weight:0.50, lr:0.0008
[23:43:34.879] iteration:2903  t-loss:0.0727, loss-lb:0.0606, loss-ulb:0.0242, weight:0.50, lr:0.0008
[23:43:35.256] iteration:2904  t-loss:0.0524, loss-lb:0.0437, loss-ulb:0.0172, weight:0.50, lr:0.0008
[23:43:35.630] iteration:2905  t-loss:0.0344, loss-lb:0.0233, loss-ulb:0.0218, weight:0.50, lr:0.0008
[23:43:36.014] iteration:2906  t-loss:0.0798, loss-lb:0.0692, loss-ulb:0.0212, weight:0.50, lr:0.0008
[23:43:36.425] iteration:2907  t-loss:0.0598, loss-lb:0.0552, loss-ulb:0.0091, weight:0.50, lr:0.0008
[23:43:36.829] iteration:2908  t-loss:0.0598, loss-lb:0.0546, loss-ulb:0.0103, weight:0.50, lr:0.0008
[23:43:37.229] iteration:2909  t-loss:0.0944, loss-lb:0.0843, loss-ulb:0.0201, weight:0.50, lr:0.0008
[23:43:37.599] iteration:2910  t-loss:0.0423, loss-lb:0.0367, loss-ulb:0.0110, weight:0.50, lr:0.0008
[23:43:37.967] iteration:2911  t-loss:0.0377, loss-lb:0.0357, loss-ulb:0.0039, weight:0.50, lr:0.0008
[23:43:38.347] iteration:2912  t-loss:0.0480, loss-lb:0.0465, loss-ulb:0.0029, weight:0.50, lr:0.0008
[23:43:38.725] iteration:2913  t-loss:0.0461, loss-lb:0.0258, loss-ulb:0.0401, weight:0.50, lr:0.0008
[23:43:39.103] iteration:2914  t-loss:0.0317, loss-lb:0.0292, loss-ulb:0.0050, weight:0.50, lr:0.0008
[23:43:39.487] iteration:2915  t-loss:0.1039, loss-lb:0.1005, loss-ulb:0.0068, weight:0.50, lr:0.0008
[23:43:39.872] iteration:2916  t-loss:0.0314, loss-lb:0.0269, loss-ulb:0.0090, weight:0.50, lr:0.0008
[23:43:40.252] iteration:2917  t-loss:0.0697, loss-lb:0.0641, loss-ulb:0.0112, weight:0.50, lr:0.0008
[23:43:40.625] iteration:2918  t-loss:0.0443, loss-lb:0.0353, loss-ulb:0.0180, weight:0.50, lr:0.0008
[23:43:40.999] iteration:2919  t-loss:0.0455, loss-lb:0.0381, loss-ulb:0.0147, weight:0.50, lr:0.0008
[23:43:41.373] iteration:2920  t-loss:0.0680, loss-lb:0.0569, loss-ulb:0.0219, weight:0.50, lr:0.0008
[23:43:41.748] iteration:2921  t-loss:0.0942, loss-lb:0.0910, loss-ulb:0.0063, weight:0.50, lr:0.0008
[23:43:42.120] iteration:2922  t-loss:0.0421, loss-lb:0.0330, loss-ulb:0.0181, weight:0.50, lr:0.0008
[23:43:42.494] iteration:2923  t-loss:0.0848, loss-lb:0.0775, loss-ulb:0.0146, weight:0.50, lr:0.0008
[23:43:42.865] iteration:2924  t-loss:0.0766, loss-lb:0.0309, loss-ulb:0.0905, weight:0.50, lr:0.0008
[23:43:43.235] iteration:2925  t-loss:0.0598, loss-lb:0.0551, loss-ulb:0.0093, weight:0.50, lr:0.0008
[23:43:43.620] iteration:2926  t-loss:0.0713, loss-lb:0.0611, loss-ulb:0.0203, weight:0.50, lr:0.0008
[23:44:48.445] iteration 2926 : dice_score: 0.782970 best_dice: 0.783000
[23:44:48.445]  <<Test>> - Ep:76  - Dice-S/T:77.47/78.30, Best-S:77.47, Best-T:78.30
[23:44:48.445]           - AvgLoss(lb/ulb/all):0.05/0.02/0.06
[23:44:49.680] iteration:2927  t-loss:0.0265, loss-lb:0.0237, loss-ulb:0.0056, weight:0.50, lr:0.0008
[23:44:50.069] iteration:2928  t-loss:0.1016, loss-lb:0.1001, loss-ulb:0.0029, weight:0.50, lr:0.0008
[23:44:50.444] iteration:2929  t-loss:0.0404, loss-lb:0.0311, loss-ulb:0.0185, weight:0.50, lr:0.0008
[23:44:50.824] iteration:2930  t-loss:0.0662, loss-lb:0.0485, loss-ulb:0.0351, weight:0.50, lr:0.0008
[23:44:51.212] iteration:2931  t-loss:0.0737, loss-lb:0.0684, loss-ulb:0.0106, weight:0.50, lr:0.0008
[23:44:51.592] iteration:2932  t-loss:0.0318, loss-lb:0.0262, loss-ulb:0.0111, weight:0.50, lr:0.0008
[23:44:51.972] iteration:2933  t-loss:0.0603, loss-lb:0.0415, loss-ulb:0.0372, weight:0.50, lr:0.0008
[23:44:52.355] iteration:2934  t-loss:0.0488, loss-lb:0.0375, loss-ulb:0.0224, weight:0.50, lr:0.0008
[23:44:52.743] iteration:2935  t-loss:0.0519, loss-lb:0.0454, loss-ulb:0.0130, weight:0.50, lr:0.0008
[23:44:53.129] iteration:2936  t-loss:0.1202, loss-lb:0.1181, loss-ulb:0.0042, weight:0.50, lr:0.0008
[23:44:53.511] iteration:2937  t-loss:0.0535, loss-lb:0.0448, loss-ulb:0.0172, weight:0.50, lr:0.0008
[23:44:53.888] iteration:2938  t-loss:0.0395, loss-lb:0.0292, loss-ulb:0.0205, weight:0.50, lr:0.0008
[23:44:54.265] iteration:2939  t-loss:0.0435, loss-lb:0.0417, loss-ulb:0.0037, weight:0.50, lr:0.0008
[23:44:54.653] iteration:2940  t-loss:0.0490, loss-lb:0.0411, loss-ulb:0.0157, weight:0.50, lr:0.0008
[23:44:55.044] iteration:2941  t-loss:0.0620, loss-lb:0.0525, loss-ulb:0.0189, weight:0.50, lr:0.0008
[23:44:55.428] iteration:2942  t-loss:0.0708, loss-lb:0.0652, loss-ulb:0.0113, weight:0.50, lr:0.0008
[23:44:55.812] iteration:2943  t-loss:0.0747, loss-lb:0.0600, loss-ulb:0.0292, weight:0.50, lr:0.0008
[23:44:56.191] iteration:2944  t-loss:0.0553, loss-lb:0.0400, loss-ulb:0.0304, weight:0.50, lr:0.0008
[23:44:56.583] iteration:2945  t-loss:0.0301, loss-lb:0.0287, loss-ulb:0.0027, weight:0.50, lr:0.0008
[23:44:56.977] iteration:2946  t-loss:0.0514, loss-lb:0.0477, loss-ulb:0.0073, weight:0.50, lr:0.0008
[23:44:57.359] iteration:2947  t-loss:0.0655, loss-lb:0.0608, loss-ulb:0.0092, weight:0.50, lr:0.0008
[23:44:57.750] iteration:2948  t-loss:0.0508, loss-lb:0.0440, loss-ulb:0.0134, weight:0.50, lr:0.0008
[23:44:58.128] iteration:2949  t-loss:0.0510, loss-lb:0.0483, loss-ulb:0.0054, weight:0.50, lr:0.0008
[23:44:58.507] iteration:2950  t-loss:0.0560, loss-lb:0.0535, loss-ulb:0.0049, weight:0.50, lr:0.0008
[23:44:58.890] iteration:2951  t-loss:0.0549, loss-lb:0.0438, loss-ulb:0.0221, weight:0.50, lr:0.0008
[23:44:59.272] iteration:2952  t-loss:0.0301, loss-lb:0.0282, loss-ulb:0.0038, weight:0.50, lr:0.0008
[23:44:59.656] iteration:2953  t-loss:0.0546, loss-lb:0.0519, loss-ulb:0.0052, weight:0.50, lr:0.0008
[23:45:00.035] iteration:2954  t-loss:0.0486, loss-lb:0.0444, loss-ulb:0.0083, weight:0.50, lr:0.0008
[23:45:00.414] iteration:2955  t-loss:0.0235, loss-lb:0.0222, loss-ulb:0.0026, weight:0.50, lr:0.0008
[23:45:00.791] iteration:2956  t-loss:0.0566, loss-lb:0.0548, loss-ulb:0.0036, weight:0.50, lr:0.0008
[23:45:01.173] iteration:2957  t-loss:0.0656, loss-lb:0.0559, loss-ulb:0.0193, weight:0.50, lr:0.0008
[23:45:01.545] iteration:2958  t-loss:0.0416, loss-lb:0.0321, loss-ulb:0.0187, weight:0.50, lr:0.0008
[23:45:01.919] iteration:2959  t-loss:0.0470, loss-lb:0.0422, loss-ulb:0.0097, weight:0.50, lr:0.0008
[23:45:02.294] iteration:2960  t-loss:0.0700, loss-lb:0.0606, loss-ulb:0.0185, weight:0.50, lr:0.0008
[23:45:02.670] iteration:2961  t-loss:0.0256, loss-lb:0.0239, loss-ulb:0.0034, weight:0.50, lr:0.0008
[23:45:03.044] iteration:2962  t-loss:0.0359, loss-lb:0.0332, loss-ulb:0.0054, weight:0.50, lr:0.0008
[23:45:03.416] iteration:2963  t-loss:0.0628, loss-lb:0.0545, loss-ulb:0.0165, weight:0.50, lr:0.0008
[23:45:03.791] iteration:2964  t-loss:0.1025, loss-lb:0.0909, loss-ulb:0.0230, weight:0.50, lr:0.0008
[23:45:05.030] iteration:2965  t-loss:0.0249, loss-lb:0.0227, loss-ulb:0.0043, weight:0.50, lr:0.0008
[23:45:05.430] iteration:2966  t-loss:0.0623, loss-lb:0.0518, loss-ulb:0.0210, weight:0.50, lr:0.0008
[23:45:05.812] iteration:2967  t-loss:0.0418, loss-lb:0.0353, loss-ulb:0.0129, weight:0.50, lr:0.0008
[23:45:06.187] iteration:2968  t-loss:0.0278, loss-lb:0.0222, loss-ulb:0.0110, weight:0.50, lr:0.0008
[23:45:06.567] iteration:2969  t-loss:0.0252, loss-lb:0.0239, loss-ulb:0.0025, weight:0.50, lr:0.0008
[23:45:06.948] iteration:2970  t-loss:0.0429, loss-lb:0.0362, loss-ulb:0.0133, weight:0.50, lr:0.0008
[23:45:07.325] iteration:2971  t-loss:0.0259, loss-lb:0.0210, loss-ulb:0.0097, weight:0.50, lr:0.0008
[23:45:07.704] iteration:2972  t-loss:0.0582, loss-lb:0.0528, loss-ulb:0.0107, weight:0.50, lr:0.0008
[23:45:08.077] iteration:2973  t-loss:0.0204, loss-lb:0.0196, loss-ulb:0.0015, weight:0.50, lr:0.0008
[23:45:08.461] iteration:2974  t-loss:0.0527, loss-lb:0.0497, loss-ulb:0.0060, weight:0.50, lr:0.0008
[23:45:08.839] iteration:2975  t-loss:0.0306, loss-lb:0.0298, loss-ulb:0.0015, weight:0.50, lr:0.0008
[23:45:09.218] iteration:2976  t-loss:0.0499, loss-lb:0.0435, loss-ulb:0.0126, weight:0.50, lr:0.0008
[23:45:09.595] iteration:2977  t-loss:0.0352, loss-lb:0.0308, loss-ulb:0.0087, weight:0.50, lr:0.0008
[23:45:09.968] iteration:2978  t-loss:0.0527, loss-lb:0.0511, loss-ulb:0.0033, weight:0.50, lr:0.0008
[23:45:10.348] iteration:2979  t-loss:0.0378, loss-lb:0.0232, loss-ulb:0.0290, weight:0.50, lr:0.0008
[23:45:10.721] iteration:2980  t-loss:0.0439, loss-lb:0.0426, loss-ulb:0.0025, weight:0.50, lr:0.0008
[23:45:11.100] iteration:2981  t-loss:0.0382, loss-lb:0.0317, loss-ulb:0.0129, weight:0.50, lr:0.0008
[23:45:11.482] iteration:2982  t-loss:0.0467, loss-lb:0.0458, loss-ulb:0.0017, weight:0.50, lr:0.0008
[23:45:11.884] iteration:2983  t-loss:0.0335, loss-lb:0.0240, loss-ulb:0.0190, weight:0.50, lr:0.0008
[23:45:12.287] iteration:2984  t-loss:0.0213, loss-lb:0.0206, loss-ulb:0.0015, weight:0.50, lr:0.0008
[23:45:12.690] iteration:2985  t-loss:0.0314, loss-lb:0.0219, loss-ulb:0.0190, weight:0.50, lr:0.0008
[23:45:13.089] iteration:2986  t-loss:0.0421, loss-lb:0.0359, loss-ulb:0.0122, weight:0.50, lr:0.0008
[23:45:13.472] iteration:2987  t-loss:0.0553, loss-lb:0.0499, loss-ulb:0.0108, weight:0.50, lr:0.0008
[23:45:13.851] iteration:2988  t-loss:0.0286, loss-lb:0.0268, loss-ulb:0.0037, weight:0.50, lr:0.0008
[23:45:14.229] iteration:2989  t-loss:0.0232, loss-lb:0.0219, loss-ulb:0.0027, weight:0.50, lr:0.0008
[23:45:14.608] iteration:2990  t-loss:0.0311, loss-lb:0.0260, loss-ulb:0.0101, weight:0.50, lr:0.0008
[23:45:14.992] iteration:2991  t-loss:0.0265, loss-lb:0.0212, loss-ulb:0.0106, weight:0.50, lr:0.0008
[23:45:15.380] iteration:2992  t-loss:0.0795, loss-lb:0.0691, loss-ulb:0.0207, weight:0.50, lr:0.0008
[23:45:15.756] iteration:2993  t-loss:0.0313, loss-lb:0.0286, loss-ulb:0.0054, weight:0.50, lr:0.0008
[23:45:16.139] iteration:2994  t-loss:0.0448, loss-lb:0.0352, loss-ulb:0.0191, weight:0.50, lr:0.0008
[23:45:16.525] iteration:2995  t-loss:0.0933, loss-lb:0.0808, loss-ulb:0.0248, weight:0.50, lr:0.0008
[23:45:16.896] iteration:2996  t-loss:0.0290, loss-lb:0.0224, loss-ulb:0.0131, weight:0.50, lr:0.0008
[23:45:17.270] iteration:2997  t-loss:0.0490, loss-lb:0.0468, loss-ulb:0.0045, weight:0.50, lr:0.0008
[23:45:17.643] iteration:2998  t-loss:0.0571, loss-lb:0.0511, loss-ulb:0.0121, weight:0.50, lr:0.0008
[23:45:18.020] iteration:2999  t-loss:0.0284, loss-lb:0.0207, loss-ulb:0.0153, weight:0.50, lr:0.0008
[23:45:18.394] iteration:3000  t-loss:0.0521, loss-lb:0.0471, loss-ulb:0.0099, weight:0.50, lr:0.0008
[23:45:18.765] iteration:3001  t-loss:0.0560, loss-lb:0.0448, loss-ulb:0.0195, weight:0.57, lr:0.0008
[23:45:19.143] iteration:3002  t-loss:0.0403, loss-lb:0.0374, loss-ulb:0.0051, weight:0.57, lr:0.0008
[23:45:20.308] iteration:3003  t-loss:0.0515, loss-lb:0.0450, loss-ulb:0.0114, weight:0.57, lr:0.0008
[23:45:20.724] iteration:3004  t-loss:0.0281, loss-lb:0.0214, loss-ulb:0.0117, weight:0.57, lr:0.0008
[23:45:21.117] iteration:3005  t-loss:0.0989, loss-lb:0.0951, loss-ulb:0.0066, weight:0.57, lr:0.0008
[23:45:21.495] iteration:3006  t-loss:0.0304, loss-lb:0.0253, loss-ulb:0.0089, weight:0.57, lr:0.0008
[23:45:21.871] iteration:3007  t-loss:0.0354, loss-lb:0.0317, loss-ulb:0.0064, weight:0.57, lr:0.0008
[23:45:22.253] iteration:3008  t-loss:0.0538, loss-lb:0.0444, loss-ulb:0.0163, weight:0.57, lr:0.0008
[23:45:22.632] iteration:3009  t-loss:0.0390, loss-lb:0.0264, loss-ulb:0.0219, weight:0.57, lr:0.0008
[23:45:23.013] iteration:3010  t-loss:0.0310, loss-lb:0.0257, loss-ulb:0.0092, weight:0.57, lr:0.0008
[23:45:23.401] iteration:3011  t-loss:0.0724, loss-lb:0.0637, loss-ulb:0.0151, weight:0.57, lr:0.0008
[23:45:23.782] iteration:3012  t-loss:0.0985, loss-lb:0.0934, loss-ulb:0.0090, weight:0.57, lr:0.0008
[23:45:24.155] iteration:3013  t-loss:0.0376, loss-lb:0.0208, loss-ulb:0.0293, weight:0.57, lr:0.0008
[23:45:24.533] iteration:3014  t-loss:0.0442, loss-lb:0.0323, loss-ulb:0.0208, weight:0.57, lr:0.0008
[23:45:24.923] iteration:3015  t-loss:0.0492, loss-lb:0.0380, loss-ulb:0.0197, weight:0.57, lr:0.0008
[23:45:25.299] iteration:3016  t-loss:0.0360, loss-lb:0.0305, loss-ulb:0.0096, weight:0.57, lr:0.0008
[23:45:25.681] iteration:3017  t-loss:0.1248, loss-lb:0.1199, loss-ulb:0.0086, weight:0.57, lr:0.0008
[23:45:26.064] iteration:3018  t-loss:0.0816, loss-lb:0.0693, loss-ulb:0.0214, weight:0.57, lr:0.0008
[23:45:26.441] iteration:3019  t-loss:0.0752, loss-lb:0.0577, loss-ulb:0.0305, weight:0.57, lr:0.0008
[23:45:26.819] iteration:3020  t-loss:0.0732, loss-lb:0.0673, loss-ulb:0.0103, weight:0.57, lr:0.0008
[23:45:27.205] iteration:3021  t-loss:0.0335, loss-lb:0.0283, loss-ulb:0.0092, weight:0.57, lr:0.0008
[23:45:27.611] iteration:3022  t-loss:0.0414, loss-lb:0.0334, loss-ulb:0.0139, weight:0.57, lr:0.0008
[23:45:28.009] iteration:3023  t-loss:0.0305, loss-lb:0.0284, loss-ulb:0.0037, weight:0.57, lr:0.0008
[23:45:28.398] iteration:3024  t-loss:0.0736, loss-lb:0.0667, loss-ulb:0.0121, weight:0.57, lr:0.0008
[23:45:28.779] iteration:3025  t-loss:0.0466, loss-lb:0.0369, loss-ulb:0.0170, weight:0.57, lr:0.0008
[23:45:29.160] iteration:3026  t-loss:0.0393, loss-lb:0.0301, loss-ulb:0.0161, weight:0.57, lr:0.0008
[23:45:29.544] iteration:3027  t-loss:0.0652, loss-lb:0.0451, loss-ulb:0.0350, weight:0.57, lr:0.0008
[23:45:29.928] iteration:3028  t-loss:0.0512, loss-lb:0.0401, loss-ulb:0.0194, weight:0.57, lr:0.0008
[23:45:30.307] iteration:3029  t-loss:0.0368, loss-lb:0.0331, loss-ulb:0.0064, weight:0.57, lr:0.0008
[23:45:30.696] iteration:3030  t-loss:0.0994, loss-lb:0.0979, loss-ulb:0.0026, weight:0.57, lr:0.0008
[23:45:31.080] iteration:3031  t-loss:0.0323, loss-lb:0.0287, loss-ulb:0.0062, weight:0.57, lr:0.0008
[23:45:31.461] iteration:3032  t-loss:0.0407, loss-lb:0.0344, loss-ulb:0.0109, weight:0.57, lr:0.0008
[23:45:31.839] iteration:3033  t-loss:0.1217, loss-lb:0.0951, loss-ulb:0.0463, weight:0.57, lr:0.0008
[23:45:32.214] iteration:3034  t-loss:0.0314, loss-lb:0.0285, loss-ulb:0.0050, weight:0.57, lr:0.0008
[23:45:32.588] iteration:3035  t-loss:0.0365, loss-lb:0.0317, loss-ulb:0.0083, weight:0.57, lr:0.0008
[23:45:32.966] iteration:3036  t-loss:0.0776, loss-lb:0.0608, loss-ulb:0.0292, weight:0.57, lr:0.0008
[23:45:33.336] iteration:3037  t-loss:0.0634, loss-lb:0.0402, loss-ulb:0.0405, weight:0.57, lr:0.0008
[23:45:33.725] iteration:3038  t-loss:0.0544, loss-lb:0.0423, loss-ulb:0.0212, weight:0.57, lr:0.0008
[23:45:34.112] iteration:3039  t-loss:0.0525, loss-lb:0.0373, loss-ulb:0.0265, weight:0.57, lr:0.0008
[23:45:34.491] iteration:3040  t-loss:0.0552, loss-lb:0.0369, loss-ulb:0.0318, weight:0.57, lr:0.0008
[23:45:35.837] iteration:3041  t-loss:0.0505, loss-lb:0.0365, loss-ulb:0.0244, weight:0.57, lr:0.0008
[23:45:36.245] iteration:3042  t-loss:0.0711, loss-lb:0.0625, loss-ulb:0.0149, weight:0.57, lr:0.0008
[23:45:36.634] iteration:3043  t-loss:0.0251, loss-lb:0.0236, loss-ulb:0.0026, weight:0.57, lr:0.0008
[23:45:37.012] iteration:3044  t-loss:0.0521, loss-lb:0.0297, loss-ulb:0.0390, weight:0.57, lr:0.0008
[23:45:37.391] iteration:3045  t-loss:0.0467, loss-lb:0.0412, loss-ulb:0.0095, weight:0.57, lr:0.0008
[23:45:37.773] iteration:3046  t-loss:0.0371, loss-lb:0.0321, loss-ulb:0.0087, weight:0.57, lr:0.0008
[23:45:38.157] iteration:3047  t-loss:0.0699, loss-lb:0.0660, loss-ulb:0.0068, weight:0.57, lr:0.0008
[23:45:38.536] iteration:3048  t-loss:0.0630, loss-lb:0.0465, loss-ulb:0.0289, weight:0.57, lr:0.0008
[23:45:38.911] iteration:3049  t-loss:0.0399, loss-lb:0.0260, loss-ulb:0.0241, weight:0.57, lr:0.0008
[23:45:39.292] iteration:3050  t-loss:0.0458, loss-lb:0.0360, loss-ulb:0.0172, weight:0.57, lr:0.0008
[23:45:39.670] iteration:3051  t-loss:0.0560, loss-lb:0.0535, loss-ulb:0.0045, weight:0.57, lr:0.0008
[23:45:40.049] iteration:3052  t-loss:0.0682, loss-lb:0.0560, loss-ulb:0.0213, weight:0.57, lr:0.0008
[23:45:40.428] iteration:3053  t-loss:0.0413, loss-lb:0.0266, loss-ulb:0.0255, weight:0.57, lr:0.0008
[23:45:40.813] iteration:3054  t-loss:0.0710, loss-lb:0.0643, loss-ulb:0.0117, weight:0.57, lr:0.0008
[23:45:41.192] iteration:3055  t-loss:0.1091, loss-lb:0.0913, loss-ulb:0.0311, weight:0.57, lr:0.0008
[23:45:41.564] iteration:3056  t-loss:0.0326, loss-lb:0.0272, loss-ulb:0.0093, weight:0.57, lr:0.0008
[23:45:41.945] iteration:3057  t-loss:0.0326, loss-lb:0.0257, loss-ulb:0.0119, weight:0.57, lr:0.0008
[23:45:42.322] iteration:3058  t-loss:0.0384, loss-lb:0.0250, loss-ulb:0.0235, weight:0.57, lr:0.0008
[23:45:42.713] iteration:3059  t-loss:0.0506, loss-lb:0.0485, loss-ulb:0.0036, weight:0.57, lr:0.0008
[23:45:43.119] iteration:3060  t-loss:0.0394, loss-lb:0.0303, loss-ulb:0.0158, weight:0.57, lr:0.0008
[23:45:43.532] iteration:3061  t-loss:0.0641, loss-lb:0.0488, loss-ulb:0.0267, weight:0.57, lr:0.0008
[23:45:43.922] iteration:3062  t-loss:0.0306, loss-lb:0.0263, loss-ulb:0.0075, weight:0.57, lr:0.0008
[23:45:44.305] iteration:3063  t-loss:0.0471, loss-lb:0.0300, loss-ulb:0.0298, weight:0.57, lr:0.0008
[23:45:44.686] iteration:3064  t-loss:0.0658, loss-lb:0.0524, loss-ulb:0.0233, weight:0.57, lr:0.0008
[23:45:45.072] iteration:3065  t-loss:0.0558, loss-lb:0.0506, loss-ulb:0.0090, weight:0.57, lr:0.0008
[23:45:45.448] iteration:3066  t-loss:0.0417, loss-lb:0.0274, loss-ulb:0.0251, weight:0.57, lr:0.0008
[23:45:45.825] iteration:3067  t-loss:0.0424, loss-lb:0.0225, loss-ulb:0.0346, weight:0.57, lr:0.0008
[23:45:46.202] iteration:3068  t-loss:0.0851, loss-lb:0.0828, loss-ulb:0.0040, weight:0.57, lr:0.0008
[23:45:46.577] iteration:3069  t-loss:0.0274, loss-lb:0.0258, loss-ulb:0.0029, weight:0.57, lr:0.0008
[23:45:46.953] iteration:3070  t-loss:0.0341, loss-lb:0.0256, loss-ulb:0.0147, weight:0.57, lr:0.0008
[23:45:47.328] iteration:3071  t-loss:0.0555, loss-lb:0.0408, loss-ulb:0.0257, weight:0.57, lr:0.0008
[23:45:47.704] iteration:3072  t-loss:0.0543, loss-lb:0.0503, loss-ulb:0.0069, weight:0.57, lr:0.0008
[23:45:48.076] iteration:3073  t-loss:0.0349, loss-lb:0.0259, loss-ulb:0.0157, weight:0.57, lr:0.0008
[23:45:48.452] iteration:3074  t-loss:0.0317, loss-lb:0.0263, loss-ulb:0.0094, weight:0.57, lr:0.0008
[23:45:48.838] iteration:3075  t-loss:0.0588, loss-lb:0.0374, loss-ulb:0.0373, weight:0.57, lr:0.0008
[23:45:49.228] iteration:3076  t-loss:0.0762, loss-lb:0.0589, loss-ulb:0.0302, weight:0.57, lr:0.0008
[23:45:49.617] iteration:3077  t-loss:0.0651, loss-lb:0.0558, loss-ulb:0.0162, weight:0.57, lr:0.0008
[23:45:49.993] iteration:3078  t-loss:0.0414, loss-lb:0.0323, loss-ulb:0.0158, weight:0.57, lr:0.0008
[23:46:53.385] iteration 3078 : dice_score: 0.745849 best_dice: 0.783000
[23:46:53.385]  <<Test>> - Ep:80  - Dice-S/T:74.23/74.58, Best-S:77.47, Best-T:78.30
[23:46:53.385]           - AvgLoss(lb/ulb/all):0.04/0.02/0.05
[23:46:54.442] iteration:3079  t-loss:0.0463, loss-lb:0.0337, loss-ulb:0.0220, weight:0.57, lr:0.0008
[23:46:54.853] iteration:3080  t-loss:0.0532, loss-lb:0.0404, loss-ulb:0.0224, weight:0.57, lr:0.0008
[23:46:55.248] iteration:3081  t-loss:0.0839, loss-lb:0.0802, loss-ulb:0.0063, weight:0.57, lr:0.0008
[23:46:55.628] iteration:3082  t-loss:0.0749, loss-lb:0.0634, loss-ulb:0.0200, weight:0.57, lr:0.0008
[23:46:56.011] iteration:3083  t-loss:0.0745, loss-lb:0.0643, loss-ulb:0.0177, weight:0.57, lr:0.0008
[23:46:56.398] iteration:3084  t-loss:0.0674, loss-lb:0.0492, loss-ulb:0.0318, weight:0.57, lr:0.0008
[23:46:56.779] iteration:3085  t-loss:0.0499, loss-lb:0.0326, loss-ulb:0.0302, weight:0.57, lr:0.0008
[23:46:57.157] iteration:3086  t-loss:0.0360, loss-lb:0.0197, loss-ulb:0.0285, weight:0.57, lr:0.0008
[23:46:57.535] iteration:3087  t-loss:0.0397, loss-lb:0.0354, loss-ulb:0.0074, weight:0.57, lr:0.0008
[23:46:57.914] iteration:3088  t-loss:0.0331, loss-lb:0.0245, loss-ulb:0.0150, weight:0.57, lr:0.0008
[23:46:58.299] iteration:3089  t-loss:0.1431, loss-lb:0.1414, loss-ulb:0.0030, weight:0.57, lr:0.0008
[23:46:58.674] iteration:3090  t-loss:0.0333, loss-lb:0.0200, loss-ulb:0.0232, weight:0.57, lr:0.0008
[23:46:59.053] iteration:3091  t-loss:0.0364, loss-lb:0.0292, loss-ulb:0.0127, weight:0.57, lr:0.0008
[23:46:59.430] iteration:3092  t-loss:0.0523, loss-lb:0.0334, loss-ulb:0.0330, weight:0.57, lr:0.0008
[23:46:59.810] iteration:3093  t-loss:0.0342, loss-lb:0.0237, loss-ulb:0.0182, weight:0.57, lr:0.0008
[23:47:00.190] iteration:3094  t-loss:0.0748, loss-lb:0.0672, loss-ulb:0.0133, weight:0.57, lr:0.0008
[23:47:00.570] iteration:3095  t-loss:0.0388, loss-lb:0.0354, loss-ulb:0.0059, weight:0.57, lr:0.0008
[23:47:00.951] iteration:3096  t-loss:0.0763, loss-lb:0.0581, loss-ulb:0.0319, weight:0.57, lr:0.0008
[23:47:01.341] iteration:3097  t-loss:0.0669, loss-lb:0.0560, loss-ulb:0.0190, weight:0.57, lr:0.0008
[23:47:01.725] iteration:3098  t-loss:0.0867, loss-lb:0.0689, loss-ulb:0.0310, weight:0.57, lr:0.0008
[23:47:02.115] iteration:3099  t-loss:0.0650, loss-lb:0.0627, loss-ulb:0.0039, weight:0.57, lr:0.0008
[23:47:02.520] iteration:3100  t-loss:0.0323, loss-lb:0.0256, loss-ulb:0.0116, weight:0.57, lr:0.0008
[23:47:02.937] iteration:3101  t-loss:0.0896, loss-lb:0.0785, loss-ulb:0.0195, weight:0.57, lr:0.0008
[23:47:03.327] iteration:3102  t-loss:0.0493, loss-lb:0.0480, loss-ulb:0.0024, weight:0.57, lr:0.0008
[23:47:03.704] iteration:3103  t-loss:0.0298, loss-lb:0.0265, loss-ulb:0.0057, weight:0.57, lr:0.0008
[23:47:04.082] iteration:3104  t-loss:0.0668, loss-lb:0.0630, loss-ulb:0.0067, weight:0.57, lr:0.0008
[23:47:04.463] iteration:3105  t-loss:0.0303, loss-lb:0.0287, loss-ulb:0.0028, weight:0.57, lr:0.0008
[23:47:04.838] iteration:3106  t-loss:0.0354, loss-lb:0.0334, loss-ulb:0.0035, weight:0.57, lr:0.0008
[23:47:05.218] iteration:3107  t-loss:0.0401, loss-lb:0.0367, loss-ulb:0.0058, weight:0.57, lr:0.0008
[23:47:05.604] iteration:3108  t-loss:0.0279, loss-lb:0.0247, loss-ulb:0.0056, weight:0.57, lr:0.0008
[23:47:05.991] iteration:3109  t-loss:0.0352, loss-lb:0.0313, loss-ulb:0.0067, weight:0.57, lr:0.0008
[23:47:06.370] iteration:3110  t-loss:0.0709, loss-lb:0.0678, loss-ulb:0.0054, weight:0.57, lr:0.0008
[23:47:06.748] iteration:3111  t-loss:0.0657, loss-lb:0.0536, loss-ulb:0.0211, weight:0.57, lr:0.0008
[23:47:07.129] iteration:3112  t-loss:0.0530, loss-lb:0.0400, loss-ulb:0.0226, weight:0.57, lr:0.0008
[23:47:07.506] iteration:3113  t-loss:0.0693, loss-lb:0.0574, loss-ulb:0.0206, weight:0.57, lr:0.0008
[23:47:07.882] iteration:3114  t-loss:0.0665, loss-lb:0.0649, loss-ulb:0.0027, weight:0.57, lr:0.0008
[23:47:08.259] iteration:3115  t-loss:0.0941, loss-lb:0.0693, loss-ulb:0.0433, weight:0.57, lr:0.0008
[23:47:08.634] iteration:3116  t-loss:0.0590, loss-lb:0.0569, loss-ulb:0.0036, weight:0.57, lr:0.0008
[23:47:09.982] iteration:3117  t-loss:0.0600, loss-lb:0.0497, loss-ulb:0.0181, weight:0.57, lr:0.0008
[23:47:10.371] iteration:3118  t-loss:0.0607, loss-lb:0.0587, loss-ulb:0.0035, weight:0.57, lr:0.0008
[23:47:10.754] iteration:3119  t-loss:0.0439, loss-lb:0.0377, loss-ulb:0.0107, weight:0.57, lr:0.0008
[23:47:11.134] iteration:3120  t-loss:0.0674, loss-lb:0.0583, loss-ulb:0.0159, weight:0.57, lr:0.0008
[23:47:11.515] iteration:3121  t-loss:0.1357, loss-lb:0.0979, loss-ulb:0.0660, weight:0.57, lr:0.0008
[23:47:11.894] iteration:3122  t-loss:0.0379, loss-lb:0.0301, loss-ulb:0.0136, weight:0.57, lr:0.0008
[23:47:12.273] iteration:3123  t-loss:0.0342, loss-lb:0.0292, loss-ulb:0.0086, weight:0.57, lr:0.0008
[23:47:12.658] iteration:3124  t-loss:0.0675, loss-lb:0.0399, loss-ulb:0.0482, weight:0.57, lr:0.0008
[23:47:13.040] iteration:3125  t-loss:0.0652, loss-lb:0.0517, loss-ulb:0.0236, weight:0.57, lr:0.0008
[23:47:13.420] iteration:3126  t-loss:0.1005, loss-lb:0.0970, loss-ulb:0.0061, weight:0.57, lr:0.0008
[23:47:13.798] iteration:3127  t-loss:0.0398, loss-lb:0.0341, loss-ulb:0.0100, weight:0.57, lr:0.0008
[23:47:14.174] iteration:3128  t-loss:0.0544, loss-lb:0.0434, loss-ulb:0.0191, weight:0.57, lr:0.0008
[23:47:14.549] iteration:3129  t-loss:0.0487, loss-lb:0.0357, loss-ulb:0.0227, weight:0.57, lr:0.0008
[23:47:14.928] iteration:3130  t-loss:0.0491, loss-lb:0.0386, loss-ulb:0.0184, weight:0.57, lr:0.0008
[23:47:15.302] iteration:3131  t-loss:0.0504, loss-lb:0.0447, loss-ulb:0.0099, weight:0.57, lr:0.0008
[23:47:15.678] iteration:3132  t-loss:0.0593, loss-lb:0.0410, loss-ulb:0.0319, weight:0.57, lr:0.0008
[23:47:16.054] iteration:3133  t-loss:0.0673, loss-lb:0.0459, loss-ulb:0.0374, weight:0.57, lr:0.0008
[23:47:16.434] iteration:3134  t-loss:0.0655, loss-lb:0.0429, loss-ulb:0.0395, weight:0.57, lr:0.0008
[23:47:16.809] iteration:3135  t-loss:0.0382, loss-lb:0.0294, loss-ulb:0.0153, weight:0.57, lr:0.0008
[23:47:17.192] iteration:3136  t-loss:0.0342, loss-lb:0.0256, loss-ulb:0.0151, weight:0.57, lr:0.0008
[23:47:17.590] iteration:3137  t-loss:0.0568, loss-lb:0.0553, loss-ulb:0.0026, weight:0.57, lr:0.0008
[23:47:17.977] iteration:3138  t-loss:0.0464, loss-lb:0.0307, loss-ulb:0.0275, weight:0.57, lr:0.0008
[23:47:18.364] iteration:3139  t-loss:0.0522, loss-lb:0.0495, loss-ulb:0.0048, weight:0.57, lr:0.0008
[23:47:18.746] iteration:3140  t-loss:0.0604, loss-lb:0.0465, loss-ulb:0.0243, weight:0.57, lr:0.0008
[23:47:19.125] iteration:3141  t-loss:0.0273, loss-lb:0.0219, loss-ulb:0.0095, weight:0.57, lr:0.0008
[23:47:19.507] iteration:3142  t-loss:0.0853, loss-lb:0.0681, loss-ulb:0.0300, weight:0.57, lr:0.0008
[23:47:19.896] iteration:3143  t-loss:0.0724, loss-lb:0.0602, loss-ulb:0.0213, weight:0.57, lr:0.0008
[23:47:20.276] iteration:3144  t-loss:0.0392, loss-lb:0.0367, loss-ulb:0.0043, weight:0.57, lr:0.0008
[23:47:20.657] iteration:3145  t-loss:0.0237, loss-lb:0.0228, loss-ulb:0.0014, weight:0.57, lr:0.0008
[23:47:21.038] iteration:3146  t-loss:0.1108, loss-lb:0.1057, loss-ulb:0.0089, weight:0.57, lr:0.0008
[23:47:21.420] iteration:3147  t-loss:0.0457, loss-lb:0.0306, loss-ulb:0.0264, weight:0.57, lr:0.0008
[23:47:21.798] iteration:3148  t-loss:0.0328, loss-lb:0.0243, loss-ulb:0.0149, weight:0.57, lr:0.0008
[23:47:22.169] iteration:3149  t-loss:0.0397, loss-lb:0.0366, loss-ulb:0.0054, weight:0.57, lr:0.0008
[23:47:22.542] iteration:3150  t-loss:0.0268, loss-lb:0.0247, loss-ulb:0.0036, weight:0.57, lr:0.0008
[23:47:22.919] iteration:3151  t-loss:0.0301, loss-lb:0.0234, loss-ulb:0.0105, weight:0.65, lr:0.0008
[23:47:23.301] iteration:3152  t-loss:0.0454, loss-lb:0.0343, loss-ulb:0.0171, weight:0.65, lr:0.0008
[23:47:23.678] iteration:3153  t-loss:0.0393, loss-lb:0.0261, loss-ulb:0.0203, weight:0.65, lr:0.0008
[23:47:24.052] iteration:3154  t-loss:0.0324, loss-lb:0.0291, loss-ulb:0.0051, weight:0.65, lr:0.0008
[23:47:25.215] iteration:3155  t-loss:0.0368, loss-lb:0.0291, loss-ulb:0.0118, weight:0.65, lr:0.0008
[23:47:25.603] iteration:3156  t-loss:0.0304, loss-lb:0.0254, loss-ulb:0.0078, weight:0.65, lr:0.0008
[23:47:25.987] iteration:3157  t-loss:0.0648, loss-lb:0.0636, loss-ulb:0.0019, weight:0.65, lr:0.0008
[23:47:26.365] iteration:3158  t-loss:0.0290, loss-lb:0.0263, loss-ulb:0.0042, weight:0.65, lr:0.0008
[23:47:26.750] iteration:3159  t-loss:0.0719, loss-lb:0.0652, loss-ulb:0.0104, weight:0.65, lr:0.0008
[23:47:27.131] iteration:3160  t-loss:0.0626, loss-lb:0.0596, loss-ulb:0.0047, weight:0.65, lr:0.0008
[23:47:27.513] iteration:3161  t-loss:0.0661, loss-lb:0.0617, loss-ulb:0.0069, weight:0.65, lr:0.0008
[23:47:27.889] iteration:3162  t-loss:0.0360, loss-lb:0.0293, loss-ulb:0.0104, weight:0.65, lr:0.0008
[23:47:28.269] iteration:3163  t-loss:0.0441, loss-lb:0.0268, loss-ulb:0.0268, weight:0.65, lr:0.0008
[23:47:28.647] iteration:3164  t-loss:0.0243, loss-lb:0.0220, loss-ulb:0.0036, weight:0.65, lr:0.0008
[23:47:29.028] iteration:3165  t-loss:0.0631, loss-lb:0.0512, loss-ulb:0.0184, weight:0.65, lr:0.0008
[23:47:29.407] iteration:3166  t-loss:0.0288, loss-lb:0.0243, loss-ulb:0.0070, weight:0.65, lr:0.0008
[23:47:29.790] iteration:3167  t-loss:0.0528, loss-lb:0.0390, loss-ulb:0.0213, weight:0.65, lr:0.0008
[23:47:30.167] iteration:3168  t-loss:0.0351, loss-lb:0.0206, loss-ulb:0.0224, weight:0.65, lr:0.0008
[23:47:30.545] iteration:3169  t-loss:0.0955, loss-lb:0.0847, loss-ulb:0.0168, weight:0.65, lr:0.0008
[23:47:30.923] iteration:3170  t-loss:0.0691, loss-lb:0.0569, loss-ulb:0.0189, weight:0.65, lr:0.0008
[23:47:31.312] iteration:3171  t-loss:0.0644, loss-lb:0.0569, loss-ulb:0.0116, weight:0.65, lr:0.0008
[23:47:31.694] iteration:3172  t-loss:0.0380, loss-lb:0.0206, loss-ulb:0.0268, weight:0.65, lr:0.0008
[23:47:32.070] iteration:3173  t-loss:0.0525, loss-lb:0.0426, loss-ulb:0.0153, weight:0.65, lr:0.0008
[23:47:32.450] iteration:3174  t-loss:0.0321, loss-lb:0.0222, loss-ulb:0.0153, weight:0.65, lr:0.0008
[23:47:32.839] iteration:3175  t-loss:0.0354, loss-lb:0.0267, loss-ulb:0.0135, weight:0.65, lr:0.0008
[23:47:33.246] iteration:3176  t-loss:0.0325, loss-lb:0.0277, loss-ulb:0.0074, weight:0.65, lr:0.0008
[23:47:33.637] iteration:3177  t-loss:0.0330, loss-lb:0.0281, loss-ulb:0.0077, weight:0.65, lr:0.0008
[23:47:34.019] iteration:3178  t-loss:0.0536, loss-lb:0.0449, loss-ulb:0.0135, weight:0.65, lr:0.0008
[23:47:34.394] iteration:3179  t-loss:0.0485, loss-lb:0.0476, loss-ulb:0.0013, weight:0.65, lr:0.0008
[23:47:34.780] iteration:3180  t-loss:0.0457, loss-lb:0.0334, loss-ulb:0.0190, weight:0.65, lr:0.0008
[23:47:35.160] iteration:3181  t-loss:0.0586, loss-lb:0.0524, loss-ulb:0.0095, weight:0.65, lr:0.0008
[23:47:35.538] iteration:3182  t-loss:0.0212, loss-lb:0.0188, loss-ulb:0.0038, weight:0.65, lr:0.0008
[23:47:35.915] iteration:3183  t-loss:0.0339, loss-lb:0.0241, loss-ulb:0.0150, weight:0.65, lr:0.0008
[23:47:36.292] iteration:3184  t-loss:0.0532, loss-lb:0.0519, loss-ulb:0.0021, weight:0.65, lr:0.0008
[23:47:36.668] iteration:3185  t-loss:0.0341, loss-lb:0.0221, loss-ulb:0.0186, weight:0.65, lr:0.0008
[23:47:37.042] iteration:3186  t-loss:0.0294, loss-lb:0.0275, loss-ulb:0.0030, weight:0.65, lr:0.0008
[23:47:37.416] iteration:3187  t-loss:0.0299, loss-lb:0.0261, loss-ulb:0.0058, weight:0.65, lr:0.0008
[23:47:37.790] iteration:3188  t-loss:0.0246, loss-lb:0.0221, loss-ulb:0.0038, weight:0.65, lr:0.0008
[23:47:38.166] iteration:3189  t-loss:0.0334, loss-lb:0.0211, loss-ulb:0.0190, weight:0.65, lr:0.0008
[23:47:38.539] iteration:3190  t-loss:0.0380, loss-lb:0.0255, loss-ulb:0.0193, weight:0.65, lr:0.0008
[23:47:38.923] iteration:3191  t-loss:0.0427, loss-lb:0.0290, loss-ulb:0.0211, weight:0.65, lr:0.0008
[23:47:39.318] iteration:3192  t-loss:0.1018, loss-lb:0.0859, loss-ulb:0.0245, weight:0.65, lr:0.0008
[23:47:40.755] iteration:3193  t-loss:0.0538, loss-lb:0.0472, loss-ulb:0.0103, weight:0.65, lr:0.0008
[23:47:41.155] iteration:3194  t-loss:0.0589, loss-lb:0.0454, loss-ulb:0.0207, weight:0.65, lr:0.0008
[23:47:41.539] iteration:3195  t-loss:0.0515, loss-lb:0.0411, loss-ulb:0.0160, weight:0.65, lr:0.0008
[23:47:41.915] iteration:3196  t-loss:0.0448, loss-lb:0.0261, loss-ulb:0.0289, weight:0.65, lr:0.0008
[23:47:42.289] iteration:3197  t-loss:0.0309, loss-lb:0.0260, loss-ulb:0.0077, weight:0.65, lr:0.0008
[23:47:42.671] iteration:3198  t-loss:0.0577, loss-lb:0.0367, loss-ulb:0.0325, weight:0.65, lr:0.0008
[23:47:43.044] iteration:3199  t-loss:0.0399, loss-lb:0.0284, loss-ulb:0.0178, weight:0.65, lr:0.0008
[23:47:43.422] iteration:3200  t-loss:0.0546, loss-lb:0.0392, loss-ulb:0.0238, weight:0.65, lr:0.0008
[23:47:43.803] iteration:3201  t-loss:0.0656, loss-lb:0.0558, loss-ulb:0.0152, weight:0.65, lr:0.0008
[23:47:44.182] iteration:3202  t-loss:0.0616, loss-lb:0.0595, loss-ulb:0.0033, weight:0.65, lr:0.0008
[23:47:44.560] iteration:3203  t-loss:0.0662, loss-lb:0.0621, loss-ulb:0.0064, weight:0.65, lr:0.0008
[23:47:44.934] iteration:3204  t-loss:0.0558, loss-lb:0.0542, loss-ulb:0.0023, weight:0.65, lr:0.0008
[23:47:45.311] iteration:3205  t-loss:0.0333, loss-lb:0.0202, loss-ulb:0.0202, weight:0.65, lr:0.0008
[23:47:45.686] iteration:3206  t-loss:0.0464, loss-lb:0.0388, loss-ulb:0.0117, weight:0.65, lr:0.0008
[23:47:46.060] iteration:3207  t-loss:0.0433, loss-lb:0.0323, loss-ulb:0.0170, weight:0.65, lr:0.0008
[23:47:46.438] iteration:3208  t-loss:0.0653, loss-lb:0.0549, loss-ulb:0.0161, weight:0.65, lr:0.0008
[23:47:46.815] iteration:3209  t-loss:0.0485, loss-lb:0.0247, loss-ulb:0.0368, weight:0.65, lr:0.0008
[23:47:47.188] iteration:3210  t-loss:0.0274, loss-lb:0.0218, loss-ulb:0.0086, weight:0.65, lr:0.0008
[23:47:47.563] iteration:3211  t-loss:0.1052, loss-lb:0.0862, loss-ulb:0.0293, weight:0.65, lr:0.0008
[23:47:47.943] iteration:3212  t-loss:0.0494, loss-lb:0.0273, loss-ulb:0.0342, weight:0.65, lr:0.0008
[23:47:48.336] iteration:3213  t-loss:0.0466, loss-lb:0.0340, loss-ulb:0.0194, weight:0.65, lr:0.0008
[23:47:48.744] iteration:3214  t-loss:0.0591, loss-lb:0.0571, loss-ulb:0.0031, weight:0.65, lr:0.0008
[23:47:49.139] iteration:3215  t-loss:0.0548, loss-lb:0.0515, loss-ulb:0.0051, weight:0.65, lr:0.0008
[23:47:49.522] iteration:3216  t-loss:0.0622, loss-lb:0.0316, loss-ulb:0.0473, weight:0.65, lr:0.0008
[23:47:49.899] iteration:3217  t-loss:0.0376, loss-lb:0.0279, loss-ulb:0.0151, weight:0.65, lr:0.0008
[23:47:50.281] iteration:3218  t-loss:0.0506, loss-lb:0.0434, loss-ulb:0.0111, weight:0.65, lr:0.0008
[23:47:50.666] iteration:3219  t-loss:0.0421, loss-lb:0.0365, loss-ulb:0.0087, weight:0.65, lr:0.0008
[23:47:51.042] iteration:3220  t-loss:0.0388, loss-lb:0.0374, loss-ulb:0.0022, weight:0.65, lr:0.0008
[23:47:51.422] iteration:3221  t-loss:0.0295, loss-lb:0.0212, loss-ulb:0.0128, weight:0.65, lr:0.0008
[23:47:51.799] iteration:3222  t-loss:0.0283, loss-lb:0.0210, loss-ulb:0.0113, weight:0.65, lr:0.0008
[23:47:52.177] iteration:3223  t-loss:0.0608, loss-lb:0.0529, loss-ulb:0.0121, weight:0.65, lr:0.0008
[23:47:52.552] iteration:3224  t-loss:0.0288, loss-lb:0.0232, loss-ulb:0.0086, weight:0.65, lr:0.0008
[23:47:52.925] iteration:3225  t-loss:0.0511, loss-lb:0.0371, loss-ulb:0.0217, weight:0.65, lr:0.0008
[23:47:53.298] iteration:3226  t-loss:0.0727, loss-lb:0.0691, loss-ulb:0.0054, weight:0.65, lr:0.0008
[23:47:53.669] iteration:3227  t-loss:0.0335, loss-lb:0.0249, loss-ulb:0.0133, weight:0.65, lr:0.0008
[23:47:54.044] iteration:3228  t-loss:0.0390, loss-lb:0.0313, loss-ulb:0.0119, weight:0.65, lr:0.0008
[23:47:54.440] iteration:3229  t-loss:0.0496, loss-lb:0.0379, loss-ulb:0.0180, weight:0.65, lr:0.0008
[23:47:54.830] iteration:3230  t-loss:0.0328, loss-lb:0.0231, loss-ulb:0.0149, weight:0.65, lr:0.0008
[23:48:58.666] iteration 3230 : dice_score: 0.814637 best_dice: 0.814600
[23:48:58.667]  <<Test>> - Ep:84  - Dice-S/T:84.62/81.46, Best-S:84.62, Best-T:81.46
[23:48:58.667]           - AvgLoss(lb/ulb/all):0.04/0.02/0.05
[23:48:59.770] iteration:3231  t-loss:0.0589, loss-lb:0.0434, loss-ulb:0.0240, weight:0.65, lr:0.0008
[23:49:00.152] iteration:3232  t-loss:0.0309, loss-lb:0.0193, loss-ulb:0.0179, weight:0.65, lr:0.0008
[23:49:00.534] iteration:3233  t-loss:0.1206, loss-lb:0.1193, loss-ulb:0.0021, weight:0.65, lr:0.0008
[23:49:00.908] iteration:3234  t-loss:0.0279, loss-lb:0.0222, loss-ulb:0.0088, weight:0.65, lr:0.0008
[23:49:01.285] iteration:3235  t-loss:0.0391, loss-lb:0.0257, loss-ulb:0.0207, weight:0.65, lr:0.0008
[23:49:01.663] iteration:3236  t-loss:0.0621, loss-lb:0.0522, loss-ulb:0.0153, weight:0.65, lr:0.0008
[23:49:02.042] iteration:3237  t-loss:0.0639, loss-lb:0.0625, loss-ulb:0.0023, weight:0.65, lr:0.0008
[23:49:02.416] iteration:3238  t-loss:0.0354, loss-lb:0.0317, loss-ulb:0.0057, weight:0.65, lr:0.0008
[23:49:02.797] iteration:3239  t-loss:0.0590, loss-lb:0.0562, loss-ulb:0.0043, weight:0.65, lr:0.0008
[23:49:03.182] iteration:3240  t-loss:0.0373, loss-lb:0.0181, loss-ulb:0.0296, weight:0.65, lr:0.0008
[23:49:03.566] iteration:3241  t-loss:0.0600, loss-lb:0.0548, loss-ulb:0.0080, weight:0.65, lr:0.0008
[23:49:03.944] iteration:3242  t-loss:0.0368, loss-lb:0.0356, loss-ulb:0.0019, weight:0.65, lr:0.0008
[23:49:04.324] iteration:3243  t-loss:0.0875, loss-lb:0.0750, loss-ulb:0.0194, weight:0.65, lr:0.0008
[23:49:04.708] iteration:3244  t-loss:0.0303, loss-lb:0.0233, loss-ulb:0.0109, weight:0.65, lr:0.0008
[23:49:05.094] iteration:3245  t-loss:0.0564, loss-lb:0.0504, loss-ulb:0.0092, weight:0.65, lr:0.0008
[23:49:05.476] iteration:3246  t-loss:0.0377, loss-lb:0.0308, loss-ulb:0.0106, weight:0.65, lr:0.0008
[23:49:05.858] iteration:3247  t-loss:0.0612, loss-lb:0.0509, loss-ulb:0.0159, weight:0.65, lr:0.0008
[23:49:06.244] iteration:3248  t-loss:0.0578, loss-lb:0.0551, loss-ulb:0.0043, weight:0.65, lr:0.0008
[23:49:06.628] iteration:3249  t-loss:0.0363, loss-lb:0.0269, loss-ulb:0.0145, weight:0.65, lr:0.0008
[23:49:07.003] iteration:3250  t-loss:0.0205, loss-lb:0.0183, loss-ulb:0.0033, weight:0.65, lr:0.0008
[23:49:07.400] iteration:3251  t-loss:0.0578, loss-lb:0.0368, loss-ulb:0.0325, weight:0.65, lr:0.0008
[23:49:07.802] iteration:3252  t-loss:0.0360, loss-lb:0.0276, loss-ulb:0.0129, weight:0.65, lr:0.0008
[23:49:08.196] iteration:3253  t-loss:0.0253, loss-lb:0.0181, loss-ulb:0.0112, weight:0.65, lr:0.0008
[23:49:08.582] iteration:3254  t-loss:0.0834, loss-lb:0.0594, loss-ulb:0.0371, weight:0.65, lr:0.0008
[23:49:08.957] iteration:3255  t-loss:0.0561, loss-lb:0.0546, loss-ulb:0.0023, weight:0.65, lr:0.0008
[23:49:09.340] iteration:3256  t-loss:0.0309, loss-lb:0.0258, loss-ulb:0.0079, weight:0.65, lr:0.0008
[23:49:09.721] iteration:3257  t-loss:0.0648, loss-lb:0.0616, loss-ulb:0.0050, weight:0.65, lr:0.0008
[23:49:10.098] iteration:3258  t-loss:0.0331, loss-lb:0.0269, loss-ulb:0.0095, weight:0.65, lr:0.0008
[23:49:10.473] iteration:3259  t-loss:0.0510, loss-lb:0.0420, loss-ulb:0.0139, weight:0.65, lr:0.0008
[23:49:10.854] iteration:3260  t-loss:0.0539, loss-lb:0.0520, loss-ulb:0.0030, weight:0.65, lr:0.0008
[23:49:11.235] iteration:3261  t-loss:0.0380, loss-lb:0.0342, loss-ulb:0.0058, weight:0.65, lr:0.0008
[23:49:11.609] iteration:3262  t-loss:0.0405, loss-lb:0.0378, loss-ulb:0.0042, weight:0.65, lr:0.0008
[23:49:11.986] iteration:3263  t-loss:0.0540, loss-lb:0.0297, loss-ulb:0.0376, weight:0.65, lr:0.0008
[23:49:12.362] iteration:3264  t-loss:0.0392, loss-lb:0.0362, loss-ulb:0.0047, weight:0.65, lr:0.0008
[23:49:12.740] iteration:3265  t-loss:0.0625, loss-lb:0.0591, loss-ulb:0.0052, weight:0.65, lr:0.0008
[23:49:13.117] iteration:3266  t-loss:0.0310, loss-lb:0.0242, loss-ulb:0.0105, weight:0.65, lr:0.0008
[23:49:13.495] iteration:3267  t-loss:0.0290, loss-lb:0.0182, loss-ulb:0.0167, weight:0.65, lr:0.0008
[23:49:13.870] iteration:3268  t-loss:0.0478, loss-lb:0.0435, loss-ulb:0.0066, weight:0.65, lr:0.0008
[23:49:15.209] iteration:3269  t-loss:0.0591, loss-lb:0.0565, loss-ulb:0.0040, weight:0.65, lr:0.0008
[23:49:15.591] iteration:3270  t-loss:0.0249, loss-lb:0.0184, loss-ulb:0.0101, weight:0.65, lr:0.0008
[23:49:15.974] iteration:3271  t-loss:0.0449, loss-lb:0.0362, loss-ulb:0.0135, weight:0.65, lr:0.0008
[23:49:16.348] iteration:3272  t-loss:0.0676, loss-lb:0.0620, loss-ulb:0.0085, weight:0.65, lr:0.0008
[23:49:16.730] iteration:3273  t-loss:0.0209, loss-lb:0.0190, loss-ulb:0.0029, weight:0.65, lr:0.0008
[23:49:17.113] iteration:3274  t-loss:0.0685, loss-lb:0.0538, loss-ulb:0.0228, weight:0.65, lr:0.0008
[23:49:17.491] iteration:3275  t-loss:0.0620, loss-lb:0.0597, loss-ulb:0.0035, weight:0.65, lr:0.0008
[23:49:17.871] iteration:3276  t-loss:0.0544, loss-lb:0.0396, loss-ulb:0.0228, weight:0.65, lr:0.0008
[23:49:18.252] iteration:3277  t-loss:0.0251, loss-lb:0.0193, loss-ulb:0.0089, weight:0.65, lr:0.0008
[23:49:18.632] iteration:3278  t-loss:0.0580, loss-lb:0.0556, loss-ulb:0.0037, weight:0.65, lr:0.0008
[23:49:19.011] iteration:3279  t-loss:0.0419, loss-lb:0.0253, loss-ulb:0.0257, weight:0.65, lr:0.0008
[23:49:19.388] iteration:3280  t-loss:0.0801, loss-lb:0.0733, loss-ulb:0.0105, weight:0.65, lr:0.0008
[23:49:19.764] iteration:3281  t-loss:0.0254, loss-lb:0.0210, loss-ulb:0.0068, weight:0.65, lr:0.0008
[23:49:20.141] iteration:3282  t-loss:0.0790, loss-lb:0.0776, loss-ulb:0.0021, weight:0.65, lr:0.0008
[23:49:20.517] iteration:3283  t-loss:0.0575, loss-lb:0.0422, loss-ulb:0.0236, weight:0.65, lr:0.0008
[23:49:20.894] iteration:3284  t-loss:0.0784, loss-lb:0.0769, loss-ulb:0.0023, weight:0.65, lr:0.0008
[23:49:21.271] iteration:3285  t-loss:0.0242, loss-lb:0.0213, loss-ulb:0.0044, weight:0.65, lr:0.0008
[23:49:21.649] iteration:3286  t-loss:0.0370, loss-lb:0.0252, loss-ulb:0.0181, weight:0.65, lr:0.0008
[23:49:22.027] iteration:3287  t-loss:0.0356, loss-lb:0.0236, loss-ulb:0.0187, weight:0.65, lr:0.0008
[23:49:22.403] iteration:3288  t-loss:0.0427, loss-lb:0.0380, loss-ulb:0.0072, weight:0.65, lr:0.0008
[23:49:22.790] iteration:3289  t-loss:0.0388, loss-lb:0.0228, loss-ulb:0.0247, weight:0.65, lr:0.0008
[23:49:23.203] iteration:3290  t-loss:0.0519, loss-lb:0.0434, loss-ulb:0.0131, weight:0.65, lr:0.0008
[23:49:23.603] iteration:3291  t-loss:0.0231, loss-lb:0.0210, loss-ulb:0.0033, weight:0.65, lr:0.0008
[23:49:23.980] iteration:3292  t-loss:0.0292, loss-lb:0.0281, loss-ulb:0.0016, weight:0.65, lr:0.0008
[23:49:24.358] iteration:3293  t-loss:0.0467, loss-lb:0.0442, loss-ulb:0.0040, weight:0.65, lr:0.0008
[23:49:24.742] iteration:3294  t-loss:0.0320, loss-lb:0.0280, loss-ulb:0.0061, weight:0.65, lr:0.0008
[23:49:25.124] iteration:3295  t-loss:0.0469, loss-lb:0.0342, loss-ulb:0.0196, weight:0.65, lr:0.0008
[23:49:25.502] iteration:3296  t-loss:0.0512, loss-lb:0.0463, loss-ulb:0.0075, weight:0.65, lr:0.0008
[23:49:25.882] iteration:3297  t-loss:0.0412, loss-lb:0.0291, loss-ulb:0.0187, weight:0.65, lr:0.0008
[23:49:26.262] iteration:3298  t-loss:0.0720, loss-lb:0.0508, loss-ulb:0.0327, weight:0.65, lr:0.0008
[23:49:26.639] iteration:3299  t-loss:0.0307, loss-lb:0.0253, loss-ulb:0.0084, weight:0.65, lr:0.0008
[23:49:27.016] iteration:3300  t-loss:0.0844, loss-lb:0.0603, loss-ulb:0.0372, weight:0.65, lr:0.0008
[23:49:27.392] iteration:3301  t-loss:0.0569, loss-lb:0.0460, loss-ulb:0.0150, weight:0.73, lr:0.0008
[23:49:27.773] iteration:3302  t-loss:0.0661, loss-lb:0.0519, loss-ulb:0.0195, weight:0.73, lr:0.0008
[23:49:28.150] iteration:3303  t-loss:0.0701, loss-lb:0.0627, loss-ulb:0.0102, weight:0.73, lr:0.0008
[23:49:28.528] iteration:3304  t-loss:0.0513, loss-lb:0.0394, loss-ulb:0.0164, weight:0.73, lr:0.0008
[23:49:28.904] iteration:3305  t-loss:0.0339, loss-lb:0.0253, loss-ulb:0.0118, weight:0.73, lr:0.0008
[23:49:29.281] iteration:3306  t-loss:0.0665, loss-lb:0.0632, loss-ulb:0.0045, weight:0.73, lr:0.0008
[23:49:30.625] iteration:3307  t-loss:0.0421, loss-lb:0.0241, loss-ulb:0.0247, weight:0.73, lr:0.0008
[23:49:31.036] iteration:3308  t-loss:0.0551, loss-lb:0.0356, loss-ulb:0.0268, weight:0.73, lr:0.0008
[23:49:31.428] iteration:3309  t-loss:0.0553, loss-lb:0.0424, loss-ulb:0.0177, weight:0.73, lr:0.0008
[23:49:31.816] iteration:3310  t-loss:0.0498, loss-lb:0.0410, loss-ulb:0.0120, weight:0.73, lr:0.0008
[23:49:32.199] iteration:3311  t-loss:0.0714, loss-lb:0.0670, loss-ulb:0.0060, weight:0.73, lr:0.0008
[23:49:32.588] iteration:3312  t-loss:0.0742, loss-lb:0.0682, loss-ulb:0.0083, weight:0.73, lr:0.0008
[23:49:32.982] iteration:3313  t-loss:0.0847, loss-lb:0.0771, loss-ulb:0.0105, weight:0.73, lr:0.0008
[23:49:33.362] iteration:3314  t-loss:0.0357, loss-lb:0.0216, loss-ulb:0.0194, weight:0.73, lr:0.0008
[23:49:33.745] iteration:3315  t-loss:0.0538, loss-lb:0.0511, loss-ulb:0.0038, weight:0.73, lr:0.0008
[23:49:34.136] iteration:3316  t-loss:0.0432, loss-lb:0.0289, loss-ulb:0.0197, weight:0.73, lr:0.0008
[23:49:34.512] iteration:3317  t-loss:0.0548, loss-lb:0.0373, loss-ulb:0.0241, weight:0.73, lr:0.0008
[23:49:34.891] iteration:3318  t-loss:0.0515, loss-lb:0.0279, loss-ulb:0.0325, weight:0.73, lr:0.0008
[23:49:35.270] iteration:3319  t-loss:0.0441, loss-lb:0.0291, loss-ulb:0.0207, weight:0.73, lr:0.0008
[23:49:35.646] iteration:3320  t-loss:0.0287, loss-lb:0.0245, loss-ulb:0.0057, weight:0.73, lr:0.0008
[23:49:36.042] iteration:3321  t-loss:0.0418, loss-lb:0.0330, loss-ulb:0.0121, weight:0.73, lr:0.0008
[23:49:36.420] iteration:3322  t-loss:0.0599, loss-lb:0.0545, loss-ulb:0.0075, weight:0.73, lr:0.0008
[23:49:36.794] iteration:3323  t-loss:0.0393, loss-lb:0.0216, loss-ulb:0.0243, weight:0.73, lr:0.0008
[23:49:37.174] iteration:3324  t-loss:0.0347, loss-lb:0.0311, loss-ulb:0.0049, weight:0.73, lr:0.0008
[23:49:37.558] iteration:3325  t-loss:0.0335, loss-lb:0.0195, loss-ulb:0.0192, weight:0.73, lr:0.0008
[23:49:37.932] iteration:3326  t-loss:0.0390, loss-lb:0.0367, loss-ulb:0.0031, weight:0.73, lr:0.0008
[23:49:38.330] iteration:3327  t-loss:0.0575, loss-lb:0.0474, loss-ulb:0.0138, weight:0.73, lr:0.0008
[23:49:38.732] iteration:3328  t-loss:0.0285, loss-lb:0.0275, loss-ulb:0.0014, weight:0.73, lr:0.0008
[23:49:39.140] iteration:3329  t-loss:0.0365, loss-lb:0.0290, loss-ulb:0.0105, weight:0.73, lr:0.0008
[23:49:39.539] iteration:3330  t-loss:0.0536, loss-lb:0.0438, loss-ulb:0.0134, weight:0.73, lr:0.0008
[23:49:39.922] iteration:3331  t-loss:0.0579, loss-lb:0.0513, loss-ulb:0.0091, weight:0.73, lr:0.0008
[23:49:40.305] iteration:3332  t-loss:0.0408, loss-lb:0.0250, loss-ulb:0.0217, weight:0.73, lr:0.0008
[23:49:40.685] iteration:3333  t-loss:0.0236, loss-lb:0.0220, loss-ulb:0.0021, weight:0.73, lr:0.0008
[23:49:41.070] iteration:3334  t-loss:0.0409, loss-lb:0.0253, loss-ulb:0.0215, weight:0.73, lr:0.0008
[23:49:41.450] iteration:3335  t-loss:0.0448, loss-lb:0.0400, loss-ulb:0.0067, weight:0.73, lr:0.0008
[23:49:41.833] iteration:3336  t-loss:0.0604, loss-lb:0.0518, loss-ulb:0.0118, weight:0.73, lr:0.0008
[23:49:42.210] iteration:3337  t-loss:0.0260, loss-lb:0.0244, loss-ulb:0.0021, weight:0.73, lr:0.0008
[23:49:42.590] iteration:3338  t-loss:0.0717, loss-lb:0.0675, loss-ulb:0.0057, weight:0.73, lr:0.0008
[23:49:42.960] iteration:3339  t-loss:0.0344, loss-lb:0.0204, loss-ulb:0.0193, weight:0.73, lr:0.0008
[23:49:43.341] iteration:3340  t-loss:0.0764, loss-lb:0.0632, loss-ulb:0.0181, weight:0.73, lr:0.0008
[23:49:43.716] iteration:3341  t-loss:0.0418, loss-lb:0.0289, loss-ulb:0.0177, weight:0.73, lr:0.0008
[23:49:44.095] iteration:3342  t-loss:0.0634, loss-lb:0.0480, loss-ulb:0.0212, weight:0.73, lr:0.0008
[23:49:44.484] iteration:3343  t-loss:0.0848, loss-lb:0.0702, loss-ulb:0.0200, weight:0.73, lr:0.0008
[23:49:44.874] iteration:3344  t-loss:0.0333, loss-lb:0.0316, loss-ulb:0.0023, weight:0.73, lr:0.0008
[23:49:46.466] iteration:3345  t-loss:0.0341, loss-lb:0.0243, loss-ulb:0.0135, weight:0.73, lr:0.0008
[23:49:46.861] iteration:3346  t-loss:0.0686, loss-lb:0.0582, loss-ulb:0.0143, weight:0.73, lr:0.0008
[23:49:47.255] iteration:3347  t-loss:0.0457, loss-lb:0.0438, loss-ulb:0.0026, weight:0.73, lr:0.0008
[23:49:47.634] iteration:3348  t-loss:0.0536, loss-lb:0.0516, loss-ulb:0.0028, weight:0.73, lr:0.0008
[23:49:48.022] iteration:3349  t-loss:0.0245, loss-lb:0.0204, loss-ulb:0.0056, weight:0.73, lr:0.0008
[23:49:48.397] iteration:3350  t-loss:0.0693, loss-lb:0.0585, loss-ulb:0.0149, weight:0.73, lr:0.0008
[23:49:48.789] iteration:3351  t-loss:0.0605, loss-lb:0.0502, loss-ulb:0.0142, weight:0.73, lr:0.0008
[23:49:49.169] iteration:3352  t-loss:0.0769, loss-lb:0.0558, loss-ulb:0.0290, weight:0.73, lr:0.0008
[23:49:49.551] iteration:3353  t-loss:0.0501, loss-lb:0.0438, loss-ulb:0.0087, weight:0.73, lr:0.0008
[23:49:49.933] iteration:3354  t-loss:0.0318, loss-lb:0.0282, loss-ulb:0.0048, weight:0.73, lr:0.0008
[23:49:50.315] iteration:3355  t-loss:0.0501, loss-lb:0.0424, loss-ulb:0.0106, weight:0.73, lr:0.0008
[23:49:50.689] iteration:3356  t-loss:0.0347, loss-lb:0.0324, loss-ulb:0.0032, weight:0.73, lr:0.0008
[23:49:51.070] iteration:3357  t-loss:0.0471, loss-lb:0.0374, loss-ulb:0.0134, weight:0.73, lr:0.0008
[23:49:51.449] iteration:3358  t-loss:0.0410, loss-lb:0.0350, loss-ulb:0.0082, weight:0.73, lr:0.0008
[23:49:51.831] iteration:3359  t-loss:0.0494, loss-lb:0.0395, loss-ulb:0.0136, weight:0.73, lr:0.0008
[23:49:52.211] iteration:3360  t-loss:0.1027, loss-lb:0.0930, loss-ulb:0.0133, weight:0.73, lr:0.0008
[23:49:52.590] iteration:3361  t-loss:0.0432, loss-lb:0.0290, loss-ulb:0.0195, weight:0.73, lr:0.0008
[23:49:52.970] iteration:3362  t-loss:0.0461, loss-lb:0.0222, loss-ulb:0.0330, weight:0.73, lr:0.0008
[23:49:53.348] iteration:3363  t-loss:0.0509, loss-lb:0.0267, loss-ulb:0.0333, weight:0.73, lr:0.0008
[23:49:53.737] iteration:3364  t-loss:0.0397, loss-lb:0.0359, loss-ulb:0.0052, weight:0.73, lr:0.0008
[23:49:54.138] iteration:3365  t-loss:0.0615, loss-lb:0.0447, loss-ulb:0.0231, weight:0.73, lr:0.0008
[23:49:54.538] iteration:3366  t-loss:0.0338, loss-lb:0.0272, loss-ulb:0.0092, weight:0.73, lr:0.0008
[23:49:54.930] iteration:3367  t-loss:0.0281, loss-lb:0.0255, loss-ulb:0.0035, weight:0.73, lr:0.0008
[23:49:55.313] iteration:3368  t-loss:0.0685, loss-lb:0.0642, loss-ulb:0.0059, weight:0.73, lr:0.0008
[23:49:55.697] iteration:3369  t-loss:0.0481, loss-lb:0.0426, loss-ulb:0.0076, weight:0.73, lr:0.0008
[23:49:56.076] iteration:3370  t-loss:0.0589, loss-lb:0.0559, loss-ulb:0.0042, weight:0.73, lr:0.0008
[23:49:56.452] iteration:3371  t-loss:0.0268, loss-lb:0.0254, loss-ulb:0.0019, weight:0.73, lr:0.0008
[23:49:56.827] iteration:3372  t-loss:0.0418, loss-lb:0.0238, loss-ulb:0.0247, weight:0.73, lr:0.0008
[23:49:57.206] iteration:3373  t-loss:0.0751, loss-lb:0.0626, loss-ulb:0.0172, weight:0.73, lr:0.0008
[23:49:57.579] iteration:3374  t-loss:0.0873, loss-lb:0.0792, loss-ulb:0.0112, weight:0.73, lr:0.0008
[23:49:57.953] iteration:3375  t-loss:0.0423, loss-lb:0.0322, loss-ulb:0.0139, weight:0.73, lr:0.0008
[23:49:58.323] iteration:3376  t-loss:0.0588, loss-lb:0.0372, loss-ulb:0.0297, weight:0.73, lr:0.0008
[23:49:58.696] iteration:3377  t-loss:0.0413, loss-lb:0.0290, loss-ulb:0.0169, weight:0.73, lr:0.0008
[23:49:59.073] iteration:3378  t-loss:0.0439, loss-lb:0.0371, loss-ulb:0.0093, weight:0.73, lr:0.0008
[23:49:59.448] iteration:3379  t-loss:0.0723, loss-lb:0.0510, loss-ulb:0.0292, weight:0.73, lr:0.0008
[23:49:59.832] iteration:3380  t-loss:0.0393, loss-lb:0.0286, loss-ulb:0.0146, weight:0.73, lr:0.0008
[23:50:00.217] iteration:3381  t-loss:0.0566, loss-lb:0.0549, loss-ulb:0.0023, weight:0.73, lr:0.0008
[23:50:00.596] iteration:3382  t-loss:0.0622, loss-lb:0.0592, loss-ulb:0.0041, weight:0.73, lr:0.0008
[23:51:04.474] iteration 3382 : dice_score: 0.786365 best_dice: 0.814600
[23:51:04.474]  <<Test>> - Ep:88  - Dice-S/T:82.35/78.64, Best-S:84.62, Best-T:81.46
[23:51:04.475]           - AvgLoss(lb/ulb/all):0.04/0.01/0.05
[23:51:05.768] iteration:3383  t-loss:0.0286, loss-lb:0.0230, loss-ulb:0.0076, weight:0.73, lr:0.0008
[23:51:06.157] iteration:3384  t-loss:0.0422, loss-lb:0.0239, loss-ulb:0.0252, weight:0.73, lr:0.0008
[23:51:06.543] iteration:3385  t-loss:0.0474, loss-lb:0.0403, loss-ulb:0.0097, weight:0.73, lr:0.0008
[23:51:06.924] iteration:3386  t-loss:0.0423, loss-lb:0.0284, loss-ulb:0.0191, weight:0.73, lr:0.0008
[23:51:07.300] iteration:3387  t-loss:0.0260, loss-lb:0.0245, loss-ulb:0.0021, weight:0.73, lr:0.0008
[23:51:07.669] iteration:3388  t-loss:0.0221, loss-lb:0.0188, loss-ulb:0.0047, weight:0.73, lr:0.0008
[23:51:08.053] iteration:3389  t-loss:0.0436, loss-lb:0.0385, loss-ulb:0.0071, weight:0.73, lr:0.0008
[23:51:08.430] iteration:3390  t-loss:0.0296, loss-lb:0.0233, loss-ulb:0.0087, weight:0.73, lr:0.0008
[23:51:08.813] iteration:3391  t-loss:0.0850, loss-lb:0.0742, loss-ulb:0.0148, weight:0.73, lr:0.0008
[23:51:09.195] iteration:3392  t-loss:0.0214, loss-lb:0.0205, loss-ulb:0.0013, weight:0.73, lr:0.0008
[23:51:09.577] iteration:3393  t-loss:0.0305, loss-lb:0.0250, loss-ulb:0.0076, weight:0.73, lr:0.0008
[23:51:09.965] iteration:3394  t-loss:0.0533, loss-lb:0.0514, loss-ulb:0.0026, weight:0.73, lr:0.0008
[23:51:10.341] iteration:3395  t-loss:0.0324, loss-lb:0.0311, loss-ulb:0.0017, weight:0.73, lr:0.0008
[23:51:10.724] iteration:3396  t-loss:0.0643, loss-lb:0.0469, loss-ulb:0.0239, weight:0.73, lr:0.0008
[23:51:11.113] iteration:3397  t-loss:0.0777, loss-lb:0.0484, loss-ulb:0.0403, weight:0.73, lr:0.0008
[23:51:11.505] iteration:3398  t-loss:0.0450, loss-lb:0.0375, loss-ulb:0.0102, weight:0.73, lr:0.0008
[23:51:11.886] iteration:3399  t-loss:0.0607, loss-lb:0.0411, loss-ulb:0.0269, weight:0.73, lr:0.0008
[23:51:12.269] iteration:3400  t-loss:0.0482, loss-lb:0.0396, loss-ulb:0.0118, weight:0.73, lr:0.0008
[23:51:12.653] iteration:3401  t-loss:0.0433, loss-lb:0.0386, loss-ulb:0.0064, weight:0.73, lr:0.0008
[23:51:13.040] iteration:3402  t-loss:0.0733, loss-lb:0.0712, loss-ulb:0.0028, weight:0.73, lr:0.0008
[23:51:13.418] iteration:3403  t-loss:0.0198, loss-lb:0.0165, loss-ulb:0.0046, weight:0.73, lr:0.0008
[23:51:13.808] iteration:3404  t-loss:0.0908, loss-lb:0.0712, loss-ulb:0.0270, weight:0.73, lr:0.0008
[23:51:14.189] iteration:3405  t-loss:0.0255, loss-lb:0.0227, loss-ulb:0.0039, weight:0.73, lr:0.0008
[23:51:14.566] iteration:3406  t-loss:0.0474, loss-lb:0.0455, loss-ulb:0.0026, weight:0.73, lr:0.0008
[23:51:14.950] iteration:3407  t-loss:0.0639, loss-lb:0.0562, loss-ulb:0.0105, weight:0.73, lr:0.0008
[23:51:15.327] iteration:3408  t-loss:0.0322, loss-lb:0.0274, loss-ulb:0.0066, weight:0.73, lr:0.0008
[23:51:15.704] iteration:3409  t-loss:0.0255, loss-lb:0.0205, loss-ulb:0.0069, weight:0.73, lr:0.0008
[23:51:16.076] iteration:3410  t-loss:0.0408, loss-lb:0.0330, loss-ulb:0.0108, weight:0.73, lr:0.0008
[23:51:16.453] iteration:3411  t-loss:0.0351, loss-lb:0.0328, loss-ulb:0.0033, weight:0.73, lr:0.0008
[23:51:16.829] iteration:3412  t-loss:0.0347, loss-lb:0.0179, loss-ulb:0.0232, weight:0.73, lr:0.0008
[23:51:17.208] iteration:3413  t-loss:0.0441, loss-lb:0.0432, loss-ulb:0.0012, weight:0.73, lr:0.0008
[23:51:17.581] iteration:3414  t-loss:0.0270, loss-lb:0.0227, loss-ulb:0.0059, weight:0.73, lr:0.0008
[23:51:17.953] iteration:3415  t-loss:0.0723, loss-lb:0.0686, loss-ulb:0.0051, weight:0.73, lr:0.0008
[23:51:18.326] iteration:3416  t-loss:0.0451, loss-lb:0.0406, loss-ulb:0.0062, weight:0.73, lr:0.0008
[23:51:18.698] iteration:3417  t-loss:0.0222, loss-lb:0.0195, loss-ulb:0.0038, weight:0.73, lr:0.0008
[23:51:19.076] iteration:3418  t-loss:0.0713, loss-lb:0.0571, loss-ulb:0.0195, weight:0.73, lr:0.0008
[23:51:19.456] iteration:3419  t-loss:0.0637, loss-lb:0.0484, loss-ulb:0.0210, weight:0.73, lr:0.0008
[23:51:19.838] iteration:3420  t-loss:0.0572, loss-lb:0.0444, loss-ulb:0.0177, weight:0.73, lr:0.0008
[23:51:21.131] iteration:3421  t-loss:0.0423, loss-lb:0.0367, loss-ulb:0.0077, weight:0.73, lr:0.0008
[23:51:21.519] iteration:3422  t-loss:0.0491, loss-lb:0.0474, loss-ulb:0.0023, weight:0.73, lr:0.0008
[23:51:21.900] iteration:3423  t-loss:0.1168, loss-lb:0.1072, loss-ulb:0.0133, weight:0.73, lr:0.0008
[23:51:22.286] iteration:3424  t-loss:0.0410, loss-lb:0.0322, loss-ulb:0.0121, weight:0.73, lr:0.0008
[23:51:22.677] iteration:3425  t-loss:0.0254, loss-lb:0.0241, loss-ulb:0.0019, weight:0.73, lr:0.0008
[23:51:23.052] iteration:3426  t-loss:0.0335, loss-lb:0.0269, loss-ulb:0.0091, weight:0.73, lr:0.0008
[23:51:23.436] iteration:3427  t-loss:0.0509, loss-lb:0.0373, loss-ulb:0.0186, weight:0.73, lr:0.0008
[23:51:23.809] iteration:3428  t-loss:0.0371, loss-lb:0.0229, loss-ulb:0.0195, weight:0.73, lr:0.0008
[23:51:24.193] iteration:3429  t-loss:0.0432, loss-lb:0.0340, loss-ulb:0.0128, weight:0.73, lr:0.0008
[23:51:24.570] iteration:3430  t-loss:0.1013, loss-lb:0.0539, loss-ulb:0.0653, weight:0.73, lr:0.0008
[23:51:24.950] iteration:3431  t-loss:0.0640, loss-lb:0.0544, loss-ulb:0.0133, weight:0.73, lr:0.0008
[23:51:25.330] iteration:3432  t-loss:0.0698, loss-lb:0.0493, loss-ulb:0.0281, weight:0.73, lr:0.0008
[23:51:25.704] iteration:3433  t-loss:0.0279, loss-lb:0.0203, loss-ulb:0.0104, weight:0.73, lr:0.0008
[23:51:26.081] iteration:3434  t-loss:0.0728, loss-lb:0.0546, loss-ulb:0.0250, weight:0.73, lr:0.0008
[23:51:26.459] iteration:3435  t-loss:0.0535, loss-lb:0.0411, loss-ulb:0.0171, weight:0.73, lr:0.0008
[23:51:26.837] iteration:3436  t-loss:0.0302, loss-lb:0.0221, loss-ulb:0.0112, weight:0.73, lr:0.0008
[23:51:27.208] iteration:3437  t-loss:0.0359, loss-lb:0.0265, loss-ulb:0.0129, weight:0.73, lr:0.0008
[23:51:27.591] iteration:3438  t-loss:0.0424, loss-lb:0.0384, loss-ulb:0.0055, weight:0.73, lr:0.0008
[23:51:27.969] iteration:3439  t-loss:0.0522, loss-lb:0.0497, loss-ulb:0.0034, weight:0.73, lr:0.0008
[23:51:28.346] iteration:3440  t-loss:0.0407, loss-lb:0.0257, loss-ulb:0.0206, weight:0.73, lr:0.0008
[23:51:28.734] iteration:3441  t-loss:0.0620, loss-lb:0.0445, loss-ulb:0.0242, weight:0.73, lr:0.0008
[23:51:29.133] iteration:3442  t-loss:0.0631, loss-lb:0.0603, loss-ulb:0.0038, weight:0.73, lr:0.0008
[23:51:29.541] iteration:3443  t-loss:0.0441, loss-lb:0.0347, loss-ulb:0.0129, weight:0.73, lr:0.0008
[23:51:29.925] iteration:3444  t-loss:0.0270, loss-lb:0.0242, loss-ulb:0.0038, weight:0.73, lr:0.0008
[23:51:30.310] iteration:3445  t-loss:0.0431, loss-lb:0.0286, loss-ulb:0.0200, weight:0.73, lr:0.0008
[23:51:30.690] iteration:3446  t-loss:0.0287, loss-lb:0.0196, loss-ulb:0.0125, weight:0.73, lr:0.0008
[23:51:31.073] iteration:3447  t-loss:0.0374, loss-lb:0.0308, loss-ulb:0.0090, weight:0.73, lr:0.0008
[23:51:31.453] iteration:3448  t-loss:0.0257, loss-lb:0.0216, loss-ulb:0.0057, weight:0.73, lr:0.0008
[23:51:31.831] iteration:3449  t-loss:0.0286, loss-lb:0.0261, loss-ulb:0.0034, weight:0.73, lr:0.0008
[23:51:32.209] iteration:3450  t-loss:0.0349, loss-lb:0.0340, loss-ulb:0.0012, weight:0.73, lr:0.0008
[23:51:32.587] iteration:3451  t-loss:0.0400, loss-lb:0.0315, loss-ulb:0.0106, weight:0.81, lr:0.0008
[23:51:32.969] iteration:3452  t-loss:0.0614, loss-lb:0.0457, loss-ulb:0.0194, weight:0.81, lr:0.0008
[23:51:33.348] iteration:3453  t-loss:0.0349, loss-lb:0.0279, loss-ulb:0.0087, weight:0.81, lr:0.0008
[23:51:33.724] iteration:3454  t-loss:0.0336, loss-lb:0.0282, loss-ulb:0.0067, weight:0.81, lr:0.0008
[23:51:34.102] iteration:3455  t-loss:0.0435, loss-lb:0.0288, loss-ulb:0.0181, weight:0.81, lr:0.0008
[23:51:34.477] iteration:3456  t-loss:0.0696, loss-lb:0.0666, loss-ulb:0.0037, weight:0.81, lr:0.0008
[23:51:34.853] iteration:3457  t-loss:0.0275, loss-lb:0.0205, loss-ulb:0.0087, weight:0.81, lr:0.0008
[23:51:35.230] iteration:3458  t-loss:0.0324, loss-lb:0.0187, loss-ulb:0.0169, weight:0.81, lr:0.0008
[23:51:36.676] iteration:3459  t-loss:0.0312, loss-lb:0.0290, loss-ulb:0.0026, weight:0.81, lr:0.0008
[23:51:37.062] iteration:3460  t-loss:0.0613, loss-lb:0.0593, loss-ulb:0.0025, weight:0.81, lr:0.0008
[23:51:37.442] iteration:3461  t-loss:0.0310, loss-lb:0.0224, loss-ulb:0.0106, weight:0.81, lr:0.0008
[23:51:37.821] iteration:3462  t-loss:0.0482, loss-lb:0.0446, loss-ulb:0.0044, weight:0.81, lr:0.0008
[23:51:38.201] iteration:3463  t-loss:0.0428, loss-lb:0.0410, loss-ulb:0.0021, weight:0.81, lr:0.0008
[23:51:38.582] iteration:3464  t-loss:0.0396, loss-lb:0.0316, loss-ulb:0.0099, weight:0.81, lr:0.0008
[23:51:38.962] iteration:3465  t-loss:0.0607, loss-lb:0.0347, loss-ulb:0.0321, weight:0.81, lr:0.0008
[23:51:39.340] iteration:3466  t-loss:0.0361, loss-lb:0.0230, loss-ulb:0.0162, weight:0.81, lr:0.0008
[23:51:39.725] iteration:3467  t-loss:0.0869, loss-lb:0.0750, loss-ulb:0.0147, weight:0.81, lr:0.0008
[23:51:40.103] iteration:3468  t-loss:0.0335, loss-lb:0.0210, loss-ulb:0.0154, weight:0.81, lr:0.0008
[23:51:40.487] iteration:3469  t-loss:0.0696, loss-lb:0.0574, loss-ulb:0.0150, weight:0.81, lr:0.0008
[23:51:40.866] iteration:3470  t-loss:0.0528, loss-lb:0.0380, loss-ulb:0.0182, weight:0.81, lr:0.0008
[23:51:41.244] iteration:3471  t-loss:0.0592, loss-lb:0.0465, loss-ulb:0.0157, weight:0.81, lr:0.0008
[23:51:41.618] iteration:3472  t-loss:0.0236, loss-lb:0.0207, loss-ulb:0.0035, weight:0.81, lr:0.0008
[23:51:41.990] iteration:3473  t-loss:0.0336, loss-lb:0.0279, loss-ulb:0.0070, weight:0.81, lr:0.0008
[23:51:42.369] iteration:3474  t-loss:0.0618, loss-lb:0.0543, loss-ulb:0.0092, weight:0.81, lr:0.0008
[23:51:42.749] iteration:3475  t-loss:0.0663, loss-lb:0.0351, loss-ulb:0.0385, weight:0.81, lr:0.0008
[23:51:43.124] iteration:3476  t-loss:0.0388, loss-lb:0.0274, loss-ulb:0.0140, weight:0.81, lr:0.0008
[23:51:43.502] iteration:3477  t-loss:0.0637, loss-lb:0.0594, loss-ulb:0.0052, weight:0.81, lr:0.0008
[23:51:43.881] iteration:3478  t-loss:0.0322, loss-lb:0.0275, loss-ulb:0.0058, weight:0.81, lr:0.0008
[23:51:44.269] iteration:3479  t-loss:0.0223, loss-lb:0.0210, loss-ulb:0.0016, weight:0.81, lr:0.0008
[23:51:44.670] iteration:3480  t-loss:0.0303, loss-lb:0.0255, loss-ulb:0.0059, weight:0.81, lr:0.0008
[23:51:45.081] iteration:3481  t-loss:0.0573, loss-lb:0.0454, loss-ulb:0.0147, weight:0.81, lr:0.0008
[23:51:45.476] iteration:3482  t-loss:0.0326, loss-lb:0.0201, loss-ulb:0.0154, weight:0.81, lr:0.0008
[23:51:45.865] iteration:3483  t-loss:0.0833, loss-lb:0.0623, loss-ulb:0.0260, weight:0.81, lr:0.0008
[23:51:46.246] iteration:3484  t-loss:0.0710, loss-lb:0.0462, loss-ulb:0.0306, weight:0.81, lr:0.0008
[23:51:46.624] iteration:3485  t-loss:0.0629, loss-lb:0.0594, loss-ulb:0.0043, weight:0.81, lr:0.0008
[23:51:47.007] iteration:3486  t-loss:0.0578, loss-lb:0.0547, loss-ulb:0.0038, weight:0.81, lr:0.0008
[23:51:47.385] iteration:3487  t-loss:0.0509, loss-lb:0.0344, loss-ulb:0.0204, weight:0.81, lr:0.0008
[23:51:47.764] iteration:3488  t-loss:0.0242, loss-lb:0.0224, loss-ulb:0.0022, weight:0.81, lr:0.0008
[23:51:48.143] iteration:3489  t-loss:0.0399, loss-lb:0.0217, loss-ulb:0.0225, weight:0.81, lr:0.0008
[23:51:48.520] iteration:3490  t-loss:0.0759, loss-lb:0.0677, loss-ulb:0.0101, weight:0.81, lr:0.0008
[23:51:48.894] iteration:3491  t-loss:0.0212, loss-lb:0.0183, loss-ulb:0.0036, weight:0.81, lr:0.0008
[23:51:49.267] iteration:3492  t-loss:0.0306, loss-lb:0.0282, loss-ulb:0.0030, weight:0.81, lr:0.0008
[23:51:49.643] iteration:3493  t-loss:0.0623, loss-lb:0.0434, loss-ulb:0.0234, weight:0.81, lr:0.0008
[23:51:50.035] iteration:3494  t-loss:0.0807, loss-lb:0.0558, loss-ulb:0.0308, weight:0.81, lr:0.0008
[23:51:50.426] iteration:3495  t-loss:0.0972, loss-lb:0.0943, loss-ulb:0.0036, weight:0.81, lr:0.0008
[23:51:50.807] iteration:3496  t-loss:0.0365, loss-lb:0.0269, loss-ulb:0.0118, weight:0.81, lr:0.0008
[23:51:52.007] iteration:3497  t-loss:0.0251, loss-lb:0.0205, loss-ulb:0.0056, weight:0.81, lr:0.0008
[23:51:52.408] iteration:3498  t-loss:0.0292, loss-lb:0.0228, loss-ulb:0.0079, weight:0.81, lr:0.0008
[23:51:52.800] iteration:3499  t-loss:0.0638, loss-lb:0.0574, loss-ulb:0.0079, weight:0.81, lr:0.0008
[23:51:53.185] iteration:3500  t-loss:0.0469, loss-lb:0.0396, loss-ulb:0.0090, weight:0.81, lr:0.0008
[23:51:53.566] iteration:3501  t-loss:0.0360, loss-lb:0.0333, loss-ulb:0.0034, weight:0.81, lr:0.0008
[23:51:53.942] iteration:3502  t-loss:0.0385, loss-lb:0.0328, loss-ulb:0.0071, weight:0.81, lr:0.0008
[23:51:54.326] iteration:3503  t-loss:0.0430, loss-lb:0.0264, loss-ulb:0.0205, weight:0.81, lr:0.0008
[23:51:54.703] iteration:3504  t-loss:0.0715, loss-lb:0.0617, loss-ulb:0.0122, weight:0.81, lr:0.0008
[23:51:55.077] iteration:3505  t-loss:0.0518, loss-lb:0.0361, loss-ulb:0.0193, weight:0.81, lr:0.0008
[23:51:55.454] iteration:3506  t-loss:0.0352, loss-lb:0.0237, loss-ulb:0.0143, weight:0.81, lr:0.0008
[23:51:55.833] iteration:3507  t-loss:0.0280, loss-lb:0.0239, loss-ulb:0.0050, weight:0.81, lr:0.0008
[23:51:56.212] iteration:3508  t-loss:0.0401, loss-lb:0.0315, loss-ulb:0.0106, weight:0.81, lr:0.0008
[23:51:56.585] iteration:3509  t-loss:0.0399, loss-lb:0.0365, loss-ulb:0.0042, weight:0.81, lr:0.0008
[23:51:56.959] iteration:3510  t-loss:0.0269, loss-lb:0.0228, loss-ulb:0.0051, weight:0.81, lr:0.0008
[23:51:57.337] iteration:3511  t-loss:0.0887, loss-lb:0.0550, loss-ulb:0.0416, weight:0.81, lr:0.0008
[23:51:57.713] iteration:3512  t-loss:0.0453, loss-lb:0.0347, loss-ulb:0.0131, weight:0.81, lr:0.0008
[23:51:58.087] iteration:3513  t-loss:0.0300, loss-lb:0.0218, loss-ulb:0.0101, weight:0.81, lr:0.0008
[23:51:58.466] iteration:3514  t-loss:0.0720, loss-lb:0.0548, loss-ulb:0.0212, weight:0.81, lr:0.0008
[23:51:58.845] iteration:3515  t-loss:0.0369, loss-lb:0.0227, loss-ulb:0.0175, weight:0.81, lr:0.0008
[23:51:59.219] iteration:3516  t-loss:0.0565, loss-lb:0.0520, loss-ulb:0.0056, weight:0.81, lr:0.0008
[23:51:59.583] iteration:3517  t-loss:0.0428, loss-lb:0.0336, loss-ulb:0.0114, weight:0.81, lr:0.0008
[23:51:59.989] iteration:3518  t-loss:0.0685, loss-lb:0.0525, loss-ulb:0.0197, weight:0.81, lr:0.0008
[23:52:00.395] iteration:3519  t-loss:0.0302, loss-lb:0.0260, loss-ulb:0.0052, weight:0.81, lr:0.0008
[23:52:00.811] iteration:3520  t-loss:0.0398, loss-lb:0.0366, loss-ulb:0.0041, weight:0.81, lr:0.0008
[23:52:01.212] iteration:3521  t-loss:0.0490, loss-lb:0.0358, loss-ulb:0.0162, weight:0.81, lr:0.0008
[23:52:01.601] iteration:3522  t-loss:0.0559, loss-lb:0.0548, loss-ulb:0.0013, weight:0.81, lr:0.0008
[23:52:01.978] iteration:3523  t-loss:0.0270, loss-lb:0.0246, loss-ulb:0.0030, weight:0.81, lr:0.0008
[23:52:02.350] iteration:3524  t-loss:0.0314, loss-lb:0.0277, loss-ulb:0.0045, weight:0.81, lr:0.0008
[23:52:02.729] iteration:3525  t-loss:0.0747, loss-lb:0.0655, loss-ulb:0.0114, weight:0.81, lr:0.0008
[23:52:03.107] iteration:3526  t-loss:0.0213, loss-lb:0.0192, loss-ulb:0.0026, weight:0.81, lr:0.0008
[23:52:03.477] iteration:3527  t-loss:0.0410, loss-lb:0.0383, loss-ulb:0.0033, weight:0.81, lr:0.0008
[23:52:03.851] iteration:3528  t-loss:0.0457, loss-lb:0.0261, loss-ulb:0.0242, weight:0.81, lr:0.0008
[23:52:04.227] iteration:3529  t-loss:0.0642, loss-lb:0.0410, loss-ulb:0.0286, weight:0.81, lr:0.0008
[23:52:04.597] iteration:3530  t-loss:0.0366, loss-lb:0.0332, loss-ulb:0.0042, weight:0.81, lr:0.0008
[23:52:04.972] iteration:3531  t-loss:0.0589, loss-lb:0.0574, loss-ulb:0.0019, weight:0.81, lr:0.0008
[23:52:05.365] iteration:3532  t-loss:0.0748, loss-lb:0.0588, loss-ulb:0.0198, weight:0.81, lr:0.0008
[23:52:05.757] iteration:3533  t-loss:0.0530, loss-lb:0.0477, loss-ulb:0.0065, weight:0.81, lr:0.0008
[23:52:06.146] iteration:3534  t-loss:0.0561, loss-lb:0.0421, loss-ulb:0.0172, weight:0.81, lr:0.0008
[23:53:11.095] iteration 3534 : dice_score: 0.794896 best_dice: 0.814600
[23:53:11.095]  <<Test>> - Ep:92  - Dice-S/T:77.03/79.49, Best-S:84.62, Best-T:81.46
[23:53:11.095]           - AvgLoss(lb/ulb/all):0.04/0.01/0.05
[23:53:12.435] iteration:3535  t-loss:0.0775, loss-lb:0.0658, loss-ulb:0.0144, weight:0.81, lr:0.0008
[23:53:12.820] iteration:3536  t-loss:0.0373, loss-lb:0.0245, loss-ulb:0.0158, weight:0.81, lr:0.0008
[23:53:13.209] iteration:3537  t-loss:0.0418, loss-lb:0.0376, loss-ulb:0.0052, weight:0.81, lr:0.0008
[23:53:13.592] iteration:3538  t-loss:0.0551, loss-lb:0.0495, loss-ulb:0.0070, weight:0.81, lr:0.0008
[23:53:13.976] iteration:3539  t-loss:0.0489, loss-lb:0.0276, loss-ulb:0.0262, weight:0.81, lr:0.0008
[23:53:14.358] iteration:3540  t-loss:0.0339, loss-lb:0.0238, loss-ulb:0.0125, weight:0.81, lr:0.0008
[23:53:14.739] iteration:3541  t-loss:0.0851, loss-lb:0.0810, loss-ulb:0.0050, weight:0.81, lr:0.0008
[23:53:15.128] iteration:3542  t-loss:0.0399, loss-lb:0.0343, loss-ulb:0.0069, weight:0.81, lr:0.0008
[23:53:15.510] iteration:3543  t-loss:0.0634, loss-lb:0.0416, loss-ulb:0.0269, weight:0.81, lr:0.0008
[23:53:15.894] iteration:3544  t-loss:0.0400, loss-lb:0.0260, loss-ulb:0.0172, weight:0.81, lr:0.0008
[23:53:16.274] iteration:3545  t-loss:0.0535, loss-lb:0.0393, loss-ulb:0.0175, weight:0.81, lr:0.0008
[23:53:16.658] iteration:3546  t-loss:0.0496, loss-lb:0.0405, loss-ulb:0.0113, weight:0.81, lr:0.0008
[23:53:17.048] iteration:3547  t-loss:0.0510, loss-lb:0.0422, loss-ulb:0.0107, weight:0.81, lr:0.0008
[23:53:17.431] iteration:3548  t-loss:0.0465, loss-lb:0.0415, loss-ulb:0.0061, weight:0.81, lr:0.0008
[23:53:17.812] iteration:3549  t-loss:0.0260, loss-lb:0.0223, loss-ulb:0.0046, weight:0.81, lr:0.0008
[23:53:18.191] iteration:3550  t-loss:0.0658, loss-lb:0.0625, loss-ulb:0.0041, weight:0.81, lr:0.0008
[23:53:18.575] iteration:3551  t-loss:0.0400, loss-lb:0.0348, loss-ulb:0.0064, weight:0.81, lr:0.0008
[23:53:18.955] iteration:3552  t-loss:0.0554, loss-lb:0.0405, loss-ulb:0.0183, weight:0.81, lr:0.0008
[23:53:19.334] iteration:3553  t-loss:0.0330, loss-lb:0.0271, loss-ulb:0.0073, weight:0.81, lr:0.0008
[23:53:19.718] iteration:3554  t-loss:0.0449, loss-lb:0.0376, loss-ulb:0.0089, weight:0.81, lr:0.0008
[23:53:20.097] iteration:3555  t-loss:0.0521, loss-lb:0.0392, loss-ulb:0.0158, weight:0.81, lr:0.0008
[23:53:20.480] iteration:3556  t-loss:0.0245, loss-lb:0.0210, loss-ulb:0.0043, weight:0.81, lr:0.0008
[23:53:20.874] iteration:3557  t-loss:0.0293, loss-lb:0.0203, loss-ulb:0.0111, weight:0.81, lr:0.0008
[23:53:21.282] iteration:3558  t-loss:0.0373, loss-lb:0.0219, loss-ulb:0.0190, weight:0.81, lr:0.0008
[23:53:21.670] iteration:3559  t-loss:0.0268, loss-lb:0.0253, loss-ulb:0.0019, weight:0.81, lr:0.0008
[23:53:22.058] iteration:3560  t-loss:0.0485, loss-lb:0.0345, loss-ulb:0.0172, weight:0.81, lr:0.0008
[23:53:22.437] iteration:3561  t-loss:0.0202, loss-lb:0.0180, loss-ulb:0.0028, weight:0.81, lr:0.0008
[23:53:22.816] iteration:3562  t-loss:0.0719, loss-lb:0.0707, loss-ulb:0.0014, weight:0.81, lr:0.0008
[23:53:23.201] iteration:3563  t-loss:0.0387, loss-lb:0.0372, loss-ulb:0.0019, weight:0.81, lr:0.0008
[23:53:23.584] iteration:3564  t-loss:0.0844, loss-lb:0.0665, loss-ulb:0.0220, weight:0.81, lr:0.0008
[23:53:23.962] iteration:3565  t-loss:0.0258, loss-lb:0.0198, loss-ulb:0.0074, weight:0.81, lr:0.0008
[23:53:24.338] iteration:3566  t-loss:0.0576, loss-lb:0.0525, loss-ulb:0.0063, weight:0.81, lr:0.0008
[23:53:24.711] iteration:3567  t-loss:0.0461, loss-lb:0.0282, loss-ulb:0.0221, weight:0.81, lr:0.0008
[23:53:25.082] iteration:3568  t-loss:0.0441, loss-lb:0.0354, loss-ulb:0.0108, weight:0.81, lr:0.0008
[23:53:25.456] iteration:3569  t-loss:0.0245, loss-lb:0.0228, loss-ulb:0.0020, weight:0.81, lr:0.0008
[23:53:25.833] iteration:3570  t-loss:0.0648, loss-lb:0.0571, loss-ulb:0.0094, weight:0.81, lr:0.0008
[23:53:26.205] iteration:3571  t-loss:0.0395, loss-lb:0.0369, loss-ulb:0.0032, weight:0.81, lr:0.0008
[23:53:26.577] iteration:3572  t-loss:0.0295, loss-lb:0.0252, loss-ulb:0.0053, weight:0.81, lr:0.0008
[23:53:27.830] iteration:3573  t-loss:0.0465, loss-lb:0.0379, loss-ulb:0.0106, weight:0.81, lr:0.0008
[23:53:28.228] iteration:3574  t-loss:0.0314, loss-lb:0.0217, loss-ulb:0.0119, weight:0.81, lr:0.0008
[23:53:28.605] iteration:3575  t-loss:0.0258, loss-lb:0.0232, loss-ulb:0.0032, weight:0.81, lr:0.0008
[23:53:28.987] iteration:3576  t-loss:0.0441, loss-lb:0.0427, loss-ulb:0.0017, weight:0.81, lr:0.0008
[23:53:29.366] iteration:3577  t-loss:0.0324, loss-lb:0.0175, loss-ulb:0.0184, weight:0.81, lr:0.0008
[23:53:29.744] iteration:3578  t-loss:0.0574, loss-lb:0.0559, loss-ulb:0.0018, weight:0.81, lr:0.0008
[23:53:30.129] iteration:3579  t-loss:0.0383, loss-lb:0.0303, loss-ulb:0.0098, weight:0.81, lr:0.0008
[23:53:30.511] iteration:3580  t-loss:0.0367, loss-lb:0.0207, loss-ulb:0.0196, weight:0.81, lr:0.0008
[23:53:30.886] iteration:3581  t-loss:0.0285, loss-lb:0.0259, loss-ulb:0.0032, weight:0.81, lr:0.0008
[23:53:31.263] iteration:3582  t-loss:0.0436, loss-lb:0.0393, loss-ulb:0.0054, weight:0.81, lr:0.0008
[23:53:31.655] iteration:3583  t-loss:0.0750, loss-lb:0.0527, loss-ulb:0.0275, weight:0.81, lr:0.0008
[23:53:32.036] iteration:3584  t-loss:0.0608, loss-lb:0.0548, loss-ulb:0.0074, weight:0.81, lr:0.0008
[23:53:32.417] iteration:3585  t-loss:0.0402, loss-lb:0.0308, loss-ulb:0.0116, weight:0.81, lr:0.0008
[23:53:32.794] iteration:3586  t-loss:0.0391, loss-lb:0.0377, loss-ulb:0.0018, weight:0.81, lr:0.0008
[23:53:33.168] iteration:3587  t-loss:0.0375, loss-lb:0.0239, loss-ulb:0.0168, weight:0.81, lr:0.0008
[23:53:33.543] iteration:3588  t-loss:0.0826, loss-lb:0.0657, loss-ulb:0.0208, weight:0.81, lr:0.0008
[23:53:33.917] iteration:3589  t-loss:0.0437, loss-lb:0.0235, loss-ulb:0.0249, weight:0.81, lr:0.0008
[23:53:34.295] iteration:3590  t-loss:0.0512, loss-lb:0.0437, loss-ulb:0.0092, weight:0.81, lr:0.0008
[23:53:34.676] iteration:3591  t-loss:0.0351, loss-lb:0.0281, loss-ulb:0.0086, weight:0.81, lr:0.0008
[23:53:35.052] iteration:3592  t-loss:0.0293, loss-lb:0.0265, loss-ulb:0.0035, weight:0.81, lr:0.0008
[23:53:35.430] iteration:3593  t-loss:0.0600, loss-lb:0.0558, loss-ulb:0.0051, weight:0.81, lr:0.0008
[23:53:35.807] iteration:3594  t-loss:0.0472, loss-lb:0.0448, loss-ulb:0.0030, weight:0.81, lr:0.0008
[23:53:36.185] iteration:3595  t-loss:0.0465, loss-lb:0.0347, loss-ulb:0.0145, weight:0.81, lr:0.0008
[23:53:36.579] iteration:3596  t-loss:0.0443, loss-lb:0.0360, loss-ulb:0.0103, weight:0.81, lr:0.0008
[23:53:36.977] iteration:3597  t-loss:0.0355, loss-lb:0.0277, loss-ulb:0.0097, weight:0.81, lr:0.0008
[23:53:37.372] iteration:3598  t-loss:0.0479, loss-lb:0.0422, loss-ulb:0.0070, weight:0.81, lr:0.0008
[23:53:37.760] iteration:3599  t-loss:0.0486, loss-lb:0.0399, loss-ulb:0.0107, weight:0.81, lr:0.0008
[23:53:38.139] iteration:3600  t-loss:0.0501, loss-lb:0.0228, loss-ulb:0.0337, weight:0.81, lr:0.0008
[23:53:38.523] iteration:3601  t-loss:0.0263, loss-lb:0.0237, loss-ulb:0.0030, weight:0.90, lr:0.0008
[23:53:38.903] iteration:3602  t-loss:0.0499, loss-lb:0.0477, loss-ulb:0.0024, weight:0.90, lr:0.0008
[23:53:39.283] iteration:3603  t-loss:0.0539, loss-lb:0.0199, loss-ulb:0.0378, weight:0.90, lr:0.0008
[23:53:39.659] iteration:3604  t-loss:0.0434, loss-lb:0.0227, loss-ulb:0.0230, weight:0.90, lr:0.0008
[23:53:40.036] iteration:3605  t-loss:0.0373, loss-lb:0.0207, loss-ulb:0.0185, weight:0.90, lr:0.0008
[23:53:40.414] iteration:3606  t-loss:0.0388, loss-lb:0.0289, loss-ulb:0.0110, weight:0.90, lr:0.0008
[23:53:40.788] iteration:3607  t-loss:0.0262, loss-lb:0.0218, loss-ulb:0.0049, weight:0.90, lr:0.0008
[23:53:41.163] iteration:3608  t-loss:0.0307, loss-lb:0.0203, loss-ulb:0.0116, weight:0.90, lr:0.0008
[23:53:41.540] iteration:3609  t-loss:0.0481, loss-lb:0.0355, loss-ulb:0.0140, weight:0.90, lr:0.0008
[23:53:41.912] iteration:3610  t-loss:0.0446, loss-lb:0.0358, loss-ulb:0.0099, weight:0.90, lr:0.0008
[23:53:43.048] iteration:3611  t-loss:0.0326, loss-lb:0.0223, loss-ulb:0.0114, weight:0.90, lr:0.0008
[23:53:43.434] iteration:3612  t-loss:0.0595, loss-lb:0.0534, loss-ulb:0.0068, weight:0.90, lr:0.0008
[23:53:43.823] iteration:3613  t-loss:0.0651, loss-lb:0.0624, loss-ulb:0.0030, weight:0.90, lr:0.0008
[23:53:44.197] iteration:3614  t-loss:0.0445, loss-lb:0.0328, loss-ulb:0.0130, weight:0.90, lr:0.0008
[23:53:44.577] iteration:3615  t-loss:0.0353, loss-lb:0.0199, loss-ulb:0.0172, weight:0.90, lr:0.0008
[23:53:44.952] iteration:3616  t-loss:0.0468, loss-lb:0.0340, loss-ulb:0.0142, weight:0.90, lr:0.0008
[23:53:45.330] iteration:3617  t-loss:0.0620, loss-lb:0.0465, loss-ulb:0.0172, weight:0.90, lr:0.0008
[23:53:45.701] iteration:3618  t-loss:0.0425, loss-lb:0.0320, loss-ulb:0.0116, weight:0.90, lr:0.0008
[23:53:46.080] iteration:3619  t-loss:0.0275, loss-lb:0.0233, loss-ulb:0.0047, weight:0.90, lr:0.0008
[23:53:46.454] iteration:3620  t-loss:0.0665, loss-lb:0.0637, loss-ulb:0.0031, weight:0.90, lr:0.0008
[23:53:46.832] iteration:3621  t-loss:0.0401, loss-lb:0.0331, loss-ulb:0.0079, weight:0.90, lr:0.0008
[23:53:47.204] iteration:3622  t-loss:0.0320, loss-lb:0.0284, loss-ulb:0.0040, weight:0.90, lr:0.0008
[23:53:47.589] iteration:3623  t-loss:0.0949, loss-lb:0.0722, loss-ulb:0.0252, weight:0.90, lr:0.0008
[23:53:47.962] iteration:3624  t-loss:0.0348, loss-lb:0.0292, loss-ulb:0.0062, weight:0.90, lr:0.0008
[23:53:48.337] iteration:3625  t-loss:0.0382, loss-lb:0.0245, loss-ulb:0.0153, weight:0.90, lr:0.0008
[23:53:48.716] iteration:3626  t-loss:0.0577, loss-lb:0.0450, loss-ulb:0.0141, weight:0.90, lr:0.0008
[23:53:49.095] iteration:3627  t-loss:0.0447, loss-lb:0.0405, loss-ulb:0.0047, weight:0.90, lr:0.0008
[23:53:49.473] iteration:3628  t-loss:0.0956, loss-lb:0.0515, loss-ulb:0.0490, weight:0.90, lr:0.0008
[23:53:49.855] iteration:3629  t-loss:0.0554, loss-lb:0.0441, loss-ulb:0.0126, weight:0.90, lr:0.0008
[23:53:50.233] iteration:3630  t-loss:0.0969, loss-lb:0.0823, loss-ulb:0.0163, weight:0.90, lr:0.0008
[23:53:50.608] iteration:3631  t-loss:0.0435, loss-lb:0.0381, loss-ulb:0.0060, weight:0.90, lr:0.0008
[23:53:50.984] iteration:3632  t-loss:0.0339, loss-lb:0.0218, loss-ulb:0.0134, weight:0.90, lr:0.0008
[23:53:51.370] iteration:3633  t-loss:0.0691, loss-lb:0.0586, loss-ulb:0.0117, weight:0.90, lr:0.0008
[23:53:51.766] iteration:3634  t-loss:0.0465, loss-lb:0.0296, loss-ulb:0.0188, weight:0.90, lr:0.0008
[23:53:52.193] iteration:3635  t-loss:0.0519, loss-lb:0.0482, loss-ulb:0.0041, weight:0.90, lr:0.0008
[23:53:52.598] iteration:3636  t-loss:0.0594, loss-lb:0.0466, loss-ulb:0.0142, weight:0.90, lr:0.0008
[23:53:52.987] iteration:3637  t-loss:0.0492, loss-lb:0.0459, loss-ulb:0.0036, weight:0.90, lr:0.0008
[23:53:53.370] iteration:3638  t-loss:0.0599, loss-lb:0.0521, loss-ulb:0.0087, weight:0.90, lr:0.0008
[23:53:53.750] iteration:3639  t-loss:0.0418, loss-lb:0.0273, loss-ulb:0.0161, weight:0.90, lr:0.0008
[23:53:54.133] iteration:3640  t-loss:0.0497, loss-lb:0.0452, loss-ulb:0.0050, weight:0.90, lr:0.0008
[23:53:54.511] iteration:3641  t-loss:0.0265, loss-lb:0.0240, loss-ulb:0.0027, weight:0.90, lr:0.0008
[23:53:54.889] iteration:3642  t-loss:0.0687, loss-lb:0.0596, loss-ulb:0.0102, weight:0.90, lr:0.0008
[23:53:55.267] iteration:3643  t-loss:0.0443, loss-lb:0.0294, loss-ulb:0.0166, weight:0.90, lr:0.0008
[23:53:55.642] iteration:3644  t-loss:0.0469, loss-lb:0.0437, loss-ulb:0.0035, weight:0.90, lr:0.0008
[23:53:56.027] iteration:3645  t-loss:0.0280, loss-lb:0.0249, loss-ulb:0.0034, weight:0.90, lr:0.0008
[23:53:56.426] iteration:3646  t-loss:0.0544, loss-lb:0.0525, loss-ulb:0.0021, weight:0.90, lr:0.0008
[23:53:56.809] iteration:3647  t-loss:0.0847, loss-lb:0.0763, loss-ulb:0.0093, weight:0.90, lr:0.0008
[23:53:57.183] iteration:3648  t-loss:0.1065, loss-lb:0.1019, loss-ulb:0.0051, weight:0.90, lr:0.0008
[23:53:58.506] iteration:3649  t-loss:0.0433, loss-lb:0.0263, loss-ulb:0.0189, weight:0.90, lr:0.0008
[23:53:58.904] iteration:3650  t-loss:0.0501, loss-lb:0.0446, loss-ulb:0.0061, weight:0.90, lr:0.0008
[23:53:59.296] iteration:3651  t-loss:0.0774, loss-lb:0.0518, loss-ulb:0.0285, weight:0.90, lr:0.0008
[23:53:59.671] iteration:3652  t-loss:0.0517, loss-lb:0.0299, loss-ulb:0.0243, weight:0.90, lr:0.0008
[23:54:00.057] iteration:3653  t-loss:0.1057, loss-lb:0.0592, loss-ulb:0.0518, weight:0.90, lr:0.0008
[23:54:00.437] iteration:3654  t-loss:0.0698, loss-lb:0.0569, loss-ulb:0.0143, weight:0.90, lr:0.0008
[23:54:00.820] iteration:3655  t-loss:0.0568, loss-lb:0.0341, loss-ulb:0.0253, weight:0.90, lr:0.0008
[23:54:01.195] iteration:3656  t-loss:0.0545, loss-lb:0.0503, loss-ulb:0.0048, weight:0.90, lr:0.0008
[23:54:01.577] iteration:3657  t-loss:0.0331, loss-lb:0.0305, loss-ulb:0.0029, weight:0.90, lr:0.0008
[23:54:01.959] iteration:3658  t-loss:0.0344, loss-lb:0.0239, loss-ulb:0.0117, weight:0.90, lr:0.0008
[23:54:02.344] iteration:3659  t-loss:0.0638, loss-lb:0.0468, loss-ulb:0.0190, weight:0.90, lr:0.0008
[23:54:02.723] iteration:3660  t-loss:0.0610, loss-lb:0.0477, loss-ulb:0.0148, weight:0.90, lr:0.0008
[23:54:03.102] iteration:3661  t-loss:0.0908, loss-lb:0.0811, loss-ulb:0.0109, weight:0.90, lr:0.0008
[23:54:03.476] iteration:3662  t-loss:0.0707, loss-lb:0.0263, loss-ulb:0.0494, weight:0.90, lr:0.0008
[23:54:03.851] iteration:3663  t-loss:0.0596, loss-lb:0.0449, loss-ulb:0.0164, weight:0.90, lr:0.0008
[23:54:04.227] iteration:3664  t-loss:0.1135, loss-lb:0.1072, loss-ulb:0.0071, weight:0.90, lr:0.0008
[23:54:04.602] iteration:3665  t-loss:0.0232, loss-lb:0.0187, loss-ulb:0.0050, weight:0.90, lr:0.0008
[23:54:04.973] iteration:3666  t-loss:0.0574, loss-lb:0.0278, loss-ulb:0.0330, weight:0.90, lr:0.0008
[23:54:05.354] iteration:3667  t-loss:0.0645, loss-lb:0.0495, loss-ulb:0.0167, weight:0.90, lr:0.0008
[23:54:05.736] iteration:3668  t-loss:0.0708, loss-lb:0.0582, loss-ulb:0.0140, weight:0.90, lr:0.0008
[23:54:06.120] iteration:3669  t-loss:0.1055, loss-lb:0.0834, loss-ulb:0.0245, weight:0.90, lr:0.0008
[23:54:06.496] iteration:3670  t-loss:0.0244, loss-lb:0.0224, loss-ulb:0.0022, weight:0.90, lr:0.0008
[23:54:06.874] iteration:3671  t-loss:0.0704, loss-lb:0.0349, loss-ulb:0.0396, weight:0.90, lr:0.0008
[23:54:07.272] iteration:3672  t-loss:0.0597, loss-lb:0.0562, loss-ulb:0.0039, weight:0.90, lr:0.0008
[23:54:07.680] iteration:3673  t-loss:0.0301, loss-lb:0.0274, loss-ulb:0.0030, weight:0.90, lr:0.0008
[23:54:08.074] iteration:3674  t-loss:0.0601, loss-lb:0.0384, loss-ulb:0.0242, weight:0.90, lr:0.0008
[23:54:08.455] iteration:3675  t-loss:0.0411, loss-lb:0.0248, loss-ulb:0.0181, weight:0.90, lr:0.0008
[23:54:08.831] iteration:3676  t-loss:0.1276, loss-lb:0.1182, loss-ulb:0.0105, weight:0.90, lr:0.0008
[23:54:09.213] iteration:3677  t-loss:0.0907, loss-lb:0.0766, loss-ulb:0.0158, weight:0.90, lr:0.0008
[23:54:09.587] iteration:3678  t-loss:0.0563, loss-lb:0.0546, loss-ulb:0.0019, weight:0.90, lr:0.0008
[23:54:09.962] iteration:3679  t-loss:0.0689, loss-lb:0.0573, loss-ulb:0.0129, weight:0.90, lr:0.0008
[23:54:10.334] iteration:3680  t-loss:0.0415, loss-lb:0.0345, loss-ulb:0.0078, weight:0.90, lr:0.0008
[23:54:10.707] iteration:3681  t-loss:0.0489, loss-lb:0.0303, loss-ulb:0.0208, weight:0.90, lr:0.0008
[23:54:11.081] iteration:3682  t-loss:0.0425, loss-lb:0.0328, loss-ulb:0.0108, weight:0.90, lr:0.0008
[23:54:11.470] iteration:3683  t-loss:0.0411, loss-lb:0.0258, loss-ulb:0.0170, weight:0.90, lr:0.0008
[23:54:11.859] iteration:3684  t-loss:0.0578, loss-lb:0.0299, loss-ulb:0.0311, weight:0.90, lr:0.0008
[23:54:12.242] iteration:3685  t-loss:0.0340, loss-lb:0.0301, loss-ulb:0.0044, weight:0.90, lr:0.0008
[23:54:12.616] iteration:3686  t-loss:0.0394, loss-lb:0.0274, loss-ulb:0.0134, weight:0.90, lr:0.0008
[23:55:17.471] iteration 3686 : dice_score: 0.769659 best_dice: 0.814600
[23:55:17.471]  <<Test>> - Ep:96  - Dice-S/T:80.33/76.97, Best-S:84.62, Best-T:81.46
[23:55:17.471]           - AvgLoss(lb/ulb/all):0.05/0.01/0.06
[23:55:18.726] iteration:3687  t-loss:0.0745, loss-lb:0.0618, loss-ulb:0.0142, weight:0.90, lr:0.0008
[23:55:19.107] iteration:3688  t-loss:0.0305, loss-lb:0.0277, loss-ulb:0.0031, weight:0.90, lr:0.0008
[23:55:19.488] iteration:3689  t-loss:0.0876, loss-lb:0.0768, loss-ulb:0.0121, weight:0.90, lr:0.0008
[23:55:19.868] iteration:3690  t-loss:0.0703, loss-lb:0.0667, loss-ulb:0.0039, weight:0.90, lr:0.0008
[23:55:20.248] iteration:3691  t-loss:0.0495, loss-lb:0.0335, loss-ulb:0.0178, weight:0.90, lr:0.0008
[23:55:20.628] iteration:3692  t-loss:0.0463, loss-lb:0.0224, loss-ulb:0.0266, weight:0.90, lr:0.0008
[23:55:21.010] iteration:3693  t-loss:0.0854, loss-lb:0.0770, loss-ulb:0.0094, weight:0.90, lr:0.0008
[23:55:21.394] iteration:3694  t-loss:0.0707, loss-lb:0.0512, loss-ulb:0.0217, weight:0.90, lr:0.0008
[23:55:21.773] iteration:3695  t-loss:0.0478, loss-lb:0.0226, loss-ulb:0.0280, weight:0.90, lr:0.0008
[23:55:22.157] iteration:3696  t-loss:0.0651, loss-lb:0.0577, loss-ulb:0.0082, weight:0.90, lr:0.0008
[23:55:22.536] iteration:3697  t-loss:0.0582, loss-lb:0.0387, loss-ulb:0.0216, weight:0.90, lr:0.0008
[23:55:22.915] iteration:3698  t-loss:0.0485, loss-lb:0.0412, loss-ulb:0.0081, weight:0.90, lr:0.0008
[23:55:23.290] iteration:3699  t-loss:0.0783, loss-lb:0.0634, loss-ulb:0.0167, weight:0.90, lr:0.0008
[23:55:23.668] iteration:3700  t-loss:0.0323, loss-lb:0.0290, loss-ulb:0.0037, weight:0.90, lr:0.0008
[23:55:24.050] iteration:3701  t-loss:0.0726, loss-lb:0.0544, loss-ulb:0.0202, weight:0.90, lr:0.0008
[23:55:24.439] iteration:3702  t-loss:0.0649, loss-lb:0.0544, loss-ulb:0.0117, weight:0.90, lr:0.0008
[23:55:24.814] iteration:3703  t-loss:0.0359, loss-lb:0.0293, loss-ulb:0.0073, weight:0.90, lr:0.0008
[23:55:25.193] iteration:3704  t-loss:0.0319, loss-lb:0.0290, loss-ulb:0.0032, weight:0.90, lr:0.0008
[23:55:25.577] iteration:3705  t-loss:0.0562, loss-lb:0.0445, loss-ulb:0.0131, weight:0.90, lr:0.0008
[23:55:25.962] iteration:3706  t-loss:0.0561, loss-lb:0.0416, loss-ulb:0.0161, weight:0.90, lr:0.0008
[23:55:26.336] iteration:3707  t-loss:0.0575, loss-lb:0.0323, loss-ulb:0.0281, weight:0.90, lr:0.0008
[23:55:26.715] iteration:3708  t-loss:0.0274, loss-lb:0.0253, loss-ulb:0.0023, weight:0.90, lr:0.0008
[23:55:27.097] iteration:3709  t-loss:0.0438, loss-lb:0.0288, loss-ulb:0.0167, weight:0.90, lr:0.0008
[23:55:27.479] iteration:3710  t-loss:0.0482, loss-lb:0.0268, loss-ulb:0.0239, weight:0.90, lr:0.0008
[23:55:27.861] iteration:3711  t-loss:0.0340, loss-lb:0.0233, loss-ulb:0.0119, weight:0.90, lr:0.0008
[23:55:28.247] iteration:3712  t-loss:0.0474, loss-lb:0.0340, loss-ulb:0.0149, weight:0.90, lr:0.0008
[23:55:28.630] iteration:3713  t-loss:0.0271, loss-lb:0.0251, loss-ulb:0.0022, weight:0.90, lr:0.0008
[23:55:29.009] iteration:3714  t-loss:0.0345, loss-lb:0.0312, loss-ulb:0.0037, weight:0.90, lr:0.0008
[23:55:29.381] iteration:3715  t-loss:0.0417, loss-lb:0.0364, loss-ulb:0.0058, weight:0.90, lr:0.0008
[23:55:29.759] iteration:3716  t-loss:0.0799, loss-lb:0.0710, loss-ulb:0.0099, weight:0.90, lr:0.0008
[23:55:30.132] iteration:3717  t-loss:0.0517, loss-lb:0.0407, loss-ulb:0.0122, weight:0.90, lr:0.0008
[23:55:30.506] iteration:3718  t-loss:0.0656, loss-lb:0.0643, loss-ulb:0.0015, weight:0.90, lr:0.0008
[23:55:30.874] iteration:3719  t-loss:0.0652, loss-lb:0.0529, loss-ulb:0.0137, weight:0.90, lr:0.0008
[23:55:31.244] iteration:3720  t-loss:0.0759, loss-lb:0.0628, loss-ulb:0.0146, weight:0.90, lr:0.0008
[23:55:31.612] iteration:3721  t-loss:0.0349, loss-lb:0.0296, loss-ulb:0.0060, weight:0.90, lr:0.0008
[23:55:31.989] iteration:3722  t-loss:0.0518, loss-lb:0.0417, loss-ulb:0.0112, weight:0.90, lr:0.0008
[23:55:32.361] iteration:3723  t-loss:0.0579, loss-lb:0.0315, loss-ulb:0.0293, weight:0.90, lr:0.0008
[23:55:32.731] iteration:3724  t-loss:0.0332, loss-lb:0.0262, loss-ulb:0.0078, weight:0.90, lr:0.0008
[23:55:33.947] iteration:3725  t-loss:0.0343, loss-lb:0.0239, loss-ulb:0.0116, weight:0.90, lr:0.0008
[23:55:34.334] iteration:3726  t-loss:0.0680, loss-lb:0.0509, loss-ulb:0.0190, weight:0.90, lr:0.0008
[23:55:34.713] iteration:3727  t-loss:0.0418, loss-lb:0.0298, loss-ulb:0.0134, weight:0.90, lr:0.0008
[23:55:35.091] iteration:3728  t-loss:0.0705, loss-lb:0.0311, loss-ulb:0.0438, weight:0.90, lr:0.0008
[23:55:35.467] iteration:3729  t-loss:0.0308, loss-lb:0.0246, loss-ulb:0.0070, weight:0.90, lr:0.0008
[23:55:35.844] iteration:3730  t-loss:0.0582, loss-lb:0.0550, loss-ulb:0.0035, weight:0.90, lr:0.0008
[23:55:36.217] iteration:3731  t-loss:0.0338, loss-lb:0.0233, loss-ulb:0.0117, weight:0.90, lr:0.0008
[23:55:36.598] iteration:3732  t-loss:0.0404, loss-lb:0.0333, loss-ulb:0.0078, weight:0.90, lr:0.0008
[23:55:36.970] iteration:3733  t-loss:0.0549, loss-lb:0.0511, loss-ulb:0.0042, weight:0.90, lr:0.0008
[23:55:37.352] iteration:3734  t-loss:0.0878, loss-lb:0.0701, loss-ulb:0.0197, weight:0.90, lr:0.0008
[23:55:37.729] iteration:3735  t-loss:0.0438, loss-lb:0.0275, loss-ulb:0.0181, weight:0.90, lr:0.0008
[23:55:38.108] iteration:3736  t-loss:0.0535, loss-lb:0.0372, loss-ulb:0.0181, weight:0.90, lr:0.0008
[23:55:38.484] iteration:3737  t-loss:0.0327, loss-lb:0.0225, loss-ulb:0.0113, weight:0.90, lr:0.0008
[23:55:38.860] iteration:3738  t-loss:0.0601, loss-lb:0.0566, loss-ulb:0.0039, weight:0.90, lr:0.0008
[23:55:39.232] iteration:3739  t-loss:0.0333, loss-lb:0.0210, loss-ulb:0.0137, weight:0.90, lr:0.0008
[23:55:39.610] iteration:3740  t-loss:0.0719, loss-lb:0.0676, loss-ulb:0.0047, weight:0.90, lr:0.0008
[23:55:39.986] iteration:3741  t-loss:0.0329, loss-lb:0.0234, loss-ulb:0.0106, weight:0.90, lr:0.0008
[23:55:40.365] iteration:3742  t-loss:0.0573, loss-lb:0.0387, loss-ulb:0.0207, weight:0.90, lr:0.0008
[23:55:40.743] iteration:3743  t-loss:0.0379, loss-lb:0.0243, loss-ulb:0.0152, weight:0.90, lr:0.0008
[23:55:41.116] iteration:3744  t-loss:0.0360, loss-lb:0.0196, loss-ulb:0.0183, weight:0.90, lr:0.0008
[23:55:41.495] iteration:3745  t-loss:0.0437, loss-lb:0.0359, loss-ulb:0.0086, weight:0.90, lr:0.0008
[23:55:41.867] iteration:3746  t-loss:0.0296, loss-lb:0.0270, loss-ulb:0.0029, weight:0.90, lr:0.0008
[23:55:42.242] iteration:3747  t-loss:0.0650, loss-lb:0.0595, loss-ulb:0.0061, weight:0.90, lr:0.0008
[23:55:42.623] iteration:3748  t-loss:0.0384, loss-lb:0.0231, loss-ulb:0.0170, weight:0.90, lr:0.0008
[23:55:43.018] iteration:3749  t-loss:0.0276, loss-lb:0.0171, loss-ulb:0.0117, weight:0.90, lr:0.0008
[23:55:43.423] iteration:3750  t-loss:0.0505, loss-lb:0.0474, loss-ulb:0.0035, weight:0.90, lr:0.0008
[23:55:43.818] iteration:3751  t-loss:0.0657, loss-lb:0.0501, loss-ulb:0.0158, weight:0.99, lr:0.0008
[23:55:44.203] iteration:3752  t-loss:0.0662, loss-lb:0.0603, loss-ulb:0.0060, weight:0.99, lr:0.0008
[23:55:44.588] iteration:3753  t-loss:0.0682, loss-lb:0.0371, loss-ulb:0.0314, weight:0.99, lr:0.0008
[23:55:44.966] iteration:3754  t-loss:0.0914, loss-lb:0.0614, loss-ulb:0.0303, weight:0.99, lr:0.0008
[23:55:45.350] iteration:3755  t-loss:0.0382, loss-lb:0.0295, loss-ulb:0.0088, weight:0.99, lr:0.0008
[23:55:45.727] iteration:3756  t-loss:0.0469, loss-lb:0.0452, loss-ulb:0.0018, weight:0.99, lr:0.0008
[23:55:46.102] iteration:3757  t-loss:0.0428, loss-lb:0.0267, loss-ulb:0.0162, weight:0.99, lr:0.0008
[23:55:46.479] iteration:3758  t-loss:0.0281, loss-lb:0.0261, loss-ulb:0.0020, weight:0.99, lr:0.0008
[23:55:46.861] iteration:3759  t-loss:0.0439, loss-lb:0.0322, loss-ulb:0.0118, weight:0.99, lr:0.0008
[23:55:47.234] iteration:3760  t-loss:0.0415, loss-lb:0.0281, loss-ulb:0.0136, weight:0.99, lr:0.0008
[23:55:47.608] iteration:3761  t-loss:0.0544, loss-lb:0.0301, loss-ulb:0.0245, weight:0.99, lr:0.0008
[23:55:47.987] iteration:3762  t-loss:0.0630, loss-lb:0.0560, loss-ulb:0.0071, weight:0.99, lr:0.0008
[23:55:49.103] iteration:3763  t-loss:0.0349, loss-lb:0.0216, loss-ulb:0.0134, weight:0.99, lr:0.0008
[23:55:49.502] iteration:3764  t-loss:0.0536, loss-lb:0.0363, loss-ulb:0.0175, weight:0.99, lr:0.0008
[23:55:49.885] iteration:3765  t-loss:0.0419, loss-lb:0.0178, loss-ulb:0.0244, weight:0.99, lr:0.0008
[23:55:50.268] iteration:3766  t-loss:0.0478, loss-lb:0.0209, loss-ulb:0.0272, weight:0.99, lr:0.0008
[23:55:50.650] iteration:3767  t-loss:0.0562, loss-lb:0.0225, loss-ulb:0.0340, weight:0.99, lr:0.0008
[23:55:51.032] iteration:3768  t-loss:0.0540, loss-lb:0.0514, loss-ulb:0.0027, weight:0.99, lr:0.0008
[23:55:51.415] iteration:3769  t-loss:0.0775, loss-lb:0.0444, loss-ulb:0.0335, weight:0.99, lr:0.0008
[23:55:51.797] iteration:3770  t-loss:0.0629, loss-lb:0.0467, loss-ulb:0.0164, weight:0.99, lr:0.0008
[23:55:52.177] iteration:3771  t-loss:0.0465, loss-lb:0.0453, loss-ulb:0.0012, weight:0.99, lr:0.0008
[23:55:52.558] iteration:3772  t-loss:0.0399, loss-lb:0.0315, loss-ulb:0.0085, weight:0.99, lr:0.0008
[23:55:52.942] iteration:3773  t-loss:0.0491, loss-lb:0.0398, loss-ulb:0.0093, weight:0.99, lr:0.0008
[23:55:53.319] iteration:3774  t-loss:0.0303, loss-lb:0.0239, loss-ulb:0.0064, weight:0.99, lr:0.0008
[23:55:53.703] iteration:3775  t-loss:0.0403, loss-lb:0.0211, loss-ulb:0.0194, weight:0.99, lr:0.0008
[23:55:54.087] iteration:3776  t-loss:0.0351, loss-lb:0.0329, loss-ulb:0.0022, weight:0.99, lr:0.0008
[23:55:54.468] iteration:3777  t-loss:0.0368, loss-lb:0.0270, loss-ulb:0.0100, weight:0.99, lr:0.0008
[23:55:54.854] iteration:3778  t-loss:0.0486, loss-lb:0.0361, loss-ulb:0.0126, weight:0.99, lr:0.0008
[23:55:55.234] iteration:3779  t-loss:0.0488, loss-lb:0.0418, loss-ulb:0.0070, weight:0.99, lr:0.0008
[23:55:55.608] iteration:3780  t-loss:0.0258, loss-lb:0.0214, loss-ulb:0.0045, weight:0.99, lr:0.0008
[23:55:55.983] iteration:3781  t-loss:0.0485, loss-lb:0.0257, loss-ulb:0.0230, weight:0.99, lr:0.0008
[23:55:56.360] iteration:3782  t-loss:0.0780, loss-lb:0.0576, loss-ulb:0.0206, weight:0.99, lr:0.0008
[23:55:56.733] iteration:3783  t-loss:0.0329, loss-lb:0.0231, loss-ulb:0.0098, weight:0.99, lr:0.0008
[23:55:57.113] iteration:3784  t-loss:0.0529, loss-lb:0.0452, loss-ulb:0.0078, weight:0.99, lr:0.0008
[23:55:57.496] iteration:3785  t-loss:0.0919, loss-lb:0.0657, loss-ulb:0.0265, weight:0.99, lr:0.0008
[23:55:57.878] iteration:3786  t-loss:0.0693, loss-lb:0.0454, loss-ulb:0.0241, weight:0.99, lr:0.0008
[23:55:58.268] iteration:3787  t-loss:0.0449, loss-lb:0.0425, loss-ulb:0.0024, weight:0.99, lr:0.0008
[23:55:58.670] iteration:3788  t-loss:0.0333, loss-lb:0.0318, loss-ulb:0.0015, weight:0.99, lr:0.0008
[23:55:59.065] iteration:3789  t-loss:0.0584, loss-lb:0.0532, loss-ulb:0.0053, weight:0.99, lr:0.0008
[23:55:59.452] iteration:3790  t-loss:0.0619, loss-lb:0.0581, loss-ulb:0.0039, weight:0.99, lr:0.0008
[23:55:59.837] iteration:3791  t-loss:0.0546, loss-lb:0.0475, loss-ulb:0.0072, weight:0.99, lr:0.0008
[23:56:00.218] iteration:3792  t-loss:0.0682, loss-lb:0.0423, loss-ulb:0.0261, weight:0.99, lr:0.0008
[23:56:00.595] iteration:3793  t-loss:0.0720, loss-lb:0.0556, loss-ulb:0.0165, weight:0.99, lr:0.0008
[23:56:00.970] iteration:3794  t-loss:0.0380, loss-lb:0.0268, loss-ulb:0.0114, weight:0.99, lr:0.0008
[23:56:01.347] iteration:3795  t-loss:0.0493, loss-lb:0.0301, loss-ulb:0.0194, weight:0.99, lr:0.0008
[23:56:01.724] iteration:3796  t-loss:0.0550, loss-lb:0.0368, loss-ulb:0.0184, weight:0.99, lr:0.0008
[23:56:02.103] iteration:3797  t-loss:0.0846, loss-lb:0.0425, loss-ulb:0.0425, weight:0.99, lr:0.0008
[23:56:02.481] iteration:3798  t-loss:0.0246, loss-lb:0.0200, loss-ulb:0.0047, weight:0.99, lr:0.0008
[23:56:02.856] iteration:3799  t-loss:0.0305, loss-lb:0.0266, loss-ulb:0.0040, weight:0.99, lr:0.0008
[23:56:03.241] iteration:3800  t-loss:0.0284, loss-lb:0.0205, loss-ulb:0.0079, weight:0.99, lr:0.0008
[23:56:04.554] iteration:3801  t-loss:0.0245, loss-lb:0.0232, loss-ulb:0.0014, weight:0.99, lr:0.0008
[23:56:04.961] iteration:3802  t-loss:0.0386, loss-lb:0.0309, loss-ulb:0.0077, weight:0.99, lr:0.0008
[23:56:05.343] iteration:3803  t-loss:0.0377, loss-lb:0.0246, loss-ulb:0.0132, weight:0.99, lr:0.0008
[23:56:05.727] iteration:3804  t-loss:0.0212, loss-lb:0.0179, loss-ulb:0.0033, weight:0.99, lr:0.0008
[23:56:06.109] iteration:3805  t-loss:0.0792, loss-lb:0.0380, loss-ulb:0.0416, weight:0.99, lr:0.0008
[23:56:06.489] iteration:3806  t-loss:0.0476, loss-lb:0.0459, loss-ulb:0.0017, weight:0.99, lr:0.0008
[23:56:06.861] iteration:3807  t-loss:0.0470, loss-lb:0.0223, loss-ulb:0.0249, weight:0.99, lr:0.0008
[23:56:07.238] iteration:3808  t-loss:0.0432, loss-lb:0.0257, loss-ulb:0.0177, weight:0.99, lr:0.0008
[23:56:07.620] iteration:3809  t-loss:0.0506, loss-lb:0.0469, loss-ulb:0.0037, weight:0.99, lr:0.0008
[23:56:08.000] iteration:3810  t-loss:0.0488, loss-lb:0.0463, loss-ulb:0.0025, weight:0.99, lr:0.0008
[23:56:08.375] iteration:3811  t-loss:0.0243, loss-lb:0.0195, loss-ulb:0.0048, weight:0.99, lr:0.0008
[23:56:08.755] iteration:3812  t-loss:0.0419, loss-lb:0.0393, loss-ulb:0.0026, weight:0.99, lr:0.0008
[23:56:09.136] iteration:3813  t-loss:0.0386, loss-lb:0.0255, loss-ulb:0.0133, weight:0.99, lr:0.0008
[23:56:09.516] iteration:3814  t-loss:0.0364, loss-lb:0.0271, loss-ulb:0.0094, weight:0.99, lr:0.0008
[23:56:09.878] iteration:3815  t-loss:0.0552, loss-lb:0.0301, loss-ulb:0.0253, weight:0.99, lr:0.0008
[23:56:10.260] iteration:3816  t-loss:0.0748, loss-lb:0.0566, loss-ulb:0.0183, weight:0.99, lr:0.0008
[23:56:10.633] iteration:3817  t-loss:0.0252, loss-lb:0.0216, loss-ulb:0.0036, weight:0.99, lr:0.0008
[23:56:11.012] iteration:3818  t-loss:0.0541, loss-lb:0.0305, loss-ulb:0.0238, weight:0.99, lr:0.0008
[23:56:11.387] iteration:3819  t-loss:0.0224, loss-lb:0.0205, loss-ulb:0.0020, weight:0.99, lr:0.0008
[23:56:11.759] iteration:3820  t-loss:0.0336, loss-lb:0.0236, loss-ulb:0.0101, weight:0.99, lr:0.0008
[23:56:12.133] iteration:3821  t-loss:0.0507, loss-lb:0.0297, loss-ulb:0.0212, weight:0.99, lr:0.0008
[23:56:12.506] iteration:3822  t-loss:0.0247, loss-lb:0.0215, loss-ulb:0.0033, weight:0.99, lr:0.0008
[23:56:12.877] iteration:3823  t-loss:0.0278, loss-lb:0.0229, loss-ulb:0.0049, weight:0.99, lr:0.0008
[23:56:13.251] iteration:3824  t-loss:0.0484, loss-lb:0.0461, loss-ulb:0.0023, weight:0.99, lr:0.0008
[23:56:13.624] iteration:3825  t-loss:0.0266, loss-lb:0.0245, loss-ulb:0.0021, weight:0.99, lr:0.0008
[23:56:13.999] iteration:3826  t-loss:0.0237, loss-lb:0.0171, loss-ulb:0.0066, weight:0.99, lr:0.0008
[23:56:14.387] iteration:3827  t-loss:0.0559, loss-lb:0.0434, loss-ulb:0.0127, weight:0.99, lr:0.0008
[23:56:14.763] iteration:3828  t-loss:0.0259, loss-lb:0.0233, loss-ulb:0.0026, weight:0.99, lr:0.0008
[23:56:15.143] iteration:3829  t-loss:0.0421, loss-lb:0.0235, loss-ulb:0.0188, weight:0.99, lr:0.0008
[23:56:15.523] iteration:3830  t-loss:0.0614, loss-lb:0.0539, loss-ulb:0.0076, weight:0.99, lr:0.0008
[23:56:15.897] iteration:3831  t-loss:0.0351, loss-lb:0.0220, loss-ulb:0.0133, weight:0.99, lr:0.0008
[23:56:16.271] iteration:3832  t-loss:0.0255, loss-lb:0.0230, loss-ulb:0.0025, weight:0.99, lr:0.0008
[23:56:16.642] iteration:3833  t-loss:0.0243, loss-lb:0.0201, loss-ulb:0.0043, weight:0.99, lr:0.0008
[23:56:17.016] iteration:3834  t-loss:0.0475, loss-lb:0.0311, loss-ulb:0.0165, weight:0.99, lr:0.0008
[23:56:17.388] iteration:3835  t-loss:0.0740, loss-lb:0.0612, loss-ulb:0.0130, weight:0.99, lr:0.0008
[23:56:17.761] iteration:3836  t-loss:0.0331, loss-lb:0.0215, loss-ulb:0.0117, weight:0.99, lr:0.0008
[23:56:18.136] iteration:3837  t-loss:0.0455, loss-lb:0.0353, loss-ulb:0.0103, weight:0.99, lr:0.0008
[23:56:18.523] iteration:3838  t-loss:0.0674, loss-lb:0.0392, loss-ulb:0.0285, weight:0.99, lr:0.0008
[23:57:19.288] iteration 3838 : dice_score: 0.756139 best_dice: 0.814600
[23:57:19.288]  <<Test>> - Ep:100  - Dice-S/T:77.68/75.61, Best-S:84.62, Best-T:81.46
[23:57:19.288]           - AvgLoss(lb/ulb/all):0.03/0.01/0.04
[23:57:20.468] iteration:3839  t-loss:0.0602, loss-lb:0.0476, loss-ulb:0.0128, weight:0.99, lr:0.0008
[23:57:20.880] iteration:3840  t-loss:0.0455, loss-lb:0.0294, loss-ulb:0.0163, weight:0.99, lr:0.0008
[23:57:21.268] iteration:3841  t-loss:0.0357, loss-lb:0.0340, loss-ulb:0.0017, weight:0.99, lr:0.0008
[23:57:21.652] iteration:3842  t-loss:0.0638, loss-lb:0.0432, loss-ulb:0.0207, weight:0.99, lr:0.0008
[23:57:22.047] iteration:3843  t-loss:0.0733, loss-lb:0.0336, loss-ulb:0.0401, weight:0.99, lr:0.0008
[23:57:22.422] iteration:3844  t-loss:0.0262, loss-lb:0.0212, loss-ulb:0.0051, weight:0.99, lr:0.0008
[23:57:22.802] iteration:3845  t-loss:0.0295, loss-lb:0.0243, loss-ulb:0.0052, weight:0.99, lr:0.0008
[23:57:23.186] iteration:3846  t-loss:0.0796, loss-lb:0.0772, loss-ulb:0.0025, weight:0.99, lr:0.0008
[23:57:23.571] iteration:3847  t-loss:0.0545, loss-lb:0.0416, loss-ulb:0.0131, weight:0.99, lr:0.0008
[23:57:23.949] iteration:3848  t-loss:0.0247, loss-lb:0.0194, loss-ulb:0.0054, weight:0.99, lr:0.0008
[23:57:24.334] iteration:3849  t-loss:0.0622, loss-lb:0.0600, loss-ulb:0.0023, weight:0.99, lr:0.0008
[23:57:24.715] iteration:3850  t-loss:0.0314, loss-lb:0.0235, loss-ulb:0.0079, weight:0.99, lr:0.0008
[23:57:25.093] iteration:3851  t-loss:0.0755, loss-lb:0.0727, loss-ulb:0.0028, weight:0.99, lr:0.0008
[23:57:25.470] iteration:3852  t-loss:0.0284, loss-lb:0.0207, loss-ulb:0.0078, weight:0.99, lr:0.0008
[23:57:25.848] iteration:3853  t-loss:0.0456, loss-lb:0.0404, loss-ulb:0.0052, weight:0.99, lr:0.0008
[23:57:26.224] iteration:3854  t-loss:0.0473, loss-lb:0.0430, loss-ulb:0.0043, weight:0.99, lr:0.0008
[23:57:26.601] iteration:3855  t-loss:0.0277, loss-lb:0.0244, loss-ulb:0.0033, weight:0.99, lr:0.0008
[23:57:26.982] iteration:3856  t-loss:0.0475, loss-lb:0.0365, loss-ulb:0.0112, weight:0.99, lr:0.0008
[23:57:27.361] iteration:3857  t-loss:0.0313, loss-lb:0.0248, loss-ulb:0.0066, weight:0.99, lr:0.0008
[23:57:27.739] iteration:3858  t-loss:0.0413, loss-lb:0.0395, loss-ulb:0.0018, weight:0.99, lr:0.0008
[23:57:28.115] iteration:3859  t-loss:0.0265, loss-lb:0.0190, loss-ulb:0.0076, weight:0.99, lr:0.0008
[23:57:28.492] iteration:3860  t-loss:0.0600, loss-lb:0.0556, loss-ulb:0.0044, weight:0.99, lr:0.0008
[23:57:28.873] iteration:3861  t-loss:0.0615, loss-lb:0.0441, loss-ulb:0.0175, weight:0.99, lr:0.0008
[23:57:29.250] iteration:3862  t-loss:0.0544, loss-lb:0.0518, loss-ulb:0.0026, weight:0.99, lr:0.0008
[23:57:29.630] iteration:3863  t-loss:0.0245, loss-lb:0.0233, loss-ulb:0.0013, weight:0.99, lr:0.0008
[23:57:30.012] iteration:3864  t-loss:0.0457, loss-lb:0.0328, loss-ulb:0.0131, weight:0.99, lr:0.0008
[23:57:30.391] iteration:3865  t-loss:0.0402, loss-lb:0.0242, loss-ulb:0.0162, weight:0.99, lr:0.0008
[23:57:30.773] iteration:3866  t-loss:0.0319, loss-lb:0.0180, loss-ulb:0.0141, weight:0.99, lr:0.0008
[23:57:31.163] iteration:3867  t-loss:0.0614, loss-lb:0.0460, loss-ulb:0.0156, weight:0.99, lr:0.0008
[23:57:31.552] iteration:3868  t-loss:0.0492, loss-lb:0.0388, loss-ulb:0.0105, weight:0.99, lr:0.0008
[23:57:31.927] iteration:3869  t-loss:0.0485, loss-lb:0.0423, loss-ulb:0.0062, weight:0.99, lr:0.0008
[23:57:32.305] iteration:3870  t-loss:0.0568, loss-lb:0.0340, loss-ulb:0.0230, weight:0.99, lr:0.0008
[23:57:32.685] iteration:3871  t-loss:0.0640, loss-lb:0.0497, loss-ulb:0.0145, weight:0.99, lr:0.0008
[23:57:33.060] iteration:3872  t-loss:0.0230, loss-lb:0.0184, loss-ulb:0.0047, weight:0.99, lr:0.0008
[23:57:33.433] iteration:3873  t-loss:0.0337, loss-lb:0.0263, loss-ulb:0.0074, weight:0.99, lr:0.0008
[23:57:33.813] iteration:3874  t-loss:0.0377, loss-lb:0.0342, loss-ulb:0.0036, weight:0.99, lr:0.0008
[23:57:34.188] iteration:3875  t-loss:0.0502, loss-lb:0.0439, loss-ulb:0.0063, weight:0.99, lr:0.0008
[23:57:34.567] iteration:3876  t-loss:0.0238, loss-lb:0.0198, loss-ulb:0.0041, weight:0.99, lr:0.0008
[23:57:36.261] iteration:3877  t-loss:0.0354, loss-lb:0.0173, loss-ulb:0.0182, weight:0.99, lr:0.0008
[23:57:36.642] iteration:3878  t-loss:0.0574, loss-lb:0.0371, loss-ulb:0.0205, weight:0.99, lr:0.0008
[23:57:37.027] iteration:3879  t-loss:0.0492, loss-lb:0.0288, loss-ulb:0.0206, weight:0.99, lr:0.0008
[23:57:37.410] iteration:3880  t-loss:0.0463, loss-lb:0.0389, loss-ulb:0.0075, weight:0.99, lr:0.0008
[23:57:37.793] iteration:3881  t-loss:0.0603, loss-lb:0.0363, loss-ulb:0.0242, weight:0.99, lr:0.0008
[23:57:38.172] iteration:3882  t-loss:0.0279, loss-lb:0.0242, loss-ulb:0.0037, weight:0.99, lr:0.0008
[23:57:38.551] iteration:3883  t-loss:0.0447, loss-lb:0.0224, loss-ulb:0.0225, weight:0.99, lr:0.0008
[23:57:38.932] iteration:3884  t-loss:0.0541, loss-lb:0.0492, loss-ulb:0.0049, weight:0.99, lr:0.0008
[23:57:39.311] iteration:3885  t-loss:0.0650, loss-lb:0.0403, loss-ulb:0.0249, weight:0.99, lr:0.0008
[23:57:39.696] iteration:3886  t-loss:0.0531, loss-lb:0.0383, loss-ulb:0.0149, weight:0.99, lr:0.0008
[23:57:40.078] iteration:3887  t-loss:0.0458, loss-lb:0.0417, loss-ulb:0.0042, weight:0.99, lr:0.0008
[23:57:40.458] iteration:3888  t-loss:0.0433, loss-lb:0.0267, loss-ulb:0.0168, weight:0.99, lr:0.0008
[23:57:40.840] iteration:3889  t-loss:0.0289, loss-lb:0.0171, loss-ulb:0.0120, weight:0.99, lr:0.0008
[23:57:41.214] iteration:3890  t-loss:0.0549, loss-lb:0.0416, loss-ulb:0.0135, weight:0.99, lr:0.0008
[23:57:41.595] iteration:3891  t-loss:0.0502, loss-lb:0.0319, loss-ulb:0.0185, weight:0.99, lr:0.0008
[23:57:41.975] iteration:3892  t-loss:0.0734, loss-lb:0.0664, loss-ulb:0.0070, weight:0.99, lr:0.0008
[23:57:42.356] iteration:3893  t-loss:0.0737, loss-lb:0.0291, loss-ulb:0.0451, weight:0.99, lr:0.0008
[23:57:42.732] iteration:3894  t-loss:0.0437, loss-lb:0.0389, loss-ulb:0.0048, weight:0.99, lr:0.0008
[23:57:43.111] iteration:3895  t-loss:0.0566, loss-lb:0.0536, loss-ulb:0.0030, weight:0.99, lr:0.0008
[23:57:43.487] iteration:3896  t-loss:0.0489, loss-lb:0.0442, loss-ulb:0.0048, weight:0.99, lr:0.0008
[23:57:43.865] iteration:3897  t-loss:0.0342, loss-lb:0.0203, loss-ulb:0.0141, weight:0.99, lr:0.0008
[23:57:44.242] iteration:3898  t-loss:0.0274, loss-lb:0.0202, loss-ulb:0.0072, weight:0.99, lr:0.0008
[23:57:44.619] iteration:3899  t-loss:0.0576, loss-lb:0.0553, loss-ulb:0.0023, weight:0.99, lr:0.0008
[23:57:44.995] iteration:3900  t-loss:0.0802, loss-lb:0.0680, loss-ulb:0.0124, weight:0.99, lr:0.0008
[23:57:45.377] iteration:3901  t-loss:0.1104, loss-lb:0.0904, loss-ulb:0.0185, weight:1.08, lr:0.0008
[23:57:45.752] iteration:3902  t-loss:0.0572, loss-lb:0.0461, loss-ulb:0.0102, weight:1.08, lr:0.0008
[23:57:46.129] iteration:3903  t-loss:0.0482, loss-lb:0.0450, loss-ulb:0.0029, weight:1.08, lr:0.0008
[23:57:46.508] iteration:3904  t-loss:0.0868, loss-lb:0.0689, loss-ulb:0.0165, weight:1.08, lr:0.0008
[23:57:46.883] iteration:3905  t-loss:0.0328, loss-lb:0.0269, loss-ulb:0.0055, weight:1.08, lr:0.0008
[23:57:47.259] iteration:3906  t-loss:0.0703, loss-lb:0.0553, loss-ulb:0.0138, weight:1.08, lr:0.0008
[23:57:47.630] iteration:3907  t-loss:0.0424, loss-lb:0.0277, loss-ulb:0.0136, weight:1.08, lr:0.0008
[23:57:48.009] iteration:3908  t-loss:0.1021, loss-lb:0.0811, loss-ulb:0.0194, weight:1.08, lr:0.0008
[23:57:48.384] iteration:3909  t-loss:0.0626, loss-lb:0.0550, loss-ulb:0.0070, weight:1.08, lr:0.0008
[23:57:48.756] iteration:3910  t-loss:0.0451, loss-lb:0.0395, loss-ulb:0.0051, weight:1.08, lr:0.0008
[23:57:49.130] iteration:3911  t-loss:0.0499, loss-lb:0.0452, loss-ulb:0.0043, weight:1.08, lr:0.0008
[23:57:49.501] iteration:3912  t-loss:0.0779, loss-lb:0.0495, loss-ulb:0.0262, weight:1.08, lr:0.0008
[23:57:49.881] iteration:3913  t-loss:0.0528, loss-lb:0.0370, loss-ulb:0.0146, weight:1.08, lr:0.0008
[23:57:50.266] iteration:3914  t-loss:0.0403, loss-lb:0.0345, loss-ulb:0.0053, weight:1.08, lr:0.0008
[23:57:51.725] iteration:3915  t-loss:0.0503, loss-lb:0.0443, loss-ulb:0.0056, weight:1.08, lr:0.0008
[23:57:52.116] iteration:3916  t-loss:0.0686, loss-lb:0.0521, loss-ulb:0.0153, weight:1.08, lr:0.0008
[23:57:52.497] iteration:3917  t-loss:0.0244, loss-lb:0.0227, loss-ulb:0.0016, weight:1.08, lr:0.0008
[23:57:52.874] iteration:3918  t-loss:0.0631, loss-lb:0.0589, loss-ulb:0.0039, weight:1.08, lr:0.0008
[23:57:53.252] iteration:3919  t-loss:0.0531, loss-lb:0.0506, loss-ulb:0.0022, weight:1.08, lr:0.0008
[23:57:53.632] iteration:3920  t-loss:0.0577, loss-lb:0.0532, loss-ulb:0.0042, weight:1.08, lr:0.0008
[23:57:54.019] iteration:3921  t-loss:0.0342, loss-lb:0.0297, loss-ulb:0.0042, weight:1.08, lr:0.0008
[23:57:54.400] iteration:3922  t-loss:0.0671, loss-lb:0.0480, loss-ulb:0.0176, weight:1.08, lr:0.0008
[23:57:54.779] iteration:3923  t-loss:0.0292, loss-lb:0.0228, loss-ulb:0.0059, weight:1.08, lr:0.0008
[23:57:55.164] iteration:3924  t-loss:0.0486, loss-lb:0.0207, loss-ulb:0.0258, weight:1.08, lr:0.0008
[23:57:55.545] iteration:3925  t-loss:0.0534, loss-lb:0.0294, loss-ulb:0.0222, weight:1.08, lr:0.0008
[23:57:55.923] iteration:3926  t-loss:0.0324, loss-lb:0.0231, loss-ulb:0.0085, weight:1.08, lr:0.0008
[23:57:56.305] iteration:3927  t-loss:0.0519, loss-lb:0.0343, loss-ulb:0.0162, weight:1.08, lr:0.0008
[23:57:56.682] iteration:3928  t-loss:0.0614, loss-lb:0.0520, loss-ulb:0.0087, weight:1.08, lr:0.0008
[23:57:57.061] iteration:3929  t-loss:0.0559, loss-lb:0.0527, loss-ulb:0.0030, weight:1.08, lr:0.0008
[23:57:57.443] iteration:3930  t-loss:0.0389, loss-lb:0.0369, loss-ulb:0.0019, weight:1.08, lr:0.0008
[23:57:57.821] iteration:3931  t-loss:0.0288, loss-lb:0.0244, loss-ulb:0.0041, weight:1.08, lr:0.0008
[23:57:58.198] iteration:3932  t-loss:0.0278, loss-lb:0.0246, loss-ulb:0.0030, weight:1.08, lr:0.0008
[23:57:58.578] iteration:3933  t-loss:0.0265, loss-lb:0.0236, loss-ulb:0.0027, weight:1.08, lr:0.0008
[23:57:58.957] iteration:3934  t-loss:0.0799, loss-lb:0.0579, loss-ulb:0.0203, weight:1.08, lr:0.0008
[23:57:59.338] iteration:3935  t-loss:0.0288, loss-lb:0.0256, loss-ulb:0.0029, weight:1.08, lr:0.0008
[23:57:59.713] iteration:3936  t-loss:0.0527, loss-lb:0.0447, loss-ulb:0.0074, weight:1.08, lr:0.0008
[23:58:00.093] iteration:3937  t-loss:0.0315, loss-lb:0.0192, loss-ulb:0.0113, weight:1.08, lr:0.0008
[23:58:00.477] iteration:3938  t-loss:0.0696, loss-lb:0.0569, loss-ulb:0.0117, weight:1.08, lr:0.0008
[23:58:00.859] iteration:3939  t-loss:0.0228, loss-lb:0.0192, loss-ulb:0.0034, weight:1.08, lr:0.0008
[23:58:01.243] iteration:3940  t-loss:0.0772, loss-lb:0.0642, loss-ulb:0.0120, weight:1.08, lr:0.0008
[23:58:01.625] iteration:3941  t-loss:0.0644, loss-lb:0.0457, loss-ulb:0.0173, weight:1.08, lr:0.0008
[23:58:02.003] iteration:3942  t-loss:0.0318, loss-lb:0.0258, loss-ulb:0.0055, weight:1.08, lr:0.0008
[23:58:02.384] iteration:3943  t-loss:0.0520, loss-lb:0.0294, loss-ulb:0.0209, weight:1.08, lr:0.0008
[23:58:02.769] iteration:3944  t-loss:0.0543, loss-lb:0.0392, loss-ulb:0.0140, weight:1.08, lr:0.0008
[23:58:03.142] iteration:3945  t-loss:0.0436, loss-lb:0.0382, loss-ulb:0.0050, weight:1.08, lr:0.0008
[23:58:03.519] iteration:3946  t-loss:0.0440, loss-lb:0.0223, loss-ulb:0.0199, weight:1.08, lr:0.0008
[23:58:03.893] iteration:3947  t-loss:0.0855, loss-lb:0.0820, loss-ulb:0.0033, weight:1.08, lr:0.0008
[23:58:04.266] iteration:3948  t-loss:0.0395, loss-lb:0.0365, loss-ulb:0.0027, weight:1.08, lr:0.0008
[23:58:04.638] iteration:3949  t-loss:0.0256, loss-lb:0.0174, loss-ulb:0.0076, weight:1.08, lr:0.0008
[23:58:05.018] iteration:3950  t-loss:0.0880, loss-lb:0.0764, loss-ulb:0.0107, weight:1.08, lr:0.0008
[23:58:05.401] iteration:3951  t-loss:0.0401, loss-lb:0.0197, loss-ulb:0.0188, weight:1.08, lr:0.0008
[23:58:05.797] iteration:3952  t-loss:0.0268, loss-lb:0.0225, loss-ulb:0.0040, weight:1.08, lr:0.0008
[23:58:07.283] iteration:3953  t-loss:0.0375, loss-lb:0.0337, loss-ulb:0.0035, weight:1.08, lr:0.0008
[23:58:07.674] iteration:3954  t-loss:0.0372, loss-lb:0.0191, loss-ulb:0.0167, weight:1.08, lr:0.0008
[23:58:08.063] iteration:3955  t-loss:0.0244, loss-lb:0.0215, loss-ulb:0.0026, weight:1.08, lr:0.0008
[23:58:08.459] iteration:3956  t-loss:0.0477, loss-lb:0.0438, loss-ulb:0.0036, weight:1.08, lr:0.0008
[23:58:08.850] iteration:3957  t-loss:0.0651, loss-lb:0.0496, loss-ulb:0.0143, weight:1.08, lr:0.0008
[23:58:09.241] iteration:3958  t-loss:0.0435, loss-lb:0.0368, loss-ulb:0.0062, weight:1.08, lr:0.0008
[23:58:09.617] iteration:3959  t-loss:0.0306, loss-lb:0.0242, loss-ulb:0.0059, weight:1.08, lr:0.0008
[23:58:09.992] iteration:3960  t-loss:0.0279, loss-lb:0.0220, loss-ulb:0.0054, weight:1.08, lr:0.0008
[23:58:10.372] iteration:3961  t-loss:0.0600, loss-lb:0.0554, loss-ulb:0.0043, weight:1.08, lr:0.0008
[23:58:10.756] iteration:3962  t-loss:0.0850, loss-lb:0.0428, loss-ulb:0.0389, weight:1.08, lr:0.0008
[23:58:11.135] iteration:3963  t-loss:0.0490, loss-lb:0.0261, loss-ulb:0.0211, weight:1.08, lr:0.0008
[23:58:11.514] iteration:3964  t-loss:0.0542, loss-lb:0.0449, loss-ulb:0.0086, weight:1.08, lr:0.0008
[23:58:11.899] iteration:3965  t-loss:0.0799, loss-lb:0.0570, loss-ulb:0.0212, weight:1.08, lr:0.0008
[23:58:12.286] iteration:3966  t-loss:0.0579, loss-lb:0.0395, loss-ulb:0.0170, weight:1.08, lr:0.0008
[23:58:12.663] iteration:3967  t-loss:0.0221, loss-lb:0.0192, loss-ulb:0.0026, weight:1.08, lr:0.0008
[23:58:13.037] iteration:3968  t-loss:0.0230, loss-lb:0.0200, loss-ulb:0.0028, weight:1.08, lr:0.0008
[23:58:13.410] iteration:3969  t-loss:0.1327, loss-lb:0.0243, loss-ulb:0.1000, weight:1.08, lr:0.0008
[23:58:13.797] iteration:3970  t-loss:0.0823, loss-lb:0.0594, loss-ulb:0.0211, weight:1.08, lr:0.0008
[23:58:14.171] iteration:3971  t-loss:0.0322, loss-lb:0.0292, loss-ulb:0.0028, weight:1.08, lr:0.0008
[23:58:14.544] iteration:3972  t-loss:0.0347, loss-lb:0.0211, loss-ulb:0.0126, weight:1.08, lr:0.0008
[23:58:14.930] iteration:3973  t-loss:0.0559, loss-lb:0.0454, loss-ulb:0.0097, weight:1.08, lr:0.0008
[23:58:15.307] iteration:3974  t-loss:0.0507, loss-lb:0.0283, loss-ulb:0.0206, weight:1.08, lr:0.0008
[23:58:15.686] iteration:3975  t-loss:0.0551, loss-lb:0.0253, loss-ulb:0.0275, weight:1.08, lr:0.0008
[23:58:16.070] iteration:3976  t-loss:0.0898, loss-lb:0.0688, loss-ulb:0.0194, weight:1.08, lr:0.0008
[23:58:16.450] iteration:3977  t-loss:0.0359, loss-lb:0.0226, loss-ulb:0.0122, weight:1.08, lr:0.0008
[23:58:16.832] iteration:3978  t-loss:0.0292, loss-lb:0.0235, loss-ulb:0.0052, weight:1.08, lr:0.0008
[23:58:17.218] iteration:3979  t-loss:0.0819, loss-lb:0.0582, loss-ulb:0.0218, weight:1.08, lr:0.0008
[23:58:17.593] iteration:3980  t-loss:0.0310, loss-lb:0.0236, loss-ulb:0.0068, weight:1.08, lr:0.0008
[23:58:17.975] iteration:3981  t-loss:0.0487, loss-lb:0.0450, loss-ulb:0.0034, weight:1.08, lr:0.0008
[23:58:18.357] iteration:3982  t-loss:0.0448, loss-lb:0.0252, loss-ulb:0.0181, weight:1.08, lr:0.0008
[23:58:18.728] iteration:3983  t-loss:0.0430, loss-lb:0.0359, loss-ulb:0.0066, weight:1.08, lr:0.0008
[23:58:19.102] iteration:3984  t-loss:0.0353, loss-lb:0.0246, loss-ulb:0.0099, weight:1.08, lr:0.0008
[23:58:19.478] iteration:3985  t-loss:0.0769, loss-lb:0.0530, loss-ulb:0.0220, weight:1.08, lr:0.0008
[23:58:19.850] iteration:3986  t-loss:0.0496, loss-lb:0.0284, loss-ulb:0.0195, weight:1.08, lr:0.0008
[23:58:20.220] iteration:3987  t-loss:0.0956, loss-lb:0.0929, loss-ulb:0.0025, weight:1.08, lr:0.0008
[23:58:20.598] iteration:3988  t-loss:0.0640, loss-lb:0.0559, loss-ulb:0.0075, weight:1.08, lr:0.0008
[23:58:20.976] iteration:3989  t-loss:0.0350, loss-lb:0.0241, loss-ulb:0.0101, weight:1.08, lr:0.0008
[23:58:21.353] iteration:3990  t-loss:0.0354, loss-lb:0.0318, loss-ulb:0.0033, weight:1.08, lr:0.0008
[23:59:26.351] iteration 3990 : dice_score: 0.797104 best_dice: 0.814600
[23:59:26.351]  <<Test>> - Ep:104  - Dice-S/T:69.74/79.71, Best-S:84.62, Best-T:81.46
[23:59:26.351]           - AvgLoss(lb/ulb/all):0.04/0.01/0.05
[23:59:27.542] iteration:3991  t-loss:0.0457, loss-lb:0.0383, loss-ulb:0.0069, weight:1.08, lr:0.0008
[23:59:27.956] iteration:3992  t-loss:0.0537, loss-lb:0.0410, loss-ulb:0.0117, weight:1.08, lr:0.0008
[23:59:28.334] iteration:3993  t-loss:0.0434, loss-lb:0.0256, loss-ulb:0.0165, weight:1.08, lr:0.0008
[23:59:28.717] iteration:3994  t-loss:0.0637, loss-lb:0.0530, loss-ulb:0.0098, weight:1.08, lr:0.0008
[23:59:29.108] iteration:3995  t-loss:0.0776, loss-lb:0.0537, loss-ulb:0.0220, weight:1.08, lr:0.0008
[23:59:29.487] iteration:3996  t-loss:0.0404, loss-lb:0.0377, loss-ulb:0.0025, weight:1.08, lr:0.0008
[23:59:29.873] iteration:3997  t-loss:0.0519, loss-lb:0.0347, loss-ulb:0.0159, weight:1.08, lr:0.0008
[23:59:30.256] iteration:3998  t-loss:0.0491, loss-lb:0.0463, loss-ulb:0.0025, weight:1.08, lr:0.0008
[23:59:30.645] iteration:3999  t-loss:0.0428, loss-lb:0.0238, loss-ulb:0.0176, weight:1.08, lr:0.0008
[23:59:31.024] iteration:4000  t-loss:0.0406, loss-lb:0.0388, loss-ulb:0.0017, weight:1.08, lr:0.0008
[23:59:31.407] iteration:4001  t-loss:0.0694, loss-lb:0.0589, loss-ulb:0.0097, weight:1.08, lr:0.0008
[23:59:31.786] iteration:4002  t-loss:0.0525, loss-lb:0.0253, loss-ulb:0.0251, weight:1.08, lr:0.0008
[23:59:32.178] iteration:4003  t-loss:0.0620, loss-lb:0.0572, loss-ulb:0.0045, weight:1.08, lr:0.0008
[23:59:32.562] iteration:4004  t-loss:0.0502, loss-lb:0.0267, loss-ulb:0.0217, weight:1.08, lr:0.0008
[23:59:32.950] iteration:4005  t-loss:0.0560, loss-lb:0.0524, loss-ulb:0.0033, weight:1.08, lr:0.0008
[23:59:33.332] iteration:4006  t-loss:0.0585, loss-lb:0.0443, loss-ulb:0.0131, weight:1.08, lr:0.0008
[23:59:33.714] iteration:4007  t-loss:0.0281, loss-lb:0.0226, loss-ulb:0.0051, weight:1.08, lr:0.0008
[23:59:34.095] iteration:4008  t-loss:0.0947, loss-lb:0.0784, loss-ulb:0.0151, weight:1.08, lr:0.0008
[23:59:34.473] iteration:4009  t-loss:0.0258, loss-lb:0.0216, loss-ulb:0.0038, weight:1.08, lr:0.0008
[23:59:34.849] iteration:4010  t-loss:0.0522, loss-lb:0.0445, loss-ulb:0.0071, weight:1.08, lr:0.0008
[23:59:35.231] iteration:4011  t-loss:0.0645, loss-lb:0.0554, loss-ulb:0.0084, weight:1.08, lr:0.0008
[23:59:35.608] iteration:4012  t-loss:0.0669, loss-lb:0.0439, loss-ulb:0.0212, weight:1.08, lr:0.0008
[23:59:35.993] iteration:4013  t-loss:0.0515, loss-lb:0.0384, loss-ulb:0.0122, weight:1.08, lr:0.0008
[23:59:36.380] iteration:4014  t-loss:0.0693, loss-lb:0.0630, loss-ulb:0.0059, weight:1.08, lr:0.0008
[23:59:36.769] iteration:4015  t-loss:0.0535, loss-lb:0.0434, loss-ulb:0.0092, weight:1.08, lr:0.0008
[23:59:37.152] iteration:4016  t-loss:0.1113, loss-lb:0.0907, loss-ulb:0.0190, weight:1.08, lr:0.0008
[23:59:37.541] iteration:4017  t-loss:0.0402, loss-lb:0.0344, loss-ulb:0.0054, weight:1.08, lr:0.0008
[23:59:37.921] iteration:4018  t-loss:0.0783, loss-lb:0.0586, loss-ulb:0.0182, weight:1.08, lr:0.0008
[23:59:38.312] iteration:4019  t-loss:0.0734, loss-lb:0.0635, loss-ulb:0.0091, weight:1.08, lr:0.0008
[23:59:38.692] iteration:4020  t-loss:0.0281, loss-lb:0.0261, loss-ulb:0.0019, weight:1.08, lr:0.0008
[23:59:39.070] iteration:4021  t-loss:0.0253, loss-lb:0.0188, loss-ulb:0.0060, weight:1.08, lr:0.0008
[23:59:39.451] iteration:4022  t-loss:0.0465, loss-lb:0.0223, loss-ulb:0.0223, weight:1.08, lr:0.0008
[23:59:39.826] iteration:4023  t-loss:0.0518, loss-lb:0.0360, loss-ulb:0.0145, weight:1.08, lr:0.0008
[23:59:40.201] iteration:4024  t-loss:0.0331, loss-lb:0.0259, loss-ulb:0.0066, weight:1.08, lr:0.0008
[23:59:40.577] iteration:4025  t-loss:0.0398, loss-lb:0.0360, loss-ulb:0.0035, weight:1.08, lr:0.0008
[23:59:40.958] iteration:4026  t-loss:0.0583, loss-lb:0.0379, loss-ulb:0.0189, weight:1.08, lr:0.0008
[23:59:41.337] iteration:4027  t-loss:0.0691, loss-lb:0.0277, loss-ulb:0.0382, weight:1.08, lr:0.0008
[23:59:41.716] iteration:4028  t-loss:0.0477, loss-lb:0.0269, loss-ulb:0.0192, weight:1.08, lr:0.0008
[23:59:43.277] iteration:4029  t-loss:0.0820, loss-lb:0.0456, loss-ulb:0.0335, weight:1.08, lr:0.0008
[23:59:43.673] iteration:4030  t-loss:0.0481, loss-lb:0.0231, loss-ulb:0.0231, weight:1.08, lr:0.0008
[23:59:44.050] iteration:4031  t-loss:0.0393, loss-lb:0.0228, loss-ulb:0.0152, weight:1.08, lr:0.0008
[23:59:44.431] iteration:4032  t-loss:0.0588, loss-lb:0.0393, loss-ulb:0.0180, weight:1.08, lr:0.0008
[23:59:44.820] iteration:4033  t-loss:0.1342, loss-lb:0.0779, loss-ulb:0.0519, weight:1.08, lr:0.0008
[23:59:45.199] iteration:4034  t-loss:0.0373, loss-lb:0.0218, loss-ulb:0.0143, weight:1.08, lr:0.0008
[23:59:45.578] iteration:4035  t-loss:0.0783, loss-lb:0.0520, loss-ulb:0.0243, weight:1.08, lr:0.0008
[23:59:45.952] iteration:4036  t-loss:0.0398, loss-lb:0.0239, loss-ulb:0.0147, weight:1.08, lr:0.0008
[23:59:46.338] iteration:4037  t-loss:0.1113, loss-lb:0.0786, loss-ulb:0.0302, weight:1.08, lr:0.0008
[23:59:46.721] iteration:4038  t-loss:0.0561, loss-lb:0.0344, loss-ulb:0.0200, weight:1.08, lr:0.0008
[23:59:47.105] iteration:4039  t-loss:0.0553, loss-lb:0.0393, loss-ulb:0.0148, weight:1.08, lr:0.0008
[23:59:47.485] iteration:4040  t-loss:0.0566, loss-lb:0.0399, loss-ulb:0.0154, weight:1.08, lr:0.0008
[23:59:47.870] iteration:4041  t-loss:0.0376, loss-lb:0.0255, loss-ulb:0.0111, weight:1.08, lr:0.0008
[23:59:48.257] iteration:4042  t-loss:0.0676, loss-lb:0.0470, loss-ulb:0.0190, weight:1.08, lr:0.0008
[23:59:48.636] iteration:4043  t-loss:0.0290, loss-lb:0.0175, loss-ulb:0.0106, weight:1.08, lr:0.0008
[23:59:49.017] iteration:4044  t-loss:0.0474, loss-lb:0.0342, loss-ulb:0.0122, weight:1.08, lr:0.0008
[23:59:49.393] iteration:4045  t-loss:0.0266, loss-lb:0.0212, loss-ulb:0.0050, weight:1.08, lr:0.0008
[23:59:49.768] iteration:4046  t-loss:0.0315, loss-lb:0.0291, loss-ulb:0.0022, weight:1.08, lr:0.0008
[23:59:50.148] iteration:4047  t-loss:0.0728, loss-lb:0.0476, loss-ulb:0.0233, weight:1.08, lr:0.0008
[23:59:50.526] iteration:4048  t-loss:0.0473, loss-lb:0.0428, loss-ulb:0.0041, weight:1.08, lr:0.0008
[23:59:50.902] iteration:4049  t-loss:0.0269, loss-lb:0.0224, loss-ulb:0.0042, weight:1.08, lr:0.0008
[23:59:51.282] iteration:4050  t-loss:0.0453, loss-lb:0.0406, loss-ulb:0.0044, weight:1.08, lr:0.0008
[23:59:51.663] iteration:4051  t-loss:0.0610, loss-lb:0.0341, loss-ulb:0.0229, weight:1.18, lr:0.0008
[23:59:52.045] iteration:4052  t-loss:0.0701, loss-lb:0.0441, loss-ulb:0.0220, weight:1.18, lr:0.0008
[23:59:52.430] iteration:4053  t-loss:0.0606, loss-lb:0.0567, loss-ulb:0.0033, weight:1.18, lr:0.0008
[23:59:52.809] iteration:4054  t-loss:0.0437, loss-lb:0.0219, loss-ulb:0.0185, weight:1.18, lr:0.0008
[23:59:53.193] iteration:4055  t-loss:0.0554, loss-lb:0.0424, loss-ulb:0.0110, weight:1.18, lr:0.0008
[23:59:53.574] iteration:4056  t-loss:0.0717, loss-lb:0.0634, loss-ulb:0.0070, weight:1.18, lr:0.0008
[23:59:53.950] iteration:4057  t-loss:0.0724, loss-lb:0.0682, loss-ulb:0.0036, weight:1.18, lr:0.0008
[23:59:54.330] iteration:4058  t-loss:0.0633, loss-lb:0.0188, loss-ulb:0.0377, weight:1.18, lr:0.0008
[23:59:54.707] iteration:4059  t-loss:0.0492, loss-lb:0.0318, loss-ulb:0.0148, weight:1.18, lr:0.0008
[23:59:55.076] iteration:4060  t-loss:0.0449, loss-lb:0.0241, loss-ulb:0.0176, weight:1.18, lr:0.0008
[23:59:55.451] iteration:4061  t-loss:0.0524, loss-lb:0.0286, loss-ulb:0.0201, weight:1.18, lr:0.0008
[23:59:55.827] iteration:4062  t-loss:0.0667, loss-lb:0.0510, loss-ulb:0.0133, weight:1.18, lr:0.0008
[23:59:56.203] iteration:4063  t-loss:0.0404, loss-lb:0.0262, loss-ulb:0.0121, weight:1.18, lr:0.0008
[23:59:56.580] iteration:4064  t-loss:0.0570, loss-lb:0.0388, loss-ulb:0.0155, weight:1.18, lr:0.0008
[23:59:56.956] iteration:4065  t-loss:0.0293, loss-lb:0.0232, loss-ulb:0.0052, weight:1.18, lr:0.0008
[23:59:57.339] iteration:4066  t-loss:0.0396, loss-lb:0.0312, loss-ulb:0.0071, weight:1.18, lr:0.0008
[23:59:58.988] iteration:4067  t-loss:0.0304, loss-lb:0.0271, loss-ulb:0.0028, weight:1.18, lr:0.0008
[23:59:59.371] iteration:4068  t-loss:0.0613, loss-lb:0.0264, loss-ulb:0.0296, weight:1.18, lr:0.0008
[23:59:59.753] iteration:4069  t-loss:0.0671, loss-lb:0.0508, loss-ulb:0.0138, weight:1.18, lr:0.0008
[00:00:00.140] iteration:4070  t-loss:0.0691, loss-lb:0.0656, loss-ulb:0.0030, weight:1.18, lr:0.0008
[00:00:00.522] iteration:4071  t-loss:0.0785, loss-lb:0.0605, loss-ulb:0.0152, weight:1.18, lr:0.0008
[00:00:00.902] iteration:4072  t-loss:0.0355, loss-lb:0.0310, loss-ulb:0.0037, weight:1.18, lr:0.0008
[00:00:01.281] iteration:4073  t-loss:0.0377, loss-lb:0.0298, loss-ulb:0.0067, weight:1.18, lr:0.0008
[00:00:01.662] iteration:4074  t-loss:0.0424, loss-lb:0.0182, loss-ulb:0.0205, weight:1.18, lr:0.0008
[00:00:02.042] iteration:4075  t-loss:0.0506, loss-lb:0.0465, loss-ulb:0.0035, weight:1.18, lr:0.0008
[00:00:02.420] iteration:4076  t-loss:0.0435, loss-lb:0.0417, loss-ulb:0.0015, weight:1.18, lr:0.0008
[00:00:02.805] iteration:4077  t-loss:0.1094, loss-lb:0.0859, loss-ulb:0.0199, weight:1.18, lr:0.0008
[00:00:03.182] iteration:4078  t-loss:0.0489, loss-lb:0.0161, loss-ulb:0.0278, weight:1.18, lr:0.0008
[00:00:03.563] iteration:4079  t-loss:0.0532, loss-lb:0.0385, loss-ulb:0.0125, weight:1.18, lr:0.0008
[00:00:03.939] iteration:4080  t-loss:0.0251, loss-lb:0.0235, loss-ulb:0.0013, weight:1.18, lr:0.0008
[00:00:04.319] iteration:4081  t-loss:0.0897, loss-lb:0.0396, loss-ulb:0.0425, weight:1.18, lr:0.0008
[00:00:04.696] iteration:4082  t-loss:0.0399, loss-lb:0.0256, loss-ulb:0.0121, weight:1.18, lr:0.0008
[00:00:05.082] iteration:4083  t-loss:0.0514, loss-lb:0.0390, loss-ulb:0.0105, weight:1.18, lr:0.0008
[00:00:05.465] iteration:4084  t-loss:0.0341, loss-lb:0.0206, loss-ulb:0.0114, weight:1.18, lr:0.0008
[00:00:05.843] iteration:4085  t-loss:0.0253, loss-lb:0.0226, loss-ulb:0.0023, weight:1.18, lr:0.0008
[00:00:06.231] iteration:4086  t-loss:0.0664, loss-lb:0.0514, loss-ulb:0.0127, weight:1.18, lr:0.0008
[00:00:06.617] iteration:4087  t-loss:0.0604, loss-lb:0.0352, loss-ulb:0.0213, weight:1.18, lr:0.0008
[00:00:07.004] iteration:4088  t-loss:0.0629, loss-lb:0.0516, loss-ulb:0.0096, weight:1.18, lr:0.0008
[00:00:07.386] iteration:4089  t-loss:0.0426, loss-lb:0.0286, loss-ulb:0.0118, weight:1.18, lr:0.0008
[00:00:07.771] iteration:4090  t-loss:0.0291, loss-lb:0.0171, loss-ulb:0.0102, weight:1.18, lr:0.0008
[00:00:08.151] iteration:4091  t-loss:0.0239, loss-lb:0.0204, loss-ulb:0.0030, weight:1.18, lr:0.0008
[00:00:08.533] iteration:4092  t-loss:0.0373, loss-lb:0.0263, loss-ulb:0.0093, weight:1.18, lr:0.0008
[00:00:08.921] iteration:4093  t-loss:0.0789, loss-lb:0.0653, loss-ulb:0.0116, weight:1.18, lr:0.0008
[00:00:09.305] iteration:4094  t-loss:0.0277, loss-lb:0.0197, loss-ulb:0.0068, weight:1.18, lr:0.0008
[00:00:09.687] iteration:4095  t-loss:0.0443, loss-lb:0.0394, loss-ulb:0.0042, weight:1.18, lr:0.0008
[00:00:10.069] iteration:4096  t-loss:0.0841, loss-lb:0.0663, loss-ulb:0.0151, weight:1.18, lr:0.0008
[00:00:10.446] iteration:4097  t-loss:0.0861, loss-lb:0.0597, loss-ulb:0.0224, weight:1.18, lr:0.0008
[00:00:10.821] iteration:4098  t-loss:0.0389, loss-lb:0.0215, loss-ulb:0.0148, weight:1.18, lr:0.0008
[00:00:11.194] iteration:4099  t-loss:0.0554, loss-lb:0.0434, loss-ulb:0.0102, weight:1.18, lr:0.0008
[00:00:11.567] iteration:4100  t-loss:0.0351, loss-lb:0.0188, loss-ulb:0.0138, weight:1.18, lr:0.0008
[00:00:11.942] iteration:4101  t-loss:0.0695, loss-lb:0.0559, loss-ulb:0.0115, weight:1.18, lr:0.0008
[00:00:12.318] iteration:4102  t-loss:0.0567, loss-lb:0.0472, loss-ulb:0.0081, weight:1.18, lr:0.0008
[00:00:12.699] iteration:4103  t-loss:0.0661, loss-lb:0.0539, loss-ulb:0.0104, weight:1.18, lr:0.0008
[00:00:13.091] iteration:4104  t-loss:0.0338, loss-lb:0.0201, loss-ulb:0.0116, weight:1.18, lr:0.0008
[00:00:14.702] iteration:4105  t-loss:0.0462, loss-lb:0.0233, loss-ulb:0.0194, weight:1.18, lr:0.0007
[00:00:15.085] iteration:4106  t-loss:0.0230, loss-lb:0.0187, loss-ulb:0.0036, weight:1.18, lr:0.0007
[00:00:15.464] iteration:4107  t-loss:0.0650, loss-lb:0.0345, loss-ulb:0.0259, weight:1.18, lr:0.0007
[00:00:15.841] iteration:4108  t-loss:0.0512, loss-lb:0.0263, loss-ulb:0.0211, weight:1.18, lr:0.0007
[00:00:16.207] iteration:4109  t-loss:0.0522, loss-lb:0.0256, loss-ulb:0.0226, weight:1.18, lr:0.0007
[00:00:16.593] iteration:4110  t-loss:0.0355, loss-lb:0.0330, loss-ulb:0.0020, weight:1.18, lr:0.0007
[00:00:16.973] iteration:4111  t-loss:0.0509, loss-lb:0.0343, loss-ulb:0.0141, weight:1.18, lr:0.0007
[00:00:17.352] iteration:4112  t-loss:0.0516, loss-lb:0.0300, loss-ulb:0.0184, weight:1.18, lr:0.0007
[00:00:17.735] iteration:4113  t-loss:0.0577, loss-lb:0.0456, loss-ulb:0.0103, weight:1.18, lr:0.0007
[00:00:18.115] iteration:4114  t-loss:0.0736, loss-lb:0.0540, loss-ulb:0.0166, weight:1.18, lr:0.0007
[00:00:18.490] iteration:4115  t-loss:0.0883, loss-lb:0.0755, loss-ulb:0.0108, weight:1.18, lr:0.0007
[00:00:18.863] iteration:4116  t-loss:0.0492, loss-lb:0.0396, loss-ulb:0.0081, weight:1.18, lr:0.0007
[00:00:19.239] iteration:4117  t-loss:0.0410, loss-lb:0.0295, loss-ulb:0.0098, weight:1.18, lr:0.0007
[00:00:19.615] iteration:4118  t-loss:0.0575, loss-lb:0.0256, loss-ulb:0.0271, weight:1.18, lr:0.0007
[00:00:19.988] iteration:4119  t-loss:0.0409, loss-lb:0.0365, loss-ulb:0.0037, weight:1.18, lr:0.0007
[00:00:20.368] iteration:4120  t-loss:0.1145, loss-lb:0.0870, loss-ulb:0.0233, weight:1.18, lr:0.0007
[00:00:20.741] iteration:4121  t-loss:0.0250, loss-lb:0.0225, loss-ulb:0.0021, weight:1.18, lr:0.0007
[00:00:21.119] iteration:4122  t-loss:0.0613, loss-lb:0.0495, loss-ulb:0.0100, weight:1.18, lr:0.0007
[00:00:21.496] iteration:4123  t-loss:0.0893, loss-lb:0.0658, loss-ulb:0.0199, weight:1.18, lr:0.0007
[00:00:21.876] iteration:4124  t-loss:0.0586, loss-lb:0.0362, loss-ulb:0.0190, weight:1.18, lr:0.0007
[00:00:22.252] iteration:4125  t-loss:0.0409, loss-lb:0.0385, loss-ulb:0.0020, weight:1.18, lr:0.0007
[00:00:22.627] iteration:4126  t-loss:0.0335, loss-lb:0.0304, loss-ulb:0.0027, weight:1.18, lr:0.0007
[00:00:23.007] iteration:4127  t-loss:0.0540, loss-lb:0.0494, loss-ulb:0.0039, weight:1.18, lr:0.0007
[00:00:23.390] iteration:4128  t-loss:0.0408, loss-lb:0.0383, loss-ulb:0.0021, weight:1.18, lr:0.0007
[00:00:23.764] iteration:4129  t-loss:0.0267, loss-lb:0.0219, loss-ulb:0.0041, weight:1.18, lr:0.0007
[00:00:24.139] iteration:4130  t-loss:0.0569, loss-lb:0.0256, loss-ulb:0.0265, weight:1.18, lr:0.0007
[00:00:24.515] iteration:4131  t-loss:0.0671, loss-lb:0.0405, loss-ulb:0.0225, weight:1.18, lr:0.0007
[00:00:24.886] iteration:4132  t-loss:0.0308, loss-lb:0.0235, loss-ulb:0.0062, weight:1.18, lr:0.0007
[00:00:25.256] iteration:4133  t-loss:0.0297, loss-lb:0.0262, loss-ulb:0.0029, weight:1.18, lr:0.0007
[00:00:25.629] iteration:4134  t-loss:0.0627, loss-lb:0.0307, loss-ulb:0.0271, weight:1.18, lr:0.0007
[00:00:26.002] iteration:4135  t-loss:0.0734, loss-lb:0.0521, loss-ulb:0.0181, weight:1.18, lr:0.0007
[00:00:26.374] iteration:4136  t-loss:0.0592, loss-lb:0.0355, loss-ulb:0.0201, weight:1.18, lr:0.0007
[00:00:26.745] iteration:4137  t-loss:0.0344, loss-lb:0.0258, loss-ulb:0.0073, weight:1.18, lr:0.0007
[00:00:27.114] iteration:4138  t-loss:0.0371, loss-lb:0.0331, loss-ulb:0.0033, weight:1.18, lr:0.0007
[00:00:27.489] iteration:4139  t-loss:0.0548, loss-lb:0.0422, loss-ulb:0.0106, weight:1.18, lr:0.0007
[00:00:27.863] iteration:4140  t-loss:0.0374, loss-lb:0.0348, loss-ulb:0.0023, weight:1.18, lr:0.0007
[00:00:28.245] iteration:4141  t-loss:0.0696, loss-lb:0.0397, loss-ulb:0.0254, weight:1.18, lr:0.0007
[00:00:28.631] iteration:4142  t-loss:0.0211, loss-lb:0.0164, loss-ulb:0.0040, weight:1.18, lr:0.0007
[00:01:32.355] iteration 4142 : dice_score: 0.809840 best_dice: 0.814600
[00:01:32.356]  <<Test>> - Ep:108  - Dice-S/T:82.39/80.98, Best-S:84.62, Best-T:81.46
[00:01:32.356]           - AvgLoss(lb/ulb/all):0.04/0.01/0.05
[00:01:33.560] iteration:4143  t-loss:0.0258, loss-lb:0.0245, loss-ulb:0.0011, weight:1.18, lr:0.0007
[00:01:33.951] iteration:4144  t-loss:0.0622, loss-lb:0.0605, loss-ulb:0.0014, weight:1.18, lr:0.0007
[00:01:34.333] iteration:4145  t-loss:0.0632, loss-lb:0.0474, loss-ulb:0.0134, weight:1.18, lr:0.0007
[00:01:34.709] iteration:4146  t-loss:0.0251, loss-lb:0.0213, loss-ulb:0.0032, weight:1.18, lr:0.0007
[00:01:35.095] iteration:4147  t-loss:0.0280, loss-lb:0.0227, loss-ulb:0.0045, weight:1.18, lr:0.0007
[00:01:35.494] iteration:4148  t-loss:0.0667, loss-lb:0.0517, loss-ulb:0.0127, weight:1.18, lr:0.0007
[00:01:35.867] iteration:4149  t-loss:0.0284, loss-lb:0.0254, loss-ulb:0.0025, weight:1.18, lr:0.0007
[00:01:36.249] iteration:4150  t-loss:0.0507, loss-lb:0.0181, loss-ulb:0.0276, weight:1.18, lr:0.0007
[00:01:36.634] iteration:4151  t-loss:0.0746, loss-lb:0.0717, loss-ulb:0.0024, weight:1.18, lr:0.0007
[00:01:37.021] iteration:4152  t-loss:0.0402, loss-lb:0.0372, loss-ulb:0.0025, weight:1.18, lr:0.0007
[00:01:37.401] iteration:4153  t-loss:0.0625, loss-lb:0.0543, loss-ulb:0.0069, weight:1.18, lr:0.0007
[00:01:37.782] iteration:4154  t-loss:0.0437, loss-lb:0.0233, loss-ulb:0.0173, weight:1.18, lr:0.0007
[00:01:38.166] iteration:4155  t-loss:0.0453, loss-lb:0.0325, loss-ulb:0.0108, weight:1.18, lr:0.0007
[00:01:38.560] iteration:4156  t-loss:0.0805, loss-lb:0.0622, loss-ulb:0.0155, weight:1.18, lr:0.0007
[00:01:38.940] iteration:4157  t-loss:0.0263, loss-lb:0.0237, loss-ulb:0.0022, weight:1.18, lr:0.0007
[00:01:39.326] iteration:4158  t-loss:0.0766, loss-lb:0.0546, loss-ulb:0.0187, weight:1.18, lr:0.0007
[00:01:39.707] iteration:4159  t-loss:0.0602, loss-lb:0.0544, loss-ulb:0.0049, weight:1.18, lr:0.0007
[00:01:40.091] iteration:4160  t-loss:0.0512, loss-lb:0.0253, loss-ulb:0.0220, weight:1.18, lr:0.0007
[00:01:40.471] iteration:4161  t-loss:0.0223, loss-lb:0.0196, loss-ulb:0.0023, weight:1.18, lr:0.0007
[00:01:40.868] iteration:4162  t-loss:0.0698, loss-lb:0.0419, loss-ulb:0.0236, weight:1.18, lr:0.0007
[00:01:41.255] iteration:4163  t-loss:0.0509, loss-lb:0.0414, loss-ulb:0.0080, weight:1.18, lr:0.0007
[00:01:41.638] iteration:4164  t-loss:0.0410, loss-lb:0.0232, loss-ulb:0.0151, weight:1.18, lr:0.0007
[00:01:42.022] iteration:4165  t-loss:0.0381, loss-lb:0.0233, loss-ulb:0.0125, weight:1.18, lr:0.0007
[00:01:42.400] iteration:4166  t-loss:0.0246, loss-lb:0.0193, loss-ulb:0.0045, weight:1.18, lr:0.0007
[00:01:42.781] iteration:4167  t-loss:0.0479, loss-lb:0.0247, loss-ulb:0.0197, weight:1.18, lr:0.0007
[00:01:43.159] iteration:4168  t-loss:0.0394, loss-lb:0.0376, loss-ulb:0.0015, weight:1.18, lr:0.0007
[00:01:43.541] iteration:4169  t-loss:0.0544, loss-lb:0.0384, loss-ulb:0.0135, weight:1.18, lr:0.0007
[00:01:43.921] iteration:4170  t-loss:0.0260, loss-lb:0.0216, loss-ulb:0.0037, weight:1.18, lr:0.0007
[00:01:44.306] iteration:4171  t-loss:0.0417, loss-lb:0.0268, loss-ulb:0.0126, weight:1.18, lr:0.0007
[00:01:44.682] iteration:4172  t-loss:0.0307, loss-lb:0.0204, loss-ulb:0.0087, weight:1.18, lr:0.0007
[00:01:45.062] iteration:4173  t-loss:0.0544, loss-lb:0.0409, loss-ulb:0.0114, weight:1.18, lr:0.0007
[00:01:45.440] iteration:4174  t-loss:0.0411, loss-lb:0.0353, loss-ulb:0.0049, weight:1.18, lr:0.0007
[00:01:45.816] iteration:4175  t-loss:0.0235, loss-lb:0.0217, loss-ulb:0.0015, weight:1.18, lr:0.0007
[00:01:46.198] iteration:4176  t-loss:0.0315, loss-lb:0.0217, loss-ulb:0.0083, weight:1.18, lr:0.0007
[00:01:46.573] iteration:4177  t-loss:0.0426, loss-lb:0.0365, loss-ulb:0.0052, weight:1.18, lr:0.0007
[00:01:46.951] iteration:4178  t-loss:0.0313, loss-lb:0.0216, loss-ulb:0.0083, weight:1.18, lr:0.0007
[00:01:47.330] iteration:4179  t-loss:0.0835, loss-lb:0.0496, loss-ulb:0.0288, weight:1.18, lr:0.0007
[00:01:47.709] iteration:4180  t-loss:0.0391, loss-lb:0.0356, loss-ulb:0.0029, weight:1.18, lr:0.0007
[00:01:48.888] iteration:4181  t-loss:0.0258, loss-lb:0.0196, loss-ulb:0.0052, weight:1.18, lr:0.0007
[00:01:49.292] iteration:4182  t-loss:0.0295, loss-lb:0.0284, loss-ulb:0.0009, weight:1.18, lr:0.0007
[00:01:49.698] iteration:4183  t-loss:0.0667, loss-lb:0.0460, loss-ulb:0.0176, weight:1.18, lr:0.0007
[00:01:50.090] iteration:4184  t-loss:0.0606, loss-lb:0.0485, loss-ulb:0.0103, weight:1.18, lr:0.0007
[00:01:50.471] iteration:4185  t-loss:0.0238, loss-lb:0.0172, loss-ulb:0.0056, weight:1.18, lr:0.0007
[00:01:50.849] iteration:4186  t-loss:0.0511, loss-lb:0.0275, loss-ulb:0.0200, weight:1.18, lr:0.0007
[00:01:51.232] iteration:4187  t-loss:0.0352, loss-lb:0.0329, loss-ulb:0.0020, weight:1.18, lr:0.0007
[00:01:51.617] iteration:4188  t-loss:0.0698, loss-lb:0.0502, loss-ulb:0.0166, weight:1.18, lr:0.0007
[00:01:51.995] iteration:4189  t-loss:0.0631, loss-lb:0.0186, loss-ulb:0.0377, weight:1.18, lr:0.0007
[00:01:52.378] iteration:4190  t-loss:0.0564, loss-lb:0.0485, loss-ulb:0.0067, weight:1.18, lr:0.0007
[00:01:52.751] iteration:4191  t-loss:0.0401, loss-lb:0.0256, loss-ulb:0.0123, weight:1.18, lr:0.0007
[00:01:53.130] iteration:4192  t-loss:0.0267, loss-lb:0.0212, loss-ulb:0.0047, weight:1.18, lr:0.0007
[00:01:53.511] iteration:4193  t-loss:0.0440, loss-lb:0.0351, loss-ulb:0.0076, weight:1.18, lr:0.0007
[00:01:53.887] iteration:4194  t-loss:0.0615, loss-lb:0.0369, loss-ulb:0.0208, weight:1.18, lr:0.0007
[00:01:54.271] iteration:4195  t-loss:0.0594, loss-lb:0.0505, loss-ulb:0.0076, weight:1.18, lr:0.0007
[00:01:54.650] iteration:4196  t-loss:0.0344, loss-lb:0.0257, loss-ulb:0.0074, weight:1.18, lr:0.0007
[00:01:55.035] iteration:4197  t-loss:0.0468, loss-lb:0.0393, loss-ulb:0.0063, weight:1.18, lr:0.0007
[00:01:55.411] iteration:4198  t-loss:0.0396, loss-lb:0.0257, loss-ulb:0.0118, weight:1.18, lr:0.0007
[00:01:55.791] iteration:4199  t-loss:0.0741, loss-lb:0.0240, loss-ulb:0.0424, weight:1.18, lr:0.0007
[00:01:56.170] iteration:4200  t-loss:0.0380, loss-lb:0.0241, loss-ulb:0.0118, weight:1.18, lr:0.0007
[00:01:56.545] iteration:4201  t-loss:0.0289, loss-lb:0.0215, loss-ulb:0.0059, weight:1.28, lr:0.0007
[00:01:56.926] iteration:4202  t-loss:0.0554, loss-lb:0.0246, loss-ulb:0.0242, weight:1.28, lr:0.0007
[00:01:57.309] iteration:4203  t-loss:0.0330, loss-lb:0.0177, loss-ulb:0.0120, weight:1.28, lr:0.0007
[00:01:57.692] iteration:4204  t-loss:0.0600, loss-lb:0.0526, loss-ulb:0.0058, weight:1.28, lr:0.0007
[00:01:58.075] iteration:4205  t-loss:0.0835, loss-lb:0.0764, loss-ulb:0.0056, weight:1.28, lr:0.0007
[00:01:58.452] iteration:4206  t-loss:0.0359, loss-lb:0.0193, loss-ulb:0.0131, weight:1.28, lr:0.0007
[00:01:58.830] iteration:4207  t-loss:0.0251, loss-lb:0.0172, loss-ulb:0.0062, weight:1.28, lr:0.0007
[00:01:59.211] iteration:4208  t-loss:0.0353, loss-lb:0.0216, loss-ulb:0.0108, weight:1.28, lr:0.0007
[00:01:59.591] iteration:4209  t-loss:0.0286, loss-lb:0.0213, loss-ulb:0.0057, weight:1.28, lr:0.0007
[00:01:59.969] iteration:4210  t-loss:0.0290, loss-lb:0.0274, loss-ulb:0.0012, weight:1.28, lr:0.0007
[00:02:00.346] iteration:4211  t-loss:0.0469, loss-lb:0.0355, loss-ulb:0.0090, weight:1.28, lr:0.0007
[00:02:00.724] iteration:4212  t-loss:0.0512, loss-lb:0.0478, loss-ulb:0.0027, weight:1.28, lr:0.0007
[00:02:01.099] iteration:4213  t-loss:0.0428, loss-lb:0.0404, loss-ulb:0.0019, weight:1.28, lr:0.0007
[00:02:01.474] iteration:4214  t-loss:0.0338, loss-lb:0.0233, loss-ulb:0.0082, weight:1.28, lr:0.0007
[00:02:01.846] iteration:4215  t-loss:0.0252, loss-lb:0.0222, loss-ulb:0.0023, weight:1.28, lr:0.0007
[00:02:02.219] iteration:4216  t-loss:0.0275, loss-lb:0.0205, loss-ulb:0.0055, weight:1.28, lr:0.0007
[00:02:02.595] iteration:4217  t-loss:0.0522, loss-lb:0.0329, loss-ulb:0.0152, weight:1.28, lr:0.0007
[00:02:02.967] iteration:4218  t-loss:0.0535, loss-lb:0.0258, loss-ulb:0.0217, weight:1.28, lr:0.0007
[00:02:04.133] iteration:4219  t-loss:0.0598, loss-lb:0.0367, loss-ulb:0.0181, weight:1.28, lr:0.0007
[00:02:04.531] iteration:4220  t-loss:0.0493, loss-lb:0.0400, loss-ulb:0.0073, weight:1.28, lr:0.0007
[00:02:04.932] iteration:4221  t-loss:0.0443, loss-lb:0.0301, loss-ulb:0.0112, weight:1.28, lr:0.0007
[00:02:05.356] iteration:4222  t-loss:0.0680, loss-lb:0.0527, loss-ulb:0.0120, weight:1.28, lr:0.0007
[00:02:05.755] iteration:4223  t-loss:0.0568, loss-lb:0.0544, loss-ulb:0.0018, weight:1.28, lr:0.0007
[00:02:06.135] iteration:4224  t-loss:0.0459, loss-lb:0.0365, loss-ulb:0.0074, weight:1.28, lr:0.0007
[00:02:06.512] iteration:4225  t-loss:0.0273, loss-lb:0.0237, loss-ulb:0.0028, weight:1.28, lr:0.0007
[00:02:06.894] iteration:4226  t-loss:0.0661, loss-lb:0.0208, loss-ulb:0.0355, weight:1.28, lr:0.0007
[00:02:07.279] iteration:4227  t-loss:0.0519, loss-lb:0.0367, loss-ulb:0.0119, weight:1.28, lr:0.0007
[00:02:07.657] iteration:4228  t-loss:0.0493, loss-lb:0.0209, loss-ulb:0.0223, weight:1.28, lr:0.0007
[00:02:08.041] iteration:4229  t-loss:0.0312, loss-lb:0.0224, loss-ulb:0.0069, weight:1.28, lr:0.0007
[00:02:08.423] iteration:4230  t-loss:0.0364, loss-lb:0.0248, loss-ulb:0.0091, weight:1.28, lr:0.0007
[00:02:08.804] iteration:4231  t-loss:0.0313, loss-lb:0.0208, loss-ulb:0.0082, weight:1.28, lr:0.0007
[00:02:09.184] iteration:4232  t-loss:0.0600, loss-lb:0.0398, loss-ulb:0.0158, weight:1.28, lr:0.0007
[00:02:09.567] iteration:4233  t-loss:0.0451, loss-lb:0.0390, loss-ulb:0.0048, weight:1.28, lr:0.0007
[00:02:09.951] iteration:4234  t-loss:0.0279, loss-lb:0.0224, loss-ulb:0.0043, weight:1.28, lr:0.0007
[00:02:10.332] iteration:4235  t-loss:0.0485, loss-lb:0.0330, loss-ulb:0.0121, weight:1.28, lr:0.0007
[00:02:10.710] iteration:4236  t-loss:0.0771, loss-lb:0.0744, loss-ulb:0.0021, weight:1.28, lr:0.0007
[00:02:11.099] iteration:4237  t-loss:0.0431, loss-lb:0.0310, loss-ulb:0.0095, weight:1.28, lr:0.0007
[00:02:11.481] iteration:4238  t-loss:0.1141, loss-lb:0.0914, loss-ulb:0.0178, weight:1.28, lr:0.0007
[00:02:11.863] iteration:4239  t-loss:0.0735, loss-lb:0.0382, loss-ulb:0.0277, weight:1.28, lr:0.0007
[00:02:12.244] iteration:4240  t-loss:0.0641, loss-lb:0.0449, loss-ulb:0.0150, weight:1.28, lr:0.0007
[00:02:12.622] iteration:4241  t-loss:0.0494, loss-lb:0.0364, loss-ulb:0.0102, weight:1.28, lr:0.0007
[00:02:13.000] iteration:4242  t-loss:0.0806, loss-lb:0.0730, loss-ulb:0.0059, weight:1.28, lr:0.0007
[00:02:13.386] iteration:4243  t-loss:0.0313, loss-lb:0.0276, loss-ulb:0.0029, weight:1.28, lr:0.0007
[00:02:13.773] iteration:4244  t-loss:0.0256, loss-lb:0.0232, loss-ulb:0.0018, weight:1.28, lr:0.0007
[00:02:14.156] iteration:4245  t-loss:0.0495, loss-lb:0.0328, loss-ulb:0.0131, weight:1.28, lr:0.0007
[00:02:14.533] iteration:4246  t-loss:0.0254, loss-lb:0.0213, loss-ulb:0.0032, weight:1.28, lr:0.0007
[00:02:14.911] iteration:4247  t-loss:0.0249, loss-lb:0.0209, loss-ulb:0.0032, weight:1.28, lr:0.0007
[00:02:15.294] iteration:4248  t-loss:0.0680, loss-lb:0.0387, loss-ulb:0.0229, weight:1.28, lr:0.0007
[00:02:15.673] iteration:4249  t-loss:0.0602, loss-lb:0.0514, loss-ulb:0.0069, weight:1.28, lr:0.0007
[00:02:16.051] iteration:4250  t-loss:0.0333, loss-lb:0.0211, loss-ulb:0.0095, weight:1.28, lr:0.0007
[00:02:16.430] iteration:4251  t-loss:0.0651, loss-lb:0.0389, loss-ulb:0.0205, weight:1.28, lr:0.0007
[00:02:16.807] iteration:4252  t-loss:0.0487, loss-lb:0.0222, loss-ulb:0.0208, weight:1.28, lr:0.0007
[00:02:17.180] iteration:4253  t-loss:0.0471, loss-lb:0.0441, loss-ulb:0.0023, weight:1.28, lr:0.0007
[00:02:17.554] iteration:4254  t-loss:0.0237, loss-lb:0.0221, loss-ulb:0.0012, weight:1.28, lr:0.0007
[00:02:17.923] iteration:4255  t-loss:0.0604, loss-lb:0.0220, loss-ulb:0.0301, weight:1.28, lr:0.0007
[00:02:18.297] iteration:4256  t-loss:0.0738, loss-lb:0.0555, loss-ulb:0.0143, weight:1.28, lr:0.0007
[00:02:19.620] iteration:4257  t-loss:0.0555, loss-lb:0.0396, loss-ulb:0.0124, weight:1.28, lr:0.0007
[00:02:20.008] iteration:4258  t-loss:0.0773, loss-lb:0.0297, loss-ulb:0.0373, weight:1.28, lr:0.0007
[00:02:20.394] iteration:4259  t-loss:0.0306, loss-lb:0.0279, loss-ulb:0.0021, weight:1.28, lr:0.0007
[00:02:20.841] iteration:4260  t-loss:0.0594, loss-lb:0.0414, loss-ulb:0.0141, weight:1.28, lr:0.0007
[00:02:21.270] iteration:4261  t-loss:0.0414, loss-lb:0.0182, loss-ulb:0.0182, weight:1.28, lr:0.0007
[00:02:21.699] iteration:4262  t-loss:0.0464, loss-lb:0.0321, loss-ulb:0.0112, weight:1.28, lr:0.0007
[00:02:22.101] iteration:4263  t-loss:0.0351, loss-lb:0.0311, loss-ulb:0.0032, weight:1.28, lr:0.0007
[00:02:22.488] iteration:4264  t-loss:0.0566, loss-lb:0.0354, loss-ulb:0.0166, weight:1.28, lr:0.0007
[00:02:22.864] iteration:4265  t-loss:0.0233, loss-lb:0.0213, loss-ulb:0.0016, weight:1.28, lr:0.0007
[00:02:23.249] iteration:4266  t-loss:0.0656, loss-lb:0.0325, loss-ulb:0.0259, weight:1.28, lr:0.0007
[00:02:23.636] iteration:4267  t-loss:0.0567, loss-lb:0.0368, loss-ulb:0.0156, weight:1.28, lr:0.0007
[00:02:24.028] iteration:4268  t-loss:0.0591, loss-lb:0.0492, loss-ulb:0.0078, weight:1.28, lr:0.0007
[00:02:24.412] iteration:4269  t-loss:0.0264, loss-lb:0.0187, loss-ulb:0.0060, weight:1.28, lr:0.0007
[00:02:24.792] iteration:4270  t-loss:0.0338, loss-lb:0.0239, loss-ulb:0.0077, weight:1.28, lr:0.0007
[00:02:25.174] iteration:4271  t-loss:0.0752, loss-lb:0.0288, loss-ulb:0.0363, weight:1.28, lr:0.0007
[00:02:25.568] iteration:4272  t-loss:0.0793, loss-lb:0.0583, loss-ulb:0.0165, weight:1.28, lr:0.0007
[00:02:25.935] iteration:4273  t-loss:0.0366, loss-lb:0.0241, loss-ulb:0.0098, weight:1.28, lr:0.0007
[00:02:26.315] iteration:4274  t-loss:0.0575, loss-lb:0.0337, loss-ulb:0.0186, weight:1.28, lr:0.0007
[00:02:26.691] iteration:4275  t-loss:0.0296, loss-lb:0.0241, loss-ulb:0.0044, weight:1.28, lr:0.0007
[00:02:27.068] iteration:4276  t-loss:0.0565, loss-lb:0.0505, loss-ulb:0.0046, weight:1.28, lr:0.0007
[00:02:27.446] iteration:4277  t-loss:0.0323, loss-lb:0.0232, loss-ulb:0.0071, weight:1.28, lr:0.0007
[00:02:27.824] iteration:4278  t-loss:0.0365, loss-lb:0.0238, loss-ulb:0.0099, weight:1.28, lr:0.0007
[00:02:28.204] iteration:4279  t-loss:0.0645, loss-lb:0.0524, loss-ulb:0.0095, weight:1.28, lr:0.0007
[00:02:28.584] iteration:4280  t-loss:0.0518, loss-lb:0.0493, loss-ulb:0.0019, weight:1.28, lr:0.0007
[00:02:28.974] iteration:4281  t-loss:0.0420, loss-lb:0.0282, loss-ulb:0.0109, weight:1.28, lr:0.0007
[00:02:29.350] iteration:4282  t-loss:0.0939, loss-lb:0.0881, loss-ulb:0.0046, weight:1.28, lr:0.0007
[00:02:29.732] iteration:4283  t-loss:0.0603, loss-lb:0.0222, loss-ulb:0.0298, weight:1.28, lr:0.0007
[00:02:30.109] iteration:4284  t-loss:0.0392, loss-lb:0.0341, loss-ulb:0.0039, weight:1.28, lr:0.0007
[00:02:30.493] iteration:4285  t-loss:0.0425, loss-lb:0.0232, loss-ulb:0.0152, weight:1.28, lr:0.0007
[00:02:30.879] iteration:4286  t-loss:0.0537, loss-lb:0.0365, loss-ulb:0.0135, weight:1.28, lr:0.0007
[00:02:31.255] iteration:4287  t-loss:0.0392, loss-lb:0.0232, loss-ulb:0.0125, weight:1.28, lr:0.0007
[00:02:31.632] iteration:4288  t-loss:0.0374, loss-lb:0.0183, loss-ulb:0.0150, weight:1.28, lr:0.0007
[00:02:32.011] iteration:4289  t-loss:0.0835, loss-lb:0.0474, loss-ulb:0.0283, weight:1.28, lr:0.0007
[00:02:32.382] iteration:4290  t-loss:0.0354, loss-lb:0.0247, loss-ulb:0.0085, weight:1.28, lr:0.0007
[00:02:32.754] iteration:4291  t-loss:0.0595, loss-lb:0.0324, loss-ulb:0.0213, weight:1.28, lr:0.0007
[00:02:33.126] iteration:4292  t-loss:0.1018, loss-lb:0.0499, loss-ulb:0.0407, weight:1.28, lr:0.0007
[00:02:33.501] iteration:4293  t-loss:0.0460, loss-lb:0.0368, loss-ulb:0.0072, weight:1.28, lr:0.0007
[00:02:33.872] iteration:4294  t-loss:0.0368, loss-lb:0.0270, loss-ulb:0.0076, weight:1.28, lr:0.0007
[00:03:37.769] iteration 4294 : dice_score: 0.849727 best_dice: 0.849700
[00:03:37.770]  <<Test>> - Ep:112  - Dice-S/T:82.70/84.97, Best-S:84.62, Best-T:84.97
[00:03:37.770]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:03:39.153] iteration:4295  t-loss:0.0486, loss-lb:0.0296, loss-ulb:0.0149, weight:1.28, lr:0.0007
[00:03:39.539] iteration:4296  t-loss:0.0375, loss-lb:0.0349, loss-ulb:0.0020, weight:1.28, lr:0.0007
[00:03:39.929] iteration:4297  t-loss:0.0600, loss-lb:0.0416, loss-ulb:0.0144, weight:1.28, lr:0.0007
[00:03:40.313] iteration:4298  t-loss:0.0642, loss-lb:0.0439, loss-ulb:0.0159, weight:1.28, lr:0.0007
[00:03:40.690] iteration:4299  t-loss:0.1431, loss-lb:0.0333, loss-ulb:0.0861, weight:1.28, lr:0.0007
[00:03:41.073] iteration:4300  t-loss:0.0572, loss-lb:0.0401, loss-ulb:0.0134, weight:1.28, lr:0.0007
[00:03:41.462] iteration:4301  t-loss:0.0621, loss-lb:0.0514, loss-ulb:0.0084, weight:1.28, lr:0.0007
[00:03:41.841] iteration:4302  t-loss:0.0524, loss-lb:0.0368, loss-ulb:0.0122, weight:1.28, lr:0.0007
[00:03:42.214] iteration:4303  t-loss:0.0324, loss-lb:0.0257, loss-ulb:0.0052, weight:1.28, lr:0.0007
[00:03:42.596] iteration:4304  t-loss:0.0656, loss-lb:0.0443, loss-ulb:0.0167, weight:1.28, lr:0.0007
[00:03:42.979] iteration:4305  t-loss:0.0459, loss-lb:0.0244, loss-ulb:0.0168, weight:1.28, lr:0.0007
[00:03:43.359] iteration:4306  t-loss:0.0421, loss-lb:0.0381, loss-ulb:0.0031, weight:1.28, lr:0.0007
[00:03:43.739] iteration:4307  t-loss:0.1236, loss-lb:0.1026, loss-ulb:0.0164, weight:1.28, lr:0.0007
[00:03:44.123] iteration:4308  t-loss:0.0354, loss-lb:0.0208, loss-ulb:0.0114, weight:1.28, lr:0.0007
[00:03:44.500] iteration:4309  t-loss:0.0533, loss-lb:0.0302, loss-ulb:0.0181, weight:1.28, lr:0.0007
[00:03:44.879] iteration:4310  t-loss:0.0373, loss-lb:0.0317, loss-ulb:0.0044, weight:1.28, lr:0.0007
[00:03:45.264] iteration:4311  t-loss:0.0672, loss-lb:0.0546, loss-ulb:0.0098, weight:1.28, lr:0.0007
[00:03:45.642] iteration:4312  t-loss:0.0426, loss-lb:0.0215, loss-ulb:0.0166, weight:1.28, lr:0.0007
[00:03:46.025] iteration:4313  t-loss:0.0324, loss-lb:0.0221, loss-ulb:0.0081, weight:1.28, lr:0.0007
[00:03:46.402] iteration:4314  t-loss:0.0409, loss-lb:0.0220, loss-ulb:0.0148, weight:1.28, lr:0.0007
[00:03:46.782] iteration:4315  t-loss:0.0430, loss-lb:0.0208, loss-ulb:0.0174, weight:1.28, lr:0.0007
[00:03:47.157] iteration:4316  t-loss:0.0466, loss-lb:0.0368, loss-ulb:0.0077, weight:1.28, lr:0.0007
[00:03:47.541] iteration:4317  t-loss:0.0740, loss-lb:0.0463, loss-ulb:0.0218, weight:1.28, lr:0.0007
[00:03:47.921] iteration:4318  t-loss:0.0660, loss-lb:0.0505, loss-ulb:0.0122, weight:1.28, lr:0.0007
[00:03:48.306] iteration:4319  t-loss:0.0605, loss-lb:0.0569, loss-ulb:0.0028, weight:1.28, lr:0.0007
[00:03:48.690] iteration:4320  t-loss:0.0657, loss-lb:0.0468, loss-ulb:0.0148, weight:1.28, lr:0.0007
[00:03:49.070] iteration:4321  t-loss:0.1023, loss-lb:0.0395, loss-ulb:0.0493, weight:1.28, lr:0.0007
[00:03:49.452] iteration:4322  t-loss:0.0333, loss-lb:0.0301, loss-ulb:0.0025, weight:1.28, lr:0.0007
[00:03:49.831] iteration:4323  t-loss:0.0643, loss-lb:0.0480, loss-ulb:0.0128, weight:1.28, lr:0.0007
[00:03:50.215] iteration:4324  t-loss:0.0407, loss-lb:0.0259, loss-ulb:0.0116, weight:1.28, lr:0.0007
[00:03:50.590] iteration:4325  t-loss:0.0781, loss-lb:0.0724, loss-ulb:0.0045, weight:1.28, lr:0.0007
[00:03:50.963] iteration:4326  t-loss:0.0593, loss-lb:0.0179, loss-ulb:0.0325, weight:1.28, lr:0.0007
[00:03:51.341] iteration:4327  t-loss:0.0448, loss-lb:0.0231, loss-ulb:0.0170, weight:1.28, lr:0.0007
[00:03:51.720] iteration:4328  t-loss:0.0499, loss-lb:0.0252, loss-ulb:0.0194, weight:1.28, lr:0.0007
[00:03:52.098] iteration:4329  t-loss:0.0533, loss-lb:0.0380, loss-ulb:0.0120, weight:1.28, lr:0.0007
[00:03:52.475] iteration:4330  t-loss:0.0363, loss-lb:0.0182, loss-ulb:0.0141, weight:1.28, lr:0.0007
[00:03:52.853] iteration:4331  t-loss:0.0855, loss-lb:0.0757, loss-ulb:0.0077, weight:1.28, lr:0.0007
[00:03:53.231] iteration:4332  t-loss:0.0651, loss-lb:0.0545, loss-ulb:0.0083, weight:1.28, lr:0.0007
[00:03:54.569] iteration:4333  t-loss:0.0593, loss-lb:0.0229, loss-ulb:0.0285, weight:1.28, lr:0.0007
[00:03:54.951] iteration:4334  t-loss:0.0267, loss-lb:0.0236, loss-ulb:0.0024, weight:1.28, lr:0.0007
[00:03:55.338] iteration:4335  t-loss:0.0556, loss-lb:0.0212, loss-ulb:0.0270, weight:1.28, lr:0.0007
[00:03:55.717] iteration:4336  t-loss:0.0694, loss-lb:0.0194, loss-ulb:0.0392, weight:1.28, lr:0.0007
[00:03:56.103] iteration:4337  t-loss:0.1635, loss-lb:0.0822, loss-ulb:0.0637, weight:1.28, lr:0.0007
[00:03:56.481] iteration:4338  t-loss:0.0239, loss-lb:0.0191, loss-ulb:0.0038, weight:1.28, lr:0.0007
[00:03:56.860] iteration:4339  t-loss:0.0855, loss-lb:0.0764, loss-ulb:0.0072, weight:1.28, lr:0.0007
[00:03:57.241] iteration:4340  t-loss:0.0632, loss-lb:0.0490, loss-ulb:0.0111, weight:1.28, lr:0.0007
[00:03:57.637] iteration:4341  t-loss:0.0876, loss-lb:0.0312, loss-ulb:0.0443, weight:1.28, lr:0.0007
[00:03:58.063] iteration:4342  t-loss:0.1023, loss-lb:0.0773, loss-ulb:0.0196, weight:1.28, lr:0.0007
[00:03:58.456] iteration:4343  t-loss:0.0937, loss-lb:0.0719, loss-ulb:0.0171, weight:1.28, lr:0.0007
[00:03:58.847] iteration:4344  t-loss:0.0358, loss-lb:0.0295, loss-ulb:0.0049, weight:1.28, lr:0.0007
[00:03:59.244] iteration:4345  t-loss:0.0639, loss-lb:0.0487, loss-ulb:0.0120, weight:1.28, lr:0.0007
[00:03:59.624] iteration:4346  t-loss:0.0241, loss-lb:0.0203, loss-ulb:0.0030, weight:1.28, lr:0.0007
[00:04:00.012] iteration:4347  t-loss:0.0492, loss-lb:0.0389, loss-ulb:0.0081, weight:1.28, lr:0.0007
[00:04:00.401] iteration:4348  t-loss:0.0395, loss-lb:0.0259, loss-ulb:0.0107, weight:1.28, lr:0.0007
[00:04:00.796] iteration:4349  t-loss:0.0544, loss-lb:0.0470, loss-ulb:0.0057, weight:1.28, lr:0.0007
[00:04:01.179] iteration:4350  t-loss:0.0622, loss-lb:0.0527, loss-ulb:0.0075, weight:1.28, lr:0.0007
[00:04:01.568] iteration:4351  t-loss:0.0468, loss-lb:0.0297, loss-ulb:0.0125, weight:1.37, lr:0.0007
[00:04:01.946] iteration:4352  t-loss:0.0725, loss-lb:0.0270, loss-ulb:0.0332, weight:1.37, lr:0.0007
[00:04:02.321] iteration:4353  t-loss:0.0397, loss-lb:0.0282, loss-ulb:0.0084, weight:1.37, lr:0.0007
[00:04:02.702] iteration:4354  t-loss:0.0369, loss-lb:0.0223, loss-ulb:0.0106, weight:1.37, lr:0.0007
[00:04:03.084] iteration:4355  t-loss:0.0674, loss-lb:0.0379, loss-ulb:0.0215, weight:1.37, lr:0.0007
[00:04:03.460] iteration:4356  t-loss:0.0315, loss-lb:0.0224, loss-ulb:0.0066, weight:1.37, lr:0.0007
[00:04:03.844] iteration:4357  t-loss:0.0628, loss-lb:0.0459, loss-ulb:0.0123, weight:1.37, lr:0.0007
[00:04:04.226] iteration:4358  t-loss:0.0540, loss-lb:0.0235, loss-ulb:0.0222, weight:1.37, lr:0.0007
[00:04:04.607] iteration:4359  t-loss:0.0449, loss-lb:0.0391, loss-ulb:0.0042, weight:1.37, lr:0.0007
[00:04:04.984] iteration:4360  t-loss:0.0472, loss-lb:0.0230, loss-ulb:0.0177, weight:1.37, lr:0.0007
[00:04:05.365] iteration:4361  t-loss:0.0477, loss-lb:0.0432, loss-ulb:0.0033, weight:1.37, lr:0.0007
[00:04:05.756] iteration:4362  t-loss:0.0497, loss-lb:0.0448, loss-ulb:0.0036, weight:1.37, lr:0.0007
[00:04:06.130] iteration:4363  t-loss:0.0231, loss-lb:0.0169, loss-ulb:0.0045, weight:1.37, lr:0.0007
[00:04:06.508] iteration:4364  t-loss:0.0436, loss-lb:0.0217, loss-ulb:0.0159, weight:1.37, lr:0.0007
[00:04:06.883] iteration:4365  t-loss:0.0485, loss-lb:0.0446, loss-ulb:0.0028, weight:1.37, lr:0.0007
[00:04:07.261] iteration:4366  t-loss:0.0400, loss-lb:0.0254, loss-ulb:0.0106, weight:1.37, lr:0.0007
[00:04:07.639] iteration:4367  t-loss:0.0667, loss-lb:0.0283, loss-ulb:0.0280, weight:1.37, lr:0.0007
[00:04:08.020] iteration:4368  t-loss:0.0593, loss-lb:0.0439, loss-ulb:0.0113, weight:1.37, lr:0.0007
[00:04:08.398] iteration:4369  t-loss:0.0407, loss-lb:0.0252, loss-ulb:0.0113, weight:1.37, lr:0.0007
[00:04:08.776] iteration:4370  t-loss:0.0618, loss-lb:0.0451, loss-ulb:0.0122, weight:1.37, lr:0.0007
[00:04:09.912] iteration:4371  t-loss:0.0396, loss-lb:0.0256, loss-ulb:0.0102, weight:1.37, lr:0.0007
[00:04:10.304] iteration:4372  t-loss:0.0419, loss-lb:0.0206, loss-ulb:0.0156, weight:1.37, lr:0.0007
[00:04:10.694] iteration:4373  t-loss:0.0590, loss-lb:0.0325, loss-ulb:0.0194, weight:1.37, lr:0.0007
[00:04:11.073] iteration:4374  t-loss:0.0509, loss-lb:0.0386, loss-ulb:0.0090, weight:1.37, lr:0.0007
[00:04:11.453] iteration:4375  t-loss:0.0532, loss-lb:0.0382, loss-ulb:0.0109, weight:1.37, lr:0.0007
[00:04:11.828] iteration:4376  t-loss:0.0228, loss-lb:0.0197, loss-ulb:0.0022, weight:1.37, lr:0.0007
[00:04:12.211] iteration:4377  t-loss:0.0407, loss-lb:0.0330, loss-ulb:0.0056, weight:1.37, lr:0.0007
[00:04:12.587] iteration:4378  t-loss:0.0438, loss-lb:0.0335, loss-ulb:0.0075, weight:1.37, lr:0.0007
[00:04:12.982] iteration:4379  t-loss:0.0285, loss-lb:0.0203, loss-ulb:0.0060, weight:1.37, lr:0.0007
[00:04:13.389] iteration:4380  t-loss:0.0327, loss-lb:0.0274, loss-ulb:0.0039, weight:1.37, lr:0.0007
[00:04:13.789] iteration:4381  t-loss:0.0489, loss-lb:0.0191, loss-ulb:0.0218, weight:1.37, lr:0.0007
[00:04:14.180] iteration:4382  t-loss:0.0733, loss-lb:0.0522, loss-ulb:0.0154, weight:1.37, lr:0.0007
[00:04:14.562] iteration:4383  t-loss:0.0742, loss-lb:0.0445, loss-ulb:0.0217, weight:1.37, lr:0.0007
[00:04:14.944] iteration:4384  t-loss:0.0858, loss-lb:0.0426, loss-ulb:0.0315, weight:1.37, lr:0.0007
[00:04:15.328] iteration:4385  t-loss:0.0613, loss-lb:0.0259, loss-ulb:0.0259, weight:1.37, lr:0.0007
[00:04:15.708] iteration:4386  t-loss:0.0439, loss-lb:0.0204, loss-ulb:0.0172, weight:1.37, lr:0.0007
[00:04:16.090] iteration:4387  t-loss:0.0331, loss-lb:0.0172, loss-ulb:0.0116, weight:1.37, lr:0.0007
[00:04:16.471] iteration:4388  t-loss:0.0412, loss-lb:0.0237, loss-ulb:0.0128, weight:1.37, lr:0.0007
[00:04:16.855] iteration:4389  t-loss:0.0394, loss-lb:0.0361, loss-ulb:0.0024, weight:1.37, lr:0.0007
[00:04:17.230] iteration:4390  t-loss:0.0210, loss-lb:0.0193, loss-ulb:0.0012, weight:1.37, lr:0.0007
[00:04:17.613] iteration:4391  t-loss:0.0535, loss-lb:0.0365, loss-ulb:0.0124, weight:1.37, lr:0.0007
[00:04:17.996] iteration:4392  t-loss:0.0318, loss-lb:0.0299, loss-ulb:0.0014, weight:1.37, lr:0.0007
[00:04:18.385] iteration:4393  t-loss:0.0478, loss-lb:0.0448, loss-ulb:0.0022, weight:1.37, lr:0.0007
[00:04:18.768] iteration:4394  t-loss:0.0255, loss-lb:0.0194, loss-ulb:0.0044, weight:1.37, lr:0.0007
[00:04:19.148] iteration:4395  t-loss:0.0213, loss-lb:0.0185, loss-ulb:0.0020, weight:1.37, lr:0.0007
[00:04:19.536] iteration:4396  t-loss:0.1026, loss-lb:0.0777, loss-ulb:0.0182, weight:1.37, lr:0.0007
[00:04:19.923] iteration:4397  t-loss:0.0538, loss-lb:0.0296, loss-ulb:0.0177, weight:1.37, lr:0.0007
[00:04:20.304] iteration:4398  t-loss:0.0596, loss-lb:0.0234, loss-ulb:0.0264, weight:1.37, lr:0.0007
[00:04:20.680] iteration:4399  t-loss:0.0243, loss-lb:0.0218, loss-ulb:0.0018, weight:1.37, lr:0.0007
[00:04:21.065] iteration:4400  t-loss:0.0653, loss-lb:0.0514, loss-ulb:0.0101, weight:1.37, lr:0.0007
[00:04:21.441] iteration:4401  t-loss:0.0304, loss-lb:0.0256, loss-ulb:0.0035, weight:1.37, lr:0.0007
[00:04:21.818] iteration:4402  t-loss:0.0318, loss-lb:0.0195, loss-ulb:0.0089, weight:1.37, lr:0.0007
[00:04:22.196] iteration:4403  t-loss:0.0721, loss-lb:0.0564, loss-ulb:0.0114, weight:1.37, lr:0.0007
[00:04:22.577] iteration:4404  t-loss:0.0674, loss-lb:0.0522, loss-ulb:0.0111, weight:1.37, lr:0.0007
[00:04:22.959] iteration:4405  t-loss:0.0577, loss-lb:0.0493, loss-ulb:0.0061, weight:1.37, lr:0.0007
[00:04:23.335] iteration:4406  t-loss:0.0413, loss-lb:0.0265, loss-ulb:0.0108, weight:1.37, lr:0.0007
[00:04:23.714] iteration:4407  t-loss:0.0901, loss-lb:0.0665, loss-ulb:0.0172, weight:1.37, lr:0.0007
[00:04:24.093] iteration:4408  t-loss:0.0591, loss-lb:0.0465, loss-ulb:0.0092, weight:1.37, lr:0.0007
[00:04:25.340] iteration:4409  t-loss:0.0733, loss-lb:0.0565, loss-ulb:0.0122, weight:1.37, lr:0.0007
[00:04:25.724] iteration:4410  t-loss:0.0498, loss-lb:0.0374, loss-ulb:0.0090, weight:1.37, lr:0.0007
[00:04:26.101] iteration:4411  t-loss:0.0392, loss-lb:0.0201, loss-ulb:0.0139, weight:1.37, lr:0.0007
[00:04:26.473] iteration:4412  t-loss:0.0326, loss-lb:0.0247, loss-ulb:0.0058, weight:1.37, lr:0.0007
[00:04:26.851] iteration:4413  t-loss:0.0566, loss-lb:0.0250, loss-ulb:0.0231, weight:1.37, lr:0.0007
[00:04:27.228] iteration:4414  t-loss:0.0329, loss-lb:0.0282, loss-ulb:0.0034, weight:1.37, lr:0.0007
[00:04:27.605] iteration:4415  t-loss:0.0299, loss-lb:0.0187, loss-ulb:0.0082, weight:1.37, lr:0.0007
[00:04:27.980] iteration:4416  t-loss:0.0566, loss-lb:0.0513, loss-ulb:0.0038, weight:1.37, lr:0.0007
[00:04:28.402] iteration:4417  t-loss:0.0570, loss-lb:0.0385, loss-ulb:0.0135, weight:1.37, lr:0.0007
[00:04:28.848] iteration:4418  t-loss:0.0531, loss-lb:0.0488, loss-ulb:0.0032, weight:1.37, lr:0.0007
[00:04:29.271] iteration:4419  t-loss:0.0246, loss-lb:0.0193, loss-ulb:0.0039, weight:1.37, lr:0.0007
[00:04:29.694] iteration:4420  t-loss:0.1039, loss-lb:0.0439, loss-ulb:0.0438, weight:1.37, lr:0.0007
[00:04:30.106] iteration:4421  t-loss:0.0556, loss-lb:0.0379, loss-ulb:0.0129, weight:1.37, lr:0.0007
[00:04:30.492] iteration:4422  t-loss:0.0294, loss-lb:0.0236, loss-ulb:0.0043, weight:1.37, lr:0.0007
[00:04:30.878] iteration:4423  t-loss:0.1048, loss-lb:0.0395, loss-ulb:0.0476, weight:1.37, lr:0.0007
[00:04:31.257] iteration:4424  t-loss:0.0445, loss-lb:0.0220, loss-ulb:0.0164, weight:1.37, lr:0.0007
[00:04:31.638] iteration:4425  t-loss:0.0638, loss-lb:0.0327, loss-ulb:0.0227, weight:1.37, lr:0.0007
[00:04:32.020] iteration:4426  t-loss:0.0548, loss-lb:0.0442, loss-ulb:0.0077, weight:1.37, lr:0.0007
[00:04:32.401] iteration:4427  t-loss:0.0354, loss-lb:0.0255, loss-ulb:0.0073, weight:1.37, lr:0.0007
[00:04:32.781] iteration:4428  t-loss:0.0818, loss-lb:0.0658, loss-ulb:0.0117, weight:1.37, lr:0.0007
[00:04:33.164] iteration:4429  t-loss:0.0598, loss-lb:0.0396, loss-ulb:0.0147, weight:1.37, lr:0.0007
[00:04:33.538] iteration:4430  t-loss:0.0896, loss-lb:0.0822, loss-ulb:0.0054, weight:1.37, lr:0.0007
[00:04:33.914] iteration:4431  t-loss:0.0591, loss-lb:0.0318, loss-ulb:0.0199, weight:1.37, lr:0.0007
[00:04:34.292] iteration:4432  t-loss:0.0538, loss-lb:0.0213, loss-ulb:0.0237, weight:1.37, lr:0.0007
[00:04:34.677] iteration:4433  t-loss:0.0367, loss-lb:0.0272, loss-ulb:0.0069, weight:1.37, lr:0.0007
[00:04:35.052] iteration:4434  t-loss:0.0657, loss-lb:0.0269, loss-ulb:0.0283, weight:1.37, lr:0.0007
[00:04:35.432] iteration:4435  t-loss:0.0979, loss-lb:0.0538, loss-ulb:0.0322, weight:1.37, lr:0.0007
[00:04:35.810] iteration:4436  t-loss:0.0551, loss-lb:0.0486, loss-ulb:0.0048, weight:1.37, lr:0.0007
[00:04:36.188] iteration:4437  t-loss:0.0366, loss-lb:0.0237, loss-ulb:0.0094, weight:1.37, lr:0.0007
[00:04:36.570] iteration:4438  t-loss:0.0638, loss-lb:0.0424, loss-ulb:0.0156, weight:1.37, lr:0.0007
[00:04:36.948] iteration:4439  t-loss:0.0614, loss-lb:0.0517, loss-ulb:0.0071, weight:1.37, lr:0.0007
[00:04:37.317] iteration:4440  t-loss:0.0827, loss-lb:0.0731, loss-ulb:0.0070, weight:1.37, lr:0.0007
[00:04:37.692] iteration:4441  t-loss:0.0587, loss-lb:0.0537, loss-ulb:0.0036, weight:1.37, lr:0.0007
[00:04:38.071] iteration:4442  t-loss:0.0612, loss-lb:0.0414, loss-ulb:0.0144, weight:1.37, lr:0.0007
[00:04:38.450] iteration:4443  t-loss:0.0875, loss-lb:0.0400, loss-ulb:0.0346, weight:1.37, lr:0.0007
[00:04:38.829] iteration:4444  t-loss:0.0552, loss-lb:0.0521, loss-ulb:0.0022, weight:1.37, lr:0.0007
[00:04:39.206] iteration:4445  t-loss:0.0506, loss-lb:0.0268, loss-ulb:0.0174, weight:1.37, lr:0.0007
[00:04:39.579] iteration:4446  t-loss:0.0268, loss-lb:0.0233, loss-ulb:0.0025, weight:1.37, lr:0.0007
[00:05:42.511] iteration 4446 : dice_score: 0.844978 best_dice: 0.849700
[00:05:42.511]  <<Test>> - Ep:116  - Dice-S/T:85.17/84.50, Best-S:85.17, Best-T:84.97
[00:05:42.512]           - AvgLoss(lb/ulb/all):0.04/0.01/0.06
[00:05:43.620] iteration:4447  t-loss:0.1208, loss-lb:0.1156, loss-ulb:0.0038, weight:1.37, lr:0.0007
[00:05:44.015] iteration:4448  t-loss:0.0535, loss-lb:0.0235, loss-ulb:0.0218, weight:1.37, lr:0.0007
[00:05:44.394] iteration:4449  t-loss:0.0352, loss-lb:0.0316, loss-ulb:0.0026, weight:1.37, lr:0.0007
[00:05:44.774] iteration:4450  t-loss:0.0790, loss-lb:0.0402, loss-ulb:0.0283, weight:1.37, lr:0.0007
[00:05:45.157] iteration:4451  t-loss:0.0703, loss-lb:0.0398, loss-ulb:0.0223, weight:1.37, lr:0.0007
[00:05:45.544] iteration:4452  t-loss:0.0497, loss-lb:0.0444, loss-ulb:0.0038, weight:1.37, lr:0.0007
[00:05:45.931] iteration:4453  t-loss:0.0637, loss-lb:0.0397, loss-ulb:0.0175, weight:1.37, lr:0.0007
[00:05:46.308] iteration:4454  t-loss:0.0808, loss-lb:0.0550, loss-ulb:0.0188, weight:1.37, lr:0.0007
[00:05:46.694] iteration:4455  t-loss:0.0527, loss-lb:0.0366, loss-ulb:0.0117, weight:1.37, lr:0.0007
[00:05:47.079] iteration:4456  t-loss:0.0578, loss-lb:0.0483, loss-ulb:0.0069, weight:1.37, lr:0.0007
[00:05:47.461] iteration:4457  t-loss:0.0893, loss-lb:0.0666, loss-ulb:0.0165, weight:1.37, lr:0.0007
[00:05:47.839] iteration:4458  t-loss:0.0371, loss-lb:0.0331, loss-ulb:0.0029, weight:1.37, lr:0.0007
[00:05:48.222] iteration:4459  t-loss:0.0614, loss-lb:0.0538, loss-ulb:0.0055, weight:1.37, lr:0.0007
[00:05:48.603] iteration:4460  t-loss:0.0885, loss-lb:0.0741, loss-ulb:0.0104, weight:1.37, lr:0.0007
[00:05:48.982] iteration:4461  t-loss:0.0938, loss-lb:0.0633, loss-ulb:0.0222, weight:1.37, lr:0.0007
[00:05:49.362] iteration:4462  t-loss:0.0605, loss-lb:0.0405, loss-ulb:0.0146, weight:1.37, lr:0.0007
[00:05:49.747] iteration:4463  t-loss:0.0411, loss-lb:0.0298, loss-ulb:0.0083, weight:1.37, lr:0.0007
[00:05:50.117] iteration:4464  t-loss:0.1228, loss-lb:0.0336, loss-ulb:0.0650, weight:1.37, lr:0.0007
[00:05:50.495] iteration:4465  t-loss:0.0686, loss-lb:0.0405, loss-ulb:0.0205, weight:1.37, lr:0.0007
[00:05:50.880] iteration:4466  t-loss:0.0485, loss-lb:0.0408, loss-ulb:0.0056, weight:1.37, lr:0.0007
[00:05:51.263] iteration:4467  t-loss:0.0474, loss-lb:0.0282, loss-ulb:0.0141, weight:1.37, lr:0.0007
[00:05:51.643] iteration:4468  t-loss:0.0541, loss-lb:0.0328, loss-ulb:0.0155, weight:1.37, lr:0.0007
[00:05:52.023] iteration:4469  t-loss:0.0608, loss-lb:0.0502, loss-ulb:0.0078, weight:1.37, lr:0.0007
[00:05:52.402] iteration:4470  t-loss:0.0531, loss-lb:0.0344, loss-ulb:0.0137, weight:1.37, lr:0.0007
[00:05:52.787] iteration:4471  t-loss:0.0517, loss-lb:0.0271, loss-ulb:0.0179, weight:1.37, lr:0.0007
[00:05:53.182] iteration:4472  t-loss:0.0876, loss-lb:0.0572, loss-ulb:0.0222, weight:1.37, lr:0.0007
[00:05:53.561] iteration:4473  t-loss:0.1868, loss-lb:0.1619, loss-ulb:0.0182, weight:1.37, lr:0.0007
[00:05:53.949] iteration:4474  t-loss:0.0800, loss-lb:0.0582, loss-ulb:0.0159, weight:1.37, lr:0.0007
[00:05:54.326] iteration:4475  t-loss:0.0502, loss-lb:0.0295, loss-ulb:0.0151, weight:1.37, lr:0.0007
[00:05:54.704] iteration:4476  t-loss:0.0615, loss-lb:0.0278, loss-ulb:0.0246, weight:1.37, lr:0.0007
[00:05:55.081] iteration:4477  t-loss:0.0652, loss-lb:0.0604, loss-ulb:0.0035, weight:1.37, lr:0.0007
[00:05:55.456] iteration:4478  t-loss:0.0403, loss-lb:0.0329, loss-ulb:0.0054, weight:1.37, lr:0.0007
[00:05:55.833] iteration:4479  t-loss:0.0889, loss-lb:0.0544, loss-ulb:0.0252, weight:1.37, lr:0.0007
[00:05:56.214] iteration:4480  t-loss:0.0541, loss-lb:0.0349, loss-ulb:0.0140, weight:1.37, lr:0.0007
[00:05:56.590] iteration:4481  t-loss:0.0792, loss-lb:0.0655, loss-ulb:0.0100, weight:1.37, lr:0.0007
[00:05:56.967] iteration:4482  t-loss:0.0743, loss-lb:0.0411, loss-ulb:0.0242, weight:1.37, lr:0.0007
[00:05:57.343] iteration:4483  t-loss:0.0399, loss-lb:0.0319, loss-ulb:0.0058, weight:1.37, lr:0.0007
[00:05:57.722] iteration:4484  t-loss:0.0627, loss-lb:0.0489, loss-ulb:0.0101, weight:1.37, lr:0.0007
[00:05:59.002] iteration:4485  t-loss:0.0896, loss-lb:0.0848, loss-ulb:0.0035, weight:1.37, lr:0.0007
[00:05:59.386] iteration:4486  t-loss:0.0755, loss-lb:0.0363, loss-ulb:0.0286, weight:1.37, lr:0.0007
[00:05:59.767] iteration:4487  t-loss:0.0654, loss-lb:0.0517, loss-ulb:0.0100, weight:1.37, lr:0.0007
[00:06:00.147] iteration:4488  t-loss:0.0270, loss-lb:0.0197, loss-ulb:0.0053, weight:1.37, lr:0.0007
[00:06:00.531] iteration:4489  t-loss:0.0707, loss-lb:0.0363, loss-ulb:0.0252, weight:1.37, lr:0.0007
[00:06:00.912] iteration:4490  t-loss:0.0435, loss-lb:0.0280, loss-ulb:0.0113, weight:1.37, lr:0.0007
[00:06:01.291] iteration:4491  t-loss:0.0677, loss-lb:0.0501, loss-ulb:0.0128, weight:1.37, lr:0.0007
[00:06:01.667] iteration:4492  t-loss:0.0443, loss-lb:0.0406, loss-ulb:0.0027, weight:1.37, lr:0.0007
[00:06:02.052] iteration:4493  t-loss:0.0626, loss-lb:0.0565, loss-ulb:0.0045, weight:1.37, lr:0.0007
[00:06:02.436] iteration:4494  t-loss:0.0247, loss-lb:0.0218, loss-ulb:0.0021, weight:1.37, lr:0.0007
[00:06:02.817] iteration:4495  t-loss:0.0797, loss-lb:0.0652, loss-ulb:0.0106, weight:1.37, lr:0.0007
[00:06:03.198] iteration:4496  t-loss:0.1052, loss-lb:0.0572, loss-ulb:0.0350, weight:1.37, lr:0.0007
[00:06:03.575] iteration:4497  t-loss:0.0339, loss-lb:0.0290, loss-ulb:0.0035, weight:1.37, lr:0.0007
[00:06:03.969] iteration:4498  t-loss:0.0356, loss-lb:0.0221, loss-ulb:0.0099, weight:1.37, lr:0.0007
[00:06:04.379] iteration:4499  t-loss:0.0341, loss-lb:0.0239, loss-ulb:0.0074, weight:1.37, lr:0.0007
[00:06:04.773] iteration:4500  t-loss:0.0576, loss-lb:0.0374, loss-ulb:0.0147, weight:1.37, lr:0.0007
[00:06:05.159] iteration:4501  t-loss:0.0770, loss-lb:0.0383, loss-ulb:0.0264, weight:1.46, lr:0.0007
[00:06:05.545] iteration:4502  t-loss:0.0635, loss-lb:0.0482, loss-ulb:0.0104, weight:1.46, lr:0.0007
[00:06:05.929] iteration:4503  t-loss:0.0535, loss-lb:0.0342, loss-ulb:0.0131, weight:1.46, lr:0.0007
[00:06:06.309] iteration:4504  t-loss:0.1735, loss-lb:0.1283, loss-ulb:0.0309, weight:1.46, lr:0.0007
[00:06:06.689] iteration:4505  t-loss:0.0951, loss-lb:0.0386, loss-ulb:0.0386, weight:1.46, lr:0.0007
[00:06:07.076] iteration:4506  t-loss:0.0663, loss-lb:0.0517, loss-ulb:0.0099, weight:1.46, lr:0.0007
[00:06:07.450] iteration:4507  t-loss:0.0344, loss-lb:0.0303, loss-ulb:0.0028, weight:1.46, lr:0.0007
[00:06:07.810] iteration:4508  t-loss:0.0647, loss-lb:0.0496, loss-ulb:0.0103, weight:1.46, lr:0.0007
[00:06:08.191] iteration:4509  t-loss:0.0833, loss-lb:0.0411, loss-ulb:0.0288, weight:1.46, lr:0.0007
[00:06:08.572] iteration:4510  t-loss:0.0515, loss-lb:0.0375, loss-ulb:0.0096, weight:1.46, lr:0.0007
[00:06:08.953] iteration:4511  t-loss:0.0365, loss-lb:0.0296, loss-ulb:0.0047, weight:1.46, lr:0.0007
[00:06:09.333] iteration:4512  t-loss:0.1024, loss-lb:0.0820, loss-ulb:0.0139, weight:1.46, lr:0.0007
[00:06:09.713] iteration:4513  t-loss:0.0918, loss-lb:0.0851, loss-ulb:0.0046, weight:1.46, lr:0.0007
[00:06:10.095] iteration:4514  t-loss:0.0654, loss-lb:0.0489, loss-ulb:0.0113, weight:1.46, lr:0.0007
[00:06:10.470] iteration:4515  t-loss:0.0376, loss-lb:0.0335, loss-ulb:0.0028, weight:1.46, lr:0.0007
[00:06:10.848] iteration:4516  t-loss:0.1412, loss-lb:0.0773, loss-ulb:0.0437, weight:1.46, lr:0.0007
[00:06:11.225] iteration:4517  t-loss:0.0497, loss-lb:0.0339, loss-ulb:0.0108, weight:1.46, lr:0.0007
[00:06:11.587] iteration:4518  t-loss:0.0817, loss-lb:0.0729, loss-ulb:0.0061, weight:1.46, lr:0.0007
[00:06:11.966] iteration:4519  t-loss:0.1039, loss-lb:0.0571, loss-ulb:0.0320, weight:1.46, lr:0.0007
[00:06:12.340] iteration:4520  t-loss:0.0469, loss-lb:0.0234, loss-ulb:0.0161, weight:1.46, lr:0.0007
[00:06:12.720] iteration:4521  t-loss:0.0563, loss-lb:0.0289, loss-ulb:0.0187, weight:1.46, lr:0.0007
[00:06:13.093] iteration:4522  t-loss:0.0383, loss-lb:0.0263, loss-ulb:0.0082, weight:1.46, lr:0.0007
[00:06:14.291] iteration:4523  t-loss:0.0780, loss-lb:0.0417, loss-ulb:0.0248, weight:1.46, lr:0.0007
[00:06:14.691] iteration:4524  t-loss:0.1095, loss-lb:0.1009, loss-ulb:0.0059, weight:1.46, lr:0.0007
[00:06:15.084] iteration:4525  t-loss:0.0641, loss-lb:0.0597, loss-ulb:0.0030, weight:1.46, lr:0.0007
[00:06:15.465] iteration:4526  t-loss:0.0730, loss-lb:0.0468, loss-ulb:0.0179, weight:1.46, lr:0.0007
[00:06:15.851] iteration:4527  t-loss:0.0323, loss-lb:0.0272, loss-ulb:0.0035, weight:1.46, lr:0.0007
[00:06:16.225] iteration:4528  t-loss:0.0241, loss-lb:0.0217, loss-ulb:0.0016, weight:1.46, lr:0.0007
[00:06:16.607] iteration:4529  t-loss:0.0665, loss-lb:0.0403, loss-ulb:0.0179, weight:1.46, lr:0.0007
[00:06:16.985] iteration:4530  t-loss:0.0441, loss-lb:0.0258, loss-ulb:0.0125, weight:1.46, lr:0.0007
[00:06:17.362] iteration:4531  t-loss:0.0522, loss-lb:0.0323, loss-ulb:0.0136, weight:1.46, lr:0.0007
[00:06:17.742] iteration:4532  t-loss:0.0828, loss-lb:0.0360, loss-ulb:0.0319, weight:1.46, lr:0.0007
[00:06:18.122] iteration:4533  t-loss:0.0238, loss-lb:0.0220, loss-ulb:0.0012, weight:1.46, lr:0.0007
[00:06:18.500] iteration:4534  t-loss:0.0414, loss-lb:0.0219, loss-ulb:0.0134, weight:1.46, lr:0.0007
[00:06:18.881] iteration:4535  t-loss:0.0374, loss-lb:0.0283, loss-ulb:0.0063, weight:1.46, lr:0.0007
[00:06:19.257] iteration:4536  t-loss:0.0236, loss-lb:0.0190, loss-ulb:0.0031, weight:1.46, lr:0.0007
[00:06:19.658] iteration:4537  t-loss:0.0772, loss-lb:0.0568, loss-ulb:0.0139, weight:1.46, lr:0.0007
[00:06:20.053] iteration:4538  t-loss:0.0525, loss-lb:0.0252, loss-ulb:0.0187, weight:1.46, lr:0.0007
[00:06:20.443] iteration:4539  t-loss:0.0765, loss-lb:0.0447, loss-ulb:0.0218, weight:1.46, lr:0.0007
[00:06:20.826] iteration:4540  t-loss:0.0536, loss-lb:0.0358, loss-ulb:0.0122, weight:1.46, lr:0.0007
[00:06:21.206] iteration:4541  t-loss:0.0492, loss-lb:0.0339, loss-ulb:0.0105, weight:1.46, lr:0.0007
[00:06:21.593] iteration:4542  t-loss:0.0631, loss-lb:0.0254, loss-ulb:0.0258, weight:1.46, lr:0.0007
[00:06:21.976] iteration:4543  t-loss:0.0686, loss-lb:0.0450, loss-ulb:0.0161, weight:1.46, lr:0.0007
[00:06:22.358] iteration:4544  t-loss:0.0562, loss-lb:0.0182, loss-ulb:0.0260, weight:1.46, lr:0.0007
[00:06:22.734] iteration:4545  t-loss:0.0477, loss-lb:0.0205, loss-ulb:0.0186, weight:1.46, lr:0.0007
[00:06:23.117] iteration:4546  t-loss:0.0692, loss-lb:0.0662, loss-ulb:0.0020, weight:1.46, lr:0.0007
[00:06:23.495] iteration:4547  t-loss:0.0579, loss-lb:0.0426, loss-ulb:0.0105, weight:1.46, lr:0.0007
[00:06:23.877] iteration:4548  t-loss:0.0926, loss-lb:0.0640, loss-ulb:0.0195, weight:1.46, lr:0.0007
[00:06:24.255] iteration:4549  t-loss:0.0275, loss-lb:0.0247, loss-ulb:0.0019, weight:1.46, lr:0.0007
[00:06:24.635] iteration:4550  t-loss:0.0321, loss-lb:0.0282, loss-ulb:0.0026, weight:1.46, lr:0.0007
[00:06:25.012] iteration:4551  t-loss:0.0265, loss-lb:0.0235, loss-ulb:0.0020, weight:1.46, lr:0.0007
[00:06:25.396] iteration:4552  t-loss:0.0544, loss-lb:0.0413, loss-ulb:0.0089, weight:1.46, lr:0.0007
[00:06:25.776] iteration:4553  t-loss:0.0397, loss-lb:0.0262, loss-ulb:0.0092, weight:1.46, lr:0.0007
[00:06:26.156] iteration:4554  t-loss:0.0317, loss-lb:0.0298, loss-ulb:0.0013, weight:1.46, lr:0.0007
[00:06:26.529] iteration:4555  t-loss:0.0510, loss-lb:0.0395, loss-ulb:0.0079, weight:1.46, lr:0.0007
[00:06:26.909] iteration:4556  t-loss:0.0682, loss-lb:0.0520, loss-ulb:0.0111, weight:1.46, lr:0.0007
[00:06:27.285] iteration:4557  t-loss:0.0608, loss-lb:0.0550, loss-ulb:0.0039, weight:1.46, lr:0.0007
[00:06:27.663] iteration:4558  t-loss:0.0643, loss-lb:0.0479, loss-ulb:0.0112, weight:1.46, lr:0.0007
[00:06:28.036] iteration:4559  t-loss:0.0965, loss-lb:0.0917, loss-ulb:0.0033, weight:1.46, lr:0.0007
[00:06:28.409] iteration:4560  t-loss:0.0442, loss-lb:0.0375, loss-ulb:0.0046, weight:1.46, lr:0.0007
[00:06:29.708] iteration:4561  t-loss:0.0483, loss-lb:0.0370, loss-ulb:0.0078, weight:1.46, lr:0.0007
[00:06:30.116] iteration:4562  t-loss:0.0716, loss-lb:0.0580, loss-ulb:0.0093, weight:1.46, lr:0.0007
[00:06:30.499] iteration:4563  t-loss:0.0335, loss-lb:0.0314, loss-ulb:0.0014, weight:1.46, lr:0.0007
[00:06:30.878] iteration:4564  t-loss:0.0981, loss-lb:0.0504, loss-ulb:0.0326, weight:1.46, lr:0.0007
[00:06:31.258] iteration:4565  t-loss:0.0763, loss-lb:0.0417, loss-ulb:0.0236, weight:1.46, lr:0.0007
[00:06:31.635] iteration:4566  t-loss:0.0426, loss-lb:0.0251, loss-ulb:0.0120, weight:1.46, lr:0.0007
[00:06:32.012] iteration:4567  t-loss:0.0744, loss-lb:0.0493, loss-ulb:0.0171, weight:1.46, lr:0.0007
[00:06:32.392] iteration:4568  t-loss:0.0824, loss-lb:0.0485, loss-ulb:0.0232, weight:1.46, lr:0.0007
[00:06:32.773] iteration:4569  t-loss:0.0535, loss-lb:0.0383, loss-ulb:0.0104, weight:1.46, lr:0.0007
[00:06:33.146] iteration:4570  t-loss:0.0576, loss-lb:0.0541, loss-ulb:0.0024, weight:1.46, lr:0.0007
[00:06:33.524] iteration:4571  t-loss:0.0427, loss-lb:0.0204, loss-ulb:0.0152, weight:1.46, lr:0.0007
[00:06:33.905] iteration:4572  t-loss:0.0364, loss-lb:0.0282, loss-ulb:0.0056, weight:1.46, lr:0.0007
[00:06:34.298] iteration:4573  t-loss:0.0530, loss-lb:0.0273, loss-ulb:0.0175, weight:1.46, lr:0.0007
[00:06:34.694] iteration:4574  t-loss:0.0359, loss-lb:0.0300, loss-ulb:0.0040, weight:1.46, lr:0.0007
[00:06:35.088] iteration:4575  t-loss:0.0350, loss-lb:0.0302, loss-ulb:0.0033, weight:1.46, lr:0.0007
[00:06:35.506] iteration:4576  t-loss:0.1028, loss-lb:0.0605, loss-ulb:0.0289, weight:1.46, lr:0.0007
[00:06:35.906] iteration:4577  t-loss:0.0596, loss-lb:0.0440, loss-ulb:0.0107, weight:1.46, lr:0.0007
[00:06:36.307] iteration:4578  t-loss:0.0644, loss-lb:0.0446, loss-ulb:0.0135, weight:1.46, lr:0.0007
[00:06:36.694] iteration:4579  t-loss:0.0416, loss-lb:0.0363, loss-ulb:0.0036, weight:1.46, lr:0.0007
[00:06:37.069] iteration:4580  t-loss:0.0383, loss-lb:0.0247, loss-ulb:0.0093, weight:1.46, lr:0.0007
[00:06:37.449] iteration:4581  t-loss:0.0647, loss-lb:0.0522, loss-ulb:0.0085, weight:1.46, lr:0.0007
[00:06:37.835] iteration:4582  t-loss:0.0494, loss-lb:0.0348, loss-ulb:0.0100, weight:1.46, lr:0.0007
[00:06:38.215] iteration:4583  t-loss:0.0430, loss-lb:0.0232, loss-ulb:0.0135, weight:1.46, lr:0.0007
[00:06:38.595] iteration:4584  t-loss:0.0789, loss-lb:0.0696, loss-ulb:0.0064, weight:1.46, lr:0.0007
[00:06:38.983] iteration:4585  t-loss:0.0696, loss-lb:0.0495, loss-ulb:0.0138, weight:1.46, lr:0.0007
[00:06:39.361] iteration:4586  t-loss:0.0437, loss-lb:0.0380, loss-ulb:0.0039, weight:1.46, lr:0.0007
[00:06:39.741] iteration:4587  t-loss:0.0301, loss-lb:0.0265, loss-ulb:0.0025, weight:1.46, lr:0.0007
[00:06:40.124] iteration:4588  t-loss:0.0459, loss-lb:0.0380, loss-ulb:0.0055, weight:1.46, lr:0.0007
[00:06:40.520] iteration:4589  t-loss:0.0713, loss-lb:0.0565, loss-ulb:0.0101, weight:1.46, lr:0.0007
[00:06:40.901] iteration:4590  t-loss:0.0450, loss-lb:0.0233, loss-ulb:0.0148, weight:1.46, lr:0.0007
[00:06:41.277] iteration:4591  t-loss:0.0439, loss-lb:0.0372, loss-ulb:0.0046, weight:1.46, lr:0.0007
[00:06:41.656] iteration:4592  t-loss:0.0655, loss-lb:0.0563, loss-ulb:0.0063, weight:1.46, lr:0.0007
[00:06:42.037] iteration:4593  t-loss:0.0687, loss-lb:0.0483, loss-ulb:0.0140, weight:1.46, lr:0.0007
[00:06:42.412] iteration:4594  t-loss:0.0289, loss-lb:0.0229, loss-ulb:0.0042, weight:1.46, lr:0.0007
[00:06:42.786] iteration:4595  t-loss:0.0617, loss-lb:0.0544, loss-ulb:0.0050, weight:1.46, lr:0.0007
[00:06:43.161] iteration:4596  t-loss:0.0462, loss-lb:0.0373, loss-ulb:0.0060, weight:1.46, lr:0.0007
[00:06:43.537] iteration:4597  t-loss:0.0527, loss-lb:0.0399, loss-ulb:0.0088, weight:1.46, lr:0.0007
[00:06:43.916] iteration:4598  t-loss:0.1186, loss-lb:0.0957, loss-ulb:0.0156, weight:1.46, lr:0.0007
[00:07:46.524] iteration 4598 : dice_score: 0.833699 best_dice: 0.849700
[00:07:46.524]  <<Test>> - Ep:120  - Dice-S/T:83.48/83.37, Best-S:85.17, Best-T:84.97
[00:07:46.524]           - AvgLoss(lb/ulb/all):0.04/0.01/0.06
[00:07:47.774] iteration:4599  t-loss:0.0922, loss-lb:0.0590, loss-ulb:0.0227, weight:1.46, lr:0.0007
[00:07:48.191] iteration:4600  t-loss:0.0480, loss-lb:0.0334, loss-ulb:0.0100, weight:1.46, lr:0.0007
[00:07:48.577] iteration:4601  t-loss:0.0354, loss-lb:0.0251, loss-ulb:0.0071, weight:1.46, lr:0.0007
[00:07:48.953] iteration:4602  t-loss:0.0480, loss-lb:0.0208, loss-ulb:0.0186, weight:1.46, lr:0.0007
[00:07:49.333] iteration:4603  t-loss:0.0367, loss-lb:0.0215, loss-ulb:0.0104, weight:1.46, lr:0.0007
[00:07:49.710] iteration:4604  t-loss:0.0509, loss-lb:0.0342, loss-ulb:0.0114, weight:1.46, lr:0.0007
[00:07:50.095] iteration:4605  t-loss:0.0417, loss-lb:0.0196, loss-ulb:0.0151, weight:1.46, lr:0.0007
[00:07:50.474] iteration:4606  t-loss:0.0767, loss-lb:0.0579, loss-ulb:0.0129, weight:1.46, lr:0.0007
[00:07:50.851] iteration:4607  t-loss:0.0211, loss-lb:0.0187, loss-ulb:0.0016, weight:1.46, lr:0.0007
[00:07:51.231] iteration:4608  t-loss:0.0415, loss-lb:0.0280, loss-ulb:0.0092, weight:1.46, lr:0.0007
[00:07:51.612] iteration:4609  t-loss:0.0613, loss-lb:0.0536, loss-ulb:0.0053, weight:1.46, lr:0.0007
[00:07:51.992] iteration:4610  t-loss:0.0459, loss-lb:0.0211, loss-ulb:0.0169, weight:1.46, lr:0.0007
[00:07:52.371] iteration:4611  t-loss:0.0295, loss-lb:0.0273, loss-ulb:0.0015, weight:1.46, lr:0.0007
[00:07:52.753] iteration:4612  t-loss:0.0272, loss-lb:0.0253, loss-ulb:0.0013, weight:1.46, lr:0.0007
[00:07:53.135] iteration:4613  t-loss:0.0537, loss-lb:0.0448, loss-ulb:0.0061, weight:1.46, lr:0.0007
[00:07:53.524] iteration:4614  t-loss:0.0377, loss-lb:0.0337, loss-ulb:0.0027, weight:1.46, lr:0.0007
[00:07:53.905] iteration:4615  t-loss:0.0261, loss-lb:0.0230, loss-ulb:0.0021, weight:1.46, lr:0.0007
[00:07:54.289] iteration:4616  t-loss:0.0618, loss-lb:0.0541, loss-ulb:0.0052, weight:1.46, lr:0.0007
[00:07:54.669] iteration:4617  t-loss:0.0594, loss-lb:0.0528, loss-ulb:0.0045, weight:1.46, lr:0.0007
[00:07:55.049] iteration:4618  t-loss:0.0267, loss-lb:0.0214, loss-ulb:0.0037, weight:1.46, lr:0.0007
[00:07:55.431] iteration:4619  t-loss:0.0299, loss-lb:0.0243, loss-ulb:0.0038, weight:1.46, lr:0.0007
[00:07:55.813] iteration:4620  t-loss:0.0374, loss-lb:0.0267, loss-ulb:0.0074, weight:1.46, lr:0.0007
[00:07:56.196] iteration:4621  t-loss:0.0664, loss-lb:0.0297, loss-ulb:0.0251, weight:1.46, lr:0.0007
[00:07:56.582] iteration:4622  t-loss:0.0327, loss-lb:0.0300, loss-ulb:0.0019, weight:1.46, lr:0.0007
[00:07:56.967] iteration:4623  t-loss:0.0600, loss-lb:0.0415, loss-ulb:0.0127, weight:1.46, lr:0.0007
[00:07:57.348] iteration:4624  t-loss:0.0508, loss-lb:0.0464, loss-ulb:0.0030, weight:1.46, lr:0.0007
[00:07:57.731] iteration:4625  t-loss:0.0426, loss-lb:0.0402, loss-ulb:0.0016, weight:1.46, lr:0.0007
[00:07:58.121] iteration:4626  t-loss:0.0697, loss-lb:0.0533, loss-ulb:0.0112, weight:1.46, lr:0.0007
[00:07:58.499] iteration:4627  t-loss:0.0858, loss-lb:0.0714, loss-ulb:0.0099, weight:1.46, lr:0.0007
[00:07:58.881] iteration:4628  t-loss:0.0278, loss-lb:0.0188, loss-ulb:0.0062, weight:1.46, lr:0.0007
[00:07:59.256] iteration:4629  t-loss:0.0372, loss-lb:0.0250, loss-ulb:0.0083, weight:1.46, lr:0.0007
[00:07:59.631] iteration:4630  t-loss:0.0270, loss-lb:0.0235, loss-ulb:0.0024, weight:1.46, lr:0.0007
[00:08:00.010] iteration:4631  t-loss:0.0405, loss-lb:0.0192, loss-ulb:0.0145, weight:1.46, lr:0.0007
[00:08:00.388] iteration:4632  t-loss:0.0410, loss-lb:0.0382, loss-ulb:0.0019, weight:1.46, lr:0.0007
[00:08:00.768] iteration:4633  t-loss:0.0436, loss-lb:0.0382, loss-ulb:0.0037, weight:1.46, lr:0.0007
[00:08:01.146] iteration:4634  t-loss:0.0400, loss-lb:0.0292, loss-ulb:0.0074, weight:1.46, lr:0.0007
[00:08:01.525] iteration:4635  t-loss:0.0783, loss-lb:0.0670, loss-ulb:0.0077, weight:1.46, lr:0.0007
[00:08:01.904] iteration:4636  t-loss:0.0565, loss-lb:0.0411, loss-ulb:0.0105, weight:1.46, lr:0.0007
[00:08:03.210] iteration:4637  t-loss:0.0463, loss-lb:0.0346, loss-ulb:0.0080, weight:1.46, lr:0.0007
[00:08:03.592] iteration:4638  t-loss:0.0329, loss-lb:0.0257, loss-ulb:0.0049, weight:1.46, lr:0.0007
[00:08:03.991] iteration:4639  t-loss:0.0527, loss-lb:0.0432, loss-ulb:0.0066, weight:1.46, lr:0.0007
[00:08:04.378] iteration:4640  t-loss:0.0340, loss-lb:0.0202, loss-ulb:0.0094, weight:1.46, lr:0.0007
[00:08:04.766] iteration:4641  t-loss:0.0556, loss-lb:0.0331, loss-ulb:0.0154, weight:1.46, lr:0.0007
[00:08:05.145] iteration:4642  t-loss:0.0513, loss-lb:0.0284, loss-ulb:0.0156, weight:1.46, lr:0.0007
[00:08:05.530] iteration:4643  t-loss:0.0293, loss-lb:0.0231, loss-ulb:0.0043, weight:1.46, lr:0.0007
[00:08:05.916] iteration:4644  t-loss:0.0511, loss-lb:0.0336, loss-ulb:0.0120, weight:1.46, lr:0.0007
[00:08:06.296] iteration:4645  t-loss:0.0612, loss-lb:0.0344, loss-ulb:0.0183, weight:1.46, lr:0.0007
[00:08:06.673] iteration:4646  t-loss:0.0375, loss-lb:0.0214, loss-ulb:0.0110, weight:1.46, lr:0.0007
[00:08:07.050] iteration:4647  t-loss:0.0797, loss-lb:0.0269, loss-ulb:0.0361, weight:1.46, lr:0.0007
[00:08:07.436] iteration:4648  t-loss:0.0459, loss-lb:0.0218, loss-ulb:0.0164, weight:1.46, lr:0.0007
[00:08:07.820] iteration:4649  t-loss:0.0288, loss-lb:0.0255, loss-ulb:0.0022, weight:1.46, lr:0.0007
[00:08:08.196] iteration:4650  t-loss:0.0224, loss-lb:0.0199, loss-ulb:0.0018, weight:1.46, lr:0.0007
[00:08:08.580] iteration:4651  t-loss:0.0488, loss-lb:0.0303, loss-ulb:0.0119, weight:1.55, lr:0.0007
[00:08:08.961] iteration:4652  t-loss:0.0518, loss-lb:0.0239, loss-ulb:0.0180, weight:1.55, lr:0.0007
[00:08:09.344] iteration:4653  t-loss:0.0530, loss-lb:0.0390, loss-ulb:0.0090, weight:1.55, lr:0.0007
[00:08:09.731] iteration:4654  t-loss:0.0941, loss-lb:0.0637, loss-ulb:0.0196, weight:1.55, lr:0.0007
[00:08:10.112] iteration:4655  t-loss:0.0322, loss-lb:0.0203, loss-ulb:0.0077, weight:1.55, lr:0.0007
[00:08:10.495] iteration:4656  t-loss:0.0449, loss-lb:0.0336, loss-ulb:0.0073, weight:1.55, lr:0.0007
[00:08:10.885] iteration:4657  t-loss:0.0292, loss-lb:0.0201, loss-ulb:0.0058, weight:1.55, lr:0.0007
[00:08:11.300] iteration:4658  t-loss:0.0649, loss-lb:0.0423, loss-ulb:0.0146, weight:1.55, lr:0.0007
[00:08:11.688] iteration:4659  t-loss:0.0455, loss-lb:0.0255, loss-ulb:0.0129, weight:1.55, lr:0.0007
[00:08:12.069] iteration:4660  t-loss:0.0468, loss-lb:0.0200, loss-ulb:0.0173, weight:1.55, lr:0.0007
[00:08:12.452] iteration:4661  t-loss:0.1340, loss-lb:0.1103, loss-ulb:0.0153, weight:1.55, lr:0.0007
[00:08:12.833] iteration:4662  t-loss:0.0301, loss-lb:0.0262, loss-ulb:0.0025, weight:1.55, lr:0.0007
[00:08:13.216] iteration:4663  t-loss:0.0728, loss-lb:0.0514, loss-ulb:0.0138, weight:1.55, lr:0.0007
[00:08:13.609] iteration:4664  t-loss:0.0578, loss-lb:0.0426, loss-ulb:0.0098, weight:1.55, lr:0.0007
[00:08:13.989] iteration:4665  t-loss:0.0406, loss-lb:0.0343, loss-ulb:0.0041, weight:1.55, lr:0.0007
[00:08:14.373] iteration:4666  t-loss:0.0596, loss-lb:0.0336, loss-ulb:0.0167, weight:1.55, lr:0.0007
[00:08:14.752] iteration:4667  t-loss:0.0486, loss-lb:0.0299, loss-ulb:0.0120, weight:1.55, lr:0.0007
[00:08:15.130] iteration:4668  t-loss:0.0569, loss-lb:0.0329, loss-ulb:0.0155, weight:1.55, lr:0.0007
[00:08:15.504] iteration:4669  t-loss:0.0484, loss-lb:0.0276, loss-ulb:0.0134, weight:1.55, lr:0.0007
[00:08:15.879] iteration:4670  t-loss:0.0596, loss-lb:0.0447, loss-ulb:0.0096, weight:1.55, lr:0.0007
[00:08:16.252] iteration:4671  t-loss:0.0754, loss-lb:0.0719, loss-ulb:0.0023, weight:1.55, lr:0.0007
[00:08:16.624] iteration:4672  t-loss:0.0534, loss-lb:0.0491, loss-ulb:0.0028, weight:1.55, lr:0.0007
[00:08:16.997] iteration:4673  t-loss:0.0958, loss-lb:0.0329, loss-ulb:0.0405, weight:1.55, lr:0.0007
[00:08:17.369] iteration:4674  t-loss:0.0840, loss-lb:0.0388, loss-ulb:0.0291, weight:1.55, lr:0.0007
[00:08:18.679] iteration:4675  t-loss:0.0526, loss-lb:0.0376, loss-ulb:0.0097, weight:1.55, lr:0.0007
[00:08:19.082] iteration:4676  t-loss:0.0404, loss-lb:0.0370, loss-ulb:0.0022, weight:1.55, lr:0.0007
[00:08:19.470] iteration:4677  t-loss:0.0429, loss-lb:0.0324, loss-ulb:0.0068, weight:1.55, lr:0.0007
[00:08:19.855] iteration:4678  t-loss:0.0448, loss-lb:0.0401, loss-ulb:0.0030, weight:1.55, lr:0.0007
[00:08:20.239] iteration:4679  t-loss:0.0494, loss-lb:0.0366, loss-ulb:0.0082, weight:1.55, lr:0.0007
[00:08:20.624] iteration:4680  t-loss:0.0239, loss-lb:0.0168, loss-ulb:0.0046, weight:1.55, lr:0.0007
[00:08:21.004] iteration:4681  t-loss:0.0560, loss-lb:0.0208, loss-ulb:0.0227, weight:1.55, lr:0.0007
[00:08:21.388] iteration:4682  t-loss:0.0722, loss-lb:0.0498, loss-ulb:0.0145, weight:1.55, lr:0.0007
[00:08:21.767] iteration:4683  t-loss:0.0799, loss-lb:0.0312, loss-ulb:0.0314, weight:1.55, lr:0.0007
[00:08:22.155] iteration:4684  t-loss:0.0808, loss-lb:0.0372, loss-ulb:0.0281, weight:1.55, lr:0.0007
[00:08:22.545] iteration:4685  t-loss:0.0544, loss-lb:0.0455, loss-ulb:0.0058, weight:1.55, lr:0.0007
[00:08:22.924] iteration:4686  t-loss:0.0382, loss-lb:0.0232, loss-ulb:0.0097, weight:1.55, lr:0.0007
[00:08:23.301] iteration:4687  t-loss:0.0396, loss-lb:0.0259, loss-ulb:0.0088, weight:1.55, lr:0.0007
[00:08:23.676] iteration:4688  t-loss:0.0399, loss-lb:0.0358, loss-ulb:0.0026, weight:1.55, lr:0.0007
[00:08:24.053] iteration:4689  t-loss:0.0490, loss-lb:0.0221, loss-ulb:0.0173, weight:1.55, lr:0.0007
[00:08:24.428] iteration:4690  t-loss:0.0999, loss-lb:0.0788, loss-ulb:0.0136, weight:1.55, lr:0.0007
[00:08:24.807] iteration:4691  t-loss:0.0584, loss-lb:0.0319, loss-ulb:0.0170, weight:1.55, lr:0.0007
[00:08:25.186] iteration:4692  t-loss:0.0671, loss-lb:0.0584, loss-ulb:0.0056, weight:1.55, lr:0.0007
[00:08:25.564] iteration:4693  t-loss:0.0405, loss-lb:0.0166, loss-ulb:0.0154, weight:1.55, lr:0.0007
[00:08:25.954] iteration:4694  t-loss:0.0504, loss-lb:0.0242, loss-ulb:0.0169, weight:1.55, lr:0.0007
[00:08:26.350] iteration:4695  t-loss:0.0592, loss-lb:0.0284, loss-ulb:0.0198, weight:1.55, lr:0.0007
[00:08:26.736] iteration:4696  t-loss:0.0299, loss-lb:0.0221, loss-ulb:0.0050, weight:1.55, lr:0.0007
[00:08:27.126] iteration:4697  t-loss:0.0517, loss-lb:0.0453, loss-ulb:0.0042, weight:1.55, lr:0.0007
[00:08:27.512] iteration:4698  t-loss:0.0650, loss-lb:0.0455, loss-ulb:0.0126, weight:1.55, lr:0.0007
[00:08:27.886] iteration:4699  t-loss:0.0377, loss-lb:0.0221, loss-ulb:0.0100, weight:1.55, lr:0.0007
[00:08:28.266] iteration:4700  t-loss:0.0835, loss-lb:0.0257, loss-ulb:0.0372, weight:1.55, lr:0.0007
[00:08:28.655] iteration:4701  t-loss:0.0673, loss-lb:0.0470, loss-ulb:0.0131, weight:1.55, lr:0.0007
[00:08:29.038] iteration:4702  t-loss:0.0555, loss-lb:0.0272, loss-ulb:0.0182, weight:1.55, lr:0.0007
[00:08:29.415] iteration:4703  t-loss:0.0861, loss-lb:0.0837, loss-ulb:0.0016, weight:1.55, lr:0.0007
[00:08:29.794] iteration:4704  t-loss:0.0218, loss-lb:0.0199, loss-ulb:0.0012, weight:1.55, lr:0.0007
[00:08:30.176] iteration:4705  t-loss:0.0465, loss-lb:0.0282, loss-ulb:0.0118, weight:1.55, lr:0.0007
[00:08:30.555] iteration:4706  t-loss:0.0707, loss-lb:0.0512, loss-ulb:0.0126, weight:1.55, lr:0.0007
[00:08:30.933] iteration:4707  t-loss:0.0806, loss-lb:0.0730, loss-ulb:0.0048, weight:1.55, lr:0.0007
[00:08:31.305] iteration:4708  t-loss:0.0327, loss-lb:0.0256, loss-ulb:0.0046, weight:1.55, lr:0.0007
[00:08:31.684] iteration:4709  t-loss:0.0711, loss-lb:0.0570, loss-ulb:0.0091, weight:1.55, lr:0.0007
[00:08:32.061] iteration:4710  t-loss:0.0499, loss-lb:0.0400, loss-ulb:0.0064, weight:1.55, lr:0.0007
[00:08:32.438] iteration:4711  t-loss:0.0871, loss-lb:0.0453, loss-ulb:0.0269, weight:1.55, lr:0.0007
[00:08:32.816] iteration:4712  t-loss:0.0507, loss-lb:0.0459, loss-ulb:0.0031, weight:1.55, lr:0.0007
[00:08:34.079] iteration:4713  t-loss:0.0634, loss-lb:0.0513, loss-ulb:0.0078, weight:1.55, lr:0.0007
[00:08:34.477] iteration:4714  t-loss:0.0365, loss-lb:0.0255, loss-ulb:0.0070, weight:1.55, lr:0.0007
[00:08:34.859] iteration:4715  t-loss:0.0348, loss-lb:0.0258, loss-ulb:0.0058, weight:1.55, lr:0.0007
[00:08:35.241] iteration:4716  t-loss:0.0450, loss-lb:0.0401, loss-ulb:0.0032, weight:1.55, lr:0.0007
[00:08:35.627] iteration:4717  t-loss:0.0881, loss-lb:0.0400, loss-ulb:0.0310, weight:1.55, lr:0.0007
[00:08:36.006] iteration:4718  t-loss:0.0575, loss-lb:0.0193, loss-ulb:0.0246, weight:1.55, lr:0.0007
[00:08:36.384] iteration:4719  t-loss:0.0403, loss-lb:0.0233, loss-ulb:0.0110, weight:1.55, lr:0.0007
[00:08:36.766] iteration:4720  t-loss:0.0975, loss-lb:0.0558, loss-ulb:0.0268, weight:1.55, lr:0.0007
[00:08:37.148] iteration:4721  t-loss:0.0642, loss-lb:0.0497, loss-ulb:0.0093, weight:1.55, lr:0.0007
[00:08:37.531] iteration:4722  t-loss:0.0827, loss-lb:0.0643, loss-ulb:0.0119, weight:1.55, lr:0.0007
[00:08:37.917] iteration:4723  t-loss:0.0608, loss-lb:0.0316, loss-ulb:0.0188, weight:1.55, lr:0.0007
[00:08:38.292] iteration:4724  t-loss:0.0380, loss-lb:0.0266, loss-ulb:0.0073, weight:1.55, lr:0.0007
[00:08:38.668] iteration:4725  t-loss:0.0707, loss-lb:0.0485, loss-ulb:0.0143, weight:1.55, lr:0.0007
[00:08:39.045] iteration:4726  t-loss:0.0378, loss-lb:0.0309, loss-ulb:0.0045, weight:1.55, lr:0.0007
[00:08:39.424] iteration:4727  t-loss:0.0697, loss-lb:0.0443, loss-ulb:0.0164, weight:1.55, lr:0.0007
[00:08:39.801] iteration:4728  t-loss:0.0636, loss-lb:0.0239, loss-ulb:0.0255, weight:1.55, lr:0.0007
[00:08:40.189] iteration:4729  t-loss:0.0682, loss-lb:0.0213, loss-ulb:0.0303, weight:1.55, lr:0.0007
[00:08:40.586] iteration:4730  t-loss:0.0649, loss-lb:0.0516, loss-ulb:0.0085, weight:1.55, lr:0.0007
[00:08:40.976] iteration:4731  t-loss:0.0374, loss-lb:0.0282, loss-ulb:0.0060, weight:1.55, lr:0.0007
[00:08:41.370] iteration:4732  t-loss:0.0370, loss-lb:0.0189, loss-ulb:0.0116, weight:1.55, lr:0.0007
[00:08:41.761] iteration:4733  t-loss:0.0315, loss-lb:0.0206, loss-ulb:0.0070, weight:1.55, lr:0.0007
[00:08:42.172] iteration:4734  t-loss:0.0748, loss-lb:0.0524, loss-ulb:0.0144, weight:1.55, lr:0.0007
[00:08:42.568] iteration:4735  t-loss:0.0593, loss-lb:0.0288, loss-ulb:0.0196, weight:1.55, lr:0.0007
[00:08:42.959] iteration:4736  t-loss:0.0416, loss-lb:0.0274, loss-ulb:0.0091, weight:1.55, lr:0.0007
[00:08:43.339] iteration:4737  t-loss:0.0478, loss-lb:0.0446, loss-ulb:0.0020, weight:1.55, lr:0.0007
[00:08:43.725] iteration:4738  t-loss:0.0714, loss-lb:0.0463, loss-ulb:0.0161, weight:1.55, lr:0.0007
[00:08:44.113] iteration:4739  t-loss:0.0554, loss-lb:0.0510, loss-ulb:0.0028, weight:1.55, lr:0.0007
[00:08:44.498] iteration:4740  t-loss:0.0624, loss-lb:0.0445, loss-ulb:0.0115, weight:1.55, lr:0.0007
[00:08:44.880] iteration:4741  t-loss:0.0283, loss-lb:0.0241, loss-ulb:0.0027, weight:1.55, lr:0.0007
[00:08:45.264] iteration:4742  t-loss:0.0229, loss-lb:0.0191, loss-ulb:0.0025, weight:1.55, lr:0.0007
[00:08:45.648] iteration:4743  t-loss:0.0586, loss-lb:0.0479, loss-ulb:0.0069, weight:1.55, lr:0.0007
[00:08:46.028] iteration:4744  t-loss:0.0548, loss-lb:0.0377, loss-ulb:0.0110, weight:1.55, lr:0.0007
[00:08:46.404] iteration:4745  t-loss:0.0281, loss-lb:0.0230, loss-ulb:0.0033, weight:1.55, lr:0.0007
[00:08:46.786] iteration:4746  t-loss:0.1318, loss-lb:0.1058, loss-ulb:0.0168, weight:1.55, lr:0.0007
[00:08:47.163] iteration:4747  t-loss:0.0202, loss-lb:0.0167, loss-ulb:0.0022, weight:1.55, lr:0.0007
[00:08:47.545] iteration:4748  t-loss:0.0518, loss-lb:0.0387, loss-ulb:0.0084, weight:1.55, lr:0.0007
[00:08:47.920] iteration:4749  t-loss:0.0559, loss-lb:0.0182, loss-ulb:0.0243, weight:1.55, lr:0.0007
[00:08:48.295] iteration:4750  t-loss:0.0673, loss-lb:0.0645, loss-ulb:0.0018, weight:1.55, lr:0.0007
[00:09:48.382] iteration 4750 : dice_score: 0.813740 best_dice: 0.849700
[00:09:48.383]  <<Test>> - Ep:124  - Dice-S/T:78.91/81.37, Best-S:85.17, Best-T:84.97
[00:09:48.383]           - AvgLoss(lb/ulb/all):0.04/0.01/0.05
[00:09:49.446] iteration:4751  t-loss:0.0817, loss-lb:0.0393, loss-ulb:0.0273, weight:1.55, lr:0.0007
[00:09:49.834] iteration:4752  t-loss:0.0470, loss-lb:0.0210, loss-ulb:0.0168, weight:1.55, lr:0.0007
[00:09:50.217] iteration:4753  t-loss:0.0662, loss-lb:0.0591, loss-ulb:0.0046, weight:1.55, lr:0.0007
[00:09:50.593] iteration:4754  t-loss:0.0230, loss-lb:0.0207, loss-ulb:0.0015, weight:1.55, lr:0.0007
[00:09:50.976] iteration:4755  t-loss:0.0455, loss-lb:0.0343, loss-ulb:0.0072, weight:1.55, lr:0.0007
[00:09:51.352] iteration:4756  t-loss:0.0283, loss-lb:0.0257, loss-ulb:0.0017, weight:1.55, lr:0.0007
[00:09:51.738] iteration:4757  t-loss:0.0600, loss-lb:0.0562, loss-ulb:0.0024, weight:1.55, lr:0.0007
[00:09:52.127] iteration:4758  t-loss:0.0418, loss-lb:0.0291, loss-ulb:0.0082, weight:1.55, lr:0.0007
[00:09:52.514] iteration:4759  t-loss:0.0739, loss-lb:0.0625, loss-ulb:0.0074, weight:1.55, lr:0.0007
[00:09:52.892] iteration:4760  t-loss:0.0348, loss-lb:0.0220, loss-ulb:0.0082, weight:1.55, lr:0.0007
[00:09:53.270] iteration:4761  t-loss:0.0726, loss-lb:0.0662, loss-ulb:0.0042, weight:1.55, lr:0.0007
[00:09:53.650] iteration:4762  t-loss:0.0794, loss-lb:0.0757, loss-ulb:0.0024, weight:1.55, lr:0.0007
[00:09:54.033] iteration:4763  t-loss:0.0498, loss-lb:0.0480, loss-ulb:0.0012, weight:1.55, lr:0.0007
[00:09:54.418] iteration:4764  t-loss:0.1348, loss-lb:0.0714, loss-ulb:0.0409, weight:1.55, lr:0.0007
[00:09:54.802] iteration:4765  t-loss:0.0427, loss-lb:0.0244, loss-ulb:0.0118, weight:1.55, lr:0.0007
[00:09:55.180] iteration:4766  t-loss:0.0371, loss-lb:0.0244, loss-ulb:0.0082, weight:1.55, lr:0.0007
[00:09:55.565] iteration:4767  t-loss:0.0246, loss-lb:0.0186, loss-ulb:0.0039, weight:1.55, lr:0.0007
[00:09:55.944] iteration:4768  t-loss:0.0425, loss-lb:0.0279, loss-ulb:0.0094, weight:1.55, lr:0.0007
[00:09:56.326] iteration:4769  t-loss:0.0590, loss-lb:0.0416, loss-ulb:0.0112, weight:1.55, lr:0.0007
[00:09:56.699] iteration:4770  t-loss:0.0290, loss-lb:0.0241, loss-ulb:0.0031, weight:1.55, lr:0.0007
[00:09:57.084] iteration:4771  t-loss:0.0490, loss-lb:0.0469, loss-ulb:0.0014, weight:1.55, lr:0.0007
[00:09:57.463] iteration:4772  t-loss:0.0618, loss-lb:0.0296, loss-ulb:0.0207, weight:1.55, lr:0.0007
[00:09:57.846] iteration:4773  t-loss:0.0745, loss-lb:0.0500, loss-ulb:0.0158, weight:1.55, lr:0.0007
[00:09:58.222] iteration:4774  t-loss:0.0359, loss-lb:0.0170, loss-ulb:0.0121, weight:1.55, lr:0.0007
[00:09:58.605] iteration:4775  t-loss:0.0447, loss-lb:0.0281, loss-ulb:0.0107, weight:1.55, lr:0.0007
[00:09:58.982] iteration:4776  t-loss:0.0412, loss-lb:0.0354, loss-ulb:0.0038, weight:1.55, lr:0.0007
[00:09:59.357] iteration:4777  t-loss:0.0252, loss-lb:0.0230, loss-ulb:0.0014, weight:1.55, lr:0.0007
[00:09:59.736] iteration:4778  t-loss:0.0238, loss-lb:0.0203, loss-ulb:0.0022, weight:1.55, lr:0.0007
[00:10:00.127] iteration:4779  t-loss:0.0590, loss-lb:0.0499, loss-ulb:0.0059, weight:1.55, lr:0.0007
[00:10:00.514] iteration:4780  t-loss:0.0986, loss-lb:0.0354, loss-ulb:0.0407, weight:1.55, lr:0.0007
[00:10:00.892] iteration:4781  t-loss:0.0261, loss-lb:0.0195, loss-ulb:0.0043, weight:1.55, lr:0.0007
[00:10:01.270] iteration:4782  t-loss:0.0621, loss-lb:0.0301, loss-ulb:0.0206, weight:1.55, lr:0.0007
[00:10:01.648] iteration:4783  t-loss:0.0393, loss-lb:0.0353, loss-ulb:0.0026, weight:1.55, lr:0.0007
[00:10:02.027] iteration:4784  t-loss:0.0380, loss-lb:0.0232, loss-ulb:0.0095, weight:1.55, lr:0.0007
[00:10:02.398] iteration:4785  t-loss:0.0380, loss-lb:0.0228, loss-ulb:0.0097, weight:1.55, lr:0.0007
[00:10:02.772] iteration:4786  t-loss:0.0414, loss-lb:0.0387, loss-ulb:0.0017, weight:1.55, lr:0.0007
[00:10:03.152] iteration:4787  t-loss:0.0426, loss-lb:0.0333, loss-ulb:0.0060, weight:1.55, lr:0.0007
[00:10:03.532] iteration:4788  t-loss:0.1028, loss-lb:0.0686, loss-ulb:0.0220, weight:1.55, lr:0.0007
[00:10:04.849] iteration:4789  t-loss:0.0975, loss-lb:0.0958, loss-ulb:0.0010, weight:1.55, lr:0.0007
[00:10:05.242] iteration:4790  t-loss:0.0415, loss-lb:0.0212, loss-ulb:0.0131, weight:1.55, lr:0.0007
[00:10:05.630] iteration:4791  t-loss:0.0453, loss-lb:0.0364, loss-ulb:0.0058, weight:1.55, lr:0.0007
[00:10:06.016] iteration:4792  t-loss:0.0771, loss-lb:0.0635, loss-ulb:0.0088, weight:1.55, lr:0.0007
[00:10:06.408] iteration:4793  t-loss:0.0810, loss-lb:0.0417, loss-ulb:0.0253, weight:1.55, lr:0.0007
[00:10:06.792] iteration:4794  t-loss:0.0294, loss-lb:0.0205, loss-ulb:0.0057, weight:1.55, lr:0.0007
[00:10:07.174] iteration:4795  t-loss:0.0245, loss-lb:0.0174, loss-ulb:0.0046, weight:1.55, lr:0.0007
[00:10:07.561] iteration:4796  t-loss:0.0482, loss-lb:0.0242, loss-ulb:0.0154, weight:1.55, lr:0.0007
[00:10:07.944] iteration:4797  t-loss:0.0682, loss-lb:0.0624, loss-ulb:0.0037, weight:1.55, lr:0.0007
[00:10:08.330] iteration:4798  t-loss:0.0729, loss-lb:0.0503, loss-ulb:0.0145, weight:1.55, lr:0.0007
[00:10:08.717] iteration:4799  t-loss:0.0303, loss-lb:0.0250, loss-ulb:0.0034, weight:1.55, lr:0.0007
[00:10:09.100] iteration:4800  t-loss:0.0413, loss-lb:0.0173, loss-ulb:0.0155, weight:1.55, lr:0.0007
[00:10:09.480] iteration:4801  t-loss:0.0292, loss-lb:0.0226, loss-ulb:0.0041, weight:1.64, lr:0.0007
[00:10:09.867] iteration:4802  t-loss:0.0537, loss-lb:0.0211, loss-ulb:0.0199, weight:1.64, lr:0.0007
[00:10:10.255] iteration:4803  t-loss:0.0557, loss-lb:0.0440, loss-ulb:0.0071, weight:1.64, lr:0.0007
[00:10:10.635] iteration:4804  t-loss:0.0420, loss-lb:0.0395, loss-ulb:0.0015, weight:1.64, lr:0.0007
[00:10:11.019] iteration:4805  t-loss:0.0330, loss-lb:0.0268, loss-ulb:0.0038, weight:1.64, lr:0.0007
[00:10:11.398] iteration:4806  t-loss:0.0412, loss-lb:0.0207, loss-ulb:0.0125, weight:1.64, lr:0.0007
[00:10:11.782] iteration:4807  t-loss:0.0667, loss-lb:0.0508, loss-ulb:0.0097, weight:1.64, lr:0.0007
[00:10:12.158] iteration:4808  t-loss:0.0205, loss-lb:0.0167, loss-ulb:0.0023, weight:1.64, lr:0.0007
[00:10:12.545] iteration:4809  t-loss:0.0415, loss-lb:0.0307, loss-ulb:0.0066, weight:1.64, lr:0.0007
[00:10:12.925] iteration:4810  t-loss:0.0487, loss-lb:0.0430, loss-ulb:0.0034, weight:1.64, lr:0.0007
[00:10:13.303] iteration:4811  t-loss:0.0336, loss-lb:0.0193, loss-ulb:0.0088, weight:1.64, lr:0.0007
[00:10:13.685] iteration:4812  t-loss:0.0382, loss-lb:0.0328, loss-ulb:0.0033, weight:1.64, lr:0.0007
[00:10:14.066] iteration:4813  t-loss:0.0375, loss-lb:0.0183, loss-ulb:0.0117, weight:1.64, lr:0.0007
[00:10:14.452] iteration:4814  t-loss:0.0396, loss-lb:0.0217, loss-ulb:0.0110, weight:1.64, lr:0.0007
[00:10:14.829] iteration:4815  t-loss:0.0319, loss-lb:0.0223, loss-ulb:0.0059, weight:1.64, lr:0.0007
[00:10:15.208] iteration:4816  t-loss:0.0476, loss-lb:0.0448, loss-ulb:0.0017, weight:1.64, lr:0.0007
[00:10:15.591] iteration:4817  t-loss:0.0626, loss-lb:0.0361, loss-ulb:0.0162, weight:1.64, lr:0.0007
[00:10:15.977] iteration:4818  t-loss:0.0510, loss-lb:0.0277, loss-ulb:0.0143, weight:1.64, lr:0.0007
[00:10:16.352] iteration:4819  t-loss:0.0576, loss-lb:0.0539, loss-ulb:0.0023, weight:1.64, lr:0.0007
[00:10:16.730] iteration:4820  t-loss:0.0344, loss-lb:0.0169, loss-ulb:0.0106, weight:1.64, lr:0.0007
[00:10:17.107] iteration:4821  t-loss:0.0614, loss-lb:0.0565, loss-ulb:0.0030, weight:1.64, lr:0.0007
[00:10:17.487] iteration:4822  t-loss:0.0438, loss-lb:0.0326, loss-ulb:0.0068, weight:1.64, lr:0.0007
[00:10:17.866] iteration:4823  t-loss:0.0410, loss-lb:0.0287, loss-ulb:0.0075, weight:1.64, lr:0.0007
[00:10:18.245] iteration:4824  t-loss:0.0261, loss-lb:0.0219, loss-ulb:0.0025, weight:1.64, lr:0.0007
[00:10:18.628] iteration:4825  t-loss:0.1827, loss-lb:0.0841, loss-ulb:0.0603, weight:1.64, lr:0.0007
[00:10:19.009] iteration:4826  t-loss:0.0566, loss-lb:0.0496, loss-ulb:0.0043, weight:1.64, lr:0.0007
[00:10:20.379] iteration:4827  t-loss:0.0345, loss-lb:0.0289, loss-ulb:0.0034, weight:1.64, lr:0.0007
[00:10:20.785] iteration:4828  t-loss:0.0329, loss-lb:0.0206, loss-ulb:0.0075, weight:1.64, lr:0.0007
[00:10:21.171] iteration:4829  t-loss:0.0409, loss-lb:0.0369, loss-ulb:0.0025, weight:1.64, lr:0.0007
[00:10:21.545] iteration:4830  t-loss:0.0574, loss-lb:0.0497, loss-ulb:0.0047, weight:1.64, lr:0.0007
[00:10:21.923] iteration:4831  t-loss:0.0379, loss-lb:0.0346, loss-ulb:0.0020, weight:1.64, lr:0.0007
[00:10:22.305] iteration:4832  t-loss:0.0531, loss-lb:0.0221, loss-ulb:0.0189, weight:1.64, lr:0.0007
[00:10:22.683] iteration:4833  t-loss:0.0875, loss-lb:0.0293, loss-ulb:0.0356, weight:1.64, lr:0.0007
[00:10:23.064] iteration:4834  t-loss:0.0910, loss-lb:0.0614, loss-ulb:0.0181, weight:1.64, lr:0.0007
[00:10:23.440] iteration:4835  t-loss:0.0704, loss-lb:0.0525, loss-ulb:0.0109, weight:1.64, lr:0.0007
[00:10:23.807] iteration:4836  t-loss:0.0225, loss-lb:0.0170, loss-ulb:0.0034, weight:1.64, lr:0.0007
[00:10:24.193] iteration:4837  t-loss:0.0533, loss-lb:0.0369, loss-ulb:0.0100, weight:1.64, lr:0.0007
[00:10:24.568] iteration:4838  t-loss:0.0388, loss-lb:0.0334, loss-ulb:0.0033, weight:1.64, lr:0.0007
[00:10:24.946] iteration:4839  t-loss:0.0634, loss-lb:0.0240, loss-ulb:0.0240, weight:1.64, lr:0.0007
[00:10:25.331] iteration:4840  t-loss:0.0639, loss-lb:0.0587, loss-ulb:0.0032, weight:1.64, lr:0.0007
[00:10:25.710] iteration:4841  t-loss:0.0357, loss-lb:0.0182, loss-ulb:0.0107, weight:1.64, lr:0.0007
[00:10:26.093] iteration:4842  t-loss:0.1054, loss-lb:0.0879, loss-ulb:0.0107, weight:1.64, lr:0.0007
[00:10:26.469] iteration:4843  t-loss:0.0256, loss-lb:0.0206, loss-ulb:0.0031, weight:1.64, lr:0.0007
[00:10:26.843] iteration:4844  t-loss:0.0382, loss-lb:0.0209, loss-ulb:0.0106, weight:1.64, lr:0.0007
[00:10:27.222] iteration:4845  t-loss:0.0548, loss-lb:0.0262, loss-ulb:0.0175, weight:1.64, lr:0.0007
[00:10:27.604] iteration:4846  t-loss:0.0294, loss-lb:0.0186, loss-ulb:0.0066, weight:1.64, lr:0.0007
[00:10:27.992] iteration:4847  t-loss:0.0969, loss-lb:0.0616, loss-ulb:0.0216, weight:1.64, lr:0.0007
[00:10:28.383] iteration:4848  t-loss:0.0389, loss-lb:0.0213, loss-ulb:0.0107, weight:1.64, lr:0.0007
[00:10:28.766] iteration:4849  t-loss:0.0483, loss-lb:0.0203, loss-ulb:0.0171, weight:1.64, lr:0.0007
[00:10:29.143] iteration:4850  t-loss:0.0562, loss-lb:0.0293, loss-ulb:0.0165, weight:1.64, lr:0.0007
[00:10:29.523] iteration:4851  t-loss:0.0302, loss-lb:0.0231, loss-ulb:0.0043, weight:1.64, lr:0.0007
[00:10:29.908] iteration:4852  t-loss:0.0393, loss-lb:0.0353, loss-ulb:0.0024, weight:1.64, lr:0.0007
[00:10:30.290] iteration:4853  t-loss:0.0375, loss-lb:0.0223, loss-ulb:0.0093, weight:1.64, lr:0.0007
[00:10:30.668] iteration:4854  t-loss:0.0440, loss-lb:0.0348, loss-ulb:0.0056, weight:1.64, lr:0.0007
[00:10:31.047] iteration:4855  t-loss:0.0495, loss-lb:0.0459, loss-ulb:0.0022, weight:1.64, lr:0.0007
[00:10:31.425] iteration:4856  t-loss:0.0473, loss-lb:0.0313, loss-ulb:0.0098, weight:1.64, lr:0.0007
[00:10:31.801] iteration:4857  t-loss:0.0732, loss-lb:0.0693, loss-ulb:0.0023, weight:1.64, lr:0.0007
[00:10:32.176] iteration:4858  t-loss:0.0304, loss-lb:0.0283, loss-ulb:0.0013, weight:1.64, lr:0.0007
[00:10:32.547] iteration:4859  t-loss:0.0307, loss-lb:0.0243, loss-ulb:0.0039, weight:1.64, lr:0.0007
[00:10:32.921] iteration:4860  t-loss:0.0672, loss-lb:0.0320, loss-ulb:0.0215, weight:1.64, lr:0.0007
[00:10:33.294] iteration:4861  t-loss:0.0364, loss-lb:0.0214, loss-ulb:0.0092, weight:1.64, lr:0.0007
[00:10:33.664] iteration:4862  t-loss:0.0218, loss-lb:0.0164, loss-ulb:0.0033, weight:1.64, lr:0.0007
[00:10:34.038] iteration:4863  t-loss:0.0248, loss-lb:0.0184, loss-ulb:0.0039, weight:1.64, lr:0.0007
[00:10:34.427] iteration:4864  t-loss:0.0701, loss-lb:0.0223, loss-ulb:0.0292, weight:1.64, lr:0.0007
[00:10:35.894] iteration:4865  t-loss:0.0445, loss-lb:0.0366, loss-ulb:0.0048, weight:1.64, lr:0.0007
[00:10:36.275] iteration:4866  t-loss:0.0264, loss-lb:0.0217, loss-ulb:0.0028, weight:1.64, lr:0.0007
[00:10:36.657] iteration:4867  t-loss:0.0320, loss-lb:0.0245, loss-ulb:0.0046, weight:1.64, lr:0.0007
[00:10:37.039] iteration:4868  t-loss:0.0554, loss-lb:0.0229, loss-ulb:0.0198, weight:1.64, lr:0.0007
[00:10:37.419] iteration:4869  t-loss:0.0510, loss-lb:0.0211, loss-ulb:0.0183, weight:1.64, lr:0.0007
[00:10:37.808] iteration:4870  t-loss:0.0483, loss-lb:0.0255, loss-ulb:0.0140, weight:1.64, lr:0.0007
[00:10:38.190] iteration:4871  t-loss:0.0376, loss-lb:0.0210, loss-ulb:0.0101, weight:1.64, lr:0.0007
[00:10:38.571] iteration:4872  t-loss:0.0233, loss-lb:0.0186, loss-ulb:0.0029, weight:1.64, lr:0.0007
[00:10:38.948] iteration:4873  t-loss:0.0869, loss-lb:0.0202, loss-ulb:0.0407, weight:1.64, lr:0.0007
[00:10:39.327] iteration:4874  t-loss:0.1018, loss-lb:0.0373, loss-ulb:0.0394, weight:1.64, lr:0.0007
[00:10:39.710] iteration:4875  t-loss:0.0680, loss-lb:0.0597, loss-ulb:0.0050, weight:1.64, lr:0.0007
[00:10:40.091] iteration:4876  t-loss:0.0395, loss-lb:0.0373, loss-ulb:0.0013, weight:1.64, lr:0.0007
[00:10:40.470] iteration:4877  t-loss:0.0481, loss-lb:0.0247, loss-ulb:0.0143, weight:1.64, lr:0.0007
[00:10:40.851] iteration:4878  t-loss:0.0597, loss-lb:0.0535, loss-ulb:0.0038, weight:1.64, lr:0.0007
[00:10:41.232] iteration:4879  t-loss:0.0604, loss-lb:0.0202, loss-ulb:0.0245, weight:1.64, lr:0.0007
[00:10:41.611] iteration:4880  t-loss:0.0585, loss-lb:0.0517, loss-ulb:0.0041, weight:1.64, lr:0.0007
[00:10:41.985] iteration:4881  t-loss:0.0235, loss-lb:0.0209, loss-ulb:0.0016, weight:1.64, lr:0.0007
[00:10:42.368] iteration:4882  t-loss:0.0577, loss-lb:0.0417, loss-ulb:0.0097, weight:1.64, lr:0.0007
[00:10:42.752] iteration:4883  t-loss:0.0929, loss-lb:0.0472, loss-ulb:0.0279, weight:1.64, lr:0.0007
[00:10:43.133] iteration:4884  t-loss:0.0859, loss-lb:0.0656, loss-ulb:0.0124, weight:1.64, lr:0.0007
[00:10:43.516] iteration:4885  t-loss:0.0893, loss-lb:0.0367, loss-ulb:0.0321, weight:1.64, lr:0.0007
[00:10:43.909] iteration:4886  t-loss:0.0576, loss-lb:0.0208, loss-ulb:0.0225, weight:1.64, lr:0.0007
[00:10:44.317] iteration:4887  t-loss:0.0475, loss-lb:0.0443, loss-ulb:0.0019, weight:1.64, lr:0.0007
[00:10:44.728] iteration:4888  t-loss:0.0975, loss-lb:0.0790, loss-ulb:0.0113, weight:1.64, lr:0.0007
[00:10:45.108] iteration:4889  t-loss:0.0418, loss-lb:0.0364, loss-ulb:0.0033, weight:1.64, lr:0.0007
[00:10:45.487] iteration:4890  t-loss:0.0275, loss-lb:0.0242, loss-ulb:0.0020, weight:1.64, lr:0.0007
[00:10:45.874] iteration:4891  t-loss:0.0759, loss-lb:0.0488, loss-ulb:0.0165, weight:1.64, lr:0.0007
[00:10:46.264] iteration:4892  t-loss:0.0627, loss-lb:0.0503, loss-ulb:0.0076, weight:1.64, lr:0.0007
[00:10:46.640] iteration:4893  t-loss:0.0566, loss-lb:0.0242, loss-ulb:0.0198, weight:1.64, lr:0.0007
[00:10:47.020] iteration:4894  t-loss:0.0268, loss-lb:0.0223, loss-ulb:0.0027, weight:1.64, lr:0.0007
[00:10:47.398] iteration:4895  t-loss:0.0346, loss-lb:0.0248, loss-ulb:0.0060, weight:1.64, lr:0.0007
[00:10:47.774] iteration:4896  t-loss:0.0377, loss-lb:0.0201, loss-ulb:0.0107, weight:1.64, lr:0.0007
[00:10:48.149] iteration:4897  t-loss:0.0605, loss-lb:0.0240, loss-ulb:0.0223, weight:1.64, lr:0.0007
[00:10:48.524] iteration:4898  t-loss:0.0647, loss-lb:0.0278, loss-ulb:0.0225, weight:1.64, lr:0.0007
[00:10:48.897] iteration:4899  t-loss:0.0289, loss-lb:0.0229, loss-ulb:0.0036, weight:1.64, lr:0.0007
[00:10:49.274] iteration:4900  t-loss:0.0473, loss-lb:0.0363, loss-ulb:0.0067, weight:1.64, lr:0.0007
[00:10:49.657] iteration:4901  t-loss:0.0302, loss-lb:0.0250, loss-ulb:0.0032, weight:1.64, lr:0.0007
[00:10:50.055] iteration:4902  t-loss:0.0279, loss-lb:0.0250, loss-ulb:0.0018, weight:1.64, lr:0.0007
[00:11:52.842] iteration 4902 : dice_score: 0.823428 best_dice: 0.849700
[00:11:52.842]  <<Test>> - Ep:128  - Dice-S/T:80.36/82.34, Best-S:85.17, Best-T:84.97
[00:11:52.842]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:11:54.040] iteration:4903  t-loss:0.0369, loss-lb:0.0233, loss-ulb:0.0084, weight:1.64, lr:0.0007
[00:11:54.431] iteration:4904  t-loss:0.0651, loss-lb:0.0610, loss-ulb:0.0025, weight:1.64, lr:0.0007
[00:11:54.817] iteration:4905  t-loss:0.0243, loss-lb:0.0209, loss-ulb:0.0021, weight:1.64, lr:0.0007
[00:11:55.195] iteration:4906  t-loss:0.0284, loss-lb:0.0257, loss-ulb:0.0016, weight:1.64, lr:0.0007
[00:11:55.579] iteration:4907  t-loss:0.0618, loss-lb:0.0364, loss-ulb:0.0155, weight:1.64, lr:0.0007
[00:11:55.965] iteration:4908  t-loss:0.0671, loss-lb:0.0436, loss-ulb:0.0144, weight:1.64, lr:0.0007
[00:11:56.362] iteration:4909  t-loss:0.0527, loss-lb:0.0474, loss-ulb:0.0032, weight:1.64, lr:0.0007
[00:11:56.737] iteration:4910  t-loss:0.0377, loss-lb:0.0213, loss-ulb:0.0100, weight:1.64, lr:0.0007
[00:11:57.118] iteration:4911  t-loss:0.0726, loss-lb:0.0570, loss-ulb:0.0096, weight:1.64, lr:0.0007
[00:11:57.498] iteration:4912  t-loss:0.0436, loss-lb:0.0361, loss-ulb:0.0046, weight:1.64, lr:0.0007
[00:11:57.891] iteration:4913  t-loss:0.0511, loss-lb:0.0463, loss-ulb:0.0030, weight:1.64, lr:0.0007
[00:11:58.274] iteration:4914  t-loss:0.0873, loss-lb:0.0566, loss-ulb:0.0187, weight:1.64, lr:0.0007
[00:11:58.660] iteration:4915  t-loss:0.0454, loss-lb:0.0263, loss-ulb:0.0117, weight:1.64, lr:0.0007
[00:11:59.051] iteration:4916  t-loss:0.0721, loss-lb:0.0470, loss-ulb:0.0153, weight:1.64, lr:0.0007
[00:11:59.433] iteration:4917  t-loss:0.0373, loss-lb:0.0309, loss-ulb:0.0039, weight:1.64, lr:0.0007
[00:11:59.810] iteration:4918  t-loss:0.0516, loss-lb:0.0473, loss-ulb:0.0027, weight:1.64, lr:0.0007
[00:12:00.186] iteration:4919  t-loss:0.0224, loss-lb:0.0194, loss-ulb:0.0018, weight:1.64, lr:0.0007
[00:12:00.572] iteration:4920  t-loss:0.0539, loss-lb:0.0337, loss-ulb:0.0123, weight:1.64, lr:0.0007
[00:12:00.957] iteration:4921  t-loss:0.0528, loss-lb:0.0215, loss-ulb:0.0191, weight:1.64, lr:0.0007
[00:12:01.339] iteration:4922  t-loss:0.0392, loss-lb:0.0214, loss-ulb:0.0109, weight:1.64, lr:0.0007
[00:12:01.724] iteration:4923  t-loss:0.0604, loss-lb:0.0419, loss-ulb:0.0113, weight:1.64, lr:0.0007
[00:12:02.115] iteration:4924  t-loss:0.0608, loss-lb:0.0429, loss-ulb:0.0110, weight:1.64, lr:0.0007
[00:12:02.496] iteration:4925  t-loss:0.0683, loss-lb:0.0410, loss-ulb:0.0167, weight:1.64, lr:0.0007
[00:12:02.872] iteration:4926  t-loss:0.0366, loss-lb:0.0277, loss-ulb:0.0054, weight:1.64, lr:0.0007
[00:12:03.256] iteration:4927  t-loss:0.0511, loss-lb:0.0376, loss-ulb:0.0083, weight:1.64, lr:0.0007
[00:12:03.638] iteration:4928  t-loss:0.0445, loss-lb:0.0359, loss-ulb:0.0052, weight:1.64, lr:0.0007
[00:12:04.023] iteration:4929  t-loss:0.0384, loss-lb:0.0338, loss-ulb:0.0028, weight:1.64, lr:0.0007
[00:12:04.398] iteration:4930  t-loss:0.0378, loss-lb:0.0196, loss-ulb:0.0111, weight:1.64, lr:0.0007
[00:12:04.775] iteration:4931  t-loss:0.0473, loss-lb:0.0243, loss-ulb:0.0140, weight:1.64, lr:0.0007
[00:12:05.152] iteration:4932  t-loss:0.0289, loss-lb:0.0171, loss-ulb:0.0072, weight:1.64, lr:0.0007
[00:12:05.526] iteration:4933  t-loss:0.0705, loss-lb:0.0467, loss-ulb:0.0146, weight:1.64, lr:0.0007
[00:12:05.897] iteration:4934  t-loss:0.0286, loss-lb:0.0226, loss-ulb:0.0037, weight:1.64, lr:0.0007
[00:12:06.272] iteration:4935  t-loss:0.0537, loss-lb:0.0494, loss-ulb:0.0027, weight:1.64, lr:0.0007
[00:12:06.645] iteration:4936  t-loss:0.0373, loss-lb:0.0326, loss-ulb:0.0029, weight:1.64, lr:0.0007
[00:12:07.041] iteration:4937  t-loss:0.0408, loss-lb:0.0367, loss-ulb:0.0025, weight:1.64, lr:0.0007
[00:12:07.416] iteration:4938  t-loss:0.0286, loss-lb:0.0232, loss-ulb:0.0033, weight:1.64, lr:0.0007
[00:12:07.790] iteration:4939  t-loss:0.0375, loss-lb:0.0333, loss-ulb:0.0026, weight:1.64, lr:0.0007
[00:12:08.169] iteration:4940  t-loss:0.0433, loss-lb:0.0209, loss-ulb:0.0137, weight:1.64, lr:0.0007
[00:12:09.642] iteration:4941  t-loss:0.0363, loss-lb:0.0277, loss-ulb:0.0052, weight:1.64, lr:0.0007
[00:12:10.033] iteration:4942  t-loss:0.0355, loss-lb:0.0276, loss-ulb:0.0048, weight:1.64, lr:0.0007
[00:12:10.417] iteration:4943  t-loss:0.0476, loss-lb:0.0355, loss-ulb:0.0074, weight:1.64, lr:0.0007
[00:12:10.803] iteration:4944  t-loss:0.0547, loss-lb:0.0385, loss-ulb:0.0099, weight:1.64, lr:0.0007
[00:12:11.182] iteration:4945  t-loss:0.0247, loss-lb:0.0205, loss-ulb:0.0025, weight:1.64, lr:0.0007
[00:12:11.555] iteration:4946  t-loss:0.0531, loss-lb:0.0241, loss-ulb:0.0177, weight:1.64, lr:0.0007
[00:12:11.940] iteration:4947  t-loss:0.0607, loss-lb:0.0540, loss-ulb:0.0041, weight:1.64, lr:0.0007
[00:12:12.317] iteration:4948  t-loss:0.0388, loss-lb:0.0189, loss-ulb:0.0121, weight:1.64, lr:0.0007
[00:12:12.700] iteration:4949  t-loss:0.0557, loss-lb:0.0457, loss-ulb:0.0061, weight:1.64, lr:0.0007
[00:12:13.081] iteration:4950  t-loss:0.0362, loss-lb:0.0225, loss-ulb:0.0084, weight:1.64, lr:0.0007
[00:12:13.459] iteration:4951  t-loss:0.0193, loss-lb:0.0173, loss-ulb:0.0012, weight:1.72, lr:0.0007
[00:12:13.845] iteration:4952  t-loss:0.0491, loss-lb:0.0456, loss-ulb:0.0020, weight:1.72, lr:0.0007
[00:12:14.230] iteration:4953  t-loss:0.0440, loss-lb:0.0294, loss-ulb:0.0085, weight:1.72, lr:0.0007
[00:12:14.612] iteration:4954  t-loss:0.0795, loss-lb:0.0202, loss-ulb:0.0346, weight:1.72, lr:0.0007
[00:12:15.000] iteration:4955  t-loss:0.0647, loss-lb:0.0444, loss-ulb:0.0118, weight:1.72, lr:0.0007
[00:12:15.381] iteration:4956  t-loss:0.0336, loss-lb:0.0158, loss-ulb:0.0104, weight:1.72, lr:0.0007
[00:12:15.761] iteration:4957  t-loss:0.1149, loss-lb:0.0770, loss-ulb:0.0221, weight:1.72, lr:0.0007
[00:12:16.143] iteration:4958  t-loss:0.0245, loss-lb:0.0201, loss-ulb:0.0025, weight:1.72, lr:0.0007
[00:12:16.525] iteration:4959  t-loss:0.0313, loss-lb:0.0148, loss-ulb:0.0097, weight:1.72, lr:0.0007
[00:12:16.907] iteration:4960  t-loss:0.0834, loss-lb:0.0752, loss-ulb:0.0048, weight:1.72, lr:0.0007
[00:12:17.286] iteration:4961  t-loss:0.0271, loss-lb:0.0226, loss-ulb:0.0027, weight:1.72, lr:0.0007
[00:12:17.667] iteration:4962  t-loss:0.1392, loss-lb:0.1216, loss-ulb:0.0103, weight:1.72, lr:0.0007
[00:12:18.051] iteration:4963  t-loss:0.0596, loss-lb:0.0332, loss-ulb:0.0154, weight:1.72, lr:0.0007
[00:12:18.436] iteration:4964  t-loss:0.0598, loss-lb:0.0393, loss-ulb:0.0119, weight:1.72, lr:0.0007
[00:12:18.818] iteration:4965  t-loss:0.0529, loss-lb:0.0306, loss-ulb:0.0130, weight:1.72, lr:0.0007
[00:12:19.207] iteration:4966  t-loss:0.0678, loss-lb:0.0405, loss-ulb:0.0159, weight:1.72, lr:0.0007
[00:12:19.592] iteration:4967  t-loss:0.0715, loss-lb:0.0478, loss-ulb:0.0138, weight:1.72, lr:0.0007
[00:12:19.972] iteration:4968  t-loss:0.0545, loss-lb:0.0189, loss-ulb:0.0208, weight:1.72, lr:0.0007
[00:12:20.360] iteration:4969  t-loss:0.0418, loss-lb:0.0392, loss-ulb:0.0015, weight:1.72, lr:0.0007
[00:12:20.745] iteration:4970  t-loss:0.0594, loss-lb:0.0367, loss-ulb:0.0132, weight:1.72, lr:0.0007
[00:12:21.125] iteration:4971  t-loss:0.0382, loss-lb:0.0320, loss-ulb:0.0036, weight:1.72, lr:0.0007
[00:12:21.500] iteration:4972  t-loss:0.0212, loss-lb:0.0179, loss-ulb:0.0019, weight:1.72, lr:0.0007
[00:12:21.878] iteration:4973  t-loss:0.0392, loss-lb:0.0201, loss-ulb:0.0111, weight:1.72, lr:0.0007
[00:12:22.259] iteration:4974  t-loss:0.0531, loss-lb:0.0247, loss-ulb:0.0166, weight:1.72, lr:0.0007
[00:12:22.636] iteration:4975  t-loss:0.0380, loss-lb:0.0315, loss-ulb:0.0038, weight:1.72, lr:0.0007
[00:12:23.018] iteration:4976  t-loss:0.0373, loss-lb:0.0261, loss-ulb:0.0066, weight:1.72, lr:0.0007
[00:12:23.391] iteration:4977  t-loss:0.0617, loss-lb:0.0192, loss-ulb:0.0248, weight:1.72, lr:0.0007
[00:12:23.771] iteration:4978  t-loss:0.0933, loss-lb:0.0661, loss-ulb:0.0158, weight:1.72, lr:0.0007
[00:12:25.033] iteration:4979  t-loss:0.0429, loss-lb:0.0385, loss-ulb:0.0026, weight:1.72, lr:0.0007
[00:12:25.457] iteration:4980  t-loss:0.0674, loss-lb:0.0378, loss-ulb:0.0172, weight:1.72, lr:0.0007
[00:12:25.867] iteration:4981  t-loss:0.0302, loss-lb:0.0245, loss-ulb:0.0033, weight:1.72, lr:0.0007
[00:12:26.253] iteration:4982  t-loss:0.0415, loss-lb:0.0242, loss-ulb:0.0101, weight:1.72, lr:0.0007
[00:12:26.637] iteration:4983  t-loss:0.0749, loss-lb:0.0616, loss-ulb:0.0077, weight:1.72, lr:0.0007
[00:12:27.012] iteration:4984  t-loss:0.0553, loss-lb:0.0216, loss-ulb:0.0197, weight:1.72, lr:0.0007
[00:12:27.387] iteration:4985  t-loss:0.0526, loss-lb:0.0438, loss-ulb:0.0052, weight:1.72, lr:0.0007
[00:12:27.765] iteration:4986  t-loss:0.0461, loss-lb:0.0239, loss-ulb:0.0129, weight:1.72, lr:0.0007
[00:12:28.146] iteration:4987  t-loss:0.0605, loss-lb:0.0511, loss-ulb:0.0055, weight:1.72, lr:0.0007
[00:12:28.524] iteration:4988  t-loss:0.0290, loss-lb:0.0238, loss-ulb:0.0030, weight:1.72, lr:0.0007
[00:12:28.912] iteration:4989  t-loss:0.0326, loss-lb:0.0163, loss-ulb:0.0095, weight:1.72, lr:0.0007
[00:12:29.286] iteration:4990  t-loss:0.0293, loss-lb:0.0238, loss-ulb:0.0033, weight:1.72, lr:0.0007
[00:12:29.661] iteration:4991  t-loss:0.0349, loss-lb:0.0217, loss-ulb:0.0077, weight:1.72, lr:0.0007
[00:12:30.043] iteration:4992  t-loss:0.0382, loss-lb:0.0190, loss-ulb:0.0112, weight:1.72, lr:0.0007
[00:12:30.425] iteration:4993  t-loss:0.0575, loss-lb:0.0168, loss-ulb:0.0237, weight:1.72, lr:0.0007
[00:12:30.805] iteration:4994  t-loss:0.0334, loss-lb:0.0243, loss-ulb:0.0053, weight:1.72, lr:0.0007
[00:12:31.185] iteration:4995  t-loss:0.0548, loss-lb:0.0412, loss-ulb:0.0079, weight:1.72, lr:0.0007
[00:12:31.569] iteration:4996  t-loss:0.0632, loss-lb:0.0440, loss-ulb:0.0112, weight:1.72, lr:0.0007
[00:12:31.949] iteration:4997  t-loss:0.0295, loss-lb:0.0264, loss-ulb:0.0018, weight:1.72, lr:0.0007
[00:12:32.333] iteration:4998  t-loss:0.0816, loss-lb:0.0595, loss-ulb:0.0129, weight:1.72, lr:0.0007
[00:12:32.715] iteration:4999  t-loss:0.0556, loss-lb:0.0520, loss-ulb:0.0021, weight:1.72, lr:0.0007
[00:12:33.094] iteration:5000  t-loss:0.0371, loss-lb:0.0319, loss-ulb:0.0030, weight:1.72, lr:0.0007
[00:12:33.483] iteration:5001  t-loss:0.0848, loss-lb:0.0519, loss-ulb:0.0192, weight:1.72, lr:0.0007
[00:12:33.861] iteration:5002  t-loss:0.0409, loss-lb:0.0190, loss-ulb:0.0127, weight:1.72, lr:0.0007
[00:12:34.242] iteration:5003  t-loss:0.0394, loss-lb:0.0187, loss-ulb:0.0120, weight:1.72, lr:0.0007
[00:12:34.629] iteration:5004  t-loss:0.0386, loss-lb:0.0224, loss-ulb:0.0095, weight:1.72, lr:0.0007
[00:12:35.011] iteration:5005  t-loss:0.0405, loss-lb:0.0323, loss-ulb:0.0048, weight:1.72, lr:0.0007
[00:12:35.392] iteration:5006  t-loss:0.0622, loss-lb:0.0183, loss-ulb:0.0256, weight:1.72, lr:0.0007
[00:12:35.772] iteration:5007  t-loss:0.0421, loss-lb:0.0201, loss-ulb:0.0128, weight:1.72, lr:0.0007
[00:12:36.155] iteration:5008  t-loss:0.0303, loss-lb:0.0261, loss-ulb:0.0024, weight:1.72, lr:0.0007
[00:12:36.542] iteration:5009  t-loss:0.0852, loss-lb:0.0627, loss-ulb:0.0131, weight:1.72, lr:0.0007
[00:12:36.918] iteration:5010  t-loss:0.0705, loss-lb:0.0574, loss-ulb:0.0076, weight:1.72, lr:0.0007
[00:12:37.294] iteration:5011  t-loss:0.0582, loss-lb:0.0426, loss-ulb:0.0091, weight:1.72, lr:0.0007
[00:12:37.670] iteration:5012  t-loss:0.0615, loss-lb:0.0574, loss-ulb:0.0024, weight:1.72, lr:0.0007
[00:12:38.045] iteration:5013  t-loss:0.0226, loss-lb:0.0176, loss-ulb:0.0029, weight:1.72, lr:0.0007
[00:12:38.425] iteration:5014  t-loss:0.0426, loss-lb:0.0162, loss-ulb:0.0154, weight:1.72, lr:0.0007
[00:12:38.804] iteration:5015  t-loss:0.0982, loss-lb:0.0407, loss-ulb:0.0335, weight:1.72, lr:0.0007
[00:12:39.179] iteration:5016  t-loss:0.0510, loss-lb:0.0432, loss-ulb:0.0045, weight:1.72, lr:0.0007
[00:12:40.413] iteration:5017  t-loss:0.0431, loss-lb:0.0284, loss-ulb:0.0086, weight:1.72, lr:0.0007
[00:12:40.818] iteration:5018  t-loss:0.0340, loss-lb:0.0205, loss-ulb:0.0079, weight:1.72, lr:0.0007
[00:12:41.210] iteration:5019  t-loss:0.0341, loss-lb:0.0217, loss-ulb:0.0072, weight:1.72, lr:0.0007
[00:12:41.588] iteration:5020  t-loss:0.0342, loss-lb:0.0288, loss-ulb:0.0031, weight:1.72, lr:0.0007
[00:12:41.969] iteration:5021  t-loss:0.0478, loss-lb:0.0417, loss-ulb:0.0036, weight:1.72, lr:0.0007
[00:12:42.347] iteration:5022  t-loss:0.0516, loss-lb:0.0233, loss-ulb:0.0165, weight:1.72, lr:0.0007
[00:12:42.734] iteration:5023  t-loss:0.0363, loss-lb:0.0311, loss-ulb:0.0031, weight:1.72, lr:0.0007
[00:12:43.128] iteration:5024  t-loss:0.0791, loss-lb:0.0517, loss-ulb:0.0160, weight:1.72, lr:0.0007
[00:12:43.515] iteration:5025  t-loss:0.0342, loss-lb:0.0215, loss-ulb:0.0074, weight:1.72, lr:0.0007
[00:12:43.897] iteration:5026  t-loss:0.0354, loss-lb:0.0319, loss-ulb:0.0020, weight:1.72, lr:0.0007
[00:12:44.281] iteration:5027  t-loss:0.0717, loss-lb:0.0533, loss-ulb:0.0107, weight:1.72, lr:0.0007
[00:12:44.661] iteration:5028  t-loss:0.0350, loss-lb:0.0305, loss-ulb:0.0027, weight:1.72, lr:0.0007
[00:12:45.040] iteration:5029  t-loss:0.0337, loss-lb:0.0208, loss-ulb:0.0075, weight:1.72, lr:0.0007
[00:12:45.422] iteration:5030  t-loss:0.0687, loss-lb:0.0281, loss-ulb:0.0237, weight:1.72, lr:0.0007
[00:12:45.801] iteration:5031  t-loss:0.0229, loss-lb:0.0193, loss-ulb:0.0021, weight:1.72, lr:0.0007
[00:12:46.182] iteration:5032  t-loss:0.0411, loss-lb:0.0219, loss-ulb:0.0112, weight:1.72, lr:0.0007
[00:12:46.568] iteration:5033  t-loss:0.0761, loss-lb:0.0362, loss-ulb:0.0233, weight:1.72, lr:0.0007
[00:12:46.953] iteration:5034  t-loss:0.0744, loss-lb:0.0494, loss-ulb:0.0146, weight:1.72, lr:0.0007
[00:12:47.336] iteration:5035  t-loss:0.0523, loss-lb:0.0295, loss-ulb:0.0133, weight:1.72, lr:0.0007
[00:12:47.716] iteration:5036  t-loss:0.0297, loss-lb:0.0253, loss-ulb:0.0026, weight:1.72, lr:0.0007
[00:12:48.098] iteration:5037  t-loss:0.0520, loss-lb:0.0335, loss-ulb:0.0108, weight:1.72, lr:0.0007
[00:12:48.483] iteration:5038  t-loss:0.0510, loss-lb:0.0183, loss-ulb:0.0190, weight:1.72, lr:0.0007
[00:12:48.868] iteration:5039  t-loss:0.0657, loss-lb:0.0470, loss-ulb:0.0109, weight:1.72, lr:0.0007
[00:12:49.253] iteration:5040  t-loss:0.0577, loss-lb:0.0270, loss-ulb:0.0179, weight:1.72, lr:0.0007
[00:12:49.637] iteration:5041  t-loss:0.0561, loss-lb:0.0386, loss-ulb:0.0102, weight:1.72, lr:0.0007
[00:12:50.024] iteration:5042  t-loss:0.0397, loss-lb:0.0217, loss-ulb:0.0105, weight:1.72, lr:0.0007
[00:12:50.428] iteration:5043  t-loss:0.0416, loss-lb:0.0381, loss-ulb:0.0020, weight:1.72, lr:0.0007
[00:12:50.818] iteration:5044  t-loss:0.0356, loss-lb:0.0190, loss-ulb:0.0097, weight:1.72, lr:0.0007
[00:12:51.202] iteration:5045  t-loss:0.0325, loss-lb:0.0209, loss-ulb:0.0068, weight:1.72, lr:0.0007
[00:12:51.582] iteration:5046  t-loss:0.0865, loss-lb:0.0440, loss-ulb:0.0248, weight:1.72, lr:0.0007
[00:12:51.961] iteration:5047  t-loss:0.0567, loss-lb:0.0305, loss-ulb:0.0152, weight:1.72, lr:0.0007
[00:12:52.335] iteration:5048  t-loss:0.0397, loss-lb:0.0325, loss-ulb:0.0042, weight:1.72, lr:0.0007
[00:12:52.709] iteration:5049  t-loss:0.0248, loss-lb:0.0231, loss-ulb:0.0010, weight:1.72, lr:0.0007
[00:12:53.078] iteration:5050  t-loss:0.0586, loss-lb:0.0196, loss-ulb:0.0227, weight:1.72, lr:0.0007
[00:12:53.449] iteration:5051  t-loss:0.0262, loss-lb:0.0180, loss-ulb:0.0047, weight:1.72, lr:0.0007
[00:12:53.820] iteration:5052  t-loss:0.0344, loss-lb:0.0178, loss-ulb:0.0096, weight:1.72, lr:0.0007
[00:12:54.197] iteration:5053  t-loss:0.0785, loss-lb:0.0292, loss-ulb:0.0287, weight:1.72, lr:0.0007
[00:12:54.568] iteration:5054  t-loss:0.0293, loss-lb:0.0240, loss-ulb:0.0031, weight:1.72, lr:0.0007
[00:13:57.924] iteration 5054 : dice_score: 0.875434 best_dice: 0.875400
[00:13:57.924]  <<Test>> - Ep:132  - Dice-S/T:88.23/87.54, Best-S:88.23, Best-T:87.54
[00:13:57.924]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:13:59.064] iteration:5055  t-loss:0.0250, loss-lb:0.0175, loss-ulb:0.0044, weight:1.72, lr:0.0007
[00:13:59.472] iteration:5056  t-loss:0.0874, loss-lb:0.0454, loss-ulb:0.0245, weight:1.72, lr:0.0007
[00:13:59.852] iteration:5057  t-loss:0.0272, loss-lb:0.0234, loss-ulb:0.0022, weight:1.72, lr:0.0007
[00:14:00.229] iteration:5058  t-loss:0.0610, loss-lb:0.0438, loss-ulb:0.0100, weight:1.72, lr:0.0007
[00:14:00.608] iteration:5059  t-loss:0.0409, loss-lb:0.0341, loss-ulb:0.0040, weight:1.72, lr:0.0007
[00:14:00.989] iteration:5060  t-loss:0.1058, loss-lb:0.0172, loss-ulb:0.0517, weight:1.72, lr:0.0007
[00:14:01.366] iteration:5061  t-loss:0.0366, loss-lb:0.0250, loss-ulb:0.0068, weight:1.72, lr:0.0007
[00:14:01.748] iteration:5062  t-loss:0.0427, loss-lb:0.0380, loss-ulb:0.0027, weight:1.72, lr:0.0007
[00:14:02.128] iteration:5063  t-loss:0.0477, loss-lb:0.0224, loss-ulb:0.0147, weight:1.72, lr:0.0007
[00:14:02.509] iteration:5064  t-loss:0.0952, loss-lb:0.0601, loss-ulb:0.0205, weight:1.72, lr:0.0007
[00:14:02.892] iteration:5065  t-loss:0.0575, loss-lb:0.0369, loss-ulb:0.0120, weight:1.72, lr:0.0007
[00:14:03.270] iteration:5066  t-loss:0.0260, loss-lb:0.0188, loss-ulb:0.0042, weight:1.72, lr:0.0007
[00:14:03.653] iteration:5067  t-loss:0.0358, loss-lb:0.0286, loss-ulb:0.0042, weight:1.72, lr:0.0007
[00:14:04.034] iteration:5068  t-loss:0.0942, loss-lb:0.0473, loss-ulb:0.0274, weight:1.72, lr:0.0007
[00:14:04.411] iteration:5069  t-loss:0.0320, loss-lb:0.0258, loss-ulb:0.0036, weight:1.72, lr:0.0007
[00:14:04.786] iteration:5070  t-loss:0.0544, loss-lb:0.0210, loss-ulb:0.0195, weight:1.72, lr:0.0007
[00:14:05.164] iteration:5071  t-loss:0.0268, loss-lb:0.0233, loss-ulb:0.0020, weight:1.72, lr:0.0007
[00:14:05.546] iteration:5072  t-loss:0.0682, loss-lb:0.0499, loss-ulb:0.0107, weight:1.72, lr:0.0007
[00:14:05.923] iteration:5073  t-loss:0.0455, loss-lb:0.0230, loss-ulb:0.0131, weight:1.72, lr:0.0007
[00:14:06.298] iteration:5074  t-loss:0.0937, loss-lb:0.0324, loss-ulb:0.0358, weight:1.72, lr:0.0007
[00:14:06.679] iteration:5075  t-loss:0.0295, loss-lb:0.0217, loss-ulb:0.0045, weight:1.72, lr:0.0007
[00:14:07.060] iteration:5076  t-loss:0.0392, loss-lb:0.0248, loss-ulb:0.0084, weight:1.72, lr:0.0007
[00:14:07.438] iteration:5077  t-loss:0.0322, loss-lb:0.0225, loss-ulb:0.0057, weight:1.72, lr:0.0007
[00:14:07.813] iteration:5078  t-loss:0.0271, loss-lb:0.0240, loss-ulb:0.0018, weight:1.72, lr:0.0007
[00:14:08.190] iteration:5079  t-loss:0.0339, loss-lb:0.0307, loss-ulb:0.0019, weight:1.72, lr:0.0007
[00:14:08.571] iteration:5080  t-loss:0.0480, loss-lb:0.0456, loss-ulb:0.0014, weight:1.72, lr:0.0007
[00:14:08.951] iteration:5081  t-loss:0.0554, loss-lb:0.0379, loss-ulb:0.0102, weight:1.72, lr:0.0007
[00:14:09.330] iteration:5082  t-loss:0.0438, loss-lb:0.0253, loss-ulb:0.0108, weight:1.72, lr:0.0007
[00:14:09.710] iteration:5083  t-loss:0.0426, loss-lb:0.0381, loss-ulb:0.0026, weight:1.72, lr:0.0007
[00:14:10.094] iteration:5084  t-loss:0.0485, loss-lb:0.0392, loss-ulb:0.0054, weight:1.72, lr:0.0007
[00:14:10.475] iteration:5085  t-loss:0.0305, loss-lb:0.0207, loss-ulb:0.0057, weight:1.72, lr:0.0007
[00:14:10.852] iteration:5086  t-loss:0.0815, loss-lb:0.0459, loss-ulb:0.0207, weight:1.72, lr:0.0007
[00:14:11.230] iteration:5087  t-loss:0.0526, loss-lb:0.0493, loss-ulb:0.0019, weight:1.72, lr:0.0007
[00:14:11.610] iteration:5088  t-loss:0.0637, loss-lb:0.0610, loss-ulb:0.0016, weight:1.72, lr:0.0007
[00:14:11.991] iteration:5089  t-loss:0.0591, loss-lb:0.0449, loss-ulb:0.0083, weight:1.72, lr:0.0007
[00:14:12.365] iteration:5090  t-loss:0.0354, loss-lb:0.0303, loss-ulb:0.0030, weight:1.72, lr:0.0007
[00:14:12.738] iteration:5091  t-loss:0.0541, loss-lb:0.0506, loss-ulb:0.0020, weight:1.72, lr:0.0007
[00:14:13.116] iteration:5092  t-loss:0.0713, loss-lb:0.0264, loss-ulb:0.0262, weight:1.72, lr:0.0007
[00:14:14.297] iteration:5093  t-loss:0.0333, loss-lb:0.0198, loss-ulb:0.0079, weight:1.72, lr:0.0007
[00:14:14.685] iteration:5094  t-loss:0.0399, loss-lb:0.0236, loss-ulb:0.0095, weight:1.72, lr:0.0007
[00:14:15.075] iteration:5095  t-loss:0.0590, loss-lb:0.0522, loss-ulb:0.0040, weight:1.72, lr:0.0007
[00:14:15.463] iteration:5096  t-loss:0.0464, loss-lb:0.0345, loss-ulb:0.0069, weight:1.72, lr:0.0007
[00:14:15.852] iteration:5097  t-loss:0.0534, loss-lb:0.0415, loss-ulb:0.0069, weight:1.72, lr:0.0007
[00:14:16.235] iteration:5098  t-loss:0.0486, loss-lb:0.0216, loss-ulb:0.0157, weight:1.72, lr:0.0007
[00:14:16.612] iteration:5099  t-loss:0.0590, loss-lb:0.0372, loss-ulb:0.0127, weight:1.72, lr:0.0007
[00:14:16.994] iteration:5100  t-loss:0.0614, loss-lb:0.0405, loss-ulb:0.0122, weight:1.72, lr:0.0007
[00:14:17.372] iteration:5101  t-loss:0.0270, loss-lb:0.0235, loss-ulb:0.0020, weight:1.79, lr:0.0007
[00:14:17.755] iteration:5102  t-loss:0.0634, loss-lb:0.0353, loss-ulb:0.0157, weight:1.79, lr:0.0007
[00:14:18.132] iteration:5103  t-loss:0.0319, loss-lb:0.0175, loss-ulb:0.0081, weight:1.79, lr:0.0007
[00:14:18.515] iteration:5104  t-loss:0.0723, loss-lb:0.0320, loss-ulb:0.0225, weight:1.79, lr:0.0007
[00:14:18.899] iteration:5105  t-loss:0.0413, loss-lb:0.0373, loss-ulb:0.0023, weight:1.79, lr:0.0007
[00:14:19.282] iteration:5106  t-loss:0.0524, loss-lb:0.0382, loss-ulb:0.0080, weight:1.79, lr:0.0007
[00:14:19.667] iteration:5107  t-loss:0.0448, loss-lb:0.0288, loss-ulb:0.0089, weight:1.79, lr:0.0007
[00:14:20.047] iteration:5108  t-loss:0.0497, loss-lb:0.0361, loss-ulb:0.0076, weight:1.79, lr:0.0007
[00:14:20.433] iteration:5109  t-loss:0.0812, loss-lb:0.0562, loss-ulb:0.0140, weight:1.79, lr:0.0007
[00:14:20.814] iteration:5110  t-loss:0.0400, loss-lb:0.0216, loss-ulb:0.0103, weight:1.79, lr:0.0007
[00:14:21.204] iteration:5111  t-loss:0.0687, loss-lb:0.0193, loss-ulb:0.0277, weight:1.79, lr:0.0007
[00:14:21.587] iteration:5112  t-loss:0.0703, loss-lb:0.0654, loss-ulb:0.0027, weight:1.79, lr:0.0007
[00:14:21.964] iteration:5113  t-loss:0.0197, loss-lb:0.0152, loss-ulb:0.0025, weight:1.79, lr:0.0007
[00:14:22.351] iteration:5114  t-loss:0.0921, loss-lb:0.0254, loss-ulb:0.0373, weight:1.79, lr:0.0007
[00:14:22.727] iteration:5115  t-loss:0.0296, loss-lb:0.0162, loss-ulb:0.0075, weight:1.79, lr:0.0007
[00:14:23.107] iteration:5116  t-loss:0.0302, loss-lb:0.0258, loss-ulb:0.0025, weight:1.79, lr:0.0007
[00:14:23.489] iteration:5117  t-loss:0.0380, loss-lb:0.0322, loss-ulb:0.0032, weight:1.79, lr:0.0007
[00:14:23.869] iteration:5118  t-loss:0.0423, loss-lb:0.0268, loss-ulb:0.0087, weight:1.79, lr:0.0007
[00:14:24.256] iteration:5119  t-loss:0.0461, loss-lb:0.0420, loss-ulb:0.0023, weight:1.79, lr:0.0007
[00:14:24.638] iteration:5120  t-loss:0.0594, loss-lb:0.0322, loss-ulb:0.0152, weight:1.79, lr:0.0007
[00:14:25.027] iteration:5121  t-loss:0.0486, loss-lb:0.0343, loss-ulb:0.0080, weight:1.79, lr:0.0007
[00:14:25.405] iteration:5122  t-loss:0.0509, loss-lb:0.0318, loss-ulb:0.0107, weight:1.79, lr:0.0007
[00:14:25.788] iteration:5123  t-loss:0.0598, loss-lb:0.0546, loss-ulb:0.0029, weight:1.79, lr:0.0007
[00:14:26.166] iteration:5124  t-loss:0.0398, loss-lb:0.0341, loss-ulb:0.0032, weight:1.79, lr:0.0007
[00:14:26.546] iteration:5125  t-loss:0.0428, loss-lb:0.0249, loss-ulb:0.0100, weight:1.79, lr:0.0007
[00:14:26.923] iteration:5126  t-loss:0.0382, loss-lb:0.0332, loss-ulb:0.0028, weight:1.79, lr:0.0007
[00:14:27.302] iteration:5127  t-loss:0.0482, loss-lb:0.0323, loss-ulb:0.0089, weight:1.79, lr:0.0007
[00:14:27.677] iteration:5128  t-loss:0.0165, loss-lb:0.0135, loss-ulb:0.0017, weight:1.79, lr:0.0007
[00:14:28.058] iteration:5129  t-loss:0.0425, loss-lb:0.0380, loss-ulb:0.0025, weight:1.79, lr:0.0007
[00:14:28.436] iteration:5130  t-loss:0.0274, loss-lb:0.0202, loss-ulb:0.0040, weight:1.79, lr:0.0007
[00:14:29.700] iteration:5131  t-loss:0.0470, loss-lb:0.0346, loss-ulb:0.0069, weight:1.79, lr:0.0007
[00:14:30.107] iteration:5132  t-loss:0.0797, loss-lb:0.0578, loss-ulb:0.0123, weight:1.79, lr:0.0007
[00:14:30.483] iteration:5133  t-loss:0.0398, loss-lb:0.0242, loss-ulb:0.0087, weight:1.79, lr:0.0007
[00:14:30.871] iteration:5134  t-loss:0.0537, loss-lb:0.0405, loss-ulb:0.0074, weight:1.79, lr:0.0007
[00:14:31.254] iteration:5135  t-loss:0.0518, loss-lb:0.0196, loss-ulb:0.0180, weight:1.79, lr:0.0007
[00:14:31.636] iteration:5136  t-loss:0.0502, loss-lb:0.0180, loss-ulb:0.0180, weight:1.79, lr:0.0007
[00:14:32.020] iteration:5137  t-loss:0.0454, loss-lb:0.0309, loss-ulb:0.0081, weight:1.79, lr:0.0007
[00:14:32.398] iteration:5138  t-loss:0.0356, loss-lb:0.0227, loss-ulb:0.0072, weight:1.79, lr:0.0007
[00:14:32.782] iteration:5139  t-loss:0.0467, loss-lb:0.0198, loss-ulb:0.0150, weight:1.79, lr:0.0007
[00:14:33.167] iteration:5140  t-loss:0.0991, loss-lb:0.0906, loss-ulb:0.0048, weight:1.79, lr:0.0007
[00:14:33.542] iteration:5141  t-loss:0.0396, loss-lb:0.0212, loss-ulb:0.0103, weight:1.79, lr:0.0007
[00:14:33.931] iteration:5142  t-loss:0.0304, loss-lb:0.0269, loss-ulb:0.0019, weight:1.79, lr:0.0007
[00:14:34.324] iteration:5143  t-loss:0.0335, loss-lb:0.0305, loss-ulb:0.0017, weight:1.79, lr:0.0007
[00:14:34.727] iteration:5144  t-loss:0.0635, loss-lb:0.0478, loss-ulb:0.0088, weight:1.79, lr:0.0007
[00:14:35.113] iteration:5145  t-loss:0.0310, loss-lb:0.0234, loss-ulb:0.0043, weight:1.79, lr:0.0007
[00:14:35.493] iteration:5146  t-loss:0.0764, loss-lb:0.0339, loss-ulb:0.0238, weight:1.79, lr:0.0007
[00:14:35.874] iteration:5147  t-loss:0.0466, loss-lb:0.0212, loss-ulb:0.0142, weight:1.79, lr:0.0007
[00:14:36.258] iteration:5148  t-loss:0.0477, loss-lb:0.0190, loss-ulb:0.0160, weight:1.79, lr:0.0007
[00:14:36.644] iteration:5149  t-loss:0.0646, loss-lb:0.0460, loss-ulb:0.0104, weight:1.79, lr:0.0007
[00:14:37.032] iteration:5150  t-loss:0.0632, loss-lb:0.0430, loss-ulb:0.0113, weight:1.79, lr:0.0007
[00:14:37.415] iteration:5151  t-loss:0.0394, loss-lb:0.0306, loss-ulb:0.0049, weight:1.79, lr:0.0007
[00:14:37.795] iteration:5152  t-loss:0.0389, loss-lb:0.0236, loss-ulb:0.0085, weight:1.79, lr:0.0007
[00:14:38.177] iteration:5153  t-loss:0.0539, loss-lb:0.0381, loss-ulb:0.0088, weight:1.79, lr:0.0007
[00:14:38.561] iteration:5154  t-loss:0.0278, loss-lb:0.0232, loss-ulb:0.0026, weight:1.79, lr:0.0007
[00:14:38.944] iteration:5155  t-loss:0.0490, loss-lb:0.0171, loss-ulb:0.0179, weight:1.79, lr:0.0007
[00:14:39.330] iteration:5156  t-loss:0.0957, loss-lb:0.0679, loss-ulb:0.0155, weight:1.79, lr:0.0007
[00:14:39.712] iteration:5157  t-loss:0.0336, loss-lb:0.0172, loss-ulb:0.0092, weight:1.79, lr:0.0007
[00:14:40.097] iteration:5158  t-loss:0.0600, loss-lb:0.0449, loss-ulb:0.0084, weight:1.79, lr:0.0007
[00:14:40.482] iteration:5159  t-loss:0.0196, loss-lb:0.0165, loss-ulb:0.0017, weight:1.79, lr:0.0007
[00:14:40.856] iteration:5160  t-loss:0.0350, loss-lb:0.0199, loss-ulb:0.0085, weight:1.79, lr:0.0007
[00:14:41.233] iteration:5161  t-loss:0.0549, loss-lb:0.0237, loss-ulb:0.0174, weight:1.79, lr:0.0007
[00:14:41.608] iteration:5162  t-loss:0.0475, loss-lb:0.0449, loss-ulb:0.0015, weight:1.79, lr:0.0007
[00:14:41.985] iteration:5163  t-loss:0.0378, loss-lb:0.0338, loss-ulb:0.0022, weight:1.79, lr:0.0007
[00:14:42.357] iteration:5164  t-loss:0.0323, loss-lb:0.0233, loss-ulb:0.0050, weight:1.79, lr:0.0007
[00:14:42.734] iteration:5165  t-loss:0.0746, loss-lb:0.0591, loss-ulb:0.0087, weight:1.79, lr:0.0007
[00:14:43.114] iteration:5166  t-loss:0.0780, loss-lb:0.0481, loss-ulb:0.0167, weight:1.79, lr:0.0007
[00:14:43.492] iteration:5167  t-loss:0.0454, loss-lb:0.0214, loss-ulb:0.0134, weight:1.79, lr:0.0007
[00:14:43.871] iteration:5168  t-loss:0.0583, loss-lb:0.0306, loss-ulb:0.0155, weight:1.79, lr:0.0007
[00:14:45.076] iteration:5169  t-loss:0.0694, loss-lb:0.0463, loss-ulb:0.0129, weight:1.79, lr:0.0007
[00:14:45.461] iteration:5170  t-loss:0.0312, loss-lb:0.0171, loss-ulb:0.0079, weight:1.79, lr:0.0007
[00:14:45.848] iteration:5171  t-loss:0.0518, loss-lb:0.0216, loss-ulb:0.0169, weight:1.79, lr:0.0007
[00:14:46.225] iteration:5172  t-loss:0.0371, loss-lb:0.0216, loss-ulb:0.0087, weight:1.79, lr:0.0007
[00:14:46.609] iteration:5173  t-loss:0.0823, loss-lb:0.0568, loss-ulb:0.0142, weight:1.79, lr:0.0007
[00:14:46.989] iteration:5174  t-loss:0.0243, loss-lb:0.0212, loss-ulb:0.0017, weight:1.79, lr:0.0007
[00:14:47.365] iteration:5175  t-loss:0.0361, loss-lb:0.0230, loss-ulb:0.0073, weight:1.79, lr:0.0007
[00:14:47.745] iteration:5176  t-loss:0.1283, loss-lb:0.0598, loss-ulb:0.0383, weight:1.79, lr:0.0007
[00:14:48.121] iteration:5177  t-loss:0.0318, loss-lb:0.0293, loss-ulb:0.0014, weight:1.79, lr:0.0007
[00:14:48.498] iteration:5178  t-loss:0.0264, loss-lb:0.0177, loss-ulb:0.0049, weight:1.79, lr:0.0007
[00:14:48.878] iteration:5179  t-loss:0.0553, loss-lb:0.0489, loss-ulb:0.0035, weight:1.79, lr:0.0007
[00:14:49.259] iteration:5180  t-loss:0.0596, loss-lb:0.0477, loss-ulb:0.0067, weight:1.79, lr:0.0007
[00:14:49.647] iteration:5181  t-loss:0.0389, loss-lb:0.0173, loss-ulb:0.0121, weight:1.79, lr:0.0007
[00:14:50.058] iteration:5182  t-loss:0.0613, loss-lb:0.0396, loss-ulb:0.0121, weight:1.79, lr:0.0007
[00:14:50.445] iteration:5183  t-loss:0.0607, loss-lb:0.0472, loss-ulb:0.0075, weight:1.79, lr:0.0007
[00:14:50.826] iteration:5184  t-loss:0.0418, loss-lb:0.0309, loss-ulb:0.0061, weight:1.79, lr:0.0007
[00:14:51.200] iteration:5185  t-loss:0.0295, loss-lb:0.0271, loss-ulb:0.0013, weight:1.79, lr:0.0007
[00:14:51.592] iteration:5186  t-loss:0.0635, loss-lb:0.0456, loss-ulb:0.0101, weight:1.79, lr:0.0007
[00:14:51.973] iteration:5187  t-loss:0.0361, loss-lb:0.0228, loss-ulb:0.0075, weight:1.79, lr:0.0007
[00:14:52.356] iteration:5188  t-loss:0.0400, loss-lb:0.0210, loss-ulb:0.0106, weight:1.79, lr:0.0007
[00:14:52.731] iteration:5189  t-loss:0.0784, loss-lb:0.0533, loss-ulb:0.0140, weight:1.79, lr:0.0007
[00:14:53.110] iteration:5190  t-loss:0.0232, loss-lb:0.0206, loss-ulb:0.0014, weight:1.79, lr:0.0007
[00:14:53.492] iteration:5191  t-loss:0.0597, loss-lb:0.0452, loss-ulb:0.0081, weight:1.79, lr:0.0007
[00:14:53.866] iteration:5192  t-loss:0.0386, loss-lb:0.0368, loss-ulb:0.0010, weight:1.79, lr:0.0007
[00:14:54.257] iteration:5193  t-loss:0.0603, loss-lb:0.0413, loss-ulb:0.0106, weight:1.79, lr:0.0007
[00:14:54.651] iteration:5194  t-loss:0.0544, loss-lb:0.0479, loss-ulb:0.0037, weight:1.79, lr:0.0007
[00:14:55.040] iteration:5195  t-loss:0.0274, loss-lb:0.0238, loss-ulb:0.0020, weight:1.79, lr:0.0007
[00:14:55.424] iteration:5196  t-loss:0.0372, loss-lb:0.0328, loss-ulb:0.0025, weight:1.79, lr:0.0007
[00:14:55.800] iteration:5197  t-loss:0.0292, loss-lb:0.0194, loss-ulb:0.0055, weight:1.79, lr:0.0007
[00:14:56.174] iteration:5198  t-loss:0.0354, loss-lb:0.0203, loss-ulb:0.0085, weight:1.79, lr:0.0007
[00:14:56.552] iteration:5199  t-loss:0.0437, loss-lb:0.0390, loss-ulb:0.0027, weight:1.79, lr:0.0007
[00:14:56.924] iteration:5200  t-loss:0.0993, loss-lb:0.0506, loss-ulb:0.0272, weight:1.79, lr:0.0007
[00:14:57.298] iteration:5201  t-loss:0.0717, loss-lb:0.0340, loss-ulb:0.0210, weight:1.79, lr:0.0007
[00:14:57.668] iteration:5202  t-loss:0.0549, loss-lb:0.0478, loss-ulb:0.0040, weight:1.79, lr:0.0007
[00:14:58.038] iteration:5203  t-loss:0.0589, loss-lb:0.0510, loss-ulb:0.0044, weight:1.79, lr:0.0007
[00:14:58.412] iteration:5204  t-loss:0.0899, loss-lb:0.0333, loss-ulb:0.0317, weight:1.79, lr:0.0007
[00:14:58.788] iteration:5205  t-loss:0.0960, loss-lb:0.0645, loss-ulb:0.0176, weight:1.79, lr:0.0007
[00:14:59.163] iteration:5206  t-loss:0.0351, loss-lb:0.0244, loss-ulb:0.0060, weight:1.79, lr:0.0007
[00:16:00.181] iteration 5206 : dice_score: 0.873058 best_dice: 0.875400
[00:16:00.181]  <<Test>> - Ep:136  - Dice-S/T:85.89/87.31, Best-S:88.23, Best-T:87.54
[00:16:00.181]           - AvgLoss(lb/ulb/all):0.04/0.01/0.05
[00:16:01.430] iteration:5207  t-loss:0.1046, loss-lb:0.0534, loss-ulb:0.0287, weight:1.79, lr:0.0007
[00:16:01.821] iteration:5208  t-loss:0.0552, loss-lb:0.0226, loss-ulb:0.0183, weight:1.79, lr:0.0007
[00:16:02.203] iteration:5209  t-loss:0.0654, loss-lb:0.0520, loss-ulb:0.0075, weight:1.79, lr:0.0007
[00:16:02.579] iteration:5210  t-loss:0.0285, loss-lb:0.0217, loss-ulb:0.0038, weight:1.79, lr:0.0007
[00:16:02.967] iteration:5211  t-loss:0.0564, loss-lb:0.0409, loss-ulb:0.0087, weight:1.79, lr:0.0007
[00:16:03.343] iteration:5212  t-loss:0.0396, loss-lb:0.0361, loss-ulb:0.0020, weight:1.79, lr:0.0007
[00:16:03.724] iteration:5213  t-loss:0.0971, loss-lb:0.0442, loss-ulb:0.0296, weight:1.79, lr:0.0007
[00:16:04.103] iteration:5214  t-loss:0.0418, loss-lb:0.0242, loss-ulb:0.0098, weight:1.79, lr:0.0007
[00:16:04.486] iteration:5215  t-loss:0.0487, loss-lb:0.0210, loss-ulb:0.0155, weight:1.79, lr:0.0007
[00:16:04.866] iteration:5216  t-loss:0.0626, loss-lb:0.0414, loss-ulb:0.0119, weight:1.79, lr:0.0007
[00:16:05.252] iteration:5217  t-loss:0.0570, loss-lb:0.0372, loss-ulb:0.0110, weight:1.79, lr:0.0007
[00:16:05.629] iteration:5218  t-loss:0.0498, loss-lb:0.0356, loss-ulb:0.0079, weight:1.79, lr:0.0007
[00:16:06.013] iteration:5219  t-loss:0.0515, loss-lb:0.0309, loss-ulb:0.0115, weight:1.79, lr:0.0007
[00:16:06.396] iteration:5220  t-loss:0.0494, loss-lb:0.0409, loss-ulb:0.0048, weight:1.79, lr:0.0007
[00:16:06.781] iteration:5221  t-loss:0.0421, loss-lb:0.0268, loss-ulb:0.0086, weight:1.79, lr:0.0007
[00:16:07.166] iteration:5222  t-loss:0.0428, loss-lb:0.0273, loss-ulb:0.0086, weight:1.79, lr:0.0007
[00:16:07.554] iteration:5223  t-loss:0.0552, loss-lb:0.0384, loss-ulb:0.0094, weight:1.79, lr:0.0007
[00:16:07.936] iteration:5224  t-loss:0.0599, loss-lb:0.0395, loss-ulb:0.0114, weight:1.79, lr:0.0007
[00:16:08.319] iteration:5225  t-loss:0.0365, loss-lb:0.0216, loss-ulb:0.0084, weight:1.79, lr:0.0007
[00:16:08.703] iteration:5226  t-loss:0.0387, loss-lb:0.0246, loss-ulb:0.0079, weight:1.79, lr:0.0007
[00:16:09.081] iteration:5227  t-loss:0.0543, loss-lb:0.0390, loss-ulb:0.0085, weight:1.79, lr:0.0007
[00:16:09.464] iteration:5228  t-loss:0.0817, loss-lb:0.0570, loss-ulb:0.0138, weight:1.79, lr:0.0007
[00:16:09.846] iteration:5229  t-loss:0.0228, loss-lb:0.0188, loss-ulb:0.0022, weight:1.79, lr:0.0007
[00:16:10.223] iteration:5230  t-loss:0.0321, loss-lb:0.0227, loss-ulb:0.0053, weight:1.79, lr:0.0007
[00:16:10.608] iteration:5231  t-loss:0.0336, loss-lb:0.0197, loss-ulb:0.0078, weight:1.79, lr:0.0007
[00:16:10.988] iteration:5232  t-loss:0.0310, loss-lb:0.0272, loss-ulb:0.0021, weight:1.79, lr:0.0007
[00:16:11.378] iteration:5233  t-loss:0.0415, loss-lb:0.0239, loss-ulb:0.0098, weight:1.79, lr:0.0007
[00:16:11.760] iteration:5234  t-loss:0.0397, loss-lb:0.0234, loss-ulb:0.0091, weight:1.79, lr:0.0007
[00:16:12.152] iteration:5235  t-loss:0.0430, loss-lb:0.0210, loss-ulb:0.0123, weight:1.79, lr:0.0007
[00:16:12.531] iteration:5236  t-loss:0.0228, loss-lb:0.0196, loss-ulb:0.0018, weight:1.79, lr:0.0007
[00:16:12.910] iteration:5237  t-loss:0.0514, loss-lb:0.0218, loss-ulb:0.0165, weight:1.79, lr:0.0007
[00:16:13.288] iteration:5238  t-loss:0.0822, loss-lb:0.0698, loss-ulb:0.0069, weight:1.79, lr:0.0007
[00:16:13.664] iteration:5239  t-loss:0.0273, loss-lb:0.0247, loss-ulb:0.0015, weight:1.79, lr:0.0007
[00:16:14.038] iteration:5240  t-loss:0.0239, loss-lb:0.0212, loss-ulb:0.0015, weight:1.79, lr:0.0007
[00:16:14.414] iteration:5241  t-loss:0.0553, loss-lb:0.0236, loss-ulb:0.0177, weight:1.79, lr:0.0007
[00:16:14.793] iteration:5242  t-loss:0.0298, loss-lb:0.0181, loss-ulb:0.0065, weight:1.79, lr:0.0007
[00:16:15.166] iteration:5243  t-loss:0.0351, loss-lb:0.0228, loss-ulb:0.0069, weight:1.79, lr:0.0007
[00:16:15.548] iteration:5244  t-loss:0.0611, loss-lb:0.0589, loss-ulb:0.0013, weight:1.79, lr:0.0007
[00:16:16.907] iteration:5245  t-loss:0.0219, loss-lb:0.0187, loss-ulb:0.0018, weight:1.79, lr:0.0007
[00:16:17.320] iteration:5246  t-loss:0.0382, loss-lb:0.0211, loss-ulb:0.0096, weight:1.79, lr:0.0007
[00:16:17.704] iteration:5247  t-loss:0.0261, loss-lb:0.0197, loss-ulb:0.0036, weight:1.79, lr:0.0007
[00:16:18.085] iteration:5248  t-loss:0.0370, loss-lb:0.0195, loss-ulb:0.0098, weight:1.79, lr:0.0007
[00:16:18.470] iteration:5249  t-loss:0.1418, loss-lb:0.0712, loss-ulb:0.0395, weight:1.79, lr:0.0007
[00:16:18.854] iteration:5250  t-loss:0.0257, loss-lb:0.0226, loss-ulb:0.0017, weight:1.79, lr:0.0007
[00:16:19.239] iteration:5251  t-loss:0.0396, loss-lb:0.0161, loss-ulb:0.0127, weight:1.85, lr:0.0007
[00:16:19.621] iteration:5252  t-loss:0.0487, loss-lb:0.0219, loss-ulb:0.0145, weight:1.85, lr:0.0007
[00:16:20.001] iteration:5253  t-loss:0.0722, loss-lb:0.0465, loss-ulb:0.0139, weight:1.85, lr:0.0007
[00:16:20.391] iteration:5254  t-loss:0.0972, loss-lb:0.0506, loss-ulb:0.0252, weight:1.85, lr:0.0007
[00:16:20.775] iteration:5255  t-loss:0.0371, loss-lb:0.0226, loss-ulb:0.0078, weight:1.85, lr:0.0007
[00:16:21.154] iteration:5256  t-loss:0.0321, loss-lb:0.0289, loss-ulb:0.0017, weight:1.85, lr:0.0007
[00:16:21.537] iteration:5257  t-loss:0.0596, loss-lb:0.0451, loss-ulb:0.0078, weight:1.85, lr:0.0007
[00:16:21.927] iteration:5258  t-loss:0.0432, loss-lb:0.0389, loss-ulb:0.0023, weight:1.85, lr:0.0007
[00:16:22.317] iteration:5259  t-loss:0.0309, loss-lb:0.0206, loss-ulb:0.0056, weight:1.85, lr:0.0007
[00:16:22.696] iteration:5260  t-loss:0.0368, loss-lb:0.0345, loss-ulb:0.0013, weight:1.85, lr:0.0007
[00:16:23.077] iteration:5261  t-loss:0.0496, loss-lb:0.0206, loss-ulb:0.0157, weight:1.85, lr:0.0007
[00:16:23.469] iteration:5262  t-loss:0.0653, loss-lb:0.0353, loss-ulb:0.0162, weight:1.85, lr:0.0007
[00:16:23.851] iteration:5263  t-loss:0.0458, loss-lb:0.0442, loss-ulb:0.0009, weight:1.85, lr:0.0007
[00:16:24.236] iteration:5264  t-loss:0.0744, loss-lb:0.0540, loss-ulb:0.0110, weight:1.85, lr:0.0007
[00:16:24.615] iteration:5265  t-loss:0.0195, loss-lb:0.0168, loss-ulb:0.0015, weight:1.85, lr:0.0007
[00:16:25.004] iteration:5266  t-loss:0.0575, loss-lb:0.0501, loss-ulb:0.0040, weight:1.85, lr:0.0007
[00:16:25.380] iteration:5267  t-loss:0.0376, loss-lb:0.0289, loss-ulb:0.0047, weight:1.85, lr:0.0007
[00:16:25.754] iteration:5268  t-loss:0.0218, loss-lb:0.0169, loss-ulb:0.0026, weight:1.85, lr:0.0007
[00:16:26.133] iteration:5269  t-loss:0.0371, loss-lb:0.0351, loss-ulb:0.0011, weight:1.85, lr:0.0007
[00:16:26.522] iteration:5270  t-loss:0.0409, loss-lb:0.0227, loss-ulb:0.0098, weight:1.85, lr:0.0007
[00:16:26.905] iteration:5271  t-loss:0.0468, loss-lb:0.0326, loss-ulb:0.0077, weight:1.85, lr:0.0007
[00:16:27.293] iteration:5272  t-loss:0.1013, loss-lb:0.0845, loss-ulb:0.0091, weight:1.85, lr:0.0007
[00:16:27.674] iteration:5273  t-loss:0.0767, loss-lb:0.0444, loss-ulb:0.0175, weight:1.85, lr:0.0007
[00:16:28.065] iteration:5274  t-loss:0.0781, loss-lb:0.0639, loss-ulb:0.0077, weight:1.85, lr:0.0007
[00:16:28.444] iteration:5275  t-loss:0.0554, loss-lb:0.0439, loss-ulb:0.0062, weight:1.85, lr:0.0007
[00:16:28.822] iteration:5276  t-loss:0.0347, loss-lb:0.0223, loss-ulb:0.0067, weight:1.85, lr:0.0007
[00:16:29.203] iteration:5277  t-loss:0.0415, loss-lb:0.0229, loss-ulb:0.0101, weight:1.85, lr:0.0007
[00:16:29.581] iteration:5278  t-loss:0.0933, loss-lb:0.0227, loss-ulb:0.0382, weight:1.85, lr:0.0007
[00:16:29.953] iteration:5279  t-loss:0.0349, loss-lb:0.0185, loss-ulb:0.0089, weight:1.85, lr:0.0007
[00:16:30.329] iteration:5280  t-loss:0.0617, loss-lb:0.0268, loss-ulb:0.0188, weight:1.85, lr:0.0007
[00:16:30.709] iteration:5281  t-loss:0.0492, loss-lb:0.0342, loss-ulb:0.0081, weight:1.85, lr:0.0007
[00:16:31.089] iteration:5282  t-loss:0.0720, loss-lb:0.0279, loss-ulb:0.0239, weight:1.85, lr:0.0007
[00:16:32.316] iteration:5283  t-loss:0.0372, loss-lb:0.0244, loss-ulb:0.0069, weight:1.85, lr:0.0007
[00:16:32.721] iteration:5284  t-loss:0.0482, loss-lb:0.0308, loss-ulb:0.0094, weight:1.85, lr:0.0007
[00:16:33.116] iteration:5285  t-loss:0.0568, loss-lb:0.0533, loss-ulb:0.0019, weight:1.85, lr:0.0007
[00:16:33.500] iteration:5286  t-loss:0.0215, loss-lb:0.0153, loss-ulb:0.0034, weight:1.85, lr:0.0007
[00:16:33.884] iteration:5287  t-loss:0.0398, loss-lb:0.0305, loss-ulb:0.0050, weight:1.85, lr:0.0007
[00:16:34.269] iteration:5288  t-loss:0.0898, loss-lb:0.0294, loss-ulb:0.0326, weight:1.85, lr:0.0007
[00:16:34.661] iteration:5289  t-loss:0.0470, loss-lb:0.0403, loss-ulb:0.0036, weight:1.85, lr:0.0007
[00:16:35.045] iteration:5290  t-loss:0.0282, loss-lb:0.0255, loss-ulb:0.0014, weight:1.85, lr:0.0007
[00:16:35.427] iteration:5291  t-loss:0.0557, loss-lb:0.0280, loss-ulb:0.0149, weight:1.85, lr:0.0007
[00:16:35.809] iteration:5292  t-loss:0.0293, loss-lb:0.0167, loss-ulb:0.0068, weight:1.85, lr:0.0007
[00:16:36.193] iteration:5293  t-loss:0.0858, loss-lb:0.0346, loss-ulb:0.0277, weight:1.85, lr:0.0007
[00:16:36.575] iteration:5294  t-loss:0.0665, loss-lb:0.0619, loss-ulb:0.0025, weight:1.85, lr:0.0007
[00:16:36.956] iteration:5295  t-loss:0.0334, loss-lb:0.0290, loss-ulb:0.0024, weight:1.85, lr:0.0007
[00:16:37.341] iteration:5296  t-loss:0.0689, loss-lb:0.0477, loss-ulb:0.0115, weight:1.85, lr:0.0007
[00:16:37.728] iteration:5297  t-loss:0.0834, loss-lb:0.0667, loss-ulb:0.0090, weight:1.85, lr:0.0007
[00:16:38.112] iteration:5298  t-loss:0.0521, loss-lb:0.0299, loss-ulb:0.0120, weight:1.85, lr:0.0007
[00:16:38.500] iteration:5299  t-loss:0.0490, loss-lb:0.0411, loss-ulb:0.0042, weight:1.85, lr:0.0007
[00:16:38.890] iteration:5300  t-loss:0.0731, loss-lb:0.0501, loss-ulb:0.0124, weight:1.85, lr:0.0007
[00:16:39.272] iteration:5301  t-loss:0.0593, loss-lb:0.0450, loss-ulb:0.0077, weight:1.85, lr:0.0007
[00:16:39.660] iteration:5302  t-loss:0.0664, loss-lb:0.0385, loss-ulb:0.0151, weight:1.85, lr:0.0007
[00:16:40.072] iteration:5303  t-loss:0.0706, loss-lb:0.0324, loss-ulb:0.0206, weight:1.85, lr:0.0007
[00:16:40.476] iteration:5304  t-loss:0.0618, loss-lb:0.0566, loss-ulb:0.0028, weight:1.85, lr:0.0007
[00:16:40.881] iteration:5305  t-loss:0.0426, loss-lb:0.0307, loss-ulb:0.0064, weight:1.85, lr:0.0007
[00:16:41.265] iteration:5306  t-loss:0.0368, loss-lb:0.0213, loss-ulb:0.0084, weight:1.85, lr:0.0007
[00:16:41.644] iteration:5307  t-loss:0.0289, loss-lb:0.0168, loss-ulb:0.0066, weight:1.85, lr:0.0007
[00:16:42.025] iteration:5308  t-loss:0.0510, loss-lb:0.0304, loss-ulb:0.0111, weight:1.85, lr:0.0007
[00:16:42.409] iteration:5309  t-loss:0.0479, loss-lb:0.0221, loss-ulb:0.0140, weight:1.85, lr:0.0007
[00:16:42.793] iteration:5310  t-loss:0.0330, loss-lb:0.0219, loss-ulb:0.0060, weight:1.85, lr:0.0007
[00:16:43.181] iteration:5311  t-loss:0.0517, loss-lb:0.0303, loss-ulb:0.0115, weight:1.85, lr:0.0007
[00:16:43.564] iteration:5312  t-loss:0.0678, loss-lb:0.0625, loss-ulb:0.0029, weight:1.85, lr:0.0007
[00:16:43.943] iteration:5313  t-loss:0.0822, loss-lb:0.0508, loss-ulb:0.0169, weight:1.85, lr:0.0007
[00:16:44.322] iteration:5314  t-loss:0.0325, loss-lb:0.0162, loss-ulb:0.0088, weight:1.85, lr:0.0007
[00:16:44.699] iteration:5315  t-loss:0.0464, loss-lb:0.0429, loss-ulb:0.0019, weight:1.85, lr:0.0007
[00:16:45.077] iteration:5316  t-loss:0.0594, loss-lb:0.0376, loss-ulb:0.0118, weight:1.85, lr:0.0007
[00:16:45.456] iteration:5317  t-loss:0.0328, loss-lb:0.0163, loss-ulb:0.0089, weight:1.85, lr:0.0007
[00:16:45.830] iteration:5318  t-loss:0.0289, loss-lb:0.0244, loss-ulb:0.0024, weight:1.85, lr:0.0007
[00:16:46.209] iteration:5319  t-loss:0.0570, loss-lb:0.0191, loss-ulb:0.0205, weight:1.85, lr:0.0007
[00:16:46.585] iteration:5320  t-loss:0.0564, loss-lb:0.0289, loss-ulb:0.0149, weight:1.85, lr:0.0007
[00:16:47.975] iteration:5321  t-loss:0.0415, loss-lb:0.0199, loss-ulb:0.0117, weight:1.85, lr:0.0007
[00:16:48.365] iteration:5322  t-loss:0.0245, loss-lb:0.0185, loss-ulb:0.0032, weight:1.85, lr:0.0007
[00:16:48.746] iteration:5323  t-loss:0.0502, loss-lb:0.0218, loss-ulb:0.0154, weight:1.85, lr:0.0007
[00:16:49.130] iteration:5324  t-loss:0.0642, loss-lb:0.0403, loss-ulb:0.0129, weight:1.85, lr:0.0007
[00:16:49.511] iteration:5325  t-loss:0.0575, loss-lb:0.0419, loss-ulb:0.0085, weight:1.85, lr:0.0007
[00:16:49.896] iteration:5326  t-loss:0.0378, loss-lb:0.0344, loss-ulb:0.0018, weight:1.85, lr:0.0007
[00:16:50.276] iteration:5327  t-loss:0.0670, loss-lb:0.0460, loss-ulb:0.0114, weight:1.85, lr:0.0007
[00:16:50.648] iteration:5328  t-loss:0.0229, loss-lb:0.0156, loss-ulb:0.0039, weight:1.85, lr:0.0007
[00:16:51.028] iteration:5329  t-loss:0.0279, loss-lb:0.0249, loss-ulb:0.0016, weight:1.85, lr:0.0007
[00:16:51.404] iteration:5330  t-loss:0.0234, loss-lb:0.0210, loss-ulb:0.0013, weight:1.85, lr:0.0007
[00:16:51.781] iteration:5331  t-loss:0.0229, loss-lb:0.0177, loss-ulb:0.0028, weight:1.85, lr:0.0007
[00:16:52.162] iteration:5332  t-loss:0.0686, loss-lb:0.0319, loss-ulb:0.0198, weight:1.85, lr:0.0007
[00:16:52.538] iteration:5333  t-loss:0.0266, loss-lb:0.0201, loss-ulb:0.0035, weight:1.85, lr:0.0007
[00:16:52.921] iteration:5334  t-loss:0.0365, loss-lb:0.0209, loss-ulb:0.0084, weight:1.85, lr:0.0007
[00:16:53.303] iteration:5335  t-loss:0.0599, loss-lb:0.0300, loss-ulb:0.0161, weight:1.85, lr:0.0007
[00:16:53.680] iteration:5336  t-loss:0.0384, loss-lb:0.0361, loss-ulb:0.0013, weight:1.85, lr:0.0007
[00:16:54.059] iteration:5337  t-loss:0.0450, loss-lb:0.0392, loss-ulb:0.0031, weight:1.85, lr:0.0007
[00:16:54.433] iteration:5338  t-loss:0.0251, loss-lb:0.0223, loss-ulb:0.0015, weight:1.85, lr:0.0007
[00:16:54.812] iteration:5339  t-loss:0.0613, loss-lb:0.0229, loss-ulb:0.0208, weight:1.85, lr:0.0007
[00:16:55.208] iteration:5340  t-loss:0.0511, loss-lb:0.0444, loss-ulb:0.0036, weight:1.85, lr:0.0007
[00:16:55.631] iteration:5341  t-loss:0.0432, loss-lb:0.0211, loss-ulb:0.0119, weight:1.85, lr:0.0007
[00:16:56.044] iteration:5342  t-loss:0.0318, loss-lb:0.0190, loss-ulb:0.0069, weight:1.85, lr:0.0007
[00:16:56.467] iteration:5343  t-loss:0.0457, loss-lb:0.0403, loss-ulb:0.0029, weight:1.85, lr:0.0007
[00:16:56.862] iteration:5344  t-loss:0.0467, loss-lb:0.0365, loss-ulb:0.0055, weight:1.85, lr:0.0007
[00:16:57.240] iteration:5345  t-loss:0.0302, loss-lb:0.0227, loss-ulb:0.0040, weight:1.85, lr:0.0007
[00:16:57.622] iteration:5346  t-loss:0.0371, loss-lb:0.0210, loss-ulb:0.0087, weight:1.85, lr:0.0007
[00:16:57.998] iteration:5347  t-loss:0.0518, loss-lb:0.0455, loss-ulb:0.0034, weight:1.85, lr:0.0007
[00:16:58.373] iteration:5348  t-loss:0.0300, loss-lb:0.0243, loss-ulb:0.0030, weight:1.85, lr:0.0007
[00:16:58.752] iteration:5349  t-loss:0.0920, loss-lb:0.0889, loss-ulb:0.0017, weight:1.85, lr:0.0007
[00:16:59.133] iteration:5350  t-loss:0.0535, loss-lb:0.0276, loss-ulb:0.0140, weight:1.85, lr:0.0007
[00:16:59.512] iteration:5351  t-loss:0.0876, loss-lb:0.0563, loss-ulb:0.0169, weight:1.85, lr:0.0007
[00:16:59.889] iteration:5352  t-loss:0.0393, loss-lb:0.0259, loss-ulb:0.0073, weight:1.85, lr:0.0007
[00:17:00.265] iteration:5353  t-loss:0.0685, loss-lb:0.0565, loss-ulb:0.0065, weight:1.85, lr:0.0007
[00:17:00.643] iteration:5354  t-loss:0.0702, loss-lb:0.0337, loss-ulb:0.0197, weight:1.85, lr:0.0007
[00:17:01.015] iteration:5355  t-loss:0.0341, loss-lb:0.0262, loss-ulb:0.0043, weight:1.85, lr:0.0007
[00:17:01.385] iteration:5356  t-loss:0.0204, loss-lb:0.0144, loss-ulb:0.0033, weight:1.85, lr:0.0007
[00:17:01.762] iteration:5357  t-loss:0.1416, loss-lb:0.0354, loss-ulb:0.0574, weight:1.85, lr:0.0007
[00:17:02.135] iteration:5358  t-loss:0.0401, loss-lb:0.0367, loss-ulb:0.0018, weight:1.85, lr:0.0007
[00:18:03.502] iteration 5358 : dice_score: 0.869421 best_dice: 0.875400
[00:18:03.502]  <<Test>> - Ep:140  - Dice-S/T:81.66/86.94, Best-S:88.23, Best-T:87.54
[00:18:03.502]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:18:04.749] iteration:5359  t-loss:0.0597, loss-lb:0.0336, loss-ulb:0.0141, weight:1.85, lr:0.0007
[00:18:05.134] iteration:5360  t-loss:0.0810, loss-lb:0.0669, loss-ulb:0.0076, weight:1.85, lr:0.0007
[00:18:05.517] iteration:5361  t-loss:0.0641, loss-lb:0.0440, loss-ulb:0.0109, weight:1.85, lr:0.0007
[00:18:05.899] iteration:5362  t-loss:0.0385, loss-lb:0.0242, loss-ulb:0.0077, weight:1.85, lr:0.0007
[00:18:06.283] iteration:5363  t-loss:0.1098, loss-lb:0.0485, loss-ulb:0.0331, weight:1.85, lr:0.0007
[00:18:06.665] iteration:5364  t-loss:0.0521, loss-lb:0.0465, loss-ulb:0.0030, weight:1.85, lr:0.0007
[00:18:07.044] iteration:5365  t-loss:0.0527, loss-lb:0.0386, loss-ulb:0.0076, weight:1.85, lr:0.0007
[00:18:07.430] iteration:5366  t-loss:0.0678, loss-lb:0.0580, loss-ulb:0.0053, weight:1.85, lr:0.0007
[00:18:07.816] iteration:5367  t-loss:0.1068, loss-lb:0.0518, loss-ulb:0.0298, weight:1.85, lr:0.0007
[00:18:08.199] iteration:5368  t-loss:0.1252, loss-lb:0.0727, loss-ulb:0.0284, weight:1.85, lr:0.0007
[00:18:08.580] iteration:5369  t-loss:0.0553, loss-lb:0.0345, loss-ulb:0.0112, weight:1.85, lr:0.0007
[00:18:08.957] iteration:5370  t-loss:0.0795, loss-lb:0.0635, loss-ulb:0.0086, weight:1.85, lr:0.0007
[00:18:09.334] iteration:5371  t-loss:0.0486, loss-lb:0.0213, loss-ulb:0.0148, weight:1.85, lr:0.0007
[00:18:09.715] iteration:5372  t-loss:0.0307, loss-lb:0.0206, loss-ulb:0.0055, weight:1.85, lr:0.0007
[00:18:10.102] iteration:5373  t-loss:0.0501, loss-lb:0.0360, loss-ulb:0.0076, weight:1.85, lr:0.0007
[00:18:10.480] iteration:5374  t-loss:0.1042, loss-lb:0.0843, loss-ulb:0.0107, weight:1.85, lr:0.0007
[00:18:10.863] iteration:5375  t-loss:0.0729, loss-lb:0.0512, loss-ulb:0.0117, weight:1.85, lr:0.0007
[00:18:11.240] iteration:5376  t-loss:0.0336, loss-lb:0.0294, loss-ulb:0.0023, weight:1.85, lr:0.0007
[00:18:11.620] iteration:5377  t-loss:0.1120, loss-lb:0.0521, loss-ulb:0.0324, weight:1.85, lr:0.0007
[00:18:12.002] iteration:5378  t-loss:0.0655, loss-lb:0.0284, loss-ulb:0.0201, weight:1.85, lr:0.0007
[00:18:12.383] iteration:5379  t-loss:0.0653, loss-lb:0.0417, loss-ulb:0.0128, weight:1.85, lr:0.0007
[00:18:12.764] iteration:5380  t-loss:0.0750, loss-lb:0.0701, loss-ulb:0.0027, weight:1.85, lr:0.0007
[00:18:13.140] iteration:5381  t-loss:0.0547, loss-lb:0.0401, loss-ulb:0.0079, weight:1.85, lr:0.0007
[00:18:13.520] iteration:5382  t-loss:0.0464, loss-lb:0.0399, loss-ulb:0.0035, weight:1.85, lr:0.0007
[00:18:13.900] iteration:5383  t-loss:0.1450, loss-lb:0.1100, loss-ulb:0.0189, weight:1.85, lr:0.0007
[00:18:14.282] iteration:5384  t-loss:0.0445, loss-lb:0.0249, loss-ulb:0.0106, weight:1.85, lr:0.0007
[00:18:14.667] iteration:5385  t-loss:0.0534, loss-lb:0.0276, loss-ulb:0.0140, weight:1.85, lr:0.0007
[00:18:15.051] iteration:5386  t-loss:0.0750, loss-lb:0.0339, loss-ulb:0.0223, weight:1.85, lr:0.0007
[00:18:15.446] iteration:5387  t-loss:0.0714, loss-lb:0.0519, loss-ulb:0.0106, weight:1.85, lr:0.0007
[00:18:15.826] iteration:5388  t-loss:0.0383, loss-lb:0.0322, loss-ulb:0.0033, weight:1.85, lr:0.0007
[00:18:16.205] iteration:5389  t-loss:0.0366, loss-lb:0.0232, loss-ulb:0.0072, weight:1.85, lr:0.0007
[00:18:16.578] iteration:5390  t-loss:0.0290, loss-lb:0.0206, loss-ulb:0.0046, weight:1.85, lr:0.0007
[00:18:16.951] iteration:5391  t-loss:0.0323, loss-lb:0.0255, loss-ulb:0.0037, weight:1.85, lr:0.0007
[00:18:17.333] iteration:5392  t-loss:0.1029, loss-lb:0.0353, loss-ulb:0.0365, weight:1.85, lr:0.0007
[00:18:17.709] iteration:5393  t-loss:0.0269, loss-lb:0.0241, loss-ulb:0.0015, weight:1.85, lr:0.0007
[00:18:18.087] iteration:5394  t-loss:0.0783, loss-lb:0.0308, loss-ulb:0.0257, weight:1.85, lr:0.0007
[00:18:18.464] iteration:5395  t-loss:0.0388, loss-lb:0.0355, loss-ulb:0.0017, weight:1.85, lr:0.0007
[00:18:18.844] iteration:5396  t-loss:0.0454, loss-lb:0.0353, loss-ulb:0.0055, weight:1.85, lr:0.0007
[00:18:20.210] iteration:5397  t-loss:0.0347, loss-lb:0.0170, loss-ulb:0.0096, weight:1.85, lr:0.0007
[00:18:20.616] iteration:5398  t-loss:0.0583, loss-lb:0.0410, loss-ulb:0.0093, weight:1.85, lr:0.0007
[00:18:21.002] iteration:5399  t-loss:0.0599, loss-lb:0.0280, loss-ulb:0.0172, weight:1.85, lr:0.0007
[00:18:21.388] iteration:5400  t-loss:0.0465, loss-lb:0.0386, loss-ulb:0.0043, weight:1.85, lr:0.0007
[00:18:21.772] iteration:5401  t-loss:0.0302, loss-lb:0.0157, loss-ulb:0.0076, weight:1.90, lr:0.0007
[00:18:22.156] iteration:5402  t-loss:0.0393, loss-lb:0.0206, loss-ulb:0.0098, weight:1.90, lr:0.0007
[00:18:22.538] iteration:5403  t-loss:0.0948, loss-lb:0.0692, loss-ulb:0.0134, weight:1.90, lr:0.0007
[00:18:22.916] iteration:5404  t-loss:0.0269, loss-lb:0.0205, loss-ulb:0.0034, weight:1.90, lr:0.0007
[00:18:23.306] iteration:5405  t-loss:0.0464, loss-lb:0.0386, loss-ulb:0.0041, weight:1.90, lr:0.0007
[00:18:23.690] iteration:5406  t-loss:0.0512, loss-lb:0.0424, loss-ulb:0.0046, weight:1.90, lr:0.0007
[00:18:24.071] iteration:5407  t-loss:0.0604, loss-lb:0.0181, loss-ulb:0.0222, weight:1.90, lr:0.0007
[00:18:24.451] iteration:5408  t-loss:0.0300, loss-lb:0.0231, loss-ulb:0.0037, weight:1.90, lr:0.0007
[00:18:24.834] iteration:5409  t-loss:0.0750, loss-lb:0.0585, loss-ulb:0.0087, weight:1.90, lr:0.0007
[00:18:25.219] iteration:5410  t-loss:0.0375, loss-lb:0.0311, loss-ulb:0.0034, weight:1.90, lr:0.0007
[00:18:25.606] iteration:5411  t-loss:0.0611, loss-lb:0.0326, loss-ulb:0.0150, weight:1.90, lr:0.0007
[00:18:25.981] iteration:5412  t-loss:0.0449, loss-lb:0.0384, loss-ulb:0.0034, weight:1.90, lr:0.0007
[00:18:26.368] iteration:5413  t-loss:0.0643, loss-lb:0.0460, loss-ulb:0.0096, weight:1.90, lr:0.0007
[00:18:26.744] iteration:5414  t-loss:0.0424, loss-lb:0.0355, loss-ulb:0.0036, weight:1.90, lr:0.0007
[00:18:27.128] iteration:5415  t-loss:0.0438, loss-lb:0.0349, loss-ulb:0.0047, weight:1.90, lr:0.0007
[00:18:27.510] iteration:5416  t-loss:0.0574, loss-lb:0.0539, loss-ulb:0.0018, weight:1.90, lr:0.0007
[00:18:27.895] iteration:5417  t-loss:0.0589, loss-lb:0.0415, loss-ulb:0.0092, weight:1.90, lr:0.0007
[00:18:28.280] iteration:5418  t-loss:0.0501, loss-lb:0.0469, loss-ulb:0.0016, weight:1.90, lr:0.0007
[00:18:28.666] iteration:5419  t-loss:0.0436, loss-lb:0.0399, loss-ulb:0.0019, weight:1.90, lr:0.0007
[00:18:29.047] iteration:5420  t-loss:0.0511, loss-lb:0.0321, loss-ulb:0.0100, weight:1.90, lr:0.0007
[00:18:29.438] iteration:5421  t-loss:0.0304, loss-lb:0.0264, loss-ulb:0.0021, weight:1.90, lr:0.0007
[00:18:29.820] iteration:5422  t-loss:0.0473, loss-lb:0.0312, loss-ulb:0.0085, weight:1.90, lr:0.0007
[00:18:30.211] iteration:5423  t-loss:0.0426, loss-lb:0.0221, loss-ulb:0.0108, weight:1.90, lr:0.0007
[00:18:30.606] iteration:5424  t-loss:0.0602, loss-lb:0.0469, loss-ulb:0.0070, weight:1.90, lr:0.0007
[00:18:30.983] iteration:5425  t-loss:0.0538, loss-lb:0.0221, loss-ulb:0.0166, weight:1.90, lr:0.0007
[00:18:31.364] iteration:5426  t-loss:0.0309, loss-lb:0.0219, loss-ulb:0.0047, weight:1.90, lr:0.0007
[00:18:31.746] iteration:5427  t-loss:0.0209, loss-lb:0.0162, loss-ulb:0.0025, weight:1.90, lr:0.0007
[00:18:32.123] iteration:5428  t-loss:0.0459, loss-lb:0.0233, loss-ulb:0.0119, weight:1.90, lr:0.0007
[00:18:32.499] iteration:5429  t-loss:0.0612, loss-lb:0.0242, loss-ulb:0.0195, weight:1.90, lr:0.0007
[00:18:32.877] iteration:5430  t-loss:0.0798, loss-lb:0.0237, loss-ulb:0.0295, weight:1.90, lr:0.0007
[00:18:33.257] iteration:5431  t-loss:0.0281, loss-lb:0.0214, loss-ulb:0.0035, weight:1.90, lr:0.0007
[00:18:33.637] iteration:5432  t-loss:0.0235, loss-lb:0.0167, loss-ulb:0.0036, weight:1.90, lr:0.0007
[00:18:34.025] iteration:5433  t-loss:0.0394, loss-lb:0.0350, loss-ulb:0.0023, weight:1.90, lr:0.0007
[00:18:34.397] iteration:5434  t-loss:0.0375, loss-lb:0.0200, loss-ulb:0.0092, weight:1.90, lr:0.0007
[00:18:35.626] iteration:5435  t-loss:0.0627, loss-lb:0.0304, loss-ulb:0.0170, weight:1.90, lr:0.0007
[00:18:36.042] iteration:5436  t-loss:0.0499, loss-lb:0.0162, loss-ulb:0.0177, weight:1.90, lr:0.0007
[00:18:36.434] iteration:5437  t-loss:0.0521, loss-lb:0.0392, loss-ulb:0.0068, weight:1.90, lr:0.0007
[00:18:36.818] iteration:5438  t-loss:0.0831, loss-lb:0.0786, loss-ulb:0.0024, weight:1.90, lr:0.0007
[00:18:37.197] iteration:5439  t-loss:0.0368, loss-lb:0.0323, loss-ulb:0.0024, weight:1.90, lr:0.0007
[00:18:37.578] iteration:5440  t-loss:0.0616, loss-lb:0.0494, loss-ulb:0.0064, weight:1.90, lr:0.0007
[00:18:37.971] iteration:5441  t-loss:0.0620, loss-lb:0.0468, loss-ulb:0.0080, weight:1.90, lr:0.0007
[00:18:38.352] iteration:5442  t-loss:0.0675, loss-lb:0.0416, loss-ulb:0.0136, weight:1.90, lr:0.0007
[00:18:38.737] iteration:5443  t-loss:0.0501, loss-lb:0.0356, loss-ulb:0.0076, weight:1.90, lr:0.0007
[00:18:39.114] iteration:5444  t-loss:0.0426, loss-lb:0.0205, loss-ulb:0.0116, weight:1.90, lr:0.0007
[00:18:39.499] iteration:5445  t-loss:0.0703, loss-lb:0.0441, loss-ulb:0.0138, weight:1.90, lr:0.0007
[00:18:39.880] iteration:5446  t-loss:0.0778, loss-lb:0.0321, loss-ulb:0.0240, weight:1.90, lr:0.0007
[00:18:40.264] iteration:5447  t-loss:0.0729, loss-lb:0.0473, loss-ulb:0.0135, weight:1.90, lr:0.0007
[00:18:40.647] iteration:5448  t-loss:0.0766, loss-lb:0.0470, loss-ulb:0.0156, weight:1.90, lr:0.0007
[00:18:41.036] iteration:5449  t-loss:0.0711, loss-lb:0.0509, loss-ulb:0.0106, weight:1.90, lr:0.0007
[00:18:41.419] iteration:5450  t-loss:0.0447, loss-lb:0.0238, loss-ulb:0.0109, weight:1.90, lr:0.0007
[00:18:41.805] iteration:5451  t-loss:0.0449, loss-lb:0.0387, loss-ulb:0.0033, weight:1.90, lr:0.0007
[00:18:42.186] iteration:5452  t-loss:0.0626, loss-lb:0.0334, loss-ulb:0.0154, weight:1.90, lr:0.0007
[00:18:42.566] iteration:5453  t-loss:0.1043, loss-lb:0.0986, loss-ulb:0.0030, weight:1.90, lr:0.0007
[00:18:42.953] iteration:5454  t-loss:0.0457, loss-lb:0.0352, loss-ulb:0.0055, weight:1.90, lr:0.0007
[00:18:43.328] iteration:5455  t-loss:0.0655, loss-lb:0.0336, loss-ulb:0.0168, weight:1.90, lr:0.0007
[00:18:43.705] iteration:5456  t-loss:0.0329, loss-lb:0.0243, loss-ulb:0.0045, weight:1.90, lr:0.0007
[00:18:44.086] iteration:5457  t-loss:0.0435, loss-lb:0.0359, loss-ulb:0.0040, weight:1.90, lr:0.0007
[00:18:44.469] iteration:5458  t-loss:0.0488, loss-lb:0.0289, loss-ulb:0.0105, weight:1.90, lr:0.0007
[00:18:44.853] iteration:5459  t-loss:0.0267, loss-lb:0.0225, loss-ulb:0.0022, weight:1.90, lr:0.0007
[00:18:45.234] iteration:5460  t-loss:0.0221, loss-lb:0.0178, loss-ulb:0.0022, weight:1.90, lr:0.0007
[00:18:45.626] iteration:5461  t-loss:0.0268, loss-lb:0.0173, loss-ulb:0.0050, weight:1.90, lr:0.0007
[00:18:46.029] iteration:5462  t-loss:0.1100, loss-lb:0.0157, loss-ulb:0.0496, weight:1.90, lr:0.0007
[00:18:46.415] iteration:5463  t-loss:0.0204, loss-lb:0.0173, loss-ulb:0.0016, weight:1.90, lr:0.0007
[00:18:46.806] iteration:5464  t-loss:0.1005, loss-lb:0.0799, loss-ulb:0.0108, weight:1.90, lr:0.0007
[00:18:47.186] iteration:5465  t-loss:0.1362, loss-lb:0.1129, loss-ulb:0.0122, weight:1.90, lr:0.0007
[00:18:47.558] iteration:5466  t-loss:0.0206, loss-lb:0.0170, loss-ulb:0.0019, weight:1.90, lr:0.0007
[00:18:47.934] iteration:5467  t-loss:0.0619, loss-lb:0.0259, loss-ulb:0.0189, weight:1.90, lr:0.0007
[00:18:48.311] iteration:5468  t-loss:0.0327, loss-lb:0.0276, loss-ulb:0.0027, weight:1.90, lr:0.0007
[00:18:48.685] iteration:5469  t-loss:0.0741, loss-lb:0.0682, loss-ulb:0.0031, weight:1.90, lr:0.0007
[00:18:49.057] iteration:5470  t-loss:0.0306, loss-lb:0.0211, loss-ulb:0.0050, weight:1.90, lr:0.0007
[00:18:49.435] iteration:5471  t-loss:0.0793, loss-lb:0.0251, loss-ulb:0.0285, weight:1.90, lr:0.0007
[00:18:49.814] iteration:5472  t-loss:0.0760, loss-lb:0.0291, loss-ulb:0.0246, weight:1.90, lr:0.0007
[00:18:51.028] iteration:5473  t-loss:0.0370, loss-lb:0.0305, loss-ulb:0.0034, weight:1.90, lr:0.0007
[00:18:51.416] iteration:5474  t-loss:0.0497, loss-lb:0.0296, loss-ulb:0.0105, weight:1.90, lr:0.0007
[00:18:51.799] iteration:5475  t-loss:0.0457, loss-lb:0.0304, loss-ulb:0.0080, weight:1.90, lr:0.0007
[00:18:52.173] iteration:5476  t-loss:0.0210, loss-lb:0.0188, loss-ulb:0.0012, weight:1.90, lr:0.0007
[00:18:52.554] iteration:5477  t-loss:0.0613, loss-lb:0.0189, loss-ulb:0.0223, weight:1.90, lr:0.0007
[00:18:52.936] iteration:5478  t-loss:0.0739, loss-lb:0.0508, loss-ulb:0.0121, weight:1.90, lr:0.0007
[00:18:53.316] iteration:5479  t-loss:0.0535, loss-lb:0.0397, loss-ulb:0.0072, weight:1.90, lr:0.0007
[00:18:53.693] iteration:5480  t-loss:0.0897, loss-lb:0.0480, loss-ulb:0.0219, weight:1.90, lr:0.0007
[00:18:54.076] iteration:5481  t-loss:0.0513, loss-lb:0.0256, loss-ulb:0.0136, weight:1.90, lr:0.0007
[00:18:54.455] iteration:5482  t-loss:0.0419, loss-lb:0.0371, loss-ulb:0.0025, weight:1.90, lr:0.0007
[00:18:54.834] iteration:5483  t-loss:0.0639, loss-lb:0.0474, loss-ulb:0.0087, weight:1.90, lr:0.0007
[00:18:55.210] iteration:5484  t-loss:0.0387, loss-lb:0.0318, loss-ulb:0.0036, weight:1.90, lr:0.0007
[00:18:55.593] iteration:5485  t-loss:0.0547, loss-lb:0.0509, loss-ulb:0.0020, weight:1.90, lr:0.0007
[00:18:55.971] iteration:5486  t-loss:0.0468, loss-lb:0.0298, loss-ulb:0.0090, weight:1.90, lr:0.0007
[00:18:56.355] iteration:5487  t-loss:0.0504, loss-lb:0.0427, loss-ulb:0.0041, weight:1.90, lr:0.0007
[00:18:56.734] iteration:5488  t-loss:0.0295, loss-lb:0.0176, loss-ulb:0.0063, weight:1.90, lr:0.0007
[00:18:57.119] iteration:5489  t-loss:0.0638, loss-lb:0.0522, loss-ulb:0.0061, weight:1.90, lr:0.0007
[00:18:57.499] iteration:5490  t-loss:0.0634, loss-lb:0.0379, loss-ulb:0.0134, weight:1.90, lr:0.0007
[00:18:57.874] iteration:5491  t-loss:0.0419, loss-lb:0.0269, loss-ulb:0.0079, weight:1.90, lr:0.0007
[00:18:58.251] iteration:5492  t-loss:0.0973, loss-lb:0.0150, loss-ulb:0.0433, weight:1.90, lr:0.0007
[00:18:58.633] iteration:5493  t-loss:0.0579, loss-lb:0.0355, loss-ulb:0.0118, weight:1.90, lr:0.0007
[00:18:59.017] iteration:5494  t-loss:0.0680, loss-lb:0.0377, loss-ulb:0.0159, weight:1.90, lr:0.0007
[00:18:59.394] iteration:5495  t-loss:0.0386, loss-lb:0.0260, loss-ulb:0.0066, weight:1.90, lr:0.0007
[00:18:59.773] iteration:5496  t-loss:0.0800, loss-lb:0.0370, loss-ulb:0.0226, weight:1.90, lr:0.0007
[00:19:00.152] iteration:5497  t-loss:0.0655, loss-lb:0.0471, loss-ulb:0.0097, weight:1.90, lr:0.0007
[00:19:00.534] iteration:5498  t-loss:0.0687, loss-lb:0.0379, loss-ulb:0.0162, weight:1.90, lr:0.0007
[00:19:00.920] iteration:5499  t-loss:0.0768, loss-lb:0.0391, loss-ulb:0.0198, weight:1.90, lr:0.0007
[00:19:01.315] iteration:5500  t-loss:0.0424, loss-lb:0.0285, loss-ulb:0.0073, weight:1.90, lr:0.0007
[00:19:01.709] iteration:5501  t-loss:0.0549, loss-lb:0.0219, loss-ulb:0.0174, weight:1.90, lr:0.0007
[00:19:02.085] iteration:5502  t-loss:0.0458, loss-lb:0.0276, loss-ulb:0.0096, weight:1.90, lr:0.0007
[00:19:02.460] iteration:5503  t-loss:0.0581, loss-lb:0.0540, loss-ulb:0.0022, weight:1.90, lr:0.0007
[00:19:02.836] iteration:5504  t-loss:0.0953, loss-lb:0.0397, loss-ulb:0.0292, weight:1.90, lr:0.0007
[00:19:03.213] iteration:5505  t-loss:0.1174, loss-lb:0.0501, loss-ulb:0.0354, weight:1.90, lr:0.0007
[00:19:03.589] iteration:5506  t-loss:0.0484, loss-lb:0.0427, loss-ulb:0.0030, weight:1.90, lr:0.0007
[00:19:03.964] iteration:5507  t-loss:0.0733, loss-lb:0.0234, loss-ulb:0.0263, weight:1.90, lr:0.0007
[00:19:04.338] iteration:5508  t-loss:0.0852, loss-lb:0.0448, loss-ulb:0.0212, weight:1.90, lr:0.0007
[00:19:04.712] iteration:5509  t-loss:0.0322, loss-lb:0.0292, loss-ulb:0.0016, weight:1.90, lr:0.0007
[00:19:05.090] iteration:5510  t-loss:0.0470, loss-lb:0.0287, loss-ulb:0.0096, weight:1.90, lr:0.0007
[00:20:07.556] iteration 5510 : dice_score: 0.854716 best_dice: 0.875400
[00:20:07.556]  <<Test>> - Ep:144  - Dice-S/T:80.00/85.47, Best-S:88.23, Best-T:87.54
[00:20:07.556]           - AvgLoss(lb/ulb/all):0.04/0.02/0.06
[00:20:08.574] iteration:5511  t-loss:0.0382, loss-lb:0.0291, loss-ulb:0.0048, weight:1.90, lr:0.0007
[00:20:08.963] iteration:5512  t-loss:0.0511, loss-lb:0.0370, loss-ulb:0.0074, weight:1.90, lr:0.0007
[00:20:09.340] iteration:5513  t-loss:0.0433, loss-lb:0.0184, loss-ulb:0.0131, weight:1.90, lr:0.0007
[00:20:09.717] iteration:5514  t-loss:0.0841, loss-lb:0.0737, loss-ulb:0.0055, weight:1.90, lr:0.0007
[00:20:10.093] iteration:5515  t-loss:0.0607, loss-lb:0.0370, loss-ulb:0.0125, weight:1.90, lr:0.0007
[00:20:10.478] iteration:5516  t-loss:0.0556, loss-lb:0.0533, loss-ulb:0.0012, weight:1.90, lr:0.0007
[00:20:10.860] iteration:5517  t-loss:0.0677, loss-lb:0.0516, loss-ulb:0.0085, weight:1.90, lr:0.0007
[00:20:11.241] iteration:5518  t-loss:0.1113, loss-lb:0.0690, loss-ulb:0.0222, weight:1.90, lr:0.0007
[00:20:11.627] iteration:5519  t-loss:0.0451, loss-lb:0.0347, loss-ulb:0.0054, weight:1.90, lr:0.0007
[00:20:12.004] iteration:5520  t-loss:0.0368, loss-lb:0.0242, loss-ulb:0.0066, weight:1.90, lr:0.0007
[00:20:12.382] iteration:5521  t-loss:0.0270, loss-lb:0.0225, loss-ulb:0.0024, weight:1.90, lr:0.0007
[00:20:12.759] iteration:5522  t-loss:0.0503, loss-lb:0.0443, loss-ulb:0.0032, weight:1.90, lr:0.0007
[00:20:13.140] iteration:5523  t-loss:0.0828, loss-lb:0.0744, loss-ulb:0.0044, weight:1.90, lr:0.0007
[00:20:13.525] iteration:5524  t-loss:0.0575, loss-lb:0.0403, loss-ulb:0.0091, weight:1.90, lr:0.0007
[00:20:13.909] iteration:5525  t-loss:0.0814, loss-lb:0.0782, loss-ulb:0.0017, weight:1.90, lr:0.0007
[00:20:14.288] iteration:5526  t-loss:0.0497, loss-lb:0.0183, loss-ulb:0.0165, weight:1.90, lr:0.0007
[00:20:14.670] iteration:5527  t-loss:0.1575, loss-lb:0.0662, loss-ulb:0.0480, weight:1.90, lr:0.0007
[00:20:15.055] iteration:5528  t-loss:0.0578, loss-lb:0.0475, loss-ulb:0.0054, weight:1.90, lr:0.0007
[00:20:15.435] iteration:5529  t-loss:0.0488, loss-lb:0.0338, loss-ulb:0.0079, weight:1.90, lr:0.0007
[00:20:15.816] iteration:5530  t-loss:0.0443, loss-lb:0.0287, loss-ulb:0.0082, weight:1.90, lr:0.0007
[00:20:16.195] iteration:5531  t-loss:0.0349, loss-lb:0.0256, loss-ulb:0.0049, weight:1.90, lr:0.0007
[00:20:16.576] iteration:5532  t-loss:0.0417, loss-lb:0.0185, loss-ulb:0.0122, weight:1.90, lr:0.0007
[00:20:16.957] iteration:5533  t-loss:0.0441, loss-lb:0.0355, loss-ulb:0.0045, weight:1.90, lr:0.0007
[00:20:17.342] iteration:5534  t-loss:0.0760, loss-lb:0.0395, loss-ulb:0.0191, weight:1.90, lr:0.0007
[00:20:17.727] iteration:5535  t-loss:0.0763, loss-lb:0.0562, loss-ulb:0.0106, weight:1.90, lr:0.0007
[00:20:18.113] iteration:5536  t-loss:0.0653, loss-lb:0.0490, loss-ulb:0.0086, weight:1.90, lr:0.0007
[00:20:18.489] iteration:5537  t-loss:0.0571, loss-lb:0.0197, loss-ulb:0.0197, weight:1.90, lr:0.0007
[00:20:18.873] iteration:5538  t-loss:0.0798, loss-lb:0.0495, loss-ulb:0.0159, weight:1.90, lr:0.0007
[00:20:19.253] iteration:5539  t-loss:0.0792, loss-lb:0.0611, loss-ulb:0.0095, weight:1.90, lr:0.0007
[00:20:19.636] iteration:5540  t-loss:0.0422, loss-lb:0.0170, loss-ulb:0.0133, weight:1.90, lr:0.0007
[00:20:20.011] iteration:5541  t-loss:0.0530, loss-lb:0.0439, loss-ulb:0.0048, weight:1.90, lr:0.0007
[00:20:20.387] iteration:5542  t-loss:0.0504, loss-lb:0.0414, loss-ulb:0.0047, weight:1.90, lr:0.0007
[00:20:20.763] iteration:5543  t-loss:0.0894, loss-lb:0.0760, loss-ulb:0.0070, weight:1.90, lr:0.0007
[00:20:21.142] iteration:5544  t-loss:0.0746, loss-lb:0.0542, loss-ulb:0.0107, weight:1.90, lr:0.0007
[00:20:21.519] iteration:5545  t-loss:0.0254, loss-lb:0.0177, loss-ulb:0.0041, weight:1.90, lr:0.0007
[00:20:21.905] iteration:5546  t-loss:0.0770, loss-lb:0.0418, loss-ulb:0.0185, weight:1.90, lr:0.0007
[00:20:22.288] iteration:5547  t-loss:0.0654, loss-lb:0.0414, loss-ulb:0.0126, weight:1.90, lr:0.0007
[00:20:22.663] iteration:5548  t-loss:0.1104, loss-lb:0.0567, loss-ulb:0.0282, weight:1.90, lr:0.0007
[00:20:23.906] iteration:5549  t-loss:0.0900, loss-lb:0.0703, loss-ulb:0.0104, weight:1.90, lr:0.0007
[00:20:24.306] iteration:5550  t-loss:0.0677, loss-lb:0.0484, loss-ulb:0.0102, weight:1.90, lr:0.0007
[00:20:24.691] iteration:5551  t-loss:0.0263, loss-lb:0.0209, loss-ulb:0.0028, weight:1.94, lr:0.0007
[00:20:25.076] iteration:5552  t-loss:0.1176, loss-lb:0.0379, loss-ulb:0.0410, weight:1.94, lr:0.0007
[00:20:25.463] iteration:5553  t-loss:0.1394, loss-lb:0.0623, loss-ulb:0.0396, weight:1.94, lr:0.0007
[00:20:25.850] iteration:5554  t-loss:0.0556, loss-lb:0.0362, loss-ulb:0.0100, weight:1.94, lr:0.0007
[00:20:26.235] iteration:5555  t-loss:0.0918, loss-lb:0.0525, loss-ulb:0.0202, weight:1.94, lr:0.0007
[00:20:26.621] iteration:5556  t-loss:0.0917, loss-lb:0.0529, loss-ulb:0.0199, weight:1.94, lr:0.0007
[00:20:27.002] iteration:5557  t-loss:0.0370, loss-lb:0.0179, loss-ulb:0.0098, weight:1.94, lr:0.0007
[00:20:27.382] iteration:5558  t-loss:0.0550, loss-lb:0.0497, loss-ulb:0.0028, weight:1.94, lr:0.0007
[00:20:27.768] iteration:5559  t-loss:0.0396, loss-lb:0.0330, loss-ulb:0.0034, weight:1.94, lr:0.0007
[00:20:28.155] iteration:5560  t-loss:0.0493, loss-lb:0.0383, loss-ulb:0.0056, weight:1.94, lr:0.0007
[00:20:28.539] iteration:5561  t-loss:0.0632, loss-lb:0.0395, loss-ulb:0.0122, weight:1.94, lr:0.0007
[00:20:28.920] iteration:5562  t-loss:0.0383, loss-lb:0.0296, loss-ulb:0.0045, weight:1.94, lr:0.0007
[00:20:29.302] iteration:5563  t-loss:0.0636, loss-lb:0.0412, loss-ulb:0.0115, weight:1.94, lr:0.0007
[00:20:29.681] iteration:5564  t-loss:0.0571, loss-lb:0.0522, loss-ulb:0.0025, weight:1.94, lr:0.0007
[00:20:30.074] iteration:5565  t-loss:0.0683, loss-lb:0.0543, loss-ulb:0.0072, weight:1.94, lr:0.0007
[00:20:30.458] iteration:5566  t-loss:0.0565, loss-lb:0.0445, loss-ulb:0.0062, weight:1.94, lr:0.0007
[00:20:30.841] iteration:5567  t-loss:0.0513, loss-lb:0.0289, loss-ulb:0.0115, weight:1.94, lr:0.0007
[00:20:31.224] iteration:5568  t-loss:0.0346, loss-lb:0.0194, loss-ulb:0.0078, weight:1.94, lr:0.0007
[00:20:31.612] iteration:5569  t-loss:0.0289, loss-lb:0.0194, loss-ulb:0.0049, weight:1.94, lr:0.0007
[00:20:31.992] iteration:5570  t-loss:0.0495, loss-lb:0.0218, loss-ulb:0.0142, weight:1.94, lr:0.0007
[00:20:32.381] iteration:5571  t-loss:0.0395, loss-lb:0.0226, loss-ulb:0.0087, weight:1.94, lr:0.0007
[00:20:32.760] iteration:5572  t-loss:0.0654, loss-lb:0.0413, loss-ulb:0.0124, weight:1.94, lr:0.0007
[00:20:33.147] iteration:5573  t-loss:0.0675, loss-lb:0.0259, loss-ulb:0.0214, weight:1.94, lr:0.0007
[00:20:33.532] iteration:5574  t-loss:0.0692, loss-lb:0.0474, loss-ulb:0.0113, weight:1.94, lr:0.0007
[00:20:33.918] iteration:5575  t-loss:0.0840, loss-lb:0.0455, loss-ulb:0.0198, weight:1.94, lr:0.0007
[00:20:34.302] iteration:5576  t-loss:0.0524, loss-lb:0.0345, loss-ulb:0.0092, weight:1.94, lr:0.0007
[00:20:34.686] iteration:5577  t-loss:0.0891, loss-lb:0.0478, loss-ulb:0.0212, weight:1.94, lr:0.0007
[00:20:35.064] iteration:5578  t-loss:0.0284, loss-lb:0.0227, loss-ulb:0.0029, weight:1.94, lr:0.0007
[00:20:35.442] iteration:5579  t-loss:0.0303, loss-lb:0.0232, loss-ulb:0.0036, weight:1.94, lr:0.0007
[00:20:35.821] iteration:5580  t-loss:0.0354, loss-lb:0.0208, loss-ulb:0.0075, weight:1.94, lr:0.0007
[00:20:36.199] iteration:5581  t-loss:0.0726, loss-lb:0.0697, loss-ulb:0.0015, weight:1.94, lr:0.0007
[00:20:36.577] iteration:5582  t-loss:0.0540, loss-lb:0.0331, loss-ulb:0.0108, weight:1.94, lr:0.0007
[00:20:36.953] iteration:5583  t-loss:0.0287, loss-lb:0.0178, loss-ulb:0.0056, weight:1.94, lr:0.0007
[00:20:37.331] iteration:5584  t-loss:0.0447, loss-lb:0.0247, loss-ulb:0.0103, weight:1.94, lr:0.0007
[00:20:37.707] iteration:5585  t-loss:0.0303, loss-lb:0.0218, loss-ulb:0.0044, weight:1.94, lr:0.0007
[00:20:38.084] iteration:5586  t-loss:0.0572, loss-lb:0.0460, loss-ulb:0.0057, weight:1.94, lr:0.0007
[00:20:39.509] iteration:5587  t-loss:0.0524, loss-lb:0.0191, loss-ulb:0.0171, weight:1.94, lr:0.0007
[00:20:39.889] iteration:5588  t-loss:0.0187, loss-lb:0.0159, loss-ulb:0.0014, weight:1.94, lr:0.0007
[00:20:40.270] iteration:5589  t-loss:0.0314, loss-lb:0.0165, loss-ulb:0.0077, weight:1.94, lr:0.0007
[00:20:40.653] iteration:5590  t-loss:0.0585, loss-lb:0.0524, loss-ulb:0.0031, weight:1.94, lr:0.0007
[00:20:41.032] iteration:5591  t-loss:0.0299, loss-lb:0.0153, loss-ulb:0.0075, weight:1.94, lr:0.0007
[00:20:41.415] iteration:5592  t-loss:0.0425, loss-lb:0.0203, loss-ulb:0.0114, weight:1.94, lr:0.0007
[00:20:41.794] iteration:5593  t-loss:0.0612, loss-lb:0.0492, loss-ulb:0.0061, weight:1.94, lr:0.0007
[00:20:42.182] iteration:5594  t-loss:0.0758, loss-lb:0.0585, loss-ulb:0.0089, weight:1.94, lr:0.0007
[00:20:42.557] iteration:5595  t-loss:0.0245, loss-lb:0.0192, loss-ulb:0.0027, weight:1.94, lr:0.0007
[00:20:42.931] iteration:5596  t-loss:0.0373, loss-lb:0.0233, loss-ulb:0.0072, weight:1.94, lr:0.0007
[00:20:43.307] iteration:5597  t-loss:0.0233, loss-lb:0.0198, loss-ulb:0.0018, weight:1.94, lr:0.0007
[00:20:43.687] iteration:5598  t-loss:0.0568, loss-lb:0.0259, loss-ulb:0.0159, weight:1.94, lr:0.0007
[00:20:44.071] iteration:5599  t-loss:0.0700, loss-lb:0.0386, loss-ulb:0.0161, weight:1.94, lr:0.0007
[00:20:44.459] iteration:5600  t-loss:0.0807, loss-lb:0.0413, loss-ulb:0.0203, weight:1.94, lr:0.0007
[00:20:44.842] iteration:5601  t-loss:0.0721, loss-lb:0.0402, loss-ulb:0.0164, weight:1.94, lr:0.0007
[00:20:45.230] iteration:5602  t-loss:0.0478, loss-lb:0.0319, loss-ulb:0.0082, weight:1.94, lr:0.0007
[00:20:45.616] iteration:5603  t-loss:0.0735, loss-lb:0.0334, loss-ulb:0.0207, weight:1.94, lr:0.0007
[00:20:45.994] iteration:5604  t-loss:0.0305, loss-lb:0.0258, loss-ulb:0.0024, weight:1.94, lr:0.0007
[00:20:46.375] iteration:5605  t-loss:0.0586, loss-lb:0.0436, loss-ulb:0.0077, weight:1.94, lr:0.0007
[00:20:46.757] iteration:5606  t-loss:0.0496, loss-lb:0.0305, loss-ulb:0.0098, weight:1.94, lr:0.0007
[00:20:47.144] iteration:5607  t-loss:0.0285, loss-lb:0.0197, loss-ulb:0.0045, weight:1.94, lr:0.0007
[00:20:47.523] iteration:5608  t-loss:0.0322, loss-lb:0.0289, loss-ulb:0.0017, weight:1.94, lr:0.0007
[00:20:47.903] iteration:5609  t-loss:0.0507, loss-lb:0.0200, loss-ulb:0.0158, weight:1.94, lr:0.0007
[00:20:48.289] iteration:5610  t-loss:0.0450, loss-lb:0.0240, loss-ulb:0.0108, weight:1.94, lr:0.0007
[00:20:48.673] iteration:5611  t-loss:0.0408, loss-lb:0.0204, loss-ulb:0.0105, weight:1.94, lr:0.0007
[00:20:49.056] iteration:5612  t-loss:0.0727, loss-lb:0.0392, loss-ulb:0.0172, weight:1.94, lr:0.0007
[00:20:49.434] iteration:5613  t-loss:0.0575, loss-lb:0.0156, loss-ulb:0.0216, weight:1.94, lr:0.0007
[00:20:49.821] iteration:5614  t-loss:0.0483, loss-lb:0.0441, loss-ulb:0.0021, weight:1.94, lr:0.0007
[00:20:50.210] iteration:5615  t-loss:0.0569, loss-lb:0.0537, loss-ulb:0.0017, weight:1.94, lr:0.0007
[00:20:50.599] iteration:5616  t-loss:0.0293, loss-lb:0.0187, loss-ulb:0.0054, weight:1.94, lr:0.0007
[00:20:50.990] iteration:5617  t-loss:0.0304, loss-lb:0.0160, loss-ulb:0.0074, weight:1.94, lr:0.0007
[00:20:51.374] iteration:5618  t-loss:0.0500, loss-lb:0.0417, loss-ulb:0.0043, weight:1.94, lr:0.0007
[00:20:51.754] iteration:5619  t-loss:0.0507, loss-lb:0.0229, loss-ulb:0.0143, weight:1.94, lr:0.0007
[00:20:52.131] iteration:5620  t-loss:0.0288, loss-lb:0.0137, loss-ulb:0.0078, weight:1.94, lr:0.0007
[00:20:52.511] iteration:5621  t-loss:0.0659, loss-lb:0.0268, loss-ulb:0.0201, weight:1.94, lr:0.0007
[00:20:52.889] iteration:5622  t-loss:0.0543, loss-lb:0.0227, loss-ulb:0.0163, weight:1.94, lr:0.0007
[00:20:53.266] iteration:5623  t-loss:0.0339, loss-lb:0.0227, loss-ulb:0.0058, weight:1.94, lr:0.0007
[00:20:53.640] iteration:5624  t-loss:0.0305, loss-lb:0.0226, loss-ulb:0.0040, weight:1.94, lr:0.0007
[00:20:54.820] iteration:5625  t-loss:0.0277, loss-lb:0.0228, loss-ulb:0.0025, weight:1.94, lr:0.0007
[00:20:55.213] iteration:5626  t-loss:0.0215, loss-lb:0.0183, loss-ulb:0.0017, weight:1.94, lr:0.0007
[00:20:55.597] iteration:5627  t-loss:0.0573, loss-lb:0.0230, loss-ulb:0.0177, weight:1.94, lr:0.0007
[00:20:55.987] iteration:5628  t-loss:0.0444, loss-lb:0.0215, loss-ulb:0.0118, weight:1.94, lr:0.0007
[00:20:56.375] iteration:5629  t-loss:0.0461, loss-lb:0.0333, loss-ulb:0.0065, weight:1.94, lr:0.0007
[00:20:56.756] iteration:5630  t-loss:0.0506, loss-lb:0.0392, loss-ulb:0.0059, weight:1.94, lr:0.0007
[00:20:57.135] iteration:5631  t-loss:0.0311, loss-lb:0.0237, loss-ulb:0.0038, weight:1.94, lr:0.0007
[00:20:57.515] iteration:5632  t-loss:0.0497, loss-lb:0.0315, loss-ulb:0.0093, weight:1.94, lr:0.0007
[00:20:57.897] iteration:5633  t-loss:0.0314, loss-lb:0.0257, loss-ulb:0.0029, weight:1.94, lr:0.0007
[00:20:58.258] iteration:5634  t-loss:0.0237, loss-lb:0.0212, loss-ulb:0.0013, weight:1.94, lr:0.0007
[00:20:58.643] iteration:5635  t-loss:0.0640, loss-lb:0.0453, loss-ulb:0.0096, weight:1.94, lr:0.0007
[00:20:59.026] iteration:5636  t-loss:0.0768, loss-lb:0.0548, loss-ulb:0.0113, weight:1.94, lr:0.0007
[00:20:59.409] iteration:5637  t-loss:0.0846, loss-lb:0.0749, loss-ulb:0.0050, weight:1.94, lr:0.0007
[00:20:59.789] iteration:5638  t-loss:0.0734, loss-lb:0.0176, loss-ulb:0.0287, weight:1.94, lr:0.0007
[00:21:00.173] iteration:5639  t-loss:0.0449, loss-lb:0.0302, loss-ulb:0.0076, weight:1.94, lr:0.0007
[00:21:00.557] iteration:5640  t-loss:0.0703, loss-lb:0.0432, loss-ulb:0.0140, weight:1.94, lr:0.0007
[00:21:00.942] iteration:5641  t-loss:0.1498, loss-lb:0.1121, loss-ulb:0.0194, weight:1.94, lr:0.0007
[00:21:01.328] iteration:5642  t-loss:0.0397, loss-lb:0.0190, loss-ulb:0.0106, weight:1.94, lr:0.0007
[00:21:01.713] iteration:5643  t-loss:0.0669, loss-lb:0.0287, loss-ulb:0.0197, weight:1.94, lr:0.0007
[00:21:02.103] iteration:5644  t-loss:0.0611, loss-lb:0.0550, loss-ulb:0.0031, weight:1.94, lr:0.0007
[00:21:02.483] iteration:5645  t-loss:0.0339, loss-lb:0.0290, loss-ulb:0.0026, weight:1.94, lr:0.0007
[00:21:02.860] iteration:5646  t-loss:0.0331, loss-lb:0.0170, loss-ulb:0.0083, weight:1.94, lr:0.0007
[00:21:03.239] iteration:5647  t-loss:0.0781, loss-lb:0.0424, loss-ulb:0.0184, weight:1.94, lr:0.0007
[00:21:03.624] iteration:5648  t-loss:0.1068, loss-lb:0.0314, loss-ulb:0.0388, weight:1.94, lr:0.0007
[00:21:04.003] iteration:5649  t-loss:0.0315, loss-lb:0.0182, loss-ulb:0.0068, weight:1.94, lr:0.0007
[00:21:04.379] iteration:5650  t-loss:0.0618, loss-lb:0.0595, loss-ulb:0.0011, weight:1.94, lr:0.0007
[00:21:04.756] iteration:5651  t-loss:0.0410, loss-lb:0.0389, loss-ulb:0.0011, weight:1.94, lr:0.0007
[00:21:05.138] iteration:5652  t-loss:0.0448, loss-lb:0.0334, loss-ulb:0.0058, weight:1.94, lr:0.0007
[00:21:05.521] iteration:5653  t-loss:0.0631, loss-lb:0.0230, loss-ulb:0.0206, weight:1.94, lr:0.0007
[00:21:05.915] iteration:5654  t-loss:0.0870, loss-lb:0.0363, loss-ulb:0.0261, weight:1.94, lr:0.0007
[00:21:06.322] iteration:5655  t-loss:0.0482, loss-lb:0.0419, loss-ulb:0.0032, weight:1.94, lr:0.0007
[00:21:06.715] iteration:5656  t-loss:0.0384, loss-lb:0.0365, loss-ulb:0.0010, weight:1.94, lr:0.0007
[00:21:07.108] iteration:5657  t-loss:0.0680, loss-lb:0.0370, loss-ulb:0.0159, weight:1.94, lr:0.0007
[00:21:07.486] iteration:5658  t-loss:0.0265, loss-lb:0.0221, loss-ulb:0.0023, weight:1.94, lr:0.0007
[00:21:07.868] iteration:5659  t-loss:0.0672, loss-lb:0.0479, loss-ulb:0.0099, weight:1.94, lr:0.0007
[00:21:08.246] iteration:5660  t-loss:0.0285, loss-lb:0.0209, loss-ulb:0.0039, weight:1.94, lr:0.0007
[00:21:08.623] iteration:5661  t-loss:0.0570, loss-lb:0.0543, loss-ulb:0.0014, weight:1.94, lr:0.0007
[00:21:09.002] iteration:5662  t-loss:0.1170, loss-lb:0.0190, loss-ulb:0.0504, weight:1.94, lr:0.0007
[00:22:11.797] iteration 5662 : dice_score: 0.860813 best_dice: 0.875400
[00:22:11.797]  <<Test>> - Ep:148  - Dice-S/T:84.70/86.08, Best-S:88.23, Best-T:87.54
[00:22:11.797]           - AvgLoss(lb/ulb/all):0.04/0.01/0.06
[00:22:12.955] iteration:5663  t-loss:0.0448, loss-lb:0.0259, loss-ulb:0.0097, weight:1.94, lr:0.0007
[00:22:13.330] iteration:5664  t-loss:0.0394, loss-lb:0.0201, loss-ulb:0.0099, weight:1.94, lr:0.0007
[00:22:13.715] iteration:5665  t-loss:0.0436, loss-lb:0.0329, loss-ulb:0.0055, weight:1.94, lr:0.0007
[00:22:14.098] iteration:5666  t-loss:0.0276, loss-lb:0.0214, loss-ulb:0.0032, weight:1.94, lr:0.0007
[00:22:14.481] iteration:5667  t-loss:0.0355, loss-lb:0.0192, loss-ulb:0.0084, weight:1.94, lr:0.0007
[00:22:14.855] iteration:5668  t-loss:0.0274, loss-lb:0.0159, loss-ulb:0.0059, weight:1.94, lr:0.0007
[00:22:15.230] iteration:5669  t-loss:0.0919, loss-lb:0.0171, loss-ulb:0.0385, weight:1.94, lr:0.0007
[00:22:15.611] iteration:5670  t-loss:0.0708, loss-lb:0.0220, loss-ulb:0.0251, weight:1.94, lr:0.0007
[00:22:15.988] iteration:5671  t-loss:0.0199, loss-lb:0.0158, loss-ulb:0.0021, weight:1.94, lr:0.0007
[00:22:16.379] iteration:5672  t-loss:0.1084, loss-lb:0.0556, loss-ulb:0.0272, weight:1.94, lr:0.0007
[00:22:16.757] iteration:5673  t-loss:0.0307, loss-lb:0.0248, loss-ulb:0.0030, weight:1.94, lr:0.0007
[00:22:17.145] iteration:5674  t-loss:0.0477, loss-lb:0.0296, loss-ulb:0.0093, weight:1.94, lr:0.0007
[00:22:17.523] iteration:5675  t-loss:0.0234, loss-lb:0.0179, loss-ulb:0.0028, weight:1.94, lr:0.0007
[00:22:17.905] iteration:5676  t-loss:0.0484, loss-lb:0.0252, loss-ulb:0.0119, weight:1.94, lr:0.0007
[00:22:18.285] iteration:5677  t-loss:0.0588, loss-lb:0.0361, loss-ulb:0.0116, weight:1.94, lr:0.0007
[00:22:18.669] iteration:5678  t-loss:0.0296, loss-lb:0.0174, loss-ulb:0.0063, weight:1.94, lr:0.0007
[00:22:19.056] iteration:5679  t-loss:0.0857, loss-lb:0.0671, loss-ulb:0.0096, weight:1.94, lr:0.0007
[00:22:19.436] iteration:5680  t-loss:0.0208, loss-lb:0.0153, loss-ulb:0.0028, weight:1.94, lr:0.0007
[00:22:19.813] iteration:5681  t-loss:0.0683, loss-lb:0.0371, loss-ulb:0.0160, weight:1.94, lr:0.0007
[00:22:20.204] iteration:5682  t-loss:0.0795, loss-lb:0.0567, loss-ulb:0.0117, weight:1.94, lr:0.0007
[00:22:20.582] iteration:5683  t-loss:0.0848, loss-lb:0.0670, loss-ulb:0.0091, weight:1.94, lr:0.0007
[00:22:20.961] iteration:5684  t-loss:0.0598, loss-lb:0.0558, loss-ulb:0.0021, weight:1.94, lr:0.0007
[00:22:21.346] iteration:5685  t-loss:0.0670, loss-lb:0.0487, loss-ulb:0.0094, weight:1.94, lr:0.0007
[00:22:21.728] iteration:5686  t-loss:0.0274, loss-lb:0.0230, loss-ulb:0.0023, weight:1.94, lr:0.0007
[00:22:22.112] iteration:5687  t-loss:0.0881, loss-lb:0.0450, loss-ulb:0.0222, weight:1.94, lr:0.0007
[00:22:22.491] iteration:5688  t-loss:0.0319, loss-lb:0.0256, loss-ulb:0.0033, weight:1.94, lr:0.0007
[00:22:22.868] iteration:5689  t-loss:0.0416, loss-lb:0.0245, loss-ulb:0.0088, weight:1.94, lr:0.0007
[00:22:23.256] iteration:5690  t-loss:0.0815, loss-lb:0.0209, loss-ulb:0.0312, weight:1.94, lr:0.0007
[00:22:23.641] iteration:5691  t-loss:0.0260, loss-lb:0.0209, loss-ulb:0.0027, weight:1.94, lr:0.0007
[00:22:24.029] iteration:5692  t-loss:0.0607, loss-lb:0.0467, loss-ulb:0.0072, weight:1.94, lr:0.0007
[00:22:24.409] iteration:5693  t-loss:0.0337, loss-lb:0.0246, loss-ulb:0.0047, weight:1.94, lr:0.0007
[00:22:24.787] iteration:5694  t-loss:0.0372, loss-lb:0.0350, loss-ulb:0.0011, weight:1.94, lr:0.0007
[00:22:25.164] iteration:5695  t-loss:0.0488, loss-lb:0.0434, loss-ulb:0.0028, weight:1.94, lr:0.0007
[00:22:25.545] iteration:5696  t-loss:0.0738, loss-lb:0.0541, loss-ulb:0.0102, weight:1.94, lr:0.0007
[00:22:25.920] iteration:5697  t-loss:0.0300, loss-lb:0.0230, loss-ulb:0.0036, weight:1.94, lr:0.0007
[00:22:26.296] iteration:5698  t-loss:0.0562, loss-lb:0.0231, loss-ulb:0.0170, weight:1.94, lr:0.0007
[00:22:26.671] iteration:5699  t-loss:0.0387, loss-lb:0.0180, loss-ulb:0.0106, weight:1.94, lr:0.0007
[00:22:27.051] iteration:5700  t-loss:0.0298, loss-lb:0.0215, loss-ulb:0.0043, weight:1.94, lr:0.0007
[00:22:28.341] iteration:5701  t-loss:0.0440, loss-lb:0.0419, loss-ulb:0.0010, weight:1.98, lr:0.0007
[00:22:28.726] iteration:5702  t-loss:0.0565, loss-lb:0.0518, loss-ulb:0.0024, weight:1.98, lr:0.0007
[00:22:29.106] iteration:5703  t-loss:0.0333, loss-lb:0.0197, loss-ulb:0.0069, weight:1.98, lr:0.0007
[00:22:29.492] iteration:5704  t-loss:0.0589, loss-lb:0.0288, loss-ulb:0.0152, weight:1.98, lr:0.0007
[00:22:29.877] iteration:5705  t-loss:0.0421, loss-lb:0.0377, loss-ulb:0.0022, weight:1.98, lr:0.0007
[00:22:30.261] iteration:5706  t-loss:0.0682, loss-lb:0.0203, loss-ulb:0.0243, weight:1.98, lr:0.0007
[00:22:30.649] iteration:5707  t-loss:0.0791, loss-lb:0.0484, loss-ulb:0.0155, weight:1.98, lr:0.0006
[00:22:31.032] iteration:5708  t-loss:0.0330, loss-lb:0.0192, loss-ulb:0.0070, weight:1.98, lr:0.0006
[00:22:31.415] iteration:5709  t-loss:0.0293, loss-lb:0.0223, loss-ulb:0.0036, weight:1.98, lr:0.0006
[00:22:31.799] iteration:5710  t-loss:0.0691, loss-lb:0.0320, loss-ulb:0.0188, weight:1.98, lr:0.0006
[00:22:32.189] iteration:5711  t-loss:0.0610, loss-lb:0.0420, loss-ulb:0.0096, weight:1.98, lr:0.0006
[00:22:32.577] iteration:5712  t-loss:0.0880, loss-lb:0.0467, loss-ulb:0.0209, weight:1.98, lr:0.0006
[00:22:32.965] iteration:5713  t-loss:0.0453, loss-lb:0.0277, loss-ulb:0.0089, weight:1.98, lr:0.0006
[00:22:33.351] iteration:5714  t-loss:0.0287, loss-lb:0.0193, loss-ulb:0.0048, weight:1.98, lr:0.0006
[00:22:33.741] iteration:5715  t-loss:0.0926, loss-lb:0.0453, loss-ulb:0.0240, weight:1.98, lr:0.0006
[00:22:34.118] iteration:5716  t-loss:0.0525, loss-lb:0.0486, loss-ulb:0.0019, weight:1.98, lr:0.0006
[00:22:34.508] iteration:5717  t-loss:0.0480, loss-lb:0.0191, loss-ulb:0.0146, weight:1.98, lr:0.0006
[00:22:34.891] iteration:5718  t-loss:0.0485, loss-lb:0.0225, loss-ulb:0.0131, weight:1.98, lr:0.0006
[00:22:35.273] iteration:5719  t-loss:0.0753, loss-lb:0.0520, loss-ulb:0.0118, weight:1.98, lr:0.0006
[00:22:35.658] iteration:5720  t-loss:0.0570, loss-lb:0.0334, loss-ulb:0.0120, weight:1.98, lr:0.0006
[00:22:36.037] iteration:5721  t-loss:0.0268, loss-lb:0.0222, loss-ulb:0.0023, weight:1.98, lr:0.0006
[00:22:36.421] iteration:5722  t-loss:0.0386, loss-lb:0.0355, loss-ulb:0.0016, weight:1.98, lr:0.0006
[00:22:36.804] iteration:5723  t-loss:0.0434, loss-lb:0.0274, loss-ulb:0.0081, weight:1.98, lr:0.0006
[00:22:37.187] iteration:5724  t-loss:0.0763, loss-lb:0.0453, loss-ulb:0.0157, weight:1.98, lr:0.0006
[00:22:37.574] iteration:5725  t-loss:0.0273, loss-lb:0.0188, loss-ulb:0.0043, weight:1.98, lr:0.0006
[00:22:37.957] iteration:5726  t-loss:0.0538, loss-lb:0.0203, loss-ulb:0.0169, weight:1.98, lr:0.0006
[00:22:38.337] iteration:5727  t-loss:0.0475, loss-lb:0.0244, loss-ulb:0.0117, weight:1.98, lr:0.0006
[00:22:38.719] iteration:5728  t-loss:0.0627, loss-lb:0.0443, loss-ulb:0.0093, weight:1.98, lr:0.0006
[00:22:39.103] iteration:5729  t-loss:0.0232, loss-lb:0.0168, loss-ulb:0.0032, weight:1.98, lr:0.0006
[00:22:39.484] iteration:5730  t-loss:0.0512, loss-lb:0.0478, loss-ulb:0.0017, weight:1.98, lr:0.0006
[00:22:39.862] iteration:5731  t-loss:0.0389, loss-lb:0.0363, loss-ulb:0.0013, weight:1.98, lr:0.0006
[00:22:40.241] iteration:5732  t-loss:0.0291, loss-lb:0.0257, loss-ulb:0.0017, weight:1.98, lr:0.0006
[00:22:40.616] iteration:5733  t-loss:0.0288, loss-lb:0.0217, loss-ulb:0.0036, weight:1.98, lr:0.0006
[00:22:40.997] iteration:5734  t-loss:0.0404, loss-lb:0.0198, loss-ulb:0.0104, weight:1.98, lr:0.0006
[00:22:41.374] iteration:5735  t-loss:0.0556, loss-lb:0.0377, loss-ulb:0.0091, weight:1.98, lr:0.0006
[00:22:41.751] iteration:5736  t-loss:0.0326, loss-lb:0.0168, loss-ulb:0.0080, weight:1.98, lr:0.0006
[00:22:42.129] iteration:5737  t-loss:0.0301, loss-lb:0.0241, loss-ulb:0.0031, weight:1.98, lr:0.0006
[00:22:42.505] iteration:5738  t-loss:0.0232, loss-lb:0.0182, loss-ulb:0.0025, weight:1.98, lr:0.0006
[00:22:43.732] iteration:5739  t-loss:0.0492, loss-lb:0.0244, loss-ulb:0.0126, weight:1.98, lr:0.0006
[00:22:44.123] iteration:5740  t-loss:0.1333, loss-lb:0.0460, loss-ulb:0.0442, weight:1.98, lr:0.0006
[00:22:44.507] iteration:5741  t-loss:0.0581, loss-lb:0.0509, loss-ulb:0.0036, weight:1.98, lr:0.0006
[00:22:44.890] iteration:5742  t-loss:0.0268, loss-lb:0.0237, loss-ulb:0.0016, weight:1.98, lr:0.0006
[00:22:45.280] iteration:5743  t-loss:0.0608, loss-lb:0.0519, loss-ulb:0.0045, weight:1.98, lr:0.0006
[00:22:45.666] iteration:5744  t-loss:0.0517, loss-lb:0.0291, loss-ulb:0.0115, weight:1.98, lr:0.0006
[00:22:46.047] iteration:5745  t-loss:0.0595, loss-lb:0.0223, loss-ulb:0.0188, weight:1.98, lr:0.0006
[00:22:46.430] iteration:5746  t-loss:0.0322, loss-lb:0.0172, loss-ulb:0.0076, weight:1.98, lr:0.0006
[00:22:46.811] iteration:5747  t-loss:0.0283, loss-lb:0.0175, loss-ulb:0.0055, weight:1.98, lr:0.0006
[00:22:47.193] iteration:5748  t-loss:0.0492, loss-lb:0.0264, loss-ulb:0.0116, weight:1.98, lr:0.0006
[00:22:47.574] iteration:5749  t-loss:0.0447, loss-lb:0.0170, loss-ulb:0.0140, weight:1.98, lr:0.0006
[00:22:47.953] iteration:5750  t-loss:0.0352, loss-lb:0.0233, loss-ulb:0.0061, weight:1.98, lr:0.0006
[00:22:48.335] iteration:5751  t-loss:0.0297, loss-lb:0.0175, loss-ulb:0.0062, weight:1.98, lr:0.0006
[00:22:48.720] iteration:5752  t-loss:0.0525, loss-lb:0.0340, loss-ulb:0.0094, weight:1.98, lr:0.0006
[00:22:49.098] iteration:5753  t-loss:0.0404, loss-lb:0.0356, loss-ulb:0.0024, weight:1.98, lr:0.0006
[00:22:49.474] iteration:5754  t-loss:0.0259, loss-lb:0.0195, loss-ulb:0.0033, weight:1.98, lr:0.0006
[00:22:49.866] iteration:5755  t-loss:0.0718, loss-lb:0.0471, loss-ulb:0.0125, weight:1.98, lr:0.0006
[00:22:50.251] iteration:5756  t-loss:0.0623, loss-lb:0.0446, loss-ulb:0.0090, weight:1.98, lr:0.0006
[00:22:50.634] iteration:5757  t-loss:0.0262, loss-lb:0.0186, loss-ulb:0.0038, weight:1.98, lr:0.0006
[00:22:51.024] iteration:5758  t-loss:0.0459, loss-lb:0.0435, loss-ulb:0.0013, weight:1.98, lr:0.0006
[00:22:51.414] iteration:5759  t-loss:0.0658, loss-lb:0.0401, loss-ulb:0.0130, weight:1.98, lr:0.0006
[00:22:51.801] iteration:5760  t-loss:0.0671, loss-lb:0.0430, loss-ulb:0.0122, weight:1.98, lr:0.0006
[00:22:52.186] iteration:5761  t-loss:0.0602, loss-lb:0.0412, loss-ulb:0.0096, weight:1.98, lr:0.0006
[00:22:52.566] iteration:5762  t-loss:0.0442, loss-lb:0.0328, loss-ulb:0.0058, weight:1.98, lr:0.0006
[00:22:52.945] iteration:5763  t-loss:0.0317, loss-lb:0.0205, loss-ulb:0.0056, weight:1.98, lr:0.0006
[00:22:53.329] iteration:5764  t-loss:0.0459, loss-lb:0.0333, loss-ulb:0.0064, weight:1.98, lr:0.0006
[00:22:53.710] iteration:5765  t-loss:0.0520, loss-lb:0.0401, loss-ulb:0.0060, weight:1.98, lr:0.0006
[00:22:54.095] iteration:5766  t-loss:0.0590, loss-lb:0.0317, loss-ulb:0.0138, weight:1.98, lr:0.0006
[00:22:54.474] iteration:5767  t-loss:0.0241, loss-lb:0.0197, loss-ulb:0.0022, weight:1.98, lr:0.0006
[00:22:54.854] iteration:5768  t-loss:0.0471, loss-lb:0.0359, loss-ulb:0.0057, weight:1.98, lr:0.0006
[00:22:55.232] iteration:5769  t-loss:0.0738, loss-lb:0.0354, loss-ulb:0.0195, weight:1.98, lr:0.0006
[00:22:55.613] iteration:5770  t-loss:0.0286, loss-lb:0.0212, loss-ulb:0.0037, weight:1.98, lr:0.0006
[00:22:56.011] iteration:5771  t-loss:0.0462, loss-lb:0.0155, loss-ulb:0.0155, weight:1.98, lr:0.0006
[00:22:56.397] iteration:5772  t-loss:0.0594, loss-lb:0.0349, loss-ulb:0.0124, weight:1.98, lr:0.0006
[00:22:56.776] iteration:5773  t-loss:0.0643, loss-lb:0.0568, loss-ulb:0.0038, weight:1.98, lr:0.0006
[00:22:57.149] iteration:5774  t-loss:0.0262, loss-lb:0.0146, loss-ulb:0.0059, weight:1.98, lr:0.0006
[00:22:57.523] iteration:5775  t-loss:0.0273, loss-lb:0.0195, loss-ulb:0.0039, weight:1.98, lr:0.0006
[00:22:57.898] iteration:5776  t-loss:0.0530, loss-lb:0.0459, loss-ulb:0.0036, weight:1.98, lr:0.0006
[00:22:59.142] iteration:5777  t-loss:0.0236, loss-lb:0.0204, loss-ulb:0.0016, weight:1.98, lr:0.0006
[00:22:59.532] iteration:5778  t-loss:0.0423, loss-lb:0.0345, loss-ulb:0.0040, weight:1.98, lr:0.0006
[00:22:59.915] iteration:5779  t-loss:0.0318, loss-lb:0.0295, loss-ulb:0.0011, weight:1.98, lr:0.0006
[00:23:00.300] iteration:5780  t-loss:0.0313, loss-lb:0.0172, loss-ulb:0.0072, weight:1.98, lr:0.0006
[00:23:00.677] iteration:5781  t-loss:0.0466, loss-lb:0.0442, loss-ulb:0.0012, weight:1.98, lr:0.0006
[00:23:01.054] iteration:5782  t-loss:0.0237, loss-lb:0.0199, loss-ulb:0.0019, weight:1.98, lr:0.0006
[00:23:01.437] iteration:5783  t-loss:0.0545, loss-lb:0.0344, loss-ulb:0.0102, weight:1.98, lr:0.0006
[00:23:01.818] iteration:5784  t-loss:0.0550, loss-lb:0.0282, loss-ulb:0.0136, weight:1.98, lr:0.0006
[00:23:02.200] iteration:5785  t-loss:0.0390, loss-lb:0.0296, loss-ulb:0.0048, weight:1.98, lr:0.0006
[00:23:02.585] iteration:5786  t-loss:0.0420, loss-lb:0.0309, loss-ulb:0.0057, weight:1.98, lr:0.0006
[00:23:02.969] iteration:5787  t-loss:0.0522, loss-lb:0.0232, loss-ulb:0.0147, weight:1.98, lr:0.0006
[00:23:03.350] iteration:5788  t-loss:0.0543, loss-lb:0.0377, loss-ulb:0.0084, weight:1.98, lr:0.0006
[00:23:03.729] iteration:5789  t-loss:0.0515, loss-lb:0.0200, loss-ulb:0.0159, weight:1.98, lr:0.0006
[00:23:04.106] iteration:5790  t-loss:0.0289, loss-lb:0.0251, loss-ulb:0.0020, weight:1.98, lr:0.0006
[00:23:04.488] iteration:5791  t-loss:0.0441, loss-lb:0.0323, loss-ulb:0.0060, weight:1.98, lr:0.0006
[00:23:04.867] iteration:5792  t-loss:0.0303, loss-lb:0.0274, loss-ulb:0.0015, weight:1.98, lr:0.0006
[00:23:05.255] iteration:5793  t-loss:0.0394, loss-lb:0.0357, loss-ulb:0.0019, weight:1.98, lr:0.0006
[00:23:05.639] iteration:5794  t-loss:0.0665, loss-lb:0.0284, loss-ulb:0.0193, weight:1.98, lr:0.0006
[00:23:06.019] iteration:5795  t-loss:0.0201, loss-lb:0.0178, loss-ulb:0.0012, weight:1.98, lr:0.0006
[00:23:06.397] iteration:5796  t-loss:0.0526, loss-lb:0.0334, loss-ulb:0.0097, weight:1.98, lr:0.0006
[00:23:06.777] iteration:5797  t-loss:0.0557, loss-lb:0.0268, loss-ulb:0.0146, weight:1.98, lr:0.0006
[00:23:07.161] iteration:5798  t-loss:0.0564, loss-lb:0.0349, loss-ulb:0.0109, weight:1.98, lr:0.0006
[00:23:07.545] iteration:5799  t-loss:0.0620, loss-lb:0.0350, loss-ulb:0.0136, weight:1.98, lr:0.0006
[00:23:07.922] iteration:5800  t-loss:0.0528, loss-lb:0.0415, loss-ulb:0.0057, weight:1.98, lr:0.0006
[00:23:08.301] iteration:5801  t-loss:0.0535, loss-lb:0.0291, loss-ulb:0.0124, weight:1.98, lr:0.0006
[00:23:08.681] iteration:5802  t-loss:0.0384, loss-lb:0.0181, loss-ulb:0.0103, weight:1.98, lr:0.0006
[00:23:09.062] iteration:5803  t-loss:0.0401, loss-lb:0.0173, loss-ulb:0.0115, weight:1.98, lr:0.0006
[00:23:09.438] iteration:5804  t-loss:0.0281, loss-lb:0.0198, loss-ulb:0.0042, weight:1.98, lr:0.0006
[00:23:09.816] iteration:5805  t-loss:0.0284, loss-lb:0.0259, loss-ulb:0.0013, weight:1.98, lr:0.0006
[00:23:10.199] iteration:5806  t-loss:0.0469, loss-lb:0.0313, loss-ulb:0.0079, weight:1.98, lr:0.0006
[00:23:10.576] iteration:5807  t-loss:0.0215, loss-lb:0.0154, loss-ulb:0.0031, weight:1.98, lr:0.0006
[00:23:10.972] iteration:5808  t-loss:0.1203, loss-lb:0.0610, loss-ulb:0.0300, weight:1.98, lr:0.0006
[00:23:11.366] iteration:5809  t-loss:0.0331, loss-lb:0.0165, loss-ulb:0.0084, weight:1.98, lr:0.0006
[00:23:11.747] iteration:5810  t-loss:0.0659, loss-lb:0.0310, loss-ulb:0.0177, weight:1.98, lr:0.0006
[00:23:12.126] iteration:5811  t-loss:0.0463, loss-lb:0.0420, loss-ulb:0.0022, weight:1.98, lr:0.0006
[00:23:12.501] iteration:5812  t-loss:0.0236, loss-lb:0.0174, loss-ulb:0.0031, weight:1.98, lr:0.0006
[00:23:12.881] iteration:5813  t-loss:0.0533, loss-lb:0.0398, loss-ulb:0.0068, weight:1.98, lr:0.0006
[00:23:13.255] iteration:5814  t-loss:0.0248, loss-lb:0.0210, loss-ulb:0.0019, weight:1.98, lr:0.0006
[00:24:15.698] iteration 5814 : dice_score: 0.885017 best_dice: 0.885000
[00:24:15.698]  <<Test>> - Ep:152  - Dice-S/T:87.55/88.50, Best-S:88.23, Best-T:88.50
[00:24:15.698]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:24:16.767] iteration:5815  t-loss:0.0742, loss-lb:0.0411, loss-ulb:0.0168, weight:1.98, lr:0.0006
[00:24:17.168] iteration:5816  t-loss:0.0535, loss-lb:0.0459, loss-ulb:0.0038, weight:1.98, lr:0.0006
[00:24:17.549] iteration:5817  t-loss:0.0556, loss-lb:0.0332, loss-ulb:0.0114, weight:1.98, lr:0.0006
[00:24:17.926] iteration:5818  t-loss:0.0427, loss-lb:0.0223, loss-ulb:0.0103, weight:1.98, lr:0.0006
[00:24:18.309] iteration:5819  t-loss:0.1016, loss-lb:0.0190, loss-ulb:0.0418, weight:1.98, lr:0.0006
[00:24:18.685] iteration:5820  t-loss:0.0502, loss-lb:0.0243, loss-ulb:0.0131, weight:1.98, lr:0.0006
[00:24:19.061] iteration:5821  t-loss:0.0494, loss-lb:0.0244, loss-ulb:0.0127, weight:1.98, lr:0.0006
[00:24:19.433] iteration:5822  t-loss:0.0434, loss-lb:0.0199, loss-ulb:0.0119, weight:1.98, lr:0.0006
[00:24:19.814] iteration:5823  t-loss:0.0263, loss-lb:0.0176, loss-ulb:0.0044, weight:1.98, lr:0.0006
[00:24:20.196] iteration:5824  t-loss:0.0563, loss-lb:0.0329, loss-ulb:0.0118, weight:1.98, lr:0.0006
[00:24:20.576] iteration:5825  t-loss:0.0251, loss-lb:0.0220, loss-ulb:0.0016, weight:1.98, lr:0.0006
[00:24:20.966] iteration:5826  t-loss:0.0773, loss-lb:0.0378, loss-ulb:0.0200, weight:1.98, lr:0.0006
[00:24:21.349] iteration:5827  t-loss:0.0675, loss-lb:0.0387, loss-ulb:0.0146, weight:1.98, lr:0.0006
[00:24:21.735] iteration:5828  t-loss:0.0869, loss-lb:0.0423, loss-ulb:0.0226, weight:1.98, lr:0.0006
[00:24:22.121] iteration:5829  t-loss:0.0278, loss-lb:0.0249, loss-ulb:0.0015, weight:1.98, lr:0.0006
[00:24:22.495] iteration:5830  t-loss:0.0250, loss-lb:0.0193, loss-ulb:0.0029, weight:1.98, lr:0.0006
[00:24:22.871] iteration:5831  t-loss:0.0199, loss-lb:0.0160, loss-ulb:0.0020, weight:1.98, lr:0.0006
[00:24:23.254] iteration:5832  t-loss:0.0616, loss-lb:0.0482, loss-ulb:0.0068, weight:1.98, lr:0.0006
[00:24:23.634] iteration:5833  t-loss:0.0519, loss-lb:0.0241, loss-ulb:0.0141, weight:1.98, lr:0.0006
[00:24:24.017] iteration:5834  t-loss:0.0801, loss-lb:0.0378, loss-ulb:0.0214, weight:1.98, lr:0.0006
[00:24:24.398] iteration:5835  t-loss:0.0521, loss-lb:0.0342, loss-ulb:0.0091, weight:1.98, lr:0.0006
[00:24:24.778] iteration:5836  t-loss:0.0407, loss-lb:0.0241, loss-ulb:0.0084, weight:1.98, lr:0.0006
[00:24:25.162] iteration:5837  t-loss:0.0409, loss-lb:0.0353, loss-ulb:0.0028, weight:1.98, lr:0.0006
[00:24:25.535] iteration:5838  t-loss:0.0257, loss-lb:0.0219, loss-ulb:0.0019, weight:1.98, lr:0.0006
[00:24:25.917] iteration:5839  t-loss:0.0536, loss-lb:0.0183, loss-ulb:0.0178, weight:1.98, lr:0.0006
[00:24:26.292] iteration:5840  t-loss:0.0246, loss-lb:0.0223, loss-ulb:0.0012, weight:1.98, lr:0.0006
[00:24:26.673] iteration:5841  t-loss:0.0352, loss-lb:0.0174, loss-ulb:0.0090, weight:1.98, lr:0.0006
[00:24:27.053] iteration:5842  t-loss:0.0235, loss-lb:0.0203, loss-ulb:0.0016, weight:1.98, lr:0.0006
[00:24:27.431] iteration:5843  t-loss:0.0236, loss-lb:0.0187, loss-ulb:0.0025, weight:1.98, lr:0.0006
[00:24:27.813] iteration:5844  t-loss:0.0540, loss-lb:0.0215, loss-ulb:0.0165, weight:1.98, lr:0.0006
[00:24:28.190] iteration:5845  t-loss:0.0636, loss-lb:0.0423, loss-ulb:0.0108, weight:1.98, lr:0.0006
[00:24:28.568] iteration:5846  t-loss:0.0560, loss-lb:0.0415, loss-ulb:0.0073, weight:1.98, lr:0.0006
[00:24:28.945] iteration:5847  t-loss:0.0296, loss-lb:0.0244, loss-ulb:0.0026, weight:1.98, lr:0.0006
[00:24:29.322] iteration:5848  t-loss:0.0374, loss-lb:0.0202, loss-ulb:0.0087, weight:1.98, lr:0.0006
[00:24:29.698] iteration:5849  t-loss:0.0554, loss-lb:0.0494, loss-ulb:0.0031, weight:1.98, lr:0.0006
[00:24:30.081] iteration:5850  t-loss:0.0811, loss-lb:0.0599, loss-ulb:0.0107, weight:1.98, lr:0.0006
[00:24:30.458] iteration:5851  t-loss:0.0290, loss-lb:0.0151, loss-ulb:0.0070, weight:1.99, lr:0.0006
[00:24:30.837] iteration:5852  t-loss:0.0406, loss-lb:0.0352, loss-ulb:0.0027, weight:1.99, lr:0.0006
[00:24:32.195] iteration:5853  t-loss:0.0282, loss-lb:0.0208, loss-ulb:0.0037, weight:1.99, lr:0.0006
[00:24:32.588] iteration:5854  t-loss:0.0501, loss-lb:0.0460, loss-ulb:0.0021, weight:1.99, lr:0.0006
[00:24:32.973] iteration:5855  t-loss:0.0515, loss-lb:0.0336, loss-ulb:0.0090, weight:1.99, lr:0.0006
[00:24:33.354] iteration:5856  t-loss:0.0329, loss-lb:0.0184, loss-ulb:0.0073, weight:1.99, lr:0.0006
[00:24:33.737] iteration:5857  t-loss:0.0422, loss-lb:0.0394, loss-ulb:0.0014, weight:1.99, lr:0.0006
[00:24:34.115] iteration:5858  t-loss:0.0416, loss-lb:0.0393, loss-ulb:0.0011, weight:1.99, lr:0.0006
[00:24:34.504] iteration:5859  t-loss:0.0464, loss-lb:0.0331, loss-ulb:0.0066, weight:1.99, lr:0.0006
[00:24:34.888] iteration:5860  t-loss:0.0504, loss-lb:0.0356, loss-ulb:0.0075, weight:1.99, lr:0.0006
[00:24:35.271] iteration:5861  t-loss:0.0319, loss-lb:0.0195, loss-ulb:0.0063, weight:1.99, lr:0.0006
[00:24:35.654] iteration:5862  t-loss:0.0464, loss-lb:0.0439, loss-ulb:0.0013, weight:1.99, lr:0.0006
[00:24:36.042] iteration:5863  t-loss:0.0502, loss-lb:0.0311, loss-ulb:0.0096, weight:1.99, lr:0.0006
[00:24:36.425] iteration:5864  t-loss:0.0624, loss-lb:0.0238, loss-ulb:0.0194, weight:1.99, lr:0.0006
[00:24:36.809] iteration:5865  t-loss:0.0632, loss-lb:0.0402, loss-ulb:0.0115, weight:1.99, lr:0.0006
[00:24:37.190] iteration:5866  t-loss:0.0366, loss-lb:0.0337, loss-ulb:0.0014, weight:1.99, lr:0.0006
[00:24:37.582] iteration:5867  t-loss:0.0347, loss-lb:0.0264, loss-ulb:0.0042, weight:1.99, lr:0.0006
[00:24:37.967] iteration:5868  t-loss:0.0726, loss-lb:0.0454, loss-ulb:0.0136, weight:1.99, lr:0.0006
[00:24:38.346] iteration:5869  t-loss:0.0537, loss-lb:0.0210, loss-ulb:0.0164, weight:1.99, lr:0.0006
[00:24:38.726] iteration:5870  t-loss:0.0591, loss-lb:0.0188, loss-ulb:0.0202, weight:1.99, lr:0.0006
[00:24:39.107] iteration:5871  t-loss:0.0655, loss-lb:0.0267, loss-ulb:0.0194, weight:1.99, lr:0.0006
[00:24:39.490] iteration:5872  t-loss:0.0330, loss-lb:0.0308, loss-ulb:0.0011, weight:1.99, lr:0.0006
[00:24:39.876] iteration:5873  t-loss:0.0316, loss-lb:0.0227, loss-ulb:0.0045, weight:1.99, lr:0.0006
[00:24:40.259] iteration:5874  t-loss:0.0736, loss-lb:0.0704, loss-ulb:0.0016, weight:1.99, lr:0.0006
[00:24:40.638] iteration:5875  t-loss:0.0339, loss-lb:0.0297, loss-ulb:0.0021, weight:1.99, lr:0.0006
[00:24:41.024] iteration:5876  t-loss:0.0330, loss-lb:0.0152, loss-ulb:0.0089, weight:1.99, lr:0.0006
[00:24:41.413] iteration:5877  t-loss:0.0641, loss-lb:0.0403, loss-ulb:0.0119, weight:1.99, lr:0.0006
[00:24:41.798] iteration:5878  t-loss:0.0713, loss-lb:0.0335, loss-ulb:0.0189, weight:1.99, lr:0.0006
[00:24:42.181] iteration:5879  t-loss:0.0378, loss-lb:0.0324, loss-ulb:0.0027, weight:1.99, lr:0.0006
[00:24:42.561] iteration:5880  t-loss:0.0705, loss-lb:0.0360, loss-ulb:0.0173, weight:1.99, lr:0.0006
[00:24:42.942] iteration:5881  t-loss:0.0221, loss-lb:0.0192, loss-ulb:0.0015, weight:1.99, lr:0.0006
[00:24:43.328] iteration:5882  t-loss:0.0397, loss-lb:0.0277, loss-ulb:0.0060, weight:1.99, lr:0.0006
[00:24:43.711] iteration:5883  t-loss:0.0792, loss-lb:0.0656, loss-ulb:0.0068, weight:1.99, lr:0.0006
[00:24:44.092] iteration:5884  t-loss:0.0794, loss-lb:0.0304, loss-ulb:0.0246, weight:1.99, lr:0.0006
[00:24:44.468] iteration:5885  t-loss:0.0388, loss-lb:0.0210, loss-ulb:0.0089, weight:1.99, lr:0.0006
[00:24:44.852] iteration:5886  t-loss:0.0611, loss-lb:0.0377, loss-ulb:0.0117, weight:1.99, lr:0.0006
[00:24:45.235] iteration:5887  t-loss:0.0709, loss-lb:0.0455, loss-ulb:0.0127, weight:1.99, lr:0.0006
[00:24:45.614] iteration:5888  t-loss:0.0404, loss-lb:0.0175, loss-ulb:0.0115, weight:1.99, lr:0.0006
[00:24:45.987] iteration:5889  t-loss:0.0218, loss-lb:0.0164, loss-ulb:0.0027, weight:1.99, lr:0.0006
[00:24:46.363] iteration:5890  t-loss:0.0619, loss-lb:0.0169, loss-ulb:0.0226, weight:1.99, lr:0.0006
[00:24:47.556] iteration:5891  t-loss:0.0361, loss-lb:0.0177, loss-ulb:0.0092, weight:1.99, lr:0.0006
[00:24:47.942] iteration:5892  t-loss:0.0528, loss-lb:0.0195, loss-ulb:0.0167, weight:1.99, lr:0.0006
[00:24:48.329] iteration:5893  t-loss:0.0513, loss-lb:0.0149, loss-ulb:0.0182, weight:1.99, lr:0.0006
[00:24:48.718] iteration:5894  t-loss:0.0727, loss-lb:0.0390, loss-ulb:0.0169, weight:1.99, lr:0.0006
[00:24:49.102] iteration:5895  t-loss:0.0549, loss-lb:0.0328, loss-ulb:0.0111, weight:1.99, lr:0.0006
[00:24:49.484] iteration:5896  t-loss:0.0411, loss-lb:0.0378, loss-ulb:0.0017, weight:1.99, lr:0.0006
[00:24:49.869] iteration:5897  t-loss:0.0938, loss-lb:0.0496, loss-ulb:0.0222, weight:1.99, lr:0.0006
[00:24:50.253] iteration:5898  t-loss:0.0458, loss-lb:0.0256, loss-ulb:0.0101, weight:1.99, lr:0.0006
[00:24:50.630] iteration:5899  t-loss:0.0432, loss-lb:0.0211, loss-ulb:0.0111, weight:1.99, lr:0.0006
[00:24:51.015] iteration:5900  t-loss:0.0300, loss-lb:0.0150, loss-ulb:0.0075, weight:1.99, lr:0.0006
[00:24:51.409] iteration:5901  t-loss:0.0387, loss-lb:0.0334, loss-ulb:0.0027, weight:1.99, lr:0.0006
[00:24:51.795] iteration:5902  t-loss:0.0701, loss-lb:0.0207, loss-ulb:0.0248, weight:1.99, lr:0.0006
[00:24:52.181] iteration:5903  t-loss:0.0220, loss-lb:0.0191, loss-ulb:0.0015, weight:1.99, lr:0.0006
[00:24:52.560] iteration:5904  t-loss:0.0415, loss-lb:0.0270, loss-ulb:0.0073, weight:1.99, lr:0.0006
[00:24:52.941] iteration:5905  t-loss:0.0260, loss-lb:0.0214, loss-ulb:0.0023, weight:1.99, lr:0.0006
[00:24:53.333] iteration:5906  t-loss:0.0708, loss-lb:0.0370, loss-ulb:0.0169, weight:1.99, lr:0.0006
[00:24:53.722] iteration:5907  t-loss:0.0191, loss-lb:0.0151, loss-ulb:0.0020, weight:1.99, lr:0.0006
[00:24:54.113] iteration:5908  t-loss:0.0923, loss-lb:0.0513, loss-ulb:0.0206, weight:1.99, lr:0.0006
[00:24:54.495] iteration:5909  t-loss:0.0391, loss-lb:0.0162, loss-ulb:0.0115, weight:1.99, lr:0.0006
[00:24:54.881] iteration:5910  t-loss:0.0341, loss-lb:0.0192, loss-ulb:0.0075, weight:1.99, lr:0.0006
[00:24:55.267] iteration:5911  t-loss:0.0544, loss-lb:0.0156, loss-ulb:0.0195, weight:1.99, lr:0.0006
[00:24:55.649] iteration:5912  t-loss:0.0285, loss-lb:0.0239, loss-ulb:0.0023, weight:1.99, lr:0.0006
[00:24:56.047] iteration:5913  t-loss:0.0466, loss-lb:0.0406, loss-ulb:0.0030, weight:1.99, lr:0.0006
[00:24:56.431] iteration:5914  t-loss:0.0564, loss-lb:0.0536, loss-ulb:0.0014, weight:1.99, lr:0.0006
[00:24:56.812] iteration:5915  t-loss:0.0430, loss-lb:0.0324, loss-ulb:0.0053, weight:1.99, lr:0.0006
[00:24:57.197] iteration:5916  t-loss:0.0265, loss-lb:0.0199, loss-ulb:0.0033, weight:1.99, lr:0.0006
[00:24:57.580] iteration:5917  t-loss:0.0459, loss-lb:0.0180, loss-ulb:0.0140, weight:1.99, lr:0.0006
[00:24:57.978] iteration:5918  t-loss:0.0644, loss-lb:0.0219, loss-ulb:0.0213, weight:1.99, lr:0.0006
[00:24:58.361] iteration:5919  t-loss:0.0263, loss-lb:0.0142, loss-ulb:0.0061, weight:1.99, lr:0.0006
[00:24:58.746] iteration:5920  t-loss:0.0709, loss-lb:0.0492, loss-ulb:0.0109, weight:1.99, lr:0.0006
[00:24:59.126] iteration:5921  t-loss:0.0285, loss-lb:0.0147, loss-ulb:0.0069, weight:1.99, lr:0.0006
[00:24:59.508] iteration:5922  t-loss:0.0376, loss-lb:0.0269, loss-ulb:0.0054, weight:1.99, lr:0.0006
[00:24:59.886] iteration:5923  t-loss:0.0402, loss-lb:0.0216, loss-ulb:0.0093, weight:1.99, lr:0.0006
[00:25:00.274] iteration:5924  t-loss:0.0464, loss-lb:0.0295, loss-ulb:0.0085, weight:1.99, lr:0.0006
[00:25:00.670] iteration:5925  t-loss:0.0490, loss-lb:0.0276, loss-ulb:0.0107, weight:1.99, lr:0.0006
[00:25:01.058] iteration:5926  t-loss:0.0593, loss-lb:0.0375, loss-ulb:0.0109, weight:1.99, lr:0.0006
[00:25:01.435] iteration:5927  t-loss:0.0366, loss-lb:0.0297, loss-ulb:0.0035, weight:1.99, lr:0.0006
[00:25:01.815] iteration:5928  t-loss:0.0540, loss-lb:0.0423, loss-ulb:0.0059, weight:1.99, lr:0.0006
[00:25:03.195] iteration:5929  t-loss:0.0319, loss-lb:0.0192, loss-ulb:0.0063, weight:1.99, lr:0.0006
[00:25:03.584] iteration:5930  t-loss:0.0613, loss-lb:0.0438, loss-ulb:0.0088, weight:1.99, lr:0.0006
[00:25:03.964] iteration:5931  t-loss:0.0362, loss-lb:0.0307, loss-ulb:0.0028, weight:1.99, lr:0.0006
[00:25:04.347] iteration:5932  t-loss:0.0815, loss-lb:0.0485, loss-ulb:0.0166, weight:1.99, lr:0.0006
[00:25:04.728] iteration:5933  t-loss:0.0537, loss-lb:0.0441, loss-ulb:0.0048, weight:1.99, lr:0.0006
[00:25:05.108] iteration:5934  t-loss:0.0331, loss-lb:0.0203, loss-ulb:0.0064, weight:1.99, lr:0.0006
[00:25:05.488] iteration:5935  t-loss:0.0983, loss-lb:0.0305, loss-ulb:0.0340, weight:1.99, lr:0.0006
[00:25:05.867] iteration:5936  t-loss:0.0282, loss-lb:0.0167, loss-ulb:0.0058, weight:1.99, lr:0.0006
[00:25:06.248] iteration:5937  t-loss:0.1477, loss-lb:0.0652, loss-ulb:0.0414, weight:1.99, lr:0.0006
[00:25:06.638] iteration:5938  t-loss:0.0467, loss-lb:0.0313, loss-ulb:0.0077, weight:1.99, lr:0.0006
[00:25:07.023] iteration:5939  t-loss:0.0295, loss-lb:0.0251, loss-ulb:0.0022, weight:1.99, lr:0.0006
[00:25:07.403] iteration:5940  t-loss:0.0286, loss-lb:0.0188, loss-ulb:0.0049, weight:1.99, lr:0.0006
[00:25:07.788] iteration:5941  t-loss:0.0480, loss-lb:0.0144, loss-ulb:0.0169, weight:1.99, lr:0.0006
[00:25:08.166] iteration:5942  t-loss:0.0249, loss-lb:0.0221, loss-ulb:0.0014, weight:1.99, lr:0.0006
[00:25:08.548] iteration:5943  t-loss:0.0497, loss-lb:0.0346, loss-ulb:0.0076, weight:1.99, lr:0.0006
[00:25:08.925] iteration:5944  t-loss:0.0296, loss-lb:0.0179, loss-ulb:0.0059, weight:1.99, lr:0.0006
[00:25:09.303] iteration:5945  t-loss:0.0391, loss-lb:0.0265, loss-ulb:0.0063, weight:1.99, lr:0.0006
[00:25:09.681] iteration:5946  t-loss:0.0731, loss-lb:0.0350, loss-ulb:0.0191, weight:1.99, lr:0.0006
[00:25:10.063] iteration:5947  t-loss:0.0421, loss-lb:0.0392, loss-ulb:0.0014, weight:1.99, lr:0.0006
[00:25:10.443] iteration:5948  t-loss:0.0238, loss-lb:0.0187, loss-ulb:0.0026, weight:1.99, lr:0.0006
[00:25:10.819] iteration:5949  t-loss:0.0301, loss-lb:0.0229, loss-ulb:0.0036, weight:1.99, lr:0.0006
[00:25:11.197] iteration:5950  t-loss:0.0403, loss-lb:0.0353, loss-ulb:0.0025, weight:1.99, lr:0.0006
[00:25:11.578] iteration:5951  t-loss:0.0393, loss-lb:0.0191, loss-ulb:0.0101, weight:1.99, lr:0.0006
[00:25:11.953] iteration:5952  t-loss:0.0705, loss-lb:0.0184, loss-ulb:0.0262, weight:1.99, lr:0.0006
[00:25:12.335] iteration:5953  t-loss:0.0667, loss-lb:0.0325, loss-ulb:0.0171, weight:1.99, lr:0.0006
[00:25:12.715] iteration:5954  t-loss:0.0337, loss-lb:0.0265, loss-ulb:0.0036, weight:1.99, lr:0.0006
[00:25:13.093] iteration:5955  t-loss:0.0247, loss-lb:0.0192, loss-ulb:0.0027, weight:1.99, lr:0.0006
[00:25:13.472] iteration:5956  t-loss:0.0707, loss-lb:0.0326, loss-ulb:0.0191, weight:1.99, lr:0.0006
[00:25:13.853] iteration:5957  t-loss:0.0487, loss-lb:0.0380, loss-ulb:0.0054, weight:1.99, lr:0.0006
[00:25:14.232] iteration:5958  t-loss:0.0616, loss-lb:0.0381, loss-ulb:0.0118, weight:1.99, lr:0.0006
[00:25:14.609] iteration:5959  t-loss:0.0665, loss-lb:0.0399, loss-ulb:0.0134, weight:1.99, lr:0.0006
[00:25:14.987] iteration:5960  t-loss:0.0378, loss-lb:0.0203, loss-ulb:0.0088, weight:1.99, lr:0.0006
[00:25:15.365] iteration:5961  t-loss:0.0421, loss-lb:0.0350, loss-ulb:0.0036, weight:1.99, lr:0.0006
[00:25:15.746] iteration:5962  t-loss:0.0390, loss-lb:0.0156, loss-ulb:0.0117, weight:1.99, lr:0.0006
[00:25:16.134] iteration:5963  t-loss:0.0292, loss-lb:0.0246, loss-ulb:0.0023, weight:1.99, lr:0.0006
[00:25:16.511] iteration:5964  t-loss:0.0604, loss-lb:0.0579, loss-ulb:0.0013, weight:1.99, lr:0.0006
[00:25:16.891] iteration:5965  t-loss:0.0437, loss-lb:0.0393, loss-ulb:0.0022, weight:1.99, lr:0.0006
[00:25:17.270] iteration:5966  t-loss:0.0313, loss-lb:0.0200, loss-ulb:0.0056, weight:1.99, lr:0.0006
[00:26:20.421] iteration 5966 : dice_score: 0.875081 best_dice: 0.885000
[00:26:20.421]  <<Test>> - Ep:156  - Dice-S/T:87.50/87.51, Best-S:88.23, Best-T:88.50
[00:26:20.421]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:26:21.785] iteration:5967  t-loss:0.0305, loss-lb:0.0255, loss-ulb:0.0025, weight:1.99, lr:0.0006
[00:26:22.239] iteration:5968  t-loss:0.0425, loss-lb:0.0237, loss-ulb:0.0095, weight:1.99, lr:0.0006
[00:26:22.623] iteration:5969  t-loss:0.0230, loss-lb:0.0179, loss-ulb:0.0026, weight:1.99, lr:0.0006
[00:26:23.002] iteration:5970  t-loss:0.0293, loss-lb:0.0156, loss-ulb:0.0068, weight:1.99, lr:0.0006
[00:26:23.381] iteration:5971  t-loss:0.0605, loss-lb:0.0201, loss-ulb:0.0203, weight:1.99, lr:0.0006
[00:26:23.765] iteration:5972  t-loss:0.0849, loss-lb:0.0404, loss-ulb:0.0223, weight:1.99, lr:0.0006
[00:26:24.143] iteration:5973  t-loss:0.1062, loss-lb:0.0598, loss-ulb:0.0233, weight:1.99, lr:0.0006
[00:26:24.518] iteration:5974  t-loss:0.1275, loss-lb:0.0188, loss-ulb:0.0545, weight:1.99, lr:0.0006
[00:26:24.898] iteration:5975  t-loss:0.0348, loss-lb:0.0191, loss-ulb:0.0079, weight:1.99, lr:0.0006
[00:26:25.272] iteration:5976  t-loss:0.1533, loss-lb:0.1206, loss-ulb:0.0164, weight:1.99, lr:0.0006
[00:26:25.651] iteration:5977  t-loss:0.0546, loss-lb:0.0201, loss-ulb:0.0173, weight:1.99, lr:0.0006
[00:26:26.037] iteration:5978  t-loss:0.0347, loss-lb:0.0175, loss-ulb:0.0086, weight:1.99, lr:0.0006
[00:26:26.419] iteration:5979  t-loss:0.0504, loss-lb:0.0337, loss-ulb:0.0083, weight:1.99, lr:0.0006
[00:26:26.802] iteration:5980  t-loss:0.0994, loss-lb:0.0584, loss-ulb:0.0206, weight:1.99, lr:0.0006
[00:26:27.189] iteration:5981  t-loss:0.0567, loss-lb:0.0360, loss-ulb:0.0104, weight:1.99, lr:0.0006
[00:26:27.573] iteration:5982  t-loss:0.0295, loss-lb:0.0237, loss-ulb:0.0029, weight:1.99, lr:0.0006
[00:26:27.958] iteration:5983  t-loss:0.0570, loss-lb:0.0526, loss-ulb:0.0022, weight:1.99, lr:0.0006
[00:26:28.341] iteration:5984  t-loss:0.0276, loss-lb:0.0200, loss-ulb:0.0038, weight:1.99, lr:0.0006
[00:26:28.722] iteration:5985  t-loss:0.0898, loss-lb:0.0328, loss-ulb:0.0286, weight:1.99, lr:0.0006
[00:26:29.101] iteration:5986  t-loss:0.0247, loss-lb:0.0203, loss-ulb:0.0022, weight:1.99, lr:0.0006
[00:26:29.484] iteration:5987  t-loss:0.1096, loss-lb:0.0586, loss-ulb:0.0256, weight:1.99, lr:0.0006
[00:26:29.865] iteration:5988  t-loss:0.0499, loss-lb:0.0212, loss-ulb:0.0144, weight:1.99, lr:0.0006
[00:26:30.245] iteration:5989  t-loss:0.0572, loss-lb:0.0532, loss-ulb:0.0020, weight:1.99, lr:0.0006
[00:26:30.636] iteration:5990  t-loss:0.0694, loss-lb:0.0266, loss-ulb:0.0215, weight:1.99, lr:0.0006
[00:26:31.021] iteration:5991  t-loss:0.0506, loss-lb:0.0452, loss-ulb:0.0027, weight:1.99, lr:0.0006
[00:26:31.411] iteration:5992  t-loss:0.0690, loss-lb:0.0406, loss-ulb:0.0142, weight:1.99, lr:0.0006
[00:26:31.793] iteration:5993  t-loss:0.0344, loss-lb:0.0239, loss-ulb:0.0053, weight:1.99, lr:0.0006
[00:26:32.184] iteration:5994  t-loss:0.1617, loss-lb:0.1292, loss-ulb:0.0163, weight:1.99, lr:0.0006
[00:26:32.574] iteration:5995  t-loss:0.0302, loss-lb:0.0198, loss-ulb:0.0053, weight:1.99, lr:0.0006
[00:26:32.961] iteration:5996  t-loss:0.0816, loss-lb:0.0745, loss-ulb:0.0036, weight:1.99, lr:0.0006
[00:26:33.340] iteration:5997  t-loss:0.0670, loss-lb:0.0579, loss-ulb:0.0046, weight:1.99, lr:0.0006
[00:26:33.725] iteration:5998  t-loss:0.0730, loss-lb:0.0431, loss-ulb:0.0150, weight:1.99, lr:0.0006
[00:26:34.105] iteration:5999  t-loss:0.0477, loss-lb:0.0301, loss-ulb:0.0088, weight:1.99, lr:0.0006
[00:26:34.481] iteration:6000  t-loss:0.0597, loss-lb:0.0388, loss-ulb:0.0105, weight:1.99, lr:0.0006
[00:26:34.861] iteration:6001  t-loss:0.0425, loss-lb:0.0219, loss-ulb:0.0103, weight:2.00, lr:0.0006
[00:26:35.242] iteration:6002  t-loss:0.0787, loss-lb:0.0616, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:26:35.622] iteration:6003  t-loss:0.0485, loss-lb:0.0333, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:26:35.996] iteration:6004  t-loss:0.0317, loss-lb:0.0244, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:26:37.225] iteration:6005  t-loss:0.0516, loss-lb:0.0219, loss-ulb:0.0149, weight:2.00, lr:0.0006
[00:26:37.627] iteration:6006  t-loss:0.0662, loss-lb:0.0414, loss-ulb:0.0124, weight:2.00, lr:0.0006
[00:26:38.012] iteration:6007  t-loss:0.0727, loss-lb:0.0325, loss-ulb:0.0201, weight:2.00, lr:0.0006
[00:26:38.395] iteration:6008  t-loss:0.0395, loss-lb:0.0226, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:26:38.779] iteration:6009  t-loss:0.0579, loss-lb:0.0297, loss-ulb:0.0141, weight:2.00, lr:0.0006
[00:26:39.160] iteration:6010  t-loss:0.0373, loss-lb:0.0203, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:26:39.547] iteration:6011  t-loss:0.0632, loss-lb:0.0248, loss-ulb:0.0192, weight:2.00, lr:0.0006
[00:26:39.923] iteration:6012  t-loss:0.0363, loss-lb:0.0248, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:26:40.308] iteration:6013  t-loss:0.0474, loss-lb:0.0330, loss-ulb:0.0072, weight:2.00, lr:0.0006
[00:26:40.690] iteration:6014  t-loss:0.0865, loss-lb:0.0604, loss-ulb:0.0130, weight:2.00, lr:0.0006
[00:26:41.078] iteration:6015  t-loss:0.0559, loss-lb:0.0447, loss-ulb:0.0056, weight:2.00, lr:0.0006
[00:26:41.470] iteration:6016  t-loss:0.0660, loss-lb:0.0435, loss-ulb:0.0113, weight:2.00, lr:0.0006
[00:26:41.852] iteration:6017  t-loss:0.0721, loss-lb:0.0289, loss-ulb:0.0216, weight:2.00, lr:0.0006
[00:26:42.239] iteration:6018  t-loss:0.0304, loss-lb:0.0246, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:26:42.624] iteration:6019  t-loss:0.0488, loss-lb:0.0314, loss-ulb:0.0087, weight:2.00, lr:0.0006
[00:26:43.005] iteration:6020  t-loss:0.0690, loss-lb:0.0218, loss-ulb:0.0236, weight:2.00, lr:0.0006
[00:26:43.385] iteration:6021  t-loss:0.0463, loss-lb:0.0415, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:26:43.768] iteration:6022  t-loss:0.0250, loss-lb:0.0190, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:26:44.149] iteration:6023  t-loss:0.0680, loss-lb:0.0286, loss-ulb:0.0197, weight:2.00, lr:0.0006
[00:26:44.526] iteration:6024  t-loss:0.0514, loss-lb:0.0228, loss-ulb:0.0143, weight:2.00, lr:0.0006
[00:26:44.911] iteration:6025  t-loss:0.0354, loss-lb:0.0323, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:26:45.295] iteration:6026  t-loss:0.0216, loss-lb:0.0178, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:26:45.674] iteration:6027  t-loss:0.0220, loss-lb:0.0172, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:26:46.054] iteration:6028  t-loss:0.0260, loss-lb:0.0210, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:26:46.437] iteration:6029  t-loss:0.0689, loss-lb:0.0183, loss-ulb:0.0253, weight:2.00, lr:0.0006
[00:26:46.818] iteration:6030  t-loss:0.0443, loss-lb:0.0400, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:26:47.196] iteration:6031  t-loss:0.0271, loss-lb:0.0150, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:26:47.574] iteration:6032  t-loss:0.0473, loss-lb:0.0414, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:26:47.964] iteration:6033  t-loss:0.0613, loss-lb:0.0402, loss-ulb:0.0106, weight:2.00, lr:0.0006
[00:26:48.344] iteration:6034  t-loss:0.0545, loss-lb:0.0271, loss-ulb:0.0137, weight:2.00, lr:0.0006
[00:26:48.728] iteration:6035  t-loss:0.0747, loss-lb:0.0296, loss-ulb:0.0226, weight:2.00, lr:0.0006
[00:26:49.107] iteration:6036  t-loss:0.0764, loss-lb:0.0593, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:26:49.486] iteration:6037  t-loss:0.0405, loss-lb:0.0185, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:26:49.865] iteration:6038  t-loss:0.0467, loss-lb:0.0312, loss-ulb:0.0078, weight:2.00, lr:0.0006
[00:26:50.240] iteration:6039  t-loss:0.0412, loss-lb:0.0366, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:26:50.619] iteration:6040  t-loss:0.0453, loss-lb:0.0204, loss-ulb:0.0125, weight:2.00, lr:0.0006
[00:26:50.996] iteration:6041  t-loss:0.0272, loss-lb:0.0185, loss-ulb:0.0044, weight:2.00, lr:0.0006
[00:26:51.378] iteration:6042  t-loss:0.0682, loss-lb:0.0346, loss-ulb:0.0168, weight:2.00, lr:0.0006
[00:26:52.753] iteration:6043  t-loss:0.0591, loss-lb:0.0188, loss-ulb:0.0201, weight:2.00, lr:0.0006
[00:26:53.144] iteration:6044  t-loss:0.0529, loss-lb:0.0202, loss-ulb:0.0163, weight:2.00, lr:0.0006
[00:26:53.531] iteration:6045  t-loss:0.0402, loss-lb:0.0348, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:26:53.916] iteration:6046  t-loss:0.0470, loss-lb:0.0337, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:26:54.299] iteration:6047  t-loss:0.0448, loss-lb:0.0281, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:26:54.680] iteration:6048  t-loss:0.0391, loss-lb:0.0156, loss-ulb:0.0118, weight:2.00, lr:0.0006
[00:26:55.068] iteration:6049  t-loss:0.0645, loss-lb:0.0355, loss-ulb:0.0145, weight:2.00, lr:0.0006
[00:26:55.453] iteration:6050  t-loss:0.0499, loss-lb:0.0465, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:26:55.833] iteration:6051  t-loss:0.0464, loss-lb:0.0172, loss-ulb:0.0146, weight:2.00, lr:0.0006
[00:26:56.217] iteration:6052  t-loss:0.0398, loss-lb:0.0249, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:26:56.600] iteration:6053  t-loss:0.0763, loss-lb:0.0569, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:26:56.983] iteration:6054  t-loss:0.0219, loss-lb:0.0181, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:26:57.366] iteration:6055  t-loss:0.0641, loss-lb:0.0373, loss-ulb:0.0134, weight:2.00, lr:0.0006
[00:26:57.752] iteration:6056  t-loss:0.0408, loss-lb:0.0343, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:26:58.135] iteration:6057  t-loss:0.0468, loss-lb:0.0196, loss-ulb:0.0136, weight:2.00, lr:0.0006
[00:26:58.522] iteration:6058  t-loss:0.0857, loss-lb:0.0325, loss-ulb:0.0266, weight:2.00, lr:0.0006
[00:26:58.904] iteration:6059  t-loss:0.0545, loss-lb:0.0443, loss-ulb:0.0051, weight:2.00, lr:0.0006
[00:26:59.301] iteration:6060  t-loss:0.0313, loss-lb:0.0219, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:26:59.683] iteration:6061  t-loss:0.0365, loss-lb:0.0229, loss-ulb:0.0068, weight:2.00, lr:0.0006
[00:27:00.072] iteration:6062  t-loss:0.0275, loss-lb:0.0168, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:27:00.456] iteration:6063  t-loss:0.0492, loss-lb:0.0287, loss-ulb:0.0102, weight:2.00, lr:0.0006
[00:27:00.846] iteration:6064  t-loss:0.0476, loss-lb:0.0397, loss-ulb:0.0040, weight:2.00, lr:0.0006
[00:27:01.238] iteration:6065  t-loss:0.0577, loss-lb:0.0383, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:27:01.621] iteration:6066  t-loss:0.0356, loss-lb:0.0315, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:27:02.006] iteration:6067  t-loss:0.0502, loss-lb:0.0259, loss-ulb:0.0122, weight:2.00, lr:0.0006
[00:27:02.392] iteration:6068  t-loss:0.0502, loss-lb:0.0358, loss-ulb:0.0072, weight:2.00, lr:0.0006
[00:27:02.775] iteration:6069  t-loss:0.0308, loss-lb:0.0215, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:27:03.162] iteration:6070  t-loss:0.0588, loss-lb:0.0201, loss-ulb:0.0193, weight:2.00, lr:0.0006
[00:27:03.553] iteration:6071  t-loss:0.0453, loss-lb:0.0314, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:27:03.941] iteration:6072  t-loss:0.0634, loss-lb:0.0357, loss-ulb:0.0139, weight:2.00, lr:0.0006
[00:27:04.327] iteration:6073  t-loss:0.0511, loss-lb:0.0319, loss-ulb:0.0096, weight:2.00, lr:0.0006
[00:27:04.713] iteration:6074  t-loss:0.0320, loss-lb:0.0287, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:27:05.095] iteration:6075  t-loss:0.0606, loss-lb:0.0376, loss-ulb:0.0115, weight:2.00, lr:0.0006
[00:27:05.476] iteration:6076  t-loss:0.0474, loss-lb:0.0236, loss-ulb:0.0119, weight:2.00, lr:0.0006
[00:27:05.853] iteration:6077  t-loss:0.0289, loss-lb:0.0214, loss-ulb:0.0038, weight:2.00, lr:0.0006
[00:27:06.246] iteration:6078  t-loss:0.0614, loss-lb:0.0272, loss-ulb:0.0171, weight:2.00, lr:0.0006
[00:27:06.646] iteration:6079  t-loss:0.0385, loss-lb:0.0358, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:27:07.027] iteration:6080  t-loss:0.0184, loss-lb:0.0155, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:27:08.405] iteration:6081  t-loss:0.0370, loss-lb:0.0288, loss-ulb:0.0041, weight:2.00, lr:0.0006
[00:27:08.790] iteration:6082  t-loss:0.0494, loss-lb:0.0226, loss-ulb:0.0134, weight:2.00, lr:0.0006
[00:27:09.171] iteration:6083  t-loss:0.0300, loss-lb:0.0232, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:27:09.556] iteration:6084  t-loss:0.0716, loss-lb:0.0414, loss-ulb:0.0151, weight:2.00, lr:0.0006
[00:27:09.937] iteration:6085  t-loss:0.0880, loss-lb:0.0625, loss-ulb:0.0128, weight:2.00, lr:0.0006
[00:27:10.319] iteration:6086  t-loss:0.0491, loss-lb:0.0271, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:27:10.705] iteration:6087  t-loss:0.0380, loss-lb:0.0314, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:27:11.082] iteration:6088  t-loss:0.0216, loss-lb:0.0197, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:27:11.468] iteration:6089  t-loss:0.0452, loss-lb:0.0432, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:27:11.857] iteration:6090  t-loss:0.0481, loss-lb:0.0395, loss-ulb:0.0043, weight:2.00, lr:0.0006
[00:27:12.245] iteration:6091  t-loss:0.0425, loss-lb:0.0363, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:27:12.633] iteration:6092  t-loss:0.0436, loss-lb:0.0411, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:27:13.018] iteration:6093  t-loss:0.0232, loss-lb:0.0178, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:27:13.406] iteration:6094  t-loss:0.0292, loss-lb:0.0180, loss-ulb:0.0056, weight:2.00, lr:0.0006
[00:27:13.793] iteration:6095  t-loss:0.0205, loss-lb:0.0180, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:27:14.178] iteration:6096  t-loss:0.0405, loss-lb:0.0192, loss-ulb:0.0107, weight:2.00, lr:0.0006
[00:27:14.562] iteration:6097  t-loss:0.0521, loss-lb:0.0493, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:27:14.949] iteration:6098  t-loss:0.0354, loss-lb:0.0188, loss-ulb:0.0083, weight:2.00, lr:0.0006
[00:27:15.345] iteration:6099  t-loss:0.0687, loss-lb:0.0280, loss-ulb:0.0204, weight:2.00, lr:0.0006
[00:27:15.730] iteration:6100  t-loss:0.0368, loss-lb:0.0182, loss-ulb:0.0093, weight:2.00, lr:0.0006
[00:27:16.115] iteration:6101  t-loss:0.0671, loss-lb:0.0501, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:27:16.503] iteration:6102  t-loss:0.0414, loss-lb:0.0290, loss-ulb:0.0062, weight:2.00, lr:0.0006
[00:27:16.886] iteration:6103  t-loss:0.0546, loss-lb:0.0423, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:27:17.275] iteration:6104  t-loss:0.0383, loss-lb:0.0313, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:27:17.658] iteration:6105  t-loss:0.0398, loss-lb:0.0349, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:27:18.043] iteration:6106  t-loss:0.0346, loss-lb:0.0198, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:27:18.421] iteration:6107  t-loss:0.0253, loss-lb:0.0157, loss-ulb:0.0048, weight:2.00, lr:0.0006
[00:27:18.801] iteration:6108  t-loss:0.0479, loss-lb:0.0159, loss-ulb:0.0160, weight:2.00, lr:0.0006
[00:27:19.178] iteration:6109  t-loss:0.0544, loss-lb:0.0169, loss-ulb:0.0188, weight:2.00, lr:0.0006
[00:27:19.561] iteration:6110  t-loss:0.0331, loss-lb:0.0189, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:27:19.936] iteration:6111  t-loss:0.0633, loss-lb:0.0167, loss-ulb:0.0233, weight:2.00, lr:0.0006
[00:27:20.316] iteration:6112  t-loss:0.0854, loss-lb:0.0590, loss-ulb:0.0132, weight:2.00, lr:0.0006
[00:27:20.692] iteration:6113  t-loss:0.0325, loss-lb:0.0216, loss-ulb:0.0055, weight:2.00, lr:0.0006
[00:27:21.071] iteration:6114  t-loss:0.0398, loss-lb:0.0357, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:27:21.458] iteration:6115  t-loss:0.0492, loss-lb:0.0343, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:27:21.859] iteration:6116  t-loss:0.0397, loss-lb:0.0360, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:27:22.248] iteration:6117  t-loss:0.0821, loss-lb:0.0199, loss-ulb:0.0311, weight:2.00, lr:0.0006
[00:27:22.624] iteration:6118  t-loss:0.0427, loss-lb:0.0314, loss-ulb:0.0056, weight:2.00, lr:0.0006
[00:28:24.779] iteration 6118 : dice_score: 0.885883 best_dice: 0.885900
[00:28:24.780]  <<Test>> - Ep:160  - Dice-S/T:87.76/88.59, Best-S:88.23, Best-T:88.59
[00:28:24.780]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:28:26.041] iteration:6119  t-loss:0.0453, loss-lb:0.0406, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:28:26.457] iteration:6120  t-loss:0.0561, loss-lb:0.0185, loss-ulb:0.0188, weight:2.00, lr:0.0006
[00:28:26.851] iteration:6121  t-loss:0.0294, loss-lb:0.0254, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:28:27.232] iteration:6122  t-loss:0.0308, loss-lb:0.0231, loss-ulb:0.0038, weight:2.00, lr:0.0006
[00:28:27.619] iteration:6123  t-loss:0.0723, loss-lb:0.0428, loss-ulb:0.0148, weight:2.00, lr:0.0006
[00:28:28.005] iteration:6124  t-loss:0.0399, loss-lb:0.0259, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:28:28.388] iteration:6125  t-loss:0.0486, loss-lb:0.0184, loss-ulb:0.0151, weight:2.00, lr:0.0006
[00:28:28.772] iteration:6126  t-loss:0.0225, loss-lb:0.0194, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:28:29.158] iteration:6127  t-loss:0.0617, loss-lb:0.0221, loss-ulb:0.0198, weight:2.00, lr:0.0006
[00:28:29.545] iteration:6128  t-loss:0.0502, loss-lb:0.0330, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:28:29.925] iteration:6129  t-loss:0.0251, loss-lb:0.0172, loss-ulb:0.0040, weight:2.00, lr:0.0006
[00:28:30.299] iteration:6130  t-loss:0.0275, loss-lb:0.0181, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:28:30.677] iteration:6131  t-loss:0.0206, loss-lb:0.0185, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:28:31.052] iteration:6132  t-loss:0.0246, loss-lb:0.0206, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:28:31.430] iteration:6133  t-loss:0.0436, loss-lb:0.0283, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:28:31.809] iteration:6134  t-loss:0.0248, loss-lb:0.0167, loss-ulb:0.0040, weight:2.00, lr:0.0006
[00:28:32.195] iteration:6135  t-loss:0.0268, loss-lb:0.0135, loss-ulb:0.0067, weight:2.00, lr:0.0006
[00:28:32.584] iteration:6136  t-loss:0.0693, loss-lb:0.0370, loss-ulb:0.0162, weight:2.00, lr:0.0006
[00:28:32.976] iteration:6137  t-loss:0.0719, loss-lb:0.0371, loss-ulb:0.0174, weight:2.00, lr:0.0006
[00:28:33.370] iteration:6138  t-loss:0.0828, loss-lb:0.0516, loss-ulb:0.0156, weight:2.00, lr:0.0006
[00:28:33.767] iteration:6139  t-loss:0.0456, loss-lb:0.0302, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:28:34.155] iteration:6140  t-loss:0.0494, loss-lb:0.0432, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:28:34.542] iteration:6141  t-loss:0.0798, loss-lb:0.0421, loss-ulb:0.0188, weight:2.00, lr:0.0006
[00:28:34.920] iteration:6142  t-loss:0.0308, loss-lb:0.0182, loss-ulb:0.0063, weight:2.00, lr:0.0006
[00:28:35.306] iteration:6143  t-loss:0.0392, loss-lb:0.0212, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:28:35.706] iteration:6144  t-loss:0.0614, loss-lb:0.0491, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:28:36.093] iteration:6145  t-loss:0.0227, loss-lb:0.0164, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:28:36.475] iteration:6146  t-loss:0.0201, loss-lb:0.0172, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:28:36.859] iteration:6147  t-loss:0.0280, loss-lb:0.0227, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:28:37.250] iteration:6148  t-loss:0.0507, loss-lb:0.0337, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:28:37.631] iteration:6149  t-loss:0.0212, loss-lb:0.0162, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:28:38.012] iteration:6150  t-loss:0.0523, loss-lb:0.0396, loss-ulb:0.0063, weight:2.00, lr:0.0006
[00:28:38.389] iteration:6151  t-loss:0.0336, loss-lb:0.0178, loss-ulb:0.0079, weight:2.00, lr:0.0006
[00:28:38.766] iteration:6152  t-loss:0.0648, loss-lb:0.0356, loss-ulb:0.0146, weight:2.00, lr:0.0006
[00:28:39.149] iteration:6153  t-loss:0.0394, loss-lb:0.0359, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:28:39.528] iteration:6154  t-loss:0.0456, loss-lb:0.0341, loss-ulb:0.0057, weight:2.00, lr:0.0006
[00:28:39.904] iteration:6155  t-loss:0.0250, loss-lb:0.0166, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:28:40.288] iteration:6156  t-loss:0.0435, loss-lb:0.0262, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:28:41.697] iteration:6157  t-loss:0.0535, loss-lb:0.0252, loss-ulb:0.0141, weight:2.00, lr:0.0006
[00:28:42.102] iteration:6158  t-loss:0.0417, loss-lb:0.0357, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:28:42.486] iteration:6159  t-loss:0.0630, loss-lb:0.0514, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:28:42.875] iteration:6160  t-loss:0.0478, loss-lb:0.0365, loss-ulb:0.0056, weight:2.00, lr:0.0006
[00:28:43.272] iteration:6161  t-loss:0.0943, loss-lb:0.0613, loss-ulb:0.0165, weight:2.00, lr:0.0006
[00:28:43.662] iteration:6162  t-loss:0.0503, loss-lb:0.0386, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:28:44.054] iteration:6163  t-loss:0.0590, loss-lb:0.0434, loss-ulb:0.0078, weight:2.00, lr:0.0006
[00:28:44.446] iteration:6164  t-loss:0.0434, loss-lb:0.0220, loss-ulb:0.0107, weight:2.00, lr:0.0006
[00:28:44.826] iteration:6165  t-loss:0.0311, loss-lb:0.0236, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:28:45.212] iteration:6166  t-loss:0.0862, loss-lb:0.0222, loss-ulb:0.0320, weight:2.00, lr:0.0006
[00:28:45.591] iteration:6167  t-loss:0.0278, loss-lb:0.0242, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:28:45.978] iteration:6168  t-loss:0.0779, loss-lb:0.0445, loss-ulb:0.0167, weight:2.00, lr:0.0006
[00:28:46.360] iteration:6169  t-loss:0.0411, loss-lb:0.0235, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:28:46.753] iteration:6170  t-loss:0.0481, loss-lb:0.0443, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:28:47.134] iteration:6171  t-loss:0.0366, loss-lb:0.0157, loss-ulb:0.0105, weight:2.00, lr:0.0006
[00:28:47.523] iteration:6172  t-loss:0.0538, loss-lb:0.0369, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:28:47.907] iteration:6173  t-loss:0.1285, loss-lb:0.0232, loss-ulb:0.0527, weight:2.00, lr:0.0006
[00:28:48.303] iteration:6174  t-loss:0.0266, loss-lb:0.0241, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:28:48.689] iteration:6175  t-loss:0.0847, loss-lb:0.0543, loss-ulb:0.0152, weight:2.00, lr:0.0006
[00:28:49.079] iteration:6176  t-loss:0.0387, loss-lb:0.0209, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:28:49.467] iteration:6177  t-loss:0.0351, loss-lb:0.0221, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:28:49.861] iteration:6178  t-loss:0.0424, loss-lb:0.0224, loss-ulb:0.0100, weight:2.00, lr:0.0006
[00:28:50.252] iteration:6179  t-loss:0.0751, loss-lb:0.0466, loss-ulb:0.0142, weight:2.00, lr:0.0006
[00:28:50.629] iteration:6180  t-loss:0.0290, loss-lb:0.0206, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:28:51.016] iteration:6181  t-loss:0.0234, loss-lb:0.0210, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:28:51.404] iteration:6182  t-loss:0.0939, loss-lb:0.0583, loss-ulb:0.0178, weight:2.00, lr:0.0006
[00:28:51.787] iteration:6183  t-loss:0.0275, loss-lb:0.0203, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:28:52.174] iteration:6184  t-loss:0.0498, loss-lb:0.0337, loss-ulb:0.0081, weight:2.00, lr:0.0006
[00:28:52.568] iteration:6185  t-loss:0.0539, loss-lb:0.0305, loss-ulb:0.0117, weight:2.00, lr:0.0006
[00:28:52.957] iteration:6186  t-loss:0.0889, loss-lb:0.0540, loss-ulb:0.0174, weight:2.00, lr:0.0006
[00:28:53.344] iteration:6187  t-loss:0.1041, loss-lb:0.0323, loss-ulb:0.0359, weight:2.00, lr:0.0006
[00:28:53.724] iteration:6188  t-loss:0.0235, loss-lb:0.0197, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:28:54.105] iteration:6189  t-loss:0.0249, loss-lb:0.0174, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:28:54.483] iteration:6190  t-loss:0.0596, loss-lb:0.0215, loss-ulb:0.0191, weight:2.00, lr:0.0006
[00:28:54.866] iteration:6191  t-loss:0.0381, loss-lb:0.0329, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:28:55.244] iteration:6192  t-loss:0.0476, loss-lb:0.0388, loss-ulb:0.0044, weight:2.00, lr:0.0006
[00:28:55.631] iteration:6193  t-loss:0.0536, loss-lb:0.0167, loss-ulb:0.0185, weight:2.00, lr:0.0006
[00:28:56.009] iteration:6194  t-loss:0.0857, loss-lb:0.0730, loss-ulb:0.0063, weight:2.00, lr:0.0006
[00:28:57.454] iteration:6195  t-loss:0.0553, loss-lb:0.0452, loss-ulb:0.0050, weight:2.00, lr:0.0006
[00:28:57.864] iteration:6196  t-loss:0.0468, loss-lb:0.0290, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:28:58.262] iteration:6197  t-loss:0.0516, loss-lb:0.0366, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:28:58.655] iteration:6198  t-loss:0.0450, loss-lb:0.0408, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:28:59.043] iteration:6199  t-loss:0.0496, loss-lb:0.0187, loss-ulb:0.0155, weight:2.00, lr:0.0006
[00:28:59.432] iteration:6200  t-loss:0.0476, loss-lb:0.0271, loss-ulb:0.0102, weight:2.00, lr:0.0006
[00:28:59.821] iteration:6201  t-loss:0.0890, loss-lb:0.0698, loss-ulb:0.0096, weight:2.00, lr:0.0006
[00:29:00.212] iteration:6202  t-loss:0.0536, loss-lb:0.0349, loss-ulb:0.0094, weight:2.00, lr:0.0006
[00:29:00.594] iteration:6203  t-loss:0.0449, loss-lb:0.0222, loss-ulb:0.0114, weight:2.00, lr:0.0006
[00:29:00.977] iteration:6204  t-loss:0.0203, loss-lb:0.0153, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:29:01.363] iteration:6205  t-loss:0.0286, loss-lb:0.0216, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:29:01.753] iteration:6206  t-loss:0.0366, loss-lb:0.0335, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:29:02.134] iteration:6207  t-loss:0.0288, loss-lb:0.0219, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:29:02.519] iteration:6208  t-loss:0.0397, loss-lb:0.0224, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:29:02.903] iteration:6209  t-loss:0.0280, loss-lb:0.0190, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:29:03.288] iteration:6210  t-loss:0.0289, loss-lb:0.0202, loss-ulb:0.0043, weight:2.00, lr:0.0006
[00:29:03.675] iteration:6211  t-loss:0.0366, loss-lb:0.0240, loss-ulb:0.0063, weight:2.00, lr:0.0006
[00:29:04.068] iteration:6212  t-loss:0.0510, loss-lb:0.0381, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:29:04.460] iteration:6213  t-loss:0.0517, loss-lb:0.0456, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:29:04.854] iteration:6214  t-loss:0.0656, loss-lb:0.0624, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:29:05.240] iteration:6215  t-loss:0.0255, loss-lb:0.0222, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:29:05.633] iteration:6216  t-loss:0.0664, loss-lb:0.0453, loss-ulb:0.0105, weight:2.00, lr:0.0006
[00:29:06.029] iteration:6217  t-loss:0.0623, loss-lb:0.0328, loss-ulb:0.0148, weight:2.00, lr:0.0006
[00:29:06.420] iteration:6218  t-loss:0.0852, loss-lb:0.0544, loss-ulb:0.0154, weight:2.00, lr:0.0006
[00:29:06.812] iteration:6219  t-loss:0.0604, loss-lb:0.0327, loss-ulb:0.0139, weight:2.00, lr:0.0006
[00:29:07.197] iteration:6220  t-loss:0.0472, loss-lb:0.0170, loss-ulb:0.0151, weight:2.00, lr:0.0006
[00:29:07.591] iteration:6221  t-loss:0.0591, loss-lb:0.0276, loss-ulb:0.0158, weight:2.00, lr:0.0006
[00:29:07.979] iteration:6222  t-loss:0.0946, loss-lb:0.0286, loss-ulb:0.0330, weight:2.00, lr:0.0006
[00:29:08.368] iteration:6223  t-loss:0.1415, loss-lb:0.0397, loss-ulb:0.0509, weight:2.00, lr:0.0006
[00:29:08.759] iteration:6224  t-loss:0.0878, loss-lb:0.0498, loss-ulb:0.0190, weight:2.00, lr:0.0006
[00:29:09.140] iteration:6225  t-loss:0.0503, loss-lb:0.0450, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:29:09.525] iteration:6226  t-loss:0.0600, loss-lb:0.0377, loss-ulb:0.0112, weight:2.00, lr:0.0006
[00:29:09.903] iteration:6227  t-loss:0.0216, loss-lb:0.0154, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:29:10.279] iteration:6228  t-loss:0.0783, loss-lb:0.0191, loss-ulb:0.0296, weight:2.00, lr:0.0006
[00:29:10.658] iteration:6229  t-loss:0.0558, loss-lb:0.0172, loss-ulb:0.0193, weight:2.00, lr:0.0006
[00:29:11.031] iteration:6230  t-loss:0.0403, loss-lb:0.0348, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:29:11.409] iteration:6231  t-loss:0.0373, loss-lb:0.0216, loss-ulb:0.0078, weight:2.00, lr:0.0006
[00:29:11.787] iteration:6232  t-loss:0.0626, loss-lb:0.0202, loss-ulb:0.0212, weight:2.00, lr:0.0006
[00:29:13.106] iteration:6233  t-loss:0.0301, loss-lb:0.0218, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:29:13.501] iteration:6234  t-loss:0.0300, loss-lb:0.0257, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:29:13.884] iteration:6235  t-loss:0.0276, loss-lb:0.0229, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:29:14.263] iteration:6236  t-loss:0.0363, loss-lb:0.0288, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:29:14.646] iteration:6237  t-loss:0.0242, loss-lb:0.0227, loss-ulb:0.0008, weight:2.00, lr:0.0006
[00:29:15.030] iteration:6238  t-loss:0.0203, loss-lb:0.0161, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:29:15.419] iteration:6239  t-loss:0.0398, loss-lb:0.0201, loss-ulb:0.0098, weight:2.00, lr:0.0006
[00:29:15.795] iteration:6240  t-loss:0.0414, loss-lb:0.0249, loss-ulb:0.0082, weight:2.00, lr:0.0006
[00:29:16.177] iteration:6241  t-loss:0.0247, loss-lb:0.0201, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:29:16.556] iteration:6242  t-loss:0.1191, loss-lb:0.0300, loss-ulb:0.0446, weight:2.00, lr:0.0006
[00:29:16.940] iteration:6243  t-loss:0.0618, loss-lb:0.0186, loss-ulb:0.0216, weight:2.00, lr:0.0006
[00:29:17.342] iteration:6244  t-loss:0.0420, loss-lb:0.0381, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:29:17.731] iteration:6245  t-loss:0.0269, loss-lb:0.0147, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:29:18.118] iteration:6246  t-loss:0.0493, loss-lb:0.0426, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:29:18.508] iteration:6247  t-loss:0.0811, loss-lb:0.0523, loss-ulb:0.0144, weight:2.00, lr:0.0006
[00:29:18.890] iteration:6248  t-loss:0.0430, loss-lb:0.0226, loss-ulb:0.0102, weight:2.00, lr:0.0006
[00:29:19.270] iteration:6249  t-loss:0.0592, loss-lb:0.0231, loss-ulb:0.0180, weight:2.00, lr:0.0006
[00:29:19.656] iteration:6250  t-loss:0.0424, loss-lb:0.0297, loss-ulb:0.0064, weight:2.00, lr:0.0006
[00:29:20.043] iteration:6251  t-loss:0.0724, loss-lb:0.0563, loss-ulb:0.0081, weight:2.00, lr:0.0006
[00:29:20.424] iteration:6252  t-loss:0.0772, loss-lb:0.0507, loss-ulb:0.0133, weight:2.00, lr:0.0006
[00:29:20.802] iteration:6253  t-loss:0.0286, loss-lb:0.0196, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:29:21.195] iteration:6254  t-loss:0.0447, loss-lb:0.0270, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:29:21.589] iteration:6255  t-loss:0.1205, loss-lb:0.0635, loss-ulb:0.0285, weight:2.00, lr:0.0006
[00:29:21.971] iteration:6256  t-loss:0.0725, loss-lb:0.0678, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:29:22.356] iteration:6257  t-loss:0.0620, loss-lb:0.0400, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:29:22.745] iteration:6258  t-loss:0.0506, loss-lb:0.0387, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:29:23.132] iteration:6259  t-loss:0.0482, loss-lb:0.0387, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:29:23.512] iteration:6260  t-loss:0.0540, loss-lb:0.0160, loss-ulb:0.0190, weight:2.00, lr:0.0006
[00:29:23.886] iteration:6261  t-loss:0.0603, loss-lb:0.0441, loss-ulb:0.0081, weight:2.00, lr:0.0006
[00:29:24.270] iteration:6262  t-loss:0.1184, loss-lb:0.0396, loss-ulb:0.0394, weight:2.00, lr:0.0006
[00:29:24.650] iteration:6263  t-loss:0.0418, loss-lb:0.0205, loss-ulb:0.0106, weight:2.00, lr:0.0006
[00:29:25.030] iteration:6264  t-loss:0.0698, loss-lb:0.0222, loss-ulb:0.0238, weight:2.00, lr:0.0006
[00:29:25.406] iteration:6265  t-loss:0.0360, loss-lb:0.0303, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:29:25.784] iteration:6266  t-loss:0.0504, loss-lb:0.0253, loss-ulb:0.0125, weight:2.00, lr:0.0006
[00:29:26.162] iteration:6267  t-loss:0.0694, loss-lb:0.0541, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:29:26.535] iteration:6268  t-loss:0.0283, loss-lb:0.0236, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:29:26.912] iteration:6269  t-loss:0.0716, loss-lb:0.0386, loss-ulb:0.0165, weight:2.00, lr:0.0006
[00:29:27.291] iteration:6270  t-loss:0.0623, loss-lb:0.0350, loss-ulb:0.0137, weight:2.00, lr:0.0006
[00:30:29.501] iteration 6270 : dice_score: 0.889653 best_dice: 0.889700
[00:30:29.501]  <<Test>> - Ep:164  - Dice-S/T:87.36/88.97, Best-S:88.23, Best-T:88.97
[00:30:29.501]           - AvgLoss(lb/ulb/all):0.03/0.01/0.06
[00:30:30.847] iteration:6271  t-loss:0.0370, loss-lb:0.0305, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:30:31.245] iteration:6272  t-loss:0.0520, loss-lb:0.0402, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:30:31.628] iteration:6273  t-loss:0.0343, loss-lb:0.0174, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:30:32.010] iteration:6274  t-loss:0.0336, loss-lb:0.0303, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:30:32.402] iteration:6275  t-loss:0.0629, loss-lb:0.0459, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:30:32.781] iteration:6276  t-loss:0.0445, loss-lb:0.0260, loss-ulb:0.0093, weight:2.00, lr:0.0006
[00:30:33.161] iteration:6277  t-loss:0.0747, loss-lb:0.0277, loss-ulb:0.0235, weight:2.00, lr:0.0006
[00:30:33.546] iteration:6278  t-loss:0.0199, loss-lb:0.0155, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:30:33.930] iteration:6279  t-loss:0.0509, loss-lb:0.0476, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:30:34.312] iteration:6280  t-loss:0.0630, loss-lb:0.0588, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:30:34.692] iteration:6281  t-loss:0.0531, loss-lb:0.0207, loss-ulb:0.0162, weight:2.00, lr:0.0006
[00:30:35.078] iteration:6282  t-loss:0.0700, loss-lb:0.0667, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:30:35.464] iteration:6283  t-loss:0.0468, loss-lb:0.0209, loss-ulb:0.0130, weight:2.00, lr:0.0006
[00:30:35.853] iteration:6284  t-loss:0.0597, loss-lb:0.0296, loss-ulb:0.0150, weight:2.00, lr:0.0006
[00:30:36.237] iteration:6285  t-loss:0.0406, loss-lb:0.0302, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:30:36.615] iteration:6286  t-loss:0.0333, loss-lb:0.0249, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:30:37.002] iteration:6287  t-loss:0.0624, loss-lb:0.0409, loss-ulb:0.0107, weight:2.00, lr:0.0006
[00:30:37.385] iteration:6288  t-loss:0.0375, loss-lb:0.0332, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:30:37.769] iteration:6289  t-loss:0.0552, loss-lb:0.0379, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:30:38.146] iteration:6290  t-loss:0.1045, loss-lb:0.1007, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:30:38.522] iteration:6291  t-loss:0.0591, loss-lb:0.0177, loss-ulb:0.0207, weight:2.00, lr:0.0006
[00:30:38.898] iteration:6292  t-loss:0.0233, loss-lb:0.0190, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:30:39.279] iteration:6293  t-loss:0.0481, loss-lb:0.0446, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:30:39.658] iteration:6294  t-loss:0.0831, loss-lb:0.0491, loss-ulb:0.0170, weight:2.00, lr:0.0006
[00:30:40.031] iteration:6295  t-loss:0.0493, loss-lb:0.0200, loss-ulb:0.0147, weight:2.00, lr:0.0006
[00:30:40.410] iteration:6296  t-loss:0.0271, loss-lb:0.0241, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:30:40.789] iteration:6297  t-loss:0.0879, loss-lb:0.0483, loss-ulb:0.0198, weight:2.00, lr:0.0006
[00:30:41.164] iteration:6298  t-loss:0.0302, loss-lb:0.0182, loss-ulb:0.0060, weight:2.00, lr:0.0006
[00:30:41.539] iteration:6299  t-loss:0.0426, loss-lb:0.0190, loss-ulb:0.0118, weight:2.00, lr:0.0006
[00:30:41.917] iteration:6300  t-loss:0.0403, loss-lb:0.0345, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:30:42.294] iteration:6301  t-loss:0.0545, loss-lb:0.0260, loss-ulb:0.0142, weight:2.00, lr:0.0006
[00:30:42.672] iteration:6302  t-loss:0.0549, loss-lb:0.0356, loss-ulb:0.0096, weight:2.00, lr:0.0006
[00:30:43.050] iteration:6303  t-loss:0.0485, loss-lb:0.0309, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:30:43.427] iteration:6304  t-loss:0.0494, loss-lb:0.0268, loss-ulb:0.0113, weight:2.00, lr:0.0006
[00:30:43.800] iteration:6305  t-loss:0.0234, loss-lb:0.0194, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:30:44.176] iteration:6306  t-loss:0.0236, loss-lb:0.0197, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:30:44.554] iteration:6307  t-loss:0.0437, loss-lb:0.0321, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:30:44.931] iteration:6308  t-loss:0.0350, loss-lb:0.0276, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:30:46.170] iteration:6309  t-loss:0.0209, loss-lb:0.0161, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:30:46.590] iteration:6310  t-loss:0.0584, loss-lb:0.0345, loss-ulb:0.0119, weight:2.00, lr:0.0006
[00:30:46.985] iteration:6311  t-loss:0.0979, loss-lb:0.0685, loss-ulb:0.0147, weight:2.00, lr:0.0006
[00:30:47.368] iteration:6312  t-loss:0.0361, loss-lb:0.0173, loss-ulb:0.0094, weight:2.00, lr:0.0006
[00:30:47.747] iteration:6313  t-loss:0.0180, loss-lb:0.0159, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:30:48.128] iteration:6314  t-loss:0.0327, loss-lb:0.0287, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:30:48.510] iteration:6315  t-loss:0.0255, loss-lb:0.0195, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:30:48.896] iteration:6316  t-loss:0.0439, loss-lb:0.0416, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:30:49.282] iteration:6317  t-loss:0.1266, loss-lb:0.0332, loss-ulb:0.0467, weight:2.00, lr:0.0006
[00:30:49.668] iteration:6318  t-loss:0.0486, loss-lb:0.0231, loss-ulb:0.0128, weight:2.00, lr:0.0006
[00:30:50.048] iteration:6319  t-loss:0.0471, loss-lb:0.0180, loss-ulb:0.0146, weight:2.00, lr:0.0006
[00:30:50.432] iteration:6320  t-loss:0.0618, loss-lb:0.0572, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:30:50.807] iteration:6321  t-loss:0.0264, loss-lb:0.0232, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:30:51.187] iteration:6322  t-loss:0.0178, loss-lb:0.0144, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:30:51.571] iteration:6323  t-loss:0.0235, loss-lb:0.0186, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:30:51.953] iteration:6324  t-loss:0.0627, loss-lb:0.0417, loss-ulb:0.0105, weight:2.00, lr:0.0006
[00:30:52.333] iteration:6325  t-loss:0.0395, loss-lb:0.0275, loss-ulb:0.0060, weight:2.00, lr:0.0006
[00:30:52.713] iteration:6326  t-loss:0.0451, loss-lb:0.0393, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:30:53.104] iteration:6327  t-loss:0.0458, loss-lb:0.0253, loss-ulb:0.0103, weight:2.00, lr:0.0006
[00:30:53.494] iteration:6328  t-loss:0.0563, loss-lb:0.0459, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:30:53.875] iteration:6329  t-loss:0.0538, loss-lb:0.0181, loss-ulb:0.0179, weight:2.00, lr:0.0006
[00:30:54.254] iteration:6330  t-loss:0.0332, loss-lb:0.0189, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:30:54.636] iteration:6331  t-loss:0.0201, loss-lb:0.0161, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:30:55.016] iteration:6332  t-loss:0.0382, loss-lb:0.0344, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:30:55.397] iteration:6333  t-loss:0.0325, loss-lb:0.0223, loss-ulb:0.0051, weight:2.00, lr:0.0006
[00:30:55.777] iteration:6334  t-loss:0.0272, loss-lb:0.0199, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:30:56.158] iteration:6335  t-loss:0.0565, loss-lb:0.0315, loss-ulb:0.0125, weight:2.00, lr:0.0006
[00:30:56.547] iteration:6336  t-loss:0.0568, loss-lb:0.0285, loss-ulb:0.0142, weight:2.00, lr:0.0006
[00:30:56.929] iteration:6337  t-loss:0.0347, loss-lb:0.0295, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:30:57.311] iteration:6338  t-loss:0.0239, loss-lb:0.0199, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:30:57.690] iteration:6339  t-loss:0.0271, loss-lb:0.0172, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:30:58.064] iteration:6340  t-loss:0.0224, loss-lb:0.0190, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:30:58.438] iteration:6341  t-loss:0.0216, loss-lb:0.0170, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:30:58.818] iteration:6342  t-loss:0.0455, loss-lb:0.0364, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:30:59.201] iteration:6343  t-loss:0.0281, loss-lb:0.0180, loss-ulb:0.0051, weight:2.00, lr:0.0006
[00:30:59.588] iteration:6344  t-loss:0.0531, loss-lb:0.0351, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:30:59.973] iteration:6345  t-loss:0.0403, loss-lb:0.0257, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:31:00.354] iteration:6346  t-loss:0.1306, loss-lb:0.1058, loss-ulb:0.0124, weight:2.00, lr:0.0006
[00:31:01.716] iteration:6347  t-loss:0.0722, loss-lb:0.0384, loss-ulb:0.0169, weight:2.00, lr:0.0006
[00:31:02.101] iteration:6348  t-loss:0.0263, loss-lb:0.0174, loss-ulb:0.0044, weight:2.00, lr:0.0006
[00:31:02.487] iteration:6349  t-loss:0.0724, loss-lb:0.0419, loss-ulb:0.0153, weight:2.00, lr:0.0006
[00:31:02.872] iteration:6350  t-loss:0.0441, loss-lb:0.0195, loss-ulb:0.0123, weight:2.00, lr:0.0006
[00:31:03.256] iteration:6351  t-loss:0.0353, loss-lb:0.0174, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:31:03.643] iteration:6352  t-loss:0.0565, loss-lb:0.0383, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:31:04.027] iteration:6353  t-loss:0.0892, loss-lb:0.0512, loss-ulb:0.0190, weight:2.00, lr:0.0006
[00:31:04.412] iteration:6354  t-loss:0.0453, loss-lb:0.0334, loss-ulb:0.0060, weight:2.00, lr:0.0006
[00:31:04.794] iteration:6355  t-loss:0.0457, loss-lb:0.0406, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:31:05.172] iteration:6356  t-loss:0.0224, loss-lb:0.0139, loss-ulb:0.0043, weight:2.00, lr:0.0006
[00:31:05.554] iteration:6357  t-loss:0.0388, loss-lb:0.0147, loss-ulb:0.0120, weight:2.00, lr:0.0006
[00:31:05.935] iteration:6358  t-loss:0.0447, loss-lb:0.0208, loss-ulb:0.0120, weight:2.00, lr:0.0006
[00:31:06.319] iteration:6359  t-loss:0.0256, loss-lb:0.0158, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:31:06.700] iteration:6360  t-loss:0.0518, loss-lb:0.0343, loss-ulb:0.0087, weight:2.00, lr:0.0006
[00:31:07.083] iteration:6361  t-loss:0.0474, loss-lb:0.0148, loss-ulb:0.0163, weight:2.00, lr:0.0006
[00:31:07.466] iteration:6362  t-loss:0.0239, loss-lb:0.0177, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:31:07.848] iteration:6363  t-loss:0.0337, loss-lb:0.0142, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:31:08.229] iteration:6364  t-loss:0.0331, loss-lb:0.0271, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:31:08.612] iteration:6365  t-loss:0.0640, loss-lb:0.0474, loss-ulb:0.0083, weight:2.00, lr:0.0006
[00:31:08.995] iteration:6366  t-loss:0.0562, loss-lb:0.0197, loss-ulb:0.0182, weight:2.00, lr:0.0006
[00:31:09.384] iteration:6367  t-loss:0.0455, loss-lb:0.0350, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:31:09.766] iteration:6368  t-loss:0.0366, loss-lb:0.0201, loss-ulb:0.0083, weight:2.00, lr:0.0006
[00:31:10.148] iteration:6369  t-loss:0.0395, loss-lb:0.0320, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:31:10.527] iteration:6370  t-loss:0.0201, loss-lb:0.0175, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:31:10.911] iteration:6371  t-loss:0.0420, loss-lb:0.0331, loss-ulb:0.0044, weight:2.00, lr:0.0006
[00:31:11.288] iteration:6372  t-loss:0.0317, loss-lb:0.0195, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:31:11.672] iteration:6373  t-loss:0.0551, loss-lb:0.0356, loss-ulb:0.0098, weight:2.00, lr:0.0006
[00:31:12.053] iteration:6374  t-loss:0.0213, loss-lb:0.0199, loss-ulb:0.0007, weight:2.00, lr:0.0006
[00:31:12.446] iteration:6375  t-loss:0.0777, loss-lb:0.0474, loss-ulb:0.0152, weight:2.00, lr:0.0006
[00:31:12.847] iteration:6376  t-loss:0.0671, loss-lb:0.0296, loss-ulb:0.0187, weight:2.00, lr:0.0006
[00:31:13.227] iteration:6377  t-loss:0.1240, loss-lb:0.1162, loss-ulb:0.0039, weight:2.00, lr:0.0006
[00:31:13.606] iteration:6378  t-loss:0.0437, loss-lb:0.0397, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:31:13.986] iteration:6379  t-loss:0.0484, loss-lb:0.0265, loss-ulb:0.0109, weight:2.00, lr:0.0006
[00:31:14.360] iteration:6380  t-loss:0.0244, loss-lb:0.0155, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:31:14.738] iteration:6381  t-loss:0.0338, loss-lb:0.0163, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:31:15.116] iteration:6382  t-loss:0.1140, loss-lb:0.0688, loss-ulb:0.0226, weight:2.00, lr:0.0006
[00:31:15.495] iteration:6383  t-loss:0.0403, loss-lb:0.0297, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:31:15.855] iteration:6384  t-loss:0.0310, loss-lb:0.0264, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:31:17.127] iteration:6385  t-loss:0.0321, loss-lb:0.0136, loss-ulb:0.0092, weight:2.00, lr:0.0006
[00:31:17.533] iteration:6386  t-loss:0.0488, loss-lb:0.0351, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:31:17.927] iteration:6387  t-loss:0.0383, loss-lb:0.0317, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:31:18.309] iteration:6388  t-loss:0.0499, loss-lb:0.0215, loss-ulb:0.0142, weight:2.00, lr:0.0006
[00:31:18.695] iteration:6389  t-loss:0.0230, loss-lb:0.0208, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:31:19.084] iteration:6390  t-loss:0.0321, loss-lb:0.0297, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:31:19.473] iteration:6391  t-loss:0.0622, loss-lb:0.0300, loss-ulb:0.0161, weight:2.00, lr:0.0006
[00:31:19.853] iteration:6392  t-loss:0.0543, loss-lb:0.0237, loss-ulb:0.0153, weight:2.00, lr:0.0006
[00:31:20.235] iteration:6393  t-loss:0.0463, loss-lb:0.0375, loss-ulb:0.0044, weight:2.00, lr:0.0006
[00:31:20.613] iteration:6394  t-loss:0.0303, loss-lb:0.0247, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:31:21.004] iteration:6395  t-loss:0.0415, loss-lb:0.0262, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:31:21.379] iteration:6396  t-loss:0.0321, loss-lb:0.0186, loss-ulb:0.0068, weight:2.00, lr:0.0006
[00:31:21.755] iteration:6397  t-loss:0.0333, loss-lb:0.0152, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:31:22.135] iteration:6398  t-loss:0.0334, loss-lb:0.0258, loss-ulb:0.0038, weight:2.00, lr:0.0006
[00:31:22.531] iteration:6399  t-loss:0.0603, loss-lb:0.0571, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:31:22.939] iteration:6400  t-loss:0.0240, loss-lb:0.0212, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:31:23.329] iteration:6401  t-loss:0.0201, loss-lb:0.0138, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:31:23.719] iteration:6402  t-loss:0.0265, loss-lb:0.0175, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:31:24.101] iteration:6403  t-loss:0.0535, loss-lb:0.0330, loss-ulb:0.0103, weight:2.00, lr:0.0006
[00:31:24.483] iteration:6404  t-loss:0.0545, loss-lb:0.0508, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:31:24.864] iteration:6405  t-loss:0.0463, loss-lb:0.0144, loss-ulb:0.0159, weight:2.00, lr:0.0006
[00:31:25.243] iteration:6406  t-loss:0.0339, loss-lb:0.0314, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:31:25.620] iteration:6407  t-loss:0.0368, loss-lb:0.0135, loss-ulb:0.0117, weight:2.00, lr:0.0006
[00:31:26.001] iteration:6408  t-loss:0.0486, loss-lb:0.0457, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:31:26.385] iteration:6409  t-loss:0.0849, loss-lb:0.0404, loss-ulb:0.0223, weight:2.00, lr:0.0006
[00:31:26.768] iteration:6410  t-loss:0.0415, loss-lb:0.0284, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:31:27.144] iteration:6411  t-loss:0.0433, loss-lb:0.0154, loss-ulb:0.0139, weight:2.00, lr:0.0006
[00:31:27.525] iteration:6412  t-loss:0.0299, loss-lb:0.0226, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:31:27.909] iteration:6413  t-loss:0.0316, loss-lb:0.0271, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:31:28.296] iteration:6414  t-loss:0.0481, loss-lb:0.0391, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:31:28.679] iteration:6415  t-loss:0.0296, loss-lb:0.0252, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:31:29.058] iteration:6416  t-loss:0.0638, loss-lb:0.0274, loss-ulb:0.0182, weight:2.00, lr:0.0006
[00:31:29.431] iteration:6417  t-loss:0.0249, loss-lb:0.0179, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:31:29.810] iteration:6418  t-loss:0.0763, loss-lb:0.0289, loss-ulb:0.0237, weight:2.00, lr:0.0006
[00:31:30.187] iteration:6419  t-loss:0.0256, loss-lb:0.0118, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:31:30.568] iteration:6420  t-loss:0.0575, loss-lb:0.0373, loss-ulb:0.0101, weight:2.00, lr:0.0006
[00:31:30.948] iteration:6421  t-loss:0.0562, loss-lb:0.0316, loss-ulb:0.0123, weight:2.00, lr:0.0006
[00:31:31.321] iteration:6422  t-loss:0.0313, loss-lb:0.0222, loss-ulb:0.0046, weight:2.00, lr:0.0006
[00:32:32.900] iteration 6422 : dice_score: 0.870497 best_dice: 0.889700
[00:32:32.900]  <<Test>> - Ep:168  - Dice-S/T:80.09/87.05, Best-S:88.23, Best-T:88.97
[00:32:32.900]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:32:34.199] iteration:6423  t-loss:0.0567, loss-lb:0.0535, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:32:34.626] iteration:6424  t-loss:0.0359, loss-lb:0.0321, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:32:35.045] iteration:6425  t-loss:0.0878, loss-lb:0.0421, loss-ulb:0.0229, weight:2.00, lr:0.0006
[00:32:35.427] iteration:6426  t-loss:0.0497, loss-lb:0.0379, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:32:35.803] iteration:6427  t-loss:0.0307, loss-lb:0.0240, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:32:36.183] iteration:6428  t-loss:0.0303, loss-lb:0.0213, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:32:36.556] iteration:6429  t-loss:0.0448, loss-lb:0.0395, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:32:36.933] iteration:6430  t-loss:0.0646, loss-lb:0.0342, loss-ulb:0.0152, weight:2.00, lr:0.0006
[00:32:37.313] iteration:6431  t-loss:0.0441, loss-lb:0.0395, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:32:37.691] iteration:6432  t-loss:0.0330, loss-lb:0.0180, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:32:38.072] iteration:6433  t-loss:0.0661, loss-lb:0.0496, loss-ulb:0.0082, weight:2.00, lr:0.0006
[00:32:38.443] iteration:6434  t-loss:0.0188, loss-lb:0.0155, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:32:38.820] iteration:6435  t-loss:0.0278, loss-lb:0.0227, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:32:39.206] iteration:6436  t-loss:0.0462, loss-lb:0.0341, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:32:39.585] iteration:6437  t-loss:0.0340, loss-lb:0.0222, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:32:39.968] iteration:6438  t-loss:0.0568, loss-lb:0.0419, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:32:40.345] iteration:6439  t-loss:0.0267, loss-lb:0.0197, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:32:40.725] iteration:6440  t-loss:0.0477, loss-lb:0.0192, loss-ulb:0.0143, weight:2.00, lr:0.0006
[00:32:41.105] iteration:6441  t-loss:0.0251, loss-lb:0.0230, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:32:41.481] iteration:6442  t-loss:0.0234, loss-lb:0.0163, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:32:41.859] iteration:6443  t-loss:0.0339, loss-lb:0.0307, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:32:42.240] iteration:6444  t-loss:0.0515, loss-lb:0.0176, loss-ulb:0.0170, weight:2.00, lr:0.0006
[00:32:42.619] iteration:6445  t-loss:0.1166, loss-lb:0.0464, loss-ulb:0.0351, weight:2.00, lr:0.0006
[00:32:42.998] iteration:6446  t-loss:0.0667, loss-lb:0.0653, loss-ulb:0.0007, weight:2.00, lr:0.0006
[00:32:43.380] iteration:6447  t-loss:0.0324, loss-lb:0.0293, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:32:43.767] iteration:6448  t-loss:0.0556, loss-lb:0.0361, loss-ulb:0.0098, weight:2.00, lr:0.0006
[00:32:44.156] iteration:6449  t-loss:0.0379, loss-lb:0.0352, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:32:44.530] iteration:6450  t-loss:0.0253, loss-lb:0.0234, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:32:44.907] iteration:6451  t-loss:0.0231, loss-lb:0.0191, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:32:45.289] iteration:6452  t-loss:0.0561, loss-lb:0.0202, loss-ulb:0.0179, weight:2.00, lr:0.0006
[00:32:45.666] iteration:6453  t-loss:0.0588, loss-lb:0.0414, loss-ulb:0.0087, weight:2.00, lr:0.0006
[00:32:46.043] iteration:6454  t-loss:0.0596, loss-lb:0.0341, loss-ulb:0.0127, weight:2.00, lr:0.0006
[00:32:46.419] iteration:6455  t-loss:0.0537, loss-lb:0.0195, loss-ulb:0.0171, weight:2.00, lr:0.0006
[00:32:46.796] iteration:6456  t-loss:0.0468, loss-lb:0.0426, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:32:47.172] iteration:6457  t-loss:0.0648, loss-lb:0.0335, loss-ulb:0.0157, weight:2.00, lr:0.0006
[00:32:47.548] iteration:6458  t-loss:0.0561, loss-lb:0.0331, loss-ulb:0.0115, weight:2.00, lr:0.0006
[00:32:47.922] iteration:6459  t-loss:0.0260, loss-lb:0.0222, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:32:48.299] iteration:6460  t-loss:0.0599, loss-lb:0.0178, loss-ulb:0.0211, weight:2.00, lr:0.0006
[00:32:49.764] iteration:6461  t-loss:0.0664, loss-lb:0.0350, loss-ulb:0.0157, weight:2.00, lr:0.0006
[00:32:50.157] iteration:6462  t-loss:0.0265, loss-lb:0.0150, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:32:50.540] iteration:6463  t-loss:0.0526, loss-lb:0.0263, loss-ulb:0.0132, weight:2.00, lr:0.0006
[00:32:50.936] iteration:6464  t-loss:0.0890, loss-lb:0.0608, loss-ulb:0.0141, weight:2.00, lr:0.0006
[00:32:51.319] iteration:6465  t-loss:0.0542, loss-lb:0.0282, loss-ulb:0.0130, weight:2.00, lr:0.0006
[00:32:51.698] iteration:6466  t-loss:0.0257, loss-lb:0.0214, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:32:52.076] iteration:6467  t-loss:0.0184, loss-lb:0.0153, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:32:52.454] iteration:6468  t-loss:0.0409, loss-lb:0.0259, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:32:52.833] iteration:6469  t-loss:0.0313, loss-lb:0.0196, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:32:53.213] iteration:6470  t-loss:0.0211, loss-lb:0.0182, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:32:53.593] iteration:6471  t-loss:0.0218, loss-lb:0.0171, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:32:53.980] iteration:6472  t-loss:0.0615, loss-lb:0.0418, loss-ulb:0.0099, weight:2.00, lr:0.0006
[00:32:54.361] iteration:6473  t-loss:0.0511, loss-lb:0.0292, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:32:54.740] iteration:6474  t-loss:0.0235, loss-lb:0.0203, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:32:55.117] iteration:6475  t-loss:0.0240, loss-lb:0.0176, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:32:55.499] iteration:6476  t-loss:0.0354, loss-lb:0.0313, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:32:55.878] iteration:6477  t-loss:0.0507, loss-lb:0.0177, loss-ulb:0.0165, weight:2.00, lr:0.0006
[00:32:56.264] iteration:6478  t-loss:0.0503, loss-lb:0.0326, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:32:56.646] iteration:6479  t-loss:0.0582, loss-lb:0.0562, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:32:57.032] iteration:6480  t-loss:0.0394, loss-lb:0.0360, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:32:57.416] iteration:6481  t-loss:0.0309, loss-lb:0.0190, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:32:57.801] iteration:6482  t-loss:0.0653, loss-lb:0.0387, loss-ulb:0.0133, weight:2.00, lr:0.0006
[00:32:58.178] iteration:6483  t-loss:0.0224, loss-lb:0.0188, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:32:58.558] iteration:6484  t-loss:0.0276, loss-lb:0.0218, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:32:58.939] iteration:6485  t-loss:0.0894, loss-lb:0.0188, loss-ulb:0.0353, weight:2.00, lr:0.0006
[00:32:59.322] iteration:6486  t-loss:0.0350, loss-lb:0.0170, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:32:59.702] iteration:6487  t-loss:0.0420, loss-lb:0.0382, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:33:00.087] iteration:6488  t-loss:0.0331, loss-lb:0.0234, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:33:00.471] iteration:6489  t-loss:0.0286, loss-lb:0.0180, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:33:00.854] iteration:6490  t-loss:0.0407, loss-lb:0.0188, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:33:01.238] iteration:6491  t-loss:0.0553, loss-lb:0.0386, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:33:01.620] iteration:6492  t-loss:0.0973, loss-lb:0.0301, loss-ulb:0.0336, weight:2.00, lr:0.0006
[00:33:01.997] iteration:6493  t-loss:0.0257, loss-lb:0.0172, loss-ulb:0.0043, weight:2.00, lr:0.0006
[00:33:02.374] iteration:6494  t-loss:0.0423, loss-lb:0.0207, loss-ulb:0.0108, weight:2.00, lr:0.0006
[00:33:02.751] iteration:6495  t-loss:0.0290, loss-lb:0.0119, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:33:03.128] iteration:6496  t-loss:0.0352, loss-lb:0.0191, loss-ulb:0.0081, weight:2.00, lr:0.0006
[00:33:03.501] iteration:6497  t-loss:0.0239, loss-lb:0.0207, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:33:03.885] iteration:6498  t-loss:0.0624, loss-lb:0.0302, loss-ulb:0.0161, weight:2.00, lr:0.0006
[00:33:05.165] iteration:6499  t-loss:0.0454, loss-lb:0.0196, loss-ulb:0.0129, weight:2.00, lr:0.0006
[00:33:05.564] iteration:6500  t-loss:0.0417, loss-lb:0.0282, loss-ulb:0.0067, weight:2.00, lr:0.0006
[00:33:05.948] iteration:6501  t-loss:0.0210, loss-lb:0.0167, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:33:06.334] iteration:6502  t-loss:0.0510, loss-lb:0.0461, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:33:06.722] iteration:6503  t-loss:0.0439, loss-lb:0.0340, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:33:07.102] iteration:6504  t-loss:0.0242, loss-lb:0.0191, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:33:07.485] iteration:6505  t-loss:0.0295, loss-lb:0.0177, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:33:07.870] iteration:6506  t-loss:0.0351, loss-lb:0.0267, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:33:08.252] iteration:6507  t-loss:0.0293, loss-lb:0.0253, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:33:08.630] iteration:6508  t-loss:0.0739, loss-lb:0.0184, loss-ulb:0.0278, weight:2.00, lr:0.0006
[00:33:09.014] iteration:6509  t-loss:0.0252, loss-lb:0.0198, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:33:09.396] iteration:6510  t-loss:0.0533, loss-lb:0.0277, loss-ulb:0.0128, weight:2.00, lr:0.0006
[00:33:09.781] iteration:6511  t-loss:0.0316, loss-lb:0.0176, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:33:10.159] iteration:6512  t-loss:0.0429, loss-lb:0.0332, loss-ulb:0.0048, weight:2.00, lr:0.0006
[00:33:10.545] iteration:6513  t-loss:0.0261, loss-lb:0.0218, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:33:10.929] iteration:6514  t-loss:0.0467, loss-lb:0.0254, loss-ulb:0.0107, weight:2.00, lr:0.0006
[00:33:11.314] iteration:6515  t-loss:0.0459, loss-lb:0.0327, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:33:11.697] iteration:6516  t-loss:0.0552, loss-lb:0.0454, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:33:12.084] iteration:6517  t-loss:0.0379, loss-lb:0.0183, loss-ulb:0.0098, weight:2.00, lr:0.0006
[00:33:12.468] iteration:6518  t-loss:0.0383, loss-lb:0.0318, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:33:12.855] iteration:6519  t-loss:0.0339, loss-lb:0.0313, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:33:13.236] iteration:6520  t-loss:0.0704, loss-lb:0.0438, loss-ulb:0.0133, weight:2.00, lr:0.0006
[00:33:13.625] iteration:6521  t-loss:0.0315, loss-lb:0.0174, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:33:14.010] iteration:6522  t-loss:0.1050, loss-lb:0.0267, loss-ulb:0.0391, weight:2.00, lr:0.0006
[00:33:14.395] iteration:6523  t-loss:0.0445, loss-lb:0.0295, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:33:14.772] iteration:6524  t-loss:0.0296, loss-lb:0.0246, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:33:15.158] iteration:6525  t-loss:0.0941, loss-lb:0.0762, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:33:15.532] iteration:6526  t-loss:0.0221, loss-lb:0.0191, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:33:15.914] iteration:6527  t-loss:0.0994, loss-lb:0.0684, loss-ulb:0.0155, weight:2.00, lr:0.0006
[00:33:16.300] iteration:6528  t-loss:0.0520, loss-lb:0.0260, loss-ulb:0.0130, weight:2.00, lr:0.0006
[00:33:16.681] iteration:6529  t-loss:0.0341, loss-lb:0.0192, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:33:17.055] iteration:6530  t-loss:0.0229, loss-lb:0.0209, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:33:17.429] iteration:6531  t-loss:0.0230, loss-lb:0.0179, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:33:17.803] iteration:6532  t-loss:0.0590, loss-lb:0.0361, loss-ulb:0.0115, weight:2.00, lr:0.0006
[00:33:18.182] iteration:6533  t-loss:0.0409, loss-lb:0.0381, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:33:18.552] iteration:6534  t-loss:0.0242, loss-lb:0.0189, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:33:18.930] iteration:6535  t-loss:0.0368, loss-lb:0.0174, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:33:19.309] iteration:6536  t-loss:0.0303, loss-lb:0.0162, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:33:20.661] iteration:6537  t-loss:0.0291, loss-lb:0.0262, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:33:21.048] iteration:6538  t-loss:0.0264, loss-lb:0.0234, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:33:21.430] iteration:6539  t-loss:0.0457, loss-lb:0.0210, loss-ulb:0.0124, weight:2.00, lr:0.0006
[00:33:21.811] iteration:6540  t-loss:0.0365, loss-lb:0.0334, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:33:22.191] iteration:6541  t-loss:0.0396, loss-lb:0.0369, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:33:22.573] iteration:6542  t-loss:0.0316, loss-lb:0.0270, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:33:22.949] iteration:6543  t-loss:0.0940, loss-lb:0.0920, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:33:23.318] iteration:6544  t-loss:0.0304, loss-lb:0.0201, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:33:23.699] iteration:6545  t-loss:0.0537, loss-lb:0.0512, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:33:24.078] iteration:6546  t-loss:0.0484, loss-lb:0.0435, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:33:24.458] iteration:6547  t-loss:0.0433, loss-lb:0.0410, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:33:24.841] iteration:6548  t-loss:0.0379, loss-lb:0.0312, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:33:25.222] iteration:6549  t-loss:0.0314, loss-lb:0.0275, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:33:25.594] iteration:6550  t-loss:0.0266, loss-lb:0.0209, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:33:25.976] iteration:6551  t-loss:0.0652, loss-lb:0.0574, loss-ulb:0.0039, weight:2.00, lr:0.0006
[00:33:26.351] iteration:6552  t-loss:0.0167, loss-lb:0.0149, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:33:26.728] iteration:6553  t-loss:0.0408, loss-lb:0.0134, loss-ulb:0.0137, weight:2.00, lr:0.0006
[00:33:27.120] iteration:6554  t-loss:0.0271, loss-lb:0.0173, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:33:27.510] iteration:6555  t-loss:0.0432, loss-lb:0.0371, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:33:27.885] iteration:6556  t-loss:0.0216, loss-lb:0.0148, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:33:28.257] iteration:6557  t-loss:0.0204, loss-lb:0.0152, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:33:28.625] iteration:6558  t-loss:0.0306, loss-lb:0.0186, loss-ulb:0.0060, weight:2.00, lr:0.0006
[00:33:29.001] iteration:6559  t-loss:0.0219, loss-lb:0.0159, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:33:29.382] iteration:6560  t-loss:0.0432, loss-lb:0.0278, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:33:29.761] iteration:6561  t-loss:0.0518, loss-lb:0.0414, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:33:30.137] iteration:6562  t-loss:0.0263, loss-lb:0.0243, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:33:30.512] iteration:6563  t-loss:0.0208, loss-lb:0.0144, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:33:30.887] iteration:6564  t-loss:0.0269, loss-lb:0.0167, loss-ulb:0.0051, weight:2.00, lr:0.0006
[00:33:31.268] iteration:6565  t-loss:0.0412, loss-lb:0.0358, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:33:31.643] iteration:6566  t-loss:0.0372, loss-lb:0.0187, loss-ulb:0.0093, weight:2.00, lr:0.0006
[00:33:32.017] iteration:6567  t-loss:0.0688, loss-lb:0.0348, loss-ulb:0.0170, weight:2.00, lr:0.0006
[00:33:32.395] iteration:6568  t-loss:0.0773, loss-lb:0.0195, loss-ulb:0.0289, weight:2.00, lr:0.0006
[00:33:32.771] iteration:6569  t-loss:0.0344, loss-lb:0.0168, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:33:33.144] iteration:6570  t-loss:0.0200, loss-lb:0.0175, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:33:33.518] iteration:6571  t-loss:0.0243, loss-lb:0.0181, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:33:33.893] iteration:6572  t-loss:0.0249, loss-lb:0.0152, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:33:34.267] iteration:6573  t-loss:0.0243, loss-lb:0.0193, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:33:34.641] iteration:6574  t-loss:0.0249, loss-lb:0.0194, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:34:34.969] iteration 6574 : dice_score: 0.882202 best_dice: 0.889700
[00:34:34.969]  <<Test>> - Ep:172  - Dice-S/T:87.15/88.22, Best-S:88.23, Best-T:88.97
[00:34:34.969]           - AvgLoss(lb/ulb/all):0.03/0.01/0.03
[00:34:36.068] iteration:6575  t-loss:0.0288, loss-lb:0.0210, loss-ulb:0.0039, weight:2.00, lr:0.0006
[00:34:36.448] iteration:6576  t-loss:0.0215, loss-lb:0.0178, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:34:36.830] iteration:6577  t-loss:0.0424, loss-lb:0.0382, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:34:37.211] iteration:6578  t-loss:0.0980, loss-lb:0.0948, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:34:37.586] iteration:6579  t-loss:0.1052, loss-lb:0.0494, loss-ulb:0.0279, weight:2.00, lr:0.0006
[00:34:37.958] iteration:6580  t-loss:0.0183, loss-lb:0.0140, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:34:38.346] iteration:6581  t-loss:0.0258, loss-lb:0.0217, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:34:38.739] iteration:6582  t-loss:0.0432, loss-lb:0.0163, loss-ulb:0.0134, weight:2.00, lr:0.0006
[00:34:39.131] iteration:6583  t-loss:0.0310, loss-lb:0.0169, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:34:39.518] iteration:6584  t-loss:0.0309, loss-lb:0.0195, loss-ulb:0.0057, weight:2.00, lr:0.0006
[00:34:39.903] iteration:6585  t-loss:0.0972, loss-lb:0.0433, loss-ulb:0.0269, weight:2.00, lr:0.0006
[00:34:40.284] iteration:6586  t-loss:0.0415, loss-lb:0.0308, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:34:40.668] iteration:6587  t-loss:0.0188, loss-lb:0.0144, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:34:41.055] iteration:6588  t-loss:0.0376, loss-lb:0.0245, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:34:41.441] iteration:6589  t-loss:0.0248, loss-lb:0.0225, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:34:41.820] iteration:6590  t-loss:0.0263, loss-lb:0.0211, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:34:42.205] iteration:6591  t-loss:0.0442, loss-lb:0.0240, loss-ulb:0.0101, weight:2.00, lr:0.0006
[00:34:42.583] iteration:6592  t-loss:0.0264, loss-lb:0.0203, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:34:42.963] iteration:6593  t-loss:0.0358, loss-lb:0.0288, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:34:43.347] iteration:6594  t-loss:0.0337, loss-lb:0.0229, loss-ulb:0.0054, weight:2.00, lr:0.0006
[00:34:43.729] iteration:6595  t-loss:0.0532, loss-lb:0.0185, loss-ulb:0.0173, weight:2.00, lr:0.0006
[00:34:44.106] iteration:6596  t-loss:0.0216, loss-lb:0.0177, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:34:44.490] iteration:6597  t-loss:0.0288, loss-lb:0.0231, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:34:44.873] iteration:6598  t-loss:0.0626, loss-lb:0.0211, loss-ulb:0.0208, weight:2.00, lr:0.0006
[00:34:45.259] iteration:6599  t-loss:0.0435, loss-lb:0.0264, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:34:45.642] iteration:6600  t-loss:0.0477, loss-lb:0.0362, loss-ulb:0.0057, weight:2.00, lr:0.0006
[00:34:46.022] iteration:6601  t-loss:0.0404, loss-lb:0.0375, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:34:46.402] iteration:6602  t-loss:0.0238, loss-lb:0.0210, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:34:46.784] iteration:6603  t-loss:0.0412, loss-lb:0.0277, loss-ulb:0.0067, weight:2.00, lr:0.0006
[00:34:47.163] iteration:6604  t-loss:0.0451, loss-lb:0.0137, loss-ulb:0.0157, weight:2.00, lr:0.0006
[00:34:47.545] iteration:6605  t-loss:0.0481, loss-lb:0.0219, loss-ulb:0.0131, weight:2.00, lr:0.0006
[00:34:47.923] iteration:6606  t-loss:0.0282, loss-lb:0.0177, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:34:48.300] iteration:6607  t-loss:0.0409, loss-lb:0.0258, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:34:48.675] iteration:6608  t-loss:0.0341, loss-lb:0.0275, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:34:49.054] iteration:6609  t-loss:0.0332, loss-lb:0.0308, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:34:49.432] iteration:6610  t-loss:0.0457, loss-lb:0.0359, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:34:49.810] iteration:6611  t-loss:0.0407, loss-lb:0.0259, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:34:50.191] iteration:6612  t-loss:0.0465, loss-lb:0.0378, loss-ulb:0.0044, weight:2.00, lr:0.0006
[00:34:51.387] iteration:6613  t-loss:0.0218, loss-lb:0.0141, loss-ulb:0.0039, weight:2.00, lr:0.0006
[00:34:51.776] iteration:6614  t-loss:0.0766, loss-lb:0.0723, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:34:52.161] iteration:6615  t-loss:0.0451, loss-lb:0.0326, loss-ulb:0.0063, weight:2.00, lr:0.0006
[00:34:52.539] iteration:6616  t-loss:0.0354, loss-lb:0.0205, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:34:52.918] iteration:6617  t-loss:0.0374, loss-lb:0.0253, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:34:53.293] iteration:6618  t-loss:0.0217, loss-lb:0.0147, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:34:53.669] iteration:6619  t-loss:0.0318, loss-lb:0.0269, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:34:54.051] iteration:6620  t-loss:0.0421, loss-lb:0.0317, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:34:54.428] iteration:6621  t-loss:0.0350, loss-lb:0.0315, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:34:54.807] iteration:6622  t-loss:0.0215, loss-lb:0.0179, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:34:55.194] iteration:6623  t-loss:0.0579, loss-lb:0.0378, loss-ulb:0.0100, weight:2.00, lr:0.0006
[00:34:55.576] iteration:6624  t-loss:0.0236, loss-lb:0.0194, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:34:55.958] iteration:6625  t-loss:0.0304, loss-lb:0.0208, loss-ulb:0.0048, weight:2.00, lr:0.0006
[00:34:56.340] iteration:6626  t-loss:0.0460, loss-lb:0.0209, loss-ulb:0.0126, weight:2.00, lr:0.0006
[00:34:56.720] iteration:6627  t-loss:0.0188, loss-lb:0.0152, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:34:57.103] iteration:6628  t-loss:0.0466, loss-lb:0.0285, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:34:57.483] iteration:6629  t-loss:0.0557, loss-lb:0.0193, loss-ulb:0.0182, weight:2.00, lr:0.0006
[00:34:57.873] iteration:6630  t-loss:0.0345, loss-lb:0.0197, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:34:58.260] iteration:6631  t-loss:0.0406, loss-lb:0.0372, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:34:58.645] iteration:6632  t-loss:0.0247, loss-lb:0.0165, loss-ulb:0.0041, weight:2.00, lr:0.0006
[00:34:59.030] iteration:6633  t-loss:0.0438, loss-lb:0.0331, loss-ulb:0.0054, weight:2.00, lr:0.0006
[00:34:59.410] iteration:6634  t-loss:0.0208, loss-lb:0.0161, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:34:59.794] iteration:6635  t-loss:0.0331, loss-lb:0.0298, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:35:00.179] iteration:6636  t-loss:0.0424, loss-lb:0.0275, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:35:00.565] iteration:6637  t-loss:0.0523, loss-lb:0.0282, loss-ulb:0.0121, weight:2.00, lr:0.0006
[00:35:00.952] iteration:6638  t-loss:0.0646, loss-lb:0.0230, loss-ulb:0.0208, weight:2.00, lr:0.0006
[00:35:01.333] iteration:6639  t-loss:0.0517, loss-lb:0.0471, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:35:01.720] iteration:6640  t-loss:0.0282, loss-lb:0.0243, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:35:02.110] iteration:6641  t-loss:0.0534, loss-lb:0.0394, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:35:02.490] iteration:6642  t-loss:0.0295, loss-lb:0.0185, loss-ulb:0.0055, weight:2.00, lr:0.0006
[00:35:02.873] iteration:6643  t-loss:0.0579, loss-lb:0.0429, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:35:03.258] iteration:6644  t-loss:0.0382, loss-lb:0.0167, loss-ulb:0.0108, weight:2.00, lr:0.0006
[00:35:03.637] iteration:6645  t-loss:0.0535, loss-lb:0.0167, loss-ulb:0.0184, weight:2.00, lr:0.0006
[00:35:04.016] iteration:6646  t-loss:0.0300, loss-lb:0.0189, loss-ulb:0.0056, weight:2.00, lr:0.0006
[00:35:04.399] iteration:6647  t-loss:0.0675, loss-lb:0.0514, loss-ulb:0.0081, weight:2.00, lr:0.0006
[00:35:04.782] iteration:6648  t-loss:0.0528, loss-lb:0.0352, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:35:05.159] iteration:6649  t-loss:0.0278, loss-lb:0.0184, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:35:05.535] iteration:6650  t-loss:0.0704, loss-lb:0.0569, loss-ulb:0.0068, weight:2.00, lr:0.0006
[00:35:06.865] iteration:6651  t-loss:0.0240, loss-lb:0.0195, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:35:07.257] iteration:6652  t-loss:0.0242, loss-lb:0.0218, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:35:07.656] iteration:6653  t-loss:0.0288, loss-lb:0.0248, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:35:08.033] iteration:6654  t-loss:0.0409, loss-lb:0.0178, loss-ulb:0.0116, weight:2.00, lr:0.0006
[00:35:08.423] iteration:6655  t-loss:0.0382, loss-lb:0.0229, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:35:08.814] iteration:6656  t-loss:0.0307, loss-lb:0.0147, loss-ulb:0.0080, weight:2.00, lr:0.0006
[00:35:09.203] iteration:6657  t-loss:0.0390, loss-lb:0.0212, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:35:09.588] iteration:6658  t-loss:0.0448, loss-lb:0.0409, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:35:09.969] iteration:6659  t-loss:0.0234, loss-lb:0.0197, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:35:10.347] iteration:6660  t-loss:0.0219, loss-lb:0.0180, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:35:10.729] iteration:6661  t-loss:0.0452, loss-lb:0.0289, loss-ulb:0.0082, weight:2.00, lr:0.0006
[00:35:11.114] iteration:6662  t-loss:0.0542, loss-lb:0.0300, loss-ulb:0.0121, weight:2.00, lr:0.0006
[00:35:11.493] iteration:6663  t-loss:0.0355, loss-lb:0.0189, loss-ulb:0.0083, weight:2.00, lr:0.0006
[00:35:11.878] iteration:6664  t-loss:0.0669, loss-lb:0.0377, loss-ulb:0.0146, weight:2.00, lr:0.0006
[00:35:12.258] iteration:6665  t-loss:0.0589, loss-lb:0.0522, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:35:12.639] iteration:6666  t-loss:0.0557, loss-lb:0.0196, loss-ulb:0.0180, weight:2.00, lr:0.0006
[00:35:13.026] iteration:6667  t-loss:0.0392, loss-lb:0.0286, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:35:13.411] iteration:6668  t-loss:0.0838, loss-lb:0.0352, loss-ulb:0.0243, weight:2.00, lr:0.0006
[00:35:13.797] iteration:6669  t-loss:0.0401, loss-lb:0.0175, loss-ulb:0.0113, weight:2.00, lr:0.0006
[00:35:14.184] iteration:6670  t-loss:0.0330, loss-lb:0.0158, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:35:14.562] iteration:6671  t-loss:0.0203, loss-lb:0.0160, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:35:14.941] iteration:6672  t-loss:0.0452, loss-lb:0.0148, loss-ulb:0.0152, weight:2.00, lr:0.0006
[00:35:15.325] iteration:6673  t-loss:0.0278, loss-lb:0.0157, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:35:15.717] iteration:6674  t-loss:0.0599, loss-lb:0.0306, loss-ulb:0.0147, weight:2.00, lr:0.0006
[00:35:16.098] iteration:6675  t-loss:0.0464, loss-lb:0.0141, loss-ulb:0.0162, weight:2.00, lr:0.0006
[00:35:16.483] iteration:6676  t-loss:0.0618, loss-lb:0.0386, loss-ulb:0.0116, weight:2.00, lr:0.0006
[00:35:16.862] iteration:6677  t-loss:0.0427, loss-lb:0.0197, loss-ulb:0.0115, weight:2.00, lr:0.0006
[00:35:17.245] iteration:6678  t-loss:0.0519, loss-lb:0.0310, loss-ulb:0.0104, weight:2.00, lr:0.0006
[00:35:17.635] iteration:6679  t-loss:0.0413, loss-lb:0.0393, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:35:18.017] iteration:6680  t-loss:0.0174, loss-lb:0.0145, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:35:18.397] iteration:6681  t-loss:0.0589, loss-lb:0.0359, loss-ulb:0.0115, weight:2.00, lr:0.0006
[00:35:18.774] iteration:6682  t-loss:0.0689, loss-lb:0.0373, loss-ulb:0.0158, weight:2.00, lr:0.0006
[00:35:19.149] iteration:6683  t-loss:0.0377, loss-lb:0.0165, loss-ulb:0.0106, weight:2.00, lr:0.0006
[00:35:19.530] iteration:6684  t-loss:0.0600, loss-lb:0.0456, loss-ulb:0.0072, weight:2.00, lr:0.0006
[00:35:19.908] iteration:6685  t-loss:0.0330, loss-lb:0.0293, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:35:20.285] iteration:6686  t-loss:0.0358, loss-lb:0.0233, loss-ulb:0.0063, weight:2.00, lr:0.0006
[00:35:20.661] iteration:6687  t-loss:0.0183, loss-lb:0.0155, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:35:21.039] iteration:6688  t-loss:0.0399, loss-lb:0.0201, loss-ulb:0.0099, weight:2.00, lr:0.0006
[00:35:22.484] iteration:6689  t-loss:0.0535, loss-lb:0.0206, loss-ulb:0.0164, weight:2.00, lr:0.0006
[00:35:22.877] iteration:6690  t-loss:0.0400, loss-lb:0.0364, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:35:23.272] iteration:6691  t-loss:0.0217, loss-lb:0.0175, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:35:23.632] iteration:6692  t-loss:0.0223, loss-lb:0.0152, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:35:24.014] iteration:6693  t-loss:0.0475, loss-lb:0.0434, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:35:24.395] iteration:6694  t-loss:0.0406, loss-lb:0.0370, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:35:24.778] iteration:6695  t-loss:0.0284, loss-lb:0.0211, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:35:25.160] iteration:6696  t-loss:0.0338, loss-lb:0.0177, loss-ulb:0.0080, weight:2.00, lr:0.0006
[00:35:25.540] iteration:6697  t-loss:0.0469, loss-lb:0.0254, loss-ulb:0.0108, weight:2.00, lr:0.0006
[00:35:25.920] iteration:6698  t-loss:0.0310, loss-lb:0.0170, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:35:26.301] iteration:6699  t-loss:0.0605, loss-lb:0.0168, loss-ulb:0.0218, weight:2.00, lr:0.0006
[00:35:26.682] iteration:6700  t-loss:0.0320, loss-lb:0.0225, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:35:27.068] iteration:6701  t-loss:0.0512, loss-lb:0.0179, loss-ulb:0.0166, weight:2.00, lr:0.0006
[00:35:27.447] iteration:6702  t-loss:0.0398, loss-lb:0.0272, loss-ulb:0.0063, weight:2.00, lr:0.0006
[00:35:27.825] iteration:6703  t-loss:0.1196, loss-lb:0.0425, loss-ulb:0.0386, weight:2.00, lr:0.0006
[00:35:28.206] iteration:6704  t-loss:0.0324, loss-lb:0.0269, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:35:28.604] iteration:6705  t-loss:0.0476, loss-lb:0.0293, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:35:28.988] iteration:6706  t-loss:0.0478, loss-lb:0.0409, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:35:29.369] iteration:6707  t-loss:0.0438, loss-lb:0.0216, loss-ulb:0.0111, weight:2.00, lr:0.0006
[00:35:29.752] iteration:6708  t-loss:0.0347, loss-lb:0.0313, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:35:30.133] iteration:6709  t-loss:0.0781, loss-lb:0.0501, loss-ulb:0.0140, weight:2.00, lr:0.0006
[00:35:30.519] iteration:6710  t-loss:0.0386, loss-lb:0.0281, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:35:30.901] iteration:6711  t-loss:0.0315, loss-lb:0.0186, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:35:31.285] iteration:6712  t-loss:0.0220, loss-lb:0.0193, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:35:31.666] iteration:6713  t-loss:0.0293, loss-lb:0.0145, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:35:32.050] iteration:6714  t-loss:0.0767, loss-lb:0.0732, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:35:32.431] iteration:6715  t-loss:0.0547, loss-lb:0.0352, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:35:32.834] iteration:6716  t-loss:0.0551, loss-lb:0.0352, loss-ulb:0.0099, weight:2.00, lr:0.0006
[00:35:33.246] iteration:6717  t-loss:0.0962, loss-lb:0.0630, loss-ulb:0.0166, weight:2.00, lr:0.0006
[00:35:33.638] iteration:6718  t-loss:0.0365, loss-lb:0.0305, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:35:34.012] iteration:6719  t-loss:0.0273, loss-lb:0.0210, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:35:34.387] iteration:6720  t-loss:0.0433, loss-lb:0.0196, loss-ulb:0.0118, weight:2.00, lr:0.0006
[00:35:34.763] iteration:6721  t-loss:0.0474, loss-lb:0.0169, loss-ulb:0.0153, weight:2.00, lr:0.0006
[00:35:35.137] iteration:6722  t-loss:0.0232, loss-lb:0.0204, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:35:35.519] iteration:6723  t-loss:0.0526, loss-lb:0.0295, loss-ulb:0.0115, weight:2.00, lr:0.0006
[00:35:35.890] iteration:6724  t-loss:0.0323, loss-lb:0.0301, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:35:36.267] iteration:6725  t-loss:0.0389, loss-lb:0.0201, loss-ulb:0.0094, weight:2.00, lr:0.0006
[00:35:36.644] iteration:6726  t-loss:0.0787, loss-lb:0.0571, loss-ulb:0.0108, weight:2.00, lr:0.0006
[00:36:38.548] iteration 6726 : dice_score: 0.888571 best_dice: 0.889700
[00:36:38.548]  <<Test>> - Ep:176  - Dice-S/T:85.59/88.86, Best-S:88.23, Best-T:88.97
[00:36:38.548]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:36:39.738] iteration:6727  t-loss:0.0467, loss-lb:0.0223, loss-ulb:0.0122, weight:2.00, lr:0.0006
[00:36:40.129] iteration:6728  t-loss:0.0457, loss-lb:0.0174, loss-ulb:0.0142, weight:2.00, lr:0.0006
[00:36:40.507] iteration:6729  t-loss:0.0748, loss-lb:0.0211, loss-ulb:0.0269, weight:2.00, lr:0.0006
[00:36:40.882] iteration:6730  t-loss:0.0237, loss-lb:0.0196, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:36:41.258] iteration:6731  t-loss:0.0408, loss-lb:0.0362, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:36:41.633] iteration:6732  t-loss:0.0378, loss-lb:0.0234, loss-ulb:0.0072, weight:2.00, lr:0.0006
[00:36:42.009] iteration:6733  t-loss:0.0318, loss-lb:0.0294, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:36:42.386] iteration:6734  t-loss:0.0688, loss-lb:0.0434, loss-ulb:0.0127, weight:2.00, lr:0.0006
[00:36:42.765] iteration:6735  t-loss:0.0343, loss-lb:0.0164, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:36:43.140] iteration:6736  t-loss:0.0487, loss-lb:0.0170, loss-ulb:0.0158, weight:2.00, lr:0.0006
[00:36:43.513] iteration:6737  t-loss:0.0256, loss-lb:0.0215, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:36:43.905] iteration:6738  t-loss:0.0459, loss-lb:0.0248, loss-ulb:0.0105, weight:2.00, lr:0.0006
[00:36:44.315] iteration:6739  t-loss:0.0654, loss-lb:0.0373, loss-ulb:0.0140, weight:2.00, lr:0.0006
[00:36:44.713] iteration:6740  t-loss:0.0269, loss-lb:0.0178, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:36:45.098] iteration:6741  t-loss:0.0330, loss-lb:0.0187, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:36:45.478] iteration:6742  t-loss:0.0286, loss-lb:0.0204, loss-ulb:0.0041, weight:2.00, lr:0.0006
[00:36:45.858] iteration:6743  t-loss:0.0246, loss-lb:0.0200, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:36:46.239] iteration:6744  t-loss:0.0276, loss-lb:0.0174, loss-ulb:0.0051, weight:2.00, lr:0.0006
[00:36:46.622] iteration:6745  t-loss:0.0315, loss-lb:0.0217, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:36:47.001] iteration:6746  t-loss:0.0499, loss-lb:0.0177, loss-ulb:0.0161, weight:2.00, lr:0.0006
[00:36:47.385] iteration:6747  t-loss:0.0546, loss-lb:0.0296, loss-ulb:0.0125, weight:2.00, lr:0.0006
[00:36:47.765] iteration:6748  t-loss:0.0300, loss-lb:0.0193, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:36:48.153] iteration:6749  t-loss:0.0381, loss-lb:0.0352, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:36:48.553] iteration:6750  t-loss:0.0510, loss-lb:0.0130, loss-ulb:0.0190, weight:2.00, lr:0.0006
[00:36:48.958] iteration:6751  t-loss:0.0251, loss-lb:0.0168, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:36:49.355] iteration:6752  t-loss:0.0477, loss-lb:0.0286, loss-ulb:0.0095, weight:2.00, lr:0.0006
[00:36:49.743] iteration:6753  t-loss:0.0411, loss-lb:0.0166, loss-ulb:0.0123, weight:2.00, lr:0.0006
[00:36:50.126] iteration:6754  t-loss:0.0296, loss-lb:0.0263, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:36:50.510] iteration:6755  t-loss:0.0639, loss-lb:0.0428, loss-ulb:0.0106, weight:2.00, lr:0.0006
[00:36:50.904] iteration:6756  t-loss:0.0333, loss-lb:0.0262, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:36:51.284] iteration:6757  t-loss:0.0450, loss-lb:0.0190, loss-ulb:0.0130, weight:2.00, lr:0.0006
[00:36:51.662] iteration:6758  t-loss:0.0247, loss-lb:0.0140, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:36:52.038] iteration:6759  t-loss:0.0309, loss-lb:0.0277, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:36:52.420] iteration:6760  t-loss:0.0416, loss-lb:0.0394, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:36:52.804] iteration:6761  t-loss:0.0636, loss-lb:0.0380, loss-ulb:0.0128, weight:2.00, lr:0.0006
[00:36:53.184] iteration:6762  t-loss:0.0357, loss-lb:0.0171, loss-ulb:0.0093, weight:2.00, lr:0.0006
[00:36:53.565] iteration:6763  t-loss:0.0614, loss-lb:0.0309, loss-ulb:0.0153, weight:2.00, lr:0.0006
[00:36:53.943] iteration:6764  t-loss:0.0302, loss-lb:0.0276, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:36:55.416] iteration:6765  t-loss:0.0608, loss-lb:0.0454, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:36:55.824] iteration:6766  t-loss:0.0419, loss-lb:0.0356, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:36:56.210] iteration:6767  t-loss:0.0247, loss-lb:0.0197, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:36:56.590] iteration:6768  t-loss:0.0584, loss-lb:0.0481, loss-ulb:0.0051, weight:2.00, lr:0.0006
[00:36:56.970] iteration:6769  t-loss:0.0236, loss-lb:0.0142, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:36:57.345] iteration:6770  t-loss:0.0613, loss-lb:0.0249, loss-ulb:0.0182, weight:2.00, lr:0.0006
[00:36:57.722] iteration:6771  t-loss:0.0384, loss-lb:0.0359, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:36:58.102] iteration:6772  t-loss:0.0500, loss-lb:0.0358, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:36:58.477] iteration:6773  t-loss:0.0301, loss-lb:0.0259, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:36:58.856] iteration:6774  t-loss:0.0659, loss-lb:0.0564, loss-ulb:0.0048, weight:2.00, lr:0.0006
[00:36:59.232] iteration:6775  t-loss:0.0537, loss-lb:0.0170, loss-ulb:0.0183, weight:2.00, lr:0.0006
[00:36:59.621] iteration:6776  t-loss:0.0467, loss-lb:0.0258, loss-ulb:0.0105, weight:2.00, lr:0.0006
[00:37:00.014] iteration:6777  t-loss:0.0199, loss-lb:0.0167, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:37:00.399] iteration:6778  t-loss:0.0457, loss-lb:0.0429, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:37:00.786] iteration:6779  t-loss:0.0508, loss-lb:0.0183, loss-ulb:0.0163, weight:2.00, lr:0.0006
[00:37:01.170] iteration:6780  t-loss:0.0482, loss-lb:0.0407, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:37:01.556] iteration:6781  t-loss:0.0375, loss-lb:0.0340, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:37:01.945] iteration:6782  t-loss:0.0306, loss-lb:0.0273, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:37:02.333] iteration:6783  t-loss:0.0308, loss-lb:0.0263, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:37:02.713] iteration:6784  t-loss:0.0355, loss-lb:0.0298, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:37:03.093] iteration:6785  t-loss:0.0385, loss-lb:0.0353, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:37:03.476] iteration:6786  t-loss:0.0258, loss-lb:0.0154, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:37:03.861] iteration:6787  t-loss:0.0647, loss-lb:0.0578, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:37:04.240] iteration:6788  t-loss:0.0227, loss-lb:0.0182, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:37:04.619] iteration:6789  t-loss:0.0211, loss-lb:0.0151, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:37:05.008] iteration:6790  t-loss:0.0521, loss-lb:0.0353, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:37:05.389] iteration:6791  t-loss:0.0300, loss-lb:0.0151, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:37:05.767] iteration:6792  t-loss:0.0206, loss-lb:0.0175, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:37:06.151] iteration:6793  t-loss:0.0631, loss-lb:0.0139, loss-ulb:0.0246, weight:2.00, lr:0.0006
[00:37:06.532] iteration:6794  t-loss:0.0332, loss-lb:0.0234, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:37:06.910] iteration:6795  t-loss:0.0194, loss-lb:0.0157, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:37:07.290] iteration:6796  t-loss:0.0338, loss-lb:0.0201, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:37:07.671] iteration:6797  t-loss:0.0499, loss-lb:0.0374, loss-ulb:0.0062, weight:2.00, lr:0.0006
[00:37:08.053] iteration:6798  t-loss:0.0533, loss-lb:0.0266, loss-ulb:0.0134, weight:2.00, lr:0.0006
[00:37:08.432] iteration:6799  t-loss:0.0461, loss-lb:0.0314, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:37:08.807] iteration:6800  t-loss:0.0313, loss-lb:0.0176, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:37:09.183] iteration:6801  t-loss:0.0343, loss-lb:0.0177, loss-ulb:0.0083, weight:2.00, lr:0.0006
[00:37:09.563] iteration:6802  t-loss:0.0590, loss-lb:0.0389, loss-ulb:0.0101, weight:2.00, lr:0.0006
[00:37:10.855] iteration:6803  t-loss:0.0632, loss-lb:0.0478, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:37:11.252] iteration:6804  t-loss:0.0501, loss-lb:0.0355, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:37:11.635] iteration:6805  t-loss:0.0429, loss-lb:0.0276, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:37:12.020] iteration:6806  t-loss:0.0330, loss-lb:0.0158, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:37:12.404] iteration:6807  t-loss:0.0511, loss-lb:0.0320, loss-ulb:0.0095, weight:2.00, lr:0.0006
[00:37:12.786] iteration:6808  t-loss:0.0176, loss-lb:0.0158, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:37:13.171] iteration:6809  t-loss:0.0483, loss-lb:0.0431, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:37:13.554] iteration:6810  t-loss:0.0422, loss-lb:0.0268, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:37:13.936] iteration:6811  t-loss:0.0193, loss-lb:0.0164, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:37:14.314] iteration:6812  t-loss:0.0336, loss-lb:0.0176, loss-ulb:0.0080, weight:2.00, lr:0.0006
[00:37:14.697] iteration:6813  t-loss:0.0387, loss-lb:0.0165, loss-ulb:0.0111, weight:2.00, lr:0.0006
[00:37:15.078] iteration:6814  t-loss:0.0317, loss-lb:0.0203, loss-ulb:0.0057, weight:2.00, lr:0.0006
[00:37:15.464] iteration:6815  t-loss:0.0324, loss-lb:0.0266, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:37:15.845] iteration:6816  t-loss:0.0300, loss-lb:0.0262, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:37:16.237] iteration:6817  t-loss:0.0308, loss-lb:0.0201, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:37:16.621] iteration:6818  t-loss:0.0406, loss-lb:0.0157, loss-ulb:0.0125, weight:2.00, lr:0.0006
[00:37:17.001] iteration:6819  t-loss:0.0415, loss-lb:0.0386, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:37:17.385] iteration:6820  t-loss:0.0357, loss-lb:0.0265, loss-ulb:0.0046, weight:2.00, lr:0.0006
[00:37:17.765] iteration:6821  t-loss:0.0415, loss-lb:0.0274, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:37:18.144] iteration:6822  t-loss:0.0382, loss-lb:0.0330, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:37:18.526] iteration:6823  t-loss:0.0303, loss-lb:0.0137, loss-ulb:0.0083, weight:2.00, lr:0.0006
[00:37:18.914] iteration:6824  t-loss:0.0486, loss-lb:0.0261, loss-ulb:0.0112, weight:2.00, lr:0.0006
[00:37:19.303] iteration:6825  t-loss:0.0325, loss-lb:0.0173, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:37:19.690] iteration:6826  t-loss:0.0299, loss-lb:0.0160, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:37:20.077] iteration:6827  t-loss:0.0289, loss-lb:0.0183, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:37:20.457] iteration:6828  t-loss:0.0201, loss-lb:0.0172, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:37:20.841] iteration:6829  t-loss:0.0310, loss-lb:0.0188, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:37:21.229] iteration:6830  t-loss:0.0403, loss-lb:0.0292, loss-ulb:0.0056, weight:2.00, lr:0.0006
[00:37:21.624] iteration:6831  t-loss:0.0342, loss-lb:0.0317, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:37:22.009] iteration:6832  t-loss:0.0406, loss-lb:0.0388, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:37:22.386] iteration:6833  t-loss:0.0335, loss-lb:0.0306, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:37:22.764] iteration:6834  t-loss:0.0417, loss-lb:0.0178, loss-ulb:0.0120, weight:2.00, lr:0.0006
[00:37:23.141] iteration:6835  t-loss:0.0281, loss-lb:0.0150, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:37:23.515] iteration:6836  t-loss:0.0329, loss-lb:0.0260, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:37:23.890] iteration:6837  t-loss:0.0380, loss-lb:0.0199, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:37:24.267] iteration:6838  t-loss:0.0205, loss-lb:0.0169, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:37:24.647] iteration:6839  t-loss:0.0340, loss-lb:0.0198, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:37:25.021] iteration:6840  t-loss:0.0182, loss-lb:0.0136, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:37:26.258] iteration:6841  t-loss:0.0436, loss-lb:0.0254, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:37:26.664] iteration:6842  t-loss:0.0523, loss-lb:0.0343, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:37:27.051] iteration:6843  t-loss:0.0608, loss-lb:0.0301, loss-ulb:0.0154, weight:2.00, lr:0.0006
[00:37:27.431] iteration:6844  t-loss:0.0444, loss-lb:0.0385, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:37:27.820] iteration:6845  t-loss:0.0477, loss-lb:0.0347, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:37:28.199] iteration:6846  t-loss:0.0186, loss-lb:0.0136, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:37:28.584] iteration:6847  t-loss:0.0579, loss-lb:0.0289, loss-ulb:0.0145, weight:2.00, lr:0.0006
[00:37:28.973] iteration:6848  t-loss:0.0716, loss-lb:0.0409, loss-ulb:0.0153, weight:2.00, lr:0.0006
[00:37:29.353] iteration:6849  t-loss:0.0439, loss-lb:0.0287, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:37:29.747] iteration:6850  t-loss:0.0502, loss-lb:0.0307, loss-ulb:0.0098, weight:2.00, lr:0.0006
[00:37:30.128] iteration:6851  t-loss:0.0224, loss-lb:0.0165, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:37:30.515] iteration:6852  t-loss:0.0336, loss-lb:0.0176, loss-ulb:0.0080, weight:2.00, lr:0.0006
[00:37:30.900] iteration:6853  t-loss:0.0394, loss-lb:0.0337, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:37:31.283] iteration:6854  t-loss:0.0217, loss-lb:0.0180, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:37:31.665] iteration:6855  t-loss:0.0343, loss-lb:0.0300, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:37:32.049] iteration:6856  t-loss:0.0422, loss-lb:0.0397, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:37:32.430] iteration:6857  t-loss:0.0426, loss-lb:0.0187, loss-ulb:0.0120, weight:2.00, lr:0.0006
[00:37:32.815] iteration:6858  t-loss:0.0359, loss-lb:0.0180, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:37:33.206] iteration:6859  t-loss:0.0326, loss-lb:0.0241, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:37:33.586] iteration:6860  t-loss:0.0263, loss-lb:0.0128, loss-ulb:0.0067, weight:2.00, lr:0.0006
[00:37:33.963] iteration:6861  t-loss:0.0198, loss-lb:0.0161, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:37:34.345] iteration:6862  t-loss:0.0293, loss-lb:0.0179, loss-ulb:0.0057, weight:2.00, lr:0.0006
[00:37:34.731] iteration:6863  t-loss:0.0227, loss-lb:0.0183, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:37:35.121] iteration:6864  t-loss:0.0541, loss-lb:0.0384, loss-ulb:0.0079, weight:2.00, lr:0.0006
[00:37:35.507] iteration:6865  t-loss:0.0648, loss-lb:0.0495, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:37:35.890] iteration:6866  t-loss:0.0244, loss-lb:0.0133, loss-ulb:0.0055, weight:2.00, lr:0.0006
[00:37:36.288] iteration:6867  t-loss:0.0475, loss-lb:0.0223, loss-ulb:0.0126, weight:2.00, lr:0.0006
[00:37:36.677] iteration:6868  t-loss:0.0854, loss-lb:0.0182, loss-ulb:0.0336, weight:2.00, lr:0.0006
[00:37:37.063] iteration:6869  t-loss:0.0264, loss-lb:0.0149, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:37:37.443] iteration:6870  t-loss:0.0222, loss-lb:0.0186, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:37:37.822] iteration:6871  t-loss:0.0611, loss-lb:0.0275, loss-ulb:0.0168, weight:2.00, lr:0.0006
[00:37:38.200] iteration:6872  t-loss:0.0624, loss-lb:0.0368, loss-ulb:0.0128, weight:2.00, lr:0.0006
[00:37:38.582] iteration:6873  t-loss:0.0260, loss-lb:0.0112, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:37:38.962] iteration:6874  t-loss:0.0716, loss-lb:0.0159, loss-ulb:0.0278, weight:2.00, lr:0.0006
[00:37:39.347] iteration:6875  t-loss:0.0533, loss-lb:0.0365, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:37:39.723] iteration:6876  t-loss:0.0432, loss-lb:0.0214, loss-ulb:0.0109, weight:2.00, lr:0.0006
[00:37:40.096] iteration:6877  t-loss:0.0322, loss-lb:0.0197, loss-ulb:0.0062, weight:2.00, lr:0.0006
[00:37:40.479] iteration:6878  t-loss:0.0519, loss-lb:0.0190, loss-ulb:0.0165, weight:2.00, lr:0.0006
[00:38:42.078] iteration 6878 : dice_score: 0.889106 best_dice: 0.889700
[00:38:42.078]  <<Test>> - Ep:180  - Dice-S/T:88.42/88.91, Best-S:88.42, Best-T:88.97
[00:38:42.079]           - AvgLoss(lb/ulb/all):0.03/0.01/0.04
[00:38:43.336] iteration:6879  t-loss:0.0373, loss-lb:0.0275, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:38:43.732] iteration:6880  t-loss:0.0280, loss-lb:0.0248, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:38:44.118] iteration:6881  t-loss:0.0239, loss-lb:0.0155, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:38:44.501] iteration:6882  t-loss:0.0482, loss-lb:0.0308, loss-ulb:0.0087, weight:2.00, lr:0.0006
[00:38:44.881] iteration:6883  t-loss:0.0368, loss-lb:0.0210, loss-ulb:0.0079, weight:2.00, lr:0.0006
[00:38:45.265] iteration:6884  t-loss:0.0543, loss-lb:0.0308, loss-ulb:0.0118, weight:2.00, lr:0.0006
[00:38:45.654] iteration:6885  t-loss:0.0807, loss-lb:0.0199, loss-ulb:0.0304, weight:2.00, lr:0.0006
[00:38:46.038] iteration:6886  t-loss:0.0479, loss-lb:0.0289, loss-ulb:0.0095, weight:2.00, lr:0.0006
[00:38:46.419] iteration:6887  t-loss:0.0470, loss-lb:0.0266, loss-ulb:0.0102, weight:2.00, lr:0.0006
[00:38:46.796] iteration:6888  t-loss:0.0409, loss-lb:0.0169, loss-ulb:0.0120, weight:2.00, lr:0.0006
[00:38:47.176] iteration:6889  t-loss:0.0376, loss-lb:0.0327, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:38:47.548] iteration:6890  t-loss:0.0219, loss-lb:0.0174, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:38:47.923] iteration:6891  t-loss:0.0458, loss-lb:0.0202, loss-ulb:0.0128, weight:2.00, lr:0.0006
[00:38:48.295] iteration:6892  t-loss:0.0230, loss-lb:0.0158, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:38:48.674] iteration:6893  t-loss:0.0472, loss-lb:0.0274, loss-ulb:0.0099, weight:2.00, lr:0.0006
[00:38:49.048] iteration:6894  t-loss:0.0332, loss-lb:0.0155, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:38:49.424] iteration:6895  t-loss:0.0335, loss-lb:0.0144, loss-ulb:0.0096, weight:2.00, lr:0.0006
[00:38:49.801] iteration:6896  t-loss:0.0477, loss-lb:0.0314, loss-ulb:0.0081, weight:2.00, lr:0.0006
[00:38:50.177] iteration:6897  t-loss:0.0235, loss-lb:0.0188, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:38:50.568] iteration:6898  t-loss:0.0318, loss-lb:0.0274, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:38:50.982] iteration:6899  t-loss:0.0326, loss-lb:0.0272, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:38:51.374] iteration:6900  t-loss:0.0206, loss-lb:0.0180, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:38:51.764] iteration:6901  t-loss:0.0400, loss-lb:0.0139, loss-ulb:0.0131, weight:2.00, lr:0.0006
[00:38:52.143] iteration:6902  t-loss:0.0530, loss-lb:0.0465, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:38:52.526] iteration:6903  t-loss:0.0298, loss-lb:0.0183, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:38:52.905] iteration:6904  t-loss:0.0757, loss-lb:0.0336, loss-ulb:0.0211, weight:2.00, lr:0.0006
[00:38:53.294] iteration:6905  t-loss:0.0511, loss-lb:0.0412, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:38:53.677] iteration:6906  t-loss:0.0615, loss-lb:0.0284, loss-ulb:0.0165, weight:2.00, lr:0.0006
[00:38:54.055] iteration:6907  t-loss:0.0225, loss-lb:0.0188, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:38:54.451] iteration:6908  t-loss:0.0295, loss-lb:0.0211, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:38:54.834] iteration:6909  t-loss:0.0515, loss-lb:0.0347, loss-ulb:0.0084, weight:2.00, lr:0.0006
[00:38:55.211] iteration:6910  t-loss:0.0284, loss-lb:0.0162, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:38:55.587] iteration:6911  t-loss:0.0168, loss-lb:0.0147, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:38:55.965] iteration:6912  t-loss:0.0764, loss-lb:0.0388, loss-ulb:0.0188, weight:2.00, lr:0.0006
[00:38:56.342] iteration:6913  t-loss:0.0330, loss-lb:0.0144, loss-ulb:0.0093, weight:2.00, lr:0.0006
[00:38:56.718] iteration:6914  t-loss:0.0665, loss-lb:0.0244, loss-ulb:0.0210, weight:2.00, lr:0.0006
[00:38:57.093] iteration:6915  t-loss:0.0301, loss-lb:0.0254, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:38:57.472] iteration:6916  t-loss:0.0443, loss-lb:0.0245, loss-ulb:0.0099, weight:2.00, lr:0.0006
[00:38:58.784] iteration:6917  t-loss:0.0604, loss-lb:0.0335, loss-ulb:0.0135, weight:2.00, lr:0.0006
[00:38:59.174] iteration:6918  t-loss:0.0180, loss-lb:0.0143, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:38:59.571] iteration:6919  t-loss:0.0503, loss-lb:0.0322, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:38:59.962] iteration:6920  t-loss:0.0646, loss-lb:0.0444, loss-ulb:0.0101, weight:2.00, lr:0.0006
[00:39:00.345] iteration:6921  t-loss:0.0643, loss-lb:0.0466, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:39:00.736] iteration:6922  t-loss:0.0208, loss-lb:0.0163, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:39:01.130] iteration:6923  t-loss:0.0221, loss-lb:0.0117, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:39:01.515] iteration:6924  t-loss:0.0521, loss-lb:0.0171, loss-ulb:0.0175, weight:2.00, lr:0.0006
[00:39:01.909] iteration:6925  t-loss:0.0616, loss-lb:0.0149, loss-ulb:0.0234, weight:2.00, lr:0.0006
[00:39:02.304] iteration:6926  t-loss:0.0405, loss-lb:0.0346, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:39:02.688] iteration:6927  t-loss:0.0241, loss-lb:0.0192, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:39:03.066] iteration:6928  t-loss:0.0441, loss-lb:0.0246, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:39:03.445] iteration:6929  t-loss:0.0365, loss-lb:0.0145, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:39:03.824] iteration:6930  t-loss:0.0306, loss-lb:0.0153, loss-ulb:0.0077, weight:2.00, lr:0.0006
[00:39:04.202] iteration:6931  t-loss:0.0537, loss-lb:0.0221, loss-ulb:0.0158, weight:2.00, lr:0.0006
[00:39:04.579] iteration:6932  t-loss:0.0555, loss-lb:0.0134, loss-ulb:0.0211, weight:2.00, lr:0.0006
[00:39:04.959] iteration:6933  t-loss:0.0669, loss-lb:0.0441, loss-ulb:0.0114, weight:2.00, lr:0.0006
[00:39:05.340] iteration:6934  t-loss:0.0503, loss-lb:0.0283, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:39:05.730] iteration:6935  t-loss:0.0533, loss-lb:0.0329, loss-ulb:0.0102, weight:2.00, lr:0.0006
[00:39:06.108] iteration:6936  t-loss:0.0396, loss-lb:0.0371, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:39:06.490] iteration:6937  t-loss:0.0222, loss-lb:0.0170, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:39:06.875] iteration:6938  t-loss:0.0407, loss-lb:0.0198, loss-ulb:0.0104, weight:2.00, lr:0.0006
[00:39:07.258] iteration:6939  t-loss:0.0486, loss-lb:0.0188, loss-ulb:0.0149, weight:2.00, lr:0.0006
[00:39:07.639] iteration:6940  t-loss:0.0275, loss-lb:0.0251, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:39:08.022] iteration:6941  t-loss:0.0361, loss-lb:0.0301, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:39:08.404] iteration:6942  t-loss:0.0237, loss-lb:0.0208, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:39:08.782] iteration:6943  t-loss:0.0168, loss-lb:0.0141, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:39:09.164] iteration:6944  t-loss:0.0387, loss-lb:0.0322, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:39:09.550] iteration:6945  t-loss:0.0209, loss-lb:0.0158, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:39:09.941] iteration:6946  t-loss:0.0597, loss-lb:0.0575, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:39:10.323] iteration:6947  t-loss:0.0721, loss-lb:0.0463, loss-ulb:0.0129, weight:2.00, lr:0.0006
[00:39:10.698] iteration:6948  t-loss:0.0289, loss-lb:0.0214, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:39:11.071] iteration:6949  t-loss:0.0313, loss-lb:0.0203, loss-ulb:0.0055, weight:2.00, lr:0.0006
[00:39:11.451] iteration:6950  t-loss:0.0398, loss-lb:0.0370, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:39:11.825] iteration:6951  t-loss:0.0203, loss-lb:0.0172, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:39:12.203] iteration:6952  t-loss:0.0518, loss-lb:0.0357, loss-ulb:0.0080, weight:2.00, lr:0.0006
[00:39:12.579] iteration:6953  t-loss:0.0722, loss-lb:0.0296, loss-ulb:0.0213, weight:2.00, lr:0.0006
[00:39:12.962] iteration:6954  t-loss:0.0413, loss-lb:0.0240, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:39:14.230] iteration:6955  t-loss:0.0308, loss-lb:0.0248, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:39:14.647] iteration:6956  t-loss:0.0412, loss-lb:0.0171, loss-ulb:0.0121, weight:2.00, lr:0.0006
[00:39:15.038] iteration:6957  t-loss:0.0259, loss-lb:0.0179, loss-ulb:0.0040, weight:2.00, lr:0.0006
[00:39:15.418] iteration:6958  t-loss:0.0669, loss-lb:0.0145, loss-ulb:0.0262, weight:2.00, lr:0.0006
[00:39:15.803] iteration:6959  t-loss:0.0224, loss-lb:0.0199, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:39:16.185] iteration:6960  t-loss:0.0345, loss-lb:0.0299, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:39:16.566] iteration:6961  t-loss:0.0312, loss-lb:0.0188, loss-ulb:0.0062, weight:2.00, lr:0.0006
[00:39:16.947] iteration:6962  t-loss:0.0243, loss-lb:0.0224, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:39:17.338] iteration:6963  t-loss:0.0506, loss-lb:0.0206, loss-ulb:0.0150, weight:2.00, lr:0.0006
[00:39:17.725] iteration:6964  t-loss:0.0498, loss-lb:0.0154, loss-ulb:0.0172, weight:2.00, lr:0.0006
[00:39:18.113] iteration:6965  t-loss:0.0377, loss-lb:0.0231, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:39:18.497] iteration:6966  t-loss:0.0371, loss-lb:0.0195, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:39:18.883] iteration:6967  t-loss:0.0230, loss-lb:0.0202, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:39:19.268] iteration:6968  t-loss:0.0981, loss-lb:0.0153, loss-ulb:0.0414, weight:2.00, lr:0.0006
[00:39:19.651] iteration:6969  t-loss:0.0629, loss-lb:0.0368, loss-ulb:0.0131, weight:2.00, lr:0.0006
[00:39:20.030] iteration:6970  t-loss:0.0410, loss-lb:0.0187, loss-ulb:0.0111, weight:2.00, lr:0.0006
[00:39:20.412] iteration:6971  t-loss:0.0249, loss-lb:0.0210, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:39:20.794] iteration:6972  t-loss:0.0726, loss-lb:0.0420, loss-ulb:0.0153, weight:2.00, lr:0.0006
[00:39:21.176] iteration:6973  t-loss:0.0405, loss-lb:0.0335, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:39:21.560] iteration:6974  t-loss:0.0302, loss-lb:0.0267, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:39:21.946] iteration:6975  t-loss:0.0460, loss-lb:0.0327, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:39:22.331] iteration:6976  t-loss:0.0336, loss-lb:0.0263, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:39:22.715] iteration:6977  t-loss:0.0467, loss-lb:0.0361, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:39:23.097] iteration:6978  t-loss:0.0440, loss-lb:0.0405, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:39:23.480] iteration:6979  t-loss:0.0423, loss-lb:0.0375, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:39:23.856] iteration:6980  t-loss:0.0315, loss-lb:0.0183, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:39:24.235] iteration:6981  t-loss:0.0401, loss-lb:0.0362, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:39:24.623] iteration:6982  t-loss:0.0507, loss-lb:0.0239, loss-ulb:0.0134, weight:2.00, lr:0.0006
[00:39:25.004] iteration:6983  t-loss:0.0241, loss-lb:0.0185, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:39:25.394] iteration:6984  t-loss:0.0448, loss-lb:0.0382, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:39:25.779] iteration:6985  t-loss:0.0508, loss-lb:0.0362, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:39:26.155] iteration:6986  t-loss:0.0393, loss-lb:0.0335, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:39:26.537] iteration:6987  t-loss:0.0371, loss-lb:0.0319, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:39:26.913] iteration:6988  t-loss:0.0398, loss-lb:0.0212, loss-ulb:0.0093, weight:2.00, lr:0.0006
[00:39:27.299] iteration:6989  t-loss:0.0606, loss-lb:0.0461, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:39:27.676] iteration:6990  t-loss:0.0389, loss-lb:0.0315, loss-ulb:0.0037, weight:2.00, lr:0.0006
[00:39:28.053] iteration:6991  t-loss:0.0200, loss-lb:0.0132, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:39:28.437] iteration:6992  t-loss:0.0674, loss-lb:0.0403, loss-ulb:0.0136, weight:2.00, lr:0.0006
[00:39:29.663] iteration:6993  t-loss:0.0428, loss-lb:0.0341, loss-ulb:0.0043, weight:2.00, lr:0.0006
[00:39:30.060] iteration:6994  t-loss:0.0420, loss-lb:0.0189, loss-ulb:0.0116, weight:2.00, lr:0.0006
[00:39:30.444] iteration:6995  t-loss:0.0398, loss-lb:0.0314, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:39:30.836] iteration:6996  t-loss:0.0598, loss-lb:0.0385, loss-ulb:0.0106, weight:2.00, lr:0.0006
[00:39:31.222] iteration:6997  t-loss:0.0421, loss-lb:0.0202, loss-ulb:0.0109, weight:2.00, lr:0.0006
[00:39:31.602] iteration:6998  t-loss:0.0195, loss-lb:0.0173, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:39:31.983] iteration:6999  t-loss:0.0377, loss-lb:0.0352, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:39:32.365] iteration:7000  t-loss:0.0266, loss-lb:0.0217, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:39:32.753] iteration:7001  t-loss:0.0708, loss-lb:0.0196, loss-ulb:0.0256, weight:2.00, lr:0.0006
[00:39:33.138] iteration:7002  t-loss:0.0331, loss-lb:0.0142, loss-ulb:0.0094, weight:2.00, lr:0.0006
[00:39:33.525] iteration:7003  t-loss:0.0254, loss-lb:0.0199, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:39:33.913] iteration:7004  t-loss:0.0431, loss-lb:0.0324, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:39:34.290] iteration:7005  t-loss:0.0221, loss-lb:0.0162, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:39:34.676] iteration:7006  t-loss:0.0557, loss-lb:0.0352, loss-ulb:0.0102, weight:2.00, lr:0.0006
[00:39:35.061] iteration:7007  t-loss:0.0221, loss-lb:0.0154, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:39:35.440] iteration:7008  t-loss:0.0482, loss-lb:0.0459, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:39:35.828] iteration:7009  t-loss:0.0428, loss-lb:0.0336, loss-ulb:0.0046, weight:2.00, lr:0.0006
[00:39:36.209] iteration:7010  t-loss:0.0295, loss-lb:0.0153, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:39:36.594] iteration:7011  t-loss:0.0478, loss-lb:0.0372, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:39:36.971] iteration:7012  t-loss:0.0196, loss-lb:0.0149, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:39:37.347] iteration:7013  t-loss:0.0227, loss-lb:0.0195, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:39:37.734] iteration:7014  t-loss:0.0416, loss-lb:0.0297, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:39:38.109] iteration:7015  t-loss:0.0303, loss-lb:0.0277, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:39:38.489] iteration:7016  t-loss:0.0434, loss-lb:0.0140, loss-ulb:0.0147, weight:2.00, lr:0.0006
[00:39:38.866] iteration:7017  t-loss:0.0268, loss-lb:0.0149, loss-ulb:0.0060, weight:2.00, lr:0.0006
[00:39:39.245] iteration:7018  t-loss:0.0260, loss-lb:0.0226, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:39:39.629] iteration:7019  t-loss:0.0469, loss-lb:0.0258, loss-ulb:0.0105, weight:2.00, lr:0.0006
[00:39:40.011] iteration:7020  t-loss:0.0502, loss-lb:0.0298, loss-ulb:0.0102, weight:2.00, lr:0.0006
[00:39:40.407] iteration:7021  t-loss:0.0495, loss-lb:0.0343, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:39:40.799] iteration:7022  t-loss:0.0373, loss-lb:0.0304, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:39:41.180] iteration:7023  t-loss:0.0390, loss-lb:0.0362, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:39:41.558] iteration:7024  t-loss:0.0341, loss-lb:0.0166, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:39:41.938] iteration:7025  t-loss:0.0401, loss-lb:0.0302, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:39:42.318] iteration:7026  t-loss:0.0392, loss-lb:0.0167, loss-ulb:0.0113, weight:2.00, lr:0.0006
[00:39:42.696] iteration:7027  t-loss:0.0265, loss-lb:0.0195, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:39:43.071] iteration:7028  t-loss:0.0191, loss-lb:0.0173, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:39:43.446] iteration:7029  t-loss:0.0211, loss-lb:0.0141, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:39:43.829] iteration:7030  t-loss:0.0435, loss-lb:0.0326, loss-ulb:0.0054, weight:2.00, lr:0.0006
[00:40:48.272] iteration 7030 : dice_score: 0.883432 best_dice: 0.889700
[00:40:48.272]  <<Test>> - Ep:184  - Dice-S/T:87.07/88.34, Best-S:88.42, Best-T:88.97
[00:40:48.272]           - AvgLoss(lb/ulb/all):0.02/0.01/0.04
[00:40:49.442] iteration:7031  t-loss:0.0201, loss-lb:0.0156, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:40:49.836] iteration:7032  t-loss:0.0682, loss-lb:0.0214, loss-ulb:0.0234, weight:2.00, lr:0.0006
[00:40:50.221] iteration:7033  t-loss:0.0316, loss-lb:0.0272, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:40:50.590] iteration:7034  t-loss:0.0315, loss-lb:0.0292, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:40:50.969] iteration:7035  t-loss:0.0217, loss-lb:0.0187, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:40:51.353] iteration:7036  t-loss:0.0678, loss-lb:0.0372, loss-ulb:0.0153, weight:2.00, lr:0.0006
[00:40:51.734] iteration:7037  t-loss:0.0480, loss-lb:0.0181, loss-ulb:0.0149, weight:2.00, lr:0.0006
[00:40:52.114] iteration:7038  t-loss:0.0394, loss-lb:0.0148, loss-ulb:0.0123, weight:2.00, lr:0.0006
[00:40:52.498] iteration:7039  t-loss:0.0428, loss-lb:0.0398, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:40:52.883] iteration:7040  t-loss:0.0512, loss-lb:0.0340, loss-ulb:0.0086, weight:2.00, lr:0.0006
[00:40:53.261] iteration:7041  t-loss:0.0239, loss-lb:0.0138, loss-ulb:0.0050, weight:2.00, lr:0.0006
[00:40:53.649] iteration:7042  t-loss:0.0458, loss-lb:0.0264, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:40:54.027] iteration:7043  t-loss:0.0280, loss-lb:0.0138, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:40:54.403] iteration:7044  t-loss:0.0259, loss-lb:0.0183, loss-ulb:0.0038, weight:2.00, lr:0.0006
[00:40:54.782] iteration:7045  t-loss:0.0401, loss-lb:0.0293, loss-ulb:0.0054, weight:2.00, lr:0.0006
[00:40:55.157] iteration:7046  t-loss:0.0362, loss-lb:0.0156, loss-ulb:0.0103, weight:2.00, lr:0.0006
[00:40:55.538] iteration:7047  t-loss:0.0268, loss-lb:0.0241, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:40:55.914] iteration:7048  t-loss:0.0341, loss-lb:0.0312, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:40:56.292] iteration:7049  t-loss:0.0314, loss-lb:0.0226, loss-ulb:0.0044, weight:2.00, lr:0.0006
[00:40:56.677] iteration:7050  t-loss:0.0642, loss-lb:0.0313, loss-ulb:0.0164, weight:2.00, lr:0.0006
[00:40:57.056] iteration:7051  t-loss:0.0323, loss-lb:0.0284, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:40:57.463] iteration:7052  t-loss:0.0381, loss-lb:0.0317, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:40:57.873] iteration:7053  t-loss:0.0331, loss-lb:0.0186, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:40:58.287] iteration:7054  t-loss:0.0377, loss-lb:0.0233, loss-ulb:0.0072, weight:2.00, lr:0.0006
[00:40:58.676] iteration:7055  t-loss:0.0552, loss-lb:0.0326, loss-ulb:0.0113, weight:2.00, lr:0.0006
[00:40:59.062] iteration:7056  t-loss:0.0189, loss-lb:0.0161, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:40:59.444] iteration:7057  t-loss:0.0532, loss-lb:0.0245, loss-ulb:0.0143, weight:2.00, lr:0.0006
[00:40:59.830] iteration:7058  t-loss:0.0653, loss-lb:0.0278, loss-ulb:0.0188, weight:2.00, lr:0.0006
[00:41:00.213] iteration:7059  t-loss:0.0256, loss-lb:0.0223, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:41:00.594] iteration:7060  t-loss:0.0247, loss-lb:0.0191, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:41:00.974] iteration:7061  t-loss:0.0465, loss-lb:0.0175, loss-ulb:0.0145, weight:2.00, lr:0.0006
[00:41:01.355] iteration:7062  t-loss:0.0411, loss-lb:0.0170, loss-ulb:0.0120, weight:2.00, lr:0.0006
[00:41:01.733] iteration:7063  t-loss:0.0214, loss-lb:0.0182, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:41:02.111] iteration:7064  t-loss:0.0256, loss-lb:0.0234, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:41:02.487] iteration:7065  t-loss:0.0437, loss-lb:0.0223, loss-ulb:0.0107, weight:2.00, lr:0.0006
[00:41:02.865] iteration:7066  t-loss:0.0341, loss-lb:0.0225, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:41:03.243] iteration:7067  t-loss:0.0311, loss-lb:0.0235, loss-ulb:0.0038, weight:2.00, lr:0.0006
[00:41:03.624] iteration:7068  t-loss:0.0649, loss-lb:0.0381, loss-ulb:0.0134, weight:2.00, lr:0.0006
[00:41:04.989] iteration:7069  t-loss:0.0348, loss-lb:0.0240, loss-ulb:0.0054, weight:2.00, lr:0.0006
[00:41:05.411] iteration:7070  t-loss:0.0351, loss-lb:0.0235, loss-ulb:0.0058, weight:2.00, lr:0.0006
[00:41:05.799] iteration:7071  t-loss:0.0214, loss-lb:0.0172, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:41:06.180] iteration:7072  t-loss:0.0203, loss-lb:0.0155, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:41:06.576] iteration:7073  t-loss:0.0421, loss-lb:0.0256, loss-ulb:0.0083, weight:2.00, lr:0.0006
[00:41:06.963] iteration:7074  t-loss:0.0247, loss-lb:0.0205, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:41:07.351] iteration:7075  t-loss:0.0511, loss-lb:0.0383, loss-ulb:0.0064, weight:2.00, lr:0.0006
[00:41:07.740] iteration:7076  t-loss:0.0625, loss-lb:0.0476, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:41:08.125] iteration:7077  t-loss:0.0306, loss-lb:0.0168, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:41:08.503] iteration:7078  t-loss:0.0218, loss-lb:0.0182, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:41:08.890] iteration:7079  t-loss:0.0260, loss-lb:0.0142, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:41:09.273] iteration:7080  t-loss:0.0341, loss-lb:0.0191, loss-ulb:0.0075, weight:2.00, lr:0.0006
[00:41:09.654] iteration:7081  t-loss:0.0628, loss-lb:0.0279, loss-ulb:0.0175, weight:2.00, lr:0.0006
[00:41:10.032] iteration:7082  t-loss:0.0433, loss-lb:0.0358, loss-ulb:0.0038, weight:2.00, lr:0.0006
[00:41:10.415] iteration:7083  t-loss:0.0450, loss-lb:0.0310, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:41:10.790] iteration:7084  t-loss:0.0441, loss-lb:0.0410, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:41:11.167] iteration:7085  t-loss:0.0208, loss-lb:0.0179, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:41:11.549] iteration:7086  t-loss:0.0726, loss-lb:0.0418, loss-ulb:0.0154, weight:2.00, lr:0.0006
[00:41:11.925] iteration:7087  t-loss:0.0193, loss-lb:0.0167, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:41:12.304] iteration:7088  t-loss:0.0361, loss-lb:0.0267, loss-ulb:0.0047, weight:2.00, lr:0.0006
[00:41:12.683] iteration:7089  t-loss:0.0243, loss-lb:0.0210, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:41:13.070] iteration:7090  t-loss:0.0272, loss-lb:0.0236, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:41:13.450] iteration:7091  t-loss:0.0221, loss-lb:0.0194, loss-ulb:0.0014, weight:2.00, lr:0.0006
[00:41:13.830] iteration:7092  t-loss:0.0571, loss-lb:0.0159, loss-ulb:0.0206, weight:2.00, lr:0.0006
[00:41:14.200] iteration:7093  t-loss:0.0387, loss-lb:0.0297, loss-ulb:0.0045, weight:2.00, lr:0.0006
[00:41:14.580] iteration:7094  t-loss:0.0212, loss-lb:0.0169, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:41:14.964] iteration:7095  t-loss:0.0295, loss-lb:0.0136, loss-ulb:0.0079, weight:2.00, lr:0.0006
[00:41:15.344] iteration:7096  t-loss:0.0492, loss-lb:0.0460, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:41:15.725] iteration:7097  t-loss:0.0323, loss-lb:0.0145, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:41:16.108] iteration:7098  t-loss:0.0303, loss-lb:0.0256, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:41:16.482] iteration:7099  t-loss:0.0431, loss-lb:0.0170, loss-ulb:0.0131, weight:2.00, lr:0.0006
[00:41:16.859] iteration:7100  t-loss:0.0317, loss-lb:0.0187, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:41:17.234] iteration:7101  t-loss:0.0417, loss-lb:0.0148, loss-ulb:0.0135, weight:2.00, lr:0.0006
[00:41:17.612] iteration:7102  t-loss:0.0464, loss-lb:0.0400, loss-ulb:0.0032, weight:2.00, lr:0.0006
[00:41:17.996] iteration:7103  t-loss:0.0289, loss-lb:0.0168, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:41:18.375] iteration:7104  t-loss:0.0444, loss-lb:0.0337, loss-ulb:0.0053, weight:2.00, lr:0.0006
[00:41:18.760] iteration:7105  t-loss:0.1146, loss-lb:0.0206, loss-ulb:0.0470, weight:2.00, lr:0.0006
[00:41:19.144] iteration:7106  t-loss:0.0715, loss-lb:0.0601, loss-ulb:0.0057, weight:2.00, lr:0.0006
[00:41:20.499] iteration:7107  t-loss:0.0256, loss-lb:0.0134, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:41:20.891] iteration:7108  t-loss:0.0366, loss-lb:0.0352, loss-ulb:0.0007, weight:2.00, lr:0.0006
[00:41:21.273] iteration:7109  t-loss:0.0193, loss-lb:0.0173, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:41:21.657] iteration:7110  t-loss:0.0453, loss-lb:0.0404, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:41:22.040] iteration:7111  t-loss:0.0448, loss-lb:0.0263, loss-ulb:0.0093, weight:2.00, lr:0.0006
[00:41:22.429] iteration:7112  t-loss:0.0415, loss-lb:0.0328, loss-ulb:0.0043, weight:2.00, lr:0.0006
[00:41:22.815] iteration:7113  t-loss:0.0239, loss-lb:0.0179, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:41:23.200] iteration:7114  t-loss:0.0227, loss-lb:0.0188, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:41:23.583] iteration:7115  t-loss:0.0194, loss-lb:0.0164, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:41:23.965] iteration:7116  t-loss:0.0247, loss-lb:0.0182, loss-ulb:0.0033, weight:2.00, lr:0.0006
[00:41:24.347] iteration:7117  t-loss:0.0430, loss-lb:0.0393, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:41:24.737] iteration:7118  t-loss:0.0442, loss-lb:0.0261, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:41:25.123] iteration:7119  t-loss:0.0230, loss-lb:0.0181, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:41:25.501] iteration:7120  t-loss:0.0260, loss-lb:0.0239, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:41:25.891] iteration:7121  t-loss:0.0335, loss-lb:0.0283, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:41:26.275] iteration:7122  t-loss:0.0225, loss-lb:0.0194, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:41:26.653] iteration:7123  t-loss:0.0210, loss-lb:0.0179, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:41:27.033] iteration:7124  t-loss:0.0353, loss-lb:0.0127, loss-ulb:0.0113, weight:2.00, lr:0.0006
[00:41:27.418] iteration:7125  t-loss:0.0245, loss-lb:0.0148, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:41:27.817] iteration:7126  t-loss:0.0577, loss-lb:0.0384, loss-ulb:0.0097, weight:2.00, lr:0.0006
[00:41:28.197] iteration:7127  t-loss:0.0431, loss-lb:0.0401, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:41:28.586] iteration:7128  t-loss:0.0315, loss-lb:0.0268, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:41:28.978] iteration:7129  t-loss:0.0544, loss-lb:0.0277, loss-ulb:0.0134, weight:2.00, lr:0.0006
[00:41:29.356] iteration:7130  t-loss:0.0374, loss-lb:0.0213, loss-ulb:0.0081, weight:2.00, lr:0.0006
[00:41:29.737] iteration:7131  t-loss:0.0219, loss-lb:0.0167, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:41:30.116] iteration:7132  t-loss:0.0162, loss-lb:0.0138, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:41:30.497] iteration:7133  t-loss:0.0311, loss-lb:0.0142, loss-ulb:0.0085, weight:2.00, lr:0.0006
[00:41:30.873] iteration:7134  t-loss:0.0225, loss-lb:0.0169, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:41:31.251] iteration:7135  t-loss:0.0241, loss-lb:0.0173, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:41:31.632] iteration:7136  t-loss:0.0371, loss-lb:0.0230, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:41:32.013] iteration:7137  t-loss:0.0315, loss-lb:0.0169, loss-ulb:0.0073, weight:2.00, lr:0.0006
[00:41:32.388] iteration:7138  t-loss:0.0187, loss-lb:0.0152, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:41:32.763] iteration:7139  t-loss:0.0413, loss-lb:0.0179, loss-ulb:0.0117, weight:2.00, lr:0.0006
[00:41:33.148] iteration:7140  t-loss:0.0284, loss-lb:0.0262, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:41:33.540] iteration:7141  t-loss:0.0668, loss-lb:0.0539, loss-ulb:0.0064, weight:2.00, lr:0.0006
[00:41:33.917] iteration:7142  t-loss:0.0210, loss-lb:0.0161, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:41:34.291] iteration:7143  t-loss:0.0183, loss-lb:0.0146, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:41:34.666] iteration:7144  t-loss:0.0223, loss-lb:0.0184, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:41:36.032] iteration:7145  t-loss:0.0483, loss-lb:0.0338, loss-ulb:0.0072, weight:2.00, lr:0.0006
[00:41:36.430] iteration:7146  t-loss:0.0225, loss-lb:0.0210, loss-ulb:0.0008, weight:2.00, lr:0.0006
[00:41:36.822] iteration:7147  t-loss:0.0351, loss-lb:0.0134, loss-ulb:0.0108, weight:2.00, lr:0.0006
[00:41:37.205] iteration:7148  t-loss:0.0731, loss-lb:0.0378, loss-ulb:0.0176, weight:2.00, lr:0.0006
[00:41:37.582] iteration:7149  t-loss:0.0171, loss-lb:0.0152, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:41:37.965] iteration:7150  t-loss:0.0158, loss-lb:0.0138, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:41:38.346] iteration:7151  t-loss:0.0298, loss-lb:0.0159, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:41:38.724] iteration:7152  t-loss:0.0212, loss-lb:0.0168, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:41:39.109] iteration:7153  t-loss:0.0334, loss-lb:0.0155, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:41:39.498] iteration:7154  t-loss:0.0162, loss-lb:0.0132, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:41:39.881] iteration:7155  t-loss:0.0429, loss-lb:0.0309, loss-ulb:0.0060, weight:2.00, lr:0.0006
[00:41:40.265] iteration:7156  t-loss:0.0556, loss-lb:0.0307, loss-ulb:0.0125, weight:2.00, lr:0.0006
[00:41:40.645] iteration:7157  t-loss:0.0324, loss-lb:0.0279, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:41:41.024] iteration:7158  t-loss:0.0234, loss-lb:0.0164, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:41:41.414] iteration:7159  t-loss:0.0553, loss-lb:0.0214, loss-ulb:0.0169, weight:2.00, lr:0.0006
[00:41:41.798] iteration:7160  t-loss:0.0594, loss-lb:0.0436, loss-ulb:0.0079, weight:2.00, lr:0.0006
[00:41:42.180] iteration:7161  t-loss:0.0353, loss-lb:0.0270, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:41:42.565] iteration:7162  t-loss:0.0349, loss-lb:0.0306, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:41:42.954] iteration:7163  t-loss:0.0323, loss-lb:0.0268, loss-ulb:0.0028, weight:2.00, lr:0.0006
[00:41:43.335] iteration:7164  t-loss:0.0160, loss-lb:0.0135, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:41:43.725] iteration:7165  t-loss:0.0521, loss-lb:0.0231, loss-ulb:0.0145, weight:2.00, lr:0.0006
[00:41:44.103] iteration:7166  t-loss:0.0481, loss-lb:0.0460, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:41:44.485] iteration:7167  t-loss:0.0547, loss-lb:0.0414, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:41:44.869] iteration:7168  t-loss:0.0447, loss-lb:0.0256, loss-ulb:0.0095, weight:2.00, lr:0.0006
[00:41:45.252] iteration:7169  t-loss:0.0369, loss-lb:0.0189, loss-ulb:0.0090, weight:2.00, lr:0.0006
[00:41:45.639] iteration:7170  t-loss:0.0494, loss-lb:0.0315, loss-ulb:0.0089, weight:2.00, lr:0.0006
[00:41:46.017] iteration:7171  t-loss:0.0389, loss-lb:0.0337, loss-ulb:0.0026, weight:2.00, lr:0.0006
[00:41:46.399] iteration:7172  t-loss:0.0523, loss-lb:0.0289, loss-ulb:0.0117, weight:2.00, lr:0.0006
[00:41:46.777] iteration:7173  t-loss:0.0184, loss-lb:0.0168, loss-ulb:0.0008, weight:2.00, lr:0.0006
[00:41:47.160] iteration:7174  t-loss:0.0209, loss-lb:0.0173, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:41:47.539] iteration:7175  t-loss:0.0582, loss-lb:0.0558, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:41:47.912] iteration:7176  t-loss:0.0220, loss-lb:0.0148, loss-ulb:0.0036, weight:2.00, lr:0.0006
[00:41:48.289] iteration:7177  t-loss:0.0249, loss-lb:0.0213, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:41:48.671] iteration:7178  t-loss:0.0173, loss-lb:0.0147, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:41:49.055] iteration:7179  t-loss:0.0483, loss-lb:0.0263, loss-ulb:0.0110, weight:2.00, lr:0.0006
[00:41:49.437] iteration:7180  t-loss:0.0453, loss-lb:0.0368, loss-ulb:0.0042, weight:2.00, lr:0.0006
[00:41:49.820] iteration:7181  t-loss:0.0723, loss-lb:0.0550, loss-ulb:0.0087, weight:2.00, lr:0.0006
[00:41:50.206] iteration:7182  t-loss:0.0173, loss-lb:0.0140, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:42:52.586] iteration 7182 : dice_score: 0.886935 best_dice: 0.889700
[00:42:52.586]  <<Test>> - Ep:188  - Dice-S/T:88.88/88.69, Best-S:88.88, Best-T:88.97
[00:42:52.587]           - AvgLoss(lb/ulb/all):0.03/0.01/0.04
[00:42:53.754] iteration:7183  t-loss:0.0255, loss-lb:0.0163, loss-ulb:0.0046, weight:2.00, lr:0.0006
[00:42:54.138] iteration:7184  t-loss:0.0265, loss-lb:0.0124, loss-ulb:0.0071, weight:2.00, lr:0.0006
[00:42:54.523] iteration:7185  t-loss:0.0326, loss-lb:0.0295, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:42:54.906] iteration:7186  t-loss:0.0476, loss-lb:0.0269, loss-ulb:0.0104, weight:2.00, lr:0.0006
[00:42:55.286] iteration:7187  t-loss:0.0225, loss-lb:0.0187, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:42:55.670] iteration:7188  t-loss:0.0735, loss-lb:0.0421, loss-ulb:0.0157, weight:2.00, lr:0.0006
[00:42:56.054] iteration:7189  t-loss:0.0423, loss-lb:0.0285, loss-ulb:0.0069, weight:2.00, lr:0.0006
[00:42:56.439] iteration:7190  t-loss:0.0550, loss-lb:0.0420, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:42:56.822] iteration:7191  t-loss:0.0365, loss-lb:0.0350, loss-ulb:0.0007, weight:2.00, lr:0.0006
[00:42:57.206] iteration:7192  t-loss:0.0307, loss-lb:0.0168, loss-ulb:0.0070, weight:2.00, lr:0.0006
[00:42:57.590] iteration:7193  t-loss:0.0658, loss-lb:0.0628, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:42:57.973] iteration:7194  t-loss:0.0419, loss-lb:0.0243, loss-ulb:0.0088, weight:2.00, lr:0.0006
[00:42:58.355] iteration:7195  t-loss:0.0496, loss-lb:0.0137, loss-ulb:0.0179, weight:2.00, lr:0.0006
[00:42:58.735] iteration:7196  t-loss:0.0244, loss-lb:0.0202, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:42:59.118] iteration:7197  t-loss:0.0477, loss-lb:0.0172, loss-ulb:0.0152, weight:2.00, lr:0.0006
[00:42:59.504] iteration:7198  t-loss:0.0460, loss-lb:0.0406, loss-ulb:0.0027, weight:2.00, lr:0.0006
[00:42:59.884] iteration:7199  t-loss:0.0276, loss-lb:0.0240, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:43:00.264] iteration:7200  t-loss:0.0337, loss-lb:0.0319, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:43:00.643] iteration:7201  t-loss:0.0225, loss-lb:0.0157, loss-ulb:0.0034, weight:2.00, lr:0.0006
[00:43:01.022] iteration:7202  t-loss:0.0318, loss-lb:0.0188, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:43:01.399] iteration:7203  t-loss:0.0410, loss-lb:0.0249, loss-ulb:0.0080, weight:2.00, lr:0.0006
[00:43:01.774] iteration:7204  t-loss:0.0651, loss-lb:0.0565, loss-ulb:0.0043, weight:2.00, lr:0.0006
[00:43:02.156] iteration:7205  t-loss:0.0295, loss-lb:0.0260, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:43:02.531] iteration:7206  t-loss:0.0252, loss-lb:0.0231, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:43:02.912] iteration:7207  t-loss:0.0358, loss-lb:0.0206, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:43:03.287] iteration:7208  t-loss:0.0172, loss-lb:0.0136, loss-ulb:0.0018, weight:2.00, lr:0.0006
[00:43:03.673] iteration:7209  t-loss:0.0427, loss-lb:0.0314, loss-ulb:0.0057, weight:2.00, lr:0.0006
[00:43:04.059] iteration:7210  t-loss:0.0251, loss-lb:0.0219, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:43:04.446] iteration:7211  t-loss:0.0486, loss-lb:0.0175, loss-ulb:0.0155, weight:2.00, lr:0.0006
[00:43:04.833] iteration:7212  t-loss:0.0438, loss-lb:0.0401, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:43:05.215] iteration:7213  t-loss:0.0603, loss-lb:0.0339, loss-ulb:0.0132, weight:2.00, lr:0.0006
[00:43:05.589] iteration:7214  t-loss:0.0330, loss-lb:0.0200, loss-ulb:0.0065, weight:2.00, lr:0.0006
[00:43:05.967] iteration:7215  t-loss:0.1280, loss-lb:0.0318, loss-ulb:0.0481, weight:2.00, lr:0.0006
[00:43:06.342] iteration:7216  t-loss:0.0203, loss-lb:0.0169, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:43:06.718] iteration:7217  t-loss:0.0362, loss-lb:0.0177, loss-ulb:0.0092, weight:2.00, lr:0.0006
[00:43:07.096] iteration:7218  t-loss:0.0503, loss-lb:0.0383, loss-ulb:0.0060, weight:2.00, lr:0.0006
[00:43:07.472] iteration:7219  t-loss:0.0543, loss-lb:0.0190, loss-ulb:0.0177, weight:2.00, lr:0.0006
[00:43:07.853] iteration:7220  t-loss:0.0650, loss-lb:0.0369, loss-ulb:0.0141, weight:2.00, lr:0.0006
[00:43:09.015] iteration:7221  t-loss:0.0286, loss-lb:0.0256, loss-ulb:0.0015, weight:2.00, lr:0.0006
[00:43:09.421] iteration:7222  t-loss:0.0680, loss-lb:0.0273, loss-ulb:0.0203, weight:2.00, lr:0.0006
[00:43:09.802] iteration:7223  t-loss:0.0152, loss-lb:0.0131, loss-ulb:0.0010, weight:2.00, lr:0.0006
[00:43:10.178] iteration:7224  t-loss:0.0271, loss-lb:0.0253, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:43:10.559] iteration:7225  t-loss:0.0458, loss-lb:0.0436, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:43:10.941] iteration:7226  t-loss:0.0289, loss-lb:0.0228, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:43:11.326] iteration:7227  t-loss:0.0404, loss-lb:0.0257, loss-ulb:0.0074, weight:2.00, lr:0.0006
[00:43:11.713] iteration:7228  t-loss:0.0971, loss-lb:0.0184, loss-ulb:0.0394, weight:2.00, lr:0.0006
[00:43:12.097] iteration:7229  t-loss:0.0427, loss-lb:0.0295, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:43:12.478] iteration:7230  t-loss:0.0421, loss-lb:0.0325, loss-ulb:0.0048, weight:2.00, lr:0.0006
[00:43:12.858] iteration:7231  t-loss:0.0324, loss-lb:0.0255, loss-ulb:0.0035, weight:2.00, lr:0.0006
[00:43:13.240] iteration:7232  t-loss:0.0168, loss-lb:0.0145, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:43:13.617] iteration:7233  t-loss:0.0192, loss-lb:0.0167, loss-ulb:0.0013, weight:2.00, lr:0.0006
[00:43:13.998] iteration:7234  t-loss:0.0454, loss-lb:0.0252, loss-ulb:0.0101, weight:2.00, lr:0.0006
[00:43:14.383] iteration:7235  t-loss:0.0304, loss-lb:0.0253, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:43:14.761] iteration:7236  t-loss:0.0538, loss-lb:0.0304, loss-ulb:0.0117, weight:2.00, lr:0.0006
[00:43:15.140] iteration:7237  t-loss:0.0256, loss-lb:0.0164, loss-ulb:0.0046, weight:2.00, lr:0.0006
[00:43:15.515] iteration:7238  t-loss:0.0178, loss-lb:0.0154, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:43:15.900] iteration:7239  t-loss:0.0311, loss-lb:0.0176, loss-ulb:0.0067, weight:2.00, lr:0.0006
[00:43:16.272] iteration:7240  t-loss:0.0203, loss-lb:0.0178, loss-ulb:0.0012, weight:2.00, lr:0.0006
[00:43:16.648] iteration:7241  t-loss:0.0261, loss-lb:0.0156, loss-ulb:0.0052, weight:2.00, lr:0.0006
[00:43:17.024] iteration:7242  t-loss:0.0151, loss-lb:0.0120, loss-ulb:0.0016, weight:2.00, lr:0.0006
[00:43:17.406] iteration:7243  t-loss:0.0825, loss-lb:0.0372, loss-ulb:0.0226, weight:2.00, lr:0.0006
[00:43:17.783] iteration:7244  t-loss:0.0422, loss-lb:0.0143, loss-ulb:0.0139, weight:2.00, lr:0.0006
[00:43:18.158] iteration:7245  t-loss:0.0396, loss-lb:0.0171, loss-ulb:0.0112, weight:2.00, lr:0.0006
[00:43:18.541] iteration:7246  t-loss:0.0395, loss-lb:0.0353, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:43:18.921] iteration:7247  t-loss:0.0365, loss-lb:0.0282, loss-ulb:0.0041, weight:2.00, lr:0.0006
[00:43:19.304] iteration:7248  t-loss:0.0326, loss-lb:0.0291, loss-ulb:0.0017, weight:2.00, lr:0.0006
[00:43:19.682] iteration:7249  t-loss:0.0176, loss-lb:0.0136, loss-ulb:0.0020, weight:2.00, lr:0.0006
[00:43:20.069] iteration:7250  t-loss:0.0500, loss-lb:0.0167, loss-ulb:0.0167, weight:2.00, lr:0.0006
[00:43:20.444] iteration:7251  t-loss:0.0179, loss-lb:0.0160, loss-ulb:0.0009, weight:2.00, lr:0.0006
[00:43:20.824] iteration:7252  t-loss:0.0657, loss-lb:0.0474, loss-ulb:0.0091, weight:2.00, lr:0.0006
[00:43:21.206] iteration:7253  t-loss:0.0648, loss-lb:0.0117, loss-ulb:0.0265, weight:2.00, lr:0.0006
[00:43:21.586] iteration:7254  t-loss:0.0456, loss-lb:0.0323, loss-ulb:0.0066, weight:2.00, lr:0.0006
[00:43:21.963] iteration:7255  t-loss:0.0440, loss-lb:0.0277, loss-ulb:0.0082, weight:2.00, lr:0.0006
[00:43:22.342] iteration:7256  t-loss:0.0323, loss-lb:0.0301, loss-ulb:0.0011, weight:2.00, lr:0.0006
[00:43:22.716] iteration:7257  t-loss:0.0385, loss-lb:0.0167, loss-ulb:0.0109, weight:2.00, lr:0.0006
[00:43:23.089] iteration:7258  t-loss:0.0247, loss-lb:0.0189, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:43:24.512] iteration:7259  t-loss:0.0178, loss-lb:0.0130, loss-ulb:0.0024, weight:2.00, lr:0.0006
[00:43:24.898] iteration:7260  t-loss:0.0219, loss-lb:0.0156, loss-ulb:0.0031, weight:2.00, lr:0.0006
[00:43:25.282] iteration:7261  t-loss:0.0311, loss-lb:0.0188, loss-ulb:0.0061, weight:2.00, lr:0.0006
[00:43:25.675] iteration:7262  t-loss:0.0308, loss-lb:0.0211, loss-ulb:0.0048, weight:2.00, lr:0.0006
[00:43:26.055] iteration:7263  t-loss:0.0227, loss-lb:0.0190, loss-ulb:0.0019, weight:2.00, lr:0.0006
[00:43:26.437] iteration:7264  t-loss:0.0221, loss-lb:0.0175, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:43:26.825] iteration:7265  t-loss:0.0468, loss-lb:0.0280, loss-ulb:0.0094, weight:2.00, lr:0.0006
[00:43:27.204] iteration:7266  t-loss:0.0316, loss-lb:0.0125, loss-ulb:0.0095, weight:2.00, lr:0.0006
[00:43:27.584] iteration:7267  t-loss:0.0504, loss-lb:0.0191, loss-ulb:0.0157, weight:2.00, lr:0.0006
[00:43:27.968] iteration:7268  t-loss:0.0415, loss-lb:0.0319, loss-ulb:0.0048, weight:2.00, lr:0.0006
[00:43:28.358] iteration:7269  t-loss:0.0410, loss-lb:0.0291, loss-ulb:0.0059, weight:2.00, lr:0.0006
[00:43:28.741] iteration:7270  t-loss:0.0178, loss-lb:0.0133, loss-ulb:0.0022, weight:2.00, lr:0.0006
[00:43:29.120] iteration:7271  t-loss:0.0435, loss-lb:0.0161, loss-ulb:0.0137, weight:2.00, lr:0.0006
[00:43:29.501] iteration:7272  t-loss:0.0263, loss-lb:0.0204, loss-ulb:0.0029, weight:2.00, lr:0.0006
[00:43:29.893] iteration:7273  t-loss:0.0387, loss-lb:0.0289, loss-ulb:0.0049, weight:2.00, lr:0.0006
[00:43:30.272] iteration:7274  t-loss:0.0343, loss-lb:0.0283, loss-ulb:0.0030, weight:2.00, lr:0.0006
[00:43:30.659] iteration:7275  t-loss:0.0432, loss-lb:0.0281, loss-ulb:0.0076, weight:2.00, lr:0.0006
[00:43:31.040] iteration:7276  t-loss:0.0741, loss-lb:0.0272, loss-ulb:0.0234, weight:2.00, lr:0.0006
[00:43:31.422] iteration:7277  t-loss:0.0201, loss-lb:0.0156, loss-ulb:0.0023, weight:2.00, lr:0.0006
[00:43:31.805] iteration:7278  t-loss:0.0544, loss-lb:0.0263, loss-ulb:0.0140, weight:2.00, lr:0.0006
[00:43:32.186] iteration:7279  t-loss:0.0220, loss-lb:0.0178, loss-ulb:0.0021, weight:2.00, lr:0.0006
[00:43:32.566] iteration:7280  t-loss:0.0489, loss-lb:0.0364, loss-ulb:0.0062, weight:2.00, lr:0.0006
[00:43:32.950] iteration:7281  t-loss:0.0255, loss-lb:0.0204, loss-ulb:0.0025, weight:2.00, lr:0.0006
[00:43:33.332] iteration:7282  t-loss:0.0819, loss-lb:0.0293, loss-ulb:0.0263, weight:2.00, lr:0.0005
[00:43:33.717] iteration:7283  t-loss:0.0355, loss-lb:0.0168, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:43:34.099] iteration:7284  t-loss:0.0489, loss-lb:0.0167, loss-ulb:0.0161, weight:2.00, lr:0.0005
[00:43:34.485] iteration:7285  t-loss:0.0301, loss-lb:0.0165, loss-ulb:0.0068, weight:2.00, lr:0.0005
[00:43:34.871] iteration:7286  t-loss:0.0609, loss-lb:0.0228, loss-ulb:0.0191, weight:2.00, lr:0.0005
[00:43:35.249] iteration:7287  t-loss:0.0398, loss-lb:0.0298, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:43:35.631] iteration:7288  t-loss:0.0266, loss-lb:0.0162, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:43:36.016] iteration:7289  t-loss:0.0820, loss-lb:0.0440, loss-ulb:0.0190, weight:2.00, lr:0.0005
[00:43:36.396] iteration:7290  t-loss:0.0323, loss-lb:0.0219, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:43:36.773] iteration:7291  t-loss:0.0610, loss-lb:0.0546, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:43:37.146] iteration:7292  t-loss:0.0286, loss-lb:0.0189, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:43:37.523] iteration:7293  t-loss:0.0440, loss-lb:0.0379, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:43:37.902] iteration:7294  t-loss:0.0482, loss-lb:0.0441, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:43:38.281] iteration:7295  t-loss:0.0463, loss-lb:0.0193, loss-ulb:0.0135, weight:2.00, lr:0.0005
[00:43:38.658] iteration:7296  t-loss:0.0631, loss-lb:0.0591, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:43:39.901] iteration:7297  t-loss:0.0513, loss-lb:0.0305, loss-ulb:0.0104, weight:2.00, lr:0.0005
[00:43:40.295] iteration:7298  t-loss:0.1046, loss-lb:0.0376, loss-ulb:0.0335, weight:2.00, lr:0.0005
[00:43:40.683] iteration:7299  t-loss:0.0583, loss-lb:0.0188, loss-ulb:0.0198, weight:2.00, lr:0.0005
[00:43:41.069] iteration:7300  t-loss:0.0321, loss-lb:0.0222, loss-ulb:0.0049, weight:2.00, lr:0.0005
[00:43:41.456] iteration:7301  t-loss:0.0663, loss-lb:0.0526, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:43:41.845] iteration:7302  t-loss:0.0543, loss-lb:0.0274, loss-ulb:0.0134, weight:2.00, lr:0.0005
[00:43:42.231] iteration:7303  t-loss:0.0585, loss-lb:0.0436, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:43:42.611] iteration:7304  t-loss:0.0568, loss-lb:0.0423, loss-ulb:0.0073, weight:2.00, lr:0.0005
[00:43:42.986] iteration:7305  t-loss:0.0726, loss-lb:0.0667, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:43:43.372] iteration:7306  t-loss:0.0427, loss-lb:0.0266, loss-ulb:0.0081, weight:2.00, lr:0.0005
[00:43:43.754] iteration:7307  t-loss:0.0508, loss-lb:0.0154, loss-ulb:0.0177, weight:2.00, lr:0.0005
[00:43:44.135] iteration:7308  t-loss:0.0369, loss-lb:0.0221, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:43:44.517] iteration:7309  t-loss:0.0376, loss-lb:0.0171, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:43:44.901] iteration:7310  t-loss:0.0332, loss-lb:0.0276, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:43:45.281] iteration:7311  t-loss:0.0422, loss-lb:0.0270, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:43:45.672] iteration:7312  t-loss:0.0503, loss-lb:0.0206, loss-ulb:0.0149, weight:2.00, lr:0.0005
[00:43:46.053] iteration:7313  t-loss:0.0807, loss-lb:0.0322, loss-ulb:0.0243, weight:2.00, lr:0.0005
[00:43:46.438] iteration:7314  t-loss:0.0414, loss-lb:0.0236, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:43:46.819] iteration:7315  t-loss:0.0527, loss-lb:0.0203, loss-ulb:0.0162, weight:2.00, lr:0.0005
[00:43:47.206] iteration:7316  t-loss:0.0293, loss-lb:0.0154, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:43:47.592] iteration:7317  t-loss:0.0462, loss-lb:0.0406, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:43:47.978] iteration:7318  t-loss:0.0664, loss-lb:0.0162, loss-ulb:0.0251, weight:2.00, lr:0.0005
[00:43:48.362] iteration:7319  t-loss:0.0320, loss-lb:0.0164, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:43:48.742] iteration:7320  t-loss:0.0243, loss-lb:0.0130, loss-ulb:0.0057, weight:2.00, lr:0.0005
[00:43:49.127] iteration:7321  t-loss:0.0387, loss-lb:0.0175, loss-ulb:0.0106, weight:2.00, lr:0.0005
[00:43:49.513] iteration:7322  t-loss:0.0293, loss-lb:0.0170, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:43:49.905] iteration:7323  t-loss:0.0411, loss-lb:0.0305, loss-ulb:0.0053, weight:2.00, lr:0.0005
[00:43:50.288] iteration:7324  t-loss:0.0422, loss-lb:0.0355, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:43:50.666] iteration:7325  t-loss:0.0195, loss-lb:0.0148, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:43:51.046] iteration:7326  t-loss:0.0284, loss-lb:0.0214, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:43:51.427] iteration:7327  t-loss:0.0808, loss-lb:0.0360, loss-ulb:0.0224, weight:2.00, lr:0.0005
[00:43:51.809] iteration:7328  t-loss:0.0473, loss-lb:0.0291, loss-ulb:0.0091, weight:2.00, lr:0.0005
[00:43:52.184] iteration:7329  t-loss:0.0344, loss-lb:0.0280, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:43:52.558] iteration:7330  t-loss:0.0327, loss-lb:0.0260, loss-ulb:0.0033, weight:2.00, lr:0.0005
[00:43:52.946] iteration:7331  t-loss:0.0254, loss-lb:0.0191, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:43:53.339] iteration:7332  t-loss:0.0435, loss-lb:0.0134, loss-ulb:0.0151, weight:2.00, lr:0.0005
[00:43:53.718] iteration:7333  t-loss:0.0333, loss-lb:0.0228, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:43:54.093] iteration:7334  t-loss:0.0491, loss-lb:0.0153, loss-ulb:0.0169, weight:2.00, lr:0.0005
[00:44:55.917] iteration 7334 : dice_score: 0.882009 best_dice: 0.889700
[00:44:55.917]  <<Test>> - Ep:192  - Dice-S/T:87.41/88.20, Best-S:88.88, Best-T:88.97
[00:44:55.917]           - AvgLoss(lb/ulb/all):0.03/0.01/0.04
[00:44:57.125] iteration:7335  t-loss:0.0609, loss-lb:0.0239, loss-ulb:0.0185, weight:2.00, lr:0.0005
[00:44:57.537] iteration:7336  t-loss:0.0223, loss-lb:0.0172, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:44:57.929] iteration:7337  t-loss:0.0506, loss-lb:0.0341, loss-ulb:0.0082, weight:2.00, lr:0.0005
[00:44:58.309] iteration:7338  t-loss:0.0254, loss-lb:0.0197, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:44:58.691] iteration:7339  t-loss:0.0233, loss-lb:0.0152, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:44:59.074] iteration:7340  t-loss:0.0479, loss-lb:0.0369, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:44:59.453] iteration:7341  t-loss:0.0248, loss-lb:0.0185, loss-ulb:0.0031, weight:2.00, lr:0.0005
[00:44:59.839] iteration:7342  t-loss:0.0428, loss-lb:0.0362, loss-ulb:0.0033, weight:2.00, lr:0.0005
[00:45:00.226] iteration:7343  t-loss:0.0547, loss-lb:0.0377, loss-ulb:0.0085, weight:2.00, lr:0.0005
[00:45:00.614] iteration:7344  t-loss:0.0470, loss-lb:0.0353, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:45:00.997] iteration:7345  t-loss:0.0638, loss-lb:0.0190, loss-ulb:0.0224, weight:2.00, lr:0.0005
[00:45:01.384] iteration:7346  t-loss:0.0777, loss-lb:0.0248, loss-ulb:0.0264, weight:2.00, lr:0.0005
[00:45:01.771] iteration:7347  t-loss:0.0349, loss-lb:0.0206, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:45:02.153] iteration:7348  t-loss:0.0607, loss-lb:0.0556, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:45:02.533] iteration:7349  t-loss:0.0247, loss-lb:0.0203, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:45:02.920] iteration:7350  t-loss:0.0381, loss-lb:0.0161, loss-ulb:0.0110, weight:2.00, lr:0.0005
[00:45:03.305] iteration:7351  t-loss:0.0388, loss-lb:0.0157, loss-ulb:0.0116, weight:2.00, lr:0.0005
[00:45:03.683] iteration:7352  t-loss:0.0350, loss-lb:0.0172, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:45:04.061] iteration:7353  t-loss:0.0291, loss-lb:0.0234, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:45:04.446] iteration:7354  t-loss:0.0632, loss-lb:0.0297, loss-ulb:0.0167, weight:2.00, lr:0.0005
[00:45:04.827] iteration:7355  t-loss:0.0387, loss-lb:0.0180, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:45:05.212] iteration:7356  t-loss:0.0717, loss-lb:0.0190, loss-ulb:0.0264, weight:2.00, lr:0.0005
[00:45:05.589] iteration:7357  t-loss:0.0752, loss-lb:0.0195, loss-ulb:0.0278, weight:2.00, lr:0.0005
[00:45:05.969] iteration:7358  t-loss:0.0328, loss-lb:0.0169, loss-ulb:0.0079, weight:2.00, lr:0.0005
[00:45:06.352] iteration:7359  t-loss:0.0660, loss-lb:0.0421, loss-ulb:0.0119, weight:2.00, lr:0.0005
[00:45:06.733] iteration:7360  t-loss:0.0722, loss-lb:0.0482, loss-ulb:0.0120, weight:2.00, lr:0.0005
[00:45:07.110] iteration:7361  t-loss:0.0822, loss-lb:0.0454, loss-ulb:0.0184, weight:2.00, lr:0.0005
[00:45:07.490] iteration:7362  t-loss:0.0869, loss-lb:0.0433, loss-ulb:0.0218, weight:2.00, lr:0.0005
[00:45:07.867] iteration:7363  t-loss:0.0660, loss-lb:0.0217, loss-ulb:0.0221, weight:2.00, lr:0.0005
[00:45:08.247] iteration:7364  t-loss:0.0453, loss-lb:0.0391, loss-ulb:0.0031, weight:2.00, lr:0.0005
[00:45:08.630] iteration:7365  t-loss:0.0616, loss-lb:0.0496, loss-ulb:0.0060, weight:2.00, lr:0.0005
[00:45:09.016] iteration:7366  t-loss:0.0785, loss-lb:0.0433, loss-ulb:0.0176, weight:2.00, lr:0.0005
[00:45:09.403] iteration:7367  t-loss:0.0675, loss-lb:0.0251, loss-ulb:0.0212, weight:2.00, lr:0.0005
[00:45:09.789] iteration:7368  t-loss:0.0862, loss-lb:0.0168, loss-ulb:0.0347, weight:2.00, lr:0.0005
[00:45:10.166] iteration:7369  t-loss:0.0397, loss-lb:0.0239, loss-ulb:0.0079, weight:2.00, lr:0.0005
[00:45:10.538] iteration:7370  t-loss:0.0383, loss-lb:0.0276, loss-ulb:0.0053, weight:2.00, lr:0.0005
[00:45:10.915] iteration:7371  t-loss:0.0538, loss-lb:0.0284, loss-ulb:0.0127, weight:2.00, lr:0.0005
[00:45:11.291] iteration:7372  t-loss:0.0531, loss-lb:0.0450, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:45:12.637] iteration:7373  t-loss:0.0530, loss-lb:0.0400, loss-ulb:0.0065, weight:2.00, lr:0.0005
[00:45:13.035] iteration:7374  t-loss:0.0465, loss-lb:0.0396, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:45:13.417] iteration:7375  t-loss:0.0671, loss-lb:0.0265, loss-ulb:0.0203, weight:2.00, lr:0.0005
[00:45:13.796] iteration:7376  t-loss:0.0416, loss-lb:0.0372, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:45:14.183] iteration:7377  t-loss:0.0514, loss-lb:0.0200, loss-ulb:0.0157, weight:2.00, lr:0.0005
[00:45:14.565] iteration:7378  t-loss:0.0549, loss-lb:0.0210, loss-ulb:0.0170, weight:2.00, lr:0.0005
[00:45:14.970] iteration:7379  t-loss:0.0463, loss-lb:0.0435, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:45:15.398] iteration:7380  t-loss:0.0559, loss-lb:0.0424, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:45:15.798] iteration:7381  t-loss:0.0287, loss-lb:0.0207, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:45:16.191] iteration:7382  t-loss:0.0321, loss-lb:0.0268, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:45:16.572] iteration:7383  t-loss:0.0655, loss-lb:0.0230, loss-ulb:0.0213, weight:2.00, lr:0.0005
[00:45:16.957] iteration:7384  t-loss:0.0303, loss-lb:0.0230, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:45:17.343] iteration:7385  t-loss:0.0578, loss-lb:0.0305, loss-ulb:0.0136, weight:2.00, lr:0.0005
[00:45:17.734] iteration:7386  t-loss:0.1041, loss-lb:0.0843, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:45:18.117] iteration:7387  t-loss:0.0390, loss-lb:0.0268, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:45:18.499] iteration:7388  t-loss:0.0516, loss-lb:0.0279, loss-ulb:0.0118, weight:2.00, lr:0.0005
[00:45:18.879] iteration:7389  t-loss:0.0237, loss-lb:0.0208, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:45:19.269] iteration:7390  t-loss:0.0855, loss-lb:0.0603, loss-ulb:0.0126, weight:2.00, lr:0.0005
[00:45:19.657] iteration:7391  t-loss:0.0633, loss-lb:0.0281, loss-ulb:0.0176, weight:2.00, lr:0.0005
[00:45:20.043] iteration:7392  t-loss:0.0774, loss-lb:0.0557, loss-ulb:0.0108, weight:2.00, lr:0.0005
[00:45:20.416] iteration:7393  t-loss:0.0642, loss-lb:0.0243, loss-ulb:0.0200, weight:2.00, lr:0.0005
[00:45:20.803] iteration:7394  t-loss:0.0766, loss-lb:0.0705, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:45:21.183] iteration:7395  t-loss:0.0343, loss-lb:0.0311, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:45:21.566] iteration:7396  t-loss:0.0951, loss-lb:0.0611, loss-ulb:0.0170, weight:2.00, lr:0.0005
[00:45:21.941] iteration:7397  t-loss:0.0393, loss-lb:0.0218, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:45:22.322] iteration:7398  t-loss:0.0551, loss-lb:0.0164, loss-ulb:0.0194, weight:2.00, lr:0.0005
[00:45:22.698] iteration:7399  t-loss:0.0349, loss-lb:0.0154, loss-ulb:0.0098, weight:2.00, lr:0.0005
[00:45:23.079] iteration:7400  t-loss:0.0358, loss-lb:0.0230, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:45:23.453] iteration:7401  t-loss:0.0301, loss-lb:0.0206, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:45:23.828] iteration:7402  t-loss:0.0281, loss-lb:0.0221, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:45:24.206] iteration:7403  t-loss:0.0515, loss-lb:0.0173, loss-ulb:0.0171, weight:2.00, lr:0.0005
[00:45:24.585] iteration:7404  t-loss:0.0677, loss-lb:0.0409, loss-ulb:0.0134, weight:2.00, lr:0.0005
[00:45:24.964] iteration:7405  t-loss:0.0471, loss-lb:0.0435, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:45:25.337] iteration:7406  t-loss:0.0461, loss-lb:0.0322, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:45:25.725] iteration:7407  t-loss:0.0697, loss-lb:0.0430, loss-ulb:0.0134, weight:2.00, lr:0.0005
[00:45:26.108] iteration:7408  t-loss:0.0278, loss-lb:0.0253, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:45:26.484] iteration:7409  t-loss:0.0564, loss-lb:0.0368, loss-ulb:0.0098, weight:2.00, lr:0.0005
[00:45:26.859] iteration:7410  t-loss:0.0671, loss-lb:0.0183, loss-ulb:0.0244, weight:2.00, lr:0.0005
[00:45:28.168] iteration:7411  t-loss:0.0587, loss-lb:0.0394, loss-ulb:0.0097, weight:2.00, lr:0.0005
[00:45:28.560] iteration:7412  t-loss:0.0524, loss-lb:0.0281, loss-ulb:0.0122, weight:2.00, lr:0.0005
[00:45:28.941] iteration:7413  t-loss:0.0435, loss-lb:0.0228, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:45:29.327] iteration:7414  t-loss:0.0858, loss-lb:0.0217, loss-ulb:0.0320, weight:2.00, lr:0.0005
[00:45:29.706] iteration:7415  t-loss:0.0345, loss-lb:0.0318, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:45:30.083] iteration:7416  t-loss:0.0250, loss-lb:0.0188, loss-ulb:0.0031, weight:2.00, lr:0.0005
[00:45:30.467] iteration:7417  t-loss:0.0503, loss-lb:0.0271, loss-ulb:0.0116, weight:2.00, lr:0.0005
[00:45:30.858] iteration:7418  t-loss:0.0429, loss-lb:0.0191, loss-ulb:0.0119, weight:2.00, lr:0.0005
[00:45:31.240] iteration:7419  t-loss:0.0402, loss-lb:0.0207, loss-ulb:0.0097, weight:2.00, lr:0.0005
[00:45:31.628] iteration:7420  t-loss:0.0491, loss-lb:0.0362, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:45:32.017] iteration:7421  t-loss:0.0505, loss-lb:0.0333, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:45:32.403] iteration:7422  t-loss:0.0223, loss-lb:0.0190, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:45:32.792] iteration:7423  t-loss:0.0641, loss-lb:0.0525, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:45:33.174] iteration:7424  t-loss:0.0725, loss-lb:0.0682, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:45:33.557] iteration:7425  t-loss:0.0266, loss-lb:0.0245, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:45:33.945] iteration:7426  t-loss:0.0919, loss-lb:0.0736, loss-ulb:0.0091, weight:2.00, lr:0.0005
[00:45:34.321] iteration:7427  t-loss:0.0375, loss-lb:0.0166, loss-ulb:0.0105, weight:2.00, lr:0.0005
[00:45:34.707] iteration:7428  t-loss:0.0456, loss-lb:0.0236, loss-ulb:0.0110, weight:2.00, lr:0.0005
[00:45:35.087] iteration:7429  t-loss:0.0223, loss-lb:0.0194, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:45:35.473] iteration:7430  t-loss:0.0561, loss-lb:0.0319, loss-ulb:0.0121, weight:2.00, lr:0.0005
[00:45:35.855] iteration:7431  t-loss:0.0484, loss-lb:0.0180, loss-ulb:0.0152, weight:2.00, lr:0.0005
[00:45:36.240] iteration:7432  t-loss:0.0515, loss-lb:0.0182, loss-ulb:0.0167, weight:2.00, lr:0.0005
[00:45:36.623] iteration:7433  t-loss:0.0334, loss-lb:0.0275, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:45:37.005] iteration:7434  t-loss:0.0543, loss-lb:0.0489, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:45:37.384] iteration:7435  t-loss:0.0490, loss-lb:0.0345, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:45:37.770] iteration:7436  t-loss:0.0429, loss-lb:0.0344, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:45:38.154] iteration:7437  t-loss:0.0244, loss-lb:0.0160, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:45:38.537] iteration:7438  t-loss:0.0353, loss-lb:0.0295, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:45:38.920] iteration:7439  t-loss:0.0422, loss-lb:0.0178, loss-ulb:0.0122, weight:2.00, lr:0.0005
[00:45:39.299] iteration:7440  t-loss:0.0459, loss-lb:0.0368, loss-ulb:0.0046, weight:2.00, lr:0.0005
[00:45:39.664] iteration:7441  t-loss:0.0223, loss-lb:0.0176, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:45:40.044] iteration:7442  t-loss:0.0646, loss-lb:0.0325, loss-ulb:0.0160, weight:2.00, lr:0.0005
[00:45:40.425] iteration:7443  t-loss:0.0855, loss-lb:0.0538, loss-ulb:0.0159, weight:2.00, lr:0.0005
[00:45:40.786] iteration:7444  t-loss:0.0292, loss-lb:0.0244, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:45:41.165] iteration:7445  t-loss:0.0547, loss-lb:0.0413, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:45:41.539] iteration:7446  t-loss:0.0190, loss-lb:0.0133, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:45:41.921] iteration:7447  t-loss:0.0502, loss-lb:0.0315, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:45:42.301] iteration:7448  t-loss:0.0641, loss-lb:0.0375, loss-ulb:0.0133, weight:2.00, lr:0.0005
[00:45:43.569] iteration:7449  t-loss:0.0637, loss-lb:0.0471, loss-ulb:0.0083, weight:2.00, lr:0.0005
[00:45:43.956] iteration:7450  t-loss:0.0924, loss-lb:0.0344, loss-ulb:0.0290, weight:2.00, lr:0.0005
[00:45:44.334] iteration:7451  t-loss:0.0326, loss-lb:0.0241, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:45:44.714] iteration:7452  t-loss:0.0482, loss-lb:0.0306, loss-ulb:0.0088, weight:2.00, lr:0.0005
[00:45:45.096] iteration:7453  t-loss:0.0610, loss-lb:0.0389, loss-ulb:0.0111, weight:2.00, lr:0.0005
[00:45:45.476] iteration:7454  t-loss:0.0516, loss-lb:0.0327, loss-ulb:0.0095, weight:2.00, lr:0.0005
[00:45:45.866] iteration:7455  t-loss:0.0565, loss-lb:0.0370, loss-ulb:0.0097, weight:2.00, lr:0.0005
[00:45:46.250] iteration:7456  t-loss:0.0510, loss-lb:0.0163, loss-ulb:0.0173, weight:2.00, lr:0.0005
[00:45:46.632] iteration:7457  t-loss:0.0217, loss-lb:0.0171, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:45:47.016] iteration:7458  t-loss:0.0642, loss-lb:0.0535, loss-ulb:0.0054, weight:2.00, lr:0.0005
[00:45:47.399] iteration:7459  t-loss:0.0466, loss-lb:0.0416, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:45:47.780] iteration:7460  t-loss:0.0420, loss-lb:0.0171, loss-ulb:0.0124, weight:2.00, lr:0.0005
[00:45:48.160] iteration:7461  t-loss:0.0361, loss-lb:0.0330, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:45:48.541] iteration:7462  t-loss:0.0279, loss-lb:0.0236, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:45:48.929] iteration:7463  t-loss:0.0383, loss-lb:0.0363, loss-ulb:0.0010, weight:2.00, lr:0.0005
[00:45:49.305] iteration:7464  t-loss:0.0210, loss-lb:0.0159, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:45:49.689] iteration:7465  t-loss:0.0483, loss-lb:0.0166, loss-ulb:0.0158, weight:2.00, lr:0.0005
[00:45:50.068] iteration:7466  t-loss:0.0408, loss-lb:0.0188, loss-ulb:0.0110, weight:2.00, lr:0.0005
[00:45:50.446] iteration:7467  t-loss:0.0277, loss-lb:0.0202, loss-ulb:0.0037, weight:2.00, lr:0.0005
[00:45:50.826] iteration:7468  t-loss:0.0404, loss-lb:0.0368, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:45:51.203] iteration:7469  t-loss:0.0344, loss-lb:0.0174, loss-ulb:0.0085, weight:2.00, lr:0.0005
[00:45:51.589] iteration:7470  t-loss:0.0444, loss-lb:0.0308, loss-ulb:0.0068, weight:2.00, lr:0.0005
[00:45:51.973] iteration:7471  t-loss:0.0256, loss-lb:0.0156, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:45:52.352] iteration:7472  t-loss:0.0433, loss-lb:0.0239, loss-ulb:0.0097, weight:2.00, lr:0.0005
[00:45:52.730] iteration:7473  t-loss:0.0323, loss-lb:0.0288, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:45:53.116] iteration:7474  t-loss:0.0362, loss-lb:0.0288, loss-ulb:0.0037, weight:2.00, lr:0.0005
[00:45:53.495] iteration:7475  t-loss:0.0357, loss-lb:0.0299, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:45:53.869] iteration:7476  t-loss:0.0339, loss-lb:0.0190, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:45:54.250] iteration:7477  t-loss:0.0274, loss-lb:0.0241, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:45:54.635] iteration:7478  t-loss:0.0547, loss-lb:0.0415, loss-ulb:0.0066, weight:2.00, lr:0.0005
[00:45:55.011] iteration:7479  t-loss:0.0170, loss-lb:0.0142, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:45:55.389] iteration:7480  t-loss:0.0526, loss-lb:0.0313, loss-ulb:0.0106, weight:2.00, lr:0.0005
[00:45:55.769] iteration:7481  t-loss:0.0516, loss-lb:0.0210, loss-ulb:0.0153, weight:2.00, lr:0.0005
[00:45:56.142] iteration:7482  t-loss:0.0519, loss-lb:0.0494, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:45:56.523] iteration:7483  t-loss:0.0800, loss-lb:0.0432, loss-ulb:0.0184, weight:2.00, lr:0.0005
[00:45:56.901] iteration:7484  t-loss:0.0582, loss-lb:0.0332, loss-ulb:0.0125, weight:2.00, lr:0.0005
[00:45:57.278] iteration:7485  t-loss:0.0287, loss-lb:0.0263, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:45:57.653] iteration:7486  t-loss:0.0210, loss-lb:0.0181, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:46:59.626] iteration 7486 : dice_score: 0.855523 best_dice: 0.889700
[00:46:59.626]  <<Test>> - Ep:196  - Dice-S/T:84.05/85.55, Best-S:88.88, Best-T:88.97
[00:46:59.627]           - AvgLoss(lb/ulb/all):0.03/0.01/0.04
[00:47:00.795] iteration:7487  t-loss:0.0529, loss-lb:0.0342, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:47:01.219] iteration:7488  t-loss:0.0372, loss-lb:0.0301, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:47:01.613] iteration:7489  t-loss:0.0738, loss-lb:0.0570, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:47:01.998] iteration:7490  t-loss:0.0308, loss-lb:0.0249, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:47:02.385] iteration:7491  t-loss:0.0276, loss-lb:0.0167, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:47:02.765] iteration:7492  t-loss:0.0337, loss-lb:0.0313, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:47:03.148] iteration:7493  t-loss:0.0179, loss-lb:0.0146, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:47:03.532] iteration:7494  t-loss:0.0465, loss-lb:0.0296, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:47:03.914] iteration:7495  t-loss:0.0839, loss-lb:0.0732, loss-ulb:0.0053, weight:2.00, lr:0.0005
[00:47:04.295] iteration:7496  t-loss:0.0431, loss-lb:0.0407, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:47:04.689] iteration:7497  t-loss:0.0312, loss-lb:0.0273, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:47:05.072] iteration:7498  t-loss:0.0604, loss-lb:0.0337, loss-ulb:0.0134, weight:2.00, lr:0.0005
[00:47:05.449] iteration:7499  t-loss:0.0441, loss-lb:0.0263, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:47:05.832] iteration:7500  t-loss:0.0286, loss-lb:0.0186, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:47:06.214] iteration:7501  t-loss:0.0690, loss-lb:0.0363, loss-ulb:0.0163, weight:2.00, lr:0.0005
[00:47:06.601] iteration:7502  t-loss:0.0535, loss-lb:0.0264, loss-ulb:0.0135, weight:2.00, lr:0.0005
[00:47:06.989] iteration:7503  t-loss:0.0542, loss-lb:0.0304, loss-ulb:0.0119, weight:2.00, lr:0.0005
[00:47:07.372] iteration:7504  t-loss:0.0562, loss-lb:0.0394, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:47:07.764] iteration:7505  t-loss:0.0462, loss-lb:0.0313, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:47:08.157] iteration:7506  t-loss:0.0413, loss-lb:0.0370, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:47:08.539] iteration:7507  t-loss:0.0359, loss-lb:0.0312, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:47:08.922] iteration:7508  t-loss:0.0397, loss-lb:0.0242, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:47:09.303] iteration:7509  t-loss:0.0282, loss-lb:0.0164, loss-ulb:0.0059, weight:2.00, lr:0.0005
[00:47:09.693] iteration:7510  t-loss:0.0610, loss-lb:0.0359, loss-ulb:0.0125, weight:2.00, lr:0.0005
[00:47:10.074] iteration:7511  t-loss:0.0312, loss-lb:0.0219, loss-ulb:0.0046, weight:2.00, lr:0.0005
[00:47:10.453] iteration:7512  t-loss:0.0257, loss-lb:0.0231, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:47:10.830] iteration:7513  t-loss:0.0215, loss-lb:0.0164, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:47:11.212] iteration:7514  t-loss:0.0194, loss-lb:0.0147, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:47:11.587] iteration:7515  t-loss:0.0279, loss-lb:0.0236, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:47:11.967] iteration:7516  t-loss:0.0487, loss-lb:0.0263, loss-ulb:0.0112, weight:2.00, lr:0.0005
[00:47:12.345] iteration:7517  t-loss:0.0307, loss-lb:0.0278, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:47:12.721] iteration:7518  t-loss:0.0332, loss-lb:0.0206, loss-ulb:0.0063, weight:2.00, lr:0.0005
[00:47:13.095] iteration:7519  t-loss:0.0336, loss-lb:0.0295, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:47:13.471] iteration:7520  t-loss:0.0344, loss-lb:0.0313, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:47:13.847] iteration:7521  t-loss:0.0201, loss-lb:0.0179, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:47:14.234] iteration:7522  t-loss:0.0199, loss-lb:0.0160, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:47:14.633] iteration:7523  t-loss:0.0559, loss-lb:0.0157, loss-ulb:0.0201, weight:2.00, lr:0.0005
[00:47:15.024] iteration:7524  t-loss:0.0366, loss-lb:0.0285, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:47:16.324] iteration:7525  t-loss:0.0785, loss-lb:0.0494, loss-ulb:0.0145, weight:2.00, lr:0.0005
[00:47:16.706] iteration:7526  t-loss:0.0262, loss-lb:0.0214, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:47:17.096] iteration:7527  t-loss:0.0426, loss-lb:0.0171, loss-ulb:0.0128, weight:2.00, lr:0.0005
[00:47:17.475] iteration:7528  t-loss:0.0206, loss-lb:0.0164, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:47:17.858] iteration:7529  t-loss:0.0344, loss-lb:0.0203, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:47:18.240] iteration:7530  t-loss:0.0223, loss-lb:0.0212, loss-ulb:0.0006, weight:2.00, lr:0.0005
[00:47:18.623] iteration:7531  t-loss:0.0361, loss-lb:0.0159, loss-ulb:0.0101, weight:2.00, lr:0.0005
[00:47:19.011] iteration:7532  t-loss:0.0291, loss-lb:0.0176, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:47:19.388] iteration:7533  t-loss:0.0359, loss-lb:0.0126, loss-ulb:0.0117, weight:2.00, lr:0.0005
[00:47:19.772] iteration:7534  t-loss:0.0701, loss-lb:0.0360, loss-ulb:0.0170, weight:2.00, lr:0.0005
[00:47:20.149] iteration:7535  t-loss:0.0201, loss-lb:0.0161, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:47:20.526] iteration:7536  t-loss:0.0327, loss-lb:0.0186, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:47:20.911] iteration:7537  t-loss:0.0501, loss-lb:0.0241, loss-ulb:0.0130, weight:2.00, lr:0.0005
[00:47:21.304] iteration:7538  t-loss:0.0539, loss-lb:0.0423, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:47:21.694] iteration:7539  t-loss:0.0352, loss-lb:0.0285, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:47:22.078] iteration:7540  t-loss:0.0574, loss-lb:0.0269, loss-ulb:0.0153, weight:2.00, lr:0.0005
[00:47:22.458] iteration:7541  t-loss:0.0298, loss-lb:0.0249, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:47:22.845] iteration:7542  t-loss:0.0629, loss-lb:0.0331, loss-ulb:0.0149, weight:2.00, lr:0.0005
[00:47:23.225] iteration:7543  t-loss:0.0339, loss-lb:0.0260, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:47:23.605] iteration:7544  t-loss:0.0402, loss-lb:0.0350, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:47:23.986] iteration:7545  t-loss:0.0343, loss-lb:0.0273, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:47:24.370] iteration:7546  t-loss:0.0432, loss-lb:0.0311, loss-ulb:0.0060, weight:2.00, lr:0.0005
[00:47:24.754] iteration:7547  t-loss:0.0485, loss-lb:0.0400, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:47:25.131] iteration:7548  t-loss:0.0240, loss-lb:0.0190, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:47:25.512] iteration:7549  t-loss:0.0790, loss-lb:0.0415, loss-ulb:0.0188, weight:2.00, lr:0.0005
[00:47:25.897] iteration:7550  t-loss:0.0613, loss-lb:0.0301, loss-ulb:0.0156, weight:2.00, lr:0.0005
[00:47:26.277] iteration:7551  t-loss:0.0810, loss-lb:0.0221, loss-ulb:0.0294, weight:2.00, lr:0.0005
[00:47:26.652] iteration:7552  t-loss:0.0184, loss-lb:0.0139, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:47:27.031] iteration:7553  t-loss:0.0547, loss-lb:0.0477, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:47:27.419] iteration:7554  t-loss:0.0639, loss-lb:0.0284, loss-ulb:0.0178, weight:2.00, lr:0.0005
[00:47:27.795] iteration:7555  t-loss:0.0457, loss-lb:0.0396, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:47:28.171] iteration:7556  t-loss:0.0350, loss-lb:0.0136, loss-ulb:0.0107, weight:2.00, lr:0.0005
[00:47:28.547] iteration:7557  t-loss:0.0262, loss-lb:0.0160, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:47:28.924] iteration:7558  t-loss:0.0505, loss-lb:0.0271, loss-ulb:0.0117, weight:2.00, lr:0.0005
[00:47:29.302] iteration:7559  t-loss:0.0343, loss-lb:0.0192, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:47:29.686] iteration:7560  t-loss:0.0535, loss-lb:0.0365, loss-ulb:0.0085, weight:2.00, lr:0.0005
[00:47:30.067] iteration:7561  t-loss:0.0399, loss-lb:0.0279, loss-ulb:0.0060, weight:2.00, lr:0.0005
[00:47:30.442] iteration:7562  t-loss:0.0210, loss-lb:0.0187, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:47:31.589] iteration:7563  t-loss:0.0321, loss-lb:0.0300, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:47:31.991] iteration:7564  t-loss:0.0280, loss-lb:0.0187, loss-ulb:0.0046, weight:2.00, lr:0.0005
[00:47:32.380] iteration:7565  t-loss:0.0436, loss-lb:0.0268, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:47:32.768] iteration:7566  t-loss:0.0412, loss-lb:0.0373, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:47:33.156] iteration:7567  t-loss:0.0387, loss-lb:0.0304, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:47:33.537] iteration:7568  t-loss:0.0457, loss-lb:0.0360, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:47:33.921] iteration:7569  t-loss:0.0525, loss-lb:0.0464, loss-ulb:0.0031, weight:2.00, lr:0.0005
[00:47:34.305] iteration:7570  t-loss:0.0213, loss-lb:0.0140, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:47:34.689] iteration:7571  t-loss:0.0296, loss-lb:0.0159, loss-ulb:0.0068, weight:2.00, lr:0.0005
[00:47:35.070] iteration:7572  t-loss:0.0554, loss-lb:0.0167, loss-ulb:0.0194, weight:2.00, lr:0.0005
[00:47:35.449] iteration:7573  t-loss:0.0694, loss-lb:0.0253, loss-ulb:0.0220, weight:2.00, lr:0.0005
[00:47:35.835] iteration:7574  t-loss:0.0210, loss-lb:0.0166, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:47:36.236] iteration:7575  t-loss:0.0379, loss-lb:0.0231, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:47:36.622] iteration:7576  t-loss:0.0349, loss-lb:0.0316, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:47:37.007] iteration:7577  t-loss:0.0343, loss-lb:0.0211, loss-ulb:0.0066, weight:2.00, lr:0.0005
[00:47:37.396] iteration:7578  t-loss:0.0435, loss-lb:0.0312, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:47:37.785] iteration:7579  t-loss:0.0611, loss-lb:0.0587, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:47:38.168] iteration:7580  t-loss:0.0207, loss-lb:0.0161, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:47:38.549] iteration:7581  t-loss:0.0310, loss-lb:0.0169, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:47:38.938] iteration:7582  t-loss:0.0722, loss-lb:0.0349, loss-ulb:0.0187, weight:2.00, lr:0.0005
[00:47:39.320] iteration:7583  t-loss:0.0205, loss-lb:0.0162, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:47:39.704] iteration:7584  t-loss:0.0257, loss-lb:0.0203, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:47:40.084] iteration:7585  t-loss:0.0716, loss-lb:0.0335, loss-ulb:0.0191, weight:2.00, lr:0.0005
[00:47:40.474] iteration:7586  t-loss:0.0394, loss-lb:0.0302, loss-ulb:0.0046, weight:2.00, lr:0.0005
[00:47:40.872] iteration:7587  t-loss:0.0252, loss-lb:0.0229, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:47:41.258] iteration:7588  t-loss:0.0443, loss-lb:0.0414, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:47:41.643] iteration:7589  t-loss:0.0772, loss-lb:0.0260, loss-ulb:0.0256, weight:2.00, lr:0.0005
[00:47:42.028] iteration:7590  t-loss:0.0310, loss-lb:0.0177, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:47:42.417] iteration:7591  t-loss:0.0252, loss-lb:0.0224, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:47:42.797] iteration:7592  t-loss:0.0420, loss-lb:0.0391, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:47:43.175] iteration:7593  t-loss:0.0191, loss-lb:0.0155, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:47:43.554] iteration:7594  t-loss:0.0269, loss-lb:0.0168, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:47:43.938] iteration:7595  t-loss:0.0421, loss-lb:0.0215, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:47:44.316] iteration:7596  t-loss:0.0540, loss-lb:0.0493, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:47:44.694] iteration:7597  t-loss:0.0493, loss-lb:0.0454, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:47:45.077] iteration:7598  t-loss:0.0385, loss-lb:0.0247, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:47:45.456] iteration:7599  t-loss:0.0321, loss-lb:0.0303, loss-ulb:0.0009, weight:2.00, lr:0.0005
[00:47:45.838] iteration:7600  t-loss:0.0431, loss-lb:0.0284, loss-ulb:0.0073, weight:2.00, lr:0.0005
[00:47:47.190] iteration:7601  t-loss:0.0248, loss-lb:0.0166, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:47:47.594] iteration:7602  t-loss:0.0237, loss-lb:0.0154, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:47:47.984] iteration:7603  t-loss:0.0333, loss-lb:0.0135, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:47:48.373] iteration:7604  t-loss:0.0400, loss-lb:0.0368, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:47:48.758] iteration:7605  t-loss:0.0397, loss-lb:0.0312, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:47:49.137] iteration:7606  t-loss:0.0181, loss-lb:0.0129, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:47:49.519] iteration:7607  t-loss:0.0357, loss-lb:0.0179, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:47:49.900] iteration:7608  t-loss:0.0272, loss-lb:0.0153, loss-ulb:0.0059, weight:2.00, lr:0.0005
[00:47:50.282] iteration:7609  t-loss:0.0488, loss-lb:0.0315, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:47:50.665] iteration:7610  t-loss:0.0546, loss-lb:0.0256, loss-ulb:0.0145, weight:2.00, lr:0.0005
[00:47:51.051] iteration:7611  t-loss:0.0430, loss-lb:0.0328, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:47:51.436] iteration:7612  t-loss:0.0194, loss-lb:0.0149, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:47:51.827] iteration:7613  t-loss:0.0274, loss-lb:0.0132, loss-ulb:0.0071, weight:2.00, lr:0.0005
[00:47:52.211] iteration:7614  t-loss:0.0310, loss-lb:0.0276, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:47:52.598] iteration:7615  t-loss:0.0344, loss-lb:0.0165, loss-ulb:0.0090, weight:2.00, lr:0.0005
[00:47:52.984] iteration:7616  t-loss:0.0377, loss-lb:0.0163, loss-ulb:0.0107, weight:2.00, lr:0.0005
[00:47:53.366] iteration:7617  t-loss:0.0311, loss-lb:0.0275, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:47:53.754] iteration:7618  t-loss:0.0424, loss-lb:0.0182, loss-ulb:0.0121, weight:2.00, lr:0.0005
[00:47:54.139] iteration:7619  t-loss:0.0276, loss-lb:0.0148, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:47:54.525] iteration:7620  t-loss:0.0267, loss-lb:0.0246, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:47:54.909] iteration:7621  t-loss:0.0290, loss-lb:0.0136, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:47:55.293] iteration:7622  t-loss:0.0421, loss-lb:0.0173, loss-ulb:0.0124, weight:2.00, lr:0.0005
[00:47:55.683] iteration:7623  t-loss:0.0467, loss-lb:0.0384, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:47:56.070] iteration:7624  t-loss:0.0523, loss-lb:0.0483, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:47:56.451] iteration:7625  t-loss:0.0416, loss-lb:0.0233, loss-ulb:0.0091, weight:2.00, lr:0.0005
[00:47:56.834] iteration:7626  t-loss:0.0323, loss-lb:0.0238, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:47:57.214] iteration:7627  t-loss:0.0335, loss-lb:0.0301, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:47:57.599] iteration:7628  t-loss:0.0379, loss-lb:0.0304, loss-ulb:0.0038, weight:2.00, lr:0.0005
[00:47:57.978] iteration:7629  t-loss:0.0202, loss-lb:0.0145, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:47:58.359] iteration:7630  t-loss:0.0278, loss-lb:0.0130, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:47:58.750] iteration:7631  t-loss:0.0360, loss-lb:0.0339, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:47:59.133] iteration:7632  t-loss:0.0448, loss-lb:0.0278, loss-ulb:0.0085, weight:2.00, lr:0.0005
[00:47:59.513] iteration:7633  t-loss:0.0639, loss-lb:0.0293, loss-ulb:0.0173, weight:2.00, lr:0.0005
[00:47:59.886] iteration:7634  t-loss:0.1253, loss-lb:0.0152, loss-ulb:0.0550, weight:2.00, lr:0.0005
[00:48:00.271] iteration:7635  t-loss:0.0320, loss-lb:0.0177, loss-ulb:0.0071, weight:2.00, lr:0.0005
[00:48:00.651] iteration:7636  t-loss:0.0243, loss-lb:0.0144, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:48:01.028] iteration:7637  t-loss:0.0470, loss-lb:0.0430, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:48:01.407] iteration:7638  t-loss:0.0352, loss-lb:0.0163, loss-ulb:0.0095, weight:2.00, lr:0.0005
[00:49:05.072] iteration 7638 : dice_score: 0.883230 best_dice: 0.889700
[00:49:05.072]  <<Test>> - Ep:200  - Dice-S/T:87.21/88.32, Best-S:88.88, Best-T:88.97
[00:49:05.072]           - AvgLoss(lb/ulb/all):0.02/0.01/0.04
[00:49:06.099] iteration:7639  t-loss:0.0367, loss-lb:0.0268, loss-ulb:0.0049, weight:2.00, lr:0.0005
[00:49:06.503] iteration:7640  t-loss:0.0363, loss-lb:0.0160, loss-ulb:0.0102, weight:2.00, lr:0.0005
[00:49:06.902] iteration:7641  t-loss:0.0288, loss-lb:0.0265, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:07.313] iteration:7642  t-loss:0.0516, loss-lb:0.0134, loss-ulb:0.0191, weight:2.00, lr:0.0005
[00:49:07.712] iteration:7643  t-loss:0.0228, loss-lb:0.0170, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:49:08.094] iteration:7644  t-loss:0.0226, loss-lb:0.0180, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:49:08.476] iteration:7645  t-loss:0.0324, loss-lb:0.0269, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:49:08.857] iteration:7646  t-loss:0.0415, loss-lb:0.0397, loss-ulb:0.0009, weight:2.00, lr:0.0005
[00:49:09.239] iteration:7647  t-loss:0.0148, loss-lb:0.0124, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:09.619] iteration:7648  t-loss:0.0334, loss-lb:0.0299, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:49:09.997] iteration:7649  t-loss:0.0177, loss-lb:0.0122, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:49:10.378] iteration:7650  t-loss:0.0691, loss-lb:0.0505, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:49:10.758] iteration:7651  t-loss:0.0342, loss-lb:0.0146, loss-ulb:0.0098, weight:2.00, lr:0.0005
[00:49:11.139] iteration:7652  t-loss:0.0230, loss-lb:0.0134, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:49:11.523] iteration:7653  t-loss:0.0317, loss-lb:0.0146, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:49:11.909] iteration:7654  t-loss:0.0566, loss-lb:0.0426, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:49:12.287] iteration:7655  t-loss:0.0162, loss-lb:0.0132, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:49:12.679] iteration:7656  t-loss:0.0457, loss-lb:0.0331, loss-ulb:0.0063, weight:2.00, lr:0.0005
[00:49:13.064] iteration:7657  t-loss:0.0698, loss-lb:0.0158, loss-ulb:0.0270, weight:2.00, lr:0.0005
[00:49:13.449] iteration:7658  t-loss:0.0487, loss-lb:0.0429, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:49:13.827] iteration:7659  t-loss:0.0796, loss-lb:0.0764, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:49:14.210] iteration:7660  t-loss:0.0340, loss-lb:0.0299, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:49:14.597] iteration:7661  t-loss:0.0625, loss-lb:0.0508, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:49:14.983] iteration:7662  t-loss:0.0634, loss-lb:0.0357, loss-ulb:0.0138, weight:2.00, lr:0.0005
[00:49:15.365] iteration:7663  t-loss:0.0329, loss-lb:0.0150, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:49:15.748] iteration:7664  t-loss:0.0270, loss-lb:0.0176, loss-ulb:0.0047, weight:2.00, lr:0.0005
[00:49:16.128] iteration:7665  t-loss:0.0198, loss-lb:0.0173, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:16.508] iteration:7666  t-loss:0.0449, loss-lb:0.0414, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:49:16.890] iteration:7667  t-loss:0.0394, loss-lb:0.0293, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:49:17.275] iteration:7668  t-loss:0.0747, loss-lb:0.0336, loss-ulb:0.0205, weight:2.00, lr:0.0005
[00:49:17.657] iteration:7669  t-loss:0.0317, loss-lb:0.0208, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:49:18.034] iteration:7670  t-loss:0.0693, loss-lb:0.0673, loss-ulb:0.0010, weight:2.00, lr:0.0005
[00:49:18.414] iteration:7671  t-loss:0.0430, loss-lb:0.0328, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:49:18.790] iteration:7672  t-loss:0.0324, loss-lb:0.0130, loss-ulb:0.0097, weight:2.00, lr:0.0005
[00:49:19.165] iteration:7673  t-loss:0.0241, loss-lb:0.0125, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:49:19.542] iteration:7674  t-loss:0.0408, loss-lb:0.0294, loss-ulb:0.0057, weight:2.00, lr:0.0005
[00:49:19.919] iteration:7675  t-loss:0.0653, loss-lb:0.0155, loss-ulb:0.0249, weight:2.00, lr:0.0005
[00:49:20.293] iteration:7676  t-loss:0.0539, loss-lb:0.0407, loss-ulb:0.0066, weight:2.00, lr:0.0005
[00:49:21.407] iteration:7677  t-loss:0.0269, loss-lb:0.0220, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:49:21.802] iteration:7678  t-loss:0.0590, loss-lb:0.0180, loss-ulb:0.0205, weight:2.00, lr:0.0005
[00:49:22.198] iteration:7679  t-loss:0.0537, loss-lb:0.0317, loss-ulb:0.0110, weight:2.00, lr:0.0005
[00:49:22.601] iteration:7680  t-loss:0.0326, loss-lb:0.0295, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:49:23.014] iteration:7681  t-loss:0.0414, loss-lb:0.0267, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:49:23.401] iteration:7682  t-loss:0.0311, loss-lb:0.0284, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:49:23.786] iteration:7683  t-loss:0.0399, loss-lb:0.0355, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:49:24.167] iteration:7684  t-loss:0.0315, loss-lb:0.0169, loss-ulb:0.0073, weight:2.00, lr:0.0005
[00:49:24.554] iteration:7685  t-loss:0.0387, loss-lb:0.0283, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:49:24.936] iteration:7686  t-loss:0.0325, loss-lb:0.0216, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:49:25.316] iteration:7687  t-loss:0.0220, loss-lb:0.0164, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:49:25.695] iteration:7688  t-loss:0.0392, loss-lb:0.0269, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:49:26.076] iteration:7689  t-loss:0.0368, loss-lb:0.0351, loss-ulb:0.0008, weight:2.00, lr:0.0005
[00:49:26.465] iteration:7690  t-loss:0.0407, loss-lb:0.0259, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:49:26.847] iteration:7691  t-loss:0.0183, loss-lb:0.0164, loss-ulb:0.0009, weight:2.00, lr:0.0005
[00:49:27.238] iteration:7692  t-loss:0.0164, loss-lb:0.0134, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:49:27.633] iteration:7693  t-loss:0.0416, loss-lb:0.0243, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:49:28.016] iteration:7694  t-loss:0.0348, loss-lb:0.0193, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:49:28.410] iteration:7695  t-loss:0.0314, loss-lb:0.0283, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:49:28.789] iteration:7696  t-loss:0.0186, loss-lb:0.0151, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:49:29.173] iteration:7697  t-loss:0.0321, loss-lb:0.0289, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:49:29.551] iteration:7698  t-loss:0.0440, loss-lb:0.0402, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:49:29.932] iteration:7699  t-loss:0.0164, loss-lb:0.0140, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:30.308] iteration:7700  t-loss:0.0169, loss-lb:0.0129, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:49:30.695] iteration:7701  t-loss:0.0331, loss-lb:0.0305, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:49:31.071] iteration:7702  t-loss:0.0736, loss-lb:0.0147, loss-ulb:0.0294, weight:2.00, lr:0.0005
[00:49:31.458] iteration:7703  t-loss:0.0429, loss-lb:0.0239, loss-ulb:0.0095, weight:2.00, lr:0.0005
[00:49:31.842] iteration:7704  t-loss:0.0783, loss-lb:0.0552, loss-ulb:0.0116, weight:2.00, lr:0.0005
[00:49:32.223] iteration:7705  t-loss:0.0332, loss-lb:0.0299, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:49:32.595] iteration:7706  t-loss:0.0496, loss-lb:0.0430, loss-ulb:0.0033, weight:2.00, lr:0.0005
[00:49:32.971] iteration:7707  t-loss:0.0312, loss-lb:0.0168, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:49:33.352] iteration:7708  t-loss:0.1365, loss-lb:0.1200, loss-ulb:0.0082, weight:2.00, lr:0.0005
[00:49:33.730] iteration:7709  t-loss:0.0511, loss-lb:0.0355, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:49:34.106] iteration:7710  t-loss:0.0329, loss-lb:0.0178, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:49:34.482] iteration:7711  t-loss:0.0268, loss-lb:0.0142, loss-ulb:0.0063, weight:2.00, lr:0.0005
[00:49:34.853] iteration:7712  t-loss:0.0181, loss-lb:0.0156, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:35.230] iteration:7713  t-loss:0.0647, loss-lb:0.0362, loss-ulb:0.0143, weight:2.00, lr:0.0005
[00:49:35.602] iteration:7714  t-loss:0.0231, loss-lb:0.0192, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:49:36.722] iteration:7715  t-loss:0.0380, loss-lb:0.0228, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:49:37.118] iteration:7716  t-loss:0.0201, loss-lb:0.0174, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:49:37.499] iteration:7717  t-loss:0.0245, loss-lb:0.0149, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:49:37.883] iteration:7718  t-loss:0.0491, loss-lb:0.0313, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:49:38.268] iteration:7719  t-loss:0.0229, loss-lb:0.0204, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:38.650] iteration:7720  t-loss:0.0196, loss-lb:0.0155, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:49:39.038] iteration:7721  t-loss:0.0451, loss-lb:0.0188, loss-ulb:0.0131, weight:2.00, lr:0.0005
[00:49:39.430] iteration:7722  t-loss:0.0542, loss-lb:0.0339, loss-ulb:0.0101, weight:2.00, lr:0.0005
[00:49:39.811] iteration:7723  t-loss:0.0211, loss-lb:0.0158, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:49:40.186] iteration:7724  t-loss:0.0258, loss-lb:0.0149, loss-ulb:0.0054, weight:2.00, lr:0.0005
[00:49:40.565] iteration:7725  t-loss:0.0435, loss-lb:0.0147, loss-ulb:0.0144, weight:2.00, lr:0.0005
[00:49:40.943] iteration:7726  t-loss:0.0300, loss-lb:0.0145, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:49:41.324] iteration:7727  t-loss:0.0404, loss-lb:0.0157, loss-ulb:0.0124, weight:2.00, lr:0.0005
[00:49:41.710] iteration:7728  t-loss:0.0287, loss-lb:0.0179, loss-ulb:0.0054, weight:2.00, lr:0.0005
[00:49:42.102] iteration:7729  t-loss:0.0433, loss-lb:0.0284, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:49:42.496] iteration:7730  t-loss:0.0499, loss-lb:0.0251, loss-ulb:0.0124, weight:2.00, lr:0.0005
[00:49:42.886] iteration:7731  t-loss:0.0884, loss-lb:0.0623, loss-ulb:0.0131, weight:2.00, lr:0.0005
[00:49:43.269] iteration:7732  t-loss:0.0295, loss-lb:0.0150, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:49:43.647] iteration:7733  t-loss:0.0213, loss-lb:0.0171, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:49:44.027] iteration:7734  t-loss:0.0438, loss-lb:0.0391, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:49:44.408] iteration:7735  t-loss:0.0209, loss-lb:0.0162, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:49:44.789] iteration:7736  t-loss:0.0207, loss-lb:0.0166, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:49:45.170] iteration:7737  t-loss:0.0863, loss-lb:0.0267, loss-ulb:0.0298, weight:2.00, lr:0.0005
[00:49:45.554] iteration:7738  t-loss:0.0379, loss-lb:0.0193, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:49:45.942] iteration:7739  t-loss:0.0517, loss-lb:0.0271, loss-ulb:0.0123, weight:2.00, lr:0.0005
[00:49:46.321] iteration:7740  t-loss:0.0237, loss-lb:0.0168, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:49:46.705] iteration:7741  t-loss:0.0358, loss-lb:0.0317, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:49:47.089] iteration:7742  t-loss:0.0580, loss-lb:0.0321, loss-ulb:0.0129, weight:2.00, lr:0.0005
[00:49:47.469] iteration:7743  t-loss:0.0596, loss-lb:0.0244, loss-ulb:0.0176, weight:2.00, lr:0.0005
[00:49:47.856] iteration:7744  t-loss:0.0276, loss-lb:0.0145, loss-ulb:0.0066, weight:2.00, lr:0.0005
[00:49:48.235] iteration:7745  t-loss:0.0725, loss-lb:0.0605, loss-ulb:0.0060, weight:2.00, lr:0.0005
[00:49:48.615] iteration:7746  t-loss:0.0229, loss-lb:0.0199, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:49:48.990] iteration:7747  t-loss:0.0152, loss-lb:0.0128, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:49.370] iteration:7748  t-loss:0.0439, loss-lb:0.0145, loss-ulb:0.0147, weight:2.00, lr:0.0005
[00:49:49.745] iteration:7749  t-loss:0.0211, loss-lb:0.0199, loss-ulb:0.0006, weight:2.00, lr:0.0005
[00:49:50.117] iteration:7750  t-loss:0.0241, loss-lb:0.0174, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:49:50.496] iteration:7751  t-loss:0.0221, loss-lb:0.0121, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:49:50.873] iteration:7752  t-loss:0.0215, loss-lb:0.0142, loss-ulb:0.0037, weight:2.00, lr:0.0005
[00:49:52.183] iteration:7753  t-loss:0.0270, loss-lb:0.0187, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:49:52.568] iteration:7754  t-loss:0.0245, loss-lb:0.0173, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:49:52.953] iteration:7755  t-loss:0.0464, loss-lb:0.0245, loss-ulb:0.0109, weight:2.00, lr:0.0005
[00:49:53.336] iteration:7756  t-loss:0.0597, loss-lb:0.0519, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:49:53.724] iteration:7757  t-loss:0.0286, loss-lb:0.0165, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:49:54.106] iteration:7758  t-loss:0.0621, loss-lb:0.0448, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:49:54.487] iteration:7759  t-loss:0.0383, loss-lb:0.0357, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:49:54.866] iteration:7760  t-loss:0.0349, loss-lb:0.0300, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:49:55.242] iteration:7761  t-loss:0.0769, loss-lb:0.0307, loss-ulb:0.0231, weight:2.00, lr:0.0005
[00:49:55.625] iteration:7762  t-loss:0.0218, loss-lb:0.0139, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:49:56.007] iteration:7763  t-loss:0.0303, loss-lb:0.0163, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:49:56.396] iteration:7764  t-loss:0.0342, loss-lb:0.0175, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:49:56.778] iteration:7765  t-loss:0.0475, loss-lb:0.0359, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:49:57.163] iteration:7766  t-loss:0.0243, loss-lb:0.0119, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:49:57.557] iteration:7767  t-loss:0.0374, loss-lb:0.0159, loss-ulb:0.0107, weight:2.00, lr:0.0005
[00:49:57.956] iteration:7768  t-loss:0.0470, loss-lb:0.0446, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:49:58.359] iteration:7769  t-loss:0.0550, loss-lb:0.0292, loss-ulb:0.0129, weight:2.00, lr:0.0005
[00:49:58.750] iteration:7770  t-loss:0.0476, loss-lb:0.0306, loss-ulb:0.0085, weight:2.00, lr:0.0005
[00:49:59.138] iteration:7771  t-loss:0.0477, loss-lb:0.0322, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:49:59.520] iteration:7772  t-loss:0.0295, loss-lb:0.0143, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:49:59.906] iteration:7773  t-loss:0.0488, loss-lb:0.0270, loss-ulb:0.0109, weight:2.00, lr:0.0005
[00:50:00.291] iteration:7774  t-loss:0.0367, loss-lb:0.0233, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:50:00.674] iteration:7775  t-loss:0.0277, loss-lb:0.0255, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:50:01.058] iteration:7776  t-loss:0.0240, loss-lb:0.0140, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:50:01.445] iteration:7777  t-loss:0.0172, loss-lb:0.0149, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:50:01.828] iteration:7778  t-loss:0.0385, loss-lb:0.0170, loss-ulb:0.0108, weight:2.00, lr:0.0005
[00:50:02.212] iteration:7779  t-loss:0.0187, loss-lb:0.0147, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:50:02.599] iteration:7780  t-loss:0.1164, loss-lb:0.0380, loss-ulb:0.0392, weight:2.00, lr:0.0005
[00:50:02.991] iteration:7781  t-loss:0.0475, loss-lb:0.0319, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:50:03.371] iteration:7782  t-loss:0.0402, loss-lb:0.0367, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:50:03.751] iteration:7783  t-loss:0.0656, loss-lb:0.0629, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:50:04.127] iteration:7784  t-loss:0.0150, loss-lb:0.0129, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:50:04.510] iteration:7785  t-loss:0.0476, loss-lb:0.0288, loss-ulb:0.0094, weight:2.00, lr:0.0005
[00:50:04.884] iteration:7786  t-loss:0.0181, loss-lb:0.0154, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:50:05.265] iteration:7787  t-loss:0.0391, loss-lb:0.0133, loss-ulb:0.0129, weight:2.00, lr:0.0005
[00:50:05.645] iteration:7788  t-loss:0.0613, loss-lb:0.0373, loss-ulb:0.0120, weight:2.00, lr:0.0005
[00:50:06.018] iteration:7789  t-loss:0.0191, loss-lb:0.0163, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:50:06.409] iteration:7790  t-loss:0.0492, loss-lb:0.0239, loss-ulb:0.0127, weight:2.00, lr:0.0005
[00:51:08.282] iteration 7790 : dice_score: 0.894461 best_dice: 0.894500
[00:51:08.282]  <<Test>> - Ep:204  - Dice-S/T:88.27/89.45, Best-S:88.88, Best-T:89.45
[00:51:08.283]           - AvgLoss(lb/ulb/all):0.03/0.01/0.04
[00:51:09.331] iteration:7791  t-loss:0.0341, loss-lb:0.0184, loss-ulb:0.0079, weight:2.00, lr:0.0005
[00:51:09.721] iteration:7792  t-loss:0.0307, loss-lb:0.0253, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:51:10.101] iteration:7793  t-loss:0.0152, loss-lb:0.0129, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:51:10.479] iteration:7794  t-loss:0.0418, loss-lb:0.0362, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:51:10.858] iteration:7795  t-loss:0.0318, loss-lb:0.0277, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:51:11.241] iteration:7796  t-loss:0.0600, loss-lb:0.0408, loss-ulb:0.0096, weight:2.00, lr:0.0005
[00:51:11.619] iteration:7797  t-loss:0.0282, loss-lb:0.0131, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:51:11.995] iteration:7798  t-loss:0.0367, loss-lb:0.0297, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:51:12.374] iteration:7799  t-loss:0.0230, loss-lb:0.0163, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:51:12.775] iteration:7800  t-loss:0.0499, loss-lb:0.0316, loss-ulb:0.0091, weight:2.00, lr:0.0005
[00:51:13.178] iteration:7801  t-loss:0.0658, loss-lb:0.0147, loss-ulb:0.0255, weight:2.00, lr:0.0005
[00:51:13.578] iteration:7802  t-loss:0.0331, loss-lb:0.0306, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:51:13.961] iteration:7803  t-loss:0.0172, loss-lb:0.0138, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:51:14.344] iteration:7804  t-loss:0.0185, loss-lb:0.0170, loss-ulb:0.0007, weight:2.00, lr:0.0005
[00:51:14.730] iteration:7805  t-loss:0.0446, loss-lb:0.0332, loss-ulb:0.0057, weight:2.00, lr:0.0005
[00:51:15.111] iteration:7806  t-loss:0.0619, loss-lb:0.0143, loss-ulb:0.0238, weight:2.00, lr:0.0005
[00:51:15.488] iteration:7807  t-loss:0.0451, loss-lb:0.0242, loss-ulb:0.0104, weight:2.00, lr:0.0005
[00:51:15.872] iteration:7808  t-loss:0.0257, loss-lb:0.0168, loss-ulb:0.0044, weight:2.00, lr:0.0005
[00:51:16.265] iteration:7809  t-loss:0.0388, loss-lb:0.0253, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:51:16.649] iteration:7810  t-loss:0.0370, loss-lb:0.0279, loss-ulb:0.0045, weight:2.00, lr:0.0005
[00:51:17.026] iteration:7811  t-loss:0.0586, loss-lb:0.0547, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:51:17.405] iteration:7812  t-loss:0.0297, loss-lb:0.0196, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:51:17.792] iteration:7813  t-loss:0.0488, loss-lb:0.0338, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:51:18.171] iteration:7814  t-loss:0.0207, loss-lb:0.0169, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:51:18.555] iteration:7815  t-loss:0.0411, loss-lb:0.0202, loss-ulb:0.0104, weight:2.00, lr:0.0005
[00:51:18.935] iteration:7816  t-loss:0.0295, loss-lb:0.0157, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:51:19.321] iteration:7817  t-loss:0.0844, loss-lb:0.0371, loss-ulb:0.0237, weight:2.00, lr:0.0005
[00:51:19.704] iteration:7818  t-loss:0.0268, loss-lb:0.0239, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:51:20.086] iteration:7819  t-loss:0.0193, loss-lb:0.0169, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:51:20.471] iteration:7820  t-loss:0.0380, loss-lb:0.0233, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:51:20.855] iteration:7821  t-loss:0.0549, loss-lb:0.0373, loss-ulb:0.0088, weight:2.00, lr:0.0005
[00:51:21.237] iteration:7822  t-loss:0.0383, loss-lb:0.0244, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:51:21.620] iteration:7823  t-loss:0.0453, loss-lb:0.0425, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:51:22.000] iteration:7824  t-loss:0.0708, loss-lb:0.0344, loss-ulb:0.0182, weight:2.00, lr:0.0005
[00:51:22.377] iteration:7825  t-loss:0.0235, loss-lb:0.0201, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:51:22.752] iteration:7826  t-loss:0.0244, loss-lb:0.0132, loss-ulb:0.0056, weight:2.00, lr:0.0005
[00:51:23.129] iteration:7827  t-loss:0.0280, loss-lb:0.0179, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:51:23.509] iteration:7828  t-loss:0.0423, loss-lb:0.0295, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:51:24.882] iteration:7829  t-loss:0.0538, loss-lb:0.0514, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:51:25.264] iteration:7830  t-loss:0.0199, loss-lb:0.0158, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:51:25.645] iteration:7831  t-loss:0.0668, loss-lb:0.0320, loss-ulb:0.0174, weight:2.00, lr:0.0005
[00:51:26.019] iteration:7832  t-loss:0.0256, loss-lb:0.0170, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:51:26.397] iteration:7833  t-loss:0.0307, loss-lb:0.0282, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:51:26.779] iteration:7834  t-loss:0.0358, loss-lb:0.0334, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:51:27.158] iteration:7835  t-loss:0.0316, loss-lb:0.0128, loss-ulb:0.0094, weight:2.00, lr:0.0005
[00:51:27.537] iteration:7836  t-loss:0.0340, loss-lb:0.0135, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:51:27.928] iteration:7837  t-loss:0.0426, loss-lb:0.0211, loss-ulb:0.0108, weight:2.00, lr:0.0005
[00:51:28.342] iteration:7838  t-loss:0.0198, loss-lb:0.0136, loss-ulb:0.0031, weight:2.00, lr:0.0005
[00:51:28.744] iteration:7839  t-loss:0.0438, loss-lb:0.0202, loss-ulb:0.0118, weight:2.00, lr:0.0005
[00:51:29.136] iteration:7840  t-loss:0.0230, loss-lb:0.0132, loss-ulb:0.0049, weight:2.00, lr:0.0005
[00:51:29.522] iteration:7841  t-loss:0.0173, loss-lb:0.0136, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:51:29.903] iteration:7842  t-loss:0.0337, loss-lb:0.0189, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:51:30.284] iteration:7843  t-loss:0.0563, loss-lb:0.0480, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:51:30.678] iteration:7844  t-loss:0.0439, loss-lb:0.0259, loss-ulb:0.0090, weight:2.00, lr:0.0005
[00:51:31.063] iteration:7845  t-loss:0.0268, loss-lb:0.0143, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:51:31.445] iteration:7846  t-loss:0.0398, loss-lb:0.0339, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:51:31.825] iteration:7847  t-loss:0.0448, loss-lb:0.0330, loss-ulb:0.0059, weight:2.00, lr:0.0005
[00:51:32.203] iteration:7848  t-loss:0.0275, loss-lb:0.0246, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:51:32.586] iteration:7849  t-loss:0.0358, loss-lb:0.0153, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:51:32.975] iteration:7850  t-loss:0.0544, loss-lb:0.0279, loss-ulb:0.0132, weight:2.00, lr:0.0005
[00:51:33.360] iteration:7851  t-loss:0.0250, loss-lb:0.0204, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:51:33.755] iteration:7852  t-loss:0.0303, loss-lb:0.0248, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:51:34.136] iteration:7853  t-loss:0.0283, loss-lb:0.0167, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:51:34.515] iteration:7854  t-loss:0.0497, loss-lb:0.0137, loss-ulb:0.0180, weight:2.00, lr:0.0005
[00:51:34.894] iteration:7855  t-loss:0.0403, loss-lb:0.0268, loss-ulb:0.0068, weight:2.00, lr:0.0005
[00:51:35.273] iteration:7856  t-loss:0.0253, loss-lb:0.0209, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:51:35.661] iteration:7857  t-loss:0.0709, loss-lb:0.0271, loss-ulb:0.0219, weight:2.00, lr:0.0005
[00:51:36.052] iteration:7858  t-loss:0.0347, loss-lb:0.0260, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:51:36.426] iteration:7859  t-loss:0.0240, loss-lb:0.0134, loss-ulb:0.0053, weight:2.00, lr:0.0005
[00:51:36.807] iteration:7860  t-loss:0.0250, loss-lb:0.0163, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:51:37.180] iteration:7861  t-loss:0.0296, loss-lb:0.0258, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:51:37.556] iteration:7862  t-loss:0.0460, loss-lb:0.0217, loss-ulb:0.0122, weight:2.00, lr:0.0005
[00:51:37.933] iteration:7863  t-loss:0.0447, loss-lb:0.0272, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:51:38.311] iteration:7864  t-loss:0.0521, loss-lb:0.0345, loss-ulb:0.0088, weight:2.00, lr:0.0005
[00:51:38.693] iteration:7865  t-loss:0.0279, loss-lb:0.0155, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:51:39.070] iteration:7866  t-loss:0.0288, loss-lb:0.0164, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:51:40.310] iteration:7867  t-loss:0.0388, loss-lb:0.0365, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:51:40.691] iteration:7868  t-loss:0.0244, loss-lb:0.0170, loss-ulb:0.0037, weight:2.00, lr:0.0005
[00:51:41.066] iteration:7869  t-loss:0.0215, loss-lb:0.0137, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:51:41.446] iteration:7870  t-loss:0.0193, loss-lb:0.0150, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:51:41.825] iteration:7871  t-loss:0.0382, loss-lb:0.0339, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:51:42.202] iteration:7872  t-loss:0.0366, loss-lb:0.0286, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:51:42.580] iteration:7873  t-loss:0.0317, loss-lb:0.0142, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:51:42.961] iteration:7874  t-loss:0.0218, loss-lb:0.0120, loss-ulb:0.0049, weight:2.00, lr:0.0005
[00:51:43.339] iteration:7875  t-loss:0.0456, loss-lb:0.0434, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:51:43.727] iteration:7876  t-loss:0.0408, loss-lb:0.0371, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:51:44.093] iteration:7877  t-loss:0.0199, loss-lb:0.0135, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:51:44.472] iteration:7878  t-loss:0.0216, loss-lb:0.0165, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:51:44.850] iteration:7879  t-loss:0.0231, loss-lb:0.0136, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:51:45.239] iteration:7880  t-loss:0.0421, loss-lb:0.0257, loss-ulb:0.0082, weight:2.00, lr:0.0005
[00:51:45.627] iteration:7881  t-loss:0.0442, loss-lb:0.0243, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:51:46.005] iteration:7882  t-loss:0.1059, loss-lb:0.0193, loss-ulb:0.0433, weight:2.00, lr:0.0005
[00:51:46.387] iteration:7883  t-loss:0.0279, loss-lb:0.0144, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:51:46.766] iteration:7884  t-loss:0.0511, loss-lb:0.0490, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:51:47.147] iteration:7885  t-loss:0.0483, loss-lb:0.0429, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:51:47.526] iteration:7886  t-loss:0.0193, loss-lb:0.0164, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:51:47.905] iteration:7887  t-loss:0.0182, loss-lb:0.0136, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:51:48.287] iteration:7888  t-loss:0.0322, loss-lb:0.0211, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:51:48.677] iteration:7889  t-loss:0.0302, loss-lb:0.0154, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:51:49.055] iteration:7890  t-loss:0.0212, loss-lb:0.0145, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:51:49.439] iteration:7891  t-loss:0.0472, loss-lb:0.0174, loss-ulb:0.0149, weight:2.00, lr:0.0005
[00:51:49.822] iteration:7892  t-loss:0.0466, loss-lb:0.0306, loss-ulb:0.0080, weight:2.00, lr:0.0005
[00:51:50.205] iteration:7893  t-loss:0.0278, loss-lb:0.0230, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:51:50.589] iteration:7894  t-loss:0.0367, loss-lb:0.0222, loss-ulb:0.0073, weight:2.00, lr:0.0005
[00:51:50.974] iteration:7895  t-loss:0.0372, loss-lb:0.0287, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:51:51.355] iteration:7896  t-loss:0.0183, loss-lb:0.0148, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:51:51.734] iteration:7897  t-loss:0.0405, loss-lb:0.0371, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:51:52.108] iteration:7898  t-loss:0.0207, loss-lb:0.0151, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:51:52.486] iteration:7899  t-loss:0.0255, loss-lb:0.0141, loss-ulb:0.0057, weight:2.00, lr:0.0005
[00:51:52.865] iteration:7900  t-loss:0.0333, loss-lb:0.0281, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:51:53.245] iteration:7901  t-loss:0.0354, loss-lb:0.0232, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:51:53.621] iteration:7902  t-loss:0.0477, loss-lb:0.0165, loss-ulb:0.0156, weight:2.00, lr:0.0005
[00:51:53.997] iteration:7903  t-loss:0.0384, loss-lb:0.0263, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:51:54.372] iteration:7904  t-loss:0.0351, loss-lb:0.0328, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:51:55.610] iteration:7905  t-loss:0.0217, loss-lb:0.0140, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:51:56.010] iteration:7906  t-loss:0.0529, loss-lb:0.0260, loss-ulb:0.0134, weight:2.00, lr:0.0005
[00:51:56.392] iteration:7907  t-loss:0.0382, loss-lb:0.0254, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:51:56.774] iteration:7908  t-loss:0.0391, loss-lb:0.0352, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:51:57.161] iteration:7909  t-loss:0.0670, loss-lb:0.0271, loss-ulb:0.0199, weight:2.00, lr:0.0005
[00:51:57.534] iteration:7910  t-loss:0.0265, loss-lb:0.0213, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:51:57.919] iteration:7911  t-loss:0.0237, loss-lb:0.0138, loss-ulb:0.0049, weight:2.00, lr:0.0005
[00:51:58.304] iteration:7912  t-loss:0.0291, loss-lb:0.0188, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:51:58.685] iteration:7913  t-loss:0.0338, loss-lb:0.0152, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:51:59.066] iteration:7914  t-loss:0.0307, loss-lb:0.0256, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:51:59.451] iteration:7915  t-loss:0.0814, loss-lb:0.0290, loss-ulb:0.0262, weight:2.00, lr:0.0005
[00:51:59.837] iteration:7916  t-loss:0.0526, loss-lb:0.0162, loss-ulb:0.0182, weight:2.00, lr:0.0005
[00:52:00.215] iteration:7917  t-loss:0.0412, loss-lb:0.0127, loss-ulb:0.0142, weight:2.00, lr:0.0005
[00:52:00.599] iteration:7918  t-loss:0.0928, loss-lb:0.0513, loss-ulb:0.0208, weight:2.00, lr:0.0005
[00:52:00.982] iteration:7919  t-loss:0.0352, loss-lb:0.0299, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:52:01.365] iteration:7920  t-loss:0.0398, loss-lb:0.0159, loss-ulb:0.0119, weight:2.00, lr:0.0005
[00:52:01.739] iteration:7921  t-loss:0.0314, loss-lb:0.0175, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:52:02.121] iteration:7922  t-loss:0.0349, loss-lb:0.0271, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:52:02.501] iteration:7923  t-loss:0.0188, loss-lb:0.0162, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:52:02.877] iteration:7924  t-loss:0.0178, loss-lb:0.0149, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:52:03.260] iteration:7925  t-loss:0.0405, loss-lb:0.0178, loss-ulb:0.0113, weight:2.00, lr:0.0005
[00:52:03.651] iteration:7926  t-loss:0.0407, loss-lb:0.0161, loss-ulb:0.0123, weight:2.00, lr:0.0005
[00:52:04.048] iteration:7927  t-loss:0.0325, loss-lb:0.0281, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:52:04.431] iteration:7928  t-loss:0.0224, loss-lb:0.0134, loss-ulb:0.0045, weight:2.00, lr:0.0005
[00:52:04.815] iteration:7929  t-loss:0.0363, loss-lb:0.0159, loss-ulb:0.0102, weight:2.00, lr:0.0005
[00:52:05.199] iteration:7930  t-loss:0.0412, loss-lb:0.0228, loss-ulb:0.0092, weight:2.00, lr:0.0005
[00:52:05.582] iteration:7931  t-loss:0.0167, loss-lb:0.0126, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:52:05.964] iteration:7932  t-loss:0.0291, loss-lb:0.0141, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:52:06.344] iteration:7933  t-loss:0.0383, loss-lb:0.0160, loss-ulb:0.0111, weight:2.00, lr:0.0005
[00:52:06.726] iteration:7934  t-loss:0.0265, loss-lb:0.0169, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:52:07.114] iteration:7935  t-loss:0.0377, loss-lb:0.0358, loss-ulb:0.0010, weight:2.00, lr:0.0005
[00:52:07.496] iteration:7936  t-loss:0.0318, loss-lb:0.0197, loss-ulb:0.0060, weight:2.00, lr:0.0005
[00:52:07.872] iteration:7937  t-loss:0.0230, loss-lb:0.0149, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:52:08.249] iteration:7938  t-loss:0.0229, loss-lb:0.0193, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:52:08.628] iteration:7939  t-loss:0.0272, loss-lb:0.0204, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:52:09.003] iteration:7940  t-loss:0.0179, loss-lb:0.0142, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:52:09.380] iteration:7941  t-loss:0.0384, loss-lb:0.0131, loss-ulb:0.0126, weight:2.00, lr:0.0005
[00:52:09.768] iteration:7942  t-loss:0.0186, loss-lb:0.0129, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:53:12.384] iteration 7942 : dice_score: 0.893410 best_dice: 0.894500
[00:53:12.385]  <<Test>> - Ep:208  - Dice-S/T:89.30/89.34, Best-S:89.30, Best-T:89.45
[00:53:12.385]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[00:53:13.686] iteration:7943  t-loss:0.0201, loss-lb:0.0164, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:53:14.087] iteration:7944  t-loss:0.0252, loss-lb:0.0175, loss-ulb:0.0038, weight:2.00, lr:0.0005
[00:53:14.478] iteration:7945  t-loss:0.0363, loss-lb:0.0178, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:53:14.854] iteration:7946  t-loss:0.0151, loss-lb:0.0118, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:53:15.233] iteration:7947  t-loss:0.0378, loss-lb:0.0249, loss-ulb:0.0065, weight:2.00, lr:0.0005
[00:53:15.613] iteration:7948  t-loss:0.0388, loss-lb:0.0223, loss-ulb:0.0082, weight:2.00, lr:0.0005
[00:53:15.990] iteration:7949  t-loss:0.0172, loss-lb:0.0130, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:53:16.369] iteration:7950  t-loss:0.0462, loss-lb:0.0165, loss-ulb:0.0148, weight:2.00, lr:0.0005
[00:53:16.753] iteration:7951  t-loss:0.0470, loss-lb:0.0312, loss-ulb:0.0079, weight:2.00, lr:0.0005
[00:53:17.132] iteration:7952  t-loss:0.0400, loss-lb:0.0229, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:53:17.514] iteration:7953  t-loss:0.0589, loss-lb:0.0471, loss-ulb:0.0059, weight:2.00, lr:0.0005
[00:53:17.902] iteration:7954  t-loss:0.0164, loss-lb:0.0131, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:53:18.300] iteration:7955  t-loss:0.0270, loss-lb:0.0189, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:53:18.702] iteration:7956  t-loss:0.0579, loss-lb:0.0299, loss-ulb:0.0140, weight:2.00, lr:0.0005
[00:53:19.086] iteration:7957  t-loss:0.0600, loss-lb:0.0524, loss-ulb:0.0038, weight:2.00, lr:0.0005
[00:53:19.478] iteration:7958  t-loss:0.0474, loss-lb:0.0333, loss-ulb:0.0071, weight:2.00, lr:0.0005
[00:53:19.857] iteration:7959  t-loss:0.0572, loss-lb:0.0512, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:53:20.239] iteration:7960  t-loss:0.0293, loss-lb:0.0224, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:53:20.617] iteration:7961  t-loss:0.0385, loss-lb:0.0241, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:53:20.996] iteration:7962  t-loss:0.0618, loss-lb:0.0574, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:53:21.383] iteration:7963  t-loss:0.0542, loss-lb:0.0291, loss-ulb:0.0126, weight:2.00, lr:0.0005
[00:53:21.768] iteration:7964  t-loss:0.0828, loss-lb:0.0373, loss-ulb:0.0228, weight:2.00, lr:0.0005
[00:53:22.151] iteration:7965  t-loss:0.0293, loss-lb:0.0182, loss-ulb:0.0056, weight:2.00, lr:0.0005
[00:53:22.536] iteration:7966  t-loss:0.0618, loss-lb:0.0195, loss-ulb:0.0212, weight:2.00, lr:0.0005
[00:53:22.921] iteration:7967  t-loss:0.0878, loss-lb:0.0841, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:53:23.306] iteration:7968  t-loss:0.0333, loss-lb:0.0123, loss-ulb:0.0105, weight:2.00, lr:0.0005
[00:53:23.684] iteration:7969  t-loss:0.0620, loss-lb:0.0373, loss-ulb:0.0123, weight:2.00, lr:0.0005
[00:53:24.069] iteration:7970  t-loss:0.0863, loss-lb:0.0343, loss-ulb:0.0260, weight:2.00, lr:0.0005
[00:53:24.456] iteration:7971  t-loss:0.0471, loss-lb:0.0177, loss-ulb:0.0147, weight:2.00, lr:0.0005
[00:53:24.843] iteration:7972  t-loss:0.0346, loss-lb:0.0134, loss-ulb:0.0106, weight:2.00, lr:0.0005
[00:53:25.221] iteration:7973  t-loss:0.0484, loss-lb:0.0281, loss-ulb:0.0102, weight:2.00, lr:0.0005
[00:53:25.597] iteration:7974  t-loss:0.0307, loss-lb:0.0176, loss-ulb:0.0065, weight:2.00, lr:0.0005
[00:53:25.978] iteration:7975  t-loss:0.0562, loss-lb:0.0311, loss-ulb:0.0126, weight:2.00, lr:0.0005
[00:53:26.360] iteration:7976  t-loss:0.0622, loss-lb:0.0357, loss-ulb:0.0132, weight:2.00, lr:0.0005
[00:53:26.739] iteration:7977  t-loss:0.0635, loss-lb:0.0291, loss-ulb:0.0172, weight:2.00, lr:0.0005
[00:53:27.116] iteration:7978  t-loss:0.0378, loss-lb:0.0192, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:53:27.495] iteration:7979  t-loss:0.0457, loss-lb:0.0313, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:53:27.871] iteration:7980  t-loss:0.0254, loss-lb:0.0198, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:53:29.007] iteration:7981  t-loss:0.0273, loss-lb:0.0198, loss-ulb:0.0037, weight:2.00, lr:0.0005
[00:53:29.400] iteration:7982  t-loss:0.0945, loss-lb:0.0380, loss-ulb:0.0282, weight:2.00, lr:0.0005
[00:53:29.783] iteration:7983  t-loss:0.0289, loss-lb:0.0173, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:53:30.163] iteration:7984  t-loss:0.0221, loss-lb:0.0176, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:53:30.541] iteration:7985  t-loss:0.0294, loss-lb:0.0229, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:53:30.917] iteration:7986  t-loss:0.0312, loss-lb:0.0164, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:53:31.295] iteration:7987  t-loss:0.0365, loss-lb:0.0152, loss-ulb:0.0107, weight:2.00, lr:0.0005
[00:53:31.673] iteration:7988  t-loss:0.0265, loss-lb:0.0221, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:53:32.055] iteration:7989  t-loss:0.0320, loss-lb:0.0182, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:53:32.433] iteration:7990  t-loss:0.0356, loss-lb:0.0166, loss-ulb:0.0095, weight:2.00, lr:0.0005
[00:53:32.809] iteration:7991  t-loss:0.0191, loss-lb:0.0162, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:53:33.189] iteration:7992  t-loss:0.0916, loss-lb:0.0598, loss-ulb:0.0159, weight:2.00, lr:0.0005
[00:53:33.587] iteration:7993  t-loss:0.0285, loss-lb:0.0233, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:53:33.986] iteration:7994  t-loss:0.0367, loss-lb:0.0134, loss-ulb:0.0117, weight:2.00, lr:0.0005
[00:53:34.381] iteration:7995  t-loss:0.0284, loss-lb:0.0129, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:53:34.748] iteration:7996  t-loss:0.0370, loss-lb:0.0340, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:53:35.129] iteration:7997  t-loss:0.0218, loss-lb:0.0185, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:53:35.508] iteration:7998  t-loss:0.0252, loss-lb:0.0135, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:53:35.888] iteration:7999  t-loss:0.0206, loss-lb:0.0138, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:53:36.264] iteration:8000  t-loss:0.0220, loss-lb:0.0181, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:53:36.648] iteration:8001  t-loss:0.0621, loss-lb:0.0244, loss-ulb:0.0189, weight:2.00, lr:0.0005
[00:53:37.031] iteration:8002  t-loss:0.0472, loss-lb:0.0286, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:53:37.417] iteration:8003  t-loss:0.0273, loss-lb:0.0130, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:53:37.800] iteration:8004  t-loss:0.0574, loss-lb:0.0402, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:53:38.182] iteration:8005  t-loss:0.0631, loss-lb:0.0313, loss-ulb:0.0159, weight:2.00, lr:0.0005
[00:53:38.561] iteration:8006  t-loss:0.0368, loss-lb:0.0201, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:53:38.955] iteration:8007  t-loss:0.0382, loss-lb:0.0351, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:53:39.340] iteration:8008  t-loss:0.0344, loss-lb:0.0274, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:53:39.726] iteration:8009  t-loss:0.0324, loss-lb:0.0138, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:53:40.111] iteration:8010  t-loss:0.0506, loss-lb:0.0255, loss-ulb:0.0126, weight:2.00, lr:0.0005
[00:53:40.498] iteration:8011  t-loss:0.0350, loss-lb:0.0330, loss-ulb:0.0010, weight:2.00, lr:0.0005
[00:53:40.878] iteration:8012  t-loss:0.0311, loss-lb:0.0156, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:53:41.258] iteration:8013  t-loss:0.0398, loss-lb:0.0294, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:53:41.633] iteration:8014  t-loss:0.0200, loss-lb:0.0162, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:53:42.005] iteration:8015  t-loss:0.0206, loss-lb:0.0123, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:53:42.382] iteration:8016  t-loss:0.0395, loss-lb:0.0267, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:53:42.765] iteration:8017  t-loss:0.0374, loss-lb:0.0249, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:53:43.144] iteration:8018  t-loss:0.0193, loss-lb:0.0169, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:53:44.490] iteration:8019  t-loss:0.0319, loss-lb:0.0284, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:53:44.885] iteration:8020  t-loss:0.0159, loss-lb:0.0133, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:53:45.280] iteration:8021  t-loss:0.0291, loss-lb:0.0136, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:53:45.667] iteration:8022  t-loss:0.0299, loss-lb:0.0174, loss-ulb:0.0063, weight:2.00, lr:0.0005
[00:53:46.043] iteration:8023  t-loss:0.0399, loss-lb:0.0357, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:53:46.427] iteration:8024  t-loss:0.0390, loss-lb:0.0267, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:53:46.809] iteration:8025  t-loss:0.0273, loss-lb:0.0132, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:53:47.189] iteration:8026  t-loss:0.0319, loss-lb:0.0141, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:53:47.568] iteration:8027  t-loss:0.0350, loss-lb:0.0155, loss-ulb:0.0098, weight:2.00, lr:0.0005
[00:53:47.953] iteration:8028  t-loss:0.0545, loss-lb:0.0253, loss-ulb:0.0146, weight:2.00, lr:0.0005
[00:53:48.333] iteration:8029  t-loss:0.0371, loss-lb:0.0160, loss-ulb:0.0105, weight:2.00, lr:0.0005
[00:53:48.718] iteration:8030  t-loss:0.0905, loss-lb:0.0214, loss-ulb:0.0346, weight:2.00, lr:0.0005
[00:53:49.104] iteration:8031  t-loss:0.0323, loss-lb:0.0126, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:53:49.490] iteration:8032  t-loss:0.0294, loss-lb:0.0238, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:53:49.869] iteration:8033  t-loss:0.0297, loss-lb:0.0262, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:53:50.263] iteration:8034  t-loss:0.0260, loss-lb:0.0166, loss-ulb:0.0047, weight:2.00, lr:0.0005
[00:53:50.643] iteration:8035  t-loss:0.0468, loss-lb:0.0171, loss-ulb:0.0148, weight:2.00, lr:0.0005
[00:53:51.035] iteration:8036  t-loss:0.0514, loss-lb:0.0389, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:53:51.419] iteration:8037  t-loss:0.0532, loss-lb:0.0212, loss-ulb:0.0160, weight:2.00, lr:0.0005
[00:53:51.805] iteration:8038  t-loss:0.0285, loss-lb:0.0139, loss-ulb:0.0073, weight:2.00, lr:0.0005
[00:53:52.189] iteration:8039  t-loss:0.0292, loss-lb:0.0142, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:53:52.573] iteration:8040  t-loss:0.0543, loss-lb:0.0322, loss-ulb:0.0111, weight:2.00, lr:0.0005
[00:53:52.957] iteration:8041  t-loss:0.0343, loss-lb:0.0124, loss-ulb:0.0110, weight:2.00, lr:0.0005
[00:53:53.343] iteration:8042  t-loss:0.0374, loss-lb:0.0334, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:53:53.724] iteration:8043  t-loss:0.0187, loss-lb:0.0129, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:53:54.114] iteration:8044  t-loss:0.0938, loss-lb:0.0673, loss-ulb:0.0132, weight:2.00, lr:0.0005
[00:53:54.500] iteration:8045  t-loss:0.0284, loss-lb:0.0243, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:53:54.890] iteration:8046  t-loss:0.0281, loss-lb:0.0228, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:53:55.277] iteration:8047  t-loss:0.0477, loss-lb:0.0349, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:53:55.660] iteration:8048  t-loss:0.0394, loss-lb:0.0153, loss-ulb:0.0120, weight:2.00, lr:0.0005
[00:53:56.044] iteration:8049  t-loss:0.0314, loss-lb:0.0288, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:53:56.423] iteration:8050  t-loss:0.0455, loss-lb:0.0168, loss-ulb:0.0143, weight:2.00, lr:0.0005
[00:53:56.805] iteration:8051  t-loss:0.0266, loss-lb:0.0164, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:53:57.188] iteration:8052  t-loss:0.0489, loss-lb:0.0260, loss-ulb:0.0114, weight:2.00, lr:0.0005
[00:53:57.565] iteration:8053  t-loss:0.0368, loss-lb:0.0311, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:53:57.945] iteration:8054  t-loss:0.0293, loss-lb:0.0164, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:53:58.320] iteration:8055  t-loss:0.0176, loss-lb:0.0137, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:53:58.703] iteration:8056  t-loss:0.0514, loss-lb:0.0361, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:54:00.085] iteration:8057  t-loss:0.0217, loss-lb:0.0159, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:54:00.473] iteration:8058  t-loss:0.0184, loss-lb:0.0119, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:54:00.857] iteration:8059  t-loss:0.0170, loss-lb:0.0142, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:54:01.245] iteration:8060  t-loss:0.0479, loss-lb:0.0462, loss-ulb:0.0009, weight:2.00, lr:0.0005
[00:54:01.627] iteration:8061  t-loss:0.0490, loss-lb:0.0450, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:54:02.014] iteration:8062  t-loss:0.0241, loss-lb:0.0166, loss-ulb:0.0037, weight:2.00, lr:0.0005
[00:54:02.398] iteration:8063  t-loss:0.0305, loss-lb:0.0247, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:54:02.784] iteration:8064  t-loss:0.0534, loss-lb:0.0333, loss-ulb:0.0100, weight:2.00, lr:0.0005
[00:54:03.163] iteration:8065  t-loss:0.0173, loss-lb:0.0122, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:54:03.553] iteration:8066  t-loss:0.0494, loss-lb:0.0231, loss-ulb:0.0132, weight:2.00, lr:0.0005
[00:54:03.940] iteration:8067  t-loss:0.0652, loss-lb:0.0280, loss-ulb:0.0186, weight:2.00, lr:0.0005
[00:54:04.321] iteration:8068  t-loss:0.0624, loss-lb:0.0291, loss-ulb:0.0166, weight:2.00, lr:0.0005
[00:54:04.709] iteration:8069  t-loss:0.0402, loss-lb:0.0371, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:54:05.091] iteration:8070  t-loss:0.0496, loss-lb:0.0358, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:54:05.479] iteration:8071  t-loss:0.0315, loss-lb:0.0284, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:54:05.864] iteration:8072  t-loss:0.0494, loss-lb:0.0213, loss-ulb:0.0140, weight:2.00, lr:0.0005
[00:54:06.251] iteration:8073  t-loss:0.0428, loss-lb:0.0405, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:54:06.639] iteration:8074  t-loss:0.0514, loss-lb:0.0369, loss-ulb:0.0073, weight:2.00, lr:0.0005
[00:54:07.014] iteration:8075  t-loss:0.0240, loss-lb:0.0217, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:54:07.395] iteration:8076  t-loss:0.0526, loss-lb:0.0152, loss-ulb:0.0187, weight:2.00, lr:0.0005
[00:54:07.774] iteration:8077  t-loss:0.0319, loss-lb:0.0266, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:54:08.154] iteration:8078  t-loss:0.0221, loss-lb:0.0182, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:54:08.543] iteration:8079  t-loss:0.0469, loss-lb:0.0299, loss-ulb:0.0085, weight:2.00, lr:0.0005
[00:54:08.927] iteration:8080  t-loss:0.0314, loss-lb:0.0162, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:54:09.310] iteration:8081  t-loss:0.0399, loss-lb:0.0174, loss-ulb:0.0112, weight:2.00, lr:0.0005
[00:54:09.700] iteration:8082  t-loss:0.0547, loss-lb:0.0306, loss-ulb:0.0121, weight:2.00, lr:0.0005
[00:54:10.088] iteration:8083  t-loss:0.0577, loss-lb:0.0455, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:54:10.468] iteration:8084  t-loss:0.1210, loss-lb:0.1167, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:54:10.849] iteration:8085  t-loss:0.0269, loss-lb:0.0128, loss-ulb:0.0071, weight:2.00, lr:0.0005
[00:54:11.237] iteration:8086  t-loss:0.0292, loss-lb:0.0224, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:54:11.617] iteration:8087  t-loss:0.0327, loss-lb:0.0154, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:54:11.996] iteration:8088  t-loss:0.0869, loss-lb:0.0784, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:54:12.375] iteration:8089  t-loss:0.0891, loss-lb:0.0281, loss-ulb:0.0305, weight:2.00, lr:0.0005
[00:54:12.755] iteration:8090  t-loss:0.0327, loss-lb:0.0231, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:54:13.129] iteration:8091  t-loss:0.0231, loss-lb:0.0168, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:54:13.514] iteration:8092  t-loss:0.0340, loss-lb:0.0217, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:54:13.906] iteration:8093  t-loss:0.0478, loss-lb:0.0356, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:54:14.281] iteration:8094  t-loss:0.0455, loss-lb:0.0400, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:55:15.701] iteration 8094 : dice_score: 0.882913 best_dice: 0.894500
[00:55:15.701]  <<Test>> - Ep:212  - Dice-S/T:85.52/88.29, Best-S:89.30, Best-T:89.45
[00:55:15.701]           - AvgLoss(lb/ulb/all):0.03/0.01/0.05
[00:55:16.707] iteration:8095  t-loss:0.0444, loss-lb:0.0407, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:55:17.112] iteration:8096  t-loss:0.0195, loss-lb:0.0155, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:55:17.495] iteration:8097  t-loss:0.0239, loss-lb:0.0196, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:55:17.883] iteration:8098  t-loss:0.0289, loss-lb:0.0221, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:55:18.271] iteration:8099  t-loss:0.0169, loss-lb:0.0146, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:55:18.661] iteration:8100  t-loss:0.0622, loss-lb:0.0419, loss-ulb:0.0101, weight:2.00, lr:0.0005
[00:55:19.045] iteration:8101  t-loss:0.0394, loss-lb:0.0361, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:55:19.435] iteration:8102  t-loss:0.0290, loss-lb:0.0196, loss-ulb:0.0047, weight:2.00, lr:0.0005
[00:55:19.820] iteration:8103  t-loss:0.0371, loss-lb:0.0191, loss-ulb:0.0090, weight:2.00, lr:0.0005
[00:55:20.202] iteration:8104  t-loss:0.0442, loss-lb:0.0398, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:55:20.581] iteration:8105  t-loss:0.0535, loss-lb:0.0153, loss-ulb:0.0191, weight:2.00, lr:0.0005
[00:55:21.005] iteration:8106  t-loss:0.0460, loss-lb:0.0196, loss-ulb:0.0132, weight:2.00, lr:0.0005
[00:55:21.394] iteration:8107  t-loss:0.0583, loss-lb:0.0385, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:55:21.774] iteration:8108  t-loss:0.0511, loss-lb:0.0433, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:55:22.151] iteration:8109  t-loss:0.0353, loss-lb:0.0265, loss-ulb:0.0044, weight:2.00, lr:0.0005
[00:55:22.529] iteration:8110  t-loss:0.0305, loss-lb:0.0283, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:55:22.910] iteration:8111  t-loss:0.0410, loss-lb:0.0359, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:55:23.293] iteration:8112  t-loss:0.0424, loss-lb:0.0243, loss-ulb:0.0090, weight:2.00, lr:0.0005
[00:55:23.672] iteration:8113  t-loss:0.0393, loss-lb:0.0238, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:55:24.052] iteration:8114  t-loss:0.0441, loss-lb:0.0330, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:55:24.428] iteration:8115  t-loss:0.0153, loss-lb:0.0120, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:55:24.819] iteration:8116  t-loss:0.0505, loss-lb:0.0337, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:55:25.211] iteration:8117  t-loss:0.0540, loss-lb:0.0207, loss-ulb:0.0166, weight:2.00, lr:0.0005
[00:55:25.600] iteration:8118  t-loss:0.0294, loss-lb:0.0143, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:55:25.979] iteration:8119  t-loss:0.0165, loss-lb:0.0135, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:55:26.358] iteration:8120  t-loss:0.0455, loss-lb:0.0168, loss-ulb:0.0143, weight:2.00, lr:0.0005
[00:55:26.732] iteration:8121  t-loss:0.0738, loss-lb:0.0149, loss-ulb:0.0295, weight:2.00, lr:0.0005
[00:55:27.111] iteration:8122  t-loss:0.0269, loss-lb:0.0232, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:55:27.498] iteration:8123  t-loss:0.0391, loss-lb:0.0356, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:55:27.887] iteration:8124  t-loss:0.0414, loss-lb:0.0252, loss-ulb:0.0081, weight:2.00, lr:0.0005
[00:55:28.265] iteration:8125  t-loss:0.0770, loss-lb:0.0185, loss-ulb:0.0292, weight:2.00, lr:0.0005
[00:55:28.647] iteration:8126  t-loss:0.0518, loss-lb:0.0331, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:55:29.031] iteration:8127  t-loss:0.0429, loss-lb:0.0333, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:55:29.413] iteration:8128  t-loss:0.0688, loss-lb:0.0308, loss-ulb:0.0190, weight:2.00, lr:0.0005
[00:55:29.786] iteration:8129  t-loss:0.0247, loss-lb:0.0194, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:55:30.170] iteration:8130  t-loss:0.0390, loss-lb:0.0216, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:55:30.548] iteration:8131  t-loss:0.0360, loss-lb:0.0330, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:55:30.925] iteration:8132  t-loss:0.0379, loss-lb:0.0307, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:55:32.306] iteration:8133  t-loss:0.0442, loss-lb:0.0351, loss-ulb:0.0046, weight:2.00, lr:0.0005
[00:55:32.707] iteration:8134  t-loss:0.0616, loss-lb:0.0493, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:55:33.088] iteration:8135  t-loss:0.0160, loss-lb:0.0134, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:55:33.478] iteration:8136  t-loss:0.0628, loss-lb:0.0462, loss-ulb:0.0083, weight:2.00, lr:0.0005
[00:55:33.857] iteration:8137  t-loss:0.0295, loss-lb:0.0156, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:55:34.237] iteration:8138  t-loss:0.0374, loss-lb:0.0200, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:55:34.617] iteration:8139  t-loss:0.0244, loss-lb:0.0210, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:55:35.003] iteration:8140  t-loss:0.1279, loss-lb:0.0412, loss-ulb:0.0433, weight:2.00, lr:0.0005
[00:55:35.388] iteration:8141  t-loss:0.0318, loss-lb:0.0150, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:55:35.770] iteration:8142  t-loss:0.0446, loss-lb:0.0215, loss-ulb:0.0116, weight:2.00, lr:0.0005
[00:55:36.150] iteration:8143  t-loss:0.0571, loss-lb:0.0499, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:55:36.527] iteration:8144  t-loss:0.0231, loss-lb:0.0205, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:55:36.907] iteration:8145  t-loss:0.0336, loss-lb:0.0174, loss-ulb:0.0081, weight:2.00, lr:0.0005
[00:55:37.285] iteration:8146  t-loss:0.0239, loss-lb:0.0198, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:55:37.674] iteration:8147  t-loss:0.0440, loss-lb:0.0311, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:55:38.056] iteration:8148  t-loss:0.0447, loss-lb:0.0288, loss-ulb:0.0080, weight:2.00, lr:0.0005
[00:55:38.436] iteration:8149  t-loss:0.0302, loss-lb:0.0213, loss-ulb:0.0045, weight:2.00, lr:0.0005
[00:55:38.818] iteration:8150  t-loss:0.0675, loss-lb:0.0273, loss-ulb:0.0201, weight:2.00, lr:0.0005
[00:55:39.197] iteration:8151  t-loss:0.0490, loss-lb:0.0366, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:55:39.574] iteration:8152  t-loss:0.0170, loss-lb:0.0139, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:55:39.954] iteration:8153  t-loss:0.0204, loss-lb:0.0174, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:55:40.350] iteration:8154  t-loss:0.0547, loss-lb:0.0322, loss-ulb:0.0113, weight:2.00, lr:0.0005
[00:55:40.742] iteration:8155  t-loss:0.0234, loss-lb:0.0165, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:55:41.129] iteration:8156  t-loss:0.0327, loss-lb:0.0155, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:55:41.514] iteration:8157  t-loss:0.0380, loss-lb:0.0354, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:55:41.895] iteration:8158  t-loss:0.0832, loss-lb:0.0362, loss-ulb:0.0235, weight:2.00, lr:0.0005
[00:55:42.281] iteration:8159  t-loss:0.0396, loss-lb:0.0268, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:55:42.663] iteration:8160  t-loss:0.0237, loss-lb:0.0125, loss-ulb:0.0056, weight:2.00, lr:0.0005
[00:55:43.051] iteration:8161  t-loss:0.0326, loss-lb:0.0191, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:55:43.434] iteration:8162  t-loss:0.1470, loss-lb:0.0673, loss-ulb:0.0398, weight:2.00, lr:0.0005
[00:55:43.818] iteration:8163  t-loss:0.0704, loss-lb:0.0342, loss-ulb:0.0181, weight:2.00, lr:0.0005
[00:55:44.199] iteration:8164  t-loss:0.0495, loss-lb:0.0337, loss-ulb:0.0079, weight:2.00, lr:0.0005
[00:55:44.581] iteration:8165  t-loss:0.0482, loss-lb:0.0124, loss-ulb:0.0179, weight:2.00, lr:0.0005
[00:55:44.960] iteration:8166  t-loss:0.0537, loss-lb:0.0312, loss-ulb:0.0112, weight:2.00, lr:0.0005
[00:55:45.338] iteration:8167  t-loss:0.0254, loss-lb:0.0218, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:55:45.716] iteration:8168  t-loss:0.0296, loss-lb:0.0259, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:55:46.097] iteration:8169  t-loss:0.0288, loss-lb:0.0165, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:55:46.479] iteration:8170  t-loss:0.0292, loss-lb:0.0158, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:55:47.838] iteration:8171  t-loss:0.0185, loss-lb:0.0140, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:55:48.239] iteration:8172  t-loss:0.0767, loss-lb:0.0507, loss-ulb:0.0130, weight:2.00, lr:0.0005
[00:55:48.620] iteration:8173  t-loss:0.0177, loss-lb:0.0150, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:55:48.998] iteration:8174  t-loss:0.0200, loss-lb:0.0156, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:55:49.376] iteration:8175  t-loss:0.0171, loss-lb:0.0125, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:55:49.762] iteration:8176  t-loss:0.0596, loss-lb:0.0354, loss-ulb:0.0121, weight:2.00, lr:0.0005
[00:55:50.152] iteration:8177  t-loss:0.0336, loss-lb:0.0306, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:55:50.535] iteration:8178  t-loss:0.0693, loss-lb:0.0481, loss-ulb:0.0106, weight:2.00, lr:0.0005
[00:55:50.916] iteration:8179  t-loss:0.0494, loss-lb:0.0441, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:55:51.295] iteration:8180  t-loss:0.0555, loss-lb:0.0171, loss-ulb:0.0192, weight:2.00, lr:0.0005
[00:55:51.681] iteration:8181  t-loss:0.0183, loss-lb:0.0130, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:55:52.066] iteration:8182  t-loss:0.0271, loss-lb:0.0254, loss-ulb:0.0009, weight:2.00, lr:0.0005
[00:55:52.448] iteration:8183  t-loss:0.0432, loss-lb:0.0252, loss-ulb:0.0090, weight:2.00, lr:0.0005
[00:55:52.826] iteration:8184  t-loss:0.0394, loss-lb:0.0188, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:55:53.206] iteration:8185  t-loss:0.0482, loss-lb:0.0328, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:55:53.585] iteration:8186  t-loss:0.0427, loss-lb:0.0326, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:55:53.966] iteration:8187  t-loss:0.0452, loss-lb:0.0414, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:55:54.344] iteration:8188  t-loss:0.0252, loss-lb:0.0224, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:55:54.725] iteration:8189  t-loss:0.0252, loss-lb:0.0118, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:55:55.102] iteration:8190  t-loss:0.0218, loss-lb:0.0180, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:55:55.482] iteration:8191  t-loss:0.0340, loss-lb:0.0221, loss-ulb:0.0060, weight:2.00, lr:0.0005
[00:55:55.863] iteration:8192  t-loss:0.0317, loss-lb:0.0270, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:55:56.246] iteration:8193  t-loss:0.0538, loss-lb:0.0266, loss-ulb:0.0136, weight:2.00, lr:0.0005
[00:55:56.633] iteration:8194  t-loss:0.0850, loss-lb:0.0275, loss-ulb:0.0287, weight:2.00, lr:0.0005
[00:55:57.021] iteration:8195  t-loss:0.0561, loss-lb:0.0237, loss-ulb:0.0162, weight:2.00, lr:0.0005
[00:55:57.399] iteration:8196  t-loss:0.0222, loss-lb:0.0154, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:55:57.783] iteration:8197  t-loss:0.0312, loss-lb:0.0289, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:55:58.163] iteration:8198  t-loss:0.0715, loss-lb:0.0338, loss-ulb:0.0188, weight:2.00, lr:0.0005
[00:55:58.546] iteration:8199  t-loss:0.0462, loss-lb:0.0310, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:55:58.925] iteration:8200  t-loss:0.0165, loss-lb:0.0144, loss-ulb:0.0010, weight:2.00, lr:0.0005
[00:55:59.303] iteration:8201  t-loss:0.0423, loss-lb:0.0144, loss-ulb:0.0140, weight:2.00, lr:0.0005
[00:55:59.683] iteration:8202  t-loss:0.0396, loss-lb:0.0370, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:56:00.058] iteration:8203  t-loss:0.0194, loss-lb:0.0146, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:56:00.434] iteration:8204  t-loss:0.0304, loss-lb:0.0174, loss-ulb:0.0065, weight:2.00, lr:0.0005
[00:56:00.819] iteration:8205  t-loss:0.0413, loss-lb:0.0310, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:56:01.198] iteration:8206  t-loss:0.0319, loss-lb:0.0290, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:56:01.578] iteration:8207  t-loss:0.0233, loss-lb:0.0123, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:56:01.959] iteration:8208  t-loss:0.0246, loss-lb:0.0222, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:56:03.259] iteration:8209  t-loss:0.0248, loss-lb:0.0218, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:56:03.653] iteration:8210  t-loss:0.0244, loss-lb:0.0207, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:56:04.033] iteration:8211  t-loss:0.0241, loss-lb:0.0132, loss-ulb:0.0054, weight:2.00, lr:0.0005
[00:56:04.416] iteration:8212  t-loss:0.0261, loss-lb:0.0129, loss-ulb:0.0066, weight:2.00, lr:0.0005
[00:56:04.796] iteration:8213  t-loss:0.0454, loss-lb:0.0171, loss-ulb:0.0141, weight:2.00, lr:0.0005
[00:56:05.177] iteration:8214  t-loss:0.0188, loss-lb:0.0160, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:56:05.568] iteration:8215  t-loss:0.0530, loss-lb:0.0329, loss-ulb:0.0100, weight:2.00, lr:0.0005
[00:56:05.961] iteration:8216  t-loss:0.0510, loss-lb:0.0315, loss-ulb:0.0098, weight:2.00, lr:0.0005
[00:56:06.341] iteration:8217  t-loss:0.0327, loss-lb:0.0152, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:56:06.722] iteration:8218  t-loss:0.0188, loss-lb:0.0172, loss-ulb:0.0008, weight:2.00, lr:0.0005
[00:56:07.108] iteration:8219  t-loss:0.0570, loss-lb:0.0276, loss-ulb:0.0147, weight:2.00, lr:0.0005
[00:56:07.499] iteration:8220  t-loss:0.0481, loss-lb:0.0258, loss-ulb:0.0112, weight:2.00, lr:0.0005
[00:56:07.884] iteration:8221  t-loss:0.0458, loss-lb:0.0304, loss-ulb:0.0077, weight:2.00, lr:0.0005
[00:56:08.262] iteration:8222  t-loss:0.0165, loss-lb:0.0143, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:56:08.650] iteration:8223  t-loss:0.0450, loss-lb:0.0259, loss-ulb:0.0095, weight:2.00, lr:0.0005
[00:56:09.035] iteration:8224  t-loss:0.0435, loss-lb:0.0286, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:56:09.416] iteration:8225  t-loss:0.0185, loss-lb:0.0164, loss-ulb:0.0010, weight:2.00, lr:0.0005
[00:56:09.798] iteration:8226  t-loss:0.0368, loss-lb:0.0246, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:56:10.182] iteration:8227  t-loss:0.0395, loss-lb:0.0257, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:56:10.566] iteration:8228  t-loss:0.0298, loss-lb:0.0261, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:56:10.950] iteration:8229  t-loss:0.0480, loss-lb:0.0305, loss-ulb:0.0088, weight:2.00, lr:0.0005
[00:56:11.336] iteration:8230  t-loss:0.0650, loss-lb:0.0500, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:56:11.717] iteration:8231  t-loss:0.0474, loss-lb:0.0371, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:56:12.100] iteration:8232  t-loss:0.0308, loss-lb:0.0239, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:56:12.484] iteration:8233  t-loss:0.0316, loss-lb:0.0275, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:56:12.863] iteration:8234  t-loss:0.0749, loss-lb:0.0647, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:56:13.243] iteration:8235  t-loss:0.0184, loss-lb:0.0152, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:56:13.628] iteration:8236  t-loss:0.0396, loss-lb:0.0144, loss-ulb:0.0126, weight:2.00, lr:0.0005
[00:56:14.011] iteration:8237  t-loss:0.0521, loss-lb:0.0403, loss-ulb:0.0059, weight:2.00, lr:0.0005
[00:56:14.396] iteration:8238  t-loss:0.0267, loss-lb:0.0241, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:56:14.784] iteration:8239  t-loss:0.0503, loss-lb:0.0258, loss-ulb:0.0123, weight:2.00, lr:0.0005
[00:56:15.166] iteration:8240  t-loss:0.0370, loss-lb:0.0294, loss-ulb:0.0038, weight:2.00, lr:0.0005
[00:56:15.540] iteration:8241  t-loss:0.0245, loss-lb:0.0167, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:56:15.913] iteration:8242  t-loss:0.0330, loss-lb:0.0259, loss-ulb:0.0035, weight:2.00, lr:0.0005
[00:56:16.296] iteration:8243  t-loss:0.0225, loss-lb:0.0203, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:56:16.689] iteration:8244  t-loss:0.0340, loss-lb:0.0312, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:56:17.077] iteration:8245  t-loss:0.0515, loss-lb:0.0316, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:56:17.456] iteration:8246  t-loss:0.0259, loss-lb:0.0134, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:57:17.883] iteration 8246 : dice_score: 0.881069 best_dice: 0.894500
[00:57:17.883]  <<Test>> - Ep:216  - Dice-S/T:86.12/88.11, Best-S:89.30, Best-T:89.45
[00:57:17.883]           - AvgLoss(lb/ulb/all):0.03/0.01/0.04
[00:57:19.004] iteration:8247  t-loss:0.0318, loss-lb:0.0113, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:57:19.439] iteration:8248  t-loss:0.0465, loss-lb:0.0378, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:57:19.846] iteration:8249  t-loss:0.0660, loss-lb:0.0447, loss-ulb:0.0106, weight:2.00, lr:0.0005
[00:57:20.232] iteration:8250  t-loss:0.0277, loss-lb:0.0132, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:57:20.619] iteration:8251  t-loss:0.0413, loss-lb:0.0360, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:57:21.001] iteration:8252  t-loss:0.0262, loss-lb:0.0184, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:57:21.389] iteration:8253  t-loss:0.0708, loss-lb:0.0636, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:57:21.771] iteration:8254  t-loss:0.0491, loss-lb:0.0434, loss-ulb:0.0029, weight:2.00, lr:0.0005
[00:57:22.161] iteration:8255  t-loss:0.0814, loss-lb:0.0309, loss-ulb:0.0252, weight:2.00, lr:0.0005
[00:57:22.546] iteration:8256  t-loss:0.0525, loss-lb:0.0363, loss-ulb:0.0081, weight:2.00, lr:0.0005
[00:57:22.928] iteration:8257  t-loss:0.0170, loss-lb:0.0135, loss-ulb:0.0017, weight:2.00, lr:0.0005
[00:57:23.310] iteration:8258  t-loss:0.0500, loss-lb:0.0270, loss-ulb:0.0115, weight:2.00, lr:0.0005
[00:57:23.693] iteration:8259  t-loss:0.0559, loss-lb:0.0340, loss-ulb:0.0109, weight:2.00, lr:0.0005
[00:57:24.080] iteration:8260  t-loss:0.0339, loss-lb:0.0272, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:57:24.468] iteration:8261  t-loss:0.0299, loss-lb:0.0273, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:57:24.849] iteration:8262  t-loss:0.0453, loss-lb:0.0266, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:57:25.231] iteration:8263  t-loss:0.0619, loss-lb:0.0164, loss-ulb:0.0228, weight:2.00, lr:0.0005
[00:57:25.612] iteration:8264  t-loss:0.0325, loss-lb:0.0290, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:57:26.000] iteration:8265  t-loss:0.0252, loss-lb:0.0225, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:57:26.383] iteration:8266  t-loss:0.0407, loss-lb:0.0294, loss-ulb:0.0057, weight:2.00, lr:0.0005
[00:57:26.765] iteration:8267  t-loss:0.0371, loss-lb:0.0250, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:57:27.148] iteration:8268  t-loss:0.0473, loss-lb:0.0376, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:57:27.524] iteration:8269  t-loss:0.0361, loss-lb:0.0191, loss-ulb:0.0085, weight:2.00, lr:0.0005
[00:57:27.901] iteration:8270  t-loss:0.0323, loss-lb:0.0125, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:57:28.281] iteration:8271  t-loss:0.0281, loss-lb:0.0242, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:57:28.661] iteration:8272  t-loss:0.0199, loss-lb:0.0176, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:57:29.037] iteration:8273  t-loss:0.0254, loss-lb:0.0146, loss-ulb:0.0054, weight:2.00, lr:0.0005
[00:57:29.409] iteration:8274  t-loss:0.0218, loss-lb:0.0143, loss-ulb:0.0037, weight:2.00, lr:0.0005
[00:57:29.791] iteration:8275  t-loss:0.0545, loss-lb:0.0352, loss-ulb:0.0096, weight:2.00, lr:0.0005
[00:57:30.165] iteration:8276  t-loss:0.0192, loss-lb:0.0168, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:57:30.549] iteration:8277  t-loss:0.0292, loss-lb:0.0140, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:57:30.934] iteration:8278  t-loss:0.0301, loss-lb:0.0160, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:57:31.326] iteration:8279  t-loss:0.0458, loss-lb:0.0346, loss-ulb:0.0056, weight:2.00, lr:0.0005
[00:57:31.705] iteration:8280  t-loss:0.0533, loss-lb:0.0382, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:57:32.083] iteration:8281  t-loss:0.0475, loss-lb:0.0415, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:57:32.461] iteration:8282  t-loss:0.0374, loss-lb:0.0264, loss-ulb:0.0055, weight:2.00, lr:0.0005
[00:57:32.841] iteration:8283  t-loss:0.0476, loss-lb:0.0403, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:57:33.217] iteration:8284  t-loss:0.0310, loss-lb:0.0224, loss-ulb:0.0043, weight:2.00, lr:0.0005
[00:57:34.428] iteration:8285  t-loss:0.0324, loss-lb:0.0140, loss-ulb:0.0092, weight:2.00, lr:0.0005
[00:57:34.824] iteration:8286  t-loss:0.0434, loss-lb:0.0206, loss-ulb:0.0114, weight:2.00, lr:0.0005
[00:57:35.219] iteration:8287  t-loss:0.0543, loss-lb:0.0344, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:57:35.598] iteration:8288  t-loss:0.0394, loss-lb:0.0208, loss-ulb:0.0093, weight:2.00, lr:0.0005
[00:57:35.987] iteration:8289  t-loss:0.0651, loss-lb:0.0243, loss-ulb:0.0204, weight:2.00, lr:0.0005
[00:57:36.366] iteration:8290  t-loss:0.0209, loss-lb:0.0184, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:57:36.758] iteration:8291  t-loss:0.0406, loss-lb:0.0258, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:57:37.136] iteration:8292  t-loss:0.0409, loss-lb:0.0347, loss-ulb:0.0031, weight:2.00, lr:0.0005
[00:57:37.516] iteration:8293  t-loss:0.1315, loss-lb:0.1059, loss-ulb:0.0128, weight:2.00, lr:0.0005
[00:57:37.899] iteration:8294  t-loss:0.0373, loss-lb:0.0154, loss-ulb:0.0110, weight:2.00, lr:0.0005
[00:57:38.281] iteration:8295  t-loss:0.0354, loss-lb:0.0160, loss-ulb:0.0097, weight:2.00, lr:0.0005
[00:57:38.657] iteration:8296  t-loss:0.0454, loss-lb:0.0154, loss-ulb:0.0150, weight:2.00, lr:0.0005
[00:57:39.035] iteration:8297  t-loss:0.0153, loss-lb:0.0138, loss-ulb:0.0008, weight:2.00, lr:0.0005
[00:57:39.416] iteration:8298  t-loss:0.0186, loss-lb:0.0154, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:57:39.797] iteration:8299  t-loss:0.0418, loss-lb:0.0359, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:57:40.178] iteration:8300  t-loss:0.0302, loss-lb:0.0144, loss-ulb:0.0079, weight:2.00, lr:0.0005
[00:57:40.562] iteration:8301  t-loss:0.0362, loss-lb:0.0197, loss-ulb:0.0083, weight:2.00, lr:0.0005
[00:57:40.945] iteration:8302  t-loss:0.0169, loss-lb:0.0148, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:57:41.333] iteration:8303  t-loss:0.0261, loss-lb:0.0217, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:57:41.709] iteration:8304  t-loss:0.0178, loss-lb:0.0153, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:57:42.088] iteration:8305  t-loss:0.0334, loss-lb:0.0171, loss-ulb:0.0082, weight:2.00, lr:0.0005
[00:57:42.474] iteration:8306  t-loss:0.0653, loss-lb:0.0327, loss-ulb:0.0163, weight:2.00, lr:0.0005
[00:57:42.855] iteration:8307  t-loss:0.0270, loss-lb:0.0132, loss-ulb:0.0069, weight:2.00, lr:0.0005
[00:57:43.231] iteration:8308  t-loss:0.0208, loss-lb:0.0178, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:57:43.616] iteration:8309  t-loss:0.0352, loss-lb:0.0225, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:57:43.994] iteration:8310  t-loss:0.0402, loss-lb:0.0363, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:57:44.373] iteration:8311  t-loss:0.0330, loss-lb:0.0292, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:57:44.748] iteration:8312  t-loss:0.0257, loss-lb:0.0231, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:57:45.132] iteration:8313  t-loss:0.0270, loss-lb:0.0174, loss-ulb:0.0048, weight:2.00, lr:0.0005
[00:57:45.513] iteration:8314  t-loss:0.0302, loss-lb:0.0135, loss-ulb:0.0083, weight:2.00, lr:0.0005
[00:57:45.894] iteration:8315  t-loss:0.0298, loss-lb:0.0254, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:57:46.283] iteration:8316  t-loss:0.0375, loss-lb:0.0337, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:57:46.674] iteration:8317  t-loss:0.0189, loss-lb:0.0141, loss-ulb:0.0024, weight:2.00, lr:0.0005
[00:57:47.053] iteration:8318  t-loss:0.0384, loss-lb:0.0212, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:57:47.432] iteration:8319  t-loss:0.0187, loss-lb:0.0147, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:57:47.816] iteration:8320  t-loss:0.0506, loss-lb:0.0294, loss-ulb:0.0106, weight:2.00, lr:0.0005
[00:57:48.195] iteration:8321  t-loss:0.0573, loss-lb:0.0367, loss-ulb:0.0103, weight:2.00, lr:0.0005
[00:57:48.570] iteration:8322  t-loss:0.0312, loss-lb:0.0287, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:57:49.971] iteration:8323  t-loss:0.0427, loss-lb:0.0262, loss-ulb:0.0083, weight:2.00, lr:0.0005
[00:57:50.362] iteration:8324  t-loss:0.0302, loss-lb:0.0167, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:57:50.753] iteration:8325  t-loss:0.0363, loss-lb:0.0171, loss-ulb:0.0096, weight:2.00, lr:0.0005
[00:57:51.136] iteration:8326  t-loss:0.0408, loss-lb:0.0228, loss-ulb:0.0090, weight:2.00, lr:0.0005
[00:57:51.519] iteration:8327  t-loss:0.0288, loss-lb:0.0164, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:57:51.908] iteration:8328  t-loss:0.0422, loss-lb:0.0282, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:57:52.290] iteration:8329  t-loss:0.0176, loss-lb:0.0153, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:57:52.673] iteration:8330  t-loss:0.0269, loss-lb:0.0226, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:57:53.061] iteration:8331  t-loss:0.0345, loss-lb:0.0315, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:57:53.447] iteration:8332  t-loss:0.0359, loss-lb:0.0254, loss-ulb:0.0053, weight:2.00, lr:0.0005
[00:57:53.835] iteration:8333  t-loss:0.0268, loss-lb:0.0156, loss-ulb:0.0056, weight:2.00, lr:0.0005
[00:57:54.214] iteration:8334  t-loss:0.0178, loss-lb:0.0145, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:57:54.597] iteration:8335  t-loss:0.0297, loss-lb:0.0154, loss-ulb:0.0072, weight:2.00, lr:0.0005
[00:57:54.985] iteration:8336  t-loss:0.0397, loss-lb:0.0273, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:57:55.372] iteration:8337  t-loss:0.0334, loss-lb:0.0109, loss-ulb:0.0113, weight:2.00, lr:0.0005
[00:57:55.754] iteration:8338  t-loss:0.0155, loss-lb:0.0133, loss-ulb:0.0011, weight:2.00, lr:0.0005
[00:57:56.143] iteration:8339  t-loss:0.0596, loss-lb:0.0220, loss-ulb:0.0188, weight:2.00, lr:0.0005
[00:57:56.522] iteration:8340  t-loss:0.0548, loss-lb:0.0137, loss-ulb:0.0206, weight:2.00, lr:0.0005
[00:57:56.902] iteration:8341  t-loss:0.0215, loss-lb:0.0154, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:57:57.287] iteration:8342  t-loss:0.0547, loss-lb:0.0286, loss-ulb:0.0130, weight:2.00, lr:0.0005
[00:57:57.667] iteration:8343  t-loss:0.0382, loss-lb:0.0237, loss-ulb:0.0073, weight:2.00, lr:0.0005
[00:57:58.045] iteration:8344  t-loss:0.0356, loss-lb:0.0310, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:57:58.421] iteration:8345  t-loss:0.0337, loss-lb:0.0293, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:57:58.796] iteration:8346  t-loss:0.0258, loss-lb:0.0163, loss-ulb:0.0047, weight:2.00, lr:0.0005
[00:57:59.173] iteration:8347  t-loss:0.0239, loss-lb:0.0193, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:57:59.546] iteration:8348  t-loss:0.0176, loss-lb:0.0138, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:57:59.927] iteration:8349  t-loss:0.0752, loss-lb:0.0565, loss-ulb:0.0094, weight:2.00, lr:0.0005
[00:58:00.306] iteration:8350  t-loss:0.0205, loss-lb:0.0156, loss-ulb:0.0025, weight:2.00, lr:0.0005
[00:58:00.682] iteration:8351  t-loss:0.0771, loss-lb:0.0576, loss-ulb:0.0098, weight:2.00, lr:0.0005
[00:58:01.065] iteration:8352  t-loss:0.0317, loss-lb:0.0140, loss-ulb:0.0089, weight:2.00, lr:0.0005
[00:58:01.447] iteration:8353  t-loss:0.0467, loss-lb:0.0276, loss-ulb:0.0096, weight:2.00, lr:0.0005
[00:58:01.820] iteration:8354  t-loss:0.0222, loss-lb:0.0156, loss-ulb:0.0033, weight:2.00, lr:0.0005
[00:58:02.199] iteration:8355  t-loss:0.0382, loss-lb:0.0357, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:58:02.581] iteration:8356  t-loss:0.0291, loss-lb:0.0192, loss-ulb:0.0049, weight:2.00, lr:0.0005
[00:58:02.962] iteration:8357  t-loss:0.0511, loss-lb:0.0307, loss-ulb:0.0102, weight:2.00, lr:0.0005
[00:58:03.344] iteration:8358  t-loss:0.0361, loss-lb:0.0158, loss-ulb:0.0102, weight:2.00, lr:0.0005
[00:58:03.720] iteration:8359  t-loss:0.0360, loss-lb:0.0260, loss-ulb:0.0050, weight:2.00, lr:0.0005
[00:58:04.091] iteration:8360  t-loss:0.0228, loss-lb:0.0168, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:58:05.226] iteration:8361  t-loss:0.0748, loss-lb:0.0284, loss-ulb:0.0232, weight:2.00, lr:0.0005
[00:58:05.621] iteration:8362  t-loss:0.0372, loss-lb:0.0183, loss-ulb:0.0095, weight:2.00, lr:0.0005
[00:58:06.003] iteration:8363  t-loss:0.0367, loss-lb:0.0203, loss-ulb:0.0082, weight:2.00, lr:0.0005
[00:58:06.381] iteration:8364  t-loss:0.0386, loss-lb:0.0339, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:58:06.765] iteration:8365  t-loss:0.0579, loss-lb:0.0464, loss-ulb:0.0058, weight:2.00, lr:0.0005
[00:58:07.147] iteration:8366  t-loss:0.0371, loss-lb:0.0306, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:58:07.530] iteration:8367  t-loss:0.0390, loss-lb:0.0347, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:58:07.920] iteration:8368  t-loss:0.0451, loss-lb:0.0329, loss-ulb:0.0061, weight:2.00, lr:0.0005
[00:58:08.331] iteration:8369  t-loss:0.0532, loss-lb:0.0357, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:58:08.719] iteration:8370  t-loss:0.0297, loss-lb:0.0157, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:58:09.106] iteration:8371  t-loss:0.0429, loss-lb:0.0298, loss-ulb:0.0065, weight:2.00, lr:0.0005
[00:58:09.489] iteration:8372  t-loss:0.0517, loss-lb:0.0182, loss-ulb:0.0168, weight:2.00, lr:0.0005
[00:58:09.876] iteration:8373  t-loss:0.0463, loss-lb:0.0434, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:58:10.261] iteration:8374  t-loss:0.0376, loss-lb:0.0221, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:58:10.646] iteration:8375  t-loss:0.0235, loss-lb:0.0150, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:58:11.026] iteration:8376  t-loss:0.0300, loss-lb:0.0241, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:58:11.412] iteration:8377  t-loss:0.0163, loss-lb:0.0130, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:58:11.797] iteration:8378  t-loss:0.0579, loss-lb:0.0395, loss-ulb:0.0092, weight:2.00, lr:0.0005
[00:58:12.169] iteration:8379  t-loss:0.0213, loss-lb:0.0170, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:58:12.551] iteration:8380  t-loss:0.0469, loss-lb:0.0442, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:58:12.936] iteration:8381  t-loss:0.0247, loss-lb:0.0192, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:58:13.315] iteration:8382  t-loss:0.0341, loss-lb:0.0304, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:58:13.693] iteration:8383  t-loss:0.0390, loss-lb:0.0317, loss-ulb:0.0036, weight:2.00, lr:0.0005
[00:58:14.082] iteration:8384  t-loss:0.0300, loss-lb:0.0161, loss-ulb:0.0070, weight:2.00, lr:0.0005
[00:58:14.475] iteration:8385  t-loss:0.0298, loss-lb:0.0156, loss-ulb:0.0071, weight:2.00, lr:0.0005
[00:58:14.857] iteration:8386  t-loss:0.0284, loss-lb:0.0158, loss-ulb:0.0063, weight:2.00, lr:0.0005
[00:58:15.237] iteration:8387  t-loss:0.0174, loss-lb:0.0148, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:58:15.618] iteration:8388  t-loss:0.0151, loss-lb:0.0127, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:58:16.001] iteration:8389  t-loss:0.0229, loss-lb:0.0188, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:58:16.383] iteration:8390  t-loss:0.0463, loss-lb:0.0130, loss-ulb:0.0166, weight:2.00, lr:0.0005
[00:58:16.758] iteration:8391  t-loss:0.0262, loss-lb:0.0220, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:58:17.136] iteration:8392  t-loss:0.0391, loss-lb:0.0347, loss-ulb:0.0022, weight:2.00, lr:0.0005
[00:58:17.517] iteration:8393  t-loss:0.0540, loss-lb:0.0332, loss-ulb:0.0104, weight:2.00, lr:0.0005
[00:58:17.897] iteration:8394  t-loss:0.0279, loss-lb:0.0142, loss-ulb:0.0068, weight:2.00, lr:0.0005
[00:58:18.272] iteration:8395  t-loss:0.0189, loss-lb:0.0162, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:58:18.657] iteration:8396  t-loss:0.0319, loss-lb:0.0280, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:58:19.054] iteration:8397  t-loss:0.0327, loss-lb:0.0160, loss-ulb:0.0083, weight:2.00, lr:0.0005
[00:58:19.449] iteration:8398  t-loss:0.0496, loss-lb:0.0308, loss-ulb:0.0094, weight:2.00, lr:0.0005
[00:59:22.559] iteration 8398 : dice_score: 0.877934 best_dice: 0.894500
[00:59:22.559]  <<Test>> - Ep:220  - Dice-S/T:87.90/87.79, Best-S:89.30, Best-T:89.45
[00:59:22.559]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[00:59:23.607] iteration:8399  t-loss:0.0207, loss-lb:0.0143, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:59:24.020] iteration:8400  t-loss:0.0354, loss-lb:0.0241, loss-ulb:0.0056, weight:2.00, lr:0.0005
[00:59:24.421] iteration:8401  t-loss:0.0308, loss-lb:0.0196, loss-ulb:0.0056, weight:2.00, lr:0.0005
[00:59:24.803] iteration:8402  t-loss:0.0292, loss-lb:0.0167, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:59:25.192] iteration:8403  t-loss:0.0397, loss-lb:0.0321, loss-ulb:0.0038, weight:2.00, lr:0.0005
[00:59:25.578] iteration:8404  t-loss:0.0434, loss-lb:0.0397, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:59:25.961] iteration:8405  t-loss:0.0461, loss-lb:0.0241, loss-ulb:0.0110, weight:2.00, lr:0.0005
[00:59:26.343] iteration:8406  t-loss:0.0533, loss-lb:0.0404, loss-ulb:0.0064, weight:2.00, lr:0.0005
[00:59:26.726] iteration:8407  t-loss:0.0192, loss-lb:0.0159, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:59:27.110] iteration:8408  t-loss:0.0685, loss-lb:0.0327, loss-ulb:0.0179, weight:2.00, lr:0.0005
[00:59:27.495] iteration:8409  t-loss:0.0270, loss-lb:0.0223, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:59:27.888] iteration:8410  t-loss:0.0388, loss-lb:0.0233, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:59:28.271] iteration:8411  t-loss:0.0419, loss-lb:0.0284, loss-ulb:0.0068, weight:2.00, lr:0.0005
[00:59:28.651] iteration:8412  t-loss:0.0622, loss-lb:0.0253, loss-ulb:0.0184, weight:2.00, lr:0.0005
[00:59:29.032] iteration:8413  t-loss:0.0366, loss-lb:0.0197, loss-ulb:0.0084, weight:2.00, lr:0.0005
[00:59:29.412] iteration:8414  t-loss:0.0589, loss-lb:0.0298, loss-ulb:0.0145, weight:2.00, lr:0.0005
[00:59:29.802] iteration:8415  t-loss:0.0352, loss-lb:0.0271, loss-ulb:0.0040, weight:2.00, lr:0.0005
[00:59:30.180] iteration:8416  t-loss:0.0268, loss-lb:0.0208, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:59:30.561] iteration:8417  t-loss:0.0566, loss-lb:0.0131, loss-ulb:0.0217, weight:2.00, lr:0.0005
[00:59:30.944] iteration:8418  t-loss:0.0581, loss-lb:0.0146, loss-ulb:0.0218, weight:2.00, lr:0.0005
[00:59:31.330] iteration:8419  t-loss:0.0380, loss-lb:0.0138, loss-ulb:0.0121, weight:2.00, lr:0.0005
[00:59:31.711] iteration:8420  t-loss:0.0425, loss-lb:0.0396, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:59:32.091] iteration:8421  t-loss:0.0325, loss-lb:0.0169, loss-ulb:0.0078, weight:2.00, lr:0.0005
[00:59:32.469] iteration:8422  t-loss:0.0363, loss-lb:0.0310, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:59:32.854] iteration:8423  t-loss:0.0758, loss-lb:0.0378, loss-ulb:0.0190, weight:2.00, lr:0.0005
[00:59:33.239] iteration:8424  t-loss:0.0166, loss-lb:0.0140, loss-ulb:0.0013, weight:2.00, lr:0.0005
[00:59:33.620] iteration:8425  t-loss:0.0402, loss-lb:0.0350, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:59:33.994] iteration:8426  t-loss:0.0320, loss-lb:0.0161, loss-ulb:0.0080, weight:2.00, lr:0.0005
[00:59:34.379] iteration:8427  t-loss:0.0542, loss-lb:0.0380, loss-ulb:0.0081, weight:2.00, lr:0.0005
[00:59:34.769] iteration:8428  t-loss:0.0453, loss-lb:0.0254, loss-ulb:0.0099, weight:2.00, lr:0.0005
[00:59:35.146] iteration:8429  t-loss:0.0344, loss-lb:0.0243, loss-ulb:0.0051, weight:2.00, lr:0.0005
[00:59:35.520] iteration:8430  t-loss:0.0392, loss-lb:0.0340, loss-ulb:0.0026, weight:2.00, lr:0.0005
[00:59:35.895] iteration:8431  t-loss:0.0280, loss-lb:0.0175, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:59:36.272] iteration:8432  t-loss:0.0309, loss-lb:0.0242, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:59:36.649] iteration:8433  t-loss:0.0493, loss-lb:0.0429, loss-ulb:0.0032, weight:2.00, lr:0.0005
[00:59:37.049] iteration:8434  t-loss:0.0557, loss-lb:0.0172, loss-ulb:0.0193, weight:2.00, lr:0.0005
[00:59:37.440] iteration:8435  t-loss:0.0427, loss-lb:0.0277, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:59:37.815] iteration:8436  t-loss:0.0233, loss-lb:0.0165, loss-ulb:0.0034, weight:2.00, lr:0.0005
[00:59:38.997] iteration:8437  t-loss:0.0260, loss-lb:0.0242, loss-ulb:0.0009, weight:2.00, lr:0.0005
[00:59:39.407] iteration:8438  t-loss:0.0755, loss-lb:0.0362, loss-ulb:0.0196, weight:2.00, lr:0.0005
[00:59:39.793] iteration:8439  t-loss:0.0280, loss-lb:0.0128, loss-ulb:0.0076, weight:2.00, lr:0.0005
[00:59:40.187] iteration:8440  t-loss:0.0406, loss-lb:0.0322, loss-ulb:0.0042, weight:2.00, lr:0.0005
[00:59:40.574] iteration:8441  t-loss:0.0309, loss-lb:0.0137, loss-ulb:0.0086, weight:2.00, lr:0.0005
[00:59:40.958] iteration:8442  t-loss:0.0199, loss-lb:0.0157, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:59:41.350] iteration:8443  t-loss:0.0355, loss-lb:0.0278, loss-ulb:0.0039, weight:2.00, lr:0.0005
[00:59:41.731] iteration:8444  t-loss:0.0291, loss-lb:0.0202, loss-ulb:0.0045, weight:2.00, lr:0.0005
[00:59:42.113] iteration:8445  t-loss:0.0463, loss-lb:0.0227, loss-ulb:0.0118, weight:2.00, lr:0.0005
[00:59:42.495] iteration:8446  t-loss:0.0281, loss-lb:0.0158, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:59:42.879] iteration:8447  t-loss:0.0362, loss-lb:0.0239, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:59:43.260] iteration:8448  t-loss:0.0336, loss-lb:0.0207, loss-ulb:0.0065, weight:2.00, lr:0.0005
[00:59:43.645] iteration:8449  t-loss:0.0318, loss-lb:0.0293, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:59:44.035] iteration:8450  t-loss:0.0299, loss-lb:0.0193, loss-ulb:0.0053, weight:2.00, lr:0.0005
[00:59:44.419] iteration:8451  t-loss:0.0215, loss-lb:0.0160, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:59:44.798] iteration:8452  t-loss:0.0386, loss-lb:0.0348, loss-ulb:0.0019, weight:2.00, lr:0.0005
[00:59:45.179] iteration:8453  t-loss:0.0477, loss-lb:0.0371, loss-ulb:0.0053, weight:2.00, lr:0.0005
[00:59:45.564] iteration:8454  t-loss:0.0219, loss-lb:0.0180, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:59:45.946] iteration:8455  t-loss:0.0586, loss-lb:0.0312, loss-ulb:0.0137, weight:2.00, lr:0.0005
[00:59:46.322] iteration:8456  t-loss:0.0382, loss-lb:0.0268, loss-ulb:0.0057, weight:2.00, lr:0.0005
[00:59:46.700] iteration:8457  t-loss:0.0256, loss-lb:0.0196, loss-ulb:0.0030, weight:2.00, lr:0.0005
[00:59:47.083] iteration:8458  t-loss:0.0329, loss-lb:0.0248, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:59:47.465] iteration:8459  t-loss:0.0171, loss-lb:0.0143, loss-ulb:0.0014, weight:2.00, lr:0.0005
[00:59:47.847] iteration:8460  t-loss:0.0302, loss-lb:0.0220, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:59:48.228] iteration:8461  t-loss:0.0244, loss-lb:0.0163, loss-ulb:0.0041, weight:2.00, lr:0.0005
[00:59:48.611] iteration:8462  t-loss:0.0565, loss-lb:0.0297, loss-ulb:0.0134, weight:2.00, lr:0.0005
[00:59:48.989] iteration:8463  t-loss:0.0162, loss-lb:0.0131, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:59:49.365] iteration:8464  t-loss:0.0554, loss-lb:0.0166, loss-ulb:0.0194, weight:2.00, lr:0.0005
[00:59:49.747] iteration:8465  t-loss:0.0399, loss-lb:0.0196, loss-ulb:0.0101, weight:2.00, lr:0.0005
[00:59:50.129] iteration:8466  t-loss:0.0450, loss-lb:0.0420, loss-ulb:0.0015, weight:2.00, lr:0.0005
[00:59:50.507] iteration:8467  t-loss:0.0623, loss-lb:0.0393, loss-ulb:0.0115, weight:2.00, lr:0.0005
[00:59:50.883] iteration:8468  t-loss:0.0333, loss-lb:0.0288, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:59:51.262] iteration:8469  t-loss:0.0442, loss-lb:0.0220, loss-ulb:0.0111, weight:2.00, lr:0.0005
[00:59:51.636] iteration:8470  t-loss:0.0181, loss-lb:0.0158, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:59:52.020] iteration:8471  t-loss:0.0383, loss-lb:0.0347, loss-ulb:0.0018, weight:2.00, lr:0.0005
[00:59:52.418] iteration:8472  t-loss:0.0444, loss-lb:0.0228, loss-ulb:0.0108, weight:2.00, lr:0.0005
[00:59:52.802] iteration:8473  t-loss:0.0318, loss-lb:0.0143, loss-ulb:0.0087, weight:2.00, lr:0.0005
[00:59:53.178] iteration:8474  t-loss:0.0302, loss-lb:0.0155, loss-ulb:0.0074, weight:2.00, lr:0.0005
[00:59:54.409] iteration:8475  t-loss:0.0218, loss-lb:0.0175, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:59:54.819] iteration:8476  t-loss:0.0286, loss-lb:0.0163, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:59:55.199] iteration:8477  t-loss:0.0322, loss-lb:0.0267, loss-ulb:0.0027, weight:2.00, lr:0.0005
[00:59:55.575] iteration:8478  t-loss:0.0221, loss-lb:0.0175, loss-ulb:0.0023, weight:2.00, lr:0.0005
[00:59:55.967] iteration:8479  t-loss:0.0401, loss-lb:0.0360, loss-ulb:0.0021, weight:2.00, lr:0.0005
[00:59:56.348] iteration:8480  t-loss:0.0405, loss-lb:0.0381, loss-ulb:0.0012, weight:2.00, lr:0.0005
[00:59:56.735] iteration:8481  t-loss:0.0286, loss-lb:0.0151, loss-ulb:0.0067, weight:2.00, lr:0.0005
[00:59:57.114] iteration:8482  t-loss:0.0288, loss-lb:0.0248, loss-ulb:0.0020, weight:2.00, lr:0.0005
[00:59:57.496] iteration:8483  t-loss:0.0278, loss-lb:0.0154, loss-ulb:0.0062, weight:2.00, lr:0.0005
[00:59:57.877] iteration:8484  t-loss:0.0564, loss-lb:0.0367, loss-ulb:0.0098, weight:2.00, lr:0.0005
[00:59:58.265] iteration:8485  t-loss:0.0435, loss-lb:0.0332, loss-ulb:0.0052, weight:2.00, lr:0.0005
[00:59:58.643] iteration:8486  t-loss:0.0178, loss-lb:0.0147, loss-ulb:0.0016, weight:2.00, lr:0.0005
[00:59:59.025] iteration:8487  t-loss:0.0281, loss-lb:0.0130, loss-ulb:0.0075, weight:2.00, lr:0.0005
[00:59:59.410] iteration:8488  t-loss:0.0391, loss-lb:0.0335, loss-ulb:0.0028, weight:2.00, lr:0.0005
[00:59:59.788] iteration:8489  t-loss:0.0444, loss-lb:0.0262, loss-ulb:0.0091, weight:2.00, lr:0.0005
[01:00:00.165] iteration:8490  t-loss:0.0173, loss-lb:0.0151, loss-ulb:0.0011, weight:2.00, lr:0.0005
[01:00:00.550] iteration:8491  t-loss:0.0280, loss-lb:0.0234, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:00:00.935] iteration:8492  t-loss:0.0375, loss-lb:0.0233, loss-ulb:0.0071, weight:2.00, lr:0.0005
[01:00:01.321] iteration:8493  t-loss:0.0339, loss-lb:0.0167, loss-ulb:0.0086, weight:2.00, lr:0.0005
[01:00:01.702] iteration:8494  t-loss:0.0393, loss-lb:0.0142, loss-ulb:0.0125, weight:2.00, lr:0.0005
[01:00:02.085] iteration:8495  t-loss:0.0558, loss-lb:0.0519, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:00:02.473] iteration:8496  t-loss:0.0375, loss-lb:0.0263, loss-ulb:0.0056, weight:2.00, lr:0.0005
[01:00:02.853] iteration:8497  t-loss:0.0570, loss-lb:0.0398, loss-ulb:0.0086, weight:2.00, lr:0.0005
[01:00:03.239] iteration:8498  t-loss:0.0454, loss-lb:0.0117, loss-ulb:0.0168, weight:2.00, lr:0.0005
[01:00:03.618] iteration:8499  t-loss:0.0413, loss-lb:0.0389, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:00:04.005] iteration:8500  t-loss:0.0606, loss-lb:0.0254, loss-ulb:0.0176, weight:2.00, lr:0.0005
[01:00:04.396] iteration:8501  t-loss:0.0416, loss-lb:0.0293, loss-ulb:0.0061, weight:2.00, lr:0.0005
[01:00:04.777] iteration:8502  t-loss:0.0319, loss-lb:0.0132, loss-ulb:0.0094, weight:2.00, lr:0.0005
[01:00:05.154] iteration:8503  t-loss:0.0274, loss-lb:0.0257, loss-ulb:0.0008, weight:2.00, lr:0.0005
[01:00:05.531] iteration:8504  t-loss:0.0253, loss-lb:0.0232, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:00:05.911] iteration:8505  t-loss:0.0306, loss-lb:0.0209, loss-ulb:0.0048, weight:2.00, lr:0.0005
[01:00:06.283] iteration:8506  t-loss:0.0165, loss-lb:0.0132, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:00:06.656] iteration:8507  t-loss:0.0251, loss-lb:0.0204, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:00:07.032] iteration:8508  t-loss:0.0270, loss-lb:0.0232, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:00:07.409] iteration:8509  t-loss:0.0224, loss-lb:0.0199, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:00:07.792] iteration:8510  t-loss:0.0285, loss-lb:0.0247, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:00:08.169] iteration:8511  t-loss:0.0680, loss-lb:0.0153, loss-ulb:0.0263, weight:2.00, lr:0.0005
[01:00:08.549] iteration:8512  t-loss:0.0237, loss-lb:0.0128, loss-ulb:0.0055, weight:2.00, lr:0.0005
[01:00:09.824] iteration:8513  t-loss:0.0200, loss-lb:0.0176, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:00:10.217] iteration:8514  t-loss:0.0219, loss-lb:0.0146, loss-ulb:0.0037, weight:2.00, lr:0.0005
[01:00:10.595] iteration:8515  t-loss:0.0193, loss-lb:0.0156, loss-ulb:0.0018, weight:2.00, lr:0.0005
[01:00:10.982] iteration:8516  t-loss:0.0275, loss-lb:0.0170, loss-ulb:0.0052, weight:2.00, lr:0.0005
[01:00:11.364] iteration:8517  t-loss:0.0457, loss-lb:0.0236, loss-ulb:0.0110, weight:2.00, lr:0.0005
[01:00:11.755] iteration:8518  t-loss:0.0594, loss-lb:0.0455, loss-ulb:0.0070, weight:2.00, lr:0.0005
[01:00:12.133] iteration:8519  t-loss:0.0301, loss-lb:0.0131, loss-ulb:0.0085, weight:2.00, lr:0.0005
[01:00:12.513] iteration:8520  t-loss:0.0612, loss-lb:0.0592, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:00:12.897] iteration:8521  t-loss:0.0583, loss-lb:0.0282, loss-ulb:0.0151, weight:2.00, lr:0.0005
[01:00:13.285] iteration:8522  t-loss:0.0166, loss-lb:0.0121, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:00:13.667] iteration:8523  t-loss:0.0379, loss-lb:0.0267, loss-ulb:0.0056, weight:2.00, lr:0.0005
[01:00:14.050] iteration:8524  t-loss:0.0388, loss-lb:0.0169, loss-ulb:0.0109, weight:2.00, lr:0.0005
[01:00:14.442] iteration:8525  t-loss:0.0450, loss-lb:0.0227, loss-ulb:0.0111, weight:2.00, lr:0.0005
[01:00:14.828] iteration:8526  t-loss:0.0399, loss-lb:0.0249, loss-ulb:0.0075, weight:2.00, lr:0.0005
[01:00:15.209] iteration:8527  t-loss:0.0209, loss-lb:0.0167, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:00:15.595] iteration:8528  t-loss:0.0264, loss-lb:0.0223, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:00:15.988] iteration:8529  t-loss:0.0249, loss-lb:0.0106, loss-ulb:0.0072, weight:2.00, lr:0.0005
[01:00:16.370] iteration:8530  t-loss:0.0487, loss-lb:0.0138, loss-ulb:0.0174, weight:2.00, lr:0.0005
[01:00:16.757] iteration:8531  t-loss:0.0229, loss-lb:0.0212, loss-ulb:0.0008, weight:2.00, lr:0.0005
[01:00:17.140] iteration:8532  t-loss:0.0198, loss-lb:0.0151, loss-ulb:0.0024, weight:2.00, lr:0.0005
[01:00:17.524] iteration:8533  t-loss:0.0275, loss-lb:0.0254, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:00:17.906] iteration:8534  t-loss:0.0246, loss-lb:0.0161, loss-ulb:0.0043, weight:2.00, lr:0.0005
[01:00:18.293] iteration:8535  t-loss:0.0392, loss-lb:0.0363, loss-ulb:0.0014, weight:2.00, lr:0.0005
[01:00:18.676] iteration:8536  t-loss:0.0206, loss-lb:0.0183, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:00:19.056] iteration:8537  t-loss:0.0355, loss-lb:0.0336, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:00:19.434] iteration:8538  t-loss:0.0230, loss-lb:0.0210, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:00:19.815] iteration:8539  t-loss:0.0329, loss-lb:0.0307, loss-ulb:0.0011, weight:2.00, lr:0.0005
[01:00:20.200] iteration:8540  t-loss:0.0461, loss-lb:0.0232, loss-ulb:0.0115, weight:2.00, lr:0.0005
[01:00:20.587] iteration:8541  t-loss:0.0482, loss-lb:0.0147, loss-ulb:0.0167, weight:2.00, lr:0.0005
[01:00:20.967] iteration:8542  t-loss:0.0251, loss-lb:0.0160, loss-ulb:0.0046, weight:2.00, lr:0.0005
[01:00:21.349] iteration:8543  t-loss:0.0291, loss-lb:0.0134, loss-ulb:0.0079, weight:2.00, lr:0.0005
[01:00:21.727] iteration:8544  t-loss:0.0295, loss-lb:0.0270, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:00:22.118] iteration:8545  t-loss:0.0305, loss-lb:0.0172, loss-ulb:0.0067, weight:2.00, lr:0.0005
[01:00:22.509] iteration:8546  t-loss:0.0216, loss-lb:0.0123, loss-ulb:0.0047, weight:2.00, lr:0.0005
[01:00:22.895] iteration:8547  t-loss:0.0192, loss-lb:0.0130, loss-ulb:0.0031, weight:2.00, lr:0.0005
[01:00:23.274] iteration:8548  t-loss:0.0392, loss-lb:0.0185, loss-ulb:0.0103, weight:2.00, lr:0.0005
[01:00:23.656] iteration:8549  t-loss:0.0452, loss-lb:0.0334, loss-ulb:0.0059, weight:2.00, lr:0.0005
[01:00:24.032] iteration:8550  t-loss:0.0365, loss-lb:0.0338, loss-ulb:0.0014, weight:2.00, lr:0.0005
[01:01:27.952] iteration 8550 : dice_score: 0.890987 best_dice: 0.894500
[01:01:27.952]  <<Test>> - Ep:224  - Dice-S/T:85.25/89.10, Best-S:89.30, Best-T:89.45
[01:01:27.952]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[01:01:29.199] iteration:8551  t-loss:0.0136, loss-lb:0.0113, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:01:29.621] iteration:8552  t-loss:0.0267, loss-lb:0.0249, loss-ulb:0.0009, weight:2.00, lr:0.0005
[01:01:30.024] iteration:8553  t-loss:0.0351, loss-lb:0.0142, loss-ulb:0.0104, weight:2.00, lr:0.0005
[01:01:30.413] iteration:8554  t-loss:0.0392, loss-lb:0.0370, loss-ulb:0.0011, weight:2.00, lr:0.0005
[01:01:30.795] iteration:8555  t-loss:0.0182, loss-lb:0.0162, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:01:31.186] iteration:8556  t-loss:0.0496, loss-lb:0.0355, loss-ulb:0.0071, weight:2.00, lr:0.0005
[01:01:31.573] iteration:8557  t-loss:0.0282, loss-lb:0.0114, loss-ulb:0.0084, weight:2.00, lr:0.0005
[01:01:31.962] iteration:8558  t-loss:0.0538, loss-lb:0.0347, loss-ulb:0.0096, weight:2.00, lr:0.0005
[01:01:32.345] iteration:8559  t-loss:0.0388, loss-lb:0.0106, loss-ulb:0.0141, weight:2.00, lr:0.0005
[01:01:32.725] iteration:8560  t-loss:0.0219, loss-lb:0.0182, loss-ulb:0.0018, weight:2.00, lr:0.0005
[01:01:33.110] iteration:8561  t-loss:0.0399, loss-lb:0.0260, loss-ulb:0.0070, weight:2.00, lr:0.0005
[01:01:33.490] iteration:8562  t-loss:0.0334, loss-lb:0.0147, loss-ulb:0.0093, weight:2.00, lr:0.0005
[01:01:33.873] iteration:8563  t-loss:0.0347, loss-lb:0.0237, loss-ulb:0.0055, weight:2.00, lr:0.0005
[01:01:34.253] iteration:8564  t-loss:0.0245, loss-lb:0.0210, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:01:34.640] iteration:8565  t-loss:0.0317, loss-lb:0.0288, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:01:35.025] iteration:8566  t-loss:0.0403, loss-lb:0.0357, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:01:35.405] iteration:8567  t-loss:0.0166, loss-lb:0.0124, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:01:35.794] iteration:8568  t-loss:0.0323, loss-lb:0.0191, loss-ulb:0.0066, weight:2.00, lr:0.0005
[01:01:36.175] iteration:8569  t-loss:0.0260, loss-lb:0.0228, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:01:36.554] iteration:8570  t-loss:0.0176, loss-lb:0.0140, loss-ulb:0.0018, weight:2.00, lr:0.0005
[01:01:36.941] iteration:8571  t-loss:0.0344, loss-lb:0.0169, loss-ulb:0.0087, weight:2.00, lr:0.0005
[01:01:37.321] iteration:8572  t-loss:0.0257, loss-lb:0.0158, loss-ulb:0.0049, weight:2.00, lr:0.0005
[01:01:37.707] iteration:8573  t-loss:0.0489, loss-lb:0.0395, loss-ulb:0.0047, weight:2.00, lr:0.0005
[01:01:38.084] iteration:8574  t-loss:0.0174, loss-lb:0.0146, loss-ulb:0.0014, weight:2.00, lr:0.0005
[01:01:38.465] iteration:8575  t-loss:0.1266, loss-lb:0.1241, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:01:38.842] iteration:8576  t-loss:0.0204, loss-lb:0.0131, loss-ulb:0.0037, weight:2.00, lr:0.0005
[01:01:39.226] iteration:8577  t-loss:0.0174, loss-lb:0.0114, loss-ulb:0.0030, weight:2.00, lr:0.0005
[01:01:39.607] iteration:8578  t-loss:0.0877, loss-lb:0.0381, loss-ulb:0.0248, weight:2.00, lr:0.0005
[01:01:39.990] iteration:8579  t-loss:0.0145, loss-lb:0.0112, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:01:40.370] iteration:8580  t-loss:0.0311, loss-lb:0.0263, loss-ulb:0.0024, weight:2.00, lr:0.0005
[01:01:40.755] iteration:8581  t-loss:0.0261, loss-lb:0.0235, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:01:41.131] iteration:8582  t-loss:0.0596, loss-lb:0.0148, loss-ulb:0.0224, weight:2.00, lr:0.0005
[01:01:41.505] iteration:8583  t-loss:0.0204, loss-lb:0.0111, loss-ulb:0.0047, weight:2.00, lr:0.0005
[01:01:41.881] iteration:8584  t-loss:0.0248, loss-lb:0.0159, loss-ulb:0.0045, weight:2.00, lr:0.0005
[01:01:42.253] iteration:8585  t-loss:0.0163, loss-lb:0.0118, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:01:42.626] iteration:8586  t-loss:0.0163, loss-lb:0.0130, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:01:43.000] iteration:8587  t-loss:0.0354, loss-lb:0.0110, loss-ulb:0.0122, weight:2.00, lr:0.0005
[01:01:43.375] iteration:8588  t-loss:0.0372, loss-lb:0.0249, loss-ulb:0.0061, weight:2.00, lr:0.0005
[01:01:44.548] iteration:8589  t-loss:0.0372, loss-lb:0.0286, loss-ulb:0.0043, weight:2.00, lr:0.0005
[01:01:44.987] iteration:8590  t-loss:0.0492, loss-lb:0.0316, loss-ulb:0.0088, weight:2.00, lr:0.0005
[01:01:45.414] iteration:8591  t-loss:0.0286, loss-lb:0.0168, loss-ulb:0.0059, weight:2.00, lr:0.0005
[01:01:45.812] iteration:8592  t-loss:0.0336, loss-lb:0.0281, loss-ulb:0.0028, weight:2.00, lr:0.0005
[01:01:46.204] iteration:8593  t-loss:0.0301, loss-lb:0.0215, loss-ulb:0.0043, weight:2.00, lr:0.0005
[01:01:46.588] iteration:8594  t-loss:0.0328, loss-lb:0.0195, loss-ulb:0.0066, weight:2.00, lr:0.0005
[01:01:46.979] iteration:8595  t-loss:0.0408, loss-lb:0.0263, loss-ulb:0.0073, weight:2.00, lr:0.0005
[01:01:47.363] iteration:8596  t-loss:0.0236, loss-lb:0.0135, loss-ulb:0.0051, weight:2.00, lr:0.0005
[01:01:47.744] iteration:8597  t-loss:0.0319, loss-lb:0.0140, loss-ulb:0.0090, weight:2.00, lr:0.0005
[01:01:48.127] iteration:8598  t-loss:0.0499, loss-lb:0.0280, loss-ulb:0.0110, weight:2.00, lr:0.0005
[01:01:48.510] iteration:8599  t-loss:0.0173, loss-lb:0.0155, loss-ulb:0.0009, weight:2.00, lr:0.0005
[01:01:48.890] iteration:8600  t-loss:0.0181, loss-lb:0.0143, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:01:49.283] iteration:8601  t-loss:0.0437, loss-lb:0.0318, loss-ulb:0.0059, weight:2.00, lr:0.0005
[01:01:49.672] iteration:8602  t-loss:0.0375, loss-lb:0.0244, loss-ulb:0.0065, weight:2.00, lr:0.0005
[01:01:50.056] iteration:8603  t-loss:0.0383, loss-lb:0.0169, loss-ulb:0.0107, weight:2.00, lr:0.0005
[01:01:50.437] iteration:8604  t-loss:0.0291, loss-lb:0.0136, loss-ulb:0.0078, weight:2.00, lr:0.0005
[01:01:50.819] iteration:8605  t-loss:0.0231, loss-lb:0.0156, loss-ulb:0.0038, weight:2.00, lr:0.0005
[01:01:51.207] iteration:8606  t-loss:0.0402, loss-lb:0.0302, loss-ulb:0.0050, weight:2.00, lr:0.0005
[01:01:51.588] iteration:8607  t-loss:0.0260, loss-lb:0.0165, loss-ulb:0.0048, weight:2.00, lr:0.0005
[01:01:51.976] iteration:8608  t-loss:0.0491, loss-lb:0.0268, loss-ulb:0.0111, weight:2.00, lr:0.0005
[01:01:52.354] iteration:8609  t-loss:0.0282, loss-lb:0.0263, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:01:52.741] iteration:8610  t-loss:0.0257, loss-lb:0.0115, loss-ulb:0.0071, weight:2.00, lr:0.0005
[01:01:53.128] iteration:8611  t-loss:0.0528, loss-lb:0.0316, loss-ulb:0.0106, weight:2.00, lr:0.0005
[01:01:53.510] iteration:8612  t-loss:0.0337, loss-lb:0.0305, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:01:53.891] iteration:8613  t-loss:0.0489, loss-lb:0.0451, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:01:54.281] iteration:8614  t-loss:0.0381, loss-lb:0.0243, loss-ulb:0.0069, weight:2.00, lr:0.0005
[01:01:54.664] iteration:8615  t-loss:0.0260, loss-lb:0.0133, loss-ulb:0.0063, weight:2.00, lr:0.0005
[01:01:55.046] iteration:8616  t-loss:0.0368, loss-lb:0.0353, loss-ulb:0.0007, weight:2.00, lr:0.0005
[01:01:55.432] iteration:8617  t-loss:0.0363, loss-lb:0.0331, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:01:55.818] iteration:8618  t-loss:0.0452, loss-lb:0.0120, loss-ulb:0.0166, weight:2.00, lr:0.0005
[01:01:56.195] iteration:8619  t-loss:0.0210, loss-lb:0.0170, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:01:56.576] iteration:8620  t-loss:0.0371, loss-lb:0.0275, loss-ulb:0.0048, weight:2.00, lr:0.0005
[01:01:56.953] iteration:8621  t-loss:0.0514, loss-lb:0.0169, loss-ulb:0.0172, weight:2.00, lr:0.0005
[01:01:57.327] iteration:8622  t-loss:0.0195, loss-lb:0.0145, loss-ulb:0.0025, weight:2.00, lr:0.0005
[01:01:57.702] iteration:8623  t-loss:0.0398, loss-lb:0.0319, loss-ulb:0.0040, weight:2.00, lr:0.0005
[01:01:58.076] iteration:8624  t-loss:0.0295, loss-lb:0.0142, loss-ulb:0.0076, weight:2.00, lr:0.0005
[01:01:58.446] iteration:8625  t-loss:0.0177, loss-lb:0.0144, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:01:58.820] iteration:8626  t-loss:0.0310, loss-lb:0.0206, loss-ulb:0.0052, weight:2.00, lr:0.0005
[01:01:59.964] iteration:8627  t-loss:0.0316, loss-lb:0.0270, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:02:00.370] iteration:8628  t-loss:0.0315, loss-lb:0.0284, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:02:00.780] iteration:8629  t-loss:0.0211, loss-lb:0.0133, loss-ulb:0.0039, weight:2.00, lr:0.0005
[01:02:01.177] iteration:8630  t-loss:0.0320, loss-lb:0.0303, loss-ulb:0.0009, weight:2.00, lr:0.0005
[01:02:01.568] iteration:8631  t-loss:0.0317, loss-lb:0.0250, loss-ulb:0.0034, weight:2.00, lr:0.0005
[01:02:01.950] iteration:8632  t-loss:0.0196, loss-lb:0.0146, loss-ulb:0.0025, weight:2.00, lr:0.0005
[01:02:02.342] iteration:8633  t-loss:0.0348, loss-lb:0.0296, loss-ulb:0.0026, weight:2.00, lr:0.0005
[01:02:02.728] iteration:8634  t-loss:0.0632, loss-lb:0.0351, loss-ulb:0.0141, weight:2.00, lr:0.0005
[01:02:03.113] iteration:8635  t-loss:0.0990, loss-lb:0.0394, loss-ulb:0.0298, weight:2.00, lr:0.0005
[01:02:03.501] iteration:8636  t-loss:0.0520, loss-lb:0.0502, loss-ulb:0.0009, weight:2.00, lr:0.0005
[01:02:03.883] iteration:8637  t-loss:0.0472, loss-lb:0.0226, loss-ulb:0.0123, weight:2.00, lr:0.0005
[01:02:04.262] iteration:8638  t-loss:0.0434, loss-lb:0.0304, loss-ulb:0.0065, weight:2.00, lr:0.0005
[01:02:04.649] iteration:8639  t-loss:0.0257, loss-lb:0.0227, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:02:05.032] iteration:8640  t-loss:0.0179, loss-lb:0.0139, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:02:05.408] iteration:8641  t-loss:0.0189, loss-lb:0.0148, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:02:05.798] iteration:8642  t-loss:0.0294, loss-lb:0.0266, loss-ulb:0.0014, weight:2.00, lr:0.0005
[01:02:06.187] iteration:8643  t-loss:0.0348, loss-lb:0.0240, loss-ulb:0.0054, weight:2.00, lr:0.0005
[01:02:06.580] iteration:8644  t-loss:0.0449, loss-lb:0.0270, loss-ulb:0.0089, weight:2.00, lr:0.0005
[01:02:06.962] iteration:8645  t-loss:0.0345, loss-lb:0.0301, loss-ulb:0.0022, weight:2.00, lr:0.0005
[01:02:07.347] iteration:8646  t-loss:0.0340, loss-lb:0.0293, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:02:07.728] iteration:8647  t-loss:0.0287, loss-lb:0.0173, loss-ulb:0.0057, weight:2.00, lr:0.0005
[01:02:08.115] iteration:8648  t-loss:0.0416, loss-lb:0.0145, loss-ulb:0.0136, weight:2.00, lr:0.0005
[01:02:08.493] iteration:8649  t-loss:0.0226, loss-lb:0.0137, loss-ulb:0.0044, weight:2.00, lr:0.0005
[01:02:08.884] iteration:8650  t-loss:0.0801, loss-lb:0.0598, loss-ulb:0.0102, weight:2.00, lr:0.0005
[01:02:09.264] iteration:8651  t-loss:0.0252, loss-lb:0.0225, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:02:09.654] iteration:8652  t-loss:0.0299, loss-lb:0.0241, loss-ulb:0.0029, weight:2.00, lr:0.0005
[01:02:10.031] iteration:8653  t-loss:0.0178, loss-lb:0.0148, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:02:10.416] iteration:8654  t-loss:0.0416, loss-lb:0.0115, loss-ulb:0.0151, weight:2.00, lr:0.0005
[01:02:10.795] iteration:8655  t-loss:0.0213, loss-lb:0.0170, loss-ulb:0.0022, weight:2.00, lr:0.0005
[01:02:11.180] iteration:8656  t-loss:0.0206, loss-lb:0.0154, loss-ulb:0.0026, weight:2.00, lr:0.0005
[01:02:11.558] iteration:8657  t-loss:0.0251, loss-lb:0.0128, loss-ulb:0.0061, weight:2.00, lr:0.0005
[01:02:11.939] iteration:8658  t-loss:0.0678, loss-lb:0.0510, loss-ulb:0.0084, weight:2.00, lr:0.0005
[01:02:12.318] iteration:8659  t-loss:0.0556, loss-lb:0.0351, loss-ulb:0.0102, weight:2.00, lr:0.0005
[01:02:12.692] iteration:8660  t-loss:0.0197, loss-lb:0.0155, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:02:13.065] iteration:8661  t-loss:0.0264, loss-lb:0.0169, loss-ulb:0.0047, weight:2.00, lr:0.0005
[01:02:13.443] iteration:8662  t-loss:0.0429, loss-lb:0.0318, loss-ulb:0.0056, weight:2.00, lr:0.0005
[01:02:13.821] iteration:8663  t-loss:0.0388, loss-lb:0.0162, loss-ulb:0.0113, weight:2.00, lr:0.0005
[01:02:14.201] iteration:8664  t-loss:0.0418, loss-lb:0.0314, loss-ulb:0.0052, weight:2.00, lr:0.0005
[01:02:15.298] iteration:8665  t-loss:0.0372, loss-lb:0.0221, loss-ulb:0.0075, weight:2.00, lr:0.0005
[01:02:15.702] iteration:8666  t-loss:0.0309, loss-lb:0.0225, loss-ulb:0.0042, weight:2.00, lr:0.0005
[01:02:16.089] iteration:8667  t-loss:0.0218, loss-lb:0.0119, loss-ulb:0.0049, weight:2.00, lr:0.0005
[01:02:16.474] iteration:8668  t-loss:0.0819, loss-lb:0.0281, loss-ulb:0.0269, weight:2.00, lr:0.0005
[01:02:16.858] iteration:8669  t-loss:0.0489, loss-lb:0.0314, loss-ulb:0.0087, weight:2.00, lr:0.0005
[01:02:17.243] iteration:8670  t-loss:0.0537, loss-lb:0.0299, loss-ulb:0.0119, weight:2.00, lr:0.0005
[01:02:17.628] iteration:8671  t-loss:0.0415, loss-lb:0.0229, loss-ulb:0.0093, weight:2.00, lr:0.0005
[01:02:18.016] iteration:8672  t-loss:0.0307, loss-lb:0.0155, loss-ulb:0.0076, weight:2.00, lr:0.0005
[01:02:18.397] iteration:8673  t-loss:0.0170, loss-lb:0.0139, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:02:18.785] iteration:8674  t-loss:0.0449, loss-lb:0.0296, loss-ulb:0.0076, weight:2.00, lr:0.0005
[01:02:19.164] iteration:8675  t-loss:0.0385, loss-lb:0.0364, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:02:19.554] iteration:8676  t-loss:0.0246, loss-lb:0.0199, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:02:19.938] iteration:8677  t-loss:0.0352, loss-lb:0.0109, loss-ulb:0.0121, weight:2.00, lr:0.0005
[01:02:20.318] iteration:8678  t-loss:0.0230, loss-lb:0.0186, loss-ulb:0.0022, weight:2.00, lr:0.0005
[01:02:20.701] iteration:8679  t-loss:0.0420, loss-lb:0.0331, loss-ulb:0.0044, weight:2.00, lr:0.0005
[01:02:21.091] iteration:8680  t-loss:0.0487, loss-lb:0.0287, loss-ulb:0.0100, weight:2.00, lr:0.0005
[01:02:21.482] iteration:8681  t-loss:0.0584, loss-lb:0.0245, loss-ulb:0.0170, weight:2.00, lr:0.0005
[01:02:21.859] iteration:8682  t-loss:0.0176, loss-lb:0.0125, loss-ulb:0.0025, weight:2.00, lr:0.0005
[01:02:22.236] iteration:8683  t-loss:0.0184, loss-lb:0.0142, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:02:22.624] iteration:8684  t-loss:0.0542, loss-lb:0.0342, loss-ulb:0.0100, weight:2.00, lr:0.0005
[01:02:23.008] iteration:8685  t-loss:0.0588, loss-lb:0.0426, loss-ulb:0.0081, weight:2.00, lr:0.0005
[01:02:23.386] iteration:8686  t-loss:0.0184, loss-lb:0.0130, loss-ulb:0.0027, weight:2.00, lr:0.0005
[01:02:23.770] iteration:8687  t-loss:0.0330, loss-lb:0.0268, loss-ulb:0.0031, weight:2.00, lr:0.0005
[01:02:24.156] iteration:8688  t-loss:0.0289, loss-lb:0.0124, loss-ulb:0.0083, weight:2.00, lr:0.0005
[01:02:24.535] iteration:8689  t-loss:0.0194, loss-lb:0.0177, loss-ulb:0.0008, weight:2.00, lr:0.0005
[01:02:24.916] iteration:8690  t-loss:0.0160, loss-lb:0.0134, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:02:25.300] iteration:8691  t-loss:0.0405, loss-lb:0.0216, loss-ulb:0.0095, weight:2.00, lr:0.0005
[01:02:25.691] iteration:8692  t-loss:0.0228, loss-lb:0.0195, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:02:26.101] iteration:8693  t-loss:0.0609, loss-lb:0.0158, loss-ulb:0.0226, weight:2.00, lr:0.0005
[01:02:26.493] iteration:8694  t-loss:0.0406, loss-lb:0.0387, loss-ulb:0.0009, weight:2.00, lr:0.0005
[01:02:26.876] iteration:8695  t-loss:0.0485, loss-lb:0.0349, loss-ulb:0.0068, weight:2.00, lr:0.0005
[01:02:27.252] iteration:8696  t-loss:0.0288, loss-lb:0.0257, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:02:27.627] iteration:8697  t-loss:0.0275, loss-lb:0.0154, loss-ulb:0.0061, weight:2.00, lr:0.0005
[01:02:28.010] iteration:8698  t-loss:0.0487, loss-lb:0.0256, loss-ulb:0.0115, weight:2.00, lr:0.0005
[01:02:28.390] iteration:8699  t-loss:0.0558, loss-lb:0.0269, loss-ulb:0.0144, weight:2.00, lr:0.0005
[01:02:28.770] iteration:8700  t-loss:0.0420, loss-lb:0.0253, loss-ulb:0.0083, weight:2.00, lr:0.0005
[01:02:29.147] iteration:8701  t-loss:0.0360, loss-lb:0.0160, loss-ulb:0.0100, weight:2.00, lr:0.0005
[01:02:29.524] iteration:8702  t-loss:0.0175, loss-lb:0.0149, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:03:34.145] iteration 8702 : dice_score: 0.898599 best_dice: 0.898600
[01:03:34.146]  <<Test>> - Ep:228  - Dice-S/T:89.44/89.86, Best-S:89.44, Best-T:89.86
[01:03:34.146]           - AvgLoss(lb/ulb/all):0.02/0.01/0.04
[01:03:35.202] iteration:8703  t-loss:0.0196, loss-lb:0.0167, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:03:35.605] iteration:8704  t-loss:0.0367, loss-lb:0.0154, loss-ulb:0.0106, weight:2.00, lr:0.0005
[01:03:35.988] iteration:8705  t-loss:0.0268, loss-lb:0.0253, loss-ulb:0.0008, weight:2.00, lr:0.0005
[01:03:36.364] iteration:8706  t-loss:0.0246, loss-lb:0.0201, loss-ulb:0.0023, weight:2.00, lr:0.0005
[01:03:36.746] iteration:8707  t-loss:0.0230, loss-lb:0.0210, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:03:37.148] iteration:8708  t-loss:0.0575, loss-lb:0.0350, loss-ulb:0.0113, weight:2.00, lr:0.0005
[01:03:37.553] iteration:8709  t-loss:0.0171, loss-lb:0.0128, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:03:37.958] iteration:8710  t-loss:0.0186, loss-lb:0.0148, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:03:38.346] iteration:8711  t-loss:0.0312, loss-lb:0.0283, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:03:38.730] iteration:8712  t-loss:0.0201, loss-lb:0.0158, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:03:39.114] iteration:8713  t-loss:0.0413, loss-lb:0.0138, loss-ulb:0.0137, weight:2.00, lr:0.0005
[01:03:39.497] iteration:8714  t-loss:0.0419, loss-lb:0.0263, loss-ulb:0.0078, weight:2.00, lr:0.0005
[01:03:39.874] iteration:8715  t-loss:0.0266, loss-lb:0.0241, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:03:40.252] iteration:8716  t-loss:0.0224, loss-lb:0.0156, loss-ulb:0.0034, weight:2.00, lr:0.0005
[01:03:40.634] iteration:8717  t-loss:0.0339, loss-lb:0.0239, loss-ulb:0.0050, weight:2.00, lr:0.0005
[01:03:41.018] iteration:8718  t-loss:0.0425, loss-lb:0.0286, loss-ulb:0.0070, weight:2.00, lr:0.0005
[01:03:41.393] iteration:8719  t-loss:0.0143, loss-lb:0.0117, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:03:41.777] iteration:8720  t-loss:0.0258, loss-lb:0.0234, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:03:42.161] iteration:8721  t-loss:0.0326, loss-lb:0.0144, loss-ulb:0.0091, weight:2.00, lr:0.0005
[01:03:42.542] iteration:8722  t-loss:0.0278, loss-lb:0.0249, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:03:42.927] iteration:8723  t-loss:0.0432, loss-lb:0.0358, loss-ulb:0.0037, weight:2.00, lr:0.0005
[01:03:43.309] iteration:8724  t-loss:0.0311, loss-lb:0.0218, loss-ulb:0.0047, weight:2.00, lr:0.0005
[01:03:43.689] iteration:8725  t-loss:0.0314, loss-lb:0.0280, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:03:44.073] iteration:8726  t-loss:0.0359, loss-lb:0.0141, loss-ulb:0.0109, weight:2.00, lr:0.0005
[01:03:44.458] iteration:8727  t-loss:0.0462, loss-lb:0.0265, loss-ulb:0.0098, weight:2.00, lr:0.0005
[01:03:44.842] iteration:8728  t-loss:0.0339, loss-lb:0.0125, loss-ulb:0.0107, weight:2.00, lr:0.0005
[01:03:45.226] iteration:8729  t-loss:0.0220, loss-lb:0.0127, loss-ulb:0.0047, weight:2.00, lr:0.0005
[01:03:45.609] iteration:8730  t-loss:0.0199, loss-lb:0.0175, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:03:45.990] iteration:8731  t-loss:0.0307, loss-lb:0.0268, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:03:46.375] iteration:8732  t-loss:0.0507, loss-lb:0.0311, loss-ulb:0.0098, weight:2.00, lr:0.0005
[01:03:46.756] iteration:8733  t-loss:0.0604, loss-lb:0.0317, loss-ulb:0.0143, weight:2.00, lr:0.0005
[01:03:47.138] iteration:8734  t-loss:0.0336, loss-lb:0.0308, loss-ulb:0.0014, weight:2.00, lr:0.0005
[01:03:47.515] iteration:8735  t-loss:0.0415, loss-lb:0.0262, loss-ulb:0.0076, weight:2.00, lr:0.0005
[01:03:47.888] iteration:8736  t-loss:0.0355, loss-lb:0.0162, loss-ulb:0.0097, weight:2.00, lr:0.0005
[01:03:48.262] iteration:8737  t-loss:0.0344, loss-lb:0.0128, loss-ulb:0.0108, weight:2.00, lr:0.0005
[01:03:48.641] iteration:8738  t-loss:0.0674, loss-lb:0.0419, loss-ulb:0.0128, weight:2.00, lr:0.0005
[01:03:49.015] iteration:8739  t-loss:0.0146, loss-lb:0.0127, loss-ulb:0.0009, weight:2.00, lr:0.0005
[01:03:49.385] iteration:8740  t-loss:0.0438, loss-lb:0.0413, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:03:50.598] iteration:8741  t-loss:0.0235, loss-lb:0.0197, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:03:50.981] iteration:8742  t-loss:0.0308, loss-lb:0.0153, loss-ulb:0.0078, weight:2.00, lr:0.0005
[01:03:51.368] iteration:8743  t-loss:0.0411, loss-lb:0.0255, loss-ulb:0.0078, weight:2.00, lr:0.0005
[01:03:51.752] iteration:8744  t-loss:0.0366, loss-lb:0.0343, loss-ulb:0.0011, weight:2.00, lr:0.0005
[01:03:52.131] iteration:8745  t-loss:0.0166, loss-lb:0.0112, loss-ulb:0.0027, weight:2.00, lr:0.0005
[01:03:52.531] iteration:8746  t-loss:0.0411, loss-lb:0.0275, loss-ulb:0.0068, weight:2.00, lr:0.0005
[01:03:52.952] iteration:8747  t-loss:0.0547, loss-lb:0.0236, loss-ulb:0.0155, weight:2.00, lr:0.0005
[01:03:53.358] iteration:8748  t-loss:0.0185, loss-lb:0.0150, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:03:53.747] iteration:8749  t-loss:0.0305, loss-lb:0.0275, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:03:54.129] iteration:8750  t-loss:0.0228, loss-lb:0.0175, loss-ulb:0.0027, weight:2.00, lr:0.0005
[01:03:54.521] iteration:8751  t-loss:0.0406, loss-lb:0.0268, loss-ulb:0.0069, weight:2.00, lr:0.0005
[01:03:54.905] iteration:8752  t-loss:0.0200, loss-lb:0.0166, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:03:55.292] iteration:8753  t-loss:0.0323, loss-lb:0.0139, loss-ulb:0.0092, weight:2.00, lr:0.0005
[01:03:55.680] iteration:8754  t-loss:0.0292, loss-lb:0.0115, loss-ulb:0.0088, weight:2.00, lr:0.0005
[01:03:56.062] iteration:8755  t-loss:0.0315, loss-lb:0.0132, loss-ulb:0.0091, weight:2.00, lr:0.0005
[01:03:56.455] iteration:8756  t-loss:0.0372, loss-lb:0.0259, loss-ulb:0.0056, weight:2.00, lr:0.0005
[01:03:56.840] iteration:8757  t-loss:0.0423, loss-lb:0.0299, loss-ulb:0.0062, weight:2.00, lr:0.0005
[01:03:57.227] iteration:8758  t-loss:0.0238, loss-lb:0.0171, loss-ulb:0.0034, weight:2.00, lr:0.0005
[01:03:57.611] iteration:8759  t-loss:0.0456, loss-lb:0.0330, loss-ulb:0.0063, weight:2.00, lr:0.0005
[01:03:57.990] iteration:8760  t-loss:0.0337, loss-lb:0.0239, loss-ulb:0.0049, weight:2.00, lr:0.0005
[01:03:58.376] iteration:8761  t-loss:0.0362, loss-lb:0.0152, loss-ulb:0.0105, weight:2.00, lr:0.0005
[01:03:58.758] iteration:8762  t-loss:0.0371, loss-lb:0.0222, loss-ulb:0.0075, weight:2.00, lr:0.0005
[01:03:59.147] iteration:8763  t-loss:0.0354, loss-lb:0.0331, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:03:59.531] iteration:8764  t-loss:0.0191, loss-lb:0.0151, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:03:59.907] iteration:8765  t-loss:0.0202, loss-lb:0.0164, loss-ulb:0.0019, weight:2.00, lr:0.0005
[01:04:00.290] iteration:8766  t-loss:0.0301, loss-lb:0.0125, loss-ulb:0.0088, weight:2.00, lr:0.0005
[01:04:00.672] iteration:8767  t-loss:0.0287, loss-lb:0.0256, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:04:01.057] iteration:8768  t-loss:0.0375, loss-lb:0.0254, loss-ulb:0.0060, weight:2.00, lr:0.0005
[01:04:01.448] iteration:8769  t-loss:0.0302, loss-lb:0.0207, loss-ulb:0.0048, weight:2.00, lr:0.0005
[01:04:01.833] iteration:8770  t-loss:0.0327, loss-lb:0.0175, loss-ulb:0.0076, weight:2.00, lr:0.0005
[01:04:02.210] iteration:8771  t-loss:0.0137, loss-lb:0.0103, loss-ulb:0.0017, weight:2.00, lr:0.0005
[01:04:02.590] iteration:8772  t-loss:0.0402, loss-lb:0.0285, loss-ulb:0.0059, weight:2.00, lr:0.0005
[01:04:02.967] iteration:8773  t-loss:0.0348, loss-lb:0.0315, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:04:03.350] iteration:8774  t-loss:0.0547, loss-lb:0.0226, loss-ulb:0.0160, weight:2.00, lr:0.0005
[01:04:03.727] iteration:8775  t-loss:0.0351, loss-lb:0.0192, loss-ulb:0.0079, weight:2.00, lr:0.0005
[01:04:04.108] iteration:8776  t-loss:0.0563, loss-lb:0.0217, loss-ulb:0.0173, weight:2.00, lr:0.0005
[01:04:04.487] iteration:8777  t-loss:0.0242, loss-lb:0.0124, loss-ulb:0.0059, weight:2.00, lr:0.0005
[01:04:04.866] iteration:8778  t-loss:0.0334, loss-lb:0.0187, loss-ulb:0.0074, weight:2.00, lr:0.0005
[01:04:05.962] iteration:8779  t-loss:0.0489, loss-lb:0.0348, loss-ulb:0.0071, weight:2.00, lr:0.0005
[01:04:06.367] iteration:8780  t-loss:0.0278, loss-lb:0.0236, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:04:06.751] iteration:8781  t-loss:0.0188, loss-lb:0.0141, loss-ulb:0.0024, weight:2.00, lr:0.0005
[01:04:07.131] iteration:8782  t-loss:0.0213, loss-lb:0.0173, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:04:07.521] iteration:8783  t-loss:0.0622, loss-lb:0.0395, loss-ulb:0.0114, weight:2.00, lr:0.0005
[01:04:07.905] iteration:8784  t-loss:0.0188, loss-lb:0.0146, loss-ulb:0.0021, weight:2.00, lr:0.0005
[01:04:08.312] iteration:8785  t-loss:0.0363, loss-lb:0.0239, loss-ulb:0.0062, weight:2.00, lr:0.0005
[01:04:08.709] iteration:8786  t-loss:0.0490, loss-lb:0.0383, loss-ulb:0.0053, weight:2.00, lr:0.0005
[01:04:09.103] iteration:8787  t-loss:0.0467, loss-lb:0.0252, loss-ulb:0.0108, weight:2.00, lr:0.0005
[01:04:09.484] iteration:8788  t-loss:0.0408, loss-lb:0.0159, loss-ulb:0.0124, weight:2.00, lr:0.0005
[01:04:09.862] iteration:8789  t-loss:0.0259, loss-lb:0.0130, loss-ulb:0.0065, weight:2.00, lr:0.0005
[01:04:10.248] iteration:8790  t-loss:0.0643, loss-lb:0.0243, loss-ulb:0.0200, weight:2.00, lr:0.0005
[01:04:10.614] iteration:8791  t-loss:0.0325, loss-lb:0.0261, loss-ulb:0.0032, weight:2.00, lr:0.0005
[01:04:10.992] iteration:8792  t-loss:0.0245, loss-lb:0.0220, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:04:11.375] iteration:8793  t-loss:0.0365, loss-lb:0.0215, loss-ulb:0.0075, weight:2.00, lr:0.0005
[01:04:11.760] iteration:8794  t-loss:0.0786, loss-lb:0.0341, loss-ulb:0.0222, weight:2.00, lr:0.0005
[01:04:12.150] iteration:8795  t-loss:0.0226, loss-lb:0.0134, loss-ulb:0.0046, weight:2.00, lr:0.0005
[01:04:12.541] iteration:8796  t-loss:0.0374, loss-lb:0.0281, loss-ulb:0.0047, weight:2.00, lr:0.0005
[01:04:12.924] iteration:8797  t-loss:0.0517, loss-lb:0.0292, loss-ulb:0.0112, weight:2.00, lr:0.0005
[01:04:13.307] iteration:8798  t-loss:0.0210, loss-lb:0.0170, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:04:13.687] iteration:8799  t-loss:0.0805, loss-lb:0.0328, loss-ulb:0.0238, weight:2.00, lr:0.0005
[01:04:14.078] iteration:8800  t-loss:0.0359, loss-lb:0.0246, loss-ulb:0.0056, weight:2.00, lr:0.0005
[01:04:14.464] iteration:8801  t-loss:0.0296, loss-lb:0.0143, loss-ulb:0.0076, weight:2.00, lr:0.0005
[01:04:14.846] iteration:8802  t-loss:0.0388, loss-lb:0.0358, loss-ulb:0.0015, weight:2.00, lr:0.0005
[01:04:15.234] iteration:8803  t-loss:0.0599, loss-lb:0.0470, loss-ulb:0.0064, weight:2.00, lr:0.0005
[01:04:15.627] iteration:8804  t-loss:0.0424, loss-lb:0.0267, loss-ulb:0.0079, weight:2.00, lr:0.0005
[01:04:16.004] iteration:8805  t-loss:0.0371, loss-lb:0.0236, loss-ulb:0.0068, weight:2.00, lr:0.0005
[01:04:16.387] iteration:8806  t-loss:0.0277, loss-lb:0.0246, loss-ulb:0.0016, weight:2.00, lr:0.0005
[01:04:16.768] iteration:8807  t-loss:0.0360, loss-lb:0.0174, loss-ulb:0.0093, weight:2.00, lr:0.0005
[01:04:17.152] iteration:8808  t-loss:0.0315, loss-lb:0.0142, loss-ulb:0.0087, weight:2.00, lr:0.0005
[01:04:17.536] iteration:8809  t-loss:0.0258, loss-lb:0.0145, loss-ulb:0.0057, weight:2.00, lr:0.0005
[01:04:17.921] iteration:8810  t-loss:0.0361, loss-lb:0.0259, loss-ulb:0.0051, weight:2.00, lr:0.0005
[01:04:18.298] iteration:8811  t-loss:0.0527, loss-lb:0.0355, loss-ulb:0.0086, weight:2.00, lr:0.0005
[01:04:18.675] iteration:8812  t-loss:0.0230, loss-lb:0.0146, loss-ulb:0.0042, weight:2.00, lr:0.0005
[01:04:19.049] iteration:8813  t-loss:0.0205, loss-lb:0.0185, loss-ulb:0.0010, weight:2.00, lr:0.0005
[01:04:19.430] iteration:8814  t-loss:0.0497, loss-lb:0.0232, loss-ulb:0.0133, weight:2.00, lr:0.0005
[01:04:19.807] iteration:8815  t-loss:0.0238, loss-lb:0.0221, loss-ulb:0.0009, weight:2.00, lr:0.0005
[01:04:20.185] iteration:8816  t-loss:0.0423, loss-lb:0.0399, loss-ulb:0.0012, weight:2.00, lr:0.0005
[01:04:21.284] iteration:8817  t-loss:0.0162, loss-lb:0.0121, loss-ulb:0.0020, weight:2.00, lr:0.0005
[01:04:21.686] iteration:8818  t-loss:0.0361, loss-lb:0.0274, loss-ulb:0.0043, weight:2.00, lr:0.0005
[01:04:22.065] iteration:8819  t-loss:0.0429, loss-lb:0.0287, loss-ulb:0.0071, weight:2.00, lr:0.0005
[01:04:22.440] iteration:8820  t-loss:0.0327, loss-lb:0.0263, loss-ulb:0.0032, weight:2.00, lr:0.0005
[01:04:22.824] iteration:8821  t-loss:0.0576, loss-lb:0.0405, loss-ulb:0.0085, weight:2.00, lr:0.0005
[01:04:23.204] iteration:8822  t-loss:0.0325, loss-lb:0.0299, loss-ulb:0.0013, weight:2.00, lr:0.0005
[01:04:23.585] iteration:8823  t-loss:0.0287, loss-lb:0.0105, loss-ulb:0.0091, weight:2.00, lr:0.0005
[01:04:23.969] iteration:8824  t-loss:0.0414, loss-lb:0.0273, loss-ulb:0.0071, weight:2.00, lr:0.0005
[01:04:24.351] iteration:8825  t-loss:0.0301, loss-lb:0.0279, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:04:24.740] iteration:8826  t-loss:0.0339, loss-lb:0.0268, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:04:25.119] iteration:8827  t-loss:0.0253, loss-lb:0.0139, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:04:25.503] iteration:8828  t-loss:0.0462, loss-lb:0.0287, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:04:25.886] iteration:8829  t-loss:0.0591, loss-lb:0.0369, loss-ulb:0.0111, weight:2.00, lr:0.0004
[01:04:26.263] iteration:8830  t-loss:0.0288, loss-lb:0.0149, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:04:26.646] iteration:8831  t-loss:0.0380, loss-lb:0.0110, loss-ulb:0.0135, weight:2.00, lr:0.0004
[01:04:27.028] iteration:8832  t-loss:0.0357, loss-lb:0.0331, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:04:27.418] iteration:8833  t-loss:0.0585, loss-lb:0.0258, loss-ulb:0.0164, weight:2.00, lr:0.0004
[01:04:27.804] iteration:8834  t-loss:0.0565, loss-lb:0.0134, loss-ulb:0.0215, weight:2.00, lr:0.0004
[01:04:28.186] iteration:8835  t-loss:0.0339, loss-lb:0.0174, loss-ulb:0.0082, weight:2.00, lr:0.0004
[01:04:28.566] iteration:8836  t-loss:0.0334, loss-lb:0.0146, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:04:28.946] iteration:8837  t-loss:0.0385, loss-lb:0.0362, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:04:29.336] iteration:8838  t-loss:0.0479, loss-lb:0.0399, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:04:29.732] iteration:8839  t-loss:0.0187, loss-lb:0.0136, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:04:30.124] iteration:8840  t-loss:0.0272, loss-lb:0.0192, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:04:30.515] iteration:8841  t-loss:0.0246, loss-lb:0.0129, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:04:30.894] iteration:8842  t-loss:0.0285, loss-lb:0.0175, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:04:31.278] iteration:8843  t-loss:0.0338, loss-lb:0.0223, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:04:31.663] iteration:8844  t-loss:0.0395, loss-lb:0.0236, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:04:32.037] iteration:8845  t-loss:0.0380, loss-lb:0.0298, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:04:32.422] iteration:8846  t-loss:0.0249, loss-lb:0.0214, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:04:32.804] iteration:8847  t-loss:0.0315, loss-lb:0.0288, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:04:33.183] iteration:8848  t-loss:0.0534, loss-lb:0.0419, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:04:33.564] iteration:8849  t-loss:0.0365, loss-lb:0.0273, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:04:33.939] iteration:8850  t-loss:0.0176, loss-lb:0.0139, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:04:34.313] iteration:8851  t-loss:0.0210, loss-lb:0.0180, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:04:34.683] iteration:8852  t-loss:0.0167, loss-lb:0.0134, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:04:35.059] iteration:8853  t-loss:0.0422, loss-lb:0.0394, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:04:35.437] iteration:8854  t-loss:0.0431, loss-lb:0.0367, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:05:44.026] iteration 8854 : dice_score: 0.896078 best_dice: 0.898600
[01:05:44.027]  <<Test>> - Ep:232  - Dice-S/T:89.63/89.61, Best-S:89.63, Best-T:89.86
[01:05:44.027]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[01:05:45.288] iteration:8855  t-loss:0.0198, loss-lb:0.0179, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:05:45.682] iteration:8856  t-loss:0.0308, loss-lb:0.0229, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:05:46.072] iteration:8857  t-loss:0.0255, loss-lb:0.0211, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:05:46.463] iteration:8858  t-loss:0.0390, loss-lb:0.0276, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:05:46.855] iteration:8859  t-loss:0.0323, loss-lb:0.0256, loss-ulb:0.0033, weight:2.00, lr:0.0004
[01:05:47.234] iteration:8860  t-loss:0.0129, loss-lb:0.0108, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:05:47.621] iteration:8861  t-loss:0.0173, loss-lb:0.0131, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:05:48.006] iteration:8862  t-loss:0.0241, loss-lb:0.0220, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:05:48.393] iteration:8863  t-loss:0.0228, loss-lb:0.0214, loss-ulb:0.0007, weight:2.00, lr:0.0004
[01:05:48.781] iteration:8864  t-loss:0.0169, loss-lb:0.0146, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:05:49.166] iteration:8865  t-loss:0.0323, loss-lb:0.0143, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:05:49.552] iteration:8866  t-loss:0.0350, loss-lb:0.0305, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:05:49.939] iteration:8867  t-loss:0.0277, loss-lb:0.0248, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:05:50.321] iteration:8868  t-loss:0.0437, loss-lb:0.0157, loss-ulb:0.0140, weight:2.00, lr:0.0004
[01:05:50.705] iteration:8869  t-loss:0.0170, loss-lb:0.0145, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:05:51.091] iteration:8870  t-loss:0.0319, loss-lb:0.0117, loss-ulb:0.0101, weight:2.00, lr:0.0004
[01:05:51.475] iteration:8871  t-loss:0.0201, loss-lb:0.0139, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:05:51.864] iteration:8872  t-loss:0.0434, loss-lb:0.0389, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:05:52.251] iteration:8873  t-loss:0.0370, loss-lb:0.0252, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:05:52.642] iteration:8874  t-loss:0.0340, loss-lb:0.0247, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:05:53.028] iteration:8875  t-loss:0.0523, loss-lb:0.0228, loss-ulb:0.0148, weight:2.00, lr:0.0004
[01:05:53.411] iteration:8876  t-loss:0.0167, loss-lb:0.0127, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:05:53.798] iteration:8877  t-loss:0.0480, loss-lb:0.0278, loss-ulb:0.0101, weight:2.00, lr:0.0004
[01:05:54.181] iteration:8878  t-loss:0.0153, loss-lb:0.0115, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:05:54.557] iteration:8879  t-loss:0.0170, loss-lb:0.0132, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:05:54.936] iteration:8880  t-loss:0.0910, loss-lb:0.0225, loss-ulb:0.0342, weight:2.00, lr:0.0004
[01:05:55.314] iteration:8881  t-loss:0.0415, loss-lb:0.0164, loss-ulb:0.0125, weight:2.00, lr:0.0004
[01:05:55.691] iteration:8882  t-loss:0.0153, loss-lb:0.0118, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:05:56.074] iteration:8883  t-loss:0.0428, loss-lb:0.0348, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:05:56.453] iteration:8884  t-loss:0.0186, loss-lb:0.0161, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:05:56.835] iteration:8885  t-loss:0.0660, loss-lb:0.0158, loss-ulb:0.0251, weight:2.00, lr:0.0004
[01:05:57.218] iteration:8886  t-loss:0.0142, loss-lb:0.0113, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:05:57.611] iteration:8887  t-loss:0.0338, loss-lb:0.0154, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:05:58.015] iteration:8888  t-loss:0.0144, loss-lb:0.0116, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:05:58.408] iteration:8889  t-loss:0.0222, loss-lb:0.0198, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:05:58.793] iteration:8890  t-loss:0.0409, loss-lb:0.0284, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:05:59.181] iteration:8891  t-loss:0.0282, loss-lb:0.0222, loss-ulb:0.0030, weight:2.00, lr:0.0004
[01:05:59.564] iteration:8892  t-loss:0.0321, loss-lb:0.0280, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:06:00.804] iteration:8893  t-loss:0.0407, loss-lb:0.0269, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:06:01.209] iteration:8894  t-loss:0.0435, loss-lb:0.0297, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:06:01.598] iteration:8895  t-loss:0.0382, loss-lb:0.0237, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:06:01.973] iteration:8896  t-loss:0.0219, loss-lb:0.0151, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:06:02.355] iteration:8897  t-loss:0.0177, loss-lb:0.0164, loss-ulb:0.0006, weight:2.00, lr:0.0004
[01:06:02.738] iteration:8898  t-loss:0.0393, loss-lb:0.0122, loss-ulb:0.0136, weight:2.00, lr:0.0004
[01:06:03.127] iteration:8899  t-loss:0.0386, loss-lb:0.0316, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:06:03.513] iteration:8900  t-loss:0.0389, loss-lb:0.0368, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:06:03.897] iteration:8901  t-loss:0.0441, loss-lb:0.0425, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:06:04.280] iteration:8902  t-loss:0.0190, loss-lb:0.0138, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:06:04.665] iteration:8903  t-loss:0.0134, loss-lb:0.0110, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:06:05.052] iteration:8904  t-loss:0.0476, loss-lb:0.0276, loss-ulb:0.0100, weight:2.00, lr:0.0004
[01:06:05.442] iteration:8905  t-loss:0.0431, loss-lb:0.0306, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:06:05.828] iteration:8906  t-loss:0.0194, loss-lb:0.0156, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:06:06.212] iteration:8907  t-loss:0.0241, loss-lb:0.0168, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:06:06.597] iteration:8908  t-loss:0.0510, loss-lb:0.0393, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:06:06.984] iteration:8909  t-loss:0.0369, loss-lb:0.0337, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:06:07.370] iteration:8910  t-loss:0.0264, loss-lb:0.0142, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:06:07.762] iteration:8911  t-loss:0.0287, loss-lb:0.0266, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:06:08.149] iteration:8912  t-loss:0.0247, loss-lb:0.0145, loss-ulb:0.0051, weight:2.00, lr:0.0004
[01:06:08.536] iteration:8913  t-loss:0.0350, loss-lb:0.0195, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:06:08.920] iteration:8914  t-loss:0.0322, loss-lb:0.0124, loss-ulb:0.0099, weight:2.00, lr:0.0004
[01:06:09.301] iteration:8915  t-loss:0.0237, loss-lb:0.0151, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:06:09.683] iteration:8916  t-loss:0.0584, loss-lb:0.0472, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:06:10.047] iteration:8917  t-loss:0.0255, loss-lb:0.0236, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:06:10.421] iteration:8918  t-loss:0.0266, loss-lb:0.0188, loss-ulb:0.0039, weight:2.00, lr:0.0004
[01:06:10.802] iteration:8919  t-loss:0.0154, loss-lb:0.0124, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:06:11.183] iteration:8920  t-loss:0.0376, loss-lb:0.0180, loss-ulb:0.0098, weight:2.00, lr:0.0004
[01:06:11.561] iteration:8921  t-loss:0.0219, loss-lb:0.0158, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:06:11.944] iteration:8922  t-loss:0.0295, loss-lb:0.0228, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:06:12.330] iteration:8923  t-loss:0.0258, loss-lb:0.0122, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:06:12.714] iteration:8924  t-loss:0.0267, loss-lb:0.0133, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:06:13.101] iteration:8925  t-loss:0.0160, loss-lb:0.0139, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:06:13.499] iteration:8926  t-loss:0.0606, loss-lb:0.0387, loss-ulb:0.0109, weight:2.00, lr:0.0004
[01:06:13.884] iteration:8927  t-loss:0.0263, loss-lb:0.0218, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:06:14.268] iteration:8928  t-loss:0.0206, loss-lb:0.0183, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:06:14.647] iteration:8929  t-loss:0.0227, loss-lb:0.0117, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:06:15.027] iteration:8930  t-loss:0.0169, loss-lb:0.0125, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:06:16.278] iteration:8931  t-loss:0.0243, loss-lb:0.0107, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:06:16.675] iteration:8932  t-loss:0.0300, loss-lb:0.0161, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:06:17.060] iteration:8933  t-loss:0.0327, loss-lb:0.0283, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:06:17.445] iteration:8934  t-loss:0.0319, loss-lb:0.0146, loss-ulb:0.0086, weight:2.00, lr:0.0004
[01:06:17.827] iteration:8935  t-loss:0.0169, loss-lb:0.0148, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:06:18.214] iteration:8936  t-loss:0.0280, loss-lb:0.0219, loss-ulb:0.0030, weight:2.00, lr:0.0004
[01:06:18.601] iteration:8937  t-loss:0.0261, loss-lb:0.0173, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:06:18.990] iteration:8938  t-loss:0.0321, loss-lb:0.0148, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:06:19.373] iteration:8939  t-loss:0.0285, loss-lb:0.0254, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:06:19.765] iteration:8940  t-loss:0.0604, loss-lb:0.0353, loss-ulb:0.0126, weight:2.00, lr:0.0004
[01:06:20.157] iteration:8941  t-loss:0.0980, loss-lb:0.0576, loss-ulb:0.0202, weight:2.00, lr:0.0004
[01:06:20.541] iteration:8942  t-loss:0.0200, loss-lb:0.0156, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:06:20.929] iteration:8943  t-loss:0.0440, loss-lb:0.0148, loss-ulb:0.0146, weight:2.00, lr:0.0004
[01:06:21.314] iteration:8944  t-loss:0.0308, loss-lb:0.0233, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:06:21.712] iteration:8945  t-loss:0.0238, loss-lb:0.0223, loss-ulb:0.0007, weight:2.00, lr:0.0004
[01:06:22.106] iteration:8946  t-loss:0.0248, loss-lb:0.0209, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:06:22.488] iteration:8947  t-loss:0.0196, loss-lb:0.0140, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:06:22.873] iteration:8948  t-loss:0.0237, loss-lb:0.0115, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:06:23.260] iteration:8949  t-loss:0.0305, loss-lb:0.0263, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:06:23.637] iteration:8950  t-loss:0.0200, loss-lb:0.0137, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:06:24.017] iteration:8951  t-loss:0.0178, loss-lb:0.0108, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:06:24.401] iteration:8952  t-loss:0.0339, loss-lb:0.0319, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:06:24.784] iteration:8953  t-loss:0.0752, loss-lb:0.0138, loss-ulb:0.0307, weight:2.00, lr:0.0004
[01:06:25.164] iteration:8954  t-loss:0.0291, loss-lb:0.0202, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:06:25.542] iteration:8955  t-loss:0.0155, loss-lb:0.0112, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:06:25.922] iteration:8956  t-loss:0.0280, loss-lb:0.0244, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:06:26.307] iteration:8957  t-loss:0.0253, loss-lb:0.0153, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:06:26.691] iteration:8958  t-loss:0.0455, loss-lb:0.0343, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:06:27.068] iteration:8959  t-loss:0.0310, loss-lb:0.0278, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:06:27.447] iteration:8960  t-loss:0.0228, loss-lb:0.0200, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:06:27.829] iteration:8961  t-loss:0.0221, loss-lb:0.0195, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:06:28.210] iteration:8962  t-loss:0.0255, loss-lb:0.0177, loss-ulb:0.0039, weight:2.00, lr:0.0004
[01:06:28.592] iteration:8963  t-loss:0.0225, loss-lb:0.0200, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:06:28.971] iteration:8964  t-loss:0.0338, loss-lb:0.0155, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:06:29.348] iteration:8965  t-loss:0.0153, loss-lb:0.0118, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:06:29.728] iteration:8966  t-loss:0.0315, loss-lb:0.0272, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:06:30.105] iteration:8967  t-loss:0.0182, loss-lb:0.0165, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:06:30.490] iteration:8968  t-loss:0.0269, loss-lb:0.0156, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:06:31.941] iteration:8969  t-loss:0.0302, loss-lb:0.0212, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:06:32.345] iteration:8970  t-loss:0.0217, loss-lb:0.0174, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:06:32.734] iteration:8971  t-loss:0.0324, loss-lb:0.0188, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:06:33.118] iteration:8972  t-loss:0.0149, loss-lb:0.0121, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:06:33.499] iteration:8973  t-loss:0.0276, loss-lb:0.0156, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:06:33.881] iteration:8974  t-loss:0.0417, loss-lb:0.0225, loss-ulb:0.0096, weight:2.00, lr:0.0004
[01:06:34.259] iteration:8975  t-loss:0.0208, loss-lb:0.0143, loss-ulb:0.0033, weight:2.00, lr:0.0004
[01:06:34.643] iteration:8976  t-loss:0.0197, loss-lb:0.0117, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:06:35.022] iteration:8977  t-loss:0.0280, loss-lb:0.0173, loss-ulb:0.0053, weight:2.00, lr:0.0004
[01:06:35.402] iteration:8978  t-loss:0.0376, loss-lb:0.0321, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:06:35.787] iteration:8979  t-loss:0.0403, loss-lb:0.0374, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:06:36.167] iteration:8980  t-loss:0.0443, loss-lb:0.0138, loss-ulb:0.0153, weight:2.00, lr:0.0004
[01:06:36.548] iteration:8981  t-loss:0.0148, loss-lb:0.0123, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:06:36.942] iteration:8982  t-loss:0.0199, loss-lb:0.0097, loss-ulb:0.0051, weight:2.00, lr:0.0004
[01:06:37.341] iteration:8983  t-loss:0.0380, loss-lb:0.0145, loss-ulb:0.0117, weight:2.00, lr:0.0004
[01:06:37.728] iteration:8984  t-loss:0.0296, loss-lb:0.0157, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:06:38.113] iteration:8985  t-loss:0.0429, loss-lb:0.0240, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:06:38.499] iteration:8986  t-loss:0.0334, loss-lb:0.0281, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:06:38.882] iteration:8987  t-loss:0.0210, loss-lb:0.0125, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:06:39.267] iteration:8988  t-loss:0.0244, loss-lb:0.0164, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:06:39.649] iteration:8989  t-loss:0.0162, loss-lb:0.0120, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:06:40.036] iteration:8990  t-loss:0.0420, loss-lb:0.0179, loss-ulb:0.0121, weight:2.00, lr:0.0004
[01:06:40.426] iteration:8991  t-loss:0.0611, loss-lb:0.0306, loss-ulb:0.0153, weight:2.00, lr:0.0004
[01:06:40.807] iteration:8992  t-loss:0.0237, loss-lb:0.0205, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:06:41.190] iteration:8993  t-loss:0.0268, loss-lb:0.0241, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:06:41.571] iteration:8994  t-loss:0.0251, loss-lb:0.0224, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:06:41.956] iteration:8995  t-loss:0.0161, loss-lb:0.0116, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:06:42.338] iteration:8996  t-loss:0.0186, loss-lb:0.0155, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:06:42.720] iteration:8997  t-loss:0.0320, loss-lb:0.0130, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:06:43.100] iteration:8998  t-loss:0.0309, loss-lb:0.0141, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:06:43.482] iteration:8999  t-loss:0.0394, loss-lb:0.0238, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:06:43.863] iteration:9000  t-loss:0.0459, loss-lb:0.0324, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:06:44.242] iteration:9001  t-loss:0.0194, loss-lb:0.0152, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:06:44.620] iteration:9002  t-loss:0.0479, loss-lb:0.0264, loss-ulb:0.0107, weight:2.00, lr:0.0004
[01:06:45.001] iteration:9003  t-loss:0.0299, loss-lb:0.0241, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:06:45.381] iteration:9004  t-loss:0.0259, loss-lb:0.0159, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:06:45.775] iteration:9005  t-loss:0.0259, loss-lb:0.0125, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:06:46.174] iteration:9006  t-loss:0.0454, loss-lb:0.0313, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:07:56.171] iteration 9006 : dice_score: 0.898336 best_dice: 0.898600
[01:07:56.171]  <<Test>> - Ep:236  - Dice-S/T:89.65/89.83, Best-S:89.65, Best-T:89.86
[01:07:56.172]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:07:57.341] iteration:9007  t-loss:0.0399, loss-lb:0.0208, loss-ulb:0.0096, weight:2.00, lr:0.0004
[01:07:57.741] iteration:9008  t-loss:0.0374, loss-lb:0.0116, loss-ulb:0.0129, weight:2.00, lr:0.0004
[01:07:58.125] iteration:9009  t-loss:0.0402, loss-lb:0.0201, loss-ulb:0.0100, weight:2.00, lr:0.0004
[01:07:58.518] iteration:9010  t-loss:0.1109, loss-lb:0.0569, loss-ulb:0.0270, weight:2.00, lr:0.0004
[01:07:58.902] iteration:9011  t-loss:0.0299, loss-lb:0.0147, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:07:59.286] iteration:9012  t-loss:0.0302, loss-lb:0.0171, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:07:59.678] iteration:9013  t-loss:0.0493, loss-lb:0.0370, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:08:00.080] iteration:9014  t-loss:0.0358, loss-lb:0.0258, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:08:00.484] iteration:9015  t-loss:0.0228, loss-lb:0.0126, loss-ulb:0.0051, weight:2.00, lr:0.0004
[01:08:00.896] iteration:9016  t-loss:0.0621, loss-lb:0.0309, loss-ulb:0.0156, weight:2.00, lr:0.0004
[01:08:01.291] iteration:9017  t-loss:0.0421, loss-lb:0.0152, loss-ulb:0.0134, weight:2.00, lr:0.0004
[01:08:01.690] iteration:9018  t-loss:0.0660, loss-lb:0.0222, loss-ulb:0.0219, weight:2.00, lr:0.0004
[01:08:02.078] iteration:9019  t-loss:0.0702, loss-lb:0.0209, loss-ulb:0.0247, weight:2.00, lr:0.0004
[01:08:02.462] iteration:9020  t-loss:0.0305, loss-lb:0.0144, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:08:02.855] iteration:9021  t-loss:0.0590, loss-lb:0.0321, loss-ulb:0.0134, weight:2.00, lr:0.0004
[01:08:03.249] iteration:9022  t-loss:0.0469, loss-lb:0.0237, loss-ulb:0.0116, weight:2.00, lr:0.0004
[01:08:03.641] iteration:9023  t-loss:0.0637, loss-lb:0.0334, loss-ulb:0.0152, weight:2.00, lr:0.0004
[01:08:04.022] iteration:9024  t-loss:0.0287, loss-lb:0.0262, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:08:04.403] iteration:9025  t-loss:0.0189, loss-lb:0.0161, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:08:04.789] iteration:9026  t-loss:0.0237, loss-lb:0.0163, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:08:05.176] iteration:9027  t-loss:0.0356, loss-lb:0.0295, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:08:05.560] iteration:9028  t-loss:0.0332, loss-lb:0.0271, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:08:05.947] iteration:9029  t-loss:0.0384, loss-lb:0.0241, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:08:06.330] iteration:9030  t-loss:0.0180, loss-lb:0.0152, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:08:06.713] iteration:9031  t-loss:0.0226, loss-lb:0.0183, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:08:07.098] iteration:9032  t-loss:0.0352, loss-lb:0.0273, loss-ulb:0.0039, weight:2.00, lr:0.0004
[01:08:07.493] iteration:9033  t-loss:0.0295, loss-lb:0.0260, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:08:07.889] iteration:9034  t-loss:0.0340, loss-lb:0.0295, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:08:08.294] iteration:9035  t-loss:0.0428, loss-lb:0.0409, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:08:08.686] iteration:9036  t-loss:0.0389, loss-lb:0.0218, loss-ulb:0.0085, weight:2.00, lr:0.0004
[01:08:09.068] iteration:9037  t-loss:0.0250, loss-lb:0.0226, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:08:09.450] iteration:9038  t-loss:0.0251, loss-lb:0.0199, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:08:09.837] iteration:9039  t-loss:0.0471, loss-lb:0.0378, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:08:10.218] iteration:9040  t-loss:0.0268, loss-lb:0.0121, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:08:10.599] iteration:9041  t-loss:0.0672, loss-lb:0.0274, loss-ulb:0.0199, weight:2.00, lr:0.0004
[01:08:10.982] iteration:9042  t-loss:0.0418, loss-lb:0.0267, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:08:11.353] iteration:9043  t-loss:0.0267, loss-lb:0.0195, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:08:11.733] iteration:9044  t-loss:0.0401, loss-lb:0.0246, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:08:13.008] iteration:9045  t-loss:0.0582, loss-lb:0.0150, loss-ulb:0.0216, weight:2.00, lr:0.0004
[01:08:13.398] iteration:9046  t-loss:0.0266, loss-lb:0.0230, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:08:13.782] iteration:9047  t-loss:0.0253, loss-lb:0.0213, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:08:14.166] iteration:9048  t-loss:0.0334, loss-lb:0.0261, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:08:14.544] iteration:9049  t-loss:0.0325, loss-lb:0.0165, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:08:14.920] iteration:9050  t-loss:0.0235, loss-lb:0.0147, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:08:15.305] iteration:9051  t-loss:0.0465, loss-lb:0.0368, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:08:15.694] iteration:9052  t-loss:0.0196, loss-lb:0.0129, loss-ulb:0.0033, weight:2.00, lr:0.0004
[01:08:16.108] iteration:9053  t-loss:0.0386, loss-lb:0.0218, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:08:16.505] iteration:9054  t-loss:0.0152, loss-lb:0.0112, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:08:16.897] iteration:9055  t-loss:0.0259, loss-lb:0.0234, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:08:17.284] iteration:9056  t-loss:0.0253, loss-lb:0.0117, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:08:17.670] iteration:9057  t-loss:0.0359, loss-lb:0.0319, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:08:18.054] iteration:9058  t-loss:0.0498, loss-lb:0.0328, loss-ulb:0.0085, weight:2.00, lr:0.0004
[01:08:18.441] iteration:9059  t-loss:0.0443, loss-lb:0.0265, loss-ulb:0.0089, weight:2.00, lr:0.0004
[01:08:18.826] iteration:9060  t-loss:0.0394, loss-lb:0.0338, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:08:19.206] iteration:9061  t-loss:0.0284, loss-lb:0.0249, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:08:19.596] iteration:9062  t-loss:0.0476, loss-lb:0.0271, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:08:19.978] iteration:9063  t-loss:0.0253, loss-lb:0.0224, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:08:20.360] iteration:9064  t-loss:0.0153, loss-lb:0.0127, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:08:20.745] iteration:9065  t-loss:0.0489, loss-lb:0.0226, loss-ulb:0.0131, weight:2.00, lr:0.0004
[01:08:21.124] iteration:9066  t-loss:0.0473, loss-lb:0.0234, loss-ulb:0.0120, weight:2.00, lr:0.0004
[01:08:21.506] iteration:9067  t-loss:0.0316, loss-lb:0.0172, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:08:21.888] iteration:9068  t-loss:0.0363, loss-lb:0.0319, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:08:22.268] iteration:9069  t-loss:0.0331, loss-lb:0.0262, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:08:22.650] iteration:9070  t-loss:0.0244, loss-lb:0.0143, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:08:23.035] iteration:9071  t-loss:0.0166, loss-lb:0.0146, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:08:23.422] iteration:9072  t-loss:0.0281, loss-lb:0.0244, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:08:23.807] iteration:9073  t-loss:0.0550, loss-lb:0.0403, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:08:24.189] iteration:9074  t-loss:0.0355, loss-lb:0.0334, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:08:24.570] iteration:9075  t-loss:0.0353, loss-lb:0.0150, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:08:24.951] iteration:9076  t-loss:0.0250, loss-lb:0.0110, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:08:25.333] iteration:9077  t-loss:0.0364, loss-lb:0.0349, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:08:25.712] iteration:9078  t-loss:0.0170, loss-lb:0.0115, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:08:26.093] iteration:9079  t-loss:0.0325, loss-lb:0.0293, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:08:26.471] iteration:9080  t-loss:0.0279, loss-lb:0.0234, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:08:26.857] iteration:9081  t-loss:0.0228, loss-lb:0.0132, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:08:27.236] iteration:9082  t-loss:0.0253, loss-lb:0.0116, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:08:28.477] iteration:9083  t-loss:0.0281, loss-lb:0.0234, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:08:28.869] iteration:9084  t-loss:0.0603, loss-lb:0.0207, loss-ulb:0.0198, weight:2.00, lr:0.0004
[01:08:29.260] iteration:9085  t-loss:0.0309, loss-lb:0.0228, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:08:29.648] iteration:9086  t-loss:0.0334, loss-lb:0.0229, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:08:30.030] iteration:9087  t-loss:0.0168, loss-lb:0.0123, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:08:30.417] iteration:9088  t-loss:0.0631, loss-lb:0.0597, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:08:30.807] iteration:9089  t-loss:0.0217, loss-lb:0.0129, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:08:31.212] iteration:9090  t-loss:0.0295, loss-lb:0.0121, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:08:31.624] iteration:9091  t-loss:0.0338, loss-lb:0.0162, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:08:32.020] iteration:9092  t-loss:0.0528, loss-lb:0.0368, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:08:32.409] iteration:9093  t-loss:0.0163, loss-lb:0.0131, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:08:32.798] iteration:9094  t-loss:0.0405, loss-lb:0.0382, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:08:33.184] iteration:9095  t-loss:0.0556, loss-lb:0.0270, loss-ulb:0.0143, weight:2.00, lr:0.0004
[01:08:33.568] iteration:9096  t-loss:0.0190, loss-lb:0.0162, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:08:33.958] iteration:9097  t-loss:0.0425, loss-lb:0.0196, loss-ulb:0.0115, weight:2.00, lr:0.0004
[01:08:34.342] iteration:9098  t-loss:0.0210, loss-lb:0.0147, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:08:34.728] iteration:9099  t-loss:0.0318, loss-lb:0.0302, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:08:35.112] iteration:9100  t-loss:0.0247, loss-lb:0.0127, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:08:35.496] iteration:9101  t-loss:0.0403, loss-lb:0.0372, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:08:35.882] iteration:9102  t-loss:0.0209, loss-lb:0.0151, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:08:36.270] iteration:9103  t-loss:0.0260, loss-lb:0.0160, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:08:36.656] iteration:9104  t-loss:0.0318, loss-lb:0.0294, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:08:37.050] iteration:9105  t-loss:0.0441, loss-lb:0.0170, loss-ulb:0.0135, weight:2.00, lr:0.0004
[01:08:37.436] iteration:9106  t-loss:0.0291, loss-lb:0.0160, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:08:37.831] iteration:9107  t-loss:0.0619, loss-lb:0.0590, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:08:38.228] iteration:9108  t-loss:0.0384, loss-lb:0.0189, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:08:38.627] iteration:9109  t-loss:0.0318, loss-lb:0.0234, loss-ulb:0.0042, weight:2.00, lr:0.0004
[01:08:39.023] iteration:9110  t-loss:0.0336, loss-lb:0.0194, loss-ulb:0.0071, weight:2.00, lr:0.0004
[01:08:39.406] iteration:9111  t-loss:0.0352, loss-lb:0.0155, loss-ulb:0.0098, weight:2.00, lr:0.0004
[01:08:39.789] iteration:9112  t-loss:0.0349, loss-lb:0.0226, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:08:40.172] iteration:9113  t-loss:0.0568, loss-lb:0.0420, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:08:40.551] iteration:9114  t-loss:0.0310, loss-lb:0.0098, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:08:40.935] iteration:9115  t-loss:0.0302, loss-lb:0.0244, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:08:41.315] iteration:9116  t-loss:0.0379, loss-lb:0.0170, loss-ulb:0.0105, weight:2.00, lr:0.0004
[01:08:41.692] iteration:9117  t-loss:0.0192, loss-lb:0.0160, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:08:42.070] iteration:9118  t-loss:0.0342, loss-lb:0.0281, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:08:42.455] iteration:9119  t-loss:0.0333, loss-lb:0.0303, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:08:42.835] iteration:9120  t-loss:0.0370, loss-lb:0.0347, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:08:44.061] iteration:9121  t-loss:0.0541, loss-lb:0.0129, loss-ulb:0.0206, weight:2.00, lr:0.0004
[01:08:44.445] iteration:9122  t-loss:0.0295, loss-lb:0.0279, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:08:44.823] iteration:9123  t-loss:0.0201, loss-lb:0.0158, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:08:45.206] iteration:9124  t-loss:0.0338, loss-lb:0.0266, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:08:45.585] iteration:9125  t-loss:0.0519, loss-lb:0.0317, loss-ulb:0.0101, weight:2.00, lr:0.0004
[01:08:45.966] iteration:9126  t-loss:0.0251, loss-lb:0.0123, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:08:46.359] iteration:9127  t-loss:0.0915, loss-lb:0.0597, loss-ulb:0.0159, weight:2.00, lr:0.0004
[01:08:46.765] iteration:9128  t-loss:0.0260, loss-lb:0.0226, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:08:47.167] iteration:9129  t-loss:0.0192, loss-lb:0.0155, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:08:47.564] iteration:9130  t-loss:0.0591, loss-lb:0.0312, loss-ulb:0.0139, weight:2.00, lr:0.0004
[01:08:47.955] iteration:9131  t-loss:0.0230, loss-lb:0.0116, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:08:48.349] iteration:9132  t-loss:0.0426, loss-lb:0.0285, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:08:48.733] iteration:9133  t-loss:0.0148, loss-lb:0.0116, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:08:49.116] iteration:9134  t-loss:0.0482, loss-lb:0.0457, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:08:49.506] iteration:9135  t-loss:0.0335, loss-lb:0.0164, loss-ulb:0.0085, weight:2.00, lr:0.0004
[01:08:49.892] iteration:9136  t-loss:0.0258, loss-lb:0.0124, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:08:50.278] iteration:9137  t-loss:0.0636, loss-lb:0.0275, loss-ulb:0.0181, weight:2.00, lr:0.0004
[01:08:50.659] iteration:9138  t-loss:0.0286, loss-lb:0.0136, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:08:51.044] iteration:9139  t-loss:0.0274, loss-lb:0.0221, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:08:51.429] iteration:9140  t-loss:0.0499, loss-lb:0.0264, loss-ulb:0.0118, weight:2.00, lr:0.0004
[01:08:51.813] iteration:9141  t-loss:0.0438, loss-lb:0.0251, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:08:52.196] iteration:9142  t-loss:0.0310, loss-lb:0.0264, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:08:52.579] iteration:9143  t-loss:0.0309, loss-lb:0.0183, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:08:52.968] iteration:9144  t-loss:0.0977, loss-lb:0.0387, loss-ulb:0.0295, weight:2.00, lr:0.0004
[01:08:53.351] iteration:9145  t-loss:0.0309, loss-lb:0.0143, loss-ulb:0.0083, weight:2.00, lr:0.0004
[01:08:53.733] iteration:9146  t-loss:0.0322, loss-lb:0.0137, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:08:54.121] iteration:9147  t-loss:0.0312, loss-lb:0.0152, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:08:54.508] iteration:9148  t-loss:0.0435, loss-lb:0.0357, loss-ulb:0.0039, weight:2.00, lr:0.0004
[01:08:54.897] iteration:9149  t-loss:0.0381, loss-lb:0.0281, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:08:55.277] iteration:9150  t-loss:0.0209, loss-lb:0.0172, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:08:55.659] iteration:9151  t-loss:0.0578, loss-lb:0.0311, loss-ulb:0.0134, weight:2.00, lr:0.0004
[01:08:56.040] iteration:9152  t-loss:0.0267, loss-lb:0.0169, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:08:56.425] iteration:9153  t-loss:0.0455, loss-lb:0.0248, loss-ulb:0.0103, weight:2.00, lr:0.0004
[01:08:56.806] iteration:9154  t-loss:0.0480, loss-lb:0.0260, loss-ulb:0.0110, weight:2.00, lr:0.0004
[01:08:57.191] iteration:9155  t-loss:0.0887, loss-lb:0.0316, loss-ulb:0.0285, weight:2.00, lr:0.0004
[01:08:57.572] iteration:9156  t-loss:0.0414, loss-lb:0.0274, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:08:57.954] iteration:9157  t-loss:0.0586, loss-lb:0.0422, loss-ulb:0.0082, weight:2.00, lr:0.0004
[01:08:58.334] iteration:9158  t-loss:0.0619, loss-lb:0.0180, loss-ulb:0.0219, weight:2.00, lr:0.0004
[01:10:08.334] iteration 9158 : dice_score: 0.896741 best_dice: 0.898600
[01:10:08.335]  <<Test>> - Ep:240  - Dice-S/T:89.38/89.67, Best-S:89.65, Best-T:89.86
[01:10:08.335]           - AvgLoss(lb/ulb/all):0.02/0.01/0.05
[01:10:09.570] iteration:9159  t-loss:0.0351, loss-lb:0.0201, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:10:09.964] iteration:9160  t-loss:0.0326, loss-lb:0.0251, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:10:10.354] iteration:9161  t-loss:0.0258, loss-lb:0.0139, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:10:10.738] iteration:9162  t-loss:0.0376, loss-lb:0.0343, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:10:11.132] iteration:9163  t-loss:0.0602, loss-lb:0.0221, loss-ulb:0.0190, weight:2.00, lr:0.0004
[01:10:11.516] iteration:9164  t-loss:0.0241, loss-lb:0.0179, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:10:11.899] iteration:9165  t-loss:0.0561, loss-lb:0.0515, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:10:12.285] iteration:9166  t-loss:0.0289, loss-lb:0.0254, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:10:12.673] iteration:9167  t-loss:0.0266, loss-lb:0.0234, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:10:13.055] iteration:9168  t-loss:0.0312, loss-lb:0.0217, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:10:13.446] iteration:9169  t-loss:0.0335, loss-lb:0.0230, loss-ulb:0.0053, weight:2.00, lr:0.0004
[01:10:13.827] iteration:9170  t-loss:0.0349, loss-lb:0.0194, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:10:14.209] iteration:9171  t-loss:0.0305, loss-lb:0.0224, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:10:14.592] iteration:9172  t-loss:0.0382, loss-lb:0.0341, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:10:14.968] iteration:9173  t-loss:0.0342, loss-lb:0.0162, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:10:15.350] iteration:9174  t-loss:0.0202, loss-lb:0.0129, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:10:15.731] iteration:9175  t-loss:0.0357, loss-lb:0.0241, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:10:16.110] iteration:9176  t-loss:0.0434, loss-lb:0.0128, loss-ulb:0.0153, weight:2.00, lr:0.0004
[01:10:16.499] iteration:9177  t-loss:0.0368, loss-lb:0.0240, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:10:16.885] iteration:9178  t-loss:0.0225, loss-lb:0.0182, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:10:17.270] iteration:9179  t-loss:0.0491, loss-lb:0.0149, loss-ulb:0.0171, weight:2.00, lr:0.0004
[01:10:17.650] iteration:9180  t-loss:0.0199, loss-lb:0.0152, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:10:18.039] iteration:9181  t-loss:0.0432, loss-lb:0.0147, loss-ulb:0.0142, weight:2.00, lr:0.0004
[01:10:18.439] iteration:9182  t-loss:0.0332, loss-lb:0.0289, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:10:18.833] iteration:9183  t-loss:0.0190, loss-lb:0.0108, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:10:19.217] iteration:9184  t-loss:0.0232, loss-lb:0.0121, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:10:19.597] iteration:9185  t-loss:0.0291, loss-lb:0.0150, loss-ulb:0.0071, weight:2.00, lr:0.0004
[01:10:19.977] iteration:9186  t-loss:0.0182, loss-lb:0.0162, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:10:20.362] iteration:9187  t-loss:0.0176, loss-lb:0.0121, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:10:20.742] iteration:9188  t-loss:0.0296, loss-lb:0.0164, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:10:21.125] iteration:9189  t-loss:0.0530, loss-lb:0.0246, loss-ulb:0.0142, weight:2.00, lr:0.0004
[01:10:21.509] iteration:9190  t-loss:0.0480, loss-lb:0.0216, loss-ulb:0.0132, weight:2.00, lr:0.0004
[01:10:21.895] iteration:9191  t-loss:0.0317, loss-lb:0.0287, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:10:22.272] iteration:9192  t-loss:0.0928, loss-lb:0.0122, loss-ulb:0.0403, weight:2.00, lr:0.0004
[01:10:22.657] iteration:9193  t-loss:0.0414, loss-lb:0.0250, loss-ulb:0.0082, weight:2.00, lr:0.0004
[01:10:23.047] iteration:9194  t-loss:0.0434, loss-lb:0.0313, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:10:23.431] iteration:9195  t-loss:0.0433, loss-lb:0.0191, loss-ulb:0.0121, weight:2.00, lr:0.0004
[01:10:23.815] iteration:9196  t-loss:0.0616, loss-lb:0.0569, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:10:25.164] iteration:9197  t-loss:0.0475, loss-lb:0.0324, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:10:25.566] iteration:9198  t-loss:0.0432, loss-lb:0.0357, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:10:25.945] iteration:9199  t-loss:0.0629, loss-lb:0.0215, loss-ulb:0.0207, weight:2.00, lr:0.0004
[01:10:26.326] iteration:9200  t-loss:0.0234, loss-lb:0.0181, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:10:26.720] iteration:9201  t-loss:0.0497, loss-lb:0.0304, loss-ulb:0.0096, weight:2.00, lr:0.0004
[01:10:27.104] iteration:9202  t-loss:0.0556, loss-lb:0.0221, loss-ulb:0.0168, weight:2.00, lr:0.0004
[01:10:27.489] iteration:9203  t-loss:0.0723, loss-lb:0.0248, loss-ulb:0.0238, weight:2.00, lr:0.0004
[01:10:27.873] iteration:9204  t-loss:0.0869, loss-lb:0.0317, loss-ulb:0.0276, weight:2.00, lr:0.0004
[01:10:28.264] iteration:9205  t-loss:0.0697, loss-lb:0.0260, loss-ulb:0.0219, weight:2.00, lr:0.0004
[01:10:28.653] iteration:9206  t-loss:0.0775, loss-lb:0.0492, loss-ulb:0.0142, weight:2.00, lr:0.0004
[01:10:29.038] iteration:9207  t-loss:0.0954, loss-lb:0.0444, loss-ulb:0.0255, weight:2.00, lr:0.0004
[01:10:29.430] iteration:9208  t-loss:0.0686, loss-lb:0.0496, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:10:29.812] iteration:9209  t-loss:0.0490, loss-lb:0.0381, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:10:30.189] iteration:9210  t-loss:0.0331, loss-lb:0.0290, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:10:30.565] iteration:9211  t-loss:0.0602, loss-lb:0.0335, loss-ulb:0.0134, weight:2.00, lr:0.0004
[01:10:30.955] iteration:9212  t-loss:0.0262, loss-lb:0.0212, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:10:31.341] iteration:9213  t-loss:0.0591, loss-lb:0.0350, loss-ulb:0.0120, weight:2.00, lr:0.0004
[01:10:31.723] iteration:9214  t-loss:0.0478, loss-lb:0.0424, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:10:32.100] iteration:9215  t-loss:0.0897, loss-lb:0.0177, loss-ulb:0.0360, weight:2.00, lr:0.0004
[01:10:32.487] iteration:9216  t-loss:0.1524, loss-lb:0.1364, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:10:32.866] iteration:9217  t-loss:0.0196, loss-lb:0.0154, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:10:33.244] iteration:9218  t-loss:0.0218, loss-lb:0.0162, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:10:33.631] iteration:9219  t-loss:0.0219, loss-lb:0.0173, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:10:34.019] iteration:9220  t-loss:0.0460, loss-lb:0.0174, loss-ulb:0.0143, weight:2.00, lr:0.0004
[01:10:34.408] iteration:9221  t-loss:0.0531, loss-lb:0.0441, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:10:34.788] iteration:9222  t-loss:0.0443, loss-lb:0.0307, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:10:35.176] iteration:9223  t-loss:0.0921, loss-lb:0.0617, loss-ulb:0.0152, weight:2.00, lr:0.0004
[01:10:35.558] iteration:9224  t-loss:0.0404, loss-lb:0.0191, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:10:35.942] iteration:9225  t-loss:0.0515, loss-lb:0.0274, loss-ulb:0.0120, weight:2.00, lr:0.0004
[01:10:36.328] iteration:9226  t-loss:0.0242, loss-lb:0.0191, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:10:36.710] iteration:9227  t-loss:0.0373, loss-lb:0.0329, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:10:37.094] iteration:9228  t-loss:0.0370, loss-lb:0.0298, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:10:37.477] iteration:9229  t-loss:0.0661, loss-lb:0.0371, loss-ulb:0.0145, weight:2.00, lr:0.0004
[01:10:37.861] iteration:9230  t-loss:0.0362, loss-lb:0.0199, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:10:38.238] iteration:9231  t-loss:0.0327, loss-lb:0.0218, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:10:38.622] iteration:9232  t-loss:0.0452, loss-lb:0.0166, loss-ulb:0.0143, weight:2.00, lr:0.0004
[01:10:39.005] iteration:9233  t-loss:0.0421, loss-lb:0.0372, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:10:39.389] iteration:9234  t-loss:0.0509, loss-lb:0.0341, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:10:40.784] iteration:9235  t-loss:0.0273, loss-lb:0.0208, loss-ulb:0.0033, weight:2.00, lr:0.0004
[01:10:41.178] iteration:9236  t-loss:0.0638, loss-lb:0.0301, loss-ulb:0.0168, weight:2.00, lr:0.0004
[01:10:41.556] iteration:9237  t-loss:0.0804, loss-lb:0.0155, loss-ulb:0.0325, weight:2.00, lr:0.0004
[01:10:41.938] iteration:9238  t-loss:0.0451, loss-lb:0.0310, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:10:42.327] iteration:9239  t-loss:0.0219, loss-lb:0.0167, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:10:42.718] iteration:9240  t-loss:0.0288, loss-lb:0.0255, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:10:43.110] iteration:9241  t-loss:0.0423, loss-lb:0.0283, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:10:43.489] iteration:9242  t-loss:0.0210, loss-lb:0.0190, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:10:43.868] iteration:9243  t-loss:0.0208, loss-lb:0.0167, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:10:44.244] iteration:9244  t-loss:0.0236, loss-lb:0.0196, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:10:44.628] iteration:9245  t-loss:0.0637, loss-lb:0.0362, loss-ulb:0.0138, weight:2.00, lr:0.0004
[01:10:45.010] iteration:9246  t-loss:0.0308, loss-lb:0.0167, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:10:45.393] iteration:9247  t-loss:0.0381, loss-lb:0.0347, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:10:45.778] iteration:9248  t-loss:0.0532, loss-lb:0.0385, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:10:46.172] iteration:9249  t-loss:0.0177, loss-lb:0.0137, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:10:46.580] iteration:9250  t-loss:0.0298, loss-lb:0.0242, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:10:46.980] iteration:9251  t-loss:0.0175, loss-lb:0.0143, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:10:47.369] iteration:9252  t-loss:0.0221, loss-lb:0.0197, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:10:47.754] iteration:9253  t-loss:0.0437, loss-lb:0.0245, loss-ulb:0.0096, weight:2.00, lr:0.0004
[01:10:48.139] iteration:9254  t-loss:0.0243, loss-lb:0.0191, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:10:48.526] iteration:9255  t-loss:0.0397, loss-lb:0.0310, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:10:48.910] iteration:9256  t-loss:0.0299, loss-lb:0.0156, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:10:49.293] iteration:9257  t-loss:0.0534, loss-lb:0.0384, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:10:49.683] iteration:9258  t-loss:0.0345, loss-lb:0.0177, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:10:50.064] iteration:9259  t-loss:0.0423, loss-lb:0.0386, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:10:50.445] iteration:9260  t-loss:0.0379, loss-lb:0.0350, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:10:50.828] iteration:9261  t-loss:0.0331, loss-lb:0.0184, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:10:51.214] iteration:9262  t-loss:0.0166, loss-lb:0.0134, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:10:51.593] iteration:9263  t-loss:0.0457, loss-lb:0.0395, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:10:51.974] iteration:9264  t-loss:0.0234, loss-lb:0.0180, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:10:52.362] iteration:9265  t-loss:0.0393, loss-lb:0.0189, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:10:52.746] iteration:9266  t-loss:0.0597, loss-lb:0.0403, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:10:53.130] iteration:9267  t-loss:0.0283, loss-lb:0.0220, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:10:53.512] iteration:9268  t-loss:0.0543, loss-lb:0.0159, loss-ulb:0.0192, weight:2.00, lr:0.0004
[01:10:53.891] iteration:9269  t-loss:0.0242, loss-lb:0.0187, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:10:54.277] iteration:9270  t-loss:0.0505, loss-lb:0.0237, loss-ulb:0.0134, weight:2.00, lr:0.0004
[01:10:54.655] iteration:9271  t-loss:0.0204, loss-lb:0.0140, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:10:55.035] iteration:9272  t-loss:0.0283, loss-lb:0.0141, loss-ulb:0.0071, weight:2.00, lr:0.0004
[01:10:56.230] iteration:9273  t-loss:0.0223, loss-lb:0.0193, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:10:56.618] iteration:9274  t-loss:0.0145, loss-lb:0.0124, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:10:57.005] iteration:9275  t-loss:0.0390, loss-lb:0.0143, loss-ulb:0.0123, weight:2.00, lr:0.0004
[01:10:57.381] iteration:9276  t-loss:0.0492, loss-lb:0.0414, loss-ulb:0.0039, weight:2.00, lr:0.0004
[01:10:57.769] iteration:9277  t-loss:0.0207, loss-lb:0.0168, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:10:58.165] iteration:9278  t-loss:0.0372, loss-lb:0.0258, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:10:58.555] iteration:9279  t-loss:0.0628, loss-lb:0.0207, loss-ulb:0.0211, weight:2.00, lr:0.0004
[01:10:58.940] iteration:9280  t-loss:0.0247, loss-lb:0.0134, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:10:59.322] iteration:9281  t-loss:0.0474, loss-lb:0.0428, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:10:59.703] iteration:9282  t-loss:0.0307, loss-lb:0.0252, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:11:00.084] iteration:9283  t-loss:0.0281, loss-lb:0.0230, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:11:00.464] iteration:9284  t-loss:0.0253, loss-lb:0.0202, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:11:00.848] iteration:9285  t-loss:0.0472, loss-lb:0.0369, loss-ulb:0.0051, weight:2.00, lr:0.0004
[01:11:01.229] iteration:9286  t-loss:0.0375, loss-lb:0.0166, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:11:01.623] iteration:9287  t-loss:0.0158, loss-lb:0.0127, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:11:02.020] iteration:9288  t-loss:0.0415, loss-lb:0.0394, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:11:02.404] iteration:9289  t-loss:0.0129, loss-lb:0.0108, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:11:02.782] iteration:9290  t-loss:0.0349, loss-lb:0.0187, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:11:03.175] iteration:9291  t-loss:0.0528, loss-lb:0.0352, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:11:03.563] iteration:9292  t-loss:0.0242, loss-lb:0.0152, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:11:03.954] iteration:9293  t-loss:0.0323, loss-lb:0.0214, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:11:04.341] iteration:9294  t-loss:0.0408, loss-lb:0.0207, loss-ulb:0.0100, weight:2.00, lr:0.0004
[01:11:04.727] iteration:9295  t-loss:0.0471, loss-lb:0.0150, loss-ulb:0.0161, weight:2.00, lr:0.0004
[01:11:05.118] iteration:9296  t-loss:0.0517, loss-lb:0.0387, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:11:05.502] iteration:9297  t-loss:0.0426, loss-lb:0.0330, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:11:05.882] iteration:9298  t-loss:0.0225, loss-lb:0.0161, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:11:06.268] iteration:9299  t-loss:0.0552, loss-lb:0.0406, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:11:06.648] iteration:9300  t-loss:0.0203, loss-lb:0.0164, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:11:07.034] iteration:9301  t-loss:0.0298, loss-lb:0.0264, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:11:07.418] iteration:9302  t-loss:0.0351, loss-lb:0.0153, loss-ulb:0.0099, weight:2.00, lr:0.0004
[01:11:07.803] iteration:9303  t-loss:0.0470, loss-lb:0.0125, loss-ulb:0.0173, weight:2.00, lr:0.0004
[01:11:08.185] iteration:9304  t-loss:0.0294, loss-lb:0.0149, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:11:08.566] iteration:9305  t-loss:0.0364, loss-lb:0.0125, loss-ulb:0.0119, weight:2.00, lr:0.0004
[01:11:08.947] iteration:9306  t-loss:0.0312, loss-lb:0.0112, loss-ulb:0.0100, weight:2.00, lr:0.0004
[01:11:09.328] iteration:9307  t-loss:0.0252, loss-lb:0.0160, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:11:09.709] iteration:9308  t-loss:0.0368, loss-lb:0.0162, loss-ulb:0.0103, weight:2.00, lr:0.0004
[01:11:10.085] iteration:9309  t-loss:0.0155, loss-lb:0.0117, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:11:10.466] iteration:9310  t-loss:0.0392, loss-lb:0.0245, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:12:20.897] iteration 9310 : dice_score: 0.893468 best_dice: 0.898600
[01:12:20.897]  <<Test>> - Ep:244  - Dice-S/T:84.30/89.35, Best-S:89.65, Best-T:89.86
[01:12:20.897]           - AvgLoss(lb/ulb/all):0.02/0.01/0.04
[01:12:22.007] iteration:9311  t-loss:0.0271, loss-lb:0.0230, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:12:22.402] iteration:9312  t-loss:0.0188, loss-lb:0.0124, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:12:22.791] iteration:9313  t-loss:0.0511, loss-lb:0.0159, loss-ulb:0.0176, weight:2.00, lr:0.0004
[01:12:23.182] iteration:9314  t-loss:0.0485, loss-lb:0.0147, loss-ulb:0.0169, weight:2.00, lr:0.0004
[01:12:23.567] iteration:9315  t-loss:0.0244, loss-lb:0.0131, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:12:23.951] iteration:9316  t-loss:0.0295, loss-lb:0.0162, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:12:24.335] iteration:9317  t-loss:0.0438, loss-lb:0.0262, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:12:24.725] iteration:9318  t-loss:0.0218, loss-lb:0.0180, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:12:25.133] iteration:9319  t-loss:0.0398, loss-lb:0.0146, loss-ulb:0.0126, weight:2.00, lr:0.0004
[01:12:25.524] iteration:9320  t-loss:0.0254, loss-lb:0.0150, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:12:25.916] iteration:9321  t-loss:0.0273, loss-lb:0.0149, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:12:26.310] iteration:9322  t-loss:0.0228, loss-lb:0.0166, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:12:26.694] iteration:9323  t-loss:0.0568, loss-lb:0.0363, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:12:27.078] iteration:9324  t-loss:0.0262, loss-lb:0.0113, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:12:27.463] iteration:9325  t-loss:0.0277, loss-lb:0.0128, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:12:27.850] iteration:9326  t-loss:0.0925, loss-lb:0.0292, loss-ulb:0.0316, weight:2.00, lr:0.0004
[01:12:28.231] iteration:9327  t-loss:0.0168, loss-lb:0.0143, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:12:28.615] iteration:9328  t-loss:0.0139, loss-lb:0.0111, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:12:29.007] iteration:9329  t-loss:0.0447, loss-lb:0.0324, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:12:29.390] iteration:9330  t-loss:0.0328, loss-lb:0.0125, loss-ulb:0.0101, weight:2.00, lr:0.0004
[01:12:29.773] iteration:9331  t-loss:0.0771, loss-lb:0.0312, loss-ulb:0.0229, weight:2.00, lr:0.0004
[01:12:30.166] iteration:9332  t-loss:0.0381, loss-lb:0.0165, loss-ulb:0.0108, weight:2.00, lr:0.0004
[01:12:30.549] iteration:9333  t-loss:0.0146, loss-lb:0.0120, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:12:30.934] iteration:9334  t-loss:0.0303, loss-lb:0.0237, loss-ulb:0.0033, weight:2.00, lr:0.0004
[01:12:31.321] iteration:9335  t-loss:0.0295, loss-lb:0.0140, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:12:31.719] iteration:9336  t-loss:0.0844, loss-lb:0.0286, loss-ulb:0.0279, weight:2.00, lr:0.0004
[01:12:32.110] iteration:9337  t-loss:0.0281, loss-lb:0.0209, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:12:32.502] iteration:9338  t-loss:0.0431, loss-lb:0.0367, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:12:32.883] iteration:9339  t-loss:0.0228, loss-lb:0.0186, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:12:33.272] iteration:9340  t-loss:0.1153, loss-lb:0.0346, loss-ulb:0.0404, weight:2.00, lr:0.0004
[01:12:33.654] iteration:9341  t-loss:0.0563, loss-lb:0.0144, loss-ulb:0.0209, weight:2.00, lr:0.0004
[01:12:34.036] iteration:9342  t-loss:0.0303, loss-lb:0.0146, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:12:34.415] iteration:9343  t-loss:0.0506, loss-lb:0.0374, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:12:34.794] iteration:9344  t-loss:0.0624, loss-lb:0.0249, loss-ulb:0.0188, weight:2.00, lr:0.0004
[01:12:35.171] iteration:9345  t-loss:0.0173, loss-lb:0.0147, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:12:35.552] iteration:9346  t-loss:0.0351, loss-lb:0.0295, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:12:35.931] iteration:9347  t-loss:0.0295, loss-lb:0.0139, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:12:36.310] iteration:9348  t-loss:0.0265, loss-lb:0.0202, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:12:37.565] iteration:9349  t-loss:0.0385, loss-lb:0.0350, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:12:37.956] iteration:9350  t-loss:0.0296, loss-lb:0.0148, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:12:38.341] iteration:9351  t-loss:0.0352, loss-lb:0.0169, loss-ulb:0.0091, weight:2.00, lr:0.0004
[01:12:38.722] iteration:9352  t-loss:0.0331, loss-lb:0.0216, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:12:39.109] iteration:9353  t-loss:0.0495, loss-lb:0.0235, loss-ulb:0.0130, weight:2.00, lr:0.0004
[01:12:39.492] iteration:9354  t-loss:0.0388, loss-lb:0.0238, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:12:39.874] iteration:9355  t-loss:0.0440, loss-lb:0.0320, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:12:40.253] iteration:9356  t-loss:0.0386, loss-lb:0.0338, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:12:40.633] iteration:9357  t-loss:0.0184, loss-lb:0.0142, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:12:41.019] iteration:9358  t-loss:0.0429, loss-lb:0.0395, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:12:41.403] iteration:9359  t-loss:0.0195, loss-lb:0.0178, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:12:41.788] iteration:9360  t-loss:0.0266, loss-lb:0.0232, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:12:42.172] iteration:9361  t-loss:0.0203, loss-lb:0.0163, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:12:42.555] iteration:9362  t-loss:0.0186, loss-lb:0.0157, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:12:42.936] iteration:9363  t-loss:0.0140, loss-lb:0.0122, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:12:43.323] iteration:9364  t-loss:0.0383, loss-lb:0.0178, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:12:43.704] iteration:9365  t-loss:0.0617, loss-lb:0.0147, loss-ulb:0.0235, weight:2.00, lr:0.0004
[01:12:44.089] iteration:9366  t-loss:0.0310, loss-lb:0.0230, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:12:44.467] iteration:9367  t-loss:0.0324, loss-lb:0.0284, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:12:44.857] iteration:9368  t-loss:0.0447, loss-lb:0.0238, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:12:45.239] iteration:9369  t-loss:0.0402, loss-lb:0.0351, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:12:45.629] iteration:9370  t-loss:0.0382, loss-lb:0.0246, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:12:46.014] iteration:9371  t-loss:0.0245, loss-lb:0.0217, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:12:46.398] iteration:9372  t-loss:0.0399, loss-lb:0.0240, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:12:46.784] iteration:9373  t-loss:0.0589, loss-lb:0.0433, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:12:47.176] iteration:9374  t-loss:0.0167, loss-lb:0.0143, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:12:47.568] iteration:9375  t-loss:0.0266, loss-lb:0.0151, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:12:47.964] iteration:9376  t-loss:0.0638, loss-lb:0.0526, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:12:48.350] iteration:9377  t-loss:0.0240, loss-lb:0.0165, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:12:48.734] iteration:9378  t-loss:0.0429, loss-lb:0.0354, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:12:49.114] iteration:9379  t-loss:0.0650, loss-lb:0.0344, loss-ulb:0.0153, weight:2.00, lr:0.0004
[01:12:49.496] iteration:9380  t-loss:0.0292, loss-lb:0.0115, loss-ulb:0.0089, weight:2.00, lr:0.0004
[01:12:49.880] iteration:9381  t-loss:0.0511, loss-lb:0.0279, loss-ulb:0.0116, weight:2.00, lr:0.0004
[01:12:50.257] iteration:9382  t-loss:0.0258, loss-lb:0.0187, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:12:50.635] iteration:9383  t-loss:0.0162, loss-lb:0.0121, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:12:51.015] iteration:9384  t-loss:0.0187, loss-lb:0.0156, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:12:51.397] iteration:9385  t-loss:0.0322, loss-lb:0.0250, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:12:51.787] iteration:9386  t-loss:0.0419, loss-lb:0.0273, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:12:53.102] iteration:9387  t-loss:0.0362, loss-lb:0.0336, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:12:53.494] iteration:9388  t-loss:0.0471, loss-lb:0.0295, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:12:53.899] iteration:9389  t-loss:0.0265, loss-lb:0.0134, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:12:54.300] iteration:9390  t-loss:0.0284, loss-lb:0.0173, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:12:54.688] iteration:9391  t-loss:0.0176, loss-lb:0.0134, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:12:55.078] iteration:9392  t-loss:0.0329, loss-lb:0.0232, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:12:55.464] iteration:9393  t-loss:0.0326, loss-lb:0.0271, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:12:55.846] iteration:9394  t-loss:0.0180, loss-lb:0.0148, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:12:56.232] iteration:9395  t-loss:0.0249, loss-lb:0.0133, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:12:56.613] iteration:9396  t-loss:0.0173, loss-lb:0.0110, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:12:56.993] iteration:9397  t-loss:0.0312, loss-lb:0.0135, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:12:57.382] iteration:9398  t-loss:0.0235, loss-lb:0.0154, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:12:57.770] iteration:9399  t-loss:0.0348, loss-lb:0.0308, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:12:58.155] iteration:9400  t-loss:0.0364, loss-lb:0.0285, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:12:58.538] iteration:9401  t-loss:0.0217, loss-lb:0.0168, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:12:58.922] iteration:9402  t-loss:0.0468, loss-lb:0.0288, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:12:59.302] iteration:9403  t-loss:0.0355, loss-lb:0.0255, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:12:59.680] iteration:9404  t-loss:0.0255, loss-lb:0.0213, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:13:00.061] iteration:9405  t-loss:0.0343, loss-lb:0.0160, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:13:00.443] iteration:9406  t-loss:0.0281, loss-lb:0.0140, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:13:00.829] iteration:9407  t-loss:0.0491, loss-lb:0.0387, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:13:01.218] iteration:9408  t-loss:0.0278, loss-lb:0.0178, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:13:01.605] iteration:9409  t-loss:0.0254, loss-lb:0.0231, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:13:01.991] iteration:9410  t-loss:0.0454, loss-lb:0.0140, loss-ulb:0.0157, weight:2.00, lr:0.0004
[01:13:02.385] iteration:9411  t-loss:0.0362, loss-lb:0.0334, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:13:02.789] iteration:9412  t-loss:0.0554, loss-lb:0.0246, loss-ulb:0.0154, weight:2.00, lr:0.0004
[01:13:03.191] iteration:9413  t-loss:0.0419, loss-lb:0.0233, loss-ulb:0.0093, weight:2.00, lr:0.0004
[01:13:03.573] iteration:9414  t-loss:0.0126, loss-lb:0.0112, loss-ulb:0.0007, weight:2.00, lr:0.0004
[01:13:03.960] iteration:9415  t-loss:0.0393, loss-lb:0.0147, loss-ulb:0.0123, weight:2.00, lr:0.0004
[01:13:04.351] iteration:9416  t-loss:0.0420, loss-lb:0.0246, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:13:04.737] iteration:9417  t-loss:0.0419, loss-lb:0.0228, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:13:05.118] iteration:9418  t-loss:0.0266, loss-lb:0.0219, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:13:05.499] iteration:9419  t-loss:0.0247, loss-lb:0.0216, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:13:05.880] iteration:9420  t-loss:0.0315, loss-lb:0.0158, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:13:06.260] iteration:9421  t-loss:0.0237, loss-lb:0.0103, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:13:06.640] iteration:9422  t-loss:0.0529, loss-lb:0.0341, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:13:07.021] iteration:9423  t-loss:0.0382, loss-lb:0.0224, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:13:07.398] iteration:9424  t-loss:0.0233, loss-lb:0.0189, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:13:08.651] iteration:9425  t-loss:0.0528, loss-lb:0.0296, loss-ulb:0.0116, weight:2.00, lr:0.0004
[01:13:09.047] iteration:9426  t-loss:0.0373, loss-lb:0.0246, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:13:09.435] iteration:9427  t-loss:0.0187, loss-lb:0.0158, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:13:09.831] iteration:9428  t-loss:0.0145, loss-lb:0.0123, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:13:10.219] iteration:9429  t-loss:0.0170, loss-lb:0.0136, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:13:10.589] iteration:9430  t-loss:0.0225, loss-lb:0.0109, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:13:10.974] iteration:9431  t-loss:0.0410, loss-lb:0.0396, loss-ulb:0.0007, weight:2.00, lr:0.0004
[01:13:11.361] iteration:9432  t-loss:0.0299, loss-lb:0.0132, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:13:11.750] iteration:9433  t-loss:0.0325, loss-lb:0.0142, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:13:12.135] iteration:9434  t-loss:0.0390, loss-lb:0.0152, loss-ulb:0.0119, weight:2.00, lr:0.0004
[01:13:12.524] iteration:9435  t-loss:0.0398, loss-lb:0.0370, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:13:12.910] iteration:9436  t-loss:0.0163, loss-lb:0.0123, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:13:13.295] iteration:9437  t-loss:0.0338, loss-lb:0.0109, loss-ulb:0.0114, weight:2.00, lr:0.0004
[01:13:13.682] iteration:9438  t-loss:0.0365, loss-lb:0.0330, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:13:14.069] iteration:9439  t-loss:0.0326, loss-lb:0.0232, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:13:14.457] iteration:9440  t-loss:0.0416, loss-lb:0.0341, loss-ulb:0.0038, weight:2.00, lr:0.0004
[01:13:14.833] iteration:9441  t-loss:0.0171, loss-lb:0.0134, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:13:15.211] iteration:9442  t-loss:0.0204, loss-lb:0.0132, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:13:15.595] iteration:9443  t-loss:0.0388, loss-lb:0.0190, loss-ulb:0.0099, weight:2.00, lr:0.0004
[01:13:15.979] iteration:9444  t-loss:0.0372, loss-lb:0.0262, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:13:16.359] iteration:9445  t-loss:0.0261, loss-lb:0.0133, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:13:16.738] iteration:9446  t-loss:0.0632, loss-lb:0.0306, loss-ulb:0.0163, weight:2.00, lr:0.0004
[01:13:17.118] iteration:9447  t-loss:0.0302, loss-lb:0.0269, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:13:17.499] iteration:9448  t-loss:0.0159, loss-lb:0.0134, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:13:17.890] iteration:9449  t-loss:0.0329, loss-lb:0.0188, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:13:18.306] iteration:9450  t-loss:0.0530, loss-lb:0.0381, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:13:18.704] iteration:9451  t-loss:0.0150, loss-lb:0.0133, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:13:19.098] iteration:9452  t-loss:0.0259, loss-lb:0.0236, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:13:19.496] iteration:9453  t-loss:0.0629, loss-lb:0.0293, loss-ulb:0.0168, weight:2.00, lr:0.0004
[01:13:19.885] iteration:9454  t-loss:0.0725, loss-lb:0.0341, loss-ulb:0.0192, weight:2.00, lr:0.0004
[01:13:20.270] iteration:9455  t-loss:0.0411, loss-lb:0.0266, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:13:20.651] iteration:9456  t-loss:0.0327, loss-lb:0.0301, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:13:21.032] iteration:9457  t-loss:0.0738, loss-lb:0.0359, loss-ulb:0.0190, weight:2.00, lr:0.0004
[01:13:21.409] iteration:9458  t-loss:0.0271, loss-lb:0.0122, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:13:21.788] iteration:9459  t-loss:0.0490, loss-lb:0.0345, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:13:22.166] iteration:9460  t-loss:0.0722, loss-lb:0.0316, loss-ulb:0.0203, weight:2.00, lr:0.0004
[01:13:22.546] iteration:9461  t-loss:0.0401, loss-lb:0.0264, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:13:22.922] iteration:9462  t-loss:0.0197, loss-lb:0.0152, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:14:34.056] iteration 9462 : dice_score: 0.897235 best_dice: 0.898600
[01:14:34.057]  <<Test>> - Ep:248  - Dice-S/T:86.05/89.72, Best-S:89.65, Best-T:89.86
[01:14:34.057]           - AvgLoss(lb/ulb/all):0.02/0.01/0.04
[01:14:35.549] iteration:9463  t-loss:0.0264, loss-lb:0.0238, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:14:35.954] iteration:9464  t-loss:0.0321, loss-lb:0.0171, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:14:36.345] iteration:9465  t-loss:0.0236, loss-lb:0.0157, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:14:36.729] iteration:9466  t-loss:0.0199, loss-lb:0.0171, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:14:37.117] iteration:9467  t-loss:0.0609, loss-lb:0.0350, loss-ulb:0.0129, weight:2.00, lr:0.0004
[01:14:37.505] iteration:9468  t-loss:0.0418, loss-lb:0.0368, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:14:37.899] iteration:9469  t-loss:0.0534, loss-lb:0.0398, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:14:38.286] iteration:9470  t-loss:0.0877, loss-lb:0.0196, loss-ulb:0.0341, weight:2.00, lr:0.0004
[01:14:38.670] iteration:9471  t-loss:0.1000, loss-lb:0.0207, loss-ulb:0.0397, weight:2.00, lr:0.0004
[01:14:39.061] iteration:9472  t-loss:0.0475, loss-lb:0.0281, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:14:39.445] iteration:9473  t-loss:0.0192, loss-lb:0.0162, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:14:39.828] iteration:9474  t-loss:0.0382, loss-lb:0.0175, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:14:40.212] iteration:9475  t-loss:0.0547, loss-lb:0.0310, loss-ulb:0.0118, weight:2.00, lr:0.0004
[01:14:40.593] iteration:9476  t-loss:0.0660, loss-lb:0.0409, loss-ulb:0.0126, weight:2.00, lr:0.0004
[01:14:40.973] iteration:9477  t-loss:0.0218, loss-lb:0.0193, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:14:41.357] iteration:9478  t-loss:0.0390, loss-lb:0.0351, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:14:41.738] iteration:9479  t-loss:0.1212, loss-lb:0.1136, loss-ulb:0.0038, weight:2.00, lr:0.0004
[01:14:42.120] iteration:9480  t-loss:0.0249, loss-lb:0.0215, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:14:42.504] iteration:9481  t-loss:0.0268, loss-lb:0.0175, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:14:42.890] iteration:9482  t-loss:0.0575, loss-lb:0.0461, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:14:43.272] iteration:9483  t-loss:0.0350, loss-lb:0.0305, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:14:43.657] iteration:9484  t-loss:0.0303, loss-lb:0.0165, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:14:44.042] iteration:9485  t-loss:0.0186, loss-lb:0.0137, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:14:44.425] iteration:9486  t-loss:0.0389, loss-lb:0.0182, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:14:44.810] iteration:9487  t-loss:0.0549, loss-lb:0.0298, loss-ulb:0.0126, weight:2.00, lr:0.0004
[01:14:45.195] iteration:9488  t-loss:0.1066, loss-lb:0.0707, loss-ulb:0.0179, weight:2.00, lr:0.0004
[01:14:45.578] iteration:9489  t-loss:0.0336, loss-lb:0.0177, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:14:45.953] iteration:9490  t-loss:0.0184, loss-lb:0.0156, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:14:46.335] iteration:9491  t-loss:0.0418, loss-lb:0.0395, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:14:46.712] iteration:9492  t-loss:0.0230, loss-lb:0.0189, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:14:47.092] iteration:9493  t-loss:0.0380, loss-lb:0.0241, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:14:47.469] iteration:9494  t-loss:0.0380, loss-lb:0.0353, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:14:47.849] iteration:9495  t-loss:0.0312, loss-lb:0.0215, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:14:48.235] iteration:9496  t-loss:0.1040, loss-lb:0.0266, loss-ulb:0.0387, weight:2.00, lr:0.0004
[01:14:48.632] iteration:9497  t-loss:0.0261, loss-lb:0.0223, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:14:49.013] iteration:9498  t-loss:0.0150, loss-lb:0.0120, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:14:49.395] iteration:9499  t-loss:0.0330, loss-lb:0.0213, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:14:49.776] iteration:9500  t-loss:0.0262, loss-lb:0.0151, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:14:51.099] iteration:9501  t-loss:0.0230, loss-lb:0.0208, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:14:51.493] iteration:9502  t-loss:0.0482, loss-lb:0.0266, loss-ulb:0.0108, weight:2.00, lr:0.0004
[01:14:51.879] iteration:9503  t-loss:0.0397, loss-lb:0.0152, loss-ulb:0.0122, weight:2.00, lr:0.0004
[01:14:52.260] iteration:9504  t-loss:0.0280, loss-lb:0.0226, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:14:52.640] iteration:9505  t-loss:0.0185, loss-lb:0.0158, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:14:53.029] iteration:9506  t-loss:0.0425, loss-lb:0.0273, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:14:53.421] iteration:9507  t-loss:0.0561, loss-lb:0.0246, loss-ulb:0.0158, weight:2.00, lr:0.0004
[01:14:53.802] iteration:9508  t-loss:0.0144, loss-lb:0.0122, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:14:54.187] iteration:9509  t-loss:0.0354, loss-lb:0.0322, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:14:54.566] iteration:9510  t-loss:0.0150, loss-lb:0.0133, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:14:54.948] iteration:9511  t-loss:0.0233, loss-lb:0.0173, loss-ulb:0.0030, weight:2.00, lr:0.0004
[01:14:55.338] iteration:9512  t-loss:0.0231, loss-lb:0.0134, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:14:55.723] iteration:9513  t-loss:0.0320, loss-lb:0.0125, loss-ulb:0.0098, weight:2.00, lr:0.0004
[01:14:56.104] iteration:9514  t-loss:0.0607, loss-lb:0.0121, loss-ulb:0.0243, weight:2.00, lr:0.0004
[01:14:56.493] iteration:9515  t-loss:0.0387, loss-lb:0.0362, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:14:56.876] iteration:9516  t-loss:0.0516, loss-lb:0.0412, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:14:57.256] iteration:9517  t-loss:0.0148, loss-lb:0.0129, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:14:57.642] iteration:9518  t-loss:0.0292, loss-lb:0.0195, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:14:58.033] iteration:9519  t-loss:0.0368, loss-lb:0.0237, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:14:58.416] iteration:9520  t-loss:0.0568, loss-lb:0.0535, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:14:58.799] iteration:9521  t-loss:0.0193, loss-lb:0.0136, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:14:59.183] iteration:9522  t-loss:0.0271, loss-lb:0.0218, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:14:59.573] iteration:9523  t-loss:0.0483, loss-lb:0.0360, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:14:59.954] iteration:9524  t-loss:0.0196, loss-lb:0.0123, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:15:00.334] iteration:9525  t-loss:0.0470, loss-lb:0.0447, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:15:00.718] iteration:9526  t-loss:0.0259, loss-lb:0.0218, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:15:01.106] iteration:9527  t-loss:0.0353, loss-lb:0.0307, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:15:01.485] iteration:9528  t-loss:0.0356, loss-lb:0.0257, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:15:01.872] iteration:9529  t-loss:0.0292, loss-lb:0.0203, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:15:02.254] iteration:9530  t-loss:0.0247, loss-lb:0.0167, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:15:02.640] iteration:9531  t-loss:0.0434, loss-lb:0.0376, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:15:03.024] iteration:9532  t-loss:0.0563, loss-lb:0.0237, loss-ulb:0.0163, weight:2.00, lr:0.0004
[01:15:03.408] iteration:9533  t-loss:0.0210, loss-lb:0.0180, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:15:03.799] iteration:9534  t-loss:0.0170, loss-lb:0.0149, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:15:04.202] iteration:9535  t-loss:0.0347, loss-lb:0.0171, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:15:04.598] iteration:9536  t-loss:0.0171, loss-lb:0.0131, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:15:04.989] iteration:9537  t-loss:0.0381, loss-lb:0.0156, loss-ulb:0.0113, weight:2.00, lr:0.0004
[01:15:05.374] iteration:9538  t-loss:0.0201, loss-lb:0.0128, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:15:06.709] iteration:9539  t-loss:0.0417, loss-lb:0.0139, loss-ulb:0.0139, weight:2.00, lr:0.0004
[01:15:07.097] iteration:9540  t-loss:0.0236, loss-lb:0.0133, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:15:07.472] iteration:9541  t-loss:0.0181, loss-lb:0.0159, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:15:07.857] iteration:9542  t-loss:0.0200, loss-lb:0.0124, loss-ulb:0.0038, weight:2.00, lr:0.0004
[01:15:08.240] iteration:9543  t-loss:0.0256, loss-lb:0.0125, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:15:08.629] iteration:9544  t-loss:0.0540, loss-lb:0.0424, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:15:09.012] iteration:9545  t-loss:0.0380, loss-lb:0.0351, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:15:09.398] iteration:9546  t-loss:0.0293, loss-lb:0.0187, loss-ulb:0.0053, weight:2.00, lr:0.0004
[01:15:09.784] iteration:9547  t-loss:0.0324, loss-lb:0.0203, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:15:10.173] iteration:9548  t-loss:0.0750, loss-lb:0.0426, loss-ulb:0.0162, weight:2.00, lr:0.0004
[01:15:10.556] iteration:9549  t-loss:0.0172, loss-lb:0.0138, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:15:10.945] iteration:9550  t-loss:0.0336, loss-lb:0.0201, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:15:11.323] iteration:9551  t-loss:0.0652, loss-lb:0.0476, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:15:11.714] iteration:9552  t-loss:0.0225, loss-lb:0.0196, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:15:12.097] iteration:9553  t-loss:0.0202, loss-lb:0.0151, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:15:12.485] iteration:9554  t-loss:0.0324, loss-lb:0.0229, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:15:12.870] iteration:9555  t-loss:0.0443, loss-lb:0.0202, loss-ulb:0.0120, weight:2.00, lr:0.0004
[01:15:13.252] iteration:9556  t-loss:0.0174, loss-lb:0.0110, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:15:13.635] iteration:9557  t-loss:0.0362, loss-lb:0.0180, loss-ulb:0.0091, weight:2.00, lr:0.0004
[01:15:14.016] iteration:9558  t-loss:0.0135, loss-lb:0.0111, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:15:14.401] iteration:9559  t-loss:0.0454, loss-lb:0.0240, loss-ulb:0.0107, weight:2.00, lr:0.0004
[01:15:14.781] iteration:9560  t-loss:0.0135, loss-lb:0.0115, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:15:15.165] iteration:9561  t-loss:0.0306, loss-lb:0.0181, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:15:15.549] iteration:9562  t-loss:0.0625, loss-lb:0.0339, loss-ulb:0.0143, weight:2.00, lr:0.0004
[01:15:15.927] iteration:9563  t-loss:0.0445, loss-lb:0.0414, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:15:16.310] iteration:9564  t-loss:0.0305, loss-lb:0.0294, loss-ulb:0.0006, weight:2.00, lr:0.0004
[01:15:16.689] iteration:9565  t-loss:0.0302, loss-lb:0.0275, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:15:17.076] iteration:9566  t-loss:0.1042, loss-lb:0.0428, loss-ulb:0.0307, weight:2.00, lr:0.0004
[01:15:17.456] iteration:9567  t-loss:0.0522, loss-lb:0.0411, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:15:17.835] iteration:9568  t-loss:0.0384, loss-lb:0.0232, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:15:18.210] iteration:9569  t-loss:0.0315, loss-lb:0.0143, loss-ulb:0.0086, weight:2.00, lr:0.0004
[01:15:18.591] iteration:9570  t-loss:0.0127, loss-lb:0.0103, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:15:18.980] iteration:9571  t-loss:0.0536, loss-lb:0.0484, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:15:19.368] iteration:9572  t-loss:0.0491, loss-lb:0.0368, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:15:19.770] iteration:9573  t-loss:0.0447, loss-lb:0.0190, loss-ulb:0.0129, weight:2.00, lr:0.0004
[01:15:20.154] iteration:9574  t-loss:0.0272, loss-lb:0.0122, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:15:20.544] iteration:9575  t-loss:0.0446, loss-lb:0.0375, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:15:20.927] iteration:9576  t-loss:0.0343, loss-lb:0.0139, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:15:22.192] iteration:9577  t-loss:0.0317, loss-lb:0.0127, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:15:22.591] iteration:9578  t-loss:0.0518, loss-lb:0.0405, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:15:22.974] iteration:9579  t-loss:0.0201, loss-lb:0.0175, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:15:23.358] iteration:9580  t-loss:0.0231, loss-lb:0.0137, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:15:23.742] iteration:9581  t-loss:0.0218, loss-lb:0.0137, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:15:24.128] iteration:9582  t-loss:0.0297, loss-lb:0.0123, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:15:24.515] iteration:9583  t-loss:0.0408, loss-lb:0.0378, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:15:24.907] iteration:9584  t-loss:0.0703, loss-lb:0.0370, loss-ulb:0.0166, weight:2.00, lr:0.0004
[01:15:25.286] iteration:9585  t-loss:0.0176, loss-lb:0.0138, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:15:25.668] iteration:9586  t-loss:0.0170, loss-lb:0.0146, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:15:26.047] iteration:9587  t-loss:0.0268, loss-lb:0.0150, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:15:26.432] iteration:9588  t-loss:0.0172, loss-lb:0.0155, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:15:26.817] iteration:9589  t-loss:0.0341, loss-lb:0.0165, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:15:27.210] iteration:9590  t-loss:0.0506, loss-lb:0.0305, loss-ulb:0.0100, weight:2.00, lr:0.0004
[01:15:27.591] iteration:9591  t-loss:0.0314, loss-lb:0.0177, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:15:27.975] iteration:9592  t-loss:0.0247, loss-lb:0.0161, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:15:28.362] iteration:9593  t-loss:0.0288, loss-lb:0.0260, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:15:28.743] iteration:9594  t-loss:0.0165, loss-lb:0.0131, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:15:29.131] iteration:9595  t-loss:0.0272, loss-lb:0.0135, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:15:29.516] iteration:9596  t-loss:0.0544, loss-lb:0.0309, loss-ulb:0.0118, weight:2.00, lr:0.0004
[01:15:29.896] iteration:9597  t-loss:0.0264, loss-lb:0.0160, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:15:30.278] iteration:9598  t-loss:0.0250, loss-lb:0.0212, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:15:30.664] iteration:9599  t-loss:0.0199, loss-lb:0.0182, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:15:31.049] iteration:9600  t-loss:0.0290, loss-lb:0.0137, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:15:31.431] iteration:9601  t-loss:0.0230, loss-lb:0.0119, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:15:31.807] iteration:9602  t-loss:0.0163, loss-lb:0.0139, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:15:32.186] iteration:9603  t-loss:0.0701, loss-lb:0.0450, loss-ulb:0.0126, weight:2.00, lr:0.0004
[01:15:32.569] iteration:9604  t-loss:0.0423, loss-lb:0.0292, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:15:32.949] iteration:9605  t-loss:0.0645, loss-lb:0.0395, loss-ulb:0.0125, weight:2.00, lr:0.0004
[01:15:33.329] iteration:9606  t-loss:0.0650, loss-lb:0.0417, loss-ulb:0.0116, weight:2.00, lr:0.0004
[01:15:33.709] iteration:9607  t-loss:0.0363, loss-lb:0.0218, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:15:34.085] iteration:9608  t-loss:0.0386, loss-lb:0.0142, loss-ulb:0.0122, weight:2.00, lr:0.0004
[01:15:34.464] iteration:9609  t-loss:0.0381, loss-lb:0.0282, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:15:34.845] iteration:9610  t-loss:0.0147, loss-lb:0.0114, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:15:35.232] iteration:9611  t-loss:0.0323, loss-lb:0.0111, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:15:35.618] iteration:9612  t-loss:0.0357, loss-lb:0.0145, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:15:36.002] iteration:9613  t-loss:0.0516, loss-lb:0.0172, loss-ulb:0.0172, weight:2.00, lr:0.0004
[01:15:36.378] iteration:9614  t-loss:0.0333, loss-lb:0.0178, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:16:47.131] iteration 9614 : dice_score: 0.882730 best_dice: 0.898600
[01:16:47.132]  <<Test>> - Ep:252  - Dice-S/T:90.09/88.27, Best-S:90.09, Best-T:89.86
[01:16:47.132]           - AvgLoss(lb/ulb/all):0.02/0.01/0.04
[01:16:48.594] iteration:9615  t-loss:0.0186, loss-lb:0.0143, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:16:48.987] iteration:9616  t-loss:0.0204, loss-lb:0.0163, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:16:49.381] iteration:9617  t-loss:0.0381, loss-lb:0.0228, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:16:49.765] iteration:9618  t-loss:0.0287, loss-lb:0.0239, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:16:50.151] iteration:9619  t-loss:0.0252, loss-lb:0.0167, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:16:50.534] iteration:9620  t-loss:0.0415, loss-lb:0.0147, loss-ulb:0.0134, weight:2.00, lr:0.0004
[01:16:50.919] iteration:9621  t-loss:0.0319, loss-lb:0.0107, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:16:51.302] iteration:9622  t-loss:0.0599, loss-lb:0.0426, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:16:51.685] iteration:9623  t-loss:0.0324, loss-lb:0.0269, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:16:52.069] iteration:9624  t-loss:0.0241, loss-lb:0.0185, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:16:52.447] iteration:9625  t-loss:0.0338, loss-lb:0.0162, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:16:52.819] iteration:9626  t-loss:0.0646, loss-lb:0.0340, loss-ulb:0.0153, weight:2.00, lr:0.0004
[01:16:53.203] iteration:9627  t-loss:0.0365, loss-lb:0.0337, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:16:53.588] iteration:9628  t-loss:0.0298, loss-lb:0.0139, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:16:53.967] iteration:9629  t-loss:0.0236, loss-lb:0.0136, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:16:54.348] iteration:9630  t-loss:0.0234, loss-lb:0.0210, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:16:54.731] iteration:9631  t-loss:0.0361, loss-lb:0.0329, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:16:55.116] iteration:9632  t-loss:0.0490, loss-lb:0.0346, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:16:55.503] iteration:9633  t-loss:0.0246, loss-lb:0.0218, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:16:55.884] iteration:9634  t-loss:0.0409, loss-lb:0.0292, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:16:56.266] iteration:9635  t-loss:0.0480, loss-lb:0.0329, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:16:56.649] iteration:9636  t-loss:0.0365, loss-lb:0.0170, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:16:57.031] iteration:9637  t-loss:0.0283, loss-lb:0.0208, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:16:57.416] iteration:9638  t-loss:0.0341, loss-lb:0.0174, loss-ulb:0.0083, weight:2.00, lr:0.0004
[01:16:57.796] iteration:9639  t-loss:0.0280, loss-lb:0.0161, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:16:58.176] iteration:9640  t-loss:0.0198, loss-lb:0.0151, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:16:58.556] iteration:9641  t-loss:0.0328, loss-lb:0.0303, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:16:58.942] iteration:9642  t-loss:0.0297, loss-lb:0.0266, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:16:59.323] iteration:9643  t-loss:0.0204, loss-lb:0.0145, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:16:59.700] iteration:9644  t-loss:0.0279, loss-lb:0.0175, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:17:00.078] iteration:9645  t-loss:0.0387, loss-lb:0.0247, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:17:00.458] iteration:9646  t-loss:0.0569, loss-lb:0.0288, loss-ulb:0.0140, weight:2.00, lr:0.0004
[01:17:00.839] iteration:9647  t-loss:0.0427, loss-lb:0.0338, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:17:01.217] iteration:9648  t-loss:0.0386, loss-lb:0.0105, loss-ulb:0.0141, weight:2.00, lr:0.0004
[01:17:01.595] iteration:9649  t-loss:0.0325, loss-lb:0.0145, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:17:01.977] iteration:9650  t-loss:0.0382, loss-lb:0.0262, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:17:02.359] iteration:9651  t-loss:0.0810, loss-lb:0.0390, loss-ulb:0.0210, weight:2.00, lr:0.0004
[01:17:02.741] iteration:9652  t-loss:0.0542, loss-lb:0.0151, loss-ulb:0.0195, weight:2.00, lr:0.0004
[01:17:04.300] iteration:9653  t-loss:0.0249, loss-lb:0.0223, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:17:04.688] iteration:9654  t-loss:0.0164, loss-lb:0.0128, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:17:05.076] iteration:9655  t-loss:0.1380, loss-lb:0.0968, loss-ulb:0.0206, weight:2.00, lr:0.0004
[01:17:05.461] iteration:9656  t-loss:0.0148, loss-lb:0.0131, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:17:05.852] iteration:9657  t-loss:0.0429, loss-lb:0.0263, loss-ulb:0.0083, weight:2.00, lr:0.0004
[01:17:06.242] iteration:9658  t-loss:0.0329, loss-lb:0.0228, loss-ulb:0.0051, weight:2.00, lr:0.0004
[01:17:06.628] iteration:9659  t-loss:0.0339, loss-lb:0.0230, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:17:07.011] iteration:9660  t-loss:0.0251, loss-lb:0.0233, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:17:07.395] iteration:9661  t-loss:0.0300, loss-lb:0.0279, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:17:07.786] iteration:9662  t-loss:0.0556, loss-lb:0.0388, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:17:08.168] iteration:9663  t-loss:0.0342, loss-lb:0.0139, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:17:08.553] iteration:9664  t-loss:0.0253, loss-lb:0.0220, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:17:08.944] iteration:9665  t-loss:0.0359, loss-lb:0.0172, loss-ulb:0.0093, weight:2.00, lr:0.0004
[01:17:09.327] iteration:9666  t-loss:0.0366, loss-lb:0.0141, loss-ulb:0.0113, weight:2.00, lr:0.0004
[01:17:09.715] iteration:9667  t-loss:0.0218, loss-lb:0.0120, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:17:10.107] iteration:9668  t-loss:0.0466, loss-lb:0.0362, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:17:10.495] iteration:9669  t-loss:0.0291, loss-lb:0.0234, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:17:10.883] iteration:9670  t-loss:0.0323, loss-lb:0.0230, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:17:11.273] iteration:9671  t-loss:0.0501, loss-lb:0.0310, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:17:11.651] iteration:9672  t-loss:0.0216, loss-lb:0.0172, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:17:12.030] iteration:9673  t-loss:0.0213, loss-lb:0.0175, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:17:12.418] iteration:9674  t-loss:0.0271, loss-lb:0.0167, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:17:12.804] iteration:9675  t-loss:0.0459, loss-lb:0.0339, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:17:13.197] iteration:9676  t-loss:0.0241, loss-lb:0.0220, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:17:13.590] iteration:9677  t-loss:0.0437, loss-lb:0.0207, loss-ulb:0.0115, weight:2.00, lr:0.0004
[01:17:13.979] iteration:9678  t-loss:0.0374, loss-lb:0.0358, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:17:14.368] iteration:9679  t-loss:0.0344, loss-lb:0.0198, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:17:14.754] iteration:9680  t-loss:0.0196, loss-lb:0.0174, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:17:15.147] iteration:9681  t-loss:0.0312, loss-lb:0.0178, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:17:15.548] iteration:9682  t-loss:0.0295, loss-lb:0.0131, loss-ulb:0.0082, weight:2.00, lr:0.0004
[01:17:15.931] iteration:9683  t-loss:0.0268, loss-lb:0.0187, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:17:16.312] iteration:9684  t-loss:0.0356, loss-lb:0.0172, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:17:16.693] iteration:9685  t-loss:0.0404, loss-lb:0.0216, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:17:17.074] iteration:9686  t-loss:0.0329, loss-lb:0.0216, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:17:17.453] iteration:9687  t-loss:0.0410, loss-lb:0.0216, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:17:17.839] iteration:9688  t-loss:0.0308, loss-lb:0.0246, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:17:18.230] iteration:9689  t-loss:0.1284, loss-lb:0.0213, loss-ulb:0.0536, weight:2.00, lr:0.0004
[01:17:18.623] iteration:9690  t-loss:0.0410, loss-lb:0.0179, loss-ulb:0.0116, weight:2.00, lr:0.0004
[01:17:19.975] iteration:9691  t-loss:0.0386, loss-lb:0.0278, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:17:20.374] iteration:9692  t-loss:0.0816, loss-lb:0.0646, loss-ulb:0.0085, weight:2.00, lr:0.0004
[01:17:20.759] iteration:9693  t-loss:0.0292, loss-lb:0.0232, loss-ulb:0.0030, weight:2.00, lr:0.0004
[01:17:21.146] iteration:9694  t-loss:0.0867, loss-lb:0.0708, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:17:21.532] iteration:9695  t-loss:0.0660, loss-lb:0.0339, loss-ulb:0.0161, weight:2.00, lr:0.0004
[01:17:21.912] iteration:9696  t-loss:0.0351, loss-lb:0.0207, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:17:22.297] iteration:9697  t-loss:0.0458, loss-lb:0.0389, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:17:22.687] iteration:9698  t-loss:0.0336, loss-lb:0.0289, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:17:23.075] iteration:9699  t-loss:0.0476, loss-lb:0.0264, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:17:23.458] iteration:9700  t-loss:0.0469, loss-lb:0.0322, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:17:23.839] iteration:9701  t-loss:0.0433, loss-lb:0.0290, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:17:24.228] iteration:9702  t-loss:0.0456, loss-lb:0.0339, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:17:24.616] iteration:9703  t-loss:0.0475, loss-lb:0.0226, loss-ulb:0.0125, weight:2.00, lr:0.0004
[01:17:25.005] iteration:9704  t-loss:0.0265, loss-lb:0.0228, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:17:25.395] iteration:9705  t-loss:0.0302, loss-lb:0.0232, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:17:25.781] iteration:9706  t-loss:0.0280, loss-lb:0.0252, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:17:26.167] iteration:9707  t-loss:0.0458, loss-lb:0.0336, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:17:26.553] iteration:9708  t-loss:0.0538, loss-lb:0.0391, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:17:26.933] iteration:9709  t-loss:0.0398, loss-lb:0.0225, loss-ulb:0.0086, weight:2.00, lr:0.0004
[01:17:27.314] iteration:9710  t-loss:0.0180, loss-lb:0.0152, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:17:27.693] iteration:9711  t-loss:0.0425, loss-lb:0.0331, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:17:28.073] iteration:9712  t-loss:0.0227, loss-lb:0.0156, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:17:28.450] iteration:9713  t-loss:0.0324, loss-lb:0.0250, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:17:28.832] iteration:9714  t-loss:0.0311, loss-lb:0.0124, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:17:29.212] iteration:9715  t-loss:0.0328, loss-lb:0.0178, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:17:29.593] iteration:9716  t-loss:0.0305, loss-lb:0.0130, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:17:29.983] iteration:9717  t-loss:0.0270, loss-lb:0.0220, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:17:30.371] iteration:9718  t-loss:0.0299, loss-lb:0.0140, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:17:30.757] iteration:9719  t-loss:0.0218, loss-lb:0.0176, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:17:31.150] iteration:9720  t-loss:0.0328, loss-lb:0.0281, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:17:31.536] iteration:9721  t-loss:0.0530, loss-lb:0.0275, loss-ulb:0.0128, weight:2.00, lr:0.0004
[01:17:31.915] iteration:9722  t-loss:0.0389, loss-lb:0.0230, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:17:32.290] iteration:9723  t-loss:0.0176, loss-lb:0.0156, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:17:32.669] iteration:9724  t-loss:0.0164, loss-lb:0.0143, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:17:33.051] iteration:9725  t-loss:0.0329, loss-lb:0.0260, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:17:33.432] iteration:9726  t-loss:0.0177, loss-lb:0.0126, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:17:33.821] iteration:9727  t-loss:0.0294, loss-lb:0.0168, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:17:34.208] iteration:9728  t-loss:0.0303, loss-lb:0.0275, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:17:35.520] iteration:9729  t-loss:0.0213, loss-lb:0.0177, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:17:35.917] iteration:9730  t-loss:0.0283, loss-lb:0.0258, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:17:36.304] iteration:9731  t-loss:0.0399, loss-lb:0.0352, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:17:36.686] iteration:9732  t-loss:0.0371, loss-lb:0.0162, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:17:37.072] iteration:9733  t-loss:0.0359, loss-lb:0.0121, loss-ulb:0.0119, weight:2.00, lr:0.0004
[01:17:37.456] iteration:9734  t-loss:0.0177, loss-lb:0.0146, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:17:37.837] iteration:9735  t-loss:0.0586, loss-lb:0.0166, loss-ulb:0.0210, weight:2.00, lr:0.0004
[01:17:38.227] iteration:9736  t-loss:0.0241, loss-lb:0.0218, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:17:38.616] iteration:9737  t-loss:0.0358, loss-lb:0.0163, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:17:39.000] iteration:9738  t-loss:0.0473, loss-lb:0.0132, loss-ulb:0.0170, weight:2.00, lr:0.0004
[01:17:39.381] iteration:9739  t-loss:0.0237, loss-lb:0.0219, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:17:39.763] iteration:9740  t-loss:0.0253, loss-lb:0.0187, loss-ulb:0.0033, weight:2.00, lr:0.0004
[01:17:40.147] iteration:9741  t-loss:0.0386, loss-lb:0.0196, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:17:40.537] iteration:9742  t-loss:0.0223, loss-lb:0.0145, loss-ulb:0.0039, weight:2.00, lr:0.0004
[01:17:40.931] iteration:9743  t-loss:0.0568, loss-lb:0.0370, loss-ulb:0.0099, weight:2.00, lr:0.0004
[01:17:41.321] iteration:9744  t-loss:0.0358, loss-lb:0.0140, loss-ulb:0.0109, weight:2.00, lr:0.0004
[01:17:41.710] iteration:9745  t-loss:0.0308, loss-lb:0.0254, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:17:42.097] iteration:9746  t-loss:0.0261, loss-lb:0.0120, loss-ulb:0.0071, weight:2.00, lr:0.0004
[01:17:42.488] iteration:9747  t-loss:0.0407, loss-lb:0.0177, loss-ulb:0.0115, weight:2.00, lr:0.0004
[01:17:42.878] iteration:9748  t-loss:0.0251, loss-lb:0.0131, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:17:43.261] iteration:9749  t-loss:0.0147, loss-lb:0.0117, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:17:43.650] iteration:9750  t-loss:0.0630, loss-lb:0.0185, loss-ulb:0.0223, weight:2.00, lr:0.0004
[01:17:44.037] iteration:9751  t-loss:0.0293, loss-lb:0.0152, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:17:44.420] iteration:9752  t-loss:0.0174, loss-lb:0.0139, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:17:44.799] iteration:9753  t-loss:0.0271, loss-lb:0.0251, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:17:45.176] iteration:9754  t-loss:0.0169, loss-lb:0.0145, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:17:45.563] iteration:9755  t-loss:0.0575, loss-lb:0.0272, loss-ulb:0.0151, weight:2.00, lr:0.0004
[01:17:45.968] iteration:9756  t-loss:0.0227, loss-lb:0.0192, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:17:46.378] iteration:9757  t-loss:0.0545, loss-lb:0.0139, loss-ulb:0.0203, weight:2.00, lr:0.0004
[01:17:46.782] iteration:9758  t-loss:0.0542, loss-lb:0.0419, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:17:47.174] iteration:9759  t-loss:0.0429, loss-lb:0.0226, loss-ulb:0.0101, weight:2.00, lr:0.0004
[01:17:47.561] iteration:9760  t-loss:0.0327, loss-lb:0.0298, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:17:47.941] iteration:9761  t-loss:0.0233, loss-lb:0.0119, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:17:48.321] iteration:9762  t-loss:0.0189, loss-lb:0.0130, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:17:48.707] iteration:9763  t-loss:0.0325, loss-lb:0.0202, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:17:49.085] iteration:9764  t-loss:0.0446, loss-lb:0.0345, loss-ulb:0.0051, weight:2.00, lr:0.0004
[01:17:49.473] iteration:9765  t-loss:0.0452, loss-lb:0.0325, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:17:49.855] iteration:9766  t-loss:0.0411, loss-lb:0.0289, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:18:59.420] iteration 9766 : dice_score: 0.897138 best_dice: 0.898600
[01:18:59.420]  <<Test>> - Ep:256  - Dice-S/T:89.33/89.71, Best-S:90.09, Best-T:89.86
[01:18:59.420]           - AvgLoss(lb/ulb/all):0.02/0.01/0.04
[01:19:00.688] iteration:9767  t-loss:0.0253, loss-lb:0.0226, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:19:01.080] iteration:9768  t-loss:0.0147, loss-lb:0.0117, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:01.464] iteration:9769  t-loss:0.0153, loss-lb:0.0124, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:01.843] iteration:9770  t-loss:0.0186, loss-lb:0.0164, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:19:02.223] iteration:9771  t-loss:0.0285, loss-lb:0.0150, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:19:02.604] iteration:9772  t-loss:0.0341, loss-lb:0.0118, loss-ulb:0.0112, weight:2.00, lr:0.0004
[01:19:02.984] iteration:9773  t-loss:0.0285, loss-lb:0.0148, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:19:03.362] iteration:9774  t-loss:0.0303, loss-lb:0.0098, loss-ulb:0.0103, weight:2.00, lr:0.0004
[01:19:03.741] iteration:9775  t-loss:0.0267, loss-lb:0.0210, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:19:04.128] iteration:9776  t-loss:0.0182, loss-lb:0.0149, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:19:04.532] iteration:9777  t-loss:0.0316, loss-lb:0.0198, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:19:04.934] iteration:9778  t-loss:0.0497, loss-lb:0.0245, loss-ulb:0.0126, weight:2.00, lr:0.0004
[01:19:05.331] iteration:9779  t-loss:0.0470, loss-lb:0.0291, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:19:05.714] iteration:9780  t-loss:0.0203, loss-lb:0.0161, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:19:06.097] iteration:9781  t-loss:0.0299, loss-lb:0.0148, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:19:06.482] iteration:9782  t-loss:0.0275, loss-lb:0.0241, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:19:06.867] iteration:9783  t-loss:0.0136, loss-lb:0.0115, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:19:07.249] iteration:9784  t-loss:0.0397, loss-lb:0.0368, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:07.631] iteration:9785  t-loss:0.0173, loss-lb:0.0147, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:19:08.015] iteration:9786  t-loss:0.0255, loss-lb:0.0233, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:19:08.399] iteration:9787  t-loss:0.0505, loss-lb:0.0268, loss-ulb:0.0118, weight:2.00, lr:0.0004
[01:19:08.782] iteration:9788  t-loss:0.0352, loss-lb:0.0318, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:19:09.168] iteration:9789  t-loss:0.0308, loss-lb:0.0278, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:09.554] iteration:9790  t-loss:0.0167, loss-lb:0.0133, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:19:09.942] iteration:9791  t-loss:0.0564, loss-lb:0.0334, loss-ulb:0.0115, weight:2.00, lr:0.0004
[01:19:10.325] iteration:9792  t-loss:0.0163, loss-lb:0.0136, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:19:10.710] iteration:9793  t-loss:0.0283, loss-lb:0.0139, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:19:11.090] iteration:9794  t-loss:0.0235, loss-lb:0.0176, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:19:11.473] iteration:9795  t-loss:0.0349, loss-lb:0.0229, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:19:11.855] iteration:9796  t-loss:0.0331, loss-lb:0.0142, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:19:12.235] iteration:9797  t-loss:0.0265, loss-lb:0.0176, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:19:12.616] iteration:9798  t-loss:0.0578, loss-lb:0.0290, loss-ulb:0.0144, weight:2.00, lr:0.0004
[01:19:12.994] iteration:9799  t-loss:0.0238, loss-lb:0.0188, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:19:13.374] iteration:9800  t-loss:0.0240, loss-lb:0.0121, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:19:13.754] iteration:9801  t-loss:0.0234, loss-lb:0.0104, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:19:14.139] iteration:9802  t-loss:0.0285, loss-lb:0.0154, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:19:14.526] iteration:9803  t-loss:0.0486, loss-lb:0.0370, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:19:14.909] iteration:9804  t-loss:0.0300, loss-lb:0.0192, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:19:16.126] iteration:9805  t-loss:0.0457, loss-lb:0.0167, loss-ulb:0.0145, weight:2.00, lr:0.0004
[01:19:16.516] iteration:9806  t-loss:0.0197, loss-lb:0.0126, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:19:16.897] iteration:9807  t-loss:0.0333, loss-lb:0.0235, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:19:17.281] iteration:9808  t-loss:0.0130, loss-lb:0.0099, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:17.660] iteration:9809  t-loss:0.0397, loss-lb:0.0289, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:19:18.041] iteration:9810  t-loss:0.0263, loss-lb:0.0234, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:18.424] iteration:9811  t-loss:0.0160, loss-lb:0.0141, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:19:18.813] iteration:9812  t-loss:0.0368, loss-lb:0.0289, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:19:19.195] iteration:9813  t-loss:0.0369, loss-lb:0.0251, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:19:19.594] iteration:9814  t-loss:0.0453, loss-lb:0.0216, loss-ulb:0.0118, weight:2.00, lr:0.0004
[01:19:19.989] iteration:9815  t-loss:0.0195, loss-lb:0.0110, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:19:20.379] iteration:9816  t-loss:0.0503, loss-lb:0.0421, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:19:20.770] iteration:9817  t-loss:0.0432, loss-lb:0.0319, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:19:21.155] iteration:9818  t-loss:0.0212, loss-lb:0.0200, loss-ulb:0.0006, weight:2.00, lr:0.0004
[01:19:21.544] iteration:9819  t-loss:0.0422, loss-lb:0.0270, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:19:21.928] iteration:9820  t-loss:0.0383, loss-lb:0.0306, loss-ulb:0.0038, weight:2.00, lr:0.0004
[01:19:22.309] iteration:9821  t-loss:0.0246, loss-lb:0.0134, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:19:22.701] iteration:9822  t-loss:0.0260, loss-lb:0.0128, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:19:23.092] iteration:9823  t-loss:0.0465, loss-lb:0.0193, loss-ulb:0.0136, weight:2.00, lr:0.0004
[01:19:23.476] iteration:9824  t-loss:0.0319, loss-lb:0.0141, loss-ulb:0.0089, weight:2.00, lr:0.0004
[01:19:23.862] iteration:9825  t-loss:0.0516, loss-lb:0.0118, loss-ulb:0.0199, weight:2.00, lr:0.0004
[01:19:24.245] iteration:9826  t-loss:0.0207, loss-lb:0.0153, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:19:24.635] iteration:9827  t-loss:0.0298, loss-lb:0.0126, loss-ulb:0.0086, weight:2.00, lr:0.0004
[01:19:25.029] iteration:9828  t-loss:0.0305, loss-lb:0.0148, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:19:25.425] iteration:9829  t-loss:0.0170, loss-lb:0.0110, loss-ulb:0.0030, weight:2.00, lr:0.0004
[01:19:25.806] iteration:9830  t-loss:0.0270, loss-lb:0.0135, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:19:26.193] iteration:9831  t-loss:0.0272, loss-lb:0.0102, loss-ulb:0.0085, weight:2.00, lr:0.0004
[01:19:26.610] iteration:9832  t-loss:0.0249, loss-lb:0.0119, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:19:26.995] iteration:9833  t-loss:0.0212, loss-lb:0.0147, loss-ulb:0.0033, weight:2.00, lr:0.0004
[01:19:27.384] iteration:9834  t-loss:0.0397, loss-lb:0.0177, loss-ulb:0.0110, weight:2.00, lr:0.0004
[01:19:27.766] iteration:9835  t-loss:0.0152, loss-lb:0.0122, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:28.146] iteration:9836  t-loss:0.0250, loss-lb:0.0143, loss-ulb:0.0053, weight:2.00, lr:0.0004
[01:19:28.525] iteration:9837  t-loss:0.0303, loss-lb:0.0284, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:19:28.906] iteration:9838  t-loss:0.0192, loss-lb:0.0176, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:19:29.286] iteration:9839  t-loss:0.0182, loss-lb:0.0121, loss-ulb:0.0030, weight:2.00, lr:0.0004
[01:19:29.668] iteration:9840  t-loss:0.0397, loss-lb:0.0235, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:19:30.052] iteration:9841  t-loss:0.0478, loss-lb:0.0263, loss-ulb:0.0107, weight:2.00, lr:0.0004
[01:19:30.431] iteration:9842  t-loss:0.0305, loss-lb:0.0141, loss-ulb:0.0082, weight:2.00, lr:0.0004
[01:19:31.745] iteration:9843  t-loss:0.0225, loss-lb:0.0128, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:19:32.139] iteration:9844  t-loss:0.0208, loss-lb:0.0189, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:19:32.532] iteration:9845  t-loss:0.0388, loss-lb:0.0300, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:19:32.912] iteration:9846  t-loss:0.0287, loss-lb:0.0255, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:19:33.293] iteration:9847  t-loss:0.0238, loss-lb:0.0146, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:19:33.688] iteration:9848  t-loss:0.0441, loss-lb:0.0380, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:19:34.064] iteration:9849  t-loss:0.0146, loss-lb:0.0114, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:19:34.448] iteration:9850  t-loss:0.0361, loss-lb:0.0243, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:19:34.836] iteration:9851  t-loss:0.0442, loss-lb:0.0303, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:19:35.226] iteration:9852  t-loss:0.0310, loss-lb:0.0219, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:19:35.610] iteration:9853  t-loss:0.0288, loss-lb:0.0121, loss-ulb:0.0083, weight:2.00, lr:0.0004
[01:19:36.002] iteration:9854  t-loss:0.0605, loss-lb:0.0220, loss-ulb:0.0192, weight:2.00, lr:0.0004
[01:19:36.388] iteration:9855  t-loss:0.0185, loss-lb:0.0147, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:19:36.772] iteration:9856  t-loss:0.0480, loss-lb:0.0204, loss-ulb:0.0138, weight:2.00, lr:0.0004
[01:19:37.156] iteration:9857  t-loss:0.0260, loss-lb:0.0228, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:19:37.541] iteration:9858  t-loss:0.0300, loss-lb:0.0218, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:19:37.929] iteration:9859  t-loss:0.0370, loss-lb:0.0196, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:19:38.311] iteration:9860  t-loss:0.0271, loss-lb:0.0142, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:19:38.693] iteration:9861  t-loss:0.0177, loss-lb:0.0154, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:19:39.081] iteration:9862  t-loss:0.0268, loss-lb:0.0195, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:19:39.462] iteration:9863  t-loss:0.0148, loss-lb:0.0108, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:19:39.844] iteration:9864  t-loss:0.0305, loss-lb:0.0225, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:19:40.230] iteration:9865  t-loss:0.0315, loss-lb:0.0123, loss-ulb:0.0096, weight:2.00, lr:0.0004
[01:19:40.615] iteration:9866  t-loss:0.0259, loss-lb:0.0229, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:40.992] iteration:9867  t-loss:0.0290, loss-lb:0.0144, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:19:41.382] iteration:9868  t-loss:0.0394, loss-lb:0.0341, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:19:41.773] iteration:9869  t-loss:0.0130, loss-lb:0.0109, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:19:42.166] iteration:9870  t-loss:0.0196, loss-lb:0.0153, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:19:42.549] iteration:9871  t-loss:0.0215, loss-lb:0.0144, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:19:42.933] iteration:9872  t-loss:0.0146, loss-lb:0.0113, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:19:43.317] iteration:9873  t-loss:0.0322, loss-lb:0.0215, loss-ulb:0.0053, weight:2.00, lr:0.0004
[01:19:43.701] iteration:9874  t-loss:0.0164, loss-lb:0.0131, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:19:44.082] iteration:9875  t-loss:0.0156, loss-lb:0.0135, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:19:44.460] iteration:9876  t-loss:0.0196, loss-lb:0.0132, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:19:44.841] iteration:9877  t-loss:0.0262, loss-lb:0.0136, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:19:45.220] iteration:9878  t-loss:0.0202, loss-lb:0.0107, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:19:45.604] iteration:9879  t-loss:0.0515, loss-lb:0.0466, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:19:45.982] iteration:9880  t-loss:0.0138, loss-lb:0.0110, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:19:47.305] iteration:9881  t-loss:0.0229, loss-lb:0.0214, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:19:47.701] iteration:9882  t-loss:0.0277, loss-lb:0.0149, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:19:48.084] iteration:9883  t-loss:0.0143, loss-lb:0.0131, loss-ulb:0.0006, weight:2.00, lr:0.0004
[01:19:48.470] iteration:9884  t-loss:0.0347, loss-lb:0.0280, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:19:48.858] iteration:9885  t-loss:0.0229, loss-lb:0.0217, loss-ulb:0.0006, weight:2.00, lr:0.0004
[01:19:49.243] iteration:9886  t-loss:0.0432, loss-lb:0.0369, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:19:49.630] iteration:9887  t-loss:0.0476, loss-lb:0.0275, loss-ulb:0.0101, weight:2.00, lr:0.0004
[01:19:50.031] iteration:9888  t-loss:0.0374, loss-lb:0.0343, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:19:50.434] iteration:9889  t-loss:0.0240, loss-lb:0.0149, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:19:50.839] iteration:9890  t-loss:0.0293, loss-lb:0.0183, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:19:51.241] iteration:9891  t-loss:0.0423, loss-lb:0.0280, loss-ulb:0.0071, weight:2.00, lr:0.0004
[01:19:51.625] iteration:9892  t-loss:0.0263, loss-lb:0.0134, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:19:52.008] iteration:9893  t-loss:0.0336, loss-lb:0.0249, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:19:52.389] iteration:9894  t-loss:0.0150, loss-lb:0.0131, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:19:52.771] iteration:9895  t-loss:0.0295, loss-lb:0.0115, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:19:53.157] iteration:9896  t-loss:0.0272, loss-lb:0.0154, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:19:53.543] iteration:9897  t-loss:0.0395, loss-lb:0.0215, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:19:53.927] iteration:9898  t-loss:0.0213, loss-lb:0.0127, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:19:54.310] iteration:9899  t-loss:0.0344, loss-lb:0.0319, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:19:54.688] iteration:9900  t-loss:0.0337, loss-lb:0.0299, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:19:55.075] iteration:9901  t-loss:0.0334, loss-lb:0.0308, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:19:55.456] iteration:9902  t-loss:0.0125, loss-lb:0.0098, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:19:55.841] iteration:9903  t-loss:0.0140, loss-lb:0.0118, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:19:56.224] iteration:9904  t-loss:0.0155, loss-lb:0.0136, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:19:56.606] iteration:9905  t-loss:0.0182, loss-lb:0.0163, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:19:57.002] iteration:9906  t-loss:0.0523, loss-lb:0.0216, loss-ulb:0.0153, weight:2.00, lr:0.0004
[01:19:57.403] iteration:9907  t-loss:0.0412, loss-lb:0.0271, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:19:57.790] iteration:9908  t-loss:0.0252, loss-lb:0.0127, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:19:58.175] iteration:9909  t-loss:0.0398, loss-lb:0.0121, loss-ulb:0.0139, weight:2.00, lr:0.0004
[01:19:58.567] iteration:9910  t-loss:0.0416, loss-lb:0.0314, loss-ulb:0.0051, weight:2.00, lr:0.0004
[01:19:58.949] iteration:9911  t-loss:0.0473, loss-lb:0.0124, loss-ulb:0.0174, weight:2.00, lr:0.0004
[01:19:59.332] iteration:9912  t-loss:0.0287, loss-lb:0.0143, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:19:59.714] iteration:9913  t-loss:0.0305, loss-lb:0.0290, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:20:00.098] iteration:9914  t-loss:0.0307, loss-lb:0.0150, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:20:00.476] iteration:9915  t-loss:0.0136, loss-lb:0.0111, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:20:00.858] iteration:9916  t-loss:0.0432, loss-lb:0.0236, loss-ulb:0.0098, weight:2.00, lr:0.0004
[01:20:01.243] iteration:9917  t-loss:0.0361, loss-lb:0.0153, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:20:01.621] iteration:9918  t-loss:0.0125, loss-lb:0.0097, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:21:12.338] iteration 9918 : dice_score: 0.897976 best_dice: 0.898600
[01:21:12.338]  <<Test>> - Ep:260  - Dice-S/T:89.34/89.80, Best-S:90.09, Best-T:89.86
[01:21:12.339]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:21:13.563] iteration:9919  t-loss:0.0510, loss-lb:0.0343, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:21:13.965] iteration:9920  t-loss:0.0428, loss-lb:0.0270, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:21:14.353] iteration:9921  t-loss:0.0327, loss-lb:0.0276, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:21:14.737] iteration:9922  t-loss:0.0508, loss-lb:0.0414, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:21:15.119] iteration:9923  t-loss:0.0172, loss-lb:0.0126, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:21:15.505] iteration:9924  t-loss:0.0138, loss-lb:0.0104, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:21:15.896] iteration:9925  t-loss:0.0351, loss-lb:0.0262, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:21:16.278] iteration:9926  t-loss:0.0173, loss-lb:0.0150, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:21:16.658] iteration:9927  t-loss:0.0149, loss-lb:0.0129, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:21:17.061] iteration:9928  t-loss:0.0341, loss-lb:0.0249, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:21:17.447] iteration:9929  t-loss:0.0330, loss-lb:0.0223, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:21:17.829] iteration:9930  t-loss:0.0313, loss-lb:0.0146, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:21:18.215] iteration:9931  t-loss:0.0308, loss-lb:0.0275, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:21:18.601] iteration:9932  t-loss:0.0931, loss-lb:0.0523, loss-ulb:0.0204, weight:2.00, lr:0.0004
[01:21:18.981] iteration:9933  t-loss:0.0264, loss-lb:0.0216, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:21:19.362] iteration:9934  t-loss:0.0354, loss-lb:0.0242, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:21:19.744] iteration:9935  t-loss:0.0243, loss-lb:0.0162, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:21:20.131] iteration:9936  t-loss:0.0313, loss-lb:0.0221, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:21:20.518] iteration:9937  t-loss:0.0449, loss-lb:0.0120, loss-ulb:0.0165, weight:2.00, lr:0.0004
[01:21:20.906] iteration:9938  t-loss:0.0232, loss-lb:0.0183, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:21:21.304] iteration:9939  t-loss:0.0287, loss-lb:0.0142, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:21:21.690] iteration:9940  t-loss:0.0192, loss-lb:0.0156, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:21:22.074] iteration:9941  t-loss:0.0283, loss-lb:0.0200, loss-ulb:0.0042, weight:2.00, lr:0.0004
[01:21:22.455] iteration:9942  t-loss:0.0272, loss-lb:0.0107, loss-ulb:0.0083, weight:2.00, lr:0.0004
[01:21:22.841] iteration:9943  t-loss:0.0397, loss-lb:0.0239, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:21:23.227] iteration:9944  t-loss:0.0426, loss-lb:0.0320, loss-ulb:0.0053, weight:2.00, lr:0.0004
[01:21:23.612] iteration:9945  t-loss:0.0316, loss-lb:0.0134, loss-ulb:0.0091, weight:2.00, lr:0.0004
[01:21:23.996] iteration:9946  t-loss:0.0289, loss-lb:0.0146, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:21:24.378] iteration:9947  t-loss:0.1466, loss-lb:0.1102, loss-ulb:0.0182, weight:2.00, lr:0.0004
[01:21:24.762] iteration:9948  t-loss:0.0490, loss-lb:0.0311, loss-ulb:0.0089, weight:2.00, lr:0.0004
[01:21:25.145] iteration:9949  t-loss:0.0745, loss-lb:0.0628, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:21:25.525] iteration:9950  t-loss:0.0277, loss-lb:0.0203, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:21:25.905] iteration:9951  t-loss:0.0432, loss-lb:0.0255, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:21:26.289] iteration:9952  t-loss:0.0593, loss-lb:0.0301, loss-ulb:0.0146, weight:2.00, lr:0.0004
[01:21:26.674] iteration:9953  t-loss:0.1192, loss-lb:0.0246, loss-ulb:0.0473, weight:2.00, lr:0.0004
[01:21:27.057] iteration:9954  t-loss:0.0336, loss-lb:0.0133, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:21:27.439] iteration:9955  t-loss:0.0307, loss-lb:0.0207, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:21:27.818] iteration:9956  t-loss:0.0180, loss-lb:0.0148, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:21:28.975] iteration:9957  t-loss:0.0306, loss-lb:0.0209, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:21:29.365] iteration:9958  t-loss:0.0234, loss-lb:0.0153, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:21:29.756] iteration:9959  t-loss:0.0279, loss-lb:0.0154, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:21:30.147] iteration:9960  t-loss:0.0397, loss-lb:0.0370, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:21:30.532] iteration:9961  t-loss:0.0292, loss-lb:0.0262, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:21:30.912] iteration:9962  t-loss:0.0213, loss-lb:0.0167, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:21:31.295] iteration:9963  t-loss:0.0341, loss-lb:0.0247, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:21:31.678] iteration:9964  t-loss:0.0302, loss-lb:0.0257, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:21:32.062] iteration:9965  t-loss:0.0378, loss-lb:0.0101, loss-ulb:0.0138, weight:2.00, lr:0.0004
[01:21:32.440] iteration:9966  t-loss:0.0213, loss-lb:0.0141, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:21:32.828] iteration:9967  t-loss:0.0447, loss-lb:0.0352, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:21:33.210] iteration:9968  t-loss:0.0179, loss-lb:0.0109, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:21:33.595] iteration:9969  t-loss:0.0419, loss-lb:0.0288, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:21:33.978] iteration:9970  t-loss:0.0339, loss-lb:0.0179, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:21:34.365] iteration:9971  t-loss:0.0211, loss-lb:0.0106, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:21:34.749] iteration:9972  t-loss:0.0231, loss-lb:0.0135, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:21:35.130] iteration:9973  t-loss:0.0232, loss-lb:0.0194, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:21:35.511] iteration:9974  t-loss:0.0148, loss-lb:0.0122, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:21:35.888] iteration:9975  t-loss:0.0148, loss-lb:0.0131, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:21:36.275] iteration:9976  t-loss:0.0355, loss-lb:0.0327, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:21:36.661] iteration:9977  t-loss:0.0492, loss-lb:0.0149, loss-ulb:0.0171, weight:2.00, lr:0.0004
[01:21:37.048] iteration:9978  t-loss:0.0268, loss-lb:0.0131, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:21:37.440] iteration:9979  t-loss:0.0344, loss-lb:0.0247, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:21:37.824] iteration:9980  t-loss:0.0249, loss-lb:0.0141, loss-ulb:0.0054, weight:2.00, lr:0.0004
[01:21:38.210] iteration:9981  t-loss:0.0293, loss-lb:0.0160, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:21:38.598] iteration:9982  t-loss:0.0359, loss-lb:0.0235, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:21:38.988] iteration:9983  t-loss:0.0462, loss-lb:0.0157, loss-ulb:0.0153, weight:2.00, lr:0.0004
[01:21:39.371] iteration:9984  t-loss:0.0379, loss-lb:0.0172, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:21:39.752] iteration:9985  t-loss:0.0170, loss-lb:0.0122, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:21:40.137] iteration:9986  t-loss:0.0225, loss-lb:0.0087, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:21:40.533] iteration:9987  t-loss:0.0150, loss-lb:0.0133, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:21:40.940] iteration:9988  t-loss:0.0251, loss-lb:0.0107, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:21:41.327] iteration:9989  t-loss:0.0307, loss-lb:0.0243, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:21:41.710] iteration:9990  t-loss:0.0257, loss-lb:0.0139, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:21:42.088] iteration:9991  t-loss:0.0229, loss-lb:0.0173, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:21:42.468] iteration:9992  t-loss:0.0138, loss-lb:0.0114, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:21:42.847] iteration:9993  t-loss:0.0132, loss-lb:0.0100, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:21:43.229] iteration:9994  t-loss:0.0451, loss-lb:0.0328, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:21:44.512] iteration:9995  t-loss:0.0608, loss-lb:0.0584, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:21:44.910] iteration:9996  t-loss:0.0365, loss-lb:0.0293, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:21:45.301] iteration:9997  t-loss:0.0166, loss-lb:0.0144, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:21:45.691] iteration:9998  t-loss:0.0396, loss-lb:0.0212, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:21:46.075] iteration:9999  t-loss:0.0194, loss-lb:0.0145, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:21:46.461] iteration:10000  t-loss:0.0337, loss-lb:0.0225, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:21:46.852] iteration:10001  t-loss:0.0313, loss-lb:0.0270, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:21:47.243] iteration:10002  t-loss:0.0359, loss-lb:0.0211, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:21:47.627] iteration:10003  t-loss:0.0354, loss-lb:0.0316, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:21:48.018] iteration:10004  t-loss:0.0484, loss-lb:0.0295, loss-ulb:0.0094, weight:2.00, lr:0.0004
[01:21:48.405] iteration:10005  t-loss:0.0227, loss-lb:0.0190, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:21:48.789] iteration:10006  t-loss:0.0505, loss-lb:0.0365, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:21:49.171] iteration:10007  t-loss:0.0199, loss-lb:0.0169, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:21:49.556] iteration:10008  t-loss:0.0401, loss-lb:0.0250, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:21:49.935] iteration:10009  t-loss:0.0187, loss-lb:0.0160, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:21:50.319] iteration:10010  t-loss:0.0297, loss-lb:0.0256, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:21:50.701] iteration:10011  t-loss:0.0294, loss-lb:0.0168, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:21:51.082] iteration:10012  t-loss:0.0186, loss-lb:0.0105, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:21:51.468] iteration:10013  t-loss:0.0284, loss-lb:0.0143, loss-ulb:0.0071, weight:2.00, lr:0.0004
[01:21:51.853] iteration:10014  t-loss:0.0210, loss-lb:0.0116, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:21:52.239] iteration:10015  t-loss:0.0511, loss-lb:0.0399, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:21:52.629] iteration:10016  t-loss:0.0357, loss-lb:0.0239, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:21:53.009] iteration:10017  t-loss:0.0242, loss-lb:0.0219, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:21:53.389] iteration:10018  t-loss:0.0270, loss-lb:0.0247, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:21:53.770] iteration:10019  t-loss:0.0376, loss-lb:0.0169, loss-ulb:0.0104, weight:2.00, lr:0.0004
[01:21:54.150] iteration:10020  t-loss:0.0451, loss-lb:0.0405, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:21:54.530] iteration:10021  t-loss:0.0329, loss-lb:0.0112, loss-ulb:0.0109, weight:2.00, lr:0.0004
[01:21:54.916] iteration:10022  t-loss:0.0393, loss-lb:0.0288, loss-ulb:0.0052, weight:2.00, lr:0.0004
[01:21:55.296] iteration:10023  t-loss:0.0243, loss-lb:0.0133, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:21:55.678] iteration:10024  t-loss:0.0438, loss-lb:0.0255, loss-ulb:0.0091, weight:2.00, lr:0.0004
[01:21:56.068] iteration:10025  t-loss:0.0285, loss-lb:0.0262, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:21:56.462] iteration:10026  t-loss:0.0346, loss-lb:0.0311, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:21:56.853] iteration:10027  t-loss:0.0436, loss-lb:0.0394, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:21:57.243] iteration:10028  t-loss:0.0231, loss-lb:0.0212, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:21:57.624] iteration:10029  t-loss:0.0190, loss-lb:0.0155, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:21:58.004] iteration:10030  t-loss:0.0392, loss-lb:0.0207, loss-ulb:0.0093, weight:2.00, lr:0.0004
[01:21:58.389] iteration:10031  t-loss:0.0275, loss-lb:0.0131, loss-ulb:0.0072, weight:2.00, lr:0.0004
[01:21:58.773] iteration:10032  t-loss:0.0340, loss-lb:0.0287, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:22:00.112] iteration:10033  t-loss:0.0280, loss-lb:0.0250, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:22:00.528] iteration:10034  t-loss:0.0276, loss-lb:0.0135, loss-ulb:0.0071, weight:2.00, lr:0.0004
[01:22:00.926] iteration:10035  t-loss:0.0398, loss-lb:0.0283, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:22:01.311] iteration:10036  t-loss:0.0139, loss-lb:0.0115, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:22:01.701] iteration:10037  t-loss:0.0346, loss-lb:0.0282, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:22:02.084] iteration:10038  t-loss:0.0297, loss-lb:0.0284, loss-ulb:0.0006, weight:2.00, lr:0.0004
[01:22:02.472] iteration:10039  t-loss:0.0293, loss-lb:0.0099, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:22:02.858] iteration:10040  t-loss:0.0240, loss-lb:0.0150, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:22:03.242] iteration:10041  t-loss:0.0277, loss-lb:0.0130, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:22:03.628] iteration:10042  t-loss:0.0269, loss-lb:0.0134, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:22:04.011] iteration:10043  t-loss:0.0147, loss-lb:0.0124, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:22:04.399] iteration:10044  t-loss:0.0405, loss-lb:0.0161, loss-ulb:0.0122, weight:2.00, lr:0.0004
[01:22:04.785] iteration:10045  t-loss:0.0509, loss-lb:0.0410, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:22:05.164] iteration:10046  t-loss:0.0148, loss-lb:0.0126, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:22:05.547] iteration:10047  t-loss:0.0139, loss-lb:0.0110, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:22:05.935] iteration:10048  t-loss:0.0472, loss-lb:0.0325, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:22:06.317] iteration:10049  t-loss:0.0491, loss-lb:0.0436, loss-ulb:0.0028, weight:2.00, lr:0.0004
[01:22:06.706] iteration:10050  t-loss:0.0309, loss-lb:0.0094, loss-ulb:0.0107, weight:2.00, lr:0.0004
[01:22:07.083] iteration:10051  t-loss:0.0174, loss-lb:0.0139, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:22:07.467] iteration:10052  t-loss:0.0280, loss-lb:0.0246, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:22:07.854] iteration:10053  t-loss:0.0300, loss-lb:0.0146, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:22:08.237] iteration:10054  t-loss:0.0446, loss-lb:0.0218, loss-ulb:0.0114, weight:2.00, lr:0.0004
[01:22:08.616] iteration:10055  t-loss:0.0366, loss-lb:0.0255, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:22:08.998] iteration:10056  t-loss:0.0159, loss-lb:0.0140, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:22:09.383] iteration:10057  t-loss:0.0248, loss-lb:0.0228, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:22:09.764] iteration:10058  t-loss:0.0252, loss-lb:0.0242, loss-ulb:0.0005, weight:2.00, lr:0.0004
[01:22:10.153] iteration:10059  t-loss:0.0324, loss-lb:0.0210, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:22:10.535] iteration:10060  t-loss:0.0433, loss-lb:0.0179, loss-ulb:0.0127, weight:2.00, lr:0.0004
[01:22:10.917] iteration:10061  t-loss:0.0271, loss-lb:0.0125, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:22:11.299] iteration:10062  t-loss:0.0161, loss-lb:0.0143, loss-ulb:0.0009, weight:2.00, lr:0.0004
[01:22:11.691] iteration:10063  t-loss:0.0185, loss-lb:0.0144, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:22:12.085] iteration:10064  t-loss:0.0341, loss-lb:0.0136, loss-ulb:0.0102, weight:2.00, lr:0.0004
[01:22:12.463] iteration:10065  t-loss:0.0181, loss-lb:0.0137, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:22:12.843] iteration:10066  t-loss:0.0318, loss-lb:0.0139, loss-ulb:0.0090, weight:2.00, lr:0.0004
[01:22:13.225] iteration:10067  t-loss:0.0620, loss-lb:0.0428, loss-ulb:0.0096, weight:2.00, lr:0.0004
[01:22:13.605] iteration:10068  t-loss:0.0589, loss-lb:0.0339, loss-ulb:0.0125, weight:2.00, lr:0.0004
[01:22:13.987] iteration:10069  t-loss:0.0326, loss-lb:0.0264, loss-ulb:0.0031, weight:2.00, lr:0.0004
[01:22:14.369] iteration:10070  t-loss:0.0272, loss-lb:0.0153, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:23:19.776] iteration 10070 : dice_score: 0.896848 best_dice: 0.898600
[01:23:19.776]  <<Test>> - Ep:264  - Dice-S/T:89.49/89.68, Best-S:90.09, Best-T:89.86
[01:23:19.776]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:23:21.010] iteration:10071  t-loss:0.0420, loss-lb:0.0257, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:23:21.401] iteration:10072  t-loss:0.0739, loss-lb:0.0138, loss-ulb:0.0300, weight:2.00, lr:0.0004
[01:23:21.803] iteration:10073  t-loss:0.0273, loss-lb:0.0113, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:23:22.193] iteration:10074  t-loss:0.0471, loss-lb:0.0177, loss-ulb:0.0147, weight:2.00, lr:0.0004
[01:23:22.577] iteration:10075  t-loss:0.0432, loss-lb:0.0096, loss-ulb:0.0168, weight:2.00, lr:0.0004
[01:23:22.959] iteration:10076  t-loss:0.0262, loss-lb:0.0166, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:23:23.339] iteration:10077  t-loss:0.0298, loss-lb:0.0099, loss-ulb:0.0099, weight:2.00, lr:0.0004
[01:23:23.722] iteration:10078  t-loss:0.0396, loss-lb:0.0261, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:23:24.107] iteration:10079  t-loss:0.0159, loss-lb:0.0120, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:23:24.508] iteration:10080  t-loss:0.0170, loss-lb:0.0118, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:23:24.910] iteration:10081  t-loss:0.0273, loss-lb:0.0242, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:23:25.296] iteration:10082  t-loss:0.0418, loss-lb:0.0242, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:23:25.672] iteration:10083  t-loss:0.0207, loss-lb:0.0172, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:23:26.058] iteration:10084  t-loss:0.0383, loss-lb:0.0284, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:23:26.445] iteration:10085  t-loss:0.0555, loss-lb:0.0279, loss-ulb:0.0138, weight:2.00, lr:0.0004
[01:23:26.828] iteration:10086  t-loss:0.0309, loss-lb:0.0276, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:23:27.219] iteration:10087  t-loss:0.0341, loss-lb:0.0249, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:23:27.611] iteration:10088  t-loss:0.0235, loss-lb:0.0196, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:23:27.992] iteration:10089  t-loss:0.0193, loss-lb:0.0111, loss-ulb:0.0041, weight:2.00, lr:0.0004
[01:23:28.378] iteration:10090  t-loss:0.0452, loss-lb:0.0199, loss-ulb:0.0127, weight:2.00, lr:0.0004
[01:23:28.761] iteration:10091  t-loss:0.0222, loss-lb:0.0132, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:23:29.145] iteration:10092  t-loss:0.0271, loss-lb:0.0137, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:23:29.535] iteration:10093  t-loss:0.0399, loss-lb:0.0249, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:23:29.924] iteration:10094  t-loss:0.0287, loss-lb:0.0229, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:23:30.331] iteration:10095  t-loss:0.0362, loss-lb:0.0137, loss-ulb:0.0113, weight:2.00, lr:0.0004
[01:23:30.713] iteration:10096  t-loss:0.0530, loss-lb:0.0144, loss-ulb:0.0193, weight:2.00, lr:0.0004
[01:23:31.094] iteration:10097  t-loss:0.0174, loss-lb:0.0124, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:23:31.484] iteration:10098  t-loss:0.0246, loss-lb:0.0115, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:23:31.866] iteration:10099  t-loss:0.0366, loss-lb:0.0132, loss-ulb:0.0117, weight:2.00, lr:0.0004
[01:23:32.252] iteration:10100  t-loss:0.0157, loss-lb:0.0144, loss-ulb:0.0007, weight:2.00, lr:0.0004
[01:23:32.643] iteration:10101  t-loss:0.0271, loss-lb:0.0245, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:23:33.026] iteration:10102  t-loss:0.0241, loss-lb:0.0221, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:23:33.407] iteration:10103  t-loss:0.0303, loss-lb:0.0279, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:23:33.790] iteration:10104  t-loss:0.0328, loss-lb:0.0206, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:23:34.171] iteration:10105  t-loss:0.0280, loss-lb:0.0159, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:23:34.549] iteration:10106  t-loss:0.0327, loss-lb:0.0177, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:23:34.933] iteration:10107  t-loss:0.0296, loss-lb:0.0243, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:23:35.314] iteration:10108  t-loss:0.0259, loss-lb:0.0238, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:23:36.449] iteration:10109  t-loss:0.0376, loss-lb:0.0254, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:23:36.836] iteration:10110  t-loss:0.0491, loss-lb:0.0421, loss-ulb:0.0035, weight:2.00, lr:0.0004
[01:23:37.224] iteration:10111  t-loss:0.0569, loss-lb:0.0374, loss-ulb:0.0098, weight:2.00, lr:0.0004
[01:23:37.608] iteration:10112  t-loss:0.0208, loss-lb:0.0154, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:23:38.000] iteration:10113  t-loss:0.0385, loss-lb:0.0212, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:23:38.378] iteration:10114  t-loss:0.0327, loss-lb:0.0163, loss-ulb:0.0082, weight:2.00, lr:0.0004
[01:23:38.760] iteration:10115  t-loss:0.0325, loss-lb:0.0155, loss-ulb:0.0085, weight:2.00, lr:0.0004
[01:23:39.148] iteration:10116  t-loss:0.0563, loss-lb:0.0381, loss-ulb:0.0091, weight:2.00, lr:0.0004
[01:23:39.535] iteration:10117  t-loss:0.0216, loss-lb:0.0126, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:23:39.926] iteration:10118  t-loss:0.0236, loss-lb:0.0122, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:23:40.319] iteration:10119  t-loss:0.0176, loss-lb:0.0150, loss-ulb:0.0013, weight:2.00, lr:0.0004
[01:23:40.711] iteration:10120  t-loss:0.0359, loss-lb:0.0221, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:23:41.093] iteration:10121  t-loss:0.0305, loss-lb:0.0137, loss-ulb:0.0084, weight:2.00, lr:0.0004
[01:23:41.479] iteration:10122  t-loss:0.0695, loss-lb:0.0365, loss-ulb:0.0165, weight:2.00, lr:0.0004
[01:23:41.865] iteration:10123  t-loss:0.0224, loss-lb:0.0184, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:23:42.254] iteration:10124  t-loss:0.0210, loss-lb:0.0118, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:23:42.643] iteration:10125  t-loss:0.0315, loss-lb:0.0124, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:23:43.035] iteration:10126  t-loss:0.0356, loss-lb:0.0297, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:23:43.420] iteration:10127  t-loss:0.0298, loss-lb:0.0143, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:23:43.809] iteration:10128  t-loss:0.0472, loss-lb:0.0299, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:23:44.196] iteration:10129  t-loss:0.0165, loss-lb:0.0142, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:23:44.585] iteration:10130  t-loss:0.0315, loss-lb:0.0164, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:23:44.977] iteration:10131  t-loss:0.0377, loss-lb:0.0282, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:23:45.367] iteration:10132  t-loss:0.0384, loss-lb:0.0198, loss-ulb:0.0093, weight:2.00, lr:0.0004
[01:23:45.753] iteration:10133  t-loss:0.0166, loss-lb:0.0119, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:23:46.139] iteration:10134  t-loss:0.0397, loss-lb:0.0280, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:23:46.524] iteration:10135  t-loss:0.0248, loss-lb:0.0113, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:23:46.910] iteration:10136  t-loss:0.0349, loss-lb:0.0252, loss-ulb:0.0048, weight:2.00, lr:0.0004
[01:23:47.294] iteration:10137  t-loss:0.0390, loss-lb:0.0258, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:23:47.676] iteration:10138  t-loss:0.0154, loss-lb:0.0114, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:23:48.071] iteration:10139  t-loss:0.0378, loss-lb:0.0245, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:23:48.465] iteration:10140  t-loss:0.0194, loss-lb:0.0178, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:23:48.852] iteration:10141  t-loss:0.0320, loss-lb:0.0168, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:23:49.247] iteration:10142  t-loss:0.0556, loss-lb:0.0286, loss-ulb:0.0135, weight:2.00, lr:0.0004
[01:23:49.638] iteration:10143  t-loss:0.0258, loss-lb:0.0096, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:23:50.021] iteration:10144  t-loss:0.0306, loss-lb:0.0146, loss-ulb:0.0080, weight:2.00, lr:0.0004
[01:23:50.404] iteration:10145  t-loss:0.0150, loss-lb:0.0127, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:23:50.791] iteration:10146  t-loss:0.0643, loss-lb:0.0517, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:23:52.176] iteration:10147  t-loss:0.0315, loss-lb:0.0205, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:23:52.565] iteration:10148  t-loss:0.0423, loss-lb:0.0399, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:23:52.945] iteration:10149  t-loss:0.0314, loss-lb:0.0191, loss-ulb:0.0062, weight:2.00, lr:0.0004
[01:23:53.331] iteration:10150  t-loss:0.0180, loss-lb:0.0153, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:23:53.723] iteration:10151  t-loss:0.0312, loss-lb:0.0223, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:23:54.108] iteration:10152  t-loss:0.0338, loss-lb:0.0322, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:23:54.490] iteration:10153  t-loss:0.0380, loss-lb:0.0332, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:23:54.879] iteration:10154  t-loss:0.0483, loss-lb:0.0238, loss-ulb:0.0122, weight:2.00, lr:0.0004
[01:23:55.265] iteration:10155  t-loss:0.0654, loss-lb:0.0258, loss-ulb:0.0198, weight:2.00, lr:0.0004
[01:23:55.659] iteration:10156  t-loss:0.0321, loss-lb:0.0228, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:23:56.057] iteration:10157  t-loss:0.0749, loss-lb:0.0539, loss-ulb:0.0105, weight:2.00, lr:0.0004
[01:23:56.447] iteration:10158  t-loss:0.0389, loss-lb:0.0276, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:23:56.829] iteration:10159  t-loss:0.0266, loss-lb:0.0246, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:23:57.215] iteration:10160  t-loss:0.0459, loss-lb:0.0345, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:23:57.593] iteration:10161  t-loss:0.0157, loss-lb:0.0127, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:23:57.977] iteration:10162  t-loss:0.0159, loss-lb:0.0137, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:23:58.367] iteration:10163  t-loss:0.0187, loss-lb:0.0166, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:23:58.766] iteration:10164  t-loss:0.0475, loss-lb:0.0289, loss-ulb:0.0093, weight:2.00, lr:0.0004
[01:23:59.155] iteration:10165  t-loss:0.0269, loss-lb:0.0155, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:23:59.543] iteration:10166  t-loss:0.0230, loss-lb:0.0191, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:23:59.924] iteration:10167  t-loss:0.0240, loss-lb:0.0143, loss-ulb:0.0049, weight:2.00, lr:0.0004
[01:24:00.313] iteration:10168  t-loss:0.0304, loss-lb:0.0275, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:24:00.696] iteration:10169  t-loss:0.0487, loss-lb:0.0376, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:24:01.077] iteration:10170  t-loss:0.0173, loss-lb:0.0135, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:24:01.465] iteration:10171  t-loss:0.0180, loss-lb:0.0142, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:24:01.849] iteration:10172  t-loss:0.0313, loss-lb:0.0131, loss-ulb:0.0091, weight:2.00, lr:0.0004
[01:24:02.232] iteration:10173  t-loss:0.0736, loss-lb:0.0685, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:24:02.619] iteration:10174  t-loss:0.0395, loss-lb:0.0250, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:24:02.996] iteration:10175  t-loss:0.0187, loss-lb:0.0110, loss-ulb:0.0038, weight:2.00, lr:0.0004
[01:24:03.389] iteration:10176  t-loss:0.0195, loss-lb:0.0115, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:24:03.776] iteration:10177  t-loss:0.0487, loss-lb:0.0311, loss-ulb:0.0088, weight:2.00, lr:0.0004
[01:24:04.164] iteration:10178  t-loss:0.0200, loss-lb:0.0107, loss-ulb:0.0047, weight:2.00, lr:0.0004
[01:24:04.553] iteration:10179  t-loss:0.0372, loss-lb:0.0351, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:24:04.942] iteration:10180  t-loss:0.0292, loss-lb:0.0259, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:24:05.328] iteration:10181  t-loss:0.0266, loss-lb:0.0127, loss-ulb:0.0070, weight:2.00, lr:0.0004
[01:24:05.712] iteration:10182  t-loss:0.0423, loss-lb:0.0212, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:24:06.096] iteration:10183  t-loss:0.0487, loss-lb:0.0365, loss-ulb:0.0061, weight:2.00, lr:0.0004
[01:24:06.493] iteration:10184  t-loss:0.0338, loss-lb:0.0189, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:24:08.112] iteration:10185  t-loss:0.0180, loss-lb:0.0160, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:24:08.504] iteration:10186  t-loss:0.0238, loss-lb:0.0215, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:24:08.894] iteration:10187  t-loss:0.0284, loss-lb:0.0213, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:24:09.302] iteration:10188  t-loss:0.0386, loss-lb:0.0192, loss-ulb:0.0097, weight:2.00, lr:0.0004
[01:24:09.693] iteration:10189  t-loss:0.0461, loss-lb:0.0256, loss-ulb:0.0103, weight:2.00, lr:0.0004
[01:24:10.080] iteration:10190  t-loss:0.0293, loss-lb:0.0131, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:24:10.462] iteration:10191  t-loss:0.0487, loss-lb:0.0339, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:24:10.850] iteration:10192  t-loss:0.0296, loss-lb:0.0233, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:24:11.244] iteration:10193  t-loss:0.0314, loss-lb:0.0187, loss-ulb:0.0064, weight:2.00, lr:0.0004
[01:24:11.639] iteration:10194  t-loss:0.0232, loss-lb:0.0212, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:24:12.023] iteration:10195  t-loss:0.0184, loss-lb:0.0130, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:24:12.416] iteration:10196  t-loss:0.0460, loss-lb:0.0354, loss-ulb:0.0053, weight:2.00, lr:0.0004
[01:24:12.799] iteration:10197  t-loss:0.0348, loss-lb:0.0331, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:24:13.184] iteration:10198  t-loss:0.0267, loss-lb:0.0246, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:24:13.574] iteration:10199  t-loss:0.0759, loss-lb:0.0148, loss-ulb:0.0305, weight:2.00, lr:0.0004
[01:24:13.967] iteration:10200  t-loss:0.0317, loss-lb:0.0128, loss-ulb:0.0095, weight:2.00, lr:0.0004
[01:24:14.357] iteration:10201  t-loss:0.0295, loss-lb:0.0227, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:24:14.740] iteration:10202  t-loss:0.0289, loss-lb:0.0136, loss-ulb:0.0076, weight:2.00, lr:0.0004
[01:24:15.132] iteration:10203  t-loss:0.0513, loss-lb:0.0356, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:24:15.517] iteration:10204  t-loss:0.0249, loss-lb:0.0111, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:24:15.903] iteration:10205  t-loss:0.0143, loss-lb:0.0118, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:24:16.287] iteration:10206  t-loss:0.0360, loss-lb:0.0315, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:24:16.672] iteration:10207  t-loss:0.0301, loss-lb:0.0137, loss-ulb:0.0082, weight:2.00, lr:0.0004
[01:24:17.064] iteration:10208  t-loss:0.0277, loss-lb:0.0254, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:24:17.445] iteration:10209  t-loss:0.0415, loss-lb:0.0177, loss-ulb:0.0119, weight:2.00, lr:0.0004
[01:24:17.829] iteration:10210  t-loss:0.0653, loss-lb:0.0328, loss-ulb:0.0163, weight:2.00, lr:0.0004
[01:24:18.214] iteration:10211  t-loss:0.0379, loss-lb:0.0260, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:24:18.595] iteration:10212  t-loss:0.0209, loss-lb:0.0131, loss-ulb:0.0039, weight:2.00, lr:0.0004
[01:24:18.978] iteration:10213  t-loss:0.0257, loss-lb:0.0226, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:24:19.366] iteration:10214  t-loss:0.0179, loss-lb:0.0127, loss-ulb:0.0026, weight:2.00, lr:0.0004
[01:24:19.767] iteration:10215  t-loss:0.0329, loss-lb:0.0228, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:24:20.151] iteration:10216  t-loss:0.0314, loss-lb:0.0273, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:24:20.532] iteration:10217  t-loss:0.0412, loss-lb:0.0263, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:24:20.905] iteration:10218  t-loss:0.0217, loss-lb:0.0146, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:24:21.282] iteration:10219  t-loss:0.0395, loss-lb:0.0171, loss-ulb:0.0112, weight:2.00, lr:0.0004
[01:24:21.662] iteration:10220  t-loss:0.0478, loss-lb:0.0210, loss-ulb:0.0134, weight:2.00, lr:0.0004
[01:24:22.046] iteration:10221  t-loss:0.0277, loss-lb:0.0237, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:24:22.441] iteration:10222  t-loss:0.0178, loss-lb:0.0140, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:25:30.909] iteration 10222 : dice_score: 0.899841 best_dice: 0.899800
[01:25:30.909]  <<Test>> - Ep:268  - Dice-S/T:89.62/89.98, Best-S:90.09, Best-T:89.98
[01:25:30.909]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:25:32.198] iteration:10223  t-loss:0.0289, loss-lb:0.0141, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:25:32.602] iteration:10224  t-loss:0.0294, loss-lb:0.0245, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:25:32.989] iteration:10225  t-loss:0.0373, loss-lb:0.0228, loss-ulb:0.0073, weight:2.00, lr:0.0004
[01:25:33.369] iteration:10226  t-loss:0.0390, loss-lb:0.0136, loss-ulb:0.0127, weight:2.00, lr:0.0004
[01:25:33.751] iteration:10227  t-loss:0.0231, loss-lb:0.0130, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:25:34.140] iteration:10228  t-loss:0.0336, loss-lb:0.0202, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:25:34.527] iteration:10229  t-loss:0.0191, loss-lb:0.0106, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:25:34.905] iteration:10230  t-loss:0.0247, loss-lb:0.0218, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:25:35.287] iteration:10231  t-loss:0.0297, loss-lb:0.0277, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:25:35.672] iteration:10232  t-loss:0.0259, loss-lb:0.0144, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:25:36.058] iteration:10233  t-loss:0.0293, loss-lb:0.0257, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:25:36.459] iteration:10234  t-loss:0.0240, loss-lb:0.0218, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:25:36.847] iteration:10235  t-loss:0.0185, loss-lb:0.0147, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:25:37.234] iteration:10236  t-loss:0.0201, loss-lb:0.0128, loss-ulb:0.0037, weight:2.00, lr:0.0004
[01:25:37.620] iteration:10237  t-loss:0.0643, loss-lb:0.0119, loss-ulb:0.0262, weight:2.00, lr:0.0004
[01:25:38.006] iteration:10238  t-loss:0.1106, loss-lb:0.0445, loss-ulb:0.0331, weight:2.00, lr:0.0004
[01:25:38.389] iteration:10239  t-loss:0.0360, loss-lb:0.0270, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:25:38.771] iteration:10240  t-loss:0.0217, loss-lb:0.0203, loss-ulb:0.0007, weight:2.00, lr:0.0004
[01:25:39.153] iteration:10241  t-loss:0.0275, loss-lb:0.0262, loss-ulb:0.0006, weight:2.00, lr:0.0004
[01:25:39.541] iteration:10242  t-loss:0.0469, loss-lb:0.0319, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:25:39.925] iteration:10243  t-loss:0.0394, loss-lb:0.0268, loss-ulb:0.0063, weight:2.00, lr:0.0004
[01:25:40.309] iteration:10244  t-loss:0.0121, loss-lb:0.0087, loss-ulb:0.0017, weight:2.00, lr:0.0004
[01:25:40.692] iteration:10245  t-loss:0.0223, loss-lb:0.0113, loss-ulb:0.0055, weight:2.00, lr:0.0004
[01:25:41.076] iteration:10246  t-loss:0.0205, loss-lb:0.0116, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:25:41.464] iteration:10247  t-loss:0.0491, loss-lb:0.0290, loss-ulb:0.0101, weight:2.00, lr:0.0004
[01:25:41.844] iteration:10248  t-loss:0.0190, loss-lb:0.0117, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:25:42.225] iteration:10249  t-loss:0.0149, loss-lb:0.0117, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:25:42.612] iteration:10250  t-loss:0.0385, loss-lb:0.0223, loss-ulb:0.0081, weight:2.00, lr:0.0004
[01:25:42.995] iteration:10251  t-loss:0.0502, loss-lb:0.0135, loss-ulb:0.0184, weight:2.00, lr:0.0004
[01:25:43.377] iteration:10252  t-loss:0.0179, loss-lb:0.0138, loss-ulb:0.0021, weight:2.00, lr:0.0004
[01:25:43.759] iteration:10253  t-loss:0.0270, loss-lb:0.0256, loss-ulb:0.0007, weight:2.00, lr:0.0004
[01:25:44.140] iteration:10254  t-loss:0.0893, loss-lb:0.0258, loss-ulb:0.0317, weight:2.00, lr:0.0004
[01:25:44.520] iteration:10255  t-loss:0.0263, loss-lb:0.0151, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:25:44.896] iteration:10256  t-loss:0.0221, loss-lb:0.0190, loss-ulb:0.0015, weight:2.00, lr:0.0004
[01:25:45.275] iteration:10257  t-loss:0.0363, loss-lb:0.0208, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:25:45.656] iteration:10258  t-loss:0.0360, loss-lb:0.0293, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:25:46.036] iteration:10259  t-loss:0.0464, loss-lb:0.0399, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:25:46.414] iteration:10260  t-loss:0.0319, loss-lb:0.0282, loss-ulb:0.0018, weight:2.00, lr:0.0004
[01:25:47.685] iteration:10261  t-loss:0.0209, loss-lb:0.0151, loss-ulb:0.0029, weight:2.00, lr:0.0004
[01:25:48.081] iteration:10262  t-loss:0.0513, loss-lb:0.0150, loss-ulb:0.0182, weight:2.00, lr:0.0004
[01:25:48.466] iteration:10263  t-loss:0.0214, loss-lb:0.0146, loss-ulb:0.0034, weight:2.00, lr:0.0004
[01:25:48.851] iteration:10264  t-loss:0.0467, loss-lb:0.0330, loss-ulb:0.0069, weight:2.00, lr:0.0004
[01:25:49.234] iteration:10265  t-loss:0.0218, loss-lb:0.0119, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:25:49.618] iteration:10266  t-loss:0.0433, loss-lb:0.0300, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:25:49.996] iteration:10267  t-loss:0.0364, loss-lb:0.0129, loss-ulb:0.0117, weight:2.00, lr:0.0004
[01:25:50.376] iteration:10268  t-loss:0.0290, loss-lb:0.0140, loss-ulb:0.0075, weight:2.00, lr:0.0004
[01:25:50.758] iteration:10269  t-loss:0.0391, loss-lb:0.0162, loss-ulb:0.0114, weight:2.00, lr:0.0004
[01:25:51.140] iteration:10270  t-loss:0.0226, loss-lb:0.0177, loss-ulb:0.0025, weight:2.00, lr:0.0004
[01:25:51.532] iteration:10271  t-loss:0.0209, loss-lb:0.0180, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:25:51.916] iteration:10272  t-loss:0.0485, loss-lb:0.0354, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:25:52.300] iteration:10273  t-loss:0.0430, loss-lb:0.0166, loss-ulb:0.0132, weight:2.00, lr:0.0004
[01:25:52.683] iteration:10274  t-loss:0.0263, loss-lb:0.0134, loss-ulb:0.0065, weight:2.00, lr:0.0004
[01:25:53.070] iteration:10275  t-loss:0.0241, loss-lb:0.0141, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:25:53.463] iteration:10276  t-loss:0.0661, loss-lb:0.0427, loss-ulb:0.0117, weight:2.00, lr:0.0004
[01:25:53.848] iteration:10277  t-loss:0.0228, loss-lb:0.0164, loss-ulb:0.0032, weight:2.00, lr:0.0004
[01:25:54.228] iteration:10278  t-loss:0.0296, loss-lb:0.0216, loss-ulb:0.0040, weight:2.00, lr:0.0004
[01:25:54.613] iteration:10279  t-loss:0.0188, loss-lb:0.0172, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:25:55.001] iteration:10280  t-loss:0.0459, loss-lb:0.0304, loss-ulb:0.0077, weight:2.00, lr:0.0004
[01:25:55.388] iteration:10281  t-loss:0.0468, loss-lb:0.0230, loss-ulb:0.0119, weight:2.00, lr:0.0004
[01:25:55.778] iteration:10282  t-loss:0.0399, loss-lb:0.0300, loss-ulb:0.0050, weight:2.00, lr:0.0004
[01:25:56.163] iteration:10283  t-loss:0.0329, loss-lb:0.0213, loss-ulb:0.0058, weight:2.00, lr:0.0004
[01:25:56.557] iteration:10284  t-loss:0.0325, loss-lb:0.0151, loss-ulb:0.0087, weight:2.00, lr:0.0004
[01:25:56.958] iteration:10285  t-loss:0.0288, loss-lb:0.0259, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:25:57.353] iteration:10286  t-loss:0.0295, loss-lb:0.0174, loss-ulb:0.0060, weight:2.00, lr:0.0004
[01:25:57.747] iteration:10287  t-loss:0.0283, loss-lb:0.0147, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:25:58.130] iteration:10288  t-loss:0.0637, loss-lb:0.0592, loss-ulb:0.0023, weight:2.00, lr:0.0004
[01:25:58.516] iteration:10289  t-loss:0.0307, loss-lb:0.0252, loss-ulb:0.0027, weight:2.00, lr:0.0004
[01:25:58.905] iteration:10290  t-loss:0.0381, loss-lb:0.0360, loss-ulb:0.0011, weight:2.00, lr:0.0004
[01:25:59.285] iteration:10291  t-loss:0.0192, loss-lb:0.0144, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:25:59.664] iteration:10292  t-loss:0.0220, loss-lb:0.0182, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:26:00.048] iteration:10293  t-loss:0.0509, loss-lb:0.0148, loss-ulb:0.0180, weight:2.00, lr:0.0004
[01:26:00.428] iteration:10294  t-loss:0.0417, loss-lb:0.0304, loss-ulb:0.0056, weight:2.00, lr:0.0004
[01:26:00.813] iteration:10295  t-loss:0.0445, loss-lb:0.0289, loss-ulb:0.0078, weight:2.00, lr:0.0004
[01:26:01.194] iteration:10296  t-loss:0.0328, loss-lb:0.0162, loss-ulb:0.0083, weight:2.00, lr:0.0004
[01:26:01.575] iteration:10297  t-loss:0.0225, loss-lb:0.0206, loss-ulb:0.0010, weight:2.00, lr:0.0004
[01:26:01.958] iteration:10298  t-loss:0.0270, loss-lb:0.0111, loss-ulb:0.0079, weight:2.00, lr:0.0004
[01:26:03.402] iteration:10299  t-loss:0.0243, loss-lb:0.0154, loss-ulb:0.0044, weight:2.00, lr:0.0004
[01:26:03.792] iteration:10300  t-loss:0.1249, loss-lb:0.1102, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:26:04.172] iteration:10301  t-loss:0.0432, loss-lb:0.0391, loss-ulb:0.0020, weight:2.00, lr:0.0004
[01:26:04.558] iteration:10302  t-loss:0.0288, loss-lb:0.0151, loss-ulb:0.0068, weight:2.00, lr:0.0004
[01:26:04.946] iteration:10303  t-loss:0.0508, loss-lb:0.0278, loss-ulb:0.0115, weight:2.00, lr:0.0004
[01:26:05.328] iteration:10304  t-loss:0.0173, loss-lb:0.0141, loss-ulb:0.0016, weight:2.00, lr:0.0004
[01:26:05.727] iteration:10305  t-loss:0.0281, loss-lb:0.0194, loss-ulb:0.0043, weight:2.00, lr:0.0004
[01:26:06.116] iteration:10306  t-loss:0.0192, loss-lb:0.0143, loss-ulb:0.0024, weight:2.00, lr:0.0004
[01:26:06.502] iteration:10307  t-loss:0.0142, loss-lb:0.0114, loss-ulb:0.0014, weight:2.00, lr:0.0004
[01:26:06.885] iteration:10308  t-loss:0.0522, loss-lb:0.0311, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:26:07.272] iteration:10309  t-loss:0.0348, loss-lb:0.0215, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:26:07.665] iteration:10310  t-loss:0.0317, loss-lb:0.0228, loss-ulb:0.0045, weight:2.00, lr:0.0004
[01:26:08.055] iteration:10311  t-loss:0.0224, loss-lb:0.0201, loss-ulb:0.0012, weight:2.00, lr:0.0004
[01:26:08.439] iteration:10312  t-loss:0.0341, loss-lb:0.0227, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:26:08.826] iteration:10313  t-loss:0.0284, loss-lb:0.0171, loss-ulb:0.0057, weight:2.00, lr:0.0004
[01:26:09.206] iteration:10314  t-loss:0.0270, loss-lb:0.0123, loss-ulb:0.0074, weight:2.00, lr:0.0004
[01:26:09.584] iteration:10315  t-loss:0.0170, loss-lb:0.0133, loss-ulb:0.0019, weight:2.00, lr:0.0004
[01:26:09.966] iteration:10316  t-loss:0.0518, loss-lb:0.0259, loss-ulb:0.0129, weight:2.00, lr:0.0004
[01:26:10.346] iteration:10317  t-loss:0.0296, loss-lb:0.0252, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:26:10.727] iteration:10318  t-loss:0.0314, loss-lb:0.0131, loss-ulb:0.0092, weight:2.00, lr:0.0004
[01:26:11.112] iteration:10319  t-loss:0.0343, loss-lb:0.0270, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:26:11.505] iteration:10320  t-loss:0.0461, loss-lb:0.0283, loss-ulb:0.0089, weight:2.00, lr:0.0004
[01:26:11.895] iteration:10321  t-loss:0.0318, loss-lb:0.0225, loss-ulb:0.0046, weight:2.00, lr:0.0004
[01:26:12.307] iteration:10322  t-loss:0.0248, loss-lb:0.0115, loss-ulb:0.0066, weight:2.00, lr:0.0004
[01:26:12.702] iteration:10323  t-loss:0.0540, loss-lb:0.0407, loss-ulb:0.0067, weight:2.00, lr:0.0004
[01:26:13.086] iteration:10324  t-loss:0.0143, loss-lb:0.0127, loss-ulb:0.0008, weight:2.00, lr:0.0004
[01:26:13.471] iteration:10325  t-loss:0.0317, loss-lb:0.0105, loss-ulb:0.0106, weight:2.00, lr:0.0004
[01:26:13.852] iteration:10326  t-loss:0.0326, loss-lb:0.0283, loss-ulb:0.0022, weight:2.00, lr:0.0004
[01:26:14.240] iteration:10327  t-loss:0.0322, loss-lb:0.0143, loss-ulb:0.0089, weight:2.00, lr:0.0004
[01:26:14.623] iteration:10328  t-loss:0.0193, loss-lb:0.0121, loss-ulb:0.0036, weight:2.00, lr:0.0004
[01:26:15.016] iteration:10329  t-loss:0.0266, loss-lb:0.0149, loss-ulb:0.0059, weight:2.00, lr:0.0004
[01:26:15.395] iteration:10330  t-loss:0.0248, loss-lb:0.0134, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:26:15.776] iteration:10331  t-loss:0.0316, loss-lb:0.0143, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:26:16.152] iteration:10332  t-loss:0.0188, loss-lb:0.0135, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:26:16.535] iteration:10333  t-loss:0.0220, loss-lb:0.0137, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:26:16.915] iteration:10334  t-loss:0.0425, loss-lb:0.0275, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:26:17.299] iteration:10335  t-loss:0.0298, loss-lb:0.0141, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:26:17.678] iteration:10336  t-loss:0.0455, loss-lb:0.0137, loss-ulb:0.0159, weight:2.00, lr:0.0003
[01:26:19.179] iteration:10337  t-loss:0.0316, loss-lb:0.0196, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:26:19.574] iteration:10338  t-loss:0.0385, loss-lb:0.0368, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:26:19.956] iteration:10339  t-loss:0.0128, loss-lb:0.0104, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:26:20.341] iteration:10340  t-loss:0.0194, loss-lb:0.0124, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:26:20.729] iteration:10341  t-loss:0.0394, loss-lb:0.0215, loss-ulb:0.0090, weight:2.00, lr:0.0003
[01:26:21.110] iteration:10342  t-loss:0.0305, loss-lb:0.0189, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:26:21.492] iteration:10343  t-loss:0.0309, loss-lb:0.0247, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:26:21.879] iteration:10344  t-loss:0.0456, loss-lb:0.0308, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:26:22.267] iteration:10345  t-loss:0.0305, loss-lb:0.0133, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:26:22.657] iteration:10346  t-loss:0.0187, loss-lb:0.0106, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:26:23.046] iteration:10347  t-loss:0.0327, loss-lb:0.0144, loss-ulb:0.0092, weight:2.00, lr:0.0003
[01:26:23.436] iteration:10348  t-loss:0.0279, loss-lb:0.0114, loss-ulb:0.0082, weight:2.00, lr:0.0003
[01:26:23.822] iteration:10349  t-loss:0.0238, loss-lb:0.0115, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:26:24.203] iteration:10350  t-loss:0.0272, loss-lb:0.0123, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:26:24.590] iteration:10351  t-loss:0.0492, loss-lb:0.0350, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:26:24.976] iteration:10352  t-loss:0.0125, loss-lb:0.0106, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:26:25.360] iteration:10353  t-loss:0.0231, loss-lb:0.0111, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:26:25.740] iteration:10354  t-loss:0.0263, loss-lb:0.0127, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:26:26.126] iteration:10355  t-loss:0.0199, loss-lb:0.0111, loss-ulb:0.0044, weight:2.00, lr:0.0003
[01:26:26.508] iteration:10356  t-loss:0.0207, loss-lb:0.0179, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:26:26.886] iteration:10357  t-loss:0.0259, loss-lb:0.0215, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:26:27.279] iteration:10358  t-loss:0.0239, loss-lb:0.0117, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:26:27.681] iteration:10359  t-loss:0.0356, loss-lb:0.0222, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:26:28.076] iteration:10360  t-loss:0.0320, loss-lb:0.0189, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:26:28.462] iteration:10361  t-loss:0.0270, loss-lb:0.0251, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:26:28.843] iteration:10362  t-loss:0.0229, loss-lb:0.0212, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:26:29.227] iteration:10363  t-loss:0.0290, loss-lb:0.0196, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:26:29.616] iteration:10364  t-loss:0.0436, loss-lb:0.0154, loss-ulb:0.0141, weight:2.00, lr:0.0003
[01:26:30.002] iteration:10365  t-loss:0.0297, loss-lb:0.0249, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:26:30.400] iteration:10366  t-loss:0.0309, loss-lb:0.0290, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:26:30.789] iteration:10367  t-loss:0.0354, loss-lb:0.0126, loss-ulb:0.0114, weight:2.00, lr:0.0003
[01:26:31.172] iteration:10368  t-loss:0.0499, loss-lb:0.0124, loss-ulb:0.0188, weight:2.00, lr:0.0003
[01:26:31.561] iteration:10369  t-loss:0.0184, loss-lb:0.0109, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:26:31.945] iteration:10370  t-loss:0.0306, loss-lb:0.0282, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:26:32.325] iteration:10371  t-loss:0.0205, loss-lb:0.0165, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:26:32.702] iteration:10372  t-loss:0.0257, loss-lb:0.0220, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:26:33.083] iteration:10373  t-loss:0.0314, loss-lb:0.0141, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:26:33.465] iteration:10374  t-loss:0.0495, loss-lb:0.0335, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:27:42.101] iteration 10374 : dice_score: 0.900279 best_dice: 0.900300
[01:27:42.102]  <<Test>> - Ep:272  - Dice-S/T:89.50/90.03, Best-S:90.09, Best-T:90.03
[01:27:42.102]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:27:43.517] iteration:10375  t-loss:0.0313, loss-lb:0.0283, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:27:43.911] iteration:10376  t-loss:0.0434, loss-lb:0.0212, loss-ulb:0.0111, weight:2.00, lr:0.0003
[01:27:44.300] iteration:10377  t-loss:0.0313, loss-lb:0.0192, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:27:44.684] iteration:10378  t-loss:0.0155, loss-lb:0.0115, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:27:45.079] iteration:10379  t-loss:0.0311, loss-lb:0.0150, loss-ulb:0.0081, weight:2.00, lr:0.0003
[01:27:45.474] iteration:10380  t-loss:0.0447, loss-lb:0.0152, loss-ulb:0.0148, weight:2.00, lr:0.0003
[01:27:45.883] iteration:10381  t-loss:0.0396, loss-lb:0.0223, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:27:46.283] iteration:10382  t-loss:0.0135, loss-lb:0.0108, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:27:46.674] iteration:10383  t-loss:0.0199, loss-lb:0.0158, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:27:47.063] iteration:10384  t-loss:0.0584, loss-lb:0.0329, loss-ulb:0.0128, weight:2.00, lr:0.0003
[01:27:47.448] iteration:10385  t-loss:0.0145, loss-lb:0.0111, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:27:47.832] iteration:10386  t-loss:0.0203, loss-lb:0.0113, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:27:48.226] iteration:10387  t-loss:0.0241, loss-lb:0.0196, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:27:48.617] iteration:10388  t-loss:0.0912, loss-lb:0.0153, loss-ulb:0.0379, weight:2.00, lr:0.0003
[01:27:49.004] iteration:10389  t-loss:0.0465, loss-lb:0.0402, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:27:49.393] iteration:10390  t-loss:0.0450, loss-lb:0.0281, loss-ulb:0.0084, weight:2.00, lr:0.0003
[01:27:49.776] iteration:10391  t-loss:0.0141, loss-lb:0.0125, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:27:50.164] iteration:10392  t-loss:0.0321, loss-lb:0.0243, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:27:50.549] iteration:10393  t-loss:0.0156, loss-lb:0.0139, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:27:50.933] iteration:10394  t-loss:0.0173, loss-lb:0.0156, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:27:51.316] iteration:10395  t-loss:0.0154, loss-lb:0.0132, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:27:51.694] iteration:10396  t-loss:0.0191, loss-lb:0.0129, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:27:52.080] iteration:10397  t-loss:0.0358, loss-lb:0.0239, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:27:52.463] iteration:10398  t-loss:0.0387, loss-lb:0.0297, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:27:52.839] iteration:10399  t-loss:0.0180, loss-lb:0.0128, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:27:53.222] iteration:10400  t-loss:0.0236, loss-lb:0.0209, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:27:53.607] iteration:10401  t-loss:0.0581, loss-lb:0.0214, loss-ulb:0.0183, weight:2.00, lr:0.0003
[01:27:53.989] iteration:10402  t-loss:0.0158, loss-lb:0.0144, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:27:54.372] iteration:10403  t-loss:0.0339, loss-lb:0.0232, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:27:54.756] iteration:10404  t-loss:0.0282, loss-lb:0.0248, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:27:55.145] iteration:10405  t-loss:0.0280, loss-lb:0.0226, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:27:55.526] iteration:10406  t-loss:0.0293, loss-lb:0.0221, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:27:55.908] iteration:10407  t-loss:0.0197, loss-lb:0.0094, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:27:56.286] iteration:10408  t-loss:0.0338, loss-lb:0.0314, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:27:56.667] iteration:10409  t-loss:0.0205, loss-lb:0.0142, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:27:57.053] iteration:10410  t-loss:0.0540, loss-lb:0.0249, loss-ulb:0.0145, weight:2.00, lr:0.0003
[01:27:57.432] iteration:10411  t-loss:0.0177, loss-lb:0.0137, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:27:57.810] iteration:10412  t-loss:0.0199, loss-lb:0.0133, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:27:59.030] iteration:10413  t-loss:0.0414, loss-lb:0.0168, loss-ulb:0.0123, weight:2.00, lr:0.0003
[01:27:59.422] iteration:10414  t-loss:0.0219, loss-lb:0.0167, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:27:59.806] iteration:10415  t-loss:0.0295, loss-lb:0.0249, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:28:00.193] iteration:10416  t-loss:0.0471, loss-lb:0.0338, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:28:00.571] iteration:10417  t-loss:0.0271, loss-lb:0.0248, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:28:00.960] iteration:10418  t-loss:0.0462, loss-lb:0.0333, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:28:01.341] iteration:10419  t-loss:0.0207, loss-lb:0.0163, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:28:01.724] iteration:10420  t-loss:0.0477, loss-lb:0.0411, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:28:02.110] iteration:10421  t-loss:0.0236, loss-lb:0.0176, loss-ulb:0.0030, weight:2.00, lr:0.0003
[01:28:02.496] iteration:10422  t-loss:0.0283, loss-lb:0.0145, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:28:02.893] iteration:10423  t-loss:0.0514, loss-lb:0.0343, loss-ulb:0.0085, weight:2.00, lr:0.0003
[01:28:03.277] iteration:10424  t-loss:0.0195, loss-lb:0.0115, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:28:03.664] iteration:10425  t-loss:0.0202, loss-lb:0.0116, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:28:04.049] iteration:10426  t-loss:0.0580, loss-lb:0.0556, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:28:04.431] iteration:10427  t-loss:0.0269, loss-lb:0.0110, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:28:04.820] iteration:10428  t-loss:0.0347, loss-lb:0.0240, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:28:05.204] iteration:10429  t-loss:0.0201, loss-lb:0.0107, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:28:05.590] iteration:10430  t-loss:0.0215, loss-lb:0.0124, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:28:05.971] iteration:10431  t-loss:0.0368, loss-lb:0.0327, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:28:06.362] iteration:10432  t-loss:0.0331, loss-lb:0.0232, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:28:06.749] iteration:10433  t-loss:0.0338, loss-lb:0.0303, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:28:07.126] iteration:10434  t-loss:0.0183, loss-lb:0.0137, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:28:07.515] iteration:10435  t-loss:0.0463, loss-lb:0.0223, loss-ulb:0.0120, weight:2.00, lr:0.0003
[01:28:07.897] iteration:10436  t-loss:0.0499, loss-lb:0.0153, loss-ulb:0.0173, weight:2.00, lr:0.0003
[01:28:08.289] iteration:10437  t-loss:0.0214, loss-lb:0.0200, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:28:08.696] iteration:10438  t-loss:0.0249, loss-lb:0.0239, loss-ulb:0.0005, weight:2.00, lr:0.0003
[01:28:09.080] iteration:10439  t-loss:0.0457, loss-lb:0.0110, loss-ulb:0.0174, weight:2.00, lr:0.0003
[01:28:09.467] iteration:10440  t-loss:0.0319, loss-lb:0.0296, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:28:09.856] iteration:10441  t-loss:0.0358, loss-lb:0.0125, loss-ulb:0.0117, weight:2.00, lr:0.0003
[01:28:10.258] iteration:10442  t-loss:0.0289, loss-lb:0.0145, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:28:10.641] iteration:10443  t-loss:0.0431, loss-lb:0.0194, loss-ulb:0.0118, weight:2.00, lr:0.0003
[01:28:11.017] iteration:10444  t-loss:0.0265, loss-lb:0.0220, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:28:11.399] iteration:10445  t-loss:0.0326, loss-lb:0.0143, loss-ulb:0.0091, weight:2.00, lr:0.0003
[01:28:11.782] iteration:10446  t-loss:0.0310, loss-lb:0.0208, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:28:12.158] iteration:10447  t-loss:0.0378, loss-lb:0.0331, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:28:12.537] iteration:10448  t-loss:0.0133, loss-lb:0.0110, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:28:12.921] iteration:10449  t-loss:0.0470, loss-lb:0.0321, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:28:13.302] iteration:10450  t-loss:0.0324, loss-lb:0.0132, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:28:14.665] iteration:10451  t-loss:0.0375, loss-lb:0.0218, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:28:15.054] iteration:10452  t-loss:0.0213, loss-lb:0.0140, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:28:15.436] iteration:10453  t-loss:0.0428, loss-lb:0.0219, loss-ulb:0.0105, weight:2.00, lr:0.0003
[01:28:15.826] iteration:10454  t-loss:0.0556, loss-lb:0.0387, loss-ulb:0.0084, weight:2.00, lr:0.0003
[01:28:16.214] iteration:10455  t-loss:0.0342, loss-lb:0.0253, loss-ulb:0.0044, weight:2.00, lr:0.0003
[01:28:16.598] iteration:10456  t-loss:0.0153, loss-lb:0.0132, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:28:16.989] iteration:10457  t-loss:0.0791, loss-lb:0.0182, loss-ulb:0.0305, weight:2.00, lr:0.0003
[01:28:17.384] iteration:10458  t-loss:0.0267, loss-lb:0.0247, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:28:17.776] iteration:10459  t-loss:0.0465, loss-lb:0.0256, loss-ulb:0.0104, weight:2.00, lr:0.0003
[01:28:18.156] iteration:10460  t-loss:0.0132, loss-lb:0.0105, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:28:18.535] iteration:10461  t-loss:0.0674, loss-lb:0.0249, loss-ulb:0.0213, weight:2.00, lr:0.0003
[01:28:18.922] iteration:10462  t-loss:0.0207, loss-lb:0.0092, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:28:19.305] iteration:10463  t-loss:0.0167, loss-lb:0.0131, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:28:19.683] iteration:10464  t-loss:0.0143, loss-lb:0.0120, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:28:20.066] iteration:10465  t-loss:0.0270, loss-lb:0.0244, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:28:20.447] iteration:10466  t-loss:0.0496, loss-lb:0.0126, loss-ulb:0.0185, weight:2.00, lr:0.0003
[01:28:20.825] iteration:10467  t-loss:0.0364, loss-lb:0.0310, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:28:21.204] iteration:10468  t-loss:0.0138, loss-lb:0.0121, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:28:21.582] iteration:10469  t-loss:0.0156, loss-lb:0.0123, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:28:21.965] iteration:10470  t-loss:0.0250, loss-lb:0.0224, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:28:22.347] iteration:10471  t-loss:0.0434, loss-lb:0.0372, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:28:22.727] iteration:10472  t-loss:0.0134, loss-lb:0.0111, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:28:23.107] iteration:10473  t-loss:0.0274, loss-lb:0.0188, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:28:23.494] iteration:10474  t-loss:0.0148, loss-lb:0.0119, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:28:23.884] iteration:10475  t-loss:0.0165, loss-lb:0.0126, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:28:24.279] iteration:10476  t-loss:0.0371, loss-lb:0.0319, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:28:24.675] iteration:10477  t-loss:0.0636, loss-lb:0.0598, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:28:25.061] iteration:10478  t-loss:0.0356, loss-lb:0.0190, loss-ulb:0.0083, weight:2.00, lr:0.0003
[01:28:25.445] iteration:10479  t-loss:0.0162, loss-lb:0.0137, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:28:25.835] iteration:10480  t-loss:0.0465, loss-lb:0.0257, loss-ulb:0.0104, weight:2.00, lr:0.0003
[01:28:26.225] iteration:10481  t-loss:0.0300, loss-lb:0.0212, loss-ulb:0.0044, weight:2.00, lr:0.0003
[01:28:26.612] iteration:10482  t-loss:0.0249, loss-lb:0.0109, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:28:27.001] iteration:10483  t-loss:0.0319, loss-lb:0.0142, loss-ulb:0.0088, weight:2.00, lr:0.0003
[01:28:27.386] iteration:10484  t-loss:0.0396, loss-lb:0.0224, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:28:27.766] iteration:10485  t-loss:0.0177, loss-lb:0.0141, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:28:28.141] iteration:10486  t-loss:0.0321, loss-lb:0.0290, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:28:28.520] iteration:10487  t-loss:0.0234, loss-lb:0.0205, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:28:28.902] iteration:10488  t-loss:0.0695, loss-lb:0.0241, loss-ulb:0.0227, weight:2.00, lr:0.0003
[01:28:30.328] iteration:10489  t-loss:0.0249, loss-lb:0.0138, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:28:30.737] iteration:10490  t-loss:0.0826, loss-lb:0.0609, loss-ulb:0.0109, weight:2.00, lr:0.0003
[01:28:31.123] iteration:10491  t-loss:0.0412, loss-lb:0.0260, loss-ulb:0.0076, weight:2.00, lr:0.0003
[01:28:31.503] iteration:10492  t-loss:0.0362, loss-lb:0.0166, loss-ulb:0.0098, weight:2.00, lr:0.0003
[01:28:31.886] iteration:10493  t-loss:0.0280, loss-lb:0.0130, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:28:32.269] iteration:10494  t-loss:0.0361, loss-lb:0.0151, loss-ulb:0.0105, weight:2.00, lr:0.0003
[01:28:32.657] iteration:10495  t-loss:0.0293, loss-lb:0.0164, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:28:33.044] iteration:10496  t-loss:0.0226, loss-lb:0.0136, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:28:33.429] iteration:10497  t-loss:0.0169, loss-lb:0.0139, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:28:33.817] iteration:10498  t-loss:0.0319, loss-lb:0.0287, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:28:34.200] iteration:10499  t-loss:0.0283, loss-lb:0.0103, loss-ulb:0.0090, weight:2.00, lr:0.0003
[01:28:34.591] iteration:10500  t-loss:0.0734, loss-lb:0.0257, loss-ulb:0.0238, weight:2.00, lr:0.0003
[01:28:34.976] iteration:10501  t-loss:0.0139, loss-lb:0.0120, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:28:35.358] iteration:10502  t-loss:0.0274, loss-lb:0.0249, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:28:35.737] iteration:10503  t-loss:0.0159, loss-lb:0.0125, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:28:36.117] iteration:10504  t-loss:0.0218, loss-lb:0.0190, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:28:36.502] iteration:10505  t-loss:0.0383, loss-lb:0.0264, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:28:36.881] iteration:10506  t-loss:0.0156, loss-lb:0.0136, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:28:37.261] iteration:10507  t-loss:0.0168, loss-lb:0.0131, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:28:37.642] iteration:10508  t-loss:0.0269, loss-lb:0.0150, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:28:38.028] iteration:10509  t-loss:0.0458, loss-lb:0.0265, loss-ulb:0.0097, weight:2.00, lr:0.0003
[01:28:38.407] iteration:10510  t-loss:0.0368, loss-lb:0.0338, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:28:38.792] iteration:10511  t-loss:0.0235, loss-lb:0.0115, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:28:39.188] iteration:10512  t-loss:0.0315, loss-lb:0.0234, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:28:39.591] iteration:10513  t-loss:0.0226, loss-lb:0.0211, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:28:39.974] iteration:10514  t-loss:0.0411, loss-lb:0.0115, loss-ulb:0.0148, weight:2.00, lr:0.0003
[01:28:40.355] iteration:10515  t-loss:0.0363, loss-lb:0.0284, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:28:40.736] iteration:10516  t-loss:0.0217, loss-lb:0.0114, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:28:41.119] iteration:10517  t-loss:0.0356, loss-lb:0.0209, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:28:41.508] iteration:10518  t-loss:0.0289, loss-lb:0.0245, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:28:41.903] iteration:10519  t-loss:0.0212, loss-lb:0.0123, loss-ulb:0.0044, weight:2.00, lr:0.0003
[01:28:42.297] iteration:10520  t-loss:0.0205, loss-lb:0.0142, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:28:42.697] iteration:10521  t-loss:0.0410, loss-lb:0.0292, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:28:43.078] iteration:10522  t-loss:0.0193, loss-lb:0.0126, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:28:43.461] iteration:10523  t-loss:0.0305, loss-lb:0.0129, loss-ulb:0.0088, weight:2.00, lr:0.0003
[01:28:43.852] iteration:10524  t-loss:0.0720, loss-lb:0.0258, loss-ulb:0.0231, weight:2.00, lr:0.0003
[01:28:44.233] iteration:10525  t-loss:0.0326, loss-lb:0.0303, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:28:44.613] iteration:10526  t-loss:0.0350, loss-lb:0.0163, loss-ulb:0.0094, weight:2.00, lr:0.0003
[01:29:53.957] iteration 10526 : dice_score: 0.896926 best_dice: 0.900300
[01:29:53.957]  <<Test>> - Ep:276  - Dice-S/T:89.37/89.69, Best-S:90.09, Best-T:90.03
[01:29:53.957]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:29:55.040] iteration:10527  t-loss:0.0343, loss-lb:0.0240, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:29:55.430] iteration:10528  t-loss:0.0158, loss-lb:0.0130, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:29:55.809] iteration:10529  t-loss:0.0556, loss-lb:0.0094, loss-ulb:0.0231, weight:2.00, lr:0.0003
[01:29:56.194] iteration:10530  t-loss:0.0344, loss-lb:0.0219, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:29:56.583] iteration:10531  t-loss:0.0258, loss-lb:0.0203, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:29:56.978] iteration:10532  t-loss:0.0325, loss-lb:0.0133, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:29:57.368] iteration:10533  t-loss:0.0283, loss-lb:0.0127, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:29:57.749] iteration:10534  t-loss:0.0177, loss-lb:0.0131, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:29:58.131] iteration:10535  t-loss:0.0251, loss-lb:0.0197, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:29:58.523] iteration:10536  t-loss:0.0210, loss-lb:0.0115, loss-ulb:0.0048, weight:2.00, lr:0.0003
[01:29:58.919] iteration:10537  t-loss:0.0157, loss-lb:0.0134, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:29:59.319] iteration:10538  t-loss:0.0209, loss-lb:0.0093, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:29:59.704] iteration:10539  t-loss:0.0334, loss-lb:0.0283, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:30:00.087] iteration:10540  t-loss:0.0249, loss-lb:0.0140, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:30:00.470] iteration:10541  t-loss:0.0328, loss-lb:0.0187, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:30:00.854] iteration:10542  t-loss:0.0491, loss-lb:0.0416, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:30:01.237] iteration:10543  t-loss:0.0254, loss-lb:0.0145, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:30:01.622] iteration:10544  t-loss:0.0246, loss-lb:0.0191, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:30:02.008] iteration:10545  t-loss:0.0575, loss-lb:0.0183, loss-ulb:0.0196, weight:2.00, lr:0.0003
[01:30:02.389] iteration:10546  t-loss:0.0451, loss-lb:0.0322, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:30:02.770] iteration:10547  t-loss:0.0305, loss-lb:0.0171, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:30:03.152] iteration:10548  t-loss:0.0512, loss-lb:0.0327, loss-ulb:0.0093, weight:2.00, lr:0.0003
[01:30:03.531] iteration:10549  t-loss:0.0216, loss-lb:0.0202, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:30:03.915] iteration:10550  t-loss:0.0678, loss-lb:0.0501, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:30:04.299] iteration:10551  t-loss:0.0214, loss-lb:0.0102, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:30:04.682] iteration:10552  t-loss:0.0306, loss-lb:0.0220, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:30:05.070] iteration:10553  t-loss:0.0246, loss-lb:0.0142, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:30:05.455] iteration:10554  t-loss:0.0155, loss-lb:0.0107, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:30:05.842] iteration:10555  t-loss:0.0275, loss-lb:0.0183, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:30:06.230] iteration:10556  t-loss:0.0218, loss-lb:0.0188, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:30:06.611] iteration:10557  t-loss:0.0157, loss-lb:0.0130, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:30:06.989] iteration:10558  t-loss:0.0275, loss-lb:0.0191, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:30:07.374] iteration:10559  t-loss:0.0183, loss-lb:0.0107, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:30:07.764] iteration:10560  t-loss:0.0388, loss-lb:0.0228, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:30:08.149] iteration:10561  t-loss:0.0457, loss-lb:0.0310, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:30:08.528] iteration:10562  t-loss:0.0140, loss-lb:0.0127, loss-ulb:0.0006, weight:2.00, lr:0.0003
[01:30:08.909] iteration:10563  t-loss:0.0524, loss-lb:0.0191, loss-ulb:0.0167, weight:2.00, lr:0.0003
[01:30:09.291] iteration:10564  t-loss:0.0416, loss-lb:0.0291, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:30:10.502] iteration:10565  t-loss:0.0167, loss-lb:0.0142, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:30:10.889] iteration:10566  t-loss:0.0328, loss-lb:0.0136, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:30:11.269] iteration:10567  t-loss:0.0181, loss-lb:0.0140, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:30:11.647] iteration:10568  t-loss:0.0653, loss-lb:0.0088, loss-ulb:0.0283, weight:2.00, lr:0.0003
[01:30:12.032] iteration:10569  t-loss:0.0458, loss-lb:0.0267, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:30:12.418] iteration:10570  t-loss:0.0248, loss-lb:0.0198, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:30:12.799] iteration:10571  t-loss:0.0280, loss-lb:0.0160, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:30:13.189] iteration:10572  t-loss:0.0345, loss-lb:0.0320, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:30:13.567] iteration:10573  t-loss:0.0152, loss-lb:0.0126, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:30:13.960] iteration:10574  t-loss:0.0500, loss-lb:0.0289, loss-ulb:0.0105, weight:2.00, lr:0.0003
[01:30:14.344] iteration:10575  t-loss:0.0237, loss-lb:0.0178, loss-ulb:0.0030, weight:2.00, lr:0.0003
[01:30:14.735] iteration:10576  t-loss:0.0488, loss-lb:0.0357, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:30:15.116] iteration:10577  t-loss:0.0328, loss-lb:0.0294, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:30:15.508] iteration:10578  t-loss:0.0257, loss-lb:0.0143, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:30:15.913] iteration:10579  t-loss:0.0178, loss-lb:0.0109, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:30:16.305] iteration:10580  t-loss:0.0289, loss-lb:0.0165, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:30:16.690] iteration:10581  t-loss:0.0174, loss-lb:0.0134, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:30:17.069] iteration:10582  t-loss:0.0240, loss-lb:0.0215, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:30:17.456] iteration:10583  t-loss:0.0424, loss-lb:0.0223, loss-ulb:0.0101, weight:2.00, lr:0.0003
[01:30:17.847] iteration:10584  t-loss:0.0429, loss-lb:0.0247, loss-ulb:0.0091, weight:2.00, lr:0.0003
[01:30:18.227] iteration:10585  t-loss:0.0373, loss-lb:0.0102, loss-ulb:0.0135, weight:2.00, lr:0.0003
[01:30:18.621] iteration:10586  t-loss:0.0406, loss-lb:0.0264, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:30:19.005] iteration:10587  t-loss:0.0218, loss-lb:0.0194, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:30:19.389] iteration:10588  t-loss:0.0351, loss-lb:0.0320, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:30:19.774] iteration:10589  t-loss:0.0378, loss-lb:0.0244, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:30:20.156] iteration:10590  t-loss:0.0293, loss-lb:0.0134, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:30:20.547] iteration:10591  t-loss:0.0277, loss-lb:0.0198, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:30:20.938] iteration:10592  t-loss:0.0485, loss-lb:0.0385, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:30:21.322] iteration:10593  t-loss:0.0343, loss-lb:0.0195, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:30:21.707] iteration:10594  t-loss:0.0341, loss-lb:0.0304, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:30:22.095] iteration:10595  t-loss:0.0355, loss-lb:0.0220, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:30:22.478] iteration:10596  t-loss:0.0209, loss-lb:0.0106, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:30:22.857] iteration:10597  t-loss:0.0252, loss-lb:0.0113, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:30:23.238] iteration:10598  t-loss:0.0465, loss-lb:0.0390, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:30:23.616] iteration:10599  t-loss:0.0297, loss-lb:0.0269, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:30:23.997] iteration:10600  t-loss:0.0230, loss-lb:0.0211, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:30:24.376] iteration:10601  t-loss:0.0136, loss-lb:0.0114, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:30:24.761] iteration:10602  t-loss:0.0415, loss-lb:0.0300, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:30:26.134] iteration:10603  t-loss:0.0262, loss-lb:0.0234, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:30:26.522] iteration:10604  t-loss:0.0257, loss-lb:0.0247, loss-ulb:0.0005, weight:2.00, lr:0.0003
[01:30:26.900] iteration:10605  t-loss:0.0188, loss-lb:0.0116, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:30:27.284] iteration:10606  t-loss:0.0158, loss-lb:0.0145, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:30:27.671] iteration:10607  t-loss:0.0331, loss-lb:0.0278, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:30:28.054] iteration:10608  t-loss:0.0216, loss-lb:0.0098, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:30:28.434] iteration:10609  t-loss:0.0237, loss-lb:0.0111, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:30:28.814] iteration:10610  t-loss:0.0167, loss-lb:0.0147, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:30:29.200] iteration:10611  t-loss:0.0394, loss-lb:0.0361, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:30:29.585] iteration:10612  t-loss:0.0339, loss-lb:0.0174, loss-ulb:0.0083, weight:2.00, lr:0.0003
[01:30:29.967] iteration:10613  t-loss:0.0308, loss-lb:0.0238, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:30:30.353] iteration:10614  t-loss:0.0364, loss-lb:0.0266, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:30:30.736] iteration:10615  t-loss:0.0400, loss-lb:0.0363, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:30:31.126] iteration:10616  t-loss:0.0113, loss-lb:0.0098, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:30:31.516] iteration:10617  t-loss:0.0158, loss-lb:0.0142, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:30:31.913] iteration:10618  t-loss:0.0207, loss-lb:0.0180, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:30:32.302] iteration:10619  t-loss:0.0238, loss-lb:0.0198, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:30:32.686] iteration:10620  t-loss:0.0130, loss-lb:0.0096, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:30:33.070] iteration:10621  t-loss:0.0140, loss-lb:0.0106, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:30:33.451] iteration:10622  t-loss:0.0159, loss-lb:0.0141, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:30:33.832] iteration:10623  t-loss:0.0360, loss-lb:0.0250, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:30:34.221] iteration:10624  t-loss:0.0323, loss-lb:0.0238, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:30:34.611] iteration:10625  t-loss:0.0321, loss-lb:0.0283, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:30:35.004] iteration:10626  t-loss:0.0143, loss-lb:0.0107, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:30:35.404] iteration:10627  t-loss:0.0385, loss-lb:0.0296, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:30:35.809] iteration:10628  t-loss:0.0305, loss-lb:0.0205, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:30:36.193] iteration:10629  t-loss:0.0133, loss-lb:0.0090, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:30:36.580] iteration:10630  t-loss:0.0601, loss-lb:0.0347, loss-ulb:0.0127, weight:2.00, lr:0.0003
[01:30:36.964] iteration:10631  t-loss:0.0433, loss-lb:0.0385, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:30:37.350] iteration:10632  t-loss:0.0217, loss-lb:0.0124, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:30:37.731] iteration:10633  t-loss:0.0242, loss-lb:0.0091, loss-ulb:0.0076, weight:2.00, lr:0.0003
[01:30:38.116] iteration:10634  t-loss:0.0322, loss-lb:0.0247, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:30:38.496] iteration:10635  t-loss:0.0372, loss-lb:0.0108, loss-ulb:0.0132, weight:2.00, lr:0.0003
[01:30:38.875] iteration:10636  t-loss:0.0250, loss-lb:0.0141, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:30:39.258] iteration:10637  t-loss:0.0333, loss-lb:0.0175, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:30:39.642] iteration:10638  t-loss:0.0351, loss-lb:0.0218, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:30:40.021] iteration:10639  t-loss:0.0243, loss-lb:0.0131, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:30:40.404] iteration:10640  t-loss:0.0747, loss-lb:0.0613, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:30:41.649] iteration:10641  t-loss:0.0357, loss-lb:0.0198, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:30:42.048] iteration:10642  t-loss:0.0498, loss-lb:0.0125, loss-ulb:0.0186, weight:2.00, lr:0.0003
[01:30:42.429] iteration:10643  t-loss:0.0174, loss-lb:0.0118, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:30:42.815] iteration:10644  t-loss:0.0355, loss-lb:0.0335, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:30:43.196] iteration:10645  t-loss:0.0323, loss-lb:0.0119, loss-ulb:0.0102, weight:2.00, lr:0.0003
[01:30:43.576] iteration:10646  t-loss:0.0304, loss-lb:0.0291, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:30:43.967] iteration:10647  t-loss:0.0344, loss-lb:0.0266, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:30:44.349] iteration:10648  t-loss:0.0309, loss-lb:0.0102, loss-ulb:0.0103, weight:2.00, lr:0.0003
[01:30:44.729] iteration:10649  t-loss:0.0152, loss-lb:0.0115, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:30:45.107] iteration:10650  t-loss:0.0194, loss-lb:0.0131, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:30:45.488] iteration:10651  t-loss:0.0229, loss-lb:0.0192, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:30:45.867] iteration:10652  t-loss:0.0381, loss-lb:0.0283, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:30:46.256] iteration:10653  t-loss:0.0317, loss-lb:0.0228, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:30:46.654] iteration:10654  t-loss:0.0165, loss-lb:0.0124, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:30:47.051] iteration:10655  t-loss:0.0360, loss-lb:0.0326, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:30:47.433] iteration:10656  t-loss:0.0222, loss-lb:0.0153, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:30:47.822] iteration:10657  t-loss:0.0286, loss-lb:0.0209, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:30:48.197] iteration:10658  t-loss:0.0188, loss-lb:0.0115, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:30:48.577] iteration:10659  t-loss:0.0309, loss-lb:0.0281, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:30:48.959] iteration:10660  t-loss:0.0251, loss-lb:0.0141, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:30:49.342] iteration:10661  t-loss:0.0271, loss-lb:0.0215, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:30:49.724] iteration:10662  t-loss:0.0268, loss-lb:0.0127, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:30:50.109] iteration:10663  t-loss:0.0228, loss-lb:0.0145, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:30:50.500] iteration:10664  t-loss:0.0149, loss-lb:0.0128, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:30:50.901] iteration:10665  t-loss:0.0308, loss-lb:0.0238, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:30:51.295] iteration:10666  t-loss:0.0228, loss-lb:0.0096, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:30:51.687] iteration:10667  t-loss:0.0363, loss-lb:0.0210, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:30:52.068] iteration:10668  t-loss:0.0210, loss-lb:0.0104, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:30:52.454] iteration:10669  t-loss:0.0301, loss-lb:0.0203, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:30:52.834] iteration:10670  t-loss:0.0174, loss-lb:0.0125, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:30:53.218] iteration:10671  t-loss:0.0193, loss-lb:0.0115, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:30:53.596] iteration:10672  t-loss:0.0204, loss-lb:0.0147, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:30:53.979] iteration:10673  t-loss:0.0286, loss-lb:0.0257, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:30:54.359] iteration:10674  t-loss:0.0183, loss-lb:0.0130, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:30:54.738] iteration:10675  t-loss:0.0369, loss-lb:0.0330, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:30:55.119] iteration:10676  t-loss:0.0249, loss-lb:0.0102, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:30:55.500] iteration:10677  t-loss:0.0259, loss-lb:0.0110, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:30:55.884] iteration:10678  t-loss:0.0544, loss-lb:0.0268, loss-ulb:0.0138, weight:2.00, lr:0.0003
[01:32:04.210] iteration 10678 : dice_score: 0.900416 best_dice: 0.900400
[01:32:04.211]  <<Test>> - Ep:280  - Dice-S/T:89.65/90.04, Best-S:90.09, Best-T:90.04
[01:32:04.211]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[01:32:05.555] iteration:10679  t-loss:0.0217, loss-lb:0.0188, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:32:05.975] iteration:10680  t-loss:0.0594, loss-lb:0.0483, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:32:06.372] iteration:10681  t-loss:0.0336, loss-lb:0.0201, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:32:06.764] iteration:10682  t-loss:0.0376, loss-lb:0.0227, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:32:07.151] iteration:10683  t-loss:0.0268, loss-lb:0.0208, loss-ulb:0.0030, weight:2.00, lr:0.0003
[01:32:07.538] iteration:10684  t-loss:0.0400, loss-lb:0.0223, loss-ulb:0.0088, weight:2.00, lr:0.0003
[01:32:07.921] iteration:10685  t-loss:0.0314, loss-lb:0.0232, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:32:08.303] iteration:10686  t-loss:0.0224, loss-lb:0.0113, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:32:08.684] iteration:10687  t-loss:0.0152, loss-lb:0.0117, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:32:09.069] iteration:10688  t-loss:0.0415, loss-lb:0.0104, loss-ulb:0.0155, weight:2.00, lr:0.0003
[01:32:09.450] iteration:10689  t-loss:0.0278, loss-lb:0.0256, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:32:09.832] iteration:10690  t-loss:0.0210, loss-lb:0.0128, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:32:10.214] iteration:10691  t-loss:0.0168, loss-lb:0.0152, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:32:10.601] iteration:10692  t-loss:0.0360, loss-lb:0.0227, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:32:10.986] iteration:10693  t-loss:0.0172, loss-lb:0.0140, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:32:11.376] iteration:10694  t-loss:0.0301, loss-lb:0.0140, loss-ulb:0.0081, weight:2.00, lr:0.0003
[01:32:11.755] iteration:10695  t-loss:0.0125, loss-lb:0.0096, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:32:12.144] iteration:10696  t-loss:0.0391, loss-lb:0.0285, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:32:12.524] iteration:10697  t-loss:0.0144, loss-lb:0.0120, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:32:12.911] iteration:10698  t-loss:0.0340, loss-lb:0.0280, loss-ulb:0.0030, weight:2.00, lr:0.0003
[01:32:13.299] iteration:10699  t-loss:0.0288, loss-lb:0.0117, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:32:13.685] iteration:10700  t-loss:0.0272, loss-lb:0.0113, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:32:14.075] iteration:10701  t-loss:0.0366, loss-lb:0.0303, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:32:14.456] iteration:10702  t-loss:0.0250, loss-lb:0.0173, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:32:14.846] iteration:10703  t-loss:0.0270, loss-lb:0.0131, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:32:15.212] iteration:10704  t-loss:0.0156, loss-lb:0.0133, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:32:15.607] iteration:10705  t-loss:0.0232, loss-lb:0.0102, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:32:15.996] iteration:10706  t-loss:0.0246, loss-lb:0.0102, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:32:16.386] iteration:10707  t-loss:0.0200, loss-lb:0.0170, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:32:16.770] iteration:10708  t-loss:0.0122, loss-lb:0.0101, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:32:17.153] iteration:10709  t-loss:0.0148, loss-lb:0.0133, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:32:17.535] iteration:10710  t-loss:0.0403, loss-lb:0.0261, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:32:17.914] iteration:10711  t-loss:0.0199, loss-lb:0.0124, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:32:18.298] iteration:10712  t-loss:0.0299, loss-lb:0.0194, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:32:18.677] iteration:10713  t-loss:0.0458, loss-lb:0.0275, loss-ulb:0.0092, weight:2.00, lr:0.0003
[01:32:19.068] iteration:10714  t-loss:0.0513, loss-lb:0.0310, loss-ulb:0.0101, weight:2.00, lr:0.0003
[01:32:19.448] iteration:10715  t-loss:0.0461, loss-lb:0.0258, loss-ulb:0.0101, weight:2.00, lr:0.0003
[01:32:19.830] iteration:10716  t-loss:0.0349, loss-lb:0.0246, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:32:21.058] iteration:10717  t-loss:0.0245, loss-lb:0.0130, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:32:21.465] iteration:10718  t-loss:0.0349, loss-lb:0.0232, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:32:21.849] iteration:10719  t-loss:0.0211, loss-lb:0.0186, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:32:22.239] iteration:10720  t-loss:0.0212, loss-lb:0.0180, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:32:22.630] iteration:10721  t-loss:0.0358, loss-lb:0.0266, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:32:23.017] iteration:10722  t-loss:0.0289, loss-lb:0.0259, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:32:23.397] iteration:10723  t-loss:0.0235, loss-lb:0.0205, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:32:23.793] iteration:10724  t-loss:0.0261, loss-lb:0.0114, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:32:24.184] iteration:10725  t-loss:0.0262, loss-lb:0.0105, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:32:24.574] iteration:10726  t-loss:0.0149, loss-lb:0.0109, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:32:24.959] iteration:10727  t-loss:0.0189, loss-lb:0.0096, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:32:25.353] iteration:10728  t-loss:0.0303, loss-lb:0.0282, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:32:25.739] iteration:10729  t-loss:0.0385, loss-lb:0.0167, loss-ulb:0.0109, weight:2.00, lr:0.0003
[01:32:26.136] iteration:10730  t-loss:0.0327, loss-lb:0.0234, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:32:26.541] iteration:10731  t-loss:0.0206, loss-lb:0.0169, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:32:26.926] iteration:10732  t-loss:0.0298, loss-lb:0.0156, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:32:27.310] iteration:10733  t-loss:0.0464, loss-lb:0.0123, loss-ulb:0.0171, weight:2.00, lr:0.0003
[01:32:27.690] iteration:10734  t-loss:0.0260, loss-lb:0.0114, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:32:28.074] iteration:10735  t-loss:0.0443, loss-lb:0.0290, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:32:28.456] iteration:10736  t-loss:0.0294, loss-lb:0.0133, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:32:28.836] iteration:10737  t-loss:0.0160, loss-lb:0.0137, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:32:29.221] iteration:10738  t-loss:0.0238, loss-lb:0.0137, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:32:29.603] iteration:10739  t-loss:0.0229, loss-lb:0.0196, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:32:29.992] iteration:10740  t-loss:0.0488, loss-lb:0.0354, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:32:30.378] iteration:10741  t-loss:0.0301, loss-lb:0.0147, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:32:30.764] iteration:10742  t-loss:0.0252, loss-lb:0.0143, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:32:31.145] iteration:10743  t-loss:0.0370, loss-lb:0.0354, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:32:31.525] iteration:10744  t-loss:0.0135, loss-lb:0.0106, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:32:31.907] iteration:10745  t-loss:0.0358, loss-lb:0.0116, loss-ulb:0.0121, weight:2.00, lr:0.0003
[01:32:32.291] iteration:10746  t-loss:0.0245, loss-lb:0.0169, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:32:32.671] iteration:10747  t-loss:0.0153, loss-lb:0.0122, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:32:33.064] iteration:10748  t-loss:0.0291, loss-lb:0.0211, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:32:33.450] iteration:10749  t-loss:0.0347, loss-lb:0.0314, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:32:33.836] iteration:10750  t-loss:0.0463, loss-lb:0.0139, loss-ulb:0.0162, weight:2.00, lr:0.0003
[01:32:34.220] iteration:10751  t-loss:0.0207, loss-lb:0.0181, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:32:34.607] iteration:10752  t-loss:0.0195, loss-lb:0.0171, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:32:34.990] iteration:10753  t-loss:0.0427, loss-lb:0.0316, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:32:35.373] iteration:10754  t-loss:0.0365, loss-lb:0.0108, loss-ulb:0.0128, weight:2.00, lr:0.0003
[01:32:36.682] iteration:10755  t-loss:0.0316, loss-lb:0.0280, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:32:37.073] iteration:10756  t-loss:0.0230, loss-lb:0.0144, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:32:37.463] iteration:10757  t-loss:0.0239, loss-lb:0.0216, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:32:37.850] iteration:10758  t-loss:0.0269, loss-lb:0.0232, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:32:38.234] iteration:10759  t-loss:0.0397, loss-lb:0.0261, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:32:38.618] iteration:10760  t-loss:0.0375, loss-lb:0.0297, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:32:39.002] iteration:10761  t-loss:0.0262, loss-lb:0.0244, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:32:39.383] iteration:10762  t-loss:0.0280, loss-lb:0.0172, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:32:39.769] iteration:10763  t-loss:0.0209, loss-lb:0.0178, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:32:40.144] iteration:10764  t-loss:0.0127, loss-lb:0.0103, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:32:40.529] iteration:10765  t-loss:0.0447, loss-lb:0.0247, loss-ulb:0.0100, weight:2.00, lr:0.0003
[01:32:40.923] iteration:10766  t-loss:0.0264, loss-lb:0.0209, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:32:41.311] iteration:10767  t-loss:0.0324, loss-lb:0.0198, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:32:41.703] iteration:10768  t-loss:0.0269, loss-lb:0.0193, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:32:42.094] iteration:10769  t-loss:0.0357, loss-lb:0.0136, loss-ulb:0.0111, weight:2.00, lr:0.0003
[01:32:42.482] iteration:10770  t-loss:0.0240, loss-lb:0.0109, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:32:42.860] iteration:10771  t-loss:0.0286, loss-lb:0.0123, loss-ulb:0.0081, weight:2.00, lr:0.0003
[01:32:43.247] iteration:10772  t-loss:0.0220, loss-lb:0.0186, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:32:43.628] iteration:10773  t-loss:0.0182, loss-lb:0.0121, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:32:44.019] iteration:10774  t-loss:0.0162, loss-lb:0.0132, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:32:44.436] iteration:10775  t-loss:0.0203, loss-lb:0.0097, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:32:44.825] iteration:10776  t-loss:0.0167, loss-lb:0.0144, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:32:45.215] iteration:10777  t-loss:0.0158, loss-lb:0.0140, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:32:45.603] iteration:10778  t-loss:0.0183, loss-lb:0.0115, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:32:45.989] iteration:10779  t-loss:0.0333, loss-lb:0.0145, loss-ulb:0.0094, weight:2.00, lr:0.0003
[01:32:46.370] iteration:10780  t-loss:0.0140, loss-lb:0.0096, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:32:46.757] iteration:10781  t-loss:0.0173, loss-lb:0.0132, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:32:47.144] iteration:10782  t-loss:0.0250, loss-lb:0.0183, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:32:47.531] iteration:10783  t-loss:0.0456, loss-lb:0.0295, loss-ulb:0.0081, weight:2.00, lr:0.0003
[01:32:47.917] iteration:10784  t-loss:0.0288, loss-lb:0.0270, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:32:48.299] iteration:10785  t-loss:0.0161, loss-lb:0.0138, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:32:48.687] iteration:10786  t-loss:0.0351, loss-lb:0.0235, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:32:49.067] iteration:10787  t-loss:0.0159, loss-lb:0.0121, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:32:49.444] iteration:10788  t-loss:0.0185, loss-lb:0.0117, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:32:49.828] iteration:10789  t-loss:0.0250, loss-lb:0.0137, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:32:50.209] iteration:10790  t-loss:0.0266, loss-lb:0.0173, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:32:50.592] iteration:10791  t-loss:0.0286, loss-lb:0.0246, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:32:50.975] iteration:10792  t-loss:0.0321, loss-lb:0.0243, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:32:52.280] iteration:10793  t-loss:0.0673, loss-lb:0.0137, loss-ulb:0.0268, weight:2.00, lr:0.0003
[01:32:52.678] iteration:10794  t-loss:0.0436, loss-lb:0.0138, loss-ulb:0.0149, weight:2.00, lr:0.0003
[01:32:53.069] iteration:10795  t-loss:0.0386, loss-lb:0.0273, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:32:53.450] iteration:10796  t-loss:0.0146, loss-lb:0.0113, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:32:53.830] iteration:10797  t-loss:0.0221, loss-lb:0.0199, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:32:54.214] iteration:10798  t-loss:0.0340, loss-lb:0.0130, loss-ulb:0.0105, weight:2.00, lr:0.0003
[01:32:54.595] iteration:10799  t-loss:0.0306, loss-lb:0.0285, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:32:54.974] iteration:10800  t-loss:0.0132, loss-lb:0.0107, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:32:55.358] iteration:10801  t-loss:0.0204, loss-lb:0.0125, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:32:55.740] iteration:10802  t-loss:0.0280, loss-lb:0.0209, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:32:56.122] iteration:10803  t-loss:0.0162, loss-lb:0.0136, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:32:56.506] iteration:10804  t-loss:0.0450, loss-lb:0.0258, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:32:56.889] iteration:10805  t-loss:0.0246, loss-lb:0.0199, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:32:57.280] iteration:10806  t-loss:0.0331, loss-lb:0.0140, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:32:57.669] iteration:10807  t-loss:0.0367, loss-lb:0.0268, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:32:58.049] iteration:10808  t-loss:0.0257, loss-lb:0.0221, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:32:58.432] iteration:10809  t-loss:0.0329, loss-lb:0.0250, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:32:58.813] iteration:10810  t-loss:0.0254, loss-lb:0.0232, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:32:59.197] iteration:10811  t-loss:0.0204, loss-lb:0.0131, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:32:59.587] iteration:10812  t-loss:0.0160, loss-lb:0.0120, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:32:59.991] iteration:10813  t-loss:0.0467, loss-lb:0.0345, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:33:00.390] iteration:10814  t-loss:0.0156, loss-lb:0.0108, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:33:00.780] iteration:10815  t-loss:0.0230, loss-lb:0.0140, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:33:01.165] iteration:10816  t-loss:0.0328, loss-lb:0.0192, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:33:01.550] iteration:10817  t-loss:0.0320, loss-lb:0.0277, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:33:01.936] iteration:10818  t-loss:0.0224, loss-lb:0.0109, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:33:02.323] iteration:10819  t-loss:0.0283, loss-lb:0.0125, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:33:02.704] iteration:10820  t-loss:0.0737, loss-lb:0.0098, loss-ulb:0.0319, weight:2.00, lr:0.0003
[01:33:03.091] iteration:10821  t-loss:0.0256, loss-lb:0.0217, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:33:03.482] iteration:10822  t-loss:0.0553, loss-lb:0.0263, loss-ulb:0.0145, weight:2.00, lr:0.0003
[01:33:03.872] iteration:10823  t-loss:0.0362, loss-lb:0.0208, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:33:04.258] iteration:10824  t-loss:0.0346, loss-lb:0.0251, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:33:04.641] iteration:10825  t-loss:0.0232, loss-lb:0.0192, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:33:05.026] iteration:10826  t-loss:0.0414, loss-lb:0.0270, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:33:05.403] iteration:10827  t-loss:0.0313, loss-lb:0.0113, loss-ulb:0.0100, weight:2.00, lr:0.0003
[01:33:05.786] iteration:10828  t-loss:0.0251, loss-lb:0.0224, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:33:06.169] iteration:10829  t-loss:0.0323, loss-lb:0.0143, loss-ulb:0.0090, weight:2.00, lr:0.0003
[01:33:06.547] iteration:10830  t-loss:0.0164, loss-lb:0.0129, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:34:14.647] iteration 10830 : dice_score: 0.890932 best_dice: 0.900400
[01:34:14.648]  <<Test>> - Ep:284  - Dice-S/T:89.15/89.09, Best-S:90.09, Best-T:90.04
[01:34:14.648]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:34:16.007] iteration:10831  t-loss:0.0365, loss-lb:0.0219, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:34:16.403] iteration:10832  t-loss:0.0348, loss-lb:0.0269, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:34:16.787] iteration:10833  t-loss:0.0371, loss-lb:0.0214, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:34:17.171] iteration:10834  t-loss:0.0489, loss-lb:0.0289, loss-ulb:0.0100, weight:2.00, lr:0.0003
[01:34:17.549] iteration:10835  t-loss:0.0134, loss-lb:0.0111, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:34:17.927] iteration:10836  t-loss:0.0617, loss-lb:0.0401, loss-ulb:0.0108, weight:2.00, lr:0.0003
[01:34:18.307] iteration:10837  t-loss:0.0345, loss-lb:0.0253, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:34:18.690] iteration:10838  t-loss:0.0165, loss-lb:0.0138, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:34:19.075] iteration:10839  t-loss:0.0334, loss-lb:0.0190, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:34:19.457] iteration:10840  t-loss:0.0158, loss-lb:0.0140, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:34:19.839] iteration:10841  t-loss:0.0245, loss-lb:0.0137, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:34:20.234] iteration:10842  t-loss:0.0635, loss-lb:0.0327, loss-ulb:0.0154, weight:2.00, lr:0.0003
[01:34:20.628] iteration:10843  t-loss:0.0171, loss-lb:0.0122, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:34:21.008] iteration:10844  t-loss:0.0219, loss-lb:0.0157, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:34:21.398] iteration:10845  t-loss:0.0382, loss-lb:0.0130, loss-ulb:0.0126, weight:2.00, lr:0.0003
[01:34:21.781] iteration:10846  t-loss:0.0288, loss-lb:0.0207, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:34:22.165] iteration:10847  t-loss:0.0201, loss-lb:0.0136, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:34:22.553] iteration:10848  t-loss:0.0382, loss-lb:0.0198, loss-ulb:0.0092, weight:2.00, lr:0.0003
[01:34:22.938] iteration:10849  t-loss:0.0263, loss-lb:0.0162, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:34:23.323] iteration:10850  t-loss:0.0200, loss-lb:0.0093, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:34:23.704] iteration:10851  t-loss:0.0268, loss-lb:0.0126, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:34:24.091] iteration:10852  t-loss:0.0371, loss-lb:0.0343, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:34:24.478] iteration:10853  t-loss:0.0237, loss-lb:0.0202, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:34:24.860] iteration:10854  t-loss:0.0492, loss-lb:0.0394, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:34:25.240] iteration:10855  t-loss:0.0256, loss-lb:0.0141, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:34:25.620] iteration:10856  t-loss:0.0187, loss-lb:0.0109, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:34:26.003] iteration:10857  t-loss:0.0127, loss-lb:0.0107, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:34:26.385] iteration:10858  t-loss:0.0225, loss-lb:0.0158, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:34:26.764] iteration:10859  t-loss:0.0179, loss-lb:0.0130, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:34:27.143] iteration:10860  t-loss:0.0137, loss-lb:0.0123, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:34:27.521] iteration:10861  t-loss:0.0228, loss-lb:0.0192, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:34:27.903] iteration:10862  t-loss:0.0317, loss-lb:0.0302, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:34:28.286] iteration:10863  t-loss:0.0446, loss-lb:0.0352, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:34:28.663] iteration:10864  t-loss:0.1217, loss-lb:0.1187, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:34:29.044] iteration:10865  t-loss:0.0269, loss-lb:0.0237, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:34:29.427] iteration:10866  t-loss:0.0178, loss-lb:0.0160, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:34:29.803] iteration:10867  t-loss:0.0341, loss-lb:0.0323, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:34:30.184] iteration:10868  t-loss:0.0351, loss-lb:0.0111, loss-ulb:0.0120, weight:2.00, lr:0.0003
[01:34:31.407] iteration:10869  t-loss:0.0213, loss-lb:0.0114, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:34:31.817] iteration:10870  t-loss:0.0235, loss-lb:0.0135, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:34:32.204] iteration:10871  t-loss:0.0278, loss-lb:0.0135, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:34:32.584] iteration:10872  t-loss:0.0228, loss-lb:0.0196, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:34:32.964] iteration:10873  t-loss:0.0362, loss-lb:0.0331, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:34:33.347] iteration:10874  t-loss:0.0170, loss-lb:0.0099, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:34:33.731] iteration:10875  t-loss:0.0285, loss-lb:0.0217, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:34:34.120] iteration:10876  t-loss:0.0258, loss-lb:0.0118, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:34:34.508] iteration:10877  t-loss:0.0422, loss-lb:0.0279, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:34:34.896] iteration:10878  t-loss:0.0266, loss-lb:0.0137, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:34:35.281] iteration:10879  t-loss:0.0291, loss-lb:0.0234, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:34:35.666] iteration:10880  t-loss:0.0166, loss-lb:0.0152, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:34:36.054] iteration:10881  t-loss:0.0288, loss-lb:0.0218, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:34:36.449] iteration:10882  t-loss:0.0234, loss-lb:0.0197, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:34:36.848] iteration:10883  t-loss:0.0352, loss-lb:0.0263, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:34:37.244] iteration:10884  t-loss:0.0234, loss-lb:0.0135, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:34:37.626] iteration:10885  t-loss:0.0665, loss-lb:0.0544, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:34:38.014] iteration:10886  t-loss:0.0483, loss-lb:0.0319, loss-ulb:0.0082, weight:2.00, lr:0.0003
[01:34:38.403] iteration:10887  t-loss:0.0288, loss-lb:0.0128, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:34:38.785] iteration:10888  t-loss:0.0151, loss-lb:0.0123, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:34:39.173] iteration:10889  t-loss:0.0437, loss-lb:0.0219, loss-ulb:0.0109, weight:2.00, lr:0.0003
[01:34:39.564] iteration:10890  t-loss:0.0492, loss-lb:0.0322, loss-ulb:0.0085, weight:2.00, lr:0.0003
[01:34:39.950] iteration:10891  t-loss:0.0353, loss-lb:0.0260, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:34:40.332] iteration:10892  t-loss:0.0163, loss-lb:0.0119, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:34:40.717] iteration:10893  t-loss:0.0283, loss-lb:0.0158, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:34:41.101] iteration:10894  t-loss:0.0241, loss-lb:0.0211, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:34:41.488] iteration:10895  t-loss:0.0401, loss-lb:0.0223, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:34:41.871] iteration:10896  t-loss:0.0231, loss-lb:0.0136, loss-ulb:0.0048, weight:2.00, lr:0.0003
[01:34:42.251] iteration:10897  t-loss:0.0198, loss-lb:0.0162, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:34:42.638] iteration:10898  t-loss:0.0210, loss-lb:0.0182, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:34:43.021] iteration:10899  t-loss:0.0147, loss-lb:0.0117, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:34:43.404] iteration:10900  t-loss:0.0285, loss-lb:0.0269, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:34:43.782] iteration:10901  t-loss:0.0323, loss-lb:0.0184, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:34:44.167] iteration:10902  t-loss:0.0312, loss-lb:0.0178, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:34:44.545] iteration:10903  t-loss:0.0242, loss-lb:0.0195, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:34:44.924] iteration:10904  t-loss:0.0165, loss-lb:0.0127, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:34:45.309] iteration:10905  t-loss:0.0273, loss-lb:0.0191, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:34:45.695] iteration:10906  t-loss:0.0261, loss-lb:0.0207, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:34:47.129] iteration:10907  t-loss:0.0403, loss-lb:0.0253, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:34:47.525] iteration:10908  t-loss:0.0353, loss-lb:0.0240, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:34:47.906] iteration:10909  t-loss:0.0128, loss-lb:0.0102, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:34:48.293] iteration:10910  t-loss:0.0407, loss-lb:0.0371, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:34:48.672] iteration:10911  t-loss:0.0219, loss-lb:0.0181, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:34:49.055] iteration:10912  t-loss:0.0332, loss-lb:0.0098, loss-ulb:0.0117, weight:2.00, lr:0.0003
[01:34:49.440] iteration:10913  t-loss:0.0218, loss-lb:0.0115, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:34:49.832] iteration:10914  t-loss:0.0252, loss-lb:0.0229, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:34:50.222] iteration:10915  t-loss:0.0151, loss-lb:0.0119, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:34:50.610] iteration:10916  t-loss:0.0189, loss-lb:0.0106, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:34:50.993] iteration:10917  t-loss:0.0138, loss-lb:0.0112, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:34:51.379] iteration:10918  t-loss:0.0647, loss-lb:0.0363, loss-ulb:0.0142, weight:2.00, lr:0.0003
[01:34:51.791] iteration:10919  t-loss:0.0246, loss-lb:0.0107, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:34:52.182] iteration:10920  t-loss:0.0352, loss-lb:0.0326, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:34:52.570] iteration:10921  t-loss:0.0284, loss-lb:0.0265, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:34:52.958] iteration:10922  t-loss:0.0327, loss-lb:0.0224, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:34:53.349] iteration:10923  t-loss:0.0344, loss-lb:0.0121, loss-ulb:0.0111, weight:2.00, lr:0.0003
[01:34:53.741] iteration:10924  t-loss:0.0738, loss-lb:0.0532, loss-ulb:0.0103, weight:2.00, lr:0.0003
[01:34:54.122] iteration:10925  t-loss:0.0114, loss-lb:0.0094, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:34:54.507] iteration:10926  t-loss:0.0392, loss-lb:0.0247, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:34:54.885] iteration:10927  t-loss:0.0312, loss-lb:0.0143, loss-ulb:0.0084, weight:2.00, lr:0.0003
[01:34:55.273] iteration:10928  t-loss:0.0260, loss-lb:0.0178, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:34:55.657] iteration:10929  t-loss:0.0251, loss-lb:0.0126, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:34:56.040] iteration:10930  t-loss:0.0309, loss-lb:0.0215, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:34:56.421] iteration:10931  t-loss:0.0147, loss-lb:0.0121, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:34:56.806] iteration:10932  t-loss:0.0475, loss-lb:0.0391, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:34:57.192] iteration:10933  t-loss:0.0278, loss-lb:0.0260, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:34:57.578] iteration:10934  t-loss:0.0145, loss-lb:0.0111, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:34:57.962] iteration:10935  t-loss:0.0354, loss-lb:0.0248, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:34:58.344] iteration:10936  t-loss:0.0135, loss-lb:0.0112, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:34:58.723] iteration:10937  t-loss:0.0144, loss-lb:0.0113, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:34:59.099] iteration:10938  t-loss:0.0474, loss-lb:0.0223, loss-ulb:0.0126, weight:2.00, lr:0.0003
[01:34:59.481] iteration:10939  t-loss:0.0356, loss-lb:0.0253, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:34:59.867] iteration:10940  t-loss:0.0287, loss-lb:0.0250, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:35:00.247] iteration:10941  t-loss:0.0268, loss-lb:0.0242, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:35:00.632] iteration:10942  t-loss:0.0489, loss-lb:0.0340, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:35:01.016] iteration:10943  t-loss:0.0279, loss-lb:0.0242, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:35:01.397] iteration:10944  t-loss:0.0255, loss-lb:0.0128, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:35:02.540] iteration:10945  t-loss:0.0215, loss-lb:0.0189, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:35:02.934] iteration:10946  t-loss:0.0170, loss-lb:0.0150, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:35:03.317] iteration:10947  t-loss:0.0361, loss-lb:0.0290, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:35:03.696] iteration:10948  t-loss:0.0168, loss-lb:0.0105, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:35:04.073] iteration:10949  t-loss:0.0149, loss-lb:0.0124, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:35:04.450] iteration:10950  t-loss:0.0290, loss-lb:0.0148, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:35:04.829] iteration:10951  t-loss:0.0245, loss-lb:0.0206, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:35:05.219] iteration:10952  t-loss:0.0378, loss-lb:0.0239, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:35:05.601] iteration:10953  t-loss:0.0174, loss-lb:0.0107, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:35:05.986] iteration:10954  t-loss:0.0162, loss-lb:0.0139, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:35:06.370] iteration:10955  t-loss:0.0186, loss-lb:0.0135, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:35:06.756] iteration:10956  t-loss:0.0194, loss-lb:0.0142, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:35:07.172] iteration:10957  t-loss:0.0383, loss-lb:0.0228, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:35:07.579] iteration:10958  t-loss:0.0415, loss-lb:0.0285, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:35:07.965] iteration:10959  t-loss:0.0316, loss-lb:0.0199, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:35:08.355] iteration:10960  t-loss:0.0449, loss-lb:0.0349, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:35:08.750] iteration:10961  t-loss:0.0331, loss-lb:0.0173, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:35:09.142] iteration:10962  t-loss:0.0519, loss-lb:0.0362, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:35:09.529] iteration:10963  t-loss:0.0322, loss-lb:0.0214, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:35:09.907] iteration:10964  t-loss:0.0204, loss-lb:0.0167, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:35:10.291] iteration:10965  t-loss:0.0266, loss-lb:0.0137, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:35:10.677] iteration:10966  t-loss:0.0249, loss-lb:0.0184, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:35:11.066] iteration:10967  t-loss:0.0383, loss-lb:0.0206, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:35:11.448] iteration:10968  t-loss:0.0152, loss-lb:0.0131, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:35:11.834] iteration:10969  t-loss:0.0652, loss-lb:0.0166, loss-ulb:0.0243, weight:2.00, lr:0.0003
[01:35:12.220] iteration:10970  t-loss:0.0343, loss-lb:0.0216, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:35:12.611] iteration:10971  t-loss:0.0400, loss-lb:0.0162, loss-ulb:0.0119, weight:2.00, lr:0.0003
[01:35:12.990] iteration:10972  t-loss:0.0176, loss-lb:0.0151, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:35:13.373] iteration:10973  t-loss:0.0224, loss-lb:0.0111, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:35:13.757] iteration:10974  t-loss:0.0257, loss-lb:0.0091, loss-ulb:0.0083, weight:2.00, lr:0.0003
[01:35:14.134] iteration:10975  t-loss:0.0151, loss-lb:0.0129, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:35:14.514] iteration:10976  t-loss:0.0298, loss-lb:0.0139, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:35:14.895] iteration:10977  t-loss:0.0429, loss-lb:0.0235, loss-ulb:0.0097, weight:2.00, lr:0.0003
[01:35:15.274] iteration:10978  t-loss:0.0265, loss-lb:0.0249, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:35:15.656] iteration:10979  t-loss:0.0342, loss-lb:0.0166, loss-ulb:0.0088, weight:2.00, lr:0.0003
[01:35:16.037] iteration:10980  t-loss:0.0207, loss-lb:0.0164, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:35:16.417] iteration:10981  t-loss:0.0280, loss-lb:0.0215, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:35:16.806] iteration:10982  t-loss:0.0233, loss-lb:0.0196, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:36:24.429] iteration 10982 : dice_score: 0.896832 best_dice: 0.900400
[01:36:24.429]  <<Test>> - Ep:288  - Dice-S/T:89.39/89.68, Best-S:90.09, Best-T:90.04
[01:36:24.429]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:36:25.993] iteration:10983  t-loss:0.0270, loss-lb:0.0143, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:36:26.395] iteration:10984  t-loss:0.0164, loss-lb:0.0123, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:36:26.782] iteration:10985  t-loss:0.0262, loss-lb:0.0167, loss-ulb:0.0048, weight:2.00, lr:0.0003
[01:36:27.164] iteration:10986  t-loss:0.0249, loss-lb:0.0106, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:36:27.551] iteration:10987  t-loss:0.0418, loss-lb:0.0228, loss-ulb:0.0095, weight:2.00, lr:0.0003
[01:36:27.935] iteration:10988  t-loss:0.0326, loss-lb:0.0298, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:36:28.316] iteration:10989  t-loss:0.0268, loss-lb:0.0246, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:36:28.700] iteration:10990  t-loss:0.0344, loss-lb:0.0235, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:36:29.085] iteration:10991  t-loss:0.0329, loss-lb:0.0269, loss-ulb:0.0030, weight:2.00, lr:0.0003
[01:36:29.473] iteration:10992  t-loss:0.0579, loss-lb:0.0562, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:36:29.857] iteration:10993  t-loss:0.0286, loss-lb:0.0207, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:36:30.243] iteration:10994  t-loss:0.0170, loss-lb:0.0131, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:36:30.627] iteration:10995  t-loss:0.0538, loss-lb:0.0171, loss-ulb:0.0183, weight:2.00, lr:0.0003
[01:36:31.007] iteration:10996  t-loss:0.0138, loss-lb:0.0108, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:36:31.389] iteration:10997  t-loss:0.0147, loss-lb:0.0126, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:36:31.770] iteration:10998  t-loss:0.0409, loss-lb:0.0228, loss-ulb:0.0091, weight:2.00, lr:0.0003
[01:36:32.153] iteration:10999  t-loss:0.0272, loss-lb:0.0145, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:36:32.538] iteration:11000  t-loss:0.0792, loss-lb:0.0302, loss-ulb:0.0245, weight:2.00, lr:0.0003
[01:36:32.926] iteration:11001  t-loss:0.0886, loss-lb:0.0253, loss-ulb:0.0317, weight:2.00, lr:0.0003
[01:36:33.314] iteration:11002  t-loss:0.0157, loss-lb:0.0131, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:36:33.701] iteration:11003  t-loss:0.0266, loss-lb:0.0234, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:36:34.086] iteration:11004  t-loss:0.0289, loss-lb:0.0246, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:36:34.471] iteration:11005  t-loss:0.0261, loss-lb:0.0121, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:36:34.858] iteration:11006  t-loss:0.0186, loss-lb:0.0114, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:36:35.239] iteration:11007  t-loss:0.0300, loss-lb:0.0144, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:36:35.620] iteration:11008  t-loss:0.0130, loss-lb:0.0095, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:36:36.009] iteration:11009  t-loss:0.0298, loss-lb:0.0102, loss-ulb:0.0098, weight:2.00, lr:0.0003
[01:36:36.394] iteration:11010  t-loss:0.0293, loss-lb:0.0115, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:36:36.775] iteration:11011  t-loss:0.0318, loss-lb:0.0282, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:36:37.160] iteration:11012  t-loss:0.0261, loss-lb:0.0145, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:36:37.536] iteration:11013  t-loss:0.0218, loss-lb:0.0146, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:36:37.916] iteration:11014  t-loss:0.0244, loss-lb:0.0108, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:36:38.307] iteration:11015  t-loss:0.0332, loss-lb:0.0209, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:36:38.689] iteration:11016  t-loss:0.0229, loss-lb:0.0197, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:36:39.068] iteration:11017  t-loss:0.0295, loss-lb:0.0268, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:36:39.449] iteration:11018  t-loss:0.0270, loss-lb:0.0125, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:36:39.833] iteration:11019  t-loss:0.0375, loss-lb:0.0227, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:36:40.219] iteration:11020  t-loss:0.0439, loss-lb:0.0314, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:36:41.475] iteration:11021  t-loss:0.0330, loss-lb:0.0217, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:36:41.874] iteration:11022  t-loss:0.0270, loss-lb:0.0233, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:36:42.258] iteration:11023  t-loss:0.0350, loss-lb:0.0335, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:36:42.642] iteration:11024  t-loss:0.0214, loss-lb:0.0119, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:36:43.024] iteration:11025  t-loss:0.0248, loss-lb:0.0125, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:36:43.410] iteration:11026  t-loss:0.0316, loss-lb:0.0258, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:36:43.798] iteration:11027  t-loss:0.0604, loss-lb:0.0144, loss-ulb:0.0230, weight:2.00, lr:0.0003
[01:36:44.185] iteration:11028  t-loss:0.0377, loss-lb:0.0254, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:36:44.572] iteration:11029  t-loss:0.0297, loss-lb:0.0267, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:36:44.955] iteration:11030  t-loss:0.0144, loss-lb:0.0114, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:36:45.344] iteration:11031  t-loss:0.0603, loss-lb:0.0353, loss-ulb:0.0125, weight:2.00, lr:0.0003
[01:36:45.734] iteration:11032  t-loss:0.0153, loss-lb:0.0125, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:36:46.123] iteration:11033  t-loss:0.0336, loss-lb:0.0214, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:36:46.514] iteration:11034  t-loss:0.0323, loss-lb:0.0100, loss-ulb:0.0111, weight:2.00, lr:0.0003
[01:36:46.924] iteration:11035  t-loss:0.0263, loss-lb:0.0136, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:36:47.306] iteration:11036  t-loss:0.0126, loss-lb:0.0109, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:36:47.692] iteration:11037  t-loss:0.0252, loss-lb:0.0116, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:36:48.076] iteration:11038  t-loss:0.0390, loss-lb:0.0284, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:36:48.455] iteration:11039  t-loss:0.0209, loss-lb:0.0133, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:36:48.844] iteration:11040  t-loss:0.0218, loss-lb:0.0102, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:36:49.235] iteration:11041  t-loss:0.0171, loss-lb:0.0094, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:36:49.621] iteration:11042  t-loss:0.0246, loss-lb:0.0223, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:36:50.011] iteration:11043  t-loss:0.0494, loss-lb:0.0325, loss-ulb:0.0085, weight:2.00, lr:0.0003
[01:36:50.392] iteration:11044  t-loss:0.0130, loss-lb:0.0090, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:36:50.776] iteration:11045  t-loss:0.0197, loss-lb:0.0171, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:36:51.161] iteration:11046  t-loss:0.0241, loss-lb:0.0124, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:36:51.544] iteration:11047  t-loss:0.0270, loss-lb:0.0256, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:36:51.930] iteration:11048  t-loss:0.0168, loss-lb:0.0096, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:36:52.315] iteration:11049  t-loss:0.0188, loss-lb:0.0096, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:36:52.704] iteration:11050  t-loss:0.0223, loss-lb:0.0140, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:36:53.087] iteration:11051  t-loss:0.0350, loss-lb:0.0176, loss-ulb:0.0087, weight:2.00, lr:0.0003
[01:36:53.467] iteration:11052  t-loss:0.0132, loss-lb:0.0116, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:36:53.856] iteration:11053  t-loss:0.0188, loss-lb:0.0097, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:36:54.245] iteration:11054  t-loss:0.0366, loss-lb:0.0224, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:36:54.627] iteration:11055  t-loss:0.0267, loss-lb:0.0239, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:36:55.009] iteration:11056  t-loss:0.0130, loss-lb:0.0098, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:36:55.403] iteration:11057  t-loss:0.0316, loss-lb:0.0128, loss-ulb:0.0094, weight:2.00, lr:0.0003
[01:36:55.793] iteration:11058  t-loss:0.0246, loss-lb:0.0206, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:36:57.152] iteration:11059  t-loss:0.0568, loss-lb:0.0144, loss-ulb:0.0212, weight:2.00, lr:0.0003
[01:36:57.558] iteration:11060  t-loss:0.0421, loss-lb:0.0236, loss-ulb:0.0093, weight:2.00, lr:0.0003
[01:36:57.941] iteration:11061  t-loss:0.0123, loss-lb:0.0109, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:36:58.321] iteration:11062  t-loss:0.0131, loss-lb:0.0116, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:36:58.702] iteration:11063  t-loss:0.0216, loss-lb:0.0124, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:36:59.090] iteration:11064  t-loss:0.0301, loss-lb:0.0210, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:36:59.470] iteration:11065  t-loss:0.0321, loss-lb:0.0119, loss-ulb:0.0101, weight:2.00, lr:0.0003
[01:36:59.851] iteration:11066  t-loss:0.0439, loss-lb:0.0268, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:37:00.234] iteration:11067  t-loss:0.0284, loss-lb:0.0258, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:37:00.617] iteration:11068  t-loss:0.0239, loss-lb:0.0125, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:37:00.998] iteration:11069  t-loss:0.0179, loss-lb:0.0106, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:37:01.386] iteration:11070  t-loss:0.0425, loss-lb:0.0296, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:37:01.779] iteration:11071  t-loss:0.0381, loss-lb:0.0355, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:37:02.185] iteration:11072  t-loss:0.0319, loss-lb:0.0248, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:37:02.594] iteration:11073  t-loss:0.0326, loss-lb:0.0197, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:37:02.986] iteration:11074  t-loss:0.0520, loss-lb:0.0363, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:37:03.374] iteration:11075  t-loss:0.0218, loss-lb:0.0114, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:37:03.768] iteration:11076  t-loss:0.0218, loss-lb:0.0143, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:37:04.153] iteration:11077  t-loss:0.0212, loss-lb:0.0138, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:37:04.536] iteration:11078  t-loss:0.0189, loss-lb:0.0132, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:37:04.919] iteration:11079  t-loss:0.0224, loss-lb:0.0208, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:37:05.301] iteration:11080  t-loss:0.0178, loss-lb:0.0160, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:37:05.683] iteration:11081  t-loss:0.0134, loss-lb:0.0119, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:37:06.064] iteration:11082  t-loss:0.0356, loss-lb:0.0327, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:37:06.443] iteration:11083  t-loss:0.0127, loss-lb:0.0114, loss-ulb:0.0006, weight:2.00, lr:0.0003
[01:37:06.826] iteration:11084  t-loss:0.0158, loss-lb:0.0121, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:37:07.208] iteration:11085  t-loss:0.0142, loss-lb:0.0106, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:37:07.590] iteration:11086  t-loss:0.0314, loss-lb:0.0100, loss-ulb:0.0107, weight:2.00, lr:0.0003
[01:37:07.974] iteration:11087  t-loss:0.0316, loss-lb:0.0199, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:37:08.359] iteration:11088  t-loss:0.0587, loss-lb:0.0349, loss-ulb:0.0119, weight:2.00, lr:0.0003
[01:37:08.739] iteration:11089  t-loss:0.0345, loss-lb:0.0276, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:37:09.119] iteration:11090  t-loss:0.0252, loss-lb:0.0218, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:37:09.498] iteration:11091  t-loss:0.0285, loss-lb:0.0247, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:37:09.880] iteration:11092  t-loss:0.0210, loss-lb:0.0108, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:37:10.264] iteration:11093  t-loss:0.0375, loss-lb:0.0243, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:37:10.656] iteration:11094  t-loss:0.0276, loss-lb:0.0213, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:37:11.045] iteration:11095  t-loss:0.0211, loss-lb:0.0166, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:37:11.438] iteration:11096  t-loss:0.0148, loss-lb:0.0109, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:37:12.845] iteration:11097  t-loss:0.0331, loss-lb:0.0310, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:37:13.242] iteration:11098  t-loss:0.0366, loss-lb:0.0138, loss-ulb:0.0114, weight:2.00, lr:0.0003
[01:37:13.631] iteration:11099  t-loss:0.0272, loss-lb:0.0245, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:37:14.012] iteration:11100  t-loss:0.0459, loss-lb:0.0280, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:37:14.397] iteration:11101  t-loss:0.0318, loss-lb:0.0183, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:37:14.779] iteration:11102  t-loss:0.0368, loss-lb:0.0296, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:37:15.168] iteration:11103  t-loss:0.0294, loss-lb:0.0138, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:37:15.550] iteration:11104  t-loss:0.0353, loss-lb:0.0215, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:37:15.935] iteration:11105  t-loss:0.0334, loss-lb:0.0238, loss-ulb:0.0048, weight:2.00, lr:0.0003
[01:37:16.316] iteration:11106  t-loss:0.0271, loss-lb:0.0249, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:37:16.697] iteration:11107  t-loss:0.0138, loss-lb:0.0114, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:37:17.088] iteration:11108  t-loss:0.0300, loss-lb:0.0273, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:37:17.480] iteration:11109  t-loss:0.0341, loss-lb:0.0115, loss-ulb:0.0113, weight:2.00, lr:0.0003
[01:37:17.890] iteration:11110  t-loss:0.0375, loss-lb:0.0310, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:37:18.280] iteration:11111  t-loss:0.0348, loss-lb:0.0231, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:37:18.665] iteration:11112  t-loss:0.0452, loss-lb:0.0108, loss-ulb:0.0172, weight:2.00, lr:0.0003
[01:37:19.044] iteration:11113  t-loss:0.0192, loss-lb:0.0163, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:37:19.428] iteration:11114  t-loss:0.0371, loss-lb:0.0169, loss-ulb:0.0101, weight:2.00, lr:0.0003
[01:37:19.820] iteration:11115  t-loss:0.0246, loss-lb:0.0183, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:37:20.209] iteration:11116  t-loss:0.0344, loss-lb:0.0317, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:37:20.594] iteration:11117  t-loss:0.0190, loss-lb:0.0107, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:37:20.978] iteration:11118  t-loss:0.0683, loss-lb:0.0136, loss-ulb:0.0274, weight:2.00, lr:0.0003
[01:37:21.368] iteration:11119  t-loss:0.0332, loss-lb:0.0306, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:37:21.749] iteration:11120  t-loss:0.0128, loss-lb:0.0102, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:37:22.130] iteration:11121  t-loss:0.0261, loss-lb:0.0170, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:37:22.519] iteration:11122  t-loss:0.0525, loss-lb:0.0339, loss-ulb:0.0093, weight:2.00, lr:0.0003
[01:37:22.899] iteration:11123  t-loss:0.0248, loss-lb:0.0207, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:37:23.285] iteration:11124  t-loss:0.0251, loss-lb:0.0159, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:37:23.663] iteration:11125  t-loss:0.0380, loss-lb:0.0347, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:37:24.047] iteration:11126  t-loss:0.0351, loss-lb:0.0121, loss-ulb:0.0115, weight:2.00, lr:0.0003
[01:37:24.429] iteration:11127  t-loss:0.0531, loss-lb:0.0335, loss-ulb:0.0098, weight:2.00, lr:0.0003
[01:37:24.807] iteration:11128  t-loss:0.0181, loss-lb:0.0111, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:37:25.187] iteration:11129  t-loss:0.0366, loss-lb:0.0124, loss-ulb:0.0121, weight:2.00, lr:0.0003
[01:37:25.563] iteration:11130  t-loss:0.0278, loss-lb:0.0248, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:37:25.946] iteration:11131  t-loss:0.0494, loss-lb:0.0349, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:37:26.341] iteration:11132  t-loss:0.0391, loss-lb:0.0303, loss-ulb:0.0044, weight:2.00, lr:0.0003
[01:37:26.738] iteration:11133  t-loss:0.0422, loss-lb:0.0128, loss-ulb:0.0147, weight:2.00, lr:0.0003
[01:37:27.121] iteration:11134  t-loss:0.0171, loss-lb:0.0148, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:38:34.985] iteration 11134 : dice_score: 0.901363 best_dice: 0.901400
[01:38:34.986]  <<Test>> - Ep:292  - Dice-S/T:89.19/90.14, Best-S:90.09, Best-T:90.14
[01:38:34.986]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:38:36.416] iteration:11135  t-loss:0.0369, loss-lb:0.0231, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:38:36.809] iteration:11136  t-loss:0.0186, loss-lb:0.0140, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:38:37.200] iteration:11137  t-loss:0.0403, loss-lb:0.0322, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:38:37.587] iteration:11138  t-loss:0.0228, loss-lb:0.0198, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:38:37.970] iteration:11139  t-loss:0.0323, loss-lb:0.0219, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:38:38.364] iteration:11140  t-loss:0.0474, loss-lb:0.0252, loss-ulb:0.0111, weight:2.00, lr:0.0003
[01:38:38.750] iteration:11141  t-loss:0.0303, loss-lb:0.0211, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:38:39.134] iteration:11142  t-loss:0.0221, loss-lb:0.0142, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:38:39.529] iteration:11143  t-loss:0.0375, loss-lb:0.0238, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:38:39.918] iteration:11144  t-loss:0.0372, loss-lb:0.0213, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:38:40.307] iteration:11145  t-loss:0.0271, loss-lb:0.0242, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:38:40.698] iteration:11146  t-loss:0.0348, loss-lb:0.0261, loss-ulb:0.0044, weight:2.00, lr:0.0003
[01:38:41.084] iteration:11147  t-loss:0.0505, loss-lb:0.0173, loss-ulb:0.0166, weight:2.00, lr:0.0003
[01:38:41.463] iteration:11148  t-loss:0.0171, loss-lb:0.0125, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:38:41.845] iteration:11149  t-loss:0.0375, loss-lb:0.0322, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:38:42.227] iteration:11150  t-loss:0.0202, loss-lb:0.0176, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:38:42.612] iteration:11151  t-loss:0.0469, loss-lb:0.0137, loss-ulb:0.0166, weight:2.00, lr:0.0003
[01:38:42.998] iteration:11152  t-loss:0.0266, loss-lb:0.0242, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:38:43.379] iteration:11153  t-loss:0.0134, loss-lb:0.0114, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:38:43.764] iteration:11154  t-loss:0.0639, loss-lb:0.0602, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:38:44.148] iteration:11155  t-loss:0.0174, loss-lb:0.0139, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:38:44.531] iteration:11156  t-loss:0.0295, loss-lb:0.0103, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:38:44.912] iteration:11157  t-loss:0.0153, loss-lb:0.0135, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:38:45.305] iteration:11158  t-loss:0.0448, loss-lb:0.0244, loss-ulb:0.0102, weight:2.00, lr:0.0003
[01:38:45.692] iteration:11159  t-loss:0.0418, loss-lb:0.0144, loss-ulb:0.0137, weight:2.00, lr:0.0003
[01:38:46.080] iteration:11160  t-loss:0.0233, loss-lb:0.0155, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:38:46.459] iteration:11161  t-loss:0.0174, loss-lb:0.0161, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:38:46.844] iteration:11162  t-loss:0.0400, loss-lb:0.0368, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:38:47.229] iteration:11163  t-loss:0.0342, loss-lb:0.0185, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:38:47.605] iteration:11164  t-loss:0.0131, loss-lb:0.0114, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:38:47.990] iteration:11165  t-loss:0.0558, loss-lb:0.0297, loss-ulb:0.0130, weight:2.00, lr:0.0003
[01:38:48.373] iteration:11166  t-loss:0.0479, loss-lb:0.0211, loss-ulb:0.0134, weight:2.00, lr:0.0003
[01:38:48.753] iteration:11167  t-loss:0.0387, loss-lb:0.0127, loss-ulb:0.0130, weight:2.00, lr:0.0003
[01:38:49.136] iteration:11168  t-loss:0.0487, loss-lb:0.0169, loss-ulb:0.0159, weight:2.00, lr:0.0003
[01:38:49.521] iteration:11169  t-loss:0.0379, loss-lb:0.0241, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:38:49.898] iteration:11170  t-loss:0.0428, loss-lb:0.0385, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:38:50.280] iteration:11171  t-loss:0.0187, loss-lb:0.0134, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:38:50.660] iteration:11172  t-loss:0.0312, loss-lb:0.0112, loss-ulb:0.0100, weight:2.00, lr:0.0003
[01:38:52.117] iteration:11173  t-loss:0.0142, loss-lb:0.0121, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:38:52.517] iteration:11174  t-loss:0.0399, loss-lb:0.0243, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:38:52.900] iteration:11175  t-loss:0.0155, loss-lb:0.0114, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:38:53.285] iteration:11176  t-loss:0.0602, loss-lb:0.0494, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:38:53.671] iteration:11177  t-loss:0.0386, loss-lb:0.0288, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:38:54.053] iteration:11178  t-loss:0.0159, loss-lb:0.0118, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:38:54.434] iteration:11179  t-loss:0.0210, loss-lb:0.0104, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:38:54.820] iteration:11180  t-loss:0.0652, loss-lb:0.0361, loss-ulb:0.0146, weight:2.00, lr:0.0003
[01:38:55.204] iteration:11181  t-loss:0.0292, loss-lb:0.0124, loss-ulb:0.0084, weight:2.00, lr:0.0003
[01:38:55.586] iteration:11182  t-loss:0.0209, loss-lb:0.0183, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:38:55.967] iteration:11183  t-loss:0.0240, loss-lb:0.0103, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:38:56.358] iteration:11184  t-loss:0.0481, loss-lb:0.0317, loss-ulb:0.0082, weight:2.00, lr:0.0003
[01:38:56.753] iteration:11185  t-loss:0.0168, loss-lb:0.0129, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:38:57.143] iteration:11186  t-loss:0.0304, loss-lb:0.0262, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:38:57.527] iteration:11187  t-loss:0.0607, loss-lb:0.0425, loss-ulb:0.0091, weight:2.00, lr:0.0003
[01:38:57.907] iteration:11188  t-loss:0.0228, loss-lb:0.0187, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:38:58.285] iteration:11189  t-loss:0.0217, loss-lb:0.0171, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:38:58.672] iteration:11190  t-loss:0.0193, loss-lb:0.0120, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:38:59.051] iteration:11191  t-loss:0.0212, loss-lb:0.0182, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:38:59.434] iteration:11192  t-loss:0.0350, loss-lb:0.0243, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:38:59.817] iteration:11193  t-loss:0.0174, loss-lb:0.0128, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:39:00.212] iteration:11194  t-loss:0.0341, loss-lb:0.0216, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:39:00.617] iteration:11195  t-loss:0.0368, loss-lb:0.0134, loss-ulb:0.0117, weight:2.00, lr:0.0003
[01:39:01.009] iteration:11196  t-loss:0.0326, loss-lb:0.0290, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:39:01.401] iteration:11197  t-loss:0.0220, loss-lb:0.0182, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:39:01.781] iteration:11198  t-loss:0.0137, loss-lb:0.0110, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:39:02.164] iteration:11199  t-loss:0.0354, loss-lb:0.0337, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:39:02.546] iteration:11200  t-loss:0.0150, loss-lb:0.0108, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:39:02.929] iteration:11201  t-loss:0.0163, loss-lb:0.0134, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:39:03.316] iteration:11202  t-loss:0.0339, loss-lb:0.0268, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:39:03.695] iteration:11203  t-loss:0.0353, loss-lb:0.0252, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:39:04.075] iteration:11204  t-loss:0.0154, loss-lb:0.0128, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:39:04.457] iteration:11205  t-loss:0.0234, loss-lb:0.0102, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:39:04.835] iteration:11206  t-loss:0.0380, loss-lb:0.0272, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:39:05.219] iteration:11207  t-loss:0.0223, loss-lb:0.0105, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:39:05.597] iteration:11208  t-loss:0.0359, loss-lb:0.0255, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:39:05.978] iteration:11209  t-loss:0.0181, loss-lb:0.0125, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:39:06.356] iteration:11210  t-loss:0.0261, loss-lb:0.0133, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:39:07.571] iteration:11211  t-loss:0.0643, loss-lb:0.0440, loss-ulb:0.0102, weight:2.00, lr:0.0003
[01:39:07.987] iteration:11212  t-loss:0.0251, loss-lb:0.0221, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:39:08.370] iteration:11213  t-loss:0.0233, loss-lb:0.0202, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:39:08.749] iteration:11214  t-loss:0.0150, loss-lb:0.0120, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:39:09.129] iteration:11215  t-loss:0.0182, loss-lb:0.0134, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:39:09.513] iteration:11216  t-loss:0.0401, loss-lb:0.0221, loss-ulb:0.0090, weight:2.00, lr:0.0003
[01:39:09.892] iteration:11217  t-loss:0.0204, loss-lb:0.0138, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:39:10.274] iteration:11218  t-loss:0.0385, loss-lb:0.0126, loss-ulb:0.0129, weight:2.00, lr:0.0003
[01:39:10.659] iteration:11219  t-loss:0.0406, loss-lb:0.0252, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:39:11.040] iteration:11220  t-loss:0.0431, loss-lb:0.0212, loss-ulb:0.0110, weight:2.00, lr:0.0003
[01:39:11.425] iteration:11221  t-loss:0.0273, loss-lb:0.0169, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:39:11.816] iteration:11222  t-loss:0.0239, loss-lb:0.0224, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:39:12.211] iteration:11223  t-loss:0.0290, loss-lb:0.0110, loss-ulb:0.0090, weight:2.00, lr:0.0003
[01:39:12.595] iteration:11224  t-loss:0.0160, loss-lb:0.0127, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:39:12.977] iteration:11225  t-loss:0.0406, loss-lb:0.0109, loss-ulb:0.0149, weight:2.00, lr:0.0003
[01:39:13.357] iteration:11226  t-loss:0.0316, loss-lb:0.0299, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:39:13.736] iteration:11227  t-loss:0.0138, loss-lb:0.0112, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:39:14.118] iteration:11228  t-loss:0.0412, loss-lb:0.0369, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:39:14.496] iteration:11229  t-loss:0.0250, loss-lb:0.0215, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:39:14.877] iteration:11230  t-loss:0.0384, loss-lb:0.0349, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:39:15.263] iteration:11231  t-loss:0.0222, loss-lb:0.0200, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:39:15.653] iteration:11232  t-loss:0.0199, loss-lb:0.0123, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:39:16.056] iteration:11233  t-loss:0.0448, loss-lb:0.0256, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:39:16.447] iteration:11234  t-loss:0.0330, loss-lb:0.0293, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:39:16.835] iteration:11235  t-loss:0.0233, loss-lb:0.0212, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:39:17.216] iteration:11236  t-loss:0.0201, loss-lb:0.0097, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:39:17.599] iteration:11237  t-loss:0.0391, loss-lb:0.0209, loss-ulb:0.0091, weight:2.00, lr:0.0003
[01:39:17.978] iteration:11238  t-loss:0.0351, loss-lb:0.0336, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:39:18.362] iteration:11239  t-loss:0.0161, loss-lb:0.0139, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:39:18.745] iteration:11240  t-loss:0.0286, loss-lb:0.0258, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:39:19.131] iteration:11241  t-loss:0.0971, loss-lb:0.0455, loss-ulb:0.0258, weight:2.00, lr:0.0003
[01:39:19.508] iteration:11242  t-loss:0.0134, loss-lb:0.0107, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:39:19.886] iteration:11243  t-loss:0.0237, loss-lb:0.0216, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:39:20.267] iteration:11244  t-loss:0.0385, loss-lb:0.0339, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:39:20.649] iteration:11245  t-loss:0.0231, loss-lb:0.0126, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:39:21.029] iteration:11246  t-loss:0.0258, loss-lb:0.0220, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:39:21.409] iteration:11247  t-loss:0.0278, loss-lb:0.0110, loss-ulb:0.0084, weight:2.00, lr:0.0003
[01:39:21.790] iteration:11248  t-loss:0.0383, loss-lb:0.0257, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:39:23.271] iteration:11249  t-loss:0.0354, loss-lb:0.0208, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:39:23.666] iteration:11250  t-loss:0.0603, loss-lb:0.0211, loss-ulb:0.0196, weight:2.00, lr:0.0003
[01:39:24.054] iteration:11251  t-loss:0.0624, loss-lb:0.0271, loss-ulb:0.0177, weight:2.00, lr:0.0003
[01:39:24.435] iteration:11252  t-loss:0.0224, loss-lb:0.0123, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:39:24.823] iteration:11253  t-loss:0.0421, loss-lb:0.0336, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:39:25.209] iteration:11254  t-loss:0.0326, loss-lb:0.0223, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:39:25.589] iteration:11255  t-loss:0.0274, loss-lb:0.0099, loss-ulb:0.0087, weight:2.00, lr:0.0003
[01:39:25.973] iteration:11256  t-loss:0.0256, loss-lb:0.0135, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:39:26.356] iteration:11257  t-loss:0.0237, loss-lb:0.0217, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:39:26.735] iteration:11258  t-loss:0.0351, loss-lb:0.0331, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:39:27.128] iteration:11259  t-loss:0.0403, loss-lb:0.0238, loss-ulb:0.0082, weight:2.00, lr:0.0003
[01:39:27.530] iteration:11260  t-loss:0.0300, loss-lb:0.0243, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:39:27.913] iteration:11261  t-loss:0.0269, loss-lb:0.0248, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:39:28.298] iteration:11262  t-loss:0.0309, loss-lb:0.0178, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:39:28.674] iteration:11263  t-loss:0.0256, loss-lb:0.0133, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:39:29.055] iteration:11264  t-loss:0.0217, loss-lb:0.0137, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:39:29.441] iteration:11265  t-loss:0.0429, loss-lb:0.0284, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:39:29.822] iteration:11266  t-loss:0.0156, loss-lb:0.0131, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:39:30.215] iteration:11267  t-loss:0.0390, loss-lb:0.0304, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:39:30.594] iteration:11268  t-loss:0.0252, loss-lb:0.0239, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:39:30.986] iteration:11269  t-loss:0.0263, loss-lb:0.0225, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:39:31.374] iteration:11270  t-loss:0.0167, loss-lb:0.0113, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:39:31.769] iteration:11271  t-loss:0.0208, loss-lb:0.0154, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:39:32.170] iteration:11272  t-loss:0.0142, loss-lb:0.0117, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:39:32.557] iteration:11273  t-loss:0.0235, loss-lb:0.0211, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:39:32.954] iteration:11274  t-loss:0.0345, loss-lb:0.0234, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:39:33.345] iteration:11275  t-loss:0.0245, loss-lb:0.0107, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:39:33.731] iteration:11276  t-loss:0.0283, loss-lb:0.0145, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:39:34.119] iteration:11277  t-loss:0.0249, loss-lb:0.0226, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:39:34.517] iteration:11278  t-loss:0.0348, loss-lb:0.0261, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:39:34.902] iteration:11279  t-loss:0.0123, loss-lb:0.0107, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:39:35.280] iteration:11280  t-loss:0.0173, loss-lb:0.0116, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:39:35.661] iteration:11281  t-loss:0.0249, loss-lb:0.0132, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:39:36.041] iteration:11282  t-loss:0.0262, loss-lb:0.0203, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:39:36.423] iteration:11283  t-loss:0.0270, loss-lb:0.0246, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:39:36.803] iteration:11284  t-loss:0.0338, loss-lb:0.0170, loss-ulb:0.0084, weight:2.00, lr:0.0003
[01:39:37.186] iteration:11285  t-loss:0.0212, loss-lb:0.0132, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:39:37.584] iteration:11286  t-loss:0.0202, loss-lb:0.0112, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:40:46.279] iteration 11286 : dice_score: 0.901462 best_dice: 0.901500
[01:40:46.280]  <<Test>> - Ep:296  - Dice-S/T:89.67/90.15, Best-S:90.09, Best-T:90.15
[01:40:46.280]           - AvgLoss(lb/ulb/all):0.02/0.00/0.02
[01:40:47.675] iteration:11287  t-loss:0.0151, loss-lb:0.0134, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:40:48.072] iteration:11288  t-loss:0.0240, loss-lb:0.0129, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:40:48.462] iteration:11289  t-loss:0.0285, loss-lb:0.0130, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:40:48.853] iteration:11290  t-loss:0.0245, loss-lb:0.0122, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:40:49.235] iteration:11291  t-loss:0.0133, loss-lb:0.0109, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:40:49.629] iteration:11292  t-loss:0.0491, loss-lb:0.0325, loss-ulb:0.0083, weight:2.00, lr:0.0003
[01:40:50.014] iteration:11293  t-loss:0.0192, loss-lb:0.0106, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:40:50.403] iteration:11294  t-loss:0.0348, loss-lb:0.0242, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:40:50.789] iteration:11295  t-loss:0.0127, loss-lb:0.0106, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:40:51.177] iteration:11296  t-loss:0.0237, loss-lb:0.0193, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:40:51.563] iteration:11297  t-loss:0.0433, loss-lb:0.0128, loss-ulb:0.0152, weight:2.00, lr:0.0003
[01:40:51.956] iteration:11298  t-loss:0.0269, loss-lb:0.0168, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:40:52.343] iteration:11299  t-loss:0.0200, loss-lb:0.0130, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:40:52.729] iteration:11300  t-loss:0.0176, loss-lb:0.0164, loss-ulb:0.0006, weight:2.00, lr:0.0003
[01:40:53.112] iteration:11301  t-loss:0.0231, loss-lb:0.0107, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:40:53.481] iteration:11302  t-loss:0.0278, loss-lb:0.0122, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:40:53.867] iteration:11303  t-loss:0.0278, loss-lb:0.0179, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:40:54.248] iteration:11304  t-loss:0.0157, loss-lb:0.0144, loss-ulb:0.0006, weight:2.00, lr:0.0003
[01:40:54.629] iteration:11305  t-loss:0.0617, loss-lb:0.0286, loss-ulb:0.0166, weight:2.00, lr:0.0003
[01:40:55.010] iteration:11306  t-loss:0.0153, loss-lb:0.0122, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:40:55.392] iteration:11307  t-loss:0.0218, loss-lb:0.0121, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:40:55.781] iteration:11308  t-loss:0.0247, loss-lb:0.0160, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:40:56.170] iteration:11309  t-loss:0.0324, loss-lb:0.0232, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:40:56.551] iteration:11310  t-loss:0.0215, loss-lb:0.0101, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:40:56.932] iteration:11311  t-loss:0.0163, loss-lb:0.0122, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:40:57.322] iteration:11312  t-loss:0.0342, loss-lb:0.0202, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:40:57.716] iteration:11313  t-loss:0.0303, loss-lb:0.0174, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:40:58.098] iteration:11314  t-loss:0.0185, loss-lb:0.0128, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:40:58.480] iteration:11315  t-loss:0.0314, loss-lb:0.0304, loss-ulb:0.0005, weight:2.00, lr:0.0003
[01:40:58.866] iteration:11316  t-loss:0.0185, loss-lb:0.0092, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:40:59.248] iteration:11317  t-loss:0.0155, loss-lb:0.0131, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:40:59.629] iteration:11318  t-loss:0.0115, loss-lb:0.0101, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:41:00.006] iteration:11319  t-loss:0.0103, loss-lb:0.0085, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:41:00.384] iteration:11320  t-loss:0.0259, loss-lb:0.0230, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:41:00.773] iteration:11321  t-loss:0.0374, loss-lb:0.0290, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:41:01.150] iteration:11322  t-loss:0.0113, loss-lb:0.0088, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:41:01.533] iteration:11323  t-loss:0.0305, loss-lb:0.0260, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:41:01.913] iteration:11324  t-loss:0.0179, loss-lb:0.0165, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:41:03.421] iteration:11325  t-loss:0.0254, loss-lb:0.0231, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:41:03.816] iteration:11326  t-loss:0.0261, loss-lb:0.0130, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:41:04.199] iteration:11327  t-loss:0.0162, loss-lb:0.0143, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:04.592] iteration:11328  t-loss:0.0543, loss-lb:0.0098, loss-ulb:0.0222, weight:2.00, lr:0.0003
[01:41:04.990] iteration:11329  t-loss:0.0249, loss-lb:0.0233, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:41:05.379] iteration:11330  t-loss:0.0288, loss-lb:0.0243, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:41:05.763] iteration:11331  t-loss:0.0123, loss-lb:0.0101, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:41:06.147] iteration:11332  t-loss:0.0539, loss-lb:0.0384, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:41:06.543] iteration:11333  t-loss:0.0261, loss-lb:0.0207, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:41:06.945] iteration:11334  t-loss:0.0409, loss-lb:0.0284, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:41:07.345] iteration:11335  t-loss:0.0292, loss-lb:0.0110, loss-ulb:0.0091, weight:2.00, lr:0.0003
[01:41:07.727] iteration:11336  t-loss:0.0157, loss-lb:0.0118, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:41:08.110] iteration:11337  t-loss:0.0282, loss-lb:0.0105, loss-ulb:0.0088, weight:2.00, lr:0.0003
[01:41:08.491] iteration:11338  t-loss:0.0276, loss-lb:0.0109, loss-ulb:0.0084, weight:2.00, lr:0.0003
[01:41:08.874] iteration:11339  t-loss:0.0393, loss-lb:0.0092, loss-ulb:0.0150, weight:2.00, lr:0.0003
[01:41:09.260] iteration:11340  t-loss:0.0232, loss-lb:0.0135, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:41:09.642] iteration:11341  t-loss:0.0438, loss-lb:0.0203, loss-ulb:0.0117, weight:2.00, lr:0.0003
[01:41:10.027] iteration:11342  t-loss:0.0356, loss-lb:0.0247, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:41:10.413] iteration:11343  t-loss:0.0281, loss-lb:0.0122, loss-ulb:0.0080, weight:2.00, lr:0.0003
[01:41:10.794] iteration:11344  t-loss:0.0223, loss-lb:0.0150, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:41:11.180] iteration:11345  t-loss:0.0141, loss-lb:0.0119, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:41:11.570] iteration:11346  t-loss:0.0347, loss-lb:0.0204, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:41:11.955] iteration:11347  t-loss:0.0396, loss-lb:0.0282, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:41:12.342] iteration:11348  t-loss:0.0250, loss-lb:0.0118, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:41:12.728] iteration:11349  t-loss:0.0174, loss-lb:0.0154, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:13.118] iteration:11350  t-loss:0.0243, loss-lb:0.0180, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:41:13.511] iteration:11351  t-loss:0.0297, loss-lb:0.0222, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:41:13.904] iteration:11352  t-loss:0.0275, loss-lb:0.0149, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:41:14.296] iteration:11353  t-loss:0.0288, loss-lb:0.0210, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:41:14.682] iteration:11354  t-loss:0.0285, loss-lb:0.0265, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:15.069] iteration:11355  t-loss:0.0206, loss-lb:0.0123, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:41:15.449] iteration:11356  t-loss:0.0337, loss-lb:0.0260, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:41:15.830] iteration:11357  t-loss:0.0136, loss-lb:0.0122, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:41:16.210] iteration:11358  t-loss:0.0373, loss-lb:0.0234, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:41:16.588] iteration:11359  t-loss:0.0169, loss-lb:0.0117, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:41:16.967] iteration:11360  t-loss:0.0266, loss-lb:0.0210, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:41:17.345] iteration:11361  t-loss:0.0392, loss-lb:0.0376, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:41:17.723] iteration:11362  t-loss:0.0143, loss-lb:0.0128, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:41:19.041] iteration:11363  t-loss:0.0339, loss-lb:0.0131, loss-ulb:0.0104, weight:2.00, lr:0.0003
[01:41:19.420] iteration:11364  t-loss:0.0132, loss-lb:0.0115, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:41:19.798] iteration:11365  t-loss:0.0119, loss-lb:0.0100, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:41:20.189] iteration:11366  t-loss:0.0279, loss-lb:0.0193, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:41:20.587] iteration:11367  t-loss:0.0176, loss-lb:0.0162, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:41:20.974] iteration:11368  t-loss:0.0176, loss-lb:0.0154, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:41:21.360] iteration:11369  t-loss:0.0373, loss-lb:0.0207, loss-ulb:0.0083, weight:2.00, lr:0.0003
[01:41:21.753] iteration:11370  t-loss:0.0215, loss-lb:0.0101, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:41:22.150] iteration:11371  t-loss:0.0396, loss-lb:0.0251, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:41:22.546] iteration:11372  t-loss:0.0248, loss-lb:0.0210, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:41:22.943] iteration:11373  t-loss:0.0464, loss-lb:0.0293, loss-ulb:0.0085, weight:2.00, lr:0.0003
[01:41:23.336] iteration:11374  t-loss:0.0485, loss-lb:0.0246, loss-ulb:0.0119, weight:2.00, lr:0.0003
[01:41:23.718] iteration:11375  t-loss:0.0171, loss-lb:0.0149, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:41:24.108] iteration:11376  t-loss:0.0210, loss-lb:0.0199, loss-ulb:0.0006, weight:2.00, lr:0.0003
[01:41:24.494] iteration:11377  t-loss:0.0129, loss-lb:0.0102, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:41:24.880] iteration:11378  t-loss:0.0465, loss-lb:0.0395, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:41:25.265] iteration:11379  t-loss:0.0248, loss-lb:0.0134, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:41:25.648] iteration:11380  t-loss:0.0237, loss-lb:0.0207, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:41:26.030] iteration:11381  t-loss:0.0157, loss-lb:0.0103, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:41:26.413] iteration:11382  t-loss:0.0327, loss-lb:0.0136, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:41:26.793] iteration:11383  t-loss:0.0304, loss-lb:0.0197, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:41:27.178] iteration:11384  t-loss:0.0345, loss-lb:0.0194, loss-ulb:0.0076, weight:2.00, lr:0.0003
[01:41:27.565] iteration:11385  t-loss:0.0279, loss-lb:0.0255, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:41:27.954] iteration:11386  t-loss:0.0611, loss-lb:0.0495, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:41:28.340] iteration:11387  t-loss:0.0163, loss-lb:0.0145, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:41:28.724] iteration:11388  t-loss:0.0245, loss-lb:0.0223, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:41:29.111] iteration:11389  t-loss:0.0202, loss-lb:0.0183, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:41:29.493] iteration:11390  t-loss:0.0116, loss-lb:0.0102, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:41:29.878] iteration:11391  t-loss:0.0142, loss-lb:0.0121, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:30.263] iteration:11392  t-loss:0.0212, loss-lb:0.0105, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:41:30.645] iteration:11393  t-loss:0.0242, loss-lb:0.0217, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:41:31.025] iteration:11394  t-loss:0.0413, loss-lb:0.0116, loss-ulb:0.0148, weight:2.00, lr:0.0003
[01:41:31.406] iteration:11395  t-loss:0.0285, loss-lb:0.0216, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:41:31.787] iteration:11396  t-loss:0.0327, loss-lb:0.0192, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:41:32.170] iteration:11397  t-loss:0.0458, loss-lb:0.0200, loss-ulb:0.0129, weight:2.00, lr:0.0003
[01:41:32.548] iteration:11398  t-loss:0.0117, loss-lb:0.0100, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:41:32.927] iteration:11399  t-loss:0.0330, loss-lb:0.0257, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:41:33.303] iteration:11400  t-loss:0.0147, loss-lb:0.0128, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:34.480] iteration:11401  t-loss:0.1368, loss-lb:0.1350, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:41:34.860] iteration:11402  t-loss:0.0221, loss-lb:0.0097, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:41:35.236] iteration:11403  t-loss:0.0368, loss-lb:0.0329, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:41:35.627] iteration:11404  t-loss:0.0189, loss-lb:0.0168, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:36.030] iteration:11405  t-loss:0.0251, loss-lb:0.0198, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:41:36.414] iteration:11406  t-loss:0.0209, loss-lb:0.0165, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:41:36.809] iteration:11407  t-loss:0.0253, loss-lb:0.0124, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:41:37.202] iteration:11408  t-loss:0.0171, loss-lb:0.0152, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:37.595] iteration:11409  t-loss:0.0140, loss-lb:0.0116, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:41:37.999] iteration:11410  t-loss:0.0470, loss-lb:0.0320, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:41:38.389] iteration:11411  t-loss:0.0241, loss-lb:0.0149, loss-ulb:0.0046, weight:2.00, lr:0.0003
[01:41:38.780] iteration:11412  t-loss:0.0294, loss-lb:0.0203, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:41:39.169] iteration:11413  t-loss:0.0210, loss-lb:0.0189, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:41:39.554] iteration:11414  t-loss:0.0323, loss-lb:0.0220, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:41:39.935] iteration:11415  t-loss:0.0146, loss-lb:0.0122, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:41:40.325] iteration:11416  t-loss:0.0312, loss-lb:0.0184, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:41:40.715] iteration:11417  t-loss:0.0267, loss-lb:0.0114, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:41:41.099] iteration:11418  t-loss:0.0145, loss-lb:0.0116, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:41:41.480] iteration:11419  t-loss:0.0148, loss-lb:0.0107, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:41:41.866] iteration:11420  t-loss:0.0161, loss-lb:0.0108, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:41:42.257] iteration:11421  t-loss:0.0306, loss-lb:0.0271, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:41:42.652] iteration:11422  t-loss:0.0297, loss-lb:0.0199, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:41:43.048] iteration:11423  t-loss:0.1031, loss-lb:0.0301, loss-ulb:0.0365, weight:2.00, lr:0.0003
[01:41:43.444] iteration:11424  t-loss:0.0239, loss-lb:0.0182, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:41:43.844] iteration:11425  t-loss:0.0308, loss-lb:0.0273, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:41:44.238] iteration:11426  t-loss:0.0163, loss-lb:0.0131, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:41:44.624] iteration:11427  t-loss:0.0159, loss-lb:0.0136, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:41:45.018] iteration:11428  t-loss:0.0239, loss-lb:0.0102, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:41:45.414] iteration:11429  t-loss:0.0332, loss-lb:0.0253, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:41:45.794] iteration:11430  t-loss:0.0345, loss-lb:0.0221, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:41:46.175] iteration:11431  t-loss:0.0697, loss-lb:0.0580, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:41:46.556] iteration:11432  t-loss:0.0341, loss-lb:0.0207, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:41:46.936] iteration:11433  t-loss:0.0259, loss-lb:0.0119, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:41:47.313] iteration:11434  t-loss:0.0141, loss-lb:0.0127, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:41:47.699] iteration:11435  t-loss:0.0292, loss-lb:0.0171, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:41:48.075] iteration:11436  t-loss:0.0181, loss-lb:0.0164, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:41:48.453] iteration:11437  t-loss:0.0364, loss-lb:0.0337, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:41:48.834] iteration:11438  t-loss:0.0214, loss-lb:0.0195, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:00.161] iteration 11438 : dice_score: 0.902949 best_dice: 0.902900
[01:43:00.162]  <<Test>> - Ep:300  - Dice-S/T:89.51/90.29, Best-S:90.09, Best-T:90.29
[01:43:00.162]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:43:01.377] iteration:11439  t-loss:0.0131, loss-lb:0.0116, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:43:01.769] iteration:11440  t-loss:0.0160, loss-lb:0.0126, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:43:02.154] iteration:11441  t-loss:0.0276, loss-lb:0.0222, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:43:02.541] iteration:11442  t-loss:0.0580, loss-lb:0.0456, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:43:02.921] iteration:11443  t-loss:0.0153, loss-lb:0.0129, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:43:03.301] iteration:11444  t-loss:0.0247, loss-lb:0.0220, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:43:03.684] iteration:11445  t-loss:0.0467, loss-lb:0.0268, loss-ulb:0.0099, weight:2.00, lr:0.0003
[01:43:04.060] iteration:11446  t-loss:0.0352, loss-lb:0.0121, loss-ulb:0.0116, weight:2.00, lr:0.0003
[01:43:04.438] iteration:11447  t-loss:0.0298, loss-lb:0.0268, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:43:04.821] iteration:11448  t-loss:0.0383, loss-lb:0.0228, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:43:05.199] iteration:11449  t-loss:0.0202, loss-lb:0.0129, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:43:05.578] iteration:11450  t-loss:0.0255, loss-lb:0.0188, loss-ulb:0.0033, weight:2.00, lr:0.0003
[01:43:05.960] iteration:11451  t-loss:0.0547, loss-lb:0.0229, loss-ulb:0.0159, weight:2.00, lr:0.0003
[01:43:06.349] iteration:11452  t-loss:0.0399, loss-lb:0.0225, loss-ulb:0.0087, weight:2.00, lr:0.0003
[01:43:06.736] iteration:11453  t-loss:0.0533, loss-lb:0.0199, loss-ulb:0.0167, weight:2.00, lr:0.0003
[01:43:07.126] iteration:11454  t-loss:0.0225, loss-lb:0.0139, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:43:07.509] iteration:11455  t-loss:0.0244, loss-lb:0.0102, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:43:07.898] iteration:11456  t-loss:0.0292, loss-lb:0.0157, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:43:08.281] iteration:11457  t-loss:0.0215, loss-lb:0.0156, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:43:08.669] iteration:11458  t-loss:0.0263, loss-lb:0.0211, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:43:09.056] iteration:11459  t-loss:0.0549, loss-lb:0.0376, loss-ulb:0.0087, weight:2.00, lr:0.0003
[01:43:09.441] iteration:11460  t-loss:0.0220, loss-lb:0.0178, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:43:09.825] iteration:11461  t-loss:0.0191, loss-lb:0.0113, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:43:10.204] iteration:11462  t-loss:0.0214, loss-lb:0.0138, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:43:10.587] iteration:11463  t-loss:0.0333, loss-lb:0.0307, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:43:10.980] iteration:11464  t-loss:0.0297, loss-lb:0.0107, loss-ulb:0.0095, weight:2.00, lr:0.0003
[01:43:11.379] iteration:11465  t-loss:0.0287, loss-lb:0.0237, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:43:11.783] iteration:11466  t-loss:0.0272, loss-lb:0.0229, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:43:12.169] iteration:11467  t-loss:0.0297, loss-lb:0.0146, loss-ulb:0.0076, weight:2.00, lr:0.0003
[01:43:12.553] iteration:11468  t-loss:0.0404, loss-lb:0.0121, loss-ulb:0.0142, weight:2.00, lr:0.0003
[01:43:12.942] iteration:11469  t-loss:0.0384, loss-lb:0.0157, loss-ulb:0.0114, weight:2.00, lr:0.0003
[01:43:13.323] iteration:11470  t-loss:0.0415, loss-lb:0.0259, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:43:13.704] iteration:11471  t-loss:0.0143, loss-lb:0.0108, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:43:14.097] iteration:11472  t-loss:0.0372, loss-lb:0.0218, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:43:14.485] iteration:11473  t-loss:0.0164, loss-lb:0.0111, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:43:14.882] iteration:11474  t-loss:0.0465, loss-lb:0.0343, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:43:15.266] iteration:11475  t-loss:0.0416, loss-lb:0.0285, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:43:15.643] iteration:11476  t-loss:0.0404, loss-lb:0.0351, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:43:17.011] iteration:11477  t-loss:0.0176, loss-lb:0.0139, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:43:17.400] iteration:11478  t-loss:0.0173, loss-lb:0.0142, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:43:17.788] iteration:11479  t-loss:0.0301, loss-lb:0.0281, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:43:18.174] iteration:11480  t-loss:0.0402, loss-lb:0.0358, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:43:18.557] iteration:11481  t-loss:0.0261, loss-lb:0.0156, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:43:18.939] iteration:11482  t-loss:0.0246, loss-lb:0.0137, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:43:19.317] iteration:11483  t-loss:0.0347, loss-lb:0.0316, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:43:19.700] iteration:11484  t-loss:0.0204, loss-lb:0.0101, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:43:20.082] iteration:11485  t-loss:0.0345, loss-lb:0.0280, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:43:20.463] iteration:11486  t-loss:0.0148, loss-lb:0.0128, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:43:20.846] iteration:11487  t-loss:0.0243, loss-lb:0.0199, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:43:21.230] iteration:11488  t-loss:0.0226, loss-lb:0.0197, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:43:21.611] iteration:11489  t-loss:0.0158, loss-lb:0.0115, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:43:21.991] iteration:11490  t-loss:0.0143, loss-lb:0.0126, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:22.375] iteration:11491  t-loss:0.0252, loss-lb:0.0227, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:43:22.760] iteration:11492  t-loss:0.0299, loss-lb:0.0213, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:43:23.143] iteration:11493  t-loss:0.0270, loss-lb:0.0127, loss-ulb:0.0072, weight:2.00, lr:0.0003
[01:43:23.522] iteration:11494  t-loss:0.0162, loss-lb:0.0126, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:43:23.904] iteration:11495  t-loss:0.0467, loss-lb:0.0239, loss-ulb:0.0114, weight:2.00, lr:0.0003
[01:43:24.286] iteration:11496  t-loss:0.0281, loss-lb:0.0191, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:43:24.665] iteration:11497  t-loss:0.0121, loss-lb:0.0101, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:43:25.042] iteration:11498  t-loss:0.0162, loss-lb:0.0131, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:43:25.425] iteration:11499  t-loss:0.0295, loss-lb:0.0227, loss-ulb:0.0034, weight:2.00, lr:0.0003
[01:43:25.813] iteration:11500  t-loss:0.0567, loss-lb:0.0161, loss-ulb:0.0203, weight:2.00, lr:0.0003
[01:43:26.197] iteration:11501  t-loss:0.0140, loss-lb:0.0109, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:43:26.590] iteration:11502  t-loss:0.0276, loss-lb:0.0105, loss-ulb:0.0085, weight:2.00, lr:0.0003
[01:43:26.989] iteration:11503  t-loss:0.0451, loss-lb:0.0107, loss-ulb:0.0172, weight:2.00, lr:0.0003
[01:43:27.381] iteration:11504  t-loss:0.0336, loss-lb:0.0230, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:43:27.764] iteration:11505  t-loss:0.0236, loss-lb:0.0102, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:43:28.146] iteration:11506  t-loss:0.0127, loss-lb:0.0105, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:43:28.527] iteration:11507  t-loss:0.0174, loss-lb:0.0113, loss-ulb:0.0030, weight:2.00, lr:0.0003
[01:43:28.903] iteration:11508  t-loss:0.0204, loss-lb:0.0150, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:43:29.286] iteration:11509  t-loss:0.0339, loss-lb:0.0255, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:43:29.670] iteration:11510  t-loss:0.0134, loss-lb:0.0107, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:43:30.057] iteration:11511  t-loss:0.0120, loss-lb:0.0102, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:30.441] iteration:11512  t-loss:0.0320, loss-lb:0.0273, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:43:30.823] iteration:11513  t-loss:0.0331, loss-lb:0.0291, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:43:31.203] iteration:11514  t-loss:0.0429, loss-lb:0.0274, loss-ulb:0.0078, weight:2.00, lr:0.0003
[01:43:32.636] iteration:11515  t-loss:0.0514, loss-lb:0.0287, loss-ulb:0.0113, weight:2.00, lr:0.0003
[01:43:33.033] iteration:11516  t-loss:0.0681, loss-lb:0.0098, loss-ulb:0.0292, weight:2.00, lr:0.0003
[01:43:33.431] iteration:11517  t-loss:0.0481, loss-lb:0.0225, loss-ulb:0.0128, weight:2.00, lr:0.0003
[01:43:33.820] iteration:11518  t-loss:0.0219, loss-lb:0.0136, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:43:34.212] iteration:11519  t-loss:0.0327, loss-lb:0.0304, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:43:34.598] iteration:11520  t-loss:0.0249, loss-lb:0.0190, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:43:34.982] iteration:11521  t-loss:0.0214, loss-lb:0.0110, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:43:35.367] iteration:11522  t-loss:0.0397, loss-lb:0.0210, loss-ulb:0.0094, weight:2.00, lr:0.0003
[01:43:35.752] iteration:11523  t-loss:0.0283, loss-lb:0.0236, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:43:36.136] iteration:11524  t-loss:0.0343, loss-lb:0.0318, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:43:36.524] iteration:11525  t-loss:0.0252, loss-lb:0.0133, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:43:36.910] iteration:11526  t-loss:0.0400, loss-lb:0.0193, loss-ulb:0.0104, weight:2.00, lr:0.0003
[01:43:37.297] iteration:11527  t-loss:0.0232, loss-lb:0.0214, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:37.683] iteration:11528  t-loss:0.0441, loss-lb:0.0236, loss-ulb:0.0102, weight:2.00, lr:0.0003
[01:43:38.072] iteration:11529  t-loss:0.0250, loss-lb:0.0228, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:43:38.456] iteration:11530  t-loss:0.0278, loss-lb:0.0253, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:43:38.839] iteration:11531  t-loss:0.0264, loss-lb:0.0207, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:43:39.214] iteration:11532  t-loss:0.0168, loss-lb:0.0139, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:43:39.604] iteration:11533  t-loss:0.0255, loss-lb:0.0236, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:39.993] iteration:11534  t-loss:0.0292, loss-lb:0.0231, loss-ulb:0.0030, weight:2.00, lr:0.0003
[01:43:40.383] iteration:11535  t-loss:0.0570, loss-lb:0.0121, loss-ulb:0.0225, weight:2.00, lr:0.0003
[01:43:40.762] iteration:11536  t-loss:0.0160, loss-lb:0.0139, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:43:41.142] iteration:11537  t-loss:0.0466, loss-lb:0.0092, loss-ulb:0.0187, weight:2.00, lr:0.0003
[01:43:41.536] iteration:11538  t-loss:0.0297, loss-lb:0.0161, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:43:41.925] iteration:11539  t-loss:0.0213, loss-lb:0.0130, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:43:42.322] iteration:11540  t-loss:0.0181, loss-lb:0.0107, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:43:42.709] iteration:11541  t-loss:0.0130, loss-lb:0.0112, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:43.091] iteration:11542  t-loss:0.0217, loss-lb:0.0117, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:43:43.473] iteration:11543  t-loss:0.0172, loss-lb:0.0122, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:43:43.860] iteration:11544  t-loss:0.0393, loss-lb:0.0303, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:43:44.243] iteration:11545  t-loss:0.0266, loss-lb:0.0185, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:43:44.621] iteration:11546  t-loss:0.0197, loss-lb:0.0114, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:43:45.009] iteration:11547  t-loss:0.0338, loss-lb:0.0202, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:43:45.401] iteration:11548  t-loss:0.0478, loss-lb:0.0294, loss-ulb:0.0092, weight:2.00, lr:0.0003
[01:43:45.793] iteration:11549  t-loss:0.0211, loss-lb:0.0189, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:43:46.176] iteration:11550  t-loss:0.0371, loss-lb:0.0115, loss-ulb:0.0128, weight:2.00, lr:0.0003
[01:43:46.556] iteration:11551  t-loss:0.0178, loss-lb:0.0147, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:43:46.934] iteration:11552  t-loss:0.0191, loss-lb:0.0173, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:48.318] iteration:11553  t-loss:0.0217, loss-lb:0.0115, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:43:48.729] iteration:11554  t-loss:0.0422, loss-lb:0.0293, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:43:49.118] iteration:11555  t-loss:0.0387, loss-lb:0.0269, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:43:49.508] iteration:11556  t-loss:0.0419, loss-lb:0.0279, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:43:49.905] iteration:11557  t-loss:0.0615, loss-lb:0.0332, loss-ulb:0.0142, weight:2.00, lr:0.0003
[01:43:50.291] iteration:11558  t-loss:0.0162, loss-lb:0.0134, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:43:50.672] iteration:11559  t-loss:0.0147, loss-lb:0.0102, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:43:51.053] iteration:11560  t-loss:0.0449, loss-lb:0.0167, loss-ulb:0.0141, weight:2.00, lr:0.0003
[01:43:51.445] iteration:11561  t-loss:0.0329, loss-lb:0.0298, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:43:51.858] iteration:11562  t-loss:0.0372, loss-lb:0.0140, loss-ulb:0.0116, weight:2.00, lr:0.0003
[01:43:52.250] iteration:11563  t-loss:0.0233, loss-lb:0.0216, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:43:52.645] iteration:11564  t-loss:0.0233, loss-lb:0.0205, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:43:53.027] iteration:11565  t-loss:0.0226, loss-lb:0.0193, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:43:53.415] iteration:11566  t-loss:0.0219, loss-lb:0.0129, loss-ulb:0.0045, weight:2.00, lr:0.0003
[01:43:53.803] iteration:11567  t-loss:0.0329, loss-lb:0.0313, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:43:54.179] iteration:11568  t-loss:0.0256, loss-lb:0.0203, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:43:54.558] iteration:11569  t-loss:0.0179, loss-lb:0.0137, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:43:54.939] iteration:11570  t-loss:0.0267, loss-lb:0.0233, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:43:55.321] iteration:11571  t-loss:0.0357, loss-lb:0.0314, loss-ulb:0.0022, weight:2.00, lr:0.0003
[01:43:55.708] iteration:11572  t-loss:0.0176, loss-lb:0.0093, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:43:56.098] iteration:11573  t-loss:0.0294, loss-lb:0.0191, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:43:56.484] iteration:11574  t-loss:0.0406, loss-lb:0.0217, loss-ulb:0.0095, weight:2.00, lr:0.0003
[01:43:56.866] iteration:11575  t-loss:0.0153, loss-lb:0.0112, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:43:57.246] iteration:11576  t-loss:0.0191, loss-lb:0.0090, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:43:57.635] iteration:11577  t-loss:0.0356, loss-lb:0.0291, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:43:58.023] iteration:11578  t-loss:0.0604, loss-lb:0.0250, loss-ulb:0.0177, weight:2.00, lr:0.0003
[01:43:58.410] iteration:11579  t-loss:0.0321, loss-lb:0.0199, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:43:58.791] iteration:11580  t-loss:0.0327, loss-lb:0.0129, loss-ulb:0.0099, weight:2.00, lr:0.0003
[01:43:59.177] iteration:11581  t-loss:0.0198, loss-lb:0.0137, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:43:59.556] iteration:11582  t-loss:0.0271, loss-lb:0.0125, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:43:59.935] iteration:11583  t-loss:0.0295, loss-lb:0.0117, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:44:00.313] iteration:11584  t-loss:0.0257, loss-lb:0.0241, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:44:00.703] iteration:11585  t-loss:0.0260, loss-lb:0.0133, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:44:01.103] iteration:11586  t-loss:0.0204, loss-lb:0.0118, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:44:01.507] iteration:11587  t-loss:0.0251, loss-lb:0.0175, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:44:01.895] iteration:11588  t-loss:0.0273, loss-lb:0.0170, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:44:02.286] iteration:11589  t-loss:0.0210, loss-lb:0.0185, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:44:02.668] iteration:11590  t-loss:0.0349, loss-lb:0.0319, loss-ulb:0.0015, weight:2.00, lr:0.0003
[01:45:12.965] iteration 11590 : dice_score: 0.901932 best_dice: 0.902900
[01:45:12.965]  <<Test>> - Ep:304  - Dice-S/T:90.00/90.19, Best-S:90.09, Best-T:90.29
[01:45:12.965]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:45:14.138] iteration:11591  t-loss:0.0325, loss-lb:0.0213, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:45:14.532] iteration:11592  t-loss:0.0260, loss-lb:0.0231, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:45:14.914] iteration:11593  t-loss:0.0275, loss-lb:0.0258, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:45:15.299] iteration:11594  t-loss:0.0376, loss-lb:0.0199, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:45:15.690] iteration:11595  t-loss:0.0406, loss-lb:0.0212, loss-ulb:0.0097, weight:2.00, lr:0.0003
[01:45:16.083] iteration:11596  t-loss:0.0144, loss-lb:0.0127, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:45:16.471] iteration:11597  t-loss:0.0197, loss-lb:0.0120, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:45:16.864] iteration:11598  t-loss:0.0558, loss-lb:0.0235, loss-ulb:0.0161, weight:2.00, lr:0.0003
[01:45:17.258] iteration:11599  t-loss:0.0423, loss-lb:0.0337, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:45:17.638] iteration:11600  t-loss:0.0149, loss-lb:0.0114, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:45:18.033] iteration:11601  t-loss:0.0343, loss-lb:0.0110, loss-ulb:0.0116, weight:2.00, lr:0.0003
[01:45:18.426] iteration:11602  t-loss:0.0201, loss-lb:0.0159, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:45:18.820] iteration:11603  t-loss:0.0287, loss-lb:0.0209, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:45:19.206] iteration:11604  t-loss:0.0294, loss-lb:0.0148, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:45:19.597] iteration:11605  t-loss:0.0373, loss-lb:0.0236, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:45:19.978] iteration:11606  t-loss:0.0307, loss-lb:0.0180, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:45:20.368] iteration:11607  t-loss:0.0393, loss-lb:0.0244, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:45:20.756] iteration:11608  t-loss:0.0412, loss-lb:0.0178, loss-ulb:0.0117, weight:2.00, lr:0.0003
[01:45:21.136] iteration:11609  t-loss:0.0173, loss-lb:0.0137, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:45:21.526] iteration:11610  t-loss:0.0230, loss-lb:0.0207, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:45:21.926] iteration:11611  t-loss:0.0171, loss-lb:0.0138, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:45:22.326] iteration:11612  t-loss:0.0373, loss-lb:0.0136, loss-ulb:0.0119, weight:2.00, lr:0.0003
[01:45:22.715] iteration:11613  t-loss:0.0230, loss-lb:0.0204, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:45:23.097] iteration:11614  t-loss:0.0290, loss-lb:0.0209, loss-ulb:0.0041, weight:2.00, lr:0.0003
[01:45:23.481] iteration:11615  t-loss:0.0225, loss-lb:0.0202, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:45:23.864] iteration:11616  t-loss:0.0239, loss-lb:0.0215, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:45:24.253] iteration:11617  t-loss:0.0233, loss-lb:0.0209, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:45:24.645] iteration:11618  t-loss:0.0428, loss-lb:0.0225, loss-ulb:0.0101, weight:2.00, lr:0.0003
[01:45:25.022] iteration:11619  t-loss:0.0136, loss-lb:0.0115, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:45:25.407] iteration:11620  t-loss:0.0263, loss-lb:0.0105, loss-ulb:0.0079, weight:2.00, lr:0.0003
[01:45:25.790] iteration:11621  t-loss:0.0246, loss-lb:0.0106, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:45:26.172] iteration:11622  t-loss:0.0244, loss-lb:0.0115, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:45:26.555] iteration:11623  t-loss:0.0431, loss-lb:0.0197, loss-ulb:0.0117, weight:2.00, lr:0.0003
[01:45:26.932] iteration:11624  t-loss:0.0206, loss-lb:0.0193, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:45:27.313] iteration:11625  t-loss:0.0344, loss-lb:0.0192, loss-ulb:0.0076, weight:2.00, lr:0.0003
[01:45:27.694] iteration:11626  t-loss:0.0326, loss-lb:0.0189, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:45:28.071] iteration:11627  t-loss:0.0245, loss-lb:0.0119, loss-ulb:0.0063, weight:2.00, lr:0.0003
[01:45:28.450] iteration:11628  t-loss:0.0197, loss-lb:0.0101, loss-ulb:0.0048, weight:2.00, lr:0.0003
[01:45:29.803] iteration:11629  t-loss:0.0422, loss-lb:0.0385, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:45:30.207] iteration:11630  t-loss:0.0325, loss-lb:0.0227, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:45:30.588] iteration:11631  t-loss:0.0300, loss-lb:0.0192, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:45:30.974] iteration:11632  t-loss:0.0325, loss-lb:0.0191, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:45:31.355] iteration:11633  t-loss:0.0189, loss-lb:0.0140, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:45:31.735] iteration:11634  t-loss:0.0155, loss-lb:0.0139, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:45:32.119] iteration:11635  t-loss:0.0456, loss-lb:0.0186, loss-ulb:0.0135, weight:2.00, lr:0.0003
[01:45:32.508] iteration:11636  t-loss:0.0302, loss-lb:0.0181, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:45:32.893] iteration:11637  t-loss:0.0139, loss-lb:0.0124, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:45:33.281] iteration:11638  t-loss:0.0322, loss-lb:0.0216, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:45:33.667] iteration:11639  t-loss:0.0270, loss-lb:0.0128, loss-ulb:0.0071, weight:2.00, lr:0.0003
[01:45:34.061] iteration:11640  t-loss:0.0596, loss-lb:0.0250, loss-ulb:0.0173, weight:2.00, lr:0.0003
[01:45:34.444] iteration:11641  t-loss:0.0246, loss-lb:0.0139, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:45:34.826] iteration:11642  t-loss:0.0286, loss-lb:0.0224, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:45:35.202] iteration:11643  t-loss:0.0147, loss-lb:0.0120, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:45:35.588] iteration:11644  t-loss:0.0327, loss-lb:0.0122, loss-ulb:0.0102, weight:2.00, lr:0.0003
[01:45:35.970] iteration:11645  t-loss:0.0179, loss-lb:0.0139, loss-ulb:0.0020, weight:2.00, lr:0.0003
[01:45:36.355] iteration:11646  t-loss:0.0248, loss-lb:0.0170, loss-ulb:0.0039, weight:2.00, lr:0.0003
[01:45:36.755] iteration:11647  t-loss:0.0396, loss-lb:0.0213, loss-ulb:0.0092, weight:2.00, lr:0.0003
[01:45:37.150] iteration:11648  t-loss:0.0258, loss-lb:0.0202, loss-ulb:0.0028, weight:2.00, lr:0.0003
[01:45:37.552] iteration:11649  t-loss:0.0356, loss-lb:0.0235, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:45:37.937] iteration:11650  t-loss:0.0365, loss-lb:0.0106, loss-ulb:0.0129, weight:2.00, lr:0.0003
[01:45:38.333] iteration:11651  t-loss:0.0399, loss-lb:0.0270, loss-ulb:0.0064, weight:2.00, lr:0.0003
[01:45:38.723] iteration:11652  t-loss:0.0184, loss-lb:0.0099, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:45:39.104] iteration:11653  t-loss:0.0247, loss-lb:0.0117, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:45:39.485] iteration:11654  t-loss:0.0233, loss-lb:0.0111, loss-ulb:0.0061, weight:2.00, lr:0.0003
[01:45:39.870] iteration:11655  t-loss:0.0196, loss-lb:0.0171, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:45:40.255] iteration:11656  t-loss:0.0313, loss-lb:0.0111, loss-ulb:0.0101, weight:2.00, lr:0.0003
[01:45:40.637] iteration:11657  t-loss:0.0165, loss-lb:0.0145, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:45:41.015] iteration:11658  t-loss:0.0130, loss-lb:0.0107, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:45:41.400] iteration:11659  t-loss:0.0251, loss-lb:0.0154, loss-ulb:0.0049, weight:2.00, lr:0.0003
[01:45:41.780] iteration:11660  t-loss:0.0389, loss-lb:0.0365, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:45:42.157] iteration:11661  t-loss:0.0231, loss-lb:0.0206, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:45:42.540] iteration:11662  t-loss:0.0301, loss-lb:0.0097, loss-ulb:0.0102, weight:2.00, lr:0.0003
[01:45:42.923] iteration:11663  t-loss:0.0225, loss-lb:0.0113, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:45:43.309] iteration:11664  t-loss:0.0411, loss-lb:0.0298, loss-ulb:0.0056, weight:2.00, lr:0.0003
[01:45:43.699] iteration:11665  t-loss:0.0366, loss-lb:0.0250, loss-ulb:0.0058, weight:2.00, lr:0.0003
[01:45:44.083] iteration:11666  t-loss:0.0387, loss-lb:0.0270, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:45:45.313] iteration:11667  t-loss:0.0231, loss-lb:0.0217, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:45:45.713] iteration:11668  t-loss:0.0374, loss-lb:0.0298, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:45:46.103] iteration:11669  t-loss:0.0361, loss-lb:0.0259, loss-ulb:0.0051, weight:2.00, lr:0.0003
[01:45:46.495] iteration:11670  t-loss:0.0415, loss-lb:0.0283, loss-ulb:0.0066, weight:2.00, lr:0.0003
[01:45:46.878] iteration:11671  t-loss:0.0240, loss-lb:0.0182, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:45:47.263] iteration:11672  t-loss:0.0590, loss-lb:0.0490, loss-ulb:0.0050, weight:2.00, lr:0.0003
[01:45:47.647] iteration:11673  t-loss:0.0162, loss-lb:0.0140, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:45:48.030] iteration:11674  t-loss:0.0386, loss-lb:0.0238, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:45:48.416] iteration:11675  t-loss:0.0549, loss-lb:0.0282, loss-ulb:0.0134, weight:2.00, lr:0.0003
[01:45:48.802] iteration:11676  t-loss:0.0334, loss-lb:0.0107, loss-ulb:0.0114, weight:2.00, lr:0.0003
[01:45:49.199] iteration:11677  t-loss:0.0335, loss-lb:0.0241, loss-ulb:0.0047, weight:2.00, lr:0.0003
[01:45:49.587] iteration:11678  t-loss:0.0184, loss-lb:0.0120, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:45:49.972] iteration:11679  t-loss:0.0281, loss-lb:0.0209, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:45:50.357] iteration:11680  t-loss:0.0372, loss-lb:0.0194, loss-ulb:0.0089, weight:2.00, lr:0.0003
[01:45:50.736] iteration:11681  t-loss:0.0233, loss-lb:0.0199, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:45:51.117] iteration:11682  t-loss:0.0285, loss-lb:0.0266, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:45:51.500] iteration:11683  t-loss:0.0277, loss-lb:0.0122, loss-ulb:0.0077, weight:2.00, lr:0.0003
[01:45:51.881] iteration:11684  t-loss:0.0264, loss-lb:0.0238, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:45:52.272] iteration:11685  t-loss:0.0259, loss-lb:0.0240, loss-ulb:0.0009, weight:2.00, lr:0.0003
[01:45:52.673] iteration:11686  t-loss:0.0228, loss-lb:0.0123, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:45:53.073] iteration:11687  t-loss:0.0377, loss-lb:0.0117, loss-ulb:0.0130, weight:2.00, lr:0.0003
[01:45:53.470] iteration:11688  t-loss:0.0259, loss-lb:0.0121, loss-ulb:0.0069, weight:2.00, lr:0.0003
[01:45:53.865] iteration:11689  t-loss:0.0427, loss-lb:0.0356, loss-ulb:0.0035, weight:2.00, lr:0.0003
[01:45:54.261] iteration:11690  t-loss:0.0283, loss-lb:0.0108, loss-ulb:0.0087, weight:2.00, lr:0.0003
[01:45:54.656] iteration:11691  t-loss:0.0216, loss-lb:0.0130, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:45:55.046] iteration:11692  t-loss:0.0343, loss-lb:0.0238, loss-ulb:0.0052, weight:2.00, lr:0.0003
[01:45:55.440] iteration:11693  t-loss:0.0199, loss-lb:0.0135, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:45:55.825] iteration:11694  t-loss:0.0284, loss-lb:0.0269, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:45:56.212] iteration:11695  t-loss:0.0336, loss-lb:0.0196, loss-ulb:0.0070, weight:2.00, lr:0.0003
[01:45:56.599] iteration:11696  t-loss:0.0222, loss-lb:0.0210, loss-ulb:0.0006, weight:2.00, lr:0.0003
[01:45:56.983] iteration:11697  t-loss:0.0220, loss-lb:0.0110, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:45:57.360] iteration:11698  t-loss:0.0151, loss-lb:0.0131, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:45:57.741] iteration:11699  t-loss:0.0449, loss-lb:0.0258, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:45:58.123] iteration:11700  t-loss:0.0592, loss-lb:0.0304, loss-ulb:0.0144, weight:2.00, lr:0.0003
[01:45:58.500] iteration:11701  t-loss:0.0128, loss-lb:0.0108, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:45:58.876] iteration:11702  t-loss:0.0179, loss-lb:0.0132, loss-ulb:0.0023, weight:2.00, lr:0.0003
[01:45:59.253] iteration:11703  t-loss:0.0264, loss-lb:0.0114, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:45:59.631] iteration:11704  t-loss:0.0135, loss-lb:0.0094, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:46:01.090] iteration:11705  t-loss:0.0175, loss-lb:0.0153, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:46:01.497] iteration:11706  t-loss:0.0236, loss-lb:0.0186, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:46:01.885] iteration:11707  t-loss:0.0434, loss-lb:0.0385, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:46:02.265] iteration:11708  t-loss:0.0849, loss-lb:0.0100, loss-ulb:0.0374, weight:2.00, lr:0.0003
[01:46:02.655] iteration:11709  t-loss:0.0343, loss-lb:0.0210, loss-ulb:0.0067, weight:2.00, lr:0.0003
[01:46:03.040] iteration:11710  t-loss:0.0212, loss-lb:0.0187, loss-ulb:0.0013, weight:2.00, lr:0.0003
[01:46:03.422] iteration:11711  t-loss:0.0265, loss-lb:0.0232, loss-ulb:0.0017, weight:2.00, lr:0.0003
[01:46:03.802] iteration:11712  t-loss:0.0203, loss-lb:0.0186, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:46:04.196] iteration:11713  t-loss:0.0366, loss-lb:0.0196, loss-ulb:0.0085, weight:2.00, lr:0.0003
[01:46:04.587] iteration:11714  t-loss:0.0209, loss-lb:0.0138, loss-ulb:0.0036, weight:2.00, lr:0.0003
[01:46:04.980] iteration:11715  t-loss:0.0304, loss-lb:0.0266, loss-ulb:0.0019, weight:2.00, lr:0.0003
[01:46:05.375] iteration:11716  t-loss:0.0137, loss-lb:0.0123, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:46:05.755] iteration:11717  t-loss:0.0306, loss-lb:0.0256, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:46:06.143] iteration:11718  t-loss:0.0453, loss-lb:0.0228, loss-ulb:0.0112, weight:2.00, lr:0.0003
[01:46:06.525] iteration:11719  t-loss:0.0158, loss-lb:0.0096, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:46:06.905] iteration:11720  t-loss:0.0573, loss-lb:0.0549, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:46:07.289] iteration:11721  t-loss:0.0329, loss-lb:0.0192, loss-ulb:0.0068, weight:2.00, lr:0.0003
[01:46:07.665] iteration:11722  t-loss:0.0510, loss-lb:0.0467, loss-ulb:0.0021, weight:2.00, lr:0.0003
[01:46:08.065] iteration:11723  t-loss:0.0427, loss-lb:0.0348, loss-ulb:0.0040, weight:2.00, lr:0.0003
[01:46:08.464] iteration:11724  t-loss:0.0408, loss-lb:0.0355, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:46:08.869] iteration:11725  t-loss:0.0352, loss-lb:0.0244, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:46:09.254] iteration:11726  t-loss:0.0172, loss-lb:0.0115, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:46:09.636] iteration:11727  t-loss:0.0194, loss-lb:0.0182, loss-ulb:0.0006, weight:2.00, lr:0.0003
[01:46:10.017] iteration:11728  t-loss:0.0263, loss-lb:0.0111, loss-ulb:0.0076, weight:2.00, lr:0.0003
[01:46:10.412] iteration:11729  t-loss:0.0216, loss-lb:0.0167, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:46:10.808] iteration:11730  t-loss:0.0388, loss-lb:0.0336, loss-ulb:0.0026, weight:2.00, lr:0.0003
[01:46:11.214] iteration:11731  t-loss:0.0331, loss-lb:0.0222, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:46:11.612] iteration:11732  t-loss:0.0670, loss-lb:0.0385, loss-ulb:0.0142, weight:2.00, lr:0.0003
[01:46:12.002] iteration:11733  t-loss:0.0250, loss-lb:0.0125, loss-ulb:0.0062, weight:2.00, lr:0.0003
[01:46:12.384] iteration:11734  t-loss:0.0209, loss-lb:0.0185, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:46:12.767] iteration:11735  t-loss:0.0411, loss-lb:0.0228, loss-ulb:0.0092, weight:2.00, lr:0.0003
[01:46:13.159] iteration:11736  t-loss:0.0389, loss-lb:0.0217, loss-ulb:0.0086, weight:2.00, lr:0.0003
[01:46:13.540] iteration:11737  t-loss:0.0178, loss-lb:0.0115, loss-ulb:0.0032, weight:2.00, lr:0.0003
[01:46:13.919] iteration:11738  t-loss:0.0243, loss-lb:0.0125, loss-ulb:0.0059, weight:2.00, lr:0.0003
[01:46:14.301] iteration:11739  t-loss:0.0146, loss-lb:0.0125, loss-ulb:0.0010, weight:2.00, lr:0.0003
[01:46:14.687] iteration:11740  t-loss:0.0444, loss-lb:0.0251, loss-ulb:0.0096, weight:2.00, lr:0.0003
[01:46:15.067] iteration:11741  t-loss:0.0292, loss-lb:0.0126, loss-ulb:0.0083, weight:2.00, lr:0.0003
[01:46:15.449] iteration:11742  t-loss:0.0378, loss-lb:0.0247, loss-ulb:0.0065, weight:2.00, lr:0.0003
[01:47:26.325] iteration 11742 : dice_score: 0.902061 best_dice: 0.902900
[01:47:26.326]  <<Test>> - Ep:308  - Dice-S/T:90.24/90.21, Best-S:90.24, Best-T:90.29
[01:47:26.326]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:47:27.356] iteration:11743  t-loss:0.0127, loss-lb:0.0110, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:47:27.759] iteration:11744  t-loss:0.0367, loss-lb:0.0290, loss-ulb:0.0038, weight:2.00, lr:0.0003
[01:47:28.142] iteration:11745  t-loss:0.0310, loss-lb:0.0261, loss-ulb:0.0024, weight:2.00, lr:0.0003
[01:47:28.524] iteration:11746  t-loss:0.0214, loss-lb:0.0191, loss-ulb:0.0012, weight:2.00, lr:0.0003
[01:47:28.911] iteration:11747  t-loss:0.0400, loss-lb:0.0206, loss-ulb:0.0097, weight:2.00, lr:0.0003
[01:47:29.293] iteration:11748  t-loss:0.0288, loss-lb:0.0257, loss-ulb:0.0016, weight:2.00, lr:0.0003
[01:47:29.674] iteration:11749  t-loss:0.0197, loss-lb:0.0134, loss-ulb:0.0031, weight:2.00, lr:0.0003
[01:47:30.053] iteration:11750  t-loss:0.0109, loss-lb:0.0098, loss-ulb:0.0005, weight:2.00, lr:0.0003
[01:47:30.441] iteration:11751  t-loss:0.0404, loss-lb:0.0200, loss-ulb:0.0102, weight:2.00, lr:0.0003
[01:47:30.822] iteration:11752  t-loss:0.0128, loss-lb:0.0101, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:47:31.211] iteration:11753  t-loss:0.0345, loss-lb:0.0197, loss-ulb:0.0074, weight:2.00, lr:0.0003
[01:47:31.594] iteration:11754  t-loss:0.0224, loss-lb:0.0104, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:47:31.979] iteration:11755  t-loss:0.0168, loss-lb:0.0093, loss-ulb:0.0037, weight:2.00, lr:0.0003
[01:47:32.360] iteration:11756  t-loss:0.0166, loss-lb:0.0151, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:47:32.743] iteration:11757  t-loss:0.0538, loss-lb:0.0387, loss-ulb:0.0075, weight:2.00, lr:0.0003
[01:47:33.129] iteration:11758  t-loss:0.0261, loss-lb:0.0176, loss-ulb:0.0043, weight:2.00, lr:0.0003
[01:47:33.516] iteration:11759  t-loss:0.0330, loss-lb:0.0185, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:47:33.908] iteration:11760  t-loss:0.0363, loss-lb:0.0253, loss-ulb:0.0055, weight:2.00, lr:0.0003
[01:47:34.290] iteration:11761  t-loss:0.0251, loss-lb:0.0085, loss-ulb:0.0083, weight:2.00, lr:0.0003
[01:47:34.677] iteration:11762  t-loss:0.0354, loss-lb:0.0271, loss-ulb:0.0042, weight:2.00, lr:0.0003
[01:47:35.054] iteration:11763  t-loss:0.0262, loss-lb:0.0116, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:47:35.440] iteration:11764  t-loss:0.0431, loss-lb:0.0209, loss-ulb:0.0111, weight:2.00, lr:0.0003
[01:47:35.819] iteration:11765  t-loss:0.0167, loss-lb:0.0132, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:47:36.199] iteration:11766  t-loss:0.0265, loss-lb:0.0238, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:47:36.575] iteration:11767  t-loss:0.0149, loss-lb:0.0112, loss-ulb:0.0018, weight:2.00, lr:0.0003
[01:47:36.977] iteration:11768  t-loss:0.0242, loss-lb:0.0214, loss-ulb:0.0014, weight:2.00, lr:0.0003
[01:47:37.389] iteration:11769  t-loss:0.0420, loss-lb:0.0314, loss-ulb:0.0053, weight:2.00, lr:0.0003
[01:47:37.799] iteration:11770  t-loss:0.0130, loss-lb:0.0109, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:47:38.187] iteration:11771  t-loss:0.0359, loss-lb:0.0117, loss-ulb:0.0121, weight:2.00, lr:0.0003
[01:47:38.567] iteration:11772  t-loss:0.0189, loss-lb:0.0131, loss-ulb:0.0029, weight:2.00, lr:0.0003
[01:47:38.947] iteration:11773  t-loss:0.0236, loss-lb:0.0186, loss-ulb:0.0025, weight:2.00, lr:0.0003
[01:47:39.330] iteration:11774  t-loss:0.0419, loss-lb:0.0187, loss-ulb:0.0116, weight:2.00, lr:0.0003
[01:47:39.709] iteration:11775  t-loss:0.0208, loss-lb:0.0100, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:47:40.091] iteration:11776  t-loss:0.0287, loss-lb:0.0173, loss-ulb:0.0057, weight:2.00, lr:0.0003
[01:47:40.476] iteration:11777  t-loss:0.0244, loss-lb:0.0099, loss-ulb:0.0073, weight:2.00, lr:0.0003
[01:47:40.861] iteration:11778  t-loss:0.0399, loss-lb:0.0204, loss-ulb:0.0098, weight:2.00, lr:0.0003
[01:47:41.237] iteration:11779  t-loss:0.0208, loss-lb:0.0192, loss-ulb:0.0008, weight:2.00, lr:0.0003
[01:47:41.616] iteration:11780  t-loss:0.0212, loss-lb:0.0105, loss-ulb:0.0054, weight:2.00, lr:0.0003
[01:47:42.965] iteration:11781  t-loss:0.0355, loss-lb:0.0300, loss-ulb:0.0027, weight:2.00, lr:0.0003
[01:47:43.355] iteration:11782  t-loss:0.0300, loss-lb:0.0279, loss-ulb:0.0011, weight:2.00, lr:0.0003
[01:47:43.746] iteration:11783  t-loss:0.0311, loss-lb:0.0298, loss-ulb:0.0007, weight:2.00, lr:0.0003
[01:47:44.135] iteration:11784  t-loss:0.0341, loss-lb:0.0221, loss-ulb:0.0060, weight:2.00, lr:0.0003
[01:47:44.528] iteration:11785  t-loss:0.0411, loss-lb:0.0235, loss-ulb:0.0088, weight:2.00, lr:0.0003
[01:47:44.919] iteration:11786  t-loss:0.0295, loss-lb:0.0124, loss-ulb:0.0085, weight:2.00, lr:0.0003
[01:47:45.301] iteration:11787  t-loss:0.0154, loss-lb:0.0120, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:47:45.681] iteration:11788  t-loss:0.0442, loss-lb:0.0292, loss-ulb:0.0075, weight:2.00, lr:0.0002
[01:47:46.061] iteration:11789  t-loss:0.0262, loss-lb:0.0111, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:47:46.443] iteration:11790  t-loss:0.0256, loss-lb:0.0119, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:47:46.824] iteration:11791  t-loss:0.0184, loss-lb:0.0134, loss-ulb:0.0025, weight:2.00, lr:0.0002
[01:47:47.203] iteration:11792  t-loss:0.0112, loss-lb:0.0088, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:47:47.587] iteration:11793  t-loss:0.0306, loss-lb:0.0293, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:47:47.967] iteration:11794  t-loss:0.0215, loss-lb:0.0186, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:47:48.356] iteration:11795  t-loss:0.0261, loss-lb:0.0229, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:47:48.743] iteration:11796  t-loss:0.0134, loss-lb:0.0100, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:47:49.129] iteration:11797  t-loss:0.0396, loss-lb:0.0262, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:47:49.510] iteration:11798  t-loss:0.0121, loss-lb:0.0088, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:47:49.895] iteration:11799  t-loss:0.0229, loss-lb:0.0140, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:47:50.278] iteration:11800  t-loss:0.0305, loss-lb:0.0192, loss-ulb:0.0057, weight:2.00, lr:0.0002
[01:47:50.663] iteration:11801  t-loss:0.0312, loss-lb:0.0290, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:47:51.044] iteration:11802  t-loss:0.0196, loss-lb:0.0158, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:47:51.432] iteration:11803  t-loss:0.0321, loss-lb:0.0251, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:47:51.811] iteration:11804  t-loss:0.0287, loss-lb:0.0137, loss-ulb:0.0075, weight:2.00, lr:0.0002
[01:47:52.199] iteration:11805  t-loss:0.0336, loss-lb:0.0213, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:47:52.605] iteration:11806  t-loss:0.0368, loss-lb:0.0230, loss-ulb:0.0069, weight:2.00, lr:0.0002
[01:47:53.024] iteration:11807  t-loss:0.0357, loss-lb:0.0276, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:47:53.428] iteration:11808  t-loss:0.0148, loss-lb:0.0119, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:47:53.821] iteration:11809  t-loss:0.0271, loss-lb:0.0173, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:47:54.219] iteration:11810  t-loss:0.0439, loss-lb:0.0225, loss-ulb:0.0107, weight:2.00, lr:0.0002
[01:47:54.608] iteration:11811  t-loss:0.0610, loss-lb:0.0213, loss-ulb:0.0198, weight:2.00, lr:0.0002
[01:47:54.992] iteration:11812  t-loss:0.0486, loss-lb:0.0203, loss-ulb:0.0141, weight:2.00, lr:0.0002
[01:47:55.373] iteration:11813  t-loss:0.0282, loss-lb:0.0191, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:47:55.754] iteration:11814  t-loss:0.0157, loss-lb:0.0112, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:47:56.133] iteration:11815  t-loss:0.0197, loss-lb:0.0167, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:47:56.520] iteration:11816  t-loss:0.0368, loss-lb:0.0244, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:47:56.903] iteration:11817  t-loss:0.0297, loss-lb:0.0208, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:47:57.290] iteration:11818  t-loss:0.0419, loss-lb:0.0130, loss-ulb:0.0145, weight:2.00, lr:0.0002
[01:47:58.729] iteration:11819  t-loss:0.0182, loss-lb:0.0148, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:47:59.123] iteration:11820  t-loss:0.0268, loss-lb:0.0159, loss-ulb:0.0054, weight:2.00, lr:0.0002
[01:47:59.514] iteration:11821  t-loss:0.0309, loss-lb:0.0191, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:47:59.907] iteration:11822  t-loss:0.0366, loss-lb:0.0252, loss-ulb:0.0057, weight:2.00, lr:0.0002
[01:48:00.296] iteration:11823  t-loss:0.0197, loss-lb:0.0188, loss-ulb:0.0005, weight:2.00, lr:0.0002
[01:48:00.675] iteration:11824  t-loss:0.0211, loss-lb:0.0175, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:48:01.058] iteration:11825  t-loss:0.0416, loss-lb:0.0215, loss-ulb:0.0100, weight:2.00, lr:0.0002
[01:48:01.447] iteration:11826  t-loss:0.0273, loss-lb:0.0094, loss-ulb:0.0089, weight:2.00, lr:0.0002
[01:48:01.830] iteration:11827  t-loss:0.0157, loss-lb:0.0123, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:48:02.218] iteration:11828  t-loss:0.0239, loss-lb:0.0120, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:48:02.599] iteration:11829  t-loss:0.0323, loss-lb:0.0134, loss-ulb:0.0095, weight:2.00, lr:0.0002
[01:48:02.987] iteration:11830  t-loss:0.0290, loss-lb:0.0152, loss-ulb:0.0069, weight:2.00, lr:0.0002
[01:48:03.365] iteration:11831  t-loss:0.0266, loss-lb:0.0116, loss-ulb:0.0075, weight:2.00, lr:0.0002
[01:48:03.761] iteration:11832  t-loss:0.0260, loss-lb:0.0242, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:48:04.155] iteration:11833  t-loss:0.0119, loss-lb:0.0099, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:48:04.548] iteration:11834  t-loss:0.0139, loss-lb:0.0112, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:48:04.936] iteration:11835  t-loss:0.0336, loss-lb:0.0261, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:48:05.315] iteration:11836  t-loss:0.0168, loss-lb:0.0088, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:48:05.694] iteration:11837  t-loss:0.0266, loss-lb:0.0237, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:48:06.082] iteration:11838  t-loss:0.0471, loss-lb:0.0324, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:48:06.466] iteration:11839  t-loss:0.0190, loss-lb:0.0093, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:48:06.847] iteration:11840  t-loss:0.0169, loss-lb:0.0148, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:48:07.226] iteration:11841  t-loss:0.0146, loss-lb:0.0118, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:48:07.611] iteration:11842  t-loss:0.0286, loss-lb:0.0265, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:48:08.004] iteration:11843  t-loss:0.0481, loss-lb:0.0143, loss-ulb:0.0169, weight:2.00, lr:0.0002
[01:48:08.398] iteration:11844  t-loss:0.0283, loss-lb:0.0192, loss-ulb:0.0046, weight:2.00, lr:0.0002
[01:48:08.794] iteration:11845  t-loss:0.0334, loss-lb:0.0211, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:48:09.188] iteration:11846  t-loss:0.0280, loss-lb:0.0255, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:48:09.565] iteration:11847  t-loss:0.0144, loss-lb:0.0130, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:48:09.948] iteration:11848  t-loss:0.0412, loss-lb:0.0274, loss-ulb:0.0069, weight:2.00, lr:0.0002
[01:48:10.332] iteration:11849  t-loss:0.0613, loss-lb:0.0527, loss-ulb:0.0043, weight:2.00, lr:0.0002
[01:48:10.710] iteration:11850  t-loss:0.0117, loss-lb:0.0098, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:48:11.087] iteration:11851  t-loss:0.0247, loss-lb:0.0163, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:48:11.464] iteration:11852  t-loss:0.0315, loss-lb:0.0184, loss-ulb:0.0065, weight:2.00, lr:0.0002
[01:48:11.841] iteration:11853  t-loss:0.0294, loss-lb:0.0139, loss-ulb:0.0077, weight:2.00, lr:0.0002
[01:48:12.225] iteration:11854  t-loss:0.0359, loss-lb:0.0198, loss-ulb:0.0081, weight:2.00, lr:0.0002
[01:48:12.610] iteration:11855  t-loss:0.0404, loss-lb:0.0209, loss-ulb:0.0098, weight:2.00, lr:0.0002
[01:48:12.995] iteration:11856  t-loss:0.0191, loss-lb:0.0101, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:48:14.180] iteration:11857  t-loss:0.0369, loss-lb:0.0215, loss-ulb:0.0077, weight:2.00, lr:0.0002
[01:48:14.593] iteration:11858  t-loss:0.0142, loss-lb:0.0109, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:48:14.983] iteration:11859  t-loss:0.0245, loss-lb:0.0125, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:48:15.375] iteration:11860  t-loss:0.0287, loss-lb:0.0202, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:48:15.756] iteration:11861  t-loss:0.0239, loss-lb:0.0113, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:48:16.135] iteration:11862  t-loss:0.0368, loss-lb:0.0212, loss-ulb:0.0078, weight:2.00, lr:0.0002
[01:48:16.514] iteration:11863  t-loss:0.0171, loss-lb:0.0112, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:48:16.895] iteration:11864  t-loss:0.0250, loss-lb:0.0218, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:48:17.271] iteration:11865  t-loss:0.0149, loss-lb:0.0123, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:48:17.654] iteration:11866  t-loss:0.0212, loss-lb:0.0147, loss-ulb:0.0033, weight:2.00, lr:0.0002
[01:48:18.032] iteration:11867  t-loss:0.0145, loss-lb:0.0100, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:48:18.414] iteration:11868  t-loss:0.0180, loss-lb:0.0127, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:48:18.795] iteration:11869  t-loss:0.0326, loss-lb:0.0298, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:48:19.198] iteration:11870  t-loss:0.0374, loss-lb:0.0268, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:48:19.583] iteration:11871  t-loss:0.0306, loss-lb:0.0177, loss-ulb:0.0065, weight:2.00, lr:0.0002
[01:48:19.966] iteration:11872  t-loss:0.0211, loss-lb:0.0122, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:48:20.349] iteration:11873  t-loss:0.0306, loss-lb:0.0244, loss-ulb:0.0031, weight:2.00, lr:0.0002
[01:48:20.729] iteration:11874  t-loss:0.0222, loss-lb:0.0205, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:48:21.106] iteration:11875  t-loss:0.0282, loss-lb:0.0146, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:48:21.484] iteration:11876  t-loss:0.0313, loss-lb:0.0181, loss-ulb:0.0066, weight:2.00, lr:0.0002
[01:48:21.860] iteration:11877  t-loss:0.0189, loss-lb:0.0096, loss-ulb:0.0046, weight:2.00, lr:0.0002
[01:48:22.240] iteration:11878  t-loss:0.0114, loss-lb:0.0095, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:48:22.622] iteration:11879  t-loss:0.0289, loss-lb:0.0109, loss-ulb:0.0090, weight:2.00, lr:0.0002
[01:48:23.004] iteration:11880  t-loss:0.0307, loss-lb:0.0278, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:48:23.380] iteration:11881  t-loss:0.0130, loss-lb:0.0115, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:48:23.761] iteration:11882  t-loss:0.0266, loss-lb:0.0112, loss-ulb:0.0077, weight:2.00, lr:0.0002
[01:48:24.141] iteration:11883  t-loss:0.0120, loss-lb:0.0093, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:48:24.522] iteration:11884  t-loss:0.0357, loss-lb:0.0230, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:48:24.897] iteration:11885  t-loss:0.0126, loss-lb:0.0085, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:48:25.292] iteration:11886  t-loss:0.0216, loss-lb:0.0121, loss-ulb:0.0047, weight:2.00, lr:0.0002
[01:48:25.681] iteration:11887  t-loss:0.0303, loss-lb:0.0177, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:48:26.059] iteration:11888  t-loss:0.0398, loss-lb:0.0249, loss-ulb:0.0074, weight:2.00, lr:0.0002
[01:48:26.436] iteration:11889  t-loss:0.0326, loss-lb:0.0114, loss-ulb:0.0106, weight:2.00, lr:0.0002
[01:48:26.815] iteration:11890  t-loss:0.0281, loss-lb:0.0185, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:48:27.191] iteration:11891  t-loss:0.0390, loss-lb:0.0116, loss-ulb:0.0137, weight:2.00, lr:0.0002
[01:48:27.580] iteration:11892  t-loss:0.0374, loss-lb:0.0179, loss-ulb:0.0098, weight:2.00, lr:0.0002
[01:48:27.964] iteration:11893  t-loss:0.0181, loss-lb:0.0119, loss-ulb:0.0031, weight:2.00, lr:0.0002
[01:48:28.346] iteration:11894  t-loss:0.0503, loss-lb:0.0145, loss-ulb:0.0179, weight:2.00, lr:0.0002
[01:49:33.076] iteration 11894 : dice_score: 0.901747 best_dice: 0.902900
[01:49:33.076]  <<Test>> - Ep:312  - Dice-S/T:89.55/90.17, Best-S:90.24, Best-T:90.29
[01:49:33.077]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:49:34.275] iteration:11895  t-loss:0.0197, loss-lb:0.0118, loss-ulb:0.0039, weight:2.00, lr:0.0002
[01:49:34.673] iteration:11896  t-loss:0.0452, loss-lb:0.0266, loss-ulb:0.0093, weight:2.00, lr:0.0002
[01:49:35.059] iteration:11897  t-loss:0.0362, loss-lb:0.0222, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:49:35.448] iteration:11898  t-loss:0.0214, loss-lb:0.0155, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:49:35.825] iteration:11899  t-loss:0.0130, loss-lb:0.0100, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:49:36.206] iteration:11900  t-loss:0.0187, loss-lb:0.0159, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:49:36.587] iteration:11901  t-loss:0.0313, loss-lb:0.0249, loss-ulb:0.0032, weight:2.00, lr:0.0002
[01:49:36.971] iteration:11902  t-loss:0.0375, loss-lb:0.0194, loss-ulb:0.0090, weight:2.00, lr:0.0002
[01:49:37.351] iteration:11903  t-loss:0.0126, loss-lb:0.0111, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:49:37.729] iteration:11904  t-loss:0.0361, loss-lb:0.0311, loss-ulb:0.0025, weight:2.00, lr:0.0002
[01:49:38.109] iteration:11905  t-loss:0.0221, loss-lb:0.0156, loss-ulb:0.0033, weight:2.00, lr:0.0002
[01:49:38.499] iteration:11906  t-loss:0.0383, loss-lb:0.0220, loss-ulb:0.0081, weight:2.00, lr:0.0002
[01:49:38.884] iteration:11907  t-loss:0.0287, loss-lb:0.0233, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:49:39.261] iteration:11908  t-loss:0.0343, loss-lb:0.0198, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:49:39.640] iteration:11909  t-loss:0.0147, loss-lb:0.0105, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:49:40.025] iteration:11910  t-loss:0.0397, loss-lb:0.0273, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:49:40.405] iteration:11911  t-loss:0.0181, loss-lb:0.0132, loss-ulb:0.0024, weight:2.00, lr:0.0002
[01:49:40.785] iteration:11912  t-loss:0.0536, loss-lb:0.0320, loss-ulb:0.0108, weight:2.00, lr:0.0002
[01:49:41.167] iteration:11913  t-loss:0.0279, loss-lb:0.0126, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:49:41.538] iteration:11914  t-loss:0.0334, loss-lb:0.0244, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:49:41.914] iteration:11915  t-loss:0.0202, loss-lb:0.0108, loss-ulb:0.0047, weight:2.00, lr:0.0002
[01:49:42.286] iteration:11916  t-loss:0.0294, loss-lb:0.0128, loss-ulb:0.0083, weight:2.00, lr:0.0002
[01:49:42.663] iteration:11917  t-loss:0.0276, loss-lb:0.0191, loss-ulb:0.0043, weight:2.00, lr:0.0002
[01:49:43.042] iteration:11918  t-loss:0.0372, loss-lb:0.0303, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:49:43.424] iteration:11919  t-loss:0.0529, loss-lb:0.0193, loss-ulb:0.0168, weight:2.00, lr:0.0002
[01:49:43.817] iteration:11920  t-loss:0.0225, loss-lb:0.0166, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:49:44.218] iteration:11921  t-loss:0.0159, loss-lb:0.0137, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:49:44.617] iteration:11922  t-loss:0.0164, loss-lb:0.0104, loss-ulb:0.0030, weight:2.00, lr:0.0002
[01:49:45.008] iteration:11923  t-loss:0.0361, loss-lb:0.0204, loss-ulb:0.0079, weight:2.00, lr:0.0002
[01:49:45.388] iteration:11924  t-loss:0.0273, loss-lb:0.0112, loss-ulb:0.0080, weight:2.00, lr:0.0002
[01:49:45.766] iteration:11925  t-loss:0.0398, loss-lb:0.0245, loss-ulb:0.0077, weight:2.00, lr:0.0002
[01:49:46.144] iteration:11926  t-loss:0.1467, loss-lb:0.1189, loss-ulb:0.0139, weight:2.00, lr:0.0002
[01:49:46.522] iteration:11927  t-loss:0.0372, loss-lb:0.0129, loss-ulb:0.0122, weight:2.00, lr:0.0002
[01:49:46.900] iteration:11928  t-loss:0.0251, loss-lb:0.0112, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:49:47.272] iteration:11929  t-loss:0.0214, loss-lb:0.0156, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:49:47.645] iteration:11930  t-loss:0.0144, loss-lb:0.0110, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:49:48.023] iteration:11931  t-loss:0.0607, loss-lb:0.0469, loss-ulb:0.0069, weight:2.00, lr:0.0002
[01:49:48.401] iteration:11932  t-loss:0.0666, loss-lb:0.0182, loss-ulb:0.0242, weight:2.00, lr:0.0002
[01:49:49.608] iteration:11933  t-loss:0.0436, loss-lb:0.0304, loss-ulb:0.0066, weight:2.00, lr:0.0002
[01:49:50.017] iteration:11934  t-loss:0.0532, loss-lb:0.0244, loss-ulb:0.0144, weight:2.00, lr:0.0002
[01:49:50.402] iteration:11935  t-loss:0.0245, loss-lb:0.0095, loss-ulb:0.0075, weight:2.00, lr:0.0002
[01:49:50.779] iteration:11936  t-loss:0.0528, loss-lb:0.0345, loss-ulb:0.0092, weight:2.00, lr:0.0002
[01:49:51.164] iteration:11937  t-loss:0.0425, loss-lb:0.0333, loss-ulb:0.0046, weight:2.00, lr:0.0002
[01:49:51.542] iteration:11938  t-loss:0.0288, loss-lb:0.0114, loss-ulb:0.0087, weight:2.00, lr:0.0002
[01:49:51.931] iteration:11939  t-loss:0.0367, loss-lb:0.0111, loss-ulb:0.0128, weight:2.00, lr:0.0002
[01:49:52.312] iteration:11940  t-loss:0.0362, loss-lb:0.0332, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:49:52.692] iteration:11941  t-loss:0.0473, loss-lb:0.0132, loss-ulb:0.0170, weight:2.00, lr:0.0002
[01:49:53.068] iteration:11942  t-loss:0.0348, loss-lb:0.0189, loss-ulb:0.0079, weight:2.00, lr:0.0002
[01:49:53.447] iteration:11943  t-loss:0.0381, loss-lb:0.0273, loss-ulb:0.0054, weight:2.00, lr:0.0002
[01:49:53.825] iteration:11944  t-loss:0.0151, loss-lb:0.0115, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:49:54.210] iteration:11945  t-loss:0.0249, loss-lb:0.0200, loss-ulb:0.0024, weight:2.00, lr:0.0002
[01:49:54.595] iteration:11946  t-loss:0.0257, loss-lb:0.0113, loss-ulb:0.0072, weight:2.00, lr:0.0002
[01:49:54.977] iteration:11947  t-loss:0.0241, loss-lb:0.0146, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:49:55.359] iteration:11948  t-loss:0.0313, loss-lb:0.0098, loss-ulb:0.0108, weight:2.00, lr:0.0002
[01:49:55.733] iteration:11949  t-loss:0.0324, loss-lb:0.0298, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:49:56.114] iteration:11950  t-loss:0.0319, loss-lb:0.0248, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:49:56.493] iteration:11951  t-loss:0.0280, loss-lb:0.0128, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:49:56.868] iteration:11952  t-loss:0.0278, loss-lb:0.0247, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:49:57.245] iteration:11953  t-loss:0.0276, loss-lb:0.0250, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:49:57.621] iteration:11954  t-loss:0.0335, loss-lb:0.0295, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:49:57.997] iteration:11955  t-loss:0.0256, loss-lb:0.0113, loss-ulb:0.0071, weight:2.00, lr:0.0002
[01:49:58.374] iteration:11956  t-loss:0.0333, loss-lb:0.0105, loss-ulb:0.0114, weight:2.00, lr:0.0002
[01:49:58.755] iteration:11957  t-loss:0.0753, loss-lb:0.0714, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:49:59.147] iteration:11958  t-loss:0.0310, loss-lb:0.0239, loss-ulb:0.0036, weight:2.00, lr:0.0002
[01:49:59.545] iteration:11959  t-loss:0.0122, loss-lb:0.0103, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:49:59.950] iteration:11960  t-loss:0.0481, loss-lb:0.0370, loss-ulb:0.0056, weight:2.00, lr:0.0002
[01:50:00.338] iteration:11961  t-loss:0.0290, loss-lb:0.0088, loss-ulb:0.0101, weight:2.00, lr:0.0002
[01:50:00.726] iteration:11962  t-loss:0.0344, loss-lb:0.0217, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:50:01.108] iteration:11963  t-loss:0.0342, loss-lb:0.0223, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:50:01.487] iteration:11964  t-loss:0.0227, loss-lb:0.0129, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:50:01.866] iteration:11965  t-loss:0.0281, loss-lb:0.0196, loss-ulb:0.0043, weight:2.00, lr:0.0002
[01:50:02.250] iteration:11966  t-loss:0.0129, loss-lb:0.0099, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:50:02.641] iteration:11967  t-loss:0.0624, loss-lb:0.0421, loss-ulb:0.0102, weight:2.00, lr:0.0002
[01:50:03.025] iteration:11968  t-loss:0.0534, loss-lb:0.0464, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:50:03.406] iteration:11969  t-loss:0.0298, loss-lb:0.0188, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:50:03.783] iteration:11970  t-loss:0.0736, loss-lb:0.0264, loss-ulb:0.0236, weight:2.00, lr:0.0002
[01:50:04.888] iteration:11971  t-loss:0.0149, loss-lb:0.0127, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:50:05.290] iteration:11972  t-loss:0.0301, loss-lb:0.0128, loss-ulb:0.0086, weight:2.00, lr:0.0002
[01:50:05.680] iteration:11973  t-loss:0.0164, loss-lb:0.0143, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:50:06.057] iteration:11974  t-loss:0.0503, loss-lb:0.0441, loss-ulb:0.0031, weight:2.00, lr:0.0002
[01:50:06.436] iteration:11975  t-loss:0.0140, loss-lb:0.0120, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:50:06.814] iteration:11976  t-loss:0.0343, loss-lb:0.0306, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:50:07.191] iteration:11977  t-loss:0.0474, loss-lb:0.0368, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:50:07.573] iteration:11978  t-loss:0.0269, loss-lb:0.0173, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:50:07.949] iteration:11979  t-loss:0.0197, loss-lb:0.0139, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:50:08.332] iteration:11980  t-loss:0.0197, loss-lb:0.0182, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:50:08.714] iteration:11981  t-loss:0.0222, loss-lb:0.0094, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:50:09.091] iteration:11982  t-loss:0.0283, loss-lb:0.0160, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:50:09.472] iteration:11983  t-loss:0.0149, loss-lb:0.0102, loss-ulb:0.0024, weight:2.00, lr:0.0002
[01:50:09.856] iteration:11984  t-loss:0.0294, loss-lb:0.0222, loss-ulb:0.0036, weight:2.00, lr:0.0002
[01:50:10.242] iteration:11985  t-loss:0.0464, loss-lb:0.0268, loss-ulb:0.0098, weight:2.00, lr:0.0002
[01:50:10.636] iteration:11986  t-loss:0.0208, loss-lb:0.0191, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:50:11.020] iteration:11987  t-loss:0.0287, loss-lb:0.0243, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:50:11.398] iteration:11988  t-loss:0.0204, loss-lb:0.0146, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:50:11.780] iteration:11989  t-loss:0.0338, loss-lb:0.0191, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:50:12.155] iteration:11990  t-loss:0.0272, loss-lb:0.0170, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:50:12.532] iteration:11991  t-loss:0.0332, loss-lb:0.0303, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:50:12.910] iteration:11992  t-loss:0.0324, loss-lb:0.0187, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:50:13.290] iteration:11993  t-loss:0.0304, loss-lb:0.0196, loss-ulb:0.0054, weight:2.00, lr:0.0002
[01:50:13.664] iteration:11994  t-loss:0.0271, loss-lb:0.0087, loss-ulb:0.0092, weight:2.00, lr:0.0002
[01:50:14.037] iteration:11995  t-loss:0.0390, loss-lb:0.0103, loss-ulb:0.0144, weight:2.00, lr:0.0002
[01:50:14.420] iteration:11996  t-loss:0.0193, loss-lb:0.0173, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:50:14.813] iteration:11997  t-loss:0.0261, loss-lb:0.0108, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:50:15.193] iteration:11998  t-loss:0.0142, loss-lb:0.0115, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:50:15.574] iteration:11999  t-loss:0.0355, loss-lb:0.0100, loss-ulb:0.0127, weight:2.00, lr:0.0002
[01:50:15.955] iteration:12000  t-loss:0.0340, loss-lb:0.0112, loss-ulb:0.0114, weight:2.00, lr:0.0002
[01:50:16.329] iteration:12001  t-loss:0.0232, loss-lb:0.0206, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:50:16.705] iteration:12002  t-loss:0.0577, loss-lb:0.0325, loss-ulb:0.0126, weight:2.00, lr:0.0002
[01:50:17.088] iteration:12003  t-loss:0.0536, loss-lb:0.0245, loss-ulb:0.0145, weight:2.00, lr:0.0002
[01:50:17.479] iteration:12004  t-loss:0.0205, loss-lb:0.0116, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:50:17.878] iteration:12005  t-loss:0.0319, loss-lb:0.0199, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:50:18.264] iteration:12006  t-loss:0.0324, loss-lb:0.0200, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:50:18.641] iteration:12007  t-loss:0.0124, loss-lb:0.0097, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:50:19.023] iteration:12008  t-loss:0.0358, loss-lb:0.0253, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:50:20.201] iteration:12009  t-loss:0.0312, loss-lb:0.0234, loss-ulb:0.0039, weight:2.00, lr:0.0002
[01:50:20.591] iteration:12010  t-loss:0.0275, loss-lb:0.0117, loss-ulb:0.0079, weight:2.00, lr:0.0002
[01:50:20.979] iteration:12011  t-loss:0.0262, loss-lb:0.0222, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:50:21.364] iteration:12012  t-loss:0.0198, loss-lb:0.0153, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:50:21.745] iteration:12013  t-loss:0.0118, loss-lb:0.0086, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:50:22.129] iteration:12014  t-loss:0.0372, loss-lb:0.0288, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:50:22.509] iteration:12015  t-loss:0.0264, loss-lb:0.0240, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:50:22.883] iteration:12016  t-loss:0.0130, loss-lb:0.0118, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:50:23.257] iteration:12017  t-loss:0.0464, loss-lb:0.0253, loss-ulb:0.0106, weight:2.00, lr:0.0002
[01:50:23.638] iteration:12018  t-loss:0.0254, loss-lb:0.0099, loss-ulb:0.0078, weight:2.00, lr:0.0002
[01:50:24.014] iteration:12019  t-loss:0.0162, loss-lb:0.0119, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:50:24.391] iteration:12020  t-loss:0.0235, loss-lb:0.0107, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:50:24.789] iteration:12021  t-loss:0.0267, loss-lb:0.0127, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:50:25.166] iteration:12022  t-loss:0.0214, loss-lb:0.0099, loss-ulb:0.0058, weight:2.00, lr:0.0002
[01:50:25.543] iteration:12023  t-loss:0.0284, loss-lb:0.0242, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:50:25.921] iteration:12024  t-loss:0.0110, loss-lb:0.0094, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:50:26.296] iteration:12025  t-loss:0.0181, loss-lb:0.0117, loss-ulb:0.0032, weight:2.00, lr:0.0002
[01:50:26.670] iteration:12026  t-loss:0.0434, loss-lb:0.0286, loss-ulb:0.0074, weight:2.00, lr:0.0002
[01:50:27.046] iteration:12027  t-loss:0.0242, loss-lb:0.0102, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:50:27.427] iteration:12028  t-loss:0.0269, loss-lb:0.0163, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:50:27.803] iteration:12029  t-loss:0.0292, loss-lb:0.0272, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:50:28.180] iteration:12030  t-loss:0.0341, loss-lb:0.0273, loss-ulb:0.0034, weight:2.00, lr:0.0002
[01:50:28.554] iteration:12031  t-loss:0.0134, loss-lb:0.0098, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:50:28.927] iteration:12032  t-loss:0.0300, loss-lb:0.0116, loss-ulb:0.0092, weight:2.00, lr:0.0002
[01:50:29.298] iteration:12033  t-loss:0.0269, loss-lb:0.0111, loss-ulb:0.0079, weight:2.00, lr:0.0002
[01:50:29.679] iteration:12034  t-loss:0.0296, loss-lb:0.0095, loss-ulb:0.0100, weight:2.00, lr:0.0002
[01:50:30.052] iteration:12035  t-loss:0.0291, loss-lb:0.0144, loss-ulb:0.0074, weight:2.00, lr:0.0002
[01:50:30.427] iteration:12036  t-loss:0.0229, loss-lb:0.0196, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:50:30.803] iteration:12037  t-loss:0.0228, loss-lb:0.0092, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:50:31.183] iteration:12038  t-loss:0.0252, loss-lb:0.0123, loss-ulb:0.0065, weight:2.00, lr:0.0002
[01:50:31.555] iteration:12039  t-loss:0.0224, loss-lb:0.0193, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:50:31.927] iteration:12040  t-loss:0.0136, loss-lb:0.0120, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:50:32.299] iteration:12041  t-loss:0.0159, loss-lb:0.0101, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:50:32.690] iteration:12042  t-loss:0.0225, loss-lb:0.0186, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:50:33.085] iteration:12043  t-loss:0.0281, loss-lb:0.0171, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:50:33.482] iteration:12044  t-loss:0.0214, loss-lb:0.0163, loss-ulb:0.0026, weight:2.00, lr:0.0002
[01:50:33.858] iteration:12045  t-loss:0.0202, loss-lb:0.0113, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:50:34.228] iteration:12046  t-loss:0.0137, loss-lb:0.0105, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:51:39.828] iteration 12046 : dice_score: 0.893783 best_dice: 0.902900
[01:51:39.828]  <<Test>> - Ep:316  - Dice-S/T:87.60/89.38, Best-S:90.24, Best-T:90.29
[01:51:39.829]           - AvgLoss(lb/ulb/all):0.02/0.00/0.02
[01:51:40.951] iteration:12047  t-loss:0.0289, loss-lb:0.0275, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:51:41.367] iteration:12048  t-loss:0.0291, loss-lb:0.0167, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:51:41.751] iteration:12049  t-loss:0.0156, loss-lb:0.0137, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:51:42.134] iteration:12050  t-loss:0.0499, loss-lb:0.0384, loss-ulb:0.0057, weight:2.00, lr:0.0002
[01:51:42.514] iteration:12051  t-loss:0.0202, loss-lb:0.0189, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:51:42.899] iteration:12052  t-loss:0.0396, loss-lb:0.0295, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:51:43.280] iteration:12053  t-loss:0.0429, loss-lb:0.0213, loss-ulb:0.0108, weight:2.00, lr:0.0002
[01:51:43.661] iteration:12054  t-loss:0.0443, loss-lb:0.0219, loss-ulb:0.0112, weight:2.00, lr:0.0002
[01:51:44.042] iteration:12055  t-loss:0.0195, loss-lb:0.0113, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:51:44.423] iteration:12056  t-loss:0.0362, loss-lb:0.0252, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:51:44.806] iteration:12057  t-loss:0.0311, loss-lb:0.0165, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:51:45.195] iteration:12058  t-loss:0.0134, loss-lb:0.0117, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:51:45.606] iteration:12059  t-loss:0.0229, loss-lb:0.0203, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:51:46.004] iteration:12060  t-loss:0.0386, loss-lb:0.0234, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:51:46.388] iteration:12061  t-loss:0.0138, loss-lb:0.0126, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:51:46.765] iteration:12062  t-loss:0.0239, loss-lb:0.0106, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:51:47.149] iteration:12063  t-loss:0.0162, loss-lb:0.0110, loss-ulb:0.0026, weight:2.00, lr:0.0002
[01:51:47.535] iteration:12064  t-loss:0.0435, loss-lb:0.0289, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:51:47.917] iteration:12065  t-loss:0.0206, loss-lb:0.0114, loss-ulb:0.0046, weight:2.00, lr:0.0002
[01:51:48.281] iteration:12066  t-loss:0.0454, loss-lb:0.0328, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:51:48.661] iteration:12067  t-loss:0.0372, loss-lb:0.0258, loss-ulb:0.0057, weight:2.00, lr:0.0002
[01:51:49.046] iteration:12068  t-loss:0.1156, loss-lb:0.1139, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:51:49.425] iteration:12069  t-loss:0.0182, loss-lb:0.0129, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:51:49.806] iteration:12070  t-loss:0.0451, loss-lb:0.0396, loss-ulb:0.0028, weight:2.00, lr:0.0002
[01:51:50.185] iteration:12071  t-loss:0.0271, loss-lb:0.0139, loss-ulb:0.0066, weight:2.00, lr:0.0002
[01:51:50.568] iteration:12072  t-loss:0.0333, loss-lb:0.0203, loss-ulb:0.0065, weight:2.00, lr:0.0002
[01:51:50.960] iteration:12073  t-loss:0.0302, loss-lb:0.0089, loss-ulb:0.0107, weight:2.00, lr:0.0002
[01:51:51.363] iteration:12074  t-loss:0.0239, loss-lb:0.0227, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:51:51.780] iteration:12075  t-loss:0.0178, loss-lb:0.0109, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:51:52.178] iteration:12076  t-loss:0.0228, loss-lb:0.0122, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:51:52.570] iteration:12077  t-loss:0.0269, loss-lb:0.0159, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:51:52.947] iteration:12078  t-loss:0.0241, loss-lb:0.0202, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:51:53.326] iteration:12079  t-loss:0.0333, loss-lb:0.0266, loss-ulb:0.0034, weight:2.00, lr:0.0002
[01:51:53.703] iteration:12080  t-loss:0.0166, loss-lb:0.0116, loss-ulb:0.0025, weight:2.00, lr:0.0002
[01:51:54.080] iteration:12081  t-loss:0.0273, loss-lb:0.0250, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:51:54.456] iteration:12082  t-loss:0.0213, loss-lb:0.0198, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:51:54.834] iteration:12083  t-loss:0.0262, loss-lb:0.0143, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:51:55.215] iteration:12084  t-loss:0.0380, loss-lb:0.0097, loss-ulb:0.0142, weight:2.00, lr:0.0002
[01:51:56.395] iteration:12085  t-loss:0.0303, loss-lb:0.0218, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:51:56.801] iteration:12086  t-loss:0.0385, loss-lb:0.0213, loss-ulb:0.0086, weight:2.00, lr:0.0002
[01:51:57.183] iteration:12087  t-loss:0.0461, loss-lb:0.0247, loss-ulb:0.0107, weight:2.00, lr:0.0002
[01:51:57.563] iteration:12088  t-loss:0.0416, loss-lb:0.0292, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:51:57.943] iteration:12089  t-loss:0.0189, loss-lb:0.0113, loss-ulb:0.0038, weight:2.00, lr:0.0002
[01:51:58.329] iteration:12090  t-loss:0.0270, loss-lb:0.0245, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:51:58.708] iteration:12091  t-loss:0.0265, loss-lb:0.0254, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:51:59.090] iteration:12092  t-loss:0.0315, loss-lb:0.0166, loss-ulb:0.0075, weight:2.00, lr:0.0002
[01:51:59.479] iteration:12093  t-loss:0.0338, loss-lb:0.0219, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:51:59.862] iteration:12094  t-loss:0.0328, loss-lb:0.0308, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:52:00.246] iteration:12095  t-loss:0.0211, loss-lb:0.0126, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:52:00.628] iteration:12096  t-loss:0.0304, loss-lb:0.0096, loss-ulb:0.0104, weight:2.00, lr:0.0002
[01:52:01.016] iteration:12097  t-loss:0.0367, loss-lb:0.0228, loss-ulb:0.0069, weight:2.00, lr:0.0002
[01:52:01.399] iteration:12098  t-loss:0.0196, loss-lb:0.0101, loss-ulb:0.0047, weight:2.00, lr:0.0002
[01:52:01.783] iteration:12099  t-loss:0.0273, loss-lb:0.0197, loss-ulb:0.0038, weight:2.00, lr:0.0002
[01:52:02.166] iteration:12100  t-loss:0.0250, loss-lb:0.0129, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:52:02.547] iteration:12101  t-loss:0.0233, loss-lb:0.0218, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:52:02.931] iteration:12102  t-loss:0.0325, loss-lb:0.0289, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:52:03.311] iteration:12103  t-loss:0.0249, loss-lb:0.0117, loss-ulb:0.0066, weight:2.00, lr:0.0002
[01:52:03.688] iteration:12104  t-loss:0.0313, loss-lb:0.0262, loss-ulb:0.0025, weight:2.00, lr:0.0002
[01:52:04.066] iteration:12105  t-loss:0.0254, loss-lb:0.0125, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:52:04.440] iteration:12106  t-loss:0.0117, loss-lb:0.0092, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:52:04.815] iteration:12107  t-loss:0.0573, loss-lb:0.0130, loss-ulb:0.0222, weight:2.00, lr:0.0002
[01:52:05.191] iteration:12108  t-loss:0.0253, loss-lb:0.0104, loss-ulb:0.0074, weight:2.00, lr:0.0002
[01:52:05.568] iteration:12109  t-loss:0.0386, loss-lb:0.0131, loss-ulb:0.0128, weight:2.00, lr:0.0002
[01:52:05.948] iteration:12110  t-loss:0.0551, loss-lb:0.0247, loss-ulb:0.0152, weight:2.00, lr:0.0002
[01:52:06.325] iteration:12111  t-loss:0.0260, loss-lb:0.0232, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:52:06.716] iteration:12112  t-loss:0.0183, loss-lb:0.0086, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:52:07.107] iteration:12113  t-loss:0.0155, loss-lb:0.0109, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:52:07.507] iteration:12114  t-loss:0.0120, loss-lb:0.0091, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:52:07.896] iteration:12115  t-loss:0.0284, loss-lb:0.0243, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:52:08.272] iteration:12116  t-loss:0.0254, loss-lb:0.0185, loss-ulb:0.0034, weight:2.00, lr:0.0002
[01:52:08.660] iteration:12117  t-loss:0.0129, loss-lb:0.0102, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:52:09.038] iteration:12118  t-loss:0.0103, loss-lb:0.0091, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:52:09.414] iteration:12119  t-loss:0.0242, loss-lb:0.0218, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:52:09.788] iteration:12120  t-loss:0.0221, loss-lb:0.0180, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:52:10.162] iteration:12121  t-loss:0.0245, loss-lb:0.0109, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:52:10.539] iteration:12122  t-loss:0.0279, loss-lb:0.0124, loss-ulb:0.0077, weight:2.00, lr:0.0002
[01:52:11.669] iteration:12123  t-loss:0.0139, loss-lb:0.0108, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:52:12.071] iteration:12124  t-loss:0.0541, loss-lb:0.0362, loss-ulb:0.0090, weight:2.00, lr:0.0002
[01:52:12.461] iteration:12125  t-loss:0.0239, loss-lb:0.0162, loss-ulb:0.0038, weight:2.00, lr:0.0002
[01:52:12.842] iteration:12126  t-loss:0.0278, loss-lb:0.0145, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:52:13.221] iteration:12127  t-loss:0.0392, loss-lb:0.0175, loss-ulb:0.0109, weight:2.00, lr:0.0002
[01:52:13.599] iteration:12128  t-loss:0.0209, loss-lb:0.0099, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:52:13.987] iteration:12129  t-loss:0.0338, loss-lb:0.0291, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:52:14.363] iteration:12130  t-loss:0.0127, loss-lb:0.0099, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:52:14.746] iteration:12131  t-loss:0.0295, loss-lb:0.0135, loss-ulb:0.0080, weight:2.00, lr:0.0002
[01:52:15.128] iteration:12132  t-loss:0.0236, loss-lb:0.0138, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:52:15.512] iteration:12133  t-loss:0.0272, loss-lb:0.0241, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:52:15.889] iteration:12134  t-loss:0.0462, loss-lb:0.0182, loss-ulb:0.0140, weight:2.00, lr:0.0002
[01:52:16.271] iteration:12135  t-loss:0.0316, loss-lb:0.0163, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:52:16.659] iteration:12136  t-loss:0.0391, loss-lb:0.0200, loss-ulb:0.0096, weight:2.00, lr:0.0002
[01:52:17.038] iteration:12137  t-loss:0.0189, loss-lb:0.0103, loss-ulb:0.0043, weight:2.00, lr:0.0002
[01:52:17.417] iteration:12138  t-loss:0.0354, loss-lb:0.0269, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:52:17.796] iteration:12139  t-loss:0.0303, loss-lb:0.0260, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:52:18.177] iteration:12140  t-loss:0.0280, loss-lb:0.0241, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:52:18.561] iteration:12141  t-loss:0.0242, loss-lb:0.0159, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:52:18.938] iteration:12142  t-loss:0.0158, loss-lb:0.0107, loss-ulb:0.0026, weight:2.00, lr:0.0002
[01:52:19.315] iteration:12143  t-loss:0.0226, loss-lb:0.0117, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:52:19.694] iteration:12144  t-loss:0.0302, loss-lb:0.0186, loss-ulb:0.0058, weight:2.00, lr:0.0002
[01:52:20.070] iteration:12145  t-loss:0.0221, loss-lb:0.0111, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:52:20.444] iteration:12146  t-loss:0.0384, loss-lb:0.0209, loss-ulb:0.0088, weight:2.00, lr:0.0002
[01:52:20.824] iteration:12147  t-loss:0.0559, loss-lb:0.0285, loss-ulb:0.0137, weight:2.00, lr:0.0002
[01:52:21.197] iteration:12148  t-loss:0.0180, loss-lb:0.0134, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:52:21.571] iteration:12149  t-loss:0.0260, loss-lb:0.0209, loss-ulb:0.0025, weight:2.00, lr:0.0002
[01:52:21.945] iteration:12150  t-loss:0.0215, loss-lb:0.0092, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:52:22.332] iteration:12151  t-loss:0.0149, loss-lb:0.0093, loss-ulb:0.0028, weight:2.00, lr:0.0002
[01:52:22.720] iteration:12152  t-loss:0.0141, loss-lb:0.0122, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:52:23.099] iteration:12153  t-loss:0.0435, loss-lb:0.0398, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:52:23.477] iteration:12154  t-loss:0.0155, loss-lb:0.0135, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:52:23.868] iteration:12155  t-loss:0.0271, loss-lb:0.0238, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:52:24.258] iteration:12156  t-loss:0.0479, loss-lb:0.0107, loss-ulb:0.0186, weight:2.00, lr:0.0002
[01:52:24.639] iteration:12157  t-loss:0.0331, loss-lb:0.0122, loss-ulb:0.0105, weight:2.00, lr:0.0002
[01:52:25.009] iteration:12158  t-loss:0.0169, loss-lb:0.0108, loss-ulb:0.0030, weight:2.00, lr:0.0002
[01:52:25.383] iteration:12159  t-loss:0.0337, loss-lb:0.0194, loss-ulb:0.0071, weight:2.00, lr:0.0002
[01:52:25.759] iteration:12160  t-loss:0.0222, loss-lb:0.0207, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:52:26.881] iteration:12161  t-loss:0.0197, loss-lb:0.0118, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:52:27.270] iteration:12162  t-loss:0.0193, loss-lb:0.0172, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:52:27.651] iteration:12163  t-loss:0.0292, loss-lb:0.0119, loss-ulb:0.0086, weight:2.00, lr:0.0002
[01:52:28.027] iteration:12164  t-loss:0.0202, loss-lb:0.0119, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:52:28.397] iteration:12165  t-loss:0.0132, loss-lb:0.0091, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:52:28.778] iteration:12166  t-loss:0.0392, loss-lb:0.0263, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:52:29.158] iteration:12167  t-loss:0.0448, loss-lb:0.0293, loss-ulb:0.0077, weight:2.00, lr:0.0002
[01:52:29.535] iteration:12168  t-loss:0.0212, loss-lb:0.0100, loss-ulb:0.0056, weight:2.00, lr:0.0002
[01:52:29.910] iteration:12169  t-loss:0.0224, loss-lb:0.0206, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:52:30.293] iteration:12170  t-loss:0.0368, loss-lb:0.0184, loss-ulb:0.0092, weight:2.00, lr:0.0002
[01:52:30.661] iteration:12171  t-loss:0.0303, loss-lb:0.0163, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:52:31.045] iteration:12172  t-loss:0.0402, loss-lb:0.0324, loss-ulb:0.0039, weight:2.00, lr:0.0002
[01:52:31.436] iteration:12173  t-loss:0.0267, loss-lb:0.0092, loss-ulb:0.0088, weight:2.00, lr:0.0002
[01:52:31.828] iteration:12174  t-loss:0.0274, loss-lb:0.0132, loss-ulb:0.0071, weight:2.00, lr:0.0002
[01:52:32.217] iteration:12175  t-loss:0.0207, loss-lb:0.0109, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:52:32.602] iteration:12176  t-loss:0.0324, loss-lb:0.0096, loss-ulb:0.0114, weight:2.00, lr:0.0002
[01:52:32.993] iteration:12177  t-loss:0.0276, loss-lb:0.0214, loss-ulb:0.0031, weight:2.00, lr:0.0002
[01:52:33.388] iteration:12178  t-loss:0.0315, loss-lb:0.0121, loss-ulb:0.0097, weight:2.00, lr:0.0002
[01:52:33.777] iteration:12179  t-loss:0.0257, loss-lb:0.0114, loss-ulb:0.0072, weight:2.00, lr:0.0002
[01:52:34.160] iteration:12180  t-loss:0.0823, loss-lb:0.0192, loss-ulb:0.0315, weight:2.00, lr:0.0002
[01:52:34.543] iteration:12181  t-loss:0.0630, loss-lb:0.0347, loss-ulb:0.0142, weight:2.00, lr:0.0002
[01:52:34.920] iteration:12182  t-loss:0.0187, loss-lb:0.0121, loss-ulb:0.0033, weight:2.00, lr:0.0002
[01:52:35.295] iteration:12183  t-loss:0.0218, loss-lb:0.0201, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:52:35.674] iteration:12184  t-loss:0.0335, loss-lb:0.0206, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:52:36.048] iteration:12185  t-loss:0.0198, loss-lb:0.0134, loss-ulb:0.0032, weight:2.00, lr:0.0002
[01:52:36.422] iteration:12186  t-loss:0.0230, loss-lb:0.0188, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:52:36.800] iteration:12187  t-loss:0.0473, loss-lb:0.0372, loss-ulb:0.0050, weight:2.00, lr:0.0002
[01:52:37.177] iteration:12188  t-loss:0.0226, loss-lb:0.0185, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:52:37.552] iteration:12189  t-loss:0.0249, loss-lb:0.0117, loss-ulb:0.0066, weight:2.00, lr:0.0002
[01:52:37.931] iteration:12190  t-loss:0.0284, loss-lb:0.0248, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:52:38.308] iteration:12191  t-loss:0.0413, loss-lb:0.0236, loss-ulb:0.0088, weight:2.00, lr:0.0002
[01:52:38.685] iteration:12192  t-loss:0.0304, loss-lb:0.0285, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:52:39.069] iteration:12193  t-loss:0.0210, loss-lb:0.0140, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:52:39.458] iteration:12194  t-loss:0.0613, loss-lb:0.0368, loss-ulb:0.0123, weight:2.00, lr:0.0002
[01:52:39.837] iteration:12195  t-loss:0.0398, loss-lb:0.0250, loss-ulb:0.0074, weight:2.00, lr:0.0002
[01:52:40.214] iteration:12196  t-loss:0.0278, loss-lb:0.0158, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:52:40.596] iteration:12197  t-loss:0.0400, loss-lb:0.0191, loss-ulb:0.0105, weight:2.00, lr:0.0002
[01:52:40.974] iteration:12198  t-loss:0.0249, loss-lb:0.0216, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:53:44.952] iteration 12198 : dice_score: 0.900167 best_dice: 0.902900
[01:53:44.952]  <<Test>> - Ep:320  - Dice-S/T:90.10/90.02, Best-S:90.24, Best-T:90.29
[01:53:44.952]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[01:53:46.234] iteration:12199  t-loss:0.0344, loss-lb:0.0234, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:53:46.623] iteration:12200  t-loss:0.0275, loss-lb:0.0104, loss-ulb:0.0085, weight:2.00, lr:0.0002
[01:53:47.019] iteration:12201  t-loss:0.0121, loss-lb:0.0104, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:53:47.400] iteration:12202  t-loss:0.0250, loss-lb:0.0106, loss-ulb:0.0072, weight:2.00, lr:0.0002
[01:53:47.785] iteration:12203  t-loss:0.0396, loss-lb:0.0335, loss-ulb:0.0030, weight:2.00, lr:0.0002
[01:53:48.164] iteration:12204  t-loss:0.0543, loss-lb:0.0517, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:53:48.548] iteration:12205  t-loss:0.0201, loss-lb:0.0175, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:53:48.935] iteration:12206  t-loss:0.0362, loss-lb:0.0322, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:53:49.319] iteration:12207  t-loss:0.0550, loss-lb:0.0439, loss-ulb:0.0056, weight:2.00, lr:0.0002
[01:53:49.699] iteration:12208  t-loss:0.0312, loss-lb:0.0295, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:53:50.080] iteration:12209  t-loss:0.0208, loss-lb:0.0164, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:53:50.460] iteration:12210  t-loss:0.0289, loss-lb:0.0264, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:53:50.844] iteration:12211  t-loss:0.0292, loss-lb:0.0264, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:53:51.223] iteration:12212  t-loss:0.0262, loss-lb:0.0234, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:53:51.621] iteration:12213  t-loss:0.0370, loss-lb:0.0256, loss-ulb:0.0057, weight:2.00, lr:0.0002
[01:53:52.026] iteration:12214  t-loss:0.0537, loss-lb:0.0294, loss-ulb:0.0122, weight:2.00, lr:0.0002
[01:53:52.428] iteration:12215  t-loss:0.0226, loss-lb:0.0117, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:53:52.816] iteration:12216  t-loss:0.0529, loss-lb:0.0350, loss-ulb:0.0089, weight:2.00, lr:0.0002
[01:53:53.204] iteration:12217  t-loss:0.0302, loss-lb:0.0224, loss-ulb:0.0039, weight:2.00, lr:0.0002
[01:53:53.583] iteration:12218  t-loss:0.0398, loss-lb:0.0356, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:53:53.961] iteration:12219  t-loss:0.0139, loss-lb:0.0121, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:53:54.345] iteration:12220  t-loss:0.0220, loss-lb:0.0197, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:53:54.723] iteration:12221  t-loss:0.0157, loss-lb:0.0134, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:53:55.101] iteration:12222  t-loss:0.0248, loss-lb:0.0220, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:53:55.483] iteration:12223  t-loss:0.0164, loss-lb:0.0125, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:53:55.863] iteration:12224  t-loss:0.0132, loss-lb:0.0101, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:53:56.244] iteration:12225  t-loss:0.0201, loss-lb:0.0180, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:53:56.625] iteration:12226  t-loss:0.0361, loss-lb:0.0245, loss-ulb:0.0058, weight:2.00, lr:0.0002
[01:53:57.005] iteration:12227  t-loss:0.0106, loss-lb:0.0090, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:53:57.390] iteration:12228  t-loss:0.0245, loss-lb:0.0119, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:53:57.773] iteration:12229  t-loss:0.0258, loss-lb:0.0214, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:53:58.175] iteration:12230  t-loss:0.0263, loss-lb:0.0198, loss-ulb:0.0032, weight:2.00, lr:0.0002
[01:53:58.567] iteration:12231  t-loss:0.0210, loss-lb:0.0169, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:53:58.960] iteration:12232  t-loss:0.0359, loss-lb:0.0205, loss-ulb:0.0077, weight:2.00, lr:0.0002
[01:53:59.342] iteration:12233  t-loss:0.0329, loss-lb:0.0194, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:53:59.722] iteration:12234  t-loss:0.0206, loss-lb:0.0124, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:54:00.100] iteration:12235  t-loss:0.0288, loss-lb:0.0103, loss-ulb:0.0092, weight:2.00, lr:0.0002
[01:54:00.481] iteration:12236  t-loss:0.0345, loss-lb:0.0127, loss-ulb:0.0109, weight:2.00, lr:0.0002
[01:54:01.722] iteration:12237  t-loss:0.0334, loss-lb:0.0197, loss-ulb:0.0069, weight:2.00, lr:0.0002
[01:54:02.109] iteration:12238  t-loss:0.0128, loss-lb:0.0107, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:02.493] iteration:12239  t-loss:0.0411, loss-lb:0.0228, loss-ulb:0.0092, weight:2.00, lr:0.0002
[01:54:02.880] iteration:12240  t-loss:0.0214, loss-lb:0.0190, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:54:03.276] iteration:12241  t-loss:0.0407, loss-lb:0.0240, loss-ulb:0.0084, weight:2.00, lr:0.0002
[01:54:03.658] iteration:12242  t-loss:0.0278, loss-lb:0.0262, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:54:04.042] iteration:12243  t-loss:0.0283, loss-lb:0.0187, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:54:04.422] iteration:12244  t-loss:0.0114, loss-lb:0.0100, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:54:04.805] iteration:12245  t-loss:0.0242, loss-lb:0.0119, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:54:05.184] iteration:12246  t-loss:0.0139, loss-lb:0.0123, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:54:05.564] iteration:12247  t-loss:0.0215, loss-lb:0.0202, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:54:05.944] iteration:12248  t-loss:0.0250, loss-lb:0.0133, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:54:06.320] iteration:12249  t-loss:0.0137, loss-lb:0.0115, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:54:06.701] iteration:12250  t-loss:0.0444, loss-lb:0.0136, loss-ulb:0.0154, weight:2.00, lr:0.0002
[01:54:07.084] iteration:12251  t-loss:0.0103, loss-lb:0.0087, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:54:07.468] iteration:12252  t-loss:0.0307, loss-lb:0.0106, loss-ulb:0.0100, weight:2.00, lr:0.0002
[01:54:07.849] iteration:12253  t-loss:0.0152, loss-lb:0.0099, loss-ulb:0.0026, weight:2.00, lr:0.0002
[01:54:08.227] iteration:12254  t-loss:0.0119, loss-lb:0.0098, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:08.608] iteration:12255  t-loss:0.0362, loss-lb:0.0282, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:54:08.997] iteration:12256  t-loss:0.0342, loss-lb:0.0247, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:54:09.382] iteration:12257  t-loss:0.0208, loss-lb:0.0187, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:54:09.762] iteration:12258  t-loss:0.0235, loss-lb:0.0195, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:54:10.143] iteration:12259  t-loss:0.0357, loss-lb:0.0260, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:54:10.522] iteration:12260  t-loss:0.0332, loss-lb:0.0130, loss-ulb:0.0101, weight:2.00, lr:0.0002
[01:54:10.901] iteration:12261  t-loss:0.0226, loss-lb:0.0203, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:54:11.281] iteration:12262  t-loss:0.0215, loss-lb:0.0196, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:11.661] iteration:12263  t-loss:0.0279, loss-lb:0.0234, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:54:12.048] iteration:12264  t-loss:0.0356, loss-lb:0.0206, loss-ulb:0.0075, weight:2.00, lr:0.0002
[01:54:12.424] iteration:12265  t-loss:0.0137, loss-lb:0.0105, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:54:12.801] iteration:12266  t-loss:0.0652, loss-lb:0.0118, loss-ulb:0.0267, weight:2.00, lr:0.0002
[01:54:13.179] iteration:12267  t-loss:0.0296, loss-lb:0.0189, loss-ulb:0.0054, weight:2.00, lr:0.0002
[01:54:13.565] iteration:12268  t-loss:0.0308, loss-lb:0.0202, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:54:13.959] iteration:12269  t-loss:0.0262, loss-lb:0.0242, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:14.354] iteration:12270  t-loss:0.0292, loss-lb:0.0176, loss-ulb:0.0058, weight:2.00, lr:0.0002
[01:54:14.733] iteration:12271  t-loss:0.0314, loss-lb:0.0232, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:54:15.115] iteration:12272  t-loss:0.0272, loss-lb:0.0116, loss-ulb:0.0078, weight:2.00, lr:0.0002
[01:54:15.489] iteration:12273  t-loss:0.0136, loss-lb:0.0109, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:54:15.861] iteration:12274  t-loss:0.0155, loss-lb:0.0115, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:54:17.032] iteration:12275  t-loss:0.0295, loss-lb:0.0255, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:54:17.432] iteration:12276  t-loss:0.0211, loss-lb:0.0107, loss-ulb:0.0052, weight:2.00, lr:0.0002
[01:54:17.824] iteration:12277  t-loss:0.0262, loss-lb:0.0179, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:54:18.200] iteration:12278  t-loss:0.0287, loss-lb:0.0267, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:18.577] iteration:12279  t-loss:0.0163, loss-lb:0.0088, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:54:18.963] iteration:12280  t-loss:0.0295, loss-lb:0.0210, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:54:19.344] iteration:12281  t-loss:0.0420, loss-lb:0.0252, loss-ulb:0.0084, weight:2.00, lr:0.0002
[01:54:19.723] iteration:12282  t-loss:0.0290, loss-lb:0.0164, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:54:20.113] iteration:12283  t-loss:0.0318, loss-lb:0.0140, loss-ulb:0.0089, weight:2.00, lr:0.0002
[01:54:20.494] iteration:12284  t-loss:0.0237, loss-lb:0.0219, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:54:20.869] iteration:12285  t-loss:0.0153, loss-lb:0.0093, loss-ulb:0.0030, weight:2.00, lr:0.0002
[01:54:21.249] iteration:12286  t-loss:0.0157, loss-lb:0.0132, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:54:21.630] iteration:12287  t-loss:0.0249, loss-lb:0.0201, loss-ulb:0.0024, weight:2.00, lr:0.0002
[01:54:22.014] iteration:12288  t-loss:0.0292, loss-lb:0.0190, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:54:22.393] iteration:12289  t-loss:0.0126, loss-lb:0.0104, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:54:22.776] iteration:12290  t-loss:0.0149, loss-lb:0.0132, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:54:23.155] iteration:12291  t-loss:0.0199, loss-lb:0.0126, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:54:23.535] iteration:12292  t-loss:0.0127, loss-lb:0.0100, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:54:23.920] iteration:12293  t-loss:0.0364, loss-lb:0.0118, loss-ulb:0.0123, weight:2.00, lr:0.0002
[01:54:24.301] iteration:12294  t-loss:0.0140, loss-lb:0.0127, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:54:24.686] iteration:12295  t-loss:0.0324, loss-lb:0.0224, loss-ulb:0.0050, weight:2.00, lr:0.0002
[01:54:25.065] iteration:12296  t-loss:0.0167, loss-lb:0.0114, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:54:25.440] iteration:12297  t-loss:0.0192, loss-lb:0.0169, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:54:25.816] iteration:12298  t-loss:0.0139, loss-lb:0.0093, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:54:26.189] iteration:12299  t-loss:0.0153, loss-lb:0.0097, loss-ulb:0.0028, weight:2.00, lr:0.0002
[01:54:26.561] iteration:12300  t-loss:0.0174, loss-lb:0.0141, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:54:26.938] iteration:12301  t-loss:0.0322, loss-lb:0.0252, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:54:27.313] iteration:12302  t-loss:0.0263, loss-lb:0.0230, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:54:27.695] iteration:12303  t-loss:0.0370, loss-lb:0.0252, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:54:28.078] iteration:12304  t-loss:0.0303, loss-lb:0.0290, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:54:28.452] iteration:12305  t-loss:0.0308, loss-lb:0.0231, loss-ulb:0.0038, weight:2.00, lr:0.0002
[01:54:28.835] iteration:12306  t-loss:0.0175, loss-lb:0.0107, loss-ulb:0.0034, weight:2.00, lr:0.0002
[01:54:29.223] iteration:12307  t-loss:0.0220, loss-lb:0.0098, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:54:29.624] iteration:12308  t-loss:0.0226, loss-lb:0.0188, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:54:30.022] iteration:12309  t-loss:0.0186, loss-lb:0.0167, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:30.407] iteration:12310  t-loss:0.0693, loss-lb:0.0579, loss-ulb:0.0057, weight:2.00, lr:0.0002
[01:54:30.785] iteration:12311  t-loss:0.0255, loss-lb:0.0111, loss-ulb:0.0072, weight:2.00, lr:0.0002
[01:54:31.158] iteration:12312  t-loss:0.0176, loss-lb:0.0131, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:54:32.418] iteration:12313  t-loss:0.0161, loss-lb:0.0133, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:54:32.821] iteration:12314  t-loss:0.0208, loss-lb:0.0186, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:54:33.210] iteration:12315  t-loss:0.0213, loss-lb:0.0103, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:54:33.591] iteration:12316  t-loss:0.0220, loss-lb:0.0107, loss-ulb:0.0056, weight:2.00, lr:0.0002
[01:54:33.952] iteration:12317  t-loss:0.0191, loss-lb:0.0122, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:54:34.333] iteration:12318  t-loss:0.0482, loss-lb:0.0200, loss-ulb:0.0141, weight:2.00, lr:0.0002
[01:54:34.718] iteration:12319  t-loss:0.0216, loss-lb:0.0192, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:54:35.096] iteration:12320  t-loss:0.0208, loss-lb:0.0190, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:54:35.472] iteration:12321  t-loss:0.0232, loss-lb:0.0213, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:35.847] iteration:12322  t-loss:0.0143, loss-lb:0.0098, loss-ulb:0.0022, weight:2.00, lr:0.0002
[01:54:36.224] iteration:12323  t-loss:0.0159, loss-lb:0.0131, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:54:36.599] iteration:12324  t-loss:0.0132, loss-lb:0.0102, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:54:36.976] iteration:12325  t-loss:0.0356, loss-lb:0.0251, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:54:37.353] iteration:12326  t-loss:0.0204, loss-lb:0.0183, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:37.741] iteration:12327  t-loss:0.0333, loss-lb:0.0259, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:54:38.125] iteration:12328  t-loss:0.0136, loss-lb:0.0109, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:54:38.503] iteration:12329  t-loss:0.0344, loss-lb:0.0181, loss-ulb:0.0081, weight:2.00, lr:0.0002
[01:54:38.891] iteration:12330  t-loss:0.0315, loss-lb:0.0192, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:54:39.279] iteration:12331  t-loss:0.0430, loss-lb:0.0297, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:54:39.656] iteration:12332  t-loss:0.0322, loss-lb:0.0180, loss-ulb:0.0071, weight:2.00, lr:0.0002
[01:54:40.035] iteration:12333  t-loss:0.0333, loss-lb:0.0244, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:54:40.413] iteration:12334  t-loss:0.0240, loss-lb:0.0193, loss-ulb:0.0024, weight:2.00, lr:0.0002
[01:54:40.791] iteration:12335  t-loss:0.0392, loss-lb:0.0217, loss-ulb:0.0088, weight:2.00, lr:0.0002
[01:54:41.163] iteration:12336  t-loss:0.0236, loss-lb:0.0218, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:54:41.538] iteration:12337  t-loss:0.0376, loss-lb:0.0256, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:54:41.913] iteration:12338  t-loss:0.0336, loss-lb:0.0101, loss-ulb:0.0118, weight:2.00, lr:0.0002
[01:54:42.290] iteration:12339  t-loss:0.0282, loss-lb:0.0162, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:54:42.664] iteration:12340  t-loss:0.0135, loss-lb:0.0119, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:54:43.036] iteration:12341  t-loss:0.0128, loss-lb:0.0096, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:54:43.413] iteration:12342  t-loss:0.0218, loss-lb:0.0125, loss-ulb:0.0046, weight:2.00, lr:0.0002
[01:54:43.791] iteration:12343  t-loss:0.0362, loss-lb:0.0272, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:54:44.164] iteration:12344  t-loss:0.0116, loss-lb:0.0087, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:54:44.538] iteration:12345  t-loss:0.0267, loss-lb:0.0215, loss-ulb:0.0026, weight:2.00, lr:0.0002
[01:54:44.922] iteration:12346  t-loss:0.0123, loss-lb:0.0086, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:54:45.305] iteration:12347  t-loss:0.0141, loss-lb:0.0121, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:54:45.688] iteration:12348  t-loss:0.0271, loss-lb:0.0188, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:54:46.069] iteration:12349  t-loss:0.0444, loss-lb:0.0302, loss-ulb:0.0071, weight:2.00, lr:0.0002
[01:54:46.448] iteration:12350  t-loss:0.0340, loss-lb:0.0168, loss-ulb:0.0086, weight:2.00, lr:0.0002
[01:55:50.774] iteration 12350 : dice_score: 0.881483 best_dice: 0.902900
[01:55:50.775]  <<Test>> - Ep:324  - Dice-S/T:85.56/88.15, Best-S:90.24, Best-T:90.29
[01:55:50.775]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[01:55:52.144] iteration:12351  t-loss:0.0282, loss-lb:0.0142, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:55:52.538] iteration:12352  t-loss:0.0225, loss-lb:0.0124, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:55:52.922] iteration:12353  t-loss:0.0187, loss-lb:0.0113, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:55:53.303] iteration:12354  t-loss:0.0148, loss-lb:0.0114, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:55:53.690] iteration:12355  t-loss:0.0202, loss-lb:0.0189, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:55:54.070] iteration:12356  t-loss:0.0252, loss-lb:0.0118, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:55:54.457] iteration:12357  t-loss:0.0333, loss-lb:0.0241, loss-ulb:0.0046, weight:2.00, lr:0.0002
[01:55:54.837] iteration:12358  t-loss:0.0224, loss-lb:0.0115, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:55:55.226] iteration:12359  t-loss:0.0146, loss-lb:0.0120, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:55:55.611] iteration:12360  t-loss:0.0285, loss-lb:0.0108, loss-ulb:0.0088, weight:2.00, lr:0.0002
[01:55:55.991] iteration:12361  t-loss:0.0456, loss-lb:0.0315, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:55:56.378] iteration:12362  t-loss:0.0299, loss-lb:0.0177, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:55:56.758] iteration:12363  t-loss:0.0104, loss-lb:0.0091, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:55:57.138] iteration:12364  t-loss:0.0165, loss-lb:0.0143, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:55:57.525] iteration:12365  t-loss:0.0359, loss-lb:0.0252, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:55:57.907] iteration:12366  t-loss:0.0304, loss-lb:0.0280, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:55:58.286] iteration:12367  t-loss:0.0240, loss-lb:0.0129, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:55:58.670] iteration:12368  t-loss:0.0599, loss-lb:0.0114, loss-ulb:0.0243, weight:2.00, lr:0.0002
[01:55:59.054] iteration:12369  t-loss:0.0251, loss-lb:0.0228, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:55:59.446] iteration:12370  t-loss:0.0239, loss-lb:0.0201, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:55:59.834] iteration:12371  t-loss:0.0222, loss-lb:0.0126, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:56:00.216] iteration:12372  t-loss:0.0439, loss-lb:0.0239, loss-ulb:0.0100, weight:2.00, lr:0.0002
[01:56:00.603] iteration:12373  t-loss:0.0200, loss-lb:0.0182, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:56:00.983] iteration:12374  t-loss:0.0177, loss-lb:0.0095, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:56:01.369] iteration:12375  t-loss:0.0291, loss-lb:0.0216, loss-ulb:0.0038, weight:2.00, lr:0.0002
[01:56:01.744] iteration:12376  t-loss:0.0140, loss-lb:0.0115, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:56:02.121] iteration:12377  t-loss:0.0321, loss-lb:0.0099, loss-ulb:0.0111, weight:2.00, lr:0.0002
[01:56:02.503] iteration:12378  t-loss:0.0366, loss-lb:0.0244, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:56:02.882] iteration:12379  t-loss:0.0187, loss-lb:0.0114, loss-ulb:0.0036, weight:2.00, lr:0.0002
[01:56:03.263] iteration:12380  t-loss:0.0388, loss-lb:0.0209, loss-ulb:0.0090, weight:2.00, lr:0.0002
[01:56:03.640] iteration:12381  t-loss:0.0373, loss-lb:0.0278, loss-ulb:0.0047, weight:2.00, lr:0.0002
[01:56:04.015] iteration:12382  t-loss:0.0224, loss-lb:0.0200, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:56:04.391] iteration:12383  t-loss:0.0411, loss-lb:0.0284, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:56:04.777] iteration:12384  t-loss:0.0336, loss-lb:0.0123, loss-ulb:0.0107, weight:2.00, lr:0.0002
[01:56:05.164] iteration:12385  t-loss:0.0231, loss-lb:0.0151, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:56:05.544] iteration:12386  t-loss:0.0356, loss-lb:0.0205, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:56:05.916] iteration:12387  t-loss:0.0124, loss-lb:0.0105, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:56:06.279] iteration:12388  t-loss:0.0264, loss-lb:0.0241, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:56:07.691] iteration:12389  t-loss:0.0345, loss-lb:0.0129, loss-ulb:0.0108, weight:2.00, lr:0.0002
[01:56:08.080] iteration:12390  t-loss:0.0119, loss-lb:0.0104, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:56:08.472] iteration:12391  t-loss:0.0132, loss-lb:0.0096, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:56:08.848] iteration:12392  t-loss:0.0132, loss-lb:0.0107, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:56:09.227] iteration:12393  t-loss:0.0157, loss-lb:0.0104, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:56:09.605] iteration:12394  t-loss:0.0254, loss-lb:0.0191, loss-ulb:0.0032, weight:2.00, lr:0.0002
[01:56:09.986] iteration:12395  t-loss:0.0198, loss-lb:0.0185, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:56:10.372] iteration:12396  t-loss:0.0211, loss-lb:0.0102, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:56:10.757] iteration:12397  t-loss:0.0259, loss-lb:0.0189, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:56:11.137] iteration:12398  t-loss:0.0279, loss-lb:0.0135, loss-ulb:0.0072, weight:2.00, lr:0.0002
[01:56:11.521] iteration:12399  t-loss:0.0406, loss-lb:0.0248, loss-ulb:0.0079, weight:2.00, lr:0.0002
[01:56:11.907] iteration:12400  t-loss:0.0302, loss-lb:0.0199, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:56:12.288] iteration:12401  t-loss:0.0177, loss-lb:0.0124, loss-ulb:0.0026, weight:2.00, lr:0.0002
[01:56:12.665] iteration:12402  t-loss:0.0356, loss-lb:0.0225, loss-ulb:0.0066, weight:2.00, lr:0.0002
[01:56:13.045] iteration:12403  t-loss:0.0272, loss-lb:0.0132, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:56:13.432] iteration:12404  t-loss:0.0268, loss-lb:0.0189, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:56:13.811] iteration:12405  t-loss:0.0143, loss-lb:0.0126, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:56:14.194] iteration:12406  t-loss:0.0536, loss-lb:0.0195, loss-ulb:0.0170, weight:2.00, lr:0.0002
[01:56:14.578] iteration:12407  t-loss:0.0200, loss-lb:0.0097, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:56:14.968] iteration:12408  t-loss:0.0315, loss-lb:0.0232, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:56:15.359] iteration:12409  t-loss:0.0246, loss-lb:0.0113, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:56:15.744] iteration:12410  t-loss:0.0373, loss-lb:0.0238, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:56:16.123] iteration:12411  t-loss:0.0301, loss-lb:0.0242, loss-ulb:0.0030, weight:2.00, lr:0.0002
[01:56:16.497] iteration:12412  t-loss:0.0241, loss-lb:0.0186, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:56:16.884] iteration:12413  t-loss:0.0355, loss-lb:0.0229, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:56:17.266] iteration:12414  t-loss:0.0275, loss-lb:0.0194, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:56:17.649] iteration:12415  t-loss:0.0143, loss-lb:0.0104, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:56:18.030] iteration:12416  t-loss:0.0324, loss-lb:0.0177, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:56:18.409] iteration:12417  t-loss:0.0268, loss-lb:0.0234, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:56:18.787] iteration:12418  t-loss:0.0111, loss-lb:0.0091, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:56:19.172] iteration:12419  t-loss:0.0224, loss-lb:0.0113, loss-ulb:0.0056, weight:2.00, lr:0.0002
[01:56:19.553] iteration:12420  t-loss:0.0701, loss-lb:0.0102, loss-ulb:0.0300, weight:2.00, lr:0.0002
[01:56:19.930] iteration:12421  t-loss:0.0194, loss-lb:0.0163, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:56:20.320] iteration:12422  t-loss:0.0385, loss-lb:0.0365, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:56:20.713] iteration:12423  t-loss:0.0230, loss-lb:0.0173, loss-ulb:0.0029, weight:2.00, lr:0.0002
[01:56:21.097] iteration:12424  t-loss:0.0311, loss-lb:0.0193, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:56:21.473] iteration:12425  t-loss:0.0211, loss-lb:0.0181, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:56:21.849] iteration:12426  t-loss:0.0321, loss-lb:0.0113, loss-ulb:0.0104, weight:2.00, lr:0.0002
[01:56:23.316] iteration:12427  t-loss:0.0278, loss-lb:0.0173, loss-ulb:0.0052, weight:2.00, lr:0.0002
[01:56:23.707] iteration:12428  t-loss:0.0187, loss-lb:0.0164, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:56:24.089] iteration:12429  t-loss:0.0269, loss-lb:0.0156, loss-ulb:0.0057, weight:2.00, lr:0.0002
[01:56:24.474] iteration:12430  t-loss:0.0272, loss-lb:0.0202, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:56:24.856] iteration:12431  t-loss:0.0325, loss-lb:0.0187, loss-ulb:0.0069, weight:2.00, lr:0.0002
[01:56:25.235] iteration:12432  t-loss:0.0296, loss-lb:0.0209, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:56:25.612] iteration:12433  t-loss:0.0161, loss-lb:0.0127, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:56:25.998] iteration:12434  t-loss:0.0277, loss-lb:0.0181, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:56:26.373] iteration:12435  t-loss:0.0162, loss-lb:0.0124, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:56:26.754] iteration:12436  t-loss:0.0195, loss-lb:0.0124, loss-ulb:0.0036, weight:2.00, lr:0.0002
[01:56:27.135] iteration:12437  t-loss:0.0256, loss-lb:0.0120, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:56:27.525] iteration:12438  t-loss:0.0422, loss-lb:0.0227, loss-ulb:0.0098, weight:2.00, lr:0.0002
[01:56:27.903] iteration:12439  t-loss:0.0163, loss-lb:0.0138, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:56:28.284] iteration:12440  t-loss:0.0319, loss-lb:0.0301, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:56:28.670] iteration:12441  t-loss:0.0306, loss-lb:0.0180, loss-ulb:0.0063, weight:2.00, lr:0.0002
[01:56:29.051] iteration:12442  t-loss:0.0371, loss-lb:0.0270, loss-ulb:0.0050, weight:2.00, lr:0.0002
[01:56:29.434] iteration:12443  t-loss:0.0236, loss-lb:0.0198, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:56:29.807] iteration:12444  t-loss:0.0186, loss-lb:0.0125, loss-ulb:0.0030, weight:2.00, lr:0.0002
[01:56:30.194] iteration:12445  t-loss:0.0557, loss-lb:0.0287, loss-ulb:0.0135, weight:2.00, lr:0.0002
[01:56:30.576] iteration:12446  t-loss:0.0323, loss-lb:0.0243, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:56:30.956] iteration:12447  t-loss:0.0268, loss-lb:0.0128, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:56:31.330] iteration:12448  t-loss:0.0242, loss-lb:0.0143, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:56:31.705] iteration:12449  t-loss:0.0186, loss-lb:0.0159, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:56:32.082] iteration:12450  t-loss:0.0252, loss-lb:0.0135, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:56:32.456] iteration:12451  t-loss:0.0210, loss-lb:0.0194, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:56:32.831] iteration:12452  t-loss:0.0682, loss-lb:0.0107, loss-ulb:0.0288, weight:2.00, lr:0.0002
[01:56:33.205] iteration:12453  t-loss:0.0448, loss-lb:0.0128, loss-ulb:0.0160, weight:2.00, lr:0.0002
[01:56:33.576] iteration:12454  t-loss:0.0116, loss-lb:0.0084, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:56:33.955] iteration:12455  t-loss:0.0229, loss-lb:0.0108, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:56:34.346] iteration:12456  t-loss:0.0394, loss-lb:0.0179, loss-ulb:0.0107, weight:2.00, lr:0.0002
[01:56:34.734] iteration:12457  t-loss:0.0179, loss-lb:0.0119, loss-ulb:0.0030, weight:2.00, lr:0.0002
[01:56:35.113] iteration:12458  t-loss:0.0392, loss-lb:0.0286, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:56:35.492] iteration:12459  t-loss:0.0433, loss-lb:0.0237, loss-ulb:0.0098, weight:2.00, lr:0.0002
[01:56:35.865] iteration:12460  t-loss:0.0677, loss-lb:0.0646, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:56:36.253] iteration:12461  t-loss:0.0424, loss-lb:0.0255, loss-ulb:0.0085, weight:2.00, lr:0.0002
[01:56:36.631] iteration:12462  t-loss:0.0213, loss-lb:0.0139, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:56:37.005] iteration:12463  t-loss:0.0251, loss-lb:0.0184, loss-ulb:0.0034, weight:2.00, lr:0.0002
[01:56:37.382] iteration:12464  t-loss:0.0514, loss-lb:0.0304, loss-ulb:0.0105, weight:2.00, lr:0.0002
[01:56:38.542] iteration:12465  t-loss:0.0309, loss-lb:0.0257, loss-ulb:0.0026, weight:2.00, lr:0.0002
[01:56:38.931] iteration:12466  t-loss:0.0286, loss-lb:0.0141, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:56:39.316] iteration:12467  t-loss:0.0651, loss-lb:0.0346, loss-ulb:0.0152, weight:2.00, lr:0.0002
[01:56:39.706] iteration:12468  t-loss:0.0252, loss-lb:0.0165, loss-ulb:0.0043, weight:2.00, lr:0.0002
[01:56:40.088] iteration:12469  t-loss:0.0504, loss-lb:0.0322, loss-ulb:0.0091, weight:2.00, lr:0.0002
[01:56:40.471] iteration:12470  t-loss:0.0499, loss-lb:0.0299, loss-ulb:0.0100, weight:2.00, lr:0.0002
[01:56:40.846] iteration:12471  t-loss:0.0206, loss-lb:0.0170, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:56:41.229] iteration:12472  t-loss:0.0320, loss-lb:0.0267, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:56:41.611] iteration:12473  t-loss:0.0255, loss-lb:0.0137, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:56:41.989] iteration:12474  t-loss:0.0286, loss-lb:0.0263, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:56:42.367] iteration:12475  t-loss:0.0271, loss-lb:0.0215, loss-ulb:0.0028, weight:2.00, lr:0.0002
[01:56:42.747] iteration:12476  t-loss:0.0430, loss-lb:0.0269, loss-ulb:0.0080, weight:2.00, lr:0.0002
[01:56:43.125] iteration:12477  t-loss:0.0728, loss-lb:0.0304, loss-ulb:0.0212, weight:2.00, lr:0.0002
[01:56:43.502] iteration:12478  t-loss:0.0285, loss-lb:0.0118, loss-ulb:0.0083, weight:2.00, lr:0.0002
[01:56:43.883] iteration:12479  t-loss:0.0372, loss-lb:0.0191, loss-ulb:0.0091, weight:2.00, lr:0.0002
[01:56:44.262] iteration:12480  t-loss:0.0840, loss-lb:0.0446, loss-ulb:0.0197, weight:2.00, lr:0.0002
[01:56:44.644] iteration:12481  t-loss:0.0220, loss-lb:0.0190, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:56:45.028] iteration:12482  t-loss:0.0370, loss-lb:0.0255, loss-ulb:0.0058, weight:2.00, lr:0.0002
[01:56:45.420] iteration:12483  t-loss:0.0264, loss-lb:0.0242, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:56:45.803] iteration:12484  t-loss:0.0333, loss-lb:0.0298, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:56:46.179] iteration:12485  t-loss:0.0209, loss-lb:0.0139, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:56:46.558] iteration:12486  t-loss:0.0339, loss-lb:0.0183, loss-ulb:0.0078, weight:2.00, lr:0.0002
[01:56:46.944] iteration:12487  t-loss:0.0341, loss-lb:0.0202, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:56:47.322] iteration:12488  t-loss:0.1270, loss-lb:0.1107, loss-ulb:0.0081, weight:2.00, lr:0.0002
[01:56:47.696] iteration:12489  t-loss:0.0186, loss-lb:0.0159, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:56:48.071] iteration:12490  t-loss:0.1338, loss-lb:0.1156, loss-ulb:0.0091, weight:2.00, lr:0.0002
[01:56:48.451] iteration:12491  t-loss:0.0342, loss-lb:0.0224, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:56:48.824] iteration:12492  t-loss:0.0258, loss-lb:0.0222, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:56:49.210] iteration:12493  t-loss:0.0551, loss-lb:0.0181, loss-ulb:0.0185, weight:2.00, lr:0.0002
[01:56:49.600] iteration:12494  t-loss:0.0379, loss-lb:0.0310, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:56:50.009] iteration:12495  t-loss:0.0286, loss-lb:0.0151, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:56:50.383] iteration:12496  t-loss:0.0213, loss-lb:0.0192, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:56:50.757] iteration:12497  t-loss:0.0251, loss-lb:0.0106, loss-ulb:0.0073, weight:2.00, lr:0.0002
[01:56:51.135] iteration:12498  t-loss:0.0435, loss-lb:0.0350, loss-ulb:0.0042, weight:2.00, lr:0.0002
[01:56:51.515] iteration:12499  t-loss:0.0150, loss-lb:0.0132, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:56:51.890] iteration:12500  t-loss:0.0302, loss-lb:0.0253, loss-ulb:0.0024, weight:2.00, lr:0.0002
[01:56:52.267] iteration:12501  t-loss:0.0138, loss-lb:0.0113, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:56:52.646] iteration:12502  t-loss:0.0376, loss-lb:0.0320, loss-ulb:0.0028, weight:2.00, lr:0.0002
[01:57:56.972] iteration 12502 : dice_score: 0.859480 best_dice: 0.902900
[01:57:56.972]  <<Test>> - Ep:328  - Dice-S/T:84.71/85.95, Best-S:90.24, Best-T:90.29
[01:57:56.972]           - AvgLoss(lb/ulb/all):0.03/0.00/0.04
[01:57:58.040] iteration:12503  t-loss:0.0166, loss-lb:0.0147, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:57:58.439] iteration:12504  t-loss:0.0254, loss-lb:0.0164, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:57:58.825] iteration:12505  t-loss:0.0135, loss-lb:0.0120, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:57:59.210] iteration:12506  t-loss:0.0239, loss-lb:0.0228, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:57:59.594] iteration:12507  t-loss:0.0487, loss-lb:0.0339, loss-ulb:0.0074, weight:2.00, lr:0.0002
[01:57:59.987] iteration:12508  t-loss:0.0161, loss-lb:0.0091, loss-ulb:0.0035, weight:2.00, lr:0.0002
[01:58:00.368] iteration:12509  t-loss:0.0162, loss-lb:0.0137, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:58:00.748] iteration:12510  t-loss:0.0328, loss-lb:0.0188, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:58:01.132] iteration:12511  t-loss:0.0548, loss-lb:0.0346, loss-ulb:0.0101, weight:2.00, lr:0.0002
[01:58:01.512] iteration:12512  t-loss:0.0287, loss-lb:0.0198, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:58:01.896] iteration:12513  t-loss:0.0225, loss-lb:0.0135, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:58:02.275] iteration:12514  t-loss:0.0168, loss-lb:0.0133, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:58:02.658] iteration:12515  t-loss:0.0415, loss-lb:0.0137, loss-ulb:0.0139, weight:2.00, lr:0.0002
[01:58:03.038] iteration:12516  t-loss:0.0215, loss-lb:0.0109, loss-ulb:0.0053, weight:2.00, lr:0.0002
[01:58:03.420] iteration:12517  t-loss:0.0289, loss-lb:0.0264, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:58:03.801] iteration:12518  t-loss:0.0166, loss-lb:0.0110, loss-ulb:0.0028, weight:2.00, lr:0.0002
[01:58:04.184] iteration:12519  t-loss:0.0200, loss-lb:0.0127, loss-ulb:0.0036, weight:2.00, lr:0.0002
[01:58:04.554] iteration:12520  t-loss:0.2604, loss-lb:0.0087, loss-ulb:0.1259, weight:2.00, lr:0.0002
[01:58:04.934] iteration:12521  t-loss:0.0216, loss-lb:0.0187, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:58:05.312] iteration:12522  t-loss:0.0260, loss-lb:0.0228, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:58:05.699] iteration:12523  t-loss:0.0409, loss-lb:0.0101, loss-ulb:0.0154, weight:2.00, lr:0.0002
[01:58:06.080] iteration:12524  t-loss:0.0259, loss-lb:0.0177, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:58:06.472] iteration:12525  t-loss:0.0167, loss-lb:0.0130, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:58:06.873] iteration:12526  t-loss:0.0193, loss-lb:0.0169, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:58:07.257] iteration:12527  t-loss:0.0206, loss-lb:0.0168, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:58:07.638] iteration:12528  t-loss:0.0261, loss-lb:0.0113, loss-ulb:0.0074, weight:2.00, lr:0.0002
[01:58:08.014] iteration:12529  t-loss:0.2725, loss-lb:0.0214, loss-ulb:0.1255, weight:2.00, lr:0.0002
[01:58:08.400] iteration:12530  t-loss:0.0175, loss-lb:0.0126, loss-ulb:0.0025, weight:2.00, lr:0.0002
[01:58:08.781] iteration:12531  t-loss:0.0190, loss-lb:0.0100, loss-ulb:0.0045, weight:2.00, lr:0.0002
[01:58:09.157] iteration:12532  t-loss:0.0193, loss-lb:0.0160, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:58:09.534] iteration:12533  t-loss:0.0340, loss-lb:0.0206, loss-ulb:0.0067, weight:2.00, lr:0.0002
[01:58:09.913] iteration:12534  t-loss:0.0456, loss-lb:0.0165, loss-ulb:0.0146, weight:2.00, lr:0.0002
[01:58:10.287] iteration:12535  t-loss:0.0376, loss-lb:0.0309, loss-ulb:0.0034, weight:2.00, lr:0.0002
[01:58:10.665] iteration:12536  t-loss:0.0330, loss-lb:0.0234, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:58:11.042] iteration:12537  t-loss:0.0238, loss-lb:0.0107, loss-ulb:0.0066, weight:2.00, lr:0.0002
[01:58:11.418] iteration:12538  t-loss:0.0254, loss-lb:0.0135, loss-ulb:0.0059, weight:2.00, lr:0.0002
[01:58:11.801] iteration:12539  t-loss:0.0653, loss-lb:0.0185, loss-ulb:0.0234, weight:2.00, lr:0.0002
[01:58:12.196] iteration:12540  t-loss:0.0286, loss-lb:0.0164, loss-ulb:0.0061, weight:2.00, lr:0.0002
[01:58:13.698] iteration:12541  t-loss:0.0181, loss-lb:0.0108, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:58:14.098] iteration:12542  t-loss:0.0112, loss-lb:0.0086, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:58:14.492] iteration:12543  t-loss:0.0268, loss-lb:0.0172, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:58:14.878] iteration:12544  t-loss:0.0168, loss-lb:0.0095, loss-ulb:0.0036, weight:2.00, lr:0.0002
[01:58:15.261] iteration:12545  t-loss:0.0236, loss-lb:0.0096, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:58:15.644] iteration:12546  t-loss:0.0297, loss-lb:0.0266, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:58:16.029] iteration:12547  t-loss:0.0263, loss-lb:0.0224, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:58:16.405] iteration:12548  t-loss:0.0535, loss-lb:0.0512, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:58:16.790] iteration:12549  t-loss:0.0204, loss-lb:0.0162, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:58:17.170] iteration:12550  t-loss:0.0218, loss-lb:0.0115, loss-ulb:0.0052, weight:2.00, lr:0.0002
[01:58:17.548] iteration:12551  t-loss:0.0179, loss-lb:0.0164, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:58:17.926] iteration:12552  t-loss:0.0388, loss-lb:0.0258, loss-ulb:0.0065, weight:2.00, lr:0.0002
[01:58:18.303] iteration:12553  t-loss:0.0172, loss-lb:0.0130, loss-ulb:0.0021, weight:2.00, lr:0.0002
[01:58:18.683] iteration:12554  t-loss:0.0292, loss-lb:0.0199, loss-ulb:0.0046, weight:2.00, lr:0.0002
[01:58:19.058] iteration:12555  t-loss:0.0360, loss-lb:0.0322, loss-ulb:0.0019, weight:2.00, lr:0.0002
[01:58:19.429] iteration:12556  t-loss:0.0134, loss-lb:0.0111, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:58:19.808] iteration:12557  t-loss:0.0237, loss-lb:0.0227, loss-ulb:0.0005, weight:2.00, lr:0.0002
[01:58:20.186] iteration:12558  t-loss:0.0498, loss-lb:0.0236, loss-ulb:0.0131, weight:2.00, lr:0.0002
[01:58:20.562] iteration:12559  t-loss:0.0315, loss-lb:0.0240, loss-ulb:0.0038, weight:2.00, lr:0.0002
[01:58:20.939] iteration:12560  t-loss:0.0253, loss-lb:0.0089, loss-ulb:0.0082, weight:2.00, lr:0.0002
[01:58:21.314] iteration:12561  t-loss:0.0424, loss-lb:0.0199, loss-ulb:0.0112, weight:2.00, lr:0.0002
[01:58:21.703] iteration:12562  t-loss:0.0424, loss-lb:0.0321, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:58:22.084] iteration:12563  t-loss:0.0432, loss-lb:0.0212, loss-ulb:0.0110, weight:2.00, lr:0.0002
[01:58:22.468] iteration:12564  t-loss:0.0147, loss-lb:0.0127, loss-ulb:0.0010, weight:2.00, lr:0.0002
[01:58:22.850] iteration:12565  t-loss:0.0151, loss-lb:0.0095, loss-ulb:0.0028, weight:2.00, lr:0.0002
[01:58:23.236] iteration:12566  t-loss:0.0226, loss-lb:0.0129, loss-ulb:0.0048, weight:2.00, lr:0.0002
[01:58:23.616] iteration:12567  t-loss:0.0215, loss-lb:0.0135, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:58:24.002] iteration:12568  t-loss:0.0543, loss-lb:0.0095, loss-ulb:0.0224, weight:2.00, lr:0.0002
[01:58:24.398] iteration:12569  t-loss:0.0406, loss-lb:0.0385, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:58:24.776] iteration:12570  t-loss:0.0107, loss-lb:0.0095, loss-ulb:0.0006, weight:2.00, lr:0.0002
[01:58:25.156] iteration:12571  t-loss:0.0333, loss-lb:0.0233, loss-ulb:0.0050, weight:2.00, lr:0.0002
[01:58:25.531] iteration:12572  t-loss:0.0116, loss-lb:0.0093, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:58:25.905] iteration:12573  t-loss:0.0145, loss-lb:0.0129, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:58:26.279] iteration:12574  t-loss:0.0222, loss-lb:0.0204, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:58:26.651] iteration:12575  t-loss:0.0220, loss-lb:0.0174, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:58:27.019] iteration:12576  t-loss:0.0112, loss-lb:0.0088, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:58:27.408] iteration:12577  t-loss:0.0336, loss-lb:0.0117, loss-ulb:0.0109, weight:2.00, lr:0.0002
[01:58:27.797] iteration:12578  t-loss:0.0190, loss-lb:0.0110, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:58:29.099] iteration:12579  t-loss:0.0122, loss-lb:0.0105, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:58:29.494] iteration:12580  t-loss:0.0139, loss-lb:0.0122, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:58:29.871] iteration:12581  t-loss:0.0247, loss-lb:0.0202, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:58:30.250] iteration:12582  t-loss:0.0283, loss-lb:0.0255, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:58:30.626] iteration:12583  t-loss:0.0234, loss-lb:0.0209, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:58:31.007] iteration:12584  t-loss:0.0217, loss-lb:0.0138, loss-ulb:0.0040, weight:2.00, lr:0.0002
[01:58:31.383] iteration:12585  t-loss:0.0116, loss-lb:0.0098, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:58:31.759] iteration:12586  t-loss:0.0281, loss-lb:0.0259, loss-ulb:0.0011, weight:2.00, lr:0.0002
[01:58:32.143] iteration:12587  t-loss:0.0232, loss-lb:0.0203, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:58:32.522] iteration:12588  t-loss:0.0320, loss-lb:0.0289, loss-ulb:0.0016, weight:2.00, lr:0.0002
[01:58:32.898] iteration:12589  t-loss:0.0181, loss-lb:0.0141, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:58:33.276] iteration:12590  t-loss:0.0207, loss-lb:0.0182, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:58:33.657] iteration:12591  t-loss:0.0257, loss-lb:0.0155, loss-ulb:0.0051, weight:2.00, lr:0.0002
[01:58:34.040] iteration:12592  t-loss:0.0283, loss-lb:0.0237, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:58:34.428] iteration:12593  t-loss:0.0340, loss-lb:0.0241, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:58:34.806] iteration:12594  t-loss:0.0186, loss-lb:0.0172, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:58:35.186] iteration:12595  t-loss:0.0332, loss-lb:0.0244, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:58:35.567] iteration:12596  t-loss:0.0249, loss-lb:0.0105, loss-ulb:0.0072, weight:2.00, lr:0.0002
[01:58:35.941] iteration:12597  t-loss:0.0136, loss-lb:0.0112, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:58:36.316] iteration:12598  t-loss:0.0193, loss-lb:0.0119, loss-ulb:0.0037, weight:2.00, lr:0.0002
[01:58:36.690] iteration:12599  t-loss:0.0138, loss-lb:0.0123, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:58:37.070] iteration:12600  t-loss:0.0267, loss-lb:0.0168, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:58:37.453] iteration:12601  t-loss:0.0466, loss-lb:0.0326, loss-ulb:0.0070, weight:2.00, lr:0.0002
[01:58:37.831] iteration:12602  t-loss:0.0243, loss-lb:0.0118, loss-ulb:0.0062, weight:2.00, lr:0.0002
[01:58:38.208] iteration:12603  t-loss:0.0469, loss-lb:0.0381, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:58:38.585] iteration:12604  t-loss:0.0295, loss-lb:0.0197, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:58:38.969] iteration:12605  t-loss:0.0342, loss-lb:0.0287, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:58:39.355] iteration:12606  t-loss:0.0153, loss-lb:0.0091, loss-ulb:0.0031, weight:2.00, lr:0.0002
[01:58:39.734] iteration:12607  t-loss:0.0182, loss-lb:0.0166, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:58:40.115] iteration:12608  t-loss:0.0367, loss-lb:0.0286, loss-ulb:0.0041, weight:2.00, lr:0.0002
[01:58:40.490] iteration:12609  t-loss:0.0125, loss-lb:0.0099, loss-ulb:0.0013, weight:2.00, lr:0.0002
[01:58:40.854] iteration:12610  t-loss:0.0151, loss-lb:0.0112, loss-ulb:0.0020, weight:2.00, lr:0.0002
[01:58:41.227] iteration:12611  t-loss:0.0221, loss-lb:0.0191, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:58:41.603] iteration:12612  t-loss:0.0318, loss-lb:0.0188, loss-ulb:0.0065, weight:2.00, lr:0.0002
[01:58:41.978] iteration:12613  t-loss:0.0330, loss-lb:0.0173, loss-ulb:0.0078, weight:2.00, lr:0.0002
[01:58:42.349] iteration:12614  t-loss:0.0118, loss-lb:0.0104, loss-ulb:0.0007, weight:2.00, lr:0.0002
[01:58:42.729] iteration:12615  t-loss:0.0213, loss-lb:0.0113, loss-ulb:0.0050, weight:2.00, lr:0.0002
[01:58:43.112] iteration:12616  t-loss:0.0131, loss-lb:0.0113, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:58:44.477] iteration:12617  t-loss:0.0339, loss-lb:0.0211, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:58:44.890] iteration:12618  t-loss:0.0159, loss-lb:0.0113, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:58:45.288] iteration:12619  t-loss:0.0281, loss-lb:0.0194, loss-ulb:0.0044, weight:2.00, lr:0.0002
[01:58:45.668] iteration:12620  t-loss:0.0152, loss-lb:0.0104, loss-ulb:0.0024, weight:2.00, lr:0.0002
[01:58:46.049] iteration:12621  t-loss:0.0392, loss-lb:0.0263, loss-ulb:0.0064, weight:2.00, lr:0.0002
[01:58:46.432] iteration:12622  t-loss:0.0279, loss-lb:0.0179, loss-ulb:0.0050, weight:2.00, lr:0.0002
[01:58:46.822] iteration:12623  t-loss:0.0263, loss-lb:0.0111, loss-ulb:0.0076, weight:2.00, lr:0.0002
[01:58:47.204] iteration:12624  t-loss:0.0207, loss-lb:0.0171, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:58:47.586] iteration:12625  t-loss:0.0278, loss-lb:0.0168, loss-ulb:0.0055, weight:2.00, lr:0.0002
[01:58:47.964] iteration:12626  t-loss:0.0354, loss-lb:0.0290, loss-ulb:0.0032, weight:2.00, lr:0.0002
[01:58:48.344] iteration:12627  t-loss:0.0164, loss-lb:0.0128, loss-ulb:0.0018, weight:2.00, lr:0.0002
[01:58:48.730] iteration:12628  t-loss:0.0325, loss-lb:0.0254, loss-ulb:0.0036, weight:2.00, lr:0.0002
[01:58:49.109] iteration:12629  t-loss:0.0276, loss-lb:0.0252, loss-ulb:0.0012, weight:2.00, lr:0.0002
[01:58:49.492] iteration:12630  t-loss:0.0459, loss-lb:0.0239, loss-ulb:0.0110, weight:2.00, lr:0.0002
[01:58:49.868] iteration:12631  t-loss:0.0122, loss-lb:0.0088, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:58:50.247] iteration:12632  t-loss:0.0133, loss-lb:0.0103, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:58:50.623] iteration:12633  t-loss:0.0282, loss-lb:0.0247, loss-ulb:0.0017, weight:2.00, lr:0.0002
[01:58:51.007] iteration:12634  t-loss:0.0189, loss-lb:0.0112, loss-ulb:0.0038, weight:2.00, lr:0.0002
[01:58:51.382] iteration:12635  t-loss:0.0219, loss-lb:0.0116, loss-ulb:0.0052, weight:2.00, lr:0.0002
[01:58:51.758] iteration:12636  t-loss:0.0152, loss-lb:0.0122, loss-ulb:0.0015, weight:2.00, lr:0.0002
[01:58:52.133] iteration:12637  t-loss:0.0330, loss-lb:0.0302, loss-ulb:0.0014, weight:2.00, lr:0.0002
[01:58:52.518] iteration:12638  t-loss:0.0450, loss-lb:0.0268, loss-ulb:0.0091, weight:2.00, lr:0.0002
[01:58:52.906] iteration:12639  t-loss:0.0373, loss-lb:0.0183, loss-ulb:0.0095, weight:2.00, lr:0.0002
[01:58:53.291] iteration:12640  t-loss:0.0329, loss-lb:0.0232, loss-ulb:0.0049, weight:2.00, lr:0.0002
[01:58:53.667] iteration:12641  t-loss:0.0139, loss-lb:0.0094, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:58:54.050] iteration:12642  t-loss:0.0263, loss-lb:0.0120, loss-ulb:0.0072, weight:2.00, lr:0.0002
[01:58:54.450] iteration:12643  t-loss:0.0428, loss-lb:0.0308, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:58:54.840] iteration:12644  t-loss:0.0147, loss-lb:0.0131, loss-ulb:0.0008, weight:2.00, lr:0.0002
[01:58:55.231] iteration:12645  t-loss:0.0303, loss-lb:0.0130, loss-ulb:0.0087, weight:2.00, lr:0.0002
[01:58:55.613] iteration:12646  t-loss:0.0418, loss-lb:0.0115, loss-ulb:0.0151, weight:2.00, lr:0.0002
[01:58:55.987] iteration:12647  t-loss:0.0283, loss-lb:0.0228, loss-ulb:0.0027, weight:2.00, lr:0.0002
[01:58:56.363] iteration:12648  t-loss:0.0339, loss-lb:0.0219, loss-ulb:0.0060, weight:2.00, lr:0.0002
[01:58:56.737] iteration:12649  t-loss:0.0283, loss-lb:0.0236, loss-ulb:0.0023, weight:2.00, lr:0.0002
[01:58:57.113] iteration:12650  t-loss:0.0220, loss-lb:0.0202, loss-ulb:0.0009, weight:2.00, lr:0.0002
[01:58:57.488] iteration:12651  t-loss:0.0220, loss-lb:0.0121, loss-ulb:0.0050, weight:2.00, lr:0.0002
[01:58:57.864] iteration:12652  t-loss:0.0423, loss-lb:0.0183, loss-ulb:0.0120, weight:2.00, lr:0.0002
[01:58:58.246] iteration:12653  t-loss:0.0302, loss-lb:0.0165, loss-ulb:0.0068, weight:2.00, lr:0.0002
[01:58:58.620] iteration:12654  t-loss:0.0187, loss-lb:0.0117, loss-ulb:0.0035, weight:2.00, lr:0.0002
[02:00:04.620] iteration 12654 : dice_score: 0.904174 best_dice: 0.904200
[02:00:04.621]  <<Test>> - Ep:332  - Dice-S/T:90.35/90.42, Best-S:90.35, Best-T:90.42
[02:00:04.621]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[02:00:05.871] iteration:12655  t-loss:0.0256, loss-lb:0.0111, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:00:06.271] iteration:12656  t-loss:0.1217, loss-lb:0.1196, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:06.671] iteration:12657  t-loss:0.0247, loss-lb:0.0092, loss-ulb:0.0078, weight:2.00, lr:0.0002
[02:00:07.052] iteration:12658  t-loss:0.0254, loss-lb:0.0113, loss-ulb:0.0070, weight:2.00, lr:0.0002
[02:00:07.427] iteration:12659  t-loss:0.0161, loss-lb:0.0146, loss-ulb:0.0007, weight:2.00, lr:0.0002
[02:00:07.809] iteration:12660  t-loss:0.0432, loss-lb:0.0229, loss-ulb:0.0101, weight:2.00, lr:0.0002
[02:00:08.195] iteration:12661  t-loss:0.0180, loss-lb:0.0111, loss-ulb:0.0034, weight:2.00, lr:0.0002
[02:00:08.583] iteration:12662  t-loss:0.0193, loss-lb:0.0166, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:00:08.968] iteration:12663  t-loss:0.0250, loss-lb:0.0115, loss-ulb:0.0068, weight:2.00, lr:0.0002
[02:00:09.350] iteration:12664  t-loss:0.0190, loss-lb:0.0160, loss-ulb:0.0015, weight:2.00, lr:0.0002
[02:00:09.737] iteration:12665  t-loss:0.0239, loss-lb:0.0097, loss-ulb:0.0071, weight:2.00, lr:0.0002
[02:00:10.111] iteration:12666  t-loss:0.0154, loss-lb:0.0099, loss-ulb:0.0027, weight:2.00, lr:0.0002
[02:00:10.493] iteration:12667  t-loss:0.0281, loss-lb:0.0130, loss-ulb:0.0075, weight:2.00, lr:0.0002
[02:00:10.872] iteration:12668  t-loss:0.0140, loss-lb:0.0094, loss-ulb:0.0023, weight:2.00, lr:0.0002
[02:00:11.258] iteration:12669  t-loss:0.0339, loss-lb:0.0234, loss-ulb:0.0052, weight:2.00, lr:0.0002
[02:00:11.639] iteration:12670  t-loss:0.0151, loss-lb:0.0126, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:00:12.016] iteration:12671  t-loss:0.0153, loss-lb:0.0121, loss-ulb:0.0016, weight:2.00, lr:0.0002
[02:00:12.396] iteration:12672  t-loss:0.0272, loss-lb:0.0189, loss-ulb:0.0042, weight:2.00, lr:0.0002
[02:00:12.800] iteration:12673  t-loss:0.0212, loss-lb:0.0197, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:13.193] iteration:12674  t-loss:0.0263, loss-lb:0.0232, loss-ulb:0.0015, weight:2.00, lr:0.0002
[02:00:13.576] iteration:12675  t-loss:0.0127, loss-lb:0.0111, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:13.960] iteration:12676  t-loss:0.0173, loss-lb:0.0118, loss-ulb:0.0027, weight:2.00, lr:0.0002
[02:00:14.342] iteration:12677  t-loss:0.0275, loss-lb:0.0252, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:00:14.727] iteration:12678  t-loss:0.0168, loss-lb:0.0148, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:15.111] iteration:12679  t-loss:0.0439, loss-lb:0.0163, loss-ulb:0.0138, weight:2.00, lr:0.0002
[02:00:15.490] iteration:12680  t-loss:0.0230, loss-lb:0.0209, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:15.878] iteration:12681  t-loss:0.0614, loss-lb:0.0112, loss-ulb:0.0251, weight:2.00, lr:0.0002
[02:00:16.263] iteration:12682  t-loss:0.0127, loss-lb:0.0106, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:16.647] iteration:12683  t-loss:0.0362, loss-lb:0.0264, loss-ulb:0.0049, weight:2.00, lr:0.0002
[02:00:17.023] iteration:12684  t-loss:0.0142, loss-lb:0.0103, loss-ulb:0.0020, weight:2.00, lr:0.0002
[02:00:17.404] iteration:12685  t-loss:0.0386, loss-lb:0.0370, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:17.779] iteration:12686  t-loss:0.0254, loss-lb:0.0155, loss-ulb:0.0050, weight:2.00, lr:0.0002
[02:00:18.156] iteration:12687  t-loss:0.0206, loss-lb:0.0180, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:00:18.530] iteration:12688  t-loss:0.0229, loss-lb:0.0189, loss-ulb:0.0020, weight:2.00, lr:0.0002
[02:00:18.906] iteration:12689  t-loss:0.0321, loss-lb:0.0255, loss-ulb:0.0033, weight:2.00, lr:0.0002
[02:00:19.281] iteration:12690  t-loss:0.0354, loss-lb:0.0214, loss-ulb:0.0070, weight:2.00, lr:0.0002
[02:00:19.663] iteration:12691  t-loss:0.0286, loss-lb:0.0122, loss-ulb:0.0082, weight:2.00, lr:0.0002
[02:00:20.053] iteration:12692  t-loss:0.0346, loss-lb:0.0278, loss-ulb:0.0034, weight:2.00, lr:0.0002
[02:00:21.648] iteration:12693  t-loss:0.0218, loss-lb:0.0086, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:00:22.042] iteration:12694  t-loss:0.0160, loss-lb:0.0113, loss-ulb:0.0023, weight:2.00, lr:0.0002
[02:00:22.423] iteration:12695  t-loss:0.0258, loss-lb:0.0106, loss-ulb:0.0076, weight:2.00, lr:0.0002
[02:00:22.805] iteration:12696  t-loss:0.0274, loss-lb:0.0189, loss-ulb:0.0042, weight:2.00, lr:0.0002
[02:00:23.193] iteration:12697  t-loss:0.0250, loss-lb:0.0227, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:00:23.585] iteration:12698  t-loss:0.0241, loss-lb:0.0202, loss-ulb:0.0019, weight:2.00, lr:0.0002
[02:00:23.969] iteration:12699  t-loss:0.0250, loss-lb:0.0222, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:00:24.355] iteration:12700  t-loss:0.0671, loss-lb:0.0525, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:00:24.741] iteration:12701  t-loss:0.0258, loss-lb:0.0170, loss-ulb:0.0044, weight:2.00, lr:0.0002
[02:00:25.129] iteration:12702  t-loss:0.0302, loss-lb:0.0238, loss-ulb:0.0032, weight:2.00, lr:0.0002
[02:00:25.510] iteration:12703  t-loss:0.0231, loss-lb:0.0113, loss-ulb:0.0059, weight:2.00, lr:0.0002
[02:00:25.888] iteration:12704  t-loss:0.0226, loss-lb:0.0088, loss-ulb:0.0069, weight:2.00, lr:0.0002
[02:00:26.274] iteration:12705  t-loss:0.0285, loss-lb:0.0163, loss-ulb:0.0061, weight:2.00, lr:0.0002
[02:00:26.670] iteration:12706  t-loss:0.0352, loss-lb:0.0317, loss-ulb:0.0018, weight:2.00, lr:0.0002
[02:00:27.055] iteration:12707  t-loss:0.0195, loss-lb:0.0115, loss-ulb:0.0040, weight:2.00, lr:0.0002
[02:00:27.439] iteration:12708  t-loss:0.0194, loss-lb:0.0108, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:00:27.820] iteration:12709  t-loss:0.0307, loss-lb:0.0223, loss-ulb:0.0042, weight:2.00, lr:0.0002
[02:00:28.205] iteration:12710  t-loss:0.0286, loss-lb:0.0234, loss-ulb:0.0026, weight:2.00, lr:0.0002
[02:00:28.589] iteration:12711  t-loss:0.0447, loss-lb:0.0280, loss-ulb:0.0083, weight:2.00, lr:0.0002
[02:00:28.970] iteration:12712  t-loss:0.0287, loss-lb:0.0262, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:00:29.353] iteration:12713  t-loss:0.0303, loss-lb:0.0106, loss-ulb:0.0099, weight:2.00, lr:0.0002
[02:00:29.737] iteration:12714  t-loss:0.0205, loss-lb:0.0114, loss-ulb:0.0045, weight:2.00, lr:0.0002
[02:00:30.116] iteration:12715  t-loss:0.0209, loss-lb:0.0085, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:00:30.509] iteration:12716  t-loss:0.0366, loss-lb:0.0228, loss-ulb:0.0069, weight:2.00, lr:0.0002
[02:00:30.920] iteration:12717  t-loss:0.0301, loss-lb:0.0216, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:00:31.325] iteration:12718  t-loss:0.0416, loss-lb:0.0313, loss-ulb:0.0052, weight:2.00, lr:0.0002
[02:00:31.726] iteration:12719  t-loss:0.0221, loss-lb:0.0208, loss-ulb:0.0007, weight:2.00, lr:0.0002
[02:00:32.108] iteration:12720  t-loss:0.0403, loss-lb:0.0258, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:00:32.486] iteration:12721  t-loss:0.0282, loss-lb:0.0098, loss-ulb:0.0092, weight:2.00, lr:0.0002
[02:00:32.862] iteration:12722  t-loss:0.0170, loss-lb:0.0120, loss-ulb:0.0025, weight:2.00, lr:0.0002
[02:00:33.237] iteration:12723  t-loss:0.0341, loss-lb:0.0255, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:00:33.612] iteration:12724  t-loss:0.0286, loss-lb:0.0261, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:00:33.987] iteration:12725  t-loss:0.0207, loss-lb:0.0097, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:00:34.362] iteration:12726  t-loss:0.0216, loss-lb:0.0096, loss-ulb:0.0060, weight:2.00, lr:0.0002
[02:00:34.735] iteration:12727  t-loss:0.0150, loss-lb:0.0125, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:00:35.121] iteration:12728  t-loss:0.0388, loss-lb:0.0187, loss-ulb:0.0101, weight:2.00, lr:0.0002
[02:00:35.507] iteration:12729  t-loss:0.0194, loss-lb:0.0122, loss-ulb:0.0036, weight:2.00, lr:0.0002
[02:00:35.898] iteration:12730  t-loss:0.0293, loss-lb:0.0277, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:37.532] iteration:12731  t-loss:0.0270, loss-lb:0.0166, loss-ulb:0.0052, weight:2.00, lr:0.0002
[02:00:37.932] iteration:12732  t-loss:0.0397, loss-lb:0.0366, loss-ulb:0.0016, weight:2.00, lr:0.0002
[02:00:38.324] iteration:12733  t-loss:0.0217, loss-lb:0.0122, loss-ulb:0.0048, weight:2.00, lr:0.0002
[02:00:38.706] iteration:12734  t-loss:0.0200, loss-lb:0.0145, loss-ulb:0.0028, weight:2.00, lr:0.0002
[02:00:39.083] iteration:12735  t-loss:0.0172, loss-lb:0.0081, loss-ulb:0.0045, weight:2.00, lr:0.0002
[02:00:39.462] iteration:12736  t-loss:0.0216, loss-lb:0.0200, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:39.844] iteration:12737  t-loss:0.0455, loss-lb:0.0226, loss-ulb:0.0115, weight:2.00, lr:0.0002
[02:00:40.223] iteration:12738  t-loss:0.0154, loss-lb:0.0137, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:40.599] iteration:12739  t-loss:0.0128, loss-lb:0.0100, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:00:40.977] iteration:12740  t-loss:0.0205, loss-lb:0.0113, loss-ulb:0.0046, weight:2.00, lr:0.0002
[02:00:41.359] iteration:12741  t-loss:0.0276, loss-lb:0.0219, loss-ulb:0.0028, weight:2.00, lr:0.0002
[02:00:41.739] iteration:12742  t-loss:0.0218, loss-lb:0.0199, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:42.123] iteration:12743  t-loss:0.0547, loss-lb:0.0101, loss-ulb:0.0223, weight:2.00, lr:0.0002
[02:00:42.499] iteration:12744  t-loss:0.0461, loss-lb:0.0107, loss-ulb:0.0177, weight:2.00, lr:0.0002
[02:00:42.876] iteration:12745  t-loss:0.0265, loss-lb:0.0125, loss-ulb:0.0070, weight:2.00, lr:0.0002
[02:00:43.257] iteration:12746  t-loss:0.0319, loss-lb:0.0205, loss-ulb:0.0057, weight:2.00, lr:0.0002
[02:00:43.634] iteration:12747  t-loss:0.0137, loss-lb:0.0097, loss-ulb:0.0020, weight:2.00, lr:0.0002
[02:00:44.010] iteration:12748  t-loss:0.0311, loss-lb:0.0267, loss-ulb:0.0022, weight:2.00, lr:0.0002
[02:00:44.398] iteration:12749  t-loss:0.0420, loss-lb:0.0279, loss-ulb:0.0071, weight:2.00, lr:0.0002
[02:00:44.775] iteration:12750  t-loss:0.0228, loss-lb:0.0212, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:45.155] iteration:12751  t-loss:0.0351, loss-lb:0.0132, loss-ulb:0.0109, weight:2.00, lr:0.0002
[02:00:45.534] iteration:12752  t-loss:0.0911, loss-lb:0.0111, loss-ulb:0.0400, weight:2.00, lr:0.0002
[02:00:45.924] iteration:12753  t-loss:0.0179, loss-lb:0.0169, loss-ulb:0.0005, weight:2.00, lr:0.0002
[02:00:46.320] iteration:12754  t-loss:0.0295, loss-lb:0.0253, loss-ulb:0.0021, weight:2.00, lr:0.0002
[02:00:46.714] iteration:12755  t-loss:0.0129, loss-lb:0.0113, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:00:47.100] iteration:12756  t-loss:0.0940, loss-lb:0.0195, loss-ulb:0.0373, weight:2.00, lr:0.0002
[02:00:47.479] iteration:12757  t-loss:0.0248, loss-lb:0.0221, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:00:47.856] iteration:12758  t-loss:0.0310, loss-lb:0.0272, loss-ulb:0.0019, weight:2.00, lr:0.0002
[02:00:48.233] iteration:12759  t-loss:0.0203, loss-lb:0.0183, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:48.610] iteration:12760  t-loss:0.0280, loss-lb:0.0105, loss-ulb:0.0088, weight:2.00, lr:0.0002
[02:00:48.986] iteration:12761  t-loss:0.0241, loss-lb:0.0188, loss-ulb:0.0026, weight:2.00, lr:0.0002
[02:00:49.363] iteration:12762  t-loss:0.0171, loss-lb:0.0089, loss-ulb:0.0041, weight:2.00, lr:0.0002
[02:00:49.739] iteration:12763  t-loss:0.0401, loss-lb:0.0268, loss-ulb:0.0067, weight:2.00, lr:0.0002
[02:00:50.113] iteration:12764  t-loss:0.0184, loss-lb:0.0100, loss-ulb:0.0042, weight:2.00, lr:0.0002
[02:00:50.492] iteration:12765  t-loss:0.0250, loss-lb:0.0090, loss-ulb:0.0080, weight:2.00, lr:0.0002
[02:00:50.879] iteration:12766  t-loss:0.0131, loss-lb:0.0097, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:00:51.262] iteration:12767  t-loss:0.0257, loss-lb:0.0132, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:00:51.644] iteration:12768  t-loss:0.0297, loss-lb:0.0182, loss-ulb:0.0057, weight:2.00, lr:0.0002
[02:00:52.743] iteration:12769  t-loss:0.0312, loss-lb:0.0096, loss-ulb:0.0108, weight:2.00, lr:0.0002
[02:00:53.153] iteration:12770  t-loss:0.0389, loss-lb:0.0198, loss-ulb:0.0095, weight:2.00, lr:0.0002
[02:00:53.544] iteration:12771  t-loss:0.0420, loss-lb:0.0099, loss-ulb:0.0160, weight:2.00, lr:0.0002
[02:00:53.920] iteration:12772  t-loss:0.0908, loss-lb:0.0274, loss-ulb:0.0317, weight:2.00, lr:0.0002
[02:00:54.297] iteration:12773  t-loss:0.0193, loss-lb:0.0167, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:00:54.674] iteration:12774  t-loss:0.0252, loss-lb:0.0120, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:00:55.056] iteration:12775  t-loss:0.0201, loss-lb:0.0175, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:00:55.434] iteration:12776  t-loss:0.0232, loss-lb:0.0101, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:00:55.824] iteration:12777  t-loss:0.0247, loss-lb:0.0183, loss-ulb:0.0032, weight:2.00, lr:0.0002
[02:00:56.206] iteration:12778  t-loss:0.0208, loss-lb:0.0096, loss-ulb:0.0056, weight:2.00, lr:0.0002
[02:00:56.583] iteration:12779  t-loss:0.0130, loss-lb:0.0108, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:00:56.956] iteration:12780  t-loss:0.0130, loss-lb:0.0094, loss-ulb:0.0018, weight:2.00, lr:0.0002
[02:00:57.338] iteration:12781  t-loss:0.0131, loss-lb:0.0110, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:00:57.715] iteration:12782  t-loss:0.0324, loss-lb:0.0292, loss-ulb:0.0016, weight:2.00, lr:0.0002
[02:00:58.089] iteration:12783  t-loss:0.0128, loss-lb:0.0107, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:58.467] iteration:12784  t-loss:0.0270, loss-lb:0.0250, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:00:58.848] iteration:12785  t-loss:0.0343, loss-lb:0.0203, loss-ulb:0.0070, weight:2.00, lr:0.0002
[02:00:59.230] iteration:12786  t-loss:0.0523, loss-lb:0.0339, loss-ulb:0.0092, weight:2.00, lr:0.0002
[02:00:59.613] iteration:12787  t-loss:0.0164, loss-lb:0.0097, loss-ulb:0.0033, weight:2.00, lr:0.0002
[02:00:59.997] iteration:12788  t-loss:0.0370, loss-lb:0.0231, loss-ulb:0.0070, weight:2.00, lr:0.0002
[02:01:00.374] iteration:12789  t-loss:0.0322, loss-lb:0.0098, loss-ulb:0.0112, weight:2.00, lr:0.0002
[02:01:00.747] iteration:12790  t-loss:0.0149, loss-lb:0.0125, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:01:01.133] iteration:12791  t-loss:0.0309, loss-lb:0.0095, loss-ulb:0.0107, weight:2.00, lr:0.0002
[02:01:01.526] iteration:12792  t-loss:0.0131, loss-lb:0.0113, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:01:01.932] iteration:12793  t-loss:0.0307, loss-lb:0.0105, loss-ulb:0.0101, weight:2.00, lr:0.0002
[02:01:02.326] iteration:12794  t-loss:0.0103, loss-lb:0.0086, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:01:02.705] iteration:12795  t-loss:0.0258, loss-lb:0.0197, loss-ulb:0.0031, weight:2.00, lr:0.0002
[02:01:03.076] iteration:12796  t-loss:0.0094, loss-lb:0.0085, loss-ulb:0.0005, weight:2.00, lr:0.0002
[02:01:03.455] iteration:12797  t-loss:0.0628, loss-lb:0.0508, loss-ulb:0.0060, weight:2.00, lr:0.0002
[02:01:03.834] iteration:12798  t-loss:0.0244, loss-lb:0.0221, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:01:04.208] iteration:12799  t-loss:0.0169, loss-lb:0.0116, loss-ulb:0.0027, weight:2.00, lr:0.0002
[02:01:04.585] iteration:12800  t-loss:0.0287, loss-lb:0.0194, loss-ulb:0.0047, weight:2.00, lr:0.0002
[02:01:04.960] iteration:12801  t-loss:0.0220, loss-lb:0.0119, loss-ulb:0.0050, weight:2.00, lr:0.0002
[02:01:05.338] iteration:12802  t-loss:0.0442, loss-lb:0.0093, loss-ulb:0.0175, weight:2.00, lr:0.0002
[02:01:05.718] iteration:12803  t-loss:0.0363, loss-lb:0.0232, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:01:06.099] iteration:12804  t-loss:0.0289, loss-lb:0.0148, loss-ulb:0.0071, weight:2.00, lr:0.0002
[02:01:06.478] iteration:12805  t-loss:0.0237, loss-lb:0.0117, loss-ulb:0.0060, weight:2.00, lr:0.0002
[02:01:06.853] iteration:12806  t-loss:0.0206, loss-lb:0.0089, loss-ulb:0.0058, weight:2.00, lr:0.0002
[02:02:11.966] iteration 12806 : dice_score: 0.903939 best_dice: 0.904200
[02:02:11.967]  <<Test>> - Ep:336  - Dice-S/T:89.85/90.39, Best-S:90.35, Best-T:90.42
[02:02:11.967]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[02:02:13.071] iteration:12807  t-loss:0.0211, loss-lb:0.0101, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:02:13.479] iteration:12808  t-loss:0.0299, loss-lb:0.0205, loss-ulb:0.0047, weight:2.00, lr:0.0002
[02:02:13.866] iteration:12809  t-loss:0.0268, loss-lb:0.0208, loss-ulb:0.0030, weight:2.00, lr:0.0002
[02:02:14.257] iteration:12810  t-loss:0.0513, loss-lb:0.0185, loss-ulb:0.0164, weight:2.00, lr:0.0002
[02:02:14.642] iteration:12811  t-loss:0.0223, loss-lb:0.0200, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:02:15.024] iteration:12812  t-loss:0.0183, loss-lb:0.0106, loss-ulb:0.0039, weight:2.00, lr:0.0002
[02:02:15.400] iteration:12813  t-loss:0.0300, loss-lb:0.0106, loss-ulb:0.0097, weight:2.00, lr:0.0002
[02:02:15.781] iteration:12814  t-loss:0.0189, loss-lb:0.0094, loss-ulb:0.0047, weight:2.00, lr:0.0002
[02:02:16.164] iteration:12815  t-loss:0.0238, loss-lb:0.0214, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:02:16.550] iteration:12816  t-loss:0.0319, loss-lb:0.0264, loss-ulb:0.0027, weight:2.00, lr:0.0002
[02:02:16.939] iteration:12817  t-loss:0.0227, loss-lb:0.0123, loss-ulb:0.0052, weight:2.00, lr:0.0002
[02:02:17.323] iteration:12818  t-loss:0.0256, loss-lb:0.0239, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:02:17.711] iteration:12819  t-loss:0.0371, loss-lb:0.0278, loss-ulb:0.0046, weight:2.00, lr:0.0002
[02:02:18.091] iteration:12820  t-loss:0.0154, loss-lb:0.0116, loss-ulb:0.0019, weight:2.00, lr:0.0002
[02:02:18.470] iteration:12821  t-loss:0.0143, loss-lb:0.0132, loss-ulb:0.0006, weight:2.00, lr:0.0002
[02:02:18.854] iteration:12822  t-loss:0.0191, loss-lb:0.0095, loss-ulb:0.0048, weight:2.00, lr:0.0002
[02:02:19.237] iteration:12823  t-loss:0.0211, loss-lb:0.0143, loss-ulb:0.0034, weight:2.00, lr:0.0002
[02:02:19.623] iteration:12824  t-loss:0.0236, loss-lb:0.0178, loss-ulb:0.0029, weight:2.00, lr:0.0002
[02:02:20.034] iteration:12825  t-loss:0.0432, loss-lb:0.0242, loss-ulb:0.0095, weight:2.00, lr:0.0002
[02:02:20.446] iteration:12826  t-loss:0.0259, loss-lb:0.0095, loss-ulb:0.0082, weight:2.00, lr:0.0002
[02:02:20.841] iteration:12827  t-loss:0.0317, loss-lb:0.0271, loss-ulb:0.0023, weight:2.00, lr:0.0002
[02:02:21.225] iteration:12828  t-loss:0.0149, loss-lb:0.0115, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:02:21.624] iteration:12829  t-loss:0.0259, loss-lb:0.0163, loss-ulb:0.0048, weight:2.00, lr:0.0002
[02:02:22.016] iteration:12830  t-loss:0.0214, loss-lb:0.0108, loss-ulb:0.0053, weight:2.00, lr:0.0002
[02:02:22.402] iteration:12831  t-loss:0.0179, loss-lb:0.0103, loss-ulb:0.0038, weight:2.00, lr:0.0002
[02:02:22.791] iteration:12832  t-loss:0.0142, loss-lb:0.0115, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:02:23.174] iteration:12833  t-loss:0.0323, loss-lb:0.0148, loss-ulb:0.0088, weight:2.00, lr:0.0002
[02:02:23.549] iteration:12834  t-loss:0.0171, loss-lb:0.0093, loss-ulb:0.0039, weight:2.00, lr:0.0002
[02:02:23.938] iteration:12835  t-loss:0.0343, loss-lb:0.0205, loss-ulb:0.0069, weight:2.00, lr:0.0002
[02:02:24.314] iteration:12836  t-loss:0.0155, loss-lb:0.0106, loss-ulb:0.0024, weight:2.00, lr:0.0002
[02:02:24.690] iteration:12837  t-loss:0.0263, loss-lb:0.0077, loss-ulb:0.0093, weight:2.00, lr:0.0002
[02:02:25.061] iteration:12838  t-loss:0.0161, loss-lb:0.0141, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:02:25.437] iteration:12839  t-loss:0.0216, loss-lb:0.0120, loss-ulb:0.0048, weight:2.00, lr:0.0002
[02:02:25.816] iteration:12840  t-loss:0.0300, loss-lb:0.0169, loss-ulb:0.0065, weight:2.00, lr:0.0002
[02:02:26.188] iteration:12841  t-loss:0.0130, loss-lb:0.0110, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:02:26.579] iteration:12842  t-loss:0.0202, loss-lb:0.0192, loss-ulb:0.0005, weight:2.00, lr:0.0002
[02:02:26.973] iteration:12843  t-loss:0.0214, loss-lb:0.0104, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:02:27.353] iteration:12844  t-loss:0.0142, loss-lb:0.0112, loss-ulb:0.0015, weight:2.00, lr:0.0002
[02:02:28.742] iteration:12845  t-loss:0.0115, loss-lb:0.0100, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:02:29.135] iteration:12846  t-loss:0.0164, loss-lb:0.0116, loss-ulb:0.0024, weight:2.00, lr:0.0002
[02:02:29.524] iteration:12847  t-loss:0.0222, loss-lb:0.0196, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:02:29.915] iteration:12848  t-loss:0.0985, loss-lb:0.0554, loss-ulb:0.0216, weight:2.00, lr:0.0002
[02:02:30.301] iteration:12849  t-loss:0.0292, loss-lb:0.0168, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:02:30.685] iteration:12850  t-loss:0.0245, loss-lb:0.0128, loss-ulb:0.0059, weight:2.00, lr:0.0002
[02:02:31.071] iteration:12851  t-loss:0.0322, loss-lb:0.0136, loss-ulb:0.0093, weight:2.00, lr:0.0002
[02:02:31.452] iteration:12852  t-loss:0.0172, loss-lb:0.0093, loss-ulb:0.0039, weight:2.00, lr:0.0002
[02:02:31.830] iteration:12853  t-loss:0.0319, loss-lb:0.0141, loss-ulb:0.0089, weight:2.00, lr:0.0002
[02:02:32.208] iteration:12854  t-loss:0.0379, loss-lb:0.0352, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:02:32.594] iteration:12855  t-loss:0.0247, loss-lb:0.0216, loss-ulb:0.0015, weight:2.00, lr:0.0002
[02:02:32.976] iteration:12856  t-loss:0.0396, loss-lb:0.0376, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:02:33.359] iteration:12857  t-loss:0.0363, loss-lb:0.0229, loss-ulb:0.0067, weight:2.00, lr:0.0002
[02:02:33.752] iteration:12858  t-loss:0.0451, loss-lb:0.0291, loss-ulb:0.0080, weight:2.00, lr:0.0002
[02:02:34.134] iteration:12859  t-loss:0.0155, loss-lb:0.0126, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:02:34.519] iteration:12860  t-loss:0.0378, loss-lb:0.0258, loss-ulb:0.0060, weight:2.00, lr:0.0002
[02:02:34.906] iteration:12861  t-loss:0.0453, loss-lb:0.0198, loss-ulb:0.0127, weight:2.00, lr:0.0002
[02:02:35.297] iteration:12862  t-loss:0.0240, loss-lb:0.0219, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:02:35.686] iteration:12863  t-loss:0.0222, loss-lb:0.0160, loss-ulb:0.0031, weight:2.00, lr:0.0002
[02:02:36.068] iteration:12864  t-loss:0.0263, loss-lb:0.0115, loss-ulb:0.0074, weight:2.00, lr:0.0002
[02:02:36.446] iteration:12865  t-loss:0.0299, loss-lb:0.0259, loss-ulb:0.0020, weight:2.00, lr:0.0002
[02:02:36.827] iteration:12866  t-loss:0.0142, loss-lb:0.0112, loss-ulb:0.0015, weight:2.00, lr:0.0002
[02:02:37.223] iteration:12867  t-loss:0.0306, loss-lb:0.0126, loss-ulb:0.0090, weight:2.00, lr:0.0002
[02:02:37.633] iteration:12868  t-loss:0.0255, loss-lb:0.0125, loss-ulb:0.0065, weight:2.00, lr:0.0002
[02:02:38.045] iteration:12869  t-loss:0.0285, loss-lb:0.0177, loss-ulb:0.0054, weight:2.00, lr:0.0002
[02:02:38.450] iteration:12870  t-loss:0.0649, loss-lb:0.0535, loss-ulb:0.0057, weight:2.00, lr:0.0002
[02:02:38.837] iteration:12871  t-loss:0.0114, loss-lb:0.0096, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:02:39.217] iteration:12872  t-loss:0.0335, loss-lb:0.0210, loss-ulb:0.0063, weight:2.00, lr:0.0002
[02:02:39.590] iteration:12873  t-loss:0.0113, loss-lb:0.0100, loss-ulb:0.0007, weight:2.00, lr:0.0002
[02:02:39.969] iteration:12874  t-loss:0.0403, loss-lb:0.0237, loss-ulb:0.0083, weight:2.00, lr:0.0002
[02:02:40.345] iteration:12875  t-loss:0.0247, loss-lb:0.0100, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:02:40.723] iteration:12876  t-loss:0.0358, loss-lb:0.0234, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:02:41.097] iteration:12877  t-loss:0.0277, loss-lb:0.0112, loss-ulb:0.0082, weight:2.00, lr:0.0002
[02:02:41.469] iteration:12878  t-loss:0.0216, loss-lb:0.0181, loss-ulb:0.0018, weight:2.00, lr:0.0002
[02:02:41.847] iteration:12879  t-loss:0.0347, loss-lb:0.0219, loss-ulb:0.0064, weight:2.00, lr:0.0002
[02:02:42.240] iteration:12880  t-loss:0.0334, loss-lb:0.0135, loss-ulb:0.0099, weight:2.00, lr:0.0002
[02:02:42.631] iteration:12881  t-loss:0.0431, loss-lb:0.0255, loss-ulb:0.0088, weight:2.00, lr:0.0002
[02:02:43.012] iteration:12882  t-loss:0.0249, loss-lb:0.0225, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:02:44.225] iteration:12883  t-loss:0.0107, loss-lb:0.0094, loss-ulb:0.0006, weight:2.00, lr:0.0002
[02:02:44.647] iteration:12884  t-loss:0.0128, loss-lb:0.0101, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:02:45.036] iteration:12885  t-loss:0.0137, loss-lb:0.0106, loss-ulb:0.0015, weight:2.00, lr:0.0002
[02:02:45.418] iteration:12886  t-loss:0.0229, loss-lb:0.0171, loss-ulb:0.0029, weight:2.00, lr:0.0002
[02:02:45.798] iteration:12887  t-loss:0.0117, loss-lb:0.0088, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:02:46.175] iteration:12888  t-loss:0.0194, loss-lb:0.0149, loss-ulb:0.0022, weight:2.00, lr:0.0002
[02:02:46.552] iteration:12889  t-loss:0.0264, loss-lb:0.0084, loss-ulb:0.0090, weight:2.00, lr:0.0002
[02:02:46.934] iteration:12890  t-loss:0.0358, loss-lb:0.0271, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:02:47.317] iteration:12891  t-loss:0.0310, loss-lb:0.0232, loss-ulb:0.0039, weight:2.00, lr:0.0002
[02:02:47.694] iteration:12892  t-loss:0.0140, loss-lb:0.0107, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:02:48.076] iteration:12893  t-loss:0.0287, loss-lb:0.0173, loss-ulb:0.0057, weight:2.00, lr:0.0002
[02:02:48.450] iteration:12894  t-loss:0.0252, loss-lb:0.0106, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:02:48.830] iteration:12895  t-loss:0.0193, loss-lb:0.0102, loss-ulb:0.0045, weight:2.00, lr:0.0002
[02:02:49.209] iteration:12896  t-loss:0.0243, loss-lb:0.0227, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:02:49.588] iteration:12897  t-loss:0.0402, loss-lb:0.0168, loss-ulb:0.0117, weight:2.00, lr:0.0002
[02:02:49.963] iteration:12898  t-loss:0.0328, loss-lb:0.0250, loss-ulb:0.0039, weight:2.00, lr:0.0002
[02:02:50.339] iteration:12899  t-loss:0.0361, loss-lb:0.0326, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:02:50.722] iteration:12900  t-loss:0.0338, loss-lb:0.0214, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:02:51.105] iteration:12901  t-loss:0.0338, loss-lb:0.0207, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:02:51.490] iteration:12902  t-loss:0.0252, loss-lb:0.0230, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:02:51.871] iteration:12903  t-loss:0.0450, loss-lb:0.0337, loss-ulb:0.0056, weight:2.00, lr:0.0002
[02:02:52.249] iteration:12904  t-loss:0.0243, loss-lb:0.0207, loss-ulb:0.0018, weight:2.00, lr:0.0002
[02:02:52.636] iteration:12905  t-loss:0.0233, loss-lb:0.0125, loss-ulb:0.0054, weight:2.00, lr:0.0002
[02:02:53.048] iteration:12906  t-loss:0.0434, loss-lb:0.0205, loss-ulb:0.0114, weight:2.00, lr:0.0002
[02:02:53.450] iteration:12907  t-loss:0.0295, loss-lb:0.0116, loss-ulb:0.0089, weight:2.00, lr:0.0002
[02:02:53.842] iteration:12908  t-loss:0.0439, loss-lb:0.0115, loss-ulb:0.0162, weight:2.00, lr:0.0002
[02:02:54.221] iteration:12909  t-loss:0.0273, loss-lb:0.0256, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:02:54.594] iteration:12910  t-loss:0.0184, loss-lb:0.0083, loss-ulb:0.0051, weight:2.00, lr:0.0002
[02:02:54.975] iteration:12911  t-loss:0.0355, loss-lb:0.0302, loss-ulb:0.0026, weight:2.00, lr:0.0002
[02:02:55.346] iteration:12912  t-loss:0.0213, loss-lb:0.0095, loss-ulb:0.0059, weight:2.00, lr:0.0002
[02:02:55.722] iteration:12913  t-loss:0.0326, loss-lb:0.0181, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:02:56.092] iteration:12914  t-loss:0.0134, loss-lb:0.0116, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:02:56.465] iteration:12915  t-loss:0.0298, loss-lb:0.0264, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:02:56.842] iteration:12916  t-loss:0.0374, loss-lb:0.0223, loss-ulb:0.0075, weight:2.00, lr:0.0002
[02:02:57.217] iteration:12917  t-loss:0.0231, loss-lb:0.0104, loss-ulb:0.0064, weight:2.00, lr:0.0002
[02:02:57.599] iteration:12918  t-loss:0.0311, loss-lb:0.0220, loss-ulb:0.0046, weight:2.00, lr:0.0002
[02:02:57.985] iteration:12919  t-loss:0.0104, loss-lb:0.0086, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:02:58.364] iteration:12920  t-loss:0.0330, loss-lb:0.0200, loss-ulb:0.0065, weight:2.00, lr:0.0002
[02:02:59.460] iteration:12921  t-loss:0.0188, loss-lb:0.0082, loss-ulb:0.0053, weight:2.00, lr:0.0002
[02:02:59.871] iteration:12922  t-loss:0.0311, loss-lb:0.0296, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:03:00.263] iteration:12923  t-loss:0.0352, loss-lb:0.0329, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:03:00.641] iteration:12924  t-loss:0.0309, loss-lb:0.0128, loss-ulb:0.0091, weight:2.00, lr:0.0002
[02:03:01.027] iteration:12925  t-loss:0.0221, loss-lb:0.0205, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:03:01.412] iteration:12926  t-loss:0.0144, loss-lb:0.0126, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:03:01.794] iteration:12927  t-loss:0.0136, loss-lb:0.0106, loss-ulb:0.0015, weight:2.00, lr:0.0002
[02:03:02.174] iteration:12928  t-loss:0.0302, loss-lb:0.0167, loss-ulb:0.0067, weight:2.00, lr:0.0002
[02:03:02.547] iteration:12929  t-loss:0.0278, loss-lb:0.0097, loss-ulb:0.0091, weight:2.00, lr:0.0002
[02:03:02.931] iteration:12930  t-loss:0.0130, loss-lb:0.0111, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:03:03.314] iteration:12931  t-loss:0.0148, loss-lb:0.0111, loss-ulb:0.0019, weight:2.00, lr:0.0002
[02:03:03.687] iteration:12932  t-loss:0.0138, loss-lb:0.0120, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:03:04.063] iteration:12933  t-loss:0.0263, loss-lb:0.0107, loss-ulb:0.0078, weight:2.00, lr:0.0002
[02:03:04.443] iteration:12934  t-loss:0.0214, loss-lb:0.0089, loss-ulb:0.0063, weight:2.00, lr:0.0002
[02:03:04.822] iteration:12935  t-loss:0.0239, loss-lb:0.0113, loss-ulb:0.0063, weight:2.00, lr:0.0002
[02:03:05.196] iteration:12936  t-loss:0.0239, loss-lb:0.0213, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:03:05.569] iteration:12937  t-loss:0.0137, loss-lb:0.0114, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:03:05.947] iteration:12938  t-loss:0.0199, loss-lb:0.0113, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:03:06.338] iteration:12939  t-loss:0.0396, loss-lb:0.0229, loss-ulb:0.0083, weight:2.00, lr:0.0002
[02:03:06.711] iteration:12940  t-loss:0.0137, loss-lb:0.0114, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:03:07.087] iteration:12941  t-loss:0.0214, loss-lb:0.0179, loss-ulb:0.0018, weight:2.00, lr:0.0002
[02:03:07.462] iteration:12942  t-loss:0.0142, loss-lb:0.0103, loss-ulb:0.0019, weight:2.00, lr:0.0002
[02:03:07.848] iteration:12943  t-loss:0.0281, loss-lb:0.0222, loss-ulb:0.0030, weight:2.00, lr:0.0002
[02:03:08.251] iteration:12944  t-loss:0.0386, loss-lb:0.0098, loss-ulb:0.0144, weight:2.00, lr:0.0002
[02:03:08.648] iteration:12945  t-loss:0.0193, loss-lb:0.0107, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:03:09.047] iteration:12946  t-loss:0.0220, loss-lb:0.0196, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:03:09.440] iteration:12947  t-loss:0.0168, loss-lb:0.0087, loss-ulb:0.0041, weight:2.00, lr:0.0002
[02:03:09.827] iteration:12948  t-loss:0.0125, loss-lb:0.0104, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:03:10.217] iteration:12949  t-loss:0.0269, loss-lb:0.0187, loss-ulb:0.0041, weight:2.00, lr:0.0002
[02:03:10.595] iteration:12950  t-loss:0.0252, loss-lb:0.0239, loss-ulb:0.0006, weight:2.00, lr:0.0002
[02:03:10.967] iteration:12951  t-loss:0.0201, loss-lb:0.0091, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:03:11.341] iteration:12952  t-loss:0.0287, loss-lb:0.0262, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:03:11.718] iteration:12953  t-loss:0.0305, loss-lb:0.0197, loss-ulb:0.0054, weight:2.00, lr:0.0002
[02:03:12.090] iteration:12954  t-loss:0.0211, loss-lb:0.0183, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:03:12.466] iteration:12955  t-loss:0.0210, loss-lb:0.0089, loss-ulb:0.0060, weight:2.00, lr:0.0002
[02:03:12.847] iteration:12956  t-loss:0.0239, loss-lb:0.0133, loss-ulb:0.0053, weight:2.00, lr:0.0002
[02:03:13.226] iteration:12957  t-loss:0.0285, loss-lb:0.0101, loss-ulb:0.0092, weight:2.00, lr:0.0002
[02:03:13.607] iteration:12958  t-loss:0.0366, loss-lb:0.0202, loss-ulb:0.0082, weight:2.00, lr:0.0002
[02:04:15.423] iteration 12958 : dice_score: 0.903751 best_dice: 0.904200
[02:04:15.423]  <<Test>> - Ep:340  - Dice-S/T:90.05/90.38, Best-S:90.35, Best-T:90.42
[02:04:15.423]           - AvgLoss(lb/ulb/all):0.02/0.00/0.02
[02:04:16.534] iteration:12959  t-loss:0.0275, loss-lb:0.0094, loss-ulb:0.0091, weight:2.00, lr:0.0002
[02:04:16.952] iteration:12960  t-loss:0.0284, loss-lb:0.0113, loss-ulb:0.0086, weight:2.00, lr:0.0002
[02:04:17.346] iteration:12961  t-loss:0.0324, loss-lb:0.0167, loss-ulb:0.0078, weight:2.00, lr:0.0002
[02:04:17.740] iteration:12962  t-loss:0.0378, loss-lb:0.0258, loss-ulb:0.0060, weight:2.00, lr:0.0002
[02:04:18.128] iteration:12963  t-loss:0.0690, loss-lb:0.0112, loss-ulb:0.0289, weight:2.00, lr:0.0002
[02:04:18.508] iteration:12964  t-loss:0.0151, loss-lb:0.0106, loss-ulb:0.0023, weight:2.00, lr:0.0002
[02:04:18.887] iteration:12965  t-loss:0.0460, loss-lb:0.0178, loss-ulb:0.0141, weight:2.00, lr:0.0002
[02:04:19.265] iteration:12966  t-loss:0.0135, loss-lb:0.0118, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:04:19.649] iteration:12967  t-loss:0.0274, loss-lb:0.0251, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:04:20.027] iteration:12968  t-loss:0.0208, loss-lb:0.0179, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:04:20.404] iteration:12969  t-loss:0.0243, loss-lb:0.0215, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:04:20.784] iteration:12970  t-loss:0.0263, loss-lb:0.0246, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:04:21.176] iteration:12971  t-loss:0.0410, loss-lb:0.0246, loss-ulb:0.0082, weight:2.00, lr:0.0002
[02:04:21.562] iteration:12972  t-loss:0.0322, loss-lb:0.0166, loss-ulb:0.0078, weight:2.00, lr:0.0002
[02:04:21.942] iteration:12973  t-loss:0.0255, loss-lb:0.0228, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:04:22.313] iteration:12974  t-loss:0.0216, loss-lb:0.0098, loss-ulb:0.0059, weight:2.00, lr:0.0002
[02:04:22.690] iteration:12975  t-loss:0.0187, loss-lb:0.0167, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:04:23.071] iteration:12976  t-loss:0.0209, loss-lb:0.0127, loss-ulb:0.0041, weight:2.00, lr:0.0002
[02:04:23.450] iteration:12977  t-loss:0.0150, loss-lb:0.0119, loss-ulb:0.0016, weight:2.00, lr:0.0002
[02:04:23.831] iteration:12978  t-loss:0.0121, loss-lb:0.0084, loss-ulb:0.0018, weight:2.00, lr:0.0002
[02:04:24.210] iteration:12979  t-loss:0.0124, loss-lb:0.0092, loss-ulb:0.0016, weight:2.00, lr:0.0002
[02:04:24.596] iteration:12980  t-loss:0.0273, loss-lb:0.0094, loss-ulb:0.0089, weight:2.00, lr:0.0002
[02:04:24.976] iteration:12981  t-loss:0.0182, loss-lb:0.0158, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:04:25.363] iteration:12982  t-loss:0.0374, loss-lb:0.0281, loss-ulb:0.0046, weight:2.00, lr:0.0002
[02:04:25.764] iteration:12983  t-loss:0.0383, loss-lb:0.0265, loss-ulb:0.0059, weight:2.00, lr:0.0002
[02:04:26.142] iteration:12984  t-loss:0.0259, loss-lb:0.0203, loss-ulb:0.0028, weight:2.00, lr:0.0002
[02:04:26.524] iteration:12985  t-loss:0.0403, loss-lb:0.0257, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:04:26.907] iteration:12986  t-loss:0.0535, loss-lb:0.0114, loss-ulb:0.0210, weight:2.00, lr:0.0002
[02:04:27.300] iteration:12987  t-loss:0.0145, loss-lb:0.0123, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:04:27.690] iteration:12988  t-loss:0.0413, loss-lb:0.0280, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:04:28.078] iteration:12989  t-loss:0.0397, loss-lb:0.0221, loss-ulb:0.0088, weight:2.00, lr:0.0002
[02:04:28.457] iteration:12990  t-loss:0.0238, loss-lb:0.0115, loss-ulb:0.0061, weight:2.00, lr:0.0002
[02:04:28.846] iteration:12991  t-loss:0.0256, loss-lb:0.0204, loss-ulb:0.0026, weight:2.00, lr:0.0002
[02:04:29.228] iteration:12992  t-loss:0.0235, loss-lb:0.0105, loss-ulb:0.0065, weight:2.00, lr:0.0002
[02:04:29.619] iteration:12993  t-loss:0.0295, loss-lb:0.0153, loss-ulb:0.0071, weight:2.00, lr:0.0002
[02:04:30.000] iteration:12994  t-loss:0.0315, loss-lb:0.0157, loss-ulb:0.0079, weight:2.00, lr:0.0002
[02:04:30.377] iteration:12995  t-loss:0.0126, loss-lb:0.0108, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:04:30.753] iteration:12996  t-loss:0.0556, loss-lb:0.0169, loss-ulb:0.0194, weight:2.00, lr:0.0002
[02:04:32.138] iteration:12997  t-loss:0.0124, loss-lb:0.0101, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:04:32.564] iteration:12998  t-loss:0.0368, loss-lb:0.0280, loss-ulb:0.0044, weight:2.00, lr:0.0002
[02:04:32.986] iteration:12999  t-loss:0.0263, loss-lb:0.0151, loss-ulb:0.0056, weight:2.00, lr:0.0002
[02:04:33.398] iteration:13000  t-loss:0.0228, loss-lb:0.0097, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:04:33.786] iteration:13001  t-loss:0.0176, loss-lb:0.0086, loss-ulb:0.0045, weight:2.00, lr:0.0002
[02:04:34.175] iteration:13002  t-loss:0.0211, loss-lb:0.0091, loss-ulb:0.0060, weight:2.00, lr:0.0002
[02:04:34.554] iteration:13003  t-loss:0.0250, loss-lb:0.0233, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:04:34.937] iteration:13004  t-loss:0.0216, loss-lb:0.0091, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:04:35.324] iteration:13005  t-loss:0.0376, loss-lb:0.0099, loss-ulb:0.0138, weight:2.00, lr:0.0002
[02:04:35.707] iteration:13006  t-loss:0.0165, loss-lb:0.0114, loss-ulb:0.0025, weight:2.00, lr:0.0002
[02:04:36.089] iteration:13007  t-loss:0.0293, loss-lb:0.0265, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:04:36.468] iteration:13008  t-loss:0.0248, loss-lb:0.0087, loss-ulb:0.0081, weight:2.00, lr:0.0002
[02:04:36.855] iteration:13009  t-loss:0.0235, loss-lb:0.0111, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:04:37.238] iteration:13010  t-loss:0.0250, loss-lb:0.0230, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:04:37.621] iteration:13011  t-loss:0.0151, loss-lb:0.0095, loss-ulb:0.0028, weight:2.00, lr:0.0002
[02:04:38.010] iteration:13012  t-loss:0.0193, loss-lb:0.0176, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:04:38.391] iteration:13013  t-loss:0.0133, loss-lb:0.0116, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:04:38.775] iteration:13014  t-loss:0.0298, loss-lb:0.0212, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:04:39.153] iteration:13015  t-loss:0.0157, loss-lb:0.0132, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:04:39.542] iteration:13016  t-loss:0.0260, loss-lb:0.0237, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:04:39.927] iteration:13017  t-loss:0.0690, loss-lb:0.0198, loss-ulb:0.0246, weight:2.00, lr:0.0002
[02:04:40.309] iteration:13018  t-loss:0.0118, loss-lb:0.0092, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:04:40.684] iteration:13019  t-loss:0.0127, loss-lb:0.0110, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:04:41.065] iteration:13020  t-loss:0.0121, loss-lb:0.0105, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:04:41.444] iteration:13021  t-loss:0.0214, loss-lb:0.0191, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:04:41.830] iteration:13022  t-loss:0.0325, loss-lb:0.0204, loss-ulb:0.0061, weight:2.00, lr:0.0002
[02:04:42.211] iteration:13023  t-loss:0.0218, loss-lb:0.0096, loss-ulb:0.0061, weight:2.00, lr:0.0002
[02:04:42.594] iteration:13024  t-loss:0.0341, loss-lb:0.0255, loss-ulb:0.0043, weight:2.00, lr:0.0002
[02:04:42.975] iteration:13025  t-loss:0.0147, loss-lb:0.0112, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:04:43.354] iteration:13026  t-loss:0.0142, loss-lb:0.0121, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:04:43.727] iteration:13027  t-loss:0.0152, loss-lb:0.0094, loss-ulb:0.0029, weight:2.00, lr:0.0002
[02:04:44.109] iteration:13028  t-loss:0.0243, loss-lb:0.0098, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:04:44.489] iteration:13029  t-loss:0.0344, loss-lb:0.0254, loss-ulb:0.0045, weight:2.00, lr:0.0002
[02:04:44.870] iteration:13030  t-loss:0.0241, loss-lb:0.0183, loss-ulb:0.0029, weight:2.00, lr:0.0002
[02:04:45.246] iteration:13031  t-loss:0.0271, loss-lb:0.0222, loss-ulb:0.0025, weight:2.00, lr:0.0002
[02:04:45.626] iteration:13032  t-loss:0.0378, loss-lb:0.0173, loss-ulb:0.0103, weight:2.00, lr:0.0002
[02:04:46.015] iteration:13033  t-loss:0.0347, loss-lb:0.0232, loss-ulb:0.0057, weight:2.00, lr:0.0002
[02:04:46.396] iteration:13034  t-loss:0.0121, loss-lb:0.0094, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:04:47.566] iteration:13035  t-loss:0.0129, loss-lb:0.0113, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:04:47.956] iteration:13036  t-loss:0.0262, loss-lb:0.0212, loss-ulb:0.0025, weight:2.00, lr:0.0002
[02:04:48.348] iteration:13037  t-loss:0.0246, loss-lb:0.0229, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:04:48.735] iteration:13038  t-loss:0.0139, loss-lb:0.0108, loss-ulb:0.0016, weight:2.00, lr:0.0002
[02:04:49.139] iteration:13039  t-loss:0.0242, loss-lb:0.0097, loss-ulb:0.0072, weight:2.00, lr:0.0002
[02:04:49.533] iteration:13040  t-loss:0.0300, loss-lb:0.0225, loss-ulb:0.0037, weight:2.00, lr:0.0002
[02:04:49.921] iteration:13041  t-loss:0.0353, loss-lb:0.0192, loss-ulb:0.0081, weight:2.00, lr:0.0002
[02:04:50.303] iteration:13042  t-loss:0.0328, loss-lb:0.0126, loss-ulb:0.0101, weight:2.00, lr:0.0002
[02:04:50.683] iteration:13043  t-loss:0.0364, loss-lb:0.0172, loss-ulb:0.0096, weight:2.00, lr:0.0002
[02:04:51.061] iteration:13044  t-loss:0.0210, loss-lb:0.0188, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:04:51.440] iteration:13045  t-loss:0.0273, loss-lb:0.0232, loss-ulb:0.0021, weight:2.00, lr:0.0002
[02:04:51.824] iteration:13046  t-loss:0.0248, loss-lb:0.0103, loss-ulb:0.0073, weight:2.00, lr:0.0002
[02:04:52.202] iteration:13047  t-loss:0.0226, loss-lb:0.0113, loss-ulb:0.0056, weight:2.00, lr:0.0002
[02:04:52.580] iteration:13048  t-loss:0.0303, loss-lb:0.0214, loss-ulb:0.0044, weight:2.00, lr:0.0002
[02:04:52.960] iteration:13049  t-loss:0.0227, loss-lb:0.0102, loss-ulb:0.0063, weight:2.00, lr:0.0002
[02:04:53.336] iteration:13050  t-loss:0.0214, loss-lb:0.0194, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:04:53.716] iteration:13051  t-loss:0.0595, loss-lb:0.0480, loss-ulb:0.0057, weight:2.00, lr:0.0002
[02:04:54.091] iteration:13052  t-loss:0.0155, loss-lb:0.0133, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:04:54.479] iteration:13053  t-loss:0.0343, loss-lb:0.0173, loss-ulb:0.0085, weight:2.00, lr:0.0002
[02:04:54.864] iteration:13054  t-loss:0.0552, loss-lb:0.0470, loss-ulb:0.0041, weight:2.00, lr:0.0002
[02:04:55.245] iteration:13055  t-loss:0.0232, loss-lb:0.0110, loss-ulb:0.0061, weight:2.00, lr:0.0002
[02:04:55.629] iteration:13056  t-loss:0.0149, loss-lb:0.0136, loss-ulb:0.0007, weight:2.00, lr:0.0002
[02:04:56.016] iteration:13057  t-loss:0.0292, loss-lb:0.0221, loss-ulb:0.0035, weight:2.00, lr:0.0002
[02:04:56.402] iteration:13058  t-loss:0.0314, loss-lb:0.0190, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:04:56.788] iteration:13059  t-loss:0.0240, loss-lb:0.0162, loss-ulb:0.0039, weight:2.00, lr:0.0002
[02:04:57.177] iteration:13060  t-loss:0.0308, loss-lb:0.0164, loss-ulb:0.0072, weight:2.00, lr:0.0002
[02:04:57.559] iteration:13061  t-loss:0.0171, loss-lb:0.0149, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:04:57.935] iteration:13062  t-loss:0.0328, loss-lb:0.0309, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:04:58.311] iteration:13063  t-loss:0.0230, loss-lb:0.0100, loss-ulb:0.0065, weight:2.00, lr:0.0002
[02:04:58.688] iteration:13064  t-loss:0.0100, loss-lb:0.0087, loss-ulb:0.0006, weight:2.00, lr:0.0002
[02:04:59.063] iteration:13065  t-loss:0.0194, loss-lb:0.0182, loss-ulb:0.0006, weight:2.00, lr:0.0002
[02:04:59.436] iteration:13066  t-loss:0.0228, loss-lb:0.0208, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:04:59.813] iteration:13067  t-loss:0.0434, loss-lb:0.0182, loss-ulb:0.0126, weight:2.00, lr:0.0002
[02:05:00.185] iteration:13068  t-loss:0.0251, loss-lb:0.0104, loss-ulb:0.0074, weight:2.00, lr:0.0002
[02:05:00.561] iteration:13069  t-loss:0.0211, loss-lb:0.0102, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:05:00.942] iteration:13070  t-loss:0.0357, loss-lb:0.0213, loss-ulb:0.0072, weight:2.00, lr:0.0002
[02:05:01.312] iteration:13071  t-loss:0.0113, loss-lb:0.0093, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:05:01.685] iteration:13072  t-loss:0.0239, loss-lb:0.0187, loss-ulb:0.0026, weight:2.00, lr:0.0002
[02:05:02.804] iteration:13073  t-loss:0.0221, loss-lb:0.0090, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:05:03.190] iteration:13074  t-loss:0.0227, loss-lb:0.0131, loss-ulb:0.0048, weight:2.00, lr:0.0002
[02:05:03.574] iteration:13075  t-loss:0.0124, loss-lb:0.0103, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:05:03.958] iteration:13076  t-loss:0.0148, loss-lb:0.0083, loss-ulb:0.0032, weight:2.00, lr:0.0002
[02:05:04.354] iteration:13077  t-loss:0.0172, loss-lb:0.0129, loss-ulb:0.0021, weight:2.00, lr:0.0002
[02:05:04.736] iteration:13078  t-loss:0.0248, loss-lb:0.0197, loss-ulb:0.0025, weight:2.00, lr:0.0002
[02:05:05.116] iteration:13079  t-loss:0.0215, loss-lb:0.0115, loss-ulb:0.0050, weight:2.00, lr:0.0002
[02:05:05.492] iteration:13080  t-loss:0.0257, loss-lb:0.0168, loss-ulb:0.0044, weight:2.00, lr:0.0002
[02:05:05.879] iteration:13081  t-loss:0.0568, loss-lb:0.0314, loss-ulb:0.0127, weight:2.00, lr:0.0002
[02:05:06.260] iteration:13082  t-loss:0.0105, loss-lb:0.0085, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:05:06.637] iteration:13083  t-loss:0.0279, loss-lb:0.0259, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:05:07.012] iteration:13084  t-loss:0.0214, loss-lb:0.0118, loss-ulb:0.0048, weight:2.00, lr:0.0002
[02:05:07.399] iteration:13085  t-loss:0.0300, loss-lb:0.0252, loss-ulb:0.0024, weight:2.00, lr:0.0002
[02:05:07.778] iteration:13086  t-loss:0.0191, loss-lb:0.0099, loss-ulb:0.0046, weight:2.00, lr:0.0002
[02:05:08.154] iteration:13087  t-loss:0.0105, loss-lb:0.0079, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:05:08.526] iteration:13088  t-loss:0.0141, loss-lb:0.0120, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:05:08.916] iteration:13089  t-loss:0.0363, loss-lb:0.0211, loss-ulb:0.0076, weight:2.00, lr:0.0002
[02:05:09.290] iteration:13090  t-loss:0.0144, loss-lb:0.0099, loss-ulb:0.0023, weight:2.00, lr:0.0002
[02:05:09.673] iteration:13091  t-loss:0.0313, loss-lb:0.0181, loss-ulb:0.0066, weight:2.00, lr:0.0002
[02:05:10.054] iteration:13092  t-loss:0.0320, loss-lb:0.0153, loss-ulb:0.0083, weight:2.00, lr:0.0002
[02:05:10.437] iteration:13093  t-loss:0.0196, loss-lb:0.0182, loss-ulb:0.0007, weight:2.00, lr:0.0002
[02:05:10.816] iteration:13094  t-loss:0.0320, loss-lb:0.0105, loss-ulb:0.0108, weight:2.00, lr:0.0002
[02:05:11.194] iteration:13095  t-loss:0.0161, loss-lb:0.0097, loss-ulb:0.0032, weight:2.00, lr:0.0002
[02:05:11.574] iteration:13096  t-loss:0.0114, loss-lb:0.0098, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:05:11.957] iteration:13097  t-loss:0.0261, loss-lb:0.0244, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:05:12.341] iteration:13098  t-loss:0.0119, loss-lb:0.0090, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:05:12.718] iteration:13099  t-loss:0.0172, loss-lb:0.0153, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:05:13.097] iteration:13100  t-loss:0.0559, loss-lb:0.0400, loss-ulb:0.0079, weight:2.00, lr:0.0002
[02:05:13.476] iteration:13101  t-loss:0.0187, loss-lb:0.0162, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:05:13.858] iteration:13102  t-loss:0.0212, loss-lb:0.0087, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:05:14.231] iteration:13103  t-loss:0.0150, loss-lb:0.0094, loss-ulb:0.0028, weight:2.00, lr:0.0002
[02:05:14.609] iteration:13104  t-loss:0.0302, loss-lb:0.0191, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:05:14.987] iteration:13105  t-loss:0.0531, loss-lb:0.0317, loss-ulb:0.0107, weight:2.00, lr:0.0002
[02:05:15.367] iteration:13106  t-loss:0.0267, loss-lb:0.0168, loss-ulb:0.0050, weight:2.00, lr:0.0002
[02:05:15.742] iteration:13107  t-loss:0.0240, loss-lb:0.0205, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:05:16.130] iteration:13108  t-loss:0.0276, loss-lb:0.0195, loss-ulb:0.0041, weight:2.00, lr:0.0002
[02:05:16.516] iteration:13109  t-loss:0.0287, loss-lb:0.0089, loss-ulb:0.0099, weight:2.00, lr:0.0002
[02:05:16.898] iteration:13110  t-loss:0.0278, loss-lb:0.0201, loss-ulb:0.0038, weight:2.00, lr:0.0002
[02:06:21.366] iteration 13110 : dice_score: 0.894716 best_dice: 0.904200
[02:06:21.367]  <<Test>> - Ep:344  - Dice-S/T:89.54/89.47, Best-S:90.35, Best-T:90.42
[02:06:21.367]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[02:06:22.376] iteration:13111  t-loss:0.0106, loss-lb:0.0092, loss-ulb:0.0007, weight:2.00, lr:0.0002
[02:06:22.787] iteration:13112  t-loss:0.0216, loss-lb:0.0197, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:06:23.173] iteration:13113  t-loss:0.0347, loss-lb:0.0243, loss-ulb:0.0052, weight:2.00, lr:0.0002
[02:06:23.558] iteration:13114  t-loss:0.0288, loss-lb:0.0181, loss-ulb:0.0053, weight:2.00, lr:0.0002
[02:06:23.945] iteration:13115  t-loss:0.0172, loss-lb:0.0157, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:06:24.332] iteration:13116  t-loss:0.0120, loss-lb:0.0103, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:06:24.719] iteration:13117  t-loss:0.0324, loss-lb:0.0266, loss-ulb:0.0029, weight:2.00, lr:0.0002
[02:06:25.111] iteration:13118  t-loss:0.0221, loss-lb:0.0122, loss-ulb:0.0050, weight:2.00, lr:0.0002
[02:06:25.503] iteration:13119  t-loss:0.0599, loss-lb:0.0264, loss-ulb:0.0168, weight:2.00, lr:0.0002
[02:06:25.889] iteration:13120  t-loss:0.0317, loss-lb:0.0194, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:06:26.275] iteration:13121  t-loss:0.0314, loss-lb:0.0216, loss-ulb:0.0049, weight:2.00, lr:0.0002
[02:06:26.652] iteration:13122  t-loss:0.0557, loss-lb:0.0101, loss-ulb:0.0228, weight:2.00, lr:0.0002
[02:06:27.031] iteration:13123  t-loss:0.0133, loss-lb:0.0114, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:06:27.413] iteration:13124  t-loss:0.0307, loss-lb:0.0220, loss-ulb:0.0044, weight:2.00, lr:0.0002
[02:06:27.796] iteration:13125  t-loss:0.0227, loss-lb:0.0211, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:06:28.177] iteration:13126  t-loss:0.0321, loss-lb:0.0222, loss-ulb:0.0049, weight:2.00, lr:0.0002
[02:06:28.556] iteration:13127  t-loss:0.0234, loss-lb:0.0142, loss-ulb:0.0046, weight:2.00, lr:0.0002
[02:06:28.930] iteration:13128  t-loss:0.0199, loss-lb:0.0182, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:06:29.317] iteration:13129  t-loss:0.0429, loss-lb:0.0306, loss-ulb:0.0061, weight:2.00, lr:0.0002
[02:06:29.693] iteration:13130  t-loss:0.0210, loss-lb:0.0191, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:06:30.071] iteration:13131  t-loss:0.0131, loss-lb:0.0093, loss-ulb:0.0019, weight:2.00, lr:0.0002
[02:06:30.451] iteration:13132  t-loss:0.0202, loss-lb:0.0186, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:06:30.840] iteration:13133  t-loss:0.0295, loss-lb:0.0207, loss-ulb:0.0044, weight:2.00, lr:0.0002
[02:06:31.220] iteration:13134  t-loss:0.0355, loss-lb:0.0124, loss-ulb:0.0115, weight:2.00, lr:0.0002
[02:06:31.597] iteration:13135  t-loss:0.0138, loss-lb:0.0110, loss-ulb:0.0014, weight:2.00, lr:0.0002
[02:06:31.976] iteration:13136  t-loss:0.0450, loss-lb:0.0310, loss-ulb:0.0070, weight:2.00, lr:0.0002
[02:06:32.356] iteration:13137  t-loss:0.0398, loss-lb:0.0119, loss-ulb:0.0140, weight:2.00, lr:0.0002
[02:06:32.736] iteration:13138  t-loss:0.0413, loss-lb:0.0102, loss-ulb:0.0155, weight:2.00, lr:0.0002
[02:06:33.118] iteration:13139  t-loss:0.0216, loss-lb:0.0099, loss-ulb:0.0059, weight:2.00, lr:0.0002
[02:06:33.501] iteration:13140  t-loss:0.0244, loss-lb:0.0126, loss-ulb:0.0059, weight:2.00, lr:0.0002
[02:06:33.884] iteration:13141  t-loss:0.0294, loss-lb:0.0183, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:06:34.268] iteration:13142  t-loss:0.0174, loss-lb:0.0106, loss-ulb:0.0034, weight:2.00, lr:0.0002
[02:06:34.650] iteration:13143  t-loss:0.0261, loss-lb:0.0219, loss-ulb:0.0021, weight:2.00, lr:0.0002
[02:06:35.026] iteration:13144  t-loss:0.0208, loss-lb:0.0131, loss-ulb:0.0039, weight:2.00, lr:0.0002
[02:06:35.407] iteration:13145  t-loss:0.0364, loss-lb:0.0237, loss-ulb:0.0063, weight:2.00, lr:0.0002
[02:06:35.786] iteration:13146  t-loss:0.0239, loss-lb:0.0223, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:06:36.167] iteration:13147  t-loss:0.0242, loss-lb:0.0104, loss-ulb:0.0069, weight:2.00, lr:0.0002
[02:06:36.549] iteration:13148  t-loss:0.0317, loss-lb:0.0301, loss-ulb:0.0008, weight:2.00, lr:0.0002
[02:06:37.900] iteration:13149  t-loss:0.0273, loss-lb:0.0102, loss-ulb:0.0085, weight:2.00, lr:0.0002
[02:06:38.296] iteration:13150  t-loss:0.0347, loss-lb:0.0324, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:06:38.671] iteration:13151  t-loss:0.0153, loss-lb:0.0138, loss-ulb:0.0007, weight:2.00, lr:0.0002
[02:06:39.049] iteration:13152  t-loss:0.0198, loss-lb:0.0163, loss-ulb:0.0017, weight:2.00, lr:0.0002
[02:06:39.426] iteration:13153  t-loss:0.0120, loss-lb:0.0096, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:06:39.801] iteration:13154  t-loss:0.0139, loss-lb:0.0120, loss-ulb:0.0009, weight:2.00, lr:0.0002
[02:06:40.178] iteration:13155  t-loss:0.0254, loss-lb:0.0119, loss-ulb:0.0067, weight:2.00, lr:0.0002
[02:06:40.569] iteration:13156  t-loss:0.0398, loss-lb:0.0244, loss-ulb:0.0077, weight:2.00, lr:0.0002
[02:06:40.982] iteration:13157  t-loss:0.0316, loss-lb:0.0296, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:06:41.387] iteration:13158  t-loss:0.0186, loss-lb:0.0150, loss-ulb:0.0018, weight:2.00, lr:0.0002
[02:06:41.781] iteration:13159  t-loss:0.0487, loss-lb:0.0216, loss-ulb:0.0135, weight:2.00, lr:0.0002
[02:06:42.166] iteration:13160  t-loss:0.0263, loss-lb:0.0111, loss-ulb:0.0076, weight:2.00, lr:0.0002
[02:06:42.544] iteration:13161  t-loss:0.0190, loss-lb:0.0095, loss-ulb:0.0047, weight:2.00, lr:0.0002
[02:06:42.931] iteration:13162  t-loss:0.0367, loss-lb:0.0212, loss-ulb:0.0078, weight:2.00, lr:0.0002
[02:06:43.308] iteration:13163  t-loss:0.0190, loss-lb:0.0088, loss-ulb:0.0051, weight:2.00, lr:0.0002
[02:06:43.697] iteration:13164  t-loss:0.0205, loss-lb:0.0096, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:06:44.082] iteration:13165  t-loss:0.0196, loss-lb:0.0174, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:06:44.468] iteration:13166  t-loss:0.0143, loss-lb:0.0102, loss-ulb:0.0020, weight:2.00, lr:0.0002
[02:06:44.851] iteration:13167  t-loss:0.0198, loss-lb:0.0172, loss-ulb:0.0013, weight:2.00, lr:0.0002
[02:06:45.238] iteration:13168  t-loss:0.0198, loss-lb:0.0093, loss-ulb:0.0052, weight:2.00, lr:0.0002
[02:06:45.620] iteration:13169  t-loss:0.0244, loss-lb:0.0221, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:06:46.002] iteration:13170  t-loss:0.0250, loss-lb:0.0125, loss-ulb:0.0062, weight:2.00, lr:0.0002
[02:06:46.381] iteration:13171  t-loss:0.0256, loss-lb:0.0235, loss-ulb:0.0011, weight:2.00, lr:0.0002
[02:06:46.765] iteration:13172  t-loss:0.0355, loss-lb:0.0239, loss-ulb:0.0058, weight:2.00, lr:0.0002
[02:06:47.154] iteration:13173  t-loss:0.0304, loss-lb:0.0195, loss-ulb:0.0055, weight:2.00, lr:0.0002
[02:06:47.541] iteration:13174  t-loss:0.0280, loss-lb:0.0256, loss-ulb:0.0012, weight:2.00, lr:0.0002
[02:06:47.917] iteration:13175  t-loss:0.0113, loss-lb:0.0094, loss-ulb:0.0010, weight:2.00, lr:0.0002
[02:06:48.298] iteration:13176  t-loss:0.0542, loss-lb:0.0453, loss-ulb:0.0044, weight:2.00, lr:0.0002
[02:06:48.685] iteration:13177  t-loss:0.0346, loss-lb:0.0152, loss-ulb:0.0097, weight:2.00, lr:0.0002
[02:06:49.072] iteration:13178  t-loss:0.0288, loss-lb:0.0120, loss-ulb:0.0084, weight:2.00, lr:0.0002
[02:06:49.450] iteration:13179  t-loss:0.0234, loss-lb:0.0139, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:06:49.827] iteration:13180  t-loss:0.0262, loss-lb:0.0103, loss-ulb:0.0080, weight:2.00, lr:0.0001
[02:06:50.205] iteration:13181  t-loss:0.0244, loss-lb:0.0209, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:06:50.580] iteration:13182  t-loss:0.0211, loss-lb:0.0190, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:06:50.959] iteration:13183  t-loss:0.0215, loss-lb:0.0177, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:06:51.339] iteration:13184  t-loss:0.0252, loss-lb:0.0133, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:06:51.741] iteration:13185  t-loss:0.0164, loss-lb:0.0142, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:06:52.134] iteration:13186  t-loss:0.0115, loss-lb:0.0091, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:06:53.491] iteration:13187  t-loss:0.0537, loss-lb:0.0256, loss-ulb:0.0141, weight:2.00, lr:0.0001
[02:06:53.885] iteration:13188  t-loss:0.0191, loss-lb:0.0114, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:06:54.272] iteration:13189  t-loss:0.0239, loss-lb:0.0118, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:06:54.647] iteration:13190  t-loss:0.0252, loss-lb:0.0235, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:06:55.027] iteration:13191  t-loss:0.0122, loss-lb:0.0095, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:06:55.404] iteration:13192  t-loss:0.0127, loss-lb:0.0113, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:06:55.782] iteration:13193  t-loss:0.0421, loss-lb:0.0172, loss-ulb:0.0125, weight:2.00, lr:0.0001
[02:06:56.177] iteration:13194  t-loss:0.0394, loss-lb:0.0232, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:06:56.576] iteration:13195  t-loss:0.0138, loss-lb:0.0116, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:06:56.980] iteration:13196  t-loss:0.0278, loss-lb:0.0158, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:06:57.380] iteration:13197  t-loss:0.0180, loss-lb:0.0166, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:06:57.758] iteration:13198  t-loss:0.0172, loss-lb:0.0093, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:06:58.140] iteration:13199  t-loss:0.0282, loss-lb:0.0257, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:06:58.526] iteration:13200  t-loss:0.0134, loss-lb:0.0110, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:06:58.919] iteration:13201  t-loss:0.0307, loss-lb:0.0212, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:06:59.298] iteration:13202  t-loss:0.0277, loss-lb:0.0090, loss-ulb:0.0094, weight:2.00, lr:0.0001
[02:06:59.683] iteration:13203  t-loss:0.0245, loss-lb:0.0215, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:07:00.073] iteration:13204  t-loss:0.0310, loss-lb:0.0188, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:07:00.471] iteration:13205  t-loss:0.0345, loss-lb:0.0266, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:07:00.855] iteration:13206  t-loss:0.0190, loss-lb:0.0107, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:07:01.235] iteration:13207  t-loss:0.0132, loss-lb:0.0114, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:07:01.625] iteration:13208  t-loss:0.0278, loss-lb:0.0120, loss-ulb:0.0079, weight:2.00, lr:0.0001
[02:07:02.020] iteration:13209  t-loss:0.0288, loss-lb:0.0222, loss-ulb:0.0033, weight:2.00, lr:0.0001
[02:07:02.400] iteration:13210  t-loss:0.0250, loss-lb:0.0216, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:07:02.788] iteration:13211  t-loss:0.0338, loss-lb:0.0314, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:07:03.169] iteration:13212  t-loss:0.0161, loss-lb:0.0100, loss-ulb:0.0031, weight:2.00, lr:0.0001
[02:07:03.549] iteration:13213  t-loss:0.0195, loss-lb:0.0168, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:07:03.931] iteration:13214  t-loss:0.0290, loss-lb:0.0130, loss-ulb:0.0080, weight:2.00, lr:0.0001
[02:07:04.309] iteration:13215  t-loss:0.0241, loss-lb:0.0110, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:07:04.686] iteration:13216  t-loss:0.0313, loss-lb:0.0290, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:07:05.060] iteration:13217  t-loss:0.0252, loss-lb:0.0107, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:07:05.434] iteration:13218  t-loss:0.0247, loss-lb:0.0089, loss-ulb:0.0079, weight:2.00, lr:0.0001
[02:07:05.806] iteration:13219  t-loss:0.0116, loss-lb:0.0103, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:07:06.180] iteration:13220  t-loss:0.0265, loss-lb:0.0251, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:07:06.553] iteration:13221  t-loss:0.0183, loss-lb:0.0108, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:07:06.928] iteration:13222  t-loss:0.0286, loss-lb:0.0111, loss-ulb:0.0088, weight:2.00, lr:0.0001
[02:07:07.323] iteration:13223  t-loss:0.0377, loss-lb:0.0308, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:07:07.716] iteration:13224  t-loss:0.0202, loss-lb:0.0099, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:07:08.861] iteration:13225  t-loss:0.0133, loss-lb:0.0102, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:07:09.254] iteration:13226  t-loss:0.0298, loss-lb:0.0225, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:07:09.641] iteration:13227  t-loss:0.0286, loss-lb:0.0231, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:07:10.015] iteration:13228  t-loss:0.0110, loss-lb:0.0093, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:07:10.395] iteration:13229  t-loss:0.0332, loss-lb:0.0256, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:07:10.772] iteration:13230  t-loss:0.1283, loss-lb:0.1100, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:07:11.155] iteration:13231  t-loss:0.0410, loss-lb:0.0281, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:07:11.553] iteration:13232  t-loss:0.0300, loss-lb:0.0152, loss-ulb:0.0074, weight:2.00, lr:0.0001
[02:07:11.961] iteration:13233  t-loss:0.0199, loss-lb:0.0170, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:07:12.372] iteration:13234  t-loss:0.0272, loss-lb:0.0141, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:07:12.768] iteration:13235  t-loss:0.0208, loss-lb:0.0187, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:07:13.152] iteration:13236  t-loss:0.0185, loss-lb:0.0106, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:07:13.539] iteration:13237  t-loss:0.0110, loss-lb:0.0097, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:07:13.919] iteration:13238  t-loss:0.1233, loss-lb:0.1200, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:07:14.307] iteration:13239  t-loss:0.0363, loss-lb:0.0270, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:07:14.700] iteration:13240  t-loss:0.0213, loss-lb:0.0201, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:07:15.079] iteration:13241  t-loss:0.0229, loss-lb:0.0187, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:07:15.460] iteration:13242  t-loss:0.0142, loss-lb:0.0115, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:07:15.853] iteration:13243  t-loss:0.0250, loss-lb:0.0209, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:07:16.238] iteration:13244  t-loss:0.0247, loss-lb:0.0160, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:07:16.622] iteration:13245  t-loss:0.0280, loss-lb:0.0190, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:07:17.006] iteration:13246  t-loss:0.0285, loss-lb:0.0255, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:07:17.389] iteration:13247  t-loss:0.0224, loss-lb:0.0192, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:07:17.767] iteration:13248  t-loss:0.0113, loss-lb:0.0102, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:07:18.151] iteration:13249  t-loss:0.0382, loss-lb:0.0137, loss-ulb:0.0122, weight:2.00, lr:0.0001
[02:07:18.531] iteration:13250  t-loss:0.0323, loss-lb:0.0272, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:07:18.911] iteration:13251  t-loss:0.0181, loss-lb:0.0091, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:07:19.290] iteration:13252  t-loss:0.0304, loss-lb:0.0137, loss-ulb:0.0084, weight:2.00, lr:0.0001
[02:07:19.667] iteration:13253  t-loss:0.0217, loss-lb:0.0106, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:07:20.042] iteration:13254  t-loss:0.0164, loss-lb:0.0137, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:07:20.414] iteration:13255  t-loss:0.0233, loss-lb:0.0191, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:07:20.786] iteration:13256  t-loss:0.0190, loss-lb:0.0116, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:07:21.161] iteration:13257  t-loss:0.0374, loss-lb:0.0279, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:07:21.537] iteration:13258  t-loss:0.0307, loss-lb:0.0256, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:07:21.909] iteration:13259  t-loss:0.0192, loss-lb:0.0176, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:07:22.286] iteration:13260  t-loss:0.0129, loss-lb:0.0094, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:07:22.687] iteration:13261  t-loss:0.0187, loss-lb:0.0177, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:07:23.100] iteration:13262  t-loss:0.0287, loss-lb:0.0177, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:08:31.032] iteration 13262 : dice_score: 0.904161 best_dice: 0.904200
[02:08:31.033]  <<Test>> - Ep:348  - Dice-S/T:90.42/90.42, Best-S:90.42, Best-T:90.42
[02:08:31.033]           - AvgLoss(lb/ulb/all):0.02/0.00/0.02
[02:08:32.386] iteration:13263  t-loss:0.0176, loss-lb:0.0102, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:08:32.784] iteration:13264  t-loss:0.0121, loss-lb:0.0099, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:08:33.183] iteration:13265  t-loss:0.0269, loss-lb:0.0161, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:08:33.569] iteration:13266  t-loss:0.0368, loss-lb:0.0310, loss-ulb:0.0029, weight:2.00, lr:0.0001
[02:08:33.950] iteration:13267  t-loss:0.0245, loss-lb:0.0083, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:08:34.331] iteration:13268  t-loss:0.0175, loss-lb:0.0158, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:08:34.712] iteration:13269  t-loss:0.0145, loss-lb:0.0121, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:08:35.107] iteration:13270  t-loss:0.0266, loss-lb:0.0185, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:08:35.487] iteration:13271  t-loss:0.0219, loss-lb:0.0110, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:08:35.881] iteration:13272  t-loss:0.0229, loss-lb:0.0203, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:08:36.281] iteration:13273  t-loss:0.0108, loss-lb:0.0093, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:08:36.680] iteration:13274  t-loss:0.0242, loss-lb:0.0176, loss-ulb:0.0033, weight:2.00, lr:0.0001
[02:08:37.061] iteration:13275  t-loss:0.0124, loss-lb:0.0105, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:08:37.443] iteration:13276  t-loss:0.0278, loss-lb:0.0240, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:08:37.822] iteration:13277  t-loss:0.0237, loss-lb:0.0110, loss-ulb:0.0064, weight:2.00, lr:0.0001
[02:08:38.202] iteration:13278  t-loss:0.0376, loss-lb:0.0196, loss-ulb:0.0090, weight:2.00, lr:0.0001
[02:08:38.589] iteration:13279  t-loss:0.0321, loss-lb:0.0212, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:08:38.975] iteration:13280  t-loss:0.0157, loss-lb:0.0118, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:08:39.361] iteration:13281  t-loss:0.0263, loss-lb:0.0100, loss-ulb:0.0082, weight:2.00, lr:0.0001
[02:08:39.744] iteration:13282  t-loss:0.0154, loss-lb:0.0078, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:08:40.129] iteration:13283  t-loss:0.0312, loss-lb:0.0259, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:08:40.513] iteration:13284  t-loss:0.0369, loss-lb:0.0205, loss-ulb:0.0082, weight:2.00, lr:0.0001
[02:08:40.892] iteration:13285  t-loss:0.0143, loss-lb:0.0121, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:08:41.277] iteration:13286  t-loss:0.0190, loss-lb:0.0095, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:08:41.662] iteration:13287  t-loss:0.0318, loss-lb:0.0227, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:08:42.037] iteration:13288  t-loss:0.0257, loss-lb:0.0113, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:08:42.414] iteration:13289  t-loss:0.0249, loss-lb:0.0231, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:08:42.805] iteration:13290  t-loss:0.0124, loss-lb:0.0098, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:08:43.190] iteration:13291  t-loss:0.0386, loss-lb:0.0199, loss-ulb:0.0093, weight:2.00, lr:0.0001
[02:08:43.574] iteration:13292  t-loss:0.0345, loss-lb:0.0181, loss-ulb:0.0082, weight:2.00, lr:0.0001
[02:08:43.955] iteration:13293  t-loss:0.0431, loss-lb:0.0286, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:08:44.331] iteration:13294  t-loss:0.0217, loss-lb:0.0097, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:08:44.710] iteration:13295  t-loss:0.0537, loss-lb:0.0085, loss-ulb:0.0226, weight:2.00, lr:0.0001
[02:08:45.083] iteration:13296  t-loss:0.0141, loss-lb:0.0103, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:08:45.458] iteration:13297  t-loss:0.0291, loss-lb:0.0177, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:08:45.836] iteration:13298  t-loss:0.0247, loss-lb:0.0213, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:08:46.212] iteration:13299  t-loss:0.0274, loss-lb:0.0241, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:08:46.589] iteration:13300  t-loss:0.0277, loss-lb:0.0264, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:08:47.985] iteration:13301  t-loss:0.0287, loss-lb:0.0168, loss-ulb:0.0059, weight:2.00, lr:0.0001
[02:08:48.373] iteration:13302  t-loss:0.0437, loss-lb:0.0122, loss-ulb:0.0157, weight:2.00, lr:0.0001
[02:08:48.753] iteration:13303  t-loss:0.0322, loss-lb:0.0181, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:08:49.131] iteration:13304  t-loss:0.0140, loss-lb:0.0106, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:08:49.504] iteration:13305  t-loss:0.0223, loss-lb:0.0201, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:08:49.880] iteration:13306  t-loss:0.0171, loss-lb:0.0098, loss-ulb:0.0036, weight:2.00, lr:0.0001
[02:08:50.251] iteration:13307  t-loss:0.0572, loss-lb:0.0228, loss-ulb:0.0172, weight:2.00, lr:0.0001
[02:08:50.625] iteration:13308  t-loss:0.0105, loss-lb:0.0087, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:08:50.995] iteration:13309  t-loss:0.0130, loss-lb:0.0111, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:08:51.392] iteration:13310  t-loss:0.0311, loss-lb:0.0198, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:08:51.782] iteration:13311  t-loss:0.0204, loss-lb:0.0108, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:08:52.167] iteration:13312  t-loss:0.0147, loss-lb:0.0093, loss-ulb:0.0027, weight:2.00, lr:0.0001
[02:08:52.556] iteration:13313  t-loss:0.0336, loss-lb:0.0231, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:08:52.929] iteration:13314  t-loss:0.0123, loss-lb:0.0084, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:08:53.311] iteration:13315  t-loss:0.0229, loss-lb:0.0210, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:08:53.689] iteration:13316  t-loss:0.0164, loss-lb:0.0096, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:08:54.074] iteration:13317  t-loss:0.0396, loss-lb:0.0248, loss-ulb:0.0074, weight:2.00, lr:0.0001
[02:08:54.444] iteration:13318  t-loss:0.0129, loss-lb:0.0111, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:08:54.817] iteration:13319  t-loss:0.0134, loss-lb:0.0117, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:08:55.197] iteration:13320  t-loss:0.0232, loss-lb:0.0196, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:08:55.573] iteration:13321  t-loss:0.0123, loss-lb:0.0110, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:08:55.954] iteration:13322  t-loss:0.0247, loss-lb:0.0181, loss-ulb:0.0033, weight:2.00, lr:0.0001
[02:08:56.333] iteration:13323  t-loss:0.0280, loss-lb:0.0212, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:08:56.720] iteration:13324  t-loss:0.0204, loss-lb:0.0147, loss-ulb:0.0029, weight:2.00, lr:0.0001
[02:08:57.100] iteration:13325  t-loss:0.0204, loss-lb:0.0192, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:08:57.483] iteration:13326  t-loss:0.0407, loss-lb:0.0303, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:08:57.865] iteration:13327  t-loss:0.0276, loss-lb:0.0157, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:08:58.249] iteration:13328  t-loss:0.0225, loss-lb:0.0209, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:08:58.637] iteration:13329  t-loss:0.0253, loss-lb:0.0233, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:08:59.016] iteration:13330  t-loss:0.0256, loss-lb:0.0118, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:08:59.392] iteration:13331  t-loss:0.0380, loss-lb:0.0237, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:08:59.765] iteration:13332  t-loss:0.0477, loss-lb:0.0102, loss-ulb:0.0188, weight:2.00, lr:0.0001
[02:09:00.138] iteration:13333  t-loss:0.0319, loss-lb:0.0226, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:09:00.517] iteration:13334  t-loss:0.0126, loss-lb:0.0096, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:09:00.904] iteration:13335  t-loss:0.0208, loss-lb:0.0169, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:09:01.291] iteration:13336  t-loss:0.0243, loss-lb:0.0214, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:09:01.666] iteration:13337  t-loss:0.0212, loss-lb:0.0189, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:09:02.043] iteration:13338  t-loss:0.0224, loss-lb:0.0143, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:09:03.531] iteration:13339  t-loss:0.0272, loss-lb:0.0156, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:09:03.908] iteration:13340  t-loss:0.0142, loss-lb:0.0108, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:09:04.287] iteration:13341  t-loss:0.0226, loss-lb:0.0104, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:09:04.668] iteration:13342  t-loss:0.0173, loss-lb:0.0105, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:09:05.044] iteration:13343  t-loss:0.0107, loss-lb:0.0093, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:09:05.419] iteration:13344  t-loss:0.0235, loss-lb:0.0114, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:09:05.801] iteration:13345  t-loss:0.0343, loss-lb:0.0241, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:09:06.176] iteration:13346  t-loss:0.0540, loss-lb:0.0525, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:09:06.553] iteration:13347  t-loss:0.0149, loss-lb:0.0103, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:09:06.951] iteration:13348  t-loss:0.0310, loss-lb:0.0225, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:09:07.346] iteration:13349  t-loss:0.0151, loss-lb:0.0121, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:09:07.744] iteration:13350  t-loss:0.0253, loss-lb:0.0218, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:09:08.144] iteration:13351  t-loss:0.0233, loss-lb:0.0173, loss-ulb:0.0030, weight:2.00, lr:0.0001
[02:09:08.525] iteration:13352  t-loss:0.0199, loss-lb:0.0180, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:09:08.908] iteration:13353  t-loss:0.0227, loss-lb:0.0098, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:09:09.288] iteration:13354  t-loss:0.0224, loss-lb:0.0108, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:09:09.675] iteration:13355  t-loss:0.0223, loss-lb:0.0109, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:09:10.059] iteration:13356  t-loss:0.0225, loss-lb:0.0190, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:09:10.437] iteration:13357  t-loss:0.0182, loss-lb:0.0118, loss-ulb:0.0032, weight:2.00, lr:0.0001
[02:09:10.819] iteration:13358  t-loss:0.0195, loss-lb:0.0173, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:09:11.206] iteration:13359  t-loss:0.0536, loss-lb:0.0202, loss-ulb:0.0167, weight:2.00, lr:0.0001
[02:09:11.597] iteration:13360  t-loss:0.0325, loss-lb:0.0131, loss-ulb:0.0097, weight:2.00, lr:0.0001
[02:09:11.977] iteration:13361  t-loss:0.0171, loss-lb:0.0155, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:09:12.352] iteration:13362  t-loss:0.0108, loss-lb:0.0087, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:09:12.725] iteration:13363  t-loss:0.0148, loss-lb:0.0117, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:09:13.103] iteration:13364  t-loss:0.0122, loss-lb:0.0104, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:09:13.482] iteration:13365  t-loss:0.0363, loss-lb:0.0241, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:09:13.860] iteration:13366  t-loss:0.0220, loss-lb:0.0189, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:09:14.238] iteration:13367  t-loss:0.0329, loss-lb:0.0243, loss-ulb:0.0043, weight:2.00, lr:0.0001
[02:09:14.615] iteration:13368  t-loss:0.0188, loss-lb:0.0104, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:09:14.989] iteration:13369  t-loss:0.0196, loss-lb:0.0182, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:09:15.364] iteration:13370  t-loss:0.0293, loss-lb:0.0118, loss-ulb:0.0087, weight:2.00, lr:0.0001
[02:09:15.756] iteration:13371  t-loss:0.0163, loss-lb:0.0077, loss-ulb:0.0043, weight:2.00, lr:0.0001
[02:09:16.157] iteration:13372  t-loss:0.0325, loss-lb:0.0091, loss-ulb:0.0117, weight:2.00, lr:0.0001
[02:09:16.546] iteration:13373  t-loss:0.0137, loss-lb:0.0122, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:09:16.927] iteration:13374  t-loss:0.0204, loss-lb:0.0175, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:09:17.304] iteration:13375  t-loss:0.0278, loss-lb:0.0096, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:09:17.683] iteration:13376  t-loss:0.0210, loss-lb:0.0188, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:09:18.985] iteration:13377  t-loss:0.0184, loss-lb:0.0104, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:09:19.369] iteration:13378  t-loss:0.0243, loss-lb:0.0196, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:09:19.751] iteration:13379  t-loss:0.0247, loss-lb:0.0183, loss-ulb:0.0032, weight:2.00, lr:0.0001
[02:09:20.126] iteration:13380  t-loss:0.0469, loss-lb:0.0196, loss-ulb:0.0137, weight:2.00, lr:0.0001
[02:09:20.499] iteration:13381  t-loss:0.0224, loss-lb:0.0125, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:09:20.871] iteration:13382  t-loss:0.0274, loss-lb:0.0250, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:09:21.242] iteration:13383  t-loss:0.0265, loss-lb:0.0236, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:09:21.617] iteration:13384  t-loss:0.0255, loss-lb:0.0142, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:09:21.994] iteration:13385  t-loss:0.0215, loss-lb:0.0085, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:09:22.388] iteration:13386  t-loss:0.0353, loss-lb:0.0315, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:09:22.795] iteration:13387  t-loss:0.0162, loss-lb:0.0089, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:09:23.179] iteration:13388  t-loss:0.0143, loss-lb:0.0112, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:09:23.558] iteration:13389  t-loss:0.0312, loss-lb:0.0095, loss-ulb:0.0109, weight:2.00, lr:0.0001
[02:09:23.945] iteration:13390  t-loss:0.0316, loss-lb:0.0222, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:09:24.320] iteration:13391  t-loss:0.0120, loss-lb:0.0092, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:09:24.696] iteration:13392  t-loss:0.0181, loss-lb:0.0105, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:09:25.078] iteration:13393  t-loss:0.0259, loss-lb:0.0241, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:09:25.459] iteration:13394  t-loss:0.0403, loss-lb:0.0273, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:09:25.839] iteration:13395  t-loss:0.0230, loss-lb:0.0082, loss-ulb:0.0074, weight:2.00, lr:0.0001
[02:09:26.217] iteration:13396  t-loss:0.0148, loss-lb:0.0129, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:09:26.596] iteration:13397  t-loss:0.0370, loss-lb:0.0324, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:09:26.981] iteration:13398  t-loss:0.0168, loss-lb:0.0154, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:09:27.359] iteration:13399  t-loss:0.0125, loss-lb:0.0106, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:09:27.731] iteration:13400  t-loss:0.0119, loss-lb:0.0085, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:09:28.112] iteration:13401  t-loss:0.0436, loss-lb:0.0418, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:09:28.492] iteration:13402  t-loss:0.0255, loss-lb:0.0223, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:09:28.868] iteration:13403  t-loss:0.0182, loss-lb:0.0109, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:09:29.242] iteration:13404  t-loss:0.0272, loss-lb:0.0099, loss-ulb:0.0087, weight:2.00, lr:0.0001
[02:09:29.623] iteration:13405  t-loss:0.0334, loss-lb:0.0185, loss-ulb:0.0074, weight:2.00, lr:0.0001
[02:09:29.999] iteration:13406  t-loss:0.0258, loss-lb:0.0232, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:09:30.371] iteration:13407  t-loss:0.0119, loss-lb:0.0111, loss-ulb:0.0004, weight:2.00, lr:0.0001
[02:09:30.744] iteration:13408  t-loss:0.0125, loss-lb:0.0092, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:09:31.135] iteration:13409  t-loss:0.0470, loss-lb:0.0187, loss-ulb:0.0141, weight:2.00, lr:0.0001
[02:09:31.534] iteration:13410  t-loss:0.0301, loss-lb:0.0252, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:09:31.920] iteration:13411  t-loss:0.0248, loss-lb:0.0200, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:09:32.299] iteration:13412  t-loss:0.0132, loss-lb:0.0116, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:09:32.677] iteration:13413  t-loss:0.0362, loss-lb:0.0220, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:09:33.053] iteration:13414  t-loss:0.0104, loss-lb:0.0089, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:10:40.330] iteration 13414 : dice_score: 0.902737 best_dice: 0.904200
[02:10:40.331]  <<Test>> - Ep:352  - Dice-S/T:89.27/90.27, Best-S:90.42, Best-T:90.42
[02:10:40.331]           - AvgLoss(lb/ulb/all):0.02/0.00/0.02
[02:10:41.625] iteration:13415  t-loss:0.0272, loss-lb:0.0086, loss-ulb:0.0093, weight:2.00, lr:0.0001
[02:10:42.031] iteration:13416  t-loss:0.0182, loss-lb:0.0093, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:10:42.423] iteration:13417  t-loss:0.0181, loss-lb:0.0088, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:10:42.813] iteration:13418  t-loss:0.0290, loss-lb:0.0111, loss-ulb:0.0089, weight:2.00, lr:0.0001
[02:10:43.191] iteration:13419  t-loss:0.0170, loss-lb:0.0090, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:10:43.580] iteration:13420  t-loss:0.0288, loss-lb:0.0177, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:10:43.965] iteration:13421  t-loss:0.0677, loss-lb:0.0255, loss-ulb:0.0211, weight:2.00, lr:0.0001
[02:10:44.349] iteration:13422  t-loss:0.0210, loss-lb:0.0100, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:10:44.730] iteration:13423  t-loss:0.0199, loss-lb:0.0184, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:10:45.107] iteration:13424  t-loss:0.0139, loss-lb:0.0120, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:10:45.497] iteration:13425  t-loss:0.0389, loss-lb:0.0255, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:10:45.876] iteration:13426  t-loss:0.0132, loss-lb:0.0113, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:10:46.259] iteration:13427  t-loss:0.0353, loss-lb:0.0269, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:10:46.638] iteration:13428  t-loss:0.0208, loss-lb:0.0091, loss-ulb:0.0059, weight:2.00, lr:0.0001
[02:10:47.017] iteration:13429  t-loss:0.0216, loss-lb:0.0111, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:10:47.398] iteration:13430  t-loss:0.0274, loss-lb:0.0111, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:10:47.777] iteration:13431  t-loss:0.0214, loss-lb:0.0094, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:10:48.156] iteration:13432  t-loss:0.0127, loss-lb:0.0091, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:10:48.545] iteration:13433  t-loss:0.0272, loss-lb:0.0252, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:10:48.926] iteration:13434  t-loss:0.0186, loss-lb:0.0089, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:10:49.312] iteration:13435  t-loss:0.0270, loss-lb:0.0118, loss-ulb:0.0076, weight:2.00, lr:0.0001
[02:10:49.692] iteration:13436  t-loss:0.0219, loss-lb:0.0198, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:10:50.089] iteration:13437  t-loss:0.0300, loss-lb:0.0176, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:10:50.466] iteration:13438  t-loss:0.0275, loss-lb:0.0250, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:10:50.853] iteration:13439  t-loss:0.0356, loss-lb:0.0183, loss-ulb:0.0086, weight:2.00, lr:0.0001
[02:10:51.231] iteration:13440  t-loss:0.0251, loss-lb:0.0093, loss-ulb:0.0079, weight:2.00, lr:0.0001
[02:10:51.608] iteration:13441  t-loss:0.0095, loss-lb:0.0084, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:10:51.992] iteration:13442  t-loss:0.0217, loss-lb:0.0089, loss-ulb:0.0064, weight:2.00, lr:0.0001
[02:10:52.377] iteration:13443  t-loss:0.0524, loss-lb:0.0372, loss-ulb:0.0076, weight:2.00, lr:0.0001
[02:10:52.758] iteration:13444  t-loss:0.0346, loss-lb:0.0176, loss-ulb:0.0085, weight:2.00, lr:0.0001
[02:10:53.135] iteration:13445  t-loss:0.0248, loss-lb:0.0228, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:10:53.510] iteration:13446  t-loss:0.0292, loss-lb:0.0266, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:10:53.884] iteration:13447  t-loss:0.0340, loss-lb:0.0114, loss-ulb:0.0113, weight:2.00, lr:0.0001
[02:10:54.268] iteration:13448  t-loss:0.0222, loss-lb:0.0192, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:10:54.641] iteration:13449  t-loss:0.0151, loss-lb:0.0132, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:10:55.013] iteration:13450  t-loss:0.0115, loss-lb:0.0095, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:10:55.391] iteration:13451  t-loss:0.0234, loss-lb:0.0215, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:10:55.765] iteration:13452  t-loss:0.0213, loss-lb:0.0089, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:10:57.030] iteration:13453  t-loss:0.0233, loss-lb:0.0094, loss-ulb:0.0070, weight:2.00, lr:0.0001
[02:10:57.463] iteration:13454  t-loss:0.0158, loss-lb:0.0132, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:10:57.873] iteration:13455  t-loss:0.1231, loss-lb:0.1211, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:10:58.271] iteration:13456  t-loss:0.0198, loss-lb:0.0109, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:10:58.664] iteration:13457  t-loss:0.0149, loss-lb:0.0126, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:10:59.058] iteration:13458  t-loss:0.0216, loss-lb:0.0119, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:10:59.442] iteration:13459  t-loss:0.0216, loss-lb:0.0107, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:10:59.837] iteration:13460  t-loss:0.0281, loss-lb:0.0157, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:11:00.225] iteration:13461  t-loss:0.0182, loss-lb:0.0082, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:11:00.605] iteration:13462  t-loss:0.0167, loss-lb:0.0147, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:11:00.985] iteration:13463  t-loss:0.0295, loss-lb:0.0191, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:11:01.366] iteration:13464  t-loss:0.0211, loss-lb:0.0171, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:11:01.752] iteration:13465  t-loss:0.0480, loss-lb:0.0103, loss-ulb:0.0189, weight:2.00, lr:0.0001
[02:11:02.136] iteration:13466  t-loss:0.0186, loss-lb:0.0169, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:11:02.511] iteration:13467  t-loss:0.0217, loss-lb:0.0210, loss-ulb:0.0004, weight:2.00, lr:0.0001
[02:11:02.891] iteration:13468  t-loss:0.0223, loss-lb:0.0110, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:11:03.278] iteration:13469  t-loss:0.0243, loss-lb:0.0227, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:11:03.658] iteration:13470  t-loss:0.0188, loss-lb:0.0165, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:11:04.036] iteration:13471  t-loss:0.0206, loss-lb:0.0174, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:11:04.416] iteration:13472  t-loss:0.0195, loss-lb:0.0093, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:11:04.808] iteration:13473  t-loss:0.0217, loss-lb:0.0113, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:11:05.226] iteration:13474  t-loss:0.0304, loss-lb:0.0190, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:11:05.623] iteration:13475  t-loss:0.0347, loss-lb:0.0252, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:11:06.003] iteration:13476  t-loss:0.0214, loss-lb:0.0162, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:11:06.378] iteration:13477  t-loss:0.0125, loss-lb:0.0108, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:11:06.752] iteration:13478  t-loss:0.0145, loss-lb:0.0110, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:11:07.123] iteration:13479  t-loss:0.0419, loss-lb:0.0352, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:11:07.495] iteration:13480  t-loss:0.0329, loss-lb:0.0314, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:11:07.870] iteration:13481  t-loss:0.0263, loss-lb:0.0094, loss-ulb:0.0085, weight:2.00, lr:0.0001
[02:11:08.250] iteration:13482  t-loss:0.0380, loss-lb:0.0283, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:11:08.625] iteration:13483  t-loss:0.0344, loss-lb:0.0097, loss-ulb:0.0124, weight:2.00, lr:0.0001
[02:11:09.000] iteration:13484  t-loss:0.0141, loss-lb:0.0097, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:11:09.373] iteration:13485  t-loss:0.0223, loss-lb:0.0185, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:11:09.741] iteration:13486  t-loss:0.0208, loss-lb:0.0174, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:11:10.110] iteration:13487  t-loss:0.0341, loss-lb:0.0188, loss-ulb:0.0076, weight:2.00, lr:0.0001
[02:11:10.480] iteration:13488  t-loss:0.0260, loss-lb:0.0113, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:11:10.853] iteration:13489  t-loss:0.0366, loss-lb:0.0203, loss-ulb:0.0082, weight:2.00, lr:0.0001
[02:11:11.223] iteration:13490  t-loss:0.0201, loss-lb:0.0090, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:11:12.352] iteration:13491  t-loss:0.0118, loss-lb:0.0099, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:11:12.757] iteration:13492  t-loss:0.0267, loss-lb:0.0218, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:11:13.160] iteration:13493  t-loss:0.0200, loss-lb:0.0155, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:11:13.565] iteration:13494  t-loss:0.0194, loss-lb:0.0097, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:11:13.975] iteration:13495  t-loss:0.0472, loss-lb:0.0360, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:11:14.371] iteration:13496  t-loss:0.0309, loss-lb:0.0212, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:11:14.756] iteration:13497  t-loss:0.0440, loss-lb:0.0257, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:11:15.144] iteration:13498  t-loss:0.0237, loss-lb:0.0140, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:11:15.539] iteration:13499  t-loss:0.0218, loss-lb:0.0103, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:11:15.923] iteration:13500  t-loss:0.0237, loss-lb:0.0164, loss-ulb:0.0036, weight:2.00, lr:0.0001
[02:11:16.313] iteration:13501  t-loss:0.0398, loss-lb:0.0272, loss-ulb:0.0063, weight:2.00, lr:0.0001
[02:11:16.691] iteration:13502  t-loss:0.0235, loss-lb:0.0093, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:11:17.067] iteration:13503  t-loss:0.0122, loss-lb:0.0109, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:11:17.441] iteration:13504  t-loss:0.0148, loss-lb:0.0127, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:11:17.818] iteration:13505  t-loss:0.0373, loss-lb:0.0161, loss-ulb:0.0106, weight:2.00, lr:0.0001
[02:11:18.196] iteration:13506  t-loss:0.0271, loss-lb:0.0216, loss-ulb:0.0027, weight:2.00, lr:0.0001
[02:11:18.572] iteration:13507  t-loss:0.0102, loss-lb:0.0080, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:11:18.949] iteration:13508  t-loss:0.0353, loss-lb:0.0248, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:11:19.322] iteration:13509  t-loss:0.0439, loss-lb:0.0141, loss-ulb:0.0149, weight:2.00, lr:0.0001
[02:11:19.700] iteration:13510  t-loss:0.0339, loss-lb:0.0176, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:11:20.088] iteration:13511  t-loss:0.0271, loss-lb:0.0134, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:11:20.478] iteration:13512  t-loss:0.0189, loss-lb:0.0179, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:11:20.867] iteration:13513  t-loss:0.0208, loss-lb:0.0182, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:11:21.250] iteration:13514  t-loss:0.0172, loss-lb:0.0095, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:11:21.630] iteration:13515  t-loss:0.0095, loss-lb:0.0083, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:11:22.006] iteration:13516  t-loss:0.0495, loss-lb:0.0485, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:11:22.386] iteration:13517  t-loss:0.0271, loss-lb:0.0257, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:11:22.763] iteration:13518  t-loss:0.0253, loss-lb:0.0177, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:11:23.151] iteration:13519  t-loss:0.0089, loss-lb:0.0073, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:11:23.527] iteration:13520  t-loss:0.0284, loss-lb:0.0102, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:11:23.905] iteration:13521  t-loss:0.0219, loss-lb:0.0190, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:11:24.292] iteration:13522  t-loss:0.0227, loss-lb:0.0083, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:11:24.672] iteration:13523  t-loss:0.0158, loss-lb:0.0085, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:11:25.051] iteration:13524  t-loss:0.0174, loss-lb:0.0142, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:11:25.431] iteration:13525  t-loss:0.0288, loss-lb:0.0093, loss-ulb:0.0097, weight:2.00, lr:0.0001
[02:11:25.810] iteration:13526  t-loss:0.0626, loss-lb:0.0308, loss-ulb:0.0159, weight:2.00, lr:0.0001
[02:11:26.184] iteration:13527  t-loss:0.0150, loss-lb:0.0124, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:11:26.560] iteration:13528  t-loss:0.0177, loss-lb:0.0081, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:11:27.784] iteration:13529  t-loss:0.0174, loss-lb:0.0086, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:11:28.174] iteration:13530  t-loss:0.0260, loss-lb:0.0183, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:11:28.562] iteration:13531  t-loss:0.0246, loss-lb:0.0198, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:11:28.953] iteration:13532  t-loss:0.0155, loss-lb:0.0129, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:11:29.346] iteration:13533  t-loss:0.0243, loss-lb:0.0177, loss-ulb:0.0033, weight:2.00, lr:0.0001
[02:11:29.737] iteration:13534  t-loss:0.0294, loss-lb:0.0260, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:11:30.118] iteration:13535  t-loss:0.0242, loss-lb:0.0086, loss-ulb:0.0078, weight:2.00, lr:0.0001
[02:11:30.495] iteration:13536  t-loss:0.0174, loss-lb:0.0156, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:11:30.878] iteration:13537  t-loss:0.0231, loss-lb:0.0199, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:11:31.258] iteration:13538  t-loss:0.0179, loss-lb:0.0144, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:11:31.646] iteration:13539  t-loss:0.0290, loss-lb:0.0168, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:11:32.023] iteration:13540  t-loss:0.0166, loss-lb:0.0122, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:11:32.400] iteration:13541  t-loss:0.0450, loss-lb:0.0174, loss-ulb:0.0138, weight:2.00, lr:0.0001
[02:11:32.776] iteration:13542  t-loss:0.0194, loss-lb:0.0173, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:11:33.151] iteration:13543  t-loss:0.0179, loss-lb:0.0126, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:11:33.525] iteration:13544  t-loss:0.0237, loss-lb:0.0154, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:11:33.900] iteration:13545  t-loss:0.0112, loss-lb:0.0091, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:11:34.277] iteration:13546  t-loss:0.0095, loss-lb:0.0076, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:11:34.656] iteration:13547  t-loss:0.0259, loss-lb:0.0209, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:11:35.033] iteration:13548  t-loss:0.0240, loss-lb:0.0079, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:11:35.418] iteration:13549  t-loss:0.0434, loss-lb:0.0172, loss-ulb:0.0131, weight:2.00, lr:0.0001
[02:11:35.819] iteration:13550  t-loss:0.0123, loss-lb:0.0107, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:11:36.228] iteration:13551  t-loss:0.0243, loss-lb:0.0152, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:11:36.607] iteration:13552  t-loss:0.0187, loss-lb:0.0148, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:11:36.983] iteration:13553  t-loss:0.0202, loss-lb:0.0181, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:11:37.356] iteration:13554  t-loss:0.0119, loss-lb:0.0087, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:11:37.739] iteration:13555  t-loss:0.0346, loss-lb:0.0250, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:11:38.118] iteration:13556  t-loss:0.0285, loss-lb:0.0173, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:11:38.501] iteration:13557  t-loss:0.0205, loss-lb:0.0120, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:11:38.875] iteration:13558  t-loss:0.0194, loss-lb:0.0099, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:11:39.253] iteration:13559  t-loss:0.0117, loss-lb:0.0104, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:11:39.632] iteration:13560  t-loss:0.0673, loss-lb:0.0095, loss-ulb:0.0289, weight:2.00, lr:0.0001
[02:11:40.008] iteration:13561  t-loss:0.0139, loss-lb:0.0096, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:11:40.385] iteration:13562  t-loss:0.0127, loss-lb:0.0111, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:11:40.761] iteration:13563  t-loss:0.0177, loss-lb:0.0158, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:11:41.136] iteration:13564  t-loss:0.0206, loss-lb:0.0092, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:11:41.510] iteration:13565  t-loss:0.0256, loss-lb:0.0097, loss-ulb:0.0079, weight:2.00, lr:0.0001
[02:11:41.887] iteration:13566  t-loss:0.0372, loss-lb:0.0195, loss-ulb:0.0088, weight:2.00, lr:0.0001
[02:12:45.822] iteration 13566 : dice_score: 0.903138 best_dice: 0.904200
[02:12:45.822]  <<Test>> - Ep:356  - Dice-S/T:90.41/90.31, Best-S:90.42, Best-T:90.42
[02:12:45.822]           - AvgLoss(lb/ulb/all):0.01/0.01/0.02
[02:12:46.981] iteration:13567  t-loss:0.0284, loss-lb:0.0171, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:12:47.374] iteration:13568  t-loss:0.0475, loss-lb:0.0431, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:12:47.767] iteration:13569  t-loss:0.0362, loss-lb:0.0241, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:12:48.147] iteration:13570  t-loss:0.0103, loss-lb:0.0085, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:12:48.531] iteration:13571  t-loss:0.0129, loss-lb:0.0115, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:12:48.912] iteration:13572  t-loss:0.0346, loss-lb:0.0098, loss-ulb:0.0124, weight:2.00, lr:0.0001
[02:12:49.301] iteration:13573  t-loss:0.0223, loss-lb:0.0171, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:12:49.678] iteration:13574  t-loss:0.0125, loss-lb:0.0106, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:12:50.074] iteration:13575  t-loss:0.0186, loss-lb:0.0145, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:12:50.482] iteration:13576  t-loss:0.0198, loss-lb:0.0169, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:12:50.872] iteration:13577  t-loss:0.0342, loss-lb:0.0209, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:12:51.257] iteration:13578  t-loss:0.0177, loss-lb:0.0109, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:12:51.637] iteration:13579  t-loss:0.0304, loss-lb:0.0123, loss-ulb:0.0090, weight:2.00, lr:0.0001
[02:12:52.019] iteration:13580  t-loss:0.0263, loss-lb:0.0096, loss-ulb:0.0084, weight:2.00, lr:0.0001
[02:12:52.411] iteration:13581  t-loss:0.0187, loss-lb:0.0169, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:12:52.784] iteration:13582  t-loss:0.0243, loss-lb:0.0101, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:12:53.165] iteration:13583  t-loss:0.0468, loss-lb:0.0221, loss-ulb:0.0123, weight:2.00, lr:0.0001
[02:12:53.543] iteration:13584  t-loss:0.0178, loss-lb:0.0156, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:12:53.926] iteration:13585  t-loss:0.0330, loss-lb:0.0310, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:12:54.308] iteration:13586  t-loss:0.0163, loss-lb:0.0087, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:12:54.692] iteration:13587  t-loss:0.0257, loss-lb:0.0228, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:12:55.073] iteration:13588  t-loss:0.0340, loss-lb:0.0285, loss-ulb:0.0027, weight:2.00, lr:0.0001
[02:12:55.457] iteration:13589  t-loss:0.0211, loss-lb:0.0107, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:12:55.841] iteration:13590  t-loss:0.0674, loss-lb:0.0194, loss-ulb:0.0240, weight:2.00, lr:0.0001
[02:12:56.222] iteration:13591  t-loss:0.0156, loss-lb:0.0109, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:12:56.603] iteration:13592  t-loss:0.0142, loss-lb:0.0123, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:12:56.992] iteration:13593  t-loss:0.0413, loss-lb:0.0205, loss-ulb:0.0104, weight:2.00, lr:0.0001
[02:12:57.372] iteration:13594  t-loss:0.0202, loss-lb:0.0110, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:12:57.758] iteration:13595  t-loss:0.0342, loss-lb:0.0201, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:12:58.134] iteration:13596  t-loss:0.0107, loss-lb:0.0088, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:12:58.519] iteration:13597  t-loss:0.1319, loss-lb:0.1195, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:12:58.898] iteration:13598  t-loss:0.0169, loss-lb:0.0159, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:12:59.275] iteration:13599  t-loss:0.0300, loss-lb:0.0273, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:12:59.651] iteration:13600  t-loss:0.0260, loss-lb:0.0188, loss-ulb:0.0036, weight:2.00, lr:0.0001
[02:13:00.023] iteration:13601  t-loss:0.0376, loss-lb:0.0148, loss-ulb:0.0114, weight:2.00, lr:0.0001
[02:13:00.404] iteration:13602  t-loss:0.0350, loss-lb:0.0244, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:13:00.782] iteration:13603  t-loss:0.0116, loss-lb:0.0098, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:13:01.160] iteration:13604  t-loss:0.0126, loss-lb:0.0092, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:13:02.460] iteration:13605  t-loss:0.0322, loss-lb:0.0235, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:13:02.866] iteration:13606  t-loss:0.0173, loss-lb:0.0086, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:13:03.254] iteration:13607  t-loss:0.0284, loss-lb:0.0191, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:13:03.632] iteration:13608  t-loss:0.0283, loss-lb:0.0083, loss-ulb:0.0100, weight:2.00, lr:0.0001
[02:13:04.010] iteration:13609  t-loss:0.0399, loss-lb:0.0327, loss-ulb:0.0036, weight:2.00, lr:0.0001
[02:13:04.387] iteration:13610  t-loss:0.0174, loss-lb:0.0095, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:13:04.765] iteration:13611  t-loss:0.0708, loss-lb:0.0110, loss-ulb:0.0299, weight:2.00, lr:0.0001
[02:13:05.144] iteration:13612  t-loss:0.0127, loss-lb:0.0111, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:13:05.551] iteration:13613  t-loss:0.0410, loss-lb:0.0209, loss-ulb:0.0101, weight:2.00, lr:0.0001
[02:13:05.955] iteration:13614  t-loss:0.0233, loss-lb:0.0095, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:13:06.365] iteration:13615  t-loss:0.0338, loss-lb:0.0239, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:13:06.750] iteration:13616  t-loss:0.0140, loss-lb:0.0115, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:13:07.134] iteration:13617  t-loss:0.0578, loss-lb:0.0266, loss-ulb:0.0156, weight:2.00, lr:0.0001
[02:13:07.518] iteration:13618  t-loss:0.0835, loss-lb:0.0107, loss-ulb:0.0364, weight:2.00, lr:0.0001
[02:13:07.915] iteration:13619  t-loss:0.0206, loss-lb:0.0106, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:13:08.295] iteration:13620  t-loss:0.0132, loss-lb:0.0110, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:13:08.677] iteration:13621  t-loss:0.0387, loss-lb:0.0271, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:13:09.060] iteration:13622  t-loss:0.0205, loss-lb:0.0095, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:13:09.448] iteration:13623  t-loss:0.0206, loss-lb:0.0110, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:13:09.831] iteration:13624  t-loss:0.0410, loss-lb:0.0206, loss-ulb:0.0102, weight:2.00, lr:0.0001
[02:13:10.217] iteration:13625  t-loss:0.0260, loss-lb:0.0244, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:13:10.602] iteration:13626  t-loss:0.0349, loss-lb:0.0326, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:13:10.991] iteration:13627  t-loss:0.0316, loss-lb:0.0163, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:13:11.370] iteration:13628  t-loss:0.0206, loss-lb:0.0143, loss-ulb:0.0031, weight:2.00, lr:0.0001
[02:13:11.747] iteration:13629  t-loss:0.0221, loss-lb:0.0120, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:13:12.136] iteration:13630  t-loss:0.0210, loss-lb:0.0078, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:13:12.533] iteration:13631  t-loss:0.0426, loss-lb:0.0218, loss-ulb:0.0104, weight:2.00, lr:0.0001
[02:13:12.934] iteration:13632  t-loss:0.0212, loss-lb:0.0197, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:13:13.317] iteration:13633  t-loss:0.0262, loss-lb:0.0127, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:13:13.695] iteration:13634  t-loss:0.0106, loss-lb:0.0076, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:13:14.067] iteration:13635  t-loss:0.0165, loss-lb:0.0106, loss-ulb:0.0030, weight:2.00, lr:0.0001
[02:13:14.438] iteration:13636  t-loss:0.1160, loss-lb:0.1135, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:13:14.813] iteration:13637  t-loss:0.0120, loss-lb:0.0104, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:13:15.191] iteration:13638  t-loss:0.0277, loss-lb:0.0157, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:13:15.567] iteration:13639  t-loss:0.0240, loss-lb:0.0091, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:13:15.941] iteration:13640  t-loss:0.0232, loss-lb:0.0134, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:13:16.323] iteration:13641  t-loss:0.0339, loss-lb:0.0218, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:13:16.705] iteration:13642  t-loss:0.0235, loss-lb:0.0204, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:13:18.045] iteration:13643  t-loss:0.0215, loss-lb:0.0092, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:13:18.438] iteration:13644  t-loss:0.0698, loss-lb:0.0188, loss-ulb:0.0255, weight:2.00, lr:0.0001
[02:13:18.815] iteration:13645  t-loss:0.0232, loss-lb:0.0188, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:13:19.192] iteration:13646  t-loss:0.0260, loss-lb:0.0092, loss-ulb:0.0084, weight:2.00, lr:0.0001
[02:13:19.576] iteration:13647  t-loss:0.0193, loss-lb:0.0179, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:13:19.952] iteration:13648  t-loss:0.0100, loss-lb:0.0082, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:13:20.329] iteration:13649  t-loss:0.0217, loss-lb:0.0194, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:13:20.708] iteration:13650  t-loss:0.0239, loss-lb:0.0112, loss-ulb:0.0064, weight:2.00, lr:0.0001
[02:13:21.091] iteration:13651  t-loss:0.0150, loss-lb:0.0113, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:13:21.490] iteration:13652  t-loss:0.0112, loss-lb:0.0093, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:13:21.880] iteration:13653  t-loss:0.0166, loss-lb:0.0094, loss-ulb:0.0036, weight:2.00, lr:0.0001
[02:13:22.261] iteration:13654  t-loss:0.0144, loss-lb:0.0098, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:13:22.640] iteration:13655  t-loss:0.0328, loss-lb:0.0213, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:13:23.020] iteration:13656  t-loss:0.0150, loss-lb:0.0122, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:13:23.403] iteration:13657  t-loss:0.1151, loss-lb:0.1082, loss-ulb:0.0035, weight:2.00, lr:0.0001
[02:13:23.794] iteration:13658  t-loss:0.0196, loss-lb:0.0095, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:13:24.173] iteration:13659  t-loss:0.0283, loss-lb:0.0089, loss-ulb:0.0097, weight:2.00, lr:0.0001
[02:13:24.555] iteration:13660  t-loss:0.0237, loss-lb:0.0226, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:13:24.929] iteration:13661  t-loss:0.0230, loss-lb:0.0132, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:13:25.307] iteration:13662  t-loss:0.0306, loss-lb:0.0100, loss-ulb:0.0103, weight:2.00, lr:0.0001
[02:13:25.682] iteration:13663  t-loss:0.0130, loss-lb:0.0116, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:13:26.061] iteration:13664  t-loss:0.0241, loss-lb:0.0161, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:13:26.433] iteration:13665  t-loss:0.0148, loss-lb:0.0113, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:13:26.813] iteration:13666  t-loss:0.0272, loss-lb:0.0216, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:13:27.193] iteration:13667  t-loss:0.0324, loss-lb:0.0211, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:13:27.573] iteration:13668  t-loss:0.0363, loss-lb:0.0154, loss-ulb:0.0105, weight:2.00, lr:0.0001
[02:13:27.967] iteration:13669  t-loss:0.0117, loss-lb:0.0098, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:13:28.371] iteration:13670  t-loss:0.0142, loss-lb:0.0118, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:13:28.746] iteration:13671  t-loss:0.0237, loss-lb:0.0213, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:13:29.132] iteration:13672  t-loss:0.0351, loss-lb:0.0228, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:13:29.512] iteration:13673  t-loss:0.0425, loss-lb:0.0256, loss-ulb:0.0085, weight:2.00, lr:0.0001
[02:13:29.886] iteration:13674  t-loss:0.0194, loss-lb:0.0159, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:13:30.261] iteration:13675  t-loss:0.0267, loss-lb:0.0239, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:13:30.637] iteration:13676  t-loss:0.0761, loss-lb:0.0262, loss-ulb:0.0250, weight:2.00, lr:0.0001
[02:13:31.014] iteration:13677  t-loss:0.0337, loss-lb:0.0194, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:13:31.392] iteration:13678  t-loss:0.0232, loss-lb:0.0154, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:13:31.766] iteration:13679  t-loss:0.0288, loss-lb:0.0240, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:13:32.148] iteration:13680  t-loss:0.0308, loss-lb:0.0225, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:13:33.431] iteration:13681  t-loss:0.0592, loss-lb:0.0450, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:13:33.822] iteration:13682  t-loss:0.0347, loss-lb:0.0108, loss-ulb:0.0119, weight:2.00, lr:0.0001
[02:13:34.201] iteration:13683  t-loss:0.0890, loss-lb:0.0530, loss-ulb:0.0180, weight:2.00, lr:0.0001
[02:13:34.579] iteration:13684  t-loss:0.0215, loss-lb:0.0113, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:13:34.956] iteration:13685  t-loss:0.0247, loss-lb:0.0215, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:13:35.332] iteration:13686  t-loss:0.0267, loss-lb:0.0105, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:13:35.707] iteration:13687  t-loss:0.0234, loss-lb:0.0195, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:13:36.083] iteration:13688  t-loss:0.0240, loss-lb:0.0138, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:13:36.460] iteration:13689  t-loss:0.0199, loss-lb:0.0116, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:13:36.859] iteration:13690  t-loss:0.0193, loss-lb:0.0092, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:13:37.249] iteration:13691  t-loss:0.0303, loss-lb:0.0208, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:13:37.640] iteration:13692  t-loss:0.0168, loss-lb:0.0087, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:13:38.027] iteration:13693  t-loss:0.0129, loss-lb:0.0108, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:13:38.402] iteration:13694  t-loss:0.0121, loss-lb:0.0101, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:13:38.777] iteration:13695  t-loss:0.0822, loss-lb:0.0111, loss-ulb:0.0356, weight:2.00, lr:0.0001
[02:13:39.162] iteration:13696  t-loss:0.0377, loss-lb:0.0172, loss-ulb:0.0103, weight:2.00, lr:0.0001
[02:13:39.538] iteration:13697  t-loss:0.0122, loss-lb:0.0104, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:13:39.911] iteration:13698  t-loss:0.0143, loss-lb:0.0111, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:13:40.286] iteration:13699  t-loss:0.0117, loss-lb:0.0088, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:13:40.660] iteration:13700  t-loss:0.0244, loss-lb:0.0213, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:13:41.035] iteration:13701  t-loss:0.0187, loss-lb:0.0163, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:13:41.410] iteration:13702  t-loss:0.0098, loss-lb:0.0077, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:13:41.785] iteration:13703  t-loss:0.0181, loss-lb:0.0159, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:13:42.158] iteration:13704  t-loss:0.0145, loss-lb:0.0119, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:13:42.537] iteration:13705  t-loss:0.0245, loss-lb:0.0102, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:13:42.921] iteration:13706  t-loss:0.0266, loss-lb:0.0215, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:13:43.330] iteration:13707  t-loss:0.0233, loss-lb:0.0211, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:13:43.732] iteration:13708  t-loss:0.0206, loss-lb:0.0110, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:13:44.121] iteration:13709  t-loss:0.0208, loss-lb:0.0108, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:13:44.501] iteration:13710  t-loss:0.0296, loss-lb:0.0284, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:13:44.874] iteration:13711  t-loss:0.0115, loss-lb:0.0093, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:13:45.252] iteration:13712  t-loss:0.0207, loss-lb:0.0194, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:13:45.627] iteration:13713  t-loss:0.0257, loss-lb:0.0103, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:13:46.001] iteration:13714  t-loss:0.0263, loss-lb:0.0251, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:13:46.374] iteration:13715  t-loss:0.0153, loss-lb:0.0100, loss-ulb:0.0027, weight:2.00, lr:0.0001
[02:13:46.747] iteration:13716  t-loss:0.0106, loss-lb:0.0091, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:13:47.124] iteration:13717  t-loss:0.0202, loss-lb:0.0117, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:13:47.502] iteration:13718  t-loss:0.0310, loss-lb:0.0087, loss-ulb:0.0112, weight:2.00, lr:0.0001
[02:14:52.317] iteration 13718 : dice_score: 0.906042 best_dice: 0.906000
[02:14:52.317]  <<Test>> - Ep:360  - Dice-S/T:90.51/90.60, Best-S:90.51, Best-T:90.60
[02:14:52.317]           - AvgLoss(lb/ulb/all):0.02/0.00/0.02
[02:14:53.626] iteration:13719  t-loss:0.0148, loss-lb:0.0110, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:14:54.012] iteration:13720  t-loss:0.0355, loss-lb:0.0224, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:14:54.406] iteration:13721  t-loss:0.0200, loss-lb:0.0173, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:14:54.791] iteration:13722  t-loss:0.0200, loss-lb:0.0109, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:14:55.179] iteration:13723  t-loss:0.0269, loss-lb:0.0176, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:14:55.564] iteration:13724  t-loss:0.0189, loss-lb:0.0111, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:14:55.942] iteration:13725  t-loss:0.0125, loss-lb:0.0096, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:14:56.327] iteration:13726  t-loss:0.0196, loss-lb:0.0181, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:14:56.706] iteration:13727  t-loss:0.0222, loss-lb:0.0208, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:14:57.086] iteration:13728  t-loss:0.0249, loss-lb:0.0236, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:14:57.469] iteration:13729  t-loss:0.0155, loss-lb:0.0132, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:14:57.856] iteration:13730  t-loss:0.0329, loss-lb:0.0231, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:14:58.232] iteration:13731  t-loss:0.0100, loss-lb:0.0087, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:14:58.625] iteration:13732  t-loss:0.0324, loss-lb:0.0305, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:14:59.031] iteration:13733  t-loss:0.0123, loss-lb:0.0105, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:14:59.431] iteration:13734  t-loss:0.0474, loss-lb:0.0292, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:14:59.815] iteration:13735  t-loss:0.0291, loss-lb:0.0248, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:15:00.197] iteration:13736  t-loss:0.0224, loss-lb:0.0113, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:15:00.582] iteration:13737  t-loss:0.0101, loss-lb:0.0086, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:00.966] iteration:13738  t-loss:0.0217, loss-lb:0.0203, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:15:01.344] iteration:13739  t-loss:0.0406, loss-lb:0.0118, loss-ulb:0.0144, weight:2.00, lr:0.0001
[02:15:01.722] iteration:13740  t-loss:0.0278, loss-lb:0.0208, loss-ulb:0.0035, weight:2.00, lr:0.0001
[02:15:02.106] iteration:13741  t-loss:0.0402, loss-lb:0.0164, loss-ulb:0.0119, weight:2.00, lr:0.0001
[02:15:02.497] iteration:13742  t-loss:0.0384, loss-lb:0.0274, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:15:02.879] iteration:13743  t-loss:0.0154, loss-lb:0.0091, loss-ulb:0.0031, weight:2.00, lr:0.0001
[02:15:03.265] iteration:13744  t-loss:0.0234, loss-lb:0.0168, loss-ulb:0.0033, weight:2.00, lr:0.0001
[02:15:03.650] iteration:13745  t-loss:0.0216, loss-lb:0.0175, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:15:04.031] iteration:13746  t-loss:0.0251, loss-lb:0.0102, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:15:04.411] iteration:13747  t-loss:0.0281, loss-lb:0.0124, loss-ulb:0.0078, weight:2.00, lr:0.0001
[02:15:04.800] iteration:13748  t-loss:0.0310, loss-lb:0.0209, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:15:05.182] iteration:13749  t-loss:0.0432, loss-lb:0.0356, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:15:05.566] iteration:13750  t-loss:0.0295, loss-lb:0.0265, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:15:05.946] iteration:13751  t-loss:0.0255, loss-lb:0.0110, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:15:06.327] iteration:13752  t-loss:0.0277, loss-lb:0.0157, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:15:06.705] iteration:13753  t-loss:0.0174, loss-lb:0.0084, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:15:07.081] iteration:13754  t-loss:0.0145, loss-lb:0.0124, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:15:07.458] iteration:13755  t-loss:0.0459, loss-lb:0.0235, loss-ulb:0.0112, weight:2.00, lr:0.0001
[02:15:07.834] iteration:13756  t-loss:0.0180, loss-lb:0.0152, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:15:09.525] iteration:13757  t-loss:0.0242, loss-lb:0.0089, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:15:09.922] iteration:13758  t-loss:0.0327, loss-lb:0.0203, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:15:10.305] iteration:13759  t-loss:0.0315, loss-lb:0.0291, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:15:10.693] iteration:13760  t-loss:0.0330, loss-lb:0.0198, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:15:11.073] iteration:13761  t-loss:0.0122, loss-lb:0.0098, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:15:11.451] iteration:13762  t-loss:0.0225, loss-lb:0.0110, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:15:11.832] iteration:13763  t-loss:0.0124, loss-lb:0.0110, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:15:12.213] iteration:13764  t-loss:0.0313, loss-lb:0.0232, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:15:12.593] iteration:13765  t-loss:0.0235, loss-lb:0.0219, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:12.975] iteration:13766  t-loss:0.0360, loss-lb:0.0250, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:15:13.351] iteration:13767  t-loss:0.0194, loss-lb:0.0148, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:15:13.737] iteration:13768  t-loss:0.0312, loss-lb:0.0236, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:15:14.164] iteration:13769  t-loss:0.0368, loss-lb:0.0227, loss-ulb:0.0070, weight:2.00, lr:0.0001
[02:15:14.581] iteration:13770  t-loss:0.0261, loss-lb:0.0140, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:15:14.986] iteration:13771  t-loss:0.0285, loss-lb:0.0166, loss-ulb:0.0059, weight:2.00, lr:0.0001
[02:15:15.366] iteration:13772  t-loss:0.0340, loss-lb:0.0116, loss-ulb:0.0112, weight:2.00, lr:0.0001
[02:15:15.754] iteration:13773  t-loss:0.0433, loss-lb:0.0129, loss-ulb:0.0152, weight:2.00, lr:0.0001
[02:15:16.142] iteration:13774  t-loss:0.0315, loss-lb:0.0292, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:15:16.524] iteration:13775  t-loss:0.0128, loss-lb:0.0113, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:15:16.907] iteration:13776  t-loss:0.0298, loss-lb:0.0116, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:15:17.292] iteration:13777  t-loss:0.0301, loss-lb:0.0165, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:15:17.674] iteration:13778  t-loss:0.0268, loss-lb:0.0218, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:15:18.057] iteration:13779  t-loss:0.0116, loss-lb:0.0098, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:15:18.442] iteration:13780  t-loss:0.0258, loss-lb:0.0168, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:15:18.831] iteration:13781  t-loss:0.0280, loss-lb:0.0270, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:15:19.249] iteration:13782  t-loss:0.0283, loss-lb:0.0195, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:15:19.674] iteration:13783  t-loss:0.0357, loss-lb:0.0224, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:15:20.084] iteration:13784  t-loss:0.0197, loss-lb:0.0084, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:15:20.477] iteration:13785  t-loss:0.0151, loss-lb:0.0105, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:15:20.859] iteration:13786  t-loss:0.0145, loss-lb:0.0107, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:15:21.240] iteration:13787  t-loss:0.0290, loss-lb:0.0265, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:15:21.616] iteration:13788  t-loss:0.0203, loss-lb:0.0112, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:15:21.991] iteration:13789  t-loss:0.0154, loss-lb:0.0086, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:15:22.366] iteration:13790  t-loss:0.0481, loss-lb:0.0366, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:15:22.744] iteration:13791  t-loss:0.0316, loss-lb:0.0219, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:15:23.123] iteration:13792  t-loss:0.0309, loss-lb:0.0165, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:15:23.498] iteration:13793  t-loss:0.0119, loss-lb:0.0103, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:23.877] iteration:13794  t-loss:0.0325, loss-lb:0.0206, loss-ulb:0.0059, weight:2.00, lr:0.0001
[02:15:25.161] iteration:13795  t-loss:0.0378, loss-lb:0.0245, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:15:25.575] iteration:13796  t-loss:0.0164, loss-lb:0.0152, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:15:25.969] iteration:13797  t-loss:0.0605, loss-lb:0.0246, loss-ulb:0.0179, weight:2.00, lr:0.0001
[02:15:26.350] iteration:13798  t-loss:0.0287, loss-lb:0.0182, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:15:26.727] iteration:13799  t-loss:0.0410, loss-lb:0.0256, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:15:27.101] iteration:13800  t-loss:0.0113, loss-lb:0.0082, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:15:27.476] iteration:13801  t-loss:0.0118, loss-lb:0.0088, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:15:27.852] iteration:13802  t-loss:0.0164, loss-lb:0.0140, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:15:28.223] iteration:13803  t-loss:0.0147, loss-lb:0.0108, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:15:28.599] iteration:13804  t-loss:0.0217, loss-lb:0.0188, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:15:28.978] iteration:13805  t-loss:0.0112, loss-lb:0.0078, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:15:29.367] iteration:13806  t-loss:0.0196, loss-lb:0.0087, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:15:29.764] iteration:13807  t-loss:0.0374, loss-lb:0.0250, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:15:30.184] iteration:13808  t-loss:0.0216, loss-lb:0.0120, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:15:30.582] iteration:13809  t-loss:0.0320, loss-lb:0.0140, loss-ulb:0.0090, weight:2.00, lr:0.0001
[02:15:30.965] iteration:13810  t-loss:0.0175, loss-lb:0.0086, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:15:31.346] iteration:13811  t-loss:0.0311, loss-lb:0.0261, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:15:31.723] iteration:13812  t-loss:0.0269, loss-lb:0.0250, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:15:32.098] iteration:13813  t-loss:0.0122, loss-lb:0.0105, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:32.474] iteration:13814  t-loss:0.0274, loss-lb:0.0212, loss-ulb:0.0031, weight:2.00, lr:0.0001
[02:15:32.852] iteration:13815  t-loss:0.0251, loss-lb:0.0182, loss-ulb:0.0035, weight:2.00, lr:0.0001
[02:15:33.229] iteration:13816  t-loss:0.0102, loss-lb:0.0082, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:15:33.609] iteration:13817  t-loss:0.0368, loss-lb:0.0166, loss-ulb:0.0101, weight:2.00, lr:0.0001
[02:15:33.989] iteration:13818  t-loss:0.0227, loss-lb:0.0203, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:15:34.380] iteration:13819  t-loss:0.0291, loss-lb:0.0181, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:15:34.776] iteration:13820  t-loss:0.0248, loss-lb:0.0154, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:15:35.184] iteration:13821  t-loss:0.0217, loss-lb:0.0097, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:15:35.573] iteration:13822  t-loss:0.0292, loss-lb:0.0138, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:15:35.952] iteration:13823  t-loss:0.0147, loss-lb:0.0128, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:15:36.331] iteration:13824  t-loss:0.0177, loss-lb:0.0158, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:15:36.709] iteration:13825  t-loss:0.0356, loss-lb:0.0180, loss-ulb:0.0088, weight:2.00, lr:0.0001
[02:15:37.089] iteration:13826  t-loss:0.0227, loss-lb:0.0204, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:15:37.464] iteration:13827  t-loss:0.0212, loss-lb:0.0189, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:15:37.839] iteration:13828  t-loss:0.0288, loss-lb:0.0261, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:15:38.212] iteration:13829  t-loss:0.0167, loss-lb:0.0083, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:15:38.590] iteration:13830  t-loss:0.0288, loss-lb:0.0268, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:15:38.965] iteration:13831  t-loss:0.0108, loss-lb:0.0093, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:39.343] iteration:13832  t-loss:0.0222, loss-lb:0.0112, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:15:40.553] iteration:13833  t-loss:0.0126, loss-lb:0.0110, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:40.951] iteration:13834  t-loss:0.0276, loss-lb:0.0264, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:15:41.345] iteration:13835  t-loss:0.0286, loss-lb:0.0211, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:15:41.722] iteration:13836  t-loss:0.0123, loss-lb:0.0107, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:42.094] iteration:13837  t-loss:0.0115, loss-lb:0.0088, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:15:42.474] iteration:13838  t-loss:0.0397, loss-lb:0.0247, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:15:42.850] iteration:13839  t-loss:0.0198, loss-lb:0.0172, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:15:43.226] iteration:13840  t-loss:0.0287, loss-lb:0.0251, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:15:43.601] iteration:13841  t-loss:0.0246, loss-lb:0.0090, loss-ulb:0.0078, weight:2.00, lr:0.0001
[02:15:43.977] iteration:13842  t-loss:0.0147, loss-lb:0.0105, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:15:44.351] iteration:13843  t-loss:0.0116, loss-lb:0.0075, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:15:44.726] iteration:13844  t-loss:0.0258, loss-lb:0.0183, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:15:45.099] iteration:13845  t-loss:0.0133, loss-lb:0.0102, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:15:45.499] iteration:13846  t-loss:0.0291, loss-lb:0.0199, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:15:45.900] iteration:13847  t-loss:0.0169, loss-lb:0.0095, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:15:46.283] iteration:13848  t-loss:0.0276, loss-lb:0.0227, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:15:46.658] iteration:13849  t-loss:0.0148, loss-lb:0.0119, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:15:47.032] iteration:13850  t-loss:0.0097, loss-lb:0.0077, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:15:47.408] iteration:13851  t-loss:0.0199, loss-lb:0.0164, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:15:47.781] iteration:13852  t-loss:0.0319, loss-lb:0.0237, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:15:48.159] iteration:13853  t-loss:0.0184, loss-lb:0.0105, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:15:48.539] iteration:13854  t-loss:0.0359, loss-lb:0.0159, loss-ulb:0.0100, weight:2.00, lr:0.0001
[02:15:48.916] iteration:13855  t-loss:0.0171, loss-lb:0.0081, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:15:49.293] iteration:13856  t-loss:0.0266, loss-lb:0.0239, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:15:49.689] iteration:13857  t-loss:0.0302, loss-lb:0.0276, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:15:50.099] iteration:13858  t-loss:0.0245, loss-lb:0.0095, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:15:50.487] iteration:13859  t-loss:0.0308, loss-lb:0.0153, loss-ulb:0.0078, weight:2.00, lr:0.0001
[02:15:50.874] iteration:13860  t-loss:0.0280, loss-lb:0.0242, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:15:51.258] iteration:13861  t-loss:0.0517, loss-lb:0.0453, loss-ulb:0.0032, weight:2.00, lr:0.0001
[02:15:51.644] iteration:13862  t-loss:0.0223, loss-lb:0.0088, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:15:52.035] iteration:13863  t-loss:0.0351, loss-lb:0.0209, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:15:52.417] iteration:13864  t-loss:0.0353, loss-lb:0.0215, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:15:52.795] iteration:13865  t-loss:0.0169, loss-lb:0.0152, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:15:53.177] iteration:13866  t-loss:0.0336, loss-lb:0.0223, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:15:53.560] iteration:13867  t-loss:0.0324, loss-lb:0.0197, loss-ulb:0.0064, weight:2.00, lr:0.0001
[02:15:53.944] iteration:13868  t-loss:0.0225, loss-lb:0.0095, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:15:54.325] iteration:13869  t-loss:0.0158, loss-lb:0.0106, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:15:54.709] iteration:13870  t-loss:0.0366, loss-lb:0.0228, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:17:04.974] iteration 13870 : dice_score: 0.904799 best_dice: 0.906000
[02:17:04.974]  <<Test>> - Ep:364  - Dice-S/T:90.49/90.48, Best-S:90.51, Best-T:90.60
[02:17:04.975]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[02:17:06.166] iteration:13871  t-loss:0.0309, loss-lb:0.0293, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:17:06.581] iteration:13872  t-loss:0.0378, loss-lb:0.0225, loss-ulb:0.0076, weight:2.00, lr:0.0001
[02:17:06.979] iteration:13873  t-loss:0.0113, loss-lb:0.0096, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:17:07.369] iteration:13874  t-loss:0.0252, loss-lb:0.0201, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:17:07.752] iteration:13875  t-loss:0.0137, loss-lb:0.0115, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:17:08.138] iteration:13876  t-loss:0.0334, loss-lb:0.0242, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:17:08.517] iteration:13877  t-loss:0.0432, loss-lb:0.0082, loss-ulb:0.0175, weight:2.00, lr:0.0001
[02:17:08.910] iteration:13878  t-loss:0.0286, loss-lb:0.0249, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:17:09.301] iteration:13879  t-loss:0.0259, loss-lb:0.0239, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:09.697] iteration:13880  t-loss:0.0182, loss-lb:0.0086, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:17:10.077] iteration:13881  t-loss:0.0423, loss-lb:0.0337, loss-ulb:0.0043, weight:2.00, lr:0.0001
[02:17:10.454] iteration:13882  t-loss:0.0120, loss-lb:0.0091, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:17:10.838] iteration:13883  t-loss:0.0159, loss-lb:0.0109, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:17:11.220] iteration:13884  t-loss:0.0160, loss-lb:0.0091, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:17:11.601] iteration:13885  t-loss:0.0162, loss-lb:0.0127, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:17:11.981] iteration:13886  t-loss:0.0158, loss-lb:0.0113, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:17:12.362] iteration:13887  t-loss:0.0323, loss-lb:0.0096, loss-ulb:0.0113, weight:2.00, lr:0.0001
[02:17:12.746] iteration:13888  t-loss:0.0272, loss-lb:0.0150, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:17:13.132] iteration:13889  t-loss:0.0163, loss-lb:0.0148, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:17:13.518] iteration:13890  t-loss:0.0273, loss-lb:0.0121, loss-ulb:0.0076, weight:2.00, lr:0.0001
[02:17:13.898] iteration:13891  t-loss:0.0127, loss-lb:0.0106, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:17:14.281] iteration:13892  t-loss:0.0275, loss-lb:0.0177, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:17:14.661] iteration:13893  t-loss:0.0256, loss-lb:0.0237, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:17:15.044] iteration:13894  t-loss:0.0295, loss-lb:0.0161, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:17:15.421] iteration:13895  t-loss:0.0211, loss-lb:0.0079, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:17:15.803] iteration:13896  t-loss:0.0103, loss-lb:0.0090, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:17:16.184] iteration:13897  t-loss:0.0251, loss-lb:0.0228, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:17:16.571] iteration:13898  t-loss:0.0500, loss-lb:0.0213, loss-ulb:0.0144, weight:2.00, lr:0.0001
[02:17:16.960] iteration:13899  t-loss:0.0254, loss-lb:0.0118, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:17:17.355] iteration:13900  t-loss:0.0265, loss-lb:0.0177, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:17:17.747] iteration:13901  t-loss:0.0182, loss-lb:0.0155, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:17:18.131] iteration:13902  t-loss:0.0346, loss-lb:0.0192, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:17:18.507] iteration:13903  t-loss:0.0191, loss-lb:0.0154, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:17:18.889] iteration:13904  t-loss:0.0368, loss-lb:0.0207, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:17:19.267] iteration:13905  t-loss:0.0258, loss-lb:0.0082, loss-ulb:0.0088, weight:2.00, lr:0.0001
[02:17:19.639] iteration:13906  t-loss:0.0185, loss-lb:0.0106, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:17:20.013] iteration:13907  t-loss:0.0238, loss-lb:0.0218, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:20.388] iteration:13908  t-loss:0.0187, loss-lb:0.0150, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:17:21.683] iteration:13909  t-loss:0.0252, loss-lb:0.0150, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:17:22.103] iteration:13910  t-loss:0.0256, loss-lb:0.0147, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:17:22.509] iteration:13911  t-loss:0.0324, loss-lb:0.0206, loss-ulb:0.0059, weight:2.00, lr:0.0001
[02:17:22.927] iteration:13912  t-loss:0.0224, loss-lb:0.0207, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:17:23.322] iteration:13913  t-loss:0.0107, loss-lb:0.0087, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:23.750] iteration:13914  t-loss:0.0139, loss-lb:0.0114, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:17:24.161] iteration:13915  t-loss:0.0329, loss-lb:0.0179, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:17:24.548] iteration:13916  t-loss:0.0257, loss-lb:0.0213, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:17:24.936] iteration:13917  t-loss:0.0309, loss-lb:0.0215, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:17:25.309] iteration:13918  t-loss:0.0166, loss-lb:0.0085, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:17:25.685] iteration:13919  t-loss:0.0103, loss-lb:0.0079, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:17:26.060] iteration:13920  t-loss:0.0286, loss-lb:0.0250, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:17:26.441] iteration:13921  t-loss:0.0286, loss-lb:0.0204, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:17:26.821] iteration:13922  t-loss:0.0528, loss-lb:0.0114, loss-ulb:0.0207, weight:2.00, lr:0.0001
[02:17:27.206] iteration:13923  t-loss:0.0094, loss-lb:0.0083, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:17:27.583] iteration:13924  t-loss:0.0280, loss-lb:0.0189, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:17:27.964] iteration:13925  t-loss:0.0109, loss-lb:0.0089, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:28.349] iteration:13926  t-loss:0.0356, loss-lb:0.0201, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:17:28.737] iteration:13927  t-loss:0.0356, loss-lb:0.0277, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:17:29.113] iteration:13928  t-loss:0.0096, loss-lb:0.0074, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:17:29.495] iteration:13929  t-loss:0.0124, loss-lb:0.0086, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:17:29.873] iteration:13930  t-loss:0.0124, loss-lb:0.0106, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:17:30.252] iteration:13931  t-loss:0.0189, loss-lb:0.0110, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:17:30.629] iteration:13932  t-loss:0.0208, loss-lb:0.0166, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:17:31.011] iteration:13933  t-loss:0.0316, loss-lb:0.0210, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:17:31.388] iteration:13934  t-loss:0.0803, loss-lb:0.0115, loss-ulb:0.0344, weight:2.00, lr:0.0001
[02:17:31.763] iteration:13935  t-loss:0.0160, loss-lb:0.0116, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:17:32.143] iteration:13936  t-loss:0.0127, loss-lb:0.0104, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:17:32.521] iteration:13937  t-loss:0.0127, loss-lb:0.0111, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:17:32.908] iteration:13938  t-loss:0.0415, loss-lb:0.0195, loss-ulb:0.0110, weight:2.00, lr:0.0001
[02:17:33.289] iteration:13939  t-loss:0.0223, loss-lb:0.0081, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:17:33.665] iteration:13940  t-loss:0.0270, loss-lb:0.0257, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:17:34.041] iteration:13941  t-loss:0.0151, loss-lb:0.0082, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:17:34.417] iteration:13942  t-loss:0.0236, loss-lb:0.0183, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:17:34.793] iteration:13943  t-loss:0.0164, loss-lb:0.0082, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:17:35.168] iteration:13944  t-loss:0.0318, loss-lb:0.0241, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:17:35.539] iteration:13945  t-loss:0.0127, loss-lb:0.0094, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:17:35.912] iteration:13946  t-loss:0.0254, loss-lb:0.0109, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:17:37.058] iteration:13947  t-loss:0.0156, loss-lb:0.0114, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:17:37.442] iteration:13948  t-loss:0.0139, loss-lb:0.0091, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:17:37.828] iteration:13949  t-loss:0.0222, loss-lb:0.0201, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:38.218] iteration:13950  t-loss:0.0188, loss-lb:0.0136, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:17:38.622] iteration:13951  t-loss:0.1088, loss-lb:0.1066, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:17:39.024] iteration:13952  t-loss:0.0112, loss-lb:0.0091, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:39.427] iteration:13953  t-loss:0.0254, loss-lb:0.0213, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:17:39.832] iteration:13954  t-loss:0.0230, loss-lb:0.0070, loss-ulb:0.0080, weight:2.00, lr:0.0001
[02:17:40.220] iteration:13955  t-loss:0.0298, loss-lb:0.0185, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:17:40.600] iteration:13956  t-loss:0.0188, loss-lb:0.0145, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:17:40.978] iteration:13957  t-loss:0.0114, loss-lb:0.0100, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:17:41.354] iteration:13958  t-loss:0.0126, loss-lb:0.0101, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:17:41.740] iteration:13959  t-loss:0.0376, loss-lb:0.0222, loss-ulb:0.0077, weight:2.00, lr:0.0001
[02:17:42.117] iteration:13960  t-loss:0.0125, loss-lb:0.0100, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:17:42.495] iteration:13961  t-loss:0.0109, loss-lb:0.0092, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:17:42.876] iteration:13962  t-loss:0.0218, loss-lb:0.0137, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:17:43.263] iteration:13963  t-loss:0.0214, loss-lb:0.0188, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:17:43.643] iteration:13964  t-loss:0.0302, loss-lb:0.0196, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:17:44.026] iteration:13965  t-loss:0.0255, loss-lb:0.0205, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:17:44.401] iteration:13966  t-loss:0.0135, loss-lb:0.0107, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:17:44.786] iteration:13967  t-loss:0.0263, loss-lb:0.0237, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:17:45.162] iteration:13968  t-loss:0.0124, loss-lb:0.0106, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:17:45.543] iteration:13969  t-loss:0.0264, loss-lb:0.0225, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:17:45.920] iteration:13970  t-loss:0.0127, loss-lb:0.0106, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:46.298] iteration:13971  t-loss:0.0201, loss-lb:0.0073, loss-ulb:0.0064, weight:2.00, lr:0.0001
[02:17:46.673] iteration:13972  t-loss:0.0140, loss-lb:0.0095, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:17:47.053] iteration:13973  t-loss:0.0251, loss-lb:0.0176, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:17:47.433] iteration:13974  t-loss:0.0299, loss-lb:0.0213, loss-ulb:0.0043, weight:2.00, lr:0.0001
[02:17:47.814] iteration:13975  t-loss:0.0292, loss-lb:0.0199, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:17:48.192] iteration:13976  t-loss:0.0204, loss-lb:0.0081, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:17:48.568] iteration:13977  t-loss:0.0602, loss-lb:0.0576, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:17:48.942] iteration:13978  t-loss:0.0157, loss-lb:0.0148, loss-ulb:0.0004, weight:2.00, lr:0.0001
[02:17:49.315] iteration:13979  t-loss:0.0205, loss-lb:0.0175, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:17:49.689] iteration:13980  t-loss:0.0302, loss-lb:0.0209, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:17:50.065] iteration:13981  t-loss:0.0397, loss-lb:0.0187, loss-ulb:0.0105, weight:2.00, lr:0.0001
[02:17:50.440] iteration:13982  t-loss:0.0462, loss-lb:0.0270, loss-ulb:0.0096, weight:2.00, lr:0.0001
[02:17:50.807] iteration:13983  t-loss:0.0157, loss-lb:0.0088, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:17:51.178] iteration:13984  t-loss:0.0106, loss-lb:0.0092, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:17:52.310] iteration:13985  t-loss:0.0149, loss-lb:0.0117, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:17:52.688] iteration:13986  t-loss:0.0255, loss-lb:0.0092, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:17:53.064] iteration:13987  t-loss:0.0202, loss-lb:0.0124, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:17:53.458] iteration:13988  t-loss:0.0364, loss-lb:0.0253, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:17:53.845] iteration:13989  t-loss:0.0183, loss-lb:0.0105, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:17:54.235] iteration:13990  t-loss:0.0475, loss-lb:0.0103, loss-ulb:0.0186, weight:2.00, lr:0.0001
[02:17:54.629] iteration:13991  t-loss:0.0264, loss-lb:0.0211, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:17:55.029] iteration:13992  t-loss:0.0189, loss-lb:0.0112, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:17:55.416] iteration:13993  t-loss:0.0345, loss-lb:0.0154, loss-ulb:0.0095, weight:2.00, lr:0.0001
[02:17:55.795] iteration:13994  t-loss:0.0187, loss-lb:0.0107, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:17:56.166] iteration:13995  t-loss:0.0151, loss-lb:0.0142, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:17:56.543] iteration:13996  t-loss:0.0195, loss-lb:0.0176, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:17:56.918] iteration:13997  t-loss:0.0117, loss-lb:0.0092, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:17:57.298] iteration:13998  t-loss:0.0210, loss-lb:0.0108, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:17:57.674] iteration:13999  t-loss:0.0173, loss-lb:0.0092, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:17:58.052] iteration:14000  t-loss:0.0174, loss-lb:0.0159, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:17:58.432] iteration:14001  t-loss:0.0213, loss-lb:0.0084, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:17:58.810] iteration:14002  t-loss:0.0149, loss-lb:0.0106, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:17:59.186] iteration:14003  t-loss:0.0152, loss-lb:0.0099, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:17:59.570] iteration:14004  t-loss:0.0362, loss-lb:0.0196, loss-ulb:0.0083, weight:2.00, lr:0.0001
[02:17:59.950] iteration:14005  t-loss:0.0274, loss-lb:0.0185, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:18:00.346] iteration:14006  t-loss:0.0335, loss-lb:0.0226, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:18:00.723] iteration:14007  t-loss:0.0285, loss-lb:0.0204, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:18:01.099] iteration:14008  t-loss:0.0097, loss-lb:0.0083, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:18:01.478] iteration:14009  t-loss:0.0280, loss-lb:0.0106, loss-ulb:0.0087, weight:2.00, lr:0.0001
[02:18:01.862] iteration:14010  t-loss:0.0244, loss-lb:0.0105, loss-ulb:0.0070, weight:2.00, lr:0.0001
[02:18:02.239] iteration:14011  t-loss:0.0214, loss-lb:0.0094, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:18:02.613] iteration:14012  t-loss:0.0135, loss-lb:0.0112, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:18:02.995] iteration:14013  t-loss:0.0455, loss-lb:0.0262, loss-ulb:0.0097, weight:2.00, lr:0.0001
[02:18:03.378] iteration:14014  t-loss:0.0256, loss-lb:0.0119, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:18:03.752] iteration:14015  t-loss:0.0146, loss-lb:0.0086, loss-ulb:0.0030, weight:2.00, lr:0.0001
[02:18:04.132] iteration:14016  t-loss:0.0288, loss-lb:0.0229, loss-ulb:0.0030, weight:2.00, lr:0.0001
[02:18:04.505] iteration:14017  t-loss:0.0132, loss-lb:0.0109, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:18:04.884] iteration:14018  t-loss:0.0311, loss-lb:0.0168, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:18:05.257] iteration:14019  t-loss:0.0134, loss-lb:0.0120, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:18:05.632] iteration:14020  t-loss:0.0202, loss-lb:0.0180, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:18:06.006] iteration:14021  t-loss:0.0133, loss-lb:0.0113, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:18:06.378] iteration:14022  t-loss:0.0184, loss-lb:0.0144, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:19:10.452] iteration 14022 : dice_score: 0.899346 best_dice: 0.906000
[02:19:10.452]  <<Test>> - Ep:368  - Dice-S/T:90.42/89.93, Best-S:90.51, Best-T:90.60
[02:19:10.452]           - AvgLoss(lb/ulb/all):0.01/0.00/0.02
[02:19:11.699] iteration:14023  t-loss:0.0231, loss-lb:0.0108, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:19:12.090] iteration:14024  t-loss:0.0125, loss-lb:0.0090, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:19:12.468] iteration:14025  t-loss:0.0146, loss-lb:0.0120, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:19:12.849] iteration:14026  t-loss:0.0146, loss-lb:0.0100, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:19:13.235] iteration:14027  t-loss:0.0348, loss-lb:0.0182, loss-ulb:0.0083, weight:2.00, lr:0.0001
[02:19:13.619] iteration:14028  t-loss:0.0154, loss-lb:0.0105, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:19:14.000] iteration:14029  t-loss:0.0221, loss-lb:0.0195, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:19:14.389] iteration:14030  t-loss:0.0200, loss-lb:0.0181, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:14.771] iteration:14031  t-loss:0.0310, loss-lb:0.0112, loss-ulb:0.0099, weight:2.00, lr:0.0001
[02:19:15.162] iteration:14032  t-loss:0.0246, loss-lb:0.0086, loss-ulb:0.0080, weight:2.00, lr:0.0001
[02:19:15.565] iteration:14033  t-loss:0.0405, loss-lb:0.0257, loss-ulb:0.0074, weight:2.00, lr:0.0001
[02:19:15.959] iteration:14034  t-loss:0.0288, loss-lb:0.0156, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:19:16.341] iteration:14035  t-loss:0.0294, loss-lb:0.0185, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:19:16.722] iteration:14036  t-loss:0.0127, loss-lb:0.0110, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:17.107] iteration:14037  t-loss:0.0264, loss-lb:0.0102, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:19:17.484] iteration:14038  t-loss:0.0125, loss-lb:0.0100, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:19:17.862] iteration:14039  t-loss:0.0123, loss-lb:0.0100, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:19:18.243] iteration:14040  t-loss:0.0302, loss-lb:0.0283, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:18.624] iteration:14041  t-loss:0.0250, loss-lb:0.0113, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:19:19.006] iteration:14042  t-loss:0.0115, loss-lb:0.0085, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:19:19.395] iteration:14043  t-loss:0.0346, loss-lb:0.0202, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:19:19.772] iteration:14044  t-loss:0.0323, loss-lb:0.0109, loss-ulb:0.0107, weight:2.00, lr:0.0001
[02:19:20.153] iteration:14045  t-loss:0.0283, loss-lb:0.0081, loss-ulb:0.0101, weight:2.00, lr:0.0001
[02:19:20.534] iteration:14046  t-loss:0.0217, loss-lb:0.0129, loss-ulb:0.0044, weight:2.00, lr:0.0001
[02:19:20.920] iteration:14047  t-loss:0.0263, loss-lb:0.0184, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:19:21.302] iteration:14048  t-loss:0.0209, loss-lb:0.0101, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:19:21.685] iteration:14049  t-loss:0.0161, loss-lb:0.0084, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:19:22.065] iteration:14050  t-loss:0.0141, loss-lb:0.0116, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:19:22.450] iteration:14051  t-loss:0.0233, loss-lb:0.0165, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:19:22.834] iteration:14052  t-loss:0.0438, loss-lb:0.0332, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:19:23.210] iteration:14053  t-loss:0.0122, loss-lb:0.0103, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:23.585] iteration:14054  t-loss:0.0167, loss-lb:0.0089, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:19:23.963] iteration:14055  t-loss:0.0131, loss-lb:0.0099, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:19:24.342] iteration:14056  t-loss:0.0168, loss-lb:0.0106, loss-ulb:0.0031, weight:2.00, lr:0.0001
[02:19:24.733] iteration:14057  t-loss:0.0299, loss-lb:0.0192, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:19:25.111] iteration:14058  t-loss:0.0256, loss-lb:0.0238, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:25.489] iteration:14059  t-loss:0.0273, loss-lb:0.0138, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:19:25.867] iteration:14060  t-loss:0.0378, loss-lb:0.0257, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:19:27.279] iteration:14061  t-loss:0.0149, loss-lb:0.0132, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:27.662] iteration:14062  t-loss:0.0277, loss-lb:0.0106, loss-ulb:0.0086, weight:2.00, lr:0.0001
[02:19:28.041] iteration:14063  t-loss:0.0182, loss-lb:0.0082, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:19:28.423] iteration:14064  t-loss:0.0281, loss-lb:0.0187, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:19:28.805] iteration:14065  t-loss:0.0248, loss-lb:0.0227, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:29.186] iteration:14066  t-loss:0.0331, loss-lb:0.0185, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:19:29.570] iteration:14067  t-loss:0.0197, loss-lb:0.0090, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:19:29.975] iteration:14068  t-loss:0.0214, loss-lb:0.0162, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:19:30.390] iteration:14069  t-loss:0.0187, loss-lb:0.0167, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:30.829] iteration:14070  t-loss:0.0339, loss-lb:0.0326, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:19:31.257] iteration:14071  t-loss:0.0131, loss-lb:0.0114, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:31.677] iteration:14072  t-loss:0.0135, loss-lb:0.0086, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:19:32.073] iteration:14073  t-loss:0.0300, loss-lb:0.0192, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:19:32.466] iteration:14074  t-loss:0.0221, loss-lb:0.0079, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:19:32.859] iteration:14075  t-loss:0.0239, loss-lb:0.0228, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:19:33.248] iteration:14076  t-loss:0.0330, loss-lb:0.0310, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:33.628] iteration:14077  t-loss:0.0202, loss-lb:0.0158, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:19:34.012] iteration:14078  t-loss:0.0357, loss-lb:0.0280, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:19:34.397] iteration:14079  t-loss:0.0224, loss-lb:0.0144, loss-ulb:0.0040, weight:2.00, lr:0.0001
[02:19:34.779] iteration:14080  t-loss:0.0291, loss-lb:0.0271, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:35.161] iteration:14081  t-loss:0.0266, loss-lb:0.0173, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:19:35.544] iteration:14082  t-loss:0.0399, loss-lb:0.0265, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:19:35.922] iteration:14083  t-loss:0.0617, loss-lb:0.0572, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:19:36.298] iteration:14084  t-loss:0.0251, loss-lb:0.0172, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:19:36.681] iteration:14085  t-loss:0.0231, loss-lb:0.0175, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:19:37.066] iteration:14086  t-loss:0.0331, loss-lb:0.0227, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:19:37.452] iteration:14087  t-loss:0.0175, loss-lb:0.0156, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:37.826] iteration:14088  t-loss:0.0147, loss-lb:0.0105, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:19:38.218] iteration:14089  t-loss:0.0337, loss-lb:0.0211, loss-ulb:0.0063, weight:2.00, lr:0.0001
[02:19:38.593] iteration:14090  t-loss:0.0150, loss-lb:0.0109, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:19:38.979] iteration:14091  t-loss:0.0241, loss-lb:0.0177, loss-ulb:0.0032, weight:2.00, lr:0.0001
[02:19:39.355] iteration:14092  t-loss:0.0108, loss-lb:0.0088, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:39.739] iteration:14093  t-loss:0.0320, loss-lb:0.0147, loss-ulb:0.0086, weight:2.00, lr:0.0001
[02:19:40.128] iteration:14094  t-loss:0.1105, loss-lb:0.0972, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:19:40.502] iteration:14095  t-loss:0.0146, loss-lb:0.0122, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:19:40.876] iteration:14096  t-loss:0.0109, loss-lb:0.0083, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:19:41.252] iteration:14097  t-loss:0.0179, loss-lb:0.0088, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:19:41.627] iteration:14098  t-loss:0.0318, loss-lb:0.0104, loss-ulb:0.0107, weight:2.00, lr:0.0001
[02:19:42.802] iteration:14099  t-loss:0.0118, loss-lb:0.0088, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:19:43.180] iteration:14100  t-loss:0.0860, loss-lb:0.0247, loss-ulb:0.0306, weight:2.00, lr:0.0001
[02:19:43.556] iteration:14101  t-loss:0.0224, loss-lb:0.0128, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:19:43.928] iteration:14102  t-loss:0.0102, loss-lb:0.0084, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:44.303] iteration:14103  t-loss:0.0241, loss-lb:0.0198, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:19:44.678] iteration:14104  t-loss:0.0382, loss-lb:0.0188, loss-ulb:0.0097, weight:2.00, lr:0.0001
[02:19:45.053] iteration:14105  t-loss:0.0116, loss-lb:0.0101, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:19:45.449] iteration:14106  t-loss:0.0375, loss-lb:0.0239, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:19:45.845] iteration:14107  t-loss:0.0204, loss-lb:0.0097, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:19:46.233] iteration:14108  t-loss:0.0104, loss-lb:0.0085, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:46.659] iteration:14109  t-loss:0.0123, loss-lb:0.0103, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:19:47.063] iteration:14110  t-loss:0.0449, loss-lb:0.0324, loss-ulb:0.0063, weight:2.00, lr:0.0001
[02:19:47.455] iteration:14111  t-loss:0.0183, loss-lb:0.0172, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:19:47.833] iteration:14112  t-loss:0.0278, loss-lb:0.0164, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:19:48.212] iteration:14113  t-loss:0.0259, loss-lb:0.0161, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:19:48.592] iteration:14114  t-loss:0.0386, loss-lb:0.0174, loss-ulb:0.0106, weight:2.00, lr:0.0001
[02:19:48.975] iteration:14115  t-loss:0.0348, loss-lb:0.0170, loss-ulb:0.0089, weight:2.00, lr:0.0001
[02:19:49.368] iteration:14116  t-loss:0.0193, loss-lb:0.0095, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:19:49.744] iteration:14117  t-loss:0.0237, loss-lb:0.0173, loss-ulb:0.0032, weight:2.00, lr:0.0001
[02:19:50.123] iteration:14118  t-loss:0.0277, loss-lb:0.0182, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:19:50.499] iteration:14119  t-loss:0.0271, loss-lb:0.0125, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:19:50.879] iteration:14120  t-loss:0.0190, loss-lb:0.0083, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:19:51.258] iteration:14121  t-loss:0.0251, loss-lb:0.0108, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:19:51.639] iteration:14122  t-loss:0.0519, loss-lb:0.0180, loss-ulb:0.0169, weight:2.00, lr:0.0001
[02:19:52.022] iteration:14123  t-loss:0.0268, loss-lb:0.0191, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:19:52.401] iteration:14124  t-loss:0.0325, loss-lb:0.0233, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:19:52.774] iteration:14125  t-loss:0.0131, loss-lb:0.0101, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:19:53.155] iteration:14126  t-loss:0.0265, loss-lb:0.0163, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:19:53.534] iteration:14127  t-loss:0.0273, loss-lb:0.0156, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:19:53.912] iteration:14128  t-loss:0.0274, loss-lb:0.0163, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:19:54.287] iteration:14129  t-loss:0.0196, loss-lb:0.0085, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:19:54.666] iteration:14130  t-loss:0.0315, loss-lb:0.0196, loss-ulb:0.0059, weight:2.00, lr:0.0001
[02:19:55.044] iteration:14131  t-loss:0.0272, loss-lb:0.0249, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:19:55.421] iteration:14132  t-loss:0.0164, loss-lb:0.0152, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:19:55.797] iteration:14133  t-loss:0.0243, loss-lb:0.0097, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:19:56.172] iteration:14134  t-loss:0.0267, loss-lb:0.0207, loss-ulb:0.0030, weight:2.00, lr:0.0001
[02:19:56.548] iteration:14135  t-loss:0.0239, loss-lb:0.0226, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:19:56.927] iteration:14136  t-loss:0.0352, loss-lb:0.0231, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:19:57.982] iteration:14137  t-loss:0.0122, loss-lb:0.0103, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:58.375] iteration:14138  t-loss:0.0335, loss-lb:0.0154, loss-ulb:0.0090, weight:2.00, lr:0.0001
[02:19:58.751] iteration:14139  t-loss:0.0127, loss-lb:0.0109, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:19:59.127] iteration:14140  t-loss:0.0383, loss-lb:0.0163, loss-ulb:0.0110, weight:2.00, lr:0.0001
[02:19:59.500] iteration:14141  t-loss:0.0103, loss-lb:0.0092, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:19:59.876] iteration:14142  t-loss:0.0230, loss-lb:0.0094, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:20:00.254] iteration:14143  t-loss:0.0222, loss-lb:0.0087, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:20:00.636] iteration:14144  t-loss:0.0238, loss-lb:0.0104, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:20:01.025] iteration:14145  t-loss:0.0153, loss-lb:0.0078, loss-ulb:0.0038, weight:2.00, lr:0.0001
[02:20:01.408] iteration:14146  t-loss:0.0134, loss-lb:0.0102, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:20:01.792] iteration:14147  t-loss:0.0110, loss-lb:0.0097, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:20:02.180] iteration:14148  t-loss:0.0233, loss-lb:0.0198, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:20:02.574] iteration:14149  t-loss:0.0214, loss-lb:0.0196, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:20:02.962] iteration:14150  t-loss:0.0257, loss-lb:0.0146, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:20:03.340] iteration:14151  t-loss:0.0119, loss-lb:0.0095, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:20:03.718] iteration:14152  t-loss:0.0363, loss-lb:0.0255, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:20:04.103] iteration:14153  t-loss:0.0210, loss-lb:0.0103, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:20:04.484] iteration:14154  t-loss:0.0251, loss-lb:0.0212, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:20:04.869] iteration:14155  t-loss:0.0291, loss-lb:0.0160, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:20:05.246] iteration:14156  t-loss:0.0224, loss-lb:0.0109, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:20:05.625] iteration:14157  t-loss:0.0197, loss-lb:0.0168, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:20:06.002] iteration:14158  t-loss:0.0109, loss-lb:0.0094, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:20:06.379] iteration:14159  t-loss:0.0206, loss-lb:0.0187, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:20:06.757] iteration:14160  t-loss:0.0290, loss-lb:0.0169, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:20:07.134] iteration:14161  t-loss:0.0195, loss-lb:0.0176, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:20:07.518] iteration:14162  t-loss:0.0870, loss-lb:0.0264, loss-ulb:0.0303, weight:2.00, lr:0.0001
[02:20:07.899] iteration:14163  t-loss:0.0376, loss-lb:0.0243, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:20:08.281] iteration:14164  t-loss:0.0270, loss-lb:0.0146, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:20:08.666] iteration:14165  t-loss:0.0322, loss-lb:0.0179, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:20:09.052] iteration:14166  t-loss:0.0270, loss-lb:0.0154, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:20:09.429] iteration:14167  t-loss:0.0271, loss-lb:0.0245, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:20:09.804] iteration:14168  t-loss:0.0321, loss-lb:0.0173, loss-ulb:0.0074, weight:2.00, lr:0.0001
[02:20:10.177] iteration:14169  t-loss:0.0546, loss-lb:0.0490, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:20:10.556] iteration:14170  t-loss:0.0197, loss-lb:0.0166, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:20:10.929] iteration:14171  t-loss:0.0220, loss-lb:0.0091, loss-ulb:0.0064, weight:2.00, lr:0.0001
[02:20:11.303] iteration:14172  t-loss:0.0740, loss-lb:0.0601, loss-ulb:0.0070, weight:2.00, lr:0.0001
[02:20:11.677] iteration:14173  t-loss:0.0197, loss-lb:0.0098, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:20:12.051] iteration:14174  t-loss:0.0128, loss-lb:0.0097, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:21:16.487] iteration 14174 : dice_score: 0.904315 best_dice: 0.906000
[02:21:16.488]  <<Test>> - Ep:372  - Dice-S/T:90.02/90.43, Best-S:90.51, Best-T:90.60
[02:21:16.488]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[02:21:17.732] iteration:14175  t-loss:0.0451, loss-lb:0.0187, loss-ulb:0.0132, weight:2.00, lr:0.0001
[02:21:18.128] iteration:14176  t-loss:0.0297, loss-lb:0.0104, loss-ulb:0.0097, weight:2.00, lr:0.0001
[02:21:18.516] iteration:14177  t-loss:0.0245, loss-lb:0.0084, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:21:18.907] iteration:14178  t-loss:0.0363, loss-lb:0.0175, loss-ulb:0.0094, weight:2.00, lr:0.0001
[02:21:19.294] iteration:14179  t-loss:0.0332, loss-lb:0.0150, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:21:19.681] iteration:14180  t-loss:0.0247, loss-lb:0.0226, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:21:20.069] iteration:14181  t-loss:0.0270, loss-lb:0.0162, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:21:20.450] iteration:14182  t-loss:0.0273, loss-lb:0.0249, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:21:20.827] iteration:14183  t-loss:0.0110, loss-lb:0.0095, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:21:21.218] iteration:14184  t-loss:0.0347, loss-lb:0.0250, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:21:21.605] iteration:14185  t-loss:0.0230, loss-lb:0.0090, loss-ulb:0.0070, weight:2.00, lr:0.0001
[02:21:21.987] iteration:14186  t-loss:0.0238, loss-lb:0.0177, loss-ulb:0.0030, weight:2.00, lr:0.0001
[02:21:22.370] iteration:14187  t-loss:0.0383, loss-lb:0.0279, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:21:22.756] iteration:14188  t-loss:0.0270, loss-lb:0.0231, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:21:23.142] iteration:14189  t-loss:0.0226, loss-lb:0.0203, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:21:23.528] iteration:14190  t-loss:0.0381, loss-lb:0.0241, loss-ulb:0.0070, weight:2.00, lr:0.0001
[02:21:23.917] iteration:14191  t-loss:0.0181, loss-lb:0.0165, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:21:24.326] iteration:14192  t-loss:0.0287, loss-lb:0.0185, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:21:24.725] iteration:14193  t-loss:0.0134, loss-lb:0.0102, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:21:25.107] iteration:14194  t-loss:0.0110, loss-lb:0.0093, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:25.494] iteration:14195  t-loss:0.0201, loss-lb:0.0174, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:21:25.882] iteration:14196  t-loss:0.0230, loss-lb:0.0106, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:21:26.268] iteration:14197  t-loss:0.0175, loss-lb:0.0076, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:21:26.649] iteration:14198  t-loss:0.0270, loss-lb:0.0223, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:21:27.036] iteration:14199  t-loss:0.0268, loss-lb:0.0248, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:21:27.417] iteration:14200  t-loss:0.0246, loss-lb:0.0231, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:21:27.798] iteration:14201  t-loss:0.0189, loss-lb:0.0093, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:21:28.179] iteration:14202  t-loss:0.0228, loss-lb:0.0098, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:21:28.558] iteration:14203  t-loss:0.0197, loss-lb:0.0104, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:21:28.943] iteration:14204  t-loss:0.0250, loss-lb:0.0169, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:21:29.319] iteration:14205  t-loss:0.0121, loss-lb:0.0092, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:21:29.694] iteration:14206  t-loss:0.0221, loss-lb:0.0152, loss-ulb:0.0035, weight:2.00, lr:0.0001
[02:21:30.075] iteration:14207  t-loss:0.0182, loss-lb:0.0092, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:21:30.455] iteration:14208  t-loss:0.0311, loss-lb:0.0170, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:21:30.837] iteration:14209  t-loss:0.0174, loss-lb:0.0123, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:21:31.219] iteration:14210  t-loss:0.0242, loss-lb:0.0224, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:31.594] iteration:14211  t-loss:0.0160, loss-lb:0.0104, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:21:31.972] iteration:14212  t-loss:0.0110, loss-lb:0.0092, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:33.468] iteration:14213  t-loss:0.0254, loss-lb:0.0142, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:21:33.867] iteration:14214  t-loss:0.0117, loss-lb:0.0100, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:21:34.258] iteration:14215  t-loss:0.0169, loss-lb:0.0080, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:21:34.646] iteration:14216  t-loss:0.0151, loss-lb:0.0103, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:21:35.041] iteration:14217  t-loss:0.0311, loss-lb:0.0165, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:21:35.420] iteration:14218  t-loss:0.0132, loss-lb:0.0092, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:21:35.797] iteration:14219  t-loss:0.0131, loss-lb:0.0097, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:21:36.180] iteration:14220  t-loss:0.0136, loss-lb:0.0086, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:21:36.561] iteration:14221  t-loss:0.0253, loss-lb:0.0089, loss-ulb:0.0082, weight:2.00, lr:0.0001
[02:21:36.940] iteration:14222  t-loss:0.0322, loss-lb:0.0173, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:21:37.325] iteration:14223  t-loss:0.0095, loss-lb:0.0077, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:37.742] iteration:14224  t-loss:0.0139, loss-lb:0.0109, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:21:38.142] iteration:14225  t-loss:0.0279, loss-lb:0.0124, loss-ulb:0.0078, weight:2.00, lr:0.0001
[02:21:38.524] iteration:14226  t-loss:0.0281, loss-lb:0.0181, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:21:38.902] iteration:14227  t-loss:0.0178, loss-lb:0.0084, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:21:39.279] iteration:14228  t-loss:0.0176, loss-lb:0.0159, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:21:39.675] iteration:14229  t-loss:0.0099, loss-lb:0.0081, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:40.079] iteration:14230  t-loss:0.0296, loss-lb:0.0211, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:21:40.488] iteration:14231  t-loss:0.0328, loss-lb:0.0234, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:21:40.881] iteration:14232  t-loss:0.0211, loss-lb:0.0084, loss-ulb:0.0063, weight:2.00, lr:0.0001
[02:21:41.270] iteration:14233  t-loss:0.0133, loss-lb:0.0090, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:21:41.648] iteration:14234  t-loss:0.0374, loss-lb:0.0186, loss-ulb:0.0094, weight:2.00, lr:0.0001
[02:21:42.030] iteration:14235  t-loss:0.0241, loss-lb:0.0096, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:21:42.414] iteration:14236  t-loss:0.0344, loss-lb:0.0308, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:21:42.794] iteration:14237  t-loss:0.0312, loss-lb:0.0088, loss-ulb:0.0112, weight:2.00, lr:0.0001
[02:21:43.171] iteration:14238  t-loss:0.0477, loss-lb:0.0353, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:21:43.550] iteration:14239  t-loss:0.0284, loss-lb:0.0266, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:43.926] iteration:14240  t-loss:0.0121, loss-lb:0.0102, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:44.313] iteration:14241  t-loss:0.0378, loss-lb:0.0234, loss-ulb:0.0072, weight:2.00, lr:0.0001
[02:21:44.692] iteration:14242  t-loss:0.0180, loss-lb:0.0095, loss-ulb:0.0043, weight:2.00, lr:0.0001
[02:21:45.068] iteration:14243  t-loss:0.0095, loss-lb:0.0082, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:21:45.448] iteration:14244  t-loss:0.0329, loss-lb:0.0111, loss-ulb:0.0109, weight:2.00, lr:0.0001
[02:21:45.824] iteration:14245  t-loss:0.0111, loss-lb:0.0101, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:21:46.202] iteration:14246  t-loss:0.0206, loss-lb:0.0150, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:21:46.593] iteration:14247  t-loss:0.0173, loss-lb:0.0149, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:21:46.977] iteration:14248  t-loss:0.0502, loss-lb:0.0218, loss-ulb:0.0142, weight:2.00, lr:0.0001
[02:21:47.356] iteration:14249  t-loss:0.0207, loss-lb:0.0188, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:21:47.730] iteration:14250  t-loss:0.0136, loss-lb:0.0087, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:21:48.891] iteration:14251  t-loss:0.0144, loss-lb:0.0118, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:21:49.280] iteration:14252  t-loss:0.0156, loss-lb:0.0083, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:21:49.656] iteration:14253  t-loss:0.0140, loss-lb:0.0101, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:21:50.033] iteration:14254  t-loss:0.0127, loss-lb:0.0109, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:21:50.412] iteration:14255  t-loss:0.0177, loss-lb:0.0167, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:21:50.789] iteration:14256  t-loss:0.0253, loss-lb:0.0146, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:21:51.169] iteration:14257  t-loss:0.0209, loss-lb:0.0097, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:21:51.546] iteration:14258  t-loss:0.0183, loss-lb:0.0171, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:21:51.921] iteration:14259  t-loss:0.0199, loss-lb:0.0176, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:21:52.293] iteration:14260  t-loss:0.0158, loss-lb:0.0115, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:21:52.679] iteration:14261  t-loss:0.0186, loss-lb:0.0111, loss-ulb:0.0037, weight:2.00, lr:0.0001
[02:21:53.067] iteration:14262  t-loss:0.0167, loss-lb:0.0101, loss-ulb:0.0033, weight:2.00, lr:0.0001
[02:21:53.450] iteration:14263  t-loss:0.0444, loss-lb:0.0240, loss-ulb:0.0102, weight:2.00, lr:0.0001
[02:21:53.834] iteration:14264  t-loss:0.0235, loss-lb:0.0227, loss-ulb:0.0004, weight:2.00, lr:0.0001
[02:21:54.209] iteration:14265  t-loss:0.0123, loss-lb:0.0080, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:21:54.589] iteration:14266  t-loss:0.0374, loss-lb:0.0211, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:21:54.980] iteration:14267  t-loss:0.0292, loss-lb:0.0198, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:21:55.386] iteration:14268  t-loss:0.0331, loss-lb:0.0267, loss-ulb:0.0032, weight:2.00, lr:0.0001
[02:21:55.782] iteration:14269  t-loss:0.0278, loss-lb:0.0249, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:21:56.169] iteration:14270  t-loss:0.0167, loss-lb:0.0081, loss-ulb:0.0043, weight:2.00, lr:0.0001
[02:21:56.551] iteration:14271  t-loss:0.0128, loss-lb:0.0092, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:21:56.931] iteration:14272  t-loss:0.0130, loss-lb:0.0094, loss-ulb:0.0018, weight:2.00, lr:0.0001
[02:21:57.308] iteration:14273  t-loss:0.0176, loss-lb:0.0087, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:21:57.681] iteration:14274  t-loss:0.0115, loss-lb:0.0095, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:21:58.075] iteration:14275  t-loss:0.0209, loss-lb:0.0169, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:21:58.454] iteration:14276  t-loss:0.0268, loss-lb:0.0086, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:21:58.831] iteration:14277  t-loss:0.0186, loss-lb:0.0088, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:21:59.207] iteration:14278  t-loss:0.0298, loss-lb:0.0266, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:21:59.591] iteration:14279  t-loss:0.0307, loss-lb:0.0180, loss-ulb:0.0063, weight:2.00, lr:0.0001
[02:21:59.975] iteration:14280  t-loss:0.0208, loss-lb:0.0108, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:22:00.357] iteration:14281  t-loss:0.0480, loss-lb:0.0344, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:22:00.737] iteration:14282  t-loss:0.0138, loss-lb:0.0075, loss-ulb:0.0031, weight:2.00, lr:0.0001
[02:22:01.111] iteration:14283  t-loss:0.0113, loss-lb:0.0101, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:22:01.489] iteration:14284  t-loss:0.0309, loss-lb:0.0226, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:22:01.861] iteration:14285  t-loss:0.0102, loss-lb:0.0085, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:22:02.243] iteration:14286  t-loss:0.0457, loss-lb:0.0174, loss-ulb:0.0141, weight:2.00, lr:0.0001
[02:22:02.616] iteration:14287  t-loss:0.0101, loss-lb:0.0082, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:22:02.992] iteration:14288  t-loss:0.0298, loss-lb:0.0098, loss-ulb:0.0100, weight:2.00, lr:0.0001
[02:22:04.188] iteration:14289  t-loss:0.0164, loss-lb:0.0115, loss-ulb:0.0025, weight:2.00, lr:0.0001
[02:22:04.583] iteration:14290  t-loss:0.0166, loss-lb:0.0097, loss-ulb:0.0035, weight:2.00, lr:0.0001
[02:22:04.968] iteration:14291  t-loss:0.0237, loss-lb:0.0218, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:22:05.340] iteration:14292  t-loss:0.0154, loss-lb:0.0121, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:22:05.720] iteration:14293  t-loss:0.0300, loss-lb:0.0195, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:22:06.096] iteration:14294  t-loss:0.0220, loss-lb:0.0197, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:22:06.473] iteration:14295  t-loss:0.0292, loss-lb:0.0181, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:22:06.849] iteration:14296  t-loss:0.0386, loss-lb:0.0204, loss-ulb:0.0091, weight:2.00, lr:0.0001
[02:22:07.226] iteration:14297  t-loss:0.0211, loss-lb:0.0109, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:22:07.600] iteration:14298  t-loss:0.0190, loss-lb:0.0105, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:22:07.983] iteration:14299  t-loss:0.0104, loss-lb:0.0091, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:22:08.383] iteration:14300  t-loss:0.0388, loss-lb:0.0096, loss-ulb:0.0146, weight:2.00, lr:0.0001
[02:22:08.767] iteration:14301  t-loss:0.0312, loss-lb:0.0092, loss-ulb:0.0110, weight:2.00, lr:0.0001
[02:22:09.147] iteration:14302  t-loss:0.0094, loss-lb:0.0082, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:22:09.525] iteration:14303  t-loss:0.0214, loss-lb:0.0199, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:22:09.896] iteration:14304  t-loss:0.0286, loss-lb:0.0224, loss-ulb:0.0031, weight:2.00, lr:0.0001
[02:22:10.276] iteration:14305  t-loss:0.0289, loss-lb:0.0261, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:22:10.685] iteration:14306  t-loss:0.0275, loss-lb:0.0178, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:22:11.107] iteration:14307  t-loss:0.0132, loss-lb:0.0084, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:22:11.526] iteration:14308  t-loss:0.0383, loss-lb:0.0204, loss-ulb:0.0090, weight:2.00, lr:0.0001
[02:22:11.925] iteration:14309  t-loss:0.0280, loss-lb:0.0165, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:22:12.318] iteration:14310  t-loss:0.0292, loss-lb:0.0114, loss-ulb:0.0089, weight:2.00, lr:0.0001
[02:22:12.715] iteration:14311  t-loss:0.0218, loss-lb:0.0186, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:22:13.116] iteration:14312  t-loss:0.0226, loss-lb:0.0186, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:22:13.509] iteration:14313  t-loss:0.0236, loss-lb:0.0106, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:22:13.892] iteration:14314  t-loss:0.0131, loss-lb:0.0101, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:22:14.278] iteration:14315  t-loss:0.0178, loss-lb:0.0166, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:22:14.661] iteration:14316  t-loss:0.0202, loss-lb:0.0091, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:22:15.048] iteration:14317  t-loss:0.0155, loss-lb:0.0088, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:22:15.437] iteration:14318  t-loss:0.0259, loss-lb:0.0109, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:22:15.813] iteration:14319  t-loss:0.0231, loss-lb:0.0183, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:22:16.190] iteration:14320  t-loss:0.0598, loss-lb:0.0485, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:22:16.567] iteration:14321  t-loss:0.0383, loss-lb:0.0192, loss-ulb:0.0096, weight:2.00, lr:0.0001
[02:22:16.942] iteration:14322  t-loss:0.0274, loss-lb:0.0113, loss-ulb:0.0081, weight:2.00, lr:0.0001
[02:22:17.322] iteration:14323  t-loss:0.0203, loss-lb:0.0177, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:22:17.695] iteration:14324  t-loss:0.0162, loss-lb:0.0077, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:22:18.076] iteration:14325  t-loss:0.0385, loss-lb:0.0228, loss-ulb:0.0078, weight:2.00, lr:0.0001
[02:22:18.453] iteration:14326  t-loss:0.0186, loss-lb:0.0088, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:23:22.848] iteration 14326 : dice_score: 0.905842 best_dice: 0.906000
[02:23:22.848]  <<Test>> - Ep:376  - Dice-S/T:89.98/90.58, Best-S:90.51, Best-T:90.60
[02:23:22.848]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[02:23:23.984] iteration:14327  t-loss:0.0489, loss-lb:0.0347, loss-ulb:0.0071, weight:2.00, lr:0.0001
[02:23:24.409] iteration:14328  t-loss:0.0314, loss-lb:0.0189, loss-ulb:0.0063, weight:2.00, lr:0.0001
[02:23:24.795] iteration:14329  t-loss:0.0459, loss-lb:0.0093, loss-ulb:0.0183, weight:2.00, lr:0.0001
[02:23:25.177] iteration:14330  t-loss:0.0174, loss-lb:0.0096, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:23:25.571] iteration:14331  t-loss:0.0328, loss-lb:0.0197, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:23:25.961] iteration:14332  t-loss:0.0312, loss-lb:0.0242, loss-ulb:0.0035, weight:2.00, lr:0.0001
[02:23:26.342] iteration:14333  t-loss:0.0140, loss-lb:0.0128, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:23:26.729] iteration:14334  t-loss:0.0210, loss-lb:0.0080, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:23:27.102] iteration:14335  t-loss:0.0129, loss-lb:0.0089, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:23:27.494] iteration:14336  t-loss:0.0283, loss-lb:0.0259, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:23:27.879] iteration:14337  t-loss:0.0303, loss-lb:0.0187, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:23:28.261] iteration:14338  t-loss:0.0286, loss-lb:0.0177, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:23:28.650] iteration:14339  t-loss:0.0166, loss-lb:0.0082, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:23:29.041] iteration:14340  t-loss:0.0305, loss-lb:0.0194, loss-ulb:0.0056, weight:2.00, lr:0.0001
[02:23:29.422] iteration:14341  t-loss:0.0099, loss-lb:0.0088, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:23:29.803] iteration:14342  t-loss:0.0352, loss-lb:0.0107, loss-ulb:0.0123, weight:2.00, lr:0.0001
[02:23:30.188] iteration:14343  t-loss:0.0335, loss-lb:0.0197, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:23:30.572] iteration:14344  t-loss:0.0235, loss-lb:0.0132, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:23:30.963] iteration:14345  t-loss:0.0203, loss-lb:0.0192, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:23:31.344] iteration:14346  t-loss:0.0126, loss-lb:0.0095, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:23:31.727] iteration:14347  t-loss:0.0174, loss-lb:0.0105, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:23:32.115] iteration:14348  t-loss:0.0121, loss-lb:0.0101, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:23:32.496] iteration:14349  t-loss:0.0212, loss-lb:0.0104, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:23:32.875] iteration:14350  t-loss:0.0144, loss-lb:0.0114, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:23:33.274] iteration:14351  t-loss:0.0186, loss-lb:0.0094, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:23:33.675] iteration:14352  t-loss:0.0239, loss-lb:0.0086, loss-ulb:0.0076, weight:2.00, lr:0.0001
[02:23:34.059] iteration:14353  t-loss:0.0258, loss-lb:0.0219, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:23:34.437] iteration:14354  t-loss:0.0135, loss-lb:0.0102, loss-ulb:0.0016, weight:2.00, lr:0.0001
[02:23:34.824] iteration:14355  t-loss:0.0283, loss-lb:0.0158, loss-ulb:0.0063, weight:2.00, lr:0.0001
[02:23:35.208] iteration:14356  t-loss:0.0156, loss-lb:0.0072, loss-ulb:0.0042, weight:2.00, lr:0.0001
[02:23:35.590] iteration:14357  t-loss:0.0243, loss-lb:0.0231, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:23:35.970] iteration:14358  t-loss:0.0274, loss-lb:0.0248, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:23:36.353] iteration:14359  t-loss:0.0335, loss-lb:0.0186, loss-ulb:0.0075, weight:2.00, lr:0.0001
[02:23:36.735] iteration:14360  t-loss:0.0294, loss-lb:0.0193, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:23:37.115] iteration:14361  t-loss:0.0357, loss-lb:0.0225, loss-ulb:0.0066, weight:2.00, lr:0.0001
[02:23:37.502] iteration:14362  t-loss:0.0204, loss-lb:0.0089, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:23:37.881] iteration:14363  t-loss:0.0097, loss-lb:0.0083, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:23:38.259] iteration:14364  t-loss:0.0204, loss-lb:0.0166, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:23:39.482] iteration:14365  t-loss:0.0097, loss-lb:0.0090, loss-ulb:0.0003, weight:2.00, lr:0.0001
[02:23:39.872] iteration:14366  t-loss:0.0198, loss-lb:0.0105, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:23:40.251] iteration:14367  t-loss:0.0128, loss-lb:0.0098, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:23:40.638] iteration:14368  t-loss:0.0326, loss-lb:0.0177, loss-ulb:0.0074, weight:2.00, lr:0.0001
[02:23:41.028] iteration:14369  t-loss:0.0396, loss-lb:0.0175, loss-ulb:0.0111, weight:2.00, lr:0.0001
[02:23:41.414] iteration:14370  t-loss:0.0299, loss-lb:0.0162, loss-ulb:0.0068, weight:2.00, lr:0.0001
[02:23:41.801] iteration:14371  t-loss:0.0188, loss-lb:0.0168, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:23:42.188] iteration:14372  t-loss:0.0352, loss-lb:0.0218, loss-ulb:0.0067, weight:2.00, lr:0.0001
[02:23:42.576] iteration:14373  t-loss:0.0343, loss-lb:0.0251, loss-ulb:0.0046, weight:2.00, lr:0.0001
[02:23:42.955] iteration:14374  t-loss:0.0209, loss-lb:0.0079, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:23:43.334] iteration:14375  t-loss:0.0155, loss-lb:0.0077, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:23:43.713] iteration:14376  t-loss:0.0217, loss-lb:0.0096, loss-ulb:0.0060, weight:2.00, lr:0.0001
[02:23:44.101] iteration:14377  t-loss:0.0327, loss-lb:0.0203, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:23:44.482] iteration:14378  t-loss:0.0314, loss-lb:0.0224, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:23:44.861] iteration:14379  t-loss:0.0153, loss-lb:0.0126, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:23:45.245] iteration:14380  t-loss:0.0167, loss-lb:0.0085, loss-ulb:0.0041, weight:2.00, lr:0.0001
[02:23:45.638] iteration:14381  t-loss:0.0288, loss-lb:0.0225, loss-ulb:0.0032, weight:2.00, lr:0.0001
[02:23:46.032] iteration:14382  t-loss:0.0383, loss-lb:0.0166, loss-ulb:0.0109, weight:2.00, lr:0.0001
[02:23:46.419] iteration:14383  t-loss:0.0323, loss-lb:0.0209, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:23:46.791] iteration:14384  t-loss:0.0157, loss-lb:0.0097, loss-ulb:0.0030, weight:2.00, lr:0.0001
[02:23:47.182] iteration:14385  t-loss:0.0419, loss-lb:0.0318, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:23:47.556] iteration:14386  t-loss:0.0129, loss-lb:0.0098, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:23:47.932] iteration:14387  t-loss:0.0248, loss-lb:0.0192, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:23:48.312] iteration:14388  t-loss:0.0292, loss-lb:0.0255, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:23:48.711] iteration:14389  t-loss:0.0214, loss-lb:0.0175, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:23:49.111] iteration:14390  t-loss:0.0203, loss-lb:0.0160, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:23:49.493] iteration:14391  t-loss:0.0126, loss-lb:0.0112, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:23:49.882] iteration:14392  t-loss:0.0220, loss-lb:0.0082, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:23:50.270] iteration:14393  t-loss:0.0131, loss-lb:0.0088, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:23:50.646] iteration:14394  t-loss:0.0268, loss-lb:0.0224, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:23:51.024] iteration:14395  t-loss:0.0644, loss-lb:0.0271, loss-ulb:0.0186, weight:2.00, lr:0.0001
[02:23:51.401] iteration:14396  t-loss:0.0640, loss-lb:0.0173, loss-ulb:0.0234, weight:2.00, lr:0.0001
[02:23:51.777] iteration:14397  t-loss:0.0172, loss-lb:0.0100, loss-ulb:0.0036, weight:2.00, lr:0.0001
[02:23:52.154] iteration:14398  t-loss:0.0509, loss-lb:0.0391, loss-ulb:0.0059, weight:2.00, lr:0.0001
[02:23:52.532] iteration:14399  t-loss:0.0317, loss-lb:0.0075, loss-ulb:0.0121, weight:2.00, lr:0.0001
[02:23:52.941] iteration:14400  t-loss:0.0145, loss-lb:0.0108, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:23:53.345] iteration:14401  t-loss:0.0244, loss-lb:0.0151, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:23:53.720] iteration:14402  t-loss:0.0218, loss-lb:0.0190, loss-ulb:0.0014, weight:2.00, lr:0.0001
[02:23:54.904] iteration:14403  t-loss:0.0206, loss-lb:0.0103, loss-ulb:0.0051, weight:2.00, lr:0.0001
[02:23:55.344] iteration:14404  t-loss:0.0240, loss-lb:0.0196, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:23:55.733] iteration:14405  t-loss:0.0141, loss-lb:0.0094, loss-ulb:0.0023, weight:2.00, lr:0.0001
[02:23:56.113] iteration:14406  t-loss:0.0215, loss-lb:0.0108, loss-ulb:0.0054, weight:2.00, lr:0.0001
[02:23:56.502] iteration:14407  t-loss:0.0298, loss-lb:0.0241, loss-ulb:0.0028, weight:2.00, lr:0.0001
[02:23:56.887] iteration:14408  t-loss:0.0448, loss-lb:0.0149, loss-ulb:0.0150, weight:2.00, lr:0.0001
[02:23:57.263] iteration:14409  t-loss:0.0143, loss-lb:0.0099, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:23:57.639] iteration:14410  t-loss:0.0241, loss-lb:0.0221, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:23:58.019] iteration:14411  t-loss:0.0290, loss-lb:0.0077, loss-ulb:0.0106, weight:2.00, lr:0.0001
[02:23:58.397] iteration:14412  t-loss:0.0237, loss-lb:0.0197, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:23:58.779] iteration:14413  t-loss:0.0317, loss-lb:0.0210, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:23:59.154] iteration:14414  t-loss:0.0210, loss-lb:0.0189, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:23:59.535] iteration:14415  t-loss:0.0269, loss-lb:0.0225, loss-ulb:0.0022, weight:2.00, lr:0.0001
[02:23:59.911] iteration:14416  t-loss:0.0181, loss-lb:0.0087, loss-ulb:0.0047, weight:2.00, lr:0.0001
[02:24:00.290] iteration:14417  t-loss:0.0292, loss-lb:0.0162, loss-ulb:0.0065, weight:2.00, lr:0.0001
[02:24:00.668] iteration:14418  t-loss:0.0231, loss-lb:0.0213, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:24:01.061] iteration:14419  t-loss:0.0237, loss-lb:0.0215, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:24:01.475] iteration:14420  t-loss:0.0116, loss-lb:0.0101, loss-ulb:0.0008, weight:2.00, lr:0.0001
[02:24:01.873] iteration:14421  t-loss:0.0408, loss-lb:0.0238, loss-ulb:0.0085, weight:2.00, lr:0.0001
[02:24:02.248] iteration:14422  t-loss:0.0118, loss-lb:0.0094, loss-ulb:0.0012, weight:2.00, lr:0.0001
[02:24:02.626] iteration:14423  t-loss:0.0156, loss-lb:0.0089, loss-ulb:0.0034, weight:2.00, lr:0.0001
[02:24:02.998] iteration:14424  t-loss:0.0177, loss-lb:0.0111, loss-ulb:0.0033, weight:2.00, lr:0.0001
[02:24:03.374] iteration:14425  t-loss:0.0207, loss-lb:0.0109, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:24:03.754] iteration:14426  t-loss:0.0285, loss-lb:0.0182, loss-ulb:0.0052, weight:2.00, lr:0.0001
[02:24:04.135] iteration:14427  t-loss:0.0112, loss-lb:0.0101, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:24:04.533] iteration:14428  t-loss:0.0130, loss-lb:0.0104, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:24:04.931] iteration:14429  t-loss:0.0292, loss-lb:0.0178, loss-ulb:0.0057, weight:2.00, lr:0.0001
[02:24:05.328] iteration:14430  t-loss:0.0199, loss-lb:0.0151, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:24:05.716] iteration:14431  t-loss:0.0262, loss-lb:0.0139, loss-ulb:0.0061, weight:2.00, lr:0.0001
[02:24:06.094] iteration:14432  t-loss:0.0367, loss-lb:0.0240, loss-ulb:0.0064, weight:2.00, lr:0.0001
[02:24:06.476] iteration:14433  t-loss:0.0238, loss-lb:0.0190, loss-ulb:0.0024, weight:2.00, lr:0.0001
[02:24:06.856] iteration:14434  t-loss:0.0262, loss-lb:0.0157, loss-ulb:0.0053, weight:2.00, lr:0.0001
[02:24:07.232] iteration:14435  t-loss:0.0217, loss-lb:0.0101, loss-ulb:0.0058, weight:2.00, lr:0.0001
[02:24:07.606] iteration:14436  t-loss:0.0195, loss-lb:0.0155, loss-ulb:0.0020, weight:2.00, lr:0.0001
[02:24:07.981] iteration:14437  t-loss:0.0112, loss-lb:0.0093, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:24:08.361] iteration:14438  t-loss:0.0322, loss-lb:0.0197, loss-ulb:0.0062, weight:2.00, lr:0.0001
[02:24:08.736] iteration:14439  t-loss:0.0336, loss-lb:0.0327, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:24:09.114] iteration:14440  t-loss:0.0208, loss-lb:0.0111, loss-ulb:0.0049, weight:2.00, lr:0.0001
[02:24:10.503] iteration:14441  t-loss:0.0203, loss-lb:0.0103, loss-ulb:0.0050, weight:2.00, lr:0.0001
[02:24:10.889] iteration:14442  t-loss:0.0327, loss-lb:0.0181, loss-ulb:0.0073, weight:2.00, lr:0.0001
[02:24:11.280] iteration:14443  t-loss:0.0230, loss-lb:0.0201, loss-ulb:0.0015, weight:2.00, lr:0.0001
[02:24:11.660] iteration:14444  t-loss:0.0106, loss-lb:0.0069, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:24:12.041] iteration:14445  t-loss:0.0109, loss-lb:0.0098, loss-ulb:0.0006, weight:2.00, lr:0.0001
[02:24:12.420] iteration:14446  t-loss:0.0223, loss-lb:0.0086, loss-ulb:0.0069, weight:2.00, lr:0.0001
[02:24:12.799] iteration:14447  t-loss:0.0158, loss-lb:0.0105, loss-ulb:0.0026, weight:2.00, lr:0.0001
[02:24:13.175] iteration:14448  t-loss:0.0194, loss-lb:0.0184, loss-ulb:0.0005, weight:2.00, lr:0.0001
[02:24:13.553] iteration:14449  t-loss:0.0096, loss-lb:0.0083, loss-ulb:0.0007, weight:2.00, lr:0.0001
[02:24:13.929] iteration:14450  t-loss:0.0340, loss-lb:0.0149, loss-ulb:0.0095, weight:2.00, lr:0.0001
[02:24:14.309] iteration:14451  t-loss:0.0177, loss-lb:0.0156, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:24:14.685] iteration:14452  t-loss:0.0195, loss-lb:0.0104, loss-ulb:0.0045, weight:2.00, lr:0.0001
[02:24:15.068] iteration:14453  t-loss:0.0303, loss-lb:0.0193, loss-ulb:0.0055, weight:2.00, lr:0.0001
[02:24:15.444] iteration:14454  t-loss:0.0246, loss-lb:0.0205, loss-ulb:0.0021, weight:2.00, lr:0.0001
[02:24:15.827] iteration:14455  t-loss:0.0302, loss-lb:0.0276, loss-ulb:0.0013, weight:2.00, lr:0.0001
[02:24:16.207] iteration:14456  t-loss:0.0153, loss-lb:0.0075, loss-ulb:0.0039, weight:2.00, lr:0.0001
[02:24:16.594] iteration:14457  t-loss:0.0142, loss-lb:0.0123, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:24:16.997] iteration:14458  t-loss:0.0185, loss-lb:0.0166, loss-ulb:0.0009, weight:2.00, lr:0.0001
[02:24:17.385] iteration:14459  t-loss:0.0221, loss-lb:0.0184, loss-ulb:0.0019, weight:2.00, lr:0.0001
[02:24:17.760] iteration:14460  t-loss:0.0098, loss-lb:0.0078, loss-ulb:0.0010, weight:2.00, lr:0.0001
[02:24:18.139] iteration:14461  t-loss:0.0185, loss-lb:0.0089, loss-ulb:0.0048, weight:2.00, lr:0.0001
[02:24:18.514] iteration:14462  t-loss:0.0113, loss-lb:0.0079, loss-ulb:0.0017, weight:2.00, lr:0.0001
[02:24:18.898] iteration:14463  t-loss:0.0201, loss-lb:0.0180, loss-ulb:0.0011, weight:2.00, lr:0.0001
[02:24:19.274] iteration:14464  t-loss:0.0352, loss-lb:0.0240, loss-ulb:0.0056, weight:2.00, lr:0.0000
[02:24:19.657] iteration:14465  t-loss:0.0183, loss-lb:0.0108, loss-ulb:0.0038, weight:2.00, lr:0.0000
[02:24:20.042] iteration:14466  t-loss:0.0094, loss-lb:0.0075, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:24:20.434] iteration:14467  t-loss:0.0202, loss-lb:0.0184, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:24:20.814] iteration:14468  t-loss:0.0244, loss-lb:0.0082, loss-ulb:0.0081, weight:2.00, lr:0.0000
[02:24:21.189] iteration:14469  t-loss:0.0107, loss-lb:0.0076, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:24:21.562] iteration:14470  t-loss:0.0747, loss-lb:0.0094, loss-ulb:0.0326, weight:2.00, lr:0.0000
[02:24:21.936] iteration:14471  t-loss:0.0195, loss-lb:0.0175, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:24:22.309] iteration:14472  t-loss:0.0111, loss-lb:0.0096, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:24:22.683] iteration:14473  t-loss:0.0284, loss-lb:0.0177, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:24:23.056] iteration:14474  t-loss:0.0235, loss-lb:0.0146, loss-ulb:0.0045, weight:2.00, lr:0.0000
[02:24:23.448] iteration:14475  t-loss:0.0406, loss-lb:0.0184, loss-ulb:0.0111, weight:2.00, lr:0.0000
[02:24:23.840] iteration:14476  t-loss:0.0193, loss-lb:0.0112, loss-ulb:0.0040, weight:2.00, lr:0.0000
[02:24:24.216] iteration:14477  t-loss:0.0283, loss-lb:0.0222, loss-ulb:0.0030, weight:2.00, lr:0.0000
[02:24:24.589] iteration:14478  t-loss:0.0195, loss-lb:0.0091, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:25:28.591] iteration 14478 : dice_score: 0.903986 best_dice: 0.906000
[02:25:28.591]  <<Test>> - Ep:380  - Dice-S/T:90.15/90.40, Best-S:90.51, Best-T:90.60
[02:25:28.591]           - AvgLoss(lb/ulb/all):0.01/0.00/0.02
[02:25:29.850] iteration:14479  t-loss:0.0231, loss-lb:0.0199, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:25:30.245] iteration:14480  t-loss:0.0231, loss-lb:0.0178, loss-ulb:0.0026, weight:2.00, lr:0.0000
[02:25:30.628] iteration:14481  t-loss:0.0230, loss-lb:0.0106, loss-ulb:0.0062, weight:2.00, lr:0.0000
[02:25:31.008] iteration:14482  t-loss:0.0232, loss-lb:0.0110, loss-ulb:0.0061, weight:2.00, lr:0.0000
[02:25:31.387] iteration:14483  t-loss:0.0200, loss-lb:0.0097, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:25:31.771] iteration:14484  t-loss:0.0262, loss-lb:0.0181, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:25:32.150] iteration:14485  t-loss:0.0205, loss-lb:0.0164, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:25:32.530] iteration:14486  t-loss:0.0318, loss-lb:0.0099, loss-ulb:0.0110, weight:2.00, lr:0.0000
[02:25:32.914] iteration:14487  t-loss:0.0339, loss-lb:0.0185, loss-ulb:0.0077, weight:2.00, lr:0.0000
[02:25:33.297] iteration:14488  t-loss:0.0209, loss-lb:0.0183, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:25:33.680] iteration:14489  t-loss:0.0281, loss-lb:0.0270, loss-ulb:0.0005, weight:2.00, lr:0.0000
[02:25:34.064] iteration:14490  t-loss:0.0125, loss-lb:0.0095, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:25:34.470] iteration:14491  t-loss:0.0262, loss-lb:0.0145, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:25:34.853] iteration:14492  t-loss:0.0300, loss-lb:0.0167, loss-ulb:0.0066, weight:2.00, lr:0.0000
[02:25:35.242] iteration:14493  t-loss:0.0343, loss-lb:0.0232, loss-ulb:0.0056, weight:2.00, lr:0.0000
[02:25:35.635] iteration:14494  t-loss:0.0327, loss-lb:0.0196, loss-ulb:0.0065, weight:2.00, lr:0.0000
[02:25:36.017] iteration:14495  t-loss:0.0199, loss-lb:0.0184, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:25:36.402] iteration:14496  t-loss:0.0104, loss-lb:0.0077, loss-ulb:0.0014, weight:2.00, lr:0.0000
[02:25:36.791] iteration:14497  t-loss:0.0366, loss-lb:0.0253, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:25:37.179] iteration:14498  t-loss:0.0340, loss-lb:0.0207, loss-ulb:0.0067, weight:2.00, lr:0.0000
[02:25:37.566] iteration:14499  t-loss:0.0321, loss-lb:0.0192, loss-ulb:0.0064, weight:2.00, lr:0.0000
[02:25:37.950] iteration:14500  t-loss:0.0364, loss-lb:0.0245, loss-ulb:0.0060, weight:2.00, lr:0.0000
[02:25:38.336] iteration:14501  t-loss:0.0251, loss-lb:0.0176, loss-ulb:0.0038, weight:2.00, lr:0.0000
[02:25:38.717] iteration:14502  t-loss:0.0164, loss-lb:0.0115, loss-ulb:0.0024, weight:2.00, lr:0.0000
[02:25:39.104] iteration:14503  t-loss:0.0203, loss-lb:0.0106, loss-ulb:0.0048, weight:2.00, lr:0.0000
[02:25:39.487] iteration:14504  t-loss:0.0104, loss-lb:0.0083, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:25:39.871] iteration:14505  t-loss:0.0131, loss-lb:0.0088, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:25:40.259] iteration:14506  t-loss:0.0208, loss-lb:0.0188, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:25:40.646] iteration:14507  t-loss:0.0317, loss-lb:0.0176, loss-ulb:0.0070, weight:2.00, lr:0.0000
[02:25:41.025] iteration:14508  t-loss:0.0159, loss-lb:0.0083, loss-ulb:0.0038, weight:2.00, lr:0.0000
[02:25:41.402] iteration:14509  t-loss:0.0276, loss-lb:0.0121, loss-ulb:0.0077, weight:2.00, lr:0.0000
[02:25:41.791] iteration:14510  t-loss:0.0189, loss-lb:0.0149, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:25:42.184] iteration:14511  t-loss:0.0200, loss-lb:0.0117, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:25:42.561] iteration:14512  t-loss:0.0126, loss-lb:0.0076, loss-ulb:0.0025, weight:2.00, lr:0.0000
[02:25:42.936] iteration:14513  t-loss:0.0156, loss-lb:0.0143, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:25:43.310] iteration:14514  t-loss:0.0109, loss-lb:0.0091, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:25:43.691] iteration:14515  t-loss:0.0233, loss-lb:0.0114, loss-ulb:0.0060, weight:2.00, lr:0.0000
[02:25:44.077] iteration:14516  t-loss:0.0263, loss-lb:0.0160, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:25:45.412] iteration:14517  t-loss:0.0315, loss-lb:0.0288, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:25:45.797] iteration:14518  t-loss:0.0120, loss-lb:0.0099, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:25:46.189] iteration:14519  t-loss:0.0225, loss-lb:0.0182, loss-ulb:0.0022, weight:2.00, lr:0.0000
[02:25:46.572] iteration:14520  t-loss:0.0299, loss-lb:0.0178, loss-ulb:0.0060, weight:2.00, lr:0.0000
[02:25:46.948] iteration:14521  t-loss:0.0179, loss-lb:0.0076, loss-ulb:0.0051, weight:2.00, lr:0.0000
[02:25:47.323] iteration:14522  t-loss:0.0102, loss-lb:0.0086, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:25:47.706] iteration:14523  t-loss:0.0093, loss-lb:0.0078, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:25:48.091] iteration:14524  t-loss:0.0291, loss-lb:0.0203, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:25:48.473] iteration:14525  t-loss:0.0194, loss-lb:0.0169, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:25:48.855] iteration:14526  t-loss:0.0097, loss-lb:0.0083, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:25:49.259] iteration:14527  t-loss:0.0491, loss-lb:0.0175, loss-ulb:0.0158, weight:2.00, lr:0.0000
[02:25:49.643] iteration:14528  t-loss:0.0274, loss-lb:0.0099, loss-ulb:0.0087, weight:2.00, lr:0.0000
[02:25:50.034] iteration:14529  t-loss:0.0236, loss-lb:0.0152, loss-ulb:0.0042, weight:2.00, lr:0.0000
[02:25:50.416] iteration:14530  t-loss:0.0202, loss-lb:0.0079, loss-ulb:0.0061, weight:2.00, lr:0.0000
[02:25:50.801] iteration:14531  t-loss:0.0215, loss-lb:0.0188, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:25:51.190] iteration:14532  t-loss:0.0350, loss-lb:0.0155, loss-ulb:0.0097, weight:2.00, lr:0.0000
[02:25:51.571] iteration:14533  t-loss:0.0152, loss-lb:0.0137, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:25:51.966] iteration:14534  t-loss:0.0290, loss-lb:0.0181, loss-ulb:0.0055, weight:2.00, lr:0.0000
[02:25:52.374] iteration:14535  t-loss:0.0105, loss-lb:0.0084, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:25:52.801] iteration:14536  t-loss:0.0310, loss-lb:0.0217, loss-ulb:0.0046, weight:2.00, lr:0.0000
[02:25:53.198] iteration:14537  t-loss:0.0122, loss-lb:0.0081, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:25:53.579] iteration:14538  t-loss:0.0180, loss-lb:0.0100, loss-ulb:0.0040, weight:2.00, lr:0.0000
[02:25:53.959] iteration:14539  t-loss:0.0236, loss-lb:0.0104, loss-ulb:0.0066, weight:2.00, lr:0.0000
[02:25:54.336] iteration:14540  t-loss:0.0198, loss-lb:0.0104, loss-ulb:0.0047, weight:2.00, lr:0.0000
[02:25:54.710] iteration:14541  t-loss:0.0139, loss-lb:0.0088, loss-ulb:0.0026, weight:2.00, lr:0.0000
[02:25:55.088] iteration:14542  t-loss:0.0262, loss-lb:0.0206, loss-ulb:0.0028, weight:2.00, lr:0.0000
[02:25:55.469] iteration:14543  t-loss:0.0320, loss-lb:0.0153, loss-ulb:0.0083, weight:2.00, lr:0.0000
[02:25:55.847] iteration:14544  t-loss:0.0269, loss-lb:0.0208, loss-ulb:0.0030, weight:2.00, lr:0.0000
[02:25:56.225] iteration:14545  t-loss:0.0452, loss-lb:0.0255, loss-ulb:0.0098, weight:2.00, lr:0.0000
[02:25:56.603] iteration:14546  t-loss:0.0318, loss-lb:0.0161, loss-ulb:0.0078, weight:2.00, lr:0.0000
[02:25:56.985] iteration:14547  t-loss:0.0192, loss-lb:0.0180, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:25:57.374] iteration:14548  t-loss:0.0311, loss-lb:0.0119, loss-ulb:0.0096, weight:2.00, lr:0.0000
[02:25:57.764] iteration:14549  t-loss:0.0332, loss-lb:0.0217, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:25:58.140] iteration:14550  t-loss:0.0239, loss-lb:0.0104, loss-ulb:0.0068, weight:2.00, lr:0.0000
[02:25:58.519] iteration:14551  t-loss:0.0223, loss-lb:0.0200, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:25:58.910] iteration:14552  t-loss:0.0194, loss-lb:0.0090, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:25:59.293] iteration:14553  t-loss:0.0208, loss-lb:0.0179, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:25:59.669] iteration:14554  t-loss:0.0124, loss-lb:0.0087, loss-ulb:0.0019, weight:2.00, lr:0.0000
[02:26:01.195] iteration:14555  t-loss:0.0276, loss-lb:0.0222, loss-ulb:0.0027, weight:2.00, lr:0.0000
[02:26:01.597] iteration:14556  t-loss:0.0209, loss-lb:0.0161, loss-ulb:0.0024, weight:2.00, lr:0.0000
[02:26:01.981] iteration:14557  t-loss:0.0233, loss-lb:0.0105, loss-ulb:0.0064, weight:2.00, lr:0.0000
[02:26:02.360] iteration:14558  t-loss:0.0137, loss-lb:0.0103, loss-ulb:0.0017, weight:2.00, lr:0.0000
[02:26:02.744] iteration:14559  t-loss:0.0199, loss-lb:0.0189, loss-ulb:0.0005, weight:2.00, lr:0.0000
[02:26:03.121] iteration:14560  t-loss:0.0218, loss-lb:0.0104, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:26:03.497] iteration:14561  t-loss:0.0333, loss-lb:0.0100, loss-ulb:0.0117, weight:2.00, lr:0.0000
[02:26:03.874] iteration:14562  t-loss:0.0249, loss-lb:0.0233, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:26:04.249] iteration:14563  t-loss:0.0237, loss-lb:0.0095, loss-ulb:0.0071, weight:2.00, lr:0.0000
[02:26:04.623] iteration:14564  t-loss:0.0102, loss-lb:0.0084, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:26:05.003] iteration:14565  t-loss:0.0388, loss-lb:0.0207, loss-ulb:0.0090, weight:2.00, lr:0.0000
[02:26:05.378] iteration:14566  t-loss:0.0179, loss-lb:0.0162, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:26:05.761] iteration:14567  t-loss:0.0216, loss-lb:0.0103, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:26:06.135] iteration:14568  t-loss:0.0150, loss-lb:0.0107, loss-ulb:0.0022, weight:2.00, lr:0.0000
[02:26:06.509] iteration:14569  t-loss:0.0282, loss-lb:0.0261, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:26:06.887] iteration:14570  t-loss:0.0303, loss-lb:0.0188, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:26:07.277] iteration:14571  t-loss:0.0180, loss-lb:0.0086, loss-ulb:0.0047, weight:2.00, lr:0.0000
[02:26:07.666] iteration:14572  t-loss:0.0180, loss-lb:0.0082, loss-ulb:0.0049, weight:2.00, lr:0.0000
[02:26:08.055] iteration:14573  t-loss:0.0468, loss-lb:0.0428, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:26:08.440] iteration:14574  t-loss:0.0264, loss-lb:0.0234, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:26:08.828] iteration:14575  t-loss:0.0186, loss-lb:0.0170, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:26:09.206] iteration:14576  t-loss:0.0301, loss-lb:0.0195, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:26:09.582] iteration:14577  t-loss:0.0199, loss-lb:0.0128, loss-ulb:0.0035, weight:2.00, lr:0.0000
[02:26:09.953] iteration:14578  t-loss:0.0125, loss-lb:0.0091, loss-ulb:0.0017, weight:2.00, lr:0.0000
[02:26:10.331] iteration:14579  t-loss:0.0231, loss-lb:0.0104, loss-ulb:0.0063, weight:2.00, lr:0.0000
[02:26:10.709] iteration:14580  t-loss:0.0202, loss-lb:0.0186, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:26:11.087] iteration:14581  t-loss:0.0672, loss-lb:0.0430, loss-ulb:0.0121, weight:2.00, lr:0.0000
[02:26:11.464] iteration:14582  t-loss:0.0278, loss-lb:0.0161, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:26:11.840] iteration:14583  t-loss:0.0093, loss-lb:0.0080, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:26:12.216] iteration:14584  t-loss:0.0261, loss-lb:0.0220, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:26:12.599] iteration:14585  t-loss:0.0088, loss-lb:0.0074, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:26:12.985] iteration:14586  t-loss:0.0258, loss-lb:0.0104, loss-ulb:0.0077, weight:2.00, lr:0.0000
[02:26:13.365] iteration:14587  t-loss:0.0381, loss-lb:0.0291, loss-ulb:0.0045, weight:2.00, lr:0.0000
[02:26:13.738] iteration:14588  t-loss:0.0210, loss-lb:0.0200, loss-ulb:0.0005, weight:2.00, lr:0.0000
[02:26:14.114] iteration:14589  t-loss:0.0114, loss-lb:0.0091, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:26:14.492] iteration:14590  t-loss:0.0299, loss-lb:0.0211, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:26:14.869] iteration:14591  t-loss:0.0209, loss-lb:0.0104, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:26:15.245] iteration:14592  t-loss:0.0171, loss-lb:0.0146, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:26:16.533] iteration:14593  t-loss:0.0109, loss-lb:0.0092, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:26:16.945] iteration:14594  t-loss:0.0250, loss-lb:0.0147, loss-ulb:0.0051, weight:2.00, lr:0.0000
[02:26:17.330] iteration:14595  t-loss:0.0239, loss-lb:0.0114, loss-ulb:0.0062, weight:2.00, lr:0.0000
[02:26:17.713] iteration:14596  t-loss:0.0398, loss-lb:0.0166, loss-ulb:0.0116, weight:2.00, lr:0.0000
[02:26:18.096] iteration:14597  t-loss:0.0186, loss-lb:0.0121, loss-ulb:0.0033, weight:2.00, lr:0.0000
[02:26:18.472] iteration:14598  t-loss:0.0262, loss-lb:0.0174, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:26:18.850] iteration:14599  t-loss:0.0263, loss-lb:0.0170, loss-ulb:0.0046, weight:2.00, lr:0.0000
[02:26:19.231] iteration:14600  t-loss:0.0406, loss-lb:0.0186, loss-ulb:0.0110, weight:2.00, lr:0.0000
[02:26:19.605] iteration:14601  t-loss:0.0207, loss-lb:0.0181, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:26:19.975] iteration:14602  t-loss:0.0142, loss-lb:0.0111, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:26:20.346] iteration:14603  t-loss:0.0102, loss-lb:0.0083, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:26:20.720] iteration:14604  t-loss:0.0296, loss-lb:0.0271, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:26:21.093] iteration:14605  t-loss:0.0122, loss-lb:0.0094, loss-ulb:0.0014, weight:2.00, lr:0.0000
[02:26:21.464] iteration:14606  t-loss:0.0140, loss-lb:0.0102, loss-ulb:0.0019, weight:2.00, lr:0.0000
[02:26:21.839] iteration:14607  t-loss:0.0267, loss-lb:0.0183, loss-ulb:0.0042, weight:2.00, lr:0.0000
[02:26:22.214] iteration:14608  t-loss:0.0338, loss-lb:0.0169, loss-ulb:0.0084, weight:2.00, lr:0.0000
[02:26:22.596] iteration:14609  t-loss:0.0253, loss-lb:0.0141, loss-ulb:0.0056, weight:2.00, lr:0.0000
[02:26:22.978] iteration:14610  t-loss:0.0121, loss-lb:0.0104, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:26:23.374] iteration:14611  t-loss:0.0273, loss-lb:0.0241, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:26:23.764] iteration:14612  t-loss:0.0353, loss-lb:0.0076, loss-ulb:0.0138, weight:2.00, lr:0.0000
[02:26:24.152] iteration:14613  t-loss:0.0111, loss-lb:0.0093, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:26:24.535] iteration:14614  t-loss:0.0432, loss-lb:0.0244, loss-ulb:0.0094, weight:2.00, lr:0.0000
[02:26:24.913] iteration:14615  t-loss:0.0163, loss-lb:0.0089, loss-ulb:0.0037, weight:2.00, lr:0.0000
[02:26:25.291] iteration:14616  t-loss:0.0251, loss-lb:0.0082, loss-ulb:0.0085, weight:2.00, lr:0.0000
[02:26:25.669] iteration:14617  t-loss:0.0300, loss-lb:0.0218, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:26:26.044] iteration:14618  t-loss:0.0241, loss-lb:0.0081, loss-ulb:0.0080, weight:2.00, lr:0.0000
[02:26:26.422] iteration:14619  t-loss:0.0253, loss-lb:0.0212, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:26:26.799] iteration:14620  t-loss:0.0257, loss-lb:0.0102, loss-ulb:0.0077, weight:2.00, lr:0.0000
[02:26:27.176] iteration:14621  t-loss:0.0206, loss-lb:0.0192, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:26:27.555] iteration:14622  t-loss:0.0301, loss-lb:0.0080, loss-ulb:0.0110, weight:2.00, lr:0.0000
[02:26:27.937] iteration:14623  t-loss:0.0118, loss-lb:0.0085, loss-ulb:0.0017, weight:2.00, lr:0.0000
[02:26:28.323] iteration:14624  t-loss:0.0223, loss-lb:0.0077, loss-ulb:0.0073, weight:2.00, lr:0.0000
[02:26:28.702] iteration:14625  t-loss:0.0322, loss-lb:0.0187, loss-ulb:0.0067, weight:2.00, lr:0.0000
[02:26:29.076] iteration:14626  t-loss:0.1024, loss-lb:0.1014, loss-ulb:0.0005, weight:2.00, lr:0.0000
[02:26:29.453] iteration:14627  t-loss:0.0181, loss-lb:0.0082, loss-ulb:0.0050, weight:2.00, lr:0.0000
[02:26:29.834] iteration:14628  t-loss:0.0221, loss-lb:0.0191, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:26:30.215] iteration:14629  t-loss:0.0149, loss-lb:0.0075, loss-ulb:0.0037, weight:2.00, lr:0.0000
[02:26:30.590] iteration:14630  t-loss:0.0316, loss-lb:0.0274, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:27:33.881] iteration 14630 : dice_score: 0.899341 best_dice: 0.906000
[02:27:33.882]  <<Test>> - Ep:384  - Dice-S/T:90.05/89.93, Best-S:90.51, Best-T:90.60
[02:27:33.882]           - AvgLoss(lb/ulb/all):0.02/0.00/0.03
[02:27:35.075] iteration:14631  t-loss:0.0164, loss-lb:0.0097, loss-ulb:0.0034, weight:2.00, lr:0.0000
[02:27:35.462] iteration:14632  t-loss:0.0107, loss-lb:0.0085, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:27:35.842] iteration:14633  t-loss:0.0186, loss-lb:0.0161, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:27:36.220] iteration:14634  t-loss:0.0122, loss-lb:0.0102, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:27:36.605] iteration:14635  t-loss:0.0240, loss-lb:0.0124, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:27:36.995] iteration:14636  t-loss:0.0349, loss-lb:0.0200, loss-ulb:0.0074, weight:2.00, lr:0.0000
[02:27:37.387] iteration:14637  t-loss:0.0413, loss-lb:0.0231, loss-ulb:0.0091, weight:2.00, lr:0.0000
[02:27:37.767] iteration:14638  t-loss:0.0186, loss-lb:0.0162, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:27:38.146] iteration:14639  t-loss:0.0099, loss-lb:0.0078, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:27:38.527] iteration:14640  t-loss:0.0256, loss-lb:0.0210, loss-ulb:0.0023, weight:2.00, lr:0.0000
[02:27:38.912] iteration:14641  t-loss:0.0116, loss-lb:0.0080, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:27:39.293] iteration:14642  t-loss:0.0613, loss-lb:0.0200, loss-ulb:0.0207, weight:2.00, lr:0.0000
[02:27:39.675] iteration:14643  t-loss:0.0253, loss-lb:0.0112, loss-ulb:0.0071, weight:2.00, lr:0.0000
[02:27:40.057] iteration:14644  t-loss:0.0182, loss-lb:0.0087, loss-ulb:0.0048, weight:2.00, lr:0.0000
[02:27:40.437] iteration:14645  t-loss:0.0114, loss-lb:0.0091, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:27:40.822] iteration:14646  t-loss:0.0317, loss-lb:0.0179, loss-ulb:0.0069, weight:2.00, lr:0.0000
[02:27:41.206] iteration:14647  t-loss:0.0130, loss-lb:0.0097, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:27:41.594] iteration:14648  t-loss:0.0247, loss-lb:0.0083, loss-ulb:0.0082, weight:2.00, lr:0.0000
[02:27:41.978] iteration:14649  t-loss:0.0179, loss-lb:0.0093, loss-ulb:0.0043, weight:2.00, lr:0.0000
[02:27:42.358] iteration:14650  t-loss:0.0254, loss-lb:0.0223, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:27:42.738] iteration:14651  t-loss:0.0147, loss-lb:0.0131, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:27:43.121] iteration:14652  t-loss:0.0286, loss-lb:0.0258, loss-ulb:0.0014, weight:2.00, lr:0.0000
[02:27:43.500] iteration:14653  t-loss:0.0118, loss-lb:0.0092, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:27:43.880] iteration:14654  t-loss:0.0203, loss-lb:0.0081, loss-ulb:0.0061, weight:2.00, lr:0.0000
[02:27:44.263] iteration:14655  t-loss:0.1274, loss-lb:0.1167, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:27:44.647] iteration:14656  t-loss:0.0187, loss-lb:0.0114, loss-ulb:0.0036, weight:2.00, lr:0.0000
[02:27:45.028] iteration:14657  t-loss:0.0203, loss-lb:0.0098, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:27:45.417] iteration:14658  t-loss:0.0301, loss-lb:0.0198, loss-ulb:0.0051, weight:2.00, lr:0.0000
[02:27:45.792] iteration:14659  t-loss:0.0095, loss-lb:0.0079, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:27:46.173] iteration:14660  t-loss:0.0322, loss-lb:0.0163, loss-ulb:0.0080, weight:2.00, lr:0.0000
[02:27:46.549] iteration:14661  t-loss:0.0206, loss-lb:0.0192, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:27:46.933] iteration:14662  t-loss:0.0326, loss-lb:0.0181, loss-ulb:0.0073, weight:2.00, lr:0.0000
[02:27:47.314] iteration:14663  t-loss:0.0230, loss-lb:0.0200, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:27:47.694] iteration:14664  t-loss:0.0251, loss-lb:0.0234, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:27:48.071] iteration:14665  t-loss:0.0220, loss-lb:0.0103, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:27:48.459] iteration:14666  t-loss:0.0239, loss-lb:0.0164, loss-ulb:0.0037, weight:2.00, lr:0.0000
[02:27:48.845] iteration:14667  t-loss:0.0245, loss-lb:0.0113, loss-ulb:0.0066, weight:2.00, lr:0.0000
[02:27:49.233] iteration:14668  t-loss:0.0199, loss-lb:0.0187, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:27:50.624] iteration:14669  t-loss:0.0277, loss-lb:0.0196, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:27:51.032] iteration:14670  t-loss:0.0286, loss-lb:0.0075, loss-ulb:0.0106, weight:2.00, lr:0.0000
[02:27:51.427] iteration:14671  t-loss:0.0354, loss-lb:0.0230, loss-ulb:0.0062, weight:2.00, lr:0.0000
[02:27:51.813] iteration:14672  t-loss:0.0340, loss-lb:0.0087, loss-ulb:0.0127, weight:2.00, lr:0.0000
[02:27:52.205] iteration:14673  t-loss:0.0400, loss-lb:0.0298, loss-ulb:0.0051, weight:2.00, lr:0.0000
[02:27:52.583] iteration:14674  t-loss:0.0160, loss-lb:0.0096, loss-ulb:0.0032, weight:2.00, lr:0.0000
[02:27:52.970] iteration:14675  t-loss:0.0171, loss-lb:0.0154, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:27:53.356] iteration:14676  t-loss:0.0129, loss-lb:0.0115, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:27:53.737] iteration:14677  t-loss:0.0185, loss-lb:0.0098, loss-ulb:0.0043, weight:2.00, lr:0.0000
[02:27:54.117] iteration:14678  t-loss:0.0280, loss-lb:0.0244, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:27:54.499] iteration:14679  t-loss:0.0172, loss-lb:0.0157, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:27:54.882] iteration:14680  t-loss:0.0543, loss-lb:0.0443, loss-ulb:0.0050, weight:2.00, lr:0.0000
[02:27:55.264] iteration:14681  t-loss:0.0118, loss-lb:0.0098, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:27:55.644] iteration:14682  t-loss:0.0174, loss-lb:0.0073, loss-ulb:0.0051, weight:2.00, lr:0.0000
[02:27:56.023] iteration:14683  t-loss:0.0311, loss-lb:0.0230, loss-ulb:0.0040, weight:2.00, lr:0.0000
[02:27:56.407] iteration:14684  t-loss:0.0125, loss-lb:0.0111, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:27:56.813] iteration:14685  t-loss:0.0340, loss-lb:0.0232, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:27:57.214] iteration:14686  t-loss:0.0319, loss-lb:0.0165, loss-ulb:0.0077, weight:2.00, lr:0.0000
[02:27:57.603] iteration:14687  t-loss:0.0400, loss-lb:0.0174, loss-ulb:0.0113, weight:2.00, lr:0.0000
[02:27:58.011] iteration:14688  t-loss:0.0326, loss-lb:0.0230, loss-ulb:0.0048, weight:2.00, lr:0.0000
[02:27:58.426] iteration:14689  t-loss:0.0209, loss-lb:0.0108, loss-ulb:0.0050, weight:2.00, lr:0.0000
[02:27:58.851] iteration:14690  t-loss:0.0293, loss-lb:0.0196, loss-ulb:0.0048, weight:2.00, lr:0.0000
[02:27:59.244] iteration:14691  t-loss:0.0248, loss-lb:0.0115, loss-ulb:0.0066, weight:2.00, lr:0.0000
[02:27:59.630] iteration:14692  t-loss:0.0325, loss-lb:0.0205, loss-ulb:0.0060, weight:2.00, lr:0.0000
[02:28:00.019] iteration:14693  t-loss:0.0196, loss-lb:0.0181, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:28:00.408] iteration:14694  t-loss:0.0357, loss-lb:0.0323, loss-ulb:0.0017, weight:2.00, lr:0.0000
[02:28:00.790] iteration:14695  t-loss:0.0208, loss-lb:0.0178, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:28:01.167] iteration:14696  t-loss:0.0232, loss-lb:0.0119, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:28:01.548] iteration:14697  t-loss:0.0237, loss-lb:0.0174, loss-ulb:0.0031, weight:2.00, lr:0.0000
[02:28:01.926] iteration:14698  t-loss:0.0189, loss-lb:0.0160, loss-ulb:0.0014, weight:2.00, lr:0.0000
[02:28:02.298] iteration:14699  t-loss:0.0203, loss-lb:0.0093, loss-ulb:0.0055, weight:2.00, lr:0.0000
[02:28:02.674] iteration:14700  t-loss:0.0217, loss-lb:0.0110, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:28:03.054] iteration:14701  t-loss:0.0277, loss-lb:0.0151, loss-ulb:0.0063, weight:2.00, lr:0.0000
[02:28:03.427] iteration:14702  t-loss:0.0130, loss-lb:0.0114, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:28:03.807] iteration:14703  t-loss:0.0301, loss-lb:0.0155, loss-ulb:0.0073, weight:2.00, lr:0.0000
[02:28:04.201] iteration:14704  t-loss:0.0355, loss-lb:0.0192, loss-ulb:0.0082, weight:2.00, lr:0.0000
[02:28:04.587] iteration:14705  t-loss:0.0108, loss-lb:0.0094, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:28:04.968] iteration:14706  t-loss:0.0255, loss-lb:0.0209, loss-ulb:0.0023, weight:2.00, lr:0.0000
[02:28:06.257] iteration:14707  t-loss:0.0264, loss-lb:0.0154, loss-ulb:0.0055, weight:2.00, lr:0.0000
[02:28:06.714] iteration:14708  t-loss:0.0416, loss-lb:0.0216, loss-ulb:0.0100, weight:2.00, lr:0.0000
[02:28:07.116] iteration:14709  t-loss:0.0137, loss-lb:0.0089, loss-ulb:0.0024, weight:2.00, lr:0.0000
[02:28:07.503] iteration:14710  t-loss:0.0101, loss-lb:0.0080, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:28:07.886] iteration:14711  t-loss:0.0404, loss-lb:0.0077, loss-ulb:0.0163, weight:2.00, lr:0.0000
[02:28:08.276] iteration:14712  t-loss:0.0328, loss-lb:0.0243, loss-ulb:0.0043, weight:2.00, lr:0.0000
[02:28:08.653] iteration:14713  t-loss:0.0165, loss-lb:0.0096, loss-ulb:0.0035, weight:2.00, lr:0.0000
[02:28:09.039] iteration:14714  t-loss:0.0190, loss-lb:0.0171, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:28:09.415] iteration:14715  t-loss:0.0341, loss-lb:0.0295, loss-ulb:0.0023, weight:2.00, lr:0.0000
[02:28:09.793] iteration:14716  t-loss:0.0257, loss-lb:0.0230, loss-ulb:0.0014, weight:2.00, lr:0.0000
[02:28:10.170] iteration:14717  t-loss:0.0605, loss-lb:0.0264, loss-ulb:0.0171, weight:2.00, lr:0.0000
[02:28:10.545] iteration:14718  t-loss:0.0117, loss-lb:0.0081, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:28:10.921] iteration:14719  t-loss:0.0141, loss-lb:0.0102, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:28:11.299] iteration:14720  t-loss:0.0272, loss-lb:0.0079, loss-ulb:0.0097, weight:2.00, lr:0.0000
[02:28:11.675] iteration:14721  t-loss:0.0226, loss-lb:0.0210, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:28:12.050] iteration:14722  t-loss:0.0246, loss-lb:0.0216, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:28:12.432] iteration:14723  t-loss:0.0228, loss-lb:0.0160, loss-ulb:0.0034, weight:2.00, lr:0.0000
[02:28:12.811] iteration:14724  t-loss:0.0268, loss-lb:0.0167, loss-ulb:0.0051, weight:2.00, lr:0.0000
[02:28:13.196] iteration:14725  t-loss:0.0139, loss-lb:0.0106, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:28:13.620] iteration:14726  t-loss:0.0254, loss-lb:0.0097, loss-ulb:0.0079, weight:2.00, lr:0.0000
[02:28:14.017] iteration:14727  t-loss:0.0290, loss-lb:0.0275, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:28:14.409] iteration:14728  t-loss:0.0177, loss-lb:0.0105, loss-ulb:0.0036, weight:2.00, lr:0.0000
[02:28:14.793] iteration:14729  t-loss:0.0157, loss-lb:0.0140, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:28:15.178] iteration:14730  t-loss:0.0226, loss-lb:0.0098, loss-ulb:0.0064, weight:2.00, lr:0.0000
[02:28:15.569] iteration:14731  t-loss:0.0322, loss-lb:0.0205, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:28:15.956] iteration:14732  t-loss:0.0107, loss-lb:0.0085, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:28:16.352] iteration:14733  t-loss:0.0119, loss-lb:0.0104, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:28:16.730] iteration:14734  t-loss:0.0187, loss-lb:0.0174, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:28:17.103] iteration:14735  t-loss:0.0104, loss-lb:0.0077, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:28:17.489] iteration:14736  t-loss:0.0260, loss-lb:0.0100, loss-ulb:0.0080, weight:2.00, lr:0.0000
[02:28:17.869] iteration:14737  t-loss:0.0260, loss-lb:0.0165, loss-ulb:0.0048, weight:2.00, lr:0.0000
[02:28:18.241] iteration:14738  t-loss:0.0114, loss-lb:0.0106, loss-ulb:0.0004, weight:2.00, lr:0.0000
[02:28:18.615] iteration:14739  t-loss:0.0130, loss-lb:0.0115, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:28:18.988] iteration:14740  t-loss:0.0557, loss-lb:0.0070, loss-ulb:0.0243, weight:2.00, lr:0.0000
[02:28:19.364] iteration:14741  t-loss:0.0176, loss-lb:0.0156, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:28:19.754] iteration:14742  t-loss:0.0278, loss-lb:0.0156, loss-ulb:0.0061, weight:2.00, lr:0.0000
[02:28:20.148] iteration:14743  t-loss:0.0171, loss-lb:0.0067, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:28:20.530] iteration:14744  t-loss:0.0270, loss-lb:0.0210, loss-ulb:0.0030, weight:2.00, lr:0.0000
[02:28:21.938] iteration:14745  t-loss:0.0269, loss-lb:0.0219, loss-ulb:0.0025, weight:2.00, lr:0.0000
[02:28:22.330] iteration:14746  t-loss:0.0259, loss-lb:0.0098, loss-ulb:0.0080, weight:2.00, lr:0.0000
[02:28:22.716] iteration:14747  t-loss:0.0225, loss-lb:0.0199, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:28:23.094] iteration:14748  t-loss:0.0281, loss-lb:0.0155, loss-ulb:0.0063, weight:2.00, lr:0.0000
[02:28:23.477] iteration:14749  t-loss:0.0271, loss-lb:0.0162, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:28:23.854] iteration:14750  t-loss:0.0129, loss-lb:0.0098, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:28:24.235] iteration:14751  t-loss:0.0316, loss-lb:0.0210, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:28:24.612] iteration:14752  t-loss:0.0196, loss-lb:0.0171, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:28:24.990] iteration:14753  t-loss:0.0121, loss-lb:0.0077, loss-ulb:0.0022, weight:2.00, lr:0.0000
[02:28:25.365] iteration:14754  t-loss:0.0206, loss-lb:0.0102, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:28:25.751] iteration:14755  t-loss:0.0137, loss-lb:0.0099, loss-ulb:0.0019, weight:2.00, lr:0.0000
[02:28:26.126] iteration:14756  t-loss:0.0154, loss-lb:0.0104, loss-ulb:0.0025, weight:2.00, lr:0.0000
[02:28:26.501] iteration:14757  t-loss:0.0198, loss-lb:0.0084, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:28:26.881] iteration:14758  t-loss:0.0186, loss-lb:0.0104, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:28:27.255] iteration:14759  t-loss:0.0210, loss-lb:0.0159, loss-ulb:0.0025, weight:2.00, lr:0.0000
[02:28:27.631] iteration:14760  t-loss:0.0108, loss-lb:0.0092, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:28:28.006] iteration:14761  t-loss:0.0232, loss-lb:0.0209, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:28:28.386] iteration:14762  t-loss:0.0336, loss-lb:0.0249, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:28:28.781] iteration:14763  t-loss:0.0178, loss-lb:0.0094, loss-ulb:0.0042, weight:2.00, lr:0.0000
[02:28:29.186] iteration:14764  t-loss:0.0181, loss-lb:0.0160, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:28:29.581] iteration:14765  t-loss:0.0292, loss-lb:0.0091, loss-ulb:0.0100, weight:2.00, lr:0.0000
[02:28:29.965] iteration:14766  t-loss:0.0193, loss-lb:0.0171, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:28:30.340] iteration:14767  t-loss:0.0109, loss-lb:0.0092, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:28:30.717] iteration:14768  t-loss:0.0119, loss-lb:0.0100, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:28:31.098] iteration:14769  t-loss:0.0275, loss-lb:0.0237, loss-ulb:0.0019, weight:2.00, lr:0.0000
[02:28:31.476] iteration:14770  t-loss:0.0119, loss-lb:0.0103, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:28:31.853] iteration:14771  t-loss:0.0498, loss-lb:0.0087, loss-ulb:0.0206, weight:2.00, lr:0.0000
[02:28:32.231] iteration:14772  t-loss:0.0288, loss-lb:0.0170, loss-ulb:0.0059, weight:2.00, lr:0.0000
[02:28:32.603] iteration:14773  t-loss:0.0104, loss-lb:0.0087, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:28:32.977] iteration:14774  t-loss:0.0156, loss-lb:0.0128, loss-ulb:0.0014, weight:2.00, lr:0.0000
[02:28:33.351] iteration:14775  t-loss:0.0298, loss-lb:0.0200, loss-ulb:0.0049, weight:2.00, lr:0.0000
[02:28:33.724] iteration:14776  t-loss:0.0223, loss-lb:0.0199, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:28:34.095] iteration:14777  t-loss:0.0258, loss-lb:0.0119, loss-ulb:0.0069, weight:2.00, lr:0.0000
[02:28:34.470] iteration:14778  t-loss:0.0189, loss-lb:0.0084, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:28:34.848] iteration:14779  t-loss:0.0331, loss-lb:0.0242, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:28:35.227] iteration:14780  t-loss:0.0136, loss-lb:0.0122, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:28:35.610] iteration:14781  t-loss:0.0202, loss-lb:0.0115, loss-ulb:0.0043, weight:2.00, lr:0.0000
[02:28:35.993] iteration:14782  t-loss:0.0176, loss-lb:0.0155, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:29:37.603] iteration 14782 : dice_score: 0.895527 best_dice: 0.906000
[02:29:37.603]  <<Test>> - Ep:388  - Dice-S/T:90.56/89.55, Best-S:90.56, Best-T:90.60
[02:29:37.603]           - AvgLoss(lb/ulb/all):0.01/0.00/0.02
[02:29:38.729] iteration:14783  t-loss:0.0298, loss-lb:0.0211, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:29:39.133] iteration:14784  t-loss:0.0150, loss-lb:0.0107, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:29:39.517] iteration:14785  t-loss:0.0359, loss-lb:0.0105, loss-ulb:0.0127, weight:2.00, lr:0.0000
[02:29:39.897] iteration:14786  t-loss:0.0368, loss-lb:0.0175, loss-ulb:0.0097, weight:2.00, lr:0.0000
[02:29:40.281] iteration:14787  t-loss:0.0341, loss-lb:0.0206, loss-ulb:0.0068, weight:2.00, lr:0.0000
[02:29:40.669] iteration:14788  t-loss:0.0195, loss-lb:0.0087, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:29:41.055] iteration:14789  t-loss:0.0101, loss-lb:0.0084, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:29:41.442] iteration:14790  t-loss:0.0272, loss-lb:0.0164, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:29:41.826] iteration:14791  t-loss:0.0209, loss-lb:0.0189, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:29:42.210] iteration:14792  t-loss:0.0210, loss-lb:0.0084, loss-ulb:0.0063, weight:2.00, lr:0.0000
[02:29:42.604] iteration:14793  t-loss:0.0235, loss-lb:0.0161, loss-ulb:0.0037, weight:2.00, lr:0.0000
[02:29:42.995] iteration:14794  t-loss:0.0271, loss-lb:0.0164, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:29:43.376] iteration:14795  t-loss:0.0146, loss-lb:0.0084, loss-ulb:0.0031, weight:2.00, lr:0.0000
[02:29:43.759] iteration:14796  t-loss:0.0219, loss-lb:0.0092, loss-ulb:0.0063, weight:2.00, lr:0.0000
[02:29:44.150] iteration:14797  t-loss:0.0366, loss-lb:0.0164, loss-ulb:0.0101, weight:2.00, lr:0.0000
[02:29:44.534] iteration:14798  t-loss:0.0206, loss-lb:0.0095, loss-ulb:0.0055, weight:2.00, lr:0.0000
[02:29:44.917] iteration:14799  t-loss:0.0306, loss-lb:0.0191, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:29:45.307] iteration:14800  t-loss:0.0202, loss-lb:0.0177, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:29:45.687] iteration:14801  t-loss:0.0186, loss-lb:0.0175, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:29:46.068] iteration:14802  t-loss:0.0269, loss-lb:0.0238, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:29:46.453] iteration:14803  t-loss:0.0331, loss-lb:0.0225, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:29:46.837] iteration:14804  t-loss:0.0251, loss-lb:0.0218, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:29:47.221] iteration:14805  t-loss:0.0353, loss-lb:0.0189, loss-ulb:0.0082, weight:2.00, lr:0.0000
[02:29:47.606] iteration:14806  t-loss:0.0229, loss-lb:0.0102, loss-ulb:0.0063, weight:2.00, lr:0.0000
[02:29:47.985] iteration:14807  t-loss:0.0321, loss-lb:0.0281, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:29:48.368] iteration:14808  t-loss:0.0106, loss-lb:0.0084, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:29:48.753] iteration:14809  t-loss:0.0281, loss-lb:0.0169, loss-ulb:0.0056, weight:2.00, lr:0.0000
[02:29:49.135] iteration:14810  t-loss:0.0242, loss-lb:0.0076, loss-ulb:0.0083, weight:2.00, lr:0.0000
[02:29:49.516] iteration:14811  t-loss:0.0209, loss-lb:0.0101, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:29:49.902] iteration:14812  t-loss:0.0179, loss-lb:0.0144, loss-ulb:0.0017, weight:2.00, lr:0.0000
[02:29:50.286] iteration:14813  t-loss:0.0256, loss-lb:0.0179, loss-ulb:0.0038, weight:2.00, lr:0.0000
[02:29:50.668] iteration:14814  t-loss:0.0192, loss-lb:0.0183, loss-ulb:0.0004, weight:2.00, lr:0.0000
[02:29:51.048] iteration:14815  t-loss:0.0266, loss-lb:0.0184, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:29:51.425] iteration:14816  t-loss:0.0189, loss-lb:0.0173, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:29:51.807] iteration:14817  t-loss:0.0205, loss-lb:0.0090, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:29:52.189] iteration:14818  t-loss:0.0424, loss-lb:0.0080, loss-ulb:0.0172, weight:2.00, lr:0.0000
[02:29:52.572] iteration:14819  t-loss:0.0198, loss-lb:0.0105, loss-ulb:0.0047, weight:2.00, lr:0.0000
[02:29:52.952] iteration:14820  t-loss:0.0396, loss-lb:0.0269, loss-ulb:0.0064, weight:2.00, lr:0.0000
[02:29:54.289] iteration:14821  t-loss:0.0231, loss-lb:0.0087, loss-ulb:0.0072, weight:2.00, lr:0.0000
[02:29:54.686] iteration:14822  t-loss:0.0301, loss-lb:0.0113, loss-ulb:0.0094, weight:2.00, lr:0.0000
[02:29:55.071] iteration:14823  t-loss:0.0157, loss-lb:0.0083, loss-ulb:0.0037, weight:2.00, lr:0.0000
[02:29:55.451] iteration:14824  t-loss:0.0249, loss-lb:0.0129, loss-ulb:0.0060, weight:2.00, lr:0.0000
[02:29:55.838] iteration:14825  t-loss:0.0216, loss-lb:0.0173, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:29:56.225] iteration:14826  t-loss:0.0216, loss-lb:0.0149, loss-ulb:0.0033, weight:2.00, lr:0.0000
[02:29:56.608] iteration:14827  t-loss:0.0176, loss-lb:0.0081, loss-ulb:0.0047, weight:2.00, lr:0.0000
[02:29:56.988] iteration:14828  t-loss:0.0251, loss-lb:0.0114, loss-ulb:0.0069, weight:2.00, lr:0.0000
[02:29:57.367] iteration:14829  t-loss:0.0092, loss-lb:0.0078, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:29:57.745] iteration:14830  t-loss:0.0238, loss-lb:0.0174, loss-ulb:0.0032, weight:2.00, lr:0.0000
[02:29:58.124] iteration:14831  t-loss:0.0116, loss-lb:0.0101, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:29:58.522] iteration:14832  t-loss:0.0142, loss-lb:0.0073, loss-ulb:0.0035, weight:2.00, lr:0.0000
[02:29:58.924] iteration:14833  t-loss:0.0125, loss-lb:0.0113, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:29:59.321] iteration:14834  t-loss:0.0217, loss-lb:0.0074, loss-ulb:0.0072, weight:2.00, lr:0.0000
[02:29:59.717] iteration:14835  t-loss:0.0316, loss-lb:0.0142, loss-ulb:0.0087, weight:2.00, lr:0.0000
[02:30:00.111] iteration:14836  t-loss:0.0319, loss-lb:0.0119, loss-ulb:0.0100, weight:2.00, lr:0.0000
[02:30:00.492] iteration:14837  t-loss:0.0253, loss-lb:0.0098, loss-ulb:0.0078, weight:2.00, lr:0.0000
[02:30:00.872] iteration:14838  t-loss:0.0401, loss-lb:0.0102, loss-ulb:0.0150, weight:2.00, lr:0.0000
[02:30:01.257] iteration:14839  t-loss:0.0187, loss-lb:0.0099, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:30:01.639] iteration:14840  t-loss:0.0085, loss-lb:0.0074, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:30:02.017] iteration:14841  t-loss:0.0099, loss-lb:0.0082, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:30:02.400] iteration:14842  t-loss:0.0222, loss-lb:0.0104, loss-ulb:0.0059, weight:2.00, lr:0.0000
[02:30:02.777] iteration:14843  t-loss:0.0096, loss-lb:0.0073, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:30:03.165] iteration:14844  t-loss:0.0277, loss-lb:0.0177, loss-ulb:0.0050, weight:2.00, lr:0.0000
[02:30:03.552] iteration:14845  t-loss:0.0227, loss-lb:0.0215, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:30:03.963] iteration:14846  t-loss:0.0440, loss-lb:0.0352, loss-ulb:0.0044, weight:2.00, lr:0.0000
[02:30:04.349] iteration:14847  t-loss:0.0098, loss-lb:0.0075, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:30:04.727] iteration:14848  t-loss:0.0136, loss-lb:0.0095, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:30:05.104] iteration:14849  t-loss:0.0265, loss-lb:0.0204, loss-ulb:0.0031, weight:2.00, lr:0.0000
[02:30:05.486] iteration:14850  t-loss:0.0158, loss-lb:0.0144, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:30:05.863] iteration:14851  t-loss:0.0095, loss-lb:0.0083, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:30:06.261] iteration:14852  t-loss:0.0280, loss-lb:0.0164, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:30:06.634] iteration:14853  t-loss:0.0102, loss-lb:0.0079, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:30:07.011] iteration:14854  t-loss:0.0133, loss-lb:0.0098, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:30:07.385] iteration:14855  t-loss:0.0113, loss-lb:0.0092, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:30:07.761] iteration:14856  t-loss:0.0180, loss-lb:0.0081, loss-ulb:0.0049, weight:2.00, lr:0.0000
[02:30:08.134] iteration:14857  t-loss:0.0134, loss-lb:0.0105, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:30:08.513] iteration:14858  t-loss:0.0385, loss-lb:0.0088, loss-ulb:0.0148, weight:2.00, lr:0.0000
[02:30:09.741] iteration:14859  t-loss:0.0266, loss-lb:0.0253, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:30:10.130] iteration:14860  t-loss:0.1069, loss-lb:0.1051, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:30:10.506] iteration:14861  t-loss:0.0144, loss-lb:0.0104, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:30:10.882] iteration:14862  t-loss:0.0256, loss-lb:0.0242, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:30:11.253] iteration:14863  t-loss:0.0109, loss-lb:0.0089, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:30:11.636] iteration:14864  t-loss:0.0220, loss-lb:0.0112, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:30:12.019] iteration:14865  t-loss:0.0188, loss-lb:0.0094, loss-ulb:0.0047, weight:2.00, lr:0.0000
[02:30:12.390] iteration:14866  t-loss:0.0238, loss-lb:0.0198, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:30:12.766] iteration:14867  t-loss:0.0182, loss-lb:0.0100, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:30:13.143] iteration:14868  t-loss:0.0189, loss-lb:0.0096, loss-ulb:0.0046, weight:2.00, lr:0.0000
[02:30:13.521] iteration:14869  t-loss:0.0204, loss-lb:0.0083, loss-ulb:0.0060, weight:2.00, lr:0.0000
[02:30:13.901] iteration:14870  t-loss:0.0309, loss-lb:0.0205, loss-ulb:0.0052, weight:2.00, lr:0.0000
[02:30:14.279] iteration:14871  t-loss:0.0115, loss-lb:0.0075, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:30:14.671] iteration:14872  t-loss:0.0157, loss-lb:0.0126, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:30:15.081] iteration:14873  t-loss:0.0112, loss-lb:0.0097, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:30:15.469] iteration:14874  t-loss:0.0289, loss-lb:0.0121, loss-ulb:0.0084, weight:2.00, lr:0.0000
[02:30:15.846] iteration:14875  t-loss:0.0207, loss-lb:0.0186, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:30:16.223] iteration:14876  t-loss:0.0170, loss-lb:0.0099, loss-ulb:0.0035, weight:2.00, lr:0.0000
[02:30:16.600] iteration:14877  t-loss:0.0631, loss-lb:0.0080, loss-ulb:0.0275, weight:2.00, lr:0.0000
[02:30:16.975] iteration:14878  t-loss:0.0214, loss-lb:0.0193, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:30:17.357] iteration:14879  t-loss:0.0310, loss-lb:0.0234, loss-ulb:0.0038, weight:2.00, lr:0.0000
[02:30:17.738] iteration:14880  t-loss:0.0362, loss-lb:0.0216, loss-ulb:0.0073, weight:2.00, lr:0.0000
[02:30:18.116] iteration:14881  t-loss:0.0119, loss-lb:0.0084, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:30:18.494] iteration:14882  t-loss:0.0281, loss-lb:0.0216, loss-ulb:0.0032, weight:2.00, lr:0.0000
[02:30:18.890] iteration:14883  t-loss:0.0187, loss-lb:0.0178, loss-ulb:0.0005, weight:2.00, lr:0.0000
[02:30:19.311] iteration:14884  t-loss:0.0342, loss-lb:0.0217, loss-ulb:0.0062, weight:2.00, lr:0.0000
[02:30:19.710] iteration:14885  t-loss:0.0114, loss-lb:0.0092, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:30:20.089] iteration:14886  t-loss:0.0177, loss-lb:0.0153, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:30:20.470] iteration:14887  t-loss:0.0124, loss-lb:0.0088, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:30:20.853] iteration:14888  t-loss:0.0344, loss-lb:0.0186, loss-ulb:0.0079, weight:2.00, lr:0.0000
[02:30:21.228] iteration:14889  t-loss:0.0138, loss-lb:0.0097, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:30:21.601] iteration:14890  t-loss:0.0347, loss-lb:0.0306, loss-ulb:0.0020, weight:2.00, lr:0.0000
[02:30:21.978] iteration:14891  t-loss:0.0167, loss-lb:0.0096, loss-ulb:0.0035, weight:2.00, lr:0.0000
[02:30:22.356] iteration:14892  t-loss:0.0300, loss-lb:0.0173, loss-ulb:0.0064, weight:2.00, lr:0.0000
[02:30:22.730] iteration:14893  t-loss:0.0125, loss-lb:0.0099, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:30:23.105] iteration:14894  t-loss:0.0187, loss-lb:0.0171, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:30:23.483] iteration:14895  t-loss:0.0323, loss-lb:0.0086, loss-ulb:0.0118, weight:2.00, lr:0.0000
[02:30:23.858] iteration:14896  t-loss:0.0213, loss-lb:0.0104, loss-ulb:0.0055, weight:2.00, lr:0.0000
[02:30:25.108] iteration:14897  t-loss:0.0273, loss-lb:0.0238, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:30:25.529] iteration:14898  t-loss:0.0239, loss-lb:0.0229, loss-ulb:0.0005, weight:2.00, lr:0.0000
[02:30:25.919] iteration:14899  t-loss:0.0142, loss-lb:0.0119, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:30:26.307] iteration:14900  t-loss:0.0254, loss-lb:0.0192, loss-ulb:0.0031, weight:2.00, lr:0.0000
[02:30:26.690] iteration:14901  t-loss:0.0121, loss-lb:0.0098, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:30:27.069] iteration:14902  t-loss:0.0272, loss-lb:0.0242, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:30:27.450] iteration:14903  t-loss:0.0372, loss-lb:0.0221, loss-ulb:0.0075, weight:2.00, lr:0.0000
[02:30:27.831] iteration:14904  t-loss:0.0222, loss-lb:0.0214, loss-ulb:0.0004, weight:2.00, lr:0.0000
[02:30:28.213] iteration:14905  t-loss:0.0301, loss-lb:0.0226, loss-ulb:0.0037, weight:2.00, lr:0.0000
[02:30:28.591] iteration:14906  t-loss:0.0195, loss-lb:0.0080, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:30:28.968] iteration:14907  t-loss:0.0309, loss-lb:0.0103, loss-ulb:0.0103, weight:2.00, lr:0.0000
[02:30:29.347] iteration:14908  t-loss:0.0188, loss-lb:0.0177, loss-ulb:0.0005, weight:2.00, lr:0.0000
[02:30:29.732] iteration:14909  t-loss:0.0314, loss-lb:0.0232, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:30:30.121] iteration:14910  t-loss:0.0102, loss-lb:0.0084, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:30:30.528] iteration:14911  t-loss:0.0706, loss-lb:0.0077, loss-ulb:0.0315, weight:2.00, lr:0.0000
[02:30:30.929] iteration:14912  t-loss:0.0140, loss-lb:0.0105, loss-ulb:0.0018, weight:2.00, lr:0.0000
[02:30:31.323] iteration:14913  t-loss:0.0175, loss-lb:0.0097, loss-ulb:0.0039, weight:2.00, lr:0.0000
[02:30:31.710] iteration:14914  t-loss:0.0200, loss-lb:0.0187, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:30:32.101] iteration:14915  t-loss:0.0305, loss-lb:0.0189, loss-ulb:0.0058, weight:2.00, lr:0.0000
[02:30:32.488] iteration:14916  t-loss:0.0627, loss-lb:0.0512, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:30:32.871] iteration:14917  t-loss:0.0210, loss-lb:0.0104, loss-ulb:0.0053, weight:2.00, lr:0.0000
[02:30:33.262] iteration:14918  t-loss:0.0279, loss-lb:0.0171, loss-ulb:0.0054, weight:2.00, lr:0.0000
[02:30:33.643] iteration:14919  t-loss:0.0240, loss-lb:0.0104, loss-ulb:0.0068, weight:2.00, lr:0.0000
[02:30:34.028] iteration:14920  t-loss:0.0422, loss-lb:0.0192, loss-ulb:0.0115, weight:2.00, lr:0.0000
[02:30:34.415] iteration:14921  t-loss:0.0262, loss-lb:0.0129, loss-ulb:0.0067, weight:2.00, lr:0.0000
[02:30:34.804] iteration:14922  t-loss:0.0168, loss-lb:0.0083, loss-ulb:0.0042, weight:2.00, lr:0.0000
[02:30:35.193] iteration:14923  t-loss:0.0335, loss-lb:0.0187, loss-ulb:0.0074, weight:2.00, lr:0.0000
[02:30:35.575] iteration:14924  t-loss:0.0228, loss-lb:0.0092, loss-ulb:0.0068, weight:2.00, lr:0.0000
[02:30:35.964] iteration:14925  t-loss:0.0229, loss-lb:0.0204, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:30:36.342] iteration:14926  t-loss:0.0131, loss-lb:0.0089, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:30:36.726] iteration:14927  t-loss:0.0318, loss-lb:0.0199, loss-ulb:0.0059, weight:2.00, lr:0.0000
[02:30:37.105] iteration:14928  t-loss:0.0265, loss-lb:0.0244, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:30:37.486] iteration:14929  t-loss:0.0312, loss-lb:0.0246, loss-ulb:0.0033, weight:2.00, lr:0.0000
[02:30:37.860] iteration:14930  t-loss:0.0116, loss-lb:0.0089, loss-ulb:0.0013, weight:2.00, lr:0.0000
[02:30:38.236] iteration:14931  t-loss:0.0682, loss-lb:0.0467, loss-ulb:0.0108, weight:2.00, lr:0.0000
[02:30:38.617] iteration:14932  t-loss:0.0161, loss-lb:0.0133, loss-ulb:0.0014, weight:2.00, lr:0.0000
[02:30:38.997] iteration:14933  t-loss:0.0200, loss-lb:0.0141, loss-ulb:0.0029, weight:2.00, lr:0.0000
[02:30:39.376] iteration:14934  t-loss:0.0290, loss-lb:0.0199, loss-ulb:0.0046, weight:2.00, lr:0.0000
[02:31:45.027] iteration 14934 : dice_score: 0.906403 best_dice: 0.906400
[02:31:45.027]  <<Test>> - Ep:392  - Dice-S/T:90.58/90.64, Best-S:90.58, Best-T:90.64
[02:31:45.027]           - AvgLoss(lb/ulb/all):0.02/0.01/0.03
[02:31:46.127] iteration:14935  t-loss:0.0103, loss-lb:0.0089, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:31:46.521] iteration:14936  t-loss:0.0277, loss-lb:0.0159, loss-ulb:0.0059, weight:2.00, lr:0.0000
[02:31:46.901] iteration:14937  t-loss:0.0198, loss-lb:0.0183, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:31:47.282] iteration:14938  t-loss:0.0392, loss-lb:0.0233, loss-ulb:0.0079, weight:2.00, lr:0.0000
[02:31:47.664] iteration:14939  t-loss:0.0171, loss-lb:0.0156, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:31:48.039] iteration:14940  t-loss:0.0228, loss-lb:0.0114, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:31:48.414] iteration:14941  t-loss:0.0288, loss-lb:0.0194, loss-ulb:0.0047, weight:2.00, lr:0.0000
[02:31:48.792] iteration:14942  t-loss:0.0219, loss-lb:0.0188, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:31:49.166] iteration:14943  t-loss:0.0107, loss-lb:0.0091, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:31:49.547] iteration:14944  t-loss:0.0252, loss-lb:0.0177, loss-ulb:0.0037, weight:2.00, lr:0.0000
[02:31:49.924] iteration:14945  t-loss:0.0383, loss-lb:0.0249, loss-ulb:0.0067, weight:2.00, lr:0.0000
[02:31:50.303] iteration:14946  t-loss:0.0390, loss-lb:0.0241, loss-ulb:0.0075, weight:2.00, lr:0.0000
[02:31:50.681] iteration:14947  t-loss:0.0202, loss-lb:0.0179, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:31:51.058] iteration:14948  t-loss:0.0187, loss-lb:0.0154, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:31:51.433] iteration:14949  t-loss:0.0124, loss-lb:0.0100, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:31:51.812] iteration:14950  t-loss:0.0231, loss-lb:0.0074, loss-ulb:0.0079, weight:2.00, lr:0.0000
[02:31:52.187] iteration:14951  t-loss:0.0126, loss-lb:0.0104, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:31:52.569] iteration:14952  t-loss:0.0197, loss-lb:0.0099, loss-ulb:0.0049, weight:2.00, lr:0.0000
[02:31:52.949] iteration:14953  t-loss:0.0277, loss-lb:0.0163, loss-ulb:0.0057, weight:2.00, lr:0.0000
[02:31:53.332] iteration:14954  t-loss:0.0247, loss-lb:0.0112, loss-ulb:0.0067, weight:2.00, lr:0.0000
[02:31:53.712] iteration:14955  t-loss:0.0242, loss-lb:0.0195, loss-ulb:0.0023, weight:2.00, lr:0.0000
[02:31:54.092] iteration:14956  t-loss:0.0304, loss-lb:0.0174, loss-ulb:0.0065, weight:2.00, lr:0.0000
[02:31:54.471] iteration:14957  t-loss:0.0194, loss-lb:0.0073, loss-ulb:0.0061, weight:2.00, lr:0.0000
[02:31:54.851] iteration:14958  t-loss:0.0196, loss-lb:0.0165, loss-ulb:0.0016, weight:2.00, lr:0.0000
[02:31:55.226] iteration:14959  t-loss:0.0156, loss-lb:0.0096, loss-ulb:0.0030, weight:2.00, lr:0.0000
[02:31:55.608] iteration:14960  t-loss:0.0265, loss-lb:0.0167, loss-ulb:0.0049, weight:2.00, lr:0.0000
[02:31:55.985] iteration:14961  t-loss:0.0164, loss-lb:0.0095, loss-ulb:0.0035, weight:2.00, lr:0.0000
[02:31:56.359] iteration:14962  t-loss:0.0158, loss-lb:0.0098, loss-ulb:0.0030, weight:2.00, lr:0.0000
[02:31:56.738] iteration:14963  t-loss:0.0196, loss-lb:0.0146, loss-ulb:0.0025, weight:2.00, lr:0.0000
[02:31:57.117] iteration:14964  t-loss:0.0680, loss-lb:0.0506, loss-ulb:0.0087, weight:2.00, lr:0.0000
[02:31:57.492] iteration:14965  t-loss:0.0177, loss-lb:0.0166, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:31:57.865] iteration:14966  t-loss:0.0120, loss-lb:0.0108, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:31:58.238] iteration:14967  t-loss:0.0117, loss-lb:0.0094, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:31:58.611] iteration:14968  t-loss:0.0085, loss-lb:0.0076, loss-ulb:0.0004, weight:2.00, lr:0.0000
[02:31:58.989] iteration:14969  t-loss:0.0205, loss-lb:0.0088, loss-ulb:0.0059, weight:2.00, lr:0.0000
[02:31:59.366] iteration:14970  t-loss:0.0278, loss-lb:0.0103, loss-ulb:0.0087, weight:2.00, lr:0.0000
[02:31:59.746] iteration:14971  t-loss:0.0360, loss-lb:0.0196, loss-ulb:0.0082, weight:2.00, lr:0.0000
[02:32:00.123] iteration:14972  t-loss:0.0228, loss-lb:0.0148, loss-ulb:0.0040, weight:2.00, lr:0.0000
[02:32:01.318] iteration:14973  t-loss:0.0453, loss-lb:0.0305, loss-ulb:0.0074, weight:2.00, lr:0.0000
[02:32:01.715] iteration:14974  t-loss:0.0119, loss-lb:0.0098, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:32:02.098] iteration:14975  t-loss:0.0138, loss-lb:0.0114, loss-ulb:0.0012, weight:2.00, lr:0.0000
[02:32:02.479] iteration:14976  t-loss:0.0876, loss-lb:0.0186, loss-ulb:0.0345, weight:2.00, lr:0.0000
[02:32:02.859] iteration:14977  t-loss:0.0225, loss-lb:0.0145, loss-ulb:0.0040, weight:2.00, lr:0.0000
[02:32:03.233] iteration:14978  t-loss:0.0141, loss-lb:0.0126, loss-ulb:0.0008, weight:2.00, lr:0.0000
[02:32:03.610] iteration:14979  t-loss:0.0111, loss-lb:0.0098, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:32:03.986] iteration:14980  t-loss:0.0225, loss-lb:0.0097, loss-ulb:0.0064, weight:2.00, lr:0.0000
[02:32:04.364] iteration:14981  t-loss:0.0094, loss-lb:0.0082, loss-ulb:0.0006, weight:2.00, lr:0.0000
[02:32:04.739] iteration:14982  t-loss:0.0184, loss-lb:0.0163, loss-ulb:0.0011, weight:2.00, lr:0.0000
[02:32:05.125] iteration:14983  t-loss:0.0319, loss-lb:0.0177, loss-ulb:0.0071, weight:2.00, lr:0.0000
[02:32:05.503] iteration:14984  t-loss:0.0097, loss-lb:0.0076, loss-ulb:0.0010, weight:2.00, lr:0.0000
[02:32:05.884] iteration:14985  t-loss:0.0195, loss-lb:0.0166, loss-ulb:0.0015, weight:2.00, lr:0.0000
[02:32:06.260] iteration:14986  t-loss:0.0903, loss-lb:0.0096, loss-ulb:0.0403, weight:2.00, lr:0.0000
[02:32:06.635] iteration:14987  t-loss:0.0094, loss-lb:0.0081, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:32:07.011] iteration:14988  t-loss:0.0118, loss-lb:0.0100, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:32:07.389] iteration:14989  t-loss:0.0108, loss-lb:0.0091, loss-ulb:0.0009, weight:2.00, lr:0.0000
[02:32:07.767] iteration:14990  t-loss:0.0468, loss-lb:0.0284, loss-ulb:0.0092, weight:2.00, lr:0.0000
[02:32:08.149] iteration:14991  t-loss:0.0402, loss-lb:0.0190, loss-ulb:0.0106, weight:2.00, lr:0.0000
[02:32:08.525] iteration:14992  t-loss:0.0117, loss-lb:0.0075, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:32:08.901] iteration:14993  t-loss:0.0111, loss-lb:0.0096, loss-ulb:0.0007, weight:2.00, lr:0.0000
[02:32:09.285] iteration:14994  t-loss:0.0326, loss-lb:0.0169, loss-ulb:0.0079, weight:2.00, lr:0.0000
[02:32:09.668] iteration:14995  t-loss:0.0303, loss-lb:0.0149, loss-ulb:0.0077, weight:2.00, lr:0.0000
[02:32:10.046] iteration:14996  t-loss:0.0183, loss-lb:0.0106, loss-ulb:0.0038, weight:2.00, lr:0.0000
[02:32:10.424] iteration:14997  t-loss:0.0186, loss-lb:0.0099, loss-ulb:0.0043, weight:2.00, lr:0.0000
[02:32:10.800] iteration:14998  t-loss:0.0201, loss-lb:0.0078, loss-ulb:0.0062, weight:2.00, lr:0.0000
[02:32:11.181] iteration:14999  t-loss:0.0236, loss-lb:0.0155, loss-ulb:0.0041, weight:2.00, lr:0.0000
[02:32:11.560] iteration:15000  t-loss:0.0159, loss-lb:0.0117, loss-ulb:0.0021, weight:2.00, lr:0.0000
[02:33:08.110] iteration 15000 : dice_score: 0.904993 best_dice: 0.906400
[02:33:08.110]  <<Test>> - Ep:394  - Dice-S/T:90.44/90.50, Best-S:90.58, Best-T:90.64
[02:33:08.110]           - AvgLoss(lb/ulb/all):0.01/0.01/0.02
[02:33:08.163] save model to ./results/LA/omega_test/v_hist_weight_0.5_4_labeled/vnet_hsseg/last.pth
